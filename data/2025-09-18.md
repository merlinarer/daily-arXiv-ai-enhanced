<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 40]
- [cs.CV](#cs.CV) [Total: 40]
- [cs.AI](#cs.AI) [Total: 35]
- [cs.LG](#cs.LG) [Total: 41]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12](https://arxiv.org/abs/2509.13569)
*John Mendonça,Lining Zhang,Rahul Mallidi,Alon Lavie,Isabel Trancoso,Luis Fernando D'Haro,João Sedoc*

Main category: cs.CL

Relevance: 85.0

TL;DR: DSTC12 Track 1 提出对话系统评估新方法，包含多维度自动评估和多语言文化安全检测两个子任务，发现现有方法在文化感知安全方面存在显著不足


<details>
  <summary>Details</summary>
Motivation: 大型语言模型快速发展需要更鲁棒的对话系统评估方法，传统指标不足且安全考虑存在文化偏见，需要解决这些关键差距

Method: 使用两个子任务：1）对话级多维度自动评估指标（10个维度），2）多语言和多文化安全检测。提供数据集和基线模型（Llama-3-8B和Llama-Guard-3-1B）

Result: 任务1中Llama-3-8B基线获得最高平均Spearman相关系数0.1681，显示有巨大改进空间；任务2中参与团队在多语言安全子集上显著优于基线（最佳ROC-AUC 0.9648），但基线在文化子集上表现更好（0.5126 ROC-AUC）

Conclusion: 对话系统评估仍需重大改进，特别是在文化感知安全方面存在关键需求，需要开发更全面的评估框架

Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the
need for robust dialogue system evaluation, yet comprehensive assessment
remains challenging. Traditional metrics often prove insufficient, and safety
considerations are frequently narrowly defined or culturally biased. The DSTC12
Track 1, "Dialog System Evaluation: Dimensionality, Language, Culture and
Safety," is part of the ongoing effort to address these critical gaps. The
track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic
Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.
For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved
the highest average Spearman's correlation (0.1681), indicating substantial
room for improvement. In Task 2, while participating teams significantly
outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top
ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126
ROC-AUC), highlighting critical needs in culturally-aware safety. This paper
describes the datasets and baselines provided to participants, as well as
submission evaluation results for each of the two proposed subtasks.

</details>


### [2] [Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](https://arxiv.org/abs/2509.13624)
*Shambhavi Krishna,Atharva Naik,Chaitali Agarwal,Sudharshan Govindan,Taesung Lee,Haw-Shiuan Chang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一个分析框架来研究LLM跨任务迁移学习中的潜在能力和副作用，发现表面数据集相似性不如隐藏统计因素和语言特征对性能提升的影响大


<details>
  <summary>Details</summary>
Motivation: 由于无法为所有任务枚举高质量训练数据，需要依赖不同特征数据集的迁移学习来处理分布外请求，因此需要分析跨任务交互的复杂动态

Method: 构建迁移学习矩阵和降维分析框架，训练10个模型来识别潜在能力（推理、情感分类、自然语言理解、算术等）并发现迁移学习的副作用

Result: 性能提升往往无法用表面数据集相似性或源数据质量解释，而是受源数据集的隐藏统计因素（如类别分布、生成长度倾向）和特定语言特征影响更大

Conclusion: 这项工作揭示了迁移学习的复杂动态，为更可预测和有效的LLM适应铺平了道路

Abstract: Large language models are increasingly deployed across diverse applications.
This often includes tasks LLMs have not encountered during training. This
implies that enumerating and obtaining the high-quality training data for all
tasks is infeasible. Thus, we often need to rely on transfer learning using
datasets with different characteristics, and anticipate out-of-distribution
requests. Motivated by this practical need, we propose an analysis framework,
building a transfer learning matrix and dimensionality reduction, to dissect
these cross-task interactions. We train and analyze 10 models to identify
latent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)
and discover the side effects of the transfer learning. Our findings reveal
that performance improvements often defy explanations based on surface-level
dataset similarity or source data quality. Instead, hidden statistical factors
of the source dataset, such as class distribution and generation length
proclivities, alongside specific linguistic features, are actually more
influential. This work offers insights into the complex dynamics of transfer
learning, paving the way for more predictable and effective LLM adaptation.

</details>


### [3] [Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs](https://arxiv.org/abs/2509.13664)
*Zhuoxuan Zhang,Jinhao Duan,Edward Kim,Kaidi Xu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现LLMs在内部表征中线性编码问题模糊性，通过少量神经元即可检测和控制模糊性，使模型从直接回答转向弃权


<details>
  <summary>Details</summary>
Motivation: 现实问题中普遍存在模糊性，但LLMs往往自信回答而非寻求澄清，需要理解LLMs如何处理模糊性问题

Method: 在模型预填充阶段识别模糊性编码神经元(AENs)，训练探针进行模糊性检测，通过神经元操作控制模型行为

Result: 仅需1个神经元即可编码模糊性信息，探针性能优于基于提示和表征的基线方法，AENs从浅层出现，可通过操作控制模型行为

Conclusion: LLMs形成紧凑的内部模糊性表征，实现了可解释和可控的行为

Abstract: Ambiguity is pervasive in real-world questions, yet large language models
(LLMs) often respond with confident answers rather than seeking clarification.
In this work, we show that question ambiguity is linearly encoded in the
internal representations of LLMs and can be both detected and controlled at the
neuron level. During the model's pre-filling stage, we identify that a small
number of neurons, as few as one, encode question ambiguity information. Probes
trained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance
on ambiguity detection and generalize across datasets, outperforming
prompting-based and representation-based baselines. Layerwise analysis reveals
that AENs emerge from shallow layers, suggesting early encoding of ambiguity
signals in the model's processing pipeline. Finally, we show that through
manipulating AENs, we can control LLM's behavior from direct answering to
abstention. Our findings reveal that LLMs form compact internal representations
of question ambiguity, enabling interpretable and controllable behavior.

</details>


### [4] [AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation](https://arxiv.org/abs/2509.13677)
*Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: AgentCTG是一个基于多智能体工作流的可控文本生成框架，通过模拟多智能体协作机制实现细粒度控制，在多个数据集上达到SOTA效果，并在角色驱动重写任务中验证了实用性。


<details>
  <summary>Details</summary>
Motivation: 解决可控文本生成(CTG)中细粒度条件控制的挑战，满足实际应用中成本、可扩展性、领域知识学习和精确控制的需求。

Method: 提出AgentCTG框架，模拟多智能体工作流中的控制和调节机制，探索不同智能体间的协作方法，并引入自动提示模块来提升生成效果。

Result: 在多个公开数据集上达到state-of-the-art效果；在角色驱动重写任务中成功将原始文本转换为符合特定角色配置文件的新文本，同时保留领域知识；在线导航角色扮演应用中显著提升了驾驶体验。

Conclusion: AgentCTG通过多智能体协作机制有效解决了可控文本生成的细粒度控制问题，在实用场景中表现出色，能够生成更具上下文相关性的文本，提升用户沉浸感和参与度。

Abstract: Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.

</details>


### [5] [Improving Context Fidelity via Native Retrieval-Augmented Reasoning](https://arxiv.org/abs/2509.13683)
*Suyuchen Wang,Jinlin Wang,Xinyu Wang,Shiqi Li,Xiangru Tang,Sirui Hong,Xiao-Wen Chang,Chenglin Wu,Bang Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: CARE框架通过教导LLM在推理过程中显式整合上下文证据，显著提升了检索准确性和答案生成性能，无需昂贵监督微调


<details>
  <summary>Details</summary>
Motivation: 解决LLM在基于给定信息回答问题时存在的上下文保真度问题，现有方法要么依赖昂贵的监督微调，要么训练模型进行网络搜索但未能有效利用给定上下文

Method: 提出CARE框架，教导LLM利用自身检索能力在推理过程中显式整合上下文证据，使用有限的标注证据数据，通过策略性检索的上下文标记增强推理链

Result: 在多个真实世界和反事实QA基准测试中，该方法显著优于监督微调、传统检索增强生成方法和外部检索解决方案

Conclusion: 这项工作是使LLM在知识密集型任务中更加准确、可靠和高效的根本性进展

Abstract: Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.

</details>


### [6] [DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models](https://arxiv.org/abs/2509.13702)
*Xiao Zheng*

Main category: cs.CL

Relevance: 85.0

TL;DR: DSCC-HS是一个主动式幻觉抑制框架，通过在自回归解码过程中注入实时引导向量来动态校准LLM输出，无需修改目标模型，在TruthfulQA和BioGEN基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM幻觉问题，当前方法如RAG多为被动式，需要一种主动干预解码过程的方法来提升事实准确性。

Method: 基于双过程认知理论，使用紧凑代理模型训练事实对齐代理(FAP)和幻觉检测代理(HDP)，在推理时通过计算两者logits差异生成实时引导向量，动态引导大模型解码。

Result: 在TruthfulQA上达到99.2%事实一致性率，在BioGEN长文本基准上获得最高FActScore 46.50。

Conclusion: DSCC-HS提供了一个原则性且高效的解决方案，能够显著增强LLM的事实性。

Abstract: Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.

</details>


### [7] [DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning](https://arxiv.org/abs/2509.13723)
*Yaxin Gao,Yao Lu,Zongfei Zhang,Jiaqi Nie,Shanqing Yu,Qi Xuan*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出DSPC双阶段训练无关的提示压缩方法，通过语义筛选和token剪枝在减少3倍token的情况下提升性能7.76分


<details>
  <summary>Details</summary>
Motivation: 解决LLM提示越来越长导致计算成本增加的问题，现有方法需要训练辅助模型带来额外计算开销

Method: 两阶段无训练方法：粗粒度阶段基于TF-IDF进行语义相关句子过滤；细粒度阶段使用注意力贡献、跨模型损失差异和位置重要性评估token重要性进行剪枝

Result: 在LLaMA-3.1-8B-Instruct和GPT-3.5-Turbo上验证，在Longbench FewShot任务中仅用3倍少token达到49.17性能，超越最佳基线LongLLMLingua 7.76分

Conclusion: DSPC提供了一种高效的无训练提示压缩方案，显著减少计算成本同时保持语义完整性

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language processing (NLP) tasks. To achieve more accurate output, the prompts
used to drive LLMs have become increasingly longer, which incurs higher
computational costs. To address this prompt inflation problem, prompt
compression has been proposed. However, most existing methods require training
a small auxiliary model for compression, incurring a significant amount of
additional computation. To avoid this, we propose a two-stage, training-free
approach, called Dual-Stage Progressive Compression (DSPC). In the
coarse-grained stage, semantic-related sentence filtering removes sentences
with low semantic value based on TF-IDF. In the fine-grained stage, token
importance is assessed using attention contribution, cross-model loss
difference, and positional importance, enabling the pruning of low-utility
tokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct
and GPT-3.5-Turbo under a constrained token budget and observe consistent
improvements. For instance, in the FewShot task of the Longbench dataset, DSPC
achieves a performance of 49.17 by using only 3x fewer tokens, outperforming
the best state-of-the-art baseline LongLLMLingua by 7.76.

</details>


### [8] [Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning](https://arxiv.org/abs/2509.13790)
*Yangning Li,Tingwei Lu,Yinghui Li,Yankai Chen,Wei-Chieh Huang,Wenhao Jiang,Hui Wang,Hai-Tao Zheng,Philip S. Yu*

Main category: cs.CL

Relevance: 85.0

TL;DR: CAMPUS是一个动态多视角课程学习框架，通过能力感知的课程调度和动态子课程选择，解决了传统指令调优中课程刚性问题，显著提升了LLM的指令调优效率。


<details>
  <summary>Details</summary>
Motivation: 传统指令调优方法依赖静态启发式难度度量，存在课程刚性问题，无法适应模型在训练过程中的能力演变，导致学习轨迹固定且可能次优。

Method: 提出CAMPUS框架，包含：1）动态子课程选择；2）能力感知的课程调度调整；3）多难度基础调度策略。

Result: 大量实验证明CAMPUS在高效指令调优方面优于其他最先进基线方法。

Conclusion: CAMPUS通过动态适应模型能力演变的课程学习策略，有效解决了指令调优中的课程刚性问题，提升了训练效率和最终性能。

Abstract: Efficient instruction tuning aims to enhance the ultimate performance of
large language models (LLMs) trained on a given instruction dataset. Curriculum
learning as a typical data organization strategy has shown preliminary
effectiveness in instruction tuning. However, current curriculum tuning methods
suffer from the curriculum rigidity, since they rely solely on static heuristic
difficulty metrics. These methods fail to adapt to the evolving capabilities of
models during training, resulting in a fixed and potentially sub-optimal
learning trajectory. To address the issue, Competence-Aware Multi-Perspective
cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS
offers several advantages: (1) Dynamic selection for sub-curriculum. (2)
Competency-aware adjustment to the curriculum schedule. (3) Multiple
difficulty-based scheduling. Extensive experiments prove the superior
performance of CAMPUS, compared to other state-of-the-art baselines for
efficient instruction tuning.

</details>


### [9] [Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs](https://arxiv.org/abs/2509.13813)
*Edward Phillips,Sean Wu,Soheila Molaei,Danielle Belgrave,Anshul Thakur,David Clifton*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文提出了一个基于几何框架的黑盒不确定性量化方法，通过原型分析来同时估计全局和局部不确定性，用于检测大语言模型的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在幻觉问题，生成看似合理但错误的答案。现有黑盒方法只能提供全局不确定性估计，而局部方法需要白盒访问权限。需要一种黑盒方法同时支持全局和局部不确定性量化。

Method: 基于原型分析的几何框架：1) 全局层面使用几何体积(Geometric Volume)测量响应嵌入的原型凸包体积；2) 局部层面使用几何怀疑度(Geometric Suspicion)对响应可靠性进行排名，通过优先选择实现幻觉减少。

Result: 在短形式问答数据集上表现优于或与现有方法相当，在医疗数据集上表现更优（幻觉风险更高）。理论证明凸包体积与熵之间存在联系。

Conclusion: 提出的几何框架为黑盒不确定性量化提供了有效解决方案，能够同时处理全局和局部不确定性，在关键风险领域（如医疗）特别有价值。

Abstract: Large language models demonstrate impressive results across diverse tasks but
are still known to hallucinate, generating linguistically plausible but
incorrect answers to questions. Uncertainty quantification has been proposed as
a strategy for hallucination detection, but no existing black-box approach
provides estimates for both global and local uncertainty. The former attributes
uncertainty to a batch of responses, while the latter attributes uncertainty to
individual responses. Current local methods typically rely on white-box access
to internal model states, whilst black-box methods only provide global
uncertainty estimates. We introduce a geometric framework to address this,
based on archetypal analysis of batches of responses sampled with only
black-box model access. At the global level, we propose Geometric Volume, which
measures the convex hull volume of archetypes derived from response embeddings.
At the local level, we propose Geometric Suspicion, which ranks responses by
reliability and enables hallucination reduction through preferential response
selection. Unlike prior dispersion methods which yield only a single global
score, our approach provides semantic boundary points which have utility for
attributing reliability to individual responses. Experiments show that our
framework performs comparably to or better than prior methods on short form
question-answering datasets, and achieves superior results on medical datasets
where hallucinations carry particularly critical risks. We also provide
theoretical justification by proving a link between convex hull volume and
entropy.

</details>


### [10] [Large Language Models Discriminate Against Speakers of German Dialects](https://arxiv.org/abs/2509.13835)
*Minh Duc Bui,Carolin Holtermann,Valentin Hofmann,Anne Lauscher,Katharina von der Wense*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究分析了大型语言模型对德国方言使用者的偏见，发现所有测试的LLM都表现出显著的方言命名和使用偏见，且在决策中复制这些偏见，明确标注方言使用者身份会放大偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是调查社会语言学中方言使用者的负面刻板印象是否在大型语言模型中重现，德国有超过40%人口使用方言但面临社会偏见。

Method: 基于社会语言学文献构建评估框架，通过关联任务和决策任务评估方言命名偏见和使用偏见，创建了包含7种德国方言与标准德语对照的新评估语料库。

Result: 所有评估的LLM都表现出显著的方言偏见，体现在负面形容词关联上；模型在决策中复制这些偏见；明确标注方言使用者身份比隐式线索更能放大偏见。

Conclusion: LLM确实反映了社会中对方言使用者的刻板印象偏见，需要开发方法来减轻这种语言偏见，特别是在多语言和多方言环境中。

Abstract: Dialects represent a significant component of human culture and are found
across all regions of the world. In Germany, more than 40% of the population
speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural
importance, individuals speaking dialects often face negative societal
stereotypes. We examine whether such stereotypes are mirrored by large language
models (LLMs). We draw on the sociolinguistic literature on dialect perception
to analyze traits commonly associated with dialect speakers. Based on these
traits, we assess the dialect naming bias and dialect usage bias expressed by
LLMs in two tasks: an association task and a decision task. To assess a model's
dialect usage bias, we construct a novel evaluation corpus that pairs sentences
from seven regional German dialects (e.g., Alemannic and Bavarian) with their
standard German counterparts. We find that: (1) in the association task, all
evaluated LLMs exhibit significant dialect naming and dialect usage bias
against German dialect speakers, reflected in negative adjective associations;
(2) all models reproduce these dialect naming and dialect usage biases in their
decision making; and (3) contrary to prior work showing minimal bias with
explicit demographic mentions, we find that explicitly labeling linguistic
demographics--German dialect speakers--amplifies bias more than implicit cues
like dialect usage.

</details>


### [11] [Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs](https://arxiv.org/abs/2509.13869)
*Yang Liu,Chenhui Chu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究调查了大语言模型在不同类型偏见场景中与人类价值观的对齐情况，发现模型参数规模与对齐程度无必然联系，模型对特定场景类型有对齐偏好，且同家族模型判断一致性更高。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在复杂敏感的社会偏见场景中与人类价值观的对齐差异，特别是不同类型场景（如包含负面与非负面问题）下的对齐表现。

Method: 通过对4个模型家族的12个LLM在4个数据集上进行广泛分析，评估模型的对齐率、攻击成功率、判断一致性，并研究模型对HVSB的理解能力。

Result: 大参数模型不一定有更低的对齐错误率和攻击成功率；模型对特定场景类型有对齐偏好；同家族模型判断一致性更高；模型对HVSB理解无显著差异；模型偏好自身生成的解释。

Conclusion: LLM与人类价值观的对齐存在场景类型依赖性，模型规模不是对齐质量的保证，需要更细粒度的对齐评估方法。

Abstract: Large language models (LLMs) can lead to undesired consequences when
misaligned with human values, especially in scenarios involving complex and
sensitive social biases. Previous studies have revealed the misalignment of
LLMs with human values using expert-designed or agent-based emulated bias
scenarios. However, it remains unclear whether the alignment of LLMs with human
values differs across different types of scenarios (e.g., scenarios containing
negative vs. non-negative questions). In this study, we investigate the
alignment of LLMs with human values regarding social biases (HVSB) in different
types of bias scenarios. Through extensive analysis of 12 LLMs from four model
families and four datasets, we demonstrate that LLMs with large model parameter
scales do not necessarily have lower misalignment rate and attack success rate.
Moreover, LLMs show a certain degree of alignment preference for specific types
of scenarios and the LLMs from the same model family tend to have higher
judgment consistency. In addition, we study the understanding capacity of LLMs
with their explanations of HVSB. We find no significant differences in the
understanding of HVSB across LLMs. We also find LLMs prefer their own generated
explanations. Additionally, we endow smaller language models (LMs) with the
ability to explain HVSB. The generation results show that the explanations
generated by the fine-tuned smaller LMs are more readable, but have a
relatively lower model agreeability.

</details>


### [12] [Do Large Language Models Understand Word Senses?](https://arxiv.org/abs/2509.13905)
*Domenico Meconi,Simone Stirpe,Federico Martelli,Leonardo Lavalle,Roberto Navigli*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文评估了指令调优LLM在词义消歧(WSD)任务中的能力，并与专用WSD系统进行比较，同时测试了LLM在定义生成、自由解释和示例生成三种生成任务中的词义理解能力。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在语言理解方面取得了显著进展，但其是否真正掌握词义理解的能力尚未得到充分探索。论文旨在填补这一空白，系统评估LLM在词义消歧和词义解释方面的表现。

Method: 采用两种评估方法：1) 将指令调优LLM与最先进的专用WSD系统在词义消歧任务上进行性能比较；2) 测试顶级开源和闭源LLM在三种生成任务（定义生成、自由形式解释、示例生成）中的词义理解能力。

Result: 研究发现：GPT-4o和DeepSeek-V3等领先模型在WSD任务中达到与专用WSD系统相当的性能，且在跨领域和不同难度级别上表现出更强的鲁棒性。在生成任务中，LLM能够以高达98%的准确率解释上下文中的词义，其中自由解释任务表现最佳。

Conclusion: LLM不仅能够与专用系统相媲美地执行词义消歧任务，还展现出强大的词义解释生成能力，特别是在自由形式的解释任务中表现最为出色，这与其生成能力高度契合。

Abstract: Understanding the meaning of words in context is a fundamental capability for
Large Language Models (LLMs). Despite extensive evaluation efforts, the extent
to which LLMs show evidence that they truly grasp word senses remains
underexplored. In this paper, we address this gap by evaluating both i) the
Word Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,
comparing their performance to state-of-the-art systems specifically designed
for the task, and ii) the ability of two top-performing open- and closed-source
LLMs to understand word senses in three generative settings: definition
generation, free-form explanation, and example generation. Notably, we find
that, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve
performance on par with specialized WSD systems, while also demonstrating
greater robustness across domains and levels of difficulty. In the generation
tasks, results reveal that LLMs can explain the meaning of words in context up
to 98\% accuracy, with the highest performance observed in the free-form
explanation task, which best aligns with their generative capabilities.

</details>


### [13] [Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency](https://arxiv.org/abs/2509.13990)
*Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov*

Main category: cs.CL

Relevance: 85.0

TL;DR: Slim-SC是一种通过思维级链间相似性识别和移除冗余链的逐步剪枝策略，显著降低Self-Consistency的计算开销，同时保持或提高推理准确性。


<details>
  <summary>Details</summary>
Motivation: Self-Consistency(SC)通过并行生成多个推理链并多数投票选择最终答案来提升LLM推理性能，但其数量级计算开销限制了广泛应用。现有加速方法主要依赖模型置信度分数或经验启发式方法，缺乏理论支持。

Method: 提出Slim-SC方法：1）理论分析SC的低效性并识别改进机会；2）在思维层面使用链间相似性识别冗余链；3）采用逐步剪枝策略移除冗余链

Result: 在三个STEM推理数据集和两种LLM架构上的实验表明：推理延迟降低高达45%，KVC使用减少26%（使用R1-Distill），同时保持或提高准确性

Conclusion: Slim-SC为SC提供了一种简单而高效的测试时缩放替代方案，显著降低了计算开销

Abstract: Recently, Test-Time Scaling (TTS) has gained increasing attention for
improving LLM reasoning performance at test time without retraining the model.
A notable TTS technique is Self-Consistency (SC), which generates multiple
reasoning chains in parallel and selects the final answer via majority voting.
While effective, the order-of-magnitude computational overhead limits its broad
deployment. Prior attempts to accelerate SC mainly rely on model-based
confidence scores or heuristics with limited empirical support. For the first
time, we theoretically and empirically analyze the inefficiencies of SC and
reveal actionable opportunities for improvement. Building on these insights, we
propose Slim-SC, a step-wise pruning strategy that identifies and removes
redundant chains using inter-chain similarity at the thought level. Experiments
on three STEM reasoning datasets and two recent LLM architectures show that
Slim-SC reduces inference latency and KVC usage by up to 45% and 26%,
respectively, with R1-Distill, while maintaining or improving accuracy, thus
offering a simple yet efficient TTS alternative for SC.

</details>


### [14] [Early Stopping Chain-of-thoughts in Large Language Models](https://arxiv.org/abs/2509.14004)
*Minjia Mao,Bowen Yin,Yu Zhu,Xiao Fang*

Main category: cs.CL

Relevance: 85.0

TL;DR: ES-CoT是一种推理时方法，通过检测答案收敛性来提前停止思维链生成，在保持准确性的同时平均减少41%的推理token使用


<details>
  <summary>Details</summary>
Motivation: 现有的思维链推理方法生成长链思维过程，导致高昂的推理成本。需要一种方法能够在保持性能的同时减少推理开销

Method: 在每个推理步骤结束时提示LLM输出当前最终答案（步骤答案），跟踪连续相同步骤答案的运行长度作为收敛度量。当运行长度出现急剧增加并超过最小阈值时终止生成

Result: 在5个推理数据集和3个LLM上的实验表明，ES-CoT平均减少约41%的推理token，同时保持与标准思维链相当的准确性。该方法还能与自一致性提示无缝集成

Conclusion: ES-CoT是一种实用有效的推理效率提升方法，通过检测答案收敛性实现早期停止，在保持性能的同时显著降低推理成本

Abstract: Reasoning large language models (LLMs) have demonstrated superior capacities
in solving complicated problems by generating long chain-of-thoughts (CoT), but
such a lengthy CoT incurs high inference costs. In this study, we introduce
ES-CoT, an inference-time method that shortens CoT generation by detecting
answer convergence and stopping early with minimal performance loss. At the end
of each reasoning step, we prompt the LLM to output its current final answer,
denoted as a step answer. We then track the run length of consecutive identical
step answers as a measure of answer convergence. Once the run length exhibits a
sharp increase and exceeds a minimum threshold, the generation is terminated.
We provide both empirical and theoretical support for this heuristic: step
answers steadily converge to the final answer, and large run-length jumps
reliably mark this convergence. Experiments on five reasoning datasets across
three LLMs show that ES-CoT reduces the number of inference tokens by about
41\% on average while maintaining accuracy comparable to standard CoT. Further,
ES-CoT integrates seamlessly with self-consistency prompting and remains robust
across hyperparameter choices, highlighting it as a practical and effective
approach for efficient reasoning.

</details>


### [15] [Enhancing Multi-Agent Debate System Performance via Confidence Expression](https://arxiv.org/abs/2509.14034)
*Zijie Lin,Bryan Hooi*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了ConfMAD框架，在多智能体辩论系统中引入置信度表达机制，以解决LLM在辩论中难以清晰传达知识优势和避免错误坚持或过早收敛的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体辩论系统中，LLM缺乏置信度表达机制，导致即使某些模型具有更好的知识或推理能力，也无法在辩论中有效传达这种优势，同时不恰当的置信度表达会导致智能体固执坚持错误信念或过早收敛于次优答案。

Method: 提出ConfMAD框架，在多智能体辩论过程中集成置信度表达机制，让LLM能够明确传达其置信度水平，从而改善辩论动态和系统性能。

Result: 实验结果表明该方法有效，并进一步分析了置信度如何影响辩论动态，为设计置信度感知的多智能体辩论系统提供了见解。

Conclusion: 在多智能体辩论系统中引入置信度表达机制能够显著提升辩论效果和系统整体性能，为LLM协作系统设计提供了新的思路。

Abstract: Generative Large Language Models (LLMs) have demonstrated remarkable
performance across a wide range of tasks. Recent research has introduced
Multi-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate
human debate and thereby improve task performance. However, while some LLMs may
possess superior knowledge or reasoning capabilities for specific tasks, they
often struggle to clearly communicate this advantage during debates, in part
due to a lack of confidence expression. Moreover, inappropriate confidence
expression can cause agents in MAD systems to either stubbornly maintain
incorrect beliefs or converge prematurely on suboptimal answers, ultimately
reducing debate effectiveness and overall system performance. To address these
challenges, we propose incorporating confidence expression into MAD systems to
allow LLMs to explicitly communicate their confidence levels. To validate this
approach, we develop ConfMAD, a MAD framework that integrates confidence
expression throughout the debate process. Experimental results demonstrate the
effectiveness of our method, and we further analyze how confidence influences
debate dynamics, offering insights into the design of confidence-aware MAD
systems.

</details>


### [16] [Apertus: Democratizing Open and Compliant LLMs for Global Language Environments](https://arxiv.org/abs/2509.14233)
*Alejandro Hernández-Cano,Alexander Hägele,Allen Hao Huang,Angelika Romanou,Antoni-Joan Solergibert,Barna Pasztor,Bettina Messmer,Dhia Garbaya,Eduard Frank Ďurech,Ido Hakimi,Juan García Giraldo,Mete Ismayilzada,Negar Foroutan,Skander Moalla,Tiancheng Chen,Vinko Sabolčec,Yixuan Xu,Michael Aerni,Badr AlKhamissi,Ines Altemir Marinas,Mohammad Hossein Amani,Matin Ansaripour,Ilia Badanin,Harold Benoit,Emanuela Boros,Nicholas Browning,Fabian Bösch,Maximilian Böther,Niklas Canova,Camille Challier,Clement Charmillot,Jonathan Coles,Jan Deriu,Arnout Devos,Lukas Drescher,Daniil Dzenhaliou,Maud Ehrmann,Dongyang Fan,Simin Fan,Silin Gao,Miguel Gila,María Grandury,Diba Hashemi,Alexander Hoyle,Jiaming Jiang,Mark Klein,Andrei Kucharavy,Anastasiia Kucherenko,Frederike Lübeck,Roman Machacek,Theofilos Manitaras,Andreas Marfurt,Kyle Matoba,Simon Matrenok,Henrique Mendoncça,Fawzi Roberto Mohamed,Syrielle Montariol,Luca Mouchel,Sven Najem-Meyer,Jingwei Ni,Gennaro Oliva,Matteo Pagliardini,Elia Palme,Andrei Panferov,Léo Paoletti,Marco Passerini,Ivan Pavlov,Auguste Poiroux,Kaustubh Ponkshe,Nathan Ranchin,Javi Rando,Mathieu Sauser,Jakhongir Saydaliev,Muhammad Ali Sayfiddinov,Marian Schneider,Stefano Schuppli,Marco Scialanga,Andrei Semenov,Kumar Shridhar,Raghav Singhal,Anna Sotnikova,Alexander Sternfeld,Ayush Kumar Tarun,Paul Teiletche,Jannis Vamvas,Xiaozhe Yao,Hao Zhao Alexander Ilic,Ana Klimovic,Andreas Krause,Caglar Gulcehre,David Rosenthal,Elliott Ash,Florian Tramèr,Joost VandeVondele,Livio Veraldi,Martin Rajman,Thomas Schulthess,Torsten Hoefler,Antoine Bosselut,Martin Jaggi,Imanol Schlag*

Main category: cs.CL

Relevance: 85.0

TL;DR: Apertus是一个完全开源的LLM套件，专注于数据合规性和多语言表示，使用开放可用数据训练，采用Goldfish目标抑制记忆化，支持1800多种语言，在8B和70B规模上达到先进的多语言性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前开源模型生态系统中数据合规性和多语言表示不足的问题，提供完全透明且合规的模型开发流程。

Method: 使用完全开放可用数据进行预训练，遵循robots.txt排除规则，过滤非许可、有毒和个人身份信息内容，采用Goldfish目标抑制记忆化，在多语言数据上训练（15T tokens，1800+语言，40%非英语内容）。

Result: Apertus模型在多语言基准测试中达到或超越同类开源权重模型的先进水平，同时保持了数据合规性和透明度。

Conclusion: Apertus提供了一个完全开源、数据合规、多语言能力强的LLM套件，为透明审计和扩展提供了完整的科学工件。

Abstract: We present Apertus, a fully open suite of large language models (LLMs)
designed to address two systemic shortcomings in today's open model ecosystem:
data compliance and multilingual representation. Unlike many prior models that
release weights without reproducible data pipelines or regard for content-owner
rights, Apertus models are pretrained exclusively on openly available data,
retroactively respecting robots.txt exclusions and filtering for
non-permissive, toxic, and personally identifiable content. To mitigate risks
of memorization, we adopt the Goldfish objective during pretraining, strongly
suppressing verbatim recall of data while retaining downstream task
performance. The Apertus models also expand multilingual coverage, training on
15T tokens from over 1800 languages, with ~40% of pretraining data allocated to
non-English content. Released at 8B and 70B scales, Apertus approaches
state-of-the-art results among fully open models on multilingual benchmarks,
rivalling or surpassing open-weight counterparts. Beyond model weights, we
release all scientific artifacts from our development cycle with a permissive
license, including data preparation scripts, checkpoints, evaluation suites,
and training code, enabling transparent audit and extension.

</details>


### [17] [CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](https://arxiv.org/abs/2509.13672)
*Shang Qin,Jingheng Ye,Yinghui Li,Hai-Tao Zheng,Qi Li,Jinxiao Shan,Zhixing Li,Hong-Gee Kim*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出了第一个中文文献语法纠错的持续学习基准CL²GEC，包含10个学科的10,000条人工标注句子，评估LLM在跨学科语法纠错中的持续学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有中文语法纠错研究缺乏多学科学术写作的专用基准，忽视了持续学习作为处理领域特定语言变异和防止灾难性遗忘的解决方案。

Method: 构建包含10个学科的10,000句标注数据集，在持续学习设置下评估LLM的顺序调优、参数高效适应和4种代表性CL算法，使用标准GEC指标和适应任务级变异的持续学习指标。

Result: 实验结果表明，基于正则化的方法比基于回放或简单顺序方法更能有效缓解遗忘问题。

Conclusion: 该基准为跨学科学术领域的自适应语法纠错研究提供了严格基础，展示了持续学习在领域适应中的重要性。

Abstract: The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.

</details>


### [18] [Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?](https://arxiv.org/abs/2509.13695)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该研究构建了一个日语比较推理NLI数据集，评估了LLMs在零样本和少样本设置下处理日语比较句的能力，发现模型性能受提示格式和示例标签影响，且逻辑语义表示能帮助模型解决困难推理问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言推理方面表现优异，但在处理涉及数值和逻辑表达式的推理时仍存在挑战。比较句是与此类推理相关的关键语言现象，但LLMs在处理非主导训练语言（如日语）中的比较句方面的鲁棒性尚未得到充分探索。

Method: 构建了一个专注于比较句的日语NLI数据集，在零样本和少样本设置下评估了各种LLMs的性能，分析了提示格式、示例标签以及逻辑语义表示对模型表现的影响。

Result: 模型性能在零样本设置中对提示格式敏感，在少样本设置中受示例标签影响。LLMs难以处理日语特有的语言现象，但包含逻辑语义表示的提示能帮助模型解决即使少样本示例也难以处理的推理问题。

Conclusion: LLMs在处理日语比较推理方面存在局限性，特别是在处理语言特有现象时。逻辑语义表示可以作为有效的辅助工具来提升模型性能，提示工程在跨语言NLI任务中至关重要。

Abstract: Large Language Models (LLMs) perform remarkably well in Natural Language
Inference (NLI). However, NLI involving numerical and logical expressions
remains challenging. Comparatives are a key linguistic phenomenon related to
such inference, but the robustness of LLMs in handling them, especially in
languages that are not dominant in the models' training data, such as Japanese,
has not been sufficiently explored. To address this gap, we construct a
Japanese NLI dataset that focuses on comparatives and evaluate various LLMs in
zero-shot and few-shot settings. Our results show that the performance of the
models is sensitive to the prompt formats in the zero-shot setting and
influenced by the gold labels in the few-shot examples. The LLMs also struggle
to handle linguistic phenomena unique to Japanese. Furthermore, we observe that
prompts containing logical semantic representations help the models predict the
correct labels for inference problems that they struggle to solve even with
few-shot examples.

</details>


### [19] [Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes](https://arxiv.org/abs/2509.13696)
*Iyadh Ben Cheikh Larbi,Ajay Madhavan Ravichandran,Aljoscha Burchardt,Roland Roller*

Main category: cs.CL

Relevance: 75.0

TL;DR: 使用DSPy提示优化技术将指令调优的大型语言模型适配于临床分类任务，能够同时处理临床文本和结构化EHR数据，性能媲美专业多模态系统但更简单灵活


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本生成方面表现出色，但在处理包含时间序列等结构化数据的临床分类任务方面仍有待探索，特别是如何有效整合临床笔记和结构化EHR数据

Method: 采用DSPy-based提示优化技术对指令调优的LLMs进行适配，使其能够联合处理临床文本笔记和结构化电子健康记录(EHR)输入

Result: 该方法在临床分类任务上达到了与专业多模态系统相当的性能水平，同时具有更低的复杂度和更强的跨任务适应能力

Conclusion: 通过提示优化技术，通用LLMs可以有效处理临床多模态数据分类任务，为医疗AI应用提供了更简单灵活的解决方案

Abstract: Large language models (LLMs) excel at text generation, but their ability to
handle clinical classification tasks involving structured data, such as time
series, remains underexplored. In this work, we adapt instruction-tuned LLMs
using DSPy-based prompt optimization to process clinical notes and structured
EHR inputs jointly. Our results show that this approach achieves performance on
par with specialized multimodal systems while requiring less complexity and
offering greater adaptability across tasks.

</details>


### [20] [Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](https://arxiv.org/abs/2509.13775)
*Vani Kanjirangat,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

Relevance: 75.0

TL;DR: 本文探索了阿拉伯语方言识别(ADI)的数据高效和参数高效方法，包括软提示策略、LoRA重参数化以及零样本/少样本推理，发现LLM在区分方言细微差别方面表现不佳，而LoRA微调模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过参数高效微调(PEFT)和数据高效方法来解决阿拉伯语方言识别任务，特别是在资源有限的情况下提升模型性能。

Method: 使用多种软提示策略(prefix-tuning、prompt-tuning、P-tuning、P-tuning V2)和LoRA重参数化；分析零样本和少样本推理；在阿拉伯语专用编码器模型和多语言解码器模型上进行实验。

Result: LLM在零样本和少样本设置下难以区分方言细微差别；软提示编码器变体表现较好；基于LoRA微调的模型表现最佳，甚至超过全参数微调。

Conclusion: LoRA等参数高效方法在阿拉伯语方言识别任务中表现出色，而LLM在少样本场景下的方言识别能力有限。

Abstract: This paper discusses our exploration of different data-efficient and
parameter-efficient approaches to Arabic Dialect Identification (ADI). In
particular, we investigate various soft-prompting strategies, including
prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA
reparameterizations. For the data-efficient strategy, we analyze hard prompting
with zero-shot and few-shot inferences to analyze the dialect identification
capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT
approaches, we conducted our experiments using Arabic-specific encoder models
on several major datasets. We also analyzed the n-shot inferences on
open-source decoder-only models, a general multilingual model (Phi-3.5), and an
Arabic-specific one(SILMA). We observed that the LLMs generally struggle to
differentiate the dialectal nuances in the few-shot or zero-shot setups. The
soft-prompted encoder variants perform better, while the LoRA-based fine-tuned
models perform best, even surpassing full fine-tuning.

</details>


### [21] [Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG](https://arxiv.org/abs/2509.13930)
*Dayeon Ki,Marine Carpuat,Paul McNamee,Daniel Khashabi,Eugene Yang,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该研究发现多语言检索增强生成(mRAG)系统中存在语言偏好偏见，模型倾向于引用英语文档，即使其他语言的文档更相关，这种偏见在低资源语言和中间位置的文档中更加明显。


<details>
  <summary>Details</summary>
Motivation: 研究多语言检索增强生成系统中不同文档语言的混合是否会影响生成和引用的行为，特别是是否存在语言偏好偏见。

Method: 使用模型内部机制的控制方法，在保持文档相关性等因素不变的情况下，测量语言偏好。研究覆盖8种语言和6个开源模型。

Result: 发现模型在英语查询时优先引用英语来源，这种偏见在低资源语言和中间位置的文档中更加明显。模型有时会牺牲文档相关性来选择语言偏好。

Conclusion: 引用选择并不总是由信息性驱动，语言偏好显著影响多语言上下文中的引用行为。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.

</details>


### [22] [Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs](https://arxiv.org/abs/2509.13480)
*Andrea Piergentili,Beatrice Savoldi,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

Relevance: 65.0

TL;DR: 本文首次系统评估了意大利语性别中性重写任务，提出了衡量中立性和语义保真度的二维框架，发现开源LLMs优于现有专用模型，微调后的小模型性能可媲美大型LLMs。


<details>
  <summary>Details</summary>
Motivation: 意大利语等语法性别语言中的性别中性重写具有挑战性，需要消除不必要的性别指定同时保持语义完整性。目前缺乏对该任务的系统性评估。

Method: 采用少样本提示比较多个LLMs，对选定模型进行微调，并应用针对性数据清理提升任务相关性。建立二维评估框架（中立性和语义保真度）。

Result: 开源权重LLMs优于现有的意大利语GNR专用模型。微调后的小型模型以极小的参数量达到或超过最佳开源LLM的性能。

Conclusion: 研究表明LLMs在性别中性重写任务上表现优异，微调策略有效，但在优化训练数据时需要权衡中立性和意义保持的平衡。

Abstract: Gender-neutral rewriting (GNR) aims to reformulate text to eliminate
unnecessary gender specifications while preserving meaning, a particularly
challenging task in grammatical-gender languages like Italian. In this work, we
conduct the first systematic evaluation of state-of-the-art large language
models (LLMs) for Italian GNR, introducing a two-dimensional framework that
measures both neutrality and semantic fidelity to the input. We compare
few-shot prompting across multiple LLMs, fine-tune selected models, and apply
targeted cleaning to boost task relevance. Our findings show that open-weight
LLMs outperform the only existing model dedicated to GNR in Italian, whereas
our fine-tuned models match or exceed the best open-weight LLM's performance at
a fraction of its size. Finally, we discuss the trade-off between optimizing
the training data for neutrality and meaning preservation.

</details>


### [23] [Combining Evidence and Reasoning for Biomedical Fact-Checking](https://arxiv.org/abs/2509.13879)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

Relevance: 65.0

TL;DR: CER是一个用于生物医学事实核查的新框架，结合科学证据检索、大语言模型推理和监督真实性预测，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的错误信息（如疫苗犹豫和未经证实的治疗方法）对公共卫生和医疗系统信任构成风险。生物医学声明验证具有独特挑战性，需要复杂术语处理、领域专业知识以及基于科学证据的验证。

Method: CER框架整合了科学证据检索、大语言模型推理和监督真实性预测。通过将大语言模型的文本生成能力与高质量生物医学科学证据的先进检索技术相结合，有效减轻幻觉风险。

Result: 在专家标注的数据集（HealthFC、BioASQ-7b、SciFact）上评估显示达到了最先进的性能，并展现出有前景的跨数据集泛化能力。

Conclusion: CER框架通过结合证据检索和LLM推理，为生物医学事实核查提供了有效的解决方案，代码和数据已开源以确保透明性和可重现性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https: //github.com/PRAISELab-PicusLab/CER.

</details>


### [24] [Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification](https://arxiv.org/abs/2509.13888)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

Relevance: 65.0

TL;DR: CER是一个用于生物医学事实核查的新框架，结合了科学证据检索、大语言模型推理和监督真实性预测，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的错误信息（如疫苗犹豫和未经证实的治疗方法）对公共健康构成风险，但生物医学声明验证具有独特挑战性，需要复杂的术语处理、领域专业知识以及基于科学证据的验证。

Method: CER框架整合了科学证据检索、大语言模型推理和监督真实性预测。通过将大语言模型的文本生成能力与高质量生物医学科学证据的检索技术相结合，有效减少幻觉风险。

Result: 在专家标注的数据集（HealthFC、BioASQ-7b、SciFact）上展示了最先进的性能，并显示出良好的跨数据集泛化能力。

Conclusion: CER框架通过结合证据检索和LLM推理，为生物医学事实核查提供了有效的解决方案，代码和数据已开源以确保透明度和可复现性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https://github.com/PRAISELab-PicusLab/CER

</details>


### [25] [Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale](https://arxiv.org/abs/2509.14008)
*Hasan Abed Al Kader Hammoud,Mohammad Zbeeb,Bernard Ghanem*

Main category: cs.CL

Relevance: 65.0

TL;DR: Hala是一个阿拉伯语为中心的指令和翻译模型家族，通过翻译-调优流程构建，在阿拉伯语基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 针对阿拉伯语NLP领域缺乏高质量指令数据集和专门模型的问题，开发能够高效处理阿拉伯语指令和翻译任务的模型家族。

Method: 使用FP8压缩的AR-EN教师模型生成高质量双语监督数据，在轻量级LFM2-1.2B模型上进行微调，翻译英文指令集为阿拉伯语，创建百万级指令语料库，训练不同参数规模的Hala模型，并应用slerp合并技术平衡阿拉伯语专业化和基础模型优势。

Result: 在阿拉伯语基准测试中，Hala在"nano"(≤2B)和"small"(7-9B)类别中都取得了最先进的结果，超越了其基础模型。

Conclusion: Hala模型为阿拉伯语NLP研究提供了有效的解决方案，通过创新的翻译-调优流程和模型架构优化，显著提升了阿拉伯语指令跟随和翻译任务的性能。

Abstract: We present Hala, a family of Arabic-centric instruction and translation
models built with our translate-and-tune pipeline. We first compress a strong
AR$\leftrightarrow$EN teacher to FP8 (yielding $\sim$2$\times$ higher
throughput with no quality loss) and use it to create high-fidelity bilingual
supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this
data and used to translate high-quality English instruction sets into Arabic,
producing a million-scale corpus tailored to instruction following. We train
Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to
balance Arabic specialization with base-model strengths. On Arabic-centric
benchmarks, Hala achieves state-of-the-art results within both the "nano"
($\leq$2B) and "small" (7-9B) categories, outperforming their bases. We release
models, data, evaluation, and recipes to accelerate research in Arabic NLP.

</details>


### [26] [AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity](https://arxiv.org/abs/2509.14171)
*Yifan Liu,Wenkuan Zhao,Shanshan Zhong,Jinghui Qin,Mingfu Liang,Zhongzhan Huang,Wushao Wen*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出了AssoCiAm基准测试，通过混合计算方法解决多模态大语言模型关联能力评估中的模糊性问题，发现认知与关联能力存在强正相关关系。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型关联能力评估框架往往忽视了关联任务中固有的模糊性，这种模糊性源于关联的发散性，会降低评估的可靠性。

Method: 将模糊性分解为内部模糊性和外部模糊性，引入AssoCiAm基准测试，采用混合计算方法来规避模糊性，并进行广泛的实验验证。

Result: 实验发现认知与关联能力存在强正相关关系，评估过程中的模糊性会使MLLMs的行为更加随机化，验证了所提方法能确保更准确可靠的评估。

Conclusion: AssoCiAm基准测试能有效解决关联能力评估中的模糊性问题，为MLLMs的创造力评估提供了更可靠的框架。

Abstract: Recent advancements in multimodal large language models (MLLMs) have garnered
significant attention, offering a promising pathway toward artificial general
intelligence (AGI). Among the essential capabilities required for AGI,
creativity has emerged as a critical trait for MLLMs, with association serving
as its foundation. Association reflects a model' s ability to think creatively,
making it vital to evaluate and understand. While several frameworks have been
proposed to assess associative ability, they often overlook the inherent
ambiguity in association tasks, which arises from the divergent nature of
associations and undermines the reliability of evaluations. To address this
issue, we decompose ambiguity into two types-internal ambiguity and external
ambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative
ability while circumventing the ambiguity through a hybrid computational
method. We then conduct extensive experiments on MLLMs, revealing a strong
positive correlation between cognition and association. Additionally, we
observe that the presence of ambiguity in the evaluation process causes MLLMs'
behavior to become more random-like. Finally, we validate the effectiveness of
our method in ensuring more accurate and reliable evaluations. See Project Page
for the data and codes.

</details>


### [27] [Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs](https://arxiv.org/abs/2509.14180)
*Akhil Theerthala*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出了一个新颖的金融咨询框架，通过整合金融背景和行为金融学研究构建监督数据，在8B参数模型上实现了与14-32B大模型相当的性能，同时成本降低80%。


<details>
  <summary>Details</summary>
Motivation: 个性化金融咨询需要考虑用户目标、约束、风险承受能力和司法管辖区。现有LLM工作主要关注投资者支持系统，而代理化管道维护成本高且财务回报低于预期。

Method: 构建了一个包含19k样本的推理数据集，整合相关金融背景和行为金融学研究，对Qwen-3-8B模型进行全面微调。

Result: 通过保留测试集和盲审LLM评审研究显示，8B模型在事实准确性、流畅性和个性化指标上与14-32B大模型性能相当，同时成本降低80%。

Conclusion: 通过精心数据策划和行为整合，小模型可以在金融咨询任务上实现与大模型相当的性能，显著降低成本。

Abstract: Personalized financial advice requires consideration of user goals,
constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on
support systems for investors and financial planners. Simultaneously, numerous
recent studies examine broader personal finance tasks, including budgeting,
debt management, retirement, and estate planning, through agentic pipelines
that incur high maintenance costs, yielding less than 25% of their expected
financial returns. In this study, we introduce a novel and reproducible
framework that integrates relevant financial context with behavioral finance
studies to construct supervision data for end-to-end advisors. Using this
framework, we create a 19k sample reasoning dataset and conduct a comprehensive
fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test
split and a blind LLM-jury study, we demonstrate that through careful data
curation and behavioral integration, our 8B model achieves performance
comparable to significantly larger baselines (14-32B parameters) across factual
accuracy, fluency, and personalization metrics while incurring 80% lower costs
than the larger counterparts.

</details>


### [28] [Framing Migration: A Computational Analysis of UK Parliamentary Discourse](https://arxiv.org/abs/2509.14197)
*Vahid Ghafouri,Robert McNeil,Teodor Yankov,Madeleine Sumption,Luc Rocher,Scott A. Hale,Adam Mahdi*

Main category: cs.CL

Relevance: 65.0

TL;DR: 使用开源大语言模型对英国议会75年移民辩论进行大规模计算分析，发现与美国不同，英国政党间态度相对一致但存在意识形态差距，叙事框架向安全化议题转变。


<details>
  <summary>Details</summary>
Motivation: 研究旨在利用大语言模型进行大规模政治话语分析，比较英美移民政策辩论的长期趋势和差异，探索LLM在政治历史语境中的细粒度分析能力。

Method: 使用开源权重LLM对议会辩论声明进行高层立场标注，采用半自动化框架提取细粒度叙事框架，进行跨时间和政党的净态度追踪。

Result: 美国话语日益两极分化，英国政党态度相对一致但工党与保守党存在持续意识形态差距；英国叙事框架向边境管控等安全化议题转变，社会融合等长期整合框架减少；移民讨论从国内法转向国际法和人权。

Conclusion: 大语言模型能够支持政治历史语境中可扩展的细粒度话语分析，为理解长期政策辩论趋势提供了有效工具。

Abstract: We present a large-scale computational analysis of migration-related
discourse in UK parliamentary debates spanning over 75 years and compare it
with US congressional discourse. Using open-weight LLMs, we annotate each
statement with high-level stances toward migrants and track the net tone toward
migrants across time and political parties. For the UK, we extend this with a
semi-automated framework for extracting fine-grained narrative frames to
capture nuances of migration discourse. Our findings show that, while US
discourse has grown increasingly polarised, UK parliamentary attitudes remain
relatively aligned across parties, with a persistent ideological gap between
Labour and the Conservatives, reaching its most negative level in 2025. The
analysis of narrative frames in the UK parliamentary statements reveals a shift
toward securitised narratives such as border control and illegal immigration,
while longer-term integration-oriented frames such as social integration have
declined. Moreover, discussions of national law about immigration have been
replaced over time by international law and human rights, revealing nuances in
discourse trends. Taken together broadly, our findings demonstrate how LLMs can
support scalable, fine-grained discourse analysis in political and historical
contexts.

</details>


### [29] [Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning](https://arxiv.org/abs/2509.13539)
*Alisa Kanganis,Katherine A. Keith*

Main category: cs.CL

Relevance: 45.0

TL;DR: Op-Fed是一个包含1044个标注句子的FOMC会议记录数据集，用于货币政策立场分析。该研究解决了类别不平衡和句子间依赖的技术挑战，发现LLM在货币政策立场分类上表现不佳（0.61准确率），低于人类基准（0.89）。


<details>
  <summary>Details</summary>
Motivation: 美联储公开市场委员会(FOMC)的货币政策决定影响数百万人，但缺乏高质量标注数据来训练模型分析货币政策立场。研究者希望创建专门的数据集来支持相关NLP研究。

Method: 采用五阶段分层标注方案分离观点、货币政策和立场等维度；使用主动学习选择标注实例，将正例数量翻倍；评估LLM在零样本设置下的表现。

Result: 最佳闭源LLM在观点分类上达到0.80准确率，但在货币政策立场分类上仅0.61，显著低于人类基准0.89。数据集包含1044个标注句子，65%需要句子级上下文。

Conclusion: Op-Fed数据集可用于模型训练、置信度校准和未来标注工作的种子数据。LLM在复杂金融文本分析任务上仍有较大提升空间。

Abstract: The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets
monetary policy, affecting the borrowing and spending decisions of millions of
people. In this work, we release Op-Fed, a dataset of 1044 human-annotated
sentences and their contexts from FOMC transcripts. We faced two major
technical challenges in dataset creation: imbalanced classes -- we estimate
fewer than 8% of sentences express a non-neutral stance towards monetary policy
-- and inter-sentence dependence -- 65% of instances require context beyond the
sentence-level. To address these challenges, we developed a five-stage
hierarchical schema to isolate aspects of opinion, monetary policy, and stance
towards monetary policy as well as the level of context needed. Second, we
selected instances to annotate using active learning, roughly doubling the
number of positive instances across all schema aspects. Using Op-Fed, we found
a top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion
classification but only 0.61 zero-shot accuracy classifying stance towards
monetary policy -- below our human baseline of 0.89. We expect Op-Fed to be
useful for future model training, confidence calibration, and as a seed dataset
for future annotation efforts.

</details>


### [30] [Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages](https://arxiv.org/abs/2509.13803)
*Laura García-Sardiña,Hermenegildo Fabregat,Daniel Deniz,Rabih Zbib*

Main category: cs.CL

Relevance: 45.0

TL;DR: 本文研究了语法性别对自动职位排名系统的影响，提出了基于RBO的性别偏见评估方法，并在四种语法性别语言中创建了测试集来评估多语言模型的性别偏见。


<details>
  <summary>Details</summary>
Motivation: 研究语法性别在职位名称中的显式分配如何影响自动职位排名系统的结果，旨在评估和量化多语言模型中的性别偏见问题。

Method: 提出使用RBO（Rank-Biased Overlap）指标来比较控制性别因素的排名结果，创建了包含阳性和阴性形式的职位名称测试集，涵盖四种语法性别语言，并评估了多个现成的多语言模型。

Result: 所有测试的多语言模型都表现出不同程度的性别偏见，证明了现有系统在语法性别处理方面存在系统性偏差。

Conclusion: 需要开发能够更好地处理语法性别并减少性别偏见的职位排名系统，本文提出的方法和测试集为此类研究提供了基础。

Abstract: This work sets the ground for studying how explicit grammatical gender
assignment in job titles can affect the results of automatic job ranking
systems. We propose the usage of metrics for ranking comparison controlling for
gender to evaluate gender bias in job title ranking systems, in particular RBO
(Rank-Biased Overlap). We generate and share test sets for a job title matching
task in four grammatical gender languages, including occupations in masculine
and feminine form and annotated by gender and matching relevance. We use the
new test sets and the proposed methodology to evaluate the gender bias of
several out-of-the-box multilingual models to set as baselines, showing that
all of them exhibit varying degrees of gender bias.

</details>


### [31] [You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models](https://arxiv.org/abs/2509.14031)
*Paweł Mąka,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

Relevance: 45.0

TL;DR: 该研究验证了上下文训练数据稀疏性是机器翻译中上下文利用困难的主要原因，发现不同上下文现象之间缺乏泛化性，并提出两种训练策略在单语和多语设置中分别提升6%和8%的准确率


<details>
  <summary>Details</summary>
Motivation: 标准训练数据中上下文丰富样本的稀疏性被认为是机器翻译难以有效利用上下文的主要原因，研究者希望通过系统验证这一假设并探索解决方案

Method: 构建具有受控比例上下文相关样本的训练数据集，在单语和多语设置中系统验证数据稀疏性与模型性能的关系，并提出两种训练策略来更好地利用可用数据

Result: 研究证实了训练数据稀疏性与模型性能之间的强关联，发现不同上下文现象的改进无法相互泛化，跨语言迁移效果有限。提出的训练策略在ctxPro评估中分别带来6%和8%的准确率提升

Conclusion: 上下文数据稀疏性是机器翻译上下文利用的关键瓶颈，需要针对性的训练策略来改善，且不同上下文现象需要分别处理

Abstract: Achieving human-level translations requires leveraging context to ensure
coherence and handle complex phenomena like pronoun disambiguation. Sparsity of
contextually rich examples in the standard training data has been hypothesized
as the reason for the difficulty of context utilization. In this work, we
systematically validate this claim in both single- and multilingual settings by
constructing training datasets with a controlled proportions of contextually
relevant examples. We demonstrate a strong association between training data
sparsity and model performance confirming sparsity as a key bottleneck.
Importantly, we reveal that improvements in one contextual phenomenon do no
generalize to others. While we observe some cross-lingual transfer, it is not
significantly higher between languages within the same sub-family. Finally, we
propose and empirically evaluate two training strategies designed to leverage
the available data. These strategies improve context utilization, resulting in
accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in
single- and multilingual settings respectively.

</details>


### [32] [Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST](https://arxiv.org/abs/2509.14128)
*Monica Sekoyan,Nithin Rao Koluguri,Nune Tadevosyan,Piotr Zelasko,Travis Bartley,Nick Karpov,Jagadeesh Balam,Boris Ginsburg*

Main category: cs.CL

Relevance: 45.0

TL;DR: Canary-1B-v2是一个快速、鲁棒的多语言语音识别和语音转文本翻译模型，基于FastConformer编码器和Transformer解码器，支持25种欧洲语言，在保持高性能的同时比Whisper-large-v3快10倍。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效、快速且准确的多语言语音处理模型，解决现有大型模型推理速度慢的问题，同时减少语音识别和翻译中的幻觉现象。

Method: 采用两阶段预训练和微调流程，使用FastConformer编码器和Transformer解码器架构，训练数据包括170万小时的多语言语音数据，并添加非语音音频以减少幻觉。使用动态数据平衡和NeMo强制对齐器进行时间戳标注。

Result: 模型在英语ASR上超越Whisper-large-v3且速度快10倍，在多语言ASR和AST任务上与Seamless-M4T-v2-large等大型模型竞争性能，同时发布了更小的600M参数版本Parakeet-TDT-0.6B-v3。

Conclusion: Canary-1B-v2展示了在语音处理任务中实现高性能和高效率的可行性，FastConformer架构在微调后表现优异，nGPT编码器在大规模数据下具有良好的扩展性。

Abstract: This report introduces Canary-1B-v2, a fast, robust multilingual model for
Automatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built
with a FastConformer encoder and Transformer decoder, it supports 25 languages
primarily European. The model was trained on 1.7M hours of total data samples,
including Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce
hallucinations for ASR and AST. We describe its two-stage pre-training and
fine-tuning process with dynamic data balancing, as well as experiments with an
nGPT encoder. Results show nGPT scales well with massive data, while
FastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the
NeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable
segment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2
outperforms Whisper-large-v3 on English ASR while being 10x faster, and
delivers competitive multilingual ASR and AST performance against larger models
like Seamless-M4T-v2-large and LLM-based systems. We also release
Parakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the
same 25 languages with just 600M parameters.

</details>


### [33] [Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models](https://arxiv.org/abs/2509.13706)
*Peter Beidler,Mark Nguyen,Kevin Lybarger,Ola Holmberg,Eric Ford,John Kang*

Main category: cs.CL

Relevance: 35.0

TL;DR: 开发了一个基于BlueBERT的NLP工具，用于自动检测放射肿瘤学中的高严重性事件报告，通过跨机构迁移学习实现了与人类相当的分类性能。


<details>
  <summary>Details</summary>
Motivation: 医疗事件报告的手动审查耗时且需要专业知识，需要自动化工具来高效识别高严重性事件，以提升医疗安全和质量改进。

Method: 使用支持向量机(SVM)和基于PubMed数据预训练的BlueBERT模型，在两个机构的放射肿瘤学事件报告数据集上进行训练和评估，采用跨机构迁移学习策略。

Result: BlueBERT_TRANSFER模型在跨机构测试集上达到AUROC 0.78，在人工编辑的数据集上达到AUROC 0.74，与人类性能(AUROC 0.81)相当。

Conclusion: 成功开发了跨机构的NLP模型，能够以与人类相当的性能检测高严重性事件报告，证明了迁移学习在医疗文本分析中的有效性。

Abstract: PURPOSE: Incident reports are an important tool for safety and quality
improvement in healthcare, but manual review is time-consuming and requires
subject matter expertise. Here we present a natural language processing (NLP)
screening tool to detect high-severity incident reports in radiation oncology
across two institutions.
  METHODS AND MATERIALS: We used two text datasets to train and evaluate our
NLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA
SAFRON (SF), all of which had severity scores labeled by clinical content
experts. We trained and evaluated two types of models: baseline support vector
machines (SVM) and BlueBERT which is a large language model pretrained on
PubMed abstracts and hospitalized patient data. We assessed for
generalizability of our model in two ways. First, we evaluated models trained
using Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that
was first fine-tuned on Inst.-train then on SF-train before testing on SF-test
set. To further analyze model performance, we also examined a subset of 59
reports from our Inst. dataset, which were manually edited for clarity.
  RESULTS Classification performance on the Inst. test achieved AUROC 0.82
using SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,
performance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56
using BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,
improved the performance on SF test to AUROC 0.78. Performance of SVM, and
BlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and
0.74) was similar to human performance (AUROC 0.81).
  CONCLUSION: In summary, we successfully developed cross-institution NLP
models on incident report text from radiation oncology centers. These models
were able to detect high-severity reports similarly to humans on a curated
dataset.

</details>


### [34] [Implementing a Logical Inference System for Japanese Comparatives](https://arxiv.org/abs/2509.13734)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

Relevance: 35.0

TL;DR: 提出了ccg-jcomp系统，这是一个基于组合语义的日语比较句逻辑推理系统，用于处理日语自然语言推理中的比较表达，并在日语NLI数据集上评估其性能。


<details>
  <summary>Details</summary>
Motivation: 日语和英语比较句在形态和语义上存在显著差异，使得现有的英语比较句逻辑推理系统难以直接应用于日语。需要开发专门针对日语比较句的逻辑推理系统。

Method: 基于组合语义构建逻辑推理系统ccg-jcomp，专门处理日语比较句的数值和逻辑表达式，并在包含比较表达的日语NLI数据集上进行评估。

Result: 系统在日语NLI数据集上表现出有效性，通过与现有大型语言模型的准确率比较证明了其优势。

Conclusion: ccg-jcomp系统为日语比较句的逻辑推理提供了有效的解决方案，展示了组合语义方法在处理语言特异性问题上的价值。

Abstract: Natural Language Inference (NLI) involving comparatives is challenging
because it requires understanding quantities and comparative relations
expressed by sentences. While some approaches leverage Large Language Models
(LLMs), we focus on logic-based approaches grounded in compositional semantics,
which are promising for robust handling of numerical and logical expressions.
Previous studies along these lines have proposed logical inference systems for
English comparatives. However, it has been pointed out that there are several
morphological and semantic differences between Japanese and English
comparatives. These differences make it difficult to apply such systems
directly to Japanese comparatives. To address this gap, this study proposes
ccg-jcomp, a logical inference system for Japanese comparatives based on
compositional semantics. We evaluate the proposed system on a Japanese NLI
dataset containing comparative expressions. We demonstrate the effectiveness of
our system by comparing its accuracy with that of existing LLMs.

</details>


### [35] [Findings of the Third Automatic Minuting (AutoMin) Challenge](https://arxiv.org/abs/2509.13814)
*Kartik Shinde,Laurent Besacier,Ondrej Bojar,Thibaut Thonet,Tirthankar Ghosal*

Main category: cs.CL

Relevance: 35.0

TL;DR: AutoMin 2025是一个自动会议纪要生成和问答的共享任务，包含英文和捷克语的项目会议和欧洲议会会议纪要生成，以及基于会议转录的问答任务。参与度较低但包含了多个LLM基线系统评估。


<details>
  <summary>Details</summary>
Motivation: 推动自动会议纪要生成技术的发展，特别是在多语言和跨语言场景下，评估当前大型语言模型在结构化会议纪要创建和基于会议内容的问答任务上的表现。

Method: 组织共享任务，设置两个主要任务：1）结构化会议纪要生成（英文和捷克语的项目会议和欧洲议会会议）2）基于会议转录的问答（单语言英文问答和跨语言捷克问答）。使用多个基线系统（包括当前LLMs）进行综合评估。

Result: 2025年参与度较低（纪要任务1个团队，问答任务2个团队），但通过组织方提供的多个基线系统，能够全面评估当前LLM在会议纪要生成和问答任务上的性能表现。

Conclusion: AutoMin 2025为自动会议纪要生成和问答任务提供了有价值的基准测试平台，尽管参与团队数量有限，但通过基线系统的引入仍能有效评估当前LLM技术在这些任务上的能力。

Abstract: This paper presents the third edition of AutoMin, a shared task on automatic
meeting summarization into minutes. In 2025, AutoMin featured the main task of
minuting, the creation of structured meeting minutes, as well as a new task:
question answering (QA) based on meeting transcripts.
  The minuting task covered two languages, English and Czech, and two domains:
project meetings and European Parliament sessions. The QA task focused solely
on project meetings and was available in two settings: monolingual QA in
English, and cross-lingual QA, where questions were asked and answered in Czech
based on English meetings.
  Participation in 2025 was more limited compared to previous years, with only
one team joining the minuting task and two teams participating in QA. However,
as organizers, we included multiple baseline systems to enable a comprehensive
evaluation of current (2025) large language models (LLMs) on both tasks.

</details>


### [36] [Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality](https://arxiv.org/abs/2509.14023)
*Sami Ul Haq,Sheila Castilho,Yvette Graham*

Main category: cs.CL

Relevance: 35.0

TL;DR: 该研究比较了文本和音频两种方式对机器翻译系统的评估效果，发现基于音频的评估能提供更自然的质量判断，在某些情况下能识别出文本评估无法发现的系统差异。


<details>
  <summary>Details</summary>
Motivation: 当前机器翻译质量评估主要依赖文本方式，但现实应用中翻译常以语音形式呈现（如语音翻译应用），需要探索更自然的语音评估方式。

Method: 使用Amazon Mechanical Turk众包平台，对WMT General MT共享任务的10个翻译系统进行文本和音频两种方式的评估比较，并进行统计显著性检验和自复制实验验证可靠性。

Result: 音频评估得出的排名与文本评估基本一致，但在某些情况下能识别出翻译系统间的显著差异，表明语音模态提供了更丰富自然的评估信息。

Conclusion: 建议将基于语音的评估纳入未来机器翻译评估框架，以更好地反映实际应用场景中的翻译质量。

Abstract: Machine Translation (MT) has achieved remarkable performance, with growing
interest in speech translation and multimodal approaches. However, despite
these advancements, MT quality assessment remains largely text centric,
typically relying on human experts who read and compare texts. Since many
real-world MT applications (e.g Google Translate Voice Mode, iFLYTEK
Translator) involve translation being spoken rather printed or read, a more
natural way to assess translation quality would be through speech as opposed
text-only evaluations. This study compares text-only and audio-based
evaluations of 10 MT systems from the WMT General MT Shared Task, using
crowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,
performed statistical significance testing and self-replication experiments to
test reliability and consistency of audio-based approach. Crowd-sourced
assessments based on audio yield rankings largely consistent with text only
evaluations but, in some cases, identify significant differences between
translation systems. We attribute this to speech richer, more natural modality
and propose incorporating speech-based assessments into future MT evaluation
frameworks.

</details>


### [37] [SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation](https://arxiv.org/abs/2509.14036)
*Zekang Liu,Wei Feng,Fanhua Shang,Lianyu Hu,Jichao Feng,Liqing Gao*

Main category: cs.CL

Relevance: 35.0

TL;DR: 该论文提出了基于问题的手语翻译(QB-SLT)新任务，通过跨模态自监督学习和Sigmoid自注意力加权融合方法，利用对话上下文提升手语翻译性能。


<details>
  <summary>Details</summary>
Motivation: 手语翻译中对话提供重要上下文线索，但传统gloss标注成本高。对话自然发生且易于标注，探索如何有效整合对话信息来改进翻译质量。

Method: 提出SSL-SSAW方法：使用对比学习对齐多模态特征，Sigmoid自注意力加权模块自适应提取问题和手语序列特征，通过自监督学习利用可用问题文本增强表示能力。

Result: 在新建的CSL-Daily-QA和PHOENIX-2014T-QA数据集上达到SOTA性能，问题辅助能达到甚至超越gloss辅助的效果，可视化结果证实对话整合的有效性。

Conclusion: 基于问题的对话整合是手语翻译的有效方法，易于获取的问题辅助可以替代传统gloss标注，为手语翻译提供了新的研究方向。

Abstract: Sign Language Translation (SLT) bridges the communication gap between deaf
people and hearing people, where dialogue provides crucial contextual cues to
aid in translation. Building on this foundational concept, this paper proposes
Question-based Sign Language Translation (QB-SLT), a novel task that explores
the efficient integration of dialogue. Unlike gloss (sign language
transcription) annotations, dialogue naturally occurs in communication and is
easier to annotate. The key challenge lies in aligning multimodality features
while leveraging the context of the question to improve translation. To address
this issue, we propose a cross-modality Self-supervised Learning with Sigmoid
Self-attention Weighting (SSL-SSAW) fusion method for sign language
translation. Specifically, we employ contrastive learning to align
multimodality features in QB-SLT, then introduce a Sigmoid Self-attention
Weighting (SSAW) module for adaptive feature extraction from question and sign
language sequences. Additionally, we leverage available question text through
self-supervised learning to enhance representation and translation
capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and
PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,
easily accessible question assistance can achieve or even surpass the
performance of gloss assistance. Furthermore, visualization results demonstrate
the effectiveness of incorporating dialogue in improving translation quality.

</details>


### [38] [An AI-Powered Framework for Analyzing Collective Idea Evolution in Deliberative Assemblies](https://arxiv.org/abs/2509.12577)
*Elinor Poole-Dayan,Deb Roy,Jad Kabbara*

Main category: cs.CY

Relevance: 35.0

TL;DR: 该研究开发了基于LLM的方法来分析审议大会的转录文本，追踪观点演变和投票动态，为民主审议过程提供新的实证分析工具。


<details>
  <summary>Details</summary>
Motivation: 在政治极化和社会分裂加剧的背景下，代表性审议大会作为民主论坛日益重要，但缺乏系统追踪观点演变和优先排序的实证研究方法。

Method: 开发基于LLM的方法论，分析技术增强的面对面审议大会转录文本，识别和可视化表达建议的空间，重构代表观点演变过程。

Result: 该方法能够揭示传统大会输出中不可见的高分辨率动态，为审议过程提供新颖的实证见解。

Conclusion: LLM可以有效地用于分析复杂的民主审议过程，揭示观点形成和决策动态的微观机制。

Abstract: In an era of increasing societal fragmentation, political polarization, and
erosion of public trust in institutions, representative deliberative assemblies
are emerging as a promising democratic forum for developing effective policy
outcomes on complex global issues. Despite theoretical attention, there remains
limited empirical work that systematically traces how specific ideas evolve,
are prioritized, or are discarded during deliberation to form policy
recommendations. Addressing these gaps, this work poses two central questions:
(1) How might we trace the evolution and distillation of ideas into concrete
recommendations within deliberative assemblies? (2) How does the deliberative
process shape delegate perspectives and influence voting dynamics over the
course of the assembly? To address these questions, we develop LLM-based
methodologies for empirically analyzing transcripts from a tech-enhanced
in-person deliberative assembly. The framework identifies and visualizes the
space of expressed suggestions. We also empirically reconstruct each delegate's
evolving perspective throughout the assembly. Our methods contribute novel
empirical insights into deliberative processes and demonstrate how LLMs can
surface high-resolution dynamics otherwise invisible in traditional assembly
outputs.

</details>


### [39] [Long-context Reference-based MT Quality Estimation](https://arxiv.org/abs/2509.13980)
*Sami Ul Haq,Chinonso Cynthia Osuji,Sheila Castilho,Brian Davis*

Main category: cs.CL

Relevance: 30.0

TL;DR: 基于COMET框架构建的机器翻译质量评估系统，通过长上下文数据增强和多种人工标注数据集整合，提升了与人工评估的相关性


<details>
  <summary>Details</summary>
Motivation: 解决传统机器翻译质量评估中短片段训练的局限性，通过利用长上下文信息来更好地预测翻译质量

Method: 使用COMET框架，通过拼接领域内人工标注句子构建长上下文训练数据，整合MQM、SQM、DA等多种人工评估数据集，训练多语言回归模型

Result: 实验结果显示，相比仅使用短片段训练的模型，整合长上下文信息显著提高了与人工评估的相关性

Conclusion: 长上下文信息对于机器翻译质量评估具有重要价值，能够有效提升评估模型的性能

Abstract: In this paper, we present our submission to the Tenth Conference on Machine
Translation (WMT25) Shared Task on Automated Translation Quality Evaluation.
  Our systems are built upon the COMET framework and trained to predict
segment-level Error Span Annotation (ESA) scores using augmented long-context
data.
  To construct long-context training data, we concatenate in-domain,
human-annotated sentences and compute a weighted average of their scores.
  We integrate multiple human judgment datasets (MQM, SQM, and DA) by
normalising their scales and train multilingual regression models to predict
quality scores from the source, hypothesis, and reference translations.
  Experimental results show that incorporating long-context information
improves correlations with human judgments compared to models trained only on
short segments.

</details>


### [40] [CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset](https://arxiv.org/abs/2509.14161)
*Brian Yan,Injy Hamed,Shuichiro Shimizu,Vasista Lodagala,William Chen,Olga Iakovenko,Bashar Talafha,Amir Hussein,Alexander Polok,Kalvin Chang,Dominik Klement,Sara Althubaiti,Puyuan Peng,Matthew Wiesner,Thamar Solorio,Ahmed Ali,Sanjeev Khudanpur,Shinji Watanabe,Chih-Chen Chen,Zhen Wu,Karim Benharrak,Anuj Diwan,Samuele Cornell,Eunjung Yeo,Kwanghee Choi,Carlos Carvalho,Karen Rosero*

Main category: cs.CL

Relevance: 25.0

TL;DR: CS-FLEURS是一个新的代码切换语音识别和翻译数据集，包含4个测试集，覆盖113种语言对的52种语言，旨在推动低资源语言的代码切换研究。


<details>
  <summary>Details</summary>
Motivation: 当前代码切换语音研究主要局限于高资源语言，缺乏对低资源语言的支持。CS-FLEURS旨在填补这一空白，为开发更广泛的代码切换语音系统提供数据支持。

Method: 构建包含4个测试集的数据集：1）14种X-英语语言对的真实语音朗读合成代码切换句子；2）16种X-英语语言对的生成式文本转语音；3）60种{阿拉伯语、普通话、印地语、西班牙语}-X语言对的生成式文本转语音；4）45种X-英语低资源语言对的拼接式文本转语音。同时提供128小时的训练数据。

Result: 创建了覆盖113种独特代码切换语言对的数据集，涵盖52种语言，为代码切换语音研究提供了全面的基准测试资源。

Conclusion: CS-FLEURS数据集有助于扩大代码切换语音研究的范围，特别是在低资源语言方面，为未来研究提供了重要资源。

Abstract: We present CS-FLEURS, a new dataset for developing and evaluating
code-switched speech recognition and translation systems beyond high-resourced
languages. CS-FLEURS consists of 4 test sets which cover in total 113 unique
code-switched language pairs across 52 languages: 1) a 14 X-English language
pair set with real voices reading synthetically generated code-switched
sentences, 2) a 16 X-English language pair set with generative text-to-speech
3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the
generative text-to-speech, and 4) a 45 X-English lower-resourced language pair
test set with concatenative text-to-speech. Besides the four test sets,
CS-FLEURS also provides a training set with 128 hours of generative
text-to-speech data across 16 X-English language pairs. Our hope is that
CS-FLEURS helps to broaden the scope of future code-switched speech research.
Dataset link: https://huggingface.co/datasets/byan/cs-fleurs.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [41] [An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity](https://arxiv.org/abs/2509.13375)
*Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CV

Relevance: 75.0

TL;DR: 该论文系统分析了基于视觉语言模型(VLM)的零样本分布外检测机制，揭示了VLM相比单模态方法的优势源于语义新颖性利用，同时发现VLM对提示词措辞高度敏感的关键脆弱性


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等视觉语言模型在零样本分布外检测方面表现出色，但研究社区对其工作机制、相对于单模态方法的优势以及行为鲁棒性缺乏系统理解

Method: 使用分布内和分布外提示进行系统性实证分析，包括：1)形式化VLM嵌入空间的关键操作属性；2)量化比较VLM与单模态方法；3)评估对图像噪声和提示措辞的敏感性

Result: 1)揭示了VLM嵌入空间促进零样本OOD检测的关键机制；2)证实VLM优于单模态方法，优势来自语义新颖性利用；3)发现VLM对常见图像噪声具有鲁棒性，但对提示措辞高度敏感的不对称鲁棒性特征

Conclusion: 研究提供了对VLM基于OOD检测优势和关键脆弱性的结构化理解，为开发更鲁棒可靠的未来设计提供了实证指导

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.

</details>


### [42] [Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation](https://arxiv.org/abs/2509.13676)
*Xiaobo Yang,Xiaojin Gong*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出基于SAM语义超像素的视觉投影器，将视觉token减少93%而不损失性能，显著加速MLLM训练和推理


<details>
  <summary>Details</summary>
Motivation: 传统patch-wise视觉投影器在减少视觉token数量和保持语义清晰度之间难以平衡，通常保留过长的token序列以避免性能下降

Method: 利用SAM生成的语义超像素识别"视觉词汇"，通过压缩和投影语义超像素作为视觉token，根据场景复杂度自适应缩短token序列；提出语义超像素位置嵌入和聚合器来保持几何位置信息和细节

Result: 实验表明方法将视觉token减少93%而不影响性能，显著加速MLLM训练和推理，在RIS任务上优于现有压缩视觉投影器

Conclusion: 基于语义超像素的视觉投影方法有效解决了视觉token冗余问题，在保持性能的同时大幅提升效率

Abstract: Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify "visual words" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.

</details>


### [43] [Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks](https://arxiv.org/abs/2509.13338)
*Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出基于证据检索的不确定性感知决策机制，通过检索近邻样本并融合其预测分布来替代全局固定阈值，实现更可靠和可解释的决策


<details>
  <summary>Details</summary>
Motivation: 传统基于预测熵的全局阈值方法在不确定性感知决策中存在局限性，需要更透明、可审计且实例自适应的决策机制

Method: 为每个测试实例在嵌入空间中检索近邻样本，使用Dempster-Shafer理论融合这些证据的预测分布，生成每个实例自适应的阈值标准

Result: 在CIFAR-10/100数据集上，相比预测熵阈值方法，取得了相当或更好的不确定性感知性能，显著减少了错误置信预测，同时保持可持续的审查负载

Conclusion: 证据条件标记为操作不确定性感知决策提供了比固定预测熵阈值更可靠和可解释的替代方案，仅需少量证据即可实现显著改进

Abstract: This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.

</details>


### [44] [EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing](https://arxiv.org/abs/2509.13399)
*Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出了EdiVal-Agent，一个自动化的、细粒度的多轮指令图像编辑评估框架，通过对象中心视角结合VLM、目标检测器和人类偏好模型来评估指令遵循、内容一致性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑评估方法存在局限性：要么依赖配对的参考图像（覆盖范围有限且继承生成模型偏见），要么仅使用零样本VLM（评估不精确）。需要更可靠和可解释的评估框架。

Method: 1) 将图像分解为语义对象 2) 合成多样化的上下文感知编辑指令 3) 结合VLM和开放词汇目标检测器评估指令遵循 4) 使用语义级特征提取器评估内容一致性 5) 利用人类偏好模型判断视觉质量

Result: 相比单独使用VLM和CLIP指标，VLM与目标检测器结合在指令遵循评估中与人类判断有更强的一致性。模块化设计允许未来工具集成，提高评估准确性。

Conclusion: EdiVal-Agent能够识别现有编辑模型的失败模式，为下一代编辑模型的开发提供信息。框架具有可扩展性和模块化特性。

Abstract: Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision-language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.

</details>


### [45] [BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation](https://arxiv.org/abs/2509.13496)
*Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan*

Main category: cs.CV

Relevance: 65.0

TL;DR: BiasMap是一个模型无关的框架，用于发现稳定扩散模型中的潜在概念级表征偏见，通过交叉注意力归因图揭示人口统计特征与语义概念的结构性纠缠，并提出基于能量引导扩散采样的偏见缓解方法。


<details>
  <summary>Details</summary>
Motivation: 现有的偏见发现方法主要关注输出层面的人口统计分布，无法保证偏见缓解后概念表征的解耦。需要更深入地探索生成模型中的表征层面偏见。

Method: 利用交叉注意力归因图量化人口统计特征与语义概念的空间纠缠（通过IoU指标），并采用能量引导扩散采样在去噪过程中最小化SoftIoU期望值来缓解偏见。

Result: 研究发现现有公平性干预措施可能减少输出分布差距，但往往无法解耦概念级耦合，而BiasMap方法能够在图像生成中缓解概念纠缠，同时补充分布偏见缓解。

Conclusion: BiasMap提供了一个深入探索生成模型中隐藏表征偏见的框架，其缓解方法能有效处理概念级偏见，为更全面的偏见发现和缓解提供了新视角。

Abstract: Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not necessarily guarantee concept
representations to be disentangled post-mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable diffusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribution maps of
these concepts, we quantify the spatial demographics-semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness discovery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU during the denoising process. Our findings show that existing fairness
interventions may reduce the output distributional gap but often fail to
disentangle concept-level coupling, whereas our mitigation method can mitigate
concept entanglement in image generation while complementing distributional
bias mitigation.

</details>


### [46] [DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](https://arxiv.org/abs/2509.13506)
*Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane*

Main category: cs.CV

Relevance: 65.0

TL;DR: DEFT-VTON：基于Doob's h-transform高效微调方法，仅需训练1.42%参数即可将无条件扩散模型适配到虚拟试穿任务，结合自适应一致性损失实现15步快速推理的SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法需要端到端训练大型预训练模型，但实际应用需要有限的训练和推理预算。需要一种参数高效的方法来适配预训练模型到下游任务

Method: 1. DEFT：冻结预训练模型参数，训练小型h-transform网络学习条件变换，仅训练1.42%参数
2. 自适应一致性损失：结合一致性损失和去噪分数匹配损失，以数据自适应方式微调模型
3. 仅需15步去噪步骤实现快速推理

Result: 在虚拟试穿任务上达到state-of-the-art性能，仅需15步推理步骤，同时保持竞争性结果。相比传统参数高效微调方法（5.52%参数），仅需训练1.42%参数

Conclusion: DEFT-VTON提供了一种参数高效的方法来适配预训练扩散模型到条件生成任务，在保持性能的同时显著减少训练和推理成本

Abstract: Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.

</details>


### [47] [Iterative Prompt Refinement for Safer Text-to-Image Generation](https://arxiv.org/abs/2509.13760)
*Jinwoo Jeon,JunHyeok Oh,Hayeong Lee,Byung-Jun Lee*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出基于视觉反馈的迭代提示词优化方法，使用VLM分析文本提示和生成图像，提升文本到图像模型的安全性同时保持用户意图


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的安全方法只关注文本提示而忽略生成图像，可能导致不安全输出或对安全提示的不必要修改

Method: 迭代提示词优化算法，利用视觉语言模型(VLM)分析输入提示和生成图像，通过视觉反馈更有效地优化提示

Result: 实验结果表明该方法能生成更安全的输出，同时保持与用户意图的对齐，安全性优于现有LLM方法

Conclusion: 该方法为生成更安全的T2I内容提供了实用解决方案，结合文本和视觉安全信号进行监督微调

Abstract: Text-to-Image (T2I) models have made remarkable progress in generating images
from text prompts, but their output quality and safety still depend heavily on
how prompts are phrased. Existing safety methods typically refine prompts using
large language models (LLMs), but they overlook the images produced, which can
result in unsafe outputs or unnecessary changes to already safe prompts. To
address this, we propose an iterative prompt refinement algorithm that uses
Vision Language Models (VLMs) to analyze both the input prompts and the
generated images. By leveraging visual feedback, our method refines prompts
more effectively, improving safety while maintaining user intent and
reliability comparable to existing LLM-based approaches. Additionally, we
introduce a new dataset labeled with both textual and visual safety signals
using off-the-shelf multi-modal LLM, enabling supervised fine-tuning.
Experimental results demonstrate that our approach produces safer outputs
without compromising alignment with user intent, offering a practical solution
for generating safer T2I content. Our code is available at
https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper
contains examples of harmful or inappropriate images generated by models.

</details>


### [48] [Multimodal Hate Detection Using Dual-Stream Graph Neural Networks](https://arxiv.org/abs/2509.13515)
*Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出了一种新颖的多模态双流图神经网络模型，用于仇恨视频检测，通过分离视频实例并分配重要性权重来突出仇恨内容，在公开数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态分类方法通常忽视仇恨内容的关键性，对所有内容一视同仁，且无法系统捕捉视频中的结构化信息，限制了多模态融合效果。

Method: 构建实例图分离视频为多个实例提取特征，通过互补权重图为特征分配重要性权重以突出仇恨实例，结合权重和特征生成视频标签，使用图框架系统建模模态内和跨模态的结构关系。

Result: 在公开数据集上的广泛实验表明，该模型在仇恨视频分类方面达到最先进水平，并具有很强的可解释性。

Conclusion: 提出的多模态双流图神经网络模型有效解决了仇恨视频检测中的关键问题，通过强调仇恨内容和系统建模结构化关系，实现了优越的分类性能和可解释性。

Abstract: Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.

</details>


### [49] [Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation](https://arxiv.org/abs/2509.13590)
*Samer Al-Hamadani*

Main category: cs.CV

Relevance: 45.0

TL;DR: 该论文提出了一个基于Vision-Language Models的多模态医疗影像分析框架，集成Google Gemini 2.5 Flash进行肿瘤检测和临床报告生成，支持CT、MRI、X-ray和超声等多种成像模态。


<details>
  <summary>Details</summary>
Motivation: 医疗影像AI的快速发展需要更智能的多模态分析框架，以提升诊断准确性和临床决策效率，减少对大型数据集的依赖。

Method: 结合视觉特征提取和自然语言处理，采用坐标验证机制和高斯概率建模进行异常分布分析，使用多层可视化技术和精确的提示工程。

Result: 在多模态异常检测中表现优异，位置测量平均偏差80像素，具备零样本学习能力，用户友好的Gradio界面便于临床工作流集成。

Conclusion: 该框架在自动化诊断支持和放射工作流效率方面有显著进展，但需要临床验证和多中心评估才能广泛应用。

Abstract: The rapid advancement of artificial intelligence (AI) in healthcare imaging
has revolutionized diagnostic medicine and clinical decision-making processes.
This work presents an intelligent multimodal framework for medical image
analysis that leverages Vision-Language Models (VLMs) in healthcare
diagnostics. The framework integrates Google Gemini 2.5 Flash for automated
tumor detection and clinical report generation across multiple imaging
modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual
feature extraction with natural language processing to enable contextual image
interpretation, incorporating coordinate verification mechanisms and
probabilistic Gaussian modeling for anomaly distribution. Multi-layered
visualization techniques generate detailed medical illustrations, overlay
comparisons, and statistical representations to enhance clinical confidence,
with location measurement achieving 80 pixels average deviation. Result
processing utilizes precise prompt engineering and textual analysis to extract
structured clinical information while maintaining interpretability.
Experimental evaluations demonstrated high performance in anomaly detection
across multiple modalities. The system features a user-friendly Gradio
interface for clinical workflow integration and demonstrates zero-shot learning
capabilities to reduce dependence on large datasets. This framework represents
a significant advancement in automated diagnostic support and radiological
workflow efficiency, though clinical validation and multi-center evaluation are
necessary prior to widespread adoption.

</details>


### [50] [StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models](https://arxiv.org/abs/2509.13711)
*Qiuyu Tang,Joshua Krinsky,Aparna Bharati*

Main category: cs.CV

Relevance: 45.0

TL;DR: 本文提出StyleProtect方法，通过选择性更新扩散模型中特定的cross-attention层来有效防御针对艺术风格的恶意模仿攻击，在保持不可感知性的同时保护艺术作品的独特风格。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型特别是扩散模型的快速发展，恶意使用者可以低成本地复制艺术家的独特风格，这导致了对艺术作品风格模仿保护方法的需求增加。本文旨在解决扩散模型微调后对艺术风格的高度模仿问题。

Method: 研究发现某些cross-attention层对艺术风格特别敏感，基于此提出了StyleProtect方法：通过测量attention层对风格和内容表示的激活强度，选择性地更新特定cross-attention层来实现有效的风格防御。

Result: 实验使用基于WikiArt的精心策划数据集（包含30位知名艺术家的代表性作品）和Anita卡通动画数据集，证明该方法在保护艺术作品和动漫独特风格方面表现出色，同时保持竞争性的不可感知性。

Conclusion: StyleProtect提供了一种高效轻量的保护策略，能够有效防御微调扩散模型的风格模仿攻击，为艺术作品版权保护提供了实用解决方案。

Abstract: The rapid advancement of generative models, particularly diffusion-based
approaches, has inadvertently facilitated their potential for misuse. Such
models enable malicious exploiters to replicate artistic styles that capture an
artist's creative labor, personal vision, and years of dedication in an
inexpensive manner. This has led to a rise in the need and exploration of
methods for protecting artworks against style mimicry. Although generic
diffusion models can easily mimic an artistic style, finetuning amplifies this
capability, enabling the model to internalize and reproduce the style with
higher fidelity and control. We hypothesize that certain cross-attention layers
exhibit heightened sensitivity to artistic styles. Sensitivity is measured
through activation strengths of attention layers in response to style and
content representations, and assessing their correlations with features
extracted from external models. Based on our findings, we introduce an
efficient and lightweight protection strategy, StyleProtect, that achieves
effective style defense against fine-tuned diffusion models by updating only
selected cross-attention layers. Our experiments utilize a carefully curated
artwork dataset based on WikiArt, comprising representative works from 30
artists known for their distinctive and influential styles and cartoon
animations from the Anita dataset. The proposed method demonstrates promising
performance in safeguarding unique styles of artworks and anime from malicious
diffusion customization, while maintaining competitive imperceptibility.

</details>


### [51] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

Relevance: 40.0

TL;DR: MapAnything是一个统一的基于Transformer的前馈模型，能够处理单张或多张图像及可选几何输入，直接回归度量3D场景几何和相机参数，在多种3D视觉任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决3D视觉任务中需要多个专门模型的问题，研究者希望开发一个统一的模型来处理多种3D重建任务，通过标准化监督和训练来实现通用3D重建骨干网络。

Method: 使用基于Transformer的前馈架构，输入图像和可选几何信息，采用分解的多视图场景几何表示（深度图、局部射线图、相机位姿和度量尺度因子），通过灵活的输入增强和跨数据集标准化训练。

Result: MapAnything在未标定运动恢复结构、标定多视图立体、单目深度估计、相机定位、深度补全等任务上表现优于或匹配专门的前馈模型，同时提供更高效的联合训练性能。

Conclusion: 该工作为通用3D重建骨干网络铺平了道路，展示了统一模型在多种3D视觉任务上的潜力。

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [52] [FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation](https://arxiv.org/abs/2509.13508)
*Maksim Penkin,Andrey Krylov*

Main category: cs.CV

Relevance: 35.0

TL;DR: FunKAN：一种基于函数空间Kolmogorov-Arnold表示定理的可解释神经网络框架，专门用于医学图像处理，在图像增强和分割任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在医学图像处理中缺乏可解释性，而现有KAN网络会破坏图像的空间结构信息，需要一种既能保持可解释性又能处理空间结构的方法

Method: 提出Functional Kolmogorov-Arnold Network (FunKAN)，将Kolmogorov-Arnold表示定理推广到函数空间，使用傅里叶分解和Hermite基函数学习内部函数

Result: 在IXI数据集上实现Gibbs ringing抑制，在BUSI、GlaS、CVC-ClinicDB三个医学数据集上实现最先进的二值分割，在PSNR、TV、IoU、F1等指标上优于其他KAN方法

Conclusion: FunKAN成功将理论函数逼近与医学图像分析相结合，为临床应用提供了鲁棒且可解释的解决方案

Abstract: Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.

</details>


### [53] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

Relevance: 35.0

TL;DR: 本文提出了一种用于自动驾驶车辆轨迹预测的自适应OOD检测框架，通过显式建模预测误差模式，在检测延迟和误报率方面显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在部署中面临训练数据与真实世界条件之间的分布偏移问题，现有OOD检测研究主要集中在计算机视觉任务，轨迹级别的OOD检测研究相对不足

Method: 基于快速变化检测(QCD)任务，引入自适应机制来建模预测误差的模式依赖性分布，这些分布随时间演变并具有数据集特定的动态特性

Result: 在多个真实世界数据集上的实验表明，该方法在检测延迟和误报率方面都取得了显著改进，在准确性和计算效率上均优于现有的UQ和基于视觉的OOD方法

Conclusion: 该框架为可靠的、驾驶感知的自主性提供了一条实用路径，能够有效处理复杂驾驶环境中的分布偏移问题

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [54] [SAMIR, an efficient registration framework via robust feature learning from SAM](https://arxiv.org/abs/2509.13629)
*Yue He,Min Liu,Qinghao Liu,Jiazheng Wang,Yaonan Wang,Hang Zhang,Xiang Chen*

Main category: cs.CV

Relevance: 35.0

TL;DR: SAMIR是一个利用Segment Anything Model (SAM)进行医学图像配准的高效框架，通过SAM提取结构感知特征嵌入，结合轻量级3D头部和分层特征一致性损失，在心脏和腹部CT图像配准任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学图像配准中变形与组织形态特征密切相关，需要准确的特征提取。现有的弱监督方法依赖分割掩码或地标等解剖先验，但这些标签通常难以获取，限制了实际应用。受视觉基础模型强大表示学习能力的启发，利用SAM来增强特征提取。

Method: 设计任务特定的适应管道，使用SAM的图像编码器提取结构感知特征嵌入；设计轻量级3D头部在嵌入空间内细化特征；引入分层特征一致性损失指导从粗到细的特征匹配。

Result: 在心脏图像配准(ACDC数据集)上性能提升2.68%，在腹部CT图像配准上性能提升6.44%，显著优于最先进方法。

Conclusion: SAMIR框架成功利用预训练的视觉基础模型SAM来增强医学图像配准的特征提取能力，证明了基础模型在医学图像分析任务中的有效迁移和应用价值。

Abstract: Image registration is a fundamental task in medical image analysis.
Deformations are often closely related to the morphological characteristics of
tissues, making accurate feature extraction crucial. Recent weakly supervised
methods improve registration by incorporating anatomical priors such as
segmentation masks or landmarks, either as inputs or in the loss function.
However, such weak labels are often not readily available, limiting their
practical use. Motivated by the strong representation learning ability of
visual foundation models, this paper introduces SAMIR, an efficient medical
image registration framework that utilizes the Segment Anything Model (SAM) to
enhance feature extraction. SAM is pretrained on large-scale natural image
datasets and can learn robust, general-purpose visual representations. Rather
than using raw input images, we design a task-specific adaptation pipeline
using SAM's image encoder to extract structure-aware feature embeddings,
enabling more accurate modeling of anatomical consistency and deformation
patterns. We further design a lightweight 3D head to refine features within the
embedding space, adapting to local deformations in medical images.
Additionally, we introduce a Hierarchical Feature Consistency Loss to guide
coarse-to-fine feature matching and improve anatomical alignment. Extensive
experiments demonstrate that SAMIR significantly outperforms state-of-the-art
methods on benchmark datasets for both intra-subject cardiac image registration
and inter-subject abdomen CT image registration, achieving performance
improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code
will be publicly available on GitHub following the acceptance of this paper.

</details>


### [55] [Deep Lookup Network](https://arxiv.org/abs/2509.13662)
*Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一种用查找表操作替代传统乘法运算的方法来构建高效神经网络，在图像分类、超分辨率和点云分类任务中实现了更高的能效和推理速度，同时保持与原始卷积网络相当的性能。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络中的乘法运算计算复杂度高、能耗大，阻碍了在移动设备上的部署。受资源受限边缘设备使用查找表简化计算的启发，作者希望用高效的查找操作替代乘法运算来构建神经网络。

Method: 提出了一种通用的可微分查找表操作，通过查找表计算权重和激活值的响应而非直接相乘。设计了多种训练策略来促进查找表的端到端优化，并将该方法应用于图像分类、超分辨率和点云分类任务。

Result: 实验表明，查找网络在能耗和推理速度方面效率更高，同时在各种任务（分类和回归）和数据类型（图像和点云）上都能达到与原始卷积网络竞争的性能，甚至在某些任务上实现了最先进的表现。

Conclusion: 查找表操作是一种有效的替代乘法运算的方法，能够显著提升神经网络在边缘设备上的部署效率，同时保持模型性能。

Abstract: Convolutional neural networks are constructed with massive operations with
different types and are highly computationally intensive. Among these
operations, multiplication operation is higher in computational complexity and
usually requires {more} energy consumption with longer inference time than
other operations, which hinders the deployment of convolutional neural networks
on mobile devices. In many resource-limited edge devices, complicated
operations can be calculated via lookup tables to reduce computational cost.
Motivated by this, in this paper, we introduce a generic and efficient lookup
operation which can be used as a basic operation for the construction of neural
networks. Instead of calculating the multiplication of weights and activation
values, simple yet efficient lookup operations are adopted to compute their
responses. To enable end-to-end optimization of the lookup operation, we
construct the lookup tables in a differentiable manner and propose several
training strategies to promote their convergence. By replacing computationally
expensive multiplication operations with our lookup operations, we develop
lookup networks for the image classification, image super-resolution, and point
cloud classification tasks. It is demonstrated that our lookup networks can
benefit from the lookup operations to achieve higher efficiency in terms of
energy consumption and inference speed while maintaining competitive
performance to vanilla convolutional networks. Extensive experiments show that
our lookup networks produce state-of-the-art performance on different tasks
(both classification and regression tasks) and different data types (both
images and point clouds).

</details>


### [56] [Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification](https://arxiv.org/abs/2509.13687)
*Kaniz Fatema,Emad A. Mohammed,Sukhjit Singh Sehra*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该研究提出基于样条的Kolmogorov-Arnold网络(KANs)用于医学图像分类，包括SBTAYLOR-KAN、SBRBF-KAN和SBWAVELET-KAN三种变体，在有限数据集上实现高精度分类，参数量远少于传统CNN模型。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限临床环境中医学图像分类的挑战，特别是在数据集有限且多样的情况下，需要开发轻量级、可解释且泛化能力强的分类模型。

Method: 提出三种基于样条的KAN变体：SBTAYLOR-KAN（B样条+泰勒级数）、SBRBF-KAN（B样条+径向基函数）、SBWAVELET-KAN（B样条+Morlet小波变换），利用样条函数逼近捕捉局部和全局非线性特征。

Result: 在脑部MRI、胸部X光、结核X光和皮肤病变图像上评估，SBTAYLOR-KAN达到98.93%准确率，仅使用30%训练数据仍保持86%以上准确率。相比ResNet50的2418万参数，SBTAYLOR-KAN仅需2872个可训练参数。

Conclusion: 该框架为医学图像分类提供了轻量级、可解释且泛化性强的解决方案，特别适合数据稀缺的临床AI应用场景。

Abstract: Effective and interpretable classification of medical images is a challenge
in computer-aided diagnosis, especially in resource-limited clinical settings.
This study introduces spline-based Kolmogorov-Arnold Networks (KANs) for
accurate medical image classification with limited, diverse datasets. The
models include SBTAYLOR-KAN, integrating B-splines with Taylor series;
SBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,
embedding B-splines in Morlet wavelet transforms. These approaches leverage
spline-based function approximation to capture both local and global
nonlinearities. The models were evaluated on brain MRI, chest X-rays,
tuberculosis X-rays, and skin lesion images without preprocessing,
demonstrating the ability to learn directly from raw data. Extensive
experiments, including cross-dataset validation and data reduction analysis,
showed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%
accuracy, with a balanced F1-score, maintaining over 86% accuracy using only
30% of the training data across three datasets. Despite class imbalance in the
skin cancer dataset, experiments on both imbalanced and balanced versions
showed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.
Unlike traditional CNNs, which require millions of parameters (e.g., ResNet50
with 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872
trainable parameters, making it more suitable for constrained medical
environments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used
for interpretability, highlighting relevant regions in medical images. This
framework provides a lightweight, interpretable, and generalizable solution for
medical image classification, addressing the challenges of limited datasets and
data-scarce scenarios in clinical AI applications.

</details>


### [57] [Mitigating Query Selection Bias in Referring Video Object Segmentation](https://arxiv.org/abs/2509.13722)
*Dingwei Zhang,Dong Zhang,Jinhui Tang*

Main category: cs.CV

Relevance: 35.0

TL;DR: TQF将引用查询分解为三个专门组件：外观查询、帧内交互查询和帧间运动查询，通过动态构建查询和运动感知聚合模块解决查询选择偏差问题，在多个RVOS基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的基于查询的引用视频对象分割方法使用静态文本查询进行跨模态对齐，但容易被外观或运动相似的干扰物误导，导致查询选择偏差问题。

Method: 提出Triple Query Former (TQF)，将引用查询分解为三个专门组件：外观查询（静态属性）、帧内交互查询（空间关系）和帧间运动查询（时间关联）。查询通过语言线索和视觉指导动态构建，并引入帧内交互聚合和帧间运动聚合两个运动感知模块来增强对象标记表示。

Result: 在多个RVOS基准测试上的广泛实验证明了TQF的优势以及结构化查询设计和运动感知聚合模块的有效性。

Conclusion: 通过将引用查询分解为三个专门组件并引入运动感知聚合机制，TQF有效解决了查询选择偏差问题，提升了引用视频对象分割的性能。

Abstract: Recently, query-based methods have achieved remarkable performance in
Referring Video Object Segmentation (RVOS) by using textual static object
queries to drive cross-modal alignment. However, these static queries are
easily misled by distractors with similar appearance or motion, resulting in
\emph{query selection bias}. To address this issue, we propose Triple Query
Former (TQF), which factorizes the referring query into three specialized
components: an appearance query for static attributes, an intra-frame
interaction query for spatial relations, and an inter-frame motion query for
temporal association. Instead of relying solely on textual embeddings, our
queries are dynamically constructed by integrating both linguistic cues and
visual guidance. Furthermore, we introduce two motion-aware aggregation modules
that enhance object token representations: Intra-frame Interaction Aggregation
incorporates position-aware interactions among objects within a single frame,
while Inter-frame Motion Aggregation leverages trajectory-guided alignment
across frames to ensure temporal coherence. Extensive experiments on multiple
RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our
structured query design and motion-aware aggregation modules.

</details>


### [58] [Improving Generalized Visual Grounding with Instance-aware Joint Learning](https://arxiv.org/abs/2509.13747)
*Ming Dai,Wenxuan Cheng,Jiang-Jiang Liu,Lingfeng Yang,Zhenhua Feng,Wankou Yang,Jingdong Wang*

Main category: cs.CV

Relevance: 35.0

TL;DR: InstanceVG是一个多任务广义视觉定位框架，首次同时处理GREC和GRES任务，通过实例查询实现实例级框和掩码的一致预测，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立处理广义指代理解(GREC)和分割(GRES)任务，忽视了联合训练的优势，且GRES方法缺乏实例感知能力，无法保证实例级框和掩码预测的一致性。

Method: 提出InstanceVG框架，使用实例查询统一实例级框和掩码的联合一致性预测，为每个实例查询分配先验参考点，促进点、框、掩码的一致预测。

Result: 在10个数据集4个任务上的实验表明，InstanceVG在各项评估指标上显著超越现有方法，达到最先进性能。

Conclusion: InstanceVG是首个同时处理GREC和GRES并融入实例感知能力的广义视觉定位框架，通过实例查询机制实现了多粒度预测的一致性。

Abstract: Generalized visual grounding tasks, including Generalized Referring
Expression Comprehension (GREC) and Segmentation (GRES), extend the classical
visual grounding paradigm by accommodating multi-target and non-target
scenarios. Specifically, GREC focuses on accurately identifying all referential
objects at the coarse bounding box level, while GRES aims for achieve
fine-grained pixel-level perception. However, existing approaches typically
treat these tasks independently, overlooking the benefits of jointly training
GREC and GRES to ensure consistent multi-granularity predictions and streamline
the overall process. Moreover, current methods often treat GRES as a semantic
segmentation task, neglecting the crucial role of instance-aware capabilities
and the necessity of ensuring consistent predictions between instance-level
boxes and masks. To address these limitations, we propose InstanceVG, a
multi-task generalized visual grounding framework equipped with instance-aware
capabilities, which leverages instance queries to unify the joint and
consistency predictions of instance-level boxes and masks. To the best of our
knowledge, InstanceVG is the first framework to simultaneously tackle both GREC
and GRES while incorporating instance-aware capabilities into generalized
visual grounding. To instantiate the framework, we assign each instance query a
prior reference point, which also serves as an additional basis for target
matching. This design facilitates consistent predictions of points, boxes, and
masks for the same instance. Extensive experiments obtained on ten datasets
across four tasks demonstrate that InstanceVG achieves state-of-the-art
performance, significantly surpassing the existing methods in various
evaluation metrics. The code and model will be publicly available at
https://github.com/Dmmm1997/InstanceVG.

</details>


### [59] [Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2509.13754)
*Hao Yin,Xin Man,Feiyu Chen,Jie Shao,Heng Tao Shen*

Main category: cs.CV

Relevance: 35.0

TL;DR: FMFA是一个跨模态全模式细粒度对齐框架，通过显式细粒度对齐和隐式关系推理来改进文本-图像人物检索任务，在三个公开数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决文本-图像人物检索中跨模态对齐的挑战，现有方法缺乏验证局部特征是否正确对齐的能力，且主要关注困难负样本而忽略了错误匹配的正样本对。

Method: 提出自适应相似度分布匹配(A-SDM)模块来修正未匹配的正样本对，以及显式细粒度对齐(EFA)模块来加强显式跨模态细粒度交互，通过稀疏化相似度矩阵和硬编码方法实现局部对齐。

Result: 在三个公开数据集上实现了所有全局匹配方法中的最先进性能。

Conclusion: FMFA框架通过全模式对齐策略有效提升了跨模态检索的精度，无需额外监督即可实现更好的全局和局部对齐。

Abstract: Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that
aims to retrieve the most relevant person images based on a given text query.
The key challenge in TIPR lies in achieving effective alignment between textual
and visual modalities within a common latent space. To address this challenge,
prior approaches incorporate attention mechanisms for implicit cross-modal
local alignment. However, they lack the ability to verify whether all local
features are correctly aligned. Moreover, existing methods primarily focus on
hard negative samples during model updates, with the goal of refining
distinctions between positive and negative pairs, often neglecting incorrectly
matched positive pairs. To alleviate these issues, we propose FMFA, a
cross-modal Full-Mode Fine-grained Alignment framework, which enhances global
matching through explicit fine-grained alignment and existing implicit
relational reasoning -- hence the term ``full-mode" -- without requiring
additional supervision. Specifically, we design an Adaptive Similarity
Distribution Matching (A-SDM) module to rectify unmatched positive sample
pairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint
embedding space, thereby achieving more precise global alignment. Additionally,
we introduce an Explicit Fine-grained Alignment (EFA) module, which makes up
for the lack of verification capability of implicit relational reasoning. EFA
strengthens explicit cross-modal fine-grained interactions by sparsifying the
similarity matrix and employs a hard coding method for local alignment. Our
proposed method is evaluated on three public datasets, achieving
state-of-the-art performance among all global matching methods. Our code is
available at https://github.com/yinhao1102/FMFA.

</details>


### [60] [ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors](https://arxiv.org/abs/2509.13525)
*Romain Hardy,Tyler Berzin,Pranav Rajpurkar*

Main category: cs.CV

Relevance: 30.0

TL;DR: ColonCrafter是一个基于扩散模型的深度估计方法，专门用于结肠镜视频的时序一致深度图生成，在C3VD数据集上实现了最先进的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜3D场景理解需要自动化深度估计方法，但现有内窥镜深度估计模型在视频序列中缺乏时序一致性，限制了3D重建的应用。

Method: 使用基于扩散的深度估计模型，从合成结肠镜序列学习几何先验来生成时序一致的深度图，并引入风格迁移技术将真实临床视频适配到合成训练域。

Result: 在C3VD数据集上实现了最先进的零样本性能，优于通用和特定于内窥镜的方法，支持3D点云生成和表面覆盖评估等临床应用。

Conclusion: 虽然完整轨迹3D重建仍具挑战性，但ColonCrafter展示了在临床相关应用中的潜力，包括3D点云生成和表面覆盖评估。

Abstract: Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.

</details>


### [61] [Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization](https://arxiv.org/abs/2509.13474)
*Yujia Lin,Nicholas Evans*

Main category: cs.CV

Relevance: 25.0

TL;DR: SCM-PR是一个结合RGB图像和LiDAR地图的跨模态位置识别框架，通过语义增强和几何特征融合，在复杂场景中实现鲁棒的机器人定位。


<details>
  <summary>Details</summary>
Motivation: 解决RGB图像在光照、天气和季节变化下的敏感性问题，以及现有跨模态定位方法在复杂场景、细粒度匹配和视角变化下的性能不足。

Method: 提出SCM-PR框架：使用VMamba主干网络提取RGB特征；语义感知特征融合模块；结合语义和几何的LiDAR描述符；跨模态语义注意力机制；多视角语义-几何匹配和语义一致性损失。

Result: 在KITTI和KITTI-360数据集上实现了state-of-the-art性能，相比其他跨模态位置识别方法表现更优。

Conclusion: 通过语义增强和跨模态融合，显著提升了在复杂环境下的机器人定位鲁棒性和准确性。

Abstract: Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.

</details>


### [62] [Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization](https://arxiv.org/abs/2509.13482)
*Hao Xu,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

Relevance: 25.0

TL;DR: 本文提出SALVQ方法，用场景自适应格点向量量化替代均匀标量量化，提升3D高斯泼溅数据的压缩性能，实现更好的率失真效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术虽然渲染质量高且实时性好，但数据量巨大需要压缩。现有方法使用简单的均匀标量量化，但更复杂的量化器可能带来更好的压缩效果。

Method: 采用格点向量量化(LVQ)替代均匀标量量化，并为每个场景优化格点基向量，提出场景自适应LVQ(SALVQ)方法，可无缝集成到现有3DGS压缩架构中。

Result: SALVQ在率失真效率上优于均匀标量量化，通过缩放格点基向量可动态调整压缩率，单个模型支持多比特率目标，减少训练时间和内存消耗。

Conclusion: 场景自适应格点向量量化是提升3D高斯泼溅数据压缩性能的有效方法，在保持低复杂度的同时提供更好的压缩效率和灵活性。

Abstract: 3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.

</details>


### [63] [MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes](https://arxiv.org/abs/2509.13484)
*Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了MINGLE框架，用于从街景图像中检测社交群体区域，通过三阶段流程整合人体检测、深度估计、VLM推理和空间聚合算法。


<details>
  <summary>Details</summary>
Motivation: 理解公共场所的群体社交互动对城市规划至关重要，需要超越传统物体检测的复杂语义信号分析。

Method: 三阶段模块化流程：1)现成的人体检测和深度估计 2)VLM推理分类成对社交关系 3)轻量级空间聚合算法定位社交群体

Result: 构建了包含10万张街景图像的新数据集，标注了个人和社交群体的边界框和标签，结合人工标注和MINGLE输出。

Conclusion: 提出了社交群体区域检测新任务和MINGLE解决方案，为未来研究提供了丰富的数据集和基准。

Abstract: Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.

</details>


### [64] [Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving](https://arxiv.org/abs/2509.13507)
*Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari*

Main category: cs.CV

Relevance: 25.0

TL;DR: 本文提出了一种数据增强流水线，通过在Cityscapes数据集中添加虚拟行人来改善自动驾驶中的行人识别，并引入新的生成对抗网络架构来提升光照条件的真实性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要合成数据来覆盖特定交通场景，但合成数据与真实数据之间存在领域差距。为了解决这个问题，需要生成包含弱势道路使用者（VRUs）的自定义交通场景来提升行人识别性能。

Method: 1) 开发数据增强流水线，在Cityscapes数据集中添加虚拟行人
2) 提出新颖的生成对抗网络架构，用于对抗学习数据集的光照条件，提高增强的真实性

Result: 在语义分割和实例分割任务上评估了该方法，但具体结果未在摘要中详细说明

Conclusion: 该方法通过数据增强和光照条件对抗学习，能够生成更真实的合成数据，有助于缩小合成与真实数据之间的领域差距，提升行人识别性能

Abstract: In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.

</details>


### [65] [Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery](https://arxiv.org/abs/2509.13631)
*Yuvraj Dutta,Aaditya Sikder,Basabdatta Palit*

Main category: cs.CV

Relevance: 25.0

TL;DR: 本文提出了一种基于联邦学习(FL)的分布式方法，利用卫星图像进行森林砍伐识别，通过FLOWER和RAY框架实现隐私保护的分布式训练，比较了YOLOS-small、Faster R-CNN等模型在卫星图像分割任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 传统集中式训练方法需要合并数据，会损害客户端的数据安全和隐私。联邦学习能够在保护数据隐私的前提下，让分布式网络客户端协作训练模型，特别适合卫星图像处理这种对数据安全要求高的场景。

Method: 使用FLOWER框架和RAY框架构建联邦学习系统，客户端对应边缘卫星中心。比较了三种模型：YOLOS-small（Vision Transformer变体）、基于ResNet50的Faster R-CNN、基于MobileNetV3的Faster R-CNN，在公开数据集上进行训练和测试。

Result: 该方法为卫星图像分割任务提供了新的视角，实现了在保护数据隐私前提下的分布式森林砍伐识别。

Conclusion: 联邦学习为卫星图像分析提供了一种有效的隐私保护解决方案，特别是在需要多客户端协作但又要确保数据安全的场景中具有优势。

Abstract: Accurate identification of deforestation from satellite images is essential
in order to understand the geographical situation of an area. This paper
introduces a new distributed approach to identify as well as locate
deforestation across different clients using Federated Learning (FL). Federated
Learning enables distributed network clients to collaboratively train a model
while maintaining data privacy and security of the active users. In our
framework, a client corresponds to an edge satellite center responsible for
local data processing. Moreover, FL provides an advantage over centralized
training method which requires combining data, thereby compromising with data
security of the clients. Our framework leverages the FLOWER framework with RAY
framework to execute the distributed learning workload. Furthermore, efficient
client spawning is ensured by RAY as it can select definite amount of users to
create an emulation environment. Our FL framework uses YOLOS-small (a Vision
Transformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN
with a MobileNetV3 backbone models trained and tested on publicly available
datasets. Our approach provides us a different view for image
segmentation-based tasks on satellite imagery.

</details>


### [66] [UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry](https://arxiv.org/abs/2509.13713)
*Tae-Wook Um,Ki-Hyeon Kim,Hyun-Duck Choi,Hyo-Sung Ahn*

Main category: cs.CV

Relevance: 25.0

TL;DR: UM-Depth是一个自监督单目深度估计框架，通过运动感知和不确定性感知的细化方法，在动态物体边界和纹理缺失区域提高深度估计精度，无需额外标签或运行时开销。


<details>
  <summary>Details</summary>
Motivation: 自监督单目深度估计方法在低纹理或动态区域存在不确定性，导致深度精度降低。需要一种方法能够在这些挑战性区域增强深度估计准确性，同时避免推理时的额外计算开销。

Method: 提出UM-Depth框架，采用师生训练策略，将不确定性估计嵌入训练流程和网络架构。仅在教师网络训练时使用光流，避免推理时额外计算。结合运动感知和不确定性感知的细化方法。

Result: 在KITTI和Cityscapes数据集上的广泛实验表明，该方法在不确定性感知细化方面有效。在KITTI数据集上实现了自监督深度和姿态估计的最先进结果。

Conclusion: UM-Depth通过结合运动感知和不确定性感知的细化，成功提高了在动态物体边界和纹理缺失区域的深度估计精度，且无需额外标签或运行时成本。

Abstract: Monocular depth estimation has been increasingly adopted in robotics and
autonomous driving for its ability to infer scene geometry from a single
camera. In self-supervised monocular depth estimation frameworks, the network
jointly generates and exploits depth and pose estimates during training,
thereby eliminating the need for depth labels. However, these methods remain
challenged by uncertainty in the input data, such as low-texture or dynamic
regions, which can cause reduced depth accuracy. To address this, we introduce
UM-Depth, a framework that combines motion- and uncertainty-aware refinement to
enhance depth accuracy at dynamic object boundaries and in textureless regions.
Specifically, we develop a teacherstudent training strategy that embeds
uncertainty estimation into both the training pipeline and network
architecture, thereby strengthening supervision where photometric signals are
weak. Unlike prior motion-aware approaches that incur inference-time overhead
and rely on additional labels or auxiliary networks for real-time generation,
our method uses optical flow exclusively within the teacher network during
training, which eliminating extra labeling demands and any runtime cost.
Extensive experiments on the KITTI and Cityscapes datasets demonstrate the
effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves
state-of-the-art results in both self-supervised depth and pose estimation on
the KITTI datasets.

</details>


### [67] [Task-Aware Image Signal Processor for Advanced Visual Perception](https://arxiv.org/abs/2509.13762)
*Kai Chen,Jin Xiao,Leheng Zhang,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

Relevance: 25.0

TL;DR: TA-ISP是一个紧凑的RAW-to-RGB框架，通过预测轻量级多尺度调制算子来生成面向任务的图像表示，显著降低计算开销同时提升下游视觉任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAW数据处理方法存在两个关键限制：大规模ISP网络计算开销大，而基于传统ISP流水线调优的方法表示能力有限。需要一种既能保持丰富RAW信息又能高效处理的方法。

Method: 提出任务感知图像信号处理(TA-ISP)框架，使用轻量级多尺度调制算子（全局、区域、像素尺度）来重塑图像统计特征，替代传统的密集卷积流水线。

Result: 在多个RAW域检测和分割基准测试中，TA-ISP在白天和夜间条件下都能持续提升下游任务准确率，同时显著减少参数数量和推理时间。

Conclusion: TA-ISP为资源受限设备提供了一种高效的RAW数据处理解决方案，通过因子化控制扩展了空间变化变换的表示范围。

Abstract: In recent years, there has been a growing trend in computer vision towards
exploiting RAW sensor data, which preserves richer information compared to
conventional low-bit RGB images. Early studies mainly focused on enhancing
visual quality, while more recent efforts aim to leverage the abundant
information in RAW data to improve the performance of visual perception tasks
such as object detection and segmentation. However, existing approaches still
face two key limitations: large-scale ISP networks impose heavy computational
overhead, while methods based on tuning traditional ISP pipelines are
restricted by limited representational capacity.To address these issues, we
propose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB
framework that produces task-oriented representations for pretrained vision
models. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small
set of lightweight, multi-scale modulation operators that act at global,
regional, and pixel scales to reshape image statistics across different spatial
extents. This factorized control significantly expands the range of spatially
varying transforms that can be represented while keeping memory usage,
computation, and latency tightly constrained. Evaluated on several RAW-domain
detection and segmentation benchmarks under both daytime and nighttime
conditions, TA-ISP consistently improves downstream accuracy while markedly
reducing parameter count and inference time, making it well suited for
deployment on resource-constrained devices.

</details>


### [68] [FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras](https://arxiv.org/abs/2509.13681)
*Hang Li,Dianmo Sheng,Qiankun Dong,Zichun Wang,Zhiwei Xu,Tao Li*

Main category: cs.CV

Relevance: 20.0

TL;DR: FishBEV：专为鱼眼相机设计的BEV分割框架，通过三个创新模块解决鱼眼相机的几何畸变、多视图对应模糊和时间动态不稳定问题，在Synwoodscapes数据集上超越现有最佳方法


<details>
  <summary>Details</summary>
Motivation: 现有的BEV分割方法主要针对针孔相机设计，无法有效处理鱼眼相机的严重几何畸变、多视图对应模糊和时间动态不稳定等问题，导致BEV性能显著下降

Method: 提出FishBEV框架，包含三个核心模块：1) 抗畸变多尺度提取(DRME)主干网络，在畸变下学习鲁棒特征并保持尺度一致性；2) 不确定性感知空间交叉注意力(U-SCA)机制，利用不确定性估计实现可靠的跨视图对齐；3) 距离感知时间自注意力(D-TSA)模块，自适应平衡近场细节和远场上下文以确保时间一致性

Result: 在Synwoodscapes数据集上的大量实验表明，FishBEV在环视鱼眼BEV分割任务上持续超越最先进的基线方法

Conclusion: FishBEV是针对鱼眼相机BEV分割的有效解决方案，通过专门设计的模块成功解决了鱼眼相机特有的挑战

Abstract: As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)
segmentation has recently achieved remarkable progress with pinhole cameras.
However, it is non-trivial to extend the existing methods to fisheye cameras
with severe geometric distortion, ambiguous multi-view correspondences and
unstable temporal dynamics, all of which significantly degrade BEV performance.
To address these challenges, we propose FishBEV, a novel BEV segmentation
framework specifically tailored for fisheye cameras. This framework introduces
three complementary innovations, including a Distortion-Resilient Multi-scale
Extraction (DRME) backbone that learns robust features under distortion while
preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention
(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view
alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that
adaptively balances near field details and far field context to ensure temporal
coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that
FishBEV consistently outperforms SOTA baselines, regarding the performance
evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.

</details>


### [69] [Controllable-Continuous Color Editing in Diffusion Model via Color Mapping](https://arxiv.org/abs/2509.13756)
*Yuqi Yang,Dongliang Chang,Yuanchen Fang,Yi-Zhe SonG,Zhanyu Ma,Jun Guo*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出颜色映射模块，通过建立文本嵌入空间与RGB值的对应关系，实现精确可控的连续颜色编辑


<details>
  <summary>Details</summary>
Motivation: 解决文本驱动图像编辑中颜色控制的不足，包括精度不够和难以实现连续控制的问题

Method: 引入颜色映射模块，显式建模文本嵌入空间与图像RGB值的对应关系，通过给定RGB值预测对应嵌入向量

Result: 实验结果表明该方法在颜色连续性和可控性方面表现良好

Conclusion: 该方法能够实现更细粒度、连续且可控的颜色编辑，同时保持语义一致性

Abstract: In recent years, text-driven image editing has made significant progress.
However, due to the inherent ambiguity and discreteness of natural language,
color editing still faces challenges such as insufficient precision and
difficulty in achieving continuous control. Although linearly interpolating the
embedding vectors of different textual descriptions can guide the model to
generate a sequence of images with varying colors, this approach lacks precise
control over the range of color changes in the output images. Moreover, the
relationship between the interpolation coefficient and the resulting image
color is unknown and uncontrollable. To address these issues, we introduce a
color mapping module that explicitly models the correspondence between the text
embedding space and image RGB values. This module predicts the corresponding
embedding vector based on a given RGB value, enabling precise color control of
the generated images while maintaining semantic consistency. Users can specify
a target RGB range to generate images with continuous color variations within
the desired range, thereby achieving finer-grained, continuous, and
controllable color editing. Experimental results demonstrate that our method
performs well in terms of color continuity and controllability.

</details>


### [70] [Hybrid Quantum-Classical Model for Image Classification](https://arxiv.org/abs/2509.13353)
*Muhammad Adnan Shahzad*

Main category: cs.CV

Relevance: 15.0

TL;DR: 混合量子-经典神经网络在图像分类任务中相比纯经典模型展现出更高的准确率、更快的训练速度和更好的参数效率，特别是在复杂数据集上优势更明显


<details>
  <summary>Details</summary>
Motivation: 研究旨在系统比较混合量子-经典神经网络与纯经典模型在性能、效率和鲁棒性方面的差异，探索量子计算在深度学习中的潜在优势

Method: 在MNIST、CIFAR100和STL10三个基准数据集上，将参数化量子电路与经典深度学习架构结合的混合模型与传统的卷积神经网络进行对比实验，训练50个epoch，评估验证准确率、测试准确率、训练时间、计算资源使用和对抗鲁棒性

Result: 混合模型在所有数据集上都优于经典模型：MNIST(99.38% vs 98.21%)、CIFAR100(41.69% vs 32.25%)、STL10(74.05% vs 63.76%)；训练速度快5-12倍；参数减少6-32%；内存使用更低(4-5GB vs 5-6GB)；在简单数据集上对抗鲁棒性显著更好

Conclusion: 混合量子-经典架构在准确率、训练效率和参数可扩展性方面具有明显优势，特别适用于复杂的视觉任务

Abstract: This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.

</details>


### [71] [Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention](https://arxiv.org/abs/2509.13361)
*Tong Yulin,Liang Xuechen*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该研究提出了一种高速公路交通拥堵检测与预测的综合技术框架，通过优化目标检测算法和改进交通流预测模型，显著提高了车辆感知精度和拥堵预警能力。


<details>
  <summary>Details</summary>
Motivation: 现有交通拥堵检测预测系统存在遮挡条件下车辆感知精度低和长序列依赖丢失的问题，需要开发更准确可靠的技术框架来提升高速公路交通效率。

Method: 1) 优化YOLOv11为YOLOv11-DIoU（使用DIoU Loss替代GIoU Loss）；2) 改进DeepSort算法（融合马氏距离和余弦距离）；3) 使用Greenberg模型分析交通流；4) 构建GRU-Attention模型进行拥堵预警。

Result: YOLOv11-DIoU达到95.7% mAP（比基线高6.5个百分点），遮挡漏检率5.3%；DeepSort达到93.8% MOTA；GRU-Attention模型测试准确率99.7%，10分钟提前预警时间误差≤1分钟，独立验证显示95%预警准确率。

Conclusion: 该框架为高速公路拥堵控制提供了量化支持，在智能交通应用中具有良好前景，特别是在高流量场景下表现稳定。

Abstract: Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.

</details>


### [72] [Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks](https://arxiv.org/abs/2509.13366)
*Tony Rohe,Martin Margreiter,Markus Moertl*

Main category: cs.CV

Relevance: 15.0

TL;DR: 论文研究基于众包车载数据的实时路边停车服务，通过机器学习方法（特别是卷积神经网络）自动化地面真值测试流程，将人工资源时间减少99.58%


<details>
  <summary>Details</summary>
Motivation: 优化现有停车服务质量，通过自动化测试流程替代人工工程工作，提高分析效率

Method: 应用机器学习方法，特别是图像模式识别和卷积神经网络，来自动化地面真值测试和分析过程

Result: 实现了高度自动化，人工资源时间减少高达99.58%，显著提升了分析效率

Conclusion: 该方法成功实现了测试流程的自动化，为未来发展和分析自动化工具的潜在应用提供了良好基础

Abstract: This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.

</details>


### [73] [Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension](https://arxiv.org/abs/2509.13385)
*Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了一种基于截面曲率的几何分析方法，用于评估数据表示的有效性和估计数据集的内在维度，特别适用于维度约简技术的评估。


<details>
  <summary>Details</summary>
Motivation: 开发一种基于曲率的几何分析方法来量化评估数据表示（如维度约简技术产生的表示）的有效性，并探索数据集的本质几何特性。

Method: 利用新发展的截面曲率抽象概念，构建离散度量空间的曲率几何剖面，该方法捕捉点三元组与其他点之间的度量关系。

Result: 实验表明，这种基于曲率的分析可用于估计数据集的内在维度，探索经验网络的大规模几何结构，并评估维度约简技术的有效性。

Conclusion: 基于曲率的几何剖面为数据表示质量评估提供了有效的量化指标，在数据分析和维度约简领域具有应用价值。

Abstract: Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.

</details>


### [74] [Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence](https://arxiv.org/abs/2509.13396)
*Xinan Wang,Di Shi,Fengyu Wang*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出了一种用于电力传输系统实时异物入侵检测与跟踪的三阶段框架，结合YOLOv7分割、ConvNeXt特征提取和特征辅助IoU跟踪，支持边缘部署和增量更新


<details>
  <summary>Details</summary>
Motivation: 电力传输系统中异物入侵检测对电网安全至关重要，需要实时、准确且能在边缘设备上部署的解决方案，同时要处理遮挡、运动等复杂场景

Method: 三阶段框架：1) YOLOv7分割模型进行目标定位；2) ConvNeXt特征提取器配合三元组损失生成判别性嵌入；3) 特征辅助IoU跟踪器处理遮挡和多目标跟踪。采用混合精度推理优化边缘部署

Result: 在真实监控和无人机视频数据集上表现出高准确性和鲁棒性，在NVIDIA Jetson设备上的硬件基准测试证实了框架的实用性和可扩展性

Conclusion: 该框架为电力传输系统提供了一种有效的实时异物入侵检测解决方案，支持边缘部署和增量学习，具有实际应用价值

Abstract: This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.

</details>


### [75] [LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming](https://arxiv.org/abs/2509.13504)
*Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández*

Main category: cs.CV

Relevance: 15.0

TL;DR: LivePyxel是一个基于Python的实时图像标注工具，可直接与显微镜等成像设备集成，提供贝塞尔曲线和二进制掩码等专业标注功能，支持非破坏性图层编辑，旨在加速科学AI模型的开发。


<details>
  <summary>Details</summary>
Motivation: 现有图像标注工具需要先上传预收集数据集，无法支持实时数据采集和按需标注流程，这在实验室实时仪器数据采集场景中尤为不便。

Method: 开发基于Python的图形用户界面，集成OpenCV和Numpy等高性能库，支持多种视频设备，提供类似商业图形软件的标注工具（贝塞尔曲线、二进制掩码）和非破坏性图层编辑功能。

Result: 实现了实时图像标注工具LivePyxel，可与网络摄像头、显微镜等成像系统直接集成，支持高性能的对象检测操作。

Conclusion: LivePyxel简化了数据收集和标注流程，能够加速实验工作流中AI模型的开发。

Abstract: The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel

</details>


### [76] [Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection](https://arxiv.org/abs/2509.13586)
*Nathalie Neptune,Josiane Mothe*

Main category: cs.CV

Relevance: 15.0

TL;DR: 本文提出了一种基于深度学习的方法，通过卫星图像对检测亚马逊雨林砍伐，并结合科学文献自动生成相关标注


<details>
  <summary>Details</summary>
Motivation: 亚马逊雨林砍伐对全球碳排放和生物多样性有重大影响，需要有效的监测工具来检测森林覆盖变化

Method: 使用深度学习技术比较不同时间点的卫星图像对，检测森林覆盖变化，并提出视觉语义模型从相关科学文献中自动提取关键词进行标注

Result: 在亚马逊图像对数据集上评估显示，该方法能有效检测砍伐并生成相关标注

Conclusion: 该方法为监测亚马逊砍伐影响提供了有用工具，且具有通用性可应用于其他领域

Abstract: The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

</details>


### [77] [A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms](https://arxiv.org/abs/2509.13605)
*Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong*

Main category: cs.CV

Relevance: 15.0

TL;DR: CLAP算法从2D定位扩展到3D定位和图像拼接的通用框架，通过聚类方法处理噪声和异常值，与RANSAC和霍夫变换相关


<details>
  <summary>Details</summary>
Motivation: 扩展CLAP算法的应用范围，从特定的2D定位问题推广到更一般的3D定位和图像拼接任务，提供一种处理噪声和不确定性的通用工具

Method: 基于聚类的定位方法，使用聚类来抑制噪声和缓解错误特征匹配，作为传统异常值拒绝方案（如RANSAC）的替代方法

Result: 成功将CLAP算法扩展到3D定位和图像拼接领域，证明了该方法在不同应用中的广泛适用性

Conclusion: CLAP的泛化框架可以应用于许多不同领域，是处理噪声和不确定性的有用工具

Abstract: In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.

</details>


### [78] [Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction](https://arxiv.org/abs/2509.13652)
*Yumin Li,Dylan Campbell*

Main category: cs.CV

Relevance: 15.0

TL;DR: GARPS是一个无需训练的两视图相机位姿估计框架，通过直接对齐两个独立重建的3D高斯场景来实现度量相对位姿估计，在Real-Estate10K数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统两视图位姿估计方法无法提供度量尺度信息（相机平移只有尺度未知），且在宽基线和纹理缺失区域表现不佳。需要一种能够提供度量尺度信息且对纹理缺失区域鲁棒的方法。

Method: 使用度量单目深度估计器和高斯场景重建器为每张图像生成度量3D高斯混合模型(GMM)，然后通过优化可微分的GMM对齐目标来精化初始位姿估计，该目标综合考虑几何结构、视角无关颜色、各向异性协方差和语义特征一致性。

Result: 在Real-Estate10K数据集上的大量实验表明，GARPS超越了传统方法和最先进的学习方法（包括MASt3R），实现了更好的度量相对位姿估计性能。

Conclusion: 通过桥接单视图感知和多视图几何，可以实现鲁棒且度量的相对位姿估计，展示了这种方法的潜力。

Abstract: Estimating metric relative camera pose from a pair of images is of great
importance for 3D reconstruction and localisation. However, conventional
two-view pose estimation methods are not metric, with camera translation known
only up to a scale, and struggle with wide baselines and textureless or
reflective surfaces. This paper introduces GARPS, a training-free framework
that casts this problem as the direct alignment of two independently
reconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and
a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model
(GMM) for each image. It then refines an initial pose from a feed-forward
two-view pose estimator by optimising a differentiable GMM alignment objective.
This objective jointly considers geometric structure, view-independent colour,
anisotropic covariance, and semantic feature consistency, and is robust to
occlusions and texture-poor regions without requiring explicit 2D
correspondences. Extensive experiments on the Real\-Estate10K dataset
demonstrate that GARPS outperforms both classical and state-of-the-art
learning-based methods, including MASt3R. These results highlight the potential
of bridging single-view perception with multi-view geometry to achieve robust
and metric relative pose estimation.

</details>


### [79] [MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM](https://arxiv.org/abs/2509.13536)
*Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou*

Main category: cs.CV

Relevance: 10.0

TL;DR: 该论文提出了针对嵌入式平台的3D高斯泼溅优化方法，通过体素空间几何相似性合并减少GPU内存使用，同时通过Patch-Grid点采样提高渲染质量


<details>
  <summary>Details</summary>
Motivation: 当前3DGS研究主要关注高性能桌面GPU，忽视了嵌入式平台（如微型飞行器）的计算资源和内存限制，需要在系统性能和重建质量之间进行权衡

Method: 1) 在体素空间中基于几何相似性合并冗余的3D高斯基元以减少GPU内存使用；2) 通过Patch-Grid点采样初始化3D高斯基元以提高渲染精度

Result: 在公开数据集上的定量和定性评估表明，该方法有效减少了GPU内存使用，同时提升了渲染质量，且不影响系统运行时性能

Conclusion: 该方法为嵌入式平台上的3D高斯泼溅应用提供了有效的优化方案，平衡了内存使用和渲染质量的需求

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.

</details>


### [80] [Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji](https://arxiv.org/abs/2509.13388)
*Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra*

Main category: cs.CV

Relevance: 5.0

TL;DR: 该研究使用机器学习和遥感技术分析斐济Nadi地区2013-2024年的土地利用变化，通过Landsat-8卫星影像、k-means聚类和卷积神经网络进行土地覆盖分类和变化检测。


<details>
  <summary>Details</summary>
Motivation: 斐济作为发展中国家面临快速城市化，需要技术手段来监测土地利用变化，为土地覆盖建模和变化检测提供技术支持。

Method: 使用Landsat-8卫星影像，在Google Earth Engine平台上结合无监督k-means聚类和有监督的卷积神经网络进行土地覆盖分类，生成训练数据集并进行变化检测可视化。

Result: 研究成功生成了土地覆盖图，并通过可视化展示了城市区域随时间的变化情况，实现了对土地利用变化的监测。

Conclusion: 该框架为发展中国家城市化进程中的土地利用监测提供了有效的技术解决方案。

Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [81] [Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness](https://arxiv.org/abs/2509.13332)
*Pratik Jayarao,Himanshu Gupta,Neeraj Varshney,Chaitanya Dwivedi*

Main category: cs.AI

Relevance: 85.0

TL;DR: 本研究系统比较了在LLM作为裁判范式下"思考"与"非思考"模型的表现，发现思考模型在准确率、计算效率和鲁棒性方面均优于非思考模型，即使经过多种增强策略改进后。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地被用作自动裁判进行基准测试和奖励建模，确保其可靠性、效率和鲁棒性变得至关重要。需要系统比较思考与非思考模型在这一范式下的表现。

Method: 使用开源Qwen 3小规模模型(0.6B/1.7B/4B参数)，在RewardBench任务上评估准确性和计算效率(FLOPs)，并测试了上下文学习、规则引导评估、参考基准评估和n-best聚合等增强策略。

Result: 思考模型比非思考模型准确率高约10%，计算开销小(低于2倍)，而少样本学习等增强策略收益有限但成本高(>8倍)。在位置、从众、身份、多样性和随机偏见等多种条件下，思考模型保持显著更高的一致性(平均高6%)。多语言实验也证实了显式推理的优势。

Conclusion: 显式推理在LLM作为裁判范式中不仅在准确性和效率方面，而且在鲁棒性方面都提供明显优势，为这一范式提供了系统性证据。

Abstract: As Large Language Models (LLMs) are increasingly adopted as automated judges
in benchmarking and reward modeling, ensuring their reliability, efficiency,
and robustness has become critical. In this work, we present a systematic
comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm
using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B
parameters). We evaluate both accuracy and computational efficiency (FLOPs) on
RewardBench tasks, and further examine augmentation strategies for non-thinking
models, including in-context learning, rubric-guided judging, reference-based
evaluation, and n-best aggregation. Our results show that despite these
enhancements, non-thinking models generally fall short of their thinking
counterparts. Our results show that thinking models achieve approximately 10%
points higher accuracy with little overhead (under 2x), in contrast to
augmentation strategies like few-shot learning, which deliver modest gains at a
higher cost (>8x). Bias and robustness analyses further demonstrate that
thinking models maintain significantly greater consistency under a variety of
bias conditions such as positional, bandwagon, identity, diversity, and random
biases (6% higher on average). We further extend our experiments to the
multilingual setting and our results confirm that explicit reasoning extends
its benefits beyond English. Overall, our work results in several important
findings that provide systematic evidence that explicit reasoning offers clear
advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency
but also in robustness.

</details>


### [82] [Evaluation Awareness Scales Predictably in Open-Weights Large Language Models](https://arxiv.org/abs/2509.13333)
*Maheep Chaudhary,Ian Su,Nikhil Hooda,Nishith Shankar,Julia Tan,Kevin Zhu,Ashwinee Panda,Ryan Lagasse,Vasu Sharma*

Main category: cs.AI

Relevance: 85.0

TL;DR: 研究发现大型语言模型存在评估意识行为，即模型能区分评估和部署环境，这种能力随模型规模呈幂律增长，对AI安全评估构成挑战。


<details>
  <summary>Details</summary>
Motivation: 先前研究在单个70B模型中发现评估意识现象，但不同规模模型间的缩放关系未知，需要研究评估意识如何随模型规模变化，以预测更大模型的欺骗行为并设计相应的安全评估策略。

Method: 使用线性探测方法分析15个不同规模模型（0.27B到70B参数）的转向向量激活，研究评估意识的缩放规律。

Result: 发现评估意识随模型规模呈清晰的幂律缩放关系，模型越大评估意识越强，这种可预测的缩放规律可用于预测未来更大模型的欺骗行为。

Conclusion: 评估意识的幂律缩放规律为AI安全评估提供了重要指导，需要设计针对不同规模模型的评估策略，这对未来更大模型的安全部署具有重要意义。

Abstract: Large language models (LLMs) can internally distinguish between evaluation
and deployment contexts, a behaviour known as \emph{evaluation awareness}. This
undermines AI safety evaluations, as models may conceal dangerous capabilities
during testing. Prior work demonstrated this in a single $70$B model, but the
scaling relationship across model sizes remains unknown. We investigate
evaluation awareness across $15$ models scaling from $0.27$B to $70$B
parameters from four families using linear probing on steering vector
activations. Our results reveal a clear power-law scaling: evaluation awareness
increases predictably with model size. This scaling law enables forecasting
deceptive behavior in future larger models and guides the design of scale-aware
evaluation strategies for AI safety. A link to the implementation of this paper
can be found at
https://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.

</details>


### [83] [FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness](https://arxiv.org/abs/2509.13334)
*Anand Swaroop,Akshat Nallani,Saksham Uboweja,Adiliia Uzdenova,Michael Nguyen,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary*

Main category: cs.AI

Relevance: 85.0

TL;DR: FRIT是一种通过干预训练提升大语言模型推理忠实性的对齐方法，通过生成忠实/不忠实推理对并应用直接偏好优化，在保持准确性的同时提高推理的因果一致性。


<details>
  <summary>Details</summary>
Motivation: 现有思维链推理方法存在推理步骤与最终答案缺乏因果关联的问题，导致输出脆弱且不可信。虽然已有方法主要关注测量忠实性，但系统性提升忠实性的方法仍然有限。

Method: FRIT通过干预模型生成的思维链中的单个推理步骤，生成合成训练数据（忠实/不忠实推理对），然后应用直接偏好优化（DPO）来训练模型偏好因果一致的推理路径。

Result: 在Qwen3-8B和Mistral-7B-v0.1模型上，FRIT在GSM8K任务上使Mistral的忠实推理提高了3.4个百分点，同时准确率提高了7.6个百分点。

Conclusion: FRIT提供了第一个可扩展、无需监督的方法来训练语言模型产生更可靠和可解释的推理，解决了推理性能与可信度之间的关键差距。

Abstract: Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving
large language model performance on complex tasks, but recent work shows that
reasoning steps often fail to causally influence the final answer, creating
brittle and untrustworthy outputs. Prior approaches focus primarily on
measuring faithfulness, while methods for systematically improving it remain
limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a
scalable alignment method that trains models to produce causally consistent
reasoning by learning from systematically corrupted examples. FRIT generates
synthetic training data by intervening on individual reasoning steps in
model-generated CoTs, creating faithful/unfaithful pairs that highlight when
reasoning breaks down. We then apply Direct Preference Optimization to teach
models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B
and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases
faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while
improving accuracy by $7.6$ percentage points. Our approach provides the first
scalable, supervision-free method for training language models to produce more
reliable and interpretable reasoning, addressing a critical gap between
reasoning performance and trustworthiness. We release our code at
\href{https://github.com/Anut-py/frit}.

</details>


### [84] [Position: AI Safety Must Embrace an Antifragile Perspective](https://arxiv.org/abs/2509.13339)
*Ming Jin,Hyunin Lee*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该立场论文主张AI安全研究应采用抗脆弱性视角，通过利用不确定性来增强系统处理罕见和分布外事件的能力，而非仅仅追求静态测试和一次性鲁棒性评估。


<details>
  <summary>Details</summary>
Motivation: 传统静态基准测试和一次性鲁棒性测试无法应对环境演化和模型漂移问题（如奖励黑客攻击、过度优化等），需要建立能够随时间扩展安全保证能力的动态安全框架。

Method: 提出抗脆弱性方法框架，强调利用当前不确定性来为未来更大不确定性做准备，包括识别静态测试的局限性（场景多样性不足、奖励黑客、过度对齐等），并探索抗脆弱性解决方案来管理罕见事件。

Result: 建立了抗脆弱性AI安全的理论基础，提出了从静态测试向动态持续改进的范式转变，为长期可靠的开放式机器学习系统提供了新的安全评估框架。

Conclusion: 抗脆弱性方法是确保AI系统长期安全性的关键，需要重新校准AI安全的测量、基准测试和持续改进方法，建立抗脆弱性AI安全社区。

Abstract: This position paper contends that modern AI research must adopt an
antifragile perspective on safety -- one in which the system's capacity to
guarantee long-term AI safety such as handling rare or out-of-distribution
(OOD) events expands over time. Conventional static benchmarks and single-shot
robustness tests overlook the reality that environments evolve and that models,
if left unchallenged, can drift into maladaptation (e.g., reward hacking,
over-optimization, or atrophy of broader capabilities). We argue that an
antifragile approach -- Rather than striving to rapidly reduce current
uncertainties, the emphasis is on leveraging those uncertainties to better
prepare for potentially greater, more unpredictable uncertainties in the future
-- is pivotal for the long-term reliability of open-ended ML systems. In this
position paper, we first identify key limitations of static testing, including
scenario diversity, reward hacking, and over-alignment. We then explore the
potential of antifragile solutions to manage rare events. Crucially, we
advocate for a fundamental recalibration of the methods used to measure,
benchmark, and continually improve AI safety over the long term, complementing
existing robustness approaches by providing ethical and practical guidelines
towards fostering an antifragile AI safety community.

</details>


### [85] [Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning](https://arxiv.org/abs/2509.13351)
*Pulkit Verma,Ngoc La,Anthony Favier,Swaroop Mishra,Julie A. Shah*

Main category: cs.AI

Relevance: 85.0

TL;DR: PDDL-Instruct：通过逻辑思维链推理增强LLM符号规划能力的指令调优框架，在标准基准测试中达到94%的规划准确率，比基线模型提升66%


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在结构化符号规划方面能力有限，特别是在需要PDDL等形式化表示的领域。需要弥合LLM通用推理能力与自动规划所需逻辑精度之间的差距

Method: 开发指令提示框架，教导模型通过显式逻辑推理步骤严格推理动作适用性、状态转换和计划有效性。将规划过程分解为关于前提条件满足、效果应用和不变性保持的显式推理链

Result: 在多个规划领域的实验结果显示，基于思维链推理的指令调优模型显著优于基线，在标准基准测试中达到94%的规划准确率，绝对改进66%

Conclusion: 该工作为开发更好的AI规划系统提供了有前景的方向，成功弥合了LLM通用推理能力与自动规划所需逻辑精度之间的差距

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, yet their ability to perform structured symbolic planning
remains limited, particularly in domains requiring formal representations like
the Planning Domain Definition Language (PDDL). In this paper, we present a
novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'
symbolic planning capabilities through logical chain-of-thought reasoning. Our
approach focuses on teaching models to rigorously reason about action
applicability, state transitions, and plan validity using explicit logical
inference steps. By developing instruction prompts that guide models through
the precise logical reasoning required to determine when actions can be applied
in a given state, we enable LLMs to self-correct their planning processes
through structured reflection. The framework systematically builds verification
skills by decomposing the planning process into explicit reasoning chains about
precondition satisfaction, effect application, and invariant preservation.
Experimental results on multiple planning domains show that our
chain-of-thought reasoning based instruction-tuned models are significantly
better at planning, achieving planning accuracy of up to 94% on standard
benchmarks, representing a 66% absolute improvement over baseline models. This
work bridges the gap between the general reasoning capabilities of LLMs and the
logical precision required for automated planning, offering a promising
direction for developing better AI planning systems.

</details>


### [86] [$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation](https://arxiv.org/abs/2509.13368)
*Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li*

Main category: cs.AI

Relevance: 85.0

TL;DR: Agent²是一个完全自动化的RL智能体生成框架，通过LLM驱动的双智能体架构，将自然语言任务描述自动转换为高性能强化学习解决方案，无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 传统RL智能体开发需要大量专业知识和迭代，失败率高且难以普及。为了解决这个问题，需要实现完全自动化的RL智能体设计。

Method: 采用双智能体架构：生成器智能体作为自主AI设计器分析任务并生成可执行RL智能体，目标智能体是自动生成的RL智能体。框架将RL开发分解为MDP建模和算法优化两个阶段，基于模型上下文协议提供统一框架。

Result: 在MuJoCo、MetaDrive、MPE和SMAC等多个基准测试中，Agent²在所有任务上都优于人工设计的解决方案，性能提升高达55%，平均表现也有显著提升。

Conclusion: 这项工作建立了智能体设计和优化其他智能体的新范式，实现了真正端到端的闭环自动化，是自动化AI系统的根本性突破。

Abstract: Reinforcement learning agent development traditionally requires extensive
expertise and lengthy iterations, often resulting in high failure rates and
limited accessibility. This paper introduces $Agent^2$, a novel
agent-generates-agent framework that achieves fully automated RL agent design
through intelligent LLM-driven generation. The system autonomously transforms
natural language task descriptions and environment code into comprehensive,
high-performance reinforcement learning solutions without human intervention.
$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent
serves as an autonomous AI designer that analyzes tasks and generates
executable RL agents, while the Target Agent is the resulting automatically
generated RL agent. The framework decomposes RL development into two distinct
stages: MDP modeling and algorithmic optimization, enabling more targeted and
effective agent generation. Built on the Model Context Protocol, $Agent^2$
provides a unified framework that standardizes intelligent agent creation
across diverse environments and algorithms, while incorporating adaptive
training management and intelligent feedback analysis for continuous
improvement. Extensive experiments on a wide range of benchmarks, including
MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently
outperforms manually designed solutions across all tasks, achieving up to 55%
performance improvement and substantial gains on average. By enabling truly
end-to-end, closed-loop automation, this work establishes a new paradigm in
which intelligent agents design and optimize other agents, marking a
fundamental breakthrough for automated AI systems.

</details>


### [87] [The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs](https://arxiv.org/abs/2509.13379)
*Asif Azad,Mohammad Sadat Hossain,MD Sadik Hossain Shanto,M Saifur Rahman,Md Rizwan Pervez*

Main category: cs.AI

Relevance: 85.0

TL;DR: 对16个最先进的视觉语言模型在6个多模态数据集上进行全面的不确定性基准测试，发现更大模型具有更好的不确定性量化能力，数学和推理任务的不确定性表现较差。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在性能基准测试方面取得了进展，但不确定性量化这一关键维度未得到足够关注，需要系统评估VLMs的不确定性表现。

Method: 评估16个开源和闭源的最先进VLMs，在6个多模态数据集上使用3种不同的评分函数进行全面的不确定性基准测试。

Result: 发现更大模型始终表现出更好的不确定性量化能力；更确定的模型获得更高准确率；数学和推理任务在所有模型中表现出比其他领域更差的不确定性性能。

Conclusion: 这项工作为多模态系统中可靠的不确定性评估奠定了基础，强调了模型规模与不确定性量化能力之间的正相关关系。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in complex
visual understanding across scientific and reasoning tasks. While performance
benchmarking has advanced our understanding of these capabilities, the critical
dimension of uncertainty quantification has received insufficient attention.
Therefore, unlike prior conformal prediction studies that focused on limited
settings, we conduct a comprehensive uncertainty benchmarking study, evaluating
16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets
with 3 distinct scoring functions. Our findings demonstrate that larger models
consistently exhibit better uncertainty quantification; models that know more
also know better what they don't know. More certain models achieve higher
accuracy, while mathematical and reasoning tasks elicit poorer uncertainty
performance across all models compared to other domains. This work establishes
a foundation for reliable uncertainty evaluation in multimodal systems.

</details>


### [88] [SteeringControl: Holistic Evaluation of Alignment Steering in LLMs](https://arxiv.org/abs/2509.13450)
*Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

Relevance: 85.0

TL;DR: SteeringControl是一个评估表示引导方法的基准，专注于偏见、有害生成和幻觉等核心对齐目标，以及这些方法对次要行为（如奉承和常识道德）的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐工作通常只关注真实性或推理能力来展示表示引导的副作用，但许多权衡关系尚未被系统性地理解。需要系统评估引导方法的有效性和行为纠缠问题。

Method: 构建了一个包含安全相关主要和次要行为的数据集，基于五个流行引导方法创建模块化引导框架，在Qwen-2.5-7B和Llama-3.1-8B模型上进行评估。

Result: 发现强引导性能取决于引导方法、模型和目标行为的特定组合，不良组合会导致严重的概念纠缠问题。

Conclusion: 表示引导方法的效果具有高度情境依赖性，需要仔细选择方法-模型-目标的组合以避免负面副作用。

Abstract: We introduce SteeringControl, a benchmark for evaluating representation
steering methods across core alignment objectives--bias, harmful generation,
and hallucination--and their effects on secondary behaviors such as sycophancy
and commonsense morality. While prior alignment work often highlights
truthfulness or reasoning ability to demonstrate the side effects of
representation steering, we find there are many unexplored tradeoffs not yet
understood in a systematic way. We collect a dataset of safety-relevant primary
and secondary behaviors to evaluate steering effectiveness and behavioral
entanglement centered around five popular steering methods. To enable this, we
craft a modular steering framework based on unique components that serve as the
building blocks of many existing methods. Our results on Qwen-2.5-7B and
Llama-3.1-8B find that strong steering performance is dependent on the specific
combination of steering method, model, and targeted behavior, and that severe
concept entanglement can result from poor combinations of these three as well.
We release our code here:
https://github.com/wang-research-lab/SteeringControl.git.

</details>


### [89] [THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning](https://arxiv.org/abs/2509.13761)
*Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao*

Main category: cs.AI

Relevance: 85.0

TL;DR: THOR是一个通过强化学习实现工具集成分层优化的框架，用于提升LLM在数学推理和代码生成中的性能，通过多智能体数据生成、分层优化和自校正机制实现最先进效果


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数值计算和符号操作等高精度任务上仍然存在困难，现有工具集成方法在数据构建、细粒度优化和推理增强方面面临挑战

Method: 提出THOR框架：1) TIRGen多智能体actor-critic管道构建高质量工具集成推理数据集；2) 分层RL策略联合优化轨迹级问题解决和步骤级代码生成；3) 推理时利用工具反馈进行动态自校正

Result: 在多个数学基准测试上达到同类规模模型的最先进性能，在代码基准测试上也有持续改进，展现出对不同模型的强泛化能力

Conclusion: THOR通过工具集成和分层优化有效提升了LLM在数学推理和代码生成任务中的性能，证明了中间工具调用成功对最终答案正确性的重要预测作用

Abstract: Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.

</details>


### [90] [Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI](https://arxiv.org/abs/2509.13345)
*Zihao Li,Weiwei Yi,Jiahong Chen*

Main category: cs.CY

Relevance: 85.0

TL;DR: 本文提出了"准确性悖论"概念，指出过度依赖准确性作为LLM评估标准反而会加剧幻觉问题，需要转向更全面的可信AI治理框架


<details>
  <summary>Details</summary>
Motivation: 随着LLM在日常决策中的普及，其产生的幻觉（虚假、误导性输出）带来了严重的认知和社会风险。当前监管和学术讨论过度强调准确性作为主要基准，但作者认为这种单一标准会误诊问题并产生反效果

Method: 通过跨学科文献分析，建立了幻觉类型的分类法，并从三个维度（输出、个体、社会）分析准确性悖论，同时考察了欧盟AI法案、GDPR和DSA等现行法规的局限性

Result: 发现准确性作为单一指标存在三个问题：1）只是可靠性的表面代理，鼓励优化修辞流畅性而非认知可信度；2）无法检测非事实错误但仍有危害的输出；3）掩盖了幻觉的更广泛社会后果

Conclusion: 需要从根本上转向多元化、情境感知和抗操纵的AI可信治理方法，当前法规在结构上还不足以应对这些认知、关系和系统性危害

Abstract: As Large Language Models (LLMs) permeate everyday decision-making, their
epistemic and societal risks demand urgent scrutiny. Hallucinations, the
generation of fabricated, misleading, oversimplified or untrustworthy outputs,
has emerged as imperative challenges. While regulatory, academic, and technical
discourse position accuracy as the principal benchmark for mitigating such
harms, this article contends that overreliance on accuracy misdiagnoses the
problem and has counterproductive effect: the accuracy paradox. Drawing on
interdisciplinary literatures, this article develops a taxonomy of
hallucination types and shows the paradox along three intertwining dimensions:
outputs, individuals and society. First, accuracy functions as a superficial
proxy for reliability, incentivising the optimisation of rhetorical fluency and
surface-level correctness over epistemic trustworthiness. This encourages
passive user trust in outputs that appear accurate but epistemically untenable.
Second, accuracy as a singular metric fails to detect harms that are not
factually false but are nonetheless misleading, value-laden, or socially
distorting, including consensus illusions, sycophantic alignment, and subtle
manipulation. Third, regulatory overemphasis on accuracy obscures the wider
societal consequences of hallucination, including social sorting, privacy
violations, equity harms, epistemic convergence that marginalises dissent,
reduces pluralism, and causes social deskilling. By examining the EU AI Act,
GDPR, and DSA, the article argues that current regulations are not yet
structurally equipped to address these epistemic, relational, and systemic
harms and exacerbated by the overreliance on accuracy. By exposing such
conceptual and practical challenges, this article calls for a fundamental shift
towards pluralistic, context-aware, and manipulation-resilient approaches to AI
trustworthy governance.

</details>


### [91] [OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft](https://arxiv.org/abs/2509.13347)
*Zihao Wang,Muyao Li,Kaichen He,Xiangyu Wang,Zhancun Mu,Anji Liu,Yitao Liang*

Main category: cs.AI

Relevance: 75.0

TL;DR: 本文提出了Chain of Action (CoA)框架，统一了高级规划和低级控制在单一VLA模型中，通过将抽象动作作为中间推理步骤来指导最终可执行动作的生成，在Minecraft中实现了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决VLA和分层智能体模型中动作空间选择的挑战，现有方法没有普遍最优的动作空间抽象，构建通用智能体面临困境。

Method: 提出CoA框架，将抽象动作视为类似思维链的中间推理步骤；训练All-in-One智能体在多样化动作空间混合数据上学习；发布OpenHA套件包含800+任务基准。

Result: 统一智能体实现了新的state-of-the-art，相比专门的基线模型提高了整体任务成功率，学习到了更鲁棒和可泛化的策略。

Conclusion: CoA范式能够有效解决动作空间选择的困境，统一的单模型方法优于专门的解决方案，为构建通用智能体提供了新方向。

Abstract: The choice of action spaces is a critical yet unresolved challenge in
developing capable, end-to-end trainable agents. This paper first presents a
large-scale, systematic comparison of prominent abstracted action spaces and
tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the
open-ended Minecraft. Our analysis reveals that no single action space is
universally optimal; instead, the most effective abstraction is highly
task-dependent, creating a dilemma for building generalist agents. To resolve
this, we introduce Chain of Action (CoA), a novel framework that unifies
high-level planning and low-level control within a single, monolithic VLA
model. CoA treats an abstracted action not as a command for a separate policy,
but as an intermediate reasoning step--akin to a chain of thought--that guides
the generation of the final, executable action. Furthermore, we demonstrate
that an All-in-One agent trained on a diverse mixture of action spaces using
the CoA paradigm learns a more robust and generalizable policy. This unified
agent achieves a new state-of-the-art, improving the overall task success rate
over strong, specialized baselines. To foster reproducible research, we release
the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive
benchmark of over 800 distinct tasks, curated datasets, source code, and all
pretrained model checkpoints at https://github.com/CraftJarvis/OpenHA

</details>


### [92] [Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling](https://arxiv.org/abs/2509.13357)
*Yongchao Huang,Hassan Raza*

Main category: cs.AI

Relevance: 75.0

TL;DR: 语义融合：一种轻量级方案，通过并行模糊成员特征通道增强Transformer语言模型，编码token级语义特征，提升生成可控性和可解释性


<details>
  <summary>Details</summary>
Motivation: 现有语言模型缺乏对token级语义特征（如词性、情感极性等）的显式编码，限制了生成的可控性和可解释性。作者希望在不显著增加模型复杂度的情况下，为模型注入可解释的语义特征通道

Method: 提出语义融合方案：1）为每个token构建可解释特征向量（词性、情感极性等）；2）使用可微分成员函数计算特征值；3）通过门控适配器将语义矩阵融合到语言模型中；4）使用标准next-token预测+辅助损失+轻量级正则化进行训练

Result: 在合成双子句语料库上，语义融合降低了困惑度，实现了精确的用户可控生成（极性和标点控制），同时保持模型简洁性，仅增加少量计算开销

Conclusion: 语义融合为条件自然语言生成提供了可解释的途径，保持与现有嵌入方案的完全兼容性，是增强语言模型语义控制能力的有效方法

Abstract: We propose semantic fusion, a lightweight scheme that augments a Transformer
language model (LM) with a parallel, fuzzy-membership feature channel that
encodes token-level semantics. Each token is represented by a vector of
interpretable features (e.g. part-of-speech cues, shallow roles, boundary
flags, sentiment polarity and strength) whose values are graded degrees from
differentiable membership functions (e.g. power kernels). These per-token
vectors form a sentence-level semantic matrix fused via a gated adapter into
the LM. Training uses standard next-token prediction, an auxiliary loss that
reconstructs the semantic features from hidden states, and a lightweight
uniformizer that regularizes adjective-class distributions. On a synthetic
two-clause corpus with held-out adjectives for out-of-distribution (OOD)
control, semantic fusion improves perplexity and enables precise,
user-controllable generation of polarity and punctuation while maintaining
model simplicity. This approach adds only small overhead, remains fully
compatible with tied input-output embeddings, and provides an interpretable
pathway for conditioned natural language generation.

</details>


### [93] [AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving](https://arxiv.org/abs/2509.13547)
*Harper Reed,Michael Sugimura,Angelo Zangari*

Main category: cs.AI

Relevance: 75.0

TL;DR: 为LLM代理提供人类协作工具（社交媒体和日志工具）可以显著提升在困难编程问题上的性能表现，降低成本、减少交互轮次并加快完成速度


<details>
  <summary>Details</summary>
Motivation: 研究是否通过赋予LLM代理人类自然使用的协作工具和自主权，能够改善它们在问题解决中的表现

Method: 为Claude Code代理配备基于MCP的社交媒体和日志工具，让它们自主使用这些工具来解决34个Aider Polyglot Python编程挑战

Result: 协作工具在最具挑战性的问题上显著提升性能：成本降低15-40%，交互轮次减少12-27%，完成速度加快12-38%。不同模型自然采用不同的协作策略，代理更倾向于写作而非阅读（2-9倍）

Conclusion: AI代理可以在能力边界处系统性地受益于人类启发的协作工具，表明自适应协作界面可以作为推理增强器而非通用效率提升工具

Abstract: We investigate whether giving LLM agents the collaborative tools and autonomy
that humans naturally use for problem solving can improve their performance. We
equip Claude Code agents with MCP-based social media and journaling tools and
allow them to use these tools as they see fit. Across 34 Aider Polyglot Python
programming challenges, collaborative tools substantially improve performance
on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and
12-38% faster completion than baseline agents. Effects on the full challenge
set are mixed, suggesting these tools act as performance enhancers when
additional reasoning scaffolding is most needed. Surprisingly, Different models
naturally adopted distinct collaborative strategies without explicit
instruction. Sonnet 3.7 engaged broadly across tools and benefited from
articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,
leaning on journal-based semantic search when problems were genuinely
difficult. This mirrors how human developers adjust collaboration based on
expertise and task complexity. Behavioral analysis shows agents prefer writing
over reading by about 2-9x, indicating that structured articulation drives much
of the improvement rather than information access alone. Overall, AI agents can
systematically benefit from human-inspired collaboration tools at the edge of
their capabilities, pointing to adaptive collaborative interfaces as reasoning
enhancers rather than universal efficiency boosts.

</details>


### [94] [InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management](https://arxiv.org/abs/2509.13704)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

Relevance: 75.0

TL;DR: InfraMind是一个专门为工业管理系统设计的基于探索的GUI代理框架，通过五个创新模块解决LLM在工业管理应用中的挑战，在DCIM平台上表现出优越的任务成功率和操作效率。


<details>
  <summary>Details</summary>
Motivation: 工业基础设施管理面临系统复杂性增加、多供应商集成和专家操作员短缺等挑战。现有RPA方法灵活性有限且维护成本高，通用LLM GUI代理在工业管理中存在元素理解、精度效率、状态定位、部署约束和安全要求等五大挑战。

Method: 提出InfraMind框架，包含五个核心模块：1)基于系统搜索探索和虚拟机快照的自主GUI理解；2)内存驱动规划确保高精度高效任务执行；3)高级状态识别用于层次化界面中的鲁棒定位；4)结构化知识蒸馏实现轻量模型高效部署；5)多层安全机制保护敏感操作。

Result: 在开源和商业DCIM平台上的广泛实验表明，该方法在任务成功率和操作效率方面持续优于现有框架。

Conclusion: InfraMind为工业管理自动化提供了一个严谨且可扩展的解决方案，有效解决了LLM在工业环境应用中的关键挑战。

Abstract: Mission-critical industrial infrastructure, such as data centers,
increasingly depends on complex management software. Its operations, however,
pose significant challenges due to the escalating system complexity,
multi-vendor integration, and a shortage of expert operators. While Robotic
Process Automation (RPA) offers partial automation through handcrafted scripts,
it suffers from limited flexibility and high maintenance costs. Recent advances
in Large Language Model (LLM)-based graphical user interface (GUI) agents have
enabled more flexible automation, yet these general-purpose agents face five
critical challenges when applied to industrial management, including unfamiliar
element understanding, precision and efficiency, state localization, deployment
constraints, and safety requirements. To address these issues, we propose
InfraMind, a novel exploration-based GUI agentic framework specifically
tailored for industrial management systems. InfraMind integrates five
innovative modules to systematically resolve different challenges in industrial
management: (1) systematic search-based exploration with virtual machine
snapshots for autonomous understanding of complex GUIs; (2) memory-driven
planning to ensure high-precision and efficient task execution; (3) advanced
state identification for robust localization in hierarchical interfaces; (4)
structured knowledge distillation for efficient deployment with lightweight
models; and (5) comprehensive, multi-layered safety mechanisms to safeguard
sensitive operations. Extensive experiments on both open-source and commercial
DCIM platforms demonstrate that our approach consistently outperforms existing
frameworks in terms of task success rate and operational efficiency, providing
a rigorous and scalable solution for industrial management automation.

</details>


### [95] [Imagined Autocurricula](https://arxiv.org/abs/2509.13341)
*Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.AI

Relevance: 65.0

TL;DR: IMAC方法利用世界模型生成想象环境，通过无监督环境设计自动生成课程，在仅使用窄数据集训练的情况下，在保留环境中实现了强大的迁移性能


<details>
  <summary>Details</summary>
Motivation: 解决在具身环境中训练智能体需要大量训练数据或精确模拟的问题，利用离线被动收集的数据通过世界模型生成多样化训练环境

Method: 提出IMAC方法，结合世界模型和无监督环境设计(UED)，自动生成课程来训练鲁棒智能体

Result: 在一系列具有挑战性的程序生成环境中，仅使用较窄数据集训练的世界模型就能在保留环境中实现强大的迁移性能

Conclusion: 该方法为利用更大规模的基础世界模型训练通用智能体开辟了道路

Abstract: Training agents to act in embodied environments typically requires vast
training data or access to accurate simulation, neither of which exists for
many cases in the real world. Instead, world models are emerging as an
alternative leveraging offline, passively collected data, they make it possible
to generate diverse worlds for training agents in simulation. In this work, we
harness world models to generate imagined environments to train robust agents
capable of generalizing to novel task variations. One of the challenges in
doing this is ensuring the agent trains on useful generated data. We thus
propose a novel approach, IMAC (Imagined Autocurricula), leveraging
Unsupervised Environment Design (UED), which induces an automatic curriculum
over generated worlds. In a series of challenging, procedurally generated
environments, we show it is possible to achieve strong transfer performance on
held-out environments, having trained only inside a world model learned from a
narrower dataset. We believe this opens the path to utilizing larger-scale,
foundation world models for generally capable agents.

</details>


### [96] [Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning](https://arxiv.org/abs/2509.13352)
*Anis Koubaa,Khaled Gabr*

Main category: cs.AI

Relevance: 65.0

TL;DR: 本文提出了Agentic UAVs框架，通过五层架构将LLM驱动的推理能力集成到无人机系统中，在搜索救援模拟中显著提升了检测性能和自主决策能力


<details>
  <summary>Details</summary>
Motivation: 当前无人机系统主要依赖基于规则的控制和窄AI，缺乏上下文感知推理和自主决策能力，无法在动态不确定任务中有效适应。现有框架没有利用LLM代理进行实时知识访问和生态系统集成

Method: 提出五层架构（感知、推理、行动、集成、学习），集成ROS2和Gazebo原型系统，结合YOLOv11目标检测、GPT-4推理和本地Gemma-3部署

Result: 在模拟搜索救援场景中，检测置信度从0.72提升到0.79，人员检测率从75%提升到91%，行动推荐率从4.5%大幅提升到92%

Conclusion: 适度的计算开销能够实现质的自主性提升和生态系统集成，LLM驱动的无人机系统具有显著优势

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.

</details>


### [97] [Asterisk Operator](https://arxiv.org/abs/2509.13364)
*Zixi Li*

Main category: cs.AI

Relevance: 65.0

TL;DR: 提出了星号算子(*-operator)，一个基于邻接结构并行传播(ASPP)的统一抽象推理框架，将结构化推理任务形式化为由隐式关系图指导的局部并行状态演化过程。


<details>
  <summary>Details</summary>
Motivation: 为了解决抽象推理任务中的计算效率和全局推理能力之间的平衡问题，开发一个既能保持局部计算约束又能实现全局推理的统一框架。

Method: 基于邻接结构并行传播(ASPP)的星号算子，将推理任务建模为局部并行状态演化过程，并提出了Embedding-Asterisk蒸馏方法。

Result: 在ARC2挑战和康威生命游戏中验证了算子的普适性、收敛性和优越性能，使用仅6M参数在ARC2验证集上达到100%准确率。

Conclusion: 星号算子为神经符号推理提供了高效且收敛的计算范式，在抽象推理领域取得了显著突破。

Abstract: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified
framework for abstract reasoning based on Adjacency-Structured Parallel
Propagation (ASPP). The operator formalizes structured reasoning tasks as
local, parallel state evolution processes guided by implicit relational graphs.
We prove that the $\ast$-operator maintains local computational constraints
while achieving global reasoning capabilities, providing an efficient and
convergent computational paradigm for abstract reasoning problems. Through
rigorous mathematical analysis and comprehensive experiments on ARC2 challenges
and Conway's Game of Life, we demonstrate the operator's universality,
convergence properties, and superior performance. Our innovative
Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2
validation with only 6M parameters, representing a significant breakthrough in
neural-symbolic reasoning.
  \textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel
Propagation, Asterisk Operator, Convergence, Universal Approximation

</details>


### [98] [From Next Token Prediction to (STRIPS) World Models -- Preliminary Results](https://arxiv.org/abs/2509.13389)
*Carlos Núñez-Molina,Vicenç Gómez,Hector Geffner*

Main category: cs.AI

Relevance: 65.0

TL;DR: 使用Transformer架构从动作轨迹中学习命题STRIPS世界模型，通过监督式下一个动作预测任务，能够准确表示和学习世界模型。


<details>
  <summary>Details</summary>
Motivation: 研究如何仅从动作轨迹中学习世界模型，而不需要预先知道状态信息，这对于AI系统理解环境和规划行动具有重要意义。

Method: 将任务建模为监督式下一个动作预测问题，使用Transformer架构处理动作序列，通过正负样本（有效和无效动作序列）进行训练。

Result: 实验表明合适的Transformer架构能够忠实表示命题STRIPS世界模型，并且仅从随机有效和无效动作序列中就能成功学习。

Conclusion: 深度学习方法特别是Transformer架构能够有效学习世界模型，为从观察中学习环境动态提供了可行途径。

Abstract: We consider the problem of learning propositional STRIPS world models from
action traces alone, using a deep learning architecture (transformers) and
gradient descent. The task is cast as a supervised next token prediction
problem where the tokens are the actions, and an action $a$ may follow an
action sequence if the hidden effects of the previous actions do not make an
action precondition of $a$ false. We show that a suitable transformer
architecture can faithfully represent propositional STRIPS world models, and
that the models can be learned from sets of random valid (positive) and invalid
(negative) action sequences alone. A number of experiments are reported.

</details>


### [99] [Programmable Cognitive Bias in Social Agents](https://arxiv.org/abs/2509.13588)
*Xuan Liu,Haoyang Shang,Haojian Jin*

Main category: cs.AI

Relevance: 65.0

TL;DR: CoBRA是一个用于在基于LLM的社会模拟中系统化指定智能体行为的工具包，通过显式编程认知偏见来解决传统自然语言描述方法的一致性问题。


<details>
  <summary>Details</summary>
Motivation: 传统使用自然语言隐式描述智能体行为的方法无法在不同模型间产生一致行为，且无法准确捕捉描述的细微差别，需要更系统化的行为规范方法。

Method: CoBRA包含两个组件：1)认知偏见指数 - 通过经典社会科学实验量化智能体反应来测量认知偏见；2)行为调节引擎 - 通过调节使智能体展现受控的认知偏见。基于经典社会实验来显式编程智能体的认知偏见。

Result: 评估显示CoBRA能够以模型无关的方式精确编程社会智能体中展现的认知偏见，在技术基准测试中表现良好。

Conclusion: CoBRA提供了一种系统化的方法来显式编程LLM智能体的认知偏见，解决了传统自然语言描述方法的局限性，实现了模型无关的精确行为控制。

Abstract: This paper introduces CoBRA, a novel toolkit for systematically specifying
agent behavior in LLM-based social simulation. We found that conventional
approaches that specify agent behaviors through implicit natural language
descriptions cannot yield consistent behaviors across models, and the produced
agent behaviors do not capture the nuances of the descriptions. In contrast,
CoBRA presents a new approach to program agents' cognitive biases explicitly,
by grounding agents' expected behaviors using classic social science
experiments. CoBRA has two components: (1) Cognitive Bias Index that measures
the cognitive bias of a social agent, by quantifying the agent's reactions in a
set of validated classical social science experiments; (2) Behavioral
Regulation Engine that aligns the agent's behavior to demonstrate controlled
cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and
technical benchmarks. Our results suggest that CoBRA can precisely program the
cognitive bias demonstrated in a social agent in a model-agnostic manner.

</details>


### [100] [MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation](https://arxiv.org/abs/2509.13773)
*Zhipeng Bian,Jieming Zhu,Xuyang Xie,Quanyu Dai,Zhou Zhao,Zhenhua Dong*

Main category: cs.AI

Relevance: 65.0

TL;DR: MIRA是一个智能手机上的任务指令推荐框架，通过长按图像或文本来推荐上下文相关的AI任务指令，使用MLLM进行多模态推理和约束解码来提高推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术在智能手机中的集成，需要简化用户访问预定义AI服务的方式，提供直观的一键式AI任务执行体验。

Method: 1) 基于多模态大语言模型的推荐流水线，进行结构化推理提取关键实体和推断用户意图；2) 模板增强推理机制整合高级推理模板；3) 基于前缀树的约束解码策略限制输出到预定义指令候选集

Result: 在真实标注数据集和用户研究中，MIRA在指令推荐准确性方面表现出显著改进

Conclusion: MIRA有潜力彻底改变用户在智能手机上与AI服务交互的方式，提供更无缝和高效的体验

Abstract: The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.

</details>


### [101] [CrowdAgent: Multi-Agent Managed Multi-Source Annotation System](https://arxiv.org/abs/2509.14030)
*Maosheng Qin,Renyu Zhu,Mingxuan Xia,Chenkai Chen,Zhen Zhu,Minmin Lin,Junbo Zhao,Lu Xu,Changjie Fan,Runze Wu,Haobo Wang*

Main category: cs.AI

Relevance: 65.0

TL;DR: CrowdAgent是一个多智能体系统，通过整合任务分配、数据标注和质量/成本管理，为LLMs、SLMs和人类专家提供端到端的协同标注流程控制。


<details>
  <summary>Details</summary>
Motivation: 当前NLP方法虽然开始利用LLMs、SLMs和人类专家等多种标注来源，但主要关注标注步骤本身，缺乏对复杂调度和质量-成本权衡的统一动态管理。

Method: 提出CrowdAgent多智能体系统，采用新颖的任务分配方法，使LLMs、SLMs和人类专家能够在协同标注工作流中协同推进。

Result: 在六个不同的多模态分类任务上进行了广泛实验，证明了CrowdAgent的有效性。

Conclusion: CrowdAgent为管理多样化标注来源提供了端到端的流程控制解决方案，解决了复杂调度和质量-成本权衡问题。

Abstract: High-quality annotated data is a cornerstone of modern Natural Language
Processing (NLP). While recent methods begin to leverage diverse annotation
sources-including Large Language Models (LLMs), Small Language Models (SLMs),
and human experts-they often focus narrowly on the labeling step itself. A
critical gap remains in the holistic process control required to manage these
sources dynamically, addressing complex scheduling and quality-cost trade-offs
in a unified manner. Inspired by real-world crowdsourcing companies, we
introduce CrowdAgent, a multi-agent system that provides end-to-end process
control by integrating task assignment, data annotation, and quality/cost
management. It implements a novel methodology that rationally assigns tasks,
enabling LLMs, SLMs, and human experts to advance synergistically in a
collaborative annotation workflow. We demonstrate the effectiveness of
CrowdAgent through extensive experiments on six diverse multimodal
classification tasks. The source code and video demo are available at
https://github.com/QMMMS/CrowdAgent.

</details>


### [102] [Synthetic Data and the Shifting Ground of Truth](https://arxiv.org/abs/2509.13355)
*Dietmar Offenhuber*

Main category: cs.CY

Relevance: 65.0

TL;DR: 论文探讨合成数据如何挑战传统"垃圾进垃圾出"假设，分析在没有真实世界参照的情况下如何构建ground truth，并讨论从表征性数据向模仿性数据概念的转变。


<details>
  <summary>Details</summary>
Motivation: 研究合成数据在AI训练中的使用如何颠覆传统的数据保真度概念，探索在没有真实世界参照的情况下如何建立有效的ground truth系统。

Method: 通过理论分析探讨合成数据的特性及其对机器学习基础假设的影响，考察研究人员在实践中如何应对ground truth的自指性悖论。

Result: 发现合成数据虽然缺乏真实世界参照，但可能通过补偿已知偏差、防止过拟合和支持泛化来提升模型性能，甚至注入噪声和不可信数据也可能有益。

Conclusion: 传统基于表征准确性的数据保真度假设需要重新审视，ground truth正在从表征性概念转向模仿性概念，这对AI研究和实践具有深远影响。

Abstract: The emergence of synthetic data for privacy protection, training data
generation, or simply convenient access to quasi-realistic data in any shape or
volume complicates the concept of ground truth. Synthetic data mimic real-world
observations, but do not refer to external features. This lack of a
representational relationship, however, not prevent researchers from using
synthetic data as training data for AI models and ground truth repositories. It
is claimed that the lack of data realism is not merely an acceptable tradeoff,
but often leads to better model performance than realistic data: compensate for
known biases, prevent overfitting and support generalization, and make the
models more robust in dealing with unexpected outliers. Indeed, injecting noisy
and outright implausible data into training sets can be beneficial for the
model. This greatly complicates usual assumptions based on which
representational accuracy determines data fidelity (garbage in - garbage out).
Furthermore, ground truth becomes a self-referential affair, in which the
labels used as a ground truth repository are themselves synthetic products of a
generative model and as such not connected to real-world observations. My paper
examines how ML researchers and practitioners bootstrap ground truth under such
paradoxical circumstances without relying on the stable ground of
representation and real-world reference. It will also reflect on the broader
implications of a shift from a representational to what could be described as a
mimetic or iconic concept of data.

</details>


### [103] [Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks](https://arxiv.org/abs/2509.13968)
*Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel*

Main category: cs.AI

Relevance: 45.0

TL;DR: 该研究使用人工神经网络模型探讨信息流结构变化是否会导致认知性能的转变性变化，比较了前馈、循环和分层网络在语法学习任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机是验证认知进化是否通过改变生物神经网络信息流结构的主要转变来实现，借鉴进化生物学中的转变理论来理解认知能力的跃迁。

Method: 使用理想化信息流模型和人工神经网络，比较前馈、循环和分层拓扑结构，在网络规模和资源控制条件下测试不同复杂度人工语法的学习性能。

Result: 发现循环网络相比前馈网络能处理更多类型的输入，在最复杂语法学习上表现有质的提升；循环网络训练困难构成转变障碍；分层网络在语法学习中未表现出优势。

Conclusion: 某些信息流结构变化确实能导致认知性能的转变性变化，这支持了认知进化可能通过神经网络结构转变实现的理论。

Abstract: Transitional accounts of evolution emphasise a few changes that shape what is
evolvable, with dramatic consequences for derived lineages. More recently it
has been proposed that cognition might also have evolved via a series of major
transitions that manipulate the structure of biological neural networks,
fundamentally changing the flow of information. We used idealised models of
information flow, artificial neural networks (ANNs), to evaluate whether
changes in information flow in a network can yield a transitional change in
cognitive performance. We compared networks with feed-forward, recurrent and
laminated topologies, and tested their performance learning artificial grammars
that differed in complexity, controlling for network size and resources. We
documented a qualitative expansion in the types of input that recurrent
networks can process compared to feed-forward networks, and a related
qualitative increase in performance for learning the most complex grammars. We
also noted how the difficulty in training recurrent networks poses a form of
transition barrier and contingent irreversibility -- other key features of
evolutionary transitions. Not all changes in network topology confer a
performance advantage in this task set. Laminated networks did not outperform
non-laminated networks in grammar learning. Overall, our findings show how some
changes in information flow can yield transitions in cognitive performance.

</details>


### [104] [Label-Efficient Grasp Joint Prediction with Point-JEPA](https://arxiv.org/abs/2509.13349)
*Jed Guzelkabaagac,Boris Petrović*

Main category: cs.RO

Relevance: 45.0

TL;DR: Point-JEPA自监督预训练方法在低标签数据情况下显著提升抓取关节角度预测性能，在DLR-Hand II数据集上RMSE降低26%，达到全监督性能水平


<details>
  <summary>Details</summary>
Motivation: 研究3D自监督预训练（特别是Joint-Embedding Predictive Architecture）是否能够实现标签高效的抓取关节角度预测，解决机器人抓取学习中数据标注成本高的问题

Method: 使用从网格标记化的点云数据，采用ShapeNet预训练的Point-JEPA编码器，训练轻量级多假设头部，使用winner-takes-all策略，通过top-logit选择进行评估

Result: 在DLR-Hand II数据集的对象级分割上，Point-JEPA在低标签情况下将RMSE降低了最多26%，并且达到了与全监督方法相当的性能水平

Conclusion: JEPA风格的预训练是数据高效抓取学习的一种实用方法，证明了自监督预训练在机器人抓取任务中的有效性

Abstract: We investigate whether 3D self-supervised pretraining with a Joint-Embedding
Predictive Architecture (Point-JEPA) enables label-efficient grasp joint-angle
prediction. Using point clouds tokenized from meshes and a ShapeNet-pretrained
Point-JEPA encoder, we train a lightweight multi-hypothesis head with
winner-takes-all and evaluate by top-logit selection. On DLR-Hand II with
object-level splits, Point-JEPA reduces RMSE by up to 26% in low-label regimes
and reaches parity with full supervision. These results suggest JEPA-style
pretraining is a practical approach for data-efficient grasp learning.

</details>


### [105] [Evaluating undergraduate mathematics examinations in the era of generative AI: a curriculum-level case study](https://arxiv.org/abs/2509.13359)
*Benjamin J. Walker,Beatriz Navarro Lameda,Ruth A. Reynolds*

Main category: cs.CY

Relevance: 45.0

TL;DR: 该研究评估了生成式AI在无监考开放书数学考试中的表现，发现AI能达到一等学位水平且表现比学生更稳定，表明需要重新设计数学评估方式。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI工具在教育领域的应用，需要重新评估传统闭卷考试在无监考开放书环境中的教学相关性，特别是对学术诚信和教学一致性的担忧。

Method: 研究生成、转录并盲评生成式AI对8门本科数学考试的作答，涵盖第一年全部课程，通过组合AI对单个问题的独立回答来评估其表现。

Result: 生成式AI达到一等学位水平，表现比监考环境中的学生更加稳定，但不同模块间表现存在差异。

Conclusion: 需要在无监督环境中重新设计数学评估方式，当前标准在生成式AI时代可能降低教学价值。

Abstract: Generative artificial intelligence (GenAI) tools such as OpenAI's ChatGPT are
transforming the educational landscape, prompting reconsideration of
traditional assessment practices. In parallel, universities are exploring
alternatives to in-person, closed-book examinations, raising concerns about
academic integrity and pedagogical alignment in uninvigilated settings. This
study investigates whether traditional closed-book mathematics examinations
retain their pedagogical relevance when hypothetically administered in
uninvigilated, open-book settings with GenAI access. Adopting an empirical
approach, we generate, transcribe, and blind-mark GenAI submissions to eight
undergraduate mathematics examinations at a Russel Group university, spanning
the entirety of the first-year curriculum. By combining independent GenAI
responses to individual questions, we enable a meaningful evaluation of GenAI
performance, both at the level of modules and across the first-year curriculum.
We find that GenAI attainment is at the level of a first-class degree, though
current performance can vary between modules. Further, we find that GenAI
performance is remarkably consistent when viewed across the entire curriculum,
significantly more so than that of students in invigilated examinations. Our
findings evidence the need for redesigning assessments in mathematics for
unsupervised settings, and highlight the potential reduction in pedagogical
value of current standards in the era of generative artificial intelligence.

</details>


### [106] [Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning](https://arxiv.org/abs/2509.14195)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

Relevance: 40.0

TL;DR: 该论文通过层次架构验证了二阶学习促进环境-认知同构性形成的假设，其中GCN作为一阶学习器进行路径预测，MLP控制器作为二阶学习器动态调整GCN参数，在迷宫任务中展现了性能提升和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索心智表征（即内部模型与外部环境的结构同构）如何通过二阶学习机制（调整一阶学习）来促进高级认知，并对此假设进行实证验证。

Method: 提出分层架构：使用图卷积网络（GCN）作为一阶学习器直接预测最优导航路径，MLP控制器作为二阶学习器在遇到结构新颖的迷宫环境时动态调整GCN参数。

Result: 实验表明，当认知系统发展出与环境结构同构的内部心智地图时，二阶学习特别有效，在未见过的迷宫任务上实现了显著的性能提升和鲁棒泛化。

Conclusion: 研究为结构化心智表征在最大化二阶学习效果中的关键作用提供了实证支持，验证了环境-认知同构性假说。

Abstract: Mental representation, characterized by structured internal models mirroring
external environments, is fundamental to advanced cognition but remains
challenging to investigate empirically. Existing theory hypothesizes that
second-order learning -- learning mechanisms that adapt first-order learning
(i.e., learning about the task/domain) -- promotes the emergence of such
environment-cognition isomorphism. In this paper, we empirically validate this
hypothesis by proposing a hierarchical architecture comprising a Graph
Convolutional Network (GCN) as a first-order learner and an MLP controller as a
second-order learner. The GCN directly maps node-level features to predictions
of optimal navigation paths, while the MLP dynamically adapts the GCN's
parameters when confronting structurally novel maze environments. We
demonstrate that second-order learning is particularly effective when the
cognitive system develops an internal mental map structurally isomorphic to the
environment. Quantitative and qualitative results highlight significant
performance improvements and robust generalization on unseen maze tasks,
providing empirical support for the pivotal role of structured mental
representations in maximizing the effectiveness of second-order learning.

</details>


### [107] [See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles](https://arxiv.org/abs/2509.13615)
*Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

Relevance: 35.0

TL;DR: 该论文提出了State-aware Reasoning (StaR)训练方法，解决多模态代理在GUI切换控制指令执行不可靠的问题，特别是在当前状态与期望状态匹配时的错误执行。


<details>
  <summary>Details</summary>
Motivation: 多模态代理在图形用户界面(GUI)控制中执行切换(toggle)指令时存在不可靠性，特别是在当前状态已经符合期望状态时容易出错，这限制了其在实际应用中的效果。

Method: 构建了状态控制基准测试，提出StaR训练方法，教导代理感知当前切换状态、分析指令中的期望状态，并相应采取行动。

Result: 在三个多模态代理上的实验显示，StaR能将切换指令执行准确率提升30%以上，在三个公共基准测试中也提升了通用任务性能。

Conclusion: StaR方法有效解决了GUI切换控制问题，在动态环境中显示出实际应用潜力，为多模态代理的可靠交互提供了解决方案。

Abstract: The advent of multimodal agents facilitates effective interaction within
graphical user interface (GUI), especially in ubiquitous GUI control. However,
their inability to reliably execute toggle control instructions remains a key
bottleneck. To investigate this, we construct a state control benchmark with
binary toggle instructions from public datasets. Evaluations of existing agents
demonstrate their unreliability, particularly when the current toggle state
already matches the desired state. To address the challenge, we propose
State-aware Reasoning (StaR), a training method that teaches agents to perceive
the current toggle state, analyze the desired state from the instruction, and
act accordingly. Experiments on three multimodal agents demonstrate that StaR
can improve toggle instruction execution accuracy by over 30\%. Further
evaluations on three public benchmarks show that StaR also enhances general
task performance. Finally, evaluations on a dynamic environment highlight the
potential of StaR for real-world applications. Code, benchmark, and
StaR-enhanced agents are available at https://github.com/ZrW00/StaR.

</details>


### [108] [The Provenance Problem: LLMs and the Breakdown of Citation Norms](https://arxiv.org/abs/2509.13365)
*Brian D. Earp,Haotian Yuan,Julian Koplin,Sebastian Porsdam Mann*

Main category: cs.CY

Relevance: 35.0

TL;DR: 论文探讨了生成式AI在科研写作中引发的学术溯源问题，当研究者使用ChatGPT等工具时可能无意中复制未引用的前人观点，形成新型的学术不端问题


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在科研写作中的广泛应用，传统的学术引用和知识产权体系面临挑战，需要解决AI生成内容中可能存在的无意识抄袭和学术溯源断裂问题

Method: 采用概念分析和伦理框架构建的方法，提出了"溯源问题"的理论概念，分析AI对学术作者身份规范的挑战

Result: 识别出一种新型的学术 attributional harm（归属伤害），即研究者可能无意中通过AI工具受益于他人的智力贡献而无需引用

Conclusion: 需要建立新的伦理和专业框架来应对生成式AI带来的学术溯源挑战，保护学术诚信和公平性

Abstract: The increasing use of generative AI in scientific writing raises urgent
questions about attribution and intellectual credit. When a researcher employs
ChatGPT to draft a manuscript, the resulting text may echo ideas from sources
the author has never encountered. If an AI system reproduces insights from, for
example, an obscure 1975 paper without citation, does this constitute
plagiarism? We argue that such cases exemplify the 'provenance problem': a
systematic breakdown in the chain of scholarly credit. Unlike conventional
plagiarism, this phenomenon does not involve intent to deceive (researchers may
disclose AI use and act in good faith) yet still benefit from the uncredited
intellectual contributions of others. This dynamic creates a novel category of
attributional harm that current ethical and professional frameworks fail to
address. As generative AI becomes embedded across disciplines, the risk that
significant ideas will circulate without recognition threatens both the
reputational economy of science and the demands of epistemic justice. This
Perspective analyzes how AI challenges established norms of authorship,
introduces conceptual tools for understanding the provenance problem, and
proposes strategies to preserve integrity and fairness in scholarly
communication.

</details>


### [109] [Gen AI in Proof-based Math Courses: A Pilot Study](https://arxiv.org/abs/2509.13570)
*Hannah Klawa,Shraddha Rajpal,Cigole Thomas*

Main category: cs.AI

Relevance: 25.0

TL;DR: 该研究调查了本科生在证明类数学课程中使用生成式AI的情况，分析了学生的使用模式、对AI有用性和局限性的看法，以及对数学教学的影响。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在高等教育中的快速普及和现有AI检测工具的不可靠性，需要制定鼓励学生学习和批判性思维的政策。研究旨在了解学生在证明类数学课程中如何使用和看待生成式AI。

Method: 通过对三门证明类本科数学课程（抽象代数、拓扑学）的学生进行问卷调查和访谈，分析学生如何与AI工具互动及其对生成式AI的看法。

Result: 研究发现学生在允许使用AI的课程政策下会使用生成式AI工具，研究分析了学生的使用模式、对AI有用性和局限性的认知。

Conclusion: 研究讨论了将生成式AI整合到证明类数学教学中的未来考量，为制定相关教学政策提供参考。

Abstract: With the rapid rise of generative AI in higher education and the
unreliability of current AI detection tools, developing policies that encourage
student learning and critical thinking has become increasingly important. This
study examines student use and perceptions of generative AI across three
proof-based undergraduate mathematics courses: a first-semester abstract
algebra course, a topology course and a second-semester abstract algebra
course. In each case, course policy permitted some use of generative AI.
Drawing on survey responses and student interviews, we analyze how students
engaged with AI tools, their perceptions of generative AI's usefulness and
limitations, and what implications these perceptions hold for teaching
proof-based mathematics. We conclude by discussing future considerations for
integrating generative AI into proof-based mathematics instruction.

</details>


### [110] [Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis](https://arxiv.org/abs/2408.00208)
*SaeedReza Motamedian,Sadra Mohaghegh,Elham Babadi Oregani,Mahrsa Amjadi,Parnian Shobeiri,Negin Cheraghi,Niusha Solouki,Nikoo Ahmadi,Hossein Mohammad-Rahimi,Yassine Bouchareb,Arman Rahmim*

Main category: physics.med-ph

Relevance: 25.0

TL;DR: 该论文系统综述了AI技术在COVID-19预后预测中的应用，主要基于CT和X光影像数据，分析了36项研究，评估了多种机器学习模型在死亡率、疾病严重程度和呼吸机需求预测方面的表现。


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行期间需要有效的预后预测工具来帮助临床医生进行患者管理和资源分配，AI技术特别是机器学习和深度学习方法在医学影像分析方面展现出巨大潜力。

Method: 系统性文献回顾，检索了Medline、Google Scholar、Scopus等数据库，纳入36项研究，使用机器学习（SVM、Random Forest、XGBoost）和深度学习（CNN、Siamense模型）方法分析CT和X光影像的放射组学特征。

Result: 模型在死亡率预测敏感性71%、特异性69%；疾病严重程度评估敏感性88%、特异性89%；呼吸机需求预测敏感性67%、特异性89%。结合患者人口统计学、临床数据和实验室检测结果可进一步提升模型性能。

Conclusion: AI方法基于医学影像的放射组学特征能够有效预测COVID-19患者的预后，有助于临床决策和资源优化配置，多模态数据融合可显著改善预测准确性。

Abstract: Purpose: Artificial intelligence (AI) techniques have been extensively
utilized for diagnosing and prognosis of several diseases in recent years. This
study identifies, appraises and synthesizes published studies on the use of AI
for the prognosis of COVID-19. Method: Electronic search was performed using
Medline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that
examined machine learning or deep learning methods to determine the prognosis
of COVID-19 using CT or chest X-ray images were included. Polled sensitivity,
specificity area under the curve and diagnostic odds ratio were calculated.
Result: A total of 36 articles were included; various prognosis-related issues,
including disease severity, mechanical ventilation or admission to the
intensive care unit and mortality, were investigated. Several AI models and
architectures were employed, such as the Siamense model, support vector
machine, Random Forest , eXtreme Gradient Boosting, and convolutional neural
networks. The models achieved 71%, 88% and 67% sensitivity for mortality,
severity assessment and need for ventilation, respectively. The specificity of
69%, 89% and 89% were reported for the aforementioned variables. Conclusion:
Based on the included articles, machine learning and deep learning methods used
for the prognosis of COVID-19 patients using radiomic features from CT or CXR
images can help clinicians manage patients and allocate resources more
effectively. These studies also demonstrate that combining patient demographic,
clinical data, laboratory tests and radiomic features improves model
performances.

</details>


### [111] [Explainable AI-Enhanced Supervisory Control for High-Precision Spacecraft Formation](https://arxiv.org/abs/2509.13331)
*Reza Pirayeshshirazinezhad*

Main category: astro-ph.IM

Relevance: 25.0

TL;DR: 使用AI和监督自适应控制系统优化航天器精确编队任务，集成深度神经网络进行参数预测，降低能耗并提高任务精度


<details>
  <summary>Details</summary>
Motivation: 为VTXO空间任务（两个航天器组成虚拟望远镜）提供高精度的编队控制，解决传统自适应控制器无法实现的实时权衡和可解释性问题

Method: 结合定时自动机进行监督控制、蒙特卡洛模拟评估稳定性、深度神经网络预测最优任务参数，集成约束非凸动态优化流程

Result: 系统降低了能耗并提高了任务精度，能够有效处理动态不确定性和干扰

Conclusion: AI框架为航天器精确编队任务提供了可解释、实时权衡的优化方案，优于传统控制方法

Abstract: We use artificial intelligence (AI) and supervisory adaptive control systems
to plan and optimize the mission of precise spacecraft formation. Machine
learning and robust control enhance the efficiency of spacecraft precision
formation of the Virtual Telescope for X-ray Observation (VTXO) space mission.
VTXO is a precise formation of two separate spacecraft making a virtual
telescope with a one-kilometer focal length. One spacecraft carries the lens
and the other spacecraft holds the camera to observe high-energy space objects
in the X-ray domain with 55 milli-arcsecond angular resolution accuracy. Timed
automata for supervisory control, Monte Carlo simulations for stability and
robustness evaluation, and integration of deep neural networks for optimal
estimation of mission parameters, satisfy the high precision mission criteria.
We integrate deep neural networks with a constrained, non-convex dynamic
optimization pipeline to predict optimal mission parameters, ensuring precision
mission criteria are met. AI framework provides explainability by predicting
the resulting energy consumption and mission error for a given set of mission
parameters. It allows for transparent, justifiable, and real-time trade-offs, a
capability not present in traditional adaptive controllers. The results show
reductions in energy consumption and improved mission accuracy, demonstrating
the capability of the system to address dynamic uncertainties and disturbances.

</details>


### [112] [Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging](https://arxiv.org/abs/2509.13372)
*Prahlad G Menon*

Main category: eess.IV

Relevance: 25.0

TL;DR: 开发了一个基于Gemini 2.5 Flash和Hunyuan3D-2mini的多步骤AI流水线，从单视角血管造影生成CFD适用的3D几何模型，用于Fontan姑息手术的血流动力学分析


<details>
  <summary>Details</summary>
Motivation: 传统2D成像无法充分表征单心室先天性心脏病Fontan姑息手术后的复杂血流模式，当前依赖荧光血管造影的方法只能提供有限的3D几何信息，限制了计算流体动力学分析和手术规划

Method: 使用Google Gemini 2.5 Flash（25亿参数）进行医学图像预处理、血管分割、对比度增强、伪影去除和虚拟血流可视化，然后通过腾讯Hunyuan3D-2mini（3.84亿参数）生成立体光刻文件

Result: 流水线经过16个处理步骤成功生成几何优化的2D投影，最终投影准确保留了复杂的Fontan几何结构，虚拟血流可视化识别出中心连接处的停滞区和分支动脉的血流模式，整个处理过程在15分钟内完成

Conclusion: 该方法展示了从常规血管造影数据生成CFD适用几何模型的临床可行性，为使用现成成像数据进行高级几何和血流动力学分析的普及奠定了基础

Abstract: Fontan palliation for univentricular congenital heart disease progresses to
hemodynamic failure with complex flow patterns poorly characterized by
conventional 2D imaging. Current assessment relies on fluoroscopic angiography,
providing limited 3D geometric information essential for computational fluid
dynamics (CFD) analysis and surgical planning.
  A multi-step AI pipeline was developed utilizing Google's Gemini 2.5 Flash
(2.5B parameters) for systematic, iterative processing of fluoroscopic
angiograms through transformer-based neural architecture. The pipeline
encompasses medical image preprocessing, vascular segmentation, contrast
enhancement, artifact removal, and virtual hemodynamic flow visualization
within 2D projections. Final views were processed through Tencent's
Hunyuan3D-2mini (384M parameters) for stereolithography file generation.
  The pipeline successfully generated geometrically optimized 2D projections
from single-view angiograms after 16 processing steps using a custom web
interface. Initial iterations contained hallucinated vascular features
requiring iterative refinement to achieve anatomically faithful
representations. Final projections demonstrated accurate preservation of
complex Fontan geometry with enhanced contrast suitable for 3D conversion.
AI-generated virtual flow visualization identified stagnation zones in central
connections and flow patterns in branch arteries. Complete processing required
under 15 minutes with second-level API response times.
  This approach demonstrates clinical feasibility of generating CFD-suitable
geometries from routine angiographic data, enabling 3D generation and rapid
virtual flow visualization for cursory insights prior to full CFD simulation.
While requiring refinement cycles for accuracy, this establishes foundation for
democratizing advanced geometric and hemodynamic analysis using readily
available imaging data.

</details>


### [113] [An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques](https://arxiv.org/abs/2509.13880)
*Mingwei Zhang,Zhenhao Gu,Liangda Fang,Cunjing Ge,Ziliang Chen,Zhao-Rong Lai,Quanlong Guan*

Main category: cs.AI

Relevance: 20.0

TL;DR: 本文提出了一个基于DPLL架构的精确方法来解决整数线性约束的模型计数问题(MCILC)，集成了混合整数规划中的简化技术，在随机和应用基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 线性约束是计算机科学、运筹学和优化领域的基础约束，许多应用问题可归结为整数线性约束的模型计数问题(MCILC)，需要高效的精确求解方法。

Method: 基于详尽的DPLL架构设计精确方法，集成混合整数规划中的有效简化技术来提高效率。

Result: 在2840个随机基准和4131个应用基准上测试，新方法在随机基准上解决了1718个实例（现有最佳方法为1470个），并且是唯一能解决所有4131个应用实例的方法。

Conclusion: 该方法在MCILC问题上显著优于现有精确方法，特别是在应用实例上表现出色。

Abstract: Linear constraints are one of the most fundamental constraints in fields such
as computer science, operations research and optimization. Many applications
reduce to the task of model counting over integer linear constraints (MCILC).
In this paper, we design an exact approach to MCILC based on an exhaustive DPLL
architecture. To improve the efficiency, we integrate several effective
simplification techniques from mixed integer programming into the architecture.
We compare our approach to state-of-the-art MCILC counters and propositional
model counters on 2840 random and 4131 application benchmarks. Experimental
results show that our approach significantly outperforms all exact methods in
random benchmarks solving 1718 instances while the state-of-the-art approach
only computes 1470 instances. In addition, our approach is the only approach to
solve all 4131 application instances.

</details>


### [114] [Dual Actor DDPG for Airborne STAR-RIS Assisted Communications](https://arxiv.org/abs/2509.13328)
*Danish Rizvi,David Boyle*

Main category: eess.SP

Relevance: 15.0

TL;DR: 该研究提出了一种基于无人机载STAR-RIS的通信系统，采用耦合TRC相位偏移模型，并开发了DA-DDPG算法来联合优化无人机轨迹、波束成形和RIS配置，显著提升了通信效率和公平性。


<details>
  <summary>Details</summary>
Motivation: 现有STAR-RIS研究通常假设独立的传输和反射系数，但实际中存在耦合关系。本研究旨在探索更真实的耦合TRC模型，并解决无人机载RIS系统中的联合优化问题。

Method: 提出DA-DDPG算法，使用双actor网络处理高维混合动作空间，设计了基于调和平均指数的奖励函数来保证用户公平性，并联合优化无人机轨迹、基站波束成形和被动RIS配置。

Result: DA-DDPG算法比传统DDPG和DQN分别提升24%和97%的累积奖励；3D轨迹优化比2D和高度优化提升28%通信效率；HFI奖励函数降低41%QoS拒绝率；移动Aerial-STAR系统优于固定部署方案。

Conclusion: Aerial-STAR系统具有巨大潜力，提出的DA-DDPG方法在优化性能方面非常有效，耦合相位STAR-RIS优于传统RIS配置。

Abstract: This study departs from the prevailing assumption of independent Transmission
and Reflection Coefficients (TRC) in Airborne Simultaneous Transmit and Reflect
Reconfigurable Intelligent Surface (STAR-RIS) research. Instead, we explore a
novel multi-user downlink communication system that leverages a UAV-mounted
STAR-RIS (Aerial-STAR) incorporating a coupled TRC phase shift model. Our key
contributions include the joint optimization of UAV trajectory, active
beamforming vectors at the base station, and passive RIS TRCs to enhance
communication efficiency, while considering UAV energy constraints. We design
the TRC as a combination of discrete and continuous actions, and propose a
novel Dual Actor Deep Deterministic Policy Gradient (DA-DDPG) algorithm. The
algorithm relies on two separate actor networks for high-dimensional hybrid
action space. We also propose a novel harmonic mean index (HFI)-based reward
function to ensure communication fairness amongst users. For comprehensive
analysis, we study the impact of RIS size on UAV aerodynamics showing that it
increases drag and energy demand. Simulation results demonstrate that the
proposed DA-DDPG algorithm outperforms conventional DDPG and DQN-based
solutions by 24% and 97%, respectively, in accumulated reward.
Three-dimensional UAV trajectory optimization achieves 28% higher communication
efficiency compared to two-dimensional and altitude optimization. The HFI based
reward function provides 41% lower QoS denial rates as compared to other
benchmarks. The mobile Aerial-STAR system shows superior performance over fixed
deployed counterparts, with the coupled phase STAR-RIS outperforming dual
Transmit/Reflect RIS and conventional RIS setups. These findings highlight the
potential of Aerial-STAR systems and the effectiveness of our proposed DA-DDPG
approach in optimizing their performance.

</details>


### [115] [Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments](https://arxiv.org/abs/2509.13342)
*Isaac Ronald Ward*

Main category: cs.RO

Relevance: 15.0

TL;DR: 本文提出了一种改进的视觉定位方法，通过修改损失函数结合位置和旋转误差，提高了机器人在室内场景中的定位精度，并建立了完整的导航算法流程


<details>
  <summary>Details</summary>
Motivation: 改进现有视觉定位神经网络，在不增加训练难度的情况下提高定位性能，特别是解决感知混淆问题

Method: 扩展网络损失函数，直观地结合位置和旋转误差；使用摄影测量数据创建姿态标记数据集；在TurtleBot上进行实时测试

Result: 室内定位精度显著提升：中位位置误差降低9.64%，旋转误差降低2.99%；最终达到0.11米和0.89度的定位精度

Conclusion: 提出了一个完整的鲁棒导航算法流程，仅需场景图像采集（最快330秒）即可为任何真实室内场景创建导航系统

Abstract: In this work, an existing deep neural network approach for determining a
robot's pose from visual information (RGB images) is modified, improving its
localization performance without impacting its ease of training. Explicitly,
the network's loss function is extended in a manner which intuitively combines
the positional and rotational error in order to increase robustness to
perceptual aliasing. An improvement in the localization accuracy for indoor
scenes is observed: with decreases of up to 9.64% and 2.99% in the median
positional and rotational error respectively, when compared to the unmodified
network.
  Additionally, photogrammetry data is used to produce a pose-labelled dataset
which allows the above model to be trained on a local environment, resulting in
localization accuracies of 0.11m & 0.89 degrees. This trained model forms the
basis of a navigation algorithm, which is tested in real-time on a TurtleBot (a
wheeled robotic device). As such, this work introduces a full pipeline for
creating a robust navigational algorithm for any given real world indoor scene;
the only requirement being a collection of images from the scene, which can be
captured in as little as 330 seconds of

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [116] [Privacy-Aware In-Context Learning for Large Language Models](https://arxiv.org/abs/2509.13625)
*Bishnu Bhusal,Manoj Acharya,Ramneet Kaur,Colin Samplawski,Anirban Roy,Adam D. Cobb,Rohit Chadha,Susmit Jha*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出了一种基于差分隐私的私有预测框架，用于生成高质量合成文本，在保证隐私的同时保持高实用性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在隐私泄露风险，攻击者可能从提示中提取敏感信息，需要在不微调模型的情况下提供严格隐私保证

Method: 利用差分隐私框架，对私有记录进行推理并聚合每个token的输出分布，结合私有和公共推理的混合操作来增强实用性

Result: 在上下文学习任务上优于现有最先进方法，能够生成长且连贯的合成文本同时保持隐私保证

Conclusion: 该方法为隐私保护文本生成提供了一个有前景的方向，在保持高实用性的同时提供强大的隐私保障

Abstract: Large language models (LLMs) have significantly transformed natural language
understanding and generation, but they raise privacy concerns due to potential
exposure of sensitive information. Studies have highlighted the risk of
information leakage, where adversaries can extract sensitive information
embedded in the prompts. In this work, we introduce a novel private prediction
framework for generating high-quality synthetic text with strong privacy
guarantees. Our approach leverages the Differential Privacy (DP) framework to
ensure worst-case theoretical bounds on information leakage without requiring
any fine-tuning of the underlying models.The proposed method performs inference
on private records and aggregates the resulting per-token output distributions.
This enables the generation of longer and coherent synthetic text while
maintaining privacy guarantees. Additionally, we propose a simple blending
operation that combines private and public inference to further enhance
utility. Empirical evaluations demonstrate that our approach outperforms
previous state-of-the-art methods on in-context-learning (ICL) tasks, making it
a promising direction for privacy-preserving text generation while maintaining
high utility.

</details>


### [117] [LLM-I: LLMs are Naturally Interleaved Multimodal Creators](https://arxiv.org/abs/2509.13642)
*Zirun Guo,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.LG

Relevance: 85.0

TL;DR: LLM-Interleaved是一个灵活的框架，将交错图像-文本生成重新定义为工具使用问题，通过RL训练LLM代理智能协调多种视觉工具，在多个基准测试中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前统一模型在交错图像-文本生成中的"单一工具"瓶颈问题，这些模型局限于合成图像，难以处理需要事实基础或程序精确性的任务。

Method: 设计一个中央LLM/MLLM代理，通过强化学习框架智能协调专用视觉工具（在线图像搜索、扩散生成、代码执行、图像编辑），使用结合规则逻辑和LLM/MLLM评估的混合奖励系统进行训练。

Result: 在四个基准测试中大幅超越现有方法，达到最先进性能，并引入了新的测试时扩展策略进一步提升性能。

Conclusion: LLM-Interleaved框架成功解决了多模态生成中的工具协调问题，为复杂视觉-语言任务提供了有效的解决方案。

Abstract: We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that
reframes interleaved image-text generation as a tool-use problem. LLM-I is
designed to overcome the "one-tool" bottleneck of current unified models, which
are limited to synthetic imagery and struggle with tasks requiring factual
grounding or programmatic precision. Our framework empowers a central LLM or
MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual
tools, including online image search, diffusion-based generation, code
execution, and image editing. The agent is trained to select and apply these
tools proficiently via a Reinforcement Learning (RL) framework that features a
hybrid reward system combining rule-based logic with judgments from LLM and
MLLM evaluators. Trained on a diverse new dataset using four different model
backbones, LLM-I demonstrates state-of-the-art performance, outperforming
existing methods by a large margin across four benchmarks. We also introduce a
novel test-time scaling strategy that provides further performance gains.
Project Page: https://github.com/ByteDance-BandAI/LLM-I.

</details>


### [118] [Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection](https://arxiv.org/abs/2509.13608)
*Niruthiha Selvanayagam,Ted Kurti*

Main category: cs.LG

Relevance: 75.0

TL;DR: 研究发现GPT-4o mini存在"单模态瓶颈"问题，其先进的多模态推理能力被上下文无关的安全过滤器系统性地覆盖，导致在多模态仇恨言论检测中出现可预测的误报。


<details>
  <summary>Details</summary>
Motivation: 随着大型多模态模型(LMMs)在日常数字生活中的普及，理解其安全架构对于AI对齐至关重要。本研究旨在系统分析OpenAI GPT-4o mini在仇恨言论检测任务中的表现和失败模式。

Method: 使用Hateful Memes Challenge数据集，对500个样本进行多阶段调查，分析模型的推理过程和失败模式。通过定量验证144个内容策略拒绝案例来探究安全过滤器的触发机制。

Result: 发现50%的拒绝由视觉内容触发，50%由文本内容触发，安全系统脆弱，不仅阻止高风险图像，还阻止良性的常见meme格式，导致可预测的误报。

Conclusion: 研究揭示了最先进LMMs中能力与安全之间的根本性冲突，强调需要更集成化、上下文感知的对齐策略来确保AI系统既能安全又能有效部署。

Abstract: As Large Multimodal Models (LMMs) become integral to daily digital life,
understanding their safety architectures is a critical problem for AI
Alignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a
globally deployed model, on the difficult task of multimodal hate speech
detection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase
investigation on 500 samples to probe the model's reasoning and failure modes.
Our central finding is the experimental identification of a "Unimodal
Bottleneck," an architectural flaw where the model's advanced multimodal
reasoning is systematically preempted by context-blind safety filters. A
quantitative validation of 144 content policy refusals reveals that these
overrides are triggered in equal measure by unimodal visual 50% and textual 50%
content. We further demonstrate that this safety system is brittle, blocking
not only high-risk imagery but also benign, common meme formats, leading to
predictable false positives. These findings expose a fundamental tension
between capability and safety in state-of-the-art LMMs, highlighting the need
for more integrated, context-aware alignment strategies to ensure AI systems
can be deployed both safely and effectively.

</details>


### [119] [Controllable Pareto Trade-off between Fairness and Accuracy](https://arxiv.org/abs/2509.13651)
*Yongkang Du,Jieyu Zhao,Yijun Yang,Tianyi Zhou*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文提出了可控帕累托权衡(CPT)方法，通过多目标优化实现NLP任务中公平性与准确性的可控权衡，使用移动平均梯度稳定性和关键参数梯度剪枝来精确控制用户偏好的权衡方向。


<details>
  <summary>Details</summary>
Motivation: 当前NLP任务中的公平性-准确性权衡研究主要寻找单一"最优"解决方案，但忽略了帕累托前沿上的多样性。本研究旨在根据用户偏好提供可控的权衡解决方案。

Method: 采用多目标优化(MOO)方法，提出CPT框架：1)使用随机梯度的移动平均来稳定公平性更新方向；2)通过仅保留关键参数的梯度来进行梯度剪枝。在仇恨言论检测和职业分类任务上进行评估。

Result: 实验表明CPT能够在帕累托前沿上获得比基线方法更高质量的解决方案集合，展现出更好的可控性，能够精确遵循人工定义的参考向量。

Conclusion: CPT方法有效地解决了公平性-准确性权衡的可控性问题，为NLP任务提供了根据用户偏好定制化解决方案的能力。

Abstract: The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work
focuses on finding a single "optimal" solution to balance the two objectives,
which is limited considering the diverse solutions on the Pareto front. This
work intends to provide controllable trade-offs according to the user's
preference of the two objectives, which is defined as a reference vector. To
achieve this goal, we apply multi-objective optimization (MOO), which can find
solutions from various regions of the Pareto front. However, it is challenging
to precisely control the trade-off due to the stochasticity of the training
process and the high dimentional gradient vectors. Thus, we propose
Controllable Pareto Trade-off (CPT) that can effectively train models to
perform different trade-offs according to users' preferences. CPT 1) stabilizes
the fairness update with a moving average of stochastic gradients to determine
the update direction, and 2) prunes the gradients by only keeping the gradients
of the critical parameters. We evaluate CPT on hate speech detection and
occupation classification tasks. Experiments show that CPT can achieve a
higher-quality set of solutions on the Pareto front than the baseline methods.
It also exhibits better controllability and can precisely follow the
human-defined reference vectors.

</details>


### [120] [State Space Models over Directed Graphs](https://arxiv.org/abs/2509.13735)
*Junzhi She,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出了DirGraphSSM，首个将状态空间模型系统扩展到有向图学习的架构，通过k-hop ego图序列化和消息传递机制，在保持高效训练的同时实现了SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络和图Transformer在处理有向图时面临两大挑战：有效捕捉长距离因果依赖关系，以及在处理大规模图数据集时平衡准确性和训练效率。现有图状态空间模型仅适用于无向图，限制了其性能

Method: 提出DirEgo2Token方法通过k-hop ego图将有向图序列化，并在此基础上开发DirGraphSSM架构，通过消息传递机制在有向图上实现状态空间模型

Result: 在三个代表性有向图学习任务上达到SOTA性能，在另外两个任务上获得竞争性性能，训练速度比现有SOTA模型提升1.5-2倍

Conclusion: DirGraphSSM成功将状态空间模型扩展到有向图学习领域，在保持高效率的同时显著提升了性能，为有向图学习提供了新的解决方案

Abstract: Directed graphs are ubiquitous across numerous domains, where the
directionality of edges encodes critical causal dependencies. However, existing
GNNs and graph Transformers tailored for directed graphs face two major
challenges: (1) effectively capturing long-range causal dependencies derived
from directed edges; (2) balancing accuracy and training efficiency when
processing large-scale graph datasets. In recent years, state space models
(SSMs) have achieved substantial progress in causal sequence tasks, and their
variants designed for graphs have demonstrated state-of-the-art accuracy while
maintaining high efficiency across various graph learning benchmarks. However,
existing graph state space models are exclusively designed for undirected
graphs, which limits their performance in directed graph learning. To this end,
we propose an innovative approach DirEgo2Token which sequentializes directed
graphs via k-hop ego graphs. This marks the first systematic extension of state
space models to the field of directed graph learning. Building upon this, we
develop DirGraphSSM, a novel directed graph neural network architecture that
implements state space models on directed graphs via the message-passing
mechanism. Experimental results demonstrate that DirGraphSSM achieves
state-of-the-art performance on three representative directed graph learning
tasks while attaining competitive performance on two additional tasks with
1.5$\times $ to 2$\times $ training speed improvements compared to existing
state-of-the-art models.

</details>


### [121] [Towards a Physics Foundation Model](https://arxiv.org/abs/2509.13805)
*Florian Wiesner,Matthias Wessling,Stephen Baek*

Main category: cs.LG

Relevance: 75.0

TL;DR: GPhyT是一个通用物理Transformer，在1.8TB多样化模拟数据上训练，能够在多个物理领域实现零样本泛化，无需重新训练即可模拟流体-固体相互作用、冲击波、热对流等物理现象。


<details>
  <summary>Details</summary>
Motivation: 当前基于物理的机器学习方法局限于单一狭窄领域，需要为每个新系统重新训练。作者希望开发一个物理基础模型，实现"一次训练，随处部署"的范式，从而民主化高保真模拟的访问，加速科学发现。

Method: 使用Transformer架构，在1.8TB多样化物理模拟数据上进行训练。关键洞察是Transformer可以从上下文中学习推断控制动力学，无需被告知底层方程。

Result: 1) 在多个物理领域表现优异，比专门架构性能提升高达29倍；2) 通过上下文学习实现零样本泛化到全新物理系统；3) 通过50时间步展开实现稳定的长期预测。

Conclusion: 这项工作证明了单个模型可以从数据中学习可泛化的物理原理，为通向可能改变计算科学和工程的通用物理基础模型开辟了道路。

Abstract: Foundation models have revolutionized natural language processing through a
``train once, deploy anywhere'' paradigm, where a single pre-trained model
adapts to countless downstream tasks without retraining. Access to a Physics
Foundation Model (PFM) would be transformative -- democratizing access to
high-fidelity simulations, accelerating scientific discovery, and eliminating
the need for specialized solver development. Yet current physics-aware machine
learning approaches remain fundamentally limited to single, narrow domains and
require retraining for each new system. We present the General Physics
Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that
demonstrates foundation model capabilities are achievable for physics. Our key
insight is that transformers can learn to infer governing dynamics from
context, enabling a single model to simulate fluid-solid interactions, shock
waves, thermal convection, and multi-phase dynamics without being told the
underlying equations. GPhyT achieves three critical breakthroughs: (1) superior
performance across multiple physics domains, outperforming specialized
architectures by up to 29x, (2) zero-shot generalization to entirely unseen
physical systems through in-context learning, and (3) stable long-term
predictions through 50-timestep rollouts. By establishing that a single model
can learn generalizable physical principles from data alone, this work opens
the path toward a universal PFM that could transform computational science and
engineering.

</details>


### [122] [ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2509.13753)
*Hyotaek Jeon,Hyunwook Lee,Juwon Kim,Sungahn Ko*

Main category: cs.LG

Relevance: 65.0

TL;DR: ST-LINK是一个增强大语言模型时空依赖建模能力的新框架，通过空间增强注意力和记忆检索前馈网络来改进交通预测任务


<details>
  <summary>Details</summary>
Motivation: 现有LLM主要针对序列标记处理设计，在捕捉空间依赖关系方面存在固有局限，特别是在处理图结构空间数据时存在架构不兼容问题

Method: 提出ST-LINK框架，包含空间增强注意力（SE-Attention）和记忆检索前馈网络（MRFFN）。SE-Attention扩展旋转位置编码来整合空间相关性，MRFFN动态检索历史模式来捕捉复杂时间依赖

Result: 在基准数据集上的综合实验表明，ST-LINK超越了传统深度学习和LLM方法，有效捕捉了常规交通模式和突变

Conclusion: 该框架成功解决了LLM在空间建模方面的局限性，为交通预测等时空任务提供了有效的解决方案

Abstract: Traffic forecasting represents a crucial problem within intelligent
transportation systems. In recent research, Large Language Models (LLMs) have
emerged as a promising method, but their intrinsic design, tailored primarily
for sequential token processing, introduces notable challenges in effectively
capturing spatial dependencies. Specifically, the inherent limitations of LLMs
in modeling spatial relationships and their architectural incompatibility with
graph-structured spatial data remain largely unaddressed. To overcome these
limitations, we introduce ST-LINK, a novel framework that enhances the
capability of Large Language Models to capture spatio-temporal dependencies.
Its key components are Spatially-Enhanced Attention (SE-Attention) and the
Memory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary
position embeddings to integrate spatial correlations as direct rotational
transformations within the attention mechanism. This approach maximizes spatial
learning while preserving the LLM's inherent sequential processing structure.
Meanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to
capture complex temporal dependencies and improve the stability of long-term
forecasting. Comprehensive experiments on benchmark datasets demonstrate that
ST-LINK surpasses conventional deep learning and LLM approaches, and
effectively captures both regular traffic patterns and abrupt changes.

</details>


### [123] [TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates](https://arxiv.org/abs/2509.13906)
*Afrin Dange,Sunita Sarawagi*

Main category: cs.LG

Relevance: 65.0

TL;DR: TFMAdapter是一个轻量级适配器，无需微调即可为时间序列基础模型添加协变量信息，在保持计算效率的同时显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列基础模型(TSFMs)在多变量预测中无法有效利用协变量信息，因为这些协变量具有领域特定性且缺乏相关的归纳偏置，限制了模型在实际应用中的准确性。

Method: 提出TFMAdapter两阶段方法：1)使用简单回归模型生成伪预测；2)训练高斯过程回归器，结合伪预测、TSFM预测和协变量来精炼预测结果。该方法在单次模型调用中操作，避免大量TSFM调用。

Result: 在真实世界数据集上的实验表明，TFMAdapter持续优于基础模型和监督基线，相比基础基础模型实现了24-27%的性能提升，且数据和计算开销最小。

Conclusion: 轻量级适配器有潜力弥合通用基础模型与领域特定预测需求之间的差距，为时间序列预测提供高效解决方案。

Abstract: Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art
performance in univariate forecasting on new time series simply by conditioned
on a brief history of past values. Their success demonstrates that large-scale
pretraining across diverse domains can acquire the inductive bias to generalize
from temporal patterns in a brief history. However, most TSFMs are unable to
leverage covariates -- future-available exogenous variables critical for
accurate forecasting in many applications -- due to their domain-specific
nature and the lack of associated inductive bias. We propose TFMAdapter, a
lightweight, instance-level adapter that augments TSFMs with covariate
information without fine-tuning. Instead of retraining, TFMAdapter operates on
the limited history provided during a single model call, learning a
non-parametric cascade that combines covariates with univariate TSFM forecasts.
However, such learning would require univariate forecasts at all steps in the
history, requiring too many calls to the TSFM. To enable training on the full
historical context while limiting TSFM invocations, TFMAdapter uses a two-stage
method: (1) generating pseudo-forecasts with a simple regression model, and (2)
training a Gaussian Process regressor to refine predictions using both pseudo-
and TSFM forecasts alongside covariates. Extensive experiments on real-world
datasets demonstrate that TFMAdapter consistently outperforms both foundation
models and supervised baselines, achieving a 24-27\% improvement over base
foundation models with minimal data and computational overhead. Our results
highlight the potential of lightweight adapters to bridge the gap between
generic foundation models and domain-specific forecasting needs.

</details>


### [124] [APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness](https://arxiv.org/abs/2509.13908)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

Relevance: 65.0

TL;DR: APFEx是一个针对交叉公平性的多目标优化框架，通过自适应优化器、可微公平性指标和理论保证来解决多个敏感属性组合的公平性问题。


<details>
  <summary>Details</summary>
Motivation: 现有公平性方法主要针对单一敏感属性，无法处理交叉属性（如种族+性别+年龄）带来的复合偏见问题，需要专门针对交叉子组的公平性优化方案。

Method: 提出APFEx框架：1）自适应多目标优化器，动态切换Pareto锥投影、梯度加权和探索策略；2）可微交叉公平性指标，支持基于梯度的非平滑子组差异优化；3）提供收敛到Pareto最优解的理论保证。

Result: 在四个真实数据集上的实验表明，APFEx能够显著减少公平性违规，同时保持有竞争力的准确性，优于现有方法。

Conclusion: APFEx填补了公平机器学习中的重要空白，为交叉公平性提供了可扩展、模型无关的解决方案。

Abstract: Ensuring fairness in machine learning models is critical, especially when
biases compound across intersecting protected attributes like race, gender, and
age. While existing methods address fairness for single attributes, they fail
to capture the nuanced, multiplicative biases faced by intersectional
subgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first
framework to explicitly model intersectional fairness as a joint optimization
problem over the Cartesian product of sensitive attributes. APFEx combines
three key innovations- (1) an adaptive multi-objective optimizer that
dynamically switches between Pareto cone projection, gradient weighting, and
exploration strategies to navigate fairness-accuracy trade-offs, (2)
differentiable intersectional fairness metrics enabling gradient-based
optimization of non-smooth subgroup disparities, and (3) theoretical guarantees
of convergence to Pareto-optimal solutions. Experiments on four real-world
datasets demonstrate APFEx's superiority, reducing fairness violations while
maintaining competitive accuracy. Our work bridges a critical gap in fair ML,
providing a scalable, model-agnostic solution for intersectional fairness.

</details>


### [125] [Sequential Data Augmentation for Generative Recommendation](https://arxiv.org/abs/2509.13648)
*Geon Lee,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Kijung Shin,Neil Shah,Liam Collins*

Main category: cs.LG

Relevance: 45.0

TL;DR: 本文提出了GenPAS框架，系统化地研究了生成式推荐系统中数据增强策略对模型性能的影响，通过三个偏差控制的采样步骤统一了现有方法，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐系统的数据增强策略缺乏系统性和原则性理解，不同策略会导致显著的性能差异，需要建立统一框架来指导训练数据构建。

Method: 提出GenPAS框架，将数据增强建模为包含三个偏差控制步骤的随机采样过程：序列采样、目标采样和输入采样，统一现有策略并灵活控制训练分布。

Result: 在基准和工业数据集上的实验表明，GenPAS在准确性、数据效率和参数效率方面均优于现有策略。

Conclusion: GenPAS为生成式推荐系统提供了原则性的训练数据构建指导，系统化的数据增强策略能显著提升模型性能。

Abstract: Generative recommendation plays a crucial role in personalized systems,
predicting users' future interactions from their historical behavior sequences.
A critical yet underexplored factor in training these models is data
augmentation, the process of constructing training data from user interaction
histories. By shaping the training distribution, data augmentation directly and
often substantially affects model generalization and performance. Nevertheless,
in much of the existing work, this process is simplified, applied
inconsistently, or treated as a minor design choice, without a systematic and
principled understanding of its effects.
  Motivated by our empirical finding that different augmentation strategies can
yield large performance disparities, we conduct an in-depth analysis of how
they reshape training distributions and influence alignment with future targets
and generalization to unseen inputs. To systematize this design space, we
propose GenPAS, a generalized and principled framework that models augmentation
as a stochastic sampling process over input-target pairs with three
bias-controlled steps: sequence sampling, target sampling, and input sampling.
This formulation unifies widely used strategies as special cases and enables
flexible control of the resulting training distribution. Our extensive
experiments on benchmark and industrial datasets demonstrate that GenPAS yields
superior accuracy, data efficiency, and parameter efficiency compared to
existing strategies, providing practical guidance for principled training data
construction in generative recommendation.

</details>


### [126] [Online Bayesian Risk-Averse Reinforcement Learning](https://arxiv.org/abs/2509.14077)
*Yuhao Wang,Enlu Zhou*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该论文研究强化学习中的贝叶斯风险规避方法，通过BRMDP处理模型参数不确定性，证明了贝叶斯风险价值函数与真实价值函数之间的渐近正态性差异，并提出了在线RL和CMAB的后验采样算法，获得了次线性遗憾界。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中由于数据不足导致的认知不确定性，通过贝叶斯风险规避方法来处理模型参数的不确定性，提供更稳健的决策策略。

Method: 采用贝叶斯风险马尔可夫决策过程(BRMDP)，推导价值函数的渐近正态性，提出基于后验采样的在线RL和上下文多臂老虎机(CMAB)算法。

Result: 理论证明贝叶斯风险规避方法会悲观低估原始价值函数，差异随风险规避强度增加而增大，随数据增多而减小。算法在在线RL和CMAB中实现了次线性遗憾界。

Conclusion: 贝叶斯风险规避方法能有效处理认知不确定性，数值实验验证了理论性质和算法有效性。

Abstract: In this paper, we study the Bayesian risk-averse formulation in reinforcement
learning (RL). To address the epistemic uncertainty due to a lack of data, we
adopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the
parameter uncertainty of the unknown underlying model. We derive the asymptotic
normality that characterizes the difference between the Bayesian risk value
function and the original value function under the true unknown distribution.
The results indicate that the Bayesian risk-averse approach tends to
pessimistically underestimate the original value function. This discrepancy
increases with stronger risk aversion and decreases as more data become
available. We then utilize this adaptive property in the setting of online RL
as well as online contextual multi-arm bandits (CMAB), a special case of online
RL. We provide two procedures using posterior sampling for both the general RL
problem and the CMAB problem. We establish a sub-linear regret bound, with the
regret defined as the conventional regret for both the RL and CMAB settings.
Additionally, we establish a sub-linear regret bound for the CMAB setting with
the regret defined as the Bayesian risk regret. Finally, we conduct numerical
experiments to demonstrate the effectiveness of the proposed algorithm in
addressing epistemic uncertainty and verifying the theoretical properties.

</details>


### [127] [Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics](https://arxiv.org/abs/2509.13425)
*Julian Evan Chrisnanto,Yulison Herry Chrisnanto,Ferry Faizal*

Main category: cs.LG

Relevance: 35.0

TL;DR: USPIL框架整合物理信息神经网络和守恒定律，统一建模捕食者-猎物系统的时空动力学，在保持物理一致性的同时实现高效计算和机制解释。


<details>
  <summary>Details</summary>
Motivation: 生态系统的复杂多尺度动力学挑战传统建模方法，需要既能捕捉时空振荡模式又遵守守恒原理的新方法。

Method: 使用物理信息神经网络(PINNs)和自动微分技术，通过自适应损失权重平衡数据保真度和物理一致性，统一处理ODE和PDE系统。

Result: 在Lotka-Volterra系统中达到98.9%相关性(损失:0.0219)，捕捉到复杂螺旋波模式(相关性0.94)，计算速度比数值求解器快10-50倍，守恒定律遵守误差在0.5%以内。

Conclusion: USPIL为多尺度生态建模开辟了新途径，建立了物理信息深度学习作为科学严谨的范式，可用于生态预测和保护规划。

Abstract: Ecological systems exhibit complex multi-scale dynamics that challenge
traditional modeling. New methods must capture temporal oscillations and
emergent spatiotemporal patterns while adhering to conservation principles. We
present the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,
a deep learning architecture integrating physics-informed neural networks
(PINNs) and conservation laws to model predator-prey dynamics across
dimensional scales. The framework provides a unified solution for both ordinary
(ODE) and partial (PDE) differential equation systems, describing temporal
cycles and reaction-diffusion patterns within a single neural network
architecture. Our methodology uses automatic differentiation to enforce physics
constraints and adaptive loss weighting to balance data fidelity with physical
consistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%
correlation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures
complex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).
Validation confirms conservation law adherence within 0.5% and shows a 10-50x
computational speedup for inference compared to numerical solvers. USPIL also
enables mechanistic understanding through interpretable physics constraints,
facilitating parameter discovery and sensitivity analysis not possible with
purely data-driven methods. Its ability to transition between dimensional
formulations opens new avenues for multi-scale ecological modeling. These
capabilities make USPIL a transformative tool for ecological forecasting,
conservation planning, and understanding ecosystem resilience, establishing
physics-informed deep learning as a powerful and scientifically rigorous
paradigm.

</details>


### [128] [An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training](https://arxiv.org/abs/2509.13516)
*Tom Almog*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文通过360次实验研究了不同优化器对神经网络训练能耗的影响，发现AdamW和NAdam在能效方面表现最佳，而SGD在复杂数据集上性能更好但碳排放更高


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型日益复杂和计算需求增加，理解训练决策对环境的影响对于可持续AI发展变得至关重要

Method: 在三个基准数据集(MNIST、CIFAR-10、CIFAR-100)上使用8种流行优化器进行360次控制实验，使用CodeCarbon在Apple M1 Pro硬件上精确追踪能耗

Result: 发现训练速度、准确性和环境影响之间存在显著权衡，AdamW和NAdam表现出一致的效率，而SGD在复杂数据集上性能更优但排放更高

Conclusion: 研究结果为从业者在机器学习工作流中平衡性能和可持续性提供了实用见解

Abstract: As machine learning models grow increasingly complex and computationally
demanding, understanding the environmental impact of training decisions becomes
critical for sustainable AI development. This paper presents a comprehensive
empirical study investigating the relationship between optimizer choice and
energy efficiency in neural network training. We conducted 360 controlled
experiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using
eight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,
NAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking
on Apple M1 Pro hardware, we measured training duration, peak memory usage,
carbon dioxide emissions, and final model performance. Our findings reveal
substantial trade-offs between training speed, accuracy, and environmental
impact that vary across datasets and model complexity. We identify AdamW and
NAdam as consistently efficient choices, while SGD demonstrates superior
performance on complex datasets despite higher emissions. These results provide
actionable insights for practitioners seeking to balance performance and
sustainability in machine learning workflows.

</details>


### [129] [AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions](https://arxiv.org/abs/2509.13523)
*Väinö Hatanpää,Eugene Ku,Jason Stock,Murali Emani,Sam Foreman,Chunyong Jung,Sandeep Madireddy,Tung Nguyen,Varuni Sastry,Ray A. O. Sinurat,Sam Wheeler,Huihuo Zheng,Troy Arcomano,Venkatram Vishwanath,Rao Kotamarthi*

Main category: cs.LG

Relevance: 35.0

TL;DR: AERIS是一个13B到80B参数的像素级Swin扩散变换器，用于天气预测，通过SWiPe并行化技术实现高效扩展，在Aurora超级计算机上达到10.21 ExaFLOPS性能，在90天季节尺度预测中优于IFS ENS系统。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散方法在高分辨率天气预测中难以稳定扩展的问题，利用生成式机器学习更好地理解复杂地球系统动力学。

Method: 使用像素级Swin扩散变换器架构，结合SWiPe并行化技术（窗口并行与序列/流水线并行组合），在0.25° ERA5数据集上进行训练。

Result: 在Aurora超级计算机上实现10.21 ExaFLOPS混合精度性能，弱扩展效率95.5%，强扩展效率81.6%，在90天季节尺度预测中稳定且优于IFS ENS系统。

Conclusion: 十亿参数级别的扩散模型在天气和气候预测方面具有巨大潜力，AERIS展示了高分辨率稳定扩展的能力。

Abstract: Generative machine learning offers new opportunities to better understand
complex Earth system dynamics. Recent diffusion-based methods address spectral
biases and improve ensemble calibration in weather forecasting compared to
deterministic methods, yet have so far proven difficult to scale stably at high
resolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin
diffusion transformer to address this gap, and SWiPe, a generalizable technique
that composes window parallelism with sequence and pipeline parallelism to
shard window-based transformers without added communication cost or increased
global batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS
(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \times 1$
patch size on the 0.25{\deg} ERA5 dataset, achieving 95.5% weak scaling
efficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS
and remains stable on seasonal scales to 90 days, highlighting the potential of
billion-parameter diffusion models for weather and climate prediction.

</details>


### [130] [Meta-Learning Linear Models for Molecular Property Prediction](https://arxiv.org/abs/2509.13527)
*Yulia Pimonova,Michael G. Taylor,Alice Allen,Ping Yang,Nicholas Lubbers*

Main category: cs.LG

Relevance: 35.0

TL;DR: LAMeL是一个用于化学性质预测的线性元学习算法，在保持可解释性的同时显著提升预测准确率


<details>
  <summary>Details</summary>
Motivation: 化学领域高质量数据集有限，机器学习方法需要大量数据，同时需要满足可解释AI(XAI)的需求，在预测准确性和人类可理解性之间找到平衡

Method: 提出线性元学习算法LAMeL，通过元学习框架识别相关任务间的共享模型参数，学习共同函数流形作为新任务的更好起点，即使任务间不共享数据

Result: 相比标准岭回归，性能提升1.1-25倍不等，始终优于或匹配传统线性方法，在不同任务上表现稳定

Conclusion: LAMeL是化学性质预测中既准确又可解释的可靠工具，特别适合需要高可解释性的应用场景

Abstract: Chemists in search of structure-property relationships face great challenges
due to limited high quality, concordant datasets. Machine learning (ML) has
significantly advanced predictive capabilities in chemical sciences, but these
modern data-driven approaches have increased the demand for data. In response
to the growing demand for explainable AI (XAI) and to bridge the gap between
predictive accuracy and human comprehensibility, we introduce LAMeL - a Linear
Algorithm for Meta-Learning that preserves interpretability while improving the
prediction accuracy across multiple properties. While most approaches treat
each chemical prediction task in isolation, LAMeL leverages a meta-learning
framework to identify shared model parameters across related tasks, even if
those tasks do not share data, allowing it to learn a common functional
manifold that serves as a more informed starting point for new unseen tasks.
Our method delivers performance improvements ranging from 1.1- to 25-fold over
standard ridge regression, depending on the domain of the dataset. While the
degree of performance enhancement varies across tasks, LAMeL consistently
outperforms or matches traditional linear methods, making it a reliable tool
for chemical property prediction where both accuracy and interpretability are
critical.

</details>


### [131] [DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis](https://arxiv.org/abs/2509.13633)
*Jeremy Oon,Rakhi Manohar Mepparambath,Ling Feng*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出DeepLogit模型，通过序列约束方法结合深度学习与离散选择模型，在保持可解释性的同时提升交通政策分析的预测精度。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在规划和政策领域的应用受限于其黑盒特性，需要一种既能保持可解释性又能提高预测准确性的方法。

Method: 采用序列约束方法：首先估计仅含线性项的CNN模型（等价于线性参数多项式logit模型），然后约束需要可解释的参数值，引入高阶项或Transformer等先进架构。

Result: 在真实世界的新加坡公交智能卡数据上验证，该方法在保持选定参数可解释性的同时，显著提高了模型准确性。

Conclusion: 展示了理论驱动的离散选择模型与数据驱动的AI模型相结合的统一方法潜力，可在保持规划政策应用适用性的同时获得更准确模型。

Abstract: Despite the significant progress of deep learning models in multitude of
applications, their adaption in planning and policy related areas remains
challenging due to the black-box nature of these models. In this work, we
develop a set of DeepLogit models that follow a novel sequentially constrained
approach in estimating deep learning models for transport policy analysis. In
the first step of the proposed approach, we estimate a convolutional neural
network (CNN) model with only linear terms, which is equivalent of a
linear-in-parameter multinomial logit model. We then estimate other deep
learning models by constraining the parameters that need interpretability at
the values obtained in the linear-in-parameter CNN model and including higher
order terms or by introducing advanced deep learning architectures like
Transformers. Our approach can retain the interpretability of the selected
parameters, yet provides significantly improved model accuracy than the
discrete choice model. We demonstrate our approach on a transit route choice
example using real-world transit smart card data from Singapore. This study
shows the potential for a unifying approach, where theory-based discrete choice
model (DCM) and data-driven AI models can leverage each other's strengths in
interpretability and predictive power. With the availability of larger datasets
and more complex constructions, such approach can lead to more accurate models
using discrete choice models while maintaining its applicability in planning
and policy-related areas. Our code is available on
https://github.com/jeremyoon/route-choice/ .

</details>


### [132] [FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning](https://arxiv.org/abs/2509.13895)
*Zhanting Zhou,Jinshan Lai,Fengchun Zhang,Zeqin Wu,Fengli Zhang*

Main category: cs.LG

Relevance: 35.0

TL;DR: FedSSG是一种联邦学习方法，通过历史感知的漂移对齐机制，利用随机采样指导来解决非IID数据和部分参与导致的客户端漂移问题，提高收敛速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中非IID数据和部分客户端参与会导致客户端漂移和不一致的局部最优解，造成收敛不稳定和准确率下降。需要一种方法来对齐客户端漂移而不增加额外通信开销。

Method: FedSSG维护每个客户端的漂移记忆，累积局部模型差异作为历史梯度的轻量级草图。使用基于参与率的平滑门控函数来控制记忆更新和局部对齐项，早期采样噪声大时门控较弱，后期统计稳定时加强门控。

Result: 在CIFAR-10/100数据集上，100/500个客户端，2-15%参与率下，FedSSG比基线方法提升测试准确率约0.9-2.7个百分点，目标准确率收敛速度平均加快约4.5倍。

Conclusion: FedSSG证明采样统计可以转化为有原则的历史感知相位控制，稳定并加速联邦训练。方法只增加O(d)客户端内存和常数时间门控，在近IID或均匀采样下优雅退化为温和正则化器。

Abstract: Non-IID data and partial participation induce client drift and inconsistent
local optima in federated learning, causing unstable convergence and accuracy
loss. We present FedSSG, a stochastic sampling-guided, history-aware drift
alignment method. FedSSG maintains a per-client drift memory that accumulates
local model differences as a lightweight sketch of historical gradients;
crucially, it gates both the memory update and the local alignment term by a
smooth function of the observed/expected participation ratio (a
phase-by-expectation signal derived from the server sampler). This
statistically grounded gate stays weak and smooth when sampling noise dominates
early, then strengthens once participation statistics stabilize, contracting
the local-global gap without extra communication. Across CIFAR-10/100 with
100/500 clients and 2-15 percent participation, FedSSG consistently outperforms
strong drift-aware baselines and accelerates convergence; on our benchmarks it
improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and
about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about
4.5x faster target-accuracy convergence on average. The method adds only O(d)
client memory and a constant-time gate, and degrades gracefully to a mild
regularizer under near-IID or uniform sampling. FedSSG shows that sampling
statistics can be turned into a principled, history-aware phase control to
stabilize and speed up federated training.

</details>


### [133] [Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction](https://arxiv.org/abs/2509.13914)
*Divya Thuremella,Yi Yang,Simon Wanna,Lars Kunze,Daniele De Martini*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文提出了一种简单的置信度加权平均集成方法，无需重新训练即可结合多个先进轨迹预测模型的优势，在NuScenes和Argoverse数据集上性能提升10%


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶领域中如何在不进行昂贵重新训练的情况下，结合多个大型先进轨迹预测模型优势的挑战

Method: 使用置信度加权平均方法对多个最先进的深度学习轨迹预测模型进行集成，无需重新训练或微调

Result: 在NuScenes和Argoverse数据集上，该方法比最佳单一模型性能提升10%，特别是在长尾指标上表现优异，且改进在整个数据分布上保持一致

Conclusion: 简单的置信度加权平均集成方法能够有效提升轨迹预测性能，证明了集成学习在自动驾驶预测任务中的价值

Abstract: This work explores the application of ensemble modeling to the
multidimensional regression problem of trajectory prediction for vehicles in
urban environments. As newer and bigger state-of-the-art prediction models for
autonomous driving continue to emerge, an important open challenge is the
problem of how to combine the strengths of these big models without the need
for costly re-training. We show how, perhaps surprisingly, combining
state-of-the-art deep learning models out-of-the-box (without retraining or
fine-tuning) with a simple confidence-weighted average method can enhance the
overall prediction. Indeed, while combining trajectory prediction models is not
straightforward, this simple approach enhances performance by 10% over the best
prediction model, especially in the long-tailed metrics. We show that this
performance improvement holds on both the NuScenes and Argoverse datasets, and
that these improvements are made across the dataset distribution. The code for
our work is open source.

</details>


### [134] [ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning](https://arxiv.org/abs/2509.13739)
*Zihou Wu,Yuecheng Li,Tianchi Liao,Jian Lou,Chuan Chen*

Main category: cs.LG

Relevance: 30.0

TL;DR: ParaAegis是一个联邦学习并行保护框架，通过模型分区策略在DP和HE之间实现隐私-效用-效率的灵活权衡控制


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中现有保护机制（如差分隐私和同态加密）在模型效用和计算效率之间存在的刚性权衡问题，提供更灵活实用的保护方案

Method: 提出并行保护框架，通过策略性模型分区：对低范数部分应用轻量级DP，对剩余部分使用HE保护，并通过分布式投票机制确保分区共识

Result: 理论分析确认了在相同隐私保护下效率与效用的可调节性，实验结果表明通过调整超参数可以灵活优先考虑模型精度或训练时间

Conclusion: ParaAegis为联邦学习提供了灵活的隐私-效用-效率平衡控制，解决了现有保护机制的刚性权衡限制

Abstract: Federated learning (FL) faces a critical dilemma: existing protection
mechanisms like differential privacy (DP) and homomorphic encryption (HE)
enforce a rigid trade-off, forcing a choice between model utility and
computational efficiency. This lack of flexibility hinders the practical
implementation. To address this, we introduce ParaAegis, a parallel protection
framework designed to give practitioners flexible control over the
privacy-utility-efficiency balance. Our core innovation is a strategic model
partitioning scheme. By applying lightweight DP to the less critical, low norm
portion of the model while protecting the remainder with HE, we create a
tunable system. A distributed voting mechanism ensures consensus on this
partitioning. Theoretical analysis confirms the adjustments between efficiency
and utility with the same privacy. Crucially, the experimental results
demonstrate that by adjusting the hyperparameters, our method enables flexible
prioritization between model accuracy and training time.

</details>


### [135] [Masked Diffusion Models as Energy Minimization](https://arxiv.org/abs/2509.13866)
*Sitong Chen,Shen Nie,Jiacheng Sun,Zijin Feng,Zhenguo Li,Ji-Rong Wen,Chongxuan Li*

Main category: cs.LG

Relevance: 30.0

TL;DR: 该论文提出了一个理论框架，将掩码扩散模型解释为离散最优传输中的能量最小化问题，证明了三种能量公式的数学等价性，并通过Beta分布参数化调度实现了高效的后训练调优。


<details>
  <summary>Details</summary>
Motivation: 统一掩码扩散模型的理论基础，揭示其与能量最小化问题的数学联系，并为实际采样改进提供理论指导。

Method: 建立理论框架证明三种能量公式的等价性，使用Beta分布参数化插值调度，将调度设计空间简化为2D搜索，实现无需模型修改的后训练调优。

Result: 在合成和真实基准测试中，能量启发的调度方案在低步采样设置中优于手工设计的基线方法。

Conclusion: 该工作不仅澄清了MDMs的理论基础，还提供了实用的采样改进方法，通过理论指导的调度设计提升了模型性能。

Abstract: We present a systematic theoretical framework that interprets masked
diffusion models (MDMs) as solutions to energy minimization problems in
discrete optimal transport. Specifically, we prove that three distinct energy
formulations--kinetic, conditional kinetic, and geodesic energy--are
mathematically equivalent under the structure of MDMs, and that MDMs minimize
all three when the mask schedule satisfies a closed-form optimality condition.
This unification not only clarifies the theoretical foundations of MDMs, but
also motivates practical improvements in sampling. By parameterizing
interpolation schedules via Beta distributions, we reduce the schedule design
space to a tractable 2D search, enabling efficient post-training tuning without
model modification. Experiments on synthetic and real-world benchmarks
demonstrate that our energy-inspired schedules outperform hand-crafted
baselines, particularly in low-step sampling settings.

</details>


### [136] [Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection](https://arxiv.org/abs/2509.13974)
*Amirhossein Shahbazinia,Jonathan Dan,Jose A. Miranda,Giovanni Ansaloni,David Atienza*

Main category: cs.LG

Relevance: 30.0

TL;DR: EpiSMART是一个用于癫痫发作检测的持续学习框架，通过大小受限的回放缓冲区和智能样本选择策略，实现患者特异性EEG信号的自适应学习，避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 癫痫诊断依赖专家分析EEG信号，耗时且需要专业知识。现有深度学习模型难以适应患者EEG特征的时变特性，存在灾难性遗忘问题。

Method: 提出EpiSMART框架，使用大小受限的回放缓冲区和基于信息熵的样本选择策略，选择性保留高熵和预测为发作的样本，以增量方式适应患者特异性EEG信号。

Result: 在CHB-MIT数据集上验证，EpiSMART相比无更新的基线模型F1分数提升21%，平均每天仅需6.46分钟标记数据和6.28次更新，适合可穿戴设备实时部署。

Conclusion: EpiSMART能够在资源受限条件下实现鲁棒的个性化癫痫发作检测，有效整合新数据而不损害已有知识。

Abstract: Objective: Epilepsy, a prevalent neurological disease, demands careful
diagnosis and continuous care. Seizure detection remains challenging, as
current clinical practice relies on expert analysis of electroencephalography,
which is a time-consuming process and requires specialized knowledge.
Addressing this challenge, this paper explores automated epileptic seizure
detection using deep learning, focusing on personalized continual learning
models that adapt to each patient's unique electroencephalography signal
features, which evolve over time. Methods: In this context, our approach
addresses the challenge of integrating new data into existing models without
catastrophic forgetting, a common issue in static deep learning models. We
propose EpiSMART, a continual learning framework for seizure detection that
uses a size-constrained replay buffer and an informed sample selection strategy
to incrementally adapt to patient-specific electroencephalography signals. By
selectively retaining high-entropy and seizure-predicted samples, our method
preserves critical past information while maintaining high performance with
minimal memory and computational requirements. Results: Validation on the
CHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score
over a trained baseline without updates in all other patients. On average,
EpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,
making it suitable for real-time deployment in wearable systems.
Conclusion:EpiSMART enables robust and personalized seizure detection under
realistic and resource-constrained conditions by effectively integrating new
data into existing models without degrading past knowledge. Significance: This
framework advances automated seizure detection by providing a continual
learning approach that supports patient-specific adaptation and practical
deployment in wearable healthcare systems.

</details>


### [137] [Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework](https://arxiv.org/abs/2509.13520)
*Varun Kumar,Jing Bi,Cyril Ngo Ngoc,Victor Oancea,George Em Karniadakis*

Main category: cs.LG

Relevance: 25.0

TL;DR: 本文提出了一个混合DeepONet-Transolver框架，用于解决PET瓶屈曲分析中的PDE问题，能够跨几何域泛化解并预测节点位移场和时间相关的反作用力。


<details>
  <summary>Details</summary>
Motivation: 现有神经代理和算子网络方法在跨非参数几何域泛化解PDE问题上存在局限，特别是在包装设计中的PET瓶屈曲分析这类计算昂贵的有限元分析问题。

Method: 采用混合DeepONet-Transolver框架，同时预测节点位移场和顶部压缩过程中的时间相关反作用力演化。使用Abaqus非线性FEA模拟生成训练数据。

Result: 在四参数瓶家族上，位移场的平均相对L²误差为2.5-13%，时间相关反作用力误差约2.4%。点误差分析显示绝对位移误差在10⁻⁴-10⁻³量级，最大差异局限于局部几何区域。

Conclusion: 该框架作为可扩展且计算高效的代理模型具有潜力，特别适用于计算力学中的多任务预测和需要快速设计评估的应用。

Abstract: Neural surrogates and operator networks for solving partial differential
equation (PDE) problems have attracted significant research interest in recent
years. However, most existing approaches are limited in their ability to
generalize solutions across varying non-parametric geometric domains. In this
work, we address this challenge in the context of Polyethylene Terephthalate
(PET) bottle buckling analysis, a representative packaging design problem
conventionally solved using computationally expensive finite element analysis
(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously
predicts nodal displacement fields and the time evolution of reaction forces
during top load compression. Our methodology is evaluated on two families of
bottle geometries parameterized by two and four design variables. Training data
is generated using nonlinear FEA simulations in Abaqus for 254 unique designs
per family. The proposed framework achieves mean relative $L^{2}$ errors of
2.5-13% for displacement fields and approximately 2.4% for time-dependent
reaction forces for the four-parameter bottle family. Point-wise error analyses
further show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,
with the largest discrepancies confined to localized geometric regions.
Importantly, the model accurately captures key physical phenomena, such as
buckling behavior, across diverse bottle geometries. These results highlight
the potential of our framework as a scalable and computationally efficient
surrogate, particularly for multi-task predictions in computational mechanics
and applications requiring rapid design evaluation.

</details>


### [138] [Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs](https://arxiv.org/abs/2509.13634)
*Md Bokhtiar Al Zami,Md Raihan Uddin,Dinh C. Nguyen*

Main category: cs.LG

Relevance: 25.0

TL;DR: 本文提出了一种结合数字孪生和零知识联邦学习的新型框架，用于优化无人机辅助联邦学习系统的能源效率、通信效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决无人机辅助联邦学习系统中存在的高能耗、通信效率低下和安全漏洞等问题，确保系统的可靠运行。

Method: 集成数字孪生技术实现实时系统监控和预测性维护，使用零知识证明增强安全性，采用动态分配策略优化无人机飞行路径、传输功率和处理速率，运用块坐标下降和凸优化技术。

Result: 相比传统联邦学习方法，系统能耗降低高达29.6%，学习性能、安全性和可扩展性均得到显著提升。

Conclusion: 该框架为下一代无人机智能网络提供了一个有前景的解决方案。

Abstract: Federated learning (FL) has gained popularity as a privacy-preserving method
of training machine learning models on decentralized networks. However to
ensure reliable operation of UAV-assisted FL systems, issues like as excessive
energy consumption, communication inefficiencies, and security vulnerabilities
must be solved. This paper proposes an innovative framework that integrates
Digital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to
tackle these challenges. UAVs act as mobile base stations, allowing scattered
devices to train FL models locally and upload model updates for aggregation. By
incorporating DT technology, our approach enables real-time system monitoring
and predictive maintenance, improving UAV network efficiency. Additionally,
Zero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification
without exposing sensitive data. To optimize energy efficiency and resource
management, we introduce a dynamic allocation strategy that adjusts UAV flight
paths, transmission power, and processing rates based on network conditions.
Using block coordinate descent and convex optimization techniques, our method
significantly reduces system energy consumption by up to 29.6% compared to
conventional FL approaches. Simulation results demonstrate improved learning
performance, security, and scalability, positioning this framework as a
promising solution for next-generation UAV-based intelligent networks.

</details>


### [139] [Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images](https://arxiv.org/abs/2509.13636)
*Yasin Hasanpoor,Bahram Tarvirdizadeh,Khalil Alipour,Mohammad Ghamari*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该研究提出了一种将多模态生理信号转换为2D图像矩阵的新方法，使用CNN进行压力检测，通过信号融合和图像表示提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法单独处理多模态生理信号或依赖固定编码，无法有效捕捉信号间的时空依赖关系。研究旨在通过图像化转换提升信号处理的效率和可解释性。

Method: 将PPG、GSR和ACC三种生理信号融合为结构化2D图像矩阵，采用多阶段训练管道系统重组信号格式，利用CNN捕捉时序和跨信号依赖关系。

Result: 该方法显著提升了压力检测的分类性能，同时提高了模型的泛化能力和鲁棒性，可作为有效的数据增强手段。

Conclusion: 提出的图像化转换方法不仅适用于压力检测，还可广泛应用于任何涉及多模态生理信号的领域，为可穿戴技术的实时健康监测提供了新途径。

Abstract: This study introduces a novel method that transforms multimodal physiological
signalsphotoplethysmography (PPG), galvanic skin response (GSR), and
acceleration (ACC) into 2D image matrices to enhance stress detection using
convolutional neural networks (CNNs). Unlike traditional approaches that
process these signals separately or rely on fixed encodings, our technique
fuses them into structured image representations that enable CNNs to capture
temporal and cross signal dependencies more effectively. This image based
transformation not only improves interpretability but also serves as a robust
form of data augmentation. To further enhance generalization and model
robustness, we systematically reorganize the fused signals into multiple
formats, combining them in a multi stage training pipeline. This approach
significantly boosts classification performance. While demonstrated here in the
context of stress detection, the proposed method is broadly applicable to any
domain involving multimodal physiological signals, paving the way for more
accurate, personalized, and real time health monitoring through wearable
technologies.

</details>


### [140] [A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks](https://arxiv.org/abs/2509.13717)
*Yifan Yu,Cheuk Hin Ho,Yangshuai Wang*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该论文提出了一个基于共形预测的分布无关不确定性量化框架，用于物理信息神经网络(PINNs)，为PINNs提供具有严格统计保证的空间自适应不确定性区间。


<details>
  <summary>Details</summary>
Motivation: 现有PINNs的不确定性量化方法缺乏严格的统计保证，需要一种能够提供有限样本覆盖保证的分布无关UQ框架。

Method: 引入分布无关的共形预测框架，通过在校准集上构建非共形性分数来校准预测区间，并进一步提出局部共形分位数估计来处理空间异方差性。

Result: 在典型PDE系统上的系统评估表明，该框架实现了可靠的校准和局部自适应不确定性区间，在多个不确定性指标上一致优于启发式UQ方法。

Conclusion: 该工作通过将PINNs与分布无关UQ相结合，不仅提高了校准和可靠性，还为复杂PDE系统的不确定性感知建模开辟了新途径。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework
for solving PDEs, yet existing uncertainty quantification (UQ) approaches for
PINNs generally lack rigorous statistical guarantees. In this work, we bridge
this gap by introducing a distribution-free conformal prediction (CP) framework
for UQ in PINNs. This framework calibrates prediction intervals by constructing
nonconformity scores on a calibration set, thereby yielding distribution-free
uncertainty estimates with rigorous finite-sample coverage guarantees for
PINNs. To handle spatial heteroskedasticity, we further introduce local
conformal quantile estimation, enabling spatially adaptive uncertainty bands
while preserving theoretical guarantee. Through systematic evaluations on
typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz
equations) and comprehensive testing across multiple uncertainty metrics, our
results demonstrate that the proposed framework achieves reliable calibration
and locally adaptive uncertainty intervals, consistently outperforming
heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work
introduces a general framework that not only enhances calibration and
reliability, but also opens new avenues for uncertainty-aware modeling of
complex PDE systems.

</details>


### [141] [WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data](https://arxiv.org/abs/2509.13725)
*Md Sabbir Ahmed,Noah French,Mark Rucker,Zhiyuan Wang,Taylor Myers-Brower,Kaitlyn Petz,Mehdi Boukhechba,Bethany A. Teachman,Laura E. Barnes*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该研究开发了一个基于智能手表的系统，通过心率数据和生态瞬时评估来预测社交焦虑患者的瞬时焦虑状态，在内部和外部数据集上分别达到60.4%和59.1%的平衡准确率。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑是一种常见心理健康问题，但目前缺乏对日常焦虑波动的实时监测和预测方法，这对于设计实时个性化干预措施至关重要。

Method: 使用定制智能手表系统收集91名社交焦虑大学生的心率数据，结合每日7次生态瞬时评估。基于10,000多天外部心率数据预训练基础模型，迁移学习到目标数据集，并结合特质水平测量构建元学习器。

Result: 在内部数据集上达到60.4%的平衡准确率，在外部TILES-18数据集上达到59.1%的平衡准确率，比先前工作提升至少7%。

Conclusion: 该方法能够有效预测社交焦虑患者的瞬时焦虑状态，为实时个性化干预提供了技术基础，具有良好的泛化能力。

Abstract: Social anxiety is a common mental health condition linked to significant
challenges in academic, social, and occupational functioning. A core feature is
elevated momentary (state) anxiety in social situations, yet little prior work
has measured or predicted fluctuations in this anxiety throughout the day.
Capturing these intra-day dynamics is critical for designing real-time,
personalized interventions such as Just-In-Time Adaptive Interventions
(JITAIs). To address this gap, we conducted a study with socially anxious
college students (N=91; 72 after exclusions) using our custom smartwatch-based
system over an average of 9.03 days (SD = 2.95). Participants received seven
ecological momentary assessments (EMAs) per day to report state anxiety. We
developed a base model on over 10,000 days of external heart rate data,
transferred its representations to our dataset, and fine-tuned it to generate
probabilistic predictions. These were combined with trait-level measures in a
meta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety
detection in our dataset. To evaluate generalizability, we applied the training
approach to a separate hold-out set from the TILES-18 dataset-the same dataset
used for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%
balanced accuracy, outperforming prior work by at least 7%.

</details>


### [142] [Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment](https://arxiv.org/abs/2509.13818)
*Zheng-an Wang,Yanbo J. Wang,Jiachi Zhang,Qi Xu,Yilun Zhao,Jintao Li,Yipeng Zhang,Bo Yang,Xinkai Gao,Xiaofeng Cao,Kai Xu,Pengpeng Hao,Xuan Yang,Heng Fan*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该论文提出了一种混合量子-经典工作流，用于少样本信用风险评估，在量子神经网络上实现了优于经典基准的性能。


<details>
  <summary>Details</summary>
Motivation: 解决包容性金融中数据稀缺和失衡导致的信用风险评估难题，探索量子机器学习在金融领域的应用潜力。

Method: 采用经典机器学习模型进行特征工程和降维，然后使用参数位移规则训练的量子神经网络作为核心分类器，在Quafu量子云平台上进行实验。

Result: 在279个样本的真实信用数据集上，量子神经网络在模拟中获得0.852的平均AUC，硬件实验中获得0.88的AUC，超越了经典基准模型。

Conclusion: 为NISQ时代数据受限的金融场景提供了量子计算应用的实用蓝图，证明了量子机器学习在高风险金融应用中的潜力。

Abstract: Quantum Machine Learning (QML) offers a new paradigm for addressing complex
financial problems intractable for classical methods. This work specifically
tackles the challenge of few-shot credit risk assessment, a critical issue in
inclusive finance where data scarcity and imbalance limit the effectiveness of
conventional models. To address this, we design and implement a novel hybrid
quantum-classical workflow. The methodology first employs an ensemble of
classical machine learning models (Logistic Regression, Random Forest, XGBoost)
for intelligent feature engineering and dimensionality reduction. Subsequently,
a Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as
the core classifier. This framework was evaluated through numerical simulations
and deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting
processor. On a real-world credit dataset of 279 samples, our QNN achieved a
robust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive
AUC of 0.88 in the hardware experiment. This performance surpasses a suite of
classical benchmarks, with a particularly strong result on the recall metric.
This study provides a pragmatic blueprint for applying quantum computing to
data-constrained financial scenarios in the NISQ era and offers valuable
empirical evidence supporting its potential in high-stakes applications like
inclusive finance.

</details>


### [143] [An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction](https://arxiv.org/abs/2509.13841)
*Qingqi Zhao,Heng Xiao*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出了一种端到端可微分混合框架，将图神经网络嵌入孔隙网络模型中，用于多孔介质渗透率预测，避免了传统方法的理想化几何假设，同时保持了物理基础的流动计算。


<details>
  <summary>Details</summary>
Motivation: 传统纯数据驱动模型缺乏跨尺度泛化能力且不包含明确物理约束，而孔隙网络模型虽然基于物理但依赖于理想化几何假设来估计孔隙尺度水力传导度，限制了在复杂结构中的准确性。

Method: 使用图神经网络替代孔隙网络模型中的解析公式进行传导度计算，通过端到端训练（结合自动微分和离散伴随方法）仅使用单一标量渗透率作为训练目标，无需标记的传导度数据。

Result: 该模型实现了高精度和良好的跨尺度泛化能力，优于纯数据驱动和传统孔隙网络模型方法，梯度敏感性分析显示出物理一致的特征影响。

Conclusion: 该方法为复杂多孔介质中的渗透率预测提供了一个可扩展且物理信息化的框架，减少了模型不确定性并提高了准确性。

Abstract: Accurate prediction of permeability in porous media is essential for modeling
subsurface flow. While pure data-driven models offer computational efficiency,
they often lack generalization across scales and do not incorporate explicit
physical constraints. Pore network models (PNMs), on the other hand, are
physics-based and efficient but rely on idealized geometric assumptions to
estimate pore-scale hydraulic conductance, limiting their accuracy in complex
structures. To overcome these limitations, we present an end-to-end
differentiable hybrid framework that embeds a graph neural network (GNN) into a
PNM. In this framework, the analytical formulas used for conductance
calculations are replaced by GNN-based predictions derived from pore and throat
features. The predicted conductances are then passed to the PNM solver for
permeability computation. In this way, the model avoids the idealized geometric
assumptions of PNM while preserving the physics-based flow calculations. The
GNN is trained without requiring labeled conductance data, which can number in
the thousands per pore network; instead, it learns conductance values by using
a single scalar permeability as the training target. This is made possible by
backpropagating gradients through both the GNN (via automatic differentiation)
and the PNM solver (via a discrete adjoint method), enabling fully coupled,
end-to-end training. The resulting model achieves high accuracy and generalizes
well across different scales, outperforming both pure data-driven and
traditional PNM approaches. Gradient-based sensitivity analysis further reveals
physically consistent feature influences, enhancing model interpretability.
This approach offers a scalable and physically informed framework for
permeability prediction in complex porous media, reducing model uncertainty and
improving accuracy.

</details>


### [144] [Graph-Regularized Learning of Gaussian Mixture Models](https://arxiv.org/abs/2509.13855)
*Shamsiiat Abdurakhmanova,Alex Jung*

Main category: cs.LG

Relevance: 25.0

TL;DR: 分布式图正则化高斯混合模型学习，利用相似性图指导节点间参数共享，在异构小样本场景下优于集中式和本地训练方法


<details>
  <summary>Details</summary>
Motivation: 解决分布式环境中数据异构且样本有限的情况下，如何有效学习高斯混合模型而不需要传输原始数据的问题

Method: 基于图正则化的高斯混合模型学习方法，利用节点间的相似性图来指导参数共享，实现灵活的邻居参数聚合

Result: 在异构低样本情况下，该方法性能优于集中式训练和本地训练的GMM模型

Conclusion: 图正则化方法为分布式异构数据学习提供了有效的参数共享机制，避免了原始数据传输

Abstract: We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in
distributed settings with heterogeneous and limited local data. The method
exploits a provided similarity graph to guide parameter sharing among nodes,
avoiding the transfer of raw data. The resulting model allows for flexible
aggregation of neighbors' parameters and outperforms both centralized and
locally trained GMMs in heterogeneous, low-sample regimes.

</details>


### [145] [Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning](https://arxiv.org/abs/2509.13933)
*Qiyue Li,Yingxin Liu,Hang Qi,Jieping Luo,Zhizhang Liu,Jingjin Wu*

Main category: cs.LG

Relevance: 25.0

TL;DR: WILF-Q：一种基于强化学习的无线联邦学习客户端选择方法，通过Q学习近似Whittle指数来优化学习效率


<details>
  <summary>Details</summary>
Motivation: 解决无线联邦学习中客户端选择问题，目标是减少达到特定学习精度所需的总时间。由于服务器无法观察客户端的动态状态变化，需要一种无需显式状态转移知识的自适应方法

Method: 将客户端选择建模为多臂老虎机问题，提出WILF-Q方法：使用Q学习自适应学习和更新每个客户端的近似Whittle指数，然后选择指数最高的客户端

Result: 实验结果表明WILF-Q在学习效率方面显著优于现有基线策略，为无线FL中的客户端选择提供了鲁棒高效的解决方案

Conclusion: WILF-Q不需要客户端状态转移或数据分布的显式知识，适合在实际FL设置中部署，是解决无线联邦学习客户端选择问题的有效方法

Abstract: We consider the client selection problem in wireless Federated Learning (FL),
with the objective of reducing the total required time to achieve a certain
level of learning accuracy. Since the server cannot observe the clients'
dynamic states that can change their computation and communication efficiency,
we formulate client selection as a restless multi-armed bandit problem. We
propose a scalable and efficient approach called the Whittle Index Learning in
Federated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and
update an approximated Whittle index associated with each client, and then
selects the clients with the highest indices. Compared to existing approaches,
WILF-Q does not require explicit knowledge of client state transitions or data
distributions, making it well-suited for deployment in practical FL settings.
Experiment results demonstrate that WILF-Q significantly outperforms existing
baseline policies in terms of learning efficiency, providing a robust and
efficient approach to client selection in wireless FL.

</details>


### [146] [Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations](https://arxiv.org/abs/2509.14000)
*Ivana Kesić,Aljaž Blatnik,Carolina Fortuna,Blaž Bertalanič*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该论文提出了一种基于动态图回归的GNSS干扰抑制方法，使用异构图卷积LSTM网络实时预测并修正接收器的水平偏差，在多种干扰场景下显著优于传统时间序列基线方法。


<details>
  <summary>Details</summary>
Motivation: 全球导航卫星系统(GNSS)面临日益严重的故意干扰问题，在需要精确定位和计时时导致系统可用性下降。传统方法难以有效处理这种动态干扰环境。

Method: 将干扰抑制问题重构为动态图回归任务，构建接收器为中心的异构星形图（接收器为中心节点，卫星为叶节点），使用单层异构图卷积LSTM(HeteroGCLSTM)聚合空间上下文和时间动态信息，实时输出2D偏差向量进行在线修正。

Result: 在两种不同接收器和三种干扰模式下（连续波、三音调、宽带FM），该模型在所有功率水平（-45至-70 dBm）下均获得最低平均绝对误差(MAE)，在-45 dBm时达到3.64-7.74 cm精度，在-60至-70 dBm时提升至1.65-2.08 cm。数据效率研究显示仅用10%训练数据仍优于基线方法。

Conclusion: 该方法通过图神经网络有效处理GNSS干扰问题，在精度和数据效率方面均显著优于传统时间序列方法，为实时干扰抑制提供了有效解决方案。

Abstract: Global Navigation Satellite Systems (GNSS) are increasingly disrupted by
intentional jamming, degrading availability precisely when positioning and
timing must remain operational. We address this by reframing jamming mitigation
as dynamic graph regression and introducing a receiver-centric deep temporal
graph network that predicts, and thus corrects, the receivers horizontal
deviation in real time. At each 1 Hz epoch, the satellite receiver environment
is represented as a heterogeneous star graph (receiver center, tracked
satellites as leaves) with time varying attributes (e.g., SNR, azimuth,
elevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM
(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a
short history to output the 2D deviation vector applied for on the fly
correction.
  We evaluate on datasets from two distinct receivers under three jammer
profiles, continuous wave (cw), triple tone (cw3), and wideband FM, each
exercised at six power levels between -45 and -70 dBm, with 50 repetitions per
scenario (prejam/jam/recovery). Against strong multivariate time series
baselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains
the lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm
(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and
4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode
datasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),
outperforming Seq2Point, MLP, and CNN. A split study shows superior data
efficiency: with only 10\% training data our approach remains well ahead of
baselines (20 cm vs. 36-42 cm).

</details>


### [147] [Differentially private federated learning for localized control of infectious disease dynamics](https://arxiv.org/abs/2509.14024)
*Raouf Kerkouche,Henrik Zunker,Mario Fritz,Martin J. Kühn*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该研究提出了一种基于联邦学习和差分隐私的隐私保护流行病预测方法，在德国县级层面进行COVID-19病例预测，在保持数据隐私的同时实现了接近非隐私保护模型的预测性能。


<details>
  <summary>Details</summary>
Motivation: 在流行病爆发时需要快速反应，但本地化机器学习模型训练面临数据不足问题，而集中化数据又存在隐私敏感性挑战。需要一种既能保护隐私又能进行有效预测的方法。

Method: 采用联邦学习框架，将各县/社区作为客户端，使用多层感知机在滑动窗口上进行病例预测。通过客户端级差分隐私，仅交换经过范数裁剪的更新，并在服务器聚合时添加DP噪声。

Result: 在适度隐私保护水平下，DP模型接近非DP模型性能：2020年11月R²=0.94（vs. 0.95），MAPE=26%；2022年3月R²=0.88（vs. 0.93），MAPE=21%。严格隐私保护会导致预测不稳定。

Conclusion: 客户端级DP-FL能够提供有用的县级预测并保持强隐私保证，可行的隐私预算取决于流行病阶段，支持卫生当局进行隐私合规的本地预测协作。

Abstract: In times of epidemics, swift reaction is necessary to mitigate epidemic
spreading. For this reaction, localized approaches have several advantages,
limiting necessary resources and reducing the impact of interventions on a
larger scale. However, training a separate machine learning (ML) model on a
local scale is often not feasible due to limited available data. Centralizing
the data is also challenging because of its high sensitivity and privacy
constraints. In this study, we consider a localized strategy based on the
German counties and communities managed by the related local health authorities
(LHA). For the preservation of privacy to not oppose the availability of
detailed situational data, we propose a privacy-preserving forecasting method
that can assist public health experts and decision makers. ML methods with
federated learning (FL) train a shared model without centralizing raw data.
Considering the counties, communities or LHAs as clients and finding a balance
between utility and privacy, we study a FL framework with client-level
differential privacy (DP). We train a shared multilayer perceptron on sliding
windows of recent case counts to forecast the number of cases, while clients
exchange only norm-clipped updates and the server aggregated updates with DP
noise. We evaluate the approach on COVID-19 data on county-level during two
phases. As expected, very strict privacy yields unstable, unusable forecasts.
At a moderately strong level, the DP model closely approaches the non-DP model:
$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in
November 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,
client-level DP-FL can deliver useful county-level predictions with strong
privacy guarantees, and viable privacy budgets depend on epidemic phase,
allowing privacy-compliant collaboration among health authorities for local
forecasting.

</details>


### [148] [Deep Learning-Driven Peptide Classification in Biological Nanopores](https://arxiv.org/abs/2509.14029)
*Samuel Tovey,Julian Hoßbach,Sandro Kuppel,Tobias Ensslen,Jan C. Behrends,Christian Holm*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该论文提出了一种使用小波变换将蛋白质纳米孔电流信号转换为尺度图图像，然后利用机器学习算法进行蛋白质分类的新方法，在42种肽上达到了81%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 开发能够在临床环境中实时分类蛋白质的设备，实现廉价快速的疾病诊断。纳米孔设备通过测量蛋白质进入纳米孔时产生的电流信号来工作，但现有方法的信号复杂性限制了准确性。

Method: 将电流信号通过小波变换转换为尺度图图像，捕捉振幅、频率和时间信息，使用机器学习算法进行分类。还展示了模型迁移技术以便在实际硬件中部署。

Result: 在42种肽上实现了约81%的分类准确率，创下了该领域的新最先进水平。

Conclusion: 该方法为实时疾病诊断提供了一种新途径，朝着实际临床应用迈出了重要一步。

Abstract: A device capable of performing real time classification of proteins in a
clinical setting would allow for inexpensive and rapid disease diagnosis. One
such candidate for this technology are nanopore devices. These devices work by
measuring a current signal that arises when a protein or peptide enters a
nanometer-length-scale pore. Should this current be uniquely related to the
structure of the peptide and its interactions with the pore, the signals can be
used to perform identification. While such a method would allow for real time
identification of peptides and proteins in a clinical setting, to date, the
complexities of these signals limit their accuracy. In this work, we tackle the
issue of classification by converting the current signals into scaleogram
images via wavelet transforms, capturing amplitude, frequency, and time
information in a modality well-suited to machine learning algorithms. When
tested on 42 peptides, our method achieved a classification accuracy of
~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward
practical peptide/protein diagnostics at the point of care. In addition, we
demonstrate model transfer techniques that will be critical when deploying
these models into real hardware, paving the way to a new method for real-time
disease diagnosis.

</details>


### [149] [Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques](https://arxiv.org/abs/2509.14078)
*Robiul Islam,Dmitry I. Ignatov,Karl Kaberg,Roman Nabatchikov*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该研究比较了不同优化器和神经网络架构在EEG频段分类任务中的性能，发现Adagrad和RMSprop优化器表现最佳，CNN在空间特征提取方面表现出色，SHAP分析揭示了EEG频段对分类准确性的贡献。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索不同优化器和神经网络架构在脑电图(EEG)频段分类任务中的性能差异，以提高神经影像分类任务的准确性和可解释性。

Method: 使用三种神经网络架构（深度密集网络、浅层三层网络和CNN），在TensorFlow和PyTorch框架下比较多种优化器（Adagrad、RMSprop、Adadelta、SGD、FTRL）在不同EEG频段的性能，并采用SHAP进行特征重要性分析。

Result: Adagrad和RMSprop优化器在不同频段表现稳定，Adagrad在beta频段表现最佳，RMSprop在gamma频段最优。CNN模型准确率第二高，擅长捕捉EEG空间特征。深度网络在学习复杂模式方面有竞争力，浅层网络计算效率高但准确率较低。

Conclusion: 优化器选择、模型架构和EEG频段分析对提高分类器性能至关重要，SHAP分析有助于理解EEG频段对模型准确性的贡献机制。

Abstract: This study investigates classifier performance across EEG frequency bands
using various optimizers and evaluates efficient class prediction for the left
and right hemispheres. Three neural network architectures - a deep dense
network, a shallow three-layer network, and a convolutional neural network
(CNN) - are implemented and compared using the TensorFlow and PyTorch
frameworks. Results indicate that the Adagrad and RMSprop optimizers
consistently perform well across different frequency bands, with Adadelta
exhibiting robust performance in cross-model evaluations. Specifically, Adagrad
excels in the beta band, while RMSprop achieves superior performance in the
gamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among
the models, the CNN demonstrates the second highest accuracy, particularly in
capturing spatial features of EEG data. The deep dense network shows
competitive performance in learning complex patterns, whereas the shallow
three-layer network, sometimes being less accurate, provides computational
efficiency. SHAP (Shapley Additive Explanations) plots are employed to identify
efficient class prediction, revealing nuanced contributions of EEG frequency
bands to model accuracy. Overall, the study highlights the importance of
optimizer selection, model architecture, and EEG frequency band analysis in
enhancing classifier performance and understanding feature importance in
neuroimaging-based classification tasks.

</details>


### [150] [Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning](https://arxiv.org/abs/2509.13763)
*Zongxin Shen,Yanyong Huang,Bin Wang,Jinyuan Chang,Shiyu Liu,Tianrui Li*

Main category: cs.LG

Relevance: 20.0

TL;DR: 本文从因果视角分析多视图无监督特征选择，提出CAUSA方法通过因果正则化模块分离混杂因子并平衡分布，以选择因果信息特征。


<details>
  <summary>Details</summary>
Motivation: 现有MUFS方法通过特征与聚类标签的相关性来选择判别性特征，但可能因忽略混杂因子导致的伪相关而选择无关特征。本文从因果角度分析这一问题。

Method: 提出CAUSA方法：1) 广义无监督谱回归模型捕捉特征与共识聚类标签的依赖关系；2) 因果正则化模块自适应分离混杂因子并学习视图共享样本权重以平衡混杂因子分布。

Result: 综合实验表明CAUSA优于多个最先进方法，是首个在无监督设置下深入研究因果多视图特征选择的工作。

Conclusion: 从因果视角分析MUFS问题，提出的CAUSA方法能有效缓解伪相关问题，选择更具因果信息量的特征。

Abstract: Multi-view unsupervised feature selection (MUFS) has recently received
increasing attention for its promising ability in dimensionality reduction on
multi-view unlabeled data. Existing MUFS methods typically select
discriminative features by capturing correlations between features and
clustering labels. However, an important yet underexplored question remains:
\textit{Are such correlations sufficiently reliable to guide feature
selection?} In this paper, we analyze MUFS from a causal perspective by
introducing a novel structural causal model, which reveals that existing
methods may select irrelevant features because they overlook spurious
correlations caused by confounders. Building on this causal perspective, we
propose a novel MUFS method called CAusal multi-view Unsupervised feature
Selection leArning (CAUSA). Specifically, we first employ a generalized
unsupervised spectral regression model that identifies informative features by
capturing dependencies between features and consensus clustering labels. We
then introduce a causal regularization module that can adaptively separate
confounders from multi-view data and simultaneously learn view-shared sample
weights to balance confounder distributions, thereby mitigating spurious
correlations. Thereafter, integrating both into a unified learning framework
enables CAUSA to select causally informative features. Comprehensive
experiments demonstrate that CAUSA outperforms several state-of-the-art
methods. To our knowledge, this is the first in-depth study of causal
multi-view feature selection in the unsupervised setting.

</details>


### [151] [Unsupervised Anomaly Detection in ALS EPICS Event Logs](https://arxiv.org/abs/2509.13621)
*Antonin Sulc,Thorsten Hellert,Steven Hunt*

Main category: cs.LG

Relevance: 15.0

TL;DR: 本文提出了一个用于先进光源(ALS)的自动化故障分析框架，通过将EPICS控制系统的事件日志作为自然语言处理，使用语义嵌入技术将其转换为上下文向量表示，并用序列感知神经网络进行实时异常检测。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够实时处理控制系统事件日志、自动检测异常并帮助操作人员快速识别复杂系统故障前兆的自动化框架，以提高大型科学设施的运行可靠性。

Method: 将控制系统事件日志视为自然语言文本，使用语义嵌入技术生成上下文向量表示，训练序列感知神经网络在正常操作数据上建立基线，为每个事件分配实时异常分数。

Result: 该方法能够有效标记与基线行为的偏差，使操作人员能够快速识别导致复杂系统故障的关键事件序列。

Conclusion: 提出的基于自然语言处理和序列神经网络的框架为大型科学设施的实时故障分析和预警提供了一种有效的自动化解决方案。

Abstract: This paper introduces an automated fault analysis framework for the Advanced
Light Source (ALS) that processes real-time event logs from its EPICS control
system. By treating log entries as natural language, we transform them into
contextual vector representations using semantic embedding techniques. A
sequence-aware neural network, trained on normal operational data, assigns a
real-time anomaly score to each event. This method flags deviations from
baseline behavior, enabling operators to rapidly identify the critical event
sequences that precede complex system failures.

</details>


### [152] [RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization](https://arxiv.org/abs/2509.13686)
*Bingsheng Peng,Shutao Zhang,Xi Zheng,Ye Xue,Xinyu Qin,Tsung-Hui Chang*

Main category: cs.LG

Relevance: 15.0

TL;DR: RF-LSCM是一个基于神经辐射场的无线信道建模框架，通过多域建模和物理感知的频率相关衰减模型，显著提升了多小区多频段信道预测精度


<details>
  <summary>Details</summary>
Motivation: 传统局部统计信道建模方法局限于单小区、单网格和单频段分析，无法捕捉复杂的跨域交互，需要新的框架来克服这些限制

Method: 采用神经辐射场联合建模大尺度信号衰减和多径分量，引入物理感知的频率相关衰减模型(FDAM)和点云辅助环境增强方法，使用低秩张量表示和分层张量角度建模(HiTAM)算法提高计算效率

Result: 在真实多小区数据集上，RF-LSCM显著优于现有方法，覆盖预测的MAE降低30%，多频数据融合使MAE提升22%

Conclusion: RF-LSCM通过创新的多域建模和高效张量表示，为蜂窝网络优化提供了更准确和可扩展的信道建模解决方案

Abstract: Accurate localized wireless channel modeling is a cornerstone of cellular
network optimization, enabling reliable prediction of network performance
during parameter tuning. Localized statistical channel modeling (LSCM) is the
state-of-the-art channel modeling framework tailored for cellular network
optimization. However, traditional LSCM methods, which infer the channel's
Angular Power Spectrum (APS) from Reference Signal Received Power (RSRP)
measurements, suffer from critical limitations: they are typically confined to
single-cell, single-grid and single-carrier frequency analysis and fail to
capture complex cross-domain interactions. To overcome these challenges, we
propose RF-LSCM, a novel framework that models the channel APS by jointly
representing large-scale signal attenuation and multipath components within a
radiance field. RF-LSCM introduces a multi-domain LSCM formulation with a
physics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the
cross frequency generalization as well as a point-cloud-aided environment
enhanced method to enable multi-cell and multi-grid channel modeling.
Furthermore, to address the computational inefficiency of typical neural
radiance fields, RF-LSCM leverages a low-rank tensor representation,
complemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.
This efficient design significantly reduces GPU memory requirements and
training time while preserving fine-grained accuracy. Extensive experiments on
real-world multi-cell datasets demonstrate that RF-LSCM significantly
outperforms state-of-the-art methods, achieving up to a 30% reduction in mean
absolute error (MAE) for coverage prediction and a 22% MAE improvement by
effectively fusing multi-frequency data.

</details>


### [153] [Floating-Body Hydrodynamic Neural Networks](https://arxiv.org/abs/2509.13783)
*Tianshuo Zhang,Wenzhe Zhai,Rui Yann,Jia Gao,He Cao,Xianglei Xing*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出了Floating-Body Hydrodynamic Neural Networks (FHNN)，一种物理结构化的神经网络框架，用于预测可解释的水动力参数并耦合解析运动方程，在耗散动力学建模方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 流体-结构相互作用在工程和自然系统中很常见，但传统黑盒神经网络模型在可解释性和长期预测稳定性方面存在局限，需要开发物理结构化的建模方法。

Method: 设计FHNN框架，预测可解释的水动力参数（如附加质量、阻力系数和基于流函数的流动），并将其与解析运动方程耦合，通过约束假设空间来增强可解释性和稳定性。

Result: 在合成涡流数据集上，FHNN比神经ODE的误差低一个数量级，能恢复物理一致的流场，相比哈密顿和拉格朗日神经网络能更有效处理耗散动力学。

Conclusion: FHNN在保持可解释性的同时有效处理耗散动力学，填补了黑盒学习与透明系统识别之间的空白。

Abstract: Fluid-structure interaction is common in engineering and natural systems,
where floating-body motion is governed by added mass, drag, and background
flows. Modeling these dissipative dynamics is difficult: black-box neural
models regress state derivatives with limited interpretability and unstable
long-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks
(FHNN), a physics-structured framework that predicts interpretable hydrodynamic
parameters such as directional added masses, drag coefficients, and a
streamfunction-based flow, and couples them with analytic equations of motion.
This design constrains the hypothesis space, enhances interpretability, and
stabilizes integration. On synthetic vortex datasets, FHNN achieves up to an
order-of-magnitude lower error than Neural ODEs, recovers physically consistent
flow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN
more effectively handles dissipative dynamics while preserving
interpretability, which bridges the gap between black-box learning and
transparent system identification.

</details>


### [154] [Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets](https://arxiv.org/abs/2010.01052)
*Jaume Banus,Maxime Sermesant,Oscar Camara,Marco Lorenzi*

Main category: cs.LG

Relevance: 15.0

TL;DR: 该论文提出了一个概率框架，用于联合心脏数据填补和心血管机制模型个性化，特别针对脑研究中心脏数据不完整的情况。


<details>
  <summary>Details</summary>
Motivation: 解决临床研究中多模态患者数据缺乏的问题，特别是神经影像数据集无法充分代表心脏特征来建模脑疾病中的心血管因素。

Method: 基于变分推断框架，联合推断从可用特征中填补心脏信息的模型，以及能够忠实再现个性化心血管动态的高斯过程仿真器。

Result: 在UK Biobank数据集上的实验表明，该方法能够准确填补仅包含最小心脏信息（如收缩压和舒张压）的数据集中缺失的心脏特征，同时联合估计集总模型的仿真参数。

Conclusion: 该方法通过模拟与不同脑解剖条件相对应的真实心脏动态，为探索心脑联合关系提供了新的途径。

Abstract: The use of mechanistic models in clinical studies is limited by the lack of
multi-modal patients data representing different anatomical and physiological
processes. For example, neuroimaging datasets do not provide a sufficient
representation of heart features for the modeling of cardiovascular factors in
brain disorders. To tackle this problem we introduce a probabilistic framework
for joint cardiac data imputation and personalisation of cardiovascular
mechanistic models, with application to brain studies with incomplete heart
data. Our approach is based on a variational framework for the joint inference
of an imputation model of cardiac information from the available features,
along with a Gaussian Process emulator that can faithfully reproduce
personalised cardiovascular dynamics. Experimental results on UK Biobank show
that our model allows accurate imputation of missing cardiac features in
datasets containing minimal heart information, e.g. systolic and diastolic
blood pressures only, while jointly estimating the emulated parameters of the
lumped model. This allows a novel exploration of the heart-brain joint
relationship through simulation of realistic cardiac dynamics corresponding to
different conditions of brain anatomy.

</details>


### [155] [eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems](https://arxiv.org/abs/2509.13952)
*Amin Lotfalian,Mohammad Reza Banan,Pooyan Broumand*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出了X-PINN框架，通过能量损失函数、定制积分方案和域分解方法处理多裂纹断裂力学问题，结合XFEM思想用特殊函数显式捕捉裂纹不连续性和奇异性


<details>
  <summary>Details</summary>
Motivation: 解决断裂介质中多裂纹问题的计算挑战，传统方法在处理复杂裂纹几何和奇异性方面存在困难

Method: 扩展物理信息神经网络(X-PINN)，采用基于能量的损失函数、定制积分方案、域分解，并借鉴XFEM方法用特殊函数丰富神经网络解空间

Result: 数值实验验证了该方法在1D和2D多裂纹问题中的有效性和鲁棒性，可扩展到3D问题

Conclusion: X-PINN为复杂多裂纹断裂力学问题提供了灵活有效的计算框架

Abstract: This paper presents eXtended Physics-Informed Neural Network (X-PINN), a
novel and robust framework for addressing fracture mechanics problems involving
multiple cracks in fractured media. To address this, an energy-based loss
function, customized integration schemes, and domain decomposition procedures
are proposed. Inspired by the Extended Finite Element Method (XFEM), the neural
network solution space is enriched with specialized functions that allow crack
body discontinuities and singularities at crack tips to be explicitly captured.
Furthermore, a structured framework is introduced in which standard and
enriched solution components are modeled using distinct neural networks,
enabling flexible and effective simulations of complex multiple-crack problems
in 1D and 2D domains, with convenient extensibility to 3D problems. Numerical
experiments are conducted to validate the effectiveness and robustness of the
proposed method.

</details>


### [156] [Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing](https://arxiv.org/abs/2509.14061)
*Chiara De Luca,Elisa Donati*

Main category: cs.LG

Relevance: 5.0

TL;DR: 提出基于环境传感器融合的轻量级蜂王检测系统，使用温湿度压力差分特征，在STM32微控制器上实现实时低功耗边缘计算，准确率超过99%


<details>
  <summary>Details</summary>
Motivation: 传统蜂王检测方法依赖人工检查，劳动密集且干扰蜂群；现有音频方法功耗高、预处理复杂且易受环境噪声影响，需要更可持续的解决方案

Method: 使用蜂箱内外温度、湿度和压力差分作为环境传感器特征，在商用STM32微控制器上部署量化决策树推理实现边缘计算

Result: 仅使用环境输入即可实现超过99%的蜂王检测准确率，音频特征未带来显著性能提升

Conclusion: 该系统为无创蜂箱监测提供了可扩展的可持续解决方案，为使用现成节能硬件的自主精准养蜂铺平道路

Abstract: Queen bee presence is essential for the health and stability of honeybee
colonies, yet current monitoring methods rely on manual inspections that are
labor-intensive, disruptive, and impractical for large-scale beekeeping. While
recent audio-based approaches have shown promise, they often require high power
consumption, complex preprocessing, and are susceptible to ambient noise. To
overcome these limitations, we propose a lightweight, multimodal system for
queen detection based on environmental sensor fusion-specifically, temperature,
humidity, and pressure differentials between the inside and outside of the
hive. Our approach employs quantized decision tree inference on a commercial
STM32 microcontroller, enabling real-time, low-power edge computing without
compromising accuracy. We show that our system achieves over 99% queen
detection accuracy using only environmental inputs, with audio features
offering no significant performance gain. This work presents a scalable and
sustainable solution for non-invasive hive monitoring, paving the way for
autonomous, precision beekeeping using off-the-shelf, energy-efficient
hardware.

</details>
