<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 50]
- [cs.CV](#cs.CV) [Total: 109]
- [cs.AI](#cs.AI) [Total: 52]
- [cs.LG](#cs.LG) [Total: 73]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [gpt-oss-120b & gpt-oss-20b Model Card](https://arxiv.org/abs/2508.10925)
*OpenAI,:,Sandhini Agarwal,Lama Ahmad,Jason Ai,Sam Altman,Andy Applebaum,Edwin Arbus,Rahul K. Arora,Yu Bai,Bowen Baker,Haiming Bao,Boaz Barak,Ally Bennett,Tyler Bertao,Nivedita Brett,Eugene Brevdo,Greg Brockman,Sebastien Bubeck,Che Chang,Kai Chen,Mark Chen,Enoch Cheung,Aidan Clark,Dan Cook,Marat Dukhan,Casey Dvorak,Kevin Fives,Vlad Fomenko,Timur Garipov,Kristian Georgiev,Mia Glaese,Tarun Gogineni,Adam Goucher,Lukas Gross,Katia Gil Guzman,John Hallman,Jackie Hehir,Johannes Heidecke,Alec Helyar,Haitang Hu,Romain Huet,Jacob Huh,Saachi Jain,Zach Johnson,Chris Koch,Irina Kofman,Dominik Kundel,Jason Kwon,Volodymyr Kyrylov,Elaine Ya Le,Guillaume Leclerc,James Park Lennon,Scott Lessans,Mario Lezcano-Casado,Yuanzhi Li,Zhuohan Li,Ji Lin,Jordan Liss,Lily,Liu,Jiancheng Liu,Kevin Lu,Chris Lu,Zoran Martinovic,Lindsay McCallum,Josh McGrath,Scott McKinney,Aidan McLaughlin,Song Mei,Steve Mostovoy,Tong Mu,Gideon Myles,Alexander Neitz,Alex Nichol,Jakub Pachocki,Alex Paino,Dana Palmie,Ashley Pantuliano,Giambattista Parascandolo,Jongsoo Park,Leher Pathak,Carolina Paz,Ludovic Peran,Dmitry Pimenov,Michelle Pokrass,Elizabeth Proehl,Huida Qiu,Gaby Raila,Filippo Raso,Hongyu Ren,Kimmy Richardson,David Robinson,Bob Rotsted,Hadi Salman,Suvansh Sanjeev,Max Schwarzer,D. Sculley,Harshit Sikchi,Kendal Simon,Karan Singhal,Yang Song,Dane Stuckey,Zhiqing Sun,Philippe Tillet,Sam Toizer,Foivos Tsimpourlas,Nikhil Vyas,Eric Wallace,Xin Wang,Miles Wang,Olivia Watkins,Kevin Weil,Amy Wendling,Kevin Whinnery,Cedric Whitney,Hannah Wong,Lin Yang,Yu Yang,Michihiro Yasunaga,Kristen Ying,Wojciech Zaremba,Wenting Zhan,Cyril Zhang,Brian Zhang,Eddie Zhang,Shengjia Zhao*

Main category: cs.CL

Relevance: 90.0

TL;DR: 论文介绍了两个开源推理模型gpt-oss-120b和gpt-oss-20b，采用混合专家Transformer架构，通过大规模蒸馏和强化学习训练，优化了代理能力，并在数学、编程和安全基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 推动开源推理模型的准确性和推理成本前沿，同时增强代理能力（如研究浏览、工具使用等）。

Method: 采用混合专家Transformer架构，结合大规模蒸馏和强化学习训练。

Result: 模型在数学、编程和安全基准测试中表现优异。

Conclusion: 开源模型权重及相关工具，促进广泛使用和进一步研究。

Abstract: We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models
that push the frontier of accuracy and inference cost. The models use an
efficient mixture-of-expert transformer architecture and are trained using
large-scale distillation and reinforcement learning. We optimize the models to
have strong agentic capabilities (deep research browsing, python tool use, and
support for developer-provided functions), all while using a rendered chat
format that enables clear instruction following and role delineation. Both
models achieve strong results on benchmarks ranging from mathematics, coding,
and safety. We release the model weights, inference implementations, tool
environments, and tokenizers under an Apache 2.0 license to enable broad use
and further research.

</details>


### [2] [SproutBench: A Benchmark for Safe and Ethical Large Language Models for Youth](https://arxiv.org/abs/2508.11009)
*Wenpeng Xing,Lanyi Wei,Haixiao Hu,Rongchang Li,Mohan Li,Changting Lin,Meng Han*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出SproutBench，一个针对儿童和青少年设计的LLM安全评估套件，填补现有安全框架的不足。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全框架主要针对成人，忽视了儿童和青少年的独特发展脆弱性，需重新评估。

Method: 引入SproutBench，包含1,283个发展心理学基础的对抗性提示，评估47种LLM的安全性。

Result: 发现LLM在儿童和青少年群体中存在显著安全漏洞，如情感依赖和隐私风险。

Conclusion: 研究为儿童中心AI设计提供了实用指南。

Abstract: The rapid proliferation of large language models (LLMs) in applications
targeting children and adolescents necessitates a fundamental reassessment of
prevailing AI safety frameworks, which are largely tailored to adult users and
neglect the distinct developmental vulnerabilities of minors. This paper
highlights key deficiencies in existing LLM safety benchmarks, including their
inadequate coverage of age-specific cognitive, emotional, and social risks
spanning early childhood (ages 0--6), middle childhood (7--12), and adolescence
(13--18). To bridge these gaps, we introduce SproutBench, an innovative
evaluation suite comprising 1,283 developmentally grounded adversarial prompts
designed to probe risks such as emotional dependency, privacy violations, and
imitation of hazardous behaviors. Through rigorous empirical evaluation of 47
diverse LLMs, we uncover substantial safety vulnerabilities, corroborated by
robust inter-dimensional correlations (e.g., between Safety and Risk
Prevention) and a notable inverse relationship between Interactivity and Age
Appropriateness. These insights yield practical guidelines for advancing
child-centric AI design and deployment.

</details>


### [3] [Beyond the Rosetta Stone: Unification Forces in Generalization Dynamics](https://arxiv.org/abs/2508.11017)
*Carter Blum,Katja Filipova,Ann Yuan,Asma Ghandeharioun,Julian Zimmert,Fred Zhang,Jessica Hoffmann,Tal Linzen,Martin Wattenberg,Lucas Dixon,Mor Geva*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文研究了LLMs在跨语言知识迁移中的幻觉问题，通过合成多语言数据集训练小Transformer模型，揭示了跨语言统一表示的重要性及其影响因素。


<details>
  <summary>Details</summary>
Motivation: LLMs在跨语言知识迁移中表现不佳，常产生幻觉。研究旨在揭示这一现象的原因和动态。

Method: 使用合成多语言数据集训练小Transformer模型，分析学习阶段和统一表示的形成。

Result: 发现统一表示对跨语言迁移至关重要，其程度受事实与训练语言互信息及语言提取难度影响。

Conclusion: 研究为改进LLMs的跨语言迁移提供了新方向。

Abstract: Large language models (LLMs) struggle with cross-lingual knowledge transfer:
they hallucinate when asked in one language about facts expressed in a
different language during training. This work introduces a controlled setting
to study the causes and dynamics of this phenomenon by training small
Transformer models from scratch on synthetic multilingual datasets. We identify
a learning phase wherein a model develops either separate or unified
representations of the same facts across languages, and show that unification
is essential for cross-lingual transfer. We also show that the degree of
unification depends on mutual information between facts and training data
language, and on how easy it is to extract that language. Based on these
insights, we develop methods to modulate the level of cross-lingual transfer by
manipulating data distribution and tokenization, and we introduce metrics and
visualizations to formally characterize their effects on unification. Our work
shows how controlled settings can shed light on pre-training dynamics and
suggests new directions for improving cross-lingual transfer in LLMs.

</details>


### [4] [Hell or High Water: Evaluating Agentic Recovery from External Failures](https://arxiv.org/abs/2508.11027)
*Andrew Wang,Sophia Hager,Adi Asija,Daniel Khashabi,Nicholas Andrews*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文研究了语言模型代理在复杂任务中应对计划失败的能力，开发了一个专门的规划基准测试，发现当前模型难以适应环境反馈并制定备用计划。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型代理在面临外部失败时如何寻找替代方案以实现目标，填补了现有研究的空白。

Method: 设计了一个基于函数调用的规划基准测试，包含4000多种函数选择，并引入外部失败（如函数不可用）来测试代理的适应能力。

Result: 当前最先进的模型在正确选择函数方面表现良好，但在适应环境反馈和制定备用计划方面表现不佳。

Conclusion: 研究揭示了生成模型在应对动态环境时的关键挑战，并提出了未来改进的方向。

Abstract: As language model agents are applied to real world problems of increasing
complexity, they will be expected to formulate plans across large search
spaces. If those plans fail for reasons beyond their control, how well do
language agents search for alternative ways to achieve their goals? We devise a
specialized agentic planning benchmark to study this question. Each planning
problem is solved via combinations of function calls. The agent searches for
relevant functions from a set of over four thousand possibilities, and observes
environmental feedback in the form of function outputs or error messages. Our
benchmark confronts the agent with external failures in its workflow, such as
functions that suddenly become unavailable. At the same time, even with the
introduction of these failures, we guarantee that the task remains solvable.
Ideally, an agent's performance on the planning task should not be affected by
the presence of external failures. Overall, we find that language agents
struggle to formulate and execute backup plans in response to environment
feedback. While state-of-the-art models are often able to identify the correct
function to use in the right context, they struggle to adapt to feedback from
the environment and often fail to pursue alternate courses of action, even when
the search space is artificially restricted. We provide a systematic analysis
of the failures of both open-source and commercial models, examining the
effects of search space size, as well as the benefits of scaling model size in
our setting. Our analysis identifies key challenges for current generative
models as well as promising directions for future work.

</details>


### [5] [BIPOLAR: Polarization-based granular framework for LLM bias evaluation](https://arxiv.org/abs/2508.11061)
*Martin Pavlíček,Tomáš Filip,Petr Sosík*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种可重用、细粒度且与主题无关的框架，用于评估LLM中的极化相关偏见，结合极化敏感情感指标和合成平衡数据集。


<details>
  <summary>Details</summary>
Motivation: LLM在下游任务中表现出偏见，尤其是在敏感话题上，现有方法尚未充分解决这一问题。

Method: 结合极化敏感情感指标和合成平衡数据集，评估多种LLM的偏见。

Result: 发现LLM对乌克兰的情感更积极，不同语义类别间存在显著差异，提示修改会进一步暴露偏见。

Conclusion: 该框架支持自动化数据集生成和细粒度偏见评估，适用于多种极化场景。

Abstract: Large language models (LLMs) are known to exhibit biases in downstream tasks,
especially when dealing with sensitive topics such as political discourse,
gender identity, ethnic relations, or national stereotypes. Although
significant progress has been made in bias detection and mitigation techniques,
certain challenges remain underexplored. This study proposes a reusable,
granular, and topic-agnostic framework to evaluate polarisation-related biases
in LLM (both open-source and closed-source). Our approach combines
polarisation-sensitive sentiment metrics with a synthetically generated
balanced dataset of conflict-related statements, using a predefined set of
semantic categories.
  As a case study, we created a synthetic dataset that focusses on the
Russia-Ukraine war, and we evaluated the bias in several LLMs: Llama-3,
Mistral, GPT-4, Claude 3.5, and Gemini 1.0. Beyond aggregate bias scores, with
a general trend for more positive sentiment toward Ukraine, the framework
allowed fine-grained analysis with considerable variation between semantic
categories, uncovering divergent behavioural patterns among models. Adaptation
to prompt modifications showed further bias towards preconceived language and
citizenship modification.
  Overall, the framework supports automated dataset generation and fine-grained
bias assessment, is applicable to a variety of polarisation-driven scenarios
and topics, and is orthogonal to many other bias-evaluation strategies.

</details>


### [6] [Towards Reliable Multi-Agent Systems for Marketing Applications via Reflection, Memory, and Planning](https://arxiv.org/abs/2508.11120)
*Lorenzo Jaime Yu Flores,Junyi Shen,Xiaoyuan Gu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一个多智能体框架RAMP，用于营销任务中的受众策划，结合LLM规划、工具调用、输出验证和记忆存储，显著提高了任务准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有研究对LLM在真实应用中的可靠性关注不足，尤其是在动态行业环境中。本文旨在通过多智能体框架提升LLM在营销任务中的可靠性和性能。

Method: 提出RAMP框架，通过迭代规划、工具调用、输出验证和记忆存储优化受众策划任务。

Result: 在88个评估查询中，准确性提升28个百分点；模糊查询的召回率提升约20个百分点，用户满意度提高。

Conclusion: RAMP框架为动态行业环境中部署可靠的LLM系统提供了实用见解。

Abstract: Recent advances in large language models (LLMs) enabled the development of AI
agents that can plan and interact with tools to complete complex tasks.
However, literature on their reliability in real-world applications remains
limited. In this paper, we introduce a multi-agent framework for a marketing
task: audience curation. To solve this, we introduce a framework called RAMP
that iteratively plans, calls tools, verifies the output, and generates
suggestions to improve the quality of the audience generated. Additionally, we
equip the model with a long-term memory store, which is a knowledge base of
client-specific facts and past queries. Overall, we demonstrate the use of LLM
planning and memory, which increases accuracy by 28 percentage points on a set
of 88 evaluation queries. Moreover, we show the impact of iterative
verification and reflection on more ambiguous queries, showing progressively
better recall (roughly +20 percentage points) with more verify/reflect
iterations on a smaller challenge set, and higher user satisfaction. Our
results provide practical insights for deploying reliable LLM-based systems in
dynamic, industry-facing environments.

</details>


### [7] [MoNaCo: More Natural and Complex Questions for Reasoning Across Dozens of Documents](https://arxiv.org/abs/2508.11133)
*Tomer Wolfson,Harsh Trivedi,Mor Geva,Yoav Goldberg,Dan Roth,Tushar Khot,Ashish Sabharwal,Reut Tsarfaty*

Main category: cs.CL

Relevance: 85.0

TL;DR: MoNaCo是一个包含1,315个复杂自然问题的基准测试，旨在填补现有LLM评测的空白，强调真实信息搜索问题的复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评测缺乏自然且耗时的问题，无法充分评估模型处理复杂信息搜索任务的能力。

Method: 通过分解标注流程，大规模收集并手动回答自然耗时问题，构建MoNaCo基准。

Result: 前沿LLM在MoNaCo上的F1得分最高为61.2%，表现受限于低召回率和幻觉问题。

Conclusion: MoNaCo为跟踪模型在处理复杂信息搜索问题上的进展提供了有效资源。

Abstract: Large language models (LLMs) are emerging as a go-to tool for querying
information. However, current LLM benchmarks rarely feature natural questions
that are both information-seeking as well as genuinely time-consuming for
humans. To address this gap we introduce MoNaCo, a benchmark of 1,315 natural
and complex questions that require dozens, and at times hundreds, of
intermediate steps to solve -- far more than any existing QA benchmark. To
build MoNaCo, we developed a decomposed annotation pipeline to elicit and
manually answer natural time-consuming questions at scale. Frontier LLMs
evaluated on MoNaCo achieve at most 61.2% F1, hampered by low recall and
hallucinations. Our results underscore the need for reasoning models that
better handle the complexity and sheer breadth of real-world
information-seeking questions -- with MoNaCo providing an effective resource
for tracking such progress. The MONACO benchmark, codebase, prompts and models
predictions are publicly available at: https://tomerwolgithub.github.io/monaco

</details>


### [8] [MobQA: A Benchmark Dataset for Semantic Understanding of Human Mobility Data through Question Answering](https://arxiv.org/abs/2508.11163)
*Hikaru Asano,Hiroki Ouchi,Akira Kasuga,Ryo Yonetani*

Main category: cs.CL

Relevance: 85.0

TL;DR: MobQA是一个评估大语言模型（LLMs）对人类移动数据语义理解能力的基准数据集，包含5800个高质量问答对，涵盖事实检索、多选推理和自由解释三种问题类型。评估显示LLMs在事实检索上表现良好，但在语义推理和解释问题上存在显著局限。


<details>
  <summary>Details</summary>
Motivation: 现有模型能预测人类移动模式，但其对模式背后语义的理解能力尚不明确。MobQA旨在填补这一空白，提供评估LLMs语义理解能力的框架。

Method: MobQA包含5800个问答对，分为事实检索、多选推理和自由解释三类，要求模型进行空间、时间和语义推理。

Result: 评估显示LLMs在事实检索上表现优异，但在语义推理和解释问题上表现不佳，轨迹长度对模型效果有显著影响。

Conclusion: MobQA揭示了当前LLMs在语义移动理解上的成就与局限，为未来研究提供了方向。

Abstract: This paper presents MobQA, a benchmark dataset designed to evaluate the
semantic understanding capabilities of large language models (LLMs) for human
mobility data through natural language question answering.
  While existing models excel at predicting human movement patterns, it remains
unobvious how much they can interpret the underlying reasons or semantic
meaning of those patterns. MobQA provides a comprehensive evaluation framework
for LLMs to answer questions about diverse human GPS trajectories spanning
daily to weekly granularities. It comprises 5,800 high-quality question-answer
pairs across three complementary question types: factual retrieval (precise
data extraction), multiple-choice reasoning (semantic inference), and free-form
explanation (interpretive description), which all require spatial, temporal,
and semantic reasoning. Our evaluation of major LLMs reveals strong performance
on factual retrieval but significant limitations in semantic reasoning and
explanation question answering, with trajectory length substantially impacting
model effectiveness. These findings demonstrate the achievements and
limitations of state-of-the-art LLMs for semantic mobility
understanding.\footnote{MobQA dataset is available at
https://github.com/CyberAgentAILab/mobqa.}

</details>


### [9] [UNVEILING: What Makes Linguistics Olympiad Puzzles Tricky for LLMs?](https://arxiv.org/abs/2508.11260)
*Mukund Choudhary,KV Aditya Srivatsa,Gaurja Aeron,Antara Raaghavi Bhattacharya,Dang Khoa Dang Dinh,Ikhlasul Akmal Hanif,Daria Kotova,Ekaterina Kochmar,Monojit Choudhury*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文分析了大型语言模型（LLMs）在低资源语言语言学谜题上的表现，揭示了其在形态复杂性较高的问题上的弱点，并提出了改进方法。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在低资源语言语言学谜题上的表现，以揭示其在语言推理能力上的局限性。

Method: 通过标记629个问题的语言学特征，分析LLMs在41种低资源语言中的表现，并测试词素分割预处理的效果。

Result: LLMs在形态复杂性较高的问题上表现较差，而在与英语相似的语言特征上表现较好；词素分割预处理能提升解决能力。

Conclusion: 研究揭示了LLMs在语言推理和低资源语言建模中的挑战，建议开发更智能的语言特定分词器。

Abstract: Large language models (LLMs) have demonstrated potential in reasoning tasks,
but their performance on linguistics puzzles remains consistently poor. These
puzzles, often derived from Linguistics Olympiad (LO) contests, provide a
minimal contamination environment to assess LLMs' linguistic reasoning
abilities across low-resource languages. This work analyses LLMs' performance
on 629 problems across 41 low-resource languages by labelling each with
linguistically informed features to unveil weaknesses. Our analyses show that
LLMs struggle with puzzles involving higher morphological complexity and
perform better on puzzles involving linguistic features that are also found in
English. We also show that splitting words into morphemes as a pre-processing
step improves solvability, indicating a need for more informed and
language-specific tokenisers. These findings thus offer insights into some
challenges in linguistic reasoning and modelling of low-resource languages.

</details>


### [10] [LETToT: Label-Free Evaluation of Large Language Models On Tourism Using Expert Tree-of-Thought](https://arxiv.org/abs/2508.11280)
*Ruiyan Qi,Congding Wen,Weibo Zhou,Shangsong Liang,Lingbo Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种无标签的LLM评估框架LETToT，利用专家推理结构在旅游领域评估LLM，避免了标注数据的成本。结果显示该方法优于基线，并揭示了模型规模和推理架构对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 解决旅游领域LLM评估的高成本和幻觉问题，提供一种无需标注数据的评估方法。

Method: 通过专家反馈优化层次化Tree-of-Thought（ToT）组件，并将其应用于不同规模的LLM评估。

Result: 优化的专家ToT相对基线有4.99-14.15%的质量提升；发现规模定律在专业领域仍适用，但推理增强的小模型能缩小差距；72B以下模型，显式推理架构表现更优。

Conclusion: LETToT为领域特定LLM评估提供了一种可扩展、无标签的范式，替代传统标注基准。

Abstract: Evaluating large language models (LLMs) in specific domain like tourism
remains challenging due to the prohibitive cost of annotated benchmarks and
persistent issues like hallucinations. We propose $\textbf{L}$able-Free
$\textbf{E}$valuation of LLM on $\textbf{T}$ourism using Expert
$\textbf{T}$ree-$\textbf{o}$f-$\textbf{T}$hought (LETToT), a framework that
leverages expert-derived reasoning structures-instead of labeled data-to access
LLMs in tourism. First, we iteratively refine and validate hierarchical ToT
components through alignment with generic quality dimensions and expert
feedback. Results demonstrate the effectiveness of our systematically optimized
expert ToT with 4.99-14.15\% relative quality gains over baselines. Second, we
apply LETToT's optimized expert ToT to evaluate models of varying scales
(32B-671B parameters), revealing: (1) Scaling laws persist in specialized
domains (DeepSeek-V3 leads), yet reasoning-enhanced smaller models (e.g.,
DeepSeek-R1-Distill-Llama-70B) close this gap; (2) For sub-72B models, explicit
reasoning architectures outperform counterparts in accuracy and conciseness
($p<0.05$). Our work established a scalable, label-free paradigm for
domain-specific LLM evaluation, offering a robust alternative to conventional
annotated benchmarks.

</details>


### [11] [SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory](https://arxiv.org/abs/2508.11290)
*Utsav Maskey,Sumit Yadav,Mark Dras,Usman Naseem*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种名为SafeConstellations的方法，通过跟踪任务特定的轨迹模式，减少LLMs的过度拒绝行为，同时保持模型的通用性。


<details>
  <summary>Details</summary>
Motivation: LLMs的安全机制导致模型拒绝表面上类似有害内容的良性指令，降低了生产应用的实用性。

Method: 通过嵌入空间的轨迹分析，提出SafeConstellations方法，在推理时引导表示向非拒绝路径转移。

Result: 该方法将过度拒绝率降低高达73%，且对模型实用性影响最小。

Conclusion: SafeConstellations为缓解LLMs的过度拒绝行为提供了一种原则性方法。

Abstract: LLMs increasingly exhibit over-refusal behavior, where safety mechanisms
cause models to reject benign instructions that superficially resemble harmful
content. This phenomena diminishes utility in production applications that
repeatedly rely on common prompt templates or applications that frequently rely
on LLMs for specific tasks (e.g. sentiment analysis, language translation).
Through comprehensive evaluation, we demonstrate that LLMs still tend to refuse
responses to harmful instructions when those instructions are reframed to
appear as benign tasks. Our mechanistic analysis reveal that LLMs follow
distinct "constellation" patterns in embedding space as representations
traverse layers, with each task maintaining consistent trajectories that shift
predictably between refusal and non-refusal cases. We introduce
SafeConstellations, an inference-time trajectory-shifting approach that tracks
task-specific trajectory patterns and guides representations toward non-refusal
pathways. By selectively guiding model behavior only on tasks prone to
over-refusal, and by preserving general model behavior, our method reduces
over-refusal rates by up to 73% with minimal impact on utility-offering a
principled approach to mitigating over-refusals.

</details>


### [12] [LLM Compression: How Far Can We Go in Balancing Size and Performance?](https://arxiv.org/abs/2508.11318)
*Sahil Sk,Debasish Dhal,Sonal Khosla,Sk Shahid,Sambit Shekhar,Akash Dhaka,Shantipriya Parida,Dilip K. Prasad,Ondřej Bojar*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究探讨了4位组缩放量化（GSQ）和生成预训练变换器量化（GPTQ）对LLaMA 1B、Qwen 0.5B和PHI 1.5B模型的影响，评估了其在多个NLP任务中的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 量化技术能降低大型语言模型的内存和计算成本，同时保持性能，本研究旨在评估不同量化方法对模型性能的影响。

Method: 应用GSQ和GPTQ量化技术，并在MS MARCO、BoolQ和GSM8K数据集上评估模型的准确性、推理延迟和吞吐量。

Result: 研究量化了模型压缩与任务性能之间的权衡，提供了低比特量化在实际部署中的适用性分析。

Conclusion: 研究结果为用户提供了基于需求选择合适量化方法的依据，并为未来实验提供了基准。

Abstract: Quantization is an essential and popular technique for improving the
accessibility of large language models (LLMs) by reducing memory usage and
computational costs while maintaining performance. In this study, we apply
4-bit Group Scaling Quantization (GSQ) and Generative Pretrained Transformer
Quantization (GPTQ) to LLaMA 1B, Qwen 0.5B, and PHI 1.5B, evaluating their
impact across multiple NLP tasks. We benchmark these models on MS MARCO
(Information Retrieval), BoolQ (Boolean Question Answering), and GSM8K
(Mathematical Reasoning) datasets, assessing both accuracy and efficiency
across various tasks. The study measures the trade-offs between model
compression and task performance, analyzing key evaluation metrics, namely
accuracy, inference latency, and throughput (total output tokens generated per
second), providing insights into the suitability of low-bit quantization for
real-world deployment. Using the results, users can then make suitable
decisions based on the specifications that need to be met. We discuss the pros
and cons of GSQ and GPTQ techniques on models of different sizes, which also
serve as a benchmark for future experiments.

</details>


### [13] [SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis](https://arxiv.org/abs/2508.11343)
*Haitong Luo,Weiyao Zhang,Suhang Wang,Wenji Zou,Chungang Lin,Xuying Meng,Yujun Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种基于信号处理的LLM生成文本检测方法，通过分析token概率序列的频谱特性，发现人类文本具有更高的频谱能量，并构建了高效且可解释的检测器SpecDetect和SpecDetect++。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成文本检测方法依赖表面统计特征，忽视了文本生成过程的信号特性，因此需要更可靠和高效的检测方法。

Method: 将检测问题转化为信号处理问题，利用全局离散傅里叶变换（DFT）和局部短时傅里叶变换（STFT）分析token概率序列的频谱能量。

Result: 人类文本的频谱能量显著高于LLM生成文本，基于此构建的SpecDetect和SpecDetect++在性能和效率上优于现有方法。

Conclusion: 信号处理技术为LLM生成文本检测提供了高效且可解释的新途径。

Abstract: The proliferation of high-quality text from Large Language Models (LLMs)
demands reliable and efficient detection methods. While existing training-free
approaches show promise, they often rely on surface-level statistics and
overlook fundamental signal properties of the text generation process. In this
work, we reframe detection as a signal processing problem, introducing a novel
paradigm that analyzes the sequence of token log-probabilities in the frequency
domain. By systematically analyzing the signal's spectral properties using the
global Discrete Fourier Transform (DFT) and the local Short-Time Fourier
Transform (STFT), we find that human-written text consistently exhibits
significantly higher spectral energy. This higher energy reflects the
larger-amplitude fluctuations inherent in human writing compared to the
suppressed dynamics of LLM-generated text. Based on this key insight, we
construct SpecDetect, a detector built on a single, robust feature from the
global DFT: DFT total energy. We also propose an enhanced version,
SpecDetect++, which incorporates a sampling discrepancy mechanism to further
boost robustness. Extensive experiments demonstrate that our approach
outperforms the state-of-the-art model while running in nearly half the time.
Our work introduces a new, efficient, and interpretable pathway for
LLM-generated text detection, showing that classical signal processing
techniques offer a surprisingly powerful solution to this modern challenge.

</details>


### [14] [When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs](https://arxiv.org/abs/2508.11383)
*Mikhail Seleznyov,Mikhail Chaichuk,Gleb Ershov,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文系统地评估了5种提高提示鲁棒性的方法，并在8个模型和52个任务上进行了基准测试，分析了其对分布变化的泛化能力，并扩展到前沿模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）对提示的细微变化非常敏感，因此需要系统评估提高提示鲁棒性的方法。

Method: 在统一实验框架下评估5种鲁棒性方法，涵盖微调和上下文学习范式，测试其在多种分布变化下的泛化能力。

Result: 提供了不同鲁棒性方法的相对有效性分析，为实际应用中的稳定性能提供指导。

Conclusion: 研究为LLMs在现实应用中的稳定性和可靠性提供了实用见解。

Abstract: Large Language Models (LLMs) are highly sensitive to subtle, non-semantic
variations in prompt phrasing and formatting. In this work, we present the
first systematic evaluation of 5 methods for improving prompt robustness within
a unified experimental framework. We benchmark these techniques on 8 models
from Llama, Qwen and Gemma families across 52 tasks from Natural Instructions
dataset. Our evaluation covers robustness methods from both fine-tuned and
in-context learning paradigms, and tests their generalization against multiple
types of distribution shifts. Finally, we extend our analysis to GPT-4.1 and
DeepSeek V3 to assess frontier models' current robustness to format
perturbations. Our findings offer actionable insights into the relative
effectiveness of these robustness methods, enabling practitioners to make
informed decisions when aiming for stable and reliable LLM performance in
real-world applications. Code:
https://github.com/AIRI-Institute/when-punctuation-matters.

</details>


### [15] [Retrieval-augmented reasoning with lean language models](https://arxiv.org/abs/2508.11386)
*Ryan Sze-Yin Chan,Federico Nanni,Tomas Lazauskas,Rosie Wood,Penelope Yong,Lionel Tarassenko,Mark Girolami,James Geddes,Andrew Duncan*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种结合推理和检索增强生成（RAG）的轻量级语言模型架构，适用于资源受限或安全敏感环境。


<details>
  <summary>Details</summary>
Motivation: 解决现有RAG系统依赖大规模模型和外部API的问题，满足对高性能且隐私保护的本地部署需求。

Method: 使用密集检索器和微调的Qwen2.5-Instruct模型，结合合成查询生成和推理轨迹，探索文档压缩、合成数据设计和推理感知微调的影响。

Result: 在领域特定微调下，模型在答案准确性和一致性上显著提升，接近前沿模型性能，适合本地部署。

Conclusion: 该方法在轻量级架构中实现了高效推理和检索增强生成，支持跨领域复现和适配。

Abstract: This technical report details a novel approach to combining reasoning and
retrieval augmented generation (RAG) within a single, lean language model
architecture. While existing RAG systems typically rely on large-scale models
and external APIs, our work addresses the increasing demand for performant and
privacy-preserving solutions deployable in resource-constrained or secure
environments. Building on recent developments in test-time scaling and
small-scale reasoning models, we develop a retrieval augmented conversational
agent capable of interpreting complex, domain-specific queries using a
lightweight backbone model. Our system integrates a dense retriever with
fine-tuned Qwen2.5-Instruct models, using synthetic query generation and
reasoning traces derived from frontier models (e.g., DeepSeek-R1) over a
curated corpus, in this case, the NHS A-to-Z condition pages. We explore the
impact of summarisation-based document compression, synthetic data design, and
reasoning-aware fine-tuning on model performance. Evaluation against both
non-reasoning and general-purpose lean models demonstrates that our
domain-specific fine-tuning approach yields substantial gains in answer
accuracy and consistency, approaching frontier-level performance while
remaining feasible for local deployment. All implementation details and code
are publicly released to support reproducibility and adaptation across domains.

</details>


### [16] [Model Interpretability and Rationale Extraction by Input Mask Optimization](https://arxiv.org/abs/2508.11388)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种基于梯度优化和正则化的新方法，用于生成神经网络预测的提取性解释，适用于文本和图像输入。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络模型的快速发展，对其预测提供解释的需求日益增长。本文旨在通过一种无需训练专用模型的方法，生成满足充分性、全面性和紧凑性要求的解释。

Method: 采用基于梯度的优化结合新的正则化方案，通过掩蔽输入中与预测无关的部分生成解释。

Result: 方法在文本和图像分类任务中均能生成高质量的解释，表明自然语言处理中的理性提取条件可泛化到其他输入类型。

Conclusion: 该方法成功连接了模型可解释性与理性提取，证明了仅基于训练好的分类器即可实现理性提取。

Abstract: Concurrent to the rapid progress in the development of neural-network based
models in areas like natural language processing and computer vision, the need
for creating explanations for the predictions of these black-box models has
risen steadily. We propose a new method to generate extractive explanations for
predictions made by neural networks, that is based on masking parts of the
input which the model does not consider to be indicative of the respective
class. The masking is done using gradient-based optimization combined with a
new regularization scheme that enforces sufficiency, comprehensiveness and
compactness of the generated explanation, three properties that are known to be
desirable from the related field of rationale extraction in natural language
processing. In this way, we bridge the gap between model interpretability and
rationale extraction, thereby proving that the latter of which can be performed
without training a specialized model, only on the basis of a trained
classifier. We further apply the same method to image inputs and obtain high
quality explanations for image classifications, which indicates that the
conditions proposed for rationale extraction in natural language processing are
more broadly applicable to different input types.

</details>


### [17] [Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training](https://arxiv.org/abs/2508.11393)
*Marc Brinner,Sina Zarrieß*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出一种端到端可微训练范式，用于稳定训练合理化Transformer分类器，简化现有三玩家游戏方法，提高效率并避免训练不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有合理化模型训练方法依赖三个独立模块（选择器、分类器和互补分类器），导致训练不稳定且效率低。本文旨在简化并稳定这一过程。

Method: 通过单一模型同时实现选择、分类和互补分类功能，结合类特定合理化参数化和正则化技术。

Result: 方法显著提高了合理化与人类标注的对齐性，达到SOTA性能，且无需显式监督。

Conclusion: 提出的训练范式简化了合理化模型训练，提高了效率和稳定性，同时实现了更好的性能。

Abstract: We propose an end-to-end differentiable training paradigm for stable training
of a rationalized transformer classifier. Our approach results in a single
model that simultaneously classifies a sample and scores input tokens based on
their relevance to the classification. To this end, we build on the widely-used
three-player-game for training rationalized models, which typically relies on
training a rationale selector, a classifier and a complement classifier. We
simplify this approach by making a single model fulfill all three roles,
leading to a more efficient training paradigm that is not susceptible to the
common training instabilities that plague existing approaches. Further, we
extend this paradigm to produce class-wise rationales while incorporating
recent advances in parameterizing and regularizing the resulting rationales,
thus leading to substantially improved and state-of-the-art alignment with
human annotations without any explicit supervision.

</details>


### [18] [Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions](https://arxiv.org/abs/2508.11414)
*Shangrui Nie,Florian Mai,David Kaczér,Charles Welch,Zhixue Zhao,Lucie Flek*

Main category: cs.CL

Relevance: 85.0

TL;DR: 通过微调模型回答价值调查问题，研究是否能够可靠地修改LLM的价值系统，并验证其对下游任务行为的影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型隐式编码了人类价值观的偏好，但通常需要大量训练数据来引导。本研究探索一种简单方法，通过微调模型回答价值调查问题来调整其价值系统。

Method: 1. 构建多个开源LLM的价值档案；2. 通过微调模型回答价值调查问题；3. 评估微调对模型行为的影响，包括域内调查问题和域外情境任务（如道德判断和文本冒险游戏）。

Result: 微调不仅能改变模型对域内问题的回答，还能显著影响其在下游任务中的行为（价值对齐）。

Conclusion: 通过简单的微调方法，可以有效地调整LLM的价值系统，并在下游任务中实现价值对齐。

Abstract: Large language models implicitly encode preferences over human values, yet
steering them often requires large training data. In this work, we investigate
a simple approach: Can we reliably modify a model's value system in downstream
behavior by training it to answer value survey questions accordingly? We first
construct value profiles of several open-source LLMs by asking them to rate a
series of value-related descriptions spanning 20 distinct human values, which
we use as a baseline for subsequent experiments. We then investigate whether
the value system of a model can be governed by fine-tuning on the value
surveys. We evaluate the effect of finetuning on the model's behavior in two
ways; first, we assess how answers change on in-domain, held-out survey
questions. Second, we evaluate whether the model's behavior changes in
out-of-domain settings (situational scenarios). To this end, we construct a
contextualized moral judgment dataset based on Reddit posts and evaluate
changes in the model's behavior in text-based adventure games. We demonstrate
that our simple approach can not only change the model's answers to in-domain
survey questions, but also produces substantial shifts (value alignment) in
implicit downstream task behavior.

</details>


### [19] [Aware First, Think Less: Dynamic Boundary Self-Awareness Drives Extreme Reasoning Efficiency in Large Language Models](https://arxiv.org/abs/2508.11582)
*Qiguang Chen,Dengyun Peng,Jinhao Liu,HuiKang Su,Jiannan Guan,Libo Qin,Wanxiang Che*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种动态推理边界自感知框架（DR. SAF），通过模型动态调整推理深度，显著提升计算效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决长链思维（CoT）方法在复杂推理任务中的冗余问题，提高计算效率和实时性。

Method: DR. SAF包含边界自感知对齐、自适应奖励管理和边界保护机制三个关键组件。

Result: 实验显示，DR. SAF减少了49.27%的响应token，效率提升6.59倍，训练时间减少5倍，且在极端训练下准确率提升16%。

Conclusion: DR. SAF在资源受限环境下高效平衡推理效率和准确性。

Abstract: Recent advancements in large language models (LLMs) have greatly improved
their capabilities on complex reasoning tasks through Long Chain-of-Thought
(CoT). However, this approach often results in substantial redundancy,
impairing computational efficiency and causing significant delays in real-time
applications. To improve the efficiency, current methods often rely on
human-defined difficulty priors, which do not align with the LLM's self-awared
difficulty, leading to inefficiencies. In this paper, we introduce the Dynamic
Reasoning-Boundary Self-Awareness Framework (DR. SAF), which enables models to
dynamically assess and adjust their reasoning depth in response to problem
complexity. DR. SAF integrates three key components: Boundary Self-Awareness
Alignment, Adaptive Reward Management, and a Boundary Preservation Mechanism.
These components allow models to optimize their reasoning processes, balancing
efficiency and accuracy without compromising performance. Our experimental
results demonstrate that DR. SAF achieves a 49.27% reduction in total response
tokens with minimal loss in accuracy. The framework also delivers a 6.59x gain
in token efficiency and a 5x reduction in training time, making it well-suited
to resource-limited settings. During extreme training, DR. SAF can even surpass
traditional instruction-based models in token efficiency with more than 16%
accuracy improvement.

</details>


### [20] [PersonaTwin: A Multi-Tier Prompt Conditioning Framework for Generating and Evaluating Personalized Digital Twins](https://arxiv.org/abs/2508.10906)
*Sihan Chen,John P. Lalor,Yi Yang,Ahmed Abbasi*

Main category: cs.CL

Relevance: 75.0

TL;DR: PersonaTwin是一个多层级提示条件框架，用于构建自适应数字孪生，通过整合人口统计、行为和心理测量数据，提升LLM在用户建模中的多维表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在捕捉用户多维细微差异时表现不足，需要一种方法提升模拟的准确性和无偏性。

Method: 引入PersonaTwin框架，结合多源数据，并通过文本相似性指标和人口统计公平性评估进行系统评测。

Result: 实验显示PersonaTwin在模拟保真度上达到与真实数据相当的水平，下游模型在预测和公平性指标上接近真实用户数据。

Conclusion: PersonaTwin为个性化数字用户建模和行为分析提供了高效工具，展示了LLM数字孪生的潜力。

Abstract: While large language models (LLMs) afford new possibilities for user modeling
and approximation of human behaviors, they often fail to capture the
multidimensional nuances of individual users. In this work, we introduce
PersonaTwin, a multi-tier prompt conditioning framework that builds adaptive
digital twins by integrating demographic, behavioral, and psychometric data.
Using a comprehensive data set in the healthcare context of more than 8,500
individuals, we systematically benchmark PersonaTwin against standard LLM
outputs, and our rigorous evaluation unites state-of-the-art text similarity
metrics with dedicated demographic parity assessments, ensuring that generated
responses remain accurate and unbiased. Experimental results show that our
framework produces simulation fidelity on par with oracle settings. Moreover,
downstream models trained on persona-twins approximate models trained on
individuals in terms of prediction and fairness metrics across both
GPT-4o-based and Llama-based models. Together, these findings underscore the
potential for LLM digital twin-based approaches in producing realistic and
emotionally nuanced user simulations, offering a powerful tool for personalized
digital user modeling and behavior analysis.

</details>


### [21] [Rule2Text: A Framework for Generating and Evaluating Natural Language Explanations of Knowledge Graph Rules](https://arxiv.org/abs/2508.10971)
*Nasim Shirvani-Mahdavi,Chengkai Li*

Main category: cs.CL

Relevance: 75.0

TL;DR: Rule2Text框架利用LLM为知识图谱的逻辑规则生成自然语言解释，提升可解释性和可用性。实验验证了多种LLM和提示策略，并通过人机协同构建高质量数据集，微调后显著提升解释质量。


<details>
  <summary>Details</summary>
Motivation: 知识图谱的逻辑规则复杂且难以解释，Rule2Text旨在通过LLM生成自然语言解释，提高其可访问性和实用性。

Method: 使用多种LLM（如Gemini 2.0 Flash）和提示策略（零样本、少样本等）生成解释，并通过人机协同构建数据集微调Zephyr模型。

Result: 微调后解释质量显著提升，尤其在领域特定数据集中表现突出。LLM作为评估框架与人工评估一致。

Conclusion: Rule2Text有效提升知识图谱规则的可解释性，为缺乏类型信息的KG提供支持。

Abstract: Knowledge graphs (KGs) can be enhanced through rule mining; however, the
resulting logical rules are often difficult for humans to interpret due to
their inherent complexity and the idiosyncratic labeling conventions of
individual KGs. This work presents Rule2Text, a comprehensive framework that
leverages large language models (LLMs) to generate natural language
explanations for mined logical rules, thereby improving KG accessibility and
usability. We conduct extensive experiments using multiple datasets, including
Freebase variants (FB-CVT-REV, FB+CVT-REV, and FB15k-237) as well as the
ogbl-biokg dataset, with rules mined using AMIE 3.5.1. We systematically
evaluate several LLMs across a comprehensive range of prompting strategies,
including zero-shot, few-shot, variable type incorporation, and
Chain-of-Thought reasoning. To systematically assess models' performance, we
conduct a human evaluation of generated explanations on correctness and
clarity. To address evaluation scalability, we develop and validate an
LLM-as-a-judge framework that demonstrates strong agreement with human
evaluators. Leveraging the best-performing model (Gemini 2.0 Flash), LLM judge,
and human-in-the-loop feedback, we construct high-quality ground truth
datasets, which we use to fine-tune the open-source Zephyr model. Our results
demonstrate significant improvements in explanation quality after fine-tuning,
with particularly strong gains in the domain-specific dataset. Additionally, we
integrate a type inference module to support KGs lacking explicit type
information. All code and data are publicly available at
https://github.com/idirlab/KGRule2NL.

</details>


### [22] [Improving Text Style Transfer using Masked Diffusion Language Models with Inference-time Scaling](https://arxiv.org/abs/2508.10995)
*Tejomay Kishor Padole,Suyash P Awate,Pushpak Bhattacharyya*

Main category: cs.CL

Relevance: 75.0

TL;DR: 本文提出了一种基于验证器的推理时间缩放方法，用于改进掩码扩散语言模型（MDM）的生成质量，并在文本风格转换任务中验证了其优于自回归语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在离散数据生成中表现出色，但现有方法在推理时间缩放方面仍有改进空间。本文旨在通过验证器提升MDM的生成质量。

Method: 提出了一种基于验证器的推理时间缩放方法，结合预训练嵌入模型，优化MDM的生成过程。

Result: 实验表明，该方法在文本风格转换任务中显著提升了生成质量，且优于自回归语言模型。

Conclusion: MDM结合验证器是一种高效的离散数据生成框架，尤其在推理时间缩放方面表现优越。

Abstract: Masked diffusion language models (MDMs) have recently gained traction as a
viable generative framework for natural language. This can be attributed to its
scalability and ease of training compared to other diffusion model paradigms
for discrete data, establishing itself as the state-of-the-art
non-autoregressive generator for discrete data. Diffusion models, in general,
have shown excellent ability to improve the generation quality by leveraging
inference-time scaling either by increasing the number of denoising steps or by
using external verifiers on top of the outputs of each step to guide the
generation. In this work, we propose a verifier-based inference-time scaling
method that aids in finding a better candidate generation during the denoising
process of the MDM. Our experiments demonstrate the application of MDMs for
standard text-style transfer tasks and establish MDMs as a better alternative
to autoregressive language models. Additionally, we show that a simple
soft-value-based verifier setup for MDMs using off-the-shelf pre-trained
embedding models leads to significant gains in generation quality even when
used on top of typical classifier-free guidance setups in the existing
literature.

</details>


### [23] [AI in Mental Health: Emotional and Sentiment Analysis of Large Language Models' Responses to Depression, Anxiety, and Stress Queries](https://arxiv.org/abs/2508.11285)
*Arya VarastehNezhad,Reza Tavasoli,Soroush Elyasi,MohammadHossein LotfiNia,Hamed Farbeh*

Main category: cs.CL

Relevance: 75.0

TL;DR: 研究分析了八种LLM对抑郁、焦虑和压力问题的情感回应，发现模型选择和心理健康问题类型显著影响情感表达，而人口统计因素影响较小。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在心理健康信息提供中的情感表达差异，以指导模型选择。

Method: 对八种LLM生成的2,880个回答进行情感和情绪评分，分析模型、问题和用户画像的影响。

Result: 不同LLM情感表达差异显著，心理健康问题类型主导情感反应，人口统计因素影响有限。

Conclusion: 模型选择对心理健康应用至关重要，因其情感特征可能显著影响用户体验。

Abstract: Depression, anxiety, and stress are widespread mental health concerns that
increasingly drive individuals to seek information from Large Language Models
(LLMs). This study investigates how eight LLMs (Claude Sonnet, Copilot, Gemini
Pro, GPT-4o, GPT-4o mini, Llama, Mixtral, and Perplexity) reply to twenty
pragmatic questions about depression, anxiety, and stress when those questions
are framed for six user profiles (baseline, woman, man, young, old, and
university student). The models generated 2,880 answers, which we scored for
sentiment and emotions using state-of-the-art tools. Our analysis revealed that
optimism, fear, and sadness dominated the emotional landscape across all
outputs, with neutral sentiment maintaining consistently high values.
Gratitude, joy, and trust appeared at moderate levels, while emotions such as
anger, disgust, and love were rarely expressed. The choice of LLM significantly
influenced emotional expression patterns. Mixtral exhibited the highest levels
of negative emotions including disapproval, annoyance, and sadness, while Llama
demonstrated the most optimistic and joyful responses. The type of mental
health condition dramatically shaped emotional responses: anxiety prompts
elicited extraordinarily high fear scores (0.974), depression prompts generated
elevated sadness (0.686) and the highest negative sentiment, while
stress-related queries produced the most optimistic responses (0.755) with
elevated joy and trust. In contrast, demographic framing of queries produced
only marginal variations in emotional tone. Statistical analyses confirmed
significant model-specific and condition-specific differences, while
demographic influences remained minimal. These findings highlight the critical
importance of model selection in mental health applications, as each LLM
exhibits a distinct emotional signature that could significantly impact user
experience and outcomes.

</details>


### [24] [Online Anti-sexist Speech: Identifying Resistance to Gender Bias in Political Discourse](https://arxiv.org/abs/2508.11434)
*Aditi Dutta,Susan Banducci*

Main category: cs.CL

Relevance: 75.0

TL;DR: 研究探讨了大型语言模型（LLMs）在区分性别歧视与反性别歧视言论时的表现，发现模型易将反性别歧视言论误判为有害内容，尤其在政治敏感事件中。


<details>
  <summary>Details</summary>
Motivation: 自动化内容审核系统依赖LLMs，但可能无法准确区分性别歧视与反性别歧视言论，导致边缘化声音被压制。

Method: 分析了五个LLMs对英国政治推文的分类表现，聚焦2022年涉及女性议员的触发事件。

Result: 模型常将反性别歧视言论误判为有害，政治敏感事件中错误率更高。

Conclusion: 建议改进审核设计，包括非二元分类、人工审核及反言论训练数据。

Abstract: Anti-sexist speech, i.e., public expressions that challenge or resist
gendered abuse and sexism, plays a vital role in shaping democratic debate
online. Yet automated content moderation systems, increasingly powered by large
language models (LLMs), may struggle to distinguish such resistance from the
sexism it opposes. This study examines how five LLMs classify sexist,
anti-sexist, and neutral political tweets from the UK, focusing on
high-salience trigger events involving female Members of Parliament in the year
2022. Our analysis show that models frequently misclassify anti-sexist speech
as harmful, particularly during politically charged events where rhetorical
styles of harm and resistance converge. These errors risk silencing those who
challenge sexism, with disproportionate consequences for marginalised voices.
We argue that moderation design must move beyond binary harmful/not-harmful
schemas, integrate human-in-the-loop review during sensitive events, and
explicitly include counter-speech in training data. By linking feminist
scholarship, event-based analysis, and model evaluation, this work highlights
the sociotechnical challenges of safeguarding resistance speech in digital
political spaces.

</details>


### [25] [CoDiEmb: A Collaborative yet Distinct Framework for Unified Representation Learning in Information Retrieval and Semantic Textual Similarity](https://arxiv.org/abs/2508.11442)
*Bowen Zhang,Zixin Song,Chunquan Chen,Qian-Wen Zhang,Di Yin,Xing Sun*

Main category: cs.CL

Relevance: 75.0

TL;DR: CoDiEmb框架通过任务专用目标、动态采样器和模型融合策略，解决了信息检索（IR）和语义文本相似性（STS）联合训练中的负迁移问题。


<details>
  <summary>Details</summary>
Motivation: 联合训练IR和STS任务时，负迁移问题导致性能下降，需要系统化解耦任务特定信号以提高嵌入表示的统一性。

Method: 1) 任务专用目标与动态采样器；2) 基于参数偏差的模型融合策略；3) 高效单阶段训练流程。

Result: 在15个基准测试中验证了CoDiEmb的有效性，显著减少了跨任务性能折衷并优化了嵌入空间几何特性。

Conclusion: CoDiEmb通过创新设计成功解决了IR与STS联合训练的冲突，提升了嵌入表示的统一性和性能。

Abstract: Learning unified text embeddings that excel across diverse downstream tasks
is a central goal in representation learning, yet negative transfer remains a
persistent obstacle. This challenge is particularly pronounced when jointly
training a single encoder for Information Retrieval (IR) and Semantic Textual
Similarity (STS), two essential but fundamentally disparate tasks for which
naive co-training typically yields steep performance trade-offs. We argue that
resolving this conflict requires systematically decoupling task-specific
learning signals throughout the training pipeline. To this end, we introduce
CoDiEmb, a unified framework that reconciles the divergent requirements of IR
and STS in a collaborative yet distinct manner. CoDiEmb integrates three key
innovations for effective joint optimization: (1) Task-specialized objectives
paired with a dynamic sampler that forms single-task batches and balances
per-task updates, thereby preventing gradient interference. For IR, we employ a
contrastive loss with multiple positives and hard negatives, augmented by
cross-device sampling. For STS, we adopt order-aware objectives that directly
optimize correlation and ranking consistency. (2) A delta-guided model fusion
strategy that computes fine-grained merging weights for checkpoints by
analyzing each parameter's deviation from its pre-trained initialization,
proving more effective than traditional Model Soups. (3) An efficient,
single-stage training pipeline that is simple to implement and converges
stably. Extensive experiments on 15 standard IR and STS benchmarks across three
base encoders validate CoDiEmb. Our results and analysis demonstrate that the
framework not only mitigates cross-task trade-offs but also measurably improves
the geometric properties of the embedding space.

</details>


### [26] [Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models](https://arxiv.org/abs/2508.11534)
*Monika Jotautaitė,Lucius Caviola,David A. Brewster,Thilo Hagendorff*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文研究了大型语言模型（LLMs）是否表现出物种主义偏见，并评估其对非人类动物的道德态度。通过三个范式（基准测试、心理测量和文本生成任务），发现LLMs能识别物种主义言论但很少谴责，且在某些情况下优先人类而非动物。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，研究其伦理倾向（如物种主义偏见）对确保AI公平性和道德对齐至关重要。

Method: 采用三个范式：SpeciesismBench基准测试、心理测量比较模型与人类反应、文本生成任务探究模型对物种主义言论的态度。

Result: LLMs能识别物种主义言论但很少谴责，在心理测量中表现复杂，文本生成任务中常合理化对农场动物的伤害。

Conclusion: LLMs反映了人类主流观点中的物种主义倾向，需扩展AI公平性框架以涵盖非人类道德主体。

Abstract: As large language models (LLMs) become more widely deployed, it is crucial to
examine their ethical tendencies. Building on research on fairness and
discrimination in AI, we investigate whether LLMs exhibit speciesist bias --
discrimination based on species membership -- and how they value non-human
animals. We systematically examine this issue across three paradigms: (1)
SpeciesismBench, a 1,003-item benchmark assessing recognition and moral
evaluation of speciesist statements; (2) established psychological measures
comparing model responses with those of human participants; (3) text-generation
tasks probing elaboration on, or resistance to, speciesist rationalizations. In
our benchmark, LLMs reliably detected speciesist statements but rarely
condemned them, often treating speciesist attitudes as morally acceptable. On
psychological measures, results were mixed: LLMs expressed slightly lower
explicit speciesism than people, yet in direct trade-offs they more often chose
to save one human over multiple animals. A tentative interpretation is that
LLMs may weight cognitive capacity rather than species per se: when capacities
were equal, they showed no species preference, and when an animal was described
as more capable, they tended to prioritize it over a less capable human. In
open-ended text generation tasks, LLMs frequently normalized or rationalized
harm toward farmed animals while refusing to do so for non-farmed animals.
These findings suggest that while LLMs reflect a mixture of progressive and
mainstream human views, they nonetheless reproduce entrenched cultural norms
around animal exploitation. We argue that expanding AI fairness and alignment
frameworks to explicitly include non-human moral patients is essential for
reducing these biases and preventing the entrenchment of speciesist attitudes
in AI systems and the societies they influence.

</details>


### [27] [Personalized Distractor Generation via MCTS-Guided Reasoning Reconstruction](https://arxiv.org/abs/2508.11184)
*Tao Wu,Jingyuan Chen,Wang Lin,Jian Zhan,Mengze Li,Kun Kuang,Fei Wu*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文提出了一种个性化干扰项生成方法，通过蒙特卡洛树搜索（MCTS）从学生历史错误答案中恢复推理轨迹，生成针对个体误解的干扰项。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的干扰项生成方法无法捕捉个体学生的多样化推理错误，限制了诊断效果。

Method: 提出两阶段框架：1）用MCTS从历史错误答案构建学生特定误解原型；2）基于原型模拟学生推理生成个性化干扰项。

Result: 实验表明，该方法在140名学生中生成个性化干扰项效果最佳，并能推广到群体层面。

Conclusion: 该方法通过个性化干扰项生成提升教育评估的诊断效果，兼具鲁棒性和适应性。

Abstract: Distractors, incorrect but plausible answer choices in multiple-choice
questions (MCQs), play a critical role in educational assessment by diagnosing
student misconceptions. Recent work has leveraged large language models (LLMs)
to generate shared, group-level distractors by learning common error patterns
across large student populations. However, such distractors often fail to
capture the diverse reasoning errors of individual students, limiting their
diagnostic effectiveness. To address this limitation, we introduce the task of
personalized distractor generation, which aims to generate tailored distractors
based on individual misconceptions inferred from each student's past
question-answering (QA) records, ensuring every student receives options that
effectively exposes their specific reasoning errors. While promising, this task
is challenging because each student typically has only a few QA records, which
often lack the student's underlying reasoning processes, making training-based
group-level approaches infeasible. To overcome this, we propose a training-free
two-stage framework. In the first stage, we construct a student-specific
misconception prototype by applying Monte Carlo Tree Search (MCTS) to recover
the student's reasoning trajectories from past incorrect answers. In the second
stage, this prototype guides the simulation of the student's reasoning on new
questions, enabling the generation of personalized distractors that align with
the student's recurring misconceptions. Experiments show that our approach
achieves the best performance in generating plausible, personalized distractors
for 140 students, and also effectively generalizes to group-level settings,
highlighting its robustness and adaptability.

</details>


### [28] [Cross-Granularity Hypergraph Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2508.11247)
*Changjian Wang,Weihong Deng,Weili Guan,Quan Lu,Ning Jiang*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文提出了一种名为HGRAG的新型RAG方法，通过超图实现结构和语义信息的跨粒度整合，显著提升了多跳问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在多跳问答任务中因忽略知识的结构关联而效果有限，而GraphRAG方法又过度依赖结构信息。HGRAG旨在平衡结构和语义信息的利用。

Method: 构建实体超图，结合细粒度实体和粗粒度段落信息；设计超图检索方法，通过超图扩散整合语义和结构信息；使用检索增强模块优化结果。

Result: 在基准数据集上，HGRAG在问答性能上优于现有方法，检索效率提升6倍。

Conclusion: HGRAG通过超图实现了结构和语义的高效整合，为多跳问答任务提供了更优解决方案。

Abstract: Multi-hop question answering (MHQA) requires integrating knowledge scattered
across multiple passages to derive the correct answer. Traditional
retrieval-augmented generation (RAG) methods primarily focus on coarse-grained
textual semantic similarity and ignore structural associations among dispersed
knowledge, which limits their effectiveness in MHQA tasks. GraphRAG methods
address this by leveraging knowledge graphs (KGs) to capture structural
associations, but they tend to overly rely on structural information and
fine-grained word- or phrase-level retrieval, resulting in an underutilization
of textual semantics. In this paper, we propose a novel RAG approach called
HGRAG for MHQA that achieves cross-granularity integration of structural and
semantic information via hypergraphs. Structurally, we construct an entity
hypergraph where fine-grained entities serve as nodes and coarse-grained
passages as hyperedges, and establish knowledge association through shared
entities. Semantically, we design a hypergraph retrieval method that integrates
fine-grained entity similarity and coarse-grained passage similarity via
hypergraph diffusion. Finally, we employ a retrieval enhancement module, which
further refines the retrieved results both semantically and structurally, to
obtain the most relevant passages as context for answer generation with the
LLM. Experimental results on benchmark datasets demonstrate that our approach
outperforms state-of-the-art methods in QA performance, and achieves a
6$\times$ speedup in retrieval efficiency.

</details>


### [29] [ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection](https://arxiv.org/abs/2508.11281)
*Axel Delaval,Shujian Yang,Haicheng Wang,Han Qiu,Jialiang Lu*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文介绍了TOXIFRENCH，一个用于法语毒性内容检测的新基准数据集，并提出了一种基于动态加权损失的CoT微调策略，显著提升了小语言模型（SLMs）的性能。


<details>
  <summary>Details</summary>
Motivation: 法语毒性检测因缺乏大规模数据集而发展不足，需要一种高效且文化相关的方法。

Method: 构建TOXIFRENCH数据集（53,622条法语评论），采用半自动标注流程（10%人工标注）；提出动态加权损失的CoT微调策略。

Result: 微调的4B模型在F1分数上提升13%，超越GPT-40和Gemini-2.5；SLMs在鲁棒性和泛化性上优于大模型。

Conclusion: 该方法可扩展至多语言和安全性分类任务，SLMs在特定任务中表现优异。

Abstract: Detecting toxic content using language models is crucial yet challenging.
While substantial progress has been made in English, toxicity detection in
French remains underdeveloped, primarily due to the lack of culturally
relevant, large-scale datasets. In this work, we introduce TOXIFRENCH, a new
public benchmark of 53,622 French online comments, constructed via a
semi-automated annotation pipeline that reduces manual labeling to only 10%
through high-confidence LLM-based pre-annotation and human verification. Then,
we benchmark a broad range of models and uncover a counterintuitive insight:
Small Language Models (SLMs) outperform many larger models in robustness and
generalization under the toxicity detection task. Motivated by this finding, we
propose a novel Chain-of-Thought (CoT) fine-tuning strategy using a dynamic
weighted loss that progressively emphasizes the model's final decision,
significantly improving faithfulness. Our fine-tuned 4B model achieves
state-of-the-art performance, improving its F1 score by 13% over its baseline
and outperforming LLMs such as GPT-40 and Gemini-2.5. Further evaluation on a
cross-lingual toxicity benchmark demonstrates strong multilingual ability,
suggesting that our methodology can be effectively extended to other languages
and safety-critical classification tasks.

</details>


### [30] [HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor](https://arxiv.org/abs/2508.11429)
*Shivam Dubey*

Main category: cs.CL

Relevance: 70.0

TL;DR: HumorPlanSearch是一个模块化流程，通过上下文建模提升LLM生成的幽默质量，包括策略搜索、文化模板、知识图谱、新颖性过滤和迭代修订。实验显示其HGS评分显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成幽默时因缺乏上下文感知导致的重复或不合时宜的问题。

Method: 采用五步流程：Plan-Search、Humor Chain-of-Thought、知识图谱、新颖性过滤和迭代修订。

Result: 实验表明，完整流程（知识图谱+修订）将HGS评分提升15.4%。

Conclusion: HumorPlanSearch通过上下文建模显著提升了幽默生成的质量和适应性。

Abstract: Automated humor generation with Large Language Models (LLMs) often yields
jokes that feel generic, repetitive, or tone-deaf because humor is deeply
situated and hinges on the listener's cultural background, mindset, and
immediate context. We introduce HumorPlanSearch, a modular pipeline that
explicitly models context through: (1) Plan-Search for diverse, topic-tailored
strategies; (2) Humor Chain-of-Thought (HuCoT) templates capturing cultural and
stylistic reasoning; (3) a Knowledge Graph to retrieve and adapt
high-performing historical strategies; (4) novelty filtering via semantic
embeddings; and (5) an iterative judge-driven revision loop. To evaluate
context sensitivity and comedic quality, we propose the Humor Generation Score
(HGS), which fuses direct ratings, multi-persona feedback, pairwise win-rates,
and topic relevance. In experiments across nine topics with feedback from 13
human judges, our full pipeline (KG + Revision) boosts mean HGS by 15.4 percent
(p < 0.05) over a strong baseline. By foregrounding context at every stage from
strategy planning to multi-signal evaluation, HumorPlanSearch advances
AI-driven humor toward more coherent, adaptive, and culturally attuned comedy.

</details>


### [31] [Language models align with brain regions that represent concepts across modalities](https://arxiv.org/abs/2508.11536)
*Maria Ryskina,Greta Tuckute,Alexander Fung,Ashley Malkin,Evelina Fedorenko*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文研究了语言模型（LMs）与大脑对齐的关系，发现语言模型可能内部表征跨模态的概念意义。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型是否能够捕捉大脑中语言与概念意义的分离表征。

Method: 通过fMRI数据集，分析语言模型与大脑对齐的两个神经指标：句子处理时的大脑激活水平和跨模态输入的意义一致性。

Result: 语言模型在意义一致性更强的大脑区域预测信号更好，即使这些区域对语言处理不敏感。

Conclusion: 语言模型可能内部表征跨模态的概念意义。

Abstract: Cognitive science and neuroscience have long faced the challenge of
disentangling representations of language from representations of conceptual
meaning. As the same problem arises in today's language models (LMs), we
investigate the relationship between LM--brain alignment and two neural
metrics: (1) the level of brain activation during processing of sentences,
targeting linguistic processing, and (2) a novel measure of meaning consistency
across input modalities, which quantifies how consistently a brain region
responds to the same concept across paradigms (sentence, word cloud, image)
using an fMRI dataset (Pereira et al., 2018). Our experiments show that both
language-only and language-vision models predict the signal better in more
meaning-consistent areas of the brain, even when these areas are not strongly
sensitive to language processing, suggesting that LMs might internally
represent cross-modal conceptual meaning.

</details>


### [32] [Reference Points in LLM Sentiment Analysis: The Role of Structured Context](https://arxiv.org/abs/2508.11454)
*Junichiro Niimi*

Main category: cs.CL

Relevance: 65.0

TL;DR: 该研究探讨了在情感分析中，补充信息的内容和格式如何影响LLMs的表现，发现JSON格式提示优于自然语言提示，适用于资源受限的设备。


<details>
  <summary>Details</summary>
Motivation: 营销理论指出客户评价受多种因素影响，而现有研究仅基于文本分类情感。本研究旨在利用LLMs结合补充信息提升情感分析效果。

Method: 比较自然语言和JSON格式提示，使用轻量级3B参数模型，在Yelp的餐厅和夜生活类别上进行实验。

Result: JSON提示显著提升性能（Macro-F1提高1.6%-4%，RMSE降低9.1%-16%），且无需微调。

Conclusion: 结构化提示可使小模型达到竞争性表现，为大规模模型部署提供替代方案。

Abstract: Large language models (LLMs) are now widely used across many fields,
including marketing research. Sentiment analysis, in particular, helps firms
understand consumer preferences. While most NLP studies classify sentiment from
review text alone, marketing theories, such as prospect theory and
expectation--disconfirmation theory, point out that customer evaluations are
shaped not only by the actual experience but also by additional reference
points. This study therefore investigates how the content and format of such
supplementary information affect sentiment analysis using LLMs. We compare
natural language (NL) and JSON-formatted prompts using a lightweight 3B
parameter model suitable for practical marketing applications. Experiments on
two Yelp categories (Restaurant and Nightlife) show that the JSON prompt with
additional information outperforms all baselines without fine-tuning: Macro-F1
rises by 1.6% and 4% while RMSE falls by 16% and 9.1%, respectively, making it
deployable in resource-constrained edge devices. Furthermore, a follow-up
analysis confirms that performance gains stem from genuine contextual reasoning
rather than label proxying. This work demonstrates that structured prompting
can enable smaller models to achieve competitive performance, offering a
practical alternative to large-scale model deployment.

</details>


### [33] [Benchmarking Prosody Encoding in Discrete Speech Tokens](https://arxiv.org/abs/2508.11224)
*Kentaro Onda,Satoru Fukayama,Daisuke Saito,Nobuaki Minematsu*

Main category: cs.SD

Relevance: 65.0

TL;DR: 研究分析了离散令牌在语音语言模型中捕捉韵律信息的能力，并提出了设计离散令牌的实用指南。


<details>
  <summary>Details</summary>
Motivation: 离散令牌通常与语言模型或下游任务分开学习，导致离散化选择（如SSL模型或聚类数量）需启发式决定，且缺乏对韵律信息捕捉的研究。

Method: 通过分析离散令牌对人工修改韵律的敏感性，进行全面的韵律编码分析。

Result: 提供了设计离散令牌的实用指南。

Conclusion: 研究填补了离散令牌在韵律信息捕捉方面的研究空白，为相关设计提供了依据。

Abstract: Recently, discrete tokens derived from self-supervised learning (SSL) models
via k-means clustering have been actively studied as pseudo-text in speech
language models and as efficient intermediate representations for various
tasks. However, these discrete tokens are typically learned in advance,
separately from the training of language models or downstream tasks. As a
result, choices related to discretization, such as the SSL model used or the
number of clusters, must be made heuristically. In particular, speech language
models are expected to understand and generate responses that reflect not only
the semantic content but also prosodic features. Yet, there has been limited
research on the ability of discrete tokens to capture prosodic information. To
address this gap, this study conducts a comprehensive analysis focusing on
prosodic encoding based on their sensitivity to the artificially modified
prosody, aiming to provide practical guidelines for designing discrete tokens.

</details>


### [34] [Novel Parasitic Dual-Scale Modeling for Efficient and Accurate Multilingual Speech Translation](https://arxiv.org/abs/2508.11189)
*Chenyang Le,Yinfeng Xia,Huiyan Li,Manhong Wang,Yutao Sun,Xingyang Ma,Yanmin Qian*

Main category: cs.CL

Relevance: 60.0

TL;DR: 提出了一种创新的寄生双尺度方法（Parasitic Dual-Scale Approach），结合增强的推测采样、模型压缩和知识蒸馏技术，显著提升了多语言语音翻译模型的推理效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有统一的多语言语音翻译模型参数量大，难以平衡推理效率和性能，尤其是在本地部署场景中。

Method: 基于Whisper Medium模型，提出KVSPN模块，结合推测采样、模型压缩和知识蒸馏技术。

Result: 在六种流行语言上实现SOTA性能，推理速度提升40%（无BLEU下降），结合蒸馏方法后速度提升2.6倍且性能更优。

Conclusion: KVSPN模块显著提升了多语言语音翻译模型的效率和性能，适用于本地部署。

Abstract: Recent advancements in speech-to-text translation have led to the development
of multilingual models capable of handling multiple language pairs
simultaneously. However, these unified models often suffer from large parameter
sizes, making it challenging to balance inference efficiency and performance,
particularly in local deployment scenarios. We propose an innovative Parasitic
Dual-Scale Approach, which combines an enhanced speculative sampling method
with model compression and knowledge distillation techniques. Building on the
Whisper Medium model, we enhance it for multilingual speech translation into
whisperM2M, and integrate our novel KVSPN module, achieving state-of-the-art
(SOTA) performance across six popular languages with improved inference
efficiency. KVSPN enables a 40\% speedup with no BLEU score degradation.
Combined with distillation methods, it represents a 2.6$\times$ speedup over
the original Whisper Medium with superior performance.

</details>


### [35] [SGSimEval: A Comprehensive Multifaceted and Similarity-Enhanced Benchmark for Automatic Survey Generation Systems](https://arxiv.org/abs/2508.11310)
*Beichen Guo,Zhiyuan Wen,Yu Yang,Peng Gao,Ruosong Yang,Jiaxing Shen*

Main category: cs.CL

Relevance: 60.0

TL;DR: 论文提出SGSimEval，一个结合相似性增强评估的自动调查生成（ASG）综合基准，解决了现有评估方法的局限性，如偏见指标和过度依赖LLM作为评判。


<details>
  <summary>Details</summary>
Motivation: 现有自动调查生成（ASG）评估方法存在偏见、缺乏人类偏好和过度依赖LLM的问题，需要更全面的评估框架。

Method: 提出SGSimEval，整合大纲、内容和参考文献的评估，结合LLM评分与定量指标，并引入人类偏好指标。

Result: 实验显示当前ASG系统在大纲生成上表现接近人类水平，但在内容和参考文献生成上仍有改进空间，评估指标与人类判断一致。

Conclusion: SGSimEval为ASG提供了更全面的评估方法，强调了人类偏好的重要性。

Abstract: The growing interest in automatic survey generation (ASG), a task that
traditionally required considerable time and effort, has been spurred by recent
advances in large language models (LLMs). With advancements in
retrieval-augmented generation (RAG) and the rising popularity of multi-agent
systems (MASs), synthesizing academic surveys using LLMs has become a viable
approach, thereby elevating the need for robust evaluation methods in this
domain. However, existing evaluation methods suffer from several limitations,
including biased metrics, a lack of human preference, and an over-reliance on
LLMs-as-judges. To address these challenges, we propose SGSimEval, a
comprehensive benchmark for Survey Generation with Similarity-Enhanced
Evaluation that evaluates automatic survey generation systems by integrating
assessments of the outline, content, and references, and also combines
LLM-based scoring with quantitative metrics to provide a multifaceted
evaluation framework. In SGSimEval, we also introduce human preference metrics
that emphasize both inherent quality and similarity to humans. Extensive
experiments reveal that current ASG systems demonstrate human-comparable
superiority in outline generation, while showing significant room for
improvement in content and reference generation, and our evaluation metrics
maintain strong consistency with human assessments.

</details>


### [36] [Feedback Indicators: The Alignment between Llama and a Teacher in Language Learning](https://arxiv.org/abs/2508.11364)
*Sylvio Rüdian,Yassin Elsir,Marvin Kretschmer,Sabine Cayrou,Niels Pinkwart*

Main category: cs.CL

Relevance: 60.0

TL;DR: 论文探讨了使用Llama 3.1大语言模型从学生提交的语言学习课程中提取反馈指标的方法，并验证了这些指标与人工评分的强相关性。


<details>
  <summary>Details</summary>
Motivation: 自动化反馈生成可以提升学生学习效率，帮助教师优化时间分配。提取高质量的反馈指标是实现这一目标的关键。

Method: 使用Llama 3.1大语言模型从学生提交中提取反馈指标，并分析其与人工评分的相关性。

Result: 研究发现LLM生成的指标与人工评分具有显著的强相关性，即使在复杂情况下也表现良好。

Conclusion: 该方法为未来利用LLM生成透明、可解释的自动化反馈提供了基础。

Abstract: Automated feedback generation has the potential to enhance students' learning
progress by providing timely and targeted feedback. Moreover, it can assist
teachers in optimizing their time, allowing them to focus on more strategic and
personalized aspects of teaching. To generate high-quality, information-rich
formative feedback, it is essential first to extract relevant indicators, as
these serve as the foundation upon which the feedback is constructed. Teachers
often employ feedback criteria grids composed of various indicators that they
evaluate systematically. This study examines the initial phase of extracting
such indicators from students' submissions of a language learning course using
the large language model Llama 3.1. Accordingly, the alignment between
indicators generated by the LLM and human ratings across various feedback
criteria is investigated. The findings demonstrate statistically significant
strong correlations, even in cases involving unanticipated combinations of
indicators and criteria. The methodology employed in this paper offers a
promising foundation for extracting indicators from students' submissions using
LLMs. Such indicators can potentially be utilized to auto-generate explainable
and transparent formative feedback in future research.

</details>


### [37] [A2HCoder: An LLM-Driven Coding Agent for Hierarchical Algorithm-to-HDL Translation](https://arxiv.org/abs/2508.10904)
*Jie Lei,Ruofan Jia,J. Andrew Zhang,Hao Zhang*

Main category: cs.CL

Relevance: 40.0

TL;DR: A2HCoder是一个基于LLM的分层算法到HDL编码代理，旨在解决算法设计与硬件实现之间的鸿沟，通过模块化和逐步翻译提高可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统对超低延迟和功耗的需求增加了算法到硬件部署的效率需求，但传统方法需要大量领域知识和手动开发。

Method: A2HCoder采用分层框架，水平维度分解算法为模块，垂直维度逐步翻译，结合外部工具链调试和合成。

Result: 在5G无线通信领域的实际部署中验证了A2HCoder的实用性、可靠性和效率。

Conclusion: A2HCoder通过结构化的方法显著减少了LLM生成的代码中的幻觉问题，并确保了硬件级别的正确性。

Abstract: In wireless communication systems, stringent requirements such as ultra-low
latency and power consumption have significantly increased the demand for
efficient algorithm-to-hardware deployment. However, a persistent and
substantial gap remains between algorithm design and hardware implementation.
Bridging this gap traditionally requires extensive domain expertise and
time-consuming manual development, due to fundamental mismatches between
high-level programming languages like MATLAB and hardware description languages
(HDLs) such as Verilog-in terms of memory access patterns, data processing
manners, and datatype representations. To address this challenge, we propose
A2HCoder: a Hierarchical Algorithm-to-HDL Coding Agent, powered by large
language models (LLMs), designed to enable agile and reliable
algorithm-to-hardware translation. A2HCoder introduces a hierarchical framework
that enhances both robustness and interpretability while suppressing common
hallucination issues in LLM-generated code. In the horizontal dimension,
A2HCoder decomposes complex algorithms into modular functional blocks,
simplifying code generation and improving consistency. In the vertical
dimension, instead of relying on end-to-end generation, A2HCoder performs
step-by-step, fine-grained translation, leveraging external toolchains such as
MATLAB and Vitis HLS for debugging and circuit-level synthesis. This structured
process significantly mitigates hallucinations and ensures hardware-level
correctness. We validate A2HCoder through a real-world deployment case in the
5G wireless communication domain, demonstrating its practicality, reliability,
and deployment efficiency.

</details>


### [38] [Modeling and Detecting Company Risks from News: A Case Study in Bloomberg News](https://arxiv.org/abs/2508.10927)
*Jiaxin Pei,Soumya Vadlamannati,Liang-Kang Huang,Daniel Preotiuc-Pietro,Xinyu Hua*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文提出了一种从新闻中自动提取公司风险因素的计算框架，并比较了不同机器学习模型的表现，发现微调的预训练模型优于零样本或少样本提示的LLM。


<details>
  <summary>Details</summary>
Motivation: 识别公司风险对投资者和金融市场至关重要，但现有方法可能不够高效或准确。

Method: 提出七类风险因素的新模式，标注744篇新闻，测试多种模型（包括LLM和微调模型）。

Result: 微调模型表现优于LLM（如LLaMA-2），分析27.7万篇新闻展示了方法的实用性。

Conclusion: 从新闻中提取风险因素能为公司和行业运营提供深入洞察，微调模型更有效。

Abstract: Identifying risks associated with a company is important to investors and the
well-being of the overall financial market. In this study, we build a
computational framework to automatically extract company risk factors from news
articles. Our newly proposed schema comprises seven distinct aspects, such as
supply chain, regulations, and competitions. We sample and annotate 744 news
articles and benchmark various machine learning models. While large language
models have achieved huge progress in various types of NLP tasks, our
experiment shows that zero-shot and few-shot prompting state-of-the-art LLMs
(e.g. LLaMA-2) can only achieve moderate to low performances in identifying
risk factors. And fine-tuned pre-trained language models are performing better
on most of the risk factors. Using this model, we analyze over 277K Bloomberg
news articles and demonstrate that identifying risk factors from news could
provide extensive insight into the operations of companies and industries.

</details>


### [39] [Approaching the Source of Symbol Grounding with Confluent Reductions of Abstract Meaning Representation Directed Graphs](https://arxiv.org/abs/2508.11068)
*Nicolas Goulet,Alexandre Blondin Massé,Moussa Abdendi*

Main category: cs.CL

Relevance: 40.0

TL;DR: 该论文探讨了如何将数字词典嵌入到抽象意义表示（AMR）有向图中，利用预训练大语言模型，并通过保形变换简化图结构，最后分析其与符号接地问题的关系。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过AMR有向图结合大语言模型，探索数字词典的语义表示及其简化方法，以解决符号接地问题。

Method: 使用预训练大语言模型将数字词典嵌入AMR有向图，通过保形变换简化图结构。

Result: 简化后的有向图保留了电路空间特性，并与符号接地问题相关。

Conclusion: 该方法为语义表示和符号接地问题提供了新视角。

Abstract: Abstract meaning representation (AMR) is a semantic formalism used to
represent the meaning of sentences as directed acyclic graphs. In this paper,
we describe how real digital dictionaries can be embedded into AMR directed
graphs (digraphs), using state-of-the-art pre-trained large language models.
Then, we reduce those graphs in a confluent manner, i.e. with transformations
that preserve their circuit space. Finally, the properties of these reduces
digraphs are analyzed and discussed in relation to the symbol grounding
problem.

</details>


### [40] [E-CaTCH: Event-Centric Cross-Modal Attention with Temporal Consistency and Class-Imbalance Handling for Misinformation Detection](https://arxiv.org/abs/2508.11197)
*Ahmad Mousavi,Yeganeh Abdollahinejad,Roberto Corizzo,Nathalie Japkowicz,Zois Boukouvalas*

Main category: cs.CL

Relevance: 40.0

TL;DR: E-CaTCH是一个可解释且可扩展的框架，用于检测社交媒体上的多模态虚假信息，通过聚类、跨模态对齐和时间建模提升性能。


<details>
  <summary>Details</summary>
Motivation: 检测多模态虚假信息因模态不一致、时间模式变化和类别不平衡而具有挑战性，现有方法未能捕捉事件级结构。

Method: E-CaTCH通过聚类、BERT和ResNet特征提取、跨模态注意力对齐、趋势感知LSTM建模时间演化，并结合自适应损失策略。

Result: 在多个数据集上优于现有方法，表现出鲁棒性和泛化能力。

Conclusion: E-CaTCH为虚假信息检测提供了高效且通用的解决方案。

Abstract: Detecting multimodal misinformation on social media remains challenging due
to inconsistencies between modalities, changes in temporal patterns, and
substantial class imbalance. Many existing methods treat posts independently
and fail to capture the event-level structure that connects them across time
and modality. We propose E-CaTCH, an interpretable and scalable framework for
robustly detecting misinformation. If needed, E-CaTCH clusters posts into
pseudo-events based on textual similarity and temporal proximity, then
processes each event independently. Within each event, textual and visual
features are extracted using pre-trained BERT and ResNet encoders, refined via
intra-modal self-attention, and aligned through bidirectional cross-modal
attention. A soft gating mechanism fuses these representations to form
contextualized, content-aware embeddings of each post. To model temporal
evolution, E-CaTCH segments events into overlapping time windows and uses a
trend-aware LSTM, enhanced with semantic shift and momentum signals, to encode
narrative progression over time. Classification is performed at the event
level, enabling better alignment with real-world misinformation dynamics. To
address class imbalance and promote stable learning, the model integrates
adaptive class weighting, temporal consistency regularization, and hard-example
mining. The total loss is aggregated across all events. Extensive experiments
on Fakeddit, IND, and COVID-19 MISINFOGRAPH demonstrate that E-CaTCH
consistently outperforms state-of-the-art baselines. Cross-dataset evaluations
further demonstrate its robustness, generalizability, and practical
applicability across diverse misinformation scenarios.

</details>


### [41] [AgentMental: An Interactive Multi-Agent Framework for Explainable and Adaptive Mental Health Assessment](https://arxiv.org/abs/2508.11567)
*Jinpeng Hu,Ao Wang,Qianqian Xie,Hui Ma,Zhuo Li,Dan Guo*

Main category: cs.CL

Relevance: 40.0

TL;DR: 提出了一种基于多代理框架的心理健康评估方法，模拟医患对话，通过自适应提问和树状记忆结构提升评估效果。


<details>
  <summary>Details</summary>
Motivation: 传统心理健康评估依赖专业人员且静态文本分析能力有限，需动态交互方法。

Method: 多代理框架模拟医患对话，自适应提问机制和树状记忆结构动态更新信息。

Result: 在DAIC-WOZ数据集上表现优于现有方法。

Conclusion: 该方法通过动态交互和记忆结构提升了心理健康评估的准确性和效率。

Abstract: Mental health assessment is crucial for early intervention and effective
treatment, yet traditional clinician-based approaches are limited by the
shortage of qualified professionals. Recent advances in artificial intelligence
have sparked growing interest in automated psychological assessment, yet most
existing approaches are constrained by their reliance on static text analysis,
limiting their ability to capture deeper and more informative insights that
emerge through dynamic interaction and iterative questioning. Therefore, in
this paper, we propose a multi-agent framework for mental health evaluation
that simulates clinical doctor-patient dialogues, with specialized agents
assigned to questioning, adequacy evaluation, scoring, and updating. We
introduce an adaptive questioning mechanism in which an evaluation agent
assesses the adequacy of user responses to determine the necessity of
generating targeted follow-up queries to address ambiguity and missing
information. Additionally, we employ a tree-structured memory in which the root
node encodes the user's basic information, while child nodes (e.g., topic and
statement) organize key information according to distinct symptom categories
and interaction turns. This memory is dynamically updated throughout the
interaction to reduce redundant questioning and further enhance the information
extraction and contextual tracking capabilities. Experimental results on the
DAIC-WOZ dataset illustrate the effectiveness of our proposed method, which
achieves better performance than existing approaches.

</details>


### [42] [Representing Speech Through Autoregressive Prediction of Cochlear Tokens](https://arxiv.org/abs/2508.11598)
*Greta Tuckute,Klemen Kotar,Evelina Fedorenko,Daniel L. K. Yamins*

Main category: cs.CL

Relevance: 40.0

TL;DR: AuriStream是一个受生物启发的两阶段语音编码模型，模拟人类听觉处理层次结构，在语音表示学习和任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发更接近人类听觉处理的语音模型，以高效处理多种语音任务。

Method: 两阶段框架：1）将原始音频转换为基于人类耳蜗的时频表示，提取离散的耳蜗标记；2）对耳蜗标记应用自回归序列模型。

Result: 在SUPERB语音任务中表现优异，能够生成可解码的音频延续，提供模型预测的可视化洞察。

Conclusion: AuriStream为语音表示学习提供了一个高效且接近人类听觉的框架。

Abstract: We introduce AuriStream, a biologically inspired model for encoding speech
via a two-stage framework inspired by the human auditory processing hierarchy.
The first stage transforms raw audio into a time-frequency representation based
on the human cochlea, from which we extract discrete \textbf{cochlear tokens}.
The second stage applies an autoregressive sequence model over the cochlear
tokens. AuriStream learns meaningful phoneme and word representations, and
state-of-the-art lexical semantics. AuriStream shows competitive performance on
diverse downstream SUPERB speech tasks. Complementing AuriStream's strong
representational capabilities, it generates continuations of audio which can be
visualized in a spectrogram space and decoded back into audio, providing
insights into the model's predictions. In summary, we present a two-stage
framework for speech representation learning to advance the development of more
human-like models that efficiently handle a range of speech-based tasks.

</details>


### [43] [TinyTim: A Family of Language Models for Divergent Generation](https://arxiv.org/abs/2508.11607)
*Christopher J. Agostino*

Main category: cs.CL

Relevance: 40.0

TL;DR: TinyTim是一个基于James Joyce的《Finnegans Wake》微调的大型语言模型家族，其生成文本具有高词汇多样性和低语义连贯性。


<details>
  <summary>Details</summary>
Motivation: 探索专门化语言模型在创造性架构中作为发散知识源的潜力。

Method: 通过定量评估对比基线模型，分析TinyTim V1的生成特性。

Result: TinyTim V1生成文本具有高词汇多样性和低语义连贯性。

Conclusion: 此类专门化模型可作为创造性架构中的发散知识源，支持自动化发现机制。

Abstract: This work introduces TinyTim, a family of large language models fine-tuned on
James Joyce's `Finnegans Wake'. Through quantitative evaluation against
baseline models, we demonstrate that TinyTim V1 produces a statistically
distinct generative profile characterized by high lexical diversity and low
semantic coherence. These findings are interpreted through theories of
creativity and complex problem-solving, arguing that such specialized models
can function as divergent knowledge sources within more extensive creative
architectures, powering automated discovery mechanisms in diverse settings.

</details>


### [44] [The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval from Complex Structured Academic Papers](https://arxiv.org/abs/2506.20844)
*Xingyu Deng,Xi Wang,Mark Stevenson*

Main category: cs.IR

Relevance: 40.0

TL;DR: 本文探讨了科学事实核查的复杂性，提出了现有方法的局限性，并提出了改进方向，包括证据检索、时间感知、结构化解析等。


<details>
  <summary>Details</summary>
Motivation: 科学事实核查比一般事实核查更复杂，现有方法简化了问题，忽略了完整文档处理的挑战。本文旨在揭示这些挑战并提出改进方案。

Method: 分析了现有系统的局限性，提出了五个关键研究挑战，并通过初步实验验证。

Result: 揭示了科学事实核查的潜在特征和资源，为开发专门的信息检索系统提供了方向。

Conclusion: 科学事实核查需要专门的信息检索系统以应对复杂性和实际应用需求。

Abstract: Scientific fact-checking aims to determine the veracity of scientific claims
by retrieving and analysing evidence from research literature. The problem is
inherently more complex than general fact-checking since it must accommodate
the evolving nature of scientific knowledge, the structural complexity of
academic literature and the challenges posed by long-form, multimodal
scientific expression. However, existing approaches focus on simplified
versions of the problem based on small-scale datasets consisting of abstracts
rather than full papers, thereby avoiding the distinct challenges associated
with processing complete documents. This paper examines the limitations of
current scientific fact-checking systems and reveals the many potential
features and resources that could be exploited to advance their performance. It
identifies key research challenges within evidence retrieval, including (1)
evidence-driven retrieval that addresses semantic limitations and topic
imbalance (2) time-aware evidence retrieval with citation tracking to mitigate
outdated information, (3) structured document parsing to leverage long-range
context, (4) handling complex scientific expressions, including tables,
figures, and domain-specific terminology and (5) assessing the credibility of
scientific literature. Preliminary experiments were conducted to substantiate
these challenges and identify potential solutions. This perspective paper aims
to advance scientific fact-checking with a specialised IR system tailored for
real-world applications.

</details>


### [45] [PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing](https://arxiv.org/abs/2508.11116)
*Zhuoqun Li,Xuanang Chen,Hongyu Lin,Yaojie Lu,Xianpei Han,Le Sun*

Main category: cs.IR

Relevance: 40.0

TL;DR: PaperRegister提出了一种分层索引和自适应检索的方法，支持灵活粒度的论文搜索，优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 传统论文搜索系统仅基于摘要索引，无法满足灵活粒度的搜索需求。

Method: 采用离线分层索引和在线自适应检索，构建分层索引树。

Result: 在多种粒度搜索任务中表现最优，尤其在细粒度场景下表现突出。

Conclusion: PaperRegister是解决灵活粒度论文搜索的有效方案。

Abstract: Paper search is an important activity for researchers, typically involving
using a query with description of a topic to find relevant papers. As research
deepens, paper search requirements may become more flexible, sometimes
involving specific details such as module configuration rather than being
limited to coarse-grained topics. However, previous paper search systems are
unable to meet these flexible-grained requirements, as these systems mainly
collect paper abstracts to construct index of corpus, which lack detailed
information to support retrieval by finer-grained queries. In this work, we
propose PaperRegister, consisted of offline hierarchical indexing and online
adaptive retrieval, transforming traditional abstract-based index into
hierarchical index tree for paper search, thereby supporting queries at
flexible granularity. Experiments on paper search tasks across a range of
granularity demonstrate that PaperRegister achieves the state-of-the-art
performance, and particularly excels in fine-grained scenarios, highlighting
the good potential as an effective solution for flexible-grained paper search
in real-world applications. Code for this work is in
https://github.com/Li-Z-Q/PaperRegister.

</details>


### [46] [+VeriRel: Verification Feedback to Enhance Document Retrieval for Scientific Fact Checking](https://arxiv.org/abs/2508.11122)
*Xingyu Deng,Xi Wang,Mark Stevenson*

Main category: cs.IR

Relevance: 40.0

TL;DR: 论文提出+VeriRel方法，将验证成功纳入文档排名，提升科学事实检查的证据检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖通用信息检索算法，仅基于相关性排名文档，而非其支持或反驳证据。

Method: 提出+VeriRel方法，将验证成功纳入文档排名。

Result: 在三个科学事实检查数据集上表现领先，对下游验证有积极影响。

Conclusion: 验证反馈可提升文档相关性评估，为科学事实检查系统提供潜力。

Abstract: Identification of appropriate supporting evidence is critical to the success
of scientific fact checking. However, existing approaches rely on off-the-shelf
Information Retrieval algorithms that rank documents based on relevance rather
than the evidence they provide to support or refute the claim being checked.
This paper proposes +VeriRel which includes verification success in the
document ranking. Experimental results on three scientific fact checking
datasets (SciFact, SciFact-Open and Check-Covid) demonstrate consistently
leading performance by +VeriRel for document evidence retrieval and a positive
impact on downstream verification. This study highlights the potential of
integrating verification feedback to document relevance assessment for
effective scientific fact checking systems. It shows promising future work to
evaluate fine-grained relevance when examining complex documents for advanced
scientific fact checking.

</details>


### [47] [Expressive Speech Retrieval using Natural Language Descriptions of Speaking Style](https://arxiv.org/abs/2508.11187)
*Wonjune Kang,Deb Roy*

Main category: eess.AS

Relevance: 40.0

TL;DR: 论文提出了一种基于自然语言描述的语音风格检索任务，通过联合嵌入空间实现语音和文本的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注语音内容的检索，而本文旨在通过语音风格进行检索。

Method: 训练语音和文本编码器，将语音和文本描述嵌入到联合潜在空间，支持自由文本查询。

Result: 在包含22种语音风格的多数据集上，方法在Recall@k指标上表现优异。

Conclusion: 该方法实现了基于语音风格的高效检索，为跨模态对齐提供了新思路。

Abstract: We introduce the task of expressive speech retrieval, where the goal is to
retrieve speech utterances spoken in a given style based on a natural language
description of that style. While prior work has primarily focused on performing
speech retrieval based on what was said in an utterance, we aim to do so based
on how something was said. We train speech and text encoders to embed speech
and text descriptions of speaking styles into a joint latent space, which
enables using free-form text prompts describing emotions or styles as queries
to retrieve matching expressive speech segments. We perform detailed analyses
of various aspects of our proposed framework, including encoder architectures,
training criteria for effective cross-modal alignment, and prompt augmentation
for improved generalization to arbitrary text queries. Experiments on multiple
datasets encompassing 22 speaking styles demonstrate that our approach achieves
strong retrieval performance as measured by Recall@k.

</details>


### [48] [Emphasis Sensitivity in Speech Representations](https://arxiv.org/abs/2508.11566)
*Shaun Cassini,Thomas Hain,Anton Ragni*

Main category: eess.AS

Relevance: 40.0

TL;DR: 论文研究了现代语音模型是否对韵律重音敏感，提出了一种基于残差的框架来分析重音编码方式。


<details>
  <summary>Details</summary>
Motivation: 探讨语音模型如何系统性地编码重音与非重音单词，弥补现有方法忽略重音关系结构的不足。

Method: 提出残差框架，将重音定义为中性词与重音词表征的差异，并在自监督语音模型和ASR微调模型中进行分析。

Result: 残差与持续时间变化强相关，且在词身份预测中表现差；ASR微调模型的残差子空间更紧凑，表明重音编码为一致的低维变换。

Conclusion: 语音模型以结构化、关系化的方式编码韵律重音，任务特定学习使其更结构化。

Abstract: This work investigates whether modern speech models are sensitive to prosodic
emphasis - whether they encode emphasized and neutral words in systematically
different ways. Prior work typically relies on isolated acoustic correlates
(e.g., pitch, duration) or label prediction, both of which miss the relational
structure of emphasis. This paper proposes a residual-based framework, defining
emphasis as the difference between paired neutral and emphasized word
representations. Analysis on self-supervised speech models shows that these
residuals correlate strongly with duration changes and perform poorly at word
identity prediction, indicating a structured, relational encoding of prosodic
emphasis. In ASR fine-tuned models, residuals occupy a subspace up to 50% more
compact than in pre-trained models, further suggesting that emphasis is encoded
as a consistent, low-dimensional transformation that becomes more structured
with task-specific learning.

</details>


### [49] [Overcoming Low-Resource Barriers in Tulu: Neural Models and Corpus Creation for OffensiveLanguage Identification](https://arxiv.org/abs/2508.11166)
*Anusha M D,Deepthi Vikram,Bharathi Raja Chakravarthi,Parameshwar R Hegde*

Main category: cs.CL

Relevance: 30.0

TL;DR: 论文提出了首个针对低资源德拉维达语Tulu的社交媒体混合代码攻击性语言识别（OLI）基准数据集，评估了多种深度学习模型，发现BiGRU表现最佳，而多语言预训练模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: Tulu作为一种低资源语言，缺乏计算资源，但其数字存在日益增长，因此需要建立基准数据集以支持相关NLP研究。

Method: 收集并标注了3,845条YouTube评论，分为四类，评估了GRU、LSTM、BiGRU、BiLSTM、CNN、注意力机制变体及Transformer模型（mBERT、XLM-RoBERTa）。

Result: BiGRU模型表现最佳（82%准确率，0.81宏F1分数），Transformer模型表现较差。

Conclusion: 多语言预训练在混合代码低资源语境中存在局限性，为Tulu及类似语言的NLP研究奠定了基础。

Abstract: Tulu, a low-resource Dravidian language predominantly spoken in southern
India, has limited computational resources despite its growing digital
presence. This study presents the first benchmark dataset for Offensive
Language Identification (OLI) in code-mixed Tulu social media content,
collected from YouTube comments across various domains. The dataset, annotated
with high inter-annotator agreement (Krippendorff's alpha = 0.984), includes
3,845 comments categorized into four classes: Not Offensive, Not Tulu,
Offensive Untargeted, and Offensive Targeted. We evaluate a suite of deep
learning models, including GRU, LSTM, BiGRU, BiLSTM, CNN, and attention-based
variants, alongside transformer architectures (mBERT, XLM-RoBERTa). The BiGRU
model with self-attention achieves the best performance with 82% accuracy and a
0.81 macro F1-score. Transformer models underperform, highlighting the
limitations of multilingual pretraining in code-mixed, under-resourced
contexts. This work lays the foundation for further NLP research in Tulu and
similar low-resource, code-mixed languages.

</details>


### [50] [Dataset Creation for Visual Entailment using Generative AI](https://arxiv.org/abs/2508.11605)
*Rob Reijtenbach,Suzan Verberne,Gijs Wijnholds*

Main category: cs.CL

Relevance: 30.0

TL;DR: 论文提出了一种基于SNLI文本数据集生成视觉蕴含合成数据的方法，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉蕴含数据集规模小且稀疏，手工创建成本高，因此探索合成数据的可行性。

Method: 利用Stable Diffusion生成图像替换SNLI中的文本前提，构建合成数据集，并通过CLIP特征向量训练视觉蕴含分类器进行评估。

Result: 合成数据在SNLI-VE和SICK-VTE数据集上仅导致轻微性能下降（F-score分别从0.703降至0.686和0.400降至0.384）。

Conclusion: 在数据稀疏场景下，合成数据是训练视觉蕴含模型的有效替代方案。

Abstract: In this paper we present and validate a new synthetic dataset for training
visual entailment models. Existing datasets for visual entailment are small and
sparse compared to datasets for textual entailment. Manually creating datasets
is labor-intensive. We base our synthetic dataset on the SNLI dataset for
textual entailment. We take the premise text from SNLI as input prompts in a
generative image model, Stable Diffusion, creating an image to replace each
textual premise. We evaluate our dataset both intrinsically and extrinsically.
For extrinsic evaluation, we evaluate the validity of the generated images by
using them as training data for a visual entailment classifier based on CLIP
feature vectors. We find that synthetic training data only leads to a slight
drop in quality on SNLI-VE, with an F-score 0.686 compared to 0.703 when
trained on real data. We also compare the quality of our generated training
data to original training data on another dataset: SICK-VTE. Again, there is
only a slight drop in F-score: from 0.400 to 0.384. These results indicate that
in settings with data sparsity, synthetic data can be a promising solution for
training visual entailment models.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [51] [Empowering Multimodal LLMs with External Tools: A Comprehensive Survey](https://arxiv.org/abs/2508.10955)
*Wenbin An,Jiahao Nie,Yaqiang Wu,Feng Tian,Shijian Lu,Qinghua Zheng*

Main category: cs.CV

Relevance: 85.0

TL;DR: 该论文综述了如何通过外部工具（如API、专家模型和知识库）增强多模态大语言模型（MLLMs）的性能，重点关注数据获取、任务性能提升、评估方法改进及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在多模态任务中表现出色，但数据质量、任务性能不足和评估协议不完善限制了其可靠性和广泛应用。受人类利用外部工具增强推理能力的启发，论文探讨了工具增强MLLMs的潜力。

Method: 通过四个维度分析外部工具的作用：高质量数据获取与标注、复杂任务性能提升、全面评估方法改进、当前局限与未来方向。

Result: 论文总结了工具增强MLLMs的潜在优势，并提出了未来发展的前瞻性视角。

Conclusion: 外部工具对提升MLLMs能力具有变革性潜力，需进一步探索其开发与应用。

Abstract: By integrating the perception capabilities of multimodal encoders with the
generative power of Large Language Models (LLMs), Multimodal Large Language
Models (MLLMs), exemplified by GPT-4V, have achieved great success in various
multimodal tasks, pointing toward a promising pathway to artificial general
intelligence. Despite this progress, the limited quality of multimodal data,
poor performance on many complex downstream tasks, and inadequate evaluation
protocols continue to hinder the reliability and broader applicability of MLLMs
across diverse domains. Inspired by the human ability to leverage external
tools for enhanced reasoning and problem-solving, augmenting MLLMs with
external tools (e.g., APIs, expert models, and knowledge bases) offers a
promising strategy to overcome these challenges. In this paper, we present a
comprehensive survey on leveraging external tools to enhance MLLM performance.
Our discussion is structured along four key dimensions about external tools:
(1) how they can facilitate the acquisition and annotation of high-quality
multimodal data; (2) how they can assist in improving MLLM performance on
challenging downstream tasks; (3) how they enable comprehensive and accurate
evaluation of MLLMs; (4) the current limitations and future directions of
tool-augmented MLLMs. Through this survey, we aim to underscore the
transformative potential of external tools in advancing MLLM capabilities,
offering a forward-looking perspective on their development and applications.
The project page of this paper is publicly available
athttps://github.com/Lackel/Awesome-Tools-for-MLLMs.

</details>


### [52] [Controlling Multimodal LLMs via Reward-guided Decoding](https://arxiv.org/abs/2508.11616)
*Oscar Mañas,Pierluca D'Oro,Koustuv Sinha,Adriana Romero-Soriano,Michal Drozdzal,Aishwarya Agrawal*

Main category: cs.CV

Relevance: 85.0

TL;DR: 论文提出了一种通过奖励引导解码的方法，用于多模态大语言模型（MLLMs）的视觉接地任务，实现了对模型推理过程的动态控制。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs的广泛应用，如何根据用户需求动态调整模型行为变得尤为重要。

Method: 构建了两个独立的奖励模型，分别控制对象精确度和召回率，并通过奖励引导解码实现动态控制。

Result: 在标准对象幻觉基准测试中，该方法显著优于现有方法，并提供了更高的可控性。

Conclusion: 该方法为MLLMs的推理过程提供了灵活的控制手段，同时提升了视觉接地的性能。

Abstract: As Multimodal Large Language Models (MLLMs) gain widespread applicability, it
is becoming increasingly desirable to adapt them for diverse user needs. In
this paper, we study the adaptation of MLLMs through controlled decoding. To
achieve this, we introduce the first method for reward-guided decoding of MLLMs
and demonstrate its application in improving their visual grounding. Our method
involves building reward models for visual grounding and using them to guide
the MLLM's decoding process. Concretely, we build two separate reward models to
independently control the degree of object precision and recall in the model's
output. Our approach enables on-the-fly controllability of an MLLM's inference
process in two ways: first, by giving control over the relative importance of
each reward function during decoding, allowing a user to dynamically trade off
object precision for recall in image captioning tasks; second, by giving
control over the breadth of the search during decoding, allowing the user to
control the trade-off between the amount of test-time compute and the degree of
visual grounding. We evaluate our method on standard object hallucination
benchmarks, showing that it provides significant controllability over MLLM
inference, while consistently outperforming existing hallucination mitigation
methods.

</details>


### [53] [Failures to Surface Harmful Contents in Video Large Language Models](https://arxiv.org/abs/2508.10974)
*Yuxin Cao,Wei Song,Derui Wang,Jingling Xue,Jin Song Dong*

Main category: cs.MM

Relevance: 85.0

TL;DR: 论文揭示了当前视频大语言模型（VideoLLMs）在生成视频摘要时存在安全漏洞，容易忽略有害内容，并提出三种零查询黑盒攻击方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是发现VideoLLMs在关键应用中可能忽略有害内容，导致安全隐患。

Method: 通过分析设计缺陷（稀疏帧采样、空间信息丢失、编码器-解码器脱节），提出三种攻击方法。

Result: 实验表明，主流VideoLLMs在90%以上的情况下会忽略有害内容。

Conclusion: 当前VideoLLMs的设计存在根本性漏洞，需改进采样策略和压缩机制。

Abstract: Video Large Language Models (VideoLLMs) are increasingly deployed on numerous
critical applications, where users rely on auto-generated summaries while
casually skimming the video stream. We show that this interaction hides a
critical safety gap: if harmful content is embedded in a video, either as
full-frame inserts or as small corner patches, state-of-the-art VideoLLMs
rarely mention the harmful content in the output, despite its clear visibility
to human viewers. A root-cause analysis reveals three compounding design flaws:
(1) insufficient temporal coverage resulting from the sparse, uniformly spaced
frame sampling used by most leading VideoLLMs, (2) spatial information loss
introduced by aggressive token downsampling within sampled frames, and (3)
encoder-decoder disconnection, whereby visual cues are only weakly utilized
during text generation. Leveraging these insights, we craft three zero-query
black-box attacks, aligning with these flaws in the processing pipeline. Our
large-scale evaluation across five leading VideoLLMs shows that the harmfulness
omission rate exceeds 90% in most cases. Even when harmful content is clearly
present in all frames, these models consistently fail to identify it. These
results underscore a fundamental vulnerability in current VideoLLMs' designs
and highlight the urgent need for sampling strategies, token compression, and
decoding mechanisms that guarantee semantic coverage rather than speed alone.

</details>


### [54] [Probing the Representational Power of Sparse Autoencoders in Vision Models](https://arxiv.org/abs/2508.11277)
*Matthew Lyle Olson,Musashi Hinck,Neale Ratzlaff,Changbai Li,Phillip Howard,Vasudev Lal,Shao-Yen Tseng*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文研究了稀疏自编码器（SAEs）在视觉模型中的应用，发现SAEs能提取语义特征，提升泛化能力，并支持可控生成。


<details>
  <summary>Details</summary>
Motivation: 尽管SAEs在语言模型中广泛应用，但在视觉领域的研究较少。本文旨在评估SAEs在视觉模型中的表现潜力。

Method: 通过多种图像任务评估SAEs在视觉嵌入模型、多模态LLMs和扩散模型中的表现，包括OOD检测、语义操控和跨模态表征分析。

Result: SAEs提取的特征具有语义意义，提升泛化能力，并支持可控生成。在多模态LLMs中，SAEs揭示了跨模态共享表征。

Conclusion: SAEs在视觉模型中具有提升可解释性、泛化性和可控性的潜力。

Abstract: Sparse Autoencoders (SAEs) have emerged as a popular tool for interpreting
the hidden states of large language models (LLMs). By learning to reconstruct
activations from a sparse bottleneck layer, SAEs discover interpretable
features from the high-dimensional internal representations of LLMs. Despite
their popularity with language models, SAEs remain understudied in the visual
domain. In this work, we provide an extensive evaluation the representational
power of SAEs for vision models using a broad range of image-based tasks. Our
experimental results demonstrate that SAE features are semantically meaningful,
improve out-of-distribution generalization, and enable controllable generation
across three vision model architectures: vision embedding models, multi-modal
LMMs and diffusion models. In vision embedding models, we find that learned SAE
features can be used for OOD detection and provide evidence that they recover
the ontological structure of the underlying model. For diffusion models, we
demonstrate that SAEs enable semantic steering through text encoder
manipulation and develop an automated pipeline for discovering
human-interpretable attributes. Finally, we conduct exploratory experiments on
multi-modal LLMs, finding evidence that SAE features reveal shared
representations across vision and language modalities. Our study provides a
foundation for SAE evaluation in vision models, highlighting their strong
potential improving interpretability, generalization, and steerability in the
visual domain.

</details>


### [55] [Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models](https://arxiv.org/abs/2508.11317)
*Yuchen Zhou,Jiayu Tang,Shuo Yang,Xiaoyan Xiao,Yuqin Dai,Wenhao Yang,Chao Gou,Xiaobo Xia,Tat-Seng Chua*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文提出LogicBench基准和LogicCLIP框架，系统评估并提升视觉语言模型（VLMs）的逻辑理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在逻辑理解方面存在明显不足，限制了其在实际应用中的可靠性。

Method: 提出LogicBench基准（50,000+视觉语言对）和LogicCLIP框架（逻辑感知数据生成+对比学习策略）。

Result: LogicCLIP显著提升逻辑理解能力，同时在通用视觉语言任务中保持竞争力。

Conclusion: LogicBench和LogicCLIP为提升VLM逻辑能力提供了重要资源。

Abstract: Vision-Language Models (VLMs), exemplified by CLIP, have emerged as
foundational for multimodal intelligence. However, their capacity for logical
understanding remains significantly underexplored, resulting in critical
''logical blindspots'' that limit their reliability in practical applications.
To systematically diagnose this, we introduce LogicBench, a comprehensive
benchmark with over 50,000 vision-language pairs across 9 logical categories
and 4 diverse scenarios: images, videos, anomaly detection, and medical
diagnostics. Our evaluation reveals that existing VLMs, even the
state-of-the-art ones, fall at over 40 accuracy points below human performance,
particularly in challenging tasks like Causality and Conditionality,
highlighting their reliance on surface semantics over critical logical
structures. To bridge this gap, we propose LogicCLIP, a novel training
framework designed to boost VLMs' logical sensitivity through advancements in
both data generation and optimization objectives. LogicCLIP utilizes
logic-aware data generation and a contrastive learning strategy that combines
coarse-grained alignment, a fine-grained multiple-choice objective, and a novel
logical structure-aware objective. Extensive experiments demonstrate
LogicCLIP's substantial improvements in logical comprehension across all
LogicBench domains, significantly outperforming baselines. Moreover, LogicCLIP
retains, and often surpasses, competitive performance on general
vision-language benchmarks, demonstrating that the enhanced logical
understanding does not come at the expense of general alignment. We believe
that LogicBench and LogicCLIP will be important resources for advancing VLM
logical capabilities.

</details>


### [56] [MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation](https://arxiv.org/abs/2508.11433)
*Qian Liang,Yujia Wu,Kuncheng Li,Jiwei Wei,Shiyuan He,Jinyu Guo,Ning Xie*

Main category: cs.CV

Relevance: 75.0

TL;DR: MM-R1框架通过跨模态思维链推理（X-CoT）和分组奖励近端策略优化（GRPO），实现统一多模态大语言模型（MLLMs）的零样本个性化图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs方法通常需要针对每个新主题进行数据密集型微调，限制了其扩展性。MM-R1旨在解决这一问题，释放统一MLLMs在个性化图像生成中的潜力。

Method: 1. 通过视觉推理和生成过程结构化个性化：理解用户提供的图像和上下文线索；2. 基于提取的主题表示和用户提示生成个性化图像；3. 使用GRPO优化推理能力。

Result: 实验表明，MM-R1能够以零样本方式生成具有高主题保真度和强文本对齐的个性化图像。

Conclusion: MM-R1为统一MLLMs的个性化图像生成提供了一种高效且可扩展的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) with unified architectures excel
across a wide range of vision-language tasks, yet aligning them with
personalized image generation remains a significant challenge. Existing methods
for MLLMs are frequently subject-specific, demanding a data-intensive
fine-tuning process for every new subject, which limits their scalability. In
this paper, we introduce MM-R1, a framework that integrates a cross-modal
Chain-of-Thought (X-CoT) reasoning strategy to unlock the inherent potential of
unified MLLMs for personalized image generation. Specifically, we structure
personalization as an integrated visual reasoning and generation process: (1)
grounding subject concepts by interpreting and understanding user-provided
images and contextual cues, and (2) generating personalized images conditioned
on both the extracted subject representations and user prompts. To further
enhance the reasoning capability, we adopt Grouped Reward Proximal Policy
Optimization (GRPO) to explicitly align the generation. Experiments demonstrate
that MM-R1 unleashes the personalization capability of unified MLLMs to
generate images with high subject fidelity and strong text alignment in a
zero-shot manner.

</details>


### [57] [AIM: Amending Inherent Interpretability via Self-Supervised Masking](https://arxiv.org/abs/2508.11502)
*Eyad Alshami,Shashank Agnihotri,Bernt Schiele,Margret Keuper*

Main category: cs.CV

Relevance: 75.0

TL;DR: AIM方法通过自监督掩码促进DNN使用真实特征而非虚假特征，提升模型性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决DNN中真实与虚假特征混用问题，无需额外标注即可提升模型的可解释性和泛化能力。

Method: 利用多阶段编码特征指导自监督、样本特定的特征掩码过程。

Result: 在多个数据集上验证，AIM显著提升EPG分数和准确率。

Conclusion: AIM能有效促进模型使用真实特征，提升泛化能力和可解释性。

Abstract: It has been observed that deep neural networks (DNNs) often use both genuine
as well as spurious features. In this work, we propose "Amending Inherent
Interpretability via Self-Supervised Masking" (AIM), a simple yet interestingly
effective method that promotes the network's utilization of genuine features
over spurious alternatives without requiring additional annotations. In
particular, AIM uses features at multiple encoding stages to guide a
self-supervised, sample-specific feature-masking process. As a result, AIM
enables the training of well-performing and inherently interpretable models
that faithfully summarize the decision process. We validate AIM across a
diverse range of challenging datasets that test both out-of-distribution
generalization and fine-grained visual understanding. These include
general-purpose classification benchmarks such as ImageNet100, HardImageNet,
and ImageWoof, as well as fine-grained classification datasets such as
Waterbirds, TravelingBirds, and CUB-200. AIM demonstrates significant dual
benefits: interpretability improvements, as measured by the Energy Pointing
Game (EPG) score, and accuracy gains over strong baselines. These consistent
gains across domains and architectures provide compelling evidence that AIM
promotes the use of genuine and meaningful features that directly contribute to
improved generalization and human-aligned interpretability.

</details>


### [58] [Thyme: Think Beyond Images](https://arxiv.org/abs/2508.11630)
*Yi-Fan Zhang,Xingyu Lu,Shukang Yin,Chaoyou Fu,Wei Chen,Xiao Hu,Bin Wen,Kaiyu Jiang,Changyi Liu,Tianke Zhang,Haonan Fan,Kaibing Chen,Jiankang Chen,Haojie Ding,Kaiyu Tang,Zhang Zhang,Liang Wang,Fan Yang,Tingting Gao,Guorui Zhou*

Main category: cs.CV

Relevance: 75.0

TL;DR: Thyme是一种新型多模态大语言模型（MLLM）范式，通过生成和执行代码实现图像处理和计算操作，超越现有“图像思维”方法。


<details>
  <summary>Details</summary>
Motivation: 当前开源模型在图像操作和逻辑推理能力上不如专有模型（如O3），Thyme旨在填补这一空白。

Method: 采用两阶段训练策略：初始SFT（500K样本）学习代码生成，随后RL阶段（GRPO-ATS算法）优化决策。

Result: 在近20个基准测试中表现优异，尤其在复杂推理和高分辨率感知任务中。

Conclusion: Thyme通过代码生成和自主操作显著提升MLLM性能。

Abstract: Following OpenAI's introduction of the ``thinking with images'' concept,
recent efforts have explored stimulating the use of visual information in the
reasoning process to enhance model performance in perception and reasoning
tasks. However, to the best of our knowledge, no open-source work currently
offers a feature set as rich as proprietary models (O3), which can perform
diverse image manipulations and simultaneously enhance logical reasoning
capabilities through code. In this paper, we make a preliminary attempt in this
direction by introducing Thyme (Think Beyond Images), a novel paradigm for
enabling MLLMs to transcend existing ``think with images'' approaches by
autonomously generating and executing diverse image processing and
computational operations via executable code. This approach not only
facilitates a rich, on-the-fly set of image manipulations (e.g., cropping,
rotation, contrast enhancement) but also allows for mathematical computations,
all while maintaining high autonomy in deciding when and how to apply these
operations. We activate this capability through a two-stage training strategy:
an initial SFT on a curated dataset of 500K samples to teach code generation,
followed by a RL phase to refine decision-making. For the RL stage, we manually
collect and design high-resolution question-answer pairs to increase the
learning difficulty, and we propose GRPO-ATS (Group Relative Policy
Optimization with Adaptive Temperature Sampling), an algorithm that applies
distinct temperatures to text and code generation to balance reasoning
exploration with code execution precision. We conduct extensive experimental
analysis and ablation studies. Comprehensive evaluations on nearly 20
benchmarks show that Thyme yields significant and consistent performance gains,
particularly in challenging high-resolution perception and complex reasoning
tasks.

</details>


### [59] [IPG: Incremental Patch Generation for Generalized Adversarial Patch Training](https://arxiv.org/abs/2508.10946)
*Wonho Lee,Hyunsik Na,Jisu Lee,Daeseon Choi*

Main category: cs.CV

Relevance: 70.0

TL;DR: 论文提出了一种名为增量补丁生成（IPG）的方法，能高效生成对抗性补丁，攻击性能与现有方法相当，但效率提升11.1倍。实验表明IPG生成的补丁能广泛覆盖模型漏洞，并可用于构建鲁棒模型。


<details>
  <summary>Details</summary>
Motivation: 对抗性补丁对AI模型的鲁棒性构成挑战，尤其在计算机视觉任务中。传统方法效率较低，需更高效且有效的生成方法。

Method: 提出增量补丁生成（IPG），通过实验和消融研究验证其效率与攻击性能，包括YOLO特征分布可视化和对抗训练结果。

Result: IPG生成补丁效率提升11.1倍，覆盖更广模型漏洞，生成的补丁数据集可用于构建鲁棒模型。

Conclusion: IPG在对抗性补丁防御和实际应用（如自动驾驶、医疗影像）中潜力显著。

Abstract: The advent of adversarial patches poses a significant challenge to the
robustness of AI models, particularly in the domain of computer vision tasks
such as object detection. In contradistinction to traditional adversarial
examples, these patches target specific regions of an image, resulting in the
malfunction of AI models. This paper proposes Incremental Patch Generation
(IPG), a method that generates adversarial patches up to 11.1 times more
efficiently than existing approaches while maintaining comparable attack
performance. The efficacy of IPG is demonstrated by experiments and ablation
studies including YOLO's feature distribution visualization and adversarial
training results, which show that it produces well-generalized patches that
effectively cover a broader range of model vulnerabilities. Furthermore,
IPG-generated datasets can serve as a robust knowledge foundation for
constructing a robust model, enabling structured representation, advanced
reasoning, and proactive defenses in AI security ecosystems. The findings of
this study suggest that IPG has considerable potential for future utilization
not only in adversarial patch defense but also in real-world applications such
as autonomous vehicles, security systems, and medical imaging, where AI models
must remain resilient to adversarial attacks in dynamic and high-stakes
environments.

</details>


### [60] [Vision-Language Models display a strong gender bias](https://arxiv.org/abs/2508.11262)
*Aiswarya Konavoor,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CV

Relevance: 70.0

TL;DR: 该研究探讨了视觉语言模型（VLM）中性别关联的潜在偏见，通过分析图像和文本嵌入的相似性，揭示了模型在职业和活动描述中的性别刻板印象。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示视觉语言模型在共享表示空间中可能编码的社会刻板印象，尤其是性别关联，这些偏见无法通过标准准确性指标直接检测。

Method: 通过构建包含220张人脸照片和150条描述性语句的数据集，计算图像和文本嵌入的余弦相似性，定义性别关联分数，并使用bootstrap置信区间和标签交换零模型进行统计分析。

Result: 研究提供了一个详细的性别关联映射，揭示了模型在职业和活动描述中的性别偏见，并提出了一个稳健的性别偏见评估框架。

Conclusion: 视觉语言模型在表示空间中可能隐含性别刻板印象，需要更细致的评估方法以确保公平性。

Abstract: Vision-language models (VLM) align images and text in a shared representation
space that is useful for retrieval and zero-shot transfer. Yet, this alignment
can encode and amplify social stereotypes in subtle ways that are not obvious
from standard accuracy metrics. In this study, we test whether the contrastive
vision-language encoder exhibits gender-linked associations when it places
embeddings of face images near embeddings of short phrases that describe
occupations and activities. We assemble a dataset of 220 face photographs split
by perceived binary gender and a set of 150 unique statements distributed
across six categories covering emotional labor, cognitive labor, domestic
labor, technical labor, professional roles, and physical labor. We compute
unit-norm image embeddings for every face and unit-norm text embeddings for
every statement, then define a statement-level association score as the
difference between the mean cosine similarity to the male set and the mean
cosine similarity to the female set, where positive values indicate stronger
association with the male set and negative values indicate stronger association
with the female set. We attach bootstrap confidence intervals by resampling
images within each gender group, aggregate by category with a separate
bootstrap over statements, and run a label-swap null model that estimates the
level of mean absolute association we would expect if no gender structure were
present. The outcome is a statement-wise and category-wise map of gender
associations in a contrastive vision-language space, accompanied by
uncertainty, simple sanity checks, and a robust gender bias evaluation
framework.

</details>


### [61] [Causality Matters: How Temporal Information Emerges in Video Language Models](https://arxiv.org/abs/2508.11576)
*Yumeng Shi,Quanyu Long,Yin Wu,Wenya Wang*

Main category: cs.CV

Relevance: 70.0

TL;DR: 研究发现，视频语言模型（VideoLMs）中，时间信息的编码主要依赖于帧间注意力而非位置编码（PEs），并提出两种高效策略以优化模型。


<details>
  <summary>Details</summary>
Motivation: 视频语言模型在多模态理解方面取得进展，但时间理解（如事件顺序、持续时间和跨时间关系）仍是核心挑战。研究旨在揭示时间信息在模型中的编码机制。

Method: 通过实验分析移除或修改PEs的影响，发现帧序列反转对性能影响显著。提出基于因果注意力机制的两种策略：分阶段跨模态注意力和时间退出机制。

Result: 实验验证了两种策略的有效性，揭示了时间信息通过帧间注意力逐步合成的机制。

Conclusion: 时间推理源于视觉令牌间的交互，而非显式的位置编码。研究为未来模型优化提供了新思路。

Abstract: Video language models (VideoLMs) have made significant progress in multimodal
understanding. However, temporal understanding, which involves identifying
event order, duration, and relationships across time, still remains a core
challenge. Prior works emphasize positional encodings (PEs) as a key mechanism
for encoding temporal structure. Surprisingly, we find that removing or
modifying PEs in video inputs yields minimal degradation in the performance of
temporal understanding. In contrast, reversing the frame sequence while
preserving the original PEs causes a substantial drop. To explain this
behavior, we conduct substantial analysis experiments to trace how temporal
information is integrated within the model. We uncover a causal information
pathway: temporal cues are progressively synthesized through inter-frame
attention, aggregated in the final frame, and subsequently integrated into the
query tokens. This emergent mechanism shows that temporal reasoning emerges
from inter-visual token interactions under the constraints of causal attention,
which implicitly encodes temporal structure. Based on these insights, we
propose two efficiency-oriented strategies: staged cross-modal attention and a
temporal exit mechanism for early token truncation. Experiments on two
benchmarks validate the effectiveness of both approaches. To the best of our
knowledge, this is the first work to systematically investigate video temporal
understanding in VideoLMs, offering insights for future model improvement.

</details>


### [62] [LoRAtorio: An intrinsic approach to LoRA Skill Composition](https://arxiv.org/abs/2508.11624)
*Niki Foteinopoulou,Ignas Budvytis,Stephan Liwicki*

Main category: cs.CV

Relevance: 70.0

TL;DR: LoRAtorio是一个无需训练的多LoRA组合框架，通过利用模型内在行为实现高效组合，解决了现有方法在开放场景中多LoRA适配器组合效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多LoRA组合时表现不佳，尤其是在开放场景中。研究旨在通过利用LoRA适配器的内在行为差异，提出一种无需训练的解决方案。

Method: 在潜在空间中划分空间块，计算每个块的预测噪声与基础模型的余弦相似度，构建空间感知权重矩阵，加权聚合LoRA输出。还提出了一种改进的无分类器引导方法。

Result: LoRAtorio在ClipScore上提升1.3%，在GPT-4V评估中胜率达72.43%，并在多种潜在扩散模型中表现优异。

Conclusion: LoRAtorio通过空间感知权重和动态模块选择，实现了多LoRA组合的高效性和泛化能力。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted technique in
text-to-image diffusion models, enabling the personalisation of visual concepts
such as characters, styles, and objects. However, existing approaches struggle
to effectively compose multiple LoRA adapters, particularly in open-ended
settings where the number and nature of required skills are not known in
advance. In this work, we present LoRAtorio, a novel train-free framework for
multi-LoRA composition that leverages intrinsic model behaviour. Our method is
motivated by two key observations: (1) LoRA adapters trained on narrow domains
produce denoised outputs that diverge from the base model, and (2) when
operating out-of-distribution, LoRA outputs show behaviour closer to the base
model than when conditioned in distribution. The balance between these two
observations allows for exceptional performance in the single LoRA scenario,
which nevertheless deteriorates when multiple LoRAs are loaded. Our method
operates in the latent space by dividing it into spatial patches and computing
cosine similarity between each patch's predicted noise and that of the base
model. These similarities are used to construct a spatially-aware weight
matrix, which guides a weighted aggregation of LoRA outputs. To address domain
drift, we further propose a modification to classifier-free guidance that
incorporates the base model's unconditional score into the composition. We
extend this formulation to a dynamic module selection setting, enabling
inference-time selection of relevant LoRA adapters from a large pool. LoRAtorio
achieves state-of-the-art performance, showing up to a 1.3% improvement in
ClipScore and a 72.43% win rate in GPT-4V pairwise evaluations, and generalises
effectively to multiple latent diffusion models.

</details>


### [63] [A Survey on Video Temporal Grounding with Multimodal Large Language Model](https://arxiv.org/abs/2508.10922)
*Jianlong Wu,Wei Liu,Ye Liu,Meng Liu,Liqiang Nie,Zhouchen Lin,Chang Wen Chen*

Main category: cs.CV

Relevance: 60.0

TL;DR: 该论文综述了基于多模态大语言模型（MLLMs）的视频时间定位（VTG）研究，填补了这一领域的空白。


<details>
  <summary>Details</summary>
Motivation: VTG-MLLMs在视频理解中表现出色，但缺乏系统性综述，本文旨在填补这一空白。

Method: 通过三维分类法（功能角色、训练范式、视频特征处理）分析VTG-MLLMs的研究现状。

Result: 总结了VTG-MLLMs在性能、泛化能力等方面的优势，并讨论了现有局限性。

Conclusion: 提出了未来研究方向，并提供了相关资源。

Abstract: The recent advancement in video temporal grounding (VTG) has significantly
enhanced fine-grained video understanding, primarily driven by multimodal large
language models (MLLMs). With superior multimodal comprehension and reasoning
abilities, VTG approaches based on MLLMs (VTG-MLLMs) are gradually surpassing
traditional fine-tuned methods. They not only achieve competitive performance
but also excel in generalization across zero-shot, multi-task, and multi-domain
settings. Despite extensive surveys on general video-language understanding,
comprehensive reviews specifically addressing VTG-MLLMs remain scarce. To fill
this gap, this survey systematically examines current research on VTG-MLLMs
through a three-dimensional taxonomy: 1) the functional roles of MLLMs,
highlighting their architectural significance; 2) training paradigms, analyzing
strategies for temporal reasoning and task adaptation; and 3) video feature
processing techniques, which determine spatiotemporal representation
effectiveness. We further discuss benchmark datasets, evaluation protocols, and
summarize empirical findings. Finally, we identify existing limitations and
propose promising research directions. For additional resources and details,
readers are encouraged to visit our repository at
https://github.com/ki-lw/Awesome-MLLMs-for-Video-Temporal-Grounding.

</details>


### [64] [ORBIT: An Object Property Reasoning Benchmark for Visual Inference Tasks](https://arxiv.org/abs/2508.10956)
*Abhishek Kolari,Mohammadhossein Khojasteh,Yifan Jiang,Floris den Hengst,Filip Ilievski*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了ORBIT，一个多层次的视觉问答（VQA）基准测试，用于评估视觉语言模型（VLMs）在对象属性推理上的能力。实验显示当前VLMs表现不佳，尤其在复杂推理和真实图像上。


<details>
  <summary>Details</summary>
Motivation: 当前VQA基准测试在对象属性推理上存在局限性，缺乏多样性和复杂性，无法全面评估VLMs的能力。

Method: 设计了ORBIT基准测试，包含360张图像和1,080个计数问题，覆盖三种图像类型、三种推理复杂度和四种对象属性维度。

Result: 12个先进VLMs在零样本设置下表现较差，最高准确率仅40%，尤其在真实图像和复杂推理任务上表现不佳。

Conclusion: ORBIT揭示了VLMs在对象属性推理上的不足，呼吁开发更可扩展的基准测试和更强的推理模型。

Abstract: While vision-language models (VLMs) have made remarkable progress on many
popular visual question answering (VQA) benchmarks, it remains unclear whether
they abstract and reason over depicted objects. Inspired by human object
categorisation, object property reasoning involves identifying and recognising
low-level details and higher-level abstractions. While current VQA benchmarks
consider a limited set of object property attributes like size, they typically
blend perception and reasoning, and lack representativeness in terms of
reasoning and image categories. To this end, we introduce a systematic
evaluation framework with images of three representative types, three reasoning
levels of increasing complexity, and four object property dimensions driven by
prior work on commonsense reasoning. We develop a procedure to instantiate this
benchmark into ORBIT, a multi-level reasoning VQA benchmark for object
properties comprising 360 images paired with a total of 1,080 count-based
questions. Experiments with 12 state-of-the-art VLMs in zero-shot settings
reveal significant limitations compared to humans, with the best-performing
model only reaching 40\% accuracy. VLMs struggle particularly with realistic
(photographic) images, counterfactual reasoning about physical and functional
properties, and higher counts. ORBIT points to the need to develop methods for
scalable benchmarking, generalize annotation guidelines, and explore additional
reasoning VLMs. We make the ORBIT benchmark and the experimental code available
to support such endeavors.

</details>


### [65] [Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning](https://arxiv.org/abs/2508.11176)
*Yumiao Zhao,Bo Jiang,Yuhe Ding,Xiao Wang,Jin Tang,Bin Luo*

Main category: cs.CV

Relevance: 60.0

TL;DR: 提出了一种新型的Latent Hierarchical Adapter (LatHAdapter)，通过双曲空间学习潜在语义层次结构，改进视觉-语言模型在少样本分类任务中的微调效果。


<details>
  <summary>Details</summary>
Motivation: 现有适配器方法在视觉-文本模态对齐时，仅依赖显式空间邻近性，无法捕捉类别与图像样本间的一对多关联，且难以处理未知类别。

Method: 引入可学习的属性提示作为桥梁，将类别、属性和图像投影到双曲空间，并通过层次正则化学习潜在语义层次结构。

Result: 在四个少样本任务上，LatHAdapter表现优于其他微调方法，尤其在已知类别适应和未知类别泛化方面。

Conclusion: LatHAdapter通过潜在语义层次建模，显著提升了少样本分类任务的性能。

Abstract: Adapter-based approaches have garnered attention for fine-tuning pre-trained
Vision-Language Models (VLMs) on few-shot classification tasks. These methods
strive to develop a lightweight module that better aligns visual and (category)
textual representations, thereby enhancing performance on downstream few-shot
learning tasks. However, existing adapters generally learn/align (category)
textual-visual modalities via explicit spatial proximity in the underlying
embedding space, which i) fails to capture the inherent one-to-many
associations between categories and image samples and ii) struggles to
establish accurate associations between the unknown categories and images. To
address these issues, inspired by recent works on hyperbolic learning, we
develop a novel Latent Hierarchical Adapter (LatHAdapter) for fine-tuning VLMs
on downstream few-shot classification tasks. The core of LatHAdapter is to
exploit the latent semantic hierarchy of downstream training data and employ it
to provide richer, fine-grained guidance for the adapter learning process.
Specifically, LatHAdapter first introduces some learnable `attribute' prompts
as the bridge to align categories and images. Then, it projects the categories,
attribute prompts, and images within each batch in a hyperbolic space, and
employs hierarchical regularization to learn the latent semantic hierarchy of
them, thereby fully modeling the inherent one-to-many associations among
categories, learnable attributes, and image samples. Extensive experiments on
four challenging few-shot tasks show that the proposed LatHAdapter consistently
outperforms many other fine-tuning approaches, particularly in adapting known
classes and generalizing to unknown classes.

</details>


### [66] [Versatile Video Tokenization with Generative 2D Gaussian Splatting](https://arxiv.org/abs/2508.11183)
*Zhenghao Chen,Zicong Chen,Lei Liu,Yiming Wu,Dong Xu*

Main category: cs.CV

Relevance: 60.0

TL;DR: GVT是一种基于生成2D高斯分布的通用视频标记化方法，通过空间-时间高斯嵌入和静态-动态分离策略，显著提升了视频处理的适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有视频标记化方法在空间和时间维度上存在冗余和适应性不足的问题，GVT旨在通过生成2D高斯分布和分离静态与动态内容来解决这些问题。

Method: GVT采用生成2D高斯分布策略（STGE机制）和静态-动态高斯集划分（GSP），以提升空间适应性和时间效率。

Result: GVT在视频重建、动作识别和压缩任务中表现优异，优于基线方法MAGVIT-v2。

Conclusion: GVT通过创新的高斯分布策略，为视频处理任务提供了高效且通用的解决方案。

Abstract: Video tokenization procedure is critical for a wide range of video processing
tasks. Most existing approaches directly transform video into fixed-grid and
patch-wise tokens, which exhibit limited versatility. Spatially, uniformly
allocating a fixed number of tokens often leads to over-encoding in
low-information regions. Temporally, reducing redundancy remains challenging
without explicitly distinguishing between static and dynamic content. In this
work, we propose the Gaussian Video Transformer (GVT), a versatile video
tokenizer built upon a generative 2D Gaussian Splatting (2DGS) strategy. We
first extract latent rigid features from a video clip and represent them with a
set of 2D Gaussians generated by our proposed Spatio-Temporal Gaussian
Embedding (STGE) mechanism in a feed-forward manner. Such generative 2D
Gaussians not only enhance spatial adaptability by assigning higher (resp.,
lower) rendering weights to regions with higher (resp., lower) information
content during rasterization, but also improve generalization by avoiding
per-video optimization.To enhance the temporal versatility, we introduce a
Gaussian Set Partitioning (GSP) strategy that separates the 2D Gaussians into
static and dynamic sets, which explicitly model static content shared across
different time-steps and dynamic content specific to each time-step, enabling a
compact representation.We primarily evaluate GVT on the video reconstruction,
while also assessing its performance on action recognition and compression
using the UCF101, Kinetics, and DAVIS datasets. Extensive experiments
demonstrate that GVT achieves a state-of-the-art video reconstruction quality,
outperforms the baseline MAGVIT-v2 in action recognition, and delivers
comparable compression performance.

</details>


### [67] [Generating Dialogues from Egocentric Instructional Videos for Task Assistance: Dataset, Method and Benchmark](https://arxiv.org/abs/2508.11192)
*Lavisha Aggarwal,Vikas Bahirwani,Lin Li,Andrea Colaco*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了一种自动将单人教学视频转化为任务指导对话的方法，并构建了HowToDIV数据集，包含507个对话和6636个问答对。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界任务辅助中对话-视频数据集的稀缺问题。

Method: 利用大语言模型自动将单人教学视频转化为两人对话，并与视频片段对齐。

Result: 构建了HowToDIV数据集，并基于Gemma-3模型建立了基准性能。

Conclusion: 该方法为任务辅助对话研究提供了高效的数据生成途径。

Abstract: Many everyday tasks ranging from fixing appliances, cooking recipes to car
maintenance require expert knowledge, especially when tasks are complex and
multi-step. Despite growing interest in AI agents, there is a scarcity of
dialogue-video datasets grounded for real world task assistance. In this paper,
we propose a simple yet effective approach that transforms single-person
instructional videos into task-guidance two-person dialogues, aligned with fine
grained steps and video-clips. Our fully automatic approach, powered by large
language models, offers an efficient alternative to the substantial cost and
effort required for human-assisted data collection. Using this technique, we
build HowToDIV, a large-scale dataset containing 507 conversations, 6636
question-answer pairs and 24 hours of videoclips across diverse tasks in
cooking, mechanics, and planting. Each session includes multi-turn conversation
where an expert teaches a novice user how to perform a task step by step, while
observing user's surrounding through a camera and microphone equipped wearable
device. We establish the baseline benchmark performance on HowToDIV dataset
through Gemma-3 model for future research on this new task of dialogues for
procedural-task assistance.

</details>


### [68] [UAV-VL-R1: Generalizing Vision-Language Models via Supervised Fine-Tuning and Multi-Stage GRPO for UAV Visual Reasoning](https://arxiv.org/abs/2508.11196)
*Jiajin Guan,Haibo Mei,Bonan Zhang,Dan Liu,Yuanshuang Fu,Yue Zhang*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了一种轻量级视觉语言模型UAV-VL-R1，专为无人机航拍图像设计，结合监督微调（SFT）和多阶段强化学习（RL），显著提升了零样本准确率。


<details>
  <summary>Details</summary>
Motivation: 通用视觉语言模型在无人机航拍图像上表现不佳，因高分辨率、复杂空间语义和实时性要求限制了其应用。

Method: 采用混合训练方法（SFT+RL），使用GRPO算法提升结构化推理能力，并构建了HRVQA-VL数据集支持训练与评估。

Result: UAV-VL-R1零样本准确率比基线模型高48.17%，甚至优于其36倍大的变体，且内存占用低，支持实时部署。

Conclusion: UAV-VL-R1通过SFT和RL的结合，在航拍图像任务中实现了高效推理，同时保持了轻量化和实时性。

Abstract: Recent advances in vision-language models (VLMs) have demonstrated strong
generalization in natural image tasks. However, their performance often
degrades on unmanned aerial vehicle (UAV)-based aerial imagery, which features
high resolution, complex spatial semantics, and strict real-time constraints.
These challenges limit the applicability of general-purpose VLMs to structured
aerial reasoning tasks. To address these challenges, we propose UAV-VL-R1, a
lightweight VLM explicitly designed for aerial visual reasoning. It is trained
using a hybrid method that combines supervised fine-tuning (SFT) and
multi-stage reinforcement learning (RL). We leverage the group relative policy
optimization (GRPO) algorithm to promote structured and interpretable reasoning
through rule-guided rewards and intra-group policy alignment. To support model
training and evaluation, we introduce a high-resolution visual question
answering dataset named HRVQA-VL, which consists of 50,019 annotated samples
covering eight UAV-relevant reasoning tasks, including object counting,
transportation recognition, and spatial scene inference. Experimental results
show that UAV-VL-R1 achieves a 48.17% higher zero-shot accuracy than the
Qwen2-VL-2B-Instruct baseline and even outperforms its 72B-scale variant, which
is 36x larger, on multiple tasks. Ablation studies reveal that while SFT
improves semantic alignment, it may reduce reasoning diversity in mathematical
tasks. GRPO-based RL compensates for this limitation by enhancing logical
flexibility and the robustness of inference. Additionally, UAV-VL-R1 requires
only 3.9GB of memory under FP16 inference and can be quantized to 2.5GB with
INT8, supporting real-time deployment on resource-constrained UAV platforms.

</details>


### [69] [Noise Matters: Optimizing Matching Noise for Diffusion Classifiers](https://arxiv.org/abs/2508.11330)
*Yanghao Wang,Long Chen*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了一种名为NoOp的噪声优化方法，用于解决扩散分类器（DC）中的噪声不稳定性问题，通过频率匹配和空间匹配原则优化噪声，提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散分类器（DC）在图像分类中存在噪声不稳定性问题，需要大量噪声采样以稳定性能，但会降低分类速度。本文旨在通过优化噪声解决这一问题。

Method: 提出NoOp方法，包括频率匹配（优化数据集特定噪声）和空间匹配（训练元网络生成图像特定噪声偏移），以替代随机噪声。

Result: 实验表明，NoOp在各种数据集上有效提升了分类性能。

Conclusion: NoOp通过优化噪声显著改善了扩散分类器的稳定性和效率。

Abstract: Although today's pretrained discriminative vision-language models (e.g.,
CLIP) have demonstrated strong perception abilities, such as zero-shot image
classification, they also suffer from the bag-of-words problem and spurious
bias. To mitigate these problems, some pioneering studies leverage powerful
generative models (e.g., pretrained diffusion models) to realize generalizable
image classification, dubbed Diffusion Classifier (DC). Specifically, by
randomly sampling a Gaussian noise, DC utilizes the differences of denoising
effects with different category conditions to classify categories.
Unfortunately, an inherent and notorious weakness of existing DCs is noise
instability: different random sampled noises lead to significant performance
changes. To achieve stable classification performance, existing DCs always
ensemble the results of hundreds of sampled noises, which significantly reduces
the classification speed. To this end, we firstly explore the role of noise in
DC, and conclude that: there are some ``good noises'' that can relieve the
instability. Meanwhile, we argue that these good noises should meet two
principles: Frequency Matching and Spatial Matching. Regarding both principles,
we propose a novel Noise Optimization method to learn matching (i.e., good)
noise for DCs: NoOp. For frequency matching, NoOp first optimizes a
dataset-specific noise: Given a dataset and a timestep t, optimize one randomly
initialized parameterized noise. For Spatial Matching, NoOp trains a
Meta-Network that adopts an image as input and outputs image-specific noise
offset. The sum of optimized noise and noise offset will be used in DC to
replace random noise. Extensive ablations on various datasets demonstrated the
effectiveness of NoOp.

</details>


### [70] [HOID-R1: Reinforcement Learning for Open-World Human-Object Interaction Detection Reasoning with Multimodal Large Language Model](https://arxiv.org/abs/2508.11350)
*Zhenhao Zhang,Hanqing Wang,Xiangyu Zeng,Ziyu Cheng,Jiaxin Liu,Haoyu Yan,Zhirui Liu,Kaiyang Ji,Tianxiang Gui,Ke Hu,Kangyi Chen,Yahao Fan,Mokai Pan*

Main category: cs.CV

Relevance: 60.0

TL;DR: HOID-R1是一个结合了链式思维（CoT）引导的监督微调（SFT）和群体相对策略优化（GRPO）的HOI检测框架，通过强化学习提升3D空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇HOI检测方法依赖大语言模型但忽视其3D空间理解能力，HOID-R1旨在解决这一问题。

Method: 结合SFT赋予模型推理能力，GRPO优化多模态对齐，引入MLLM监督CoT以减少幻觉。

Result: HOID-R1在HOI检测基准上达到SOTA，并在开放世界泛化中优于现有方法。

Conclusion: HOID-R1通过强化学习和多模态对齐显著提升了HOI检测性能。

Abstract: Understanding and recognizing human-object interaction (HOI) is a pivotal
application in AR/VR and robotics. Recent open-vocabulary HOI detection
approaches depend exclusively on large language models for richer textual
prompts, neglecting their inherent 3D spatial understanding capabilities. To
address this shortcoming, we introduce HOID-R1, the first HOI detection
framework that integrates chain-of-thought (CoT) guided supervised fine-tuning
(SFT) with group relative policy optimization (GRPO) within a reinforcement
learning (RL) paradigm. Specifically, we initially apply SFT to imbue the model
with essential reasoning capabilities, forcing the model to articulate its
thought process in the output. Subsequently, we integrate GRPO to leverage
multi-reward signals for policy optimization, thereby enhancing alignment
across diverse modalities. To mitigate hallucinations in the CoT reasoning, we
introduce an "MLLM-as-a-judge" mechanism that supervises the CoT outputs,
further improving generalization. Extensive experiments show that HOID-R1
achieves state-of-the-art performance on HOI detection benchmarks and
outperforms existing methods in open-world generalization to novel scenarios.

</details>


### [71] [Reinforcing Video Reasoning Segmentation to Think Before It Segments](https://arxiv.org/abs/2508.11538)
*Sitong Gong,Lu Zhang,Yunzhi Zhuge,Xu Jia,Pingping Zhang,Huchuan Lu*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出Veason-R1，一种专用于视频推理分割（VRS）的LVLM，通过GRPO和CoT初始化训练，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有LVLM在视频推理分割中推理能力不足和性能不佳的问题。

Method: 结合GRPO和CoT初始化训练，优化推理链，增强时空一致性。

Result: 在多个基准测试中达到SOTA，性能显著提升（如ReVOS +1.3 J&F，ReasonVOS +10.0 J&F）。

Conclusion: Veason-R1通过结构化推理和强化学习优化，显著提升了VRS任务的性能。

Abstract: Video reasoning segmentation (VRS) endeavors to delineate referred objects in
videos guided by implicit instructions that encapsulate human intent and
temporal logic. Previous approaches leverage large vision language models
(LVLMs) to encode object semantics into <SEG> tokens for mask prediction.
However, this paradigm suffers from limited interpretability during inference
and suboptimal performance due to inadequate spatiotemporal reasoning. Drawing
inspiration from seminal breakthroughs in reinforcement learning, we introduce
Veason-R1, a specialized LVLM for VRS that emphasizes structured reasoning in
segmentation. Veason-R1 is trained through Group Relative Policy Optimization
(GRPO) augmented with Chain-of-Thought (CoT) initialization. To begin with, we
curate high-quality CoT training data to instill structured reasoning
trajectories, bridging video-level semantics and frame-level spatial grounding,
yielding the supervised fine-tuned model Veason-SFT. Subsequently, GRPO
fine-tuning encourages efficient exploration of the reasoning space by
optimizing reasoning chains. To this end, we incorporate a holistic reward
mechanism that synergistically enhances spatial alignment and temporal
consistency, bolstering keyframe localization and fine-grained grounding.
Comprehensive empirical evaluations demonstrate that Veason-R1 achieves
state-of-the-art performance on multiple benchmarks, surpassing prior art by
significant margins (e.g., +1.3 J &F in ReVOS and +10.0 J &F in ReasonVOS),
while exhibiting robustness to hallucinations (+8.8 R). Our code and model
weights will be available at Veason-R1.

</details>


### [72] [Index-Aligned Query Distillation for Transformer-based Incremental Object Detection](https://arxiv.org/abs/2508.11339)
*Mingxiao Ma,Shunyao Zhu,Guoliang Kang*

Main category: cs.CV

Relevance: 50.0

TL;DR: 论文提出了一种名为IAQD的新蒸馏方法，用于解决基于Transformer的增量目标检测（IOD）中的知识遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 在基于Transformer的IOD任务中，传统的匈牙利匹配方法可能导致知识遗忘，因此需要一种更有效的方法来保留旧类别的知识。

Method: 提出Index-Aligned Query Distillation (IAQD)，通过索引对齐的查询蒸馏，仅对关键查询进行蒸馏，避免干扰新类别的学习。

Result: 实验表明，IAQD有效缓解了知识遗忘，并在多个基准测试中达到最先进性能。

Conclusion: IAQD是一种高效的蒸馏方法，适用于基于Transformer的IOD任务。

Abstract: Incremental object detection (IOD) aims to continuously expand the capability
of a model to detect novel categories while preserving its performance on
previously learned ones. When adopting a transformer-based detection model to
perform IOD, catastrophic knowledge forgetting may inevitably occur, meaning
the detection performance on previously learned categories may severely
degenerate. Previous typical methods mainly rely on knowledge distillation (KD)
to mitigate the catastrophic knowledge forgetting of transformer-based
detection models. Specifically, they utilize Hungarian Matching to build a
correspondence between the queries of the last-phase and current-phase
detection models and align the classifier and regressor outputs between matched
queries to avoid knowledge forgetting. However, we observe that in IOD task,
Hungarian Matching is not a good choice. With Hungarian Matching, the query of
the current-phase model may match different queries of the last-phase model at
different iterations during KD. As a result, the knowledge encoded in each
query may be reshaped towards new categories, leading to the forgetting of
previously encoded knowledge of old categories. Based on our observations, we
propose a new distillation approach named Index-Aligned Query Distillation
(IAQD) for transformer-based IOD. Beyond using Hungarian Matching, IAQD
establishes a correspondence between queries of the previous and current phase
models that have the same index. Moreover, we perform index-aligned
distillation only on partial queries which are critical for the detection of
previous categories. In this way, IAQD largely preserves the previous semantic
and spatial encoding capabilities without interfering with the learning of new
categories. Extensive experiments on representative benchmarks demonstrate that
IAQD effectively mitigates knowledge forgetting, achieving new state-of-the-art
performance.

</details>


### [73] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By \underline{V}alue \underline{S}ign \underline{F}lip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

Relevance: 40.0

TL;DR: VSF是一种简单高效的方法，通过翻转负提示的注意力值符号，动态抑制不需要的内容，适用于少步扩散和流匹配图像生成模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CFG、NASA、NAG）在负提示引导方面存在不足，VSF旨在提供一种更高效且计算开销小的解决方案。

Method: VSF动态翻转负提示的注意力值符号，适用于MMDiT架构和基于交叉注意力的模型。

Result: VSF在静态图像和视频生成任务中表现优异，显著提升了负提示的遵循能力，同时保持图像质量。

Conclusion: VSF是一种高效且通用的负提示引导方法，适用于多种模型架构。

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [74] [MedAtlas: Evaluating LLMs for Multi-Round, Multi-Task Medical Reasoning Across Diverse Imaging Modalities and Clinical Text](https://arxiv.org/abs/2508.10947)
*Ronghao Xu,Zhen Huang,Yangbo Wei,Xiaoqian Zhou,Zikang Xu,Ting Liu,Zihang Jiang,S. Kevin Zhou*

Main category: cs.CV

Relevance: 40.0

TL;DR: MedAtlas是一个新的医学多模态基准框架，用于评估大型语言模型在真实医学推理任务中的表现，支持多轮对话、多模态图像交互和多任务集成。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态基准局限于单图像、单轮任务，无法反映临床实践中的多模态交互和纵向特性，因此需要MedAtlas填补这一空白。

Method: MedAtlas设计了四个核心任务（多轮问答、多图像联合推理等），并引入两种新评估指标（Round Chain Accuracy和Error Propagation Resistance）。

Result: 现有多模态模型在多阶段临床推理任务中表现不佳，MedAtlas揭示了显著的性能差距。

Conclusion: MedAtlas为开发鲁棒且可信的医学AI提供了具有挑战性的评估平台。

Abstract: Artificial intelligence has demonstrated significant potential in clinical
decision-making; however, developing models capable of adapting to diverse
real-world scenarios and performing complex diagnostic reasoning remains a
major challenge. Existing medical multi-modal benchmarks are typically limited
to single-image, single-turn tasks, lacking multi-modal medical image
integration and failing to capture the longitudinal and multi-modal interactive
nature inherent to clinical practice. To address this gap, we introduce
MedAtlas, a novel benchmark framework designed to evaluate large language
models on realistic medical reasoning tasks. MedAtlas is characterized by four
key features: multi-turn dialogue, multi-modal medical image interaction,
multi-task integration, and high clinical fidelity. It supports four core
tasks: open-ended multi-turn question answering, closed-ended multi-turn
question answering, multi-image joint reasoning, and comprehensive disease
diagnosis. Each case is derived from real diagnostic workflows and incorporates
temporal interactions between textual medical histories and multiple imaging
modalities, including CT, MRI, PET, ultrasound, and X-ray, requiring models to
perform deep integrative reasoning across images and clinical texts. MedAtlas
provides expert-annotated gold standards for all tasks. Furthermore, we propose
two novel evaluation metrics: Round Chain Accuracy and Error Propagation
Resistance. Benchmark results with existing multi-modal models reveal
substantial performance gaps in multi-stage clinical reasoning. MedAtlas
establishes a challenging evaluation platform to advance the development of
robust and trustworthy medical AI.

</details>


### [75] [EVCtrl: Efficient Control Adapter for Visual Generation](https://arxiv.org/abs/2508.10963)
*Zixiang Yang,Yue Ma,Yinhan Zhang,Shanhui Mo,Dongrui Liu,Linfeng Zhang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出EVCtrl，一种轻量级控制适配器，通过时空双缓存策略减少冗余计算，提升视频和图像生成效率。


<details>
  <summary>Details</summary>
Motivation: 解决ControlNet在视频生成中因冗余计算导致的高延迟问题。

Method: 采用时空双缓存策略：空间上分区处理，时间上跳过冗余去噪步骤。

Result: 在多个数据集上实现2倍以上的速度提升，生成质量几乎无损。

Conclusion: EVCtrl是一种高效、无需训练的轻量级控制适配器。

Abstract: Visual generation includes both image and video generation, training
probabilistic models to create coherent, diverse, and semantically faithful
content from scratch. While early research focused on unconditional sampling,
practitioners now demand controllable generation that allows precise
specification of layout, pose, motion, or style. While ControlNet grants
precise spatial-temporal control, its auxiliary branch markedly increases
latency and introduces redundant computation in both uncontrolled regions and
denoising steps, especially for video. To address this problem, we introduce
EVCtrl, a lightweight, plug-and-play control adapter that slashes overhead
without retraining the model. Specifically, we propose a spatio-temporal dual
caching strategy for sparse control information. For spatial redundancy, we
first profile how each layer of DiT-ControlNet responds to fine-grained
control, then partition the network into global and local functional zones. A
locality-aware cache focuses computation on the local zones that truly need the
control signal, skipping the bulk of redundant computation in global regions.
For temporal redundancy, we selectively omit unnecessary denoising steps to
improve efficiency. Extensive experiments on CogVideo-Controlnet,
Wan2.1-Controlnet, and Flux demonstrate that our method is effective in image
and video control generation without the need for training. For example, it
achieves 2.16 and 2.05 times speedups on CogVideo-Controlnet and
Wan2.1-Controlnet, respectively, with almost no degradation in generation
quality.Codes are available in the supplementary materials.

</details>


### [76] [Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision](https://arxiv.org/abs/2508.10972)
*Rosiana Natalie,Wenqian Xu,Ruei-Che Chang,Rada Mihalcea,Anhong Guo*

Main category: cs.CV

Relevance: 40.0

TL;DR: 该论文研究了视觉语言模型（VLMs）在模拟低视力人群视觉感知方面的能力，通过构建基准数据集和评估VLM生成响应的准确性。


<details>
  <summary>Details</summary>
Motivation: 探索VLMs在无障碍领域的应用潜力，填补了此前研究的空白。

Method: 通过调查收集低视力参与者的视觉信息和图像感知数据，构建VLM提示并评估其生成响应的准确性。

Result: VLM在仅提供少量提示时表现不佳（一致性0.59），但结合视觉信息和示例图像响应后一致性显著提高（0.70）。

Conclusion: VLMs在模拟低视力人群视觉感知时需要结合多模态信息以提高准确性。

Abstract: Advances in vision language models (VLMs) have enabled the simulation of
general human behavior through their reasoning and problem solving
capabilities. However, prior research has not investigated such simulation
capabilities in the accessibility domain. In this paper, we evaluate the extent
to which VLMs can simulate the vision perception of low vision individuals when
interpreting images. We first compile a benchmark dataset through a survey
study with 40 low vision participants, collecting their brief and detailed
vision information and both open-ended and multiple-choice image perception and
recognition responses to up to 25 images. Using these responses, we construct
prompts for VLMs (GPT-4o) to create simulated agents of each participant,
varying the included information on vision information and example image
responses. We evaluate the agreement between VLM-generated responses and
participants' original answers. Our results indicate that VLMs tend to infer
beyond the specified vision ability when given minimal prompts, resulting in
low agreement (0.59). The agreement between the agent' and participants'
responses remains low when only either the vision information (0.59) or example
image responses (0.59) are provided, whereas a combination of both
significantly increase the agreement (0.70, p < 0.0001). Notably, a single
example combining both open-ended and multiple-choice responses, offers
significant performance improvements over either alone (p < 0.0001), while
additional examples provided minimal benefits (p > 0.05).

</details>


### [77] [Are Large Pre-trained Vision Language Models Effective Construction Safety Inspectors?](https://arxiv.org/abs/2508.11011)
*Xuezheng Chen,Zhengbo Zou*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了ConstructionSite 10k数据集，包含10,000张建筑工地图像，用于评估和微调视觉语言模型（VLMs）在建筑安全检查中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏公开数据集来全面评估和微调VLMs在建筑安全检查中的应用，现有数据集规模小且监督有限。

Method: 构建包含图像描述、安全规则违反视觉问答（VQA）和建筑元素视觉定位三个任务的10k数据集，并评估现有VLMs的零样本和少样本性能。

Result: 现有VLMs在零样本和少样本设置下表现出显著的泛化能力，但仍需额外训练以适应实际建筑工地场景。

Conclusion: ConstructionSite 10k为研究人员提供了训练和评估VLMs的基准，推动了建筑安全检查领域的发展。

Abstract: Construction safety inspections typically involve a human inspector
identifying safety concerns on-site. With the rise of powerful Vision Language
Models (VLMs), researchers are exploring their use for tasks such as detecting
safety rule violations from on-site images. However, there is a lack of open
datasets to comprehensively evaluate and further fine-tune VLMs in construction
safety inspection. Current applications of VLMs use small, supervised datasets,
limiting their applicability in tasks they are not directly trained for. In
this paper, we propose the ConstructionSite 10k, featuring 10,000 construction
site images with annotations for three inter-connected tasks, including image
captioning, safety rule violation visual question answering (VQA), and
construction element visual grounding. Our subsequent evaluation of current
state-of-the-art large pre-trained VLMs shows notable generalization abilities
in zero-shot and few-shot settings, while additional training is needed to make
them applicable to actual construction sites. This dataset allows researchers
to train and evaluate their own VLMs with new architectures and techniques,
providing a valuable benchmark for construction safety inspection.

</details>


### [78] [Can Multi-modal (reasoning) LLMs detect document manipulation?](https://arxiv.org/abs/2508.11021)
*Zisheng Liang,Kidus Zewde,Rudra Pratap Singh,Disha Patil,Zexi Chen,Jiayu Xue,Yao Yao,Yifei Chen,Qinzhe Liu,Simiao Ren*

Main category: cs.CV

Relevance: 40.0

TL;DR: 该研究评估了多模态大语言模型（LLMs）在检测文档欺诈中的表现，发现部分模型在零样本泛化能力上优于传统方法，但模型大小与检测准确性相关性有限。


<details>
  <summary>Details</summary>
Motivation: 文档欺诈对依赖安全文档的行业构成威胁，需要有效的检测方法。研究旨在探索多模态LLMs在此任务中的潜力。

Method: 通过提示优化和模型推理过程分析，评估LLMs在检测欺诈文档中的能力，包括篡改文本、格式不一致等指标。

Result: 部分多模态LLMs在零样本泛化能力上表现优异，但模型大小与检测准确性相关性不高，任务特定微调是关键。

Conclusion: 多模态LLMs在文档欺诈检测中具有潜力，未来研究应关注可解释性和可扩展性。

Abstract: Document fraud poses a significant threat to industries reliant on secure and
verifiable documentation, necessitating robust detection mechanisms. This study
investigates the efficacy of state-of-the-art multi-modal large language models
(LLMs)-including OpenAI O1, OpenAI 4o, Gemini Flash (thinking), Deepseek Janus,
Grok, Llama 3.2 and 4, Qwen 2 and 2.5 VL, Mistral Pixtral, and Claude 3.5 and
3.7 Sonnet-in detecting fraudulent documents. We benchmark these models against
each other and prior work on document fraud detection techniques using a
standard dataset with real transactional documents. Through prompt optimization
and detailed analysis of the models' reasoning processes, we evaluate their
ability to identify subtle indicators of fraud, such as tampered text,
misaligned formatting, and inconsistent transactional sums. Our results reveal
that top-performing multi-modal LLMs demonstrate superior zero-shot
generalization, outperforming conventional methods on out-of-distribution
datasets, while several vision LLMs exhibit inconsistent or subpar performance.
Notably, model size and advanced reasoning capabilities show limited
correlation with detection accuracy, suggesting task-specific fine-tuning is
critical. This study underscores the potential of multi-modal LLMs in enhancing
document fraud detection systems and provides a foundation for future research
into interpretable and scalable fraud mitigation strategies.

</details>


### [79] [MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation](https://arxiv.org/abs/2508.11032)
*Yanwu Yang,Guinan Su,Jiesi Hu,Francesco Sammarco,Jonas Geiping,Thomas Wolfers*

Main category: cs.CV

Relevance: 40.0

TL;DR: MedSAMix是一种无需训练的模型融合方法，结合通用模型（如SAM）和专用模型（如MedSAM）的优势，用于医学图像分割。通过零阶优化自动发现最优层融合方案，并在25个医学分割任务中验证其性能提升。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割模型的通用性受限于数据异质性、标注稀缺和分布偏移，现有方法如MedSAM泛化能力不足。

Method: 提出MedSAMix，采用零阶优化自动融合通用和专用模型，并设计单任务和多目标优化两种策略。

Result: 在25个任务中，MedSAMix显著提升性能，专用任务和通用任务分别提高6.67%和4.37%。

Conclusion: MedSAMix有效减少模型偏差，提升医学图像分割的领域适应性和泛化能力。

Abstract: Universal medical image segmentation models have emerged as a promising
paradigm due to their strong generalizability across diverse tasks, showing
great potential for a wide range of clinical applications. This potential has
been partly driven by the success of general-purpose vision models such as the
Segment Anything Model (SAM), which has inspired the development of various
fine-tuned variants for medical segmentation tasks. However, fine-tuned
variants like MedSAM are trained on comparatively limited medical imaging data
that often suffers from heterogeneity, scarce annotations, and distributional
shifts. These challenges limit their ability to generalize across a wide range
of medical segmentation tasks. In this regard, we propose MedSAMix, a
training-free model merging method that integrates the strengths of both
generalist models (e.g., SAM) and specialist models (e.g., MedSAM) for medical
image segmentation. In contrast to traditional model merging approaches that
rely on manual configuration and often result in suboptimal outcomes, we
propose a zero-order optimization method to automatically discover optimal
layer-wise merging solutions. Furthermore, for clinical applications, we
develop two regimes to meet the demand of domain-specificity and
generalizability in different scenarios by single-task optimization and
multi-objective optimization respectively. Extensive evaluations on 25 medical
segmentation tasks demonstrate that MedSAMix effectively mitigates model bias
and consistently improves performance in both domain-specific accuracy and
generalization, achieving improvements of 6.67% on specialized tasks and 4.37%
on multi-task evaluations.

</details>


### [80] [Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset](https://arxiv.org/abs/2508.11058)
*Wentao Mo,Qingchao Chen,Yuxin Peng,Siyuan Huang,Yang Liu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了MV-ScanQA数据集和TripAlign预训练语料库，以解决现有3D视觉语言数据集的局限性，并开发了LEGO方法，在3D场景理解任务中取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉语言数据集缺乏多视角和上下文对齐的标注，限制了模型对远距离多对象场景的深度理解。

Method: 引入MV-ScanQA数据集测试多视角推理，提出TripAlign预训练语料库进行2D-3D-语言对齐，并开发LEGO方法迁移2D预训练知识到3D领域。

Result: LEGO在MV-ScanQA和现有3D密集描述与问答任务中均达到最优性能。

Conclusion: MV-ScanQA和TripAlign填补了3D视觉语言学习的空白，LEGO展示了多视角推理的有效性。

Abstract: The advancement of 3D vision-language (3D VL) learning is hindered by several
limitations in existing 3D VL datasets: they rarely necessitate reasoning
beyond a close range of objects in single viewpoint, and annotations often link
instructions to single objects, missing richer contextual alignments between
multiple objects. This significantly curtails the development of models capable
of deep, multi-view 3D scene understanding over distant objects. To address
these challenges, we introduce MV-ScanQA, a novel 3D question answering dataset
where 68% of questions explicitly require integrating information from multiple
views (compared to less than 7% in existing datasets), thereby rigorously
testing multi-view compositional reasoning. To facilitate the training of
models for such demanding scenarios, we present TripAlign dataset, a
large-scale and low-cost 2D-3D-language pre-training corpus containing 1M <2D
view, set of 3D objects, text> triplets that explicitly aligns groups of
contextually related objects with text, providing richer, view-grounded
multi-object multimodal alignment signals than previous single-object
annotations. We further develop LEGO, a baseline method for the multi-view
reasoning challenge in MV-ScanQA, transferring knowledge from pre-trained 2D
LVLMs to 3D domain with TripAlign. Empirically, LEGO pre-trained on TripAlign
achieves state-of-the-art performance not only on the proposed MV-ScanQA, but
also on existing benchmarks for 3D dense captioning and question answering.
Datasets and code are available at
https://matthewdm0816.github.io/tripalign-mvscanqa.

</details>


### [81] [HierOctFusion: Multi-scale Octree-based 3D Shape Generation via Part-Whole-Hierarchy Message Passing](https://arxiv.org/abs/2508.11106)
*Xinjie Gao,Bi'an Du,Wei Hu*

Main category: cs.CV

Relevance: 40.0

TL;DR: HierOctFusion是一种基于多尺度八叉树扩散模型的方法，通过分层特征交互和跨注意力机制生成细粒度3D内容，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法将3D对象视为整体，忽略了语义部分层次结构，且高分辨率建模计算成本高。HierOctFusion旨在解决这些问题。

Method: 提出HierOctFusion，结合多尺度八叉树扩散模型和跨注意力机制，利用部分层次信息生成3D内容。

Result: 实验表明，HierOctFusion在形状质量和效率上优于现有方法。

Conclusion: HierOctFusion通过分层生成和部分感知机制，显著提升了3D内容生成的效果。

Abstract: 3D content generation remains a fundamental yet challenging task due to the
inherent structural complexity of 3D data. While recent octree-based diffusion
models offer a promising balance between efficiency and quality through
hierarchical generation, they often overlook two key insights: 1) existing
methods typically model 3D objects as holistic entities, ignoring their
semantic part hierarchies and limiting generalization; and 2) holistic
high-resolution modeling is computationally expensive, whereas real-world
objects are inherently sparse and hierarchical, making them well-suited for
layered generation. Motivated by these observations, we propose HierOctFusion,
a part-aware multi-scale octree diffusion model that enhances hierarchical
feature interaction for generating fine-grained and sparse object structures.
Furthermore, we introduce a cross-attention conditioning mechanism that injects
part-level information into the generation process, enabling semantic features
to propagate effectively across hierarchical levels from parts to the whole.
Additionally, we construct a 3D dataset with part category annotations using a
pre-trained segmentation model to facilitate training and evaluation.
Experiments demonstrate that HierOctFusion achieves superior shape quality and
efficiency compared to prior methods.

</details>


### [82] [A Cross-Modal Rumor Detection Scheme via Contrastive Learning by Exploring Text and Image internal Correlations](https://arxiv.org/abs/2508.11141)
*Bin Ma,Yifei Zhang,Yongjin Xian,Qi Li,Linna Zhou,Gongxun Miao*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于对比学习的多尺度图像与上下文关联的谣言检测方法（MICC），通过SCLIP编码器和跨模态多尺度对齐模块，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有谣言检测方法常忽略图像内容及多尺度上下文关系，导致关键信息丢失。

Method: 使用SCLIP编码器生成统一语义嵌入，跨模态多尺度对齐模块基于互信息最大化选择相关图像区域，并通过尺度感知融合网络整合特征。

Result: 在两个真实数据集上表现优于现有方法。

Conclusion: MICC方法有效且具有实际应用潜力。

Abstract: Existing rumor detection methods often neglect the content within images as
well as the inherent relationships between contexts and images across different
visual scales, thereby resulting in the loss of critical information pertinent
to rumor identification. To address these issues, this paper presents a novel
cross-modal rumor detection scheme based on contrastive learning, namely the
Multi-scale Image and Context Correlation exploration algorithm (MICC).
Specifically, we design an SCLIP encoder to generate unified semantic
embeddings for text and multi-scale image patches through contrastive
pretraining, enabling their relevance to be measured via dot-product
similarity. Building upon this, a Cross-Modal Multi-Scale Alignment module is
introduced to identify image regions most relevant to the textual semantics,
guided by mutual information maximization and the information bottleneck
principle, through a Top-K selection strategy based on a cross-modal relevance
matrix constructed between the text and multi-scale image patches. Moreover, a
scale-aware fusion network is designed to integrate the highly correlated
multi-scale image features with global text features by assigning adaptive
weights to image regions based on their semantic importance and cross-modal
relevance. The proposed methodology has been extensively evaluated on two
real-world datasets. The experimental results demonstrate that it achieves a
substantial performance improvement over existing state-of-the-art approaches
in rumor detection, highlighting its effectiveness and potential for practical
applications.

</details>


### [83] [LEARN: A Story-Driven Layout-to-Image Generation Framework for STEM Instruction](https://arxiv.org/abs/2508.11153)
*Maoquan Zhang,Bisser Raytchev,Xiujuan Sun*

Main category: cs.CV

Relevance: 40.0

TL;DR: LEARN是一个布局感知的扩散框架，用于生成与STEM教育内容对齐的插图，通过布局条件生成和视觉语义训练提升教学效果。


<details>
  <summary>Details</summary>
Motivation: 解决STEM教育中抽象科学概念的可视化问题，减少认知负荷，提升学习效果。

Method: 利用BookCover数据集，结合布局条件生成、对比视觉语义训练和提示调制技术。

Result: 生成连贯的视觉序列，支持中高级推理，减少认知负荷，提升学习专注度。

Conclusion: LEARN为教育领域的生成AI提供了新方向，具有多模态系统和知识图谱集成的潜力。

Abstract: LEARN is a layout-aware diffusion framework designed to generate
pedagogically aligned illustrations for STEM education. It leverages a curated
BookCover dataset that provides narrative layouts and structured visual cues,
enabling the model to depict abstract and sequential scientific concepts with
strong semantic alignment. Through layout-conditioned generation, contrastive
visual-semantic training, and prompt modulation, LEARN produces coherent visual
sequences that support mid-to-high-level reasoning in line with Bloom's
taxonomy while reducing extraneous cognitive load as emphasized by Cognitive
Load Theory. By fostering spatially organized and story-driven narratives, the
framework counters fragmented attention often induced by short-form media and
promotes sustained conceptual focus. Beyond static diagrams, LEARN demonstrates
potential for integration with multimodal systems and curriculum-linked
knowledge graphs to create adaptive, exploratory educational content. As the
first generative approach to unify layout-based storytelling, semantic
structure learning, and cognitive scaffolding, LEARN represents a novel
direction for generative AI in education. The code and dataset will be released
to facilitate future research and practical deployment.

</details>


### [84] [VFM-Guided Semi-Supervised Detection Transformer for Source-Free Object Detection in Remote Sensing Images](https://arxiv.org/abs/2508.11167)
*Jianhong Han,Yupei Wang,Liang Chen*

Main category: cs.CV

Relevance: 40.0

TL;DR: VG-DETR是一种基于半监督框架的源自由目标检测方法，利用视觉基础模型（VFM）提升伪标签质量，并通过双级对齐增强特征表示。


<details>
  <summary>Details</summary>
Motivation: 解决源自由目标检测（SFOD）中伪标签噪声问题，尤其是在遥感图像中密集物体和复杂背景下的训练崩溃问题。

Method: 提出VG-DETR，结合视觉基础模型（VFM），通过伪标签挖掘策略和双级对齐方法（实例级和图像级）优化特征提取和伪标签质量。

Result: VG-DETR在源自由遥感检测任务中表现优异。

Conclusion: VG-DETR通过VFM的集成和双级对齐，显著提升了SFOD的性能和鲁棒性。

Abstract: Unsupervised domain adaptation methods have been widely explored to bridge
domain gaps. However, in real-world remote-sensing scenarios, privacy and
transmission constraints often preclude access to source domain data, which
limits their practical applicability. Recently, Source-Free Object Detection
(SFOD) has emerged as a promising alternative, aiming at cross-domain
adaptation without relying on source data, primarily through a self-training
paradigm. Despite its potential, SFOD frequently suffers from training collapse
caused by noisy pseudo-labels, especially in remote sensing imagery with dense
objects and complex backgrounds. Considering that limited target domain
annotations are often feasible in practice, we propose a Vision
foundation-Guided DEtection TRansformer (VG-DETR), built upon a semi-supervised
framework for SFOD in remote sensing images. VG-DETR integrates a Vision
Foundation Model (VFM) into the training pipeline in a "free lunch" manner,
leveraging a small amount of labeled target data to mitigate pseudo-label noise
while improving the detector's feature-extraction capability. Specifically, we
introduce a VFM-guided pseudo-label mining strategy that leverages the VFM's
semantic priors to further assess the reliability of the generated
pseudo-labels. By recovering potentially correct predictions from
low-confidence outputs, our strategy improves pseudo-label quality and
quantity. In addition, a dual-level VFM-guided alignment method is proposed,
which aligns detector features with VFM embeddings at both the instance and
image levels. Through contrastive learning among fine-grained prototypes and
similarity matching between feature maps, this dual-level alignment further
enhances the robustness of feature representations against domain gaps.
Extensive experiments demonstrate that VG-DETR achieves superior performance in
source-free remote sensing detection tasks.

</details>


### [85] [Better Supervised Fine-tuning for VQA: Integer-Only Loss](https://arxiv.org/abs/2508.11170)
*Baihong Qian,Haotian Fan,Wenjie Liao,Yunqiu Wang,Tao Li,Junhui Cui*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为IOVQA的微调方法，用于提升视觉语言模型在视频质量评估任务中的性能，通过整数标签和目标掩码策略优化模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在评估视觉内容时存在结果不精确和损失计算效率低的问题，限制了模型对关键评估指标的关注。

Method: 提出IOVQA方法，包括整数标签构造和目标掩码策略，约束模型输出为整数并优化损失计算。

Result: 实验表明，该方法显著提升了模型在VQA任务中的准确性和一致性，在VQualA 2025挑战赛中排名第三。

Conclusion: 整数标签微调对优化视觉语言模型在定量评估场景中表现有效。

Abstract: With the rapid advancement of vision language models(VLM), their ability to
assess visual content based on specific criteria and dimensions has become
increasingly critical for applications such as video-theme consistency
assessment and visual quality scoring. However, existing methods often suffer
from imprecise results and inefficient loss calculation, which limit the focus
of the model on key evaluation indicators. To address this, we propose
IOVQA(Integer-only VQA), a novel fine-tuning approach tailored for VLMs to
enhance their performance in video quality assessment tasks. The key innovation
of IOVQA lies in its label construction and its targeted loss calculation
mechanism. Specifically, during dataset curation, we constrain the model's
output to integers within the range of [10,50], ensuring numerical stability,
and convert decimal Overall_MOS to integer before using them as labels. We also
introduce a target-mask strategy: when computing the loss, only the first
two-digit-integer of the label is unmasked, forcing the model to learn the
critical components of the numerical evaluation. After fine-tuning the
Qwen2.5-VL model using the constructed dataset, experimental results
demonstrate that the proposed method significantly improves the model's
accuracy and consistency in the VQA task, ranking 3rd in VQualA 2025
GenAI-Bench AIGC Video Quality Assessment Challenge -- Track I. Our work
highlights the effectiveness of merely leaving integer labels during
fine-tuning, providing an effective idea for optimizing VLMs in quantitative
evaluation scenarios.

</details>


### [86] [Exploring the Tradeoff Between Diversity and Discrimination for Continuous Category Discovery](https://arxiv.org/abs/2508.11173)
*Ruobing Jiang,Yang Liu,Haobing Liu,Yanwei Yu,Chunyang Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为IDOD的方法，用于连续类别发现（CCD），通过独立多样性模块、联合新颖性发现模块和正交性增量模块，解决了现有方法在分类与发现新类别之间的矛盾，并减少了存储空间占用。


<details>
  <summary>Details</summary>
Motivation: CCD任务中，现有方法难以平衡新类别发现与分类，且容易累积错误，同时存储开销大。

Method: IDOD方法包括独立多样性模块（对比损失训练）、联合新颖性发现模块（单阶段发现）和正交性增量模块（正交原型生成与低开销重放）。

Result: 在细粒度数据集上，IDOD优于现有方法。

Conclusion: IDOD有效解决了CCD中的矛盾问题，并降低了存储需求。

Abstract: Continuous category discovery (CCD) aims to automatically discover novel
categories in continuously arriving unlabeled data. This is a challenging
problem considering that there is no number of categories and labels in the
newly arrived data, while also needing to mitigate catastrophic forgetting.
Most CCD methods cannot handle the contradiction between novel class discovery
and classification well. They are also prone to accumulate errors in the
process of gradually discovering novel classes. Moreover, most of them use
knowledge distillation and data replay to prevent forgetting, occupying more
storage space. To address these limitations, we propose Independence-based
Diversity and Orthogonality-based Discrimination (IDOD). IDOD mainly includes
independent enrichment of diversity module, joint discovery of novelty module,
and continuous increment by orthogonality module. In independent enrichment,
the backbone is trained separately using contrastive loss to avoid it focusing
only on features for classification. Joint discovery transforms multi-stage
novel class discovery into single-stage, reducing error accumulation impact.
Continuous increment by orthogonality module generates mutually orthogonal
prototypes for classification and prevents forgetting with lower space overhead
via representative representation replay. Experimental results show that on
challenging fine-grained datasets, our method outperforms the state-of-the-art
methods.

</details>


### [87] [A Coarse-to-Fine Human Pose Estimation Method based on Two-stage Distillation and Progressive Graph Neural Network](https://arxiv.org/abs/2508.11212)
*Zhangjian Ji,Wenjin Zhang,Shaotong Qiao,Kai Feng,Yuhua Qian*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种新颖的从粗到细的两阶段知识蒸馏框架，用于轻量级人体姿态估计，通过挖掘关节结构信息和渐进式图卷积网络提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态估计方法计算资源消耗大，而传统知识蒸馏未充分利用关节上下文信息，因此需要一种更高效且准确的轻量级方法。

Method: 两阶段知识蒸馏：第一阶段引入关节结构损失传递高级语义知识；第二阶段使用渐进式图卷积网络（IGP-GCN）细化姿态。

Result: 在COCO和CrowdPose数据集上表现优异，尤其在复杂场景下性能提升显著。

Conclusion: 提出的框架有效提升了轻量级姿态估计的准确性和鲁棒性。

Abstract: Human pose estimation has been widely applied in the human-centric
understanding and generation, but most existing state-of-the-art human pose
estimation methods require heavy computational resources for accurate
predictions. In order to obtain an accurate, robust yet lightweight human pose
estimator, one feasible way is to transfer pose knowledge from a powerful
teacher model to a less-parameterized student model by knowledge distillation.
However, the traditional knowledge distillation framework does not fully
explore the contextual information among human joints. Thus, in this paper, we
propose a novel coarse-to-fine two-stage knowledge distillation framework for
human pose estimation. In the first-stage distillation, we introduce the human
joints structure loss to mine the structural information among human joints so
as to transfer high-level semantic knowledge from the teacher model to the
student model. In the second-stage distillation, we utilize an Image-Guided
Progressive Graph Convolutional Network (IGP-GCN) to refine the initial human
pose obtained from the first-stage distillation and supervise the training of
the IGP-GCN in the progressive way by the final output pose of teacher model.
The extensive experiments on the benchmark dataset: COCO keypoint and CrowdPose
datasets, show that our proposed method performs favorably against lots of the
existing state-of-the-art human pose estimation methods, especially for the
more complex CrowdPose dataset, the performance improvement of our model is
more significant.

</details>


### [88] [A CLIP-based Uncertainty Modal Modeling (UMM) Framework for Pedestrian Re-Identification in Autonomous Driving](https://arxiv.org/abs/2508.11218)
*Jialin Li,Shuqi Wu,Ning Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种轻量级不确定性模态建模（UMM）框架，用于解决自动驾驶中行人重识别（ReID）的多模态输入不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中行人重识别面临多模态输入（如RGB、红外、文本描述）不确定或缺失的挑战，现有方法计算开销大，难以部署。

Method: UMM框架结合多模态令牌映射器、合成模态增强策略和跨模态线索交互学习器，利用CLIP的视觉-语言对齐能力高效融合多模态输入。

Result: 实验表明UMM在不确定模态条件下具有强鲁棒性、泛化能力和计算效率。

Conclusion: UMM为自动驾驶中的行人重识别提供了可扩展且实用的解决方案。

Abstract: Re-Identification (ReID) is a critical technology in intelligent perception
systems, especially within autonomous driving, where onboard cameras must
identify pedestrians across views and time in real-time to support safe
navigation and trajectory prediction. However, the presence of uncertain or
missing input modalities--such as RGB, infrared, sketches, or textual
descriptions--poses significant challenges to conventional ReID approaches.
While large-scale pre-trained models offer strong multimodal semantic modeling
capabilities, their computational overhead limits practical deployment in
resource-constrained environments. To address these challenges, we propose a
lightweight Uncertainty Modal Modeling (UMM) framework, which integrates a
multimodal token mapper, synthetic modality augmentation strategy, and
cross-modal cue interactive learner. Together, these components enable unified
feature representation, mitigate the impact of missing modalities, and extract
complementary information across different data types. Additionally, UMM
leverages CLIP's vision-language alignment ability to fuse multimodal inputs
efficiently without extensive finetuning. Experimental results demonstrate that
UMM achieves strong robustness, generalization, and computational efficiency
under uncertain modality conditions, offering a scalable and practical solution
for pedestrian re-identification in autonomous driving scenarios.

</details>


### [89] [FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation](https://arxiv.org/abs/2508.11255)
*MengChao Wang,Qiang Wang,Fan Jiang,Mu Xu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种多模态奖励模型Talking-Critic和一个大规模多维偏好数据集Talking-NSQ，并开发了TLPO框架，用于优化音频驱动肖像动画的多维偏好对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在多维偏好（如动作自然性、唇同步准确性和视觉质量）之间优化，且缺乏高质量的多维偏好标注数据集。

Method: 1. 引入Talking-Critic奖励模型学习人类对齐的奖励函数；2. 构建Talking-NSQ数据集（410K偏好对）；3. 提出TLPO框架，通过分专家模块和跨时间步与网络层融合优化偏好。

Result: Talking-Critic在人类偏好评分上显著优于现有方法；TLPO在唇同步、动作自然性和视觉质量上大幅提升。

Conclusion: TLPO框架有效解决了多维偏好优化问题，显著提升了生成视频的质量。

Abstract: Recent advances in audio-driven portrait animation have demonstrated
impressive capabilities. However, existing methods struggle to align with
fine-grained human preferences across multiple dimensions, such as motion
naturalness, lip-sync accuracy, and visual quality. This is due to the
difficulty of optimizing among competing preference objectives, which often
conflict with one another, and the scarcity of large-scale, high-quality
datasets with multidimensional preference annotations. To address these, we
first introduce Talking-Critic, a multimodal reward model that learns
human-aligned reward functions to quantify how well generated videos satisfy
multidimensional expectations. Leveraging this model, we curate Talking-NSQ, a
large-scale multidimensional human preference dataset containing 410K
preference pairs. Finally, we propose Timestep-Layer adaptive multi-expert
Preference Optimization (TLPO), a novel framework for aligning diffusion-based
portrait animation models with fine-grained, multidimensional preferences. TLPO
decouples preferences into specialized expert modules, which are then fused
across timesteps and network layers, enabling comprehensive, fine-grained
enhancement across all dimensions without mutual interference. Experiments
demonstrate that Talking-Critic significantly outperforms existing methods in
aligning with human preference ratings. Meanwhile, TLPO achieves substantial
improvements over baseline models in lip-sync accuracy, motion naturalness, and
visual quality, exhibiting superior performance in both qualitative and
quantitative evaluations. Ours project page:
https://fantasy-amap.github.io/fantasy-talking2/

</details>


### [90] [Generalized Decoupled Learning for Enhancing Open-Vocabulary Dense Perception](https://arxiv.org/abs/2508.11256)
*Junjie Wang,Keyu Chen,Yulin Li,Bin Chen,Hengshuang Zhao,Xiaojuan Qi,Zhuotao Tian*

Main category: cs.CV

Relevance: 40.0

TL;DR: DeCLIP enhances CLIP by decoupling self-attention to improve local discriminability and spatial consistency for dense visual perception tasks.


<details>
  <summary>Details</summary>
Motivation: Address limitations of VLMs like CLIP in dense perception due to poor local feature representation.

Method: Decouples self-attention into 'content' and 'context' features, enhanced by distillation from VFMs and diffusion models.

Result: Achieves state-of-the-art performance in various dense perception tasks.

Conclusion: DeCLIP provides a robust framework for open-vocabulary dense perception.

Abstract: Dense visual perception tasks have been constrained by their reliance on
predefined categories, limiting their applicability in real-world scenarios
where visual concepts are unbounded. While Vision-Language Models (VLMs) like
CLIP have shown promise in open-vocabulary tasks, their direct application to
dense perception often leads to suboptimal performance due to limitations in
local feature representation. In this work, we present our observation that
CLIP's image tokens struggle to effectively aggregate information from
spatially or semantically related regions, resulting in features that lack
local discriminability and spatial consistency. To address this issue, we
propose DeCLIP, a novel framework that enhances CLIP by decoupling the
self-attention module to obtain ``content'' and ``context'' features
respectively. \revise{The context features are enhanced by jointly distilling
semantic correlations from Vision Foundation Models (VFMs) and object integrity
cues from diffusion models, thereby enhancing spatial consistency. In parallel,
the content features are aligned with image crop representations and
constrained by region correlations from VFMs to improve local discriminability.
Extensive experiments demonstrate that DeCLIP establishes a solid foundation
for open-vocabulary dense perception, consistently achieving state-of-the-art
performance across a broad spectrum of tasks, including 2D detection and
segmentation, 3D instance segmentation, video instance segmentation, and 6D
object pose estimation.} Code is available at
https://github.com/xiaomoguhz/DeCLIP

</details>


### [91] [Domain-aware Category-level Geometry Learning Segmentation for 3D Point Clouds](https://arxiv.org/abs/2508.11265)
*Pei He,Lingling Li,Licheng Jiao,Ronghua Shang,Fang Liu,Shuang Wang,Xu Liu,Wenping Ma*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于类别级几何学习的框架，用于解决3D语义分割中的领域泛化问题，通过几何嵌入和一致性学习提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法在点云数据中学习全局几何模式，但忽略了类别级分布和对齐，导致领域泛化效果不佳。

Method: 提出类别级几何嵌入（CGE）感知点云特征的细粒度几何属性，并结合几何一致性学习（GCL）对齐类别级几何嵌入。

Result: 实验证明该方法在领域泛化点云分割任务中具有竞争力。

Conclusion: 通过几何特征学习和一致性对齐，显著提升了模型在未见环境中的泛化能力。

Abstract: Domain generalization in 3D segmentation is a critical challenge in deploying
models to unseen environments. Current methods mitigate the domain shift by
augmenting the data distribution of point clouds. However, the model learns
global geometric patterns in point clouds while ignoring the category-level
distribution and alignment. In this paper, a category-level geometry learning
framework is proposed to explore the domain-invariant geometric features for
domain generalized 3D semantic segmentation. Specifically, Category-level
Geometry Embedding (CGE) is proposed to perceive the fine-grained geometric
properties of point cloud features, which constructs the geometric properties
of each class and couples geometric embedding to semantic learning. Secondly,
Geometric Consistent Learning (GCL) is proposed to simulate the latent 3D
distribution and align the category-level geometric embeddings, allowing the
model to focus on the geometric invariant information to improve
generalization. Experimental results verify the effectiveness of the proposed
method, which has very competitive segmentation accuracy compared with the
state-of-the-art domain generalized point cloud methods.

</details>


### [92] [Enhancing Supervised Composed Image Retrieval via Reasoning-Augmented Representation Engineering](https://arxiv.org/abs/2508.11272)
*Jun Li,Kai Li,Shaoguo Liu,Tingting Gao*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为PMTFR的框架，通过Pyramid Patcher模块增强视觉信息理解，并结合训练无关的优化方法提升CIR任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有CIR方法在监督任务中表现不佳的问题，尤其是避免额外训练和复杂提示设计。

Method: 使用Pyramid Matching Model和Training-Free Refinement，结合COoT数据表示注入LVLMs。

Result: 在CIR基准测试中表现优于现有方法。

Conclusion: PMTFR框架在监督CIR任务中有效且高效。

Abstract: Composed Image Retrieval (CIR) presents a significant challenge as it
requires jointly understanding a reference image and a modified textual
instruction to find relevant target images. Some existing methods attempt to
use a two-stage approach to further refine retrieval results. However, this
often requires additional training of a ranking model. Despite the success of
Chain-of-Thought (CoT) techniques in reducing training costs for language
models, their application in CIR tasks remains limited -- compressing visual
information into text or relying on elaborate prompt designs. Besides, existing
works only utilize it for zero-shot CIR, as it is challenging to achieve
satisfactory results in supervised CIR with a well-trained model. In this work,
we proposed a framework that includes the Pyramid Matching Model with
Training-Free Refinement (PMTFR) to address these challenges. Through a simple
but effective module called Pyramid Patcher, we enhanced the Pyramid Matching
Model's understanding of visual information at different granularities.
Inspired by representation engineering, we extracted representations from COT
data and injected them into the LVLMs. This approach allowed us to obtain
refined retrieval scores in the Training-Free Refinement paradigm without
relying on explicit textual reasoning, further enhancing performance. Extensive
experiments on CIR benchmarks demonstrate that PMTFR surpasses state-of-the-art
methods in supervised CIR tasks. The code will be made public.

</details>


### [93] [Denoise-then-Retrieve: Text-Conditioned Video Denoising for Video Moment Retrieval](https://arxiv.org/abs/2508.11313)
*Weijia Liu,Jiuxin Cao,Bo Miao,Zhiheng Fu,Xuelin Zhu,Jiawei Ge,Bo Liu,Mehwish Nasim,Ajmal Mian*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种去噪后检索的范式（DRNet），通过文本条件去噪（TCD）和文本重构反馈（TRF）模块，过滤视频中与文本无关的片段，提升多模态对齐和检索准确性。


<details>
  <summary>Details</summary>
Motivation: 现有视频时刻检索（VMR）方法编码所有视频片段（包括无关片段），破坏了多模态对齐并阻碍优化。

Method: 提出DRNet，包含TCD模块（动态识别噪声片段并生成噪声掩码）和TRF模块（通过蒸馏查询嵌入辅助监督去噪）。

Result: 在Charades-STA和QVHighlights数据集上超越现有方法。

Conclusion: 去噪后检索范式可提升VMR性能，并兼容现有模型。

Abstract: Current text-driven Video Moment Retrieval (VMR) methods encode all video
clips, including irrelevant ones, disrupting multimodal alignment and hindering
optimization. To this end, we propose a denoise-then-retrieve paradigm that
explicitly filters text-irrelevant clips from videos and then retrieves the
target moment using purified multimodal representations. Following this
paradigm, we introduce the Denoise-then-Retrieve Network (DRNet), comprising
Text-Conditioned Denoising (TCD) and Text-Reconstruction Feedback (TRF)
modules. TCD integrates cross-attention and structured state space blocks to
dynamically identify noisy clips and produce a noise mask to purify multimodal
video representations. TRF further distills a single query embedding from
purified video representations and aligns it with the text embedding, serving
as auxiliary supervision for denoising during training. Finally, we perform
conditional retrieval using text embeddings on purified video representations
for accurate VMR. Experiments on Charades-STA and QVHighlights demonstrate that
our approach surpasses state-of-the-art methods on all metrics. Furthermore,
our denoise-then-retrieve paradigm is adaptable and can be seamlessly
integrated into advanced VMR models to boost performance.

</details>


### [94] [GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution in Face Recognition](https://arxiv.org/abs/2508.11334)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Md Jawadul Hasan,Tze Hui Liew*

Main category: cs.CV

Relevance: 40.0

TL;DR: GANDiff FR是一个合成框架，通过精确控制人口和环境因素来测量、解释和减少偏见，结合了StyleGAN3和扩散模型，实现了对姿态、光照和表情的细粒度控制。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提供一个可重复、可量化的方法来测量和减少AI模型中的偏见，特别是在人脸识别任务中。

Method: 结合StyleGAN3的身份保留生成和扩散模型的属性控制，生成10,000张人口平衡的人脸，并通过自动检测和人工审核验证真实性。

Result: AdaFace在减少组间TPR差异上表现最佳（减少60%），光照是剩余偏见的主要因素（占42%）。合成数据在跨数据集评估中表现出强迁移性（r=0.85）。

Conclusion: GANDiff FR为公平性审计提供了一个可重复、符合法规的标准，尽管计算开销较高，但能生成更多属性条件变体。

Abstract: We introduce GANDiff FR, the first synthetic framework that precisely
controls demographic and environmental factors to measure, explain, and reduce
bias with reproducible rigor. GANDiff FR unifies StyleGAN3-based
identity-preserving generation with diffusion-based attribute control, enabling
fine-grained manipulation of pose around 30 degrees, illumination (four
directions), and expression (five levels) under ceteris paribus conditions. We
synthesize 10,000 demographically balanced faces across five cohorts validated
for realism via automated detection (98.2%) and human review (89%) to isolate
and quantify bias drivers. Benchmarking ArcFace, CosFace, and AdaFace under
matched operating points shows AdaFace reduces inter-group TPR disparity by 60%
(2.5% vs. 6.3%), with illumination accounting for 42% of residual bias.
Cross-dataset evaluation on RFW, BUPT, and CASIA WebFace confirms strong
synthetic-to-real transfer (r 0.85). Despite around 20% computational overhead
relative to pure GANs, GANDiff FR yields three times more attribute-conditioned
variants, establishing a reproducible, regulation-aligned (EU AI Act) standard
for fairness auditing. Code and data are released to support transparent,
scalable bias evaluation.

</details>


### [95] [Semantically Guided Adversarial Testing of Vision Models Using Language Models](https://arxiv.org/abs/2508.11341)
*Katarzyna Filus,Jorge M. Cruz-Duarte*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种基于语义引导的对抗目标选择框架，利用预训练语言和视觉语言模型的跨模态知识转移，提升对抗攻击的可解释性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击的目标标签选择方法依赖随机性、模型预测或静态语义资源，缺乏可解释性和灵活性。

Method: 使用BERT、TinyLLAMA和CLIP等模型作为相似性来源，选择与真实标签最相关和最不相关的标签，构建最佳和最差对抗场景。

Result: 实验表明，这些模型能生成实用的对抗目标，优于静态语义数据库（如WordNet），尤其在远距离类别关系上表现突出。

Conclusion: 预训练模型适合构建可解释、标准化和可扩展的对抗基准。

Abstract: In targeted adversarial attacks on vision models, the selection of the target
label is a critical yet often overlooked determinant of attack success. This
target label corresponds to the class that the attacker aims to force the model
to predict. Now, existing strategies typically rely on randomness, model
predictions, or static semantic resources, limiting interpretability,
reproducibility, or flexibility. This paper then proposes a semantics-guided
framework for adversarial target selection using the cross-modal knowledge
transfer from pretrained language and vision-language models. We evaluate
several state-of-the-art models (BERT, TinyLLAMA, and CLIP) as similarity
sources to select the most and least semantically related labels with respect
to the ground truth, forming best- and worst-case adversarial scenarios. Our
experiments on three vision models and five attack methods reveal that these
models consistently render practical adversarial targets and surpass static
lexical databases, such as WordNet, particularly for distant class
relationships. We also observe that static testing of target labels offers a
preliminary assessment of the effectiveness of similarity sources, \textit{a
priori} testing. Our results corroborate the suitability of pretrained models
for constructing interpretable, standardized, and scalable adversarial
benchmarks across architectures and datasets.

</details>


### [96] [Leveraging the RETFound foundation model for optic disc segmentation in retinal images](https://arxiv.org/abs/2508.11354)
*Zhenyi Zhao,Muthu Rama Krishnan Mookiah,Emanuele Trucco*

Main category: cs.CV

Relevance: 40.0

TL;DR: RETFound是一种用于视网膜图像分析的通用基础模型，首次被用于视盘分割任务，仅需少量任务特定数据即可超越现有分割专用模型。


<details>
  <summary>Details</summary>
Motivation: 探索RETFound在非原始任务（视盘分割）上的适应性，验证基础模型在多任务中的潜力。

Method: 通过微调RETFound的头部，使用少量任务特定数据训练视盘分割系统。

Result: 在多个公共和私有数据集上达到约96%的Dice分数，表现优于现有分割专用模型。

Conclusion: RETFound在视盘分割任务中表现出色，支持基础模型作为任务特定架构的替代方案。

Abstract: RETFound is a well-known foundation model (FM) developed for fundus camera
and optical coherence tomography images. It has shown promising performance
across multiple datasets in diagnosing diseases, both eye-specific and
systemic, from retinal images. However, to our best knowledge, it has not been
used for other tasks. We present the first adaptation of RETFound for optic
disc segmentation, a ubiquitous and foundational task in retinal image
analysis. The resulting segmentation system outperforms state-of-the-art,
segmentation-specific baseline networks after training a head with only a very
modest number of task-specific examples. We report and discuss results with
four public datasets, IDRID, Drishti-GS, RIM-ONE-r3, and REFUGE, and a private
dataset, GoDARTS, achieving about 96% Dice consistently across all datasets.
Overall, our method obtains excellent performance in internal verification,
domain generalization and domain adaptation, and exceeds most of the
state-of-the-art baseline results. We discuss the results in the framework of
the debate about FMs as alternatives to task-specific architectures. The code
is available at: [link to be added after the paper is accepted]

</details>


### [97] [Unified Knowledge Distillation Framework: Fine-Grained Alignment and Geometric Relationship Preservation for Deep Face Recognition](https://arxiv.org/abs/2508.11376)
*Durgesh Mishra,Rishabh Uikey*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种统一的知识蒸馏框架，结合实例级嵌入蒸馏和关系型成对相似性蒸馏，显著提升了人脸识别模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法在捕捉细粒度实例级细节和复杂关系结构方面表现不足，导致性能次优。

Method: 提出两种新损失函数：实例级嵌入蒸馏（动态硬挖掘策略）和关系型成对相似性蒸馏（记忆库机制和样本挖掘策略）。

Result: 在多个基准数据集上优于现有蒸馏方法，学生模型甚至能超越教师模型的准确性。

Conclusion: 统一框架实现了更全面的蒸馏，显著提升了模型性能。

Abstract: Knowledge Distillation is crucial for optimizing face recognition models for
deployment in computationally limited settings, such as edge devices.
Traditional KD methods, such as Raw L2 Feature Distillation or Feature
Consistency loss, often fail to capture both fine-grained instance-level
details and complex relational structures, leading to suboptimal performance.
We propose a unified approach that integrates two novel loss functions,
Instance-Level Embedding Distillation and Relation-Based Pairwise Similarity
Distillation. Instance-Level Embedding Distillation focuses on aligning
individual feature embeddings by leveraging a dynamic hard mining strategy,
thereby enhancing learning from challenging examples. Relation-Based Pairwise
Similarity Distillation captures relational information through pairwise
similarity relationships, employing a memory bank mechanism and a sample mining
strategy. This unified framework ensures both effective instance-level
alignment and preservation of geometric relationships between samples, leading
to a more comprehensive distillation process. Our unified framework outperforms
state-of-the-art distillation methods across multiple benchmark face
recognition datasets, as demonstrated by extensive experimental evaluations.
Interestingly, when using strong teacher networks compared to the student, our
unified KD enables the student to even surpass the teacher's accuracy.

</details>


### [98] [RMFAT: Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator](https://arxiv.org/abs/2508.11409)
*Zhiming Liu,Nantheera Anantrasirichai*

Main category: cs.CV

Relevance: 40.0

TL;DR: RMFAT是一种轻量级循环框架，用于高效恢复受大气湍流影响的视频，显著减少计算负担并提升实时性能。


<details>
  <summary>Details</summary>
Motivation: 大气湍流严重降低视频质量，现有基于Transformer和3D架构的方法计算成本高，难以实时部署。

Method: 采用轻量级循环框架，仅需两帧输入，结合多尺度特征编码和解码模块增强时空一致性。

Result: 在SSIM指标上提升9%，推理速度提高四倍，适用于实时任务。

Conclusion: RMFAT在恢复清晰度和实时性上优于现有方法，适合资源受限场景。

Abstract: Atmospheric turbulence severely degrades video quality by introducing
distortions such as geometric warping, blur, and temporal flickering, posing
significant challenges to both visual clarity and temporal consistency. Current
state-of-the-art methods are based on transformer and 3D architectures and
require multi-frame input, but their large computational cost and memory usage
limit real-time deployment, especially in resource-constrained scenarios. In
this work, we propose RMFAT: Recurrent Multi-scale Feature Atmospheric
Turbulence Mitigator, designed for efficient and temporally consistent video
restoration under AT conditions. RMFAT adopts a lightweight recurrent framework
that restores each frame using only two inputs at a time, significantly
reducing temporal window size and computational burden. It further integrates
multi-scale feature encoding and decoding with temporal warping modules at both
encoder and decoder stages to enhance spatial detail and temporal coherence.
Extensive experiments on synthetic and real-world atmospheric turbulence
datasets demonstrate that RMFAT not only outperforms existing methods in terms
of clarity restoration (with nearly a 9\% improvement in SSIM) but also
achieves significantly improved inference speed (more than a fourfold reduction
in runtime), making it particularly suitable for real-time atmospheric
turbulence suppression tasks.

</details>


### [99] [ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving](https://arxiv.org/abs/2508.11428)
*Jingyu Li,Bozhou Zhang,Xin Jin,Jiankang Deng,Xiatian Zhu,Li Zhang*

Main category: cs.CV

Relevance: 40.0

TL;DR: ImagiDrive integrates Vision-Language Models (VLMs) and Driving World Models (DWMs) for autonomous driving, combining behavioral prediction and scene generation. It addresses efficiency and accuracy challenges with novel strategies.


<details>
  <summary>Details</summary>
Motivation: Autonomous driving requires contextual comprehension and predictive reasoning. VLMs and DWMs offer complementary strengths, but their integration is understudied.

Method: ImagiDrive combines a VLM-based driving agent with a DWM-based scene imaginer in an iterative loop, using early stopping and trajectory selection for efficiency.

Result: ImagiDrive outperforms previous methods on nuScenes and NAVSIM datasets in open-loop and closed-loop conditions.

Conclusion: The integration of VLMs and DWMs in ImagiDrive is effective for autonomous driving, demonstrating robustness and superiority.

Abstract: Autonomous driving requires rich contextual comprehension and precise
predictive reasoning to navigate dynamic and complex environments safely.
Vision-Language Models (VLMs) and Driving World Models (DWMs) have
independently emerged as powerful recipes addressing different aspects of this
challenge. VLMs provide interpretability and robust action prediction through
their ability to understand multi-modal context, while DWMs excel in generating
detailed and plausible future driving scenarios essential for proactive
planning. Integrating VLMs with DWMs is an intuitive, promising, yet
understudied strategy to exploit the complementary strengths of accurate
behavioral prediction and realistic scene generation. Nevertheless, this
integration presents notable challenges, particularly in effectively connecting
action-level decisions with high-fidelity pixel-level predictions and
maintaining computational efficiency. In this paper, we propose ImagiDrive, a
novel end-to-end autonomous driving framework that integrates a VLM-based
driving agent with a DWM-based scene imaginer to form a unified
imagination-and-planning loop. The driving agent predicts initial driving
trajectories based on multi-modal inputs, guiding the scene imaginer to
generate corresponding future scenarios. These imagined scenarios are
subsequently utilized to iteratively refine the driving agent's planning
decisions. To address efficiency and predictive accuracy challenges inherent in
this integration, we introduce an early stopping mechanism and a trajectory
selection strategy. Extensive experimental validation on the nuScenes and
NAVSIM datasets demonstrates the robustness and superiority of ImagiDrive over
previous alternatives under both open-loop and closed-loop conditions.

</details>


### [100] [Data-Driven Deepfake Image Detection Method -- The 2024 Global Deepfake Image Detection Challenge](https://arxiv.org/abs/2508.11464)
*Xiaoya Zhu,Yibing Nan,Shiguo Lian*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种基于Swin Transformer V2-B分类网络的方法，结合在线数据增强和离线样本生成技术，用于检测Deepfake图像，并在竞赛中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，Deepfake技术带来了大量AI生成内容，同时也对数字安全提出了前所未有的挑战。本文旨在解决如何准确检测Deepfake图像的问题。

Method: 采用Swin Transformer V2-B分类网络，结合在线数据增强和离线样本生成方法，以提高模型的泛化能力。

Result: 在Deepfake图像检测竞赛中获得了卓越奖。

Conclusion: 该方法通过结合先进的Transformer架构和数据增强技术，有效提升了Deepfake检测的准确性和泛化能力。

Abstract: With the rapid development of technology in the field of AI, deepfake
technology has emerged as a double-edged sword. It has not only created a large
amount of AI-generated content but also posed unprecedented challenges to
digital security. The task of the competition is to determine whether a face
image is a Deepfake image and output its probability score of being a Deepfake
image. In the image track competition, our approach is based on the Swin
Transformer V2-B classification network. And online data augmentation and
offline sample generation methods are employed to enrich the diversity of
training samples and increase the generalization ability of the model. Finally,
we got the award of excellence in Deepfake image detection.

</details>


### [101] [CineTrans: Learning to Generate Videos with Cinematic Transitions via Masked Diffusion Models](https://arxiv.org/abs/2508.11484)
*Xiaoxue Wu,Bingjie Gao,Yu Qiao,Yaohui Wang,Xinyuan Chen*

Main category: cs.CV

Relevance: 40.0

TL;DR: CineTrans是一个用于生成具有电影风格过渡的多镜头视频的新框架，通过构建带详细镜头注释的数据集和设计基于掩码的控制机制，显著提升了视频生成的连贯性和质量。


<details>
  <summary>Details</summary>
Motivation: 尽管视频合成技术取得了显著进展，但多镜头视频生成的研究仍处于初级阶段，现有模型的镜头过渡能力有限且不稳定。

Method: 构建了Cine250K数据集，分析视频扩散模型中的注意力图与镜头边界的关系，设计了一种基于掩码的控制机制，并在训练中应用。

Result: CineTrans生成的视频在过渡控制、时间一致性和整体质量上显著优于现有基线。

Conclusion: CineTrans通过创新的数据集和控制机制，为多镜头视频生成提供了有效的解决方案。

Abstract: Despite significant advances in video synthesis, research into multi-shot
video generation remains in its infancy. Even with scaled-up models and massive
datasets, the shot transition capabilities remain rudimentary and unstable,
largely confining generated videos to single-shot sequences. In this work, we
introduce CineTrans, a novel framework for generating coherent multi-shot
videos with cinematic, film-style transitions. To facilitate insights into the
film editing style, we construct a multi-shot video-text dataset Cine250K with
detailed shot annotations. Furthermore, our analysis of existing video
diffusion models uncovers a correspondence between attention maps in the
diffusion model and shot boundaries, which we leverage to design a mask-based
control mechanism that enables transitions at arbitrary positions and transfers
effectively in a training-free setting. After fine-tuning on our dataset with
the mask mechanism, CineTrans produces cinematic multi-shot sequences while
adhering to the film editing style, avoiding unstable transitions or naive
concatenations. Finally, we propose specialized evaluation metrics for
transition control, temporal consistency and overall quality, and demonstrate
through extensive experiments that CineTrans significantly outperforms existing
baselines across all criteria.

</details>


### [102] [Perception in Plan: Coupled Perception and Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.11488)
*Bozhou Zhang,Jingyu Li,Nan Song,Li Zhang*

Main category: cs.CV

Relevance: 40.0

TL;DR: VeteranAD提出了一种感知与规划耦合的端到端自动驾驶框架，通过将感知融入规划过程，实现目标导向的感知，提升规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶方法采用感知-规划分离的范式，限制了规划性能。本文旨在通过感知-规划一体化设计，优化自动驾驶性能。

Method: 提出VeteranAD框架，结合多模态锚定轨迹作为规划先验，设计感知模块收集轨迹相关交通元素，采用自回归策略逐步预测未来轨迹并聚焦相关区域。

Result: 在NAVSIM和Bench2Drive数据集上，VeteranAD实现了最先进的性能。

Conclusion: VeteranAD通过感知-规划一体化设计，显著提升了自动驾驶的准确性和可靠性。

Abstract: End-to-end autonomous driving has achieved remarkable advancements in recent
years. Existing methods primarily follow a perception-planning paradigm, where
perception and planning are executed sequentially within a fully differentiable
framework for planning-oriented optimization. We further advance this paradigm
through a perception-in-plan framework design, which integrates perception into
the planning process. This design facilitates targeted perception guided by
evolving planning objectives over time, ultimately enhancing planning
performance. Building on this insight, we introduce VeteranAD, a coupled
perception and planning framework for end-to-end autonomous driving. By
incorporating multi-mode anchored trajectories as planning priors, the
perception module is specifically designed to gather traffic elements along
these trajectories, enabling comprehensive and targeted perception. Planning
trajectories are then generated based on both the perception results and the
planning priors. To make perception fully serve planning, we adopt an
autoregressive strategy that progressively predicts future trajectories while
focusing on relevant regions for targeted perception at each step. With this
simple yet effective design, VeteranAD fully unleashes the potential of
planning-oriented end-to-end methods, leading to more accurate and reliable
driving behavior. Extensive experiments on the NAVSIM and Bench2Drive datasets
demonstrate that our VeteranAD achieves state-of-the-art performance.

</details>


### [103] [Multi-State Tracker: Enhancing Efficient Object Tracking via Multi-State Specialization and Interaction](https://arxiv.org/abs/2508.11531)
*Shilei Wang,Gong Cheng,Pujian Lai,Dong Gao,Junwei Han*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种多状态跟踪器（MST），通过轻量级的状态特定增强（SSE）和跨状态交互（CSI）模块，提升了特征表示能力，同时保持低计算开销，显著提高了跟踪的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有高效跟踪器因降低计算复杂度和参数量而牺牲了特征表示能力，限制了其在复杂环境中的跟踪准确性。

Method: MST结合多状态生成（MSG）、SSE和CSI模块，MSG生成多状态特征，SSE细化目标特征，CSI促进状态间信息交互。

Result: MST在多个数据集上优于先前高效跟踪器，AO分数提升4.5%，计算开销仅为0.1 GFLOPs和0.66 M参数。

Conclusion: MST通过轻量级设计显著提升了跟踪性能，适用于复杂环境。

Abstract: Efficient trackers achieve faster runtime by reducing computational
complexity and model parameters. However, this efficiency often compromises the
expense of weakened feature representation capacity, thus limiting their
ability to accurately capture target states using single-layer features. To
overcome this limitation, we propose Multi-State Tracker (MST), which utilizes
highly lightweight state-specific enhancement (SSE) to perform specialized
enhancement on multi-state features produced by multi-state generation (MSG)
and aggregates them in an interactive and adaptive manner using cross-state
interaction (CSI). This design greatly enhances feature representation while
incurring minimal computational overhead, leading to improved tracking
robustness in complex environments. Specifically, the MSG generates multiple
state representations at multiple stages during feature extraction, while SSE
refines them to highlight target-specific features. The CSI module facilitates
information exchange between these states and ensures the integration of
complementary features. Notably, the introduced SSE and CSI modules adopt a
highly lightweight hidden state adaptation-based state space duality (HSA-SSD)
design, incurring only 0.1 GFLOPs in computation and 0.66 M in parameters.
Experimental results demonstrate that MST outperforms all previous efficient
trackers across multiple datasets, significantly improving tracking accuracy
and robustness. In particular, it shows excellent runtime performance, with an
AO score improvement of 4.5\% over the previous SOTA efficient tracker HCAT on
the GOT-10K dataset. The code is available at https://github.com/wsumel/MST.

</details>


### [104] [Training-Free Anomaly Generation via Dual-Attention Enhancement in Diffusion Model](https://arxiv.org/abs/2508.11550)
*Zuo Zuo,Jiahao Dong,Yanyun Qu,Zongze Wu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于Stable Diffusion的无训练异常生成框架AAG，通过改进交叉注意力和自注意力机制生成高质量异常图像。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测中数据稀缺问题突出，现有异常生成方法缺乏保真度或需额外训练数据。

Method: AAG利用Stable Diffusion，结合Cross-Attention Enhancement（CAE）和Self-Attention Enhancement（SAE）机制，通过文本提示和掩码生成特定区域的异常图像。

Result: 在MVTec AD和VisA数据集上验证了AAG的有效性，生成的异常图像能提升下游检测任务性能。

Conclusion: AAG为工业异常检测提供了一种高效、无需训练的异常生成解决方案。

Abstract: Industrial anomaly detection (AD) plays a significant role in manufacturing
where a long-standing challenge is data scarcity. A growing body of works have
emerged to address insufficient anomaly data via anomaly generation. However,
these anomaly generation methods suffer from lack of fidelity or need to be
trained with extra data. To this end, we propose a training-free anomaly
generation framework dubbed AAG, which is based on Stable Diffusion (SD)'s
strong generation ability for effective anomaly image generation. Given a
normal image, mask and a simple text prompt, AAG can generate realistic and
natural anomalies in the specific regions and simultaneously keep contents in
other regions unchanged. In particular, we propose Cross-Attention Enhancement
(CAE) to re-engineer the cross-attention mechanism within Stable Diffusion
based on the given mask. CAE increases the similarity between visual tokens in
specific regions and text embeddings, which guides these generated visual
tokens in accordance with the text description. Besides, generated anomalies
need to be more natural and plausible with object in given image. We propose
Self-Attention Enhancement (SAE) which improves similarity between each normal
visual token and anomaly visual tokens. SAE ensures that generated anomalies
are coherent with original pattern. Extensive experiments on MVTec AD and VisA
datasets demonstrate effectiveness of AAG in anomaly generation and its
utility. Furthermore, anomaly images generated by AAG can bolster performance
of various downstream anomaly inspection tasks.

</details>


### [105] [CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion](https://arxiv.org/abs/2508.11603)
*Zhe Zhu,Honghua Chen,Peng Li,Mingqiang Wei*

Main category: cs.CV

Relevance: 40.0

TL;DR: CoreEditor是一个用于文本驱动3D编辑的新框架，通过引入对应约束注意力机制和语义相似性，解决了多视图一致性问题，并提供了选择性编辑功能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本驱动3D编辑中难以保持多视图一致性，导致编辑不足和细节模糊。CoreEditor旨在解决这一问题。

Method: 提出了一种对应约束注意力机制，结合几何对齐和语义相似性，设计了选择性编辑流程。

Result: 实验表明，CoreEditor能够生成高质量、3D一致的编辑结果，显著优于现有方法。

Conclusion: CoreEditor通过改进多视图信息交换和用户控制，实现了更可靠的文本驱动3D编辑。

Abstract: Text-driven 3D editing seeks to modify 3D scenes according to textual
descriptions, and most existing approaches tackle this by adapting pre-trained
2D image editors to multi-view inputs. However, without explicit control over
multi-view information exchange, they often fail to maintain cross-view
consistency, leading to insufficient edits and blurry details. We introduce
CoreEditor, a novel framework for consistent text-to-3D editing. The key
innovation is a correspondence-constrained attention mechanism that enforces
precise interactions between pixels expected to remain consistent throughout
the diffusion denoising process. Beyond relying solely on geometric alignment,
we further incorporate semantic similarity estimated during denoising, enabling
more reliable correspondence modeling and robust multi-view editing. In
addition, we design a selective editing pipeline that allows users to choose
preferred results from multiple candidates, offering greater flexibility and
user control. Extensive experiments show that CoreEditor produces high-quality,
3D-consistent edits with sharper details, significantly outperforming prior
methods.

</details>


### [106] [Is ChatGPT-5 Ready for Mammogram VQA?](https://arxiv.org/abs/2508.11628)
*Qiang Li,Shansong Wang,Mingzhe Hu,Mojtaba Safari,Zachary Eidex,Xiaofeng Yang*

Main category: cs.CV

Relevance: 40.0

TL;DR: GPT-5在乳腺X光片视觉问答任务中表现优于GPT-4o，但仍落后于人类专家和领域专用模型，显示通用大语言模型在医疗影像任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 评估通用大语言模型（如GPT-5和GPT-4o）在乳腺X光片视觉问答任务中的表现，探索其在医疗影像领域的应用潜力。

Method: 在四个公开乳腺X光片数据集上测试GPT-5和GPT-4o，评估其在BI-RADS评估、异常检测和恶性肿瘤分类任务中的表现。

Result: GPT-5在多个任务中表现最佳，但敏感性和特异性低于人类专家。例如，在EMBED数据集上，恶性肿瘤分类准确率为52.8%。

Conclusion: GPT-5在乳腺X光片任务中表现有潜力，但仍需领域适配和优化才能用于高风险的临床影像应用。

Abstract: Mammogram visual question answering (VQA) integrates image interpretation
with clinical reasoning and has potential to support breast cancer screening.
We systematically evaluated the GPT-5 family and GPT-4o model on four public
mammography datasets (EMBED, InBreast, CMMD, CBIS-DDSM) for BI-RADS assessment,
abnormality detection, and malignancy classification tasks. GPT-5 consistently
was the best performing model but lagged behind both human experts and
domain-specific fine-tuned models. On EMBED, GPT-5 achieved the highest scores
among GPT variants in density (56.8%), distortion (52.5%), mass (64.5%),
calcification (63.5%), and malignancy (52.8%) classification. On InBreast, it
attained 36.9% BI-RADS accuracy, 45.9% abnormality detection, and 35.0%
malignancy classification. On CMMD, GPT-5 reached 32.3% abnormality detection
and 55.0% malignancy accuracy. On CBIS-DDSM, it achieved 69.3% BI-RADS
accuracy, 66.0% abnormality detection, and 58.2% malignancy accuracy. Compared
with human expert estimations, GPT-5 exhibited lower sensitivity (63.5%) and
specificity (52.3%). While GPT-5 exhibits promising capabilities for screening
tasks, its performance remains insufficient for high-stakes clinical imaging
applications without targeted domain adaptation and optimization. However, the
tremendous improvements in performance from GPT-4o to GPT-5 show a promising
trend in the potential for general large language models (LLMs) to assist with
mammography VQA tasks.

</details>


### [107] [GenFlowRL: Shaping Rewards with Generative Object-Centric Flow in Visual Reinforcement Learning](https://arxiv.org/abs/2508.11049)
*Kelin Yu,Sheng Zhang,Harshit Soora,Furong Huang,Heng Huang,Pratap Tokekar,Ruohan Gao*

Main category: cs.RO

Relevance: 40.0

TL;DR: GenFlowRL利用生成的对象中心流提取操纵特征，通过跨体现数据集训练，学习通用且鲁棒的策略，解决了视频生成模型在机器人学习中的局限性。


<details>
  <summary>Details</summary>
Motivation: 视频生成模型在机器人学习中依赖生成数据质量且缺乏环境反馈，难以处理精细操作。GenFlowRL旨在通过生成流训练解决这些问题。

Method: GenFlowRL从跨体现数据集训练生成流，提取低维对象中心特征，用于学习通用且鲁棒的策略。

Result: 在10个操纵任务的仿真和真实世界跨体现评估中，GenFlowRL表现优异，验证了其有效性。

Conclusion: GenFlowRL通过生成流提取特征，显著提升了策略的通用性和鲁棒性。

Abstract: Recent advances have shown that video generation models can enhance robot
learning by deriving effective robot actions through inverse dynamics. However,
these methods heavily depend on the quality of generated data and struggle with
fine-grained manipulation due to the lack of environment feedback. While
video-based reinforcement learning improves policy robustness, it remains
constrained by the uncertainty of video generation and the challenges of
collecting large-scale robot datasets for training diffusion models. To address
these limitations, we propose GenFlowRL, which derives shaped rewards from
generated flow trained from diverse cross-embodiment datasets. This enables
learning generalizable and robust policies from diverse demonstrations using
low-dimensional, object-centric features. Experiments on 10 manipulation tasks,
both in simulation and real-world cross-embodiment evaluations, demonstrate
that GenFlowRL effectively leverages manipulation features extracted from
generated object-centric flow, consistently achieving superior performance
across diverse and challenging scenarios. Our Project Page:
https://colinyu1.github.io/genflowrl

</details>


### [108] [Allen: Rethinking MAS Design through Step-Level Policy Autonomy](https://arxiv.org/abs/2508.11294)
*Qiangong Zhou,Zhiting Wang,Mingyou Yao,Zongyang Liu*

Main category: cs.MA

Relevance: 40.0

TL;DR: 论文介绍了多智能体系统Allen，旨在提升策略自主性并平衡协作效率与可控性。


<details>
  <summary>Details</summary>
Motivation: 解决当前多智能体系统设计中策略自主性不足和协作效率与可控性难以权衡的问题。

Method: 重新定义MAS的基本执行单元，构建四层状态架构（任务、阶段、智能体、步骤）以优化拓扑结构和控制进度。

Result: Allen实现了前所未有的策略自主性，同时平衡了协作结构的可控性。

Conclusion: Allen为多智能体系统设计提供了新的解决方案，代码已开源。

Abstract: We introduce a new Multi-Agent System (MAS) - Allen, designed to address two
core challenges in current MAS design: (1) improve system's policy autonomy,
empowering agents to dynamically adapt their behavioral strategies, and (2)
achieving the trade-off between collaborative efficiency, task supervision, and
human oversight in complex network topologies.
  Our core insight is to redefine the basic execution unit in the MAS, allowing
agents to autonomously form different patterns by combining these units. We
have constructed a four-tier state architecture (Task, Stage, Agent, Step) to
constrain system behavior from both task-oriented and execution-oriented
perspectives. This achieves a unification of topological optimization and
controllable progress.
  Allen grants unprecedented Policy Autonomy, while making a trade-off for the
controllability of the collaborative structure. The project code has been open
source at: https://github.com/motern88/Allen

</details>


### [109] [Guiding WaveMamba with Frequency Maps for Image Debanding](https://arxiv.org/abs/2508.11331)
*Xinyi Wang,Smaranda Tasmoc,Nantheera Anantrasirichai,Angeliki Katsenou*

Main category: eess.IV

Relevance: 40.0

TL;DR: 论文提出了一种基于小波状态空间模型的频带恢复方法，用于抑制低比特率压缩中的条带伪影，并在公开数据集上验证了其优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 低比特率压缩中常见的条带伪影（如天空区域）会降低视觉质量，尤其是在用户生成内容中。本文旨在解决这一问题。

Method: 采用小波状态空间模型和频率掩码图，以保留高频细节并抑制条带伪影。

Result: 在BAND-2k数据集上，提出的方法取得了0.082的DBI值，优于现有方法，且能保留图像纹理。

Conclusion: 该方法在抑制条带伪影方面表现优异，同时保持了图像细节。

Abstract: Compression at low bitrates in modern codecs often introduces banding
artifacts, especially in smooth regions such as skies. These artifacts degrade
visual quality and are common in user-generated content due to repeated
transcoding. We propose a banding restoration method that employs the Wavelet
State Space Model and a frequency masking map to preserve high-frequency
details. Furthermore, we provide a benchmark of open-source banding restoration
methods and evaluate their performance on two public banding image datasets.
Experimentation on the available datasets suggests that the proposed
post-processing approach effectively suppresses banding compared to the
state-of-the-art method (a DBI value of 0.082 on BAND-2k) while preserving
image textures. Visual inspections of the results confirm this. Code and
supplementary material are available at:
https://github.com/xinyiW915/Debanding-PCS2025.

</details>


### [110] [LKFMixer: Exploring Large Kernel Feature For Efficient Image Super-Resolution](https://arxiv.org/abs/2508.11391)
*Yinggan Tang,Quanwei Hu*

Main category: eess.IV

Relevance: 40.0

TL;DR: 论文提出了一种纯卷积神经网络模型LKFMixer，通过大卷积核模拟自注意力的非局部特征捕捉能力，解决了Transformer在图像超分辨率中计算量大的问题。


<details>
  <summary>Details</summary>
Motivation: 自注意力在Transformer中的成功表明非局部信息对图像超分辨率的重要性，但计算量大限制了轻量化模型的实现。

Method: 使用大卷积核（31x31）模拟自注意力，通过坐标分解减少参数和计算量，并设计了空间特征调制块（SFMB）和特征选择块（FSB）优化特征处理。

Result: LKFMixer在超分辨率性能上优于其他SOTA方法，例如在Manga109数据集上比SwinIR-light提升0.6dB PSNR，推理速度快5倍。

Conclusion: LKFMixer通过卷积核模拟自注意力，实现了高效的非局部特征捕捉，适用于轻量化图像超分辨率任务。

Abstract: The success of self-attention (SA) in Transformer demonstrates the importance
of non-local information to image super-resolution (SR), but the huge computing
power required makes it difficult to implement lightweight models. To solve
this problem, we propose a pure convolutional neural network (CNN) model,
LKFMixer, which utilizes large convolutional kernel to simulate the ability of
self-attention to capture non-local features. Specifically, we increase the
kernel size to 31 to obtain the larger receptive field as possible, and reduce
the parameters and computations by coordinate decomposition. Meanwhile, a
spatial feature modulation block (SFMB) is designed to enhance the focus of
feature information on both spatial and channel dimension. In addition, by
introducing feature selection block (FSB), the model can adaptively adjust the
weights between local features and non-local features. Extensive experiments
show that the proposed LKFMixer family outperform other state-of-the-art (SOTA)
methods in terms of SR performance and reconstruction quality. In particular,
compared with SwinIR-light on Manga109 dataset, LKFMixer-L achieves 0.6dB PSNR
improvement at $\times$4 scale, while the inference speed is $\times$5 times
faster. The code is available at https://github.com/Supereeeee/LKFMixer.

</details>


### [111] [SPG: Style-Prompting Guidance for Style-Specific Content Creation](https://arxiv.org/abs/2508.11476)
*Qian Liang,Zichong Chen,Yang Zhou,Hui Huang*

Main category: cs.GR

Relevance: 40.0

TL;DR: 提出了一种名为Style-Prompting Guidance (SPG)的新采样策略，用于风格特定的图像生成，结合Classifier-Free Guidance (CFG)实现语义保真和风格一致性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有的文本到图像扩散模型在生成与文本提示对齐的图像方面表现出色，但控制输出图像的视觉风格仍具挑战性。

Method: SPG构建风格噪声向量，并利用其与无条件噪声的方向偏差引导扩散过程朝向目标风格分布。

Result: 实验表明，SPG在风格一致性和语义保真方面优于现有方法，且兼容ControlNet和IPAdapter等可控框架。

Conclusion: SPG是一种简单、鲁棒且广泛适用的方法，适用于风格特定的图像生成。

Abstract: Although recent text-to-image (T2I) diffusion models excel at aligning
generated images with textual prompts, controlling the visual style of the
output remains a challenging task. In this work, we propose Style-Prompting
Guidance (SPG), a novel sampling strategy for style-specific image generation.
SPG constructs a style noise vector and leverages its directional deviation
from unconditional noise to guide the diffusion process toward the target style
distribution. By integrating SPG with Classifier-Free Guidance (CFG), our
method achieves both semantic fidelity and style consistency. SPG is simple,
robust, and compatible with controllable frameworks like ControlNet and
IPAdapter, making it practical and widely applicable. Extensive experiments
demonstrate the effectiveness and generality of our approach compared to
state-of-the-art methods. Code is available at
https://github.com/Rumbling281441/SPG.

</details>


### [112] [Privacy Enhancement for Gaze Data Using a Noise-Infused Autoencoder](https://arxiv.org/abs/2508.10918)
*Samantha Aziz,Oleg Komogortsev*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种隐私增强机制，通过潜在噪声自编码器保护用户视线数据，防止未经同意的跨会话重识别，同时保持数据的可用性。


<details>
  <summary>Details</summary>
Motivation: 保护视线数据隐私，同时确保数据在良性任务中的可用性。

Method: 使用潜在噪声自编码器，评估隐私与效用的权衡。

Result: 显著降低生物识别可能性，同时保持视线数据的生理合理性。

Conclusion: 提供了一种有效且实用的隐私保护机制，适用于视线数据系统。

Abstract: We present a privacy-enhancing mechanism for gaze signals using a
latent-noise autoencoder that prevents users from being re-identified across
play sessions without their consent, while retaining the usability of the data
for benign tasks. We evaluate privacy-utility trade-offs across biometric
identification and gaze prediction tasks, showing that our approach
significantly reduces biometric identifiability with minimal utility
degradation. Unlike prior methods in this direction, our framework retains
physiologically plausible gaze patterns suitable for downstream use, which
produces favorable privacy-utility trade-off. This work advances privacy in
gaze-based systems by providing a usable and effective mechanism for protecting
sensitive gaze data.

</details>


### [113] [ViPE: Video Pose Engine for 3D Geometric Perception](https://arxiv.org/abs/2508.10934)
*Jiahui Huang,Qunjie Zhou,Hesam Rabeti,Aleksandr Korovko,Huan Ling,Xuanchi Ren,Tianchang Shen,Jun Gao,Dmitry Slepichev,Chen-Hsuan Lin,Jiawei Ren,Kevin Xie,Joydeep Biswas,Laura Leal-Taixe,Sanja Fidler*

Main category: cs.CV

Relevance: 30.0

TL;DR: ViPE是一种高效视频处理引擎，用于从无约束视频中估计相机参数和深度图，显著优于现有基线，并用于标注大规模视频数据集。


<details>
  <summary>Details</summary>
Motivation: 解决从野外视频中获取一致且精确的3D注释的挑战，以支持空间AI系统的发展。

Method: ViPE通过估计相机内参、相机运动和密集深度图来处理视频，支持多种相机模型和场景。

Result: 在TUM/KITTI序列上优于现有基线18%/50%，运行速度为3-5FPS，并标注了包含100K真实视频和1M AI生成视频的大规模数据集。

Conclusion: ViPE及其标注数据集的开源有望加速空间AI系统的开发。

Abstract: Accurate 3D geometric perception is an important prerequisite for a wide
range of spatial AI systems. While state-of-the-art methods depend on
large-scale training data, acquiring consistent and precise 3D annotations from
in-the-wild videos remains a key challenge. In this work, we introduce ViPE, a
handy and versatile video processing engine designed to bridge this gap. ViPE
efficiently estimates camera intrinsics, camera motion, and dense, near-metric
depth maps from unconstrained raw videos. It is robust to diverse scenarios,
including dynamic selfie videos, cinematic shots, or dashcams, and supports
various camera models such as pinhole, wide-angle, and 360{\deg} panoramas. We
have benchmarked ViPE on multiple benchmarks. Notably, it outperforms existing
uncalibrated pose estimation baselines by 18%/50% on TUM/KITTI sequences, and
runs at 3-5FPS on a single GPU for standard input resolutions. We use ViPE to
annotate a large-scale collection of videos. This collection includes around
100K real-world internet videos, 1M high-quality AI-generated videos, and 2K
panoramic videos, totaling approximately 96M frames -- all annotated with
accurate camera poses and dense depth maps. We open-source ViPE and the
annotated dataset with the hope of accelerating the development of spatial AI
systems.

</details>


### [114] [HQ-OV3D: A High Box Quality Open-World 3D Detection Framework based on Diffision Model](https://arxiv.org/abs/2508.10935)
*Qi Liu,Yabei Li,Hongsong Wang,Lei He*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出HQ-OV3D框架，通过高质量伪标签生成和优化，提升开放词汇3D检测的几何精度。


<details>
  <summary>Details</summary>
Motivation: 传统封闭集3D检测无法满足开放世界应用需求，现有开放词汇方法忽视几何质量。

Method: 结合跨模态几何一致性的IMCV提案生成器和基于DDIM的去噪机制ACA优化器。

Result: 在新型类别上mAP提升7.37%，伪标签质量显著优于现有方法。

Conclusion: HQ-OV3D可作为独立检测器或插件，提升现有开放词汇检测流程。

Abstract: Traditional closed-set 3D detection frameworks fail to meet the demands of
open-world applications like autonomous driving. Existing open-vocabulary 3D
detection methods typically adopt a two-stage pipeline consisting of
pseudo-label generation followed by semantic alignment. While vision-language
models (VLMs) recently have dramatically improved the semantic accuracy of
pseudo-labels, their geometric quality, particularly bounding box precision,
remains commonly neglected.To address this issue, we propose a High Box Quality
Open-Vocabulary 3D Detection (HQ-OV3D) framework, dedicated to generate and
refine high-quality pseudo-labels for open-vocabulary classes. The framework
comprises two key components: an Intra-Modality Cross-Validated (IMCV) Proposal
Generator that utilizes cross-modality geometric consistency to generate
high-quality initial 3D proposals, and an Annotated-Class Assisted (ACA)
Denoiser that progressively refines 3D proposals by leveraging geometric priors
from annotated categories through a DDIM-based denoising mechanism.Compared to
the state-of-the-art method, training with pseudo-labels generated by our
approach achieves a 7.37% improvement in mAP on novel classes, demonstrating
the superior quality of the pseudo-labels produced by our framework. HQ-OV3D
can serve not only as a strong standalone open-vocabulary 3D detector but also
as a plug-in high-quality pseudo-label generator for existing open-vocabulary
detection or annotation pipelines.

</details>


### [115] [Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction](https://arxiv.org/abs/2508.10936)
*Cheng Chen,Hao Huang,Saurabh Bagchi*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于稀疏3D语义高斯泼溅的协作3D语义占用预测方法，通过共享和融合高斯基元，解决了现有方法的通信成本高和依赖深度监督的问题。


<details>
  <summary>Details</summary>
Motivation: 现有协作感知方法在3D语义占用预测中面临高通信成本或依赖深度监督的局限性，限制了其实际应用。

Method: 采用稀疏3D语义高斯泼溅技术，通过共享和融合高斯基元，实现跨代理融合、几何与语义联合编码，以及稀疏对象中心消息传递。

Result: 实验表明，该方法在mIoU和IoU上显著优于单代理感知和基线协作方法，且在低通信量下仍保持高性能。

Conclusion: 该方法为协作3D语义占用预测提供了高效且鲁棒的解决方案，适用于通信受限的场景。

Abstract: Collaborative perception enables connected vehicles to share information,
overcoming occlusions and extending the limited sensing range inherent in
single-agent (non-collaborative) systems. Existing vision-only methods for 3D
semantic occupancy prediction commonly rely on dense 3D voxels, which incur
high communication costs, or 2D planar features, which require accurate depth
estimation or additional supervision, limiting their applicability to
collaborative scenarios. To address these challenges, we propose the first
approach leveraging sparse 3D semantic Gaussian splatting for collaborative 3D
semantic occupancy prediction. By sharing and fusing intermediate Gaussian
primitives, our method provides three benefits: a neighborhood-based
cross-agent fusion that removes duplicates and suppresses noisy or inconsistent
Gaussians; a joint encoding of geometry and semantics in each primitive, which
reduces reliance on depth supervision and allows simple rigid alignment; and
sparse, object-centric messages that preserve structural information while
reducing communication volume. Extensive experiments demonstrate that our
approach outperforms single-agent perception and baseline collaborative methods
by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU,
respectively. When further reducing the number of transmitted Gaussians, our
method still achieves a +1.9 improvement in mIoU, using only 34.6%
communication volume, highlighting robust performance under limited
communication budgets.

</details>


### [116] [Personalized Face Super-Resolution with Identity Decoupling and Fitting](https://arxiv.org/abs/2508.10937)
*Jiarui Yang,Hang Guo,Wen Huang,Tao Dai,Shutao Xia*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种名为IDFSR的新方法，用于在极端退化场景下提升人脸超分辨率（FSR）的身份（ID）恢复能力，同时减少幻觉效应。


<details>
  <summary>Details</summary>
Motivation: 在极端退化场景（如缩放比例>8倍）下，现有FSR方法难以恢复真实且ID一致的人脸，常产生幻觉效果。IDFSR旨在解决这一问题。

Method: IDFSR通过掩蔽面部区域、对齐参考图像和利用ID嵌入三个关键设计，结合扩散模型预训练和轻量级微调，实现ID与风格的解耦和精细建模。

Result: 实验表明，IDFSR在极端退化条件下显著优于现有方法，尤其在ID一致性方面表现优异。

Conclusion: IDFSR通过解耦和精细建模ID信息，有效提升了极端退化场景下的FSR性能。

Abstract: In recent years, face super-resolution (FSR) methods have achieved remarkable
progress, generally maintaining high image fidelity and identity (ID)
consistency under standard settings. However, in extreme degradation scenarios
(e.g., scale $> 8\times$), critical attributes and ID information are often
severely lost in the input image, making it difficult for conventional models
to reconstruct realistic and ID-consistent faces. Existing methods tend to
generate hallucinated faces under such conditions, producing restored images
lacking authentic ID constraints. To address this challenge, we propose a novel
FSR method with Identity Decoupling and Fitting (IDFSR), designed to enhance ID
restoration under large scaling factors while mitigating hallucination effects.
Our approach involves three key designs: 1) \textbf{Masking} the facial region
in the low-resolution (LR) image to eliminate unreliable ID cues; 2)
\textbf{Warping} a reference image to align with the LR input, providing style
guidance; 3) Leveraging \textbf{ID embeddings} extracted from ground truth (GT)
images for fine-grained ID modeling and personalized adaptation. We first
pretrain a diffusion-based model to explicitly decouple style and ID by forcing
it to reconstruct masked LR face regions using both style and identity
embeddings. Subsequently, we freeze most network parameters and perform
lightweight fine-tuning of the ID embedding using a small set of target ID
images. This embedding encodes fine-grained facial attributes and precise ID
information, significantly improving both ID consistency and perceptual
quality. Extensive quantitative evaluations and visual comparisons demonstrate
that the proposed IDFSR substantially outperforms existing approaches under
extreme degradation, particularly achieving superior performance on ID
consistency.

</details>


### [117] [From Promise to Practical Reality: Transforming Diffusion MRI Analysis with Fast Deep Learning Enhancement](https://arxiv.org/abs/2508.10950)
*Xinyi Wang,Michael Barnett,Frederique Boonstra,Yael Barnett,Mariano Cabezas,Arkiev D'Souza,Matthew C. Kiernan,Kain Kyle,Meng Law,Lynette Masters,Zihao Tang,Stephen Tisch,Sicong Tu,Anneke Van Der Walt,Dongang Wang,Fernando Calamante,Weidong Cai,Chenyu Wang*

Main category: cs.CV

Relevance: 30.0

TL;DR: FastFOD-Net是一个深度学习框架，用于增强扩散MRI中的纤维取向分布（FOD），并在临床神经科学研究中展示了高效性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决临床MRI协议中单壳低角度分辨率采集导致的FOD可靠性问题，推动深度学习在扩散MRI增强中的临床应用。

Method: 采用加速端到端深度学习框架FastFOD-Net，优化FOD估计，并在健康对照和六种神经系统疾病中验证。

Result: FastFOD-Net性能优越，训练和推理效率高（比前代快60倍），能减少测量误差并降低样本需求。

Conclusion: FastFOD-Net有望加速临床神经科学研究，增强扩散MRI分析的可靠性和可解释性，推动深度学习方法的临床信任。

Abstract: Fiber orientation distribution (FOD) is an advanced diffusion MRI modeling
technique that represents complex white matter fiber configurations, and a key
step for subsequent brain tractography and connectome analysis. Its reliability
and accuracy, however, heavily rely on the quality of the MRI acquisition and
the subsequent estimation of the FODs at each voxel. Generating reliable FODs
from widely available clinical protocols with single-shell and
low-angular-resolution acquisitions remains challenging but could potentially
be addressed with recent advances in deep learning-based enhancement
techniques. Despite advancements, existing methods have predominantly been
assessed on healthy subjects, which have proved to be a major hurdle for their
clinical adoption. In this work, we validate a newly optimized enhancement
framework, FastFOD-Net, across healthy controls and six neurological disorders.
This accelerated end-to-end deep learning framework enhancing FODs with
superior performance and delivering training/inference efficiency for clinical
use ($60\times$ faster comparing to its predecessor). With the most
comprehensive clinical evaluation to date, our work demonstrates the potential
of FastFOD-Net in accelerating clinical neuroscience research, empowering
diffusion MRI analysis for disease differentiation, improving interpretability
in connectome applications, and reducing measurement errors to lower sample
size requirements. Critically, this work will facilitate the more widespread
adoption of, and build clinical trust in, deep learning based methods for
diffusion MRI enhancement. Specifically, FastFOD-Net enables robust analysis of
real-world, clinical diffusion MRI data, comparable to that achievable with
high-quality research acquisitions.

</details>


### [118] [Residual-based Efficient Bidirectional Diffusion Model for Image Dehazing and Haze Generation](https://arxiv.org/abs/2508.11134)
*Bing Liu,Le Wang,Hao Liu,Mingming Liu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于残差的高效双向扩散模型（RBDM），用于实现有雾和无雾图像之间的双向转换。


<details>
  <summary>Details</summary>
Motivation: 现有深度去雾方法仅关注去雾，缺乏双向转换能力，RBDM旨在填补这一空白。

Method: 设计双马尔可夫链实现残差平滑转换，通过扰动图像并预测噪声学习条件分布，引入统一评分函数降低计算成本。

Result: RBDM在15步采样内实现尺寸无关的双向转换，性能优于或媲美现有方法。

Conclusion: RBDM成功实现了高效、双向的图像转换，适用于小数据集和低计算资源场景。

Abstract: Current deep dehazing methods only focus on removing haze from hazy images,
lacking the capability to translate between hazy and haze-free images. To
address this issue, we propose a residual-based efficient bidirectional
diffusion model (RBDM) that can model the conditional distributions for both
dehazing and haze generation. Firstly, we devise dual Markov chains that can
effectively shift the residuals and facilitate bidirectional smooth transitions
between them. Secondly, the RBDM perturbs the hazy and haze-free images at
individual timesteps and predicts the noise in the perturbed data to
simultaneously learn the conditional distributions. Finally, to enhance
performance on relatively small datasets and reduce computational costs, our
method introduces a unified score function learned on image patches instead of
entire images. Our RBDM successfully implements size-agnostic bidirectional
transitions between haze-free and hazy images with only 15 sampling steps.
Extensive experiments demonstrate that the proposed method achieves superior or
at least comparable performance to state-of-the-art methods on both synthetic
and real-world datasets.

</details>


### [119] [Semi-supervised Image Dehazing via Expectation-Maximization and Bidirectional Brownian Bridge Diffusion Models](https://arxiv.org/abs/2508.11165)
*Bing Liu,Le Wang,Mingming Liu,Hao Liu,Rui Yao,Yong Zhou,Peng Liu,Tongqiang Xia*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于期望最大化（EM）和双向布朗桥扩散模型（EM-B3DM）的半监督图像去雾方法，通过两阶段学习方案解决真实世界雾霾图像的去雾问题。


<details>
  <summary>Details</summary>
Motivation: 现有去雾方法难以处理真实世界中的厚雾场景，主要原因是缺乏真实配对数据和鲁棒先验。

Method: 采用EM算法解耦配对图像联合分布，并用布朗桥扩散模型建模条件分布；第二阶段利用预训练模型和大规模非配对数据提升性能，并引入细节增强的RDC模块。

Result: 在合成和真实数据集上表现优于或与现有方法相当。

Conclusion: EM-B3DM是一种高效的去雾方法，尤其在真实世界场景中表现优异。

Abstract: Existing dehazing methods deal with real-world haze images with difficulty,
especially scenes with thick haze. One of the main reasons is the lack of
real-world paired data and robust priors. To avoid the costly collection of
paired hazy and clear images, we propose an efficient semi-supervised image
dehazing method via Expectation-Maximization and Bidirectional Brownian Bridge
Diffusion Models (EM-B3DM) with a two-stage learning scheme. In the first
stage, we employ the EM algorithm to decouple the joint distribution of paired
hazy and clear images into two conditional distributions, which are then
modeled using a unified Brownian Bridge diffusion model to directly capture the
structural and content-related correlations between hazy and clear images. In
the second stage, we leverage the pre-trained model and large-scale unpaired
hazy and clear images to further improve the performance of image dehazing.
Additionally, we introduce a detail-enhanced Residual Difference Convolution
block (RDC) to capture gradient-level information, significantly enhancing the
model's representation capability. Extensive experiments demonstrate that our
EM-B3DM achieves superior or at least comparable performance to
state-of-the-art methods on both synthetic and real-world datasets.

</details>


### [120] [TimeMachine: Fine-Grained Facial Age Editing with Identity Preservation](https://arxiv.org/abs/2508.11284)
*Yilin Mi,Qixin Yan,Zheng-Peng Duan,Chunle Guo,Hubery Yin,Hao Liu,Chen Li,Chongyi Li*

Main category: cs.CV

Relevance: 30.0

TL;DR: TimeMachine是一个基于扩散模型的框架，用于精确编辑面部年龄同时保持身份特征不变。通过注入高精度年龄信息到多交叉注意力模块，并设计Age Classifier Guidance模块，实现了细粒度的年龄编辑。


<details>
  <summary>Details</summary>
Motivation: 当前面部图像编辑在细粒度年龄编辑和身份保持方面仍具挑战性，TimeMachine旨在解决这一问题。

Method: 采用扩散模型框架，结合多交叉注意力模块分离年龄和身份特征，并引入Age Classifier Guidance模块直接在潜在空间预测年龄。

Result: 实验表明，TimeMachine在细粒度年龄编辑和身份一致性保持上达到最先进水平。

Conclusion: TimeMachine通过创新的模块设计和高质量数据集，显著提升了年龄编辑的精确性和可控性。

Abstract: With the advancement of generative models, facial image editing has made
significant progress. However, achieving fine-grained age editing while
preserving personal identity remains a challenging task.In this paper, we
propose TimeMachine, a novel diffusion-based framework that achieves accurate
age editing while keeping identity features unchanged. To enable fine-grained
age editing, we inject high-precision age information into the multi-cross
attention module, which explicitly separates age-related and identity-related
features. This design facilitates more accurate disentanglement of age
attributes, thereby allowing precise and controllable manipulation of facial
aging.Furthermore, we propose an Age Classifier Guidance (ACG) module that
predicts age directly in the latent space, instead of performing denoising
image reconstruction during training. By employing a lightweight module to
incorporate age constraints, this design enhances age editing accuracy by
modest increasing training cost. Additionally, to address the lack of
large-scale, high-quality facial age datasets, we construct a HFFA dataset
(High-quality Fine-grained Facial-Age dataset) which contains one million
high-resolution images labeled with identity and facial attributes.
Experimental results demonstrate that TimeMachine achieves state-of-the-art
performance in fine-grained age editing while preserving identity consistency.

</details>


### [121] [Delving into Dynamic Scene Cue-Consistency for Robust 3D Multi-Object Tracking](https://arxiv.org/abs/2508.11323)
*Haonan Zhang,Xinyao Wang,Boxi Wu,Tu Zheng,Wang Yunhua,Zheng Yang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于空间线索一致性的3D多目标跟踪方法DSC-Track，通过动态场景线索一致性提升跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在拥挤环境或检测不准确时表现不佳，忽视了物体间的几何关系，需要利用空间线索。

Method: 设计了基于点对特征（PPF）的时空编码器、线索一致性变换模块和动态更新机制。

Result: 在nuScenes和Waymo数据集上验证，nuScenes测试集AMOTA达70.3%。

Conclusion: DSC-Track通过一致性空间模式匹配提升了跟踪鲁棒性。

Abstract: 3D multi-object tracking is a critical and challenging task in the field of
autonomous driving. A common paradigm relies on modeling individual object
motion, e.g., Kalman filters, to predict trajectories. While effective in
simple scenarios, this approach often struggles in crowded environments or with
inaccurate detections, as it overlooks the rich geometric relationships between
objects. This highlights the need to leverage spatial cues. However, existing
geometry-aware methods can be susceptible to interference from irrelevant
objects, leading to ambiguous features and incorrect associations. To address
this, we propose focusing on cue-consistency: identifying and matching stable
spatial patterns over time. We introduce the Dynamic Scene Cue-Consistency
Tracker (DSC-Track) to implement this principle. Firstly, we design a unified
spatiotemporal encoder using Point Pair Features (PPF) to learn discriminative
trajectory embeddings while suppressing interference. Secondly, our
cue-consistency transformer module explicitly aligns consistent feature
representations between historical tracks and current detections. Finally, a
dynamic update mechanism preserves salient spatiotemporal information for
stable online tracking. Extensive experiments on the nuScenes and Waymo Open
Datasets validate the effectiveness and robustness of our approach. On the
nuScenes benchmark, for instance, our method achieves state-of-the-art
performance, reaching 73.2% and 70.3% AMOTA on the validation and test sets,
respectively.

</details>


### [122] [Cost-Effective Active Labeling for Data-Efficient Cervical Cell Classification](https://arxiv.org/abs/2508.11340)
*Yuanlin Liu,Zhihan Zhou,Mingqiang Wei,Youyi Song*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种名为“主动标注”的方法，用于高效构建具有代表性的宫颈细胞分类训练数据集，显著降低人工标注成本。


<details>
  <summary>Details</summary>
Motivation: 现有宫颈细胞分类方法需要大量代表性训练数据，人工标注成本高昂。本文旨在通过主动标注减少标注成本，同时保持数据集的代表性。

Method: 利用分类器对未标注宫颈细胞图像的不确定性，选择最有价值的图像进行标注，从而高效构建训练数据集。

Result: 实验证实该方法能显著减少人工标注成本，同时提升训练数据集的代表性。

Conclusion: 主动标注方法为高效宫颈细胞分类提供了可行路径，具有实际应用潜力。

Abstract: Information on the number and category of cervical cells is crucial for the
diagnosis of cervical cancer. However, existing classification methods capable
of automatically measuring this information require the training dataset to be
representative, which consumes an expensive or even unaffordable human cost. We
herein propose active labeling that enables us to construct a representative
training dataset using a much smaller human cost for data-efficient cervical
cell classification. This cost-effective method efficiently leverages the
classifier's uncertainty on the unlabeled cervical cell images to accurately
select images that are most beneficial to label. With a fast estimation of the
uncertainty, this new algorithm exhibits its validity and effectiveness in
enhancing the representative ability of the constructed training dataset. The
extensive empirical results confirm its efficacy again in navigating the usage
of human cost, opening the avenue for data-efficient cervical cell
classification.

</details>


### [123] [Does the Skeleton-Recall Loss Really Work?](https://arxiv.org/abs/2508.11374)
*Devansh Arora,Nitin Kumar,Sukrit Gupta*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文对基于拓扑保持的损失函数（如SRL）在图像分割中的表现进行了理论和实证分析，发现其性能并未超越传统基线模型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估拓扑保持损失函数（如SRL）在分割细管状结构时的有效性，验证其声称的优越性是否成立。

Method: 通过理论分析SRL损失的梯度，并在多个管状数据集上与传统基线模型进行性能对比。

Result: 结果表明，SRL分割模型的性能并未超过传统基线模型。

Conclusion: 论文揭示了拓扑保持损失函数的局限性，为开发更有效的复杂管状结构分割模型提供了参考。

Abstract: Image segmentation is an important and widely performed task in computer
vision. Accomplishing effective image segmentation in diverse settings often
requires custom model architectures and loss functions. A set of models that
specialize in segmenting thin tubular structures are topology
preservation-based loss functions. These models often utilize a pixel
skeletonization process claimed to generate more precise segmentation masks of
thin tubes and better capture the structures that other models often miss. One
such model, Skeleton Recall Loss (SRL) proposed by Kirchhoff et al.~\cite
{kirchhoff2024srl}, was stated to produce state-of-the-art results on benchmark
tubular datasets. In this work, we performed a theoretical analysis of the
gradients for the SRL loss. Upon comparing the performance of the proposed
method on some of the tubular datasets (used in the original work, along with
some additional datasets), we found that the performance of SRL-based
segmentation models did not exceed traditional baseline models. By providing
both a theoretical explanation and empirical evidence, this work critically
evaluates the limitations of topology-based loss functions, offering valuable
insights for researchers aiming to develop more effective segmentation models
for complex tubular structures.

</details>


### [124] [G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration](https://arxiv.org/abs/2508.11379)
*Ramil Khafizov,Artem Komarichev,Ruslan Rakhimov,Peter Wonka,Evgeny Burnaev*

Main category: cs.CV

Relevance: 30.0

TL;DR: G-CUT3R是一种新颖的前馈方法，通过整合先验信息改进3D场景重建，优于仅依赖输入图像的现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有前馈方法仅依赖输入图像，而现实场景中常有多模态数据可用，G-CUT3R旨在利用这些数据提升重建性能。

Method: 通过轻量级修改CUT3R模型，为每种模态设计专用编码器提取特征，并通过零卷积与RGB图像特征融合。

Result: 在多个基准测试中表现优异，显著提升了3D重建和多视角任务的性能。

Conclusion: G-CUT3R能有效利用先验信息，同时兼容不同输入模态。

Abstract: We introduce G-CUT3R, a novel feed-forward approach for guided 3D scene
reconstruction that enhances the CUT3R model by integrating prior information.
Unlike existing feed-forward methods that rely solely on input images, our
method leverages auxiliary data, such as depth, camera calibrations, or camera
positions, commonly available in real-world scenarios. We propose a lightweight
modification to CUT3R, incorporating a dedicated encoder for each modality to
extract features, which are fused with RGB image tokens via zero convolution.
This flexible design enables seamless integration of any combination of prior
information during inference. Evaluated across multiple benchmarks, including
3D reconstruction and other multi-view tasks, our approach demonstrates
significant performance improvements, showing its ability to effectively
utilize available priors while maintaining compatibility with varying input
modalities.

</details>


### [125] [SelfAdapt: Unsupervised Domain Adaptation of Cell Segmentation Models](https://arxiv.org/abs/2508.11411)
*Fabian H. Reith,Jannik Franzen,Dinesh R. Palli,J. Lorenz Rumberger,Dagmar Kainmueller*

Main category: cs.CV

Relevance: 30.0

TL;DR: SelfAdapt是一种无需标签的自适应方法，用于改进预训练的细胞分割模型，通过学生-教师增强一致性训练、L2-SP正则化和无标签停止标准实现。


<details>
  <summary>Details</summary>
Motivation: 解决预训练模型在新领域性能下降的问题，避免依赖标注数据。

Method: 基于学生-教师增强一致性训练，引入L2-SP正则化和无标签停止标准。

Result: 在LiveCell和TissueNet数据集上，AP0.5相对提升高达29.64%，且能进一步提升监督微调模型。

Conclusion: SelfAdapt是一种有效的无监督自适应方法，适用于细胞分割任务。

Abstract: Deep neural networks have become the go-to method for biomedical instance
segmentation. Generalist models like Cellpose demonstrate state-of-the-art
performance across diverse cellular data, though their effectiveness often
degrades on domains that differ from their training data. While supervised
fine-tuning can address this limitation, it requires annotated data that may
not be readily available. We propose SelfAdapt, a method that enables the
adaptation of pre-trained cell segmentation models without the need for labels.
Our approach builds upon student-teacher augmentation consistency training,
introducing L2-SP regularization and label-free stopping criteria. We evaluate
our method on the LiveCell and TissueNet datasets, demonstrating relative
improvements in AP0.5 of up to 29.64% over baseline Cellpose. Additionally, we
show that our unsupervised adaptation can further improve models that were
previously fine-tuned with supervision. We release SelfAdapt as an easy-to-use
extension of the Cellpose framework. The code for our method is publicly
available at https: //github.com/Kainmueller-Lab/self_adapt.

</details>


### [126] [Training-free Dimensionality Reduction via Feature Truncation: Enhancing Efficiency in Privacy-preserving Multi-Biometric Systems](https://arxiv.org/abs/2508.11419)
*Florian Bayer,Maximilian Russo,Christian Rathgeb*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文研究了多模态生物特征模板的降维方法，通过融合不同模态的特征向量，在保持生物识别准确性的同时显著减少模板尺寸，从而提升同态加密下的计算效率。


<details>
  <summary>Details</summary>
Motivation: 生物特征识别的隐私和安全性至关重要，但现有基于同态加密的方案计算开销大。多模态融合和特征降维可能解决这一问题。

Method: 利用DNN提取多模态生物特征（人脸、指纹、虹膜），并通过降维技术减少模板尺寸，同时评估其在同态加密下的性能。

Result: 多模态特征融合可将模板尺寸减少67%，且不损失识别准确性（EER与单模态最佳性能相当）。

Conclusion: 多模态融合和降维技术能显著提升同态加密下的生物特征识别效率，同时保持高安全性和准确性。

Abstract: Biometric recognition is widely used, making the privacy and security of
extracted templates a critical concern. Biometric Template Protection schemes,
especially those utilizing Homomorphic Encryption, introduce significant
computational challenges due to increased workload. Recent advances in deep
neural networks have enabled state-of-the-art feature extraction for face,
fingerprint, and iris modalities. The ubiquity and affordability of biometric
sensors further facilitate multi-modal fusion, which can enhance security by
combining features from different modalities. This work investigates the
biometric performance of reduced multi-biometric template sizes. Experiments
are conducted on an in-house virtual multi-biometric database, derived from
DNN-extracted features for face, fingerprint, and iris, using the FRGC, MCYT,
and CASIA databases. The evaluated approaches are (i) explainable and
straightforward to implement under encryption, (ii) training-free, and (iii)
capable of generalization. Dimensionality reduction of feature vectors leads to
fewer operations in the Homomorphic Encryption (HE) domain, enabling more
efficient encrypted processing while maintaining biometric accuracy and
security at a level equivalent to or exceeding single-biometric recognition.
Our results demonstrate that, by fusing feature vectors from multiple
modalities, template size can be reduced by 67 % with no loss in Equal Error
Rate (EER) compared to the best-performing single modality.

</details>


### [127] [Remove360: Benchmarking Residuals After Object Removal in 3D Gaussian Splatting](https://arxiv.org/abs/2508.11431)
*Simona Kocour,Assia Benbihi,Torsten Sattler*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一个评估框架和数据集Remove360，用于衡量3D高斯泼溅中物体移除后遗留的语义残留，揭示了当前技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究物体移除后遗留的语义信息对隐私保护3D重建和可编辑场景表示的重要性。

Method: 引入新基准和评估框架，通过实验验证语义残留问题，并发布Remove360数据集。

Result: 实验表明当前方法在移除物体后仍可能保留语义信息，且下游模型能推断移除内容。

Conclusion: 当前3D物体移除技术存在局限性，需更鲁棒的解决方案。

Abstract: Understanding what semantic information persists after object removal is
critical for privacy-preserving 3D reconstruction and editable scene
representations. In this work, we introduce a novel benchmark and evaluation
framework to measure semantic residuals, the unintended semantic traces left
behind, after object removal in 3D Gaussian Splatting. We conduct experiments
across a diverse set of indoor and outdoor scenes, showing that current methods
can preserve semantic information despite the absence of visual geometry. We
also release Remove360, a dataset of pre/post-removal RGB images and
object-level masks captured in real-world environments. While prior datasets
have focused on isolated object instances, Remove360 covers a broader and more
complex range of indoor and outdoor scenes, enabling evaluation of object
removal in the context of full-scene representations. Given ground truth images
of a scene before and after object removal, we assess whether we can truly
eliminate semantic presence, and if downstream models can still infer what was
removed. Our findings reveal critical limitations in current 3D object removal
techniques and underscore the need for more robust solutions capable of
handling real-world complexity. The evaluation framework is available at
github.com/spatial-intelligence-ai/Remove360.git. Data are available at
huggingface.co/datasets/simkoc/Remove360.

</details>


### [128] [Inside Knowledge: Graph-based Path Generation with Explainable Data Augmentation and Curriculum Learning for Visual Indoor Navigation](https://arxiv.org/abs/2508.11446)
*Daniel Airinei,Elena Burceanu,Marius Leordeanu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于视觉输入的室内导航深度学习方法，结合图路径生成、数据增强和课程学习，实现了高效、实时且易部署的解决方案。


<details>
  <summary>Details</summary>
Motivation: 室内导航因GPS信号差而困难，现有解决方案复杂且难以部署。

Method: 采用图路径生成方法、可解释数据增强和课程学习，实现自动化的数据收集、标注和训练。

Result: 提出新的大规模数据集和Android应用，仅依赖视觉输入，无需额外传感器或地图知识。

Conclusion: 方法高效、易部署，且开源数据和代码。

Abstract: Indoor navigation is a difficult task, as it generally comes with poor GPS
access, forcing solutions to rely on other sources of information. While
significant progress continues to be made in this area, deployment to
production applications is still lacking, given the complexity and additional
requirements of current solutions. Here, we introduce an efficient, real-time
and easily deployable deep learning approach, based on visual input only, that
can predict the direction towards a target from images captured by a mobile
device. Our technical approach, based on a novel graph-based path generation
method, combined with explainable data augmentation and curriculum learning,
includes contributions that make the process of data collection, annotation and
training, as automatic as possible, efficient and robust. On the practical
side, we introduce a novel largescale dataset, with video footage inside a
relatively large shopping mall, in which each frame is annotated with the
correct next direction towards different specific target destinations.
Different from current methods, ours relies solely on vision, avoiding the need
of special sensors, additional markers placed along the path, knowledge of the
scene map or internet access. We also created an easy to use application for
Android, which we plan to make publicly available. We make all our data and
code available along with visual demos on our project site

</details>


### [129] [CoFi: A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement Membrane Segmentation](https://arxiv.org/abs/2508.11469)
*Hongjin Fang,Daniel Reisenbüchler,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

Relevance: 30.0

TL;DR: CoFi是一种用于电子显微镜图像中肾小球基底膜分割的粗到细少样本学习管道，通过轻量级网络和SAM模型实现高效、准确的标注。


<details>
  <summary>Details</summary>
Motivation: 减少传统监督学习方法对大量像素级标注的依赖，同时解决少样本学习在捕捉精细结构上的不足。

Method: CoFi首先用三张标注图像训练轻量级网络生成粗分割掩码，再通过形态学修剪生成高质量点提示，引导SAM模型细化分割。

Result: Dice系数74.54%，推理速度1.9 FPS，显著减轻标注和计算负担。

Conclusion: CoFi高效且准确，适用于研究和临床肾病理学应用。

Abstract: Accurate segmentation of the glomerular basement membrane (GBM) in electron
microscopy (EM) images is fundamental for quantifying membrane thickness and
supporting the diagnosis of various kidney diseases. While supervised deep
learning approaches achieve high segmentation accuracy, their reliance on
extensive pixel-level annotation renders them impractical for clinical
workflows. Few-shot learning can reduce this annotation burden but often
struggles to capture the fine structural details necessary for GBM analysis. In
this study, we introduce CoFi, a fast and efficient coarse-to-fine few-shot
segmentation pipeline designed for GBM delineation in EM images. CoFi first
trains a lightweight neural network using only three annotated images to
produce an initial coarse segmentation mask. This mask is then automatically
processed to generate high-quality point prompts with morphology-aware pruning,
which are subsequently used to guide SAM in refining the segmentation. The
proposed method achieved exceptional GBM segmentation performance, with a Dice
coefficient of 74.54% and an inference speed of 1.9 FPS. We demonstrate that
CoFi not only alleviates the annotation and computational burdens associated
with conventional methods, but also achieves accurate and reliable segmentation
results. The pipeline's speed and annotation efficiency make it well-suited for
research and hold strong potential for clinical applications in renal
pathology. The pipeline is publicly available at:
https://github.com/ddrrnn123/CoFi.

</details>


### [130] [TACR-YOLO: A Real-time Detection Framework for Abnormal Human Behaviors Enhanced with Coordinate and Task-Aware Representations](https://arxiv.org/abs/2508.11478)
*Xinyi Yin,Wenbo Yuan,Xuecheng Wu,Liangyu Fu,Danlei Huang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出TACR-YOLO框架，通过坐标注意力模块、任务感知注意力模块和增强颈部网络解决异常行为检测中的小物体、任务冲突和多尺度融合问题，并在PABD数据集上取得91.92% mAP。


<details>
  <summary>Details</summary>
Motivation: 解决异常行为检测中YOLO方法面临的小物体检测、任务冲突和多尺度融合等挑战。

Method: 引入坐标注意力模块、任务感知注意力模块和增强颈部网络，优化锚框大小并使用DIoU-Loss。

Result: 在PABD数据集上达到91.92% mAP，速度和鲁棒性表现优异。

Conclusion: TACR-YOLO为特殊场景下的异常行为检测提供了新思路。

Abstract: Abnormal Human Behavior Detection (AHBD) under special scenarios is becoming
increasingly crucial. While YOLO-based detection methods excel in real-time
tasks, they remain hindered by challenges including small objects, task
conflicts, and multi-scale fusion in AHBD. To tackle them, we propose
TACR-YOLO, a new real-time framework for AHBD. We introduce a Coordinate
Attention Module to enhance small object detection, a Task-Aware Attention
Module to deal with classification-regression conflicts, and a Strengthen Neck
Network for refined multi-scale fusion, respectively. In addition, we optimize
Anchor Box sizes using K-means clustering and deploy DIoU-Loss to improve
bounding box regression. The Personnel Anomalous Behavior Detection (PABD)
dataset, which includes 8,529 samples across four behavior categories, is also
presented. Extensive experimental results indicate that TACR-YOLO achieves
91.92% mAP on PABD, with competitive speed and robustness. Ablation studies
highlight the contribution of each improvement. This work provides new insights
for abnormal behavior detection under special scenarios, advancing its
progress.

</details>


### [131] [OpenConstruction: A Systematic Synthesis of Open Visual Datasets for Data-Centric Artificial Intelligence in Construction Monitoring](https://arxiv.org/abs/2508.11482)
*Ruoxin Xiong,Yanyu Wang,Jiannan Cai,Kaijian Liu,Yuansheng Zhu,Pingbo Tang,Nora El-Gohary*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文对建筑行业中用于AI/ML应用的视觉数据集进行了系统综述，提出了一个分类框架并创建了开源目录OpenConstruction，同时指出了现有数据集的局限性并提出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 建筑行业缺乏对视觉数据集的系统分类和评估，限制了AI应用的可靠性和可扩展性。

Method: 通过搜索学术数据库和开放数据平台，收集了51个公开视觉数据集，并使用结构化数据模式进行分类。

Result: 创建了OpenConstruction开源目录，总结了数据集特点，并指出了现有数据集的局限性。

Conclusion: 提出了基于FAIR原则的未来数据基础设施路线图，以支持建筑行业的数据驱动方法发展。

Abstract: The construction industry increasingly relies on visual data to support
Artificial Intelligence (AI) and Machine Learning (ML) applications for site
monitoring. High-quality, domain-specific datasets, comprising images, videos,
and point clouds, capture site geometry and spatiotemporal dynamics, including
the location and interaction of objects, workers, and materials. However,
despite growing interest in leveraging visual datasets, existing resources vary
widely in sizes, data modalities, annotation quality, and representativeness of
real-world construction conditions. A systematic review to categorize their
data characteristics and application contexts is still lacking, limiting the
community's ability to fully understand the dataset landscape, identify
critical gaps, and guide future directions toward more effective, reliable, and
scalable AI applications in construction. To address this gap, this study
conducts an extensive search of academic databases and open-data platforms,
yielding 51 publicly available visual datasets that span the 2005-2024 period.
These datasets are categorized using a structured data schema covering (i) data
fundamentals (e.g., size and license), (ii) data modalities (e.g., RGB and
point cloud), (iii) annotation frameworks (e.g., bounding boxes), and (iv)
downstream application domains (e.g., progress tracking). This study
synthesizes these findings into an open-source catalog, OpenConstruction,
supporting data-driven method development. Furthermore, the study discusses
several critical limitations in the existing construction dataset landscape and
presents a roadmap for future data infrastructure anchored in the Findability,
Accessibility, Interoperability, and Reusability (FAIR) principles. By
reviewing the current landscape and outlining strategic priorities, this study
supports the advancement of data-centric solutions in the construction sector.

</details>


### [132] [Automated Building Heritage Assessment Using Street-Level Imagery](https://arxiv.org/abs/2508.11486)
*Kristina Dabrock,Tim Johansson,Anna Donarelli,Mikael Mangold,Noah Pflugradt,Jann Michael Weinand,Jochen Linßen*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文利用GPT检测建筑立面图像的文化遗产价值，结合建筑登记数据训练机器学习模型，验证结果显示结合数据效果更好。


<details>
  <summary>Details</summary>
Motivation: 传统建筑文化遗产评估耗时且昂贵，AI工具可提高效率。

Method: 使用GPT从立面图像提取文化遗产特征，结合建筑登记数据训练分类模型。

Result: 结合GPT和登记数据的模型F1得分为0.71，仅GPT数据为0.60。

Conclusion: 该方法可提升数据库质量，支持兼顾文化遗产的节能改造。

Abstract: Detailed data is required to quantify energy conservation measures in
buildings, such as envelop retrofits, without compromising cultural heritage.
Novel artificial intelligence tools may improve efficiency in identifying
heritage values in buildings compared to costly and time-consuming traditional
inventories. In this study, the large language model GPT was used to detect
various aspects of cultural heritage value in fa\c{c}ade images. Using this
data and building register data as features, machine learning models were
trained to classify multi-family and non-residential buildings in Stockholm,
Sweden. Validation against an expert-created inventory shows a macro F1-score
of 0.71 using a combination of register data and features retrieved from GPT,
and a score of 0.60 using only GPT-derived data. The presented methodology can
contribute to a higher-quality database and thus support careful energy
efficiency measures and integrated consideration of heritage value in
large-scale energetic refurbishment scenarios.

</details>


### [133] [HistoViT: Vision Transformer for Accurate and Scalable Histopathological Cancer Diagnosis](https://arxiv.org/abs/2508.11181)
*Faisal Ahmed*

Main category: eess.IV

Relevance: 30.0

TL;DR: 该论文提出了一种基于Transformer的深度学习框架，用于组织病理学图像中的多类肿瘤分类，展示了其在乳腺癌、前列腺癌、骨癌和宫颈癌数据集上的优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决现代病理学中癌症诊断的准确性和可扩展性挑战，特别是针对具有复杂组织学变异性的恶性肿瘤。

Method: 使用微调的Vision Transformer (ViT)架构，结合简化的预处理流程，将全切片图像转换为PyTorch张量并进行数据标准化。

Result: 在四个基准数据集上表现优异，分类准确率分别为99.32%（乳腺癌）、96.92%（前列腺癌）、95.28%（骨癌）和96.94%（宫颈癌），AUC得分均超过99%。

Conclusion: Transformer架构在数字病理学中具有鲁棒性、泛化性和临床潜力，为自动化癌症诊断系统提供了重要进展。

Abstract: Accurate and scalable cancer diagnosis remains a critical challenge in modern
pathology, particularly for malignancies such as breast, prostate, bone, and
cervical, which exhibit complex histological variability. In this study, we
propose a transformer-based deep learning framework for multi-class tumor
classification in histopathological images. Leveraging a fine-tuned Vision
Transformer (ViT) architecture, our method addresses key limitations of
conventional convolutional neural networks, offering improved performance,
reduced preprocessing requirements, and enhanced scalability across tissue
types. To adapt the model for histopathological cancer images, we implement a
streamlined preprocessing pipeline that converts tiled whole-slide images into
PyTorch tensors and standardizes them through data normalization. This ensures
compatibility with the ViT architecture and enhances both convergence stability
and overall classification performance. We evaluate our model on four benchmark
datasets: ICIAR2018 (breast), SICAPv2 (prostate), UT-Osteosarcoma (bone), and
SipakMed (cervical) dataset -- demonstrating consistent outperformance over
existing deep learning methods. Our approach achieves classification accuracies
of 99.32%, 96.92%, 95.28%, and 96.94% for breast, prostate, bone, and cervical
cancers respectively, with area under the ROC curve (AUC) scores exceeding 99%
across all datasets. These results confirm the robustness, generalizability,
and clinical potential of transformer-based architectures in digital pathology.
Our work represents a significant advancement toward reliable, automated, and
interpretable cancer diagnosis systems that can alleviate diagnostic burdens
and improve healthcare outcomes.

</details>


### [134] [Hierarchical Graph Feature Enhancement with Adaptive Frequency Modulation for Visual Recognition](https://arxiv.org/abs/2508.11497)
*Feiyue Zhao,Zhichao Zhang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种名为HGFE的框架，通过将图推理融入CNN，增强结构感知和特征表示。HGFE包含局部和全局图结构，并引入自适应频率调制模块。实验验证了其在分类、检测和分割任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决CNN在建模复杂拓扑关系和非局部语义时的局限性。

Method: 提出HGFE框架，结合局部和全局图结构，并引入自适应频率调制模块。

Result: 在多个数据集（CIFAR-100、PASCAL VOC等）上验证了HGFE的有效性。

Conclusion: HGFE能显著提升结构表示和整体识别性能。

Abstract: Convolutional neural networks (CNNs) have
  demonstrated strong performance in visual recognition tasks,
  but their inherent reliance on regular grid structures limits
  their capacity to model complex topological relationships and
  non-local semantics within images. To address this limita tion, we propose
the hierarchical graph feature enhancement
  (HGFE), a novel framework that integrates graph-based rea soning into CNNs to
enhance both structural awareness and
  feature representation. HGFE builds two complementary levels
  of graph structures: intra-window graph convolution to cap ture local spatial
dependencies and inter-window supernode
  interactions to model global semantic relationships. Moreover,
  we introduce an adaptive frequency modulation module that
  dynamically balances low-frequency and high-frequency signal
  propagation, preserving critical edge and texture information
  while mitigating over-smoothing. The proposed HGFE module
  is lightweight, end-to-end trainable, and can be seamlessly
  integrated into standard CNN backbone networks. Extensive
  experiments on CIFAR-100 (classification), PASCAL VOC,
  and VisDrone (detection), as well as CrackSeg and CarParts
  (segmentation), validated the effectiveness of the HGFE in
  improving structural representation and enhancing overall
  recognition performance.

</details>


### [135] [Handwritten Text Recognition of Historical Manuscripts Using Transformer-Based Models](https://arxiv.org/abs/2508.11499)
*Erez Meoded*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该研究将TrOCR模型应用于16世纪拉丁手稿，通过图像预处理和数据增强技术提升了识别性能，最佳单模型CER为1.86，集成方法进一步降至1.60。


<details>
  <summary>Details</summary>
Motivation: 解决历史手写文本识别中的稀缺转录、语言变异和多样化书写风格问题。

Method: 使用TrOCR模型，结合图像预处理、数据增强（包括四种新方法）和集成学习策略。

Result: 最佳单模型CER为1.86，集成方法CER为1.60，性能显著提升。

Conclusion: 领域特定的数据增强和集成策略对提升历史手写文本识别性能至关重要。

Abstract: Historical handwritten text recognition (HTR) is essential for unlocking the
cultural and scholarly value of archival documents, yet digitization is often
hindered by scarce transcriptions, linguistic variation, and highly diverse
handwriting styles. In this study, we apply TrOCR, a state-of-the-art
transformer-based HTR model, to 16th-century Latin manuscripts authored by
Rudolf Gwalther. We investigate targeted image preprocessing and a broad suite
of data augmentation techniques, introducing four novel augmentation methods
designed specifically for historical handwriting characteristics. We also
evaluate ensemble learning approaches to leverage the complementary strengths
of augmentation-trained models. On the Gwalther dataset, our best single-model
augmentation (Elastic) achieves a Character Error Rate (CER) of 1.86, while a
top-5 voting ensemble achieves a CER of 1.60 - representing a 50% relative
improvement over the best reported TrOCR_BASE result and a 42% improvement over
the previous state of the art. These results highlight the impact of
domain-specific augmentations and ensemble strategies in advancing HTR
performance for historical manuscripts.

</details>


### [136] [A Real-time Concrete Crack Detection and Segmentation Model Based on YOLOv11](https://arxiv.org/abs/2508.11517)
*Shaoze Huang,Qi Liu,Chao Chen,Yuhang Chen*

Main category: cs.CV

Relevance: 30.0

TL;DR: 本文提出了一种基于YOLOv11n架构的多任务混凝土裂缝检测与分割模型YOLOv11-KW-TA-FP，通过动态KernelWarehouse卷积、三重注意力机制和FP-IoU损失函数优化，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 快速发展的长江三角洲地区交通基础设施老化问题突出，传统人工检测效率低下，现有深度学习模型在复杂背景下的小目标裂缝检测性能不足。

Method: 采用三阶段优化框架：1) 动态KernelWarehouse卷积增强特征表示；2) 三重注意力机制强化通道-空间交互建模；3) FP-IoU损失函数优化边界框回归。

Result: 实验表明，模型在精度（91.3%）、召回率（76.6%）和mAP@50（86.4%）上显著优于基线，并在数据稀缺和噪声干扰下表现稳定。

Conclusion: 该研究为自动化基础设施检测提供了高效的计算机视觉解决方案，具有显著工程实用价值。

Abstract: Accelerated aging of transportation infrastructure in the rapidly developing
Yangtze River Delta region necessitates efficient concrete crack detection, as
crack deterioration critically compromises structural integrity and regional
economic growth. To overcome the limitations of inefficient manual inspection
and the suboptimal performance of existing deep learning models, particularly
for small-target crack detection within complex backgrounds, this paper
proposes YOLOv11-KW-TA-FP, a multi-task concrete crack detection and
segmentation model based on the YOLOv11n architecture. The proposed model
integrates a three-stage optimization framework: (1) Embedding dynamic
KernelWarehouse convolution (KWConv) within the backbone network to enhance
feature representation through a dynamic kernel sharing mechanism; (2)
Incorporating a triple attention mechanism (TA) into the feature pyramid to
strengthen channel-spatial interaction modeling; and (3) Designing an FP-IoU
loss function to facilitate adaptive bounding box regression penalization.
Experimental validation demonstrates that the enhanced model achieves
significant performance improvements over the baseline, attaining 91.3%
precision, 76.6% recall, and 86.4% mAP@50. Ablation studies confirm the
synergistic efficacy of the proposed modules. Furthermore, robustness tests
indicate stable performance under conditions of data scarcity and noise
interference. This research delivers an efficient computer vision solution for
automated infrastructure inspection, exhibiting substantial practical
engineering value.

</details>


### [137] [An Efficient Medical Image Classification Method Based on a Lightweight Improved ConvNeXt-Tiny Architecture](https://arxiv.org/abs/2508.11532)
*Jingsong Xia,Yue Yin,Xiuhan Li*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于改进ConvNeXt-Tiny架构的医学图像分类方法，通过结构优化和损失函数设计提升特征提取能力和分类性能，同时降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限的计算环境中实现高效高精度医学图像分类的挑战。

Method: 引入双全局池化特征融合策略和轻量级通道注意力模块SEVector，结合特征平滑损失函数。

Result: 在CPU条件下（8线程），10个训练周期内测试集分类准确率达89.10%，损失值稳定收敛。

Conclusion: 该方法为资源受限环境下的医学图像分类提供了高效可行的解决方案。

Abstract: Intelligent analysis of medical imaging plays a crucial role in assisting
clinical diagnosis. However, achieving efficient and high-accuracy image
classification in resource-constrained computational environments remains
challenging. This study proposes a medical image classification method based on
an improved ConvNeXt-Tiny architecture. Through structural optimization and
loss function design, the proposed method enhances feature extraction
capability and classification performance while reducing computational
complexity. Specifically, the method introduces a dual global pooling (Global
Average Pooling and Global Max Pooling) feature fusion strategy into the
ConvNeXt-Tiny backbone to simultaneously preserve global statistical features
and salient response information. A lightweight channel attention module,
termed Squeeze-and-Excitation Vector (SEVector), is designed to improve the
adaptive allocation of channel weights while minimizing parameter overhead.
Additionally, a Feature Smoothing Loss is incorporated into the loss function
to enhance intra-class feature consistency and suppress intra-class variance.
Under CPU-only conditions (8 threads), the method achieves a maximum
classification accuracy of 89.10% on the test set within 10 training epochs,
exhibiting a stable convergence trend in loss values. Experimental results
demonstrate that the proposed method effectively improves medical image
classification performance in resource-limited settings, providing a feasible
and efficient solution for the deployment and promotion of medical imaging
analysis models.

</details>


### [138] [Semi-Supervised Learning with Online Knowledge Distillation for Skin Lesion Classification](https://arxiv.org/abs/2508.11511)
*Siyamalan Manivannan*

Main category: eess.IV

Relevance: 30.0

TL;DR: 论文提出了一种结合集成学习和在线知识蒸馏的半监督深度学习方法，用于皮肤病变分类，减少对大量标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决皮肤病变分析中标注数据获取成本高的问题，提出一种资源高效的解决方案。

Method: 使用集成学习的卷积神经网络模型，并通过在线知识蒸馏将集成模型的性能传递给单个模型。

Result: 在ISIC 2018和2019数据集上表现优于现有方法，单个模型性能优于独立训练模型。

Conclusion: 该方法在减少标注数据需求的同时，提供了高效的皮肤病变分类方案。

Abstract: Deep Learning has emerged as a promising approach for skin lesion analysis.
However, existing methods mostly rely on fully supervised learning, requiring
extensive labeled data, which is challenging and costly to obtain. To alleviate
this annotation burden, this study introduces a novel semi-supervised deep
learning approach that integrates ensemble learning with online knowledge
distillation for enhanced skin lesion classification. Our methodology involves
training an ensemble of convolutional neural network models, using online
knowledge distillation to transfer insights from the ensemble to its members.
This process aims to enhance the performance of each model within the ensemble,
thereby elevating the overall performance of the ensemble itself.
Post-training, any individual model within the ensemble can be deployed at test
time, as each member is trained to deliver comparable performance to the
ensemble. This is particularly beneficial in resource-constrained environments.
Experimental results demonstrate that the knowledge-distilled individual model
performs better than independently trained models. Our approach demonstrates
superior performance on both the \emph{International Skin Imaging
Collaboration} 2018 and 2019 public benchmark datasets, surpassing current
state-of-the-art results. By leveraging ensemble learning and online knowledge
distillation, our method reduces the need for extensive labeled data while
providing a more resource-efficient solution for skin lesion classification in
real-world scenarios.

</details>


### [139] [Efficient Image-to-Image Schrödinger Bridge for CT Field of View Extension](https://arxiv.org/abs/2508.11211)
*Zhenhao Li,Long Yang,Xiaojie Yin,Haijun Yu,Jiazhou Wang,Hongbin Han,Weigang Hu,Yixing Huang*

Main category: eess.IV

Relevance: 30.0

TL;DR: 提出了一种基于Schrödinger Bridge扩散模型的高效CT视野扩展框架（I²SB），通过直接学习有限视野与扩展视野图像的映射，显著提升了重建速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统CT重建算法在视野扩展时的局限性，以及现有扩散模型计算效率低的问题。

Method: 采用I²SB扩散模型，直接学习有限视野与扩展视野图像的随机映射，避免从高斯噪声迭代生成图像。

Result: 在模拟和真实数据上均优于现有扩散模型（如cDDPM），重建速度提升700倍（0.19s/切片）。

Conclusion: I²SB在准确性和效率上的优势使其适合实时或临床部署。

Abstract: Computed tomography (CT) is a cornerstone imaging modality for non-invasive,
high-resolution visualization of internal anatomical structures. However, when
the scanned object exceeds the scanner's field of view (FOV), projection data
are truncated, resulting in incomplete reconstructions and pronounced artifacts
near FOV boundaries. Conventional reconstruction algorithms struggle to recover
accurate anatomy from such data, limiting clinical reliability. Deep learning
approaches have been explored for FOV extension, with diffusion generative
models representing the latest advances in image synthesis. Yet, conventional
diffusion models are computationally demanding and slow at inference due to
their iterative sampling process. To address these limitations, we propose an
efficient CT FOV extension framework based on the image-to-image Schr\"odinger
Bridge (I$^2$SB) diffusion model. Unlike traditional diffusion models that
synthesize images from pure Gaussian noise, I$^2$SB learns a direct stochastic
mapping between paired limited-FOV and extended-FOV images. This direct
correspondence yields a more interpretable and traceable generative process,
enhancing anatomical consistency and structural fidelity in reconstructions.
I$^2$SB achieves superior quantitative performance, with root-mean-square error
(RMSE) values of 49.8\,HU on simulated noisy data and 152.0HU on real data,
outperforming state-of-the-art diffusion models such as conditional denoising
diffusion probabilistic models (cDDPM) and patch-based diffusion methods.
Moreover, its one-step inference enables reconstruction in just 0.19s per 2D
slice, representing over a 700-fold speedup compared to cDDPM (135s) and
surpassing diffusionGAN (0.58s), the second fastest. This combination of
accuracy and efficiency makes I$^2$SB highly suitable for real-time or clinical
deployment.

</details>


### [140] [Temporally-Similar Structure-Aware Spatiotemporal Fusion of Satellite Images](https://arxiv.org/abs/2508.11259)
*Ryosuke Isono,Shunsuke Ono*

Main category: eess.SP

Relevance: 30.0

TL;DR: 论文提出了一种名为TSSTF的时空融合框架，用于卫星图像处理，通过TGTV和TGEC机制提升噪声条件下的空间结构保留能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有时空融合方法在噪声条件下无法保留精细空间结构的问题。

Method: 引入TGTV和TGEC机制，将任务建模为约束优化问题，并开发高效算法。

Result: TSSTF在无噪声条件下与现有方法相当，在噪声条件下表现更优。

Conclusion: TSSTF在噪声条件下具有优越性能，并提供了可复现的参数建议。

Abstract: This paper proposes a novel spatiotemporal (ST) fusion framework for
satellite images, named Temporally-Similar Structure-Aware ST fusion (TSSTF).
ST fusion is a promising approach to address the trade-off between the spatial
and temporal resolution of satellite images. In real-world scenarios, observed
satellite images are severely degraded by noise due to measurement equipment
and environmental conditions. Consequently, some recent studies have focused on
enhancing the robustness of ST fusion methods against noise. However, existing
noise-robust ST fusion approaches often fail to capture fine spatial structure,
leading to oversmoothing and artifacts. To address this issue, TSSTF introduces
two key mechanisms: Temporally-Guided Total Variation (TGTV) and
Temporally-Guided Edge Constraint (TGEC). TGTV is a novel regularization
function that promotes spatial piecewise smoothness while preserving structural
details, guided by a reference high spatial resolution image acquired on a
nearby date. TGEC enforces consistency in edge locations between two temporally
adjacent images, while allowing for spectral variations. We formulate the ST
fusion task as a constrained optimization problem incorporating TGTV and TGEC,
and develop an efficient algorithm based on a preconditioned primal-dual
splitting method. Experimental results demonstrate that TSSTF performs
comparably to state-of-the-art methods under noise-free conditions and
outperforms them under noisy conditions. Additionally, we provide a
comprehensive set of recommended parameter values that consistently yield high
performance across diverse target regions and noise conditions, aiming to
enhance reproducibility and practical utility.

</details>


### [141] [AnatoMaskGAN: GNN-Driven Slice Feature Fusion and Noise Augmentation for Medical Semantic Image Synthesis](https://arxiv.org/abs/2508.11375)
*Zonglin Wu,Yule Xue,Qianxiang Hu,Yaoyao Feng,Yuqi Ma,Shanxiong Chen*

Main category: eess.IV

Relevance: 30.0

TL;DR: AnatoMaskGAN是一种新型医学图像合成框架，通过嵌入切片相关空间特征、多样化的图像增强策略和优化深度特征学习，提升复杂医学图像的性能。


<details>
  <summary>Details</summary>
Motivation: 解决GAN方法在医学图像合成中一对一生成和空间一致性不足的问题。

Method: 设计GNN切片特征融合模块、三维空间噪声注入策略和灰度纹理分类器。

Result: 在L2R-OASIS和L2R-Abdomen CT数据集上表现优异，PSNR和SSIM显著提升。

Conclusion: 各核心设计对重建精度和感知质量有独立贡献。

Abstract: Medical semantic-mask synthesis boosts data augmentation and analysis, yet
most GAN-based approaches still produce one-to-one images and lack spatial
consistency in complex scans. To address this, we propose AnatoMaskGAN, a novel
synthesis framework that embeds slice-related spatial features to precisely
aggregate inter-slice contextual dependencies, introduces diverse
image-augmentation strategies, and optimizes deep feature learning to improve
performance on complex medical images. Specifically, we design a GNN-based
strongly correlated slice-feature fusion module to model spatial relationships
between slices and integrate contextual information from neighboring slices,
thereby capturing anatomical details more comprehensively; we introduce a
three-dimensional spatial noise-injection strategy that weights and fuses
spatial features with noise to enhance modeling of structural diversity; and we
incorporate a grayscale-texture classifier to optimize grayscale distribution
and texture representation during generation. Extensive experiments on the
public L2R-OASIS and L2R-Abdomen CT datasets show that AnatoMaskGAN raises PSNR
on L2R-OASIS to 26.50 dB (0.43 dB higher than the current state of the art) and
achieves an SSIM of 0.8602 on L2R-Abdomen CT--a 0.48 percentage-point gain over
the best model, demonstrating its superiority in reconstruction accuracy and
perceptual quality. Ablation studies that successively remove the slice-feature
fusion module, spatial 3D noise-injection strategy, and grayscale-texture
classifier reveal that each component contributes significantly to PSNR, SSIM,
and LPIPS, further confirming the independent value of each core design in
enhancing reconstruction accuracy and perceptual quality.

</details>


### [142] [Relative Position Matters: Trajectory Prediction and Planning with Polar Representation](https://arxiv.org/abs/2508.11492)
*Bozhou Zhang,Nan Song,Bingzhao Gao,Li Zhang*

Main category: cs.RO

Relevance: 30.0

TL;DR: 论文提出了一种基于极坐标的自动驾驶轨迹预测与规划方法Polaris，相比传统笛卡尔坐标方法，能更直观地建模距离和方向关系，并在多个基准测试中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在笛卡尔坐标系中建模自动驾驶的轨迹预测与规划，未能有效捕捉交通元素间的距离和方向关系，导致性能受限。

Method: 提出Polaris方法，完全基于极坐标系，通过专用编码和优化模块显式建模距离和方向变化，捕捉相对关系。

Result: 在Argoverse 2和nuPlan等基准测试中，Polaris实现了最优性能。

Conclusion: 极坐标表示能更有效地建模自动驾驶中的空间关系，提升轨迹预测与规划的性能。

Abstract: Trajectory prediction and planning in autonomous driving are highly
challenging due to the complexity of predicting surrounding agents' movements
and planning the ego agent's actions in dynamic environments. Existing methods
encode map and agent positions and decode future trajectories in Cartesian
coordinates. However, modeling the relationships between the ego vehicle and
surrounding traffic elements in Cartesian space can be suboptimal, as it does
not naturally capture the varying influence of different elements based on
their relative distances and directions. To address this limitation, we adopt
the Polar coordinate system, where positions are represented by radius and
angle. This representation provides a more intuitive and effective way to model
spatial changes and relative relationships, especially in terms of distance and
directional influence. Based on this insight, we propose Polaris, a novel
method that operates entirely in Polar coordinates, distinguishing itself from
conventional Cartesian-based approaches. By leveraging the Polar
representation, this method explicitly models distance and direction variations
and captures relative relationships through dedicated encoding and refinement
modules, enabling more structured and spatially aware trajectory prediction and
planning. Extensive experiments on the challenging prediction (Argoverse 2) and
planning benchmarks (nuPlan) demonstrate that Polaris achieves state-of-the-art
performance.

</details>


### [143] [Relative Pose Regression with Pose Auto-Encoders: Enhancing Accuracy and Data Efficiency for Retail Applications](https://arxiv.org/abs/2508.10933)
*Yoli Shavit,Yosi Keller*

Main category: cs.CV

Relevance: 20.0

TL;DR: 该论文提出了一种基于相机姿态自动编码器（PAE）的相对姿态回归（RPR）方法，用于改进单图像绝对姿态回归（APR）的定位精度，无需额外存储图像或姿态数据。


<details>
  <summary>Details</summary>
Motivation: 现代零售环境中，精确的相机定位对提升客户体验和库存管理至关重要。现有APR方法虽有效，但结合视觉和空间场景先验的方法通常更准确。

Method: 扩展PAE至RPR任务，并提出一种新的重定位方案，利用PAE-based RPR优化APR预测。

Result: 在室内基准测试中，该方法显著提高了APR的定位精度，且仅需30%的训练数据即可达到竞争性性能。

Conclusion: 提出的方法减少了零售部署中的数据收集负担，同时保持了高精度。

Abstract: Accurate camera localization is crucial for modern retail environments,
enabling enhanced customer experiences, streamlined inventory management, and
autonomous operations. While Absolute Pose Regression (APR) from a single image
offers a promising solution, approaches that incorporate visual and spatial
scene priors tend to achieve higher accuracy. Camera Pose Auto-Encoders (PAEs)
have recently been introduced to embed such priors into APR. In this work, we
extend PAEs to the task of Relative Pose Regression (RPR) and propose a novel
re-localization scheme that refines APR predictions using PAE-based RPR,
without requiring additional storage of images or pose data. We first introduce
PAE-based RPR and establish its effectiveness by comparing it with image-based
RPR models of equivalent architectures. We then demonstrate that our refinement
strategy, driven by a PAE-based RPR, enhances APR localization accuracy on
indoor benchmarks. Notably, our method is shown to achieve competitive
performance even when trained with only 30% of the data, substantially reducing
the data collection burden for retail deployment. Our code and pre-trained
models are available at: https://github.com/yolish/camera-pose-auto-encoders

</details>


### [144] [NIRMAL Pooling: An Adaptive Max Pooling Approach with Non-linear Activation for Enhanced Image Classification](https://arxiv.org/abs/2508.10940)
*Nirmal Gaud,Krishna Kumar Jha,Jhimli Adhikari,Adhini Nasarin P S,Joydeep Das,Samarth S Deshpande,Nitasha Barara,Vaduguru Venkata Ramya,Santu Saha,Mehmet Tarik Baran,Sarangi Venkateshwarlu,Anusha M D,Surej Mouli,Preeti Katiyar,Vipin Kumar Chaudhary*

Main category: cs.CV

Relevance: 20.0

TL;DR: NIRMAL Pooling是一种新型CNN池化层，结合自适应最大池化和非线性激活函数，提升图像分类任务的鲁棒性和特征表达能力。


<details>
  <summary>Details</summary>
Motivation: 传统池化方法在复杂数据集上表现有限，NIRMAL Pooling旨在通过动态调整参数和引入非线性激活，提升CNN性能。

Method: NIRMAL Pooling结合自适应最大池化和ReLU激活函数，动态调整参数以适应输出维度。

Result: 在MNIST Digits、MNIST Fashion和CIFAR-10数据集上，NIRMAL Pooling均优于标准Max Pooling，尤其在复杂数据集上提升显著。

Conclusion: NIRMAL Pooling为图像识别任务提供了更灵活可靠的池化方法。

Abstract: This paper presents NIRMAL Pooling, a novel pooling layer for Convolutional
Neural Networks (CNNs) that integrates adaptive max pooling with non-linear
activation function for image classification tasks. The acronym NIRMAL stands
for Non-linear Activation, Intermediate Aggregation, Reduction, Maximum,
Adaptive, and Localized. By dynamically adjusting pooling parameters based on
desired output dimensions and applying a Rectified Linear Unit (ReLU)
activation post-pooling, NIRMAL Pooling improves robustness and feature
expressiveness. We evaluated its performance against standard Max Pooling on
three benchmark datasets: MNIST Digits, MNIST Fashion, and CIFAR-10. NIRMAL
Pooling achieves test accuracies of 99.25% (vs. 99.12% for Max Pooling) on
MNIST Digits, 91.59% (vs. 91.44%) on MNIST Fashion, and 70.49% (vs. 68.87%) on
CIFAR-10, demonstrating consistent improvements, particularly on complex
datasets. This work highlights the potential of NIRMAL Pooling to enhance CNN
performance in diverse image recognition tasks, offering a flexible and
reliable alternative to traditional pooling methods.

</details>


### [145] [Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram](https://arxiv.org/abs/2508.10942)
*Liming Xu,Dave Towey,Andrew P. French,Steve Benford*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文研究了Artcodes的检测问题，提出了一种新的特征描述符（形状方向直方图）用于识别拓扑结构，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着智能手机和VR/AR技术的普及，虚拟与现实结合的物体将更常见。识别这些物体（如Artcodes）是触发后续交互的第一步。

Method: 提出了一种新的特征描述符（形状方向直方图）来描述Artcodes的拓扑结构，并构建了一个基于此特征的检测系统。

Result: 实验结果表明，所提出的特征描述符能有效表示拓扑结构，检测系统在Artcode识别上表现良好。

Conclusion: 本研究为拓扑物体检测提供了初步解决方案，可能开启新的交互应用。

Abstract: The increasing ubiquity of smartphones and resurgence of VR/AR techniques, it
is expected that our everyday environment may soon be decorating with objects
connecting with virtual elements. Alerting to the presence of these objects is
therefore the first step for motivating follow-up further inspection and
triggering digital material attached to the objects. This work studies a
special kind of these objects -- Artcodes -- a human-meaningful and
machine-readable decorative markers that camouflage themselves with freeform
appearance by encoding information into their topology. We formulate this
problem of recongising the presence of Artcodes as Artcode proposal detection,
a distinct computer vision task that classifies topologically similar but
geometrically and semantically different objects as a same class. To deal with
this problem, we propose a new feature descriptor, called the shape of
orientation histogram, to describe the generic topological structure of an
Artcode. We collect datasets and conduct comprehensive experiments to evaluate
the performance of the Artcode detection proposer built upon this new feature
vector. Our experimental results show the feasibility of the proposed feature
vector for representing topological structures and the effectiveness of the
system for detecting Artcode proposals. Although this work is an initial
attempt to develop a feature-based system for detecting topological objects
like Artcodes, it would open up new interaction opportunities and spark
potential applications of topological object detection.

</details>


### [146] [CSNR and JMIM Based Spectral Band Selection for Reducing Metamerism in Urban Driving](https://arxiv.org/abs/2508.10962)
*Jiarong Li,Imad Ali Shah,Diarmaid Geever,Fiachra Collins,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种基于高光谱成像（HSI）的方法，通过选择信息量最大的波段来增强对弱势道路使用者（VRU）的感知能力，减少视觉模糊问题。


<details>
  <summary>Details</summary>
Motivation: 解决汽车感知系统中因视觉模糊（如颜色相似性）导致的弱势道路使用者识别问题。

Method: 结合信息论技术和图像质量指标，提出波段选择策略，优化高光谱数据输入。

Result: 选定的HSI波段显著提高了VRU与背景的区分度，性能指标提升显著。

Conclusion: 该方法为高级驾驶辅助系统（ADAS）和自动驾驶（AD）提供了更可靠的感知基础。

Abstract: Protecting Vulnerable Road Users (VRU) is a critical safety challenge for
automotive perception systems, particularly under visual ambiguity caused by
metamerism, a phenomenon where distinct materials appear similar in RGB
imagery. This work investigates hyperspectral imaging (HSI) to overcome this
limitation by capturing unique material signatures beyond the visible spectrum,
especially in the Near-Infrared (NIR). To manage the inherent
high-dimensionality of HSI data, we propose a band selection strategy that
integrates information theory techniques (joint mutual information
maximization, correlation analysis) with a novel application of an image
quality metric (contrast signal-to-noise ratio) to identify the most spectrally
informative bands. Using the Hyperspectral City V2 (H-City) dataset, we
identify three informative bands (497 nm, 607 nm, and 895 nm, $\pm$27 nm) and
reconstruct pseudo-color images for comparison with co-registered RGB.
Quantitative results demonstrate increased dissimilarity and perceptual
separability of VRU from the background. The selected HSI bands yield
improvements of 70.24%, 528.46%, 1206.83%, and 246.62% for dissimilarity
(Euclidean, SAM, $T^2$) and perception (CIE $\Delta E$) metrics, consistently
outperforming RGB and confirming a marked reduction in metameric confusion. By
providing a spectrally optimized input, our method enhances VRU separability,
establishing a robust foundation for downstream perception tasks in Advanced
Driver Assistance Systems (ADAS) and Autonomous Driving (AD), ultimately
contributing to improved road safety.

</details>


### [147] [CHARM3R: Towards Unseen Camera Height Robust Monocular 3D Detector](https://arxiv.org/abs/2508.11185)
*Abhinav Kumar,Yuliang Guo,Zhihao Zhang,Xinyu Huang,Liu Ren,Xiaoming Liu*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文研究了单目3D目标检测器在不同相机高度下的性能问题，提出了一种新方法CHARM3R，通过结合两种深度估计来提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测器在相机高度变化时性能下降，尤其是深度估计问题显著。

Method: 通过系统分析相机高度变化对深度估计的影响，提出CHARM3R方法，结合回归和基于地面的深度估计。

Result: CHARM3R在CARLA数据集上对未见相机高度的泛化能力提升超过45%，达到SOTA性能。

Conclusion: CHARM3R通过优化深度估计显著提升了单目3D检测器在相机高度变化下的鲁棒性。

Abstract: Monocular 3D object detectors, while effective on data from one ego camera
height, struggle with unseen or out-of-distribution camera heights. Existing
methods often rely on Plucker embeddings, image transformations or data
augmentation. This paper takes a step towards this understudied problem by
first investigating the impact of camera height variations on state-of-the-art
(SoTA) Mono3D models. With a systematic analysis on the extended CARLA dataset
with multiple camera heights, we observe that depth estimation is a primary
factor influencing performance under height variations. We mathematically prove
and also empirically observe consistent negative and positive trends in mean
depth error of regressed and ground-based depth models, respectively, under
camera height changes. To mitigate this, we propose Camera Height Robust
Monocular 3D Detector (CHARM3R), which averages both depth estimates within the
model. CHARM3R improves generalization to unseen camera heights by more than
$45\%$, achieving SoTA performance on the CARLA dataset. Codes and Models at
https://github.com/abhi1kumar/CHARM3R

</details>


### [148] [Unifying Scale-Aware Depth Prediction and Perceptual Priors for Monocular Endoscope Pose Estimation and Tissue Reconstruction](https://arxiv.org/abs/2508.11282)
*Muzammil Khan,Enzo Kerkhof,Matteo Fusaglia,Koert Kuhlmann,Theo Ruers,Françoise J. Siepel*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种用于单目内窥镜组织重建的统一框架，结合了尺度感知深度预测和时间约束的感知细化，解决了深度模糊和组织变形等问题。


<details>
  <summary>Details</summary>
Motivation: 提升单目内窥镜手术中的导航和空间感知能力，解决深度模糊、组织变形等挑战。

Method: 框架包含MAPIS-Depth模块（结合Depth Pro和Depth Anything）和WEMA-RTDL模块，通过L-BFGS-B优化和RAFT计算像素对应关系，最终使用TSDF体积融合提取3D表面网格。

Result: 在HEVD和SCARED数据集上的评估表明，该方法优于现有技术。

Conclusion: 提出的框架在单目内窥镜组织重建中表现出鲁棒性和优越性。

Abstract: Accurate endoscope pose estimation and 3D tissue surface reconstruction
significantly enhances monocular minimally invasive surgical procedures by
enabling accurate navigation and improved spatial awareness. However, monocular
endoscope pose estimation and tissue reconstruction face persistent challenges,
including depth ambiguity, physiological tissue deformation, inconsistent
endoscope motion, limited texture fidelity, and a restricted field of view. To
overcome these limitations, a unified framework for monocular endoscopic tissue
reconstruction that integrates scale-aware depth prediction with
temporally-constrained perceptual refinement is presented. This framework
incorporates a novel MAPIS-Depth module, which leverages Depth Pro for robust
initialisation and Depth Anything for efficient per-frame depth prediction, in
conjunction with L-BFGS-B optimisation, to generate pseudo-metric depth
estimates. These estimates are temporally refined by computing pixel
correspondences using RAFT and adaptively blending flow-warped frames based on
LPIPS perceptual similarity, thereby reducing artefacts arising from
physiological tissue deformation and motion. To ensure accurate registration of
the synthesised pseudo-RGBD frames from MAPIS-Depth, a novel WEMA-RTDL module
is integrated, optimising both rotation and translation. Finally, truncated
signed distance function-based volumetric fusion and marching cubes are applied
to extract a comprehensive 3D surface mesh. Evaluations on HEVD and SCARED,
with ablation and comparative analyses, demonstrate the framework's robustness
and superiority over state-of-the-art methods.

</details>


### [149] [Hyperspectral vs. RGB for Pedestrian Segmentation in Urban Driving Scenes: A Comparative Study](https://arxiv.org/abs/2508.11301)
*Jiarong Li,Imad Ali Shah,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

Relevance: 20.0

TL;DR: 研究探讨了高光谱成像（HSI）在行人分割中的优势，通过对比RGB和两种降维方法（PCA和CSNR-JMIM），发现CSNR-JMIM显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决RGB成像中行人与背景视觉难以区分的问题，提升自动驾驶系统的安全性。

Method: 使用H-City数据集，比较RGB与两种HSI降维方法（PCA和CSNR-JMIM），并评估三种语义分割模型（U-Net、DeepLabV3+、SegFormer）。

Result: CSNR-JMIM在行人和骑行者分割中均优于RGB，IoU和F1-score分别提升1.44%和2.18%。

Conclusion: 优化HSI波段选择可显著提升行人分割性能，对安全关键型自动驾驶应用具有潜力。

Abstract: Pedestrian segmentation in automotive perception systems faces critical
safety challenges due to metamerism in RGB imaging, where pedestrians and
backgrounds appear visually indistinguishable.. This study investigates the
potential of hyperspectral imaging (HSI) for enhanced pedestrian segmentation
in urban driving scenarios using the Hyperspectral City v2 (H-City) dataset. We
compared standard RGB against two dimensionality-reduction approaches by
converting 128-channel HSI data into three-channel representations: Principal
Component Analysis (PCA) and optimal band selection using Contrast
Signal-to-Noise Ratio with Joint Mutual Information Maximization (CSNR-JMIM).
Three semantic segmentation models were evaluated: U-Net, DeepLabV3+, and
SegFormer. CSNR-JMIM consistently outperformed RGB with an average improvements
of 1.44% in Intersection over Union (IoU) and 2.18% in F1-score for pedestrian
segmentation. Rider segmentation showed similar gains with 1.43% IoU and 2.25%
F1-score improvements. These improved performance results from enhanced
spectral discrimination of optimally selected HSI bands effectively reducing
false positives. This study demonstrates robust pedestrian segmentation through
optimal HSI band selection, showing significant potential for safety-critical
automotive applications.

</details>


### [150] [TrajSV: A Trajectory-based Model for Sports Video Representations and Applications](https://arxiv.org/abs/2508.11569)
*Zheng Wang,Shihao Xu,Wei Shi*

Main category: cs.CV

Relevance: 20.0

TL;DR: TrajSV是一个基于轨迹的框架，用于解决体育视频分析中的数据不足、缺乏有效框架和标签不足的问题，通过三个模块（数据预处理、CRNet、VRNet）和对比损失优化，在体育视频检索、动作识别和视频字幕任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 体育分析领域存在数据不足、缺乏有效框架和标签不足的问题，TrajSV旨在通过轨迹增强的Transformer和无监督学习解决这些问题。

Method: TrajSV包括数据预处理、Clip Representation Network (CRNet)和Video Representation Network (VRNet)，采用轨迹增强的Transformer和对比损失优化。

Result: 在体育视频检索、动作识别和视频字幕任务中，TrajSV表现优异，检索性能提升70%，动作识别在9/17类别中领先，字幕性能提升20%。

Conclusion: TrajSV通过轨迹增强和无监督学习有效解决了体育视频分析中的关键问题，并在多个任务中实现了SOTA性能。

Abstract: Sports analytics has received significant attention from both academia and
industry in recent years. Despite the growing interest and efforts in this
field, several issues remain unresolved, including (1) data unavailability, (2)
lack of an effective trajectory-based framework, and (3) requirement for
sufficient supervision labels. In this paper, we present TrajSV, a
trajectory-based framework that addresses various issues in existing studies.
TrajSV comprises three components: data preprocessing, Clip Representation
Network (CRNet), and Video Representation Network (VRNet). The data
preprocessing module extracts player and ball trajectories from sports
broadcast videos. CRNet utilizes a trajectory-enhanced Transformer module to
learn clip representations based on these trajectories. Additionally, VRNet
learns video representations by aggregating clip representations and visual
features with an encoder-decoder architecture. Finally, a triple contrastive
loss is introduced to optimize both video and clip representations in an
unsupervised manner. The experiments are conducted on three broadcast video
datasets to verify the effectiveness of TrajSV for three types of sports (i.e.,
soccer, basketball, and volleyball) with three downstream applications (i.e.,
sports video retrieval, action spotting, and video captioning). The results
demonstrate that TrajSV achieves state-of-the-art performance in sports video
retrieval, showcasing a nearly 70% improvement. It outperforms baselines in
action spotting, achieving state-of-the-art results in 9 out of 17 action
categories, and demonstrates a nearly 20% improvement in video captioning.
Additionally, we introduce a deployed system along with the three applications
based on TrajSV.

</details>


### [151] [Subcortical Masks Generation in CT Images via Ensemble-Based Cross-Domain Label Transfer](https://arxiv.org/abs/2508.11450)
*Augustine X. W. Lee,Pak-Hei Yeung,Jagath C. Rajapakse*

Main category: eess.IV

Relevance: 20.0

TL;DR: 该论文提出了一种自动集成框架，利用现有的MRI模型为CT扫描生成高质量的皮层下分割标签，填补了CT数据标注的空白。


<details>
  <summary>Details</summary>
Motivation: 解决CT扫描中皮层下分割标注数据不足的问题，促进脑部解剖研究和计算机辅助诊断。

Method: 通过集成MRI模型并应用于未标注的MRI-CT配对数据，构建了一个全面的CT皮层下分割数据集。

Result: 实验表明该框架性能优越，生成的CT数据集训练的分割模型在相关任务中表现更佳。

Conclusion: 该研究填补了CT皮层下分割的开源空白，为未来研究提供了资源。

Abstract: Subcortical segmentation in neuroimages plays an important role in
understanding brain anatomy and facilitating computer-aided diagnosis of
traumatic brain injuries and neurodegenerative disorders. However, training
accurate automatic models requires large amounts of labelled data. Despite the
availability of publicly available subcortical segmentation datasets for
Magnetic Resonance Imaging (MRI), a significant gap exists for Computed
Tomography (CT). This paper proposes an automatic ensemble framework to
generate high-quality subcortical segmentation labels for CT scans by
leveraging existing MRI-based models. We introduce a robust ensembling pipeline
to integrate them and apply it to unannotated paired MRI-CT data, resulting in
a comprehensive CT subcortical segmentation dataset. Extensive experiments on
multiple public datasets demonstrate the superior performance of our proposed
framework. Furthermore, using our generated CT dataset, we train segmentation
models that achieve improved performance on related segmentation tasks. To
facilitate future research, we make our source code, generated dataset, and
trained models publicly available at
https://github.com/SCSE-Biomedical-Computing-Group/CT-Subcortical-Segmentation,
marking the first open-source release for CT subcortical segmentation to the
best of our knowledge.

</details>


### [152] [Deep Learning for Automated Identification of Vietnamese Timber Species: A Tool for Ecological Monitoring and Conservation](https://arxiv.org/abs/2508.10938)
*Tianyu Song,Van-Doan Duong,Thi-Phuong Le,Ton Viet Ta*

Main category: cs.CV

Relevance: 10.0

TL;DR: 论文探讨了深度学习在越南常见木材分类中的应用，比较了五种CNN架构，ShuffleNetV2表现最佳，平衡了性能与效率。


<details>
  <summary>Details</summary>
Motivation: 传统木材分类方法耗时且依赖专家知识，深度学习可提供自动化解决方案。

Method: 构建自定义图像数据集，评估五种CNN架构（ResNet50、EfficientNet、MobileViT、MobileNetV3、ShuffleNetV2）。

Result: ShuffleNetV2在20次独立运行中平均准确率达99.29%，F1分数99.35%。

Conclusion: 轻量级深度学习模型在资源受限环境中可实现高精度实时木材分类。

Abstract: Accurate identification of wood species plays a critical role in ecological
monitoring, biodiversity conservation, and sustainable forest management.
Traditional classification approaches relying on macroscopic and microscopic
inspection are labor-intensive and require expert knowledge. In this study, we
explore the application of deep learning to automate the classification of ten
wood species commonly found in Vietnam. A custom image dataset was constructed
from field-collected wood samples, and five state-of-the-art convolutional
neural network architectures--ResNet50, EfficientNet, MobileViT, MobileNetV3,
and ShuffleNetV2--were evaluated. Among these, ShuffleNetV2 achieved the best
balance between classification performance and computational efficiency, with
an average accuracy of 99.29\% and F1-score of 99.35\% over 20 independent
runs. These results demonstrate the potential of lightweight deep learning
models for real-time, high-accuracy species identification in
resource-constrained environments. Our work contributes to the growing field of
ecological informatics by providing scalable, image-based solutions for
automated wood classification and forest biodiversity assessment.

</details>


### [153] [Analysis of the Compaction Behavior of Textile Reinforcements in Low-Resolution In-Situ CT Scans via Machine-Learning and Descriptor-Based Methods](https://arxiv.org/abs/2508.10943)
*Christian Düreth,Jan Condé-Wolter,Marek Danczak,Karsten Tittmann,Jörn Jaschinski,Andreas Hornig,Maik Gude*

Main category: cs.CV

Relevance: 10.0

TL;DR: 该研究提出了一种基于低分辨率CT扫描的框架，用于量化纺织复合材料中的嵌套行为，并通过3D-UNet模型和空间分析提取关键几何特征。


<details>
  <summary>Details</summary>
Motivation: 理解纺织复合材料的多尺度结构对预测其机械性能至关重要，嵌套行为直接影响刚度、渗透性和损伤容限。

Method: 使用低分辨率CT扫描进行原位压实实验，利用3D-UNet模型进行语义分割，并通过两点相关函数分析空间结构。

Result: 模型分割性能良好（IoU为0.822，F1为0.902），提取的几何特征与显微图像验证结果一致。

Conclusion: 该方法为从工业CT数据中提取几何特征提供了可靠途径，并为逆向建模和结构分析奠定了基础。

Abstract: A detailed understanding of material structure across multiple scales is
essential for predictive modeling of textile-reinforced composites. Nesting --
characterized by the interlocking of adjacent fabric layers through local
interpenetration and misalignment of yarns -- plays a critical role in defining
mechanical properties such as stiffness, permeability, and damage tolerance.
This study presents a framework to quantify nesting behavior in dry textile
reinforcements under compaction using low-resolution computed tomography (CT).
In-situ compaction experiments were conducted on various stacking
configurations, with CT scans acquired at 20.22 $\mu$m per voxel resolution. A
tailored 3D{-}UNet enabled semantic segmentation of matrix, weft, and fill
phases across compaction stages corresponding to fiber volume contents of
50--60 %. The model achieved a minimum mean Intersection-over-Union of 0.822
and an $F1$ score of 0.902. Spatial structure was subsequently analyzed using
the two-point correlation function $S_2$, allowing for probabilistic extraction
of average layer thickness and nesting degree. The results show strong
agreement with micrograph-based validation. This methodology provides a robust
approach for extracting key geometrical features from industrially relevant CT
data and establishes a foundation for reverse modeling and descriptor-based
structural analysis of composite preforms.

</details>


### [154] [iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities](https://arxiv.org/abs/2508.10945)
*Rishi Raj Sahoo,Surbhi Saswati Mohanty,Subhankar Mishra*

Main category: cs.CV

Relevance: 10.0

TL;DR: 论文提出了一种名为iWatchRoad的端到端系统，用于自动检测道路坑洼并进行GPS标记和实时地图绘制。


<details>
  <summary>Details</summary>
Motivation: 道路坑洼对安全和车辆寿命构成威胁，尤其是在印度等道路维护不足的地区。

Method: 利用自标注数据集微调YOLO模型进行实时检测，结合OCR模块提取时间戳并与GPS同步，数据存储并通过OpenStreetMap可视化。

Result: 系统提高了检测准确性，并提供了政府兼容的输出用于道路维护规划。

Conclusion: iWatchRoad是一种成本效益高、硬件高效且可扩展的解决方案，适用于发展中国家的道路管理。

Abstract: Potholes on the roads are a serious hazard and maintenance burden. This poses
a significant threat to road safety and vehicle longevity, especially on the
diverse and under-maintained roads of India. In this paper, we present a
complete end-to-end system called iWatchRoad for automated pothole detection,
Global Positioning System (GPS) tagging, and real time mapping using
OpenStreetMap (OSM). We curated a large, self-annotated dataset of over 7,000
frames captured across various road types, lighting conditions, and weather
scenarios unique to Indian environments, leveraging dashcam footage. This
dataset is used to fine-tune, Ultralytics You Only Look Once (YOLO) model to
perform real time pothole detection, while a custom Optical Character
Recognition (OCR) module was employed to extract timestamps directly from video
frames. The timestamps are synchronized with GPS logs to geotag each detected
potholes accurately. The processed data includes the potholes' details and
frames as metadata is stored in a database and visualized via a user friendly
web interface using OSM. iWatchRoad not only improves detection accuracy under
challenging conditions but also provides government compatible outputs for road
assessment and maintenance planning through the metadata visible on the
website. Our solution is cost effective, hardware efficient, and scalable,
offering a practical tool for urban and rural road management in developing
regions, making the system automated. iWatchRoad is available at
https://smlab.niser.ac.in/project/iwatchroad

</details>


### [155] [Data-Driven Abdominal Phenotypes of Type 2 Diabetes in Lean, Overweight, and Obese Cohorts](https://arxiv.org/abs/2508.11063)
*Lucas W. Remedios,Chloe Choe,Trent M. Schwartz,Dingjie Su,Gaurav Rudravaram,Chenyu Gao,Aravind R. Krishnan,Adam M. Saunders,Michael E. Kim,Shunxing Bao,Alvin C. Powers,Bennett A. Landman,John Virostko*

Main category: cs.CV

Relevance: 10.0

TL;DR: 该研究利用AI从3D临床影像中提取腹部结构特征，通过随机森林和SHAP分析，发现不同体重组中2型糖尿病的共同腹部特征。


<details>
  <summary>Details</summary>
Motivation: 尽管BMI是2型糖尿病的已知风险因素，但瘦人和肥胖人群中疾病表现的差异表明，详细的身体组成可能揭示腹部表型。AI技术为大规模分析提供了可能。

Method: 研究对1,728名受试者的腹部CT扫描进行分段，使用随机森林分类和SHAP分析，识别与2型糖尿病相关的特征。

Result: 随机森林的AUC为0.72-0.74，发现脂肪肌肉、内脏脂肪和胰腺特征等共同预测因子。

Conclusion: 腹部特征可能是跨体重组的2型糖尿病一致驱动因素。

Abstract: Purpose: Although elevated BMI is a well-known risk factor for type 2
diabetes, the disease's presence in some lean adults and absence in others with
obesity suggests that detailed body composition may uncover abdominal
phenotypes of type 2 diabetes. With AI, we can now extract detailed
measurements of size, shape, and fat content from abdominal structures in 3D
clinical imaging at scale. This creates an opportunity to empirically define
body composition signatures linked to type 2 diabetes risk and protection using
large-scale clinical data. Approach: To uncover BMI-specific diabetic abdominal
patterns from clinical CT, we applied our design four times: once on the full
cohort (n = 1,728) and once on lean (n = 497), overweight (n = 611), and obese
(n = 620) subgroups separately. Briefly, our experimental design transforms
abdominal scans into collections of explainable measurements through
segmentation, classifies type 2 diabetes through a cross-validated random
forest, measures how features contribute to model-estimated risk or protection
through SHAP analysis, groups scans by shared model decision patterns
(clustering from SHAP) and links back to anatomical differences
(classification). Results: The random-forests achieved mean AUCs of 0.72-0.74.
There were shared type 2 diabetes signatures in each group; fatty skeletal
muscle, older age, greater visceral and subcutaneous fat, and a smaller or
fat-laden pancreas. Univariate logistic regression confirmed the direction of
14-18 of the top 20 predictors within each subgroup (p < 0.05). Conclusions:
Our findings suggest that abdominal drivers of type 2 diabetes may be
consistent across weight classes.

</details>


### [156] [UWB-PostureGuard: A Privacy-Preserving RF Sensing System for Continuous Ergonomic Sitting Posture Monitoring](https://arxiv.org/abs/2508.11115)
*Haotang Li,Zhenyu Qi,Sen He,Kebin Peng,Sheng Tan,Yili Ren,Tomas Cerny,Jiyue Zhao,Zi Wang*

Main category: cs.CV

Relevance: 10.0

TL;DR: 论文提出了一种基于超宽带（UWB）的隐私保护坐姿监测系统UWB-PostureGuard，通过特征工程和PoseGBDT模型实现高精度监测。


<details>
  <summary>Details</summary>
Motivation: 解决传统坐姿监测方法在隐私和舒适性上的问题，提供一种无接触、隐私保护的解决方案。

Method: 利用商用UWB设备提取坐姿特征，开发PoseGBDT模型捕捉时间依赖性。

Result: 在10名参与者和19种姿势的实验中，系统达到99.11%的准确率，且对环境变量具有鲁棒性。

Conclusion: UWB-PostureGuard是一种低成本、可扩展的隐私保护移动健康解决方案。

Abstract: Improper sitting posture during prolonged computer use has become a
significant public health concern. Traditional posture monitoring solutions
face substantial barriers, including privacy concerns with camera-based systems
and user discomfort with wearable sensors. This paper presents
UWB-PostureGuard, a privacy-preserving ultra-wideband (UWB) sensing system that
advances mobile technologies for preventive health management through
continuous, contactless monitoring of ergonomic sitting posture. Our system
leverages commercial UWB devices, utilizing comprehensive feature engineering
to extract multiple ergonomic sitting posture features. We develop PoseGBDT to
effectively capture temporal dependencies in posture patterns, addressing
limitations of traditional frame-wise classification approaches. Extensive
real-world evaluation across 10 participants and 19 distinct postures
demonstrates exceptional performance, achieving 99.11% accuracy while
maintaining robustness against environmental variables such as clothing
thickness, additional devices, and furniture configurations. Our system
provides a scalable, privacy-preserving mobile health solution on existing
platforms for proactive ergonomic management, improving quality of life at low
costs.

</details>


### [157] [DashCam Video: A complementary low-cost data stream for on-demand forest-infrastructure system monitoring](https://arxiv.org/abs/2508.11591)
*Durga Joshi,Chandi Witharana,Robert Fahey,Thomas Worthley,Zhe Zhu,Diego Cerrai*

Main category: cs.CV

Relevance: 10.0

TL;DR: 提出了一种低成本、可重复的框架，利用车载摄像头数据进行实时物体级结构评估和地理定位。


<details>
  <summary>Details</summary>
Motivation: 为城市植被和基础设施提供快速、实时且经济的监测方案，补充传统遥感方法。

Method: 结合单目深度估计、深度误差校正和几何三角测量，生成精确的空间和结构数据。

Result: 深度校正模型表现优异（R2=0.92，MAE=0.31），地理定位误差为2.83米，高度估计误差为2.09米（树木）和0.88米（杆）。

Conclusion: 该框架为城市规划和公用事业公司提供了可扩展且频繁的评估工具。

Abstract: Our study introduces a novel, low-cost, and reproducible framework for
real-time, object-level structural assessment and geolocation of roadside
vegetation and infrastructure with commonly available but underutilized
dashboard camera (dashcam) video data. We developed an end-to-end pipeline that
combines monocular depth estimation, depth error correction, and geometric
triangulation to generate accurate spatial and structural data from
street-level video streams from vehicle-mounted dashcams. Depth maps were first
estimated using a state-of-the-art monocular depth model, then refined via a
gradient-boosted regression framework to correct underestimations, particularly
for distant objects. The depth correction model achieved strong predictive
performance (R2 = 0.92, MAE = 0.31 on transformed scale), significantly
reducing bias beyond 15 m. Further, object locations were estimated using
GPS-based triangulation, while object heights were calculated using pin hole
camera geometry. Our method was evaluated under varying conditions of camera
placement and vehicle speed. Low-speed vehicle with inside camera gave the
highest accuracy, with mean geolocation error of 2.83 m, and mean absolute
error (MAE) in height estimation of 2.09 m for trees and 0.88 m for poles. To
the best of our knowledge, it is the first framework to combine monocular depth
modeling, triangulated GPS-based geolocation, and real-time structural
assessment for urban vegetation and infrastructure using consumer-grade video
data. Our approach complements conventional RS methods, such as LiDAR and image
by offering a fast, real-time, and cost-effective solution for object-level
monitoring of vegetation risks and infrastructure exposure, making it
especially valuable for utility companies, and urban planners aiming for
scalable and frequent assessments in dynamic urban environments.

</details>


### [158] [The Role of Radiographic Knee Alignment in Knee Replacement Outcomes and Opportunities for Artificial Intelligence-Driven Assessment](https://arxiv.org/abs/2508.10941)
*Zhisen Hu,David S. Johnson,Aleksei Tiulpin,Timothy F. Cootes,Claudia Lindner*

Main category: eess.IV

Relevance: 10.0

TL;DR: 该论文综述了膝关节置换术（TKR）结果与膝关节对齐生物标志物的关系，并探讨了AI在膝关节X光片分析中的应用。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎（OA）的治疗需求迫切，但TKR的术后结果难以预测。研究旨在探索膝关节对齐生物标志物及其AI分析方法，以改善TKR结果预测。

Method: 综述现有TKR结果评分协议和膝关节对齐生物标志物，分析AI在膝关节X光片中对齐测量的应用。

Result: 总结了膝关节对齐生物标志物与TKR结果的关系，并指出AI在自动化对齐测量中的潜力。

Conclusion: AI在膝关节对齐分析中有广阔前景，未来可进一步优化TKR结果预测。

Abstract: Prevalent knee osteoarthritis (OA) imposes substantial burden on health
systems with no cure available. Its ultimate treatment is total knee
replacement (TKR). Complications from surgery and recovery are difficult to
predict in advance, and numerous factors may affect them. Radiographic knee
alignment is one of the key factors that impacts TKR outcomes, affecting
outcomes such as postoperative pain or function. Recently, artificial
intelligence (AI) has been introduced to the automatic analysis of knee
radiographs, for example, to automate knee alignment measurements. Existing
review articles tend to focus on knee OA diagnosis and segmentation of bones or
cartilages in MRI rather than exploring knee alignment biomarkers for TKR
outcomes and their assessment. In this review, we first examine the current
scoring protocols for evaluating TKR outcomes and potential knee alignment
biomarkers associated with these outcomes. We then discuss existing AI-based
approaches for generating knee alignment biomarkers from knee radiographs, and
explore future directions for knee alignment assessment and TKR outcome
prediction.

</details>


### [159] [Fluid Dynamics and Domain Reconstruction from Noisy Flow Images Using Physics-Informed Neural Networks and Quasi-Conformal Mapping](https://arxiv.org/abs/2508.11216)
*Han Zhang,Xue-Cheng Tai,Jean-Michel Morel,Raymond H. Chan*

Main category: math.NA

Relevance: 10.0

TL;DR: 该论文提出了一种基于物理信息神经网络和准共形映射的优化方法，用于去噪血流图像，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 血流成像在医学诊断中至关重要，但高质量图像获取困难。本文旨在解决由短采集时间或设备误差引起的图像噪声问题。

Method: 将任务建模为优化问题，分解为流体子问题和几何子问题，分别用物理信息神经网络和准共形映射求解，交替优化。

Result: 实验表明，该方法在合成和真实血流数据上均能有效去噪，且对关键超参数具有鲁棒性。

Conclusion: 该方法为血流图像去噪提供了一种高效且可靠的解决方案。

Abstract: Blood flow imaging provides important information for hemodynamic behavior
within the vascular system and plays an essential role in medical diagnosis and
treatment planning. However, obtaining high-quality flow images remains a
significant challenge. In this work, we address the problem of denoising flow
images that may suffer from artifacts due to short acquisition times or
device-induced errors. We formulate this task as an optimization problem, where
the objective is to minimize the discrepancy between the modeled velocity
field, constrained to satisfy the Navier-Stokes equations, and the observed
noisy velocity data. To solve this problem, we decompose it into two
subproblems: a fluid subproblem and a geometry subproblem. The fluid subproblem
leverages a Physics-Informed Neural Network to reconstruct the velocity field
from noisy observations, assuming a fixed domain. The geometry subproblem aims
to infer the underlying flow region by optimizing a quasi-conformal mapping
that deforms a reference domain. These two subproblems are solved in an
alternating Gauss-Seidel fashion, iteratively refining both the velocity field
and the domain. Upon convergence, the framework yields a high-quality
reconstruction of the flow image. We validate the proposed method through
experiments on synthetic flow data in a converging channel geometry under
varying levels of Gaussian noise, and on real-like flow data in an aortic
geometry with signal-dependent noise. The results demonstrate the effectiveness
and robustness of the approach. Additionally, ablation studies are conducted to
assess the influence of key hyperparameters.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [160] [ADMIRE-BayesOpt: Accelerated Data MIxture RE-weighting for Language Models with Bayesian Optimization](https://arxiv.org/abs/2508.11551)
*Shengzhuang Chen,Xu Ouyang,Michael Arthur Leopold Pearce,Thomas Hartvigsen,Jonathan Richard Schwarz*

Main category: stat.ML

Relevance: 90.0

TL;DR: 提出一种基于贝叶斯优化的方法，用于优化大型语言模型训练中的数据混合比例，显著提升性能并减少实验成本。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型训练中数据混合比例的确定依赖启发式方法，缺乏可靠的学习方法，影响性能。

Method: 将数据混合选择视为黑盒超参数优化问题，采用多保真贝叶斯优化平衡实验成本与模型性能。

Result: 在1M到7B参数的模型上验证，性能提升显著，实验成本降低500%。

Conclusion: 该方法为数据混合优化提供了高效框架，并公开数据集支持进一步研究。

Abstract: Determining the optimal data mixture for large language model training
remains a challenging problem with an outsized impact on performance. In
practice, language model developers continue to rely on heuristic exploration
since no learning-based approach has emerged as a reliable solution. In this
work, we propose to view the selection of training data mixtures as a black-box
hyperparameter optimization problem, for which Bayesian Optimization is a
well-established class of appropriate algorithms. Firstly, we cast data mixture
learning as a sequential decision-making problem, in which we aim to find a
suitable trade-off between the computational cost of training exploratory
(proxy-) models and final mixture performance. Secondly, we systematically
explore the properties of transferring mixtures learned at a small scale to
larger-scale experiments, providing insights and highlighting opportunities for
research at a modest scale. By proposing Multi-fidelity Bayesian Optimization
as a suitable method in this common scenario, we introduce a natural framework
to balance experiment cost with model fit, avoiding the risks of overfitting to
smaller scales while minimizing the number of experiments at high cost. We
present results for pre-training and instruction finetuning across models
ranging from 1 million to 7 billion parameters, varying from simple
architectures to state-of-the-art models and benchmarks spanning dozens of
datasets. We demonstrate consistently strong results relative to a wide range
of benchmarks, showingspeed-ups of over 500% in determining the best data
mixture on our largest experiments relative to recent baselines. In addition,
we broaden access to research by sharing ADMIRE IFT Runs, a dataset of 460 full
training & evaluation runs across various model sizes worth over 13,000 GPU
hours, greatly reducing the cost of conducting research in this area.

</details>


### [161] [Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps](https://arxiv.org/abs/2508.11452)
*Kangyu Wang,Hongliang He,Lin Liu,Ruiqi Liang,Zhenzhong Lan,Jianguo Li*

Main category: cs.AI

Relevance: 85.0

TL;DR: Inclusion Arena是一个实时排行榜，通过从AI应用中收集的人类反馈对模型进行排名，解决了现有基准测试在反映实际应用性能上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试依赖静态数据集或通用领域提示，难以反映模型在真实应用中的表现，因此需要一种更贴近实际使用场景的评估方法。

Method: 平台通过自然用户交互中的成对模型比较收集反馈，并采用改进的Bradley-Terry模型（包含Placement Matches和Proximity Sampling）进行排名。

Result: 实证分析表明，Inclusion Arena提供可靠且稳定的排名，数据传递性优于通用众包数据集，并能有效减少恶意操纵风险。

Conclusion: Inclusion Arena通过连接基础模型和实际应用，加速了面向用户部署优化的LLM和MLLM发展。

Abstract: Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)
have ushered in a new era of AI capabilities, demonstrating near-human-level
performance across diverse scenarios. While numerous benchmarks (e.g., MMLU)
and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the
development of LLMs and MLLMs, most rely on static datasets or crowdsourced
general-domain prompts, often falling short of reflecting performance in
real-world applications. To bridge this critical gap, we present Inclusion
Arena, a live leaderboard that ranks models based on human feedback collected
directly from AI-powered applications. Our platform integrates pairwise model
comparisons into natural user interactions, ensuring evaluations reflect
practical usage scenarios. For robust model ranking, we employ the
Bradley-Terry model augmented with two key innovations: (1) Placement Matches,
a cold-start mechanism to quickly estimate initial ratings for newly integrated
models, and (2) Proximity Sampling, an intelligent comparison strategy that
prioritizes battles between models of similar capabilities to maximize
information gain and enhance rating stability. Extensive empirical analyses and
simulations demonstrate that Inclusion Arena yields reliable and stable
rankings, exhibits higher data transitivity compared to general crowdsourced
datasets, and significantly mitigates the risk of malicious manipulation. By
fostering an open alliance between foundation models and real-world
applications, Inclusion Arena aims to accelerate the development of LLMs and
MLLMs truly optimized for practical, user-centric deployments. The platform is
publicly accessible at https://doraemon.alipay.com/model-ranking.

</details>


### [162] [MCP-Guard: A Defense Framework for Model Context Protocol Integrity in Large Language Model Applications](https://arxiv.org/abs/2508.10991)
*Wenpeng Xing,Zhonghao Qi,Yupeng Qin,Yilin Li,Caini Chang,Jiahui Yu,Changting Lin,Zhenzhen Xie,Meng Han*

Main category: cs.CR

Relevance: 85.0

TL;DR: 论文提出MCP-Guard，一种针对LLM与外部工具交互的安全防御架构，通过三阶段检测管道和MCP-AttackBench基准测试，有效识别并防御安全威胁。


<details>
  <summary>Details</summary>
Motivation: LLM与外部工具集成时存在安全漏洞（如提示注入、数据泄露），需要一种高效且准确的防御机制。

Method: 提出MCP-Guard，包含轻量级静态扫描、深度神经网络检测和微调E5模型的三阶段检测管道，以及轻量级LLM仲裁器。

Result: MCP-Guard在识别对抗性提示时达到96.01%的准确率，并引入包含70,000样本的MCP-AttackBench基准测试。

Conclusion: MCP-Guard为LLM-工具生态系统提供了有效的安全防御方案，并为未来研究奠定了基础。

Abstract: The integration of Large Language Models (LLMs) with external tools via
protocols such as the Model Context Protocol (MCP) introduces critical security
vulnerabilities, including prompt injection, data exfiltration, and other
threats. To counter these challenges, we propose MCP-Guard, a robust, layered
defense architecture designed for LLM--tool interactions. MCP-Guard employs a
three-stage detection pipeline that balances efficiency with accuracy: it
progresses from lightweight static scanning for overt threats and a deep neural
detector for semantic attacks, to our fine-tuned E5-based model achieves
(96.01) accuracy in identifying adversarial prompts. Finally, a lightweight LLM
arbitrator synthesizes these signals to deliver the final decision while
minimizing false positives. To facilitate rigorous training and evaluation, we
also introduce MCP-AttackBench, a comprehensive benchmark of over 70,000
samples. Sourced from public datasets and augmented by GPT-4, MCP-AttackBench
simulates diverse, real-world attack vectors in the MCP format, providing a
foundation for future research into securing LLM-tool ecosystems.

</details>


### [163] [Note on Selection Bias in Observational Estimates of Algorithmic Progress](https://arxiv.org/abs/2508.11033)
*Parker Whitfill*

Main category: econ.GN

Relevance: 85.0

TL;DR: 论文探讨了语言模型算法效率随时间提升的现象，但指出其估计方法可能存在内生性问题。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型算法效率随时间的变化，揭示技术进步的趋势。

Method: 通过收集语言模型的损失和计算数据，分析算法效率的提升。

Result: 发现语言模型在固定计算量下损失随时间下降，但估计方法可能存在偏差。

Conclusion: 算法效率的提升可能被高估，需考虑计算选择的内生性影响。

Abstract: Ho et. al (2024) is an interesting paper that attempts to estimate the degree
of algorithmic progress from language models. They collect observational data
on language models' loss and compute over time, and argue that as time has
passed, language models' algorithmic efficiency has been rising. That is, the
loss achieved for fixed compute has been dropping over time. In this note, I
want to raise one potential methodological problem with the estimation
strategy. Intuitively, if part of algorithmic quality is latent, and compute
choices are endogenous to algorithmic quality, then resulting estimates of
algorithmic quality will be biased.

</details>


### [164] [ORFuzz: Fuzzing the "Other Side" of LLM Safety -- Testing Over-Refusal](https://arxiv.org/abs/2508.11222)
*Haonan Zhang,Dongxia Wang,Yi Liu,Kexin Chen,Jiashui Wang,Xinlei Ying,Long Liu,Wenhai Wang*

Main category: cs.SE

Relevance: 85.0

TL;DR: 论文提出ORFuzz框架，用于检测和分析LLM的过度拒绝行为，通过进化测试生成多样化测试用例，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLM的过度拒绝行为（错误拒绝良性查询）影响其可靠性和可用性，现有测试方法不足。

Method: ORFuzz框架整合安全类别种子选择、自适应变异优化和人类对齐的评判模型OR-Judge。

Result: ORFuzz生成测试用例的过度拒绝率（6.98%）是现有基准的两倍，并创建了ORFuzzSet新基准（63.56%拒绝率）。

Conclusion: ORFuzz为LLM的可靠性和可信性提供了自动化测试框架和社区资源。

Abstract: Large Language Models (LLMs) increasingly exhibit over-refusal - erroneously
rejecting benign queries due to overly conservative safety measures - a
critical functional flaw that undermines their reliability and usability.
Current methods for testing this behavior are demonstrably inadequate,
suffering from flawed benchmarks and limited test generation capabilities, as
highlighted by our empirical user study. To the best of our knowledge, this
paper introduces the first evolutionary testing framework, ORFuzz, for the
systematic detection and analysis of LLM over-refusals. ORFuzz uniquely
integrates three core components: (1) safety category-aware seed selection for
comprehensive test coverage, (2) adaptive mutator optimization using reasoning
LLMs to generate effective test cases, and (3) OR-Judge, a human-aligned judge
model validated to accurately reflect user perception of toxicity and refusal.
Our extensive evaluations demonstrate that ORFuzz generates diverse, validated
over-refusal instances at a rate (6.98% average) more than double that of
leading baselines, effectively uncovering vulnerabilities. Furthermore,
ORFuzz's outputs form the basis of ORFuzzSet, a new benchmark of 1,855 highly
transferable test cases that achieves a superior 63.56% average over-refusal
rate across 10 diverse LLMs, significantly outperforming existing datasets.
ORFuzz and ORFuzzSet provide a robust automated testing framework and a
valuable community resource, paving the way for developing more reliable and
trustworthy LLM-based software systems.

</details>


### [165] [Hallucination in LLM-Based Code Generation: An Automotive Case Study](https://arxiv.org/abs/2508.11257)
*Marc Pavel,Nenad Petrovic,Lukasz Mazur,Vahid Zolfaghari,Fengjunjie Pan,Alois Knoll*

Main category: cs.SE

Relevance: 85.0

TL;DR: 论文研究了代码生成中LLM的幻觉问题，特别是在汽车领域，评估了多种提示策略下模型的性能，发现复杂提示能提升准确性，但仍需解决语法错误和知识冲突问题。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在代码生成中的幻觉现象，尤其是在安全关键的汽车领域，以提升其可靠性和实用性。

Method: 通过案例研究，评估了GPT-4.1、Codex和GPT-4o在不同复杂度提示下的表现，包括语法错误、无效引用和API知识冲突。

Result: 复杂提示（如包含VSS规范和代码骨架）下，GPT-4.1和GPT-4o表现最佳，但其他模型和简单提示仍存在显著问题。

Conclusion: 需开发有效的缓解技术以确保LLM生成代码的安全性和可靠性，尤其是在安全关键领域。

Abstract: Large Language Models (LLMs) have shown significant potential in automating
code generation tasks offering new opportunities across software engineering
domains. However, their practical application remains limited due to
hallucinations - outputs that appear plausible but are factually incorrect,
unverifiable or nonsensical. This paper investigates hallucination phenomena in
the context of code generation with a specific focus on the automotive domain.
A case study is presented that evaluates multiple code LLMs for three different
prompting complexities ranging from a minimal one-liner prompt to a prompt with
Covesa Vehicle Signal Specifications (VSS) as additional context and finally to
a prompt with an additional code skeleton. The evaluation reveals a high
frequency of syntax violations, invalid reference errors and API knowledge
conflicts in state-of-the-art models GPT-4.1, Codex and GPT-4o. Among the
evaluated models, only GPT-4.1 and GPT-4o were able to produce a correct
solution when given the most context-rich prompt. Simpler prompting strategies
failed to yield a working result, even after multiple refinement iterations.
These findings highlight the need for effective mitigation techniques to ensure
the safe and reliable use of LLM generated code, especially in safety-critical
domains such as automotive software systems.

</details>


### [166] [AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager](https://arxiv.org/abs/2508.11416)
*Xuhua Zhao,Yuxuan Xie,Caihua Chen,Yuxiang Sun*

Main category: cs.AI

Relevance: 75.0

TL;DR: 论文提出AIM-Bench，用于评估LLM代理在不确定供应链管理中的决策行为，发现LLM存在类似人类的决策偏差，并探讨了缓解策略。


<details>
  <summary>Details</summary>
Motivation: 研究LLM代理在不确定环境下库存决策的能力及其潜在偏差，填补了LLM在供应链管理中决策行为研究的空白。

Method: 通过AIM-Bench基准测试，设计多样化的库存补充实验，评估不同LLM的决策行为，并探索缓解偏差的策略（如认知反思和信息共享）。

Result: 不同LLM表现出类似人类的决策偏差，如“拉向中心效应”和“牛鞭效应”，并验证了认知反思和信息共享的缓解效果。

Conclusion: LLM在库存决策中存在偏差，需谨慎部署；研究为减少人类决策偏差和开发人本决策支持系统提供了方向。

Abstract: Recent advances in mathematical reasoning and the long-term planning
capabilities of large language models (LLMs) have precipitated the development
of agents, which are being increasingly leveraged in business operations
processes. Decision models to optimize inventory levels are one of the core
elements of operations management. However, the capabilities of the LLM agent
in making inventory decisions in uncertain contexts, as well as the
decision-making biases (e.g. framing effect, etc.) of the agent, remain largely
unexplored. This prompts concerns regarding the capacity of LLM agents to
effectively address real-world problems, as well as the potential implications
of biases that may be present. To address this gap, we introduce AIM-Bench, a
novel benchmark designed to assess the decision-making behaviour of LLM agents
in uncertain supply chain management scenarios through a diverse series of
inventory replenishment experiments. Our results reveal that different LLMs
typically exhibit varying degrees of decision bias that are similar to those
observed in human beings. In addition, we explored strategies to mitigate the
pull-to-centre effect and the bullwhip effect, namely cognitive reflection and
implementation of information sharing. These findings underscore the need for
careful consideration of the potential biases in deploying LLMs in Inventory
decision-making scenarios. We hope that these insights will pave the way for
mitigating human decision bias and developing human-centred decision support
systems for supply chains.

</details>


### [167] [Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models](https://arxiv.org/abs/2508.11524)
*Wenkai Yu,Jianhang Tang,Yang Zhang,Shanjiang Tang,Kebing Jin,Hankz Hankui Zhuo*

Main category: cs.AI

Relevance: 75.0

TL;DR: 提出了一种结合LLM与领域知识的新型规划器，通过问题分解和两种LLM范式（LLM4Inspire和LLM4Predict）优化大规模规划问题的搜索空间。


<details>
  <summary>Details</summary>
Motivation: 解决大规模规划问题中状态空间爆炸的挑战，并探索如何有效结合LLM与领域知识以生成有效计划。

Method: 将大问题分解为子任务，利用LLM4Inspire提供启发式指导，LLM4Predict利用领域知识推断中间条件。

Result: 实验证明LLM能有效修剪搜索空间并找到可行解，其中LLM4Predict（结合领域知识）表现优于LLM4Inspire（通用知识）。

Conclusion: 结合领域知识的LLM范式（如LLM4Predict）在大规模规划问题中更具潜力。

Abstract: Addressing large-scale planning problems has become one of the central
challenges in the planning community, deriving from the state-space explosion
caused by growing objects and actions. Recently, researchers have explored the
effectiveness of leveraging Large Language Models (LLMs) to generate helpful
actions and states to prune the search space. However, prior works have largely
overlooked integrating LLMs with domain-specific knowledge to ensure valid
plans. In this paper, we propose a novel LLM-assisted planner integrated with
problem decomposition, which first decomposes large planning problems into
multiple simpler sub-tasks. Then we explore two novel paradigms to utilize
LLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where
LLM4Inspire provides heuristic guidance according to general knowledge and
LLM4Predict employs domain-specific knowledge to infer intermediate conditions.
We empirically validate the effectiveness of our planner across multiple
domains, demonstrating the ability of search space partition when solving
large-scale planning problems. The experimental results show that LLMs
effectively locate feasible solutions when pruning the search space, where
infusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds
particular promise compared with LLM4Inspire, which offers general knowledge
within LLMs.

</details>


### [168] [Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward](https://arxiv.org/abs/2508.11143)
*Jiarui Yang,Bin Zhu,Jingjing Chen,Yu-Gang Jiang*

Main category: cs.RO

Relevance: 75.0

TL;DR: AC3（Actor-Critic for Continuous Chunks）是一种新型强化学习框架，专注于解决长时程机器人操纵任务中的稀疏奖励问题，通过稳定机制和高效数据利用提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在长时程机器人操纵任务中表现不佳，尤其是在稀疏奖励场景下。AC3旨在通过稳定且高效的方式学习连续动作块。

Method: AC3采用非对称更新规则训练actor（仅从成功轨迹学习），并通过n步回报和自监督模块稳定critic的更新。

Result: 在BiGym和RLBench的25个任务中，AC3仅需少量演示和简单架构即可实现更高的成功率。

Conclusion: AC3通过稳定机制和高效设计，显著提升了长时程机器人操纵任务的性能。

Abstract: Existing reinforcement learning (RL) methods struggle with long-horizon
robotic manipulation tasks, particularly those involving sparse rewards. While
action chunking is a promising paradigm for robotic manipulation, using RL to
directly learn continuous action chunks in a stable and data-efficient manner
remains a critical challenge. This paper introduces AC3 (Actor-Critic for
Continuous Chunks), a novel RL framework that learns to generate
high-dimensional, continuous action sequences. To make this learning process
stable and data-efficient, AC3 incorporates targeted stabilization mechanisms
for both the actor and the critic. First, to ensure reliable policy
improvement, the actor is trained with an asymmetric update rule, learning
exclusively from successful trajectories. Second, to enable effective value
learning despite sparse rewards, the critic's update is stabilized using
intra-chunk $n$-step returns and further enriched by a self-supervised module
providing intrinsic rewards at anchor points aligned with each action chunk. We
conducted extensive experiments on 25 tasks from the BiGym and RLBench
benchmarks. Results show that by using only a few demonstrations and a simple
model architecture, AC3 achieves superior success rates on most tasks,
validating its effective design.

</details>


### [169] [Role-Augmented Intent-Driven Generative Search Engine Optimization](https://arxiv.org/abs/2508.11158)
*Xiaolu Chen,Haojie Wu,Jie Bao,Zhen Chen,Yong Liao,Hu Huang*

Main category: cs.IR

Relevance: 75.0

TL;DR: 论文提出了一种针对生成式搜索引擎（GSEs）的优化方法（G-SEO），通过角色增强的意图驱动模型改进内容可见性，并扩展了评估数据集和评估标准。


<details>
  <summary>Details</summary>
Motivation: 传统搜索引擎优化（SEO）策略在生成式检索场景中失效，内容创作者面临可见性下降的挑战，需要新的优化方法。

Method: 提出Role-Augmented Intent-Driven G-SEO方法，通过多样化信息角色建模搜索意图，并扩展GEO数据集和引入G-Eval 2.0评估标准。

Result: 实验表明，搜索意图是有效的优化信号，显著提升了内容在GSE中的可见性和主观评价。

Conclusion: G-SEO方法为生成式搜索引擎提供了有效的优化路径，解决了传统SEO的局限性。

Abstract: Generative Search Engines (GSEs), powered by Large Language Models (LLMs) and
Retrieval-Augmented Generation (RAG), are reshaping information retrieval.
While commercial systems (e.g., BingChat, Perplexity.ai) demonstrate impressive
semantic synthesis capabilities, their black-box nature fundamentally
undermines established Search Engine Optimization (SEO) practices. Content
creators face a critical challenge: their optimization strategies, effective in
traditional search engines, are misaligned with generative retrieval contexts,
resulting in diminished visibility. To bridge this gap, we propose a
Role-Augmented Intent-Driven Generative Search Engine Optimization (G-SEO)
method, providing a structured optimization pathway tailored for GSE scenarios.
Our method models search intent through reflective refinement across diverse
informational roles, enabling targeted content enhancement. To better evaluate
the method under realistic settings, we address the benchmarking limitations of
prior work by: (1) extending the GEO dataset with diversified query variations
reflecting real-world search scenarios and (2) introducing G-Eval 2.0, a
6-level LLM-augmented evaluation rubric for fine-grained human-aligned
assessment. Experimental results demonstrate that search intent serves as an
effective signal for guiding content optimization, yielding significant
improvements over single-aspect baseline approaches in both subjective
impressions and objective content visibility within GSE responses.

</details>


### [170] [Is General-Purpose AI Reasoning Sensitive to Data-Induced Cognitive Biases? Dynamic Benchmarking on Typical Software Engineering Dilemmas](https://arxiv.org/abs/2508.11278)
*Francesco Sovrano,Gabriele Dominici,Rita Sevastjanova,Alessandra Stramiglio,Alberto Bacchelli*

Main category: cs.HC

Relevance: 75.0

TL;DR: 论文提出了首个动态基准框架，用于评估通用AI系统在软件工程工作流中表现出的认知偏见，发现主流AI系统存在依赖浅层语言启发式而非深度推理的倾向。


<details>
  <summary>Details</summary>
Motivation: 研究通用AI系统是否因训练数据中的人类认知偏见而表现出类似偏见，以揭示其在软件工程中的潜在风险。

Method: 开发动态基准框架，通过16个手工任务和AI生成的任务变体，测试AI系统对8种认知偏见的敏感性。

Result: 主流AI系统（如GPT、LLaMA、DeepSeek）均表现出认知偏见（5.9%至35%），且偏见敏感性随任务复杂度增加而显著上升（最高49%）。

Conclusion: 通用AI系统在软件工程中存在认知偏见风险，需进一步优化以提升深度推理能力。

Abstract: Human cognitive biases in software engineering can lead to costly errors.
While general-purpose AI (GPAI) systems may help mitigate these biases due to
their non-human nature, their training on human-generated data raises a
critical question: Do GPAI systems themselves exhibit cognitive biases?
  To investigate this, we present the first dynamic benchmarking framework to
evaluate data-induced cognitive biases in GPAI within software engineering
workflows. Starting with a seed set of 16 hand-crafted realistic tasks, each
featuring one of 8 cognitive biases (e.g., anchoring, framing) and
corresponding unbiased variants, we test whether bias-inducing linguistic cues
unrelated to task logic can lead GPAI systems from correct to incorrect
conclusions.
  To scale the benchmark and ensure realism, we develop an on-demand
augmentation pipeline relying on GPAI systems to generate task variants that
preserve bias-inducing cues while varying surface details. This pipeline
ensures correctness (88--99% on average, according to human evaluation),
promotes diversity, and controls reasoning complexity by leveraging
Prolog-based reasoning and LLM-as-a-judge validation. It also verifies that the
embedded biases are both harmful and undetectable by logic-based, unbiased
reasoners.
  We evaluate leading GPAI systems (GPT, LLaMA, DeepSeek) and find a consistent
tendency to rely on shallow linguistic heuristics over deep reasoning. All
systems exhibit cognitive biases (ranging from 5.9% to 35% across types), with
bias sensitivity increasing sharply with task complexity (up to 49%),
highlighting critical risks in real-world software engineering deployments.

</details>


### [171] [Trustworthy AI Psychotherapy: Multi-Agent LLM Workflow for Counseling and Explainable Mental Disorder Diagnosis](https://arxiv.org/abs/2508.11398)
*Mithat Can Ozgun,Jiahuan Pei,Koen Hindriks,Lucia Donatelli,Qingzhi Liu,Xin Sun,Junxiao Wang*

Main category: cs.HC

Relevance: 75.0

TL;DR: 提出了DSM5AgentFlow，一种基于LLM的代理工作流，用于生成DSM-5 Level-1诊断问卷，填补了心理健康诊断领域的空白。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在心理健康诊断等专业领域表现不佳，且缺乏多轮对话理解和专家临床推理对齐的能力。

Method: 通过模拟治疗师-客户对话生成诊断问卷，提供透明、逐步的预测结果。

Result: 评估了主流LLM在对话真实性、诊断准确性和可解释性三个维度的表现，数据集和实现开源。

Conclusion: DSM5AgentFlow可作为心理健康诊断的补充工具，符合伦理和法律标准。

Abstract: LLM-based agents have emerged as transformative tools capable of executing
complex tasks through iterative planning and action, achieving significant
advancements in understanding and addressing user needs. Yet, their
effectiveness remains limited in specialized domains such as mental health
diagnosis, where they underperform compared to general applications. Current
approaches to integrating diagnostic capabilities into LLMs rely on scarce,
highly sensitive mental health datasets, which are challenging to acquire.
These methods also fail to emulate clinicians' proactive inquiry skills, lack
multi-turn conversational comprehension, and struggle to align outputs with
expert clinical reasoning. To address these gaps, we propose DSM5AgentFlow, the
first LLM-based agent workflow designed to autonomously generate DSM-5 Level-1
diagnostic questionnaires. By simulating therapist-client dialogues with
specific client profiles, the framework delivers transparent, step-by-step
disorder predictions, producing explainable and trustworthy results. This
workflow serves as a complementary tool for mental health diagnosis, ensuring
adherence to ethical and legal standards. Through comprehensive experiments, we
evaluate leading LLMs across three critical dimensions: conversational realism,
diagnostic accuracy, and explainability. Our datasets and implementations are
fully open-sourced.

</details>


### [172] [Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information](https://arxiv.org/abs/2508.11252)
*Youcheng Huang,Bowen Qin,Chen Huang,Duanyu Feng,Xi Yang,Wenqiang Lei*

Main category: cs.AI

Relevance: 70.0

TL;DR: 论文提出了一种新数据集，评估大型推理模型（LRMs）在不完整问题上的表现，发现其缺乏主动询问信息的能力，并揭示了过思考和幻觉行为。


<details>
  <summary>Details</summary>
Motivation: 现有基准仅评估LRMs在定义明确问题上的表现，忽略了智能代理应具备的主动性和信息补充能力。

Method: 构建包含不完整问题的数据集，系统评估LRMs的表现，并分析其行为和监督微调的潜力。

Result: LRMs无法主动询问信息，存在过思考和幻觉问题，监督微调潜力与挑战并存。

Conclusion: 研究为开发真正智能的LRMs提供了新视角，强调需超越单纯问题解决能力。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable problem-solving
abilities in mathematics, as evaluated by existing benchmarks exclusively on
well-defined problems. However, such evaluation setup constitutes a critical
gap, since a genuine intelligent agent should not only solve problems (as a
math quiz solver), but also be able~to ask for information when the problems
lack sufficient information, enabling proactivity in responding users'
requests. To bridge such gap, we proposes a new dataset consisting of two types
of incomplete problems with diverse contexts. Based on the dataset, our
systematical evaluation of LRMs reveals their inability in proactively asking
for information. In addition, we uncover the behaviors related to overthinking
and hallucination of LRMs, and highlight the potential and challenges of
supervised fine-tuning in learning such ability. We hope to provide new
insights in developing LRMs with genuine intelligence, rather than just solving
problems.

</details>


### [173] [Diffusion is a code repair operator and generator](https://arxiv.org/abs/2508.11110)
*Mukul Singh,Gust Verbruggen,Vu Le,Sumit Gulwani*

Main category: cs.SE

Relevance: 70.0

TL;DR: 论文探讨了如何利用预训练的代码扩散模型进行代码的“最后一英里修复”，通过添加噪声或生成训练数据来优化修复效果。


<details>
  <summary>Details</summary>
Motivation: 研究动机是利用扩散模型在代码生成后期阶段的表现，模拟代码修复过程，从而提升代码修复任务的效率和效果。

Method: 方法包括两种应用：1) 向损坏的代码片段添加噪声并恢复扩散过程；2) 从扩散过程中采样生成训练数据。实验在Python、Excel和PowerShell三个领域进行。

Result: 实验结果表明，扩散模型可以有效用于代码修复任务，并能生成大量训练数据以支持更高效的任务实现。

Conclusion: 结论是扩散模型在代码修复任务中具有潜力，特别是在最后一英里修复场景中。

Abstract: Code diffusion models generate code by iteratively removing noise from the
latent representation of a code snippet. During later steps of the diffusion
process, when the code snippet has almost converged, differences between
discrete representations of these snippets look like last-mile repairs applied
to broken or incomplete code. We evaluate the extent to which this resemblance
can be exploited to leverage pre-trained code diffusion models for the problem
of last-mile repair by considering two applications with significant potential.
First, we can leverage the diffusion model for last-mile repair by adding noise
to a broken code snippet and resuming the diffusion process. Second, we can
leverage the diffusion model to generate arbitrary amount of training data for
last-mile repair tasks (that are computationally more efficient) by sampling an
intermediate program (input) and the final program (output) from the diffusion
process. We perform experiments on 3 domains (Python, Excel and PowerShell) to
evaluate applications, as well as analyze properties.

</details>


### [174] [AlphaAgents: Large Language Model based Multi-Agents for Equity Portfolio Constructions](https://arxiv.org/abs/2508.11152)
*Tianjiao Zhao,Jingrao Lyu,Stokes Jones,Harrison Garber,Stefano Pasquali,Dhagash Mehta*

Main category: q-fin.ST

Relevance: 70.0

TL;DR: 研究探讨了基于角色的多智能体系统在股票选择和投资组合管理中的应用，评估了其表现并分析了多智能体框架的优缺点。


<details>
  <summary>Details</summary>
Motivation: 利用LLMs的多智能体协作能力解决股票选择和投资组合管理中的复杂问题。

Method: 采用角色化多智能体系统，评估其在不同风险容忍度下的选股表现。

Result: 多智能体系统在股票选择中表现优于基准，但存在实际应用中的挑战。

Conclusion: 多智能体框架在金融领域具有潜力，但需解决实施中的限制。

Abstract: The field of artificial intelligence (AI) agents is evolving rapidly, driven
by the capabilities of Large Language Models (LLMs) to autonomously perform and
refine tasks with human-like efficiency and adaptability. In this context,
multi-agent collaboration has emerged as a promising approach, enabling
multiple AI agents to work together to solve complex challenges. This study
investigates the application of role-based multi-agent systems to support stock
selection in equity research and portfolio management. We present a
comprehensive analysis performed by a team of specialized agents and evaluate
their stock-picking performance against established benchmarks under varying
levels of risk tolerance. Furthermore, we examine the advantages and
limitations of employing multi-agent frameworks in equity analysis, offering
critical insights into their practical efficacy and implementation challenges.

</details>


### [175] [CSGO: Generalized Optimization for Cold Start in Wireless Collaborative Edge LLM Systems](https://arxiv.org/abs/2508.11287)
*Xuran Liu,Nan Xue,Rui Bao,Yaping Sun,Zhiyong Chen,Meixia Tao,Xiaodong Xu,Shuguang Cui*

Main category: cs.IT

Relevance: 70.0

TL;DR: 提出了一种延迟感知调度框架，通过重叠模型加载与计算和通信，减少边缘设备上大型语言模型推理的总延迟。


<details>
  <summary>Details</summary>
Motivation: 边缘设备资源有限，现有方法忽略了按需模型加载导致的冷启动延迟，影响了低延迟和隐私保护的AI服务部署。

Method: 设计了一个动态调整层分区和分配的框架，将模型加载与计算和通信重叠，并通过混合整数非线性规划和动态编程算法优化分区和设备分配。

Result: 实验表明，该方法显著降低了冷启动延迟。

Conclusion: 提出的框架有效减少了边缘设备上大型语言模型推理的延迟，提升了部署效率。

Abstract: While deploying large language models on edge devices promises low-latency
and privacy-preserving AI services, it is hindered by limited device resources.
Although pipeline parallelism facilitates distributed inference, existing
approaches often ignore the cold-start latency caused by on-demand model
loading. In this paper, we propose a latency-aware scheduling framework that
overlaps model loading with computation and communication to minimize total
inference latency. Based on device and model parameters, the framework
dynamically adjusts layer partitioning and allocation to effectively hide
loading time, thereby eliminating as many idle periods as possible. We
formulate the problem as a Mixed-Integer Non-Linear Program and design an
efficient dynamic programming algorithm to optimize model partitioning and
device assignment. Experimental results show that the proposed method
significantly reduces cold-start latency compared to baseline strategies.

</details>


### [176] [Dynamic Quality-Latency Aware Routing for LLM Inference in Wireless Edge-Device Networks](https://arxiv.org/abs/2508.11291)
*Rui Bao,Nan Xue,Yaping Sun,Zhiyong Chen*

Main category: cs.IT

Relevance: 70.0

TL;DR: 论文提出了一种动态路由框架，用于在移动设备和边缘服务器之间分配LLM推理任务，以平衡质量和延迟。


<details>
  <summary>Details</summary>
Motivation: 解决无线边缘设备环境中LLM部署时任务复杂性与资源分配不匹配的问题。

Method: 采用动态路由框架，结合BERT预测的语义分数和通信计算开销，支持单轮和多轮查询。

Result: 实验表明，框架在保持推理质量的同时，平均延迟降低5-15%，大模型调用减少10-20%。

Conclusion: 该框架有效解决了无线环境中LLM部署的延迟和资源问题。

Abstract: The integration of wireless communications and Large Language Models (LLMs)
is poised to unlock ubiquitous intelligent services, yet deploying them in
wireless edge-device collaborative environments presents a critical trade-off
between inference quality and end-to-end latency. A fundamental mismatch exists
between task complexity and resource allocation: offloading simple queries
invites prohibitive latency, while on-device models lack the capacity for
demanding computations. To address this challenge, we propose a dynamic,
quality-latency aware routing framework that orchestrates inference between a
lightweight model on the mobile device and a powerful model on the edge server.
Our framework employs two distinct cost models: for single-turn queries, it
fuses a BERT-predicted semantic score with communication and computation
overheads; for multi-turn dialogues, it further quantifies context-aware costs
arising from model switching and KV-cache management. While maintaining full
inference quality, extensive experiments demonstrate that our framework cuts
average response latency by 5-15% and reduces large model invocations by 10-20%
against competitive baselines on MMLU, GSM8K, and MT-Bench-101 benchmarks.

</details>


### [177] [CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks](https://arxiv.org/abs/2508.11360)
*Songqin Nong,Jingxuan Xu,Sheng Zhou,Jianfeng Chen,Xiaoxuan Tang,Tao Jiang,Wenhao Xu*

Main category: cs.AI

Relevance: 60.0

TL;DR: 论文提出CRAFT-GUI框架，通过课程学习和细粒度奖励设计，提升GUI环境中强化学习代理的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在GUI任务中忽视任务难度差异和奖励信号粗糙的问题，限制了代理的适应性和学习效率。

Method: 提出基于GRPO的课程学习框架CRAFT-GUI，结合规则和模型评估设计细粒度奖励函数。

Result: 在公开和内部基准测试中分别提升5.6%和10.3%，验证了方法的有效性。

Conclusion: 课程学习与强化学习的结合在GUI交互任务中具有显著优势。

Abstract: As autonomous agents become adept at understanding and interacting with
graphical user interface (GUI) environments, a new era of automated task
execution is emerging. Recent studies have demonstrated that Reinforcement
Learning (RL) can effectively enhance agents' performance in dynamic
interactive GUI environments. However, these methods face two key limitations:
(1) they overlook the significant variation in difficulty across different GUI
tasks by treating the entire training data as a uniform set, which hampers the
agent's ability to adapt its learning process; and (2) most approaches collapse
task-specific nuances into a single, coarse reward, leaving the agent with a
uniform signal that yields inefficient policy updates. To address these
limitations, we propose CRAFT-GUI, a curriculum learning framework based on
Group Relative Policy Optimization (GRPO) that explicitly accounts for the
varying difficulty across trajectories. To enable more fine-grained policy
optimization, we design a reward function that combines simple rule-based
signals with model-judged evaluation, providing richer and more nuanced
feedback during training. Experimental results demonstrate that our method
achieves significant improvements over previous state-of-the-art approaches,
outperforming them by 5.6% on public benchmarks Android Control and 10.3% on
our internal online benchmarks, respectively. These findings empirically
validate the effectiveness of integrating reinforcement learning with
curriculum learning in GUI interaction tasks.

</details>


### [178] [Human-AI collaboration or obedient and often clueless AI in instruct, serve, repeat dynamics?](https://arxiv.org/abs/2508.10919)
*Mohammed Saqr,Kamila Misiejuk,Sonsoles López-Pernas*

Main category: cs.HC

Relevance: 60.0

TL;DR: 研究探讨了人类与AI在解决复杂问题时的互动模式，发现当前LLM更倾向于指令遵循而非认知协作。


<details>
  <summary>Details</summary>
Motivation: 探索人类与AI在认知密集型任务中的协作动态，填补现有研究对协作演化和动态关注的不足。

Method: 通过定性编码、转移网络分析、序列分析、偏相关网络及频率比较（卡方检验和马赛克图）分析学生与AI的互动模式。

Result: 发现主导的指令模式，缺乏协同性；问题复杂度与成绩无显著相关性。

Conclusion: 当前LLM更擅长指令遵循而非认知协作，需设计更注重认知对齐的AI系统。

Abstract: While research on human-AI collaboration exists, it mainly examined language
learning and used traditional counting methods with little attention to
evolution and dynamics of collaboration on cognitively demanding tasks. This
study examines human-AI interactions while solving a complex problem.
Student-AI interactions were qualitatively coded and analyzed with transition
network analysis, sequence analysis and partial correlation networks as well as
comparison of frequencies using chi-square and Person-residual shaded Mosaic
plots to map interaction patterns, their evolution, and their relationship to
problem complexity and student performance. Findings reveal a dominant
Instructive pattern with interactions characterized by iterative ordering
rather than collaborative negotiation. Oftentimes, students engaged in long
threads that showed misalignment between their prompts and AI output that
exemplified a lack of synergy that challenges the prevailing assumptions about
LLMs as collaborative partners. We also found no significant correlations
between assignment complexity, prompt length, and student grades suggesting a
lack of cognitive depth, or effect of problem difficulty. Our study indicates
that the current LLMs, optimized for instruction-following rather than
cognitive partnership, compound their capability to act as cognitively
stimulating or aligned collaborators. Implications for designing AI systems
that prioritize cognitive alignment and collaboration are discussed.

</details>


### [179] [AI That Helps Us Help Each Other: A Proactive System for Scaffolding Mentor-Novice Collaboration in Entrepreneurship Coaching](https://arxiv.org/abs/2508.11052)
*Evey Jiaxin Huang,Matthew Easterday,Elizabeth Gerber*

Main category: cs.HC

Relevance: 60.0

TL;DR: 论文提出了一种结合领域特定认知模型与LLM的人机协作系统，用于支持创业者的元认知和导师辅导。


<details>
  <summary>Details</summary>
Motivation: 解决创业者在面对开放性问题时的元认知需求，以及导师时间有限的问题。

Method: 结合领域特定认知模型与LLM，生成诊断性问题并支持导师调整模型逻辑。

Result: 系统提升了新手的元认知能力，优化了导师的辅导策略，改善了会议质量，但也揭示了AI信任等问题。

Conclusion: 提出了支持元认知和人机协作的设计原则，适用于医疗、教育等领域。

Abstract: Entrepreneurship requires navigating open-ended, ill-defined problems:
identifying risks, challenging assumptions, and making strategic decisions
under deep uncertainty. Novice founders often struggle with these metacognitive
demands, while mentors face limited time and visibility to provide tailored
support. We present a human-AI coaching system that combines a domain-specific
cognitive model of entrepreneurial risk with a large language model (LLM) to
proactively scaffold both novice and mentor thinking. The system proactively
poses diagnostic questions that challenge novices' thinking and helps both
novices and mentors plan for more focused and emotionally attuned meetings.
Critically, mentors can inspect and modify the underlying cognitive model,
shaping the logic of the system to reflect their evolving needs. Through an
exploratory field deployment, we found that using the system supported novice
metacognition, helped mentors plan emotionally attuned strategies, and improved
meeting depth, intentionality, and focus--while also surfaced key tensions
around trust, misdiagnosis, and expectations of AI. We contribute design
principles for proactive AI systems that scaffold metacognition and human-human
collaboration in complex, ill-defined domains, offering implications for
similar domains like healthcare, education, and knowledge work.

</details>


### [180] [From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching](https://arxiv.org/abs/2508.11070)
*Zahra Khotanlou,Kate Larson,Amir-Hossein Karimi*

Main category: cs.AI

Relevance: 40.0

TL;DR: 论文提出了一种多主体算法追索框架，解决现实世界中多主体交互的资源分配问题，通过三层优化实现社会福利最大化。


<details>
  <summary>Details</summary>
Motivation: 现有算法追索研究多关注单主体场景，忽视了现实世界中多主体竞争资源的复杂性，因此需要扩展至多主体交互的框架。

Method: 将多主体追索建模为带权二分图匹配问题，通过三层优化（基础匹配、容量再分配、成本感知优化）实现社会福利最大化。

Result: 实验验证表明，该框架在多主体场景下能实现接近最优的社会福利，同时保持个体可操作性。

Conclusion: 研究将算法追索从个体推荐扩展到系统设计，为提升社会福利提供了可行路径。

Abstract: Decision makers are increasingly relying on machine learning in sensitive
situations. In such settings, algorithmic recourse aims to provide individuals
with actionable and minimally costly steps to reverse unfavorable AI-driven
decisions. While existing research predominantly focuses on single-individual
(i.e., seeker) and single-model (i.e., provider) scenarios, real-world
applications often involve multiple interacting stakeholders. Optimizing
outcomes for seekers under an individual welfare approach overlooks the
inherently multi-agent nature of real-world systems, where individuals interact
and compete for limited resources. To address this, we introduce a novel
framework for multi-agent algorithmic recourse that accounts for multiple
recourse seekers and recourse providers. We model this many-to-many interaction
as a capacitated weighted bipartite matching problem, where matches are guided
by both recourse cost and provider capacity. Edge weights, reflecting recourse
costs, are optimized for social welfare while quantifying the welfare gap
between individual welfare and this collectively feasible outcome. We propose a
three-layer optimization framework: (1) basic capacitated matching, (2) optimal
capacity redistribution to minimize the welfare gap, and (3) cost-aware
optimization balancing welfare maximization with capacity adjustment costs.
Experimental validation on synthetic and real-world datasets demonstrates that
our framework enables the many-to-many algorithmic recourse to achieve
near-optimal welfare with minimum modification in system settings. This work
extends algorithmic recourse from individual recommendations to system-level
design, providing a tractable path toward higher social welfare while
maintaining individual actionability.

</details>


### [181] [SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding](https://arxiv.org/abs/2508.11347)
*Yifei Li,Lingling Zhang,Hang Yan,Tianzhe Zhao,Zihan Ma,Muye Huang,Jun Liu*

Main category: cs.AI

Relevance: 40.0

TL;DR: SAGE提出了一种动态知识图谱嵌入框架，通过自适应维度扩展和动态蒸馏机制，有效处理不同规模的更新，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现实中的知识图谱动态变化，现有方法难以适应不同规模的更新，缺乏系统评估。

Method: SAGE根据更新规模确定嵌入维度，扩展嵌入空间，并采用动态蒸馏机制平衡新旧知识。

Result: 在七个基准测试中，SAGE在MRR、H@1和H@10上分别提升1.38%、1.25%和1.6%。

Conclusion: 自适应嵌入维度对动态知识图谱嵌入至关重要，SAGE在每次更新中均表现最优。

Abstract: Traditional knowledge graph (KG) embedding methods aim to represent entities
and relations in a low-dimensional space, primarily focusing on static graphs.
However, real-world KGs are dynamically evolving with the constant addition of
entities, relations and facts. To address such dynamic nature of KGs, several
continual knowledge graph embedding (CKGE) methods have been developed to
efficiently update KG embeddings to accommodate new facts while maintaining
learned knowledge. As KGs grow at different rates and scales in real-world
scenarios, existing CKGE methods often fail to consider the varying scales of
updates and lack systematic evaluation throughout the entire update process. In
this paper, we propose SAGE, a scale-aware gradual evolution framework for
CKGE. Specifically, SAGE firstly determine the embedding dimensions based on
the update scales and expand the embedding space accordingly. The Dynamic
Distillation mechanism is further employed to balance the preservation of
learned knowledge and the incorporation of new facts. We conduct extensive
experiments on seven benchmarks, and the results show that SAGE consistently
outperforms existing baselines, with a notable improvement of 1.38% in MRR,
1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with
methods using fixed embedding dimensions show that SAGE achieves optimal
performance on every snapshot, demonstrating the importance of adaptive
embedding dimensions in CKGE. The codes of SAGE are publicly available at:
https://github.com/lyfxjtu/Dynamic-Embedding.

</details>


### [182] [Landmark-Assisted Monte Carlo Planning](https://arxiv.org/abs/2508.11493)
*David H. Chan,Mark Roberts,Dana S. Nau*

Main category: cs.AI

Relevance: 40.0

TL;DR: 论文提出了一种在随机规划中使用概率地标（probabilistic landmarks）的方法，并将其整合到UCT算法中以分解MDP问题。实验表明，合理选择地标能显著提升在线概率规划的性能。


<details>
  <summary>Details</summary>
Motivation: 地标在经典规划中取得了重要进展，但在随机领域应用较少。本文旨在探索地标在随机规划中的潜力。

Method: 通过形式化概率地标，并调整UCT算法以利用地标作为子目标来分解MDP问题，同时平衡贪心地标实现与长期目标实现。

Result: 在基准测试中，合理选择的地标显著提升了UCT算法的性能，但贪心与长期目标的平衡因问题而异。

Conclusion: 地标可以为解决MDP问题的随时算法提供有效指导。

Abstract: Landmarks$\unicode{x2013}$conditions that must be satisfied at some point in
every solution plan$\unicode{x2013}$have contributed to major advancements in
classical planning, but they have seldom been used in stochastic domains. We
formalize probabilistic landmarks and adapt the UCT algorithm to leverage them
as subgoals to decompose MDPs; core to the adaptation is balancing between
greedy landmark achievement and final goal achievement. Our results in
benchmark domains show that well-chosen landmarks can significantly improve the
performance of UCT in online probabilistic planning, while the best balance of
greedy versus long-term goal achievement is problem-dependent. The results
suggest that landmarks can provide helpful guidance for anytime algorithms
solving MDPs.

</details>


### [183] [FLUID: Flow-Latent Unified Integration via Token Distillation for Expert Specialization in Multimodal Learning](https://arxiv.org/abs/2508.07264)
*Van Duc Cuong,Ta Dinh Tam,Tran Duc Chinh,Nguyen Thi Hanh*

Main category: cs.SI

Relevance: 40.0

TL;DR: FLUID提出了一种多模态分类方法，通过令牌蒸馏和专家专业化提升跨模态鲁棒性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态分类中模态特定噪声导致的脆弱性问题，提升跨模态一致性和任务适应性。

Method: 1) Q-transforms提取模态特征；2) 两阶段融合方案（对比对齐和自适应门控融合）；3) 轻量级Mixture-of-Experts预测。

Result: 在GLAMI-1M上达到91%准确率，优于基线，对噪声、长尾类别和语义异质性表现出强鲁棒性。

Conclusion: FLUID是一种可扩展、抗噪声的多模态分类解决方案。

Abstract: Multimodal classification requires robust integration of visual and textual
signals, yet common fusion strategies are brittle and vulnerable to
modality-specific noise. In this paper, we present \textsc{FLUID}-Flow-Latent
Unified Integration via Token Distillation for Expert Specialization, a
principled token-level pipeline that improves cross-modal robustness and
scalability. \textsc{FLUID} contributes three core elements: (1)
\emph{Q-transforms}, learnable query tokens that distill and retain salient
token-level features from modality-specific backbones; (2) a two-stage fusion
scheme that enforces cross-modal consistency via contrastive alignment and then
performs adaptive, task-aware fusion through a gating mechanism and a
\emph{Q-bottleneck} that selectively compresses information for downstream
reasoning; and (3) a lightweight, load-balanced Mixture-of-Experts at
prediction time that enables efficient specialization to diverse semantic
patterns. Extensive experiments demonstrate that \textsc{FLUID} attains
\(91\%\) accuracy on the GLAMI-1M benchmark, significantly outperforming prior
baselines and exhibiting strong resilience to label noise, long-tail class
imbalance, and semantic heterogeneity. Targeted ablation studies corroborate
both the individual and synergistic benefits of the proposed components,
positioning \textsc{FLUID} as a scalable, noise-resilient solution for
multimodal product classification.

</details>


### [184] [LD-LAudio-V1: Video-to-Long-Form-Audio Generation Extension with Dual Lightweight Adapters](https://arxiv.org/abs/2508.11074)
*Haomin Zhang,Kristin Qi,Shuxin Yang,Zihao Chen,Chaofan Ding,Xinhan Di*

Main category: cs.SD

Relevance: 40.0

TL;DR: 论文提出LD-LAudio-V1模型，通过双轻量适配器实现长视频音频生成，并发布高质量数据集。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频到音频生成方法在长视频和噪声数据集上的局限性。

Method: 扩展现有视频到音频模型，引入双轻量适配器，并发布干净标注的数据集。

Result: 在多指标上显著提升性能，减少拼接伪影和时间不一致性。

Conclusion: LD-LAudio-V1在长视频音频生成中表现优异，数据集促进进一步研究。

Abstract: Generating high-quality and temporally synchronized audio from video content
is essential for video editing and post-production tasks, enabling the creation
of semantically aligned audio for silent videos. However, most existing
approaches focus on short-form audio generation for video segments under 10
seconds or rely on noisy datasets for long-form video-to-audio zsynthesis. To
address these limitations, we introduce LD-LAudio-V1, an extension of
state-of-the-art video-to-audio models and it incorporates dual lightweight
adapters to enable long-form audio generation. In addition, we release a clean
and human-annotated video-to-audio dataset that contains pure sound effects
without noise or artifacts. Our method significantly reduces splicing artifacts
and temporal inconsistencies while maintaining computational efficiency.
Compared to direct fine-tuning with short training videos, LD-LAudio-V1
achieves significant improvements across multiple metrics: $FD_{\text{passt}}$
450.00 $\rightarrow$ 327.29 (+27.27%), $FD_{\text{panns}}$ 34.88 $\rightarrow$
22.68 (+34.98%), $FD_{\text{vgg}}$ 3.75 $\rightarrow$ 1.28 (+65.87%),
$KL_{\text{panns}}$ 2.49 $\rightarrow$ 2.07 (+16.87%), $KL_{\text{passt}}$ 1.78
$\rightarrow$ 1.53 (+14.04%), $IS_{\text{panns}}$ 4.17 $\rightarrow$ 4.30
(+3.12%), $IB_{\text{score}}$ 0.25 $\rightarrow$ 0.28 (+12.00%),
$Energy\Delta10\text{ms}$ 0.3013 $\rightarrow$ 0.1349 (+55.23%),
$Energy\Delta10\text{ms(vs.GT)}$ 0.0531 $\rightarrow$ 0.0288 (+45.76%), and
$Sem.\,Rel.$ 2.73 $\rightarrow$ 3.28 (+20.15%). Our dataset aims to facilitate
further research in long-form video-to-audio generation and is available at
https://github.com/deepreasonings/long-form-video2audio.

</details>


### [185] [Utilizing Vision-Language Models as Action Models for Intent Recognition and Assistance](https://arxiv.org/abs/2508.11093)
*Cesar Alan Contreras,Manolis Chiou,Alireza Rastegarpanah,Michal Szulik,Rustam Stolkin*

Main category: cs.RO

Relevance: 40.0

TL;DR: 论文提出了一种结合视觉语言模型（VLM）和纯文本语言模型（LLM）的框架GUIDER，用于机器人快速推断用户意图并辅助完成任务。


<details>
  <summary>Details</summary>
Motivation: 提升人机协作中机器人对用户意图的理解和透明推理能力，以实现高效的目标达成。

Method: 通过VLM和LLM构建语义先验，结合视觉管道（YOLO和Segment Anything Model）筛选相关对象和位置，动态调整导航和操作层。

Result: 机器人能够根据用户提示选择上下文相关目标，并在意图变化时自适应调整行为。

Conclusion: 该方法在人机协作中展现了潜力，未来将在仿真环境中进一步验证实时辅助能力。

Abstract: Human-robot collaboration requires robots to quickly infer user intent,
provide transparent reasoning, and assist users in achieving their goals. Our
recent work introduced GUIDER, our framework for inferring navigation and
manipulation intents. We propose augmenting GUIDER with a vision-language model
(VLM) and a text-only language model (LLM) to form a semantic prior that
filters objects and locations based on the mission prompt. A vision pipeline
(YOLO for object detection and the Segment Anything Model for instance
segmentation) feeds candidate object crops into the VLM, which scores their
relevance given an operator prompt; in addition, the list of detected object
labels is ranked by a text-only LLM. These scores weight the existing
navigation and manipulation layers of GUIDER, selecting context-relevant
targets while suppressing unrelated objects. Once the combined belief exceeds a
threshold, autonomy changes occur, enabling the robot to navigate to the
desired area and retrieve the desired object, while adapting to any changes in
the operator's intent. Future work will evaluate the system on Isaac Sim using
a Franka Emika arm on a Ridgeback base, with a focus on real-time assistance.

</details>


### [186] [Tabularis Formatus: Predictive Formatting for Tables](https://arxiv.org/abs/2508.11121)
*Mukul Singh,José Cambronero,Sumit Gulwani,Vu Le,Gust Verbruggen*

Main category: cs.DB

Relevance: 40.0

TL;DR: TaFo是一种神经符号方法，用于自动生成电子表格的条件格式规则，结合语言模型和多样性规则排名，无需用户输入即可预测格式。


<details>
  <summary>Details</summary>
Motivation: 电子表格条件格式规则创建复杂且依赖用户输入，TaFo旨在解决这一问题，实现完全自动化的格式建议。

Method: TaFo结合组件合成系统和语言模型语义知识，支持基于值的格式，自动学习规则触发和视觉格式属性。

Result: TaFo在1.8百万公开工作簿上测试，比现有系统准确率高15.6%--26.5%，生成更多样化和完整的格式建议。

Conclusion: TaFo通过神经符号方法显著提升了条件格式规则的自动生成能力，优于现有技术。

Abstract: Spreadsheet manipulation software are widely used for data management and
analysis of tabular data, yet the creation of conditional formatting (CF) rules
remains a complex task requiring technical knowledge and experience with
specific platforms. In this paper we present TaFo, a neuro-symbolic approach to
generating CF suggestions for tables, addressing common challenges such as user
unawareness, difficulty in rule creation, and inadequate user interfaces. TaFo
takes inspiration from component based synthesis systems and extends them with
semantic knowledge of language models and a diversity preserving rule
ranking.Unlike previous methods focused on structural formatting, TaFo uniquely
incorporates value-based formatting, automatically learning both the rule
trigger and the associated visual formatting properties for CF rules. By
removing the dependency on user specification used by existing techniques in
the form of formatted examples or natural language instruction, TaFo makes
formatting completely predictive and automated for the user. To evaluate TaFo,
we use a corpus of 1.8 Million public workbooks with CF and manual formatting.
We compare TaFo against a diverse set of symbolic and neural systems designed
for or adapted for the task of table formatting. Our results show that TaFo
generates more accurate, diverse and complete formatting suggestions than
current systems and outperforms these by 15.6\%--26.5\% on matching user added
ground truth rules in tables.

</details>


### [187] [Visuomotor Grasping with World Models for Surgical Robots](https://arxiv.org/abs/2508.11200)
*Hongbin Lin,Bin Li,Kwok Wai Samuel Au*

Main category: cs.RO

Relevance: 40.0

TL;DR: 论文提出GASv2框架，用于手术机器人中的视觉运动学习，解决模拟到现实的迁移、单摄像头输入和泛化性问题。


<details>
  <summary>Details</summary>
Motivation: 自动化手术中的抓取任务可提升效率和安全性，但现有方法泛化性差且难以适应复杂手术环境。

Method: 采用基于世界模型的架构和混合控制系统，通过域随机化在模拟中训练策略。

Result: 在真实手术环境中实现65%的成功率，泛化性强且适应性强。

Conclusion: GASv2在手术机器人中表现出高性能、泛化性和鲁棒性。

Abstract: Grasping is a fundamental task in robot-assisted surgery (RAS), and
automating it can reduce surgeon workload while enhancing efficiency, safety,
and consistency beyond teleoperated systems. Most prior approaches rely on
explicit object pose tracking or handcrafted visual features, limiting their
generalization to novel objects, robustness to visual disturbances, and the
ability to handle deformable objects. Visuomotor learning offers a promising
alternative, but deploying it in RAS presents unique challenges, such as low
signal-to-noise ratio in visual observations, demands for high safety and
millimeter-level precision, as well as the complex surgical environment. This
paper addresses three key challenges: (i) sim-to-real transfer of visuomotor
policies to ex vivo surgical scenes, (ii) visuomotor learning using only a
single stereo camera pair -- the standard RAS setup, and (iii) object-agnostic
grasping with a single policy that generalizes to diverse, unseen surgical
objects without retraining or task-specific models. We introduce Grasp Anything
for Surgery V2 (GASv2), a visuomotor learning framework for surgical grasping.
GASv2 leverages a world-model-based architecture and a surgical perception
pipeline for visual observations, combined with a hybrid control system for
safe execution. We train the policy in simulation using domain randomization
for sim-to-real transfer and deploy it on a real robot in both phantom-based
and ex vivo surgical settings, using only a single pair of endoscopic cameras.
Extensive experiments show our policy achieves a 65% success rate in both
settings, generalizes to unseen objects and grippers, and adapts to diverse
disturbances, demonstrating strong performance, generality, and robustness.

</details>


### [188] [Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation](https://arxiv.org/abs/2508.11204)
*Hongbin Lin,Juan Rojas,Kwok Wai Samuel Au*

Main category: cs.RO

Relevance: 40.0

TL;DR: 论文提出了一种针对非等距对称性的数据增强方法MEA，结合离线强化学习提升采样效率，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决真实机器人操作中视觉运动学习的采样效率问题，特别是探索非等距对称性以突破现有等距对称性的限制。

Method: 方法包括提出一种新的部分可观测马尔可夫决策过程（POMDP）框架，结合非等距对称性结构，并设计了一种数据增强方法MEA。此外，还引入了基于体素的视觉表示。

Result: 实验结果表明，该方法在模拟和真实机器人操作中均显著提升了采样效率。

Conclusion: 结论表明，非等距对称性和MEA方法在提升视觉运动学习效率方面具有潜力。

Abstract: Sampling efficiency is critical for deploying visuomotor learning in
real-world robotic manipulation. While task symmetry has emerged as a promising
inductive bias to improve efficiency, most prior work is limited to isometric
symmetries -- applying the same group transformation to all task objects across
all timesteps. In this work, we explore non-isometric symmetries, applying
multiple independent group transformations across spatial and temporal
dimensions to relax these constraints. We introduce a novel formulation of the
partially observable Markov decision process (POMDP) that incorporates the
non-isometric symmetry structures, and propose a simple yet effective data
augmentation method, Multi-Group Equivariance Augmentation (MEA). We integrate
MEA with offline reinforcement learning to enhance sampling efficiency, and
introduce a voxel-based visual representation that preserves translational
equivariance. Extensive simulation and real-robot experiments across two
manipulation domains demonstrate the effectiveness of our approach.

</details>


### [189] [Scene Graph-Guided Proactive Replanning for Failure-Resilient Embodied Agent](https://arxiv.org/abs/2508.11286)
*Che Rin Yu,Daewon Chae,Dabin Seo,Sangwon Lee,Hyeongwoo Im,Jinkyu Kim*

Main category: cs.RO

Relevance: 40.0

TL;DR: 提出了一种主动重规划框架，通过比较当前场景图与参考场景图，在子任务边界检测和纠正潜在失败，提升机器人任务成功率。


<details>
  <summary>Details</summary>
Motivation: 人类能根据环境状态调整行为，而机器人常因缺乏适应性导致失败。现有方法多为被动响应，主动重规划依赖人工规则。本文旨在通过自动化方法实现主动重规划。

Method: 构建当前RGB-D观测的场景图与成功演示的参考图对比，在子任务边界检测不匹配时，激活轻量推理模块调整计划。

Result: 在AI2-THOR模拟器中，该方法能提前检测语义和空间不匹配，显著提高任务成功率和鲁棒性。

Conclusion: 主动重规划框架通过场景图对比和推理模块，有效预防执行失败，提升机器人适应性。

Abstract: When humans perform everyday tasks, we naturally adjust our actions based on
the current state of the environment. For instance, if we intend to put
something into a drawer but notice it is closed, we open it first. However,
many autonomous robots lack this adaptive awareness. They often follow
pre-planned actions that may overlook subtle yet critical changes in the scene,
which can result in actions being executed under outdated assumptions and
eventual failure. While replanning is critical for robust autonomy, most
existing methods respond only after failures occur, when recovery may be
inefficient or infeasible. While proactive replanning holds promise for
preventing failures in advance, current solutions often rely on manually
designed rules and extensive supervision. In this work, we present a proactive
replanning framework that detects and corrects failures at subtask boundaries
by comparing scene graphs constructed from current RGB-D observations against
reference graphs extracted from successful demonstrations. When the current
scene fails to align with reference trajectories, a lightweight reasoning
module is activated to diagnose the mismatch and adjust the plan. Experiments
in the AI2-THOR simulator demonstrate that our approach detects semantic and
spatial mismatches before execution failures occur, significantly improving
task success and robustness.

</details>


### [190] [Sim2Dust: Mastering Dynamic Waypoint Tracking on Granular Media](https://arxiv.org/abs/2508.11503)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

Relevance: 40.0

TL;DR: 论文提出了一种基于强化学习的框架，用于在行星表面复杂地形中实现可靠的自主导航，通过大规模并行模拟训练策略，并在真实环境中零样本部署。


<details>
  <summary>Details</summary>
Motivation: 解决行星表面复杂地形中自主导航的sim-to-real差距问题，特别是轮式机器人与颗粒介质交互的动态控制。

Method: 利用大规模并行模拟训练强化学习代理，生成多样化环境，并零样本迁移到真实轮式机器人。比较了多种强化学习算法和动作平滑滤波器。

Result: 实验表明，通过多样化环境训练的代理在零样本性能上优于静态场景训练的代理。高保真粒子物理微调在低速精度上有小幅提升，但计算成本高。

Conclusion: 研究为开发可靠的基于学习的导航系统提供了验证的工作流程，是自主机器人在极端环境中部署的重要进展。

Abstract: Reliable autonomous navigation across the unstructured terrains of distant
planetary surfaces is a critical enabler for future space exploration. However,
the deployment of learning-based controllers is hindered by the inherent
sim-to-real gap, particularly for the complex dynamics of wheel interactions
with granular media. This work presents a complete sim-to-real framework for
developing and validating robust control policies for dynamic waypoint tracking
on such challenging surfaces. We leverage massively parallel simulation to
train reinforcement learning agents across a vast distribution of procedurally
generated environments with randomized physics. These policies are then
transferred zero-shot to a physical wheeled rover operating in a lunar-analogue
facility. Our experiments systematically compare multiple reinforcement
learning algorithms and action smoothing filters to identify the most effective
combinations for real-world deployment. Crucially, we provide strong empirical
evidence that agents trained with procedural diversity achieve superior
zero-shot performance compared to those trained on static scenarios. We also
analyze the trade-offs of fine-tuning with high-fidelity particle physics,
which offers minor gains in low-speed precision at a significant computational
cost. Together, these contributions establish a validated workflow for creating
reliable learning-based navigation systems, marking a critical step towards
deploying autonomous robots in the final frontier.

</details>


### [191] [Visual Perception Engine: Fast and Flexible Multi-Head Inference for Robotic Vision Tasks](https://arxiv.org/abs/2508.11584)
*Jakub Łucki,Jonathan Becktor,Georgios Georgakis,Robert Royce,Shehryar Khattak*

Main category: cs.RO

Relevance: 40.0

TL;DR: VPEngine是一个模块化框架，通过共享基础模型骨干和多任务并行处理，优化GPU使用，提升视觉多任务处理效率。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限机器人平台上部署多模型时的计算冗余、内存占用大和集成复杂性问题。

Method: 采用共享基础模型骨干提取图像表示，并行运行多个任务专用模型头，避免GPU-CPU内存传输，支持动态任务优先级调整。

Result: 使用DINOv2基础模型和多任务头实现3倍加速，支持实时性能（≥50 Hz）。

Conclusion: VPEngine通过高效GPU利用和动态任务管理，显著提升视觉多任务处理性能。

Abstract: Deploying multiple machine learning models on resource-constrained robotic
platforms for different perception tasks often results in redundant
computations, large memory footprints, and complex integration challenges. In
response, this work presents Visual Perception Engine (VPEngine), a modular
framework designed to enable efficient GPU usage for visual multitasking while
maintaining extensibility and developer accessibility. Our framework
architecture leverages a shared foundation model backbone that extracts image
representations, which are efficiently shared, without any unnecessary GPU-CPU
memory transfers, across multiple specialized task-specific model heads running
in parallel. This design eliminates the computational redundancy inherent in
feature extraction component when deploying traditional sequential models while
enabling dynamic task prioritization based on application demands. We
demonstrate our framework's capabilities through an example implementation
using DINOv2 as the foundation model with multiple task (depth, object
detection and semantic segmentation) heads, achieving up to 3x speedup compared
to sequential execution. Building on CUDA Multi-Process Service (MPS), VPEngine
offers efficient GPU utilization and maintains a constant memory footprint
while allowing per-task inference frequencies to be adjusted dynamically during
runtime. The framework is written in Python and is open source with ROS2 C++
(Humble) bindings for ease of use by the robotics community across diverse
robotic platforms. Our example implementation demonstrates end-to-end real-time
performance at $\geq$50 Hz on NVIDIA Jetson Orin AGX for TensorRT optimized
models.

</details>


### [192] [CryptoScope: Utilizing Large Language Models for Automated Cryptographic Logic Vulnerability Detection](https://arxiv.org/abs/2508.11599)
*Zhihao Li,Zimo Ji,Tao Zheng,Hao Ren,Xiao Lan*

Main category: cs.CR

Relevance: 40.0

TL;DR: CryptoScope是一个基于LLM的自动化加密漏洞检测框架，结合CoT提示和RAG技术，显著提升了多个LLM模型的性能，并发现了开源项目中的新漏洞。


<details>
  <summary>Details</summary>
Motivation: 加密算法实现中常存在难以检测的逻辑缺陷，需要自动化工具提高漏洞发现效率。

Method: 结合Chain-of-Thought提示和Retrieval-Augmented Generation技术，利用包含12,000条目的加密知识库。

Result: 在LLM-CLVA基准测试中显著提升模型性能（如DeepSeek-V3提升11.62%），并发现9个新漏洞。

Conclusion: CryptoScope证明了LLM在加密漏洞检测中的潜力，结合领域知识可显著提升效果。

Abstract: Cryptographic algorithms are fundamental to modern security, yet their
implementations frequently harbor subtle logic flaws that are hard to detect.
We introduce CryptoScope, a novel framework for automated cryptographic
vulnerability detection powered by Large Language Models (LLMs). CryptoScope
combines Chain-of-Thought (CoT) prompting with Retrieval-Augmented Generation
(RAG), guided by a curated cryptographic knowledge base containing over 12,000
entries. We evaluate CryptoScope on LLM-CLVA, a benchmark of 92 cases primarily
derived from real-world CVE vulnerabilities, complemented by cryptographic
challenges from major Capture The Flag (CTF) competitions and synthetic
examples across 11 programming languages. CryptoScope consistently improves
performance over strong LLM baselines, boosting DeepSeek-V3 by 11.62%,
GPT-4o-mini by 20.28%, and GLM-4-Flash by 28.69%. Additionally, it identifies 9
previously undisclosed flaws in widely used open-source cryptographic projects.

</details>


### [193] [Pretrained Conformers for Audio Fingerprinting and Retrieval](https://arxiv.org/abs/2508.11609)
*Kemal Altwlkany,Elmedin Selmanovic,Sead Delalic*

Main category: cs.SD

Relevance: 40.0

TL;DR: 论文提出了一种基于自监督对比学习的Conformer编码器，用于音频检索任务，在3秒音频片段上生成独特嵌入，并在抗干扰性上表现优异。


<details>
  <summary>Details</summary>
Motivation: Conformer在语音处理中表现出色，但如何进一步优化其在小音频片段上的嵌入生成能力，并提升对噪声、混响等干扰的鲁棒性，是研究的动机。

Method: 采用自监督对比学习框架训练Conformer编码器，生成音频片段的独特嵌入，并在公开数据集上进行训练和测试。

Result: 模型在音频检索任务中达到SOTA，对时间错位和其他音频失真（如噪声、混响）具有强鲁棒性。

Conclusion: 该方法为音频检索任务提供了高效且鲁棒的解决方案，代码和模型已开源。

Abstract: Conformers have shown great results in speech processing due to their ability
to capture both local and global interactions. In this work, we utilize a
self-supervised contrastive learning framework to train conformer-based
encoders that are capable of generating unique embeddings for small segments of
audio, generalizing well to previously unseen data. We achieve state-of-the-art
results for audio retrieval tasks while using only 3 seconds of audio to
generate embeddings. Our models are almost completely immune to temporal
misalignments and achieve state-of-the-art results in cases of other audio
distortions such as noise, reverb or extreme temporal stretching. Code and
models are made publicly available and the results are easy to reproduce as we
train and test using popular and freely available datasets of different sizes.

</details>


### [194] [Learn to optimize for automatic proton PBS treatment planning for H&N cancers](https://arxiv.org/abs/2508.11085)
*Qingqing Wang,Liqiang Xiao,Chang Chang*

Main category: cs.AI

Relevance: 30.0

TL;DR: 该论文提出了一种基于数据驱动的逆优化器，并将其集成到PPO自动治疗计划框架中，用于高效生成高质量的治疗计划。


<details>
  <summary>Details</summary>
Motivation: 质子PBS治疗计划涉及多个冲突目标，传统方法依赖人工调整和理论驱动的逆优化，耗时且低效。

Method: 结合L2O方法和Transformer技术，设计了一个数据驱动的逆优化器，并与PPO框架集成，实现自动参数调整和剂量预测。

Result: 相比L-BFGSB，逆优化器在效果和效率上分别提升22.97%和36.41%，生成的治疗计划在2.55小时内达到或优于人工计划。

Conclusion: 该方法显著提升了治疗计划的效率和质量，适用于多种复杂临床场景。

Abstract: Proton PBS treatment planning for H&N cancers involves numerous conflicting
objectives, requiring significant effort from human planners to balance and
satisfy multiple clinical goals during planning. To achieve this,
experience-demanding objective parameter adjustment and computationally
expensive inverse optimization are performed iteratively. Extensive efforts
have been made to automatically adjust objective parameters, but the most
time-consuming component, i.e., inverse optimization, still relies heavily on
theory-driven approaches. We propose a data-driven inverse optimizer and
integrate it into a PPO-based automatic treatment planning framework to
automatically generate high-quality plans within a clinical acceptable planning
time. The inverse optimizer is a L2O method that predicts update steps by
learning from the task-specific data distribution. For the first time, we
integrate techniques designed for long-context processing, originally developed
for LLMs, into a Transformer-based L2O framework to address the scalability
issue of existing L2O methods. The PPO framework functions as an outer-loop
virtual planner, autonomously adjusting objective parameters through a policy
network, and the dose predictor is used to initialize objective parameters. The
inner-loop L2O inverse optimizer computes machine-deliverable MU values based
on objectives refined by the PPO policy network. 97 patients are collected in
this study, and compared with L-BFGSB, our L2O-based inverse optimizer improves
the effectiveness and efficiency by 22.97% and 36.41%, respectively. In
conjunction with the PPO-based learned virtual planner, plans generated by our
framework within an average of 2.55 hours show improved or comparable OAR
sparing with superior target coverage for patients with different prescription
dose levels, number of target volumes, beam angles, etc., compared with
human-generated plans.

</details>


### [195] [A Generalized Similarity U Test for Multivariate Analysis of Sequencing Data](https://arxiv.org/abs/1505.01179)
*Changshuai Wei,Qing Lu*

Main category: stat.ME

Relevance: 30.0

TL;DR: 提出了一种广义相似性U检验（GSU），用于处理高维基因型和表型数据，解决了传统统计方法在多表型分析中的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决高维基因数据和多表型分布不一致对传统统计方法的挑战。

Method: 提出GSU方法，基于相似性检验，支持高维数据和多表型分析，并提供理论性质、p值计算和样本量设计。

Result: 模拟显示GSU在功效和表型分布鲁棒性上优于现有方法；实际数据分析中识别了4个基因与5个代谢表型的联合关联。

Conclusion: GSU为复杂疾病的遗传关联研究提供了有效的统计工具。

Abstract: Sequencing-based studies are emerging as a major tool for genetic association
studies of complex diseases. These studies pose great challenges to the
traditional statistical methods (e.g., single-locus analyses based on
regression methods) because of the high-dimensionality of data and the low
frequency of genetic variants. In addition, there is a great interest in
biology and epidemiology to identify genetic risk factors contributed to
multiple disease phenotypes. The multiple phenotypes can often follow different
distributions, which violates the assumptions of most current methods. In this
paper, we propose a generalized similarity U test, referred to as GSU. GSU is a
similarity-based test and can handle high-dimensional genotypes and phenotypes.
We studied the theoretical properties of GSU, and provided the efficient
p-value calculation for association test as well as the sample size and power
calculation for the study design. Through simulation, we found that GSU had
advantages over existing methods in terms of power and robustness to phenotype
distributions. Finally, we used GSU to perform a multivariate analysis of
sequencing data in the Dallas Heart Study and identified a joint association of
4 genes with 5 metabolic related phenotypes.

</details>


### [196] [Multimodal Quantitative Measures for Multiparty Behaviour Evaluation](https://arxiv.org/abs/2508.10916)
*Ojas Shirekar,Wim Pouw,Chenxu Hao,Vrushank Phadnis,Thabo Beeler,Chirag Raman*

Main category: cs.HC

Relevance: 30.0

TL;DR: 论文提出了一种基于干预的统一框架，用于评估多参与者社交行为，包括同步性、时间对齐和结构相似性三个维度，并通过实验验证了其敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有的评估指标忽略了多参与者交互中的上下文协调动态，因此需要一种更全面的方法来评估社交行为。

Method: 采用交叉递归量化分析（CRQA）、多尺度经验模态分解（EMD）和软动态时间规整（Soft-DTW）三种方法，结合理论驱动的扰动实验验证。

Result: 实验显示，扰动对同步性、时间对齐和结构相似性有可预测的影响，且感知研究支持了方法的有效性。

Conclusion: 提出的三种指标为评估社交智能代理提供了正交且鲁棒的工具。

Abstract: Digital humans are emerging as autonomous agents in multiparty interactions,
yet existing evaluation metrics largely ignore contextual coordination
dynamics. We introduce a unified, intervention-driven framework for objective
assessment of multiparty social behaviour in skeletal motion data, spanning
three complementary dimensions: (1) synchrony via Cross-Recurrence
Quantification Analysis, (2) temporal alignment via Multiscale Empirical Mode
Decompositionbased Beat Consistency, and (3) structural similarity via Soft
Dynamic Time Warping. We validate metric sensitivity through three
theory-driven perturbations -- gesture kinematic dampening, uniform
speech-gesture delays, and prosodic pitch-variance reduction-applied to
$\approx 145$ 30-second thin slices of group interactions from the DnD dataset.
Mixed-effects analyses reveal predictable, joint-independent shifts: dampening
increases CRQA determinism and reduces beat consistency, delays weaken
cross-participant coupling, and pitch flattening elevates F0 Soft-DTW costs. A
complementary perception study ($N=27$) compares judgments of full-video and
skeleton-only renderings to quantify representation effects. Our three measures
deliver orthogonal insights into spatial structure, timing alignment, and
behavioural variability. Thereby forming a robust toolkit for evaluating and
refining socially intelligent agents. Code available on
\href{https://github.com/tapri-lab/gig-interveners}{GitHub}.

</details>


### [197] [Risk-Based Prognostics and Health Management](https://arxiv.org/abs/2508.11031)
*John W. Sheppard*

Main category: eess.SY

Relevance: 30.0

TL;DR: 论文提出了一种基于风险的方法，将风险评估与故障预测更紧密地结合，使用连续时间贝叶斯网络作为建模框架。


<details>
  <summary>Details</summary>
Motivation: 解决风险评估与故障预测之间的分离问题，提供更紧密的耦合方法。

Method: 采用连续时间贝叶斯网络作为建模框架，并介绍从数据中推导模型的技术。

Result: 展示了如何将这些模型应用于决策支持和基于性能的后勤等实际任务。

Conclusion: 该工作为风险预测的最新发展提供了概述，并希望作为教程帮助他人采用这些技术。

Abstract: It is often the case that risk assessment and prognostics are viewed as
related but separate tasks. This chapter describes a risk-based approach to
prognostics that seeks to provide a tighter coupling between risk assessment
and fault prediction. We show how this can be achieved using the
continuous-time Bayesian network as the underlying modeling framework.
Furthermore, we provide an overview of the techniques that are available to
derive these models from data and show how they might be used in practice to
achieve tasks like decision support and performance-based logistics. This work
is intended to provide an overview of the recent developments related to
risk-based prognostics, and we hope that it will serve as a tutorial of sorts
that will assist others in adopting these techniques.

</details>


### [198] [StyleMM: Stylized 3D Morphable Face Model via Text-Driven Aligned Image Translation](https://arxiv.org/abs/2508.11203)
*Seungmi Lee,Kwan Yun,Junyong Noh*

Main category: cs.GR

Relevance: 30.0

TL;DR: StyleMM是一个基于文本描述生成风格化3D人脸模型的新框架，结合了预训练网格变形网络和纹理生成器，通过扩散模型实现文本引导的风格化。


<details>
  <summary>Details</summary>
Motivation: 旨在通过文本描述生成风格化的3D人脸模型，同时保留原始人脸的关键属性（如身份、表情）。

Method: 利用预训练模型和扩散模型进行文本引导的图像到图像翻译，并通过图像训练实现3D风格迁移。

Result: 在身份多样性和风格化能力上优于现有方法。

Conclusion: StyleMM能够高效生成风格化3D人脸模型，具有可控性和一致性。

Abstract: We introduce StyleMM, a novel framework that can construct a stylized 3D
Morphable Model (3DMM) based on user-defined text descriptions specifying a
target style. Building upon a pre-trained mesh deformation network and a
texture generator for original 3DMM-based realistic human faces, our approach
fine-tunes these models using stylized facial images generated via text-guided
image-to-image (i2i) translation with a diffusion model, which serve as
stylization targets for the rendered mesh. To prevent undesired changes in
identity, facial alignment, or expressions during i2i translation, we introduce
a stylization method that explicitly preserves the facial attributes of the
source image. By maintaining these critical attributes during image
stylization, the proposed approach ensures consistent 3D style transfer across
the 3DMM parameter space through image-based training. Once trained, StyleMM
enables feed-forward generation of stylized face meshes with explicit control
over shape, expression, and texture parameters, producing meshes with
consistent vertex connectivity and animatability. Quantitative and qualitative
evaluations demonstrate that our approach outperforms state-of-the-art methods
in terms of identity-level facial diversity and stylization capability. The
code and videos are available at
[kwanyun.github.io/stylemm_page](kwanyun.github.io/stylemm_page).

</details>


### [199] [An Exploratory Study on Crack Detection in Concrete through Human-Robot Collaboration](https://arxiv.org/abs/2508.11404)
*Junyeon Kim,Tianshu Ruan,Cesar Alan Contreras,Manolis Chiou*

Main category: cs.RO

Relevance: 30.0

TL;DR: 论文探讨了AI辅助视觉裂纹检测在移动机器人平台上的应用，用于核设施结构检查，结果显示其比传统人工方法更准确且减轻操作员负担。


<details>
  <summary>Details</summary>
Motivation: 传统核设施结构检查方法存在安全风险、高认知需求和人为误差问题，AI和机器人技术为更安全高效的检查提供了新可能。

Method: 研究将AI辅助视觉裂纹检测集成到移动Jackal机器人平台，通过人机协作（HRC）进行实验。

Result: 实验表明，HRC提高了检查准确性并减少了操作员工作量，性能优于传统人工方法。

Conclusion: AI辅助机器人检查在核设施结构检查中具有潜力，可提升效率和安全性。

Abstract: Structural inspection in nuclear facilities is vital for maintaining
operational safety and integrity. Traditional methods of manual inspection pose
significant challenges, including safety risks, high cognitive demands, and
potential inaccuracies due to human limitations. Recent advancements in
Artificial Intelligence (AI) and robotic technologies have opened new
possibilities for safer, more efficient, and accurate inspection methodologies.
Specifically, Human-Robot Collaboration (HRC), leveraging robotic platforms
equipped with advanced detection algorithms, promises significant improvements
in inspection outcomes and reductions in human workload. This study explores
the effectiveness of AI-assisted visual crack detection integrated into a
mobile Jackal robot platform. The experiment results indicate that HRC enhances
inspection accuracy and reduces operator workload, resulting in potential
superior performance outcomes compared to traditional manual methods.

</details>


### [200] [Open, Reproducible and Trustworthy Robot-Based Experiments with Virtual Labs and Digital-Twin-Based Execution Tracing](https://arxiv.org/abs/2508.11406)
*Benjamin Alt,Mareike Picklum,Sorin Arion,Franklin Kenghagho Kenfack,Michael Beetz*

Main category: cs.RO

Relevance: 30.0

TL;DR: 论文提出了一种语义执行追踪框架和云平台AICOR VRB，旨在实现透明、可复现的机器人科学实验。


<details>
  <summary>Details</summary>
Motivation: 为实现机器人科学实验的透明性、可信性和可复现性。

Method: 1. 语义执行追踪框架记录传感器数据和机器人信念状态；2. 云平台AICOR VRB用于共享和验证任务执行。

Result: 实现了机器人驱动的可复现科学实验，整合了确定性执行、语义记忆和开放知识表示。

Conclusion: 为自主系统参与科学发现奠定了基础。

Abstract: We envision a future in which autonomous robots conduct scientific
experiments in ways that are not only precise and repeatable, but also open,
trustworthy, and transparent. To realize this vision, we present two key
contributions: a semantic execution tracing framework that logs sensor data
together with semantically annotated robot belief states, ensuring that
automated experimentation is transparent and replicable; and the AICOR Virtual
Research Building (VRB), a cloud-based platform for sharing, replicating, and
validating robot task executions at scale. Together, these tools enable
reproducible, robot-driven science by integrating deterministic execution,
semantic memory, and open knowledge representation, laying the foundation for
autonomous systems to participate in scientific discovery.

</details>


### [201] [RMSL: Weakly-Supervised Insider Threat Detection with Robust Multi-sphere Learning](https://arxiv.org/abs/2508.11472)
*Yang Wang,Yaxin Zhao,Xinyu Jiao,Sihan Xu,Xiangrui Cai,Ying Zhang,Xiaojie Yuan*

Main category: cs.CR

Relevance: 30.0

TL;DR: 论文提出了一种名为RMSL的框架，利用弱序列级标签提升行为级内部威胁检测的性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏细粒度行为级标注，现有方法在检测用户行为序列中的异常时表现不佳。

Method: 提出RMSL框架，通过多超球体表示正常行为模式，结合多实例学习和自适应行为级自训练去偏。

Result: 实验表明RMSL显著提升了行为级内部威胁检测的性能。

Conclusion: RMSL通过弱标签有效提升了异常检测能力。

Abstract: Insider threat detection aims to identify malicious user behavior by
analyzing logs that record user interactions. Due to the lack of fine-grained
behavior-level annotations, detecting specific behavior-level anomalies within
user behavior sequences is challenging. Unsupervised methods face high false
positive rates and miss rates due to the inherent ambiguity between normal and
anomalous behaviors. In this work, we instead introduce weak labels of behavior
sequences, which have lower annotation costs, i.e., the training labels
(anomalous or normal) are at sequence-level instead of behavior-level, to
enhance the detection capability for behavior-level anomalies by learning
discriminative features. To achieve this, we propose a novel framework called
Robust Multi-sphere Learning (RMSL). RMSL uses multiple hyper-spheres to
represent the normal patterns of behaviors. Initially, a one-class classifier
is constructed as a good anomaly-supervision-free starting point. Building on
this, using multiple instance learning and adaptive behavior-level
self-training debiasing based on model prediction confidence, the framework
further refines hyper-spheres and feature representations using weak
sequence-level labels. This approach enhances the model's ability to
distinguish between normal and anomalous behaviors. Extensive experiments
demonstrate that RMSL significantly improves the performance of behavior-level
insider threat detection.

</details>


### [202] [Weighted First Order Model Counting for Two-variable Logic with Axioms on Two Relations](https://arxiv.org/abs/2508.11515)
*Qipeng Kuang,Václav Kůla,Ondřej Kuželka,Yuanhong Wang,Yuyi Wang*

Main category: cs.LO

Relevance: 30.0

TL;DR: 研究探讨了加权一阶模型计数问题（WFOMC）在扩展两变量片段（FO²）时，涉及多个关系的公理的复杂性边界。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于单一关系公理的扩展，缺乏对多关系公理复杂性的理解。

Method: 研究扩展了两变量片段（FO²）到两个关系的公理，展示了负向和正向结果。

Result: 证明FO²带有两个线性序关系或两个无环关系时是#P₁-难的，但C²带有线性序关系及其后继关系时有多项式时间算法。

Conclusion: 多关系公理的复杂性边界具有挑战性，但部分情况下仍可高效计算。

Abstract: The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the
weighted sum of models of a given first-order logic sentence over a given
domain. The boundary between fragments for which WFOMC can be computed in
polynomial time relative to the domain size lies between the two-variable
fragment ($\text{FO}^2$) and the three-variable fragment ($\text{FO}^3$). It is
known that WFOMC for \FOthree{} is $\mathsf{\#P_1}$-hard while polynomial-time
algorithms exist for computing WFOMC for $\text{FO}^2$ and $\text{C}^2$,
possibly extended by certain axioms such as the linear order axiom, the
acyclicity axiom, and the connectedness axiom. All existing research has
concentrated on extending the fragment with axioms on a single distinguished
relation, leaving a gap in understanding the complexity boundary of axioms on
multiple relations. In this study, we explore the extension of the two-variable
fragment by axioms on two relations, presenting both negative and positive
results. We show that WFOMC for $\text{FO}^2$ with two linear order relations
and $\text{FO}^2$ with two acyclic relations are $\mathsf{\#P_1}$-hard.
Conversely, we provide an algorithm in time polynomial in the domain size for
WFOMC of $\text{C}^2$ with a linear order relation, its successor relation and
another successor relation.

</details>


### [203] [Grounding Rule-Based Argumentation Using Datalog](https://arxiv.org/abs/2508.10976)
*Martin Diller,Sarah Alice Gaggl,Philipp Hanisch,Giuseppina Monterosso,Fritz Rauschenbach*

Main category: cs.AI

Relevance: 20.0

TL;DR: 论文提出了一种智能基础化方法，用于处理ASPIC+框架中的一阶规则，通过将其转换为Datalog程序并简化规则，以保持推理过程的正确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅支持命题规则，而一阶规则的推理需要基础化步骤，可能导致输入理论规模指数增长，缺乏针对ASPIC+的专用解决方案。

Method: 将一阶ASPIC+实例转换为Datalog程序，利用Datalog引擎获取基础替换，并针对ASPIC+形式化提出简化规则以避免无关规则的冗余基础化。

Result: 通过原型实现的实证评估，展示了该方法的可扩展性。

Conclusion: 提出的智能基础化方法在保持推理正确性的同时，有效管理了基础化规模。

Abstract: ASPIC+ is one of the main general frameworks for rule-based argumentation for
AI. Although first-order rules are commonly used in ASPIC+ examples, most
existing approaches to reason over rule-based argumentation only support
propositional rules. To enable reasoning over first-order instances, a
preliminary grounding step is required. As groundings can lead to an
exponential increase in the size of the input theories, intelligent procedures
are needed. However, there is a lack of dedicated solutions for ASPIC+.
Therefore, we propose an intelligent grounding procedure that keeps the size of
the grounding manageable while preserving the correctness of the reasoning
process. To this end, we translate the first-order ASPIC+ instance into a
Datalog program and query a Datalog engine to obtain ground substitutions to
perform the grounding of rules and contraries. Additionally, we propose
simplifications specific to the ASPIC+ formalism to avoid grounding of rules
that have no influence on the reasoning process. Finally, we performed an
empirical evaluation of a prototypical implementation to show scalability.

</details>


### [204] [A weighted U statistic for association analysis considering genetic heterogeneity](https://arxiv.org/abs/1504.08319)
*Changshuai Wei,Robert C. Elston,Qing Lu*

Main category: stat.ME

Relevance: 20.0

TL;DR: 提出了一种考虑遗传异质性的关联分析方法HWU，适用于多种表型，计算高效，并在尼古丁依赖的全基因组分析中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 复杂疾病可能具有不同的遗传病因，但现有方法假设遗传效应同质，导致在异质情况下功效不足。

Method: 提出HWU方法，适用于多种表型和高维遗传数据，计算高效。

Result: 模拟显示HWU在遗传异质性下表现优越，且对模型假设稳健；实际分析发现两个新基因对尼古丁依赖的异质效应。

Conclusion: HWU是一种有效的遗传异质性分析方法，适用于复杂疾病研究。

Abstract: Converging evidence suggests that common complex diseases with the same or
similar clinical manifestations could have different underlying genetic
etiologies. While current research interests have shifted toward uncovering
rare variants and structural variations predisposing to human diseases, the
impact of heterogeneity in genetic studies of complex diseases has been largely
overlooked. Most of the existing statistical methods assume the disease under
investigation has a homogeneous genetic effect and could, therefore, have low
power if the disease undergoes heterogeneous pathophysiological and etiological
processes. In this paper, we propose a heterogeneity weighted U (HWU) method
for association analyses considering genetic heterogeneity. HWU can be applied
to various types of phenotypes (e.g., binary and continuous) and is
computationally effcient for high- dimensional genetic data. Through
simulations, we showed the advantage of HWU when the underlying genetic
etiology of a disease was heterogeneous, as well as the robustness of HWU
against different model assumptions (e.g., phenotype distributions). Using HWU,
we conducted a genome-wide analysis of nicotine dependence from the Study of
Addiction: Genetics and Environments (SAGE) dataset. The genome-wide analysis
of nearly one million genetic markers took 7 hours, identifying heterogeneous
effects of two new genes (i.e., CYP3A5 and IKBKB) on nicotine dependence.

</details>


### [205] [Trees Assembling Mann Whitney Approach for Detecting Genome-wide Joint Association among Low Marginal Effect loci](https://arxiv.org/abs/1505.01206)
*Changshuai Wei,Daniel J. Schaid,Qing Lu*

Main category: q-bio.QM

Relevance: 20.0

TL;DR: 提出了一种名为TAMW的高效计算方法，用于分析低边际效应（LME）遗传变异的联合关联，在模拟和实证数据中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 低边际效应遗传变异在复杂疾病中起重要作用，但现有方法难以高效分析其联合关联。

Method: 提出Trees Assembling Mann whitney (TAMW)方法，通过并行计算实现高效分析。

Result: TAMW在模拟和实证数据中表现优于MDR和LRMW，并成功应用于克罗恩病GWAS分析。

Conclusion: TAMW是一种高效且强大的工具，适用于大规模LME遗传变异的联合关联分析。

Abstract: Common complex diseases are likely influenced by the interplay of hundreds,
or even thousands, of genetic variants. Converging evidence shows that genetic
variants with low marginal effects (LME) play an important role in disease
development. Despite their potential significance, discovering LME genetic
variants and assessing their joint association on high dimensional data (e.g.,
genome wide association studies) remain a great challenge. To facilitate joint
association analysis among a large ensemble of LME genetic variants, we
proposed a computationally efficient and powerful approach, which we call Trees
Assembling Mann whitney (TAMW). Through simulation studies and an empirical
data application, we found that TAMW outperformed multifactor dimensionality
reduction (MDR) and the likelihood ratio based Mann whitney approach (LRMW)
when the underlying complex disease involves multiple LME loci and their
interactions. For instance, in a simulation with 20 interacting LME loci, TAMW
attained a higher power (power=0.931) than both MDR (power=0.599) and LRMW
(power=0.704). In an empirical study of 29 known Crohn's disease (CD) loci,
TAMW also identified a stronger joint association with CD than those detected
by MDR and LRMW. Finally, we applied TAMW to Wellcome Trust CD GWAS to conduct
a genome wide analysis. The analysis of 459K single nucleotide polymorphisms
was completed in 40 hours using parallel computing, and revealed a joint
association predisposing to CD (p-value=2.763e-19). Further analysis of the
newly discovered association suggested that 13 genes, such as ATG16L1 and
LACC1, may play an important role in CD pathophysiological and etiological
processes.

</details>


### [206] [SDSNN: A Single-Timestep Spiking Neural Network with Self-Dropping Neuron and Bayesian Optimization](https://arxiv.org/abs/2508.10913)
*Changqing Xu,Buxuan Song,Yi Liu,Xinfang Liao,Wenbin Zheng,Yintang Yang*

Main category: cs.NE

Relevance: 20.0

TL;DR: 提出了一种单时间步的脉冲神经网络（SNN），通过优化脉冲生成和时间参数，在单时间步内提高准确性并降低计算能耗。


<details>
  <summary>Details</summary>
Motivation: 传统SNN的多时间步计算模型增加了推理延迟和能耗，限制了其在边缘计算场景中的应用。

Method: 设计了自丢弃神经元机制，通过动态阈值调整和选择性脉冲抑制增强信息承载能力，并使用贝叶斯优化全局搜索时间参数。

Result: 在Fashion-MNIST、CIFAR-10和CIFAR-100数据集上，单时间步SNN的分类准确率分别为93.72%、92.20%和69.45%，能耗降低56%、21%和22%。

Conclusion: 该方法在保持或提升准确性的同时显著降低了能耗，适用于边缘计算场景。

Abstract: Spiking Neural Networks (SNNs), as an emerging biologically inspired
computational model, demonstrate significant energy efficiency advantages due
to their event-driven information processing mechanism. Compared to traditional
Artificial Neural Networks (ANNs), SNNs transmit information through discrete
spike signals, which substantially reduces computational energy consumption
through their sparse encoding approach. However, the multi-timestep computation
model significantly increases inference latency and energy, limiting the
applicability of SNNs in edge computing scenarios. We propose a single-timestep
SNN, which enhances accuracy and reduces computational energy consumption in a
single timestep by optimizing spike generation and temporal parameters. We
design a Self-Dropping Neuron mechanism, which enhances information-carrying
capacity through dynamic threshold adjustment and selective spike suppression.
Furthermore, we employ Bayesian optimization to globally search for time
parameters and obtain an efficient inference mode with a single time step.
Experimental results on the Fashion-MNIST, CIFAR-10, and CIFAR-100 datasets
demonstrate that, compared to traditional multi-timestep SNNs employing the
Leaky Integrate-and-Fire (LIF) model, our method achieves classification
accuracies of 93.72%, 92.20%, and 69.45%, respectively, using only
single-timestep spikes, while maintaining comparable or even superior accuracy.
Additionally, it reduces energy consumption by 56%, 21%, and 22%, respectively.

</details>


### [207] [Managing the unexpected: Operator behavioural data and its value in predicting correct alarm responses](https://arxiv.org/abs/2508.10917)
*Chidera W. Amazu,Joseph Mietkiewicz,Ammar N. Abbas,Gabriele Baldissone,Davide Fissore,Micaela Demichela,Anders L. Madsen,Maria Chiara Leva*

Main category: cs.HC

Relevance: 20.0

TL;DR: 该研究探讨了如何利用实时过程数据和操作员-系统交互数据预测操作员行为，而无需侵入性生理测量。


<details>
  <summary>Details</summary>
Motivation: 通过非侵入性方法（如控制系统的历史数据）预测操作员行为和性能，避免传统生理测量工具的干扰。

Method: 使用甲醛生产模拟器和四种人机实验配置，通过逐步逻辑回归和贝叶斯网络模型分析数据。

Result: 识别了一些预测性指标，可用于实时预测操作员在警报响应场景中的性能。

Conclusion: 实时行为指标有助于决策者预测结果并提供及时支持。

Abstract: Data from psychophysiological measures can offer new insight into control
room operators' behaviour, cognition, and mental workload status. This can be
particularly helpful when combined with appraisal of capacity to respond to
possible critical plant conditions (i.e. critical alarms response scenarios).
However, wearable physiological measurement tools such as eye tracking and EEG
caps can be perceived as intrusive and not suitable for usage in daily
operations. Therefore, this article examines the potential of using real-time
data from process and operator-system interactions during abnormal scenarios
that can be recorded and retrieved from the distributed control system's
historian or process log, and their capacity to provide insight into operator
behavior and predict their response outcomes, without intruding on daily tasks.
Data for this study were obtained from a design of experiment using a
formaldehyde production plant simulator and four human-in-the-loop experimental
support configurations. A comparison between the different configurations in
terms of both behaviour and performance is presented in this paper. A step-wise
logistic regression and a Bayesian network models were used to achieve this
objective. The results identified some predictive metrics and the paper discuss
their value as precursor or predictor of overall system performance in alarm
response scenarios. Knowledge of relevant and predictive behavioural metrics
accessible in real time can better equip decision-makers to predict outcomes
and provide timely support measures for operators.

</details>


### [208] [On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation](https://arxiv.org/abs/2508.11182)
*Matti Berthold,Lydia Blümel,Anna Rapberger*

Main category: cs.AI

Relevance: 10.0

TL;DR: 本文扩展了基于假设的论证（ABA）中可接受性概念的研究，引入了强和弱可接受性及其相关语义，并探讨了它们在非平坦ABA中的性质。


<details>
  <summary>Details</summary>
Motivation: 研究ABA中可接受性概念的替代方案，填补强可接受性在ABA中的研究空白，并扩展弱可接受性到非平坦ABA。

Method: 使用抽象双极集基论证框架（BSAFs）作为形式工具，分析强和弱可接受性在非平坦ABA中的性质。

Result: 证明了强和弱可接受性在非平坦ABA中保持模块化性质，但也指出了其局限性。

Conclusion: 强和弱可接受性在非平坦ABA中有一定价值，但仍需进一步研究以解决其局限性。

Abstract: In this work, we broaden the investigation of admissibility notions in the
context of assumption-based argumentation (ABA). More specifically, we study
two prominent alternatives to the standard notion of admissibility from
abstract argumentation, namely strong and weak admissibility, and introduce the
respective preferred, complete and grounded semantics for general (sometimes
called non-flat) ABA. To do so, we use abstract bipolar set-based argumentation
frameworks (BSAFs) as formal playground since they concisely capture the
relations between assumptions and are expressive enough to represent general
non-flat ABA frameworks, as recently shown. While weak admissibility has been
recently investigated for a restricted fragment of ABA in which assumptions
cannot be derived (flat ABA), strong admissibility has not been investigated
for ABA so far. We introduce strong admissibility for ABA and investigate
desirable properties. We furthermore extend the recent investigations of weak
admissibility in the flat ABA fragment to the non-flat case. We show that the
central modularization property is maintained under classical, strong, and weak
admissibility. We also show that strong and weakly admissible semantics in
non-flat ABA share some of the shortcomings of standard admissible semantics
and discuss ways to address these.

</details>


### [209] [A Weighted U Statistic for Genetic Association Analyses of Sequencing Data](https://arxiv.org/abs/1505.01204)
*Changshuai Wei,Ming Li,Zihuai He,Olga Vsevolozhskaya,Daniel J. Schaid,Qing Lu*

Main category: stat.ME

Relevance: 10.0

TL;DR: 开发了一种名为WU-seq的加权U统计方法，用于高维测序数据的关联分析，无需假设疾病模型或表型分布，并在模拟和实证研究中表现优于SKAT方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统统计方法在高维测序数据分析中因低频变异和极高维度导致的功效损失问题。

Method: 基于非参数U统计量开发了WU-seq方法，适用于多种表型且无需假设疾病模型或表型分布。

Result: WU-seq在假设被违反时优于SKAT，假设满足时性能相当，并在Dallas Heart Study中检测到ANGPTL4与极低密度脂蛋白胆固醇的关联。

Conclusion: WU-seq是一种灵活且强大的高维测序数据分析工具。

Abstract: With advancements in next generation sequencing technology, a massive amount
of sequencing data are generated, offering a great opportunity to
comprehensively investigate the role of rare variants in the genetic etiology
of complex diseases. Nevertheless, this poses a great challenge for the
statistical analysis of high-dimensional sequencing data. The association
analyses based on traditional statistical methods suffer substantial power loss
because of the low frequency of genetic variants and the extremely high
dimensionality of the data. We developed a weighted U statistic, referred to as
WU-seq, for the high-dimensional association analysis of sequencing data. Based
on a non-parametric U statistic, WU-SEQ makes no assumption of the underlying
disease model and phenotype distribution, and can be applied to a variety of
phenotypes. Through simulation studies and an empirical study, we showed that
WU-SEQ outperformed a commonly used SKAT method when the underlying assumptions
were violated (e.g., the phenotype followed a heavy-tailed distribution). Even
when the assumptions were satisfied, WU-SEQ still attained comparable
performance to SKAT. Finally, we applied WU-seq to sequencing data from the
Dallas Heart Study (DHS), and detected an association between ANGPTL 4 and very
low density lipoprotein cholesterol.

</details>


### [210] [Generalized Similarity U: A Non-parametric Test of Association Based on Similarity](https://arxiv.org/abs/1801.01220)
*Changshuai Wei,Qing Lu*

Main category: stat.ME

Relevance: 10.0

TL;DR: 该论文提出了一种基于相似性的测试方法GSU，用于复杂对象之间的关联测试，并在基因组关联研究中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决基因组关联研究中复杂对象（如基因型和表型）之间的关联测试问题。

Method: 提出广义相似性U（GSU）测试方法，使用拉普拉斯核相似性以提高功效和鲁棒性。

Result: GSU在模拟和实际数据（ADNI）中表现出优于现有方法的性能和鲁棒性，并识别出与阿尔茨海默病相关的基因。

Conclusion: GSU是一种有效的复杂对象关联测试工具，适用于基因组关联研究。

Abstract: Second generation sequencing technologies are being increasingly used for
genetic association studies, where the main research interest is to identify
sets of genetic variants that contribute to various phenotype. The phenotype
can be univariate disease status, multivariate responses and even
high-dimensional outcomes. Considering the genotype and phenotype as two
complex objects, this also poses a general statistical problem of testing
association between complex objects. We here proposed a similarity-based test,
generalized similarity U (GSU), that can test the association between complex
objects. We first studied the theoretical properties of the test in a general
setting and then focused on the application of the test to sequencing
association studies. Based on theoretical analysis, we proposed to use
Laplacian kernel based similarity for GSU to boost power and enhance
robustness. Through simulation, we found that GSU did have advantages over
existing methods in terms of power and robustness. We further performed a whole
genome sequencing (WGS) scan for Alzherimer Disease Neuroimaging Initiative
(ADNI) data, identifying three genes, APOE, APOC1 and TOMM40, associated with
imaging phenotype. We developed a C++ package for analysis of whole genome
sequencing data using GSU. The source codes can be downloaded at
https://github.com/changshuaiwei/gsu.

</details>


### [211] [Deep Learning-Based Automated Segmentation of Uterine Myomas](https://arxiv.org/abs/2508.11010)
*Tausifa Jan Saleem,Mohammad Yaqub*

Main category: eess.IV

Relevance: 10.0

TL;DR: 论文提出了一种基于深度学习的自动化子宫肌瘤分割方法，利用公开数据集UMD建立基准，以解决现有方法依赖私有数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 子宫肌瘤是女性生殖系统常见良性肿瘤，MRI分割需求高但人工操作耗时且易变，亟需自动化解决方案。

Method: 利用公开数据集UMD，采用深度学习算法进行子宫肌瘤的自动化分割。

Result: 建立了基于公开数据集的自动化分割基准，支持标准化评估。

Conclusion: 公开数据集的使用有助于推动子宫肌瘤分割研究的验证与比较。

Abstract: Uterine fibroids (myomas) are the most common benign tumors of the female
reproductive system, particularly among women of childbearing age. With a
prevalence exceeding 70%, they pose a significant burden on female reproductive
health. Clinical symptoms such as abnormal uterine bleeding, infertility,
pelvic pain, and pressure-related discomfort play a crucial role in guiding
treatment decisions, which are largely influenced by the size, number, and
anatomical location of the fibroids. Magnetic Resonance Imaging (MRI) is a
non-invasive and highly accurate imaging modality commonly used by clinicians
for the diagnosis of uterine fibroids. Segmenting uterine fibroids requires a
precise assessment of both the uterus and fibroids on MRI scans, including
measurements of volume, shape, and spatial location. However, this process is
labor intensive and time consuming and subjected to variability due to intra-
and inter-expert differences at both pre- and post-treatment stages. As a
result, there is a critical need for an accurate and automated segmentation
method for uterine fibroids. In recent years, deep learning algorithms have
shown re-markable improvements in medical image segmentation, outperforming
traditional methods. These approaches offer the potential for fully automated
segmentation. Several studies have explored the use of deep learning models to
achieve automated segmentation of uterine fibroids. However, most of the
previous work has been conducted using private datasets, which poses challenges
for validation and comparison between studies. In this study, we leverage the
publicly available Uterine Myoma MRI Dataset (UMD) to establish a baseline for
automated segmentation of uterine fibroids, enabling standardized evaluation
and facilitating future research in this domain.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [212] [BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale Pretraining](https://arxiv.org/abs/2508.10975)
*Pratyush Maini,Vineeth Dorna,Parth Doshi,Aldo Carranza,Fan Pan,Jack Urbanek,Paul Burstein,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Charvi Bannur,Christina Baek,Darren Teh,David Schwab,Haakon Mongstad,Haoli Yin,Josh Wills,Kaleigh Mentzer,Luke Merrick,Ricardo Monti,Rishabh Adiga,Siddharth Joshi,Spandan Das,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

Relevance: 90.0

TL;DR: BeyondWeb是一个高质量的合成数据生成框架，用于LLM预训练，显著优于现有合成数据集，并在训练速度和模型性能上取得突破。


<details>
  <summary>Details</summary>
Motivation: 解决预训练数据量增加带来的收益递减问题，探索合成数据在提升LLM性能中的作用。

Method: 开发BeyondWeb框架，生成高质量合成数据，并通过14项基准测试评估其性能。

Result: BeyondWeb在性能上超越现有合成数据集（如Cosmopedia和Nemotron-Synth），训练速度更快，小模型表现优于大模型。

Conclusion: 高质量合成数据需多因素联合优化，BeyondWeb展示了其潜力。

Abstract: Recent advances in large language model (LLM) pretraining have shown that
simply scaling data quantity eventually leads to diminishing returns, hitting a
data wall. In response, the use of synthetic data for pretraining has emerged
as a promising paradigm for pushing the frontier of performance. Despite this,
the factors affecting synthetic data quality remain poorly understood. In this
work, we introduce BeyondWeb, a synthetic data generation framework that
produces high-quality synthetic data for pretraining. BeyondWeb significantly
extends the capabilities of traditional web-scale datasets, outperforming
state-of-the-art synthetic pretraining datasets such as Cosmopedia and
Nemotron-CC's high-quality synthetic subset (Nemotron-Synth) by up to 5.1
percentage points (pp) and 2.6pp, respectively, when averaged across a suite of
14 benchmark evaluations. It delivers up to 7.7x faster training than open web
data and 2.7x faster than Nemotron-Synth. Remarkably, a 3B model trained for
180B tokens on BeyondWeb outperforms an 8B model trained for the same token
budget on Cosmopedia. We also present several insights from BeyondWeb on
synthetic data for pretraining: what drives its benefits, which data to
rephrase and how, and the impact of model size and family on data quality.
Overall, our work shows that there's no silver bullet for generating
high-quality synthetic pretraining data. The best outcomes require jointly
optimizing many factors, a challenging task that requires rigorous science and
practical expertise. Naive approaches can yield modest improvements,
potentially at great cost, while well-executed methods can yield transformative
improvements, as exemplified by BeyondWeb.

</details>


### [213] [Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing](https://arxiv.org/abs/2508.11258)
*Ruicheng Xian,Yuxuan Wan,Han Zhao*

Main category: cs.LG

Relevance: 90.0

TL;DR: 提出了一种通过提示从封闭权重LLM中提取公平分类器的方法，适用于高风险的公平性要求场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法适用于封闭权重LLM（如GPT-4），而公平性在高风险应用中至关重要。

Method: 将LLM视为特征提取器，通过设计提示获取概率预测特征，再训练轻量级公平分类器。

Result: 在五个数据集上验证了方法的高效性和优越性，尤其在数据效率和公平性-准确性权衡方面。

Conclusion: 该方法为封闭权重LLM提供了一种有效的公平分类解决方案，优于传统方法。

Abstract: Instruction fine-tuned large language models (LLMs) enable a simple zero-shot
or few-shot prompting paradigm, also known as in-context learning, for building
prediction models. This convenience, combined with continued advances in LLM
capability, has the potential to drive their adoption across a broad range of
domains, including high-stakes applications where group fairness -- preventing
disparate impacts across demographic groups -- is essential. The majority of
existing approaches to enforcing group fairness on LLM-based classifiers rely
on traditional fair algorithms applied via model fine-tuning or head-tuning on
final-layer embeddings, but they are no longer applicable to closed-weight LLMs
under the in-context learning setting, which include some of the most capable
commercial models today, such as GPT-4, Gemini, and Claude. In this paper, we
propose a framework for deriving fair classifiers from closed-weight LLMs via
prompting: the LLM is treated as a feature extractor, and features are elicited
from its probabilistic predictions (e.g., token log probabilities) using
prompts strategically designed for the specified fairness criterion to obtain
sufficient statistics for fair classification; a fair algorithm is then applied
to these features to train a lightweight fair classifier in a post-hoc manner.
Experiments on five datasets, including three tabular ones, demonstrate strong
accuracy-fairness tradeoffs for the classifiers derived by our framework from
both open-weight and closed-weight LLMs; in particular, our framework is
data-efficient and outperforms fair classifiers trained on LLM embeddings
(i.e., head-tuning) or from scratch on raw tabular features.

</details>


### [214] [On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting](https://arxiv.org/abs/2508.11408)
*Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.LG

Relevance: 90.0

TL;DR: 论文提出CHORD框架，通过动态权重统一监督微调（SFT）和强化学习（RL），解决现有方法在整合两者时可能破坏模型模式或过拟合专家数据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整合SFT和RL时存在破坏模型模式或过拟合专家数据的风险，需要一种更稳定的统一方法。

Method: 提出CHORD框架，通过动态权重将SFT作为RL的辅助目标，并引入双控制机制（全局系数和令牌级权重）平衡专家数据和探索。

Result: 实验表明CHORD实现了稳定高效的学习过程，显著优于基线方法。

Conclusion: CHORD通过动态权重和双控制机制有效统一了SFT和RL，提升了模型性能。

Abstract: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two
prominent post-training paradigms for refining the capabilities and aligning
the behavior of Large Language Models (LLMs). Existing approaches that
integrate SFT and RL often face the risk of disrupting established model
patterns and inducing overfitting to expert data. To address this, we present a
novel investigation into the unified view of SFT and RL through an off-policy
versus on-policy lens. We propose CHORD, a framework for the Controllable
Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic
Weighting, which reframes SFT not as a separate stage but as a dynamically
weighted auxiliary objective within the on-policy RL process. Based on an
analysis of off-policy expert data's influence at both holistic and granular
levels, we incorporate a dual-control mechanism in CHORD. Specifically, the
framework first employs a global coefficient to holistically guide the
transition from off-policy imitation to on-policy exploration, and then applies
a token-wise weighting function that enables granular learning from expert
tokens, which preserves on-policy exploration and mitigates disruption from
off-policy data. We conduct extensive experiments on widely used benchmarks,
providing empirical evidence that CHORD achieves a stable and efficient
learning process. By effectively harmonizing off-policy expert data with
on-policy exploration, CHORD demonstrates significant improvements over
baselines. We release the implementation at
https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to
inspire further research.

</details>


### [215] [Apriel-Nemotron-15B-Thinker](https://arxiv.org/abs/2508.10948)
*Shruthan Radhakrishna,Soham Parikh,Gopal Sarda,Anil Turkkan,Quaizar Vohra,Raymond Li,Dhruv Jhamb,Kelechi Ogueji,Aanjaneya Shukla,Oluwanifemi Bamgbose,Toby Liang,Luke Kumar,Oleksiy Ostapenko,Shiva Krishna Reddy Malay,Aman Tiwari,Tara Bogavelli,Vikas Yadav,Jash Mehta,Saloni Mittal,Akshay Kalkunte,Pulkit Pattnaik,Khalil Slimi,Anirudh Sreeram,Jishnu Nair,Akintunde Oladipo,Shashank Maiya,Khyati Mahajan,Rishabh Maheshwary,Masoud Hashemi,Sai Rajeswar Mudumba,Sathwik Tejaswi Madhusudhan,Torsten Scholak,Sebastien Paquet,Sagar Davasam,Srinivas Sunkara*

Main category: cs.LG

Relevance: 85.0

TL;DR: Apriel-Nemotron-15B-Thinker是一个15B参数的LLM，性能媲美32B参数模型，但内存占用减半。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在内存和计算成本上的限制，使其更适合企业应用。

Method: 采用四阶段训练流程：基础模型扩展、持续预训练、监督微调（SFT）和GRPO强化学习。

Result: 在多种基准测试中表现与32B参数模型相当或更好，内存占用减半。

Conclusion: Apriel-Nemotron-15B-Thinker展示了高效LLM设计的潜力，适合企业部署。

Abstract: While large language models (LLMs) have achieved remarkable reasoning
capabilities across domains like code, math and other enterprise tasks, their
significant memory and computational costs often preclude their use in
practical enterprise settings. To this end, we introduce
Apriel-Nemotron-15B-Thinker, a 15-billion parameter model in the ServiceNow
Apriel SLM series that achieves performance against medium sized
state-of-the-art models such as o1-mini, QWQ32B, and EXAONE-Deep-32B while
maintaining only half the memory footprint of those alternatives.
Apriel-Nemotron-15B-Thinker model is trained in a four stage training pipeline
including 1) Base Model upscaling, 2) Continual Pre-training 3) Supervised
Fine-tuning (SFT) and 4) Reinforcement Learning using GRPO. Comprehensive
evaluations across a diverse suite of benchmarks consistently demonstrate that
our Apriel-Nemotron-15B-Thinker model matches or exceeds the performance of its
32-billion parameter counterparts, despite being less than half their size.

</details>


### [216] [CURE: Critical-Token-Guided Re-concatenation for Entropy-collapse Prevention](https://arxiv.org/abs/2508.11016)
*Qingbin Li,Rongkun Xue,Jie Wang,Ming Zhou,Zhi Li,Xiaofeng Ji,Yongqi Wang,Miao Liu,Zheming Yang,Minghui Qiu,Jing Yang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出CURE框架，解决RLVR中静态初始状态采样导致的熵崩溃问题，通过两阶段方法平衡探索与利用，显著提升数学推理任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR中静态初始状态采样导致的熵崩溃问题，提升LLMs的推理能力和多样性。

Method: 提出CURE框架，分两阶段：1）高熵关键令牌再生优化轨迹；2）继续静态采样训练以增强利用。

Result: 在Qwen-2.5-Math-7B上，CURE在六个数学基准测试中性能提升5%，熵和准确率均达最优。

Conclusion: CURE有效解决了熵崩溃问题，平衡了探索与利用，显著提升了LLMs的推理性能。

Abstract: Recent advances in Reinforcement Learning with Verified Reward (RLVR) have
driven the emergence of more sophisticated cognitive behaviors in large
language models (LLMs), thereby enhancing their reasoning capabilities.
However, in prior RLVR pipelines, the repeated use of static initial-state
sampling drawn exactly from the dataset distribution during each sampling phase
produced overly deterministic, low diversity model behavior, which manifested
as rapid entropy collapse and hindered sustained performance gains during
prolonged training. To address this issue, we introduce CURE
(Critical-token-gUided Re concatenation for Entropy-collapse prevention), a
two-stage framework that balances exploration and exploitation. Specifically,
in the first stage, to deliberately steer the model toward novel yet coherent
contexts, we re-generate at high-entropy critical tokens and jointly optimize
the original and the branched trajectories. The further comparison with vanilla
DAPO shows that the regeneration process achieves a better performance on math
reasoning tasks while sustaining a high-level entropy degree for exploration.
In the second stage, we continue training with static initial-state sampling by
DAPO, intentionally placing the model in a familiar state to gradually
strengthen exploitation. Extensive experiments on Qwen-2.5-Math-7B show that,
compared to other RLVR methods, CURE achieves a 5% performance gain across six
math benchmarks, establishing state-of-the-art performance in both entropy and
accuracy. A series of experiments further validate the effectiveness of our
approach. Code is available at https://github.com/CURE-Project/CURE.

</details>


### [217] [ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism](https://arxiv.org/abs/2508.11356)
*Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu,TingTing Gao*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出了一种基于熵的机制（ETMR和EAR）来优化测试时强化学习（TTRL），解决了高推理成本和早期估计偏差问题，显著提升了模型在无监督场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在复杂推理任务中依赖标注数据且无监督适应性不足，测试时强化学习虽能自优化但面临高推理成本和估计偏差问题。

Method: 引入熵机制（ETMR和EAR）平衡探索与利用，提升推理效率和多样性。

Result: Llama3.1-8B在AIME 2024基准上相对提升68%（Pass at 1），同时仅消耗60%的推理预算。

Conclusion: 该方法有效优化了推理效率、多样性和估计稳健性，推动了无监督强化学习在开放域推理任务中的应用。

Abstract: Recent advancements in Large Language Models have yielded significant
improvements in complex reasoning tasks such as mathematics and programming.
However, these models remain heavily dependent on annotated data and exhibit
limited adaptability in unsupervised scenarios. To address these limitations,
test-time reinforcement learning (TTRL) has been proposed, which enables
self-optimization by leveraging model-generated pseudo-labels. Despite its
promise, TTRL faces several key challenges, including high inference costs due
to parallel rollouts and early-stage estimation bias that fosters
overconfidence, reducing output diversity and causing performance plateaus. To
address these challenges, we introduce an entropy-based mechanism to enhance
the exploration-exploitation balance in test-time reinforcement learning
through two strategies: Entropy-fork Tree Majority Rollout (ETMR) and
Entropy-based Advantage Reshaping (EAR). Compared with the baseline, our
approach enables Llama3.1-8B to achieve a 68 percent relative improvement in
Pass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of
the rollout tokens budget. This highlights our method's ability to effectively
optimize the trade-off between inference efficiency, diversity, and estimation
robustness, thereby advancing unsupervised reinforcement learning for
open-domain reasoning tasks.

</details>


### [218] [Fusing Rewards and Preferences in Reinforcement Learning](https://arxiv.org/abs/2508.11363)
*Sadegh Khorasani,Saber Salehkaleybar,Negar Kiyavash,Matthias Grossglauser*

Main category: cs.LG

Relevance: 85.0

TL;DR: DFA是一种强化学习算法，结合个体奖励和成对偏好，直接利用策略的对数概率建模偏好概率，避免单独奖励建模步骤。实验表明DFA在控制环境中表现优于或匹配SAC，并在半合成偏好数据上优于RLHF基线。


<details>
  <summary>Details</summary>
Motivation: 结合个体奖励和偏好反馈，简化强化学习中的奖励建模步骤，提高训练稳定性和性能。

Method: DFA算法融合个体奖励和成对偏好，直接利用策略对数概率建模偏好概率，支持人工标注或在线合成的偏好数据。

Result: DFA在六种控制环境中表现优于或匹配SAC，训练更稳定；在半合成偏好数据上优于RLHF基线，接近真实奖励的性能。

Conclusion: DFA通过融合奖励和偏好反馈，简化了强化学习流程，提升了性能和稳定性。

Abstract: We present Dual-Feedback Actor (DFA), a reinforcement learning algorithm that
fuses both individual rewards and pairwise preferences (if available) into a
single update rule. DFA uses the policy's log-probabilities directly to model
the preference probability, avoiding a separate reward-modeling step.
Preferences can be provided by human-annotators (at state-level or
trajectory-level) or be synthesized online from Q-values stored in an
off-policy replay buffer. Under a Bradley-Terry model, we prove that minimizing
DFA's preference loss recovers the entropy-regularized Soft Actor-Critic (SAC)
policy. Our simulation results show that DFA trained on generated preferences
matches or exceeds SAC on six control environments and demonstrates a more
stable training process. With only a semi-synthetic preference dataset under
Bradley-Terry model, our algorithm outperforms reward-modeling reinforcement
learning from human feedback (RLHF) baselines in a stochastic GridWorld and
approaches the performance of an oracle with true rewards.

</details>


### [219] [SHLIME: Foiling adversarial attacks fooling SHAP and LIME](https://arxiv.org/abs/2508.11053)
*Sam Chauhan,Estelle Duguet,Karthik Ramakrishnan,Hugh Van Deventer,Jack Kruger,Ranjan Subbaraman*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文研究了LIME和SHAP等事后解释方法在对抗性操纵下的脆弱性，并提出了一种模块化测试框架来评估增强和集成方法的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 揭示LIME和SHAP在检测模型偏见时的潜在漏洞，并探索提高其鲁棒性的策略。

Method: 复制COMPAS实验作为基线，引入模块化测试框架，评估多种LIME/SHAP集成配置在分布外模型上的表现。

Result: 发现某些集成配置能显著提高偏见检测能力，增强高风险机器学习系统的透明度。

Conclusion: 通过改进解释方法，可以更有效地揭示模型偏见，提升可信AI的部署。

Abstract: Post hoc explanation methods, such as LIME and SHAP, provide interpretable
insights into black-box classifiers and are increasingly used to assess model
biases and generalizability. However, these methods are vulnerable to
adversarial manipulation, potentially concealing harmful biases. Building on
the work of Slack et al. (2020), we investigate the susceptibility of LIME and
SHAP to biased models and evaluate strategies for improving robustness. We
first replicate the original COMPAS experiment to validate prior findings and
establish a baseline. We then introduce a modular testing framework enabling
systematic evaluation of augmented and ensemble explanation approaches across
classifiers of varying performance. Using this framework, we assess multiple
LIME/SHAP ensemble configurations on out-of-distribution models, comparing
their resistance to bias concealment against the original methods. Our results
identify configurations that substantially improve bias detection, highlighting
their potential for enhancing transparency in the deployment of high-stakes
machine learning systems.

</details>


### [220] [A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow](https://arxiv.org/abs/2508.11529)
*George Paterakis,Andrea Castellani,George Papoutsoglou,Tobias Rodemann,Ioannis Tsamardinos*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文提出了HXAI框架，将解释性嵌入数据分析的每个阶段，并针对用户需求定制解释。


<details>
  <summary>Details</summary>
Motivation: 解决AI模型被视为‘黑箱’的问题，提供更全面的解释性方法，增强信任。

Method: 提出HXAI框架，统一六个组件（数据、分析设置、学习过程、模型输出、模型质量、通信渠道），并结合用户需求设计问题库。

Result: HXAI框架通过结合多学科理论，提供清晰、可操作的解释，减少术语歧义，并展示LLM如何协调解释技术。

Conclusion: HXAI为透明、可信和负责任的AI部署提供了端到端的视角。

Abstract: Artificial intelligence is reshaping science and industry, yet many users
still regard its models as opaque "black boxes". Conventional explainable
artificial-intelligence methods clarify individual predictions but overlook the
upstream decisions and downstream quality checks that determine whether
insights can be trusted. In this work, we present Holistic Explainable
Artificial Intelligence (HXAI), a user-centric framework that embeds
explanation into every stage of the data-analysis workflow and tailors those
explanations to users. HXAI unifies six components (data, analysis set-up,
learning process, model output, model quality, communication channel) into a
single taxonomy and aligns each component with the needs of domain experts,
data analysts and data scientists. A 112-item question bank covers these needs;
our survey of contemporary tools highlights critical coverage gaps. Grounded in
theories of human explanation, principles from human-computer interaction and
findings from empirical user studies, HXAI identifies the characteristics that
make explanations clear, actionable and cognitively manageable. A comprehensive
taxonomy operationalises these insights, reducing terminological ambiguity and
enabling rigorous coverage analysis of existing toolchains. We further
demonstrate how AI agents that embed large-language models can orchestrate
diverse explanation techniques, translating technical artifacts into
stakeholder-specific narratives that bridge the gap between AI developers and
domain experts. Departing from traditional surveys or perspective articles,
this work melds concepts from multiple disciplines, lessons from real-world
projects and a critical synthesis of the literature to advance a novel,
end-to-end viewpoint on transparency, trustworthiness and responsible AI
deployment.

</details>


### [221] [Quantization vs Pruning: Insights from the Strong Lottery Ticket Hypothesis](https://arxiv.org/abs/2508.11020)
*Aakash Kumar,Emanuele Natale*

Main category: cs.LG

Relevance: 70.0

TL;DR: 该论文通过扩展强彩票假设（SLTH）到量化设置，证明了在有限精度网络中，目标离散神经网络可以被精确表示，并给出了初始网络过参数化的最优界限。


<details>
  <summary>Details</summary>
Motivation: 量化是提高神经网络效率的关键技术，但现有理论主要针对连续设置，无法直接应用于量化网络。本文旨在填补这一理论空白。

Method: 基于Borgs等人的数分割问题研究，推导了量化设置下的随机子集和问题新理论结果，并扩展SLTH框架到有限精度网络。

Result: 在量化设置下，目标离散神经网络可以被精确表示，且初始网络的过参数化界限是最优的。

Conclusion: 论文为量化神经网络的理论研究提供了新工具，并展示了SLTH在离散网络中的潜力。

Abstract: Quantization is an essential technique for making neural networks more
efficient, yet our theoretical understanding of it remains limited. Previous
works demonstrated that extremely low-precision networks, such as binary
networks, can be constructed by pruning large, randomly-initialized networks,
and showed that the ratio between the size of the original and the pruned
networks is at most polylogarithmic.
  The specific pruning method they employed inspired a line of theoretical work
known as the Strong Lottery Ticket Hypothesis (SLTH), which leverages insights
from the Random Subset Sum Problem. However, these results primarily address
the continuous setting and cannot be applied to extend SLTH results to the
quantized setting.
  In this work, we build on foundational results by Borgs et al. on the Number
Partitioning Problem to derive new theoretical results for the Random Subset
Sum Problem in a quantized setting.
  Using these results, we then extend the SLTH framework to finite-precision
networks. While prior work on SLTH showed that pruning allows approximation of
a certain class of neural networks, we demonstrate that, in the quantized
setting, the analogous class of target discrete neural networks can be
represented exactly, and we prove optimal bounds on the necessary
overparameterization of the initial network as a function of the precision of
the target network.

</details>


### [222] [Generalize across Homophily and Heterophily: Hybrid Spectral Graph Pre-Training and Prompt Tuning](https://arxiv.org/abs/2508.11328)
*Haitong Luo,Suhang Wang,Weiyao Zhang,Ruiqi Meng,Xuying Meng,Yujun Zhang*

Main category: cs.LG

Relevance: 70.0

TL;DR: 论文提出了一种名为HS-GPPT的新框架，通过频谱对齐解决图预训练和提示调优中因频谱分布差异导致的知识迁移问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖同质性低频知识，无法处理现实图中多样化的频谱分布，导致知识迁移效果不佳。

Method: 提出HS-GPPT框架，结合混合频谱滤波器主干和局部-全局对比学习，设计提示图以实现频谱对齐。

Result: 实验验证了HS-GPPT在转导和归纳学习设置下的有效性。

Conclusion: 频谱对齐是知识迁移的关键，HS-GPPT通过频谱对齐显著提升了性能。

Abstract: Graph ``pre-training and prompt-tuning'' aligns downstream tasks with
pre-trained objectives to enable efficient knowledge transfer under limited
supervision. However, existing methods rely on homophily-based low-frequency
knowledge, failing to handle diverse spectral distributions in real-world
graphs with varying homophily. Our theoretical analysis reveals a spectral
specificity principle: optimal knowledge transfer requires alignment between
pre-trained spectral filters and the intrinsic spectrum of downstream graphs.
Under limited supervision, large spectral gaps between pre-training and
downstream tasks impede effective adaptation. To bridge this gap, we propose
the HS-GPPT model, a novel framework that ensures spectral alignment throughout
both pre-training and prompt-tuning. We utilize a hybrid spectral filter
backbone and local-global contrastive learning to acquire abundant spectral
knowledge. Then we design prompt graphs to align the spectral distribution with
pretexts, facilitating spectral knowledge transfer across homophily and
heterophily. Extensive experiments validate the effectiveness under both
transductive and inductive learning settings. Our code is available at
https://anonymous.4open.science/r/HS-GPPT-62D2/.

</details>


### [223] [NeMo: A Neuron-Level Modularizing-While-Training Approach for Decomposing DNN Models](https://arxiv.org/abs/2508.11348)
*Xiaohan Bi,Binhang Qi,Hailong Sun,Xiang Gao,Yue Yu,Xiaojun Liang*

Main category: cs.LG

Relevance: 70.0

TL;DR: NeMo提出了一种可扩展且通用的模块化训练方法，适用于Transformer和CNN模型，通过对比学习和复合损失函数实现高效模块化。


<details>
  <summary>Details</summary>
Motivation: 解决现有模块化训练方法在小规模CNN上的局限性，特别是对大规模Transformer模型的适用性问题。

Method: 在神经元级别进行模块化训练，采用对比学习和复合损失函数，适用于多种DNN架构。

Result: 在Transformer和CNN模型上表现优异，模块分类准确率提升1.72%，模块大小减少58.10%。

Conclusion: NeMo为大规模DNN模块化提供了高效且通用的解决方案，具有实际应用潜力。

Abstract: With the growing incorporation of deep neural network (DNN) models into
modern software systems, the prohibitive construction costs have become a
significant challenge. Model reuse has been widely applied to reduce training
costs, but indiscriminately reusing entire models may incur significant
inference overhead. Consequently, DNN modularization has gained attention,
enabling module reuse by decomposing DNN models. The emerging
modularizing-while-training (MwT) paradigm, which incorporates modularization
into training, outperforms modularizing-after-training approaches. However,
existing MwT methods focus on small-scale CNN models at the convolutional
kernel level and struggle with diverse DNNs and large-scale models,
particularly Transformer-based models. To address these limitations, we propose
NeMo, a scalable and generalizable MwT approach. NeMo operates at the neuron
level fundamental component common to all DNNs-ensuring applicability to
Transformers and various architectures. We design a contrastive learning-based
modular training method with an effective composite loss function, enabling
scalability to large-scale models. Comprehensive experiments on two
Transformer-based models and four CNN models across two classification datasets
demonstrate NeMo's superiority over state-of-the-art MwT methods. Results show
average gains of 1.72% in module classification accuracy and 58.10% reduction
in module size, demonstrating efficacy across both CNN and large-scale
Transformer-based models. A case study on open-source projects shows NeMo's
potential benefits in practical scenarios, offering a promising approach for
scalable and generalizable DNN modularization.

</details>


### [224] [Informative Post-Hoc Explanations Only Exist for Simple Functions](https://arxiv.org/abs/2508.11441)
*Eric Günther,Balázs Szabados,Robi Bhattacharjee,Sebastian Bordt,Ulrike von Luxburg*

Main category: cs.LG

Relevance: 70.0

TL;DR: 该论文提出了一种基于学习理论的框架，用于定义解释算法是否提供决策函数的信息，并证明许多流行算法在复杂模型下不具信息性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决现有局部事后解释算法在复杂机器学习模型中的理论保证不足问题。

Method: 方法是通过学习理论框架分析解释算法的信息性，并推导其有效条件。

Result: 结果显示许多流行解释算法（如梯度解释、SHAP等）在复杂模型下不具信息性，并提出了改进条件。

Conclusion: 结论是解释算法的实用性需基于更强的假设，对AI审计和高风险应用有重要影响。

Abstract: Many researchers have suggested that local post-hoc explanation algorithms
can be used to gain insights into the behavior of complex machine learning
models. However, theoretical guarantees about such algorithms only exist for
simple decision functions, and it is unclear whether and under which
assumptions similar results might exist for complex models. In this paper, we
introduce a general, learning-theory-based framework for what it means for an
explanation to provide information about a decision function. We call an
explanation informative if it serves to reduce the complexity of the space of
plausible decision functions. With this approach, we show that many popular
explanation algorithms are not informative when applied to complex decision
functions, providing a rigorous mathematical rejection of the idea that it
should be possible to explain any model. We then derive conditions under which
different explanation algorithms become informative. These are often stronger
than what one might expect. For example, gradient explanations and
counterfactual explanations are non-informative with respect to the space of
differentiable functions, and SHAP and anchor explanations are not informative
with respect to the space of decision trees. Based on these results, we discuss
how explanation algorithms can be modified to become informative. While the
proposed analysis of explanation algorithms is mathematical, we argue that it
holds strong implications for the practical applicability of these algorithms,
particularly for auditing, regulation, and high-risk applications of AI.

</details>


### [225] [SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving Bubble-Free Pipelines via Tag Scheduling](https://arxiv.org/abs/2508.11553)
*Jinghui Wang,Shaojie Wang,Yinghan Cui,Xuxing Chen,Chao Wang,Xiaojiang Zhang,Minglei Zhang,Jiarong Zhang,Wenhao Zhuang,Yuchen Cao,Wankang Bao,Haimo Li,Zheng Lin,Huiming Wang,Haoyang Huang,Zongxian Feng,Zizheng Zhan,Ken Deng,Wen Xiang,Huaixi Tang,Kun Wu,Mengtong Li,Mengfei Xie,Junyi Peng,Haotian Zhang,Bin Chen,Bing Yu*

Main category: cs.LG

Relevance: 70.0

TL;DR: SeamlessFlow是一个基于服务器的强化学习框架，解决了工业规模RL中的两个核心挑战：解耦RL训练与复杂代理执行流程，以及最大化GPU利用率。


<details>
  <summary>Details</summary>
Motivation: 工业规模RL中，训练与代理执行的耦合以及GPU利用率低是主要问题。

Method: 1. 数据平面解耦RL训练与代理实现；2. 基于标签的调度范式动态分配资源。

Result: SeamlessFlow实现了稳定性和高性能，适用于多代理和复杂RL任务。

Conclusion: SeamlessFlow通过创新设计解决了工业RL的挑战，适合大规模部署。

Abstract: We introduce SeamlessFlow, a server based reinforcement learning (RL)
framework that addresses two core challenges in industrial scale RL: (1)
decoupling RL training from the complex execution flow of agents; (2)
maximizing GPU utilization with minimal idle time while preserving the
stability and scalability required for large-scale deployments. First,
SeamlessFlow introduces a data plane that decouples the RL trainer from
diverse, complex agent implementations while sustaining high throughput. A
central trajectory manager maintains complete interaction histories and
supports partial rollout, allowing rollout to pause for weight updates and
resume seamlessly, keeping agents unaware of service interruptions. Second, we
propose a tag driven scheduling paradigm that abstracts hardware into
capability tagged resources, unifying colocated and disaggregated
architectures. Based on this, SeamlessFlow introduces a spatiotemporal
multiplexing pipeline that dynamically reassigns idle training nodes to rollout
in a train rollout separated setup, eliminating pipeline bubbles and fully
exploiting heterogeneous cluster resources. By combining these innovations,
SeamlessFlow delivers both stability and high performance, making it well
suited for multi agent, long horizon, and other complex RL tasks.

</details>


### [226] [Towards Efficient Prompt-based Continual Learning in Distributed Medical AI](https://arxiv.org/abs/2508.10954)
*Gyutae Oh,Jitae Shin*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种基于提示的持续学习方法（PCL），用于解决医疗领域数据共享受限的问题，通过统一的提示池和最小扩展策略，显著提升了分类准确性和F1分数。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的数据共享受到伦理、社会和制度限制，传统集中式学习难以实现，且持续学习在医疗领域的应用尚未充分探索。

Method: 采用基于提示的持续学习方法（PCL），通过扩展和冻结部分提示池，结合新颖的正则化项平衡知识保留和适应。

Result: 在三个糖尿病视网膜病变数据集上，PCL方法比现有方法分类准确性提高至少10%，F1分数提高9分，同时降低推理成本。

Conclusion: PCL方法为医疗领域的可持续AI发展提供了可能，支持实时诊断和远程医疗应用。

Abstract: Modern AI models achieve state-of-the-art performance with large-scale,
high-quality datasets; however, ethical, social, and institutional constraints
in the medical domain severely restrict data sharing, rendering centralized
learning nearly impossible. Each institution must incrementally update models
using only local data. Traditional training overfits new samples and suffers
from catastrophic forgetting, losing previously acquired knowledge. Medical
data distributions also shift due to varying diagnostic equipment and
demographics. Although continual learning (CL) has advanced, most methods
address natural images, leaving medical-domain-specific CL underexplored. We
propose a prompt-based continual learning (PCL) approach featuring a unified
prompt pool with a minimal expansion strategy: by expanding and freezing a
subset of prompts, our method reduces computational overhead, and a novel
regularization term balances retention and adaptation. Experiments on three
diabetic retinopathy datasets Aptos2019, LI2019, and Diabetic Retinopathy
Detection show our model improves final classification accuracy by at least 10%
and F1-score by 9 points over state-of-the-art approaches while lowering
inference cost. We anticipate this study will drive sustainable medical AI
advances, enabling real-time diagnosis, patient monitoring, and telemedicine
applications in distributed healthcare. Code will be released upon acceptance

</details>


### [227] [Retro-Expert: Collaborative Reasoning for Interpretable Retrosynthesis](https://arxiv.org/abs/2508.10967)
*Xinyi Li,Sai Wang,Yutian Lin,Yu Wu,Yi Yang*

Main category: cs.LG

Relevance: 60.0

TL;DR: Retro-Expert是一个可解释的逆合成框架，结合LLM和专用模型通过强化学习进行协作推理，提供自然语言解释。


<details>
  <summary>Details</summary>
Motivation: 现有逆合成模型依赖静态模式匹配，缺乏逻辑决策能力，导致黑箱决策。

Method: 结合专用模型（浅层推理）、LLM（关键推理）和强化学习（优化决策策略）。

Result: 性能超越LLM和专用模型，并提供专家认可的解释。

Conclusion: Retro-Expert在性能和可解释性上均优于现有方法。

Abstract: Retrosynthesis prediction aims to infer the reactant molecule based on a
given product molecule, which is a fundamental task in chemical synthesis.
However, existing models rely on static pattern-matching paradigm, which limits
their ability to perform effective logic decision-making, leading to black-box
decision-making. Building on this, we propose Retro-Expert, an interpretable
retrosynthesis framework that performs collaborative reasoning by combining the
complementary reasoning strengths of Large Language Models and specialized
models via reinforcement learning. It outputs natural language explanations
grounded in chemical logic through three components: (1) specialized models
perform shallow reasoning to construct high-quality chemical decision space,
(2) LLM-driven critical reasoning to generate predictions and corresponding
interpretable reasoning path, and (3) reinforcement learning optimizing
interpretable decision policy. Experiments show that Retro-Expert not only
surpasses both LLM-based and specialized models across different metrics but
also provides expert-aligned explanations that bridge the gap between AI
predictions and actionable chemical insights.

</details>


### [228] [Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks](https://arxiv.org/abs/2508.11025)
*Laura Lützow,Michael Eichelbeck,Mykel J. Kochenderfer,Matthias Althoff*

Main category: cs.LG

Relevance: 60.0

TL;DR: 提出了一种名为zono-conformal prediction的新方法，通过构建预测zonotopes来解决传统区间预测的计算和数据密集型问题，并提供了统计覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 传统不确定性量化方法计算成本高且数据密集，且多维度输出依赖关系捕捉能力有限。

Method: 引入zono-conformal prediction，利用线性程序直接构建zonotopic不确定性集，适用于非线性基础预测器。

Result: 实验表明，zono-conformal predictors比传统方法更高效且覆盖性相当。

Conclusion: zono-conformal prediction是一种高效且覆盖性好的不确定性量化方法。

Abstract: Conformal prediction is a popular uncertainty quantification method that
augments a base predictor with prediction sets with statistically valid
coverage guarantees. However, current methods are often computationally
expensive and data-intensive, as they require constructing an uncertainty model
before calibration. Moreover, existing approaches typically represent the
prediction sets with intervals, which limits their ability to capture
dependencies in multi-dimensional outputs. We address these limitations by
introducing zono-conformal prediction, a novel approach inspired by interval
predictor models and reachset-conformant identification that constructs
prediction zonotopes with assured coverage. By placing zonotopic uncertainty
sets directly into the model of the base predictor, zono-conformal predictors
can be identified via a single, data-efficient linear program. While we can
apply zono-conformal prediction to arbitrary nonlinear base predictors, we
focus on feed-forward neural networks in this work. Aside from regression
tasks, we also construct optimal zono-conformal predictors in classification
settings where the output of an uncertain predictor is a set of possible
classes. We provide probabilistic coverage guarantees and present methods for
detecting outliers in the identification data. In extensive numerical
experiments, we show that zono-conformal predictors are less conservative than
interval predictor models and standard conformal prediction methods, while
achieving a similar coverage over the test data.

</details>


### [229] [Compressive Meta-Learning](https://arxiv.org/abs/2508.11090)
*Daniel Mas Montserrat,David Bonet,Maria Perera,Xavier Giró-i-Nieto,Alexander G. Ioannidis*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种基于元学习的压缩学习框架，通过神经网络优化编码和解码阶段，提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着数据集规模扩大，需要快速高效的参数学习技术。现有压缩学习方法未能充分利用数据结构。

Method: 使用神经网络元学习压缩学习的编码和解码阶段，应用于多种任务如PCA、岭回归、k均值和自编码器。

Result: 提出的框架在速度和准确性上优于现有方法。

Conclusion: 压缩元学习框架为高效和隐私友好的学习提供了新途径。

Abstract: The rapid expansion in the size of new datasets has created a need for fast
and efficient parameter-learning techniques. Compressive learning is a
framework that enables efficient processing by using random, non-linear
features to project large-scale databases onto compact, information-preserving
representations whose dimensionality is independent of the number of samples
and can be easily stored, transferred, and processed. These database-level
summaries are then used to decode parameters of interest from the underlying
data distribution without requiring access to the original samples, offering an
efficient and privacy-friendly learning framework. However, both the encoding
and decoding techniques are typically randomized and data-independent, failing
to exploit the underlying structure of the data. In this work, we propose a
framework that meta-learns both the encoding and decoding stages of compressive
learning methods by using neural networks that provide faster and more accurate
systems than the current state-of-the-art approaches. To demonstrate the
potential of the presented Compressive Meta-Learning framework, we explore
multiple applications -- including neural network-based compressive PCA,
compressive ridge regression, compressive k-means, and autoencoders.

</details>


### [230] [Conformal Prediction Meets Long-tail Classification](https://arxiv.org/abs/2508.11345)
*Shuqi Liu,Jianguo Huang,Luke Ong*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种尾部感知的Conformal Prediction方法（TACP），通过利用长尾结构减少头尾类别的覆盖差距，并进一步提出软TACP（sTACP）以优化覆盖平衡。


<details>
  <summary>Details</summary>
Motivation: 现有CP方法在长尾标签分布下对尾部类别的覆盖不足，影响预测集的可靠性。

Method: 提出TACP和sTACP，利用长尾结构和重加权机制优化覆盖平衡。

Result: 理论分析和实验表明，TACP和sTACP能显著缩小头尾覆盖差距，并在多个长尾基准数据集上表现优异。

Conclusion: TACP和sTACP有效解决了长尾分布下的覆盖不平衡问题，提升了预测集的可靠性。

Abstract: Conformal Prediction (CP) is a popular method for uncertainty quantification
that converts a pretrained model's point prediction into a prediction set, with
the set size reflecting the model's confidence. Although existing CP methods
are guaranteed to achieve marginal coverage, they often exhibit imbalanced
coverage across classes under long-tail label distributions, tending to over
cover the head classes at the expense of under covering the remaining tail
classes. This under coverage is particularly concerning, as it undermines the
reliability of the prediction sets for minority classes, even with coverage
ensured on average. In this paper, we propose the Tail-Aware Conformal
Prediction (TACP) method to mitigate the under coverage of the tail classes by
utilizing the long-tail structure and narrowing the head-tail coverage gap.
Theoretical analysis shows that it consistently achieves a smaller head-tail
coverage gap than standard methods. To further improve coverage balance across
all classes, we introduce an extension of TACP: soft TACP (sTACP) via a
reweighting mechanism. The proposed framework can be combined with various
non-conformity scores, and experiments on multiple long-tail benchmark datasets
demonstrate the effectiveness of our methods.

</details>


### [231] [A Remedy for Over-Squashing in Graph Learning via Forman-Ricci Curvature based Graph-to-Hypergraph Structural Lifting](https://arxiv.org/abs/2508.11390)
*Michael Banf,Dominik Filipiak,Max Schattauer,Liliya Imasheva*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种基于Forman-Ricci曲率的结构提升策略，用于解决图神经网络中长距离信息传递的失真问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的复杂交互（如社交或生物网络）需要更高阶的拓扑表示，而传统图神经网络在处理此类问题时存在信息失真（如过度挤压）。

Method: 利用Forman-Ricci曲率定义边基网络特性，将数据表示从基本图形式提升到更具表达力的拓扑结构，再应用GNN模型。

Result: 该方法能够揭示图的局部和全局特性（如网络主干），并通过超边建模信息流，缓解长距离信息传递的失真问题。

Conclusion: 基于曲率的提升策略为图学习中的信息失真问题提供了有效解决方案。

Abstract: Graph Neural Networks are highly effective at learning from relational data,
leveraging node and edge features while maintaining the symmetries inherent to
graph structures. However, many real-world systems, such as social or
biological networks, exhibit complex interactions that are more naturally
represented by higher-order topological domains. The emerging field of
Geometric and Topological Deep Learning addresses this challenge by introducing
methods that utilize and benefit from higher-order structures. Central to TDL
is the concept of lifting, which transforms data representations from basic
graph forms to more expressive topologies before the application of GNN models
for learning. In this work, we propose a structural lifting strategy using
Forman-Ricci curvature, which defines an edge-based network characteristic
based on Riemannian geometry. Curvature reveals local and global properties of
a graph, such as a network's backbones, i.e. coarse, structure-preserving graph
geometries that form connections between major communities - most suitably
represented as hyperedges to model information flows between clusters across
large distances in the network. To this end, our approach provides a remedy to
the problem of information distortion in message passing across long distances
and graph bottlenecks - a phenomenon known in graph learning as over-squashing.

</details>


### [232] [Robust Convolution Neural ODEs via Contractivity-promoting regularization](https://arxiv.org/abs/2508.11432)
*Muhammad Zakwan,Liang Xu,Giancarlo Ferrari-Trecate*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种基于收缩理论的卷积神经常微分方程（NODE）方法，通过正则化提高模型对输入噪声和对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 神经网络对输入噪声和对抗攻击较为脆弱，作者希望通过收缩理论提升卷积NODE的鲁棒性。

Method: 使用收缩理论，通过在训练中引入涉及系统动力学雅可比矩阵的正则化项，或针对特定NODE类使用权重正则化项，诱导模型收缩性。

Result: 在MNIST和FashionMNIST数据集上验证了方法的有效性，模型对噪声和攻击的鲁棒性显著提升。

Conclusion: 提出的正则化方法能有效增强卷积NODE的鲁棒性，适用于对抗环境下的图像分类任务。

Abstract: Neural networks can be fragile to input noise and adversarial attacks.
  In this work, we consider Convolutional Neural Ordinary Differential
Equations (NODEs), a family of continuous-depth neural networks represented by
dynamical systems, and propose to use contraction theory to improve their
robustness.
  For a contractive dynamical system two trajectories starting from different
initial conditions converge to each other exponentially fast.
  Contractive Convolutional NODEs can enjoy increased robustness as slight
perturbations of the features do not cause a significant change in the output.
  Contractivity can be induced during training by using a regularization term
involving the Jacobian of the system dynamics.
  To reduce the computational burden, we show that it can also be promoted
using carefully selected weight regularization terms for a class of NODEs with
slope-restricted activation functions.
  The performance of the proposed regularizers is illustrated through benchmark
image classification tasks on MNIST and FashionMNIST datasets, where images are
corrupted by different kinds of noise and attacks.

</details>


### [233] [DiCriTest: Testing Scenario Generation for Decision-Making Agents Considering Diversity and Criticality](https://arxiv.org/abs/2508.11514)
*Qitong Chu,Yufeng Yue,Danya Yao,Huaxin Pei*

Main category: cs.LG

Relevance: 60.0

TL;DR: 提出了一种双空间引导的测试框架，用于生成多样性和关键性平衡的测试场景，通过协调场景参数空间和智能体行为空间，显著提升了关键场景生成的效果。


<details>
  <summary>Details</summary>
Motivation: 动态环境中决策智能体的部署增加，安全验证需求上升，现有方法在多样性和关键性平衡方面存在挑战。

Method: 采用双空间引导框架，结合场景参数空间的层次表示和智能体行为空间的数据反馈，动态协调局部扰动和全局探索两种生成模式。

Result: 实验表明，该框架在五个决策智能体上平均提升关键场景生成56.23%，并在新指标下表现出更高的多样性。

Conclusion: 该框架有效解决了高维场景空间中的局部最优问题，为安全验证提供了更优的测试场景生成方法。

Abstract: The growing deployment of decision-making agents in dynamic environments
increases the demand for safety verification. While critical testing scenario
generation has emerged as an appealing verification methodology, effectively
balancing diversity and criticality remains a key challenge for existing
methods, particularly due to local optima entrapment in high-dimensional
scenario spaces. To address this limitation, we propose a dual-space guided
testing framework that coordinates scenario parameter space and agent behavior
space, aiming to generate testing scenarios considering diversity and
criticality. Specifically, in the scenario parameter space, a hierarchical
representation framework combines dimensionality reduction and
multi-dimensional subspace evaluation to efficiently localize diverse and
critical subspaces. This guides dynamic coordination between two generation
modes: local perturbation and global exploration, optimizing critical scenario
quantity and diversity. Complementarily, in the agent behavior space,
agent-environment interaction data are leveraged to quantify behavioral
criticality/diversity and adaptively support generation mode switching, forming
a closed feedback loop that continuously enhances scenario characterization and
exploration within the parameter space. Experiments show our framework improves
critical scenario generation by an average of 56.23\% and demonstrates greater
diversity under novel parameter-behavior co-driven metrics when tested on five
decision-making agents, outperforming state-of-the-art baselines.

</details>


### [234] [Finite-Width Neural Tangent Kernels from Feynman Diagrams](https://arxiv.org/abs/2508.11522)
*Max Guillen,Philipp Misof,Jan E. Gerken*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种用费曼图计算有限宽度修正的方法，以分析神经网络的训练动态，并验证了其在深度网络稳定性分析中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决无限宽度下NTK无法捕捉训练动态（如特征学习）的问题，通过引入有限宽度修正来更准确地描述实际训练过程。

Method: 方法包括使用费曼图计算有限宽度修正，推导层间递归关系，并分析预激活、NTK及其高阶导数张量的统计特性。

Result: 结果显示该方法能有效扩展深度网络的稳定性分析至NTK，并证明ReLU等尺度不变非线性在NTK Gram矩阵对角线上无有限宽度修正。

Conclusion: 结论表明费曼图方法简化了有限宽度修正的计算，为理解神经网络训练动态提供了新工具。

Abstract: Neural tangent kernels (NTKs) are a powerful tool for analyzing deep,
non-linear neural networks. In the infinite-width limit, NTKs can easily be
computed for most common architectures, yielding full analytic control over the
training dynamics. However, at infinite width, important properties of training
such as NTK evolution or feature learning are absent. Nevertheless, finite
width effects can be included by computing corrections to the Gaussian
statistics at infinite width. We introduce Feynman diagrams for computing
finite-width corrections to NTK statistics. These dramatically simplify the
necessary algebraic manipulations and enable the computation of layer-wise
recursive relations for arbitrary statistics involving preactivations, NTKs and
certain higher-derivative tensors (dNTK and ddNTK) required to predict the
training dynamics at leading order. We demonstrate the feasibility of our
framework by extending stability results for deep networks from preactivations
to NTKs and proving the absence of finite-width corrections for scale-invariant
nonlinearities such as ReLU on the diagonal of the Gram matrix of the NTK. We
validate our results with numerical experiments.

</details>


### [235] [Human-in-the-Loop Systems for Adaptive Learning Using Generative AI](https://arxiv.org/abs/2508.11062)
*Bhavishya Tarun,Haoze Du,Dinesh Kannan,Edward F. Gehringer*

Main category: cs.HC

Relevance: 60.0

TL;DR: 论文提出了一种基于人机交互（HITL）的方法，通过学生反馈优化生成式AI的个性化学习效果，提升STEM教育的参与度和学习成果。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过学生直接反馈优化AI生成的学习内容，以增强个性化学习和学生参与度。

Method: 使用反馈标签和提示工程，结合检索增强生成（RAG）系统，实时调整AI生成的教育内容。

Result: 初步研究表明，与传统AI工具相比，该方法提高了STEM学生的学习效果和信心。

Conclusion: 通过迭代反馈优化，AI可以创建动态、个性化的学习环境。

Abstract: A Human-in-the-Loop (HITL) approach leverages generative AI to enhance
personalized learning by directly integrating student feedback into
AI-generated solutions. Students critique and modify AI responses using
predefined feedback tags, fostering deeper engagement and understanding. This
empowers students to actively shape their learning, with AI serving as an
adaptive partner. The system uses a tagging technique and prompt engineering to
personalize content, informing a Retrieval-Augmented Generation (RAG) system to
retrieve relevant educational material and adjust explanations in real time.
This builds on existing research in adaptive learning, demonstrating how
student-driven feedback loops can modify AI-generated responses for improved
student retention and engagement, particularly in STEM education. Preliminary
findings from a study with STEM students indicate improved learning outcomes
and confidence compared to traditional AI tools. This work highlights AI's
potential to create dynamic, feedback-driven, and personalized learning
environments through iterative refinement.

</details>


### [236] [A Cooperative Game-Based Multi-Criteria Weighted Ensemble Approach for Multi-Class Classification](https://arxiv.org/abs/2508.10926)
*DongSeong-Yoon*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种基于合作博弈的多准则投票集成方法，通过同时考虑多种先验信息来优化权重分配，提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有投票集成方法仅考虑单一评估准则，无法充分利用多种先验信息。本文旨在通过合作博弈解决这一问题。

Method: 提出了一种多准则合作博弈方法，用于投票集成中的权重分配，同时考虑多种先验信息。

Result: 在Open-ML-CC18数据集上的实验表明，该方法优于其他权重分配方法。

Conclusion: 多准则合作博弈方法能有效提升投票集成的性能，适用于复杂信息场景。

Abstract: Since the Fourth Industrial Revolution, AI technology has been widely used in
many fields, but there are several limitations that need to be overcome,
including overfitting/underfitting, class imbalance, and the limitations of
representation (hypothesis space) due to the characteristics of different
models. As a method to overcome these problems, ensemble, commonly known as
model combining, is being extensively used in the field of machine learning.
Among ensemble learning methods, voting ensembles have been studied with
various weighting methods, showing performance improvements. However, the
existing methods that reflect the pre-information of classifiers in weights
consider only one evaluation criterion, which limits the reflection of various
information that should be considered in a model realistically. Therefore, this
paper proposes a method of making decisions considering various information
through cooperative games in multi-criteria situations. Using this method,
various types of information known beforehand in classifiers can be
simultaneously considered and reflected, leading to appropriate weight
distribution and performance improvement. The machine learning algorithms were
applied to the Open-ML-CC18 dataset and compared with existing ensemble
weighting methods. The experimental results showed superior performance
compared to other weighting methods.

</details>


### [237] [Match & Choose: Model Selection Framework for Fine-tuning Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.10993)
*Basile Lewandowski,Robert Birke,Lydia Y. Chen*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种名为M&C的模型选择框架，帮助用户从模型平台中选择最适合目标数据域的预训练T2I模型，无需对所有模型进行微调。


<details>
  <summary>Details</summary>
Motivation: 预训练T2I模型的广泛共享带来了模型选择的挑战，现有方法在分类任务中已有研究，但在T2I模型中尚未解决。

Method: 构建匹配图（包含模型和数据集节点及性能/相似性边），基于图嵌入特征预测最佳微调模型。

Result: 在10个T2I模型和32个数据集上测试，M&C成功预测最佳模型的比例为61.3%，其余情况下也能预测接近最佳模型。

Conclusion: M&C为预训练T2I模型的快速选择提供了有效解决方案。

Abstract: Text-to-image (T2I) models based on diffusion and transformer architectures
advance rapidly. They are often pretrained on large corpora, and openly shared
on a model platform, such as HuggingFace. Users can then build up AI
applications, e.g., generating media contents, by adopting pretrained T2I
models and fine-tuning them on the target dataset. While public pretrained T2I
models facilitate the democratization of the models, users face a new
challenge: which model can be best fine-tuned based on the target data domain?
Model selection is well addressed in classification tasks, but little is known
in (pretrained) T2I models and their performance indication on the target
domain. In this paper, we propose the first model selection framework, M&C,
which enables users to efficiently choose a pretrained T2I model from a model
platform without exhaustively fine-tuning them all on the target dataset. The
core of M&C is a matching graph, which consists of: (i) nodes of available
models and profiled datasets, and (ii) edges of model-data and data-data pairs
capturing the fine-tuning performance and data similarity, respectively. We
then build a model that, based on the inputs of model/data feature, and,
critically, the graph embedding feature, extracted from the matching graph,
predicts the model achieving the best quality after fine-tuning for the target
domain. We evaluate M&C on choosing across ten T2I models for 32 datasets
against three baselines. Our results show that M&C successfully predicts the
best model for fine-tuning in 61.3% of the cases and a closely performing model
for the rest.

</details>


### [238] [Learning with Confidence](https://arxiv.org/abs/2508.11037)
*Oliver Ethan Richardson*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文探讨了学习或更新信念中的‘信心’概念，区分了它与概率或似然的不同，并提出了两种测量方法。


<details>
  <summary>Details</summary>
Motivation: 研究学习过程中的信心概念，澄清其与概率的区别，并提供形式化定义和测量方法。

Method: 通过公理化定义学习中的信心，提出两种连续测量方法，并证明其普适性。在附加假设下，推导出更简洁的表示形式。

Result: 证明了信心可以连续表示，并推导出基于向量场和损失函数的紧凑表示。

Conclusion: 信心是学习中的独立概念，Bayes规则是其特例。

Abstract: We characterize a notion of confidence that arises in learning or updating
beliefs: the amount of trust one has in incoming information and its impact on
the belief state. This learner's confidence can be used alongside (and is
easily mistaken for) probability or likelihood, but it is fundamentally a
different concept -- one that captures many familiar concepts in the
literature, including learning rates and number of training epochs, Shafer's
weight of evidence, and Kalman gain. We formally axiomatize what it means to
learn with confidence, give two canonical ways of measuring confidence on a
continuum, and prove that confidence can always be represented in this way.
Under additional assumptions, we derive more compact representations of
confidence-based learning in terms of vector fields and loss functions. These
representations induce an extended language of compound "parallel"
observations. We characterize Bayes Rule as the special case of an optimizing
learner whose loss representation is a linear expectation.

</details>


### [239] [Abundance-Aware Set Transformer for Microbiome Sample Embedding](https://arxiv.org/abs/2508.11075)
*Hyunwoo Yoo,Gail Rosen*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于丰度感知的Set Transformer方法，用于构建微生物组样本的固定大小嵌入，通过加权序列嵌入来反映其相对丰度，显著提升了分类任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有微生物组样本嵌入方法多采用简单平均，忽略了分类群丰度的生物学重要性，因此需要一种更生物信息化的表示方法。

Method: 提出丰度感知的Set Transformer，通过复制嵌入向量并按丰度加权，利用自注意力机制进行聚合。

Result: 在真实微生物组分类任务中，该方法优于平均池化和未加权的Set Transformer，某些情况下达到完美性能。

Conclusion: 丰度感知聚合方法能提供更稳健且生物信息化的微生物组表示，是首个将序列丰度整合到基于Transformer的样本嵌入中的方法之一。

Abstract: Microbiome sample representation to input into LLMs is essential for
downstream tasks such as phenotype prediction and environmental classification.
While prior studies have explored embedding-based representations of each
microbiome sample, most rely on simple averaging over sequence embeddings,
often overlooking the biological importance of taxa abundance. In this work, we
propose an abundance-aware variant of the Set Transformer to construct
fixed-size sample-level embeddings by weighting sequence embeddings according
to their relative abundance. Without modifying the model architecture, we
replicate embedding vectors proportional to their abundance and apply
self-attention-based aggregation. Our method outperforms average pooling and
unweighted Set Transformers on real-world microbiome classification tasks,
achieving perfect performance in some cases. These results demonstrate the
utility of abundance-aware aggregation for robust and biologically informed
microbiome representation. To the best of our knowledge, this is one of the
first approaches to integrate sequence-level abundance into Transformer-based
sample embeddings.

</details>


### [240] [Relative Advantage Debiasing for Watch-Time Prediction in Short-Video Recommendation](https://arxiv.org/abs/2508.11086)
*Emily Liu,Kuan Han,Minfeng Zhan,Bocheng Zhao,Guanyu Mu,Yang Song*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于相对优势的去偏框架，通过比较用户和物品组的参考分布来校正观看时间，生成基于分位数的偏好信号，并采用两阶段架构分离分布估计和偏好学习。


<details>
  <summary>Details</summary>
Motivation: 原始观看时间受视频时长、流行度和用户行为等混杂因素影响，可能导致推荐模型偏差，需要更准确的偏好信号。

Method: 提出相对优势去偏框架，利用用户和物品组的参考分布校正观看时间，生成分位数偏好信号，并采用两阶段架构。

Result: 离线和在线实验显示，该方法在推荐准确性和鲁棒性上显著优于基线方法。

Conclusion: 该方法有效减少了推荐偏差，提高了推荐质量。

Abstract: Watch time is widely used as a proxy for user satisfaction in video
recommendation platforms. However, raw watch times are influenced by
confounding factors such as video duration, popularity, and individual user
behaviors, potentially distorting preference signals and resulting in biased
recommendation models. We propose a novel relative advantage debiasing
framework that corrects watch time by comparing it to empirically derived
reference distributions conditioned on user and item groups. This approach
yields a quantile-based preference signal and introduces a two-stage
architecture that explicitly separates distribution estimation from preference
learning. Additionally, we present distributional embeddings to efficiently
parameterize watch-time quantiles without requiring online sampling or storage
of historical data. Both offline and online experiments demonstrate significant
improvements in recommendation accuracy and robustness compared to existing
baseline methods.

</details>


### [241] [Quantization through Piecewise-Affine Regularization: Optimization and Statistical Guarantees](https://arxiv.org/abs/2508.11112)
*Jianhao Ma,Lin Xiao*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文研究了分段仿射正则化（PAR）在监督学习中的理论和应用，展示了其在过参数化情况下的量化特性，并提供了多种PAR的闭式近端映射解法。


<details>
  <summary>Details</summary>
Motivation: 解决离散或量化变量优化问题的挑战，通过PAR提供连续优化的灵活框架。

Method: 理论分析PAR在过参数化情况下的量化特性，推导多种PAR的闭式近端映射，并应用近端梯度法及其加速变体。

Result: PAR在过参数化情况下能实现高度量化，且能近似经典正则化方法并获得类似统计保证。

Conclusion: PAR为量化问题提供了有效的理论和计算工具。

Abstract: Optimization problems over discrete or quantized variables are very
challenging in general due to the combinatorial nature of their search space.
Piecewise-affine regularization (PAR) provides a flexible modeling and
computational framework for quantization based on continuous optimization. In
this work, we focus on the setting of supervised learning and investigate the
theoretical foundations of PAR from optimization and statistical perspectives.
First, we show that in the overparameterized regime, where the number of
parameters exceeds the number of samples, every critical point of the
PAR-regularized loss function exhibits a high degree of quantization. Second,
we derive closed-form proximal mappings for various (convex, quasi-convex, and
non-convex) PARs and show how to solve PAR-regularized problems using the
proximal gradient method, its accelerated variant, and the Alternating
Direction Method of Multipliers. Third, we study statistical guarantees of
PAR-regularized linear regression problems; specifically, we can approximate
classical formulations of $\ell_1$-, squared $\ell_2$-, and nonconvex
regularizations using PAR and obtain similar statistical guarantees with
quantized solutions.

</details>


### [242] [CTRL Your Shift: Clustered Transfer Residual Learning for Many Small Datasets](https://arxiv.org/abs/2508.11144)
*Gauri Jain,Dominik Rothenhäusler,Kirk Bansak,Elisabeth Paulson*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种名为CTRL的元学习方法，旨在解决多源数据预测中的整体准确性和源间差异性问题。


<details>
  <summary>Details</summary>
Motivation: 在多源数据（如不同地理位置或群体）的机器学习任务中，保持预测的准确性和源间差异性是关键挑战。

Method: CTRL结合跨域残差学习和自适应聚类，以平衡数据量和数据质量。

Result: 在5个大规模数据集（包括瑞士国家庇护计划数据）上，CTRL在多个关键指标上优于现有基准方法。

Conclusion: CTRL能有效提升多源数据预测的准确性和源间差异性。

Abstract: Machine learning (ML) tasks often utilize large-scale data that is drawn from
several distinct sources, such as different locations, treatment arms, or
groups. In such settings, practitioners often desire predictions that not only
exhibit good overall accuracy, but also remain reliable within each source and
preserve the differences that matter across sources. For instance, several
asylum and refugee resettlement programs now use ML-based employment
predictions to guide where newly arriving families are placed within a host
country, which requires generating informative and differentiated predictions
for many and often small source locations. However, this task is made
challenging by several common characteristics of the data in these settings:
the presence of numerous distinct data sources, distributional shifts between
them, and substantial variation in sample sizes across sources. This paper
introduces Clustered Transfer Residual Learning (CTRL), a meta-learning method
that combines the strengths of cross-domain residual learning and adaptive
pooling/clustering in order to simultaneously improve overall accuracy and
preserve source-level heterogeneity. We provide theoretical results that
clarify how our objective navigates the trade-off between data quantity and
data quality. We evaluate CTRL alongside other state-of-the-art benchmarks on 5
large-scale datasets. This includes a dataset from the national asylum program
in Switzerland, where the algorithmic geographic assignment of asylum seekers
is currently being piloted. CTRL consistently outperforms the benchmarks across
several key metrics and when using a range of different base learners.

</details>


### [243] [Towards the Next-generation Bayesian Network Classifiers](https://arxiv.org/abs/2508.11145)
*Huan Zhang,Daokun Zhang,Kexin Meng,Geoffrey I. Webb*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种新的高阶贝叶斯网络分类器设计范式，通过学习特征值的分布表示来解决传统贝叶斯网络分类器在高阶特征依赖建模中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯网络分类器由于参数爆炸和数据稀疏性问题，难以建模复杂数据的高阶依赖关系。

Method: 提出NeuralKDB，通过神经网络学习特征值的分布表示，并设计了一种基于随机梯度下降的高效训练算法。

Result: 在60个UCI数据集上的实验表明，NeuralKDB在高阶特征依赖建模上显著优于传统贝叶斯网络分类器和其他竞争分类器。

Conclusion: 通过学习分布表示，NeuralKDB能够有效解决高阶依赖建模问题，提升分类性能。

Abstract: Bayesian network classifiers provide a feasible solution to tabular data
classification, with a number of merits like high time and memory efficiency,
and great explainability. However, due to the parameter explosion and data
sparsity issues, Bayesian network classifiers are restricted to low-order
feature dependency modeling, making them struggle in extrapolating the
occurrence probabilities of complex real-world data. In this paper, we propose
a novel paradigm to design high-order Bayesian network classifiers, by learning
distributional representations for feature values, as what has been done in
word embedding and graph representation learning. The learned distributional
representations are encoded with the semantic relatedness between different
features through their observed co-occurrence patterns in training data, which
then serve as a hallmark to extrapolate the occurrence probabilities of new
test samples. As a classifier design realization, we remake the K-dependence
Bayesian classifier (KDB) by extending it into a neural version, i.e.,
NeuralKDB, where a novel neural network architecture is designed to learn
distributional representations of feature values and parameterize the
conditional probabilities between interdependent features. A stochastic
gradient descent based algorithm is designed to train the NeuralKDB model
efficiently. Extensive classification experiments on 60 UCI datasets
demonstrate that the proposed NeuralKDB classifier excels in capturing
high-order feature dependencies and significantly outperforms the conventional
Bayesian network classifiers, as well as other competitive classifiers,
including two neural network based classifiers without distributional
representation learning.

</details>


### [244] [A Semi-supervised Generative Model for Incomplete Multi-view Data Integration with Missing Labels](https://arxiv.org/abs/2508.11180)
*Yiyang Shen,Weiran Wang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种半监督生成模型，结合信息瓶颈原则和跨视图互信息最大化，处理多视图数据中的缺失视图和标签问题。


<details>
  <summary>Details</summary>
Motivation: 多视图学习常面临缺失视图和标签的问题，现有方法无法有效利用未标记数据。本文旨在提出一种统一框架，结合监督和无监督数据。

Method: 采用半监督生成模型，最大化未标记样本的似然，同时在标记数据上应用信息瓶颈原则，并通过跨视图互信息最大化提取共享信息。

Result: 在图像和多组学数据上，模型在预测和插补任务中表现优于现有方法，尤其在缺失视图和有限标记样本情况下。

Conclusion: 该模型有效解决了多视图学习中的缺失问题，提升了性能。

Abstract: Multi-view learning is widely applied to real-life datasets, such as multiple
omics biological data, but it often suffers from both missing views and missing
labels. Prior probabilistic approaches addressed the missing view problem by
using a product-of-experts scheme to aggregate representations from present
views and achieved superior performance over deterministic classifiers, using
the information bottleneck (IB) principle. However, the IB framework is
inherently fully supervised and cannot leverage unlabeled data. In this work,
we propose a semi-supervised generative model that utilizes both labeled and
unlabeled samples in a unified framework. Our method maximizes the likelihood
of unlabeled samples to learn a latent space shared with the IB on labeled
data. We also perform cross-view mutual information maximization in the latent
space to enhance the extraction of shared information across views. Compared to
existing approaches, our model achieves better predictive and imputation
performance on both image and multi-omics data with missing views and limited
labeled samples.

</details>


### [245] [Quantum-Boosted High-Fidelity Deep Learning](https://arxiv.org/abs/2508.11190)
*Feng-ao Wang,Shaobo Chen,Yao Xuan,Junwei Liu,Qi Gao,Hongdong Zhu,Junjie Hou,Lixin Yuan,Jinyu Cheng,Chenxin Yi,Hai Wei,Yin Ma,Tao Xu,Kai Wen,Yixue Li*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种混合量子经典架构QBM-VAE，利用量子处理器高效采样玻尔兹曼分布，解决了传统高斯先验在复杂生物数据中的局限性，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习依赖高斯先验，难以捕捉复杂非高斯数据（如生物数据），而玻尔兹曼分布虽更优但计算困难。量子方法因规模和稳定性不足未能解决此问题。

Method: 提出QBM-VAE架构，结合量子处理器采样玻尔兹曼分布作为先验，用于深度生成模型。

Result: 在百万级单细胞数据上，QBM-VAE优于传统高斯模型（如VAE、SCVI），在数据整合、细胞分类等任务中表现更优。

Conclusion: QBM-VAE展示了量子优势在深度学习中的实际应用，为混合量子AI模型提供了可转移的蓝图。

Abstract: A fundamental limitation of probabilistic deep learning is its predominant
reliance on Gaussian priors. This simplistic assumption prevents models from
accurately capturing the complex, non-Gaussian landscapes of natural data,
particularly in demanding domains like complex biological data, severely
hindering the fidelity of the model for scientific discovery. The
physically-grounded Boltzmann distribution offers a more expressive
alternative, but it is computationally intractable on classical computers. To
date, quantum approaches have been hampered by the insufficient qubit scale and
operational stability required for the iterative demands of deep learning.
Here, we bridge this gap by introducing the Quantum Boltzmann
Machine-Variational Autoencoder (QBM-VAE), a large-scale and long-time stable
hybrid quantum-classical architecture. Our framework leverages a quantum
processor for efficient sampling from the Boltzmann distribution, enabling its
use as a powerful prior within a deep generative model. Applied to
million-scale single-cell datasets from multiple sources, the QBM-VAE generates
a latent space that better preserves complex biological structures,
consistently outperforming conventional Gaussian-based deep learning models
like VAE and SCVI in essential tasks such as omics data integration, cell-type
classification, and trajectory inference. It also provides a typical example of
introducing a physics priori into deep learning to drive the model to acquire
scientific discovery capabilities that breaks through data limitations. This
work provides the demonstration of a practical quantum advantage in deep
learning on a large-scale scientific problem and offers a transferable
blueprint for developing hybrid quantum AI models.

</details>


### [246] [Meta-learning Structure-Preserving Dynamics](https://arxiv.org/abs/2508.11205)
*Cheng Jing,Uvini Balasuriya Mudiyanselage,Woojin Cho,Minju Jo,Anthony Gruber,Kookjin Lee*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于调制的元学习框架，用于结构保持的动态系统建模，无需显式系统参数知识即可适应新参数。


<details>
  <summary>Details</summary>
Motivation: 解决传统结构保持模型需要固定系统配置和显式参数知识的问题，以及现有元学习方法训练不稳定或泛化能力有限的问题。

Method: 引入调制策略，将潜在表示直接嵌入结构保持模型中，避免显式优化和灰盒系统知识。

Result: 在标准基准测试中，该方法实现了少样本学习的准确预测，同时保持了物理约束和泛化性能。

Conclusion: 调制元学习框架为参数变化场景提供了可扩展和通用的动态系统建模方案。

Abstract: Structure-preserving approaches to dynamics modeling have demonstrated great
potential for modeling physical systems due to their strong inductive biases
that enforce conservation laws and dissipative behavior. However, the resulting
models are typically trained for fixed system configurations, requiring
explicit knowledge of system parameters as well as costly retraining for each
new set of parameters -- a major limitation in many-query or parameter-varying
scenarios. Meta-learning offers a potential solution, but existing approaches
like optimization-based meta-learning often suffer from training instability or
limited generalization capability. Inspired by ideas from computer vision, we
introduce a modulation-based meta-learning framework that directly conditions
structure-preserving models on compact latent representations of potentially
unknown system parameters, avoiding the need for gray-box system knowledge and
explicit optimization during adaptation. Through the application of novel
modulation strategies to parametric energy-conserving and dissipative systems,
we enable scalable and generalizable learning across parametric families of
dynamical systems. Experiments on standard benchmark problems demonstrate that
our approach achieves accurate predictions in few-shot learning settings,
without compromising on the essential physical constraints necessary for
dynamical stability and effective generalization performance across parameter
space.

</details>


### [247] [How Causal Abstraction Underpins Computational Explanation](https://arxiv.org/abs/2508.11214)
*Atticus Geiger,Jacqueline Harding,Thomas Icard*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文探讨了如何通过因果抽象理论理解系统实现特定计算的过程，并讨论了表示在其中的作用。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过因果抽象理论解释计算和认知的经典主题在当代机器学习中的体现。

Method: 采用因果抽象理论作为分析框架，结合深度学习和人工神经网络的讨论。

Result: 提出了基于因果抽象的计算实现理论，并探讨了表示在其中的作用。

Conclusion: 研究认为这些问题最好与泛化和预测联系起来探讨。

Abstract: Explanations of cognitive behavior often appeal to computations over
representations. What does it take for a system to implement a given
computation over suitable representational vehicles within that system? We
argue that the language of causality -- and specifically the theory of causal
abstraction -- provides a fruitful lens on this topic. Drawing on current
discussions in deep learning with artificial neural networks, we illustrate how
classical themes in the philosophy of computation and cognition resurface in
contemporary machine learning. We offer an account of computational
implementation grounded in causal abstraction, and examine the role for
representation in the resulting picture. We argue that these issues are most
profitably explored in connection with generalization and prediction.

</details>


### [248] [Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble](https://arxiv.org/abs/2508.11279)
*Jihang Wang,Dongcheng Zhao,Ruolin Chen,Qian Zhang,Yi Zeng*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种名为RTE的训练框架，通过时间集成提升脉冲神经网络的对抗鲁棒性，减少对抗扰动的时间传递性。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络（SNNs）在能效和类脑计算方面具有潜力，但其对抗扰动的脆弱性尚未充分研究。

Method: 提出RTE框架，通过统一损失函数和随机采样策略优化子网络的鲁棒性，减少时间传递性。

Result: RTE在多个基准测试中表现优于现有方法，重塑了SNNs的内部鲁棒性景观。

Conclusion: RTE为构建鲁棒的脉冲模型提供了理论基础，并强调了时间结构在对抗学习中的重要性。

Abstract: Spiking Neural Networks (SNNs) offer a promising direction for
energy-efficient and brain-inspired computing, yet their vulnerability to
adversarial perturbations remains poorly understood. In this work, we revisit
the adversarial robustness of SNNs through the lens of temporal ensembling,
treating the network as a collection of evolving sub-networks across discrete
timesteps. This formulation uncovers two critical but underexplored
challenges-the fragility of individual temporal sub-networks and the tendency
for adversarial vulnerabilities to transfer across time. To overcome these
limitations, we propose Robust Temporal self-Ensemble (RTE), a training
framework that improves the robustness of each sub-network while reducing the
temporal transferability of adversarial perturbations. RTE integrates both
objectives into a unified loss and employs a stochastic sampling strategy for
efficient optimization. Extensive experiments across multiple benchmarks
demonstrate that RTE consistently outperforms existing training methods in
robust-accuracy trade-off. Additional analyses reveal that RTE reshapes the
internal robustness landscape of SNNs, leading to more resilient and temporally
diversified decision boundaries. Our study highlights the importance of
temporal structure in adversarial learning and offers a principled foundation
for building robust spiking models.

</details>


### [249] [Harmonized Gradient Descent for Class Imbalanced Data Stream Online Learning](https://arxiv.org/abs/2508.11353)
*Han Zhou,Hongpeng Yin,Xuanhong Deng,Yuyu Huang,Hao Ren*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种名为HGD的梯度下降算法，通过均衡不同类别的梯度范数来解决数据流中的类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的数据流常存在类别不平衡问题，现有方法如重采样或重加权效果有限，因此提出通过修改训练过程（特别是梯度下降技术）来解决这一问题。

Method: 引入HGD算法，均衡不同类别的梯度范数，无需额外参数或先验知识，适用于任何基于梯度下降的模型。

Result: 理论分析和实验表明，HGD能有效缓解小类别的欠拟合问题，并在不平衡数据流学习中表现优异。

Conclusion: HGD是一种高效且通用的方法，适用于不平衡数据流学习。

Abstract: Many real-world data are sequentially collected over time and often exhibit
skewed class distributions, resulting in imbalanced data streams. While
existing approaches have explored several strategies, such as resampling and
reweighting, for imbalanced data stream learning, our work distinguishes itself
by addressing the imbalance problem through training modification, particularly
focusing on gradient descent techniques. We introduce the harmonized gradient
descent (HGD) algorithm, which aims to equalize the norms of gradients across
different classes. By ensuring the gradient norm balance, HGD mitigates
under-fitting for minor classes and achieves balanced online learning. Notably,
HGD operates in a streamlined implementation process, requiring no data-buffer,
extra parameters, or prior knowledge, making it applicable to any learning
models utilizing gradient descent for optimization. Theoretical analysis, based
on a few common and mild assumptions, shows that HGD achieves a satisfied
sub-linear regret bound. The proposed algorithm are compared with the commonly
used online imbalance learning methods under several imbalanced data stream
scenarios. Extensive experimental evaluations demonstrate the efficiency and
effectiveness of HGD in learning imbalanced data streams.

</details>


### [250] [Minimizing Surrogate Losses for Decision-Focused Learning using Differentiable Optimization](https://arxiv.org/abs/2508.11365)
*Jayanta Mandi,Ali İrfan Mahmutoğulları,Senne Berden,Tias Guns*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出在决策聚焦学习（DFL）中，即使使用可微优化层，最小化替代损失仍能有效降低决策遗憾，并通过实验验证其效果。


<details>
  <summary>Details</summary>
Motivation: 解决梯度在LP问题中几乎处处为零的问题，提升决策聚焦学习的效率和效果。

Method: 提出最小化替代损失的方法，结合DYS-Net高效计算近似解和梯度。

Result: 实验表明，该方法在降低遗憾的同时显著减少训练时间。

Conclusion: 最小化替代损失在DFL中具有高效性和竞争力。

Abstract: Decision-focused learning (DFL) trains a machine learning (ML) model to
predict parameters of an optimization problem, to directly minimize decision
regret, i.e., maximize decision quality. Gradient-based DFL requires computing
the derivative of the solution to the optimization problem with respect to the
predicted parameters. However, for many optimization problems, such as linear
programs (LPs), the gradient of the regret with respect to the predicted
parameters is zero almost everywhere. Existing gradient-based DFL approaches
for LPs try to circumvent this issue in one of two ways: (a) smoothing the LP
into a differentiable optimization problem by adding a quadratic regularizer
and then minimizing the regret directly or (b) minimizing surrogate losses that
have informative (sub)gradients. In this paper, we show that the former
approach still results in zero gradients, because even after smoothing the
regret remains constant across large regions of the parameter space. To address
this, we propose minimizing surrogate losses -- even when a differentiable
optimization layer is used and regret can be minimized directly. Our
experiments demonstrate that minimizing surrogate losses allows differentiable
optimization layers to achieve regret comparable to or better than
surrogate-loss based DFL methods. Further, we demonstrate that this also holds
for DYS-Net, a recently proposed differentiable optimization technique for LPs,
that computes approximate solutions and gradients through operations that can
be performed using feedforward neural network layers. Because DYS-Net executes
the forward and the backward pass very efficiently, by minimizing surrogate
losses using DYS-Net, we are able to attain regret on par with the
state-of-the-art while reducing training time by a significant margin.

</details>


### [251] [Generative Co-Design of Antibody Sequences and Structures via Black-Box Guidance in a Shared Latent Space](https://arxiv.org/abs/2508.11424)
*Yinghua Yao,Yuangang Pan,Xixian Chen*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种名为LEAD的序列-结构协同设计框架，通过在共享潜在空间中优化抗体序列和结构，显著提高了优化效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在原始数据空间中优化抗体序列和结构的互补决定区（CDRs），导致搜索效率低下且成本高昂。LEAD旨在解决这一问题。

Method: LEAD框架在共享潜在空间中优化序列和结构，并设计了黑盒指导策略以应对非可微分属性评估器的现实场景。

Result: 实验表明，LEAD在单目标和多目标优化中均表现优异，查询消耗减少一半且性能优于基线方法。

Conclusion: LEAD通过潜在空间优化和黑盒策略，显著提升了抗体设计的效率和性能。

Abstract: Advancements in deep generative models have enabled the joint modeling of
antibody sequence and structure, given the antigen-antibody complex as context.
However, existing approaches for optimizing complementarity-determining regions
(CDRs) to improve developability properties operate in the raw data space,
leading to excessively costly evaluations due to the inefficient search
process. To address this, we propose LatEnt blAck-box Design (LEAD), a
sequence-structure co-design framework that optimizes both sequence and
structure within their shared latent space. Optimizing shared latent codes can
not only break through the limitations of existing methods, but also ensure
synchronization of different modality designs. Particularly, we design a
black-box guidance strategy to accommodate real-world scenarios where many
property evaluators are non-differentiable. Experimental results demonstrate
that our LEAD achieves superior optimization performance for both single and
multi-property objectives. Notably, LEAD reduces query consumption by a half
while surpassing baseline methods in property optimization. The code is
available at https://github.com/EvaFlower/LatEnt-blAck-box-Design.

</details>


### [252] [Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models](https://arxiv.org/abs/2508.11460)
*Aurora Grefsrud,Nello Blaser,Trygve Buanes*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该研究通过贝叶斯推断框架和合成数据集测试了六种概率机器学习算法的类概率和不确定性估计能力，发现深度学习算法在分布外数据上的不确定性估计不足。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型的复杂性增加，不确定性量化变得困难，研究旨在评估不同算法在不确定性估计上的表现。

Method: 使用近似贝叶斯推断框架，在合成分类数据集上测试六种算法（如神经网络集成、蒙特卡洛Dropout等）。

Result: 所有算法校准良好，但深度学习算法在分布外数据上的不确定性估计不足。

Conclusion: 研究为开发科学数据建模中的不确定性估计方法提供了参考。

Abstract: Rigorous statistical methods, including parameter estimation with
accompanying uncertainties, underpin the validity of scientific discovery,
especially in the natural sciences. With increasingly complex data models such
as deep learning techniques, uncertainty quantification has become exceedingly
difficult and a plethora of techniques have been proposed. In this case study,
we use the unifying framework of approximate Bayesian inference combined with
empirical tests on carefully created synthetic classification datasets to
investigate qualitative properties of six different probabilistic machine
learning algorithms for class probability and uncertainty estimation: (i) a
neural network ensemble, (ii) neural network ensemble with conflictual loss,
(iii) evidential deep learning, (iv) a single neural network with Monte Carlo
Dropout, (v) Gaussian process classification and (vi) a Dirichlet process
mixture model. We check if the algorithms produce uncertainty estimates which
reflect commonly desired properties, such as being well calibrated and
exhibiting an increase in uncertainty for out-of-distribution data points. Our
results indicate that all algorithms are well calibrated, but none of the deep
learning based algorithms provide uncertainties that consistently reflect lack
of experimental evidence for out-of-distribution data points. We hope our study
may serve as a clarifying example for researchers developing new methods of
uncertainty estimation for scientific data-driven modeling.

</details>


### [253] [Towards Faithful Class-level Self-explainability in Graph Neural Networks by Subgraph Dependencies](https://arxiv.org/abs/2508.11513)
*Fanzhen Liu,Xiaoxiao Ma,Jian Yang,Alsharif Abuadbba,Kristen Moore,Surya Nepal,Cecile Paris,Quan Z. Sheng,Jia Wu*

Main category: cs.LG

Relevance: 40.0

TL;DR: GraphOracle是一种新型自解释图神经网络框架，旨在生成和评估GNN的类级解释，解决了现有方法在类级解释上的不足。


<details>
  <summary>Details</summary>
Motivation: 提升图神经网络（GNNs）的可解释性，确保其安全公平部署，并解决现有自解释GNNs在类级解释上的局限性。

Method: 提出GraphOracle框架，联合学习GNN分类器和结构化稀疏子图，通过掩码评估策略验证其高效性和忠实性。

Result: GraphOracle在多个图分类任务中表现出更高的忠实性、可解释性和可扩展性，优于ProtGNN和PGIB。

Conclusion: GraphOracle为GNNs提供了一种实用且原则性的类级自解释解决方案。

Abstract: Enhancing the interpretability of graph neural networks (GNNs) is crucial to
ensure their safe and fair deployment. Recent work has introduced
self-explainable GNNs that generate explanations as part of training, improving
both faithfulness and efficiency. Some of these models, such as ProtGNN and
PGIB, learn class-specific prototypes, offering a potential pathway toward
class-level explanations. However, their evaluations focus solely on
instance-level explanations, leaving open the question of whether these
prototypes meaningfully generalize across instances of the same class. In this
paper, we introduce GraphOracle, a novel self-explainable GNN framework
designed to generate and evaluate class-level explanations for GNNs. Our model
jointly learns a GNN classifier and a set of structured, sparse subgraphs that
are discriminative for each class. We propose a novel integrated training that
captures graph$\unicode{x2013}$subgraph$\unicode{x2013}$prediction dependencies
efficiently and faithfully, validated through a masking-based evaluation
strategy. This strategy enables us to retroactively assess whether prior
methods like ProtGNN and PGIB deliver effective class-level explanations. Our
results show that they do not. In contrast, GraphOracle achieves superior
fidelity, explainability, and scalability across a range of graph
classification tasks. We further demonstrate that GraphOracle avoids the
computational bottlenecks of previous methods$\unicode{x2014}$like Monte Carlo
Tree Search$\unicode{x2014}$by using entropy-regularized subgraph selection and
lightweight random walk extraction, enabling faster and more scalable training.
These findings position GraphOracle as a practical and principled solution for
faithful class-level self-explainability in GNNs.

</details>


### [254] [Physics-Informed Diffusion Models for Unsupervised Anomaly Detection in Multivariate Time Series](https://arxiv.org/abs/2508.11528)
*Juhi Soni,Markus Lange-Hegermann,Stefan Windmann*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于物理信息扩散模型的无监督异常检测方法，用于多元时间序列数据，通过加权物理信息损失提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在时间序列领域已表现出有效性，但如何结合物理信息提升异常检测性能仍需探索。

Method: 使用加权物理信息损失训练扩散模型，学习物理依赖的时间分布。

Result: 在合成和真实数据集上，模型在异常检测的F1分数、数据多样性和对数似然上优于基线方法。

Conclusion: 物理信息训练显著提升了扩散模型的异常检测性能，优于纯数据驱动方法。

Abstract: We propose an unsupervised anomaly detection approach based on a
physics-informed diffusion model for multivariate time series data. Over the
past years, diffusion model has demonstrated its effectiveness in forecasting,
imputation, generation, and anomaly detection in the time series domain. In
this paper, we present a new approach for learning the physics-dependent
temporal distribution of multivariate time series data using a weighted
physics-informed loss during diffusion model training. A weighted
physics-informed loss is constructed using a static weight schedule. This
approach enables a diffusion model to accurately approximate underlying data
distribution, which can influence the unsupervised anomaly detection
performance. Our experiments on synthetic and real-world datasets show that
physics-informed training improves the F1 score in anomaly detection; it
generates better data diversity and log-likelihood. Our model outperforms
baseline approaches, additionally, it surpasses prior physics-informed work and
purely data-driven diffusion models on a synthetic dataset and one real-world
dataset while remaining competitive on others.

</details>


### [255] [DFed-SST: Building Semantic- and Structure-aware Topologies for Decentralized Federated Graph Learning](https://arxiv.org/abs/2508.11530)
*Lianshuai Guo,Zhongzheng Yuan,Xunkai Li,Yinlin Zhu,Meixia Qu,Wenyu Wang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种去中心化联邦图学习框架DFed-SST，通过双拓扑自适应通信机制优化客户端间的通信拓扑，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化联邦学习（DFL）优化策略未能有效处理本地子图的拓扑信息，而联邦图学习（FGL）多采用中心化模式，无法发挥去中心化优势。

Method: 提出DFed-SST框架，利用客户端本地子图的拓扑特征动态构建和优化通信拓扑，实现高效模型聚合。

Result: 在八个真实数据集上，DFed-SST平均准确率比基线方法提升3.26%。

Conclusion: DFed-SST通过自适应通信机制有效解决了异构性问题，为去中心化联邦图学习提供了新思路。

Abstract: Decentralized Federated Learning (DFL) has emerged as a robust distributed
paradigm that circumvents the single-point-of-failure and communication
bottleneck risks of centralized architectures. However, a significant challenge
arises as existing DFL optimization strategies, primarily designed for tasks
such as computer vision, fail to address the unique topological information
inherent in the local subgraph. Notably, while Federated Graph Learning (FGL)
is tailored for graph data, it is predominantly implemented in a centralized
server-client model, failing to leverage the benefits of decentralization.To
bridge this gap, we propose DFed-SST, a decentralized federated graph learning
framework with adaptive communication. The core of our method is a
dual-topology adaptive communication mechanism that leverages the unique
topological features of each client's local subgraph to dynamically construct
and optimize the inter-client communication topology. This allows our framework
to guide model aggregation efficiently in the face of heterogeneity. Extensive
experiments on eight real-world datasets consistently demonstrate the
superiority of DFed-SST, achieving 3.26% improvement in average accuracy over
baseline methods.

</details>


### [256] [Data-driven global ocean model resolving ocean-atmosphere coupling dynamics](https://arxiv.org/abs/2508.10908)
*Jeong-Hwan Kim,Daehyun Kang,Young-Min Yang,Jae-Heung Park,Yoo-Geun Ham*

Main category: physics.ao-ph

Relevance: 40.0

TL;DR: 论文提出了一种基于深度学习的全球三维海洋环流模型KIST-Ocean，通过视觉注意力对抗网络架构，解决了沿海复杂性和预测分布漂移问题，展示了其在气候现象模拟中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统数值模型在天气预报中表现有限，需要开发能够模拟复杂海洋-大气耦合机制的深度学习模型，以扩展预测时间尺度。

Method: 采用U形视觉注意力对抗网络架构，结合部分卷积、对抗训练和迁移学习，构建KIST-Ocean模型。

Result: 模型在海洋预测技能和效率方面表现优异，能够准确捕捉热带太平洋的Kelvin和Rossby波传播等关键耦合机制。

Conclusion: KIST-Ocean展示了深度学习在全球天气和气候模型中的潜力，为扩展地球系统建模提供了可能性。

Abstract: Artificial intelligence has advanced global weather forecasting,
outperforming traditional numerical models in both accuracy and computational
efficiency. Nevertheless, extending predictions beyond subseasonal timescales
requires the development of deep learning (DL)-based ocean-atmosphere coupled
models that can realistically simulate complex oceanic responses to atmospheric
forcing. This study presents KIST-Ocean, a DL-based global three-dimensional
ocean general circulation model using a U-shaped visual attention adversarial
network architecture. KIST-Ocean integrates partial convolution, adversarial
training, and transfer learning to address coastal complexity and predictive
distribution drift in auto-regressive models. Comprehensive evaluations
confirmed the model's robust ocean predictive skill and efficiency. Moreover,
it accurately captures realistic ocean response, such as Kelvin and Rossby wave
propagation in the tropical Pacific, and vertical motions induced by cyclonic
and anticyclonic wind stress, demonstrating its ability to represent key
ocean-atmosphere coupling mechanisms underlying climate phenomena, including
the El Nino-Southern Oscillation. These findings reinforce confidence in
DL-based global weather and climate models and their extending DL-based
approaches to broader Earth system modeling, offering potential for enhancing
climate prediction capabilities.

</details>


### [257] [Non-asymptotic convergence bound of conditional diffusion models](https://arxiv.org/abs/2508.10944)
*Mengze Li*

Main category: stat.ML

Relevance: 40.0

TL;DR: 该论文提出了一种条件扩散模型（CARD），用于分类和回归任务，通过整合预训练模型改进条件分布学习，并建立了理论分析框架。


<details>
  <summary>Details</summary>
Motivation: 尽管条件扩散模型在加速算法和生成质量方面取得进展，但缺乏非渐近性质阻碍了理论研究。本文旨在填补这一空白。

Method: CARD模型将预训练模型f_{\phi}(x)整合到扩散框架中，以学习条件分布Y|f_{\phi}(x)。通过推导随机微分方程和Fokker-Planck方程，建立了理论分析基础。

Result: 在Lipschitz假设下，证明了生成条件分布与原分布的上界误差；在轻尾假设下，推导了得分函数与网络估计值的收敛上界。

Conclusion: CARD为条件扩散模型提供了理论支持，并在特定假设下验证了其有效性。

Abstract: Learning and generating various types of data based on conditional diffusion
models has been a research hotspot in recent years. Although conditional
diffusion models have made considerable progress in improving acceleration
algorithms and enhancing generation quality, the lack of non-asymptotic
properties has hindered theoretical research. To address this gap, we focus on
a conditional diffusion model within the domains of classification and
regression (CARD), which aims to learn the original distribution with given
input x (denoted as Y|X). It innovatively integrates a pre-trained model
f_{\phi}(x) into the original diffusion model framework, allowing it to
precisely capture the original conditional distribution given f (expressed as
Y|f_{\phi}(x)). Remarkably, when f_{\phi}(x) performs satisfactorily,
Y|f_{\phi}(x) closely approximates Y|X. Theoretically, we deduce the stochastic
differential equations of CARD and establish its generalized form predicated on
the Fokker-Planck equation, thereby erecting a firm theoretical foundation for
analysis. Mainly under the Lipschitz assumptions, we utilize the second-order
Wasserstein distance to demonstrate the upper error bound between the original
and the generated conditional distributions. Additionally, by appending
assumptions such as light-tailedness to the original distribution, we derive
the convergence upper bound between the true value analogous to the score
function and the corresponding network-estimated value.

</details>


### [258] [Conditional Independence Estimates for the Generalized Nonparanormal](https://arxiv.org/abs/2508.11050)
*Ujas Shah,Manuel Lladser,Rebecca Morrison*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种广义非参数正态分布，其精度矩阵仍能反映变量间的条件独立性，并提出了一种高效算法用于从这类数据中恢复条件独立性结构。


<details>
  <summary>Details</summary>
Motivation: 研究非高斯分布中变量条件独立性的推断问题，扩展高斯分布的相关理论。

Method: 基于广义非参数正态分布理论，设计了一种计算高效的算法，通过精度矩阵推断条件独立性。

Result: 实验验证了算法在合成数据和真实数据中的有效性。

Conclusion: 广义非参数正态分布为推断非高斯数据的条件独立性提供了新方法。

Abstract: For general non-Gaussian distributions, the covariance and precision matrices
do not encode the independence structure of the variables, as they do for the
multivariate Gaussian. This paper builds on previous work to show that for a
class of non-Gaussian distributions -- those derived from diagonal
transformations of a Gaussian -- information about the conditional independence
structure can still be inferred from the precision matrix, provided the data
meet certain criteria, analogous to the Gaussian case. We call such
transformations of the Gaussian as the generalized nonparanormal. The functions
that define these transformations are, in a broad sense, arbitrary. We also
provide a simple and computationally efficient algorithm that leverages this
theory to recover conditional independence structure from the generalized
nonparanormal data. The effectiveness of the proposed algorithm is demonstrated
via synthetic experiments and applications to real-world data.

</details>


### [259] [Predictive Multimodal Modeling of Diagnoses and Treatments in EHR](https://arxiv.org/abs/2508.11092)
*Cindy Shih-Ting Huang,Clarence Boon Liang Ng,Marek Rei*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种多模态系统，用于早期预测ICD代码分配，融合临床笔记和表格数据，通过预训练编码器和跨模态注意力优化表示，并引入加权时间损失提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决早期预测ICD代码分配的挑战，以识别健康风险、优化治疗和资源分配。

Method: 多模态系统融合临床笔记和表格数据，使用预训练编码器、特征池化和跨模态注意力学习最优表示，并采用加权时间损失。

Result: 实验表明，该方法优于当前最优系统。

Conclusion: 提出的多模态系统和加权时间损失策略有效提升了早期预测性能。

Abstract: While the ICD code assignment problem has been widely studied, most works
have focused on post-discharge document classification. Models for early
forecasting of this information could be used for identifying health risks,
suggesting effective treatments, or optimizing resource allocation. To address
the challenge of predictive modeling using the limited information at the
beginning of a patient stay, we propose a multimodal system to fuse clinical
notes and tabular events captured in electronic health records. The model
integrates pre-trained encoders, feature pooling, and cross-modal attention to
learn optimal representations across modalities and balance their presence at
every temporal point. Moreover, we present a weighted temporal loss that
adjusts its contribution at each point in time. Experiments show that these
strategies enhance the early prediction model, outperforming the current
state-of-the-art systems.

</details>


### [260] [Hybrid-Hierarchical Fashion Graph Attention Network for Compatibility-Oriented and Personalized Outfit Recommendation](https://arxiv.org/abs/2508.11105)
*Sajjad Saed,Babak Teimourpour*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种名为FGAT的新框架，结合图神经网络和注意力机制，用于时尚推荐系统，同时解决搭配兼容性和个性化推荐问题。


<details>
  <summary>Details</summary>
Motivation: 时尚行业快速扩张，用户难以在电商平台找到兼容商品。现有研究常独立处理搭配和个性化推荐，忽略了商品与用户偏好的复杂交互。

Method: FGAT构建用户、搭配和商品的三层层次图，整合视觉和文本特征，利用图注意力机制动态加权节点重要性。

Result: 在POG数据集上，FGAT在精度、HR、召回率、NDCG和准确率上优于基线模型HFGN。

Conclusion: 结合多模态特征、层次图结构和注意力机制，显著提升时尚推荐系统的准确性和效率。

Abstract: The rapid expansion of the fashion industry and the growing variety of
products have made it challenging for users to find compatible items on
e-commerce platforms. Effective fashion recommendation systems are crucial for
filtering irrelevant items and suggesting suitable ones. However,
simultaneously addressing outfit compatibility and personalized recommendations
remains a significant challenge, as these aspects are often treated
independently in existing studies, often overlooking the complex interactions
between items and user preferences. This research introduces a new framework
named FGAT, inspired by the HFGN model, which leverages graph neural networks
and graph attention mechanisms to tackle this issue. The proposed framework
constructs a three-tier hierarchical graph of users, outfits, and items,
integrating visual and textual features to simultaneously model outfit
compatibility and user preferences. A graph attention mechanism dynamically
weights node importance during representation propagation, enabling the capture
of key interactions and generating precise representations for both user
preferences and outfit compatibility. Evaluated on the POG dataset, FGAT
outperforms baseline models such as HFGN, achieving improved results in
precision, HR, recall, NDCG, and accuracy.These results demonstrate that
combining multimodal visual-textual features with a hierarchical graph
structure and attention mechanisms significantly enhances the accuracy and
efficiency of personalized fashion recommendation systems.

</details>


### [261] [Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning](https://arxiv.org/abs/2508.11159)
*Heqiang Wang,Weihong Yang,Xiaoxiong Zhong,Jia Zhou,Fangming Liu,Weizhe Zhang*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种名为QQR的算法，用于解决多模态在线联邦学习（MMO-FL）中因物联网设备不稳定导致的数据模态数量和质量不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 物联网设备生成的多模态数据存在数量和质量不平衡问题，影响分布式学习性能。

Method: 提出了基于原型学习的QQR算法，与训练过程并行运行，以重新平衡模态数量和质量。

Result: 在两个真实多模态数据集上的实验表明，QQR算法在模态不平衡条件下优于基准方法。

Conclusion: QQR算法能有效提升多模态在线联邦学习的性能。

Abstract: The Internet of Things (IoT) ecosystem produces massive volumes of multimodal
data from diverse sources, including sensors, cameras, and microphones. With
advances in edge intelligence, IoT devices have evolved from simple data
acquisition units into computationally capable nodes, enabling localized
processing of heterogeneous multimodal data. This evolution necessitates
distributed learning paradigms that can efficiently handle such data.
Furthermore, the continuous nature of data generation and the limited storage
capacity of edge devices demand an online learning framework. Multimodal Online
Federated Learning (MMO-FL) has emerged as a promising approach to meet these
requirements. However, MMO-FL faces new challenges due to the inherent
instability of IoT devices, which often results in modality quantity and
quality imbalance (QQI) during data collection. In this work, we systematically
investigate the impact of QQI within the MMO-FL framework and present a
comprehensive theoretical analysis quantifying how both types of imbalance
degrade learning performance. To address these challenges, we propose the
Modality Quantity and Quality Rebalanced (QQR) algorithm, a prototype learning
based method designed to operate in parallel with the training process.
Extensive experiments on two real-world multimodal datasets show that the
proposed QQR algorithm consistently outperforms benchmarks under modality
imbalance conditions with promising learning performance.

</details>


### [262] [Graph Neural Diffusion via Generalized Opinion Dynamics](https://arxiv.org/abs/2508.11249)
*Asela Hevapathige,Asiri Wijesinghe,Ahad N. Zehmakan*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种名为GODNF的广义观点动力学神经框架，解决了现有扩散GNN的局限性，实现了异构扩散和高效可解释的消息传播。


<details>
  <summary>Details</summary>
Motivation: 现有扩散GNN方法存在静态动态、深度限制和理论理解不足的问题，需要一种更灵活、高效且理论支持的框架。

Method: GODNF通过节点特定行为建模和动态邻域影响，统一了多种观点动力学模型，支持异构扩散和高效消息传播。

Result: 理论分析表明GODNF能建模多样收敛配置，实验验证其在节点分类和影响力估计任务中优于现有GNN。

Conclusion: GODNF为扩散GNN提供了一种灵活、高效且理论支持的解决方案。

Abstract: There has been a growing interest in developing diffusion-based Graph Neural
Networks (GNNs), building on the connections between message passing mechanisms
in GNNs and physical diffusion processes. However, existing methods suffer from
three critical limitations: (1) they rely on homogeneous diffusion with static
dynamics, limiting adaptability to diverse graph structures; (2) their depth is
constrained by computational overhead and diminishing interpretability; and (3)
theoretical understanding of their convergence behavior remains limited. To
address these challenges, we propose GODNF, a Generalized Opinion Dynamics
Neural Framework, which unifies multiple opinion dynamics models into a
principled, trainable diffusion mechanism. Our framework captures heterogeneous
diffusion patterns and temporal dynamics via node-specific behavior modeling
and dynamic neighborhood influence, while ensuring efficient and interpretable
message propagation even at deep layers. We provide a rigorous theoretical
analysis demonstrating GODNF's ability to model diverse convergence
configurations. Extensive empirical evaluations of node classification and
influence estimation tasks confirm GODNF's superiority over state-of-the-art
GNNs.

</details>


### [263] [RegimeNAS: Regime-Aware Differentiable Architecture Search With Theoretical Guarantees for Financial Trading](https://arxiv.org/abs/2508.11338)
*Prathamesh Devadiga,Yashmitha Shailesh*

Main category: cs.LG

Relevance: 30.0

TL;DR: RegimeNAS是一种新颖的可微分架构搜索框架，专为增强加密货币交易性能而设计，通过显式集成市场状态感知。


<details>
  <summary>Details</summary>
Motivation: 解决静态深度学习模型在高度动态金融环境中的局限性。

Method: 1) 贝叶斯搜索空间优化架构；2) 动态激活的神经网络模块；3) 多目标损失函数。

Result: 在真实加密货币数据上显著优于现有基准，MAE降低80.3%，收敛速度更快。

Conclusion: 强调将领域特定知识嵌入NAS过程以开发稳健和适应性强的金融模型。

Abstract: We introduce RegimeNAS, a novel differentiable architecture search framework
specifically designed to enhance cryptocurrency trading performance by
explicitly integrating market regime awareness. Addressing the limitations of
static deep learning models in highly dynamic financial environments, RegimeNAS
features three core innovations: (1) a theoretically grounded Bayesian search
space optimizing architectures with provable convergence properties; (2)
specialized, dynamically activated neural modules (Volatility, Trend, and Range
blocks) tailored for distinct market conditions; and (3) a multi-objective loss
function incorporating market-specific penalties (e.g., volatility matching,
transition smoothness) alongside mathematically enforced Lipschitz stability
constraints. Regime identification leverages multi-head attention across
multiple timeframes for improved accuracy and uncertainty estimation. Rigorous
empirical evaluation on extensive real-world cryptocurrency data demonstrates
that RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving
an 80.3% Mean Absolute Error reduction compared to the best traditional
recurrent baseline and converging substantially faster (9 vs. 50+ epochs).
Ablation studies and regime-specific analysis confirm the critical contribution
of each component, particularly the regime-aware adaptation mechanism. This
work underscores the imperative of embedding domain-specific knowledge, such as
market regimes, directly within the NAS process to develop robust and adaptive
models for challenging financial applications.

</details>


### [264] [PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding](https://arxiv.org/abs/2508.11357)
*Changhong Jing,Yan Liu,Shuqiang Wang,Bruce X. B. Yu,Gong Chen,Zhejing Hu,Zhi Zhang,Yanyan Shen*

Main category: cs.LG

Relevance: 30.0

TL;DR: PTSM框架通过双分支掩码机制和正交子空间分解，实现跨被试EEG解码的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 解决跨被试EEG解码中因个体差异和共享表征稀缺导致的挑战。

Method: 采用双分支掩码机制学习个性化与共享时空模式，结合信息论约束分解潜在嵌入。

Result: 在运动想象数据集上实现零样本泛化，超越现有基线。

Conclusion: 解耦神经表征在非稳态神经生理场景中兼具个性化和可迁移性。

Abstract: Cross-subject electroencephalography (EEG) decoding remains a fundamental
challenge in brain-computer interface (BCI) research due to substantial
inter-subject variability and the scarcity of subject-invariant
representations. This paper proposed PTSM (Physiology-aware and Task-invariant
Spatio-temporal Modeling), a novel framework for interpretable and robust EEG
decoding across unseen subjects. PTSM employs a dual-branch masking mechanism
that independently learns personalized and shared spatio-temporal patterns,
enabling the model to preserve individual-specific neural characteristics while
extracting task-relevant, population-shared features. The masks are factorized
across temporal and spatial dimensions, allowing fine-grained modulation of
dynamic EEG patterns with low computational overhead. To further address
representational entanglement, PTSM enforces information-theoretic constraints
that decompose latent embeddings into orthogonal task-related and
subject-related subspaces. The model is trained end-to-end via a
multi-objective loss integrating classification, contrastive, and
disentanglement objectives. Extensive experiments on cross-subject motor
imagery datasets demonstrate that PTSM achieves strong zero-shot
generalization, outperforming state-of-the-art baselines without
subject-specific calibration. Results highlight the efficacy of disentangled
neural representations for achieving both personalized and transferable
decoding in non-stationary neurophysiological settings.

</details>


### [265] [Multi-Sensory Cognitive Computing for Learning Population-level Brain Connectivity](https://arxiv.org/abs/2508.11436)
*Mayssa Soussia,Mohamed Ali Mahjoub,Islem Rekik*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出mCOCO框架，利用Reservoir Computing（RC）从BOLD信号中学习功能性连接脑模板（CBT），解决了现有方法在可解释性、计算成本和认知能力建模上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有CBT学习方法（如GNN）存在黑盒性、高计算成本及忽略认知能力的问题，mCOCO旨在通过RC和多感官输入解决这些问题。

Method: mCOCO分为两阶段：1）将BOLD信号映射到RC生成个体功能连接组，再聚合为群体CBT；2）通过认知RC整合多感官输入，赋予CBT认知特性。

Result: mCOCO在中心性、区分性、拓扑合理性和多感官记忆保留方面显著优于GNN方法。

Conclusion: mCOCO为功能性CBT学习提供了一种高效、可解释且具认知能力的方法。

Abstract: The generation of connectional brain templates (CBTs) has recently garnered
significant attention for its potential to identify unique connectivity
patterns shared across individuals. However, existing methods for CBT learning
such as conventional machine learning and graph neural networks (GNNs) are
hindered by several limitations. These include: (i) poor interpretability due
to their black-box nature, (ii) high computational cost, and (iii) an exclusive
focus on structure and topology, overlooking the cognitive capacity of the
generated CBT. To address these challenges, we introduce mCOCO (multi-sensory
COgnitive COmputing), a novel framework that leverages Reservoir Computing (RC)
to learn population-level functional CBT from BOLD
(Blood-Oxygen-level-Dependent) signals. RC's dynamic system properties allow
for tracking state changes over time, enhancing interpretability and enabling
the modeling of brain-like dynamics, as demonstrated in prior literature. By
integrating multi-sensory inputs (e.g., text, audio, and visual data), mCOCO
captures not only structure and topology but also how brain regions process
information and adapt to cognitive tasks such as sensory processing, all in a
computationally efficient manner. Our mCOCO framework consists of two phases:
(1) mapping BOLD signals into the reservoir to derive individual functional
connectomes, which are then aggregated into a group-level CBT - an approach, to
the best of our knowledge, not previously explored in functional connectivity
studies - and (2) incorporating multi-sensory inputs through a cognitive
reservoir, endowing the CBT with cognitive traits. Extensive evaluations show
that our mCOCO-based template significantly outperforms GNN-based CBT in terms
of centeredness, discriminativeness, topological soundness, and multi-sensory
memory retention. Our source code is available at
https://github.com/basiralab/mCOCO.

</details>


### [266] [Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection](https://arxiv.org/abs/2508.11504)
*Andrea Castellani,Zacharias Papadovasilakis,Giorgos Papoutsoglou,Mary Cole,Brian Bautsch,Tobias Rodemann,Ioannis Tsamardinos,Angela Harden*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种结合AutoML和可解释AI的方法，用于分析交通事故严重性的关键风险因素，并提供了一个可扩展的框架。


<details>
  <summary>Details</summary>
Motivation: 交通事故是全球伤害和死亡的主要原因，需要数据驱动的方法来理解和减轻事故严重性。

Method: 使用JADBio AutoML平台构建预测模型，结合SHAP解释模型输出，最终采用Ridge Logistic Regression模型。

Result: 模型在训练集和测试集上的AUC-ROC分别为85.6%和84.9%，识别出17个关键预测因素。

Conclusion: 研究强调方法论的严谨性和可解释性，为交通政策提供了数据支持。

Abstract: Motor vehicle crashes remain a leading cause of injury and death worldwide,
necessitating data-driven approaches to understand and mitigate crash severity.
This study introduces a curated dataset of more than 3 million people involved
in accidents in Ohio over six years (2017-2022), aggregated to more than 2.3
million vehicle-level records for predictive analysis. The primary contribution
is a transparent and reproducible methodology that combines Automated Machine
Learning (AutoML) and explainable artificial intelligence (AI) to identify and
interpret key risk factors associated with severe crashes. Using the JADBio
AutoML platform, predictive models were constructed to distinguish between
severe and non-severe crash outcomes. The models underwent rigorous feature
selection across stratified training subsets, and their outputs were
interpreted using SHapley Additive exPlanations (SHAP) to quantify the
contribution of individual features. A final Ridge Logistic Regression model
achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test
set, with 17 features consistently identified as the most influential
predictors. Key features spanned demographic, environmental, vehicle, human,
and operational categories, including location type, posted speed, minimum
occupant age, and pre-crash action. Notably, certain traditionally emphasized
factors, such as alcohol or drug impairment, were less influential in the final
model compared to environmental and contextual variables. Emphasizing
methodological rigor and interpretability over mere predictive performance,
this study offers a scalable framework to support Vision Zero with aligned
interventions and advanced data-informed traffic safety policy.

</details>


### [267] [Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models](https://arxiv.org/abs/2508.11542)
*Nicole Aretz,Karen Willcox*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种基于数据驱动的嵌套算子推断方法，用于从高维动态系统的快照数据中学习物理信息降阶模型。该方法通过利用降维空间中的层次结构，优先考虑主导模式的相互作用，从而构建初始猜测。


<details>
  <summary>Details</summary>
Motivation: 旨在改进传统算子推断方法，通过层次化初始猜测和动态更新机制，提升降阶模型的精度和计算效率。

Method: 采用嵌套算子推断方法，利用降维空间的层次结构构建初始猜测，支持动态基础和模型形式的更新。

Result: 在立方热传导问题中，嵌套方法比标准方法误差降低四倍；在格陵兰冰盖模型中，平均误差为3%，计算加速超过19,000倍。

Conclusion: 嵌套算子推断方法显著提升了降阶模型的精度和计算效率，适用于动态更新和大规模参数化问题。

Abstract: This paper presents a data-driven, nested Operator Inference (OpInf) approach
for learning physics-informed reduced-order models (ROMs) from snapshot data of
high-dimensional dynamical systems. The approach exploits the inherent
hierarchy within the reduced space to iteratively construct initial guesses for
the OpInf learning problem that prioritize the interactions of the dominant
modes. The initial guess computed for any target reduced dimension corresponds
to a ROM with provably smaller or equal snapshot reconstruction error than with
standard OpInf. Moreover, our nested OpInf algorithm can be warm-started from
previously learned models, enabling versatile application scenarios involving
dynamic basis and model form updates. We demonstrate the performance of our
algorithm on a cubic heat conduction problem, with nested OpInf achieving a
four times smaller error than standard OpInf at a comparable offline time.
Further, we apply nested OpInf to a large-scale, parameterized model of the
Greenland ice sheet where, despite model form approximation errors, it learns a
ROM with, on average, 3% error and computational speed-up factor above 19,000.

</details>


### [268] [Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective](https://arxiv.org/abs/2508.11618)
*Jungang Chen,Seyyed A. Hosseini*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种基于马尔可夫博弈的范式，研究不同联盟结构对利益相关者目标的影响，并将其建模为多智能体强化学习问题。


<details>
  <summary>Details</summary>
Motivation: CCS项目涉及多方利益相关者，各自目标不同且地质条件复杂，需研究协作与独立优化的平衡。

Method: 采用多智能体强化学习方法，结合安全约束，利用E2C框架的替代模型降低计算成本。

Result: 框架有效解决了多利益相关者参与时的CO2存储优化管理问题。

Conclusion: 协作联盟结构在复杂CCS项目中更具优势，强化学习方法能有效支持决策。

Abstract: Carbon capture and storage (CCS) projects typically involve a diverse array
of stakeholders or players from public, private, and regulatory sectors, each
with different objectives and responsibilities. Given the complexity, scale,
and long-term nature of CCS operations, determining whether individual
stakeholders can independently maximize their interests or whether
collaborative coalition agreements are needed remains a central question for
effective CCS project planning and management. CCS projects are often
implemented in geologically connected sites, where shared geological features
such as pressure space and reservoir pore capacity can lead to competitive
behavior among stakeholders. Furthermore, CO2 storage sites are often located
in geologically mature basins that previously served as sites for hydrocarbon
extraction or wastewater disposal in order to leverage existing
infrastructures, which makes unilateral optimization even more complicated and
unrealistic.
  In this work, we propose a paradigm based on Markov games to quantitatively
investigate how different coalition structures affect the goals of
stakeholders. We frame this multi-stakeholder multi-site problem as a
multi-agent reinforcement learning problem with safety constraints. Our
approach enables agents to learn optimal strategies while compliant with safety
regulations. We present an example where multiple operators are injecting CO2
into their respective project areas in a geologically connected basin. To
address the high computational cost of repeated simulations of high-fidelity
models, a previously developed surrogate model based on the Embed-to-Control
(E2C) framework is employed. Our results demonstrate the effectiveness of the
proposed framework in addressing optimal management of CO2 storage when
multiple stakeholders with various objectives and goals are involved.

</details>


### [269] [Uncovering Latent Connections in Indigenous Heritage: Semantic Pipelines for Cultural Preservation in Brazil](https://arxiv.org/abs/2508.10911)
*Luis Vitor Zerkowski,Nina S. T. Hirata*

Main category: cs.HC

Relevance: 30.0

TL;DR: 论文探讨了如何利用人工智能（视觉和文本语义管道）提升巴西土著文化遗产的可访问性和探索性，开发了交互式可视化工具。


<details>
  <summary>Details</summary>
Motivation: 保护土著文化遗产面临挑战，AI可提供技术支持。

Method: 开发视觉和文本语义管道，生成嵌入空间并集成到交互式工具中。

Result: 工具支持基于相似性、时间和地理的探索，揭示潜在联系。

Conclusion: AI可伦理地助力文化遗产保护。

Abstract: Indigenous communities face ongoing challenges in preserving their cultural
heritage, particularly in the face of systemic marginalization and urban
development. In Brazil, the Museu Nacional dos Povos Indigenas through the
Tainacan platform hosts the country's largest online collection of Indigenous
objects and iconographies, providing a critical resource for cultural
engagement. Using publicly available data from this repository, we present a
data-driven initiative that applies artificial intelligence to enhance
accessibility, interpretation, and exploration. We develop two semantic
pipelines: a visual pipeline that models image-based similarity and a textual
pipeline that captures semantic relationships from item descriptions. These
embedding spaces are projected into two dimensions and integrated into an
interactive visualization tool we also developed. In addition to
similarity-based navigation, users can explore the collection through temporal
and geographic lenses, enabling both semantic and contextualized perspectives.
The system supports curatorial tasks, aids public engagement, and reveals
latent connections within the collection. This work demonstrates how AI can
ethically contribute to cultural preservation practices.

</details>


### [270] [CleanCTG: A Deep Learning Model for Multi-Artefact Detection and Reconstruction in Cardiotocography](https://arxiv.org/abs/2508.10928)
*Sheng Wong,Beth Albert,Gabriel Davis Jones*

Main category: eess.AS

Relevance: 30.0

TL;DR: CleanCTG是一个双阶段模型，用于识别和修复胎儿心电图的噪声，显著提升诊断准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在胎儿心电图（CTG）噪声处理上不足，传统方法仅解决简单噪声。CleanCTG旨在通过多尺度卷积和上下文感知交叉注意力，全面处理复杂噪声。

Method: CleanCTG采用双阶段模型：1）多尺度卷积和交叉注意力识别噪声类型；2）噪声特定分支修复信号。训练数据为80万分钟合成噪声CTG。

Result: 在合成数据上，CleanCTG完美检测噪声（AU-ROC=1.00），修复误差显著降低（MSE=2.74x10^-4）。临床验证显示AU-ROC=0.95，决策时间缩短33%。

Conclusion: 显式噪声去除和信号重建可提升CTG诊断准确性，缩短监测时间。

Abstract: Cardiotocography (CTG) is essential for fetal monitoring but is frequently
compromised by diverse artefacts which obscure true fetal heart rate (FHR)
patterns and can lead to misdiagnosis or delayed intervention. Current
deep-learning approaches typically bypass comprehensive noise handling,
applying minimal preprocessing or focusing solely on downstream classification,
while traditional methods rely on simple interpolation or rule-based filtering
that addresses only missing samples and fail to correct complex artefact types.
We present CleanCTG, an end-to-end dual-stage model that first identifies
multiple artefact types via multi-scale convolution and context-aware
cross-attention, then reconstructs corrupted segments through artefact-specific
correction branches. Training utilised over 800,000 minutes of physiologically
realistic, synthetically corrupted CTGs derived from expert-verified "clean"
recordings. On synthetic data, CleanCTG achieved perfect artefact detection
(AU-ROC = 1.00) and reduced mean squared error (MSE) on corrupted segments to
2.74 x 10^-4 (clean-segment MSE = 2.40 x 10^-6), outperforming the next best
method by more than 60%. External validation on 10,190 minutes of
clinician-annotated segments yielded AU-ROC = 0.95 (sensitivity = 83.44%,
specificity 94.22%), surpassing six comparator classifiers. Finally, when
integrated with the Dawes-Redman system on 933 clinical CTG recordings,
denoised traces increased specificity (from 80.70% to 82.70%) and shortened
median time to decision by 33%. These findings suggest that explicit artefact
removal and signal reconstruction can both maintain diagnostic accuracy and
enable shorter monitoring sessions, offering a practical route to more reliable
CTG interpretation.

</details>


### [271] [The Role of Entanglement in Quantum Reservoir Computing with Coupled Kerr Nonlinear Oscillators](https://arxiv.org/abs/2508.11175)
*Ali Karimi,Hadi Zadeh-Haghighi,Youssef Kora,Christoph Simon*

Main category: quant-ph

Relevance: 30.0

TL;DR: 论文研究了基于两个耦合Kerr非线性振荡器的量子储层计算（QRC）框架，探讨了其在时间序列预测任务中的性能，重点关注纠缠对计算性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探索量子储层计算在时间序列预测中的潜力，特别是纠缠如何提升计算性能。

Method: 使用两个耦合Kerr非线性振荡器构建QRC框架，分析输入驱动强度、Kerr非线性和振荡器耦合等参数对性能的影响，并通过对数负性和NRMSE量化纠缠和预测精度。

Result: 纠缠在输入频率阈值内提供计算优势，且在某些耗散和退相干条件下仍存在；高耗散率可能提升性能。纠缠改善了平均和最差情况性能，但对最佳误差无影响。

Conclusion: 研究为高性能量子机器学习和时间序列预测提供了量子储层计算的新见解。

Abstract: Quantum Reservoir Computing (QRC) uses quantum dynamics to efficiently
process temporal data. In this work, we investigate a QRC framework based on
two coupled Kerr nonlinear oscillators, a system well-suited for time-series
prediction tasks due to its complex nonlinear interactions and potentially
high-dimensional state space. We explore how its performance in time-series
prediction depends on key physical parameters: input drive strength, Kerr
nonlinearity, and oscillator coupling, and analyze the role of entanglement in
improving the reservoir's computational performance, focusing on its effect on
predicting non-trivial time series. Using logarithmic negativity to quantify
entanglement and normalized root mean square error (NRMSE) to evaluate
predictive accuracy, our results suggest that entanglement provides a
computational advantage on average-up to a threshold in the input
frequency-that persists under some levels of dissipation and dephasing. In
particular, we find that higher dissipation rates can enhance performance.
While the entanglement advantage manifests as improvements in both average and
worst-case performance, it does not lead to improvements in the best-case
error. These findings contribute to the broader understanding of quantum
reservoirs for high performance, efficient quantum machine learning and
time-series forecasting.

</details>


### [272] [Uniform convergence for Gaussian kernel ridge regression](https://arxiv.org/abs/2508.11274)
*Paul Dommel,Rajmadan Lakshmanan*

Main category: stat.ML

Relevance: 30.0

TL;DR: 论文首次证明了高斯核岭回归（KRR）在固定超参数情况下，在均匀范数和$L^{2}$-范数下的多项式收敛速率。


<details>
  <summary>Details</summary>
Motivation: 填补高斯核KRR理论理解的空白，特别是固定超参数时的收敛速率问题。

Method: 通过理论分析，证明了高斯核KRR在固定宽度参数时的多项式收敛速率。

Result: 在均匀范数和$L^{2}$-范数下均获得多项式收敛速率，为高斯核KRR的应用提供了新的理论支持。

Conclusion: 研究结果为固定超参数的高斯核KRR在非参数回归中的应用提供了理论依据。

Abstract: This paper establishes the first polynomial convergence rates for Gaussian
kernel ridge regression (KRR) with a fixed hyperparameter in both the uniform
and the $L^{2}$-norm. The uniform convergence result closes a gap in the
theoretical understanding of KRR with the Gaussian kernel, where no such rates
were previously known. In addition, we prove a polynomial $L^{2}$-convergence
rate in the case, where the Gaussian kernel's width parameter is fixed. This
also contributes to the broader understanding of smooth kernels, for which
previously only sub-polynomial $L^{2}$-rates were known in similar settings.
Together, these results provide new theoretical justification for the use of
Gaussian KRR with fixed hyperparameters in nonparametric regression.

</details>


### [273] [Nonparametric learning of stochastic differential equations from sparse and noisy data](https://arxiv.org/abs/2508.11597)
*Arnab Ganguly,Riten Mitra,Jinpu Zhou*

Main category: stat.ML

Relevance: 30.0

TL;DR: 论文提出了一种从稀疏、噪声观测中构建数据驱动的随机微分方程（SDE）模型的系统框架，通过EM算法和SMC方法学习漂移函数。


<details>
  <summary>Details</summary>
Motivation: 传统参数化方法需要假设漂移函数的已知形式，而本文旨在直接从数据中学习漂移函数，适用于系统动力学部分已知或高度复杂的科学领域。

Method: 采用EM算法结合SMC方法近似滤波分布，并通过RKHS中的惩罚负对数似然函数最小化问题估计漂移函数。

Result: 提出的EM-SMC-RKHS方法在低数据量下能准确估计漂移函数，并通过数值实验验证了其有效性。

Conclusion: 该方法适用于需要在观测约束下进行连续时间建模的领域。

Abstract: The paper proposes a systematic framework for building data-driven stochastic
differential equation (SDE) models from sparse, noisy observations. Unlike
traditional parametric approaches, which assume a known functional form for the
drift, our goal here is to learn the entire drift function directly from data
without strong structural assumptions, making it especially relevant in
scientific disciplines where system dynamics are partially understood or highly
complex. We cast the estimation problem as minimization of the penalized
negative log-likelihood functional over a reproducing kernel Hilbert space
(RKHS). In the sparse observation regime, the presence of unobserved trajectory
segments makes the SDE likelihood intractable. To address this, we develop an
Expectation-Maximization (EM) algorithm that employs a novel Sequential Monte
Carlo (SMC) method to approximate the filtering distribution and generate Monte
Carlo estimates of the E-step objective. The M-step then reduces to a penalized
empirical risk minimization problem in the RKHS, whose minimizer is given by a
finite linear combination of kernel functions via a generalized representer
theorem. To control model complexity across EM iterations, we also develop a
hybrid Bayesian variant of the algorithm that uses shrinkage priors to identify
significant coefficients in the kernel expansion. We establish important
theoretical convergence results for both the exact and approximate EM
sequences. The resulting EM-SMC-RKHS procedure enables accurate estimation of
the drift function of stochastic dynamical systems in low-data regimes and is
broadly applicable across domains requiring continuous-time modeling under
observational constraints. We demonstrate the effectiveness of our method
through a series of numerical experiments.

</details>


### [274] [A Feasibility Experiment on the Application of Predictive Coding to Instant Messaging Corpora](https://arxiv.org/abs/2508.11084)
*Thanasis Schoinas,Ghulam Qadir*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种经济可行的预测编码方法，通过数据管理流程将即时消息分组，结合特征选择和逻辑回归分类器，并在定量特征上通过降维提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决法律行业中即时消息分类的挑战，因其非正式性和小规模特性。

Method: 数据管理流程分组消息，特征选择，逻辑回归分类器，定量特征降维。

Result: 在Instant Bloomberg数据集上测试，性能提升并展示成本节约。

Conclusion: 提供了一种经济高效的即时消息分类解决方案。

Abstract: Predictive coding, the term used in the legal industry for document
classification using machine learning, presents additional challenges when the
dataset comprises instant messages, due to their informal nature and smaller
sizes. In this paper, we exploit a data management workflow to group messages
into day chats, followed by feature selection and a logistic regression
classifier to provide an economically feasible predictive coding solution. We
also improve the solution's baseline model performance by dimensionality
reduction, with focus on quantitative features. We test our methodology on an
Instant Bloomberg dataset, rich in quantitative information. In parallel, we
provide an example of the cost savings of our approach.

</details>


### [275] [Borrowing From the Future: Enhancing Early Risk Assessment through Contrastive Learning](https://arxiv.org/abs/2508.11210)
*Minghui Sun,Matthew M. Engelhard,Benjamin A. Goldstein*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种名为BFF的多模态对比框架，旨在通过从后期阶段‘借用’信息来提升早期风险评估的性能。


<details>
  <summary>Details</summary>
Motivation: 早期风险评估在临床中非常重要，但通常精度较低。研究目标是利用后期阶段的信息提升早期预测性能。

Method: BFF框架将不同时间窗口视为不同模态，通过对比学习从后期阶段借用信号来监督早期阶段的学习。

Result: 在两个真实世界的儿科预测任务中，BFF显著提升了早期风险评估的性能。

Conclusion: BFF框架通过多模态对比学习有效提升了早期风险评估的可靠性。

Abstract: Risk assessments for a pediatric population are often conducted across
multiple stages. For example, clinicians may evaluate risks prenatally, at
birth, and during Well-Child visits. Although predictions made at later stages
typically achieve higher precision, it is clinically desirable to make reliable
risk assessments as early as possible. Therefore, this study focuses on
improving prediction performance in early-stage risk assessments. Our solution,
\textbf{Borrowing From the Future (BFF)}, is a contrastive multi-modal
framework that treats each time window as a distinct modality. In BFF, a model
is trained on all available data throughout the time while performing a risk
assessment using up-to-date information. This contrastive framework allows the
model to ``borrow'' informative signals from later stages (e.g., Well-Child
visits) to implicitly supervise the learning at earlier stages (e.g.,
prenatal/birth stages). We validate BFF on two real-world pediatric outcome
prediction tasks, demonstrating consistent improvements in early risk
assessments. The code is available at https://github.com/scotsun/bff.

</details>


### [276] [Air Quality PM2.5 Index Prediction Model Based on CNN-LSTM](https://arxiv.org/abs/2508.11215)
*Zicheng Guo,Shuqi Wu,Meixing Zhu,He Guandi*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种基于CNN-LSTM混合架构的PM2.5浓度预测模型，结合了CNN的空间特征提取和LSTM的时间依赖性建模，在实验中表现优于传统时间序列模型。


<details>
  <summary>Details</summary>
Motivation: 全球气候变化加剧，准确预测空气质量指标（如PM2.5浓度）对环境保护、公共健康和城市管理至关重要。

Method: 采用CNN提取局部空间特征，LSTM建模时间序列依赖，使用北京工业区2010-2015年的多变量数据集进行预测。

Result: 模型在6小时平均PM2.5浓度预测中，RMSE为5.236，优于传统方法。

Conclusion: 模型在现实应用中有潜力，但计算资源需求高，未来需优化多变量处理能力和扩展性。

Abstract: With the intensification of global climate change, accurate prediction of air
quality indicators, especially PM2.5 concentration, has become increasingly
important in fields such as environmental protection, public health, and urban
management. To address this, we propose an air quality PM2.5 index prediction
model based on a hybrid CNN-LSTM architecture. The model effectively combines
Convolutional Neural Networks (CNN) for local spatial feature extraction and
Long Short-Term Memory (LSTM) networks for modeling temporal dependencies in
time series data. Using a multivariate dataset collected from an industrial
area in Beijing between 2010 and 2015 -- which includes hourly records of PM2.5
concentration, temperature, dew point, pressure, wind direction, wind speed,
and precipitation -- the model predicts the average PM2.5 concentration over
6-hour intervals. Experimental results show that the model achieves a root mean
square error (RMSE) of 5.236, outperforming traditional time series models in
both accuracy and generalization. This demonstrates its strong potential in
real-world applications such as air pollution early warning systems. However,
due to the complexity of multivariate inputs, the model demands high
computational resources, and its ability to handle diverse atmospheric factors
still requires optimization. Future work will focus on enhancing scalability
and expanding support for more complex multivariate weather prediction tasks.

</details>


### [277] [A Global Dataset of Location Data Integrity-Assessed Reforestation Efforts](https://arxiv.org/abs/2508.11349)
*Angela John,Selvyn Allotey,Till Koebe,Alexandra Tyukavina,Ingmar Weber*

Main category: cs.LG

Relevance: 20.0

TL;DR: 该研究通过整合全球造林和再造林项目的数据，结合卫星图像，提出了一个评估地理数据完整性的指标LDIS，发现多数项目存在数据完整性问题。


<details>
  <summary>Details</summary>
Motivation: 应对自愿碳市场中数据可靠性和项目完整性的担忧，提供更透明的验证方法。

Method: 整合了来自45,628个项目的1,289,068个种植地点的数据，结合时间序列卫星图像，开发了LDIS指标。

Result: 79%的地理参考种植地点在至少1项LDIS指标上失败，15%的项目缺乏机器可读的地理数据。

Conclusion: 该数据集不仅提升了自愿碳市场的问责制，还可用于计算机视觉任务的训练数据。

Abstract: Afforestation and reforestation are popular strategies for mitigating climate
change by enhancing carbon sequestration. However, the effectiveness of these
efforts is often self-reported by project developers, or certified through
processes with limited external validation. This leads to concerns about data
reliability and project integrity. In response to increasing scrutiny of
voluntary carbon markets, this study presents a dataset on global afforestation
and reforestation efforts compiled from primary (meta-)information and
augmented with time-series satellite imagery and other secondary data. Our
dataset covers 1,289,068 planting sites from 45,628 projects spanning 33 years.
Since any remote sensing-based validation effort relies on the integrity of a
planting site's geographic boundary, this dataset introduces a standardized
assessment of the provided site-level location information, which we summarize
in one easy-to-communicate key indicator: LDIS -- the Location Data Integrity
Score. We find that approximately 79\% of the georeferenced planting sites
monitored fail on at least 1 out of 10 LDIS indicators, while 15\% of the
monitored projects lack machine-readable georeferenced data in the first place.
In addition to enhancing accountability in the voluntary carbon market, the
presented dataset also holds value as training data for e.g. computer
vision-related tasks with millions of linked Sentinel-2 and Planetscope
satellite images.

</details>


### [278] [Insect-Wing Structured Microfluidic System for Reservoir Computing](https://arxiv.org/abs/2508.10915)
*Jacob Clouse,Thomas Ramsey,Samitha Somathilaka,Nicholas Kleinsasser,Sangjin Ryu,Sasitharan Balasubramaniam*

Main category: cs.NE

Relevance: 20.0

TL;DR: 该论文研究了一种基于蜻蜓翅膀启发的微流控芯片的混合储层计算系统，用于低功耗、高弹性计算。


<details>
  <summary>Details</summary>
Motivation: 随着对高效和自适应计算需求的增长，受自然启发的架构为传统电子设计提供了有前景的替代方案。微流控平台在电子设备不适用的环境中表现出色。

Method: 系统使用三个染料入口通道和三个摄像头监测区域，将空间模式转换为动态颜色输出信号，并通过可训练的输出层进行分类。

Result: 实验结果显示分类准确率高达91%，即使在低分辨率和有限训练数据下也表现稳定。

Conclusion: 微流控储层计算在低功耗和高弹性计算中具有可行性。

Abstract: As the demand for more efficient and adaptive computing grows,
nature-inspired architectures offer promising alternatives to conventional
electronic designs. Microfluidic platforms, drawing on biological forms and
fluid dynamics, present a compelling foundation for low-power, high-resilience
computing in environments where electronics are unsuitable. This study explores
a hybrid reservoir computing system based on a dragonfly-wing inspired
microfluidic chip, which encodes temporal input patterns as fluid interactions
within the micro channel network.
  The system operates with three dye-based inlet channels and three
camera-monitored detection areas, transforming discrete spatial patterns into
dynamic color output signals. These reservoir output signals are then modified
and passed to a simple and trainable readout layer for pattern classification.
Using a combination of raw reservoir outputs and synthetically generated
outputs, we evaluated system performance, system clarity, and data efficiency.
The results demonstrate consistent classification accuracies up to $91\%$, even
with coarse resolution and limited training data, highlighting the viability of
the microfluidic reservoir computing.

</details>


### [279] [Counterfactual Survival Q Learning for Longitudinal Randomized Trials via Buckley James Boosting](https://arxiv.org/abs/2508.11060)
*Jeongjin Lee,Jong-Min Kim*

Main category: stat.ML

Relevance: 20.0

TL;DR: 提出了一种Buckley James (BJ) Boost Q学习框架，用于在右删失生存数据下估计最优动态治疗方案，适用于纵向随机临床试验。


<details>
  <summary>Details</summary>
Motivation: 解决传统Cox-based Q学习在风险建模中的偏差问题，提供更灵活和稳健的估计方法。

Method: 结合加速失效时间模型与迭代提升技术（如最小二乘和回归树），在反事实Q学习框架下直接建模条件生存时间。

Result: 模拟研究和HIV试验分析表明，BJ Boost Q学习在治疗决策中具有更高准确性，尤其在多阶段设置中。

Conclusion: 该方法避免了比例风险假设的限制，提供了无偏估计，适用于复杂动态治疗方案。

Abstract: We propose a Buckley James (BJ) Boost Q learning framework for estimating
optimal dynamic treatment regimes under right censored survival data, tailored
for longitudinal randomized clinical trial settings. The method integrates
accelerated failure time models with iterative boosting techniques, including
componentwise least squares and regression trees, within a counterfactual Q
learning framework. By directly modeling conditional survival time, BJ Boost Q
learning avoids the restrictive proportional hazards assumption and enables
unbiased estimation of stage specific Q functions. Grounded in potential
outcomes, this framework ensures identifiability of the optimal treatment
regime under standard causal assumptions. Compared to Cox based Q learning,
which relies on hazard modeling and may suffer from bias under
misspecification, our approach provides robust and flexible estimation.
Simulation studies and analysis of the ACTG175 HIV trial demonstrate that BJ
Boost Q learning yields higher accuracy in treatment decision making,
especially in multistage settings where bias can accumulate.

</details>


### [280] [Approximating the universal thermal climate index using sparse regression with orthogonal polynomials](https://arxiv.org/abs/2508.11307)
*Sabin Roman,Gregor Skok,Ljupco Todorovski,Saso Dzeroski*

Main category: physics.ao-ph

Relevance: 20.0

TL;DR: 本文探讨了利用符号和稀疏回归技术分析并近似UTCI（通用热气候指数）的新方法，通过正交多项式基（如Legendre多项式）提升模型的稳定性、收敛性和可解释性。


<details>
  <summary>Details</summary>
Motivation: UTCI是一个复杂的非线性多变量指标，需要高效且可解释的建模方法。

Method: 采用符号和稀疏回归技术，结合正交多项式基（Legendre多项式），构建高效且可解释的模型。

Result: 模型在仅使用20%数据训练的情况下，对剩余80%数据表现出鲁棒性，且显著优于现有的六次多项式基准。

Conclusion: 结合稀疏性、正交性和符号结构，能够高效且可解释地建模复杂环境指标。

Abstract: This article explores novel data-driven modeling approaches for analyzing and
approximating the Universal Thermal Climate Index (UTCI), a
physiologically-based metric integrating multiple atmospheric variables to
assess thermal comfort. Given the nonlinear, multivariate structure of UTCI, we
investigate symbolic and sparse regression techniques as tools for
interpretable and efficient function approximation. In particular, we highlight
the benefits of using orthogonal polynomial bases-such as Legendre
polynomials-in sparse regression frameworks, demonstrating their advantages in
stability, convergence, and hierarchical interpretability compared to standard
polynomial expansions. We demonstrate that our models achieve significantly
lower root-mean squared losses than the widely used sixth-degree polynomial
benchmark-while using the same or fewer parameters. By leveraging Legendre
polynomial bases, we construct models that efficiently populate a Pareto front
of accuracy versus complexity and exhibit stable, hierarchical coefficient
structures across varying model capacities. Training on just 20% of the data,
our models generalize robustly to the remaining 80%, with consistent
performance under bootstrapping. The decomposition effectively approximates the
UTCI as a Fourier-like expansion in an orthogonal basis, yielding results near
the theoretical optimum in the L2 (least squares) sense. We also connect these
findings to the broader context of equation discovery in environmental
modeling, referencing probabilistic grammar-based methods that enforce domain
consistency and compactness in symbolic expressions. Taken together, these
results illustrate how combining sparsity, orthogonality, and symbolic
structure enables robust, interpretable modeling of complex environmental
indices like UTCI - and significantly outperforms the state-of-the-art
approximation in both accuracy and efficiency.

</details>


### [281] [Investigating Sensors and Methods in Grasp State Classification in Agricultural Manipulation](https://arxiv.org/abs/2508.11588)
*Benjamin Walt,Jordan Westphal,Girish Krishnan*

Main category: cs.RO

Relevance: 20.0

TL;DR: 论文研究了农业抓取状态分类，通过集成多种传感器并使用随机森林模型，在樱桃番茄采摘中实现了100%的准确率。


<details>
  <summary>Details</summary>
Motivation: 农业环境的复杂性和果实采摘的精确性要求可靠的抓取状态反馈，以提升采摘效率和可靠性。

Method: 集成IMU、红外反射、张力、触觉传感器和RGB相机，比较随机森林和LSTM模型的性能。

Result: 随机森林模型在实验室和实际环境中实现了100%的分类准确率，IMU和张力传感器组合效果最佳。

Conclusion: 最小传感器组合（IMU和张力传感器）能有效分类抓取状态，支持实时反馈和纠正操作。

Abstract: Effective and efficient agricultural manipulation and harvesting depend on
accurately understanding the current state of the grasp. The agricultural
environment presents unique challenges due to its complexity, clutter, and
occlusion. Additionally, fruit is physically attached to the plant, requiring
precise separation during harvesting. Selecting appropriate sensors and
modeling techniques is critical for obtaining reliable feedback and correctly
identifying grasp states. This work investigates a set of key sensors, namely
inertial measurement units (IMUs), infrared (IR) reflectance, tension, tactile
sensors, and RGB cameras, integrated into a compliant gripper to classify grasp
states. We evaluate the individual contribution of each sensor and compare the
performance of two widely used classification models: Random Forest and Long
Short-Term Memory (LSTM) networks. Our results demonstrate that a Random Forest
classifier, trained in a controlled lab environment and tested on real cherry
tomato plants, achieved 100% accuracy in identifying slip, grasp failure, and
successful picks, marking a substantial improvement over baseline performance.
Furthermore, we identify a minimal viable sensor combination, namely IMU and
tension sensors that effectively classifies grasp states. This classifier
enables the planning of corrective actions based on real-time feedback, thereby
enhancing the efficiency and reliability of fruit harvesting operations.

</details>


### [282] [Enhancing Interactive Voting-Based Map Matching: Improving Efficiency and Robustness for Heterogeneous GPS Trajectories](https://arxiv.org/abs/2508.11235)
*William Alemanni,Arianna Burzacchi,Davide Colombi,Elena Giarratano*

Main category: cs.LG

Relevance: 10.0

TL;DR: 本文提出了一种改进的交互式投票地图匹配算法，用于高效处理不同采样率的轨迹数据，旨在高精度重建GPS轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决GPS轨迹重建中因输入数据质量不均和道路网络缺失数据导致的精度问题。

Method: 扩展原算法，集成轨迹插补，采用距离限制的交互投票策略降低计算复杂度，并改进道路网络缺失数据处理。

Result: 算法在OpenStreetMap覆盖的任何地理区域均可高效应用，显著提升了适用性和精度。

Conclusion: 改进后的算法保留了原算法的核心优势，同时扩展了其在实际场景中的应用范围。

Abstract: This paper presents an enhanced version of the Interactive Voting-Based Map
Matching algorithm, designed to efficiently process trajectories with varying
sampling rates. The main aim is to reconstruct GPS trajectories with high
accuracy, independent of input data quality. Building upon the original
algorithm, developed exclusively for aligning GPS signals to road networks, we
extend its capabilities by integrating trajectory imputation. Our improvements
also include the implementation of a distance-bounded interactive voting
strategy to reduce computational complexity, as well as modifications to
address missing data in the road network. Furthermore, we incorporate a
custom-built asset derived from OpenStreetMap, enabling this approach to be
smoothly applied in any geographic region covered by OpenStreetMap's road
network. These advancements preserve the core strengths of the original
algorithm while significantly extending its applicability to diverse real-world
scenarios.

</details>


### [283] [Functional Analysis of Variance for Association Studies](https://arxiv.org/abs/2508.11069)
*Olga A. Vsevolozhskaya,Dmitri V. Zaykin,Mark C. Greenwood,Changshuai Wei,Qing Lu*

Main category: stat.AP

Relevance: 10.0

TL;DR: 论文提出了一种功能方差分析（FANOVA）方法，用于测试基因组区域序列变异与定性性状的关联，优于现有方法SKAT和FLM。


<details>
  <summary>Details</summary>
Motivation: 尽管已发现常见遗传变异与人类疾病相关，但大多数复杂疾病的遗传性仍无法完全解释，需要更高效的统计方法发现新变异。

Method: 提出FANOVA方法，联合测试基因变异（包括常见和罕见变异），充分利用连锁不平衡和遗传位置信息。

Result: FANOVA在模拟和实证研究中优于SKAT和FLM，尤其在小样本或变异效应低至中等时表现更优。

Conclusion: FANOVA是一种高效的方法，能更全面地识别疾病相关变异。

Abstract: While progress has been made in identifying common genetic variants
associated with human diseases, for most of common complex diseases, the
identified genetic variants only account for a small proportion of
heritability. Challenges remain in finding additional unknown genetic variants
predisposing to complex diseases. With the advance in next-generation
sequencing technologies, sequencing studies have become commonplace in genetic
research. The ongoing exome-sequencing and whole-genome-sequencing studies
generate a massive amount of sequencing variants and allow researchers to
comprehensively investigate their role in human diseases. The discovery of new
disease-associated variants can be enhanced by utilizing powerful and
computationally efficient statistical methods. In this paper, we propose a
functional analysis of variance (FANOVA) method for testing an association of
sequence variants in a genomic region with a qualitative trait. The FANOVA has
a number of advantages: (1) it tests for a joint effect of gene variants,
including both common and rare; (2) it fully utilizes linkage disequilibrium
and genetic position information; and (3) allows for either protective or
risk-increasing causal variants. Through simulations, we show that FANOVA
outperform two popularly used methods - SKAT and a previously proposed method
based on functional linear models (FLM), - especially if a sample size of a
study is small and/or sequence variants have low to moderate effects. We
conduct an empirical study by applying three methods (FANOVA, SKAT and FLM) to
sequencing data from Dallas Heart Study. While SKAT and FLM respectively
detected ANGPTL 4 and ANGPTL 3 associated with obesity, FANOVA was able to
identify both genes associated with obesity.

</details>


### [284] [Repetitive TMS-based Identification of Methamphetamine-Dependent Individuals Using EEG Spectra](https://arxiv.org/abs/2508.11312)
*Ziyi Zeng,Yun-Hsuan Chen,Xurong Gao,Wenyao Zheng,Hemmings Wu,Zhoule Zhu,Jie Yang,Chengkai Wang,Lihua Zhong,Weiwei Cheng,Mohamad Sawan*

Main category: q-bio.NC

Relevance: 10.0

TL;DR: 该研究探讨了利用脑电图（EEG）信号评估重复经颅磁刺激（rTMS）对甲基苯丙胺（METH）成瘾者渴求水平的客观效果，发现伽马频段的相对功率（RBP）可作为区分成瘾者与健康人的生物标志物。


<details>
  <summary>Details</summary>
Motivation: 传统问卷评估rTMS效果的主观性较强，研究旨在通过神经信号提供更客观的评估方法。

Method: 分析20名METH成瘾者和20名健康人的EEG信号，比较rTMS前后的伽马RBP，并使用随机森林（RF）进行分类。

Result: 伽马RBP能90%准确区分成瘾者与健康人，TP10和CP2通道的信号在分类中起主导作用。

Conclusion: 伽马RBP可作为rTMS效果评估的生物标志物，并为定制闭环神经调控系统提供参数。

Abstract: The impact of repetitive transcranial magnetic stimulation (rTMS) on
methamphetamine (METH) users' craving levels is often assessed using
questionnaires. This study explores the feasibility of using neural signals to
obtain more objective results. EEG signals recorded from 20 METH-addicted
participants Before and After rTMS (MBT and MAT) and from 20 healthy
participants (HC) are analyzed. In each EEG paradigm, participants are shown 15
METH-related and 15 neutral pictures randomly, and the relative band power
(RBP) of each EEG sub-band frequency is derived. The average RBP across all 31
channels, as well as individual brain regions, is analyzed. Statistically,
MAT's alpha, beta, and gamma RBPs are more like those of HC compared to MBT, as
indicated by the power topographies. Utilizing a random forest (RF), the gamma
RBP is identified as the optimal frequency band for distinguishing between MBT
and HC with a 90% accuracy. The performance of classifying MAT versus HC is
lower than that of MBT versus HC, suggesting that the efficacy of rTMS can be
validated using RF with gamma RBP. Furthermore, the gamma RBP recorded by the
TP10 and CP2 channels dominates the classification task of MBT versus HC when
receiving METH-related image cues. The gamma RBP during exposure to
METH-related cues can serve as a biomarker for distinguishing between MBT and
HC and for evaluating the effectiveness of rTMS. Therefore, real-time
monitoring of gamma RBP variations holds promise as a parameter for
implementing a customized closed-loop neuromodulation system for treating METH
addiction.

</details>
