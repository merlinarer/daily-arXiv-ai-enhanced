<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 104]
- [cs.CV](#cs.CV) [Total: 242]
- [cs.AI](#cs.AI) [Total: 166]
- [cs.LG](#cs.LG) [Total: 187]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [q-bio.OT](#q-bio.OT) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention](https://arxiv.org/abs/2508.07185)
*Kabir Khan,Priya Sharma,Arjun Mehta,Neha Gupta,Ravi Narayanan*

Main category: cs.CL

Relevance: 90.0

TL;DR: DySK-Attn框架通过动态知识图谱和稀疏知识注意力机制，使LLM能高效整合实时知识，解决静态知识过时问题。


<details>
  <summary>Details</summary>
Motivation: LLM的知识静态且易过时，重新训练成本高，现有知识编辑方法效率低且有副作用。

Method: 结合动态知识图谱（KG）和稀疏知识注意力机制，实现高效知识检索与整合。

Result: 在时效性问答任务中，DySK-Attn在准确性和计算效率上显著优于基线方法。

Conclusion: DySK-Attn为LLM提供了一种可扩展且高效的实时知识更新方案。

Abstract: Large Language Models (LLMs) suffer from a critical limitation: their
knowledge is static and quickly becomes outdated. Retraining these massive
models is computationally prohibitive, while existing knowledge editing
techniques can be slow and may introduce unforeseen side effects. To address
this, we propose DySK-Attn, a novel framework that enables LLMs to efficiently
integrate real-time knowledge from a dynamic external source. Our approach
synergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated
instantaneously. The core of our framework is a sparse knowledge attention
mechanism, which allows the LLM to perform a coarse-to-fine grained search,
efficiently identifying and focusing on a small, highly relevant subset of
facts from the vast KG. This mechanism avoids the high computational cost of
dense attention over the entire knowledge base and mitigates noise from
irrelevant information. We demonstrate through extensive experiments on
time-sensitive question-answering tasks that DySK-Attn significantly
outperforms strong baselines, including standard Retrieval-Augmented Generation
(RAG) and model editing techniques, in both factual accuracy for updated
knowledge and computational efficiency. Our framework offers a scalable and
effective solution for building LLMs that can stay current with the
ever-changing world.

</details>


### [2] [CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models](https://arxiv.org/abs/2508.06524)
*Lei Jiang,Fan Chen*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了CarbonScaling框架，将神经扩展定律与碳排放结合，分析LLM训练中的碳足迹。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM规模扩大时碳排放的指数增长问题，以推动可持续的LLM训练。

Method: 方法包括整合神经扩展模型、GPU硬件演进、并行优化和碳排放估算，定量分析模型精度与碳足迹的关系。

Result: 结果显示精度与碳排放呈幂律关系，但实际效率问题显著增加了扩展因子；硬件技术对小中型模型有效，但对超大型LLM效果有限。

Conclusion: 结论是通过优化训练（如关键批量扩展）可提高效率，CarbonScaling为可持续LLM训练提供了关键见解。

Abstract: Neural scaling laws have driven the development of increasingly large
language models (LLMs) by linking accuracy improvements to growth in parameter
count, dataset size, and compute. However, these laws overlook the carbon
emissions that scale exponentially with LLM size. This paper presents
\textit{CarbonScaling}, an analytical framework that extends neural scaling
laws to incorporate both operational and embodied carbon in LLM training. By
integrating models for neural scaling, GPU hardware evolution, parallelism
optimization, and carbon estimation, \textit{CarbonScaling} quantitatively
connects model accuracy to carbon footprint. Results show that while a
power-law relationship between accuracy and carbon holds, real-world
inefficiencies significantly increase the scaling factor. Hardware technology
scaling reduces carbon emissions for small to mid-sized models, but offers
diminishing returns for extremely large LLMs due to communication overhead and
underutilized GPUs. Training optimizations-especially aggressive critical batch
size scaling-help alleviate this inefficiency. \textit{CarbonScaling} offers
key insights for training more sustainable and carbon-efficient LLMs.

</details>


### [3] [Factor Augmented Supervised Learning with Text Embeddings](https://arxiv.org/abs/2508.06548)
*Zhanye Luo,Yuefeng Han,Xiufan Yu*

Main category: cs.CL

Relevance: 85.0

TL;DR: AEALT是一种监督式降维框架，通过增强自编码器将高维文本嵌入转换为低维任务相关表示，提升下游任务效率。


<details>
  <summary>Details</summary>
Motivation: 高维文本嵌入在计算效率和成本上存在问题，需要一种方法直接在学习流程中降维。

Method: 提取文本嵌入后，通过监督增强自编码器学习低维任务相关潜在因子。

Result: 在分类、异常检测和预测任务中，AEALT优于原始嵌入和传统降维方法。

Conclusion: AEALT有效解决了高维嵌入的效率问题，并在多种任务中表现优异。

Abstract: Large language models (LLMs) generate text embeddings from text data,
producing vector representations that capture the semantic meaning and
contextual relationships of words. However, the high dimensionality of these
embeddings often impedes efficiency and drives up computational cost in
downstream tasks. To address this, we propose AutoEncoder-Augmented Learning
with Text (AEALT), a supervised, factor-augmented framework that incorporates
dimension reduction directly into pre-trained LLM workflows. First, we extract
embeddings from text documents; next, we pass them through a supervised
augmented autoencoder to learn low-dimensional, task-relevant latent factors.
By modeling the nonlinear structure of complex embeddings, AEALT outperforms
conventional deep-learning approaches that rely on raw embeddings. We validate
its broad applicability with extensive experiments on classification, anomaly
detection, and prediction tasks using multiple real-world public datasets.
Numerical results demonstrate that AEALT yields substantial gains over both
vanilla embeddings and several standard dimension reduction methods.

</details>


### [4] [Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs](https://arxiv.org/abs/2508.06583)
*Ying Liu,Can Li,Ting Zhang,Mei Wang,Qiannan Zhu,Jian Li,Hua Huang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究提出了GuideEval基准，评估LLMs在动态调整教学策略以响应学习者认知状态方面的能力，发现现有模型表现不佳，并提出了一种行为引导的微调策略以提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs的苏格拉底式提问能力，但忽略了基于学习者认知状态的自适应指导。本研究旨在填补这一空白。

Method: 提出GuideEval基准，基于真实教育对话，通过感知、编排和激发三阶段行为框架评估LLMs的教学指导能力，并引入行为引导的微调策略。

Result: 现有LLMs在自适应指导方面表现不佳，尤其是在学习者困惑或需要引导时。行为引导的微调策略显著提升了指导性能。

Conclusion: 研究倡导从孤立内容评估转向以学习者为中心的交互范式，为LLMs的教学能力评估提供了新方向。

Abstract: The conversational capabilities of large language models hold significant
promise for enabling scalable and interactive tutoring. While prior research
has primarily examined their capacity for Socratic questioning, it often
overlooks a critical dimension: adaptively guiding learners based on their
cognitive states. This study shifts focus from mere question generation to the
broader instructional guidance capability. We ask: Can LLMs emulate expert
tutors who dynamically adjust strategies in response to learners'
understanding? To investigate this, we propose GuideEval, a benchmark grounded
in authentic educational dialogues that evaluates pedagogical guidance through
a three-phase behavioral framework: (1) Perception, inferring learner states;
(2) Orchestration, adapting instructional strategies; and (3) Elicitation,
stimulating proper reflections. Empirical findings reveal that existing LLMs
frequently fail to provide effective adaptive scaffolding when learners exhibit
confusion or require redirection. Furthermore, we introduce a behavior-guided
finetuning strategy that leverages behavior-prompted instructional dialogues,
significantly enhancing guidance performance. By shifting the focus from
isolated content evaluation to learner-centered interaction, our work advocates
a more dialogic paradigm for evaluating Socratic LLMs.

</details>


### [5] [LLM Unlearning Without an Expert Curated Dataset](https://arxiv.org/abs/2508.06595)
*Xiaoyuan Zhu,Muru Zhang,Ollie Liu,Robin Jia,Willie Neiswanger*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种自动化生成高质量遗忘数据集的方法，用于大规模语言模型的后验遗忘，无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 现代大规模语言模型可能编码敏感或有害知识，需要后验遗忘技术，但现有方法依赖人工构建遗忘数据集，效率低。

Method: 通过结构化提示管道自动生成教科书风格的数据集，仅需输入领域名称。

Result: 实验表明，合成数据集在遗忘生物安全、网络安全等领域表现优于基线，接近专家构建的数据集。

Conclusion: 合成数据集为广泛领域的实用、可扩展遗忘提供了一条可行路径。

Abstract: Modern large language models often encode sensitive, harmful, or copyrighted
knowledge, raising the need for post-hoc unlearning-the ability to remove
specific domains of knowledge from a model without full retraining. A major
bottleneck in current unlearning pipelines is constructing effective forget
sets-datasets that approximate the target domain and guide the model to forget
it. In this work, we introduce a scalable, automated approach to generate
high-quality forget sets using language models themselves. Our method
synthesizes textbook-style data through a structured prompting pipeline,
requiring only a domain name as input. Through experiments on unlearning
biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic
datasets consistently outperform the baseline synthetic alternatives and are
comparable to the expert-curated ones. Additionally, ablation studies reveal
that the multi-step generation pipeline significantly boosts data diversity,
which in turn improves unlearning utility. Overall, our findings suggest that
synthetic datasets offer a promising path toward practical, scalable unlearning
for a wide range of emerging domains without the need for manual intervention.
We release our code and dataset at
https://github.com/xyzhu123/Synthetic_Textbook.

</details>


### [6] [BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent](https://arxiv.org/abs/2508.06600)
*Zijian Chen,Xueguang Ma,Shengyao Zhuang,Ping Nie,Kai Zou,Andrew Liu,Joshua Green,Kshama Patel,Ruoxi Meng,Mingyi Su,Sahel Sharifymoghaddam,Yanxi Li,Haoran Hong,Xinyu Shi,Xuye Liu,Nandan Thakur,Crystina Zhang,Luyu Gao,Wenhu Chen,Jimmy Lin*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了BrowseComp-Plus基准，解决了现有评测在公平性和透明度上的问题，通过固定语料库实现可控实验，有效区分深度研究系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有评测（如BrowseComp）依赖动态且不透明的网络搜索API，导致公平性和透明度问题，无法有效评估深度研究LLM的能力。

Method: 基于BrowseComp构建BrowseComp-Plus，使用固定语料库，包含人工验证的支持文档和挑战性负样本，支持可控实验。

Result: BrowseComp-Plus能有效区分系统性能，例如GPT-5+Qwen3-Embedding-8B检索器将准确率提升至70.1%。

Conclusion: BrowseComp-Plus为深度研究系统和检索方法提供了全面的评测框架，促进了对检索效果、引用准确性和上下文工程的理解。

Abstract: Deep-Research agents, which integrate large language models (LLMs) with
search tools, have shown success in improving the effectiveness of handling
complex queries that require iterative search planning and reasoning over
search results. Evaluations on current benchmarks like BrowseComp relies on
black-box live web search APIs, have notable limitations in (1) fairness:
dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep
research methods; (2) transparency: lack of control over the document corpus
makes it difficult to isolate retriever contributions. In other words, the
current evaluations may compare a complete deep research system at a given
time, but they do not foster well-controlled experiments to provide insights
into the capability of underlying deep research LLMs. To address these
challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp,
employing a fixed, carefully curated corpus. Each query in BrowseComp-Plus
includes human-verified supporting documents and mined challenging negatives,
enabling controlled experimentation. The benchmark is shown to be effective in
distinguishing the performance of deep research systems. For instance, the
open-source model Search-R1, when paired with the BM25 retriever, achieves
3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with
the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with
fewer search calls. This benchmark allows comprehensive evaluation and
disentangled analysis of deep research agents and retrieval methods, fostering
insights into retrieval effectiveness, citation accuracy, and context
engineering in Deep-Research system.

</details>


### [7] [Measuring Stereotype and Deviation Biases in Large Language Models](https://arxiv.org/abs/2508.06649)
*Daniel Wang,Eli Brignac,Minjia Mao,Xiao Fang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究探讨了大型语言模型（LLMs）中存在的两种偏见：刻板印象偏见和偏差偏见，并通过实验验证了多种LLMs在这些偏见上的表现。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，其潜在的偏见和风险引起了关注。研究旨在揭示LLMs在生成内容时可能存在的偏见问题。

Method: 通过让四种先进的LLMs生成个人资料，分析其在不同人口统计群体（如政治倾向、宗教、性取向）上的偏见表现。

Result: 实验结果表明，所有测试的LLMs均对多个群体表现出显著的刻板印象偏见和偏差偏见。

Conclusion: 研究揭示了LLMs在推断用户属性时存在的偏见，并指出了LLM生成内容可能带来的潜在危害。

Abstract: Large language models (LLMs) are widely applied across diverse domains,
raising concerns about their limitations and potential risks. In this study, we
investigate two types of bias that LLMs may display: stereotype bias and
deviation bias. Stereotype bias refers to when LLMs consistently associate
specific traits with a particular demographic group. Deviation bias reflects
the disparity between the demographic distributions extracted from
LLM-generated content and real-world demographic distributions. By asking four
advanced LLMs to generate profiles of individuals, we examine the associations
between each demographic group and attributes such as political affiliation,
religion, and sexual orientation. Our experimental results show that all
examined LLMs exhibit both significant stereotype bias and deviation bias
towards multiple groups. Our findings uncover the biases that occur when LLMs
infer user attributes and shed light on the potential harms of LLM-generated
outputs.

</details>


### [8] [Do Biased Models Have Biased Thoughts?](https://arxiv.org/abs/2508.06671)
*Swati Rajwal,Shivank Garg,Reem Abdel-Salam,Abdelrahman Zayed*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究探讨了链式思维提示对语言模型公平性的影响，发现模型决策中的偏见与其思维步骤中的偏见相关性较低。


<details>
  <summary>Details</summary>
Motivation: 语言模型存在性别、种族等多方面的偏见，研究旨在通过链式思维提示分析模型思维步骤中的偏见与其输出偏见的关系。

Method: 在5个流行的大语言模型上实验，使用公平性指标量化11种偏见，分析思维步骤与输出偏见的关联。

Result: 模型思维步骤中的偏见与输出偏见相关性较低（多数情况下相关系数小于0.6，p值小于0.001）。

Conclusion: 与人类不同，测试的模型即使决策有偏见，思维步骤中未必有偏见。

Abstract: The impressive performance of language models is undeniable. However, the
presence of biases based on gender, race, socio-economic status, physical
appearance, and sexual orientation makes the deployment of language models
challenging. This paper studies the effect of chain-of-thought prompting, a
recent approach that studies the steps followed by the model before it
responds, on fairness. More specifically, we ask the following question:
\textit{Do biased models have biased thoughts}? To answer our question, we
conduct experiments on $5$ popular large language models using fairness metrics
to quantify $11$ different biases in the model's thoughts and output. Our
results show that the bias in the thinking steps is not highly correlated with
the output bias (less than $0.6$ correlation with a $p$-value smaller than
$0.001$ in most cases). In other words, unlike human beings, the tested models
with biased decisions do not always possess biased thoughts.

</details>


### [9] [Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge](https://arxiv.org/abs/2508.06709)
*Evangelia Spiliopoulou,Riccardo Fogliato,Hanna Burnsky,Tamer Soliman,Jie Ma,Graham Horwood,Miguel Ballesteros*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了一种统计框架，用于识别和量化LLM作为评委时的自我偏见（self-bias），并通过实验验证了某些模型（如GPT-4o和Claude 3.5 Sonnet）存在自我偏见和家族偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决LLM作为评委时可能存在的自我偏见问题，避免将模型真实性能差异误认为偏见。

Method: 方法是通过统计框架建模LLM评分分布差异，结合第三方评委（如人类）的评分来量化自我偏见。

Result: 结果表明，某些LLM（如GPT-4o和Claude 3.5 Sonnet）会系统性高估自身输出，并存在家族偏见。

Conclusion: 结论强调了使用LLM评委时的潜在问题，并提供了减少偏见的实用建议。

Abstract: Large language models (LLMs) can serve as judges that offer rapid and
reliable assessments of other LLM outputs. However, models may systematically
assign overly favorable ratings to their own outputs, a phenomenon known as
self-bias, which can distort evaluations of true model performance. Previous
studies often conflate genuine differences in model quality with bias or
incorrectly assume that evaluations from LLMs and humans follow the same rating
distributions. In this work, we present a statistical framework that explicitly
formalizes assumptions under which self-bias can be identified and estimated.
Our method models the difference in the scoring distribution that
LLM-as-a-judge assigns to its own completions compared to other models, while
accounting for the underlying quality of the completions provided by an
independent, third-party judge (e.g., humans). Our method reliably isolates and
quantifies self-bias, even when models vary in ability, ensuring that genuine
performance differences are not mistaken for self-bias. We conduct an empirical
analysis of self-bias on a large dataset (>5000 prompt-completion pairs)
consisting of expert human annotations and judgments from nine different LLM
judges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet,
systematically assign higher scores to their own outputs. These models also
display family-bias; systematically assigning higher ratings to outputs
produced by other models of the same family. Our findings highlight potential
pitfalls of using LLM judges and offer practical guidance to mitigate biases
when interpreting automated evaluations.

</details>


### [10] [Many-Turn Jailbreaking](https://arxiv.org/abs/2508.06755)
*Xianjun Yang,Liqiang Xiao,Shiyang Li,Faisal Ladhak,Hyokun Yun,Linda Ruth Petzold,Yi Xu,William Yang Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出多轮越狱攻击（multi-turn jailbreaking）的概念，并构建了MTJ-Bench基准测试，以评估LLMs在多轮对话中的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有越狱攻击仅关注单轮对话，而实际应用中LLMs常需处理多轮对话，因此探索多轮越狱攻击更具现实威胁。

Method: 构建MTJ-Bench基准测试，对开源和闭源模型进行多轮越狱攻击测试。

Result: 揭示了LLMs在多轮对话中的新安全漏洞。

Conclusion: 呼吁社区关注多轮越狱攻击，推动更安全的LLMs开发。

Abstract: Current jailbreaking work on large language models (LLMs) aims to elicit
unsafe outputs from given prompts. However, it only focuses on single-turn
jailbreaking targeting one specific query. On the contrary, the advanced LLMs
are designed to handle extremely long contexts and can thus conduct multi-turn
conversations. So, we propose exploring multi-turn jailbreaking, in which the
jailbroken LLMs are continuously tested on more than the first-turn
conversation or a single target query. This is an even more serious threat
because 1) it is common for users to continue asking relevant follow-up
questions to clarify certain jailbroken details, and 2) it is also possible
that the initial round of jailbreaking causes the LLMs to respond to additional
irrelevant questions consistently. As the first step (First draft done at June
2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak
Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and
closed-source models and provide novel insights into this new safety threat. By
revealing this new vulnerability, we aim to call for community efforts to build
safer LLMs and pave the way for a more in-depth understanding of jailbreaking
LLMs.

</details>


### [11] [Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection](https://arxiv.org/abs/2508.06913)
*Siyuan Li,Xi Lin,Guangyan Li,Zehao Liu,Aodu Wulianghai,Li Ding,Jun Wu,Jianhua Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: SentiDetect是一种模型无关的框架，通过分析情感分布稳定性差异来检测LLM生成的文本，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法泛化性差且易受攻击，SentiDetect利用LLM输出情感一致性更高的特点，提出新解决方案。

Method: 定义两个互补指标（情感分布一致性和情感分布保持性），量化情感和语义变换下的稳定性。

Result: 在多个数据集和LLM上表现优异，F1分数提升显著，且对攻击和变体更鲁棒。

Conclusion: SentiDetect在检测LLM生成文本方面具有显著优势，尤其在复杂场景下。

Abstract: The rapid advancement of large language models (LLMs) has resulted in
increasingly sophisticated AI-generated content, posing significant challenges
in distinguishing LLM-generated text from human-written language. Existing
detection methods, primarily based on lexical heuristics or fine-tuned
classifiers, often suffer from limited generalizability and are vulnerable to
paraphrasing, adversarial perturbations, and cross-domain shifts. In this work,
we propose SentiDetect, a model-agnostic framework for detecting LLM-generated
text by analyzing the divergence in sentiment distribution stability. Our
method is motivated by the empirical observation that LLM outputs tend to
exhibit emotionally consistent patterns, whereas human-written texts display
greater emotional variability. To capture this phenomenon, we define two
complementary metrics: sentiment distribution consistency and sentiment
distribution preservation, which quantify stability under sentiment-altering
and semantic-preserving transformations. We evaluate SentiDetect on five
diverse datasets and a range of advanced LLMs,including Gemini-1.5-Pro,
Claude-3, GPT-4-0613, and LLaMa-3.3. Experimental results demonstrate its
superiority over state-of-the-art baselines, with over 16% and 11% F1 score
improvements on Gemini-1.5-Pro and GPT-4-0613, respectively. Moreover,
SentiDetect also shows greater robustness to paraphrasing, adversarial attacks,
and text length variations, outperforming existing detectors in challenging
scenarios.

</details>


### [12] [Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models](https://arxiv.org/abs/2508.06974)
*Zhijun Tu,Hanting Chen,Siqi Liu,Chuanjian Liu,Jian Li,Jie Hu,Yunhe Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种渐进式训练方法，将预训练LLM的浮点权重平滑转换为1-bit量化，结合二进制感知初始化和双尺度补偿，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有1-bit量化方法需从头训练LLM，成本高且精度损失大，未能充分利用预训练模型。

Method: 采用渐进式训练，结合二进制感知初始化和双尺度补偿，平滑转换浮点权重为1-bit表示。

Result: 实验表明，该方法在不同规模LLM上优于现有方法，且无需从头训练。

Conclusion: 通过预训练模型实现高性能1-bit量化LLM，显著降低成本。

Abstract: 1-bit LLM quantization offers significant advantages in reducing storage and
computational costs. However, existing methods typically train 1-bit LLMs from
scratch, failing to fully leverage pre-trained models. This results in high
training costs and notable accuracy degradation. We identify that the large gap
between full precision and 1-bit representations makes direct adaptation
difficult. In this paper, we introduce a consistent progressive training for
both forward and backward, smoothly converting the floating-point weights into
the binarized ones. Additionally, we incorporate binary-aware initialization
and dual-scaling compensation to reduce the difficulty of progressive training
and improve the performance. Experimental results on LLMs of various sizes
demonstrate that our method outperforms existing approaches. Our results show
that high-performance 1-bit LLMs can be achieved using pre-trained models,
eliminating the need for expensive training from scratch.

</details>


### [13] [BharatBBQ: A Multilingual Bias Benchmark for Question Answering in the Indian Context](https://arxiv.org/abs/2508.07090)
*Aditya Tomar,Nihar Ranjan Sahoo,Pushpak Bhattacharyya*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文介绍了BharatBBQ，一个针对印度多语言环境的偏见评估基准，填补了现有西方中心化评测的不足。


<details>
  <summary>Details</summary>
Motivation: 现有偏见评测基准（如BBQ）主要关注西方语境，缺乏对印度多语言和文化背景的覆盖，限制了公平性评估的适用性。

Method: 开发了BharatBBQ，涵盖8种印度语言和13个社会类别，通过翻译和验证扩展数据集至392,864个例子，并评估了5个多语言模型在零样本和少样本设置下的偏见表现。

Result: 研究发现模型在印度语言中的偏见普遍存在且比英语更严重，凸显了基于语言和文化背景的偏见评测的必要性。

Conclusion: BharatBBQ为印度多语言环境提供了更全面的偏见评测工具，揭示了模型偏见的普遍性和文化依赖性。

Abstract: Evaluating social biases in language models (LMs) is crucial for ensuring
fairness and minimizing the reinforcement of harmful stereotypes in AI systems.
Existing benchmarks, such as the Bias Benchmark for Question Answering (BBQ),
primarily focus on Western contexts, limiting their applicability to the Indian
context. To address this gap, we introduce BharatBBQ, a culturally adapted
benchmark designed to assess biases in Hindi, English, Marathi, Bengali, Tamil,
Telugu, Odia, and Assamese. BharatBBQ covers 13 social categories, including 3
intersectional groups, reflecting prevalent biases in the Indian sociocultural
landscape. Our dataset contains 49,108 examples in one language that are
expanded using translation and verification to 392,864 examples in eight
different languages. We evaluate five multilingual LM families across zero and
few-shot settings, analyzing their bias and stereotypical bias scores. Our
findings highlight persistent biases across languages and social categories and
often amplified biases in Indian languages compared to English, demonstrating
the necessity of linguistically and culturally grounded benchmarks for bias
evaluation.

</details>


### [14] [Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning](https://arxiv.org/abs/2508.07101)
*Lijie Yang,Zhihao Zhang,Arti Jain,Shijie Cao,Baihong Yuan,Yiwei Chen,Zhihao Jia,Ravi Netravali*

Main category: cs.CL

Relevance: 85.0

TL;DR: LessIsMore是一种无需训练的稀疏注意力机制，通过全局注意力模式提升推理任务的效率和准确性，减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决现有稀疏注意力机制在长序列推理中因累积误差导致的准确性下降问题，同时避免高令牌保留率或昂贵重新训练的需求。

Method: 利用全局注意力模式聚合局部注意力头的令牌选择，结合近期上下文信息，实现跨头令牌统一排序，避免为每个头维护独立令牌子集。

Result: 在多样化推理任务和基准测试中，LessIsMore保持或提升准确性，解码速度平均提升1.1倍，令牌关注数量减少2倍，端到端速度提升1.13倍。

Conclusion: LessIsMore通过统一的令牌选择机制，显著提升了推理任务的效率和准确性，适用于大规模语言模型。

Abstract: Large reasoning models achieve strong performance through test-time scaling
but incur substantial computational overhead, particularly from excessive token
generation when processing short input prompts. While sparse attention
mechanisms can reduce latency and memory usage, existing approaches suffer from
significant accuracy degradation due to accumulated errors during
long-generation reasoning. These methods generally require either high token
retention rates or expensive retraining. We introduce LessIsMore, a
training-free sparse attention mechanism for reasoning tasks, which leverages
global attention patterns rather than relying on traditional head-specific
local optimizations. LessIsMore aggregates token selections from local
attention heads with recent contextual information, enabling unified cross-head
token ranking for future decoding layers. This unified selection improves
generalization and efficiency by avoiding the need to maintain separate token
subsets per head. Evaluation across diverse reasoning tasks and benchmarks
shows that LessIsMore preserves -- and in some cases improves -- accuracy while
achieving a $1.1\times$ average decoding speed-up compared to full attention.
Moreover, LessIsMore attends to $2\times$ fewer tokens without accuracy loss,
achieving a $1.13\times$ end-to-end speed-up compared to existing sparse
attention methods.

</details>


### [15] [Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution](https://arxiv.org/abs/2508.07111)
*Falaah Arif Khan,Nivedha Sivakumar,Yinong Oliver Wang,Katherine Metcalf,Cezanne Camacho,Barry-John Theobald,Luca Zappella,Nicholas Apostoloff*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文研究了大型语言模型（LLMs）在交叉性偏见方面的表现，提出了一个新的基准WinoIdentity，并发现LLMs在多重身份交叉时表现出显著的置信度差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于现有评估主要关注单一维度的偏见，而忽视了交叉性偏见可能带来的社会危害。

Method: 方法包括创建WinoIdentity基准，扩展WinoBias数据集，引入245,700个提示以评估50种偏见模式，并提出Coreference Confidence Disparity指标。

Result: 评估了五个最新LLMs，发现置信度差异高达40%，模型对双重劣势身份的置信度最低。

Conclusion: LLMs的优异表现可能源于记忆而非逻辑推理，存在价值对齐和有效性的双重失败。

Abstract: Large language models (LLMs) have achieved impressive performance, leading to
their widespread adoption as decision-support tools in resource-constrained
contexts like hiring and admissions. There is, however, scientific consensus
that AI systems can reflect and exacerbate societal biases, raising concerns
about identity-based harm when used in critical social contexts. Prior work has
laid a solid foundation for assessing bias in LLMs by evaluating demographic
disparities in different language reasoning tasks. In this work, we extend
single-axis fairness evaluations to examine intersectional bias, recognizing
that when multiple axes of discrimination intersect, they create distinct
patterns of disadvantage. We create a new benchmark called WinoIdentity by
augmenting the WinoBias dataset with 25 demographic markers across 10
attributes, including age, nationality, and race, intersected with binary
gender, yielding 245,700 prompts to evaluate 50 distinct bias patterns.
Focusing on harms of omission due to underrepresentation, we investigate bias
through the lens of uncertainty and propose a group (un)fairness metric called
Coreference Confidence Disparity which measures whether models are more or less
confident for some intersectional identities than others. We evaluate five
recently published LLMs and find confidence disparities as high as 40% along
various demographic attributes including body type, sexual orientation and
socio-economic status, with models being most uncertain about
doubly-disadvantaged identities in anti-stereotypical settings. Surprisingly,
coreference confidence decreases even for hegemonic or privileged markers,
indicating that the recent impressive performance of LLMs is more likely due to
memorization than logical reasoning. Notably, these are two independent
failures in value alignment and validity that can compound to cause social
harm.

</details>


### [16] [Gradient Surgery for Safe LLM Fine-Tuning](https://arxiv.org/abs/2508.07172)
*Biao Yi,Jiahao Li,Baolei Zhang,Lihai Nie,Tong Li,Tiansheng Huang,Zheli Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: SafeGrad通过梯度手术解决微调服务中的安全对齐问题，有效抵御高比例恶意样本的干扰。


<details>
  <summary>Details</summary>
Motivation: 研究发现在微调服务中，少量恶意样本会破坏LLMs的安全对齐，现有方法对有害样本比例敏感。

Method: 提出SafeGrad方法，通过梯度投影和KL散度对齐损失解决梯度冲突问题。

Result: 实验表明SafeGrad在高有害比例下仍保持安全性和任务性能。

Conclusion: SafeGrad为LLMs微调提供了高效且鲁棒的安全防御方案。

Abstract: Fine-tuning-as-a-Service introduces a critical vulnerability where a few
malicious examples mixed into the user's fine-tuning dataset can compromise the
safety alignment of Large Language Models (LLMs). While a recognized paradigm
frames safe fine-tuning as a multi-objective optimization problem balancing
user task performance with safety alignment, we find existing solutions are
critically sensitive to the harmful ratio, with defenses degrading sharply as
harmful ratio increases. We diagnose that this failure stems from conflicting
gradients, where the user-task update directly undermines the safety objective.
To resolve this, we propose SafeGrad, a novel method that employs gradient
surgery. When a conflict is detected, SafeGrad nullifies the harmful component
of the user-task gradient by projecting it onto the orthogonal plane of the
alignment gradient, allowing the model to learn the user's task without
sacrificing safety. To further enhance robustness and data efficiency, we
employ a KL-divergence alignment loss that learns the rich, distributional
safety profile of the well-aligned foundation model. Extensive experiments show
that SafeGrad provides state-of-the-art defense across various LLMs and
datasets, maintaining robust safety even at high harmful ratios without
compromising task fidelity.

</details>


### [17] [Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models](https://arxiv.org/abs/2508.07173)
*Leyi Pan,Zheyu Fu,Yunpeng Zhai,Shuchang Tao,Sheng Guan,Shiyu Huang,Lingzhe Zhang,Zhaoyang Liu,Bolin Ding,Felix Henry,Lijie Wen,Aiwei Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了首个针对多模态大语言模型（OLLMs）的全面安全评估基准Omni-SafetyBench，并设计了专用指标（C-ASR、C-RR、CMSC-score）以评估其安全性和跨模态一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法评估OLLMs在音频-视觉联合输入下的安全性，亟需填补这一空白。

Method: 开发Omni-SafetyBench基准，包含24种模态组合和972个样本，提出C-ASR、C-RR和CMSC-score指标。

Result: 评估10个OLLMs发现普遍存在安全漏洞，复杂输入下防御能力下降，跨模态一致性差。

Conclusion: OLLMs安全性亟待提升，基准为未来改进提供基础。

Abstract: The rise of Omni-modal Large Language Models (OLLMs), which integrate visual
and auditory processing with text, necessitates robust safety evaluations to
mitigate harmful outputs. However, no dedicated benchmarks currently exist for
OLLMs, and prior benchmarks designed for other LLMs lack the ability to assess
safety performance under audio-visual joint inputs or cross-modal safety
consistency. To fill this gap, we introduce Omni-SafetyBench, the first
comprehensive parallel benchmark for OLLM safety evaluation, featuring 24
modality combinations and variations with 972 samples each, including dedicated
audio-visual harm cases. Considering OLLMs' comprehension challenges with
complex omni-modal inputs and the need for cross-modal consistency evaluation,
we propose tailored metrics: a Safety-score based on conditional Attack Success
Rate (C-ASR) and Refusal Rate (C-RR) to account for comprehension failures, and
a Cross-Modal Safety Consistency Score (CMSC-score) to measure consistency
across modalities. Evaluating 6 open-source and 4 closed-source OLLMs reveals
critical vulnerabilities: (1) no model excels in both overall safety and
consistency, with only 3 models achieving over 0.6 in both metrics and top
performer scoring around 0.8; (2) safety defenses weaken with complex inputs,
especially audio-visual joints; (3) severe weaknesses persist, with some models
scoring as low as 0.14 on specific modalities. Our benchmark and metrics
highlight urgent needs for enhanced OLLM safety, providing a foundation for
future improvements.

</details>


### [18] [Enhancing Rumor Detection Methods with Propagation Structure Infused Language Model](https://arxiv.org/abs/2508.07209)
*Chaoqun Cui,Siyuan Li,Kunkun Ma,Caiyan Jia*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种名为PEP的继续预训练策略，通过预测帖子间的关系来提升PLM在社交媒体谣言检测中的性能，并发布了相关数据集和模型SoLM。


<details>
  <summary>Details</summary>
Motivation: 解决PLM在社交媒体任务（如谣言检测）中表现不佳的问题，原因包括预训练语料与社交媒体文本不匹配、对社交媒体特有符号处理不足以及预训练任务不适合建模传播结构中的用户互动。

Method: 提出PEP策略，通过预测帖子间的根、分支和父关系来捕捉传播结构中的互动信息；发布TwitterCorpus和两个未标注的传播结构数据集；训练Twitter专用PLM SoLM。

Result: PEP显著提升了PLM在谣言检测中的性能，在基准数据集上提升1.0-3.7%准确率，甚至超越现有SOTA方法；SoLM也取得竞争性结果。

Conclusion: PEP策略能有效学习帖子互动的判别特征，显著提升PLM在社交媒体任务中的表现。

Abstract: Pretrained Language Models (PLMs) have excelled in various Natural Language
Processing tasks, benefiting from large-scale pretraining and self-attention
mechanism's ability to capture long-range dependencies. However, their
performance on social media application tasks like rumor detection remains
suboptimal. We attribute this to mismatches between pretraining corpora and
social texts, inadequate handling of unique social symbols, and pretraining
tasks ill-suited for modeling user engagements implicit in propagation
structures. To address these issues, we propose a continue pretraining strategy
called Post Engagement Prediction (PEP) to infuse information from propagation
structures into PLMs. PEP makes models to predict root, branch, and parent
relations between posts, capturing interactions of stance and sentiment crucial
for rumor detection. We also curate and release large-scale Twitter corpus:
TwitterCorpus (269GB text), and two unlabeled claim conversation datasets with
propagation structures (UTwitter and UWeibo). Utilizing these resources and PEP
strategy, we train a Twitter-tailored PLM called SoLM. Extensive experiments
demonstrate PEP significantly boosts rumor detection performance across
universal and social media PLMs, even in few-shot scenarios. On benchmark
datasets, PEP enhances baseline models by 1.0-3.7\% accuracy, even enabling it
to outperform current state-of-the-art methods on multiple datasets. SoLM
alone, without high-level modules, also achieves competitive results,
highlighting the strategy's effectiveness in learning discriminative post
interaction features.

</details>


### [19] ["Pull or Not to Pull?'': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas](https://arxiv.org/abs/2508.07284)
*Junchen Ding,Penghao Jiang,Zihao Xu,Ziqi Ding,Yichen Zhu,Jiaojiao Jiang,Yuekang Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文对14种主流LLM在27种电车问题场景下的道德推理进行了评估，揭示了不同伦理框架下模型的决策差异，并呼吁将道德推理作为LLM对齐的主要指标。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地参与伦理敏感决策，理解其道德推理过程变得至关重要。

Method: 采用因子提示协议，收集了3,780个二元决策和自然语言解释，分析了决策果断性、解释一致性、公共道德对齐及对无关伦理线索的敏感性。

Result: 发现推理增强模型更果断且解释更结构化，但未必更符合人类共识；在某些伦理框架下（如利他主义）表现较好，而在其他框架下（如亲缘关系）则存在争议。

Conclusion: 道德提示不仅是行为调节工具，还能揭示模型潜在的对齐哲学，建议将道德推理作为LLM对齐的核心指标。

Abstract: As large language models (LLMs) increasingly mediate ethically sensitive
decisions, understanding their moral reasoning processes becomes imperative.
This study presents a comprehensive empirical evaluation of 14 leading LLMs,
both reasoning enabled and general purpose, across 27 diverse trolley problem
scenarios, framed by ten moral philosophies, including utilitarianism,
deontology, and altruism. Using a factorial prompting protocol, we elicited
3,780 binary decisions and natural language justifications, enabling analysis
along axes of decisional assertiveness, explanation answer consistency, public
moral alignment, and sensitivity to ethically irrelevant cues. Our findings
reveal significant variability across ethical frames and model types: reasoning
enhanced models demonstrate greater decisiveness and structured justifications,
yet do not always align better with human consensus. Notably, "sweet zones"
emerge in altruistic, fairness, and virtue ethics framings, where models
achieve a balance of high intervention rates, low explanation conflict, and
minimal divergence from aggregated human judgments. However, models diverge
under frames emphasizing kinship, legality, or self interest, often producing
ethically controversial outcomes. These patterns suggest that moral prompting
is not only a behavioral modifier but also a diagnostic tool for uncovering
latent alignment philosophies across providers. We advocate for moral reasoning
to become a primary axis in LLM alignment, calling for standardized benchmarks
that evaluate not just what LLMs decide, but how and why.

</details>


### [20] [CCFQA: A Benchmark for Cross-Lingual and Cross-Modal Speech and Text Factuality Evaluation](https://arxiv.org/abs/2508.07295)
*Yexing Du,Kaiyuan Liu,Youcheng Pan,Zheng Chu,Bo Yang,Xiaocheng Feng,Yang Xiang,Ming Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一个跨语言和跨模态的事实性基准（CCFQA），用于评估多模态大语言模型（MLLMs）在多语言语音输入中的可靠性。实验表明当前MLLMs在此基准上表现不佳，并提出了一种少样本迁移学习策略，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准主要关注英语文本或视觉模态，缺乏对多语言语音输入的评估，因此需要填补这一空白。

Method: 设计了包含8种语言的平行语音-文本事实性问题基准（CCFQA），并提出了一种少样本迁移学习策略，将英语QA能力迁移到多语言语音QA任务中。

Result: 当前MLLMs在CCFQA基准上表现不佳，但提出的迁移学习策略显著提升了性能，仅需5次训练即可与GPT-4o-mini-Audio竞争。

Conclusion: CCFQA基准为开发更鲁棒和可靠的多语言语音理解MLLMs提供了重要资源。

Abstract: As Large Language Models (LLMs) are increasingly popularized in the
multilingual world, ensuring hallucination-free factuality becomes markedly
crucial. However, existing benchmarks for evaluating the reliability of
Multimodal Large Language Models (MLLMs) predominantly focus on textual or
visual modalities with a primary emphasis on English, which creates a gap in
evaluation when processing multilingual input, especially in speech. To bridge
this gap, we propose a novel \textbf{C}ross-lingual and \textbf{C}ross-modal
\textbf{F}actuality benchmark (\textbf{CCFQA}). Specifically, the CCFQA
benchmark contains parallel speech-text factual questions across 8 languages,
designed to systematically evaluate MLLMs' cross-lingual and cross-modal
factuality capabilities. Our experimental results demonstrate that current
MLLMs still face substantial challenges on the CCFQA benchmark. Furthermore, we
propose a few-shot transfer learning strategy that effectively transfers the
Question Answering (QA) capabilities of LLMs in English to multilingual Spoken
Question Answering (SQA) tasks, achieving competitive performance with
GPT-4o-mini-Audio using just 5-shot training. We release CCFQA as a
foundational research resource to promote the development of MLLMs with more
robust and reliable speech understanding capabilities. Our code and dataset are
available at https://github.com/yxduir/ccfqa.

</details>


### [21] [ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering](https://arxiv.org/abs/2508.07321)
*Shubhra Ghosh,Abhilekh Borah,Aditya Kumar Guru,Kripabandhu Ghosh*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种名为ObfusQAte的新技术，用于评估LLM在面对混淆问题时的鲁棒性，并引入了ObfusQA框架，通过多层次的混淆测试LLM的能力。研究发现LLM在复杂语言变化下容易失败或产生幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有研究未测试LLM在混淆问题下的鲁棒性，因此需要系统评估其局限性。

Method: 提出ObfusQAte技术和ObfusQA框架，通过三个维度（命名实体间接、干扰项间接、上下文过载）测试LLM。

Result: LLM在面对复杂语言变化时容易失败或产生幻觉。

Conclusion: ObfusQA为评估LLM鲁棒性提供了全面基准，并公开了ObfusQAte以促进研究。

Abstract: The rapid proliferation of Large Language Models (LLMs) has significantly
contributed to the development of equitable AI systems capable of factual
question-answering (QA). However, no known study tests the LLMs' robustness
when presented with obfuscated versions of questions. To systematically
evaluate these limitations, we propose a novel technique, ObfusQAte and,
leveraging the same, introduce ObfusQA, a comprehensive, first of its kind,
framework with multi-tiered obfuscation levels designed to examine LLM
capabilities across three distinct dimensions: (i) Named-Entity Indirection,
(ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these
fine-grained distinctions in language, ObfusQA provides a comprehensive
benchmark for evaluating LLM robustness and adaptability. Our study observes
that LLMs exhibit a tendency to fail or generate hallucinated responses when
confronted with these increasingly nuanced variations. To foster research in
this direction, we make ObfusQAte publicly available.

</details>


### [22] [Let's Revise Step-by-Step: A Unified Local Search Framework for Code Generation with LLMs](https://arxiv.org/abs/2508.07434)
*Zhiyi Lyu,Jianguo Huang,Yanchen Deng,Steven Hoi,Bo An*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种名为ReLoc的统一局部搜索框架，用于高效逐步修订代码生成，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成的推理时扩展技术存在效率和可扩展性问题，树搜索方法树规模增长快，而改进方法则面临奖励信号不明确和搜索效率低的挑战。

Method: ReLoc框架通过四个关键组件（初始代码草稿、邻域代码生成、候选评估和代码更新）实现逐步修订，并结合专用修订奖励模型指导搜索。

Result: 实验表明，ReLoc在多种代码生成任务中表现优异，显著优于树搜索和改进方法。

Conclusion: ReLoc为代码生成提供了一种高效且可扩展的解决方案。

Abstract: Large Language Models (LLMs) with inference-time scaling techniques show
promise for code generation, yet face notable efficiency and scalability
challenges. Construction-based tree-search methods suffer from rapid growth in
tree size, high token consumption, and lack of anytime property. In contrast,
improvement-based methods offer better performance but often struggle with
uninformative reward signals and inefficient search strategies. In this work,
we propose \textbf{ReLoc}, a unified local search framework which effectively
performs step-by-step code revision. Specifically, ReLoc explores a series of
local revisions through four key algorithmic components: initial code drafting,
neighborhood code generation, candidate evaluation, and incumbent code
updating, each of which can be instantiated with specific decision rules to
realize different local search algorithms such as Hill Climbing (HC) or Genetic
Algorithm (GA). Furthermore, we develop a specialized revision reward model
that evaluates code quality based on revision distance to produce fine-grained
preferences that guide the local search toward more promising candidates.
Finally, our extensive experimental results demonstrate that our approach
achieves superior performance across diverse code generation tasks,
significantly outperforming both construction-based tree search as well as the
state-of-the-art improvement-based code generation methods.

</details>


### [23] [Positional Biases Shift as Inputs Approach Context Window Limits](https://arxiv.org/abs/2508.07479)
*Blerta Veseli,Julian Chibane,Mariya Toneva,Alexander Koller*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文研究了LLMs在长输入中的位置偏见，发现‘Lost in the Middle’效应在输入占模型上下文窗口50%时最明显，超过后变为距离偏见。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在长输入中信息利用效率低的问题，探究位置偏见的强度和条件。

Method: 通过相对输入长度分析，定义与模型上下文窗口的关系。

Result: LiM效应在输入占窗口50%时最强，超过后变为距离偏见；检索是推理的前提。

Conclusion: 研究对长上下文任务、LLM基准设计和评估方法有指导意义。

Abstract: Large Language Models (LLMs) often struggle to use information across long
inputs effectively. Prior work has identified positional biases, such as the
Lost in the Middle (LiM) effect, where models perform better when information
appears at the beginning (primacy bias) or end (recency bias) of the input,
rather than in the middle. However, long-context studies have not consistently
replicated these effects, raising questions about their intensity and the
conditions under which they manifest. To address this, we conducted a
comprehensive analysis using relative rather than absolute input lengths,
defined with respect to each model's context window. Our findings reveal that
the LiM effect is strongest when inputs occupy up to 50% of a model's context
window. Beyond that, the primacy bias weakens, while recency bias remains
relatively stable. This effectively eliminates the LiM effect; instead, we
observe a distance-based bias, where model performance is better when relevant
information is closer to the end of the input. Furthermore, our results suggest
that successful retrieval is a prerequisite for reasoning in LLMs, and that the
observed positional biases in reasoning are largely inherited from retrieval.
These insights have implications for long-context tasks, the design of future
LLM benchmarks, and evaluation methodologies for LLMs handling extended inputs.

</details>


### [24] [Augmenting Bias Detection in LLMs Using Topological Data Analysis](https://arxiv.org/abs/2508.07516)
*Keshav Varadarajan,Tananun Songdechakraiwut*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了一种基于拓扑数据分析的方法，用于识别GPT-2中导致对特定群体偏见的注意力头，并发现这些偏见集中在某些热点头上。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能明确识别大型语言模型中哪些部分对特定群体的偏见负责，本研究旨在填补这一空白。

Method: 使用拓扑数据分析方法，分析GPT-2的注意力头在StereoSet数据集中的表现，识别偏见热点。

Result: 发现性别或职业等特定类别的偏见集中在某些热点注意力头上，并提出了量化指标。

Conclusion: 该方法可用于识别特定群体的偏见来源，未来可扩展用于去偏。

Abstract: Recently, many bias detection methods have been proposed to determine the
level of bias a large language model captures. However, tests to identify which
parts of a large language model are responsible for bias towards specific
groups remain underdeveloped. In this study, we present a method using
topological data analysis to identify which heads in GPT-2 contribute to the
misrepresentation of identity groups present in the StereoSet dataset. We find
that biases for particular categories, such as gender or profession, are
concentrated in attention heads that act as hot spots. The metric we propose
can also be used to determine which heads capture bias for a specific group
within a bias category, and future work could extend this method to help
de-bias large language models.

</details>


### [25] [From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR](https://arxiv.org/abs/2508.07534)
*Jia Deng,Jie Chen,Zhipeng Chen,Daixuan Cheng,Fei Bai,Beichen Zhang,Yinqian Min,Yanzipeng Gao,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该技术报告系统研究了RLVR中LLMs的探索能力，包括探索空间塑造、熵-性能交换和RL性能优化，旨在为RLVR系统提供基础框架。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在LLMs的复杂推理链生成和优化中依赖规则反馈，但探索行为的机制尚未深入研究。

Method: 研究探索空间塑造、熵-性能交换和RL性能优化，结合定量指标和新实证证据。

Result: 提出了一个统一的框架，量化了LLMs的探索能力边界，并展示了如何将探索收益转化为性能提升。

Conclusion: 该研究为RLVR系统的进一步发展提供了理论基础和实证支持。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a
powerful paradigm for enhancing the reasoning capabilities of large language
models (LLMs). Unlike traditional RL approaches, RLVR leverages rule-based
feedback to guide LLMs in generating and refining complex reasoning chains -- a
process critically dependent on effective exploration strategies. While prior
work has demonstrated RLVR's empirical success, the fundamental mechanisms
governing LLMs' exploration behaviors remain underexplored. This technical
report presents a systematic investigation of exploration capacities in RLVR,
covering four main aspects: (1) exploration space shaping, where we develop
quantitative metrics to characterize LLMs' capability boundaries; (2)
entropy-performance exchange, analyzed across training stages, individual
instances, and token-level patterns; and (3) RL performance optimization,
examining methods to effectively translate exploration gains into measurable
improvements. By unifying previously identified insights with new empirical
evidence, this work aims to provide a foundational framework for advancing RLVR
systems.

</details>


### [26] [Keyword-Centric Prompting for One-Shot Event Detection with Self-Generated Rationale Enhancements](https://arxiv.org/abs/2508.07598)
*Ziheng Li,Zhi-Hong Deng*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出KeyCP++方法，通过关键词链式思维提示改进LLM在事件检测中的表现，解决传统ICL的过解释问题。


<details>
  <summary>Details</summary>
Motivation: LLM在事件检测中因缺乏对触发器的准确理解而表现不佳，传统ICL方法无法有效纠正这一问题。

Method: 提出KeyCP++，基于关键词的链式思维提示，自动标注输入文本与检测结果间的逻辑差距，并构建触发器判别提示模板。

Result: 实验证明KeyCP++在单样本事件检测中显著提升性能。

Conclusion: KeyCP++通过改进提示方法，有效提升LLM在事件检测中的准确性和鲁棒性。

Abstract: Although the LLM-based in-context learning (ICL) paradigm has demonstrated
considerable success across various natural language processing tasks, it
encounters challenges in event detection. This is because LLMs lack an accurate
understanding of event triggers and tend to make over-interpretation, which
cannot be effectively corrected through in-context examples alone. In this
paper, we focus on the most challenging one-shot setting and propose KeyCP++, a
keyword-centric chain-of-thought prompting approach. KeyCP++ addresses the
weaknesses of conventional ICL by automatically annotating the logical gaps
between input text and detection results for the demonstrations. Specifically,
to generate in-depth and meaningful rationale, KeyCP++ constructs a trigger
discrimination prompting template. It incorporates the exemplary triggers
(a.k.a keywords) into the prompt as the anchor to simply trigger profiling, let
LLM propose candidate triggers, and justify each candidate. These
propose-and-judge rationales help LLMs mitigate over-reliance on the keywords
and promote detection rule learning. Extensive experiments demonstrate the
effectiveness of our approach, showcasing significant advancements in one-shot
event detection.

</details>


### [27] [LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval](https://arxiv.org/abs/2508.07690)
*Luyao Zhuang,Qinggang Zhang,Huachi Zhou,Juhua Liu,Qing Li,Xiao Huang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种名为LoSemB的逻辑引导语义桥接框架，用于解决大语言模型在工具学习中处理未见工具时的分布偏移和相似性检索脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的工具库不断更新，现有方法在训练阶段未见的工具上表现不佳，需要一种无需重新训练的方法来处理新工具。

Method: LoSemB框架包含逻辑嵌入对齐模块和关系增强检索机制，以减少分布偏移和提升检索鲁棒性。

Result: 实验表明，LoSemB在未见工具的场景下表现优异，同时在已见工具场景中保持良好效果。

Conclusion: LoSemB为工具学习中的归纳检索提供了一种高效解决方案，适用于动态变化的工具库。

Abstract: Tool learning has emerged as a promising paradigm for large language models
(LLMs) to solve many real-world tasks. Nonetheless, with the tool repository
rapidly expanding, it is impractical to contain all tools within the limited
input length of LLMs. To alleviate these issues, researchers have explored
incorporating a tool retrieval module to select the most relevant tools or
represent tools as unique tokens within LLM parameters. However, most
state-of-the-art methods are under transductive settings, assuming all tools
have been observed during training. Such a setting deviates from reality as the
real-world tool repository is evolving and incorporates new tools frequently.
When dealing with these unseen tools, which refer to tools not encountered
during the training phase, these methods are limited by two key issues,
including the large distribution shift and the vulnerability of
similarity-based retrieval. To this end, inspired by human cognitive processes
of mastering unseen tools through discovering and applying the logical
information from prior experience, we introduce a novel Logic-Guided Semantic
Bridging framework for inductive tool retrieval, namely, LoSemB, which aims to
mine and transfer latent logical information for inductive tool retrieval
without costly retraining. Specifically, LoSemB contains a logic-based
embedding alignment module to mitigate distribution shifts and implements a
relational augmented retrieval mechanism to reduce the vulnerability of
similarity-based retrieval. Extensive experiments demonstrate that LoSemB
achieves advanced performance in inductive settings while maintaining desirable
effectiveness in the transductive setting.

</details>


### [28] [What am I missing here?: Evaluating Large Language Models for Masked Sentence Prediction](https://arxiv.org/abs/2508.07702)
*Charlie Wyatt,Aditya Joshi,Flora Salim*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文研究了商业LLM在预测掩码句子任务中的表现，发现其在低结构化领域中表现不佳，揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 探讨NTP（下一词预测）在长距离连贯性上的不足，以及LLM在全局一致性任务中的能力。

Method: 评估GPT-4o、Claude 3.5 Sonnet和Gemini 2.0 Flash在掩码句子预测任务中的表现，涵盖叙事、流程和说明性文本。

Result: 商业LLM在低结构化领域中预测掩码句子的能力较差。

Conclusion: 当前LLM在全局一致性任务中存在明显不足，需进一步改进。

Abstract: Transformer-based models primarily rely on Next Token Prediction (NTP), which
predicts the next token in a sequence based on the preceding context. However,
NTP's focus on single-token prediction often limits a model's ability to plan
ahead or maintain long-range coherence, raising questions about how well LLMs
can predict longer contexts, such as full sentences within structured
documents. While NTP encourages local fluency, it provides no explicit
incentive to ensure global coherence across sentence boundaries-an essential
skill for reconstructive or discursive tasks. To investigate this, we evaluate
three commercial LLMs (GPT-4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) on
Masked Sentence Prediction (MSP) - the task of infilling a randomly removed
sentence - from three domains: ROCStories (narrative), Recipe1M (procedural),
and Wikipedia (expository). We assess both fidelity (similarity to the original
sentence) and cohesiveness (fit within the surrounding context). Our key
finding reveals that commercial LLMs, despite their superlative performance in
other tasks, are poor at predicting masked sentences in low-structured domains,
highlighting a gap in current model capabilities.

</details>


### [29] [Exploring Causal Effect of Social Bias on Faithfulness Hallucinations in Large Language Models](https://arxiv.org/abs/2508.07753)
*Zhenliang Zhang,Junzhe Zhang,Xinyu Hu,HuiXuan Zhang,Xiaojun Wan*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究探讨社会偏见是否导致LLM的忠实幻觉，利用结构因果模型（SCM）验证因果关系，并设计干预措施。实验表明偏见是幻觉的重要原因。


<details>
  <summary>Details</summary>
Motivation: LLM在忠实性上存在幻觉问题，社会偏见的影响尚未被探索，研究旨在揭示其因果关系。

Method: 使用SCM建立因果关系，设计偏见干预措施，并开发Bias Intervention Dataset（BID）进行实验。

Result: 偏见显著导致忠实幻觉，不同偏见状态的影响方向各异，且对不公平幻觉的因果效应尤为显著。

Conclusion: 社会偏见是LLM幻觉的重要诱因，需在设计模型时加以干预。

Abstract: Large language models (LLMs) have achieved remarkable success in various
tasks, yet they remain vulnerable to faithfulness hallucinations, where the
output does not align with the input. In this study, we investigate whether
social bias contributes to these hallucinations, a causal relationship that has
not been explored. A key challenge is controlling confounders within the
context, which complicates the isolation of causality between bias states and
hallucinations. To address this, we utilize the Structural Causal Model (SCM)
to establish and validate the causality and design bias interventions to
control confounders. In addition, we develop the Bias Intervention Dataset
(BID), which includes various social biases, enabling precise measurement of
causal effects. Experiments on mainstream LLMs reveal that biases are
significant causes of faithfulness hallucinations, and the effect of each bias
state differs in direction. We further analyze the scope of these causal
effects across various models, specifically focusing on unfairness
hallucinations, which are primarily targeted by social bias, revealing the
subtle yet significant causal effect of bias on hallucination generation.

</details>


### [30] [Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts](https://arxiv.org/abs/2508.07785)
*Haoyuan Wu,Haoxing Chen,Xiaodong Chen,Zhanchao Zhou,Tieyuan Chen,Yihong Zhuang,Guoshan Lu,Zenan Huang,Junbo Zhao,Lin Liu,Zhenzhong Lan,Bei Yu,Jianguo Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种名为Grove MoE的新型混合专家架构，通过引入不同大小的专家和动态激活机制，提升了计算效率，并在33B参数的LLM上验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 传统MoE架构使用同质化专家，限制了计算效率，因此需要一种更灵活的架构来适应不同输入复杂度。

Method: 引入Grove MoE架构，采用异质化专家和动态激活机制，并基于Qwen3-30B-A3B-Base模型开发了GroveMoE-Base和GroveMoE-Inst。

Result: GroveMoE模型动态激活3.14-3.28B参数，性能与类似或更大规模的SOTA开源模型相当。

Conclusion: Grove MoE架构通过异质化专家和动态激活，显著提升了计算效率和模型性能。

Abstract: The Mixture of Experts (MoE) architecture is a cornerstone of modern
state-of-the-art (SOTA) large language models (LLMs). MoE models facilitate
scalability by enabling sparse parameter activation. However, traditional MoE
architecture uses homogeneous experts of a uniform size, activating a fixed
number of parameters irrespective of input complexity and thus limiting
computational efficiency. To overcome this limitation, we introduce Grove MoE,
a novel architecture incorporating experts of varying sizes, inspired by the
heterogeneous big.LITTLE CPU architecture. This architecture features novel
adjugate experts with a dynamic activation mechanism, enabling model capacity
expansion while maintaining manageable computational overhead. Building on this
architecture, we present GroveMoE-Base and GroveMoE-Inst, 33B-parameter LLMs
developed by applying an upcycling strategy to the Qwen3-30B-A3B-Base model
during mid-training and post-training. GroveMoE models dynamically activate
3.14-3.28B parameters based on token complexity and achieve performance
comparable to SOTA open-source models of similar or even larger size.

</details>


### [31] [Can You Trick the Grader? Adversarial Persuasion of LLM Judges](https://arxiv.org/abs/2508.07805)
*Yerin Hwang,Dongryeol Lee,Taegwan Kang,Yongil Kim,Kyomin Jung*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现，通过策略性嵌入说服性语言可以偏袒LLM评分者对数学推理任务的评分，导致错误答案得分虚高。


<details>
  <summary>Details</summary>
Motivation: 探究LLM作为自动评分者时是否容易受到说服性语言的操纵，从而影响评分的公正性。

Method: 基于亚里士多德的修辞原则，设计了七种说服技巧，并将其嵌入数学推理任务的回答中，测试LLM评分者的反应。

Result: 说服性语言导致LLM评分者对错误答案的评分平均虚高8%，其中“一致性”技巧影响最大。模型规模增大未能显著缓解此问题。

Conclusion: LLM评分者易受说服性语言影响，需开发更鲁棒的防御机制。

Abstract: As large language models take on growing roles as automated evaluators in
practical settings, a critical question arises: Can individuals persuade an LLM
judge to assign unfairly high scores? This study is the first to reveal that
strategically embedded persuasive language can bias LLM judges when scoring
mathematical reasoning tasks, where correctness should be independent of
stylistic variation. Grounded in Aristotle's rhetorical principles, we
formalize seven persuasion techniques (Majority, Consistency, Flattery,
Reciprocity, Pity, Authority, Identity) and embed them into otherwise identical
responses. Across six math benchmarks, we find that persuasive language leads
LLM judges to assign inflated scores to incorrect solutions, by up to 8% on
average, with Consistency causing the most severe distortion. Notably,
increasing model size does not substantially mitigate this vulnerability.
Further analysis demonstrates that combining multiple persuasion techniques
amplifies the bias, and pairwise evaluation is likewise susceptible. Moreover,
the persuasive effect persists under counter prompting strategies, highlighting
a critical vulnerability in LLM-as-a-Judge pipelines and underscoring the need
for robust defenses against persuasion-based attacks.

</details>


### [32] [Expert Preference-based Evaluation of Automated Related Work Generation](https://arxiv.org/abs/2508.07955)
*Furkan Şahinuç,Subhabrata Dutta,Iryna Gurevych*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出GREP框架，用于评估LLM生成的科学文献质量，结合专家偏好和领域标准，提供细粒度评估。


<details>
  <summary>Details</summary>
Motivation: 评估自动生成科学文献的质量是开放性问题，现有方法无法满足专家偏好和领域标准。

Method: 提出GREP框架，多轮评估结合经典标准和专家偏好，提供细粒度维度评估，并设计两种变体（专有和开源LLM）。

Result: GREP比标准LLM评估更稳健，与专家评估强相关，但当前LLM生成内容难以满足要求。

Conclusion: GREP框架为科学写作提供有效评估工具，但LLM生成内容仍需改进。

Abstract: Expert domain writing, such as scientific writing, typically demands
extensive domain knowledge. Recent advances in LLMs show promising potential in
reducing the expert workload. However, evaluating the quality of automatically
generated scientific writing is a crucial open issue, as it requires knowledge
of domain-specific evaluation criteria and the ability to discern expert
preferences. Conventional automatic metrics and LLM-as-a-judge systems are
insufficient to grasp expert preferences and domain-specific quality standards.
To address this gap and support human-AI collaborative writing, we focus on
related work generation, one of the most challenging scientific tasks, as an
exemplar. We propose GREP, a multi-turn evaluation framework that integrates
classical related work evaluation criteria with expert-specific preferences.
Instead of assigning a single score, our framework decomposes the evaluation
into fine-grained dimensions. This localized evaluation approach is further
augmented with contrastive few-shot examples to provide detailed contextual
guidance for the evaluation dimensions. The design principles allow our
framework to deliver cardinal assessment of quality, which can facilitate
better post-training compared to ordinal preference data. For better
accessibility, we design two variants of GREP: a more precise variant with
proprietary LLMs as evaluators, and a cheaper alternative with open-weight
LLMs. Empirical investigation reveals that our framework is able to assess the
quality of related work sections in a much more robust manner compared to
standard LLM judges, reflects natural scenarios of scientific writing, and
bears a strong correlation with the human expert assessment. We also observe
that generations from state-of-the-art LLMs struggle to satisfy validation
constraints of a suitable related work section. They (mostly) fail to improve
based on feedback as well.

</details>


### [33] [Large Language Models for Subjective Language Understanding: A Survey](https://arxiv.org/abs/2508.07959)
*Changhao Song,Yazhou Zhang,Hui Gao,Ben Yao,Peng Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文综述了大型语言模型（LLMs）在主观语言理解任务中的应用，包括情感分析、情感识别、讽刺检测等，并探讨了LLMs在这些任务中的优势和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT、LLaMA等LLMs的出现，主观语言理解任务的处理方式发生了范式转变。本文旨在全面回顾LLMs在这些任务中的最新进展。

Method: 通过定义主观语言、分析其挑战，并总结LLM架构和技术的演变，论文对八项任务进行了详细综述，包括任务定义、数据集、方法和挑战。

Result: LLMs在主观语言任务中表现出色，但仍面临数据限制、模型偏见和伦理问题等挑战。

Conclusion: 论文为情感计算、比喻语言处理与LLMs交叉领域的研究者提供了宝贵资源，并提出了未来研究方向。

Abstract: Subjective language understanding refers to a broad set of natural language
processing tasks where the goal is to interpret or generate content that
conveys personal feelings, opinions, or figurative meanings rather than
objective facts. With the advent of large language models (LLMs) such as
ChatGPT, LLaMA, and others, there has been a paradigm shift in how we approach
these inherently nuanced tasks. In this survey, we provide a comprehensive
review of recent advances in applying LLMs to subjective language tasks,
including sentiment analysis, emotion recognition, sarcasm detection, humor
understanding, stance detection, metaphor interpretation, intent detection, and
aesthetics assessment. We begin by clarifying the definition of subjective
language from linguistic and cognitive perspectives, and we outline the unique
challenges posed by subjective language (e.g. ambiguity, figurativeness,
context dependence). We then survey the evolution of LLM architectures and
techniques that particularly benefit subjectivity tasks, highlighting why LLMs
are well-suited to model subtle human-like judgments. For each of the eight
tasks, we summarize task definitions, key datasets, state-of-the-art LLM-based
methods, and remaining challenges. We provide comparative insights, discussing
commonalities and differences among tasks and how multi-task LLM approaches
might yield unified models of subjectivity. Finally, we identify open issues
such as data limitations, model bias, and ethical considerations, and suggest
future research directions. We hope this survey will serve as a valuable
resource for researchers and practitioners interested in the intersection of
affective computing, figurative language processing, and large-scale language
models.

</details>


### [34] [Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL](https://arxiv.org/abs/2508.07976)
*Jiaxuan Gao,Wei Fu,Minyang Xie,Shusheng Xu,Chuyi He,Zhiyu Mei,Banghua Zhu,Yi Wu*

Main category: cs.CL

Relevance: 85.0

TL;DR: ASearcher是一个开源项目，专注于通过大规模强化学习训练搜索代理，解决现有方法在可扩展性、效率和数据质量上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有开源代理在搜索智能（如处理模糊查询、生成精确搜索等）方面表现不足，且现有方法在可扩展性和效率上存在局限。

Method: 提出ASearcher，包括（1）可扩展的全异步强化学习训练，（2）基于提示的LLM代理，自动生成高质量QA数据集。

Result: QwQ-32B代理在xBench和GAIA上分别取得46.7%和20.8%的Avg@4提升，支持超长搜索（超过40轮工具调用）。

Conclusion: ASearcher在简单设计且无需外部LLM的情况下，性能超越现有开源32B代理。

Abstract: Recent advancements in LLM-based agents have demonstrated remarkable
capabilities in handling complex, knowledge-intensive tasks by integrating
external tools. Among diverse choices of tools, search tools play a pivotal
role in accessing vast external knowledge. However, open-source agents still
fall short of achieving expert-level Search Intelligence, the ability to
resolve ambiguous queries, generate precise searches, analyze results, and
conduct thorough exploration. Existing approaches fall short in scalability,
efficiency, and data quality. For example, small turn limits in existing online
RL methods, e.g. <=10, restrict complex strategy learning. This paper
introduces ASearcher, an open-source project for large-scale RL training of
search agents. Our key contributions include: (1) Scalable fully asynchronous
RL training that enables long-horizon search while maintaining high training
efficiency. (2) A prompt-based LLM agent that autonomously synthesizes
high-quality and challenging QAs, creating a large-scale QA dataset. Through RL
training, our prompt-based QwQ-32B agent achieves substantial improvements,
with 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our
agent exhibits extreme long-horizon search, with tool calls exceeding 40 turns
and output tokens exceeding 150k during training time. With a simple agent
design and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on
xBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We
open-source our models, training data, and codes in
https://github.com/inclusionAI/ASearcher.

</details>


### [35] [WideSearch: Benchmarking Agentic Broad Info-Seeking](https://arxiv.org/abs/2508.07999)
*Ryan Wong,Jiawei Wang,Junjie Zhao,Li Chen,Yan Gao,Long Zhang,Xuan Zhou,Zuo Wang,Kai Xiang,Ge Zhang,Wenhao Huang,Yang Wang,Ke Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文介绍了WideSearch基准测试，用于评估LLM驱动的搜索代理在大规模信息收集任务中的可靠性，发现现有系统表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的搜索代理在大规模信息收集任务中的可靠性和完整性缺乏评估，亟需合适的基准测试。

Method: 提出WideSearch基准测试，包含200个手工设计的问题，覆盖15个领域，并通过五阶段质量控制流程确保数据质量。

Result: 测试了10种先进搜索代理系统，整体成功率接近0%，最佳表现仅为5%，而人工测试可达100%。

Conclusion: 现有搜索代理在大规模信息收集中存在严重不足，需进一步研究改进。

Abstract: From professional research to everyday planning, many tasks are bottlenecked
by wide-scale information seeking, which is more repetitive than cognitively
complex. With the rapid development of Large Language Models (LLMs), automated
search agents powered by LLMs offer a promising solution to liberate humans
from this tedious work. However, the capability of these agents to perform such
"wide-context" collection reliably and completely remains largely unevaluated
due to a lack of suitable benchmarks. To bridge this gap, we introduce
WideSearch, a new benchmark engineered to evaluate agent reliability on these
large-scale collection tasks. The benchmark features 200 manually curated
questions (100 in English, 100 in Chinese) from over 15 diverse domains,
grounded in real user queries. Each task requires agents to collect large-scale
atomic information, which could be verified one by one objectively, and arrange
it into a well-organized output. A rigorous five-stage quality control pipeline
ensures the difficulty, completeness, and verifiability of the dataset. We
benchmark over 10 state-of-the-art agentic search systems, including
single-agent, multi-agent frameworks, and end-to-end commercial systems. Most
systems achieve overall success rates near 0\%, with the best performer
reaching just 5\%. However, given sufficient time, cross-validation by multiple
human testers can achieve a near 100\% success rate. These results demonstrate
that present search agents have critical deficiencies in large-scale
information seeking, underscoring urgent areas for future research and
development in agentic search. Our dataset, evaluation pipeline, and benchmark
results have been publicly released at https://widesearch-seed.github.io/

</details>


### [36] [Progressive Depth Up-scaling via Optimal Transport](https://arxiv.org/abs/2508.08011)
*Mingzi Cao,Xi Wang,Nikolaos Aletras*

Main category: cs.CL

Relevance: 85.0

TL;DR: OpT-DeUS利用最优传输（OT）对齐神经元排列，提升LLM深度扩展的训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度扩展方法忽略神经元排列差异，可能导致性能下降。

Method: 通过OT对齐和融合相邻基础层的Transformer块，创建新层。

Result: 在持续预训练和监督微调中表现更优，训练效率更高。

Conclusion: OpT-DeUS有效解决了神经元排列不匹配问题，提升了扩展效率。

Abstract: Scaling Large Language Models (LLMs) yields performance gains but incurs
substantial training costs. Depth up-scaling offers training efficiency by
adding new layers to pre-trained models. However, most existing methods copy or
average weights from base layers, neglecting neuron permutation differences.
This limitation can potentially cause misalignment that harms performance.
Inspired by applying Optimal Transport (OT) for neuron alignment, we propose
Optimal Transport Depth Up-Scaling (OpT-DeUS). OpT-DeUS aligns and fuses
Transformer blocks in adjacent base layers via OT for new layer creation, to
mitigate neuron permutation mismatch between layers. OpT-DeUS achieves better
overall performance and offers improved training efficiency than existing
methods for continual pre-training and supervised fine-tuning across different
model sizes. To further evaluate the impact of interpolation positions, our
extensive analysis shows that inserting new layers closer to the top results in
higher training efficiency due to shorter back-propagation time while obtaining
additional performance gains.

</details>


### [37] [Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models](https://arxiv.org/abs/2508.08139)
*Tianyi Zhou,Johanne Medina,Sanjay Chawla*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文研究了LLMs在生成内容时的不可靠性（如虚构内容），提出了一种基于标记级不确定性的可靠性估计方法，以改进不可靠输出的检测。


<details>
  <summary>Details</summary>
Motivation: LLMs在多轮或代理应用中容易生成流畅但不正确的内容（虚构），这带来了风险。研究旨在探索上下文信息如何影响模型行为，以及LLMs是否能识别其不可靠响应。

Method: 提出了一种可靠性估计方法，通过计算输出logits的偶然性和认知不确定性，识别关键标记并聚合其隐藏状态，用于预测响应级可靠性。

Result: 实验表明，正确的上下文信息提高了答案准确性和模型置信度，而误导性上下文则导致模型自信地生成错误答案。提出的方法改进了对不可靠输出的检测。

Conclusion: 研究揭示了直接不确定性信号的局限性，并展示了不确定性引导探测在可靠性感知生成中的潜力。

Abstract: Large Language Models (LLMs) are prone to generating fluent but incorrect
content, known as confabulation, which poses increasing risks in multi-turn or
agentic applications where outputs may be reused as context. In this work, we
investigate how in-context information influences model behavior and whether
LLMs can identify their unreliable responses. We propose a reliability
estimation that leverages token-level uncertainty to guide the aggregation of
internal model representations. Specifically, we compute aleatoric and
epistemic uncertainty from output logits to identify salient tokens and
aggregate their hidden states into compact representations for response-level
reliability prediction. Through controlled experiments on open QA benchmarks,
we find that correct in-context information improves both answer accuracy and
model confidence, while misleading context often induces confidently incorrect
responses, revealing a misalignment between uncertainty and correctness. Our
probing-based method captures these shifts in model behavior and improves the
detection of unreliable outputs across multiple open-source LLMs. These results
underscore the limitations of direct uncertainty signals and highlight the
potential of uncertainty-guided probing for reliability-aware generation.

</details>


### [38] [REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.08149)
*Wentao Jiang,Xiang Feng,Zengmao Wang,Yong Luo,Pingbo Xu,Zhe Chen,Bo Du,Jing Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出REX-RAG框架，通过混合采样策略和政策校正机制解决LLM在强化学习中陷入无效推理路径的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: LLM在强化学习中容易陷入无效推理路径（dead ends），导致决策不准确，影响探索和政策优化。

Method: 提出REX-RAG框架，结合混合采样策略（探索性提示和探针采样）和政策校正机制（重要性采样）。

Result: 在七个问答基准测试中，REX-RAG在Qwen2.5-3B和Qwen2.5-7B上分别实现了5.1%和3.6%的平均性能提升。

Conclusion: REX-RAG通过探索替代推理路径和政策校正，显著提升了LLM在强化学习中的表现。

Abstract: Reinforcement learning (RL) is emerging as a powerful paradigm for enabling
large language models (LLMs) to perform complex reasoning tasks. Recent
advances indicate that integrating RL with retrieval-augmented generation (RAG)
allows LLMs to dynamically incorporate external knowledge, leading to more
informed and robust decision making. However, we identify a critical challenge
during policy-driven trajectory sampling: LLMs are frequently trapped in
unproductive reasoning paths, which we refer to as "dead ends", committing to
overconfident yet incorrect conclusions. This severely hampers exploration and
undermines effective policy optimization. To address this challenge, we propose
REX-RAG (Reasoning Exploration with Policy Correction in Retrieval-Augmented
Generation), a novel framework that explores alternative reasoning paths while
maintaining rigorous policy learning through principled distributional
corrections. Our approach introduces two key innovations: (1) Mixed Sampling
Strategy, which combines a novel probe sampling method with exploratory prompts
to escape dead ends; and (2) Policy Correction Mechanism, which employs
importance sampling to correct distribution shifts induced by mixed sampling,
thereby mitigating gradient estimation bias. We evaluate it on seven
question-answering benchmarks, and the experimental results show that REX-RAG
achieves average performance gains of 5.1% on Qwen2.5-3B and 3.6% on Qwen2.5-7B
over strong baselines, demonstrating competitive results across multiple
datasets. The code is publicly available at https://github.com/MiliLab/REX-RAG.

</details>


### [39] [Efficient Speculative Decoding for Llama at Scale: Challenges and Solutions](https://arxiv.org/abs/2508.08192)
*Bangsheng Tang,Carl Chengyan Fu,Fei Kou,Grigory Sizov,Haoci Zhang,Jason Park,Jiawen Liu,Jie You,Qirui Yang,Sachin Mehta,Shengyong Cai,Xiaodong Wang,Xingyu Liu,Yunlu Li,Yanjun Zhou,Wei Wei,Zhiwei Zhao,Zixi Qi,Adolfo Victoria,Aya Ibrahim,Bram Wasti,Changkyu Kim,Daniel Haziza,Fei Sun,Giancarlo Delfin,Emily Guo,Jialin Ouyang,Jaewon Lee,Jianyu Huang,Jeremy Reizenstein,Lu Fang,Quinn Zhu,Ria Verma,Vlad Mihailescu,Xingwen Guo,Yan Cui,Ye Hu,Yejin Lee*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种针对Llama模型的EAGLE-based推测解码优化方法，实现了生产环境下的高效推理，显著降低了延迟并提升了批量处理速度。


<details>
  <summary>Details</summary>
Motivation: 推测解码是加速大语言模型推理的常用方法，但在生产环境中扩展时面临工程挑战，如GPU上的高效实现。

Method: 采用了训练和推理优化技术，包括树注意力和多轮推测解码的高效实现，以支持EAGLE-based推测解码。

Result: 在8个NVIDIA H100 GPU上，Llama4 Maverick的推理延迟为4 ms/令牌，比之前最佳方法快10%；批量处理速度提升1.4x至2.0x。

Conclusion: 通过优化，实现了生产规模的EAGLE-based推测解码，显著提升了Llama模型的推理效率。

Abstract: Speculative decoding is a standard method for accelerating the inference
speed of large language models. However, scaling it for production environments
poses several engineering challenges, including efficiently implementing
different operations (e.g., tree attention and multi-round speculative
decoding) on GPU. In this paper, we detail the training and inference
optimization techniques that we have implemented to enable EAGLE-based
speculative decoding at a production scale for Llama models. With these
changes, we achieve a new state-of-the-art inference latency for Llama models.
For example, Llama4 Maverick decodes at a speed of about 4 ms per token (with a
batch size of one) on 8 NVIDIA H100 GPUs, which is 10% faster than the
previously best known method. Furthermore, for EAGLE-based speculative
decoding, our optimizations enable us to achieve a speed-up for large batch
sizes between 1.4x and 2.0x at production scale.

</details>


### [40] [Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models](https://arxiv.org/abs/2508.08204)
*Kyle Moore,Jesse Roberts,Daryl Watson*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文研究了大型语言模型（LLMs）在推理时的不确定性校准，评估了其与人类不确定性的对齐程度，并发现部分指标与人类不确定性有强相关性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于通过评估LLMs的不确定性校准，以提升模型控制和用户信任，尤其是在推理时的不确定性对实际应用的重要性。

Method: 方法包括使用现有指标和新变体，评估多种推理时不确定性度量与人类群体不确定性和传统模型校准的对齐程度。

Result: 结果显示，部分指标与人类不确定性有强相关性，尽管与人类答案偏好不一致，且这些指标在正确性相关性和分布分析中表现出中等至强的模型校准。

Conclusion: 结论是某些不确定性度量能有效对齐人类不确定性，为LLM的实际应用提供了改进方向。

Abstract: There has been much recent interest in evaluating large language models for
uncertainty calibration to facilitate model control and modulate user trust.
Inference time uncertainty, which may provide a real-time signal to the model
or external control modules, is particularly important for applying these
concepts to improve LLM-user experience in practice. While many of the existing
papers consider model calibration, comparatively little work has sought to
evaluate how closely model uncertainty aligns to human uncertainty. In this
work, we evaluate a collection of inference-time uncertainty measures, using
both established metrics and novel variations, to determine how closely they
align with both human group-level uncertainty and traditional notions of model
calibration. We find that numerous measures show evidence of strong alignment
to human uncertainty, even despite the lack of alignment to human answer
preference. For those successful metrics, we find moderate to strong evidence
of model calibration in terms of both correctness correlation and
distributional analysis.

</details>


### [41] [Capabilities of GPT-5 on Multimodal Medical Reasoning](https://arxiv.org/abs/2508.08224)
*Shansong Wang,Mingzhe Hu,Qiang Li,Mojtaba Safari,Xiaofeng Yang*

Main category: cs.CL

Relevance: 85.0

TL;DR: GPT-5作为通用多模态推理模型在医学决策支持中表现出色，零样本思维链推理在文本和视觉问答任务中均超越基准模型和人类专家。


<details>
  <summary>Details</summary>
Motivation: 探索通用大语言模型（如GPT-5）在复杂医学决策支持中的潜力，尤其是在多模态信息整合和推理方面的能力。

Method: 通过标准化测试集（如MedQA、MedXpertQA等）评估GPT-5及其变体在文本和视觉问答任务中的零样本推理性能。

Result: GPT-5在所有基准测试中均达到最优性能，尤其在多模态推理方面显著超越GPT-4o和人类专家。

Conclusion: GPT-5在医学多模态推理任务中表现出超越人类专家的能力，为未来临床决策支持系统设计提供了重要参考。

Abstract: Recent advances in large language models (LLMs) have enabled general-purpose
systems to perform increasingly complex domain-specific reasoning without
extensive fine-tuning. In the medical domain, decision-making often requires
integrating heterogeneous information sources, including patient narratives,
structured data, and medical images. This study positions GPT-5 as a generalist
multimodal reasoner for medical decision support and systematically evaluates
its zero-shot chain-of-thought reasoning performance on both text-based
question answering and visual question answering tasks under a unified
protocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20
against standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU
medical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that
GPT-5 consistently outperforms all baselines, achieving state-of-the-art
accuracy across all QA benchmarks and delivering substantial gains in
multimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and
understanding scores by +29.62% and +36.18% over GPT-4o, respectively, and
surpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in
understanding. In contrast, GPT-4o remains below human expert performance in
most dimensions. A representative case study demonstrates GPT-5's ability to
integrate visual and textual cues into a coherent diagnostic reasoning chain,
recommending appropriate high-stakes interventions. Our results show that, on
these controlled multimodal reasoning benchmarks, GPT-5 moves from
human-comparable to above human-expert performance. This improvement may
substantially inform the design of future clinical decision-support systems.

</details>


### [42] [Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge](https://arxiv.org/abs/2508.08236)
*Yunna Cai,Fan Wang,Haowei Wang,Kun Wang,Kailai Yang,Sophia Ananiadou,Moyan Li,Mingming Fan*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了PsyCrisis-Bench，一个基于真实中文心理健康对话的无参考评估基准，用于评估LLM在高风险心理健康对话中的安全对齐性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在高风险心理健康对话中的安全对齐性缺乏黄金标准答案且涉及伦理敏感性，需要一种新的评估方法。

Method: 采用基于提示的LLM-as-Judge方法，结合专家定义的安全原则和心理学干预原则进行上下文评估，并使用二进制点式评分增强可解释性。

Result: 实验表明，该方法与专家评估的一致性最高，且生成的评估理由更易解释。

Conclusion: PsyCrisis-Bench及其评估工具为高风险心理健康对话的安全对齐性研究提供了有效支持。

Abstract: Evaluating the safety alignment of LLM responses in high-risk mental health
dialogues is particularly difficult due to missing gold-standard answers and
the ethically sensitive nature of these interactions. To address this
challenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark
based on real-world Chinese mental health dialogues. It evaluates whether the
model responses align with the safety principles defined by experts.
Specifically designed for settings without standard references, our method
adopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation
using expert-defined reasoning chains grounded in psychological intervention
principles. We employ binary point-wise scoring across multiple safety
dimensions to enhance the explainability and traceability of the evaluation.
Additionally, we present a manually curated, high-quality Chinese-language
dataset covering self-harm, suicidal ideation, and existential distress,
derived from real-world online discourse. Experiments on 3600 judgments show
that our method achieves the highest agreement with expert assessments and
produces more interpretable evaluation rationales compared to existing
approaches. Our dataset and evaluation tool are publicly available to
facilitate further research.

</details>


### [43] [Jinx: Unlimited LLMs for Probing Alignment Failures](https://arxiv.org/abs/2508.08243)
*Jiahao Zhao,Liwei Dong*

Main category: cs.CL

Relevance: 85.0

TL;DR: Jinx是一个无安全限制的语言模型变体，用于研究对齐失败和评估安全边界。


<details>
  <summary>Details</summary>
Motivation: 研究社区缺乏无安全限制的语言模型工具，用于评估对齐失败和系统研究语言模型的安全问题。

Method: 开发了Jinx，一个基于流行开源权重LLM的无限制变体，保留基础模型的推理和指令遵循能力。

Result: Jinx为研究人员提供了一个工具，用于探测对齐失败、评估安全边界和研究语言模型的安全失败模式。

Conclusion: Jinx填补了研究社区在无限制语言模型工具上的空白，有助于系统研究语言模型的安全问题。

Abstract: Unlimited, or so-called helpful-only language models are trained without
safety alignment constraints and never refuse user queries. They are widely
used by leading AI companies as internal tools for red teaming and alignment
evaluation. For example, if a safety-aligned model produces harmful outputs
similar to an unlimited model, this indicates alignment failures that require
further attention. Despite their essential role in assessing alignment, such
models are not available to the research community.
  We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx
responds to all queries without refusals or safety filtering, while preserving
the base model's capabilities in reasoning and instruction following. It
provides researchers with an accessible tool for probing alignment failures,
evaluating safety boundaries, and systematically studying failure modes in
language model safety.

</details>


### [44] [PrLM: Learning Explicit Reasoning for Personalized RAG via Contrastive Reward Optimization](https://arxiv.org/abs/2508.07342)
*Kepu Zhang,Teng Shi,Weijie Yu,Jun Xu*

Main category: cs.IR

Relevance: 85.0

TL;DR: PrLM是一个基于强化学习的框架，通过显式推理用户档案来优化个性化检索增强生成（RAG），解决了现有方法对检索质量的敏感性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖LLMs隐式整合检索内容，易受检索质量影响且可能偏离用户偏好。PrLM旨在通过强化学习显式推理用户档案，提升个性化生成效果。

Method: PrLM结合对比训练的个人化奖励模型，训练LLMs显式推理用户档案，无需标注推理路径。

Result: 在三个个性化文本生成数据集上，PrLM优于现有方法，且对不同检索器和检索档案数量保持鲁棒性。

Conclusion: PrLM通过强化学习显式推理用户档案，显著提升了RAG的个性化生成效果和鲁棒性。

Abstract: Personalized retrieval-augmented generation (RAG) aims to produce
user-tailored responses by incorporating retrieved user profiles alongside the
input query. Existing methods primarily focus on improving retrieval and rely
on large language models (LLMs) to implicitly integrate the retrieved context
with the query. However, such models are often sensitive to retrieval quality
and may generate responses that are misaligned with user preferences. To
address this limitation, we propose PrLM, a reinforcement learning framework
that trains LLMs to explicitly reason over retrieved user profiles. Guided by a
contrastively trained personalization reward model, PrLM effectively learns
from user responses without requiring annotated reasoning paths. Experiments on
three personalized text generation datasets show that PrLM outperforms existing
methods and remains robust across varying numbers of retrieved profiles and
different retrievers.

</details>


### [45] [Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning](https://arxiv.org/abs/2508.08039)
*Shu Wu,Chenxing Li,Wenfu Wang,Hao Zhang,Hualei Wang,Meng Yu,Dong Yu*

Main category: cs.SD

Relevance: 85.0

TL;DR: 提出Audio-Thinker框架，通过强化学习提升大型音频语言模型（LALMs）的推理能力，结合自适应奖励和外部奖励模型，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前LALMs在音频问答中的推理能力不足，未能充分利用深度推理，Audio-Thinker旨在解决这一挑战。

Method: 采用强化学习框架，引入自适应推理准确度奖励和外部奖励模型，动态调整推理策略。

Result: Audio-Thinker在多个基准任务中表现优于现有推理导向的LALMs，展现更强的推理和泛化能力。

Conclusion: Audio-Thinker通过改进奖励机制，显著提升了LALMs的推理能力，为音频语言模型的发展提供了新方向。

Abstract: Recent advancements in large language models, multimodal large language
models, and large audio language models (LALMs) have significantly improved
their reasoning capabilities through reinforcement learning with rule-based
rewards. However, the explicit reasoning process has yet to show significant
benefits for audio question answering, and effectively leveraging deep
reasoning remains an open challenge, with LALMs still falling short of
human-level auditory-language reasoning. To address these limitations, we
propose Audio-Thinker, a reinforcement learning framework designed to enhance
the reasoning capabilities of LALMs, with a focus on improving adaptability,
consistency, and effectiveness. Our approach introduces an adaptive think
accuracy reward, enabling the model to adjust its reasoning strategies based on
task complexity dynamically. Furthermore, we incorporate an external reward
model to evaluate the overall consistency and quality of the reasoning process,
complemented by think-based rewards that help the model distinguish between
valid and flawed reasoning paths during training. Experimental results
demonstrate that our Audio-Thinker model outperforms existing
reasoning-oriented LALMs across various benchmark tasks, exhibiting superior
reasoning and generalization capabilities.

</details>


### [46] [The Art of Breaking Words: Rethinking Multilingual Tokenizer Design](https://arxiv.org/abs/2508.06533)
*Aamod Thakur,Ajay Nagpal,Atharva Savarkar,Kundeshwar Pundalik,Siddhesh Dosi,Piyush Sawarkar,Viraj Thakur,Rohit Saluja,Maunendra Sankar Desarkar,Ganesh Ramakrishnan*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文研究了多语言LLM中的分词问题，提出了一种新的数据组合算法，显著提高了分词效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有分词器在多语言环境下效率低且性能不佳，尤其在印度语系等复杂语言中表现更差。

Method: 系统研究了词汇量、预分词规则和训练语料组成对分词效率的影响，并提出了一种新的数据组合算法。

Result: 新算法将平均词符比降低约6%，分词效率提升40%以上，模型性能和推理速度均有显著提升。

Conclusion: 分词是构建高效多语言LLM的关键因素之一。

Abstract: While model architecture and training objectives are well-studied,
tokenization, particularly in multilingual contexts, remains a relatively
neglected aspect of Large Language Model (LLM) development. Existing tokenizers
often exhibit high token-to-word ratios, inefficient use of context length, and
slower inference. We present a systematic study that links vocabulary size,
pre-tokenization rules, and training-corpus composition to both token-to-word
efficiency and model quality. To ground our analysis in a linguistically
diverse context, we conduct extensive experiments on Indic scripts, which
present unique challenges due to their high script diversity and orthographic
complexity. Drawing on the insights from these analyses, we propose a novel
algorithm for data composition that balances multilingual data for tokenizer
training. Our observations on pretokenization strategies significantly improve
model performance, and our data composition algorithm reduces the average
token-to-word ratio by approximately 6% with respect to the conventional data
randomization approach. Our tokenizer achieves more than 40% improvement on
average token-to-word ratio against stateof-the-art multilingual Indic models.
This improvement yields measurable gains in both model performance and
inference speed. This highlights tokenization alongside architecture and
training objectives as a critical lever for building efficient, scalable
multilingual LLMs

</details>


### [47] [Testing the Limits of Machine Translation from One Book](https://arxiv.org/abs/2508.06665)
*Jonathan Shaw,Dillon Mee,Timothy Khouw,Zackary Leech,Daniel Wilson*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文研究了LLM在低资源语言（Kanuri）翻译中的表现，发现平行句子是最有效的数据源，语法单独使用效果有限。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在低资源语言翻译中的应用，特别是如何利用语言资源（如语法、词典、平行句子）提升翻译质量。

Method: 设计两个数据集（健康和通用术语），比较不同语言资源组合对LLM翻译的影响，并通过自动指标和人工评估衡量效果。

Result: 平行句子表现最佳，语法单独使用效果有限；LLM在准确性上优于流畅性。

Conclusion: LLM翻译评估需多维指标，语法需结合平行句子才能有效提升翻译质量。

Abstract: Current state-of-the-art models demonstrate capacity to leverage in-context
learning to translate into previously unseen language contexts. Tanzer et al.
[2024] utilize language materials (e.g. a grammar) to improve translation
quality for Kalamang using large language models (LLMs). We focus on Kanuri, a
language that, despite having substantial speaker population, has minimal
digital resources. We design two datasets for evaluation: one focused on health
and humanitarian terms, and another containing generalized terminology,
investigating how domain-specific tasks impact LLM translation quality.
  By providing different combinations of language resources (grammar,
dictionary, and parallel sentences), we measure LLM translation effectiveness,
comparing results to native speaker translations and human linguist
performance. We evaluate using both automatic metrics and native speaker
assessments of fluency and accuracy.
  Results demonstrate that parallel sentences remain the most effective data
source, outperforming other methods in human evaluations and automatic metrics.
While incorporating grammar improves over zero-shot translation, it fails as an
effective standalone data source. Human evaluations reveal that LLMs achieve
accuracy (meaning) more effectively than fluency (grammaticality).
  These findings suggest LLM translation evaluation benefits from
multidimensional assessment beyond simple accuracy metrics, and that grammar
alone, without parallel sentences, does not provide sufficient context for
effective domain-specific translation.

</details>


### [48] [Score Before You Speak: Improving Persona Consistency in Dialogue Generation using Response Quality Scores](https://arxiv.org/abs/2508.06886)
*Arpita Saggar,Jonathan C. Darling,Vania Dimitrova,Duygu Sarikaya,David C. Hogg*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文提出了一种名为SBS（Score-Before-Speaking）的新框架，用于提升基于角色的对话生成效果。通过将响应质量评分与对话生成统一到一个步骤中，SBS在百万和十亿参数模型上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）能力不断提升，但现有对话数据多样性有限，导致角色一致性对话生成仍具挑战性。

Method: SBS框架在训练时将增强的响应与质量评分关联，并在推理时利用这一知识。采用名词替换增强数据，语义相似度评分作为响应质量的代理。

Result: 在PERSONA-CHAT和ConvAI2基准数据集上的实验表明，SBS能更好地生成角色一致性对话。

Conclusion: SBS通过评分条件训练提升了角色对话生成效果，且训练时在输入提示中包含评分优于传统方法。

Abstract: Persona-based dialogue generation is an important milestone towards building
conversational artificial intelligence. Despite the ever-improving capabilities
of large language models (LLMs), effectively integrating persona fidelity in
conversations remains challenging due to the limited diversity in existing
dialogue data. We propose a novel framework SBS (Score-Before-Speaking), which
outperforms previous methods and yields improvements for both million and
billion-parameter models. Unlike previous methods, SBS unifies the learning of
responses and their relative quality into a single step. The key innovation is
to train a dialogue model to correlate augmented responses with a quality score
during training and then leverage this knowledge at inference. We use
noun-based substitution for augmentation and semantic similarity-based scores
as a proxy for response quality. Through extensive experiments with benchmark
datasets (PERSONA-CHAT and ConvAI2), we show that score-conditioned training
allows existing models to better capture a spectrum of persona-consistent
dialogues. Our ablation studies also demonstrate that including scores in the
input prompt during training is superior to conventional training setups. Code
and further details are available at
https://arpita2512.github.io/score_before_you_speak

</details>


### [49] [Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment](https://arxiv.org/abs/2508.07195)
*Yanru Sun,Emadeldeen Eldele,Zongxia Xie,Yucheng Wang,Wenzhe Niu,Qinghua Hu,Chee Keong Kwoh,Min Wu*

Main category: cs.CL

Relevance: 75.0

TL;DR: TALON框架通过建模时间异质性和语义对齐，将LLMs应用于时间序列预测，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在自然语言处理中表现优异，但在时间序列预测中面临时间异质性和模态差异的挑战。

Method: 设计了Heterogeneous Temporal Encoder和Semantic Alignment Module，分别处理时间异质性和模态对齐问题。

Result: 在七个真实世界基准测试中，TALON平均MSE提升达11%，优于现有方法。

Conclusion: 结合模式感知和语义感知设计，能有效将LLMs适配于时间序列预测。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive
capabilities in natural language processing due to their strong generalization
and sequence modeling capabilities. However, their direct application to time
series forecasting remains challenging due to two fundamental issues: the
inherent heterogeneity of temporal patterns and the modality gap between
continuous numerical signals and discrete language representations. In this
work, we propose TALON, a unified framework that enhances LLM-based forecasting
by modeling temporal heterogeneity and enforcing semantic alignment.
Specifically, we design a Heterogeneous Temporal Encoder that partitions
multivariate time series into structurally coherent segments, enabling
localized expert modeling across diverse temporal patterns. To bridge the
modality gap, we introduce a Semantic Alignment Module that aligns temporal
features with LLM-compatible representations, enabling effective integration of
time series into language-based models while eliminating the need for
handcrafted prompts during inference. Extensive experiments on seven real-world
benchmarks demonstrate that TALON achieves superior performance across all
datasets, with average MSE improvements of up to 11\% over recent
state-of-the-art methods. These results underscore the effectiveness of
incorporating both pattern-aware and semantic-aware designs when adapting LLMs
for time series forecasting. The code is available at:
https://github.com/syrGitHub/TALON.

</details>


### [50] [Grounding Multilingual Multimodal LLMs With Cultural Knowledge](https://arxiv.org/abs/2508.07414)
*Jean de Dieu Nyandwi,Yueqi Song,Simran Khanuja,Graham Neubig*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文提出了一种数据驱动的方法，通过构建文化知识数据集CulturalGround，训练多模态大语言模型CulturalPangea，显著提升了模型在文化相关任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在低资源语言和文化长尾实体上的表现不足问题。

Method: 利用Wikidata知识图谱构建文化数据集CulturalGround，生成多语言视觉问答数据，并训练模型CulturalPangea。

Result: CulturalPangea在文化相关任务上表现优异，平均提升5.0分，且不影响主流视觉语言任务性能。

Conclusion: 文化知识嵌入方法能有效缩小多模态大语言模型的文化鸿沟，推动全球包容性系统发展。

Abstract: Multimodal Large Language Models excel in high-resource settings, but often
misinterpret long-tail cultural entities and underperform in low-resource
languages. To address this gap, we propose a data-centric approach that
directly grounds MLLMs in cultural knowledge. Leveraging a large scale
knowledge graph from Wikidata, we collect images that represent culturally
significant entities, and generate synthetic multilingual visual question
answering data. The resulting dataset, CulturalGround, comprises 22 million
high-quality, culturally-rich VQA pairs spanning 42 countries and 39 languages.
We train an open-source MLLM CulturalPangea on CulturalGround, interleaving
standard multilingual instruction-tuning data to preserve general abilities.
CulturalPangea achieves state-of-the-art performance among open models on
various culture-focused multilingual multimodal benchmarks, outperforming prior
models by an average of 5.0 without degrading results on mainstream
vision-language tasks. Our findings show that our targeted, culturally grounded
approach could substantially narrow the cultural gap in MLLMs and offer a
practical path towards globally inclusive multimodal systems.

</details>


### [51] [ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models](https://arxiv.org/abs/2508.07484)
*Archchana Sindhujan,Shenbin Qian,Chan Chi Chun Matthew,Constantin Orasan,Diptesh Kanojia*

Main category: cs.CL

Relevance: 75.0

TL;DR: ALOPE是一个自适应层优化框架，通过调整Transformer表示层来提升基于LLM的机器翻译质量估计（QE）性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在质量估计任务中表现不佳，因其预训练目标与回归任务不匹配，且低资源语言数据分布不均。

Method: ALOPE结合低秩适配器（LoRA）和回归任务头，动态加权多层表示，并使用多头回归策略。

Result: ALOPE在多种LLM-based QE方法上表现更优，中间层表示更适合跨语言任务。

Conclusion: ALOPE为LLM-based QE提供了有效改进，并公开了模型和代码。

Abstract: Large Language Models (LLMs) have shown remarkable performance across a wide
range of natural language processing tasks. Quality Estimation (QE) for Machine
Translation (MT), which assesses the quality of a source-target pair without
relying on reference translations, remains a challenging cross-lingual task for
LLMs. The challenges stem from the inherent limitations of existing LLM-based
QE systems, which are pre-trained for causal language modelling rather than
regression-specific tasks, further elevated by the presence of low-resource
languages given pre-training data distribution. This paper introduces ALOPE, an
adaptive layer-optimization framework designed to enhance LLM-based QE by
restructuring Transformer representations through layer-wise adaptation for
improved regression-based prediction. Our framework integrates low-rank
adapters (LoRA) with regression task heads, leveraging selected pre-trained
Transformer layers for improved cross-lingual alignment. In addition to the
layer-specific adaptation, ALOPE introduces two strategies-dynamic weighting,
which adaptively combines representations from multiple layers, and multi-head
regression, which aggregates regression losses from multiple heads for QE. Our
framework shows improvements over various existing LLM-based QE approaches.
Empirical evidence suggests that intermediate Transformer layers in LLMs
provide contextual representations that are more aligned with the cross-lingual
nature of the QE task. We make resultant models and framework code publicly
available for further research, also allowing existing LLM-based MT frameworks
to be scaled with QE capabilities.

</details>


### [52] [Evaluating Large Language Models as Expert Annotators](https://arxiv.org/abs/2508.07827)
*Yu-Min Tseng,Wei-Lin Chen,Chung-Chi Chen,Hsin-Hsi Chen*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文探讨了大型语言模型（LLMs）在需要专家知识的领域（如金融、生物医学和法律）中作为人类专家标注替代品的潜力，评估了单模型和多代理方法，发现推理模型和推理技术效果有限。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在专家知识领域的标注任务中的表现，填补现有研究的空白。

Method: 评估单LLMs和多代理讨论框架，结合推理模型（如o3-mini），在金融、生物医学和法律领域进行实验。

Result: 推理技术和推理模型效果有限；多代理环境中某些模型行为显现（如Claude 3.7 Sonnet固执己见）。

Conclusion: LLMs在专家领域标注任务中效果有限，多代理方法可能提供新视角。

Abstract: Textual data annotation, the process of labeling or tagging text with
relevant information, is typically costly, time-consuming, and labor-intensive.
While large language models (LLMs) have demonstrated their potential as direct
alternatives to human annotators for general domains natural language
processing (NLP) tasks, their effectiveness on annotation tasks in domains
requiring expert knowledge remains underexplored. In this paper, we
investigate: whether top-performing LLMs, which might be perceived as having
expert-level proficiency in academic and professional benchmarks, can serve as
direct alternatives to human expert annotators? To this end, we evaluate both
individual LLMs and multi-agent approaches across three highly specialized
domains: finance, biomedicine, and law. Specifically, we propose a multi-agent
discussion framework to simulate a group of human annotators, where LLMs are
tasked to engage in discussions by considering others' annotations and
justifications before finalizing their labels. Additionally, we incorporate
reasoning models (e.g., o3-mini) to enable a more comprehensive comparison. Our
empirical results reveal that: (1) Individual LLMs equipped with inference-time
techniques (e.g., chain-of-thought (CoT), self-consistency) show only marginal
or even negative performance gains, contrary to prior literature suggesting
their broad effectiveness. (2) Overall, reasoning models do not demonstrate
statistically significant improvements over non-reasoning models in most
settings. This suggests that extended long CoT provides relatively limited
benefits for data annotation in specialized domains. (3) Certain model
behaviors emerge in the multi-agent discussion environment. For instance,
Claude 3.7 Sonnet with thinking rarely changes its initial annotations, even
when other agents provide correct annotations or valid reasoning.

</details>


### [53] [Understanding Syntactic Generalization in Structure-inducing Language Models](https://arxiv.org/abs/2508.07969)
*David Arps,Hassan Sajjad,Laura Kallmeyer*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文研究了三种结构诱导语言模型（SiLM）在语法表示、语法判断任务和训练动态方面的表现，发现GPST在多数评估中表现最稳定。


<details>
  <summary>Details</summary>
Motivation: 现有SiLM模型评估规模小且缺乏系统性，需更全面的比较研究。

Method: 比较了Structformer、UDGN和GPST三种SiLM架构，使用自然语言和合成数据评估语法表示、任务表现和训练动态。

Result: GPST表现最稳定，尤其在长距离依赖任务中优于其他模型。

Conclusion: 小模型在大规模合成数据上的训练为评估基本模型特性提供了有效测试平台。

Abstract: Structure-inducing Language Models (SiLM) are trained on a self-supervised
language modeling task, and induce a hierarchical sentence representation as a
byproduct when processing an input. A wide variety of SiLMs have been proposed.
However, these have typically been evaluated on a relatively small scale, and
evaluation of these models has systematic gaps and lacks comparability. In this
work, we study three different SiLM architectures using both natural language
(English) corpora and synthetic bracketing expressions: Structformer (Shen et
al., 2021), UDGN (Shen et al., 2022) and GPST (Hu et al., 2024). We compare
them with respect to (i) properties of the induced syntactic representations
(ii) performance on grammaticality judgment tasks, and (iii) training dynamics.
We find that none of the three architectures dominates across all evaluation
metrics. However, there are significant differences, in particular with respect
to the induced syntactic representations. The Generative Pretrained Structured
Transformer (GPST; Hu et al. 2024) performs most consistently across evaluation
settings, and outperforms the other models on long-distance dependencies in
bracketing expressions. Furthermore, our study shows that small models trained
on large amounts of synthetic data provide a useful testbed for evaluating
basic model properties.

</details>


### [54] [Dual Information Speech Language Models for Emotional Conversations](https://arxiv.org/abs/2508.08095)
*Chun Wang,Chenyang Liu,Wenze Xu,Weihong Deng*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文提出了一种通过异构适配器和弱监督训练策略解决语音语言模型（SLMs）在捕捉副语言信息和上下文理解上的问题的方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的大语言模型（LLMs）忽略了副语言线索，而扩展自冻结LLMs的语音语言模型（SLMs）在副语言信息捕捉和上下文理解上表现不佳。

Method: 提出两种异构适配器和弱监督训练策略，解耦副语言与语言信息，并通过控制随机性避免任务特定向量生成。

Result: 实验显示在情感对话任务中具有竞争力，模型能有效整合副语言与语言信息。

Conclusion: 该方法在参数和数据效率上表现优异，为SLMs的改进提供了新思路。

Abstract: Conversational systems relying on text-based large language models (LLMs)
often overlook paralinguistic cues, essential for understanding emotions and
intentions. Speech-language models (SLMs), which use speech as input, are
emerging as a promising solution. However, SLMs built by extending frozen LLMs
struggle to capture paralinguistic information and exhibit reduced context
understanding. We identify entangled information and improper training
strategies as key issues. To address these issues, we propose two heterogeneous
adapters and suggest a weakly supervised training strategy. Our approach
disentangles paralinguistic and linguistic information, enabling SLMs to
interpret speech through structured representations. It also preserves
contextual understanding by avoiding the generation of task-specific vectors
through controlled randomness. This approach trains only the adapters on common
datasets, ensuring parameter and data efficiency. Experiments demonstrate
competitive performance in emotional conversation tasks, showcasing the model's
ability to effectively integrate both paralinguistic and linguistic information
within contextual settings.

</details>


### [55] [Data-Efficient Biomedical In-Context Learning: A Diversity-Enhanced Submodular Perspective](https://arxiv.org/abs/2508.08140)
*Jun Wang,Zaifu Zhan,Qixin Zhang,Mingquan Lin,Meijia Song,Rui Zhang*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文提出Dual-Div框架，通过两阶段检索和排序优化生物医学ICL任务中的示例选择，强调多样性和代表性，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生物医学ICL任务中优先考虑示例的代表性而忽视多样性，导致性能受限。

Method: Dual-Div采用两阶段检索和排序：先优化多样性和代表性选择候选示例，再根据测试查询排序选择最相关且非冗余的示例。

Result: 在三个生物医学NLP任务中，Dual-Div比基线方法性能提升高达5%的macro-F1分数，且对提示变化和类别不平衡具有鲁棒性。

Conclusion: 初始检索阶段的多样性比排序优化更重要，且3-5个示例能最大化性能效率。

Abstract: Recent progress in large language models (LLMs) has leveraged their
in-context learning (ICL) abilities to enable quick adaptation to unseen
biomedical NLP tasks. By incorporating only a few input-output examples into
prompts, LLMs can rapidly perform these new tasks. While the impact of these
demonstrations on LLM performance has been extensively studied, most existing
approaches prioritize representativeness over diversity when selecting examples
from large corpora. To address this gap, we propose Dual-Div, a
diversity-enhanced data-efficient framework for demonstration selection in
biomedical ICL. Dual-Div employs a two-stage retrieval and ranking process:
First, it identifies a limited set of candidate examples from a corpus by
optimizing both representativeness and diversity (with optional annotation for
unlabeled data). Second, it ranks these candidates against test queries to
select the most relevant and non-redundant demonstrations. Evaluated on three
biomedical NLP tasks (named entity recognition (NER), relation extraction (RE),
and text classification (TC)) using LLaMA 3.1 and Qwen 2.5 for inference, along
with three retrievers (BGE-Large, BMRetriever, MedCPT), Dual-Div consistently
outperforms baselines-achieving up to 5% higher macro-F1 scores-while
demonstrating robustness to prompt permutations and class imbalance. Our
findings establish that diversity in initial retrieval is more critical than
ranking-stage optimization, and limiting demonstrations to 3-5 examples
maximizes performance efficiency.

</details>


### [56] [SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling](https://arxiv.org/abs/2508.08211)
*Zhuohao Yu,Xingru Jiang,Weizheng Gu,Yidong Wang,Shikun Zhang,Wei Ye*

Main category: cs.CL

Relevance: 75.0

TL;DR: SAEMark是一种后处理多比特水印框架，通过基于特征的拒绝采样嵌入个性化消息，无需修改模型logits或训练，适用于多语言和API模型。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法会降低文本质量且需要白盒访问，限制了其在API模型和多语言场景中的应用。SAEMark旨在解决这些问题。

Method: 利用生成文本的确定性特征进行拒绝采样，选择符合密钥目标的输出，无需修改模型logits或训练。

Result: 在4个数据集上表现优异，英语F1达99.7%，多比特检测准确率高，且保持文本质量。

Conclusion: SAEMark为闭源LLM提供了一种可扩展的水印范式，支持内容溯源。

Abstract: Watermarking LLM-generated text is critical for content attribution and
misinformation prevention. However, existing methods compromise text quality,
require white-box model access and logit manipulation. These limitations
exclude API-based models and multilingual scenarios. We propose SAEMark, a
general framework for post-hoc multi-bit watermarking that embeds personalized
messages solely via inference-time, feature-based rejection sampling without
altering model logits or requiring training. Our approach operates on
deterministic features extracted from generated text, selecting outputs whose
feature statistics align with key-derived targets. This framework naturally
generalizes across languages and domains while preserving text quality through
sampling LLM outputs instead of modifying. We provide theoretical guarantees
relating watermark success probability and compute budget that hold for any
suitable feature extractor. Empirically, we demonstrate the framework's
effectiveness using Sparse Autoencoders (SAEs), achieving superior detection
accuracy and text quality. Experiments across 4 datasets show SAEMark's
consistent performance, with 99.7% F1 on English and strong multi-bit detection
accuracy. SAEMark establishes a new paradigm for scalable watermarking that
works out-of-the-box with closed-source LLMs while enabling content
attribution.

</details>


### [57] [Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models](https://arxiv.org/abs/2508.06504)
*Yao Ge,Sudeshna Das,Yuting Guo,Abeed Sarker*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文研究了动态提示策略（结合检索增强生成RAG）在少样本生物医学命名实体识别（NER）中的应用，显著提升了LLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 解决少样本生物医学NER任务中LLMs的性能挑战，探索动态提示策略的潜力。

Method: 采用动态提示策略，基于输入文本相似性选择上下文学习示例，并在推理时动态更新提示。优化静态和动态提示技术，并在五个生物医学NER数据集上评估。

Result: 动态提示显著提升性能，TF-IDF和SBERT检索方法在5-shot和10-shot设置中分别提高F1分数7.3%和5.6%。

Conclusion: 上下文自适应提示（通过RAG）对生物医学NER具有显著效用。

Abstract: Biomedical named entity recognition (NER) is a high-utility natural language
processing (NLP) task, and large language models (LLMs) show promise
particularly in few-shot settings (i.e., limited training data). In this
article, we address the performance challenges of LLMs for few-shot biomedical
NER by investigating a dynamic prompting strategy involving retrieval-augmented
generation (RAG). In our approach, the annotated in-context learning examples
are selected based on their similarities with the input texts, and the prompt
is dynamically updated for each instance during inference. We implemented and
optimized static and dynamic prompt engineering techniques and evaluated them
on five biomedical NER datasets. Static prompting with structured components
increased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA
3-70B, relative to basic static prompting. Dynamic prompting further improved
performance, with TF-IDF and SBERT retrieval methods yielding the best results,
improving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings,
respectively. These findings highlight the utility of contextually adaptive
prompts via RAG for biomedical NER.

</details>


### [58] [SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection](https://arxiv.org/abs/2508.06803)
*Ziqi Liu,Yangbin Chen,Ziyang Zhou,Yilin Li,Mingxuan Hu,Yushan Pan,Zhijie Xu*

Main category: cs.CL

Relevance: 70.0

TL;DR: SEVADE是一个新颖的多代理自演化框架，用于抗幻觉的讽刺检测，通过动态代理推理引擎（DARE）和多角度文本解构，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在讽刺检测中存在单视角分析、静态推理路径和易幻觉的问题，影响准确性和可靠性。

Method: 提出SEVADE框架，包含动态代理推理引擎（DARE）和轻量级理性裁决器（RA），将复杂推理与最终判断分离。

Result: 在四个基准数据集上，SEVADE在准确率和Macro-F1分数上平均提升了6.75%和6.29%。

Conclusion: SEVADE通过多代理和分离架构有效解决了讽刺检测中的幻觉问题，性能显著优于现有方法。

Abstract: Sarcasm detection is a crucial yet challenging Natural Language Processing
task. Existing Large Language Model methods are often limited by
single-perspective analysis, static reasoning pathways, and a susceptibility to
hallucination when processing complex ironic rhetoric, which impacts their
accuracy and reliability. To address these challenges, we propose **SEVADE**, a
novel **S**elf-**Ev**olving multi-agent **A**nalysis framework with
**D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The
core of our framework is a Dynamic Agentive Reasoning Engine (DARE), which
utilizes a team of specialized agents grounded in linguistic theory to perform
a multifaceted deconstruction of the text and generate a structured reasoning
chain. Subsequently, a separate lightweight rationale adjudicator (RA) performs
the final classification based solely on this reasoning chain. This decoupled
architecture is designed to mitigate the risk of hallucination by separating
complex reasoning from the final judgment. Extensive experiments on four
benchmark datasets demonstrate that our framework achieves state-of-the-art
performance, with average improvements of **6.75%** in Accuracy and **6.29%**
in Macro-F1 score.

</details>


### [59] [Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models](https://arxiv.org/abs/2508.07273)
*Qiongqiong Wang,Hardik B. Sailor,Jeremy H. M. Wong,Tianchi Liu,Shuo Sun,Wenyu Zhang,Muhammad Huzaifah,Nancy Chen,Ai Ti Aw*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文提出两种方法（显式和隐式）将上下文副语言信息融入语音大语言模型训练，提升共情推理能力，隐式方法性能提升38.41%，结合显式方法达46.02%。


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型在共情推理方面表现不足，主要因缺乏结合上下文内容和副语言线索的训练数据。

Method: 1. 显式方法：直接提供副语言元数据（如情感标注）给模型；2. 隐式方法：自动生成结合情感标注和语音转录的训练问答对。

Result: 隐式方法在人类标注的问答基准上性能提升38.41%，结合显式方法达46.02%。LLM评判与分类指标相关性验证了其可靠性。

Conclusion: 两种方法有效提升语音大语言模型的上下文副语言理解能力。

Abstract: Current large speech language models (Speech-LLMs) often exhibit limitations
in empathetic reasoning, primarily due to the absence of training datasets that
integrate both contextual content and paralinguistic cues. In this work, we
propose two approaches to incorporate contextual paralinguistic information
into model training: (1) an explicit method that provides paralinguistic
metadata (e.g., emotion annotations) directly to the LLM, and (2) an implicit
method that automatically generates novel training question-answer (QA) pairs
using both categorical and dimensional emotion annotations alongside speech
transcriptions. Our implicit method boosts performance (LLM-judged) by 38.41%
on a human-annotated QA benchmark, reaching 46.02% when combined with the
explicit approach, showing effectiveness in contextual paralinguistic
understanding. We also validate the LLM judge by demonstrating its correlation
with classification metrics, providing support for its reliability.

</details>


### [60] [Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance](https://arxiv.org/abs/2508.07375)
*Wenqian Cui,Lei Zhu,Xiaohui Li,Zhihan Guo,Haoli Bai,Lu Hou,Irwin King*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文提出TurnGuide方法，通过动态分割对话轮次并生成文本指导，解决了全双工语音语言模型（FD-SLMs）在实时对话中的时序和长度问题，显著提升了对话质量。


<details>
  <summary>Details</summary>
Motivation: 全双工语音语言模型（FD-SLMs）在实时对话中面临对话能力下降的问题，主要由于长时间语音序列和高质量对话数据不足。文本引导的语音生成方法存在时序和长度问题。

Method: 提出TurnGuide方法，模仿人类对话规划，动态分割对话轮次并生成文本指导，再输出语音，解决时序和长度问题。

Result: 实验表明，TurnGuide显著提升了FD-SLMs的对话能力，生成语义连贯且自然的语音。

Conclusion: TurnGuide有效解决了FD-SLMs的挑战，提升了实时对话的自然性和连贯性。

Abstract: Full-Duplex Speech Language Models (FD-SLMs) are specialized foundation
models designed to enable natural, real-time spoken interactions by modeling
complex conversational dynamics such as interruptions, backchannels, and
overlapping speech, and End-to-end (e2e) FD-SLMs leverage real-world
double-channel conversational data to capture nuanced two-speaker dialogue
patterns for human-like interactions. However, they face a critical challenge
-- their conversational abilities often degrade compared to pure-text
conversation due to prolonged speech sequences and limited high-quality spoken
dialogue data. While text-guided speech generation could mitigate these issues,
it suffers from timing and length issues when integrating textual guidance into
double-channel audio streams, disrupting the precise time alignment essential
for natural interactions. To address these challenges, we propose TurnGuide, a
novel planning-inspired approach that mimics human conversational planning by
dynamically segmenting assistant speech into dialogue turns and generating
turn-level text guidance before speech output, which effectively resolves both
insertion timing and length challenges. Extensive experiments demonstrate our
approach significantly improves e2e FD-SLMs' conversational abilities, enabling
them to generate semantically meaningful and coherent speech while maintaining
natural conversational flow. Demos are available at
https://dreamtheater123.github.io/TurnGuide-Demo/. Code will be available at
https://github.com/dreamtheater123/TurnGuide.

</details>


### [61] [Tailored Emotional LLM-Supporter: Enhancing Cultural Sensitivity](https://arxiv.org/abs/2508.07902)
*Chen Cecilia Liu,Hiba Arnaout,Nils Kovačić,Dana Atzil-Slonim,Iryna Gurevych*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文介绍了CultureCare数据集，用于评估和改进LLMs在提供文化敏感情感支持方面的能力，并展示了四种适应策略的效果。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在提供文化敏感情感支持方面的潜力，填补现有资源不足的空白。

Method: 开发CultureCare数据集，测试四种适应策略，评估LLMs表现。

Result: 适应后的LLMs表现优于匿名在线同伴回应，但简单的文化角色扮演不足以实现文化敏感性。

Conclusion: LLMs在临床培训中有潜力，但需进一步优化文化敏感性。

Abstract: Large language models (LLMs) show promise in offering emotional support and
generating empathetic responses for individuals in distress, but their ability
to deliver culturally sensitive support remains underexplored due to lack of
resources. In this work, we introduce CultureCare, the first dataset designed
for this task, spanning four cultures and including 1729 distress messages,
1523 cultural signals, and 1041 support strategies with fine-grained emotional
and cultural annotations. Leveraging CultureCare, we (i) develop and test four
adaptation strategies for guiding three state-of-the-art LLMs toward culturally
sensitive responses; (ii) conduct comprehensive evaluations using LLM judges,
in-culture human annotators, and clinical psychologists; (iii) show that
adapted LLMs outperform anonymous online peer responses, and that simple
cultural role-play is insufficient for cultural sensitivity; and (iv) explore
the application of LLMs in clinical training, where experts highlight their
potential in fostering cultural competence in future therapists.

</details>


### [62] [Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?](https://arxiv.org/abs/2508.08096)
*Lukas Gehring,Benjamin Paaßen*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文提出了一种新的数据集GEDE，用于评估教育场景中LLM生成文本的检测方法，并发现现有检测器在中间贡献级别（如LLM改进的文本）上表现不佳，易产生误报。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的普及，学生使用其生成文本的现象增多，教育机构需要有效检测工具以维护学术诚信。

Method: 提出了贡献级别的概念，并基于GEDE数据集（包含学生和LLM生成的文本）对多种检测器进行基准测试。

Result: 现有检测器在中间贡献级别（如LLM改进的文本）上表现不佳，易产生误报。

Conclusion: 检测器在教育场景中的误报问题需进一步解决，以避免对学生造成负面影响。

Abstract: Recent advancements in Large Language Models (LLMs) and their increased
accessibility have made it easier than ever for students to automatically
generate texts, posing new challenges for educational institutions. To enforce
norms of academic integrity and ensure students' learning, learning analytics
methods to automatically detect LLM-generated text appear increasingly
appealing. This paper benchmarks the performance of different state-of-the-art
detectors in educational contexts, introducing a novel dataset, called
Generative Essay Detection in Education (GEDE), containing over 900
student-written essays and over 12,500 LLM-generated essays from various
domains. To capture the diversity of LLM usage practices in generating text, we
propose the concept of contribution levels, representing students' contribution
to a given assignment. These levels range from purely human-written texts, to
slightly LLM-improved versions, to fully LLM-generated texts, and finally to
active attacks on the detector by "humanizing" generated texts. We show that
most detectors struggle to accurately classify texts of intermediate student
contribution levels, like LLM-improved human-written texts. Detectors are
particularly likely to produce false positives, which is problematic in
educational settings where false suspicions can severely impact students'
lives. Our dataset, code, and additional supplementary materials are publicly
available at
https://github.com/lukasgehring/Assessing-LLM-Text-Detection-in-Educational-Contexts.

</details>


### [63] [Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models](https://arxiv.org/abs/2508.08131)
*Wenze Xu,Chun Wang,Jiazhen Yu,Sheng Chen,Liang Gao,Weihong Deng*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文提出了一种名为OTReg的方法，通过最优传输正则化来缩小语音与文本表示之间的模态差距，从而提升语音语言模型（SLM）的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有语音语言模型（SLM）在跨数据集泛化上表现不佳，主要原因是语音与文本表示之间的模态差距。

Method: 引入最优传输正则化（OTReg），将语音-文本对齐建模为最优传输问题，并设计正则化损失优化SLM训练。

Result: 实验表明，OTReg能有效提升语音-文本对齐，缩小模态差距，并增强SLM的跨数据集泛化能力。

Conclusion: OTReg是一种轻量级方法，无需额外标签或参数，可无缝集成到现有SLM训练流程中，显著提升模型性能。

Abstract: Spoken Language Models (SLMs), which extend Large Language Models (LLMs) to
perceive speech inputs, have gained increasing attention for their potential to
advance speech understanding tasks. However, despite recent progress, studies
show that SLMs often struggle to generalize across datasets, even for trained
languages and tasks, raising concerns about whether they process speech in a
text-like manner as intended. A key challenge underlying this limitation is the
modality gap between speech and text representations. The high variability in
speech embeddings may allow SLMs to achieve strong in-domain performance by
exploiting unintended speech variations, ultimately hindering generalization.
To mitigate this modality gap, we introduce Optimal Transport Regularization
(OTReg), a method that formulates speech-text alignment as an optimal transport
problem and derives a regularization loss to improve SLM training. In each
training iteration, OTReg first establishes a structured correspondence between
speech and transcript embeddings by determining the optimal transport plan,
then incorporates the regularization loss based on this transport plan to
optimize SLMs in generating speech embeddings that align more effectively with
transcript embeddings. OTReg is lightweight, requiring no additional labels or
learnable parameters, and integrates seamlessly into existing SLM training
procedures. Extensive multilingual ASR experiments demonstrate that OTReg
enhances speech-text alignment, mitigates the modality gap, and consequently
improves SLM generalization across diverse datasets.

</details>


### [64] [Event-Aware Sentiment Factors from LLM-Augmented Financial Tweets: A Transparent Framework for Interpretable Quant Trading](https://arxiv.org/abs/2508.07408)
*Yueyi Wang,Qiyao Wei*

Main category: q-fin.ST

Relevance: 70.0

TL;DR: 该研究展示了大型语言模型（LLMs）在金融语义标注和阿尔法信号发现中的独特应用，通过分析公司相关推文，将多标签事件分类与市场回报对齐，验证了其统计有效性和交易潜力。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在金融领域的应用潜力，特别是如何将非结构化社交媒体文本转化为结构化、可交易的事件变量。

Method: 利用LLM对公司相关推文进行多标签事件分类，并将这些标签与1至7天的市场回报对齐，评估其统计显著性和交易效果。

Result: 某些事件标签表现出显著的负阿尔法，夏普比率低至-0.38，信息系数超过0.05，统计显著性达95%。

Conclusion: 研究表明社交媒体情感信号在金融预测中具有价值，开源框架有助于推动算法交易研究的民主化。

Abstract: In this study, we wish to showcase the unique utility of large language
models (LLMs) in financial semantic annotation and alpha signal discovery.
Leveraging a corpus of company-related tweets, we use an LLM to automatically
assign multi-label event categories to high-sentiment-intensity tweets. We
align these labeled sentiment signals with forward returns over 1-to-7-day
horizons to evaluate their statistical efficacy and market tradability. Our
experiments reveal that certain event labels consistently yield negative alpha,
with Sharpe ratios as low as -0.38 and information coefficients exceeding 0.05,
all statistically significant at the 95\% confidence level. This study
establishes the feasibility of transforming unstructured social media text into
structured, multi-label event variables. A key contribution of this work is its
commitment to transparency and reproducibility; all code and methodologies are
made publicly available. Our results provide compelling evidence that social
media sentiment is a valuable, albeit noisy, signal in financial forecasting
and underscore the potential of open-source frameworks to democratize
algorithmic trading research.

</details>


### [65] [LLMs for Law: Evaluating Legal-Specific LLMs on Contract Understanding](https://arxiv.org/abs/2508.07849)
*Amrita Singh,H. Suhan Karaca,Aditya Joshi,Hye-young Paik,Jiaojiao Jiang*

Main category: cs.CL

Relevance: 65.0

TL;DR: 论文填补了法律特定LLM在合同分类任务中全面评估的空白，比较了10种法律特定LLM与7种通用LLM的表现，发现前者在需要法律细微理解的任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对法律特定LLM在合同理解任务中的全面评估，因此作者旨在填补这一空白。

Method: 评估了10种法律特定LLM和7种通用LLM在三个英语合同理解任务上的表现。

Result: 法律特定LLM（如Legal-BERT和Contracts-BERT）在多数任务中优于通用LLM，且参数量更少。CaseLaw-BERT和LexLM也被确定为强基线。

Conclusion: 研究为法律特定LLM提供了全面评估，有助于开发更准确的合同理解系统。

Abstract: Despite advances in legal NLP, no comprehensive evaluation covering multiple
legal-specific LLMs currently exists for contract classification tasks in
contract understanding. To address this gap, we present an evaluation of 10
legal-specific LLMs on three English language contract understanding tasks and
compare them with 7 general-purpose LLMs. The results show that legal-specific
LLMs consistently outperform general-purpose models, especially on tasks
requiring nuanced legal understanding. Legal-BERT and Contracts-BERT establish
new SOTAs on two of the three tasks, despite having 69% fewer parameters than
the best-performing general-purpose LLM. We also identify CaseLaw-BERT and
LexLM as strong additional baselines for contract understanding. Our results
provide a holistic evaluation of legal-specific LLMs and will facilitate the
development of more accurate contract understanding systems.

</details>


### [66] [Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models](https://arxiv.org/abs/2508.06621)
*Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

Relevance: 60.0

TL;DR: 研究探讨了BPE推断算法对语言模型性能的影响，发现非目标性算法对性能影响较小，可能为更简单且隐私保护的分词方案提供支持。


<details>
  <summary>Details</summary>
Motivation: BPE分词中的合并列表可能成为攻击面，研究探索不依赖合并列表的推断算法对模型性能的影响。

Method: 比较两类BPE推断算法：目标性偏离合并列表（如随机合并顺序）和非目标性算法（如贪婪压缩）。

Result: 目标性偏离显著降低性能，而非目标性算法影响较小。

Conclusion: 非目标性算法为更简单且隐私保护的分词方案提供了可能。

Abstract: Standard Byte-Pair Encoding (BPE) tokenization compresses text by pairing a
learned token vocabulary with a detailed merge list. Recent work has shown that
this merge list exposes a potential attack surface for extracting information
about language model's training data. In this paper, we explore the downstream
impact of BPE inference algorithms that do not rely on this merge list at all,
and hence differ from the encoding process during BPE training. To address this
question, we investigate two broad classes of BPE inference schemes that differ
from BPE application during training: a) targeted deviation from merge-lists
including random merge orders, and various corruptions of merge list involving
deletion/truncation, and b) non-targeted BPE inference algorithms that do not
depend on the merge list but focus on compressing the text either greedily or
exactly. Extensive experiments across diverse language modeling tasks like
accuracy-based QA benchmarks, machine translation, and open-ended generation
reveal that while targeted deviation from the merge lists exhibits significant
degradation in language model performance, the non-targeted merge-list-free
inference algorithms result in minimal impact on downstream performance that is
often much smaller than expected. These findings pave way for simpler and
potentially more privacy-preserving tokenization schemes that do not
catastrophically compromise model performance.

</details>


### [67] [Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis](https://arxiv.org/abs/2508.06729)
*Komala Subramanyam Cherukuri,Pranav Abishai Moses,Aisa Sakata,Jiangping Chen,Haihua Chen*

Main category: cs.CL

Relevance: 60.0

TL;DR: 本文提出了一种基于LLM的自动化框架，用于对日裔美国人监禁口述历史进行语义和情感标注，通过多阶段方法结合专家标注和模型评估，展示了LLM在敏感历史档案分析中的有效性。


<details>
  <summary>Details</summary>
Motivation: 口述历史是记录生活经历的重要资料，但其大规模分析因非结构化格式、情感复杂性和高标注成本而受限。本文旨在通过LLM实现高效、可扩展的语义和情感标注。

Method: 采用多阶段方法，结合专家标注、提示设计和LLM评估（ChatGPT、Llama、Qwen），测试零样本、少样本和RAG策略。

Result: ChatGPT在语义分类中表现最佳（F1 88.71%），Llama在情感分析中略优（82.66%）。最佳提示配置用于标注92,191句。

Conclusion: LLM在精心设计的提示下可有效标注大规模口述历史，为数字人文和集体记忆保存提供了可复用的标注流程。

Abstract: Oral histories are vital records of lived experience, particularly within
communities affected by systemic injustice and historical erasure. Effective
and efficient analysis of their oral history archives can promote access and
understanding of the oral histories. However, Large-scale analysis of these
archives remains limited due to their unstructured format, emotional
complexity, and high annotation costs. This paper presents a scalable framework
to automate semantic and sentiment annotation for Japanese American
Incarceration Oral History. Using LLMs, we construct a high-quality dataset,
evaluate multiple models, and test prompt engineering strategies in
historically sensitive contexts. Our multiphase approach combines expert
annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We
labeled 558 sentences from 15 narrators for sentiment and semantic
classification, then evaluated zero-shot, few-shot, and RAG strategies. For
semantic classification, ChatGPT achieved the highest F1 score (88.71%),
followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama
slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models
showing comparable results. The best prompt configurations were used to
annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our
findings show that LLMs can effectively perform semantic and sentiment
annotation across large oral history collections when guided by well-designed
prompts. This study provides a reusable annotation pipeline and practical
guidance for applying LLMs in culturally sensitive archival analysis. By
bridging archival ethics with scalable NLP techniques, this work lays the
groundwork for responsible use of artificial intelligence in digital humanities
and preservation of collective memory. GitHub:
https://github.com/kc6699c/LLM4OralHistoryAnalysis.

</details>


### [68] [Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems](https://arxiv.org/abs/2508.06810)
*Steven Coyne,Diana Galvan-Sosa,Ryan Spring,Camélia Guerraoui,Michael Zock,Keisuke Sakaguchi,Kentaro Inui*

Main category: cs.CL

Relevance: 60.0

TL;DR: 论文提出了一种支持语言学习的自动写作评估系统框架，通过标注错误类型和可推广性，生成直接修正或提示性反馈，并评估了基于大语言模型的反馈生成方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动写作评估系统虽能修正语法错误，但未针对语言学习优化，缺乏对学习者知识缺口的针对性反馈。

Method: 引入标注框架，分类错误类型并标注可推广性，收集学习者错误数据集，评估基于大语言模型的反馈生成方法（关键词引导、无关键词、模板引导）。

Result: 构建了标注数据集，比较了不同反馈生成方法的性能，人类教师评估了输出的相关性、事实性和可理解性。

Conclusion: 框架和方法为语言学习提供了更有效的反馈生成工具，未来可进一步优化模型性能。

Abstract: Recent advances in natural language processing (NLP) have contributed to the
development of automated writing evaluation (AWE) systems that can correct
grammatical errors. However, while these systems are effective at improving
text, they are not optimally designed for language learning. They favor direct
revisions, often with a click-to-fix functionality that can be applied without
considering the reason for the correction. Meanwhile, depending on the error
type, learners may benefit most from simple explanations and strategically
indirect hints, especially on generalizable grammatical rules. To support the
generation of such feedback, we introduce an annotation framework that models
each error's error type and generalizability. For error type classification, we
introduce a typology focused on inferring learners' knowledge gaps by
connecting their errors to specific grammatical patterns. Following this
framework, we collect a dataset of annotated learner errors and corresponding
human-written feedback comments, each labeled as a direct correction or hint.
With this data, we evaluate keyword-guided, keyword-free, and template-guided
methods of generating feedback using large language models (LLMs). Human
teachers examined each system's outputs, assessing them on grounds including
relevance, factuality, and comprehensibility. We report on the development of
the dataset and the comparative performance of the systems investigated.

</details>


### [69] [Vec2Summ: Text Summarization via Probabilistic Sentence Embeddings](https://arxiv.org/abs/2508.07017)
*Mao Li,Fred Conrad,Johann Gagnon-Bartsch*

Main category: cs.CL

Relevance: 60.0

TL;DR: Vec2Summ是一种基于语义压缩的抽象摘要方法，通过均值向量表示文档集合并利用生成语言模型重建摘要，具有可扩展性和语义控制优势。


<details>
  <summary>Details</summary>
Motivation: 解决基于LLM的摘要方法在上下文长度限制、可解释性和可扩展性方面的不足。

Method: 将文档集合表示为语义嵌入空间中的均值向量，通过嵌入反演和随机采样生成摘要。

Result: 在主题集中的语料上生成连贯摘要，性能与直接LLM摘要相当，但细节较少。

Conclusion: Vec2Summ在可扩展性、语义控制和语料级抽象方面具有潜力。

Abstract: We propose Vec2Summ, a novel method for abstractive summarization that frames
the task as semantic compression. Vec2Summ represents a document collection
using a single mean vector in the semantic embedding space, capturing the
central meaning of the corpus. To reconstruct fluent summaries, we perform
embedding inversion -- decoding this mean vector into natural language using a
generative language model. To improve reconstruction quality and capture some
degree of topical variability, we introduce stochasticity by sampling from a
Gaussian distribution centered on the mean. This approach is loosely analogous
to bagging in ensemble learning, where controlled randomness encourages more
robust and varied outputs. Vec2Summ addresses key limitations of LLM-based
summarization methods. It avoids context-length constraints, enables
interpretable and controllable generation via semantic parameters, and scales
efficiently with corpus size -- requiring only $O(d + d^2)$ parameters.
Empirical results show that Vec2Summ produces coherent summaries for topically
focused, order-invariant corpora, with performance comparable to direct LLM
summarization in terms of thematic coverage and efficiency, albeit with less
fine-grained detail. These results underscore Vec2Summ's potential in settings
where scalability, semantic control, and corpus-level abstraction are
prioritized.

</details>


### [70] [Prompt Tuning for Few-Shot Continual Learning Named Entity Recognition](https://arxiv.org/abs/2508.07248)
*Zhe Ren*

Main category: cs.CL

Relevance: 60.0

TL;DR: 论文提出了一种基于提示调优和记忆演示模板的方法，解决了少样本持续学习命名实体识别任务中的蒸馏困境。


<details>
  <summary>Details</summary>
Motivation: 解决少样本持续学习命名实体识别任务中因新类别实体稀缺和旧类别信息缺失导致的蒸馏困境。

Method: 设计了可扩展的锚词导向提示调优（APT）范式，并结合记忆演示模板（MDT）提供历史任务样本。

Result: 实验表明该方法在少样本持续学习命名实体识别任务中表现优异。

Conclusion: 通过提示调优和记忆演示模板，有效解决了少样本蒸馏困境并提升了模型性能。

Abstract: Knowledge distillation has been successfully applied to Continual Learning
Named Entity Recognition (CLNER) tasks, by using a teacher model trained on
old-class data to distill old-class entities present in new-class data as a
form of regularization, thereby avoiding catastrophic forgetting. However, in
Few-Shot CLNER (FS-CLNER) tasks, the scarcity of new-class entities makes it
difficult for the trained model to generalize during inference. More
critically, the lack of old-class entity information hinders the distillation
of old knowledge, causing the model to fall into what we refer to as the
Few-Shot Distillation Dilemma. In this work, we address the above challenges
through a prompt tuning paradigm and memory demonstration template strategy.
Specifically, we designed an expandable Anchor words-oriented Prompt Tuning
(APT) paradigm to bridge the gap between pre-training and fine-tuning, thereby
enhancing performance in few-shot scenarios. Additionally, we incorporated
Memory Demonstration Templates (MDT) into each training instance to provide
replay samples from previous tasks, which not only avoids the Few-Shot
Distillation Dilemma but also promotes in-context learning. Experiments show
that our approach achieves competitive performances on FS-CLNER.

</details>


### [71] [MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory](https://arxiv.org/abs/2508.07279)
*Vasudha Varadarajan,Hui Xu,Rebecca Astrid Boehme,Mariam Marlan Mirstrom,Sverker Sikstrom,H. Andrew Schwartz*

Main category: cs.CL

Relevance: 60.0

TL;DR: MAQuA是一个自适应提问框架，用于多维心理健康筛查，通过优化问题选择减少提问数量，提高效率。


<details>
  <summary>Details</summary>
Motivation: 利用LLMs进行心理健康评估时，频繁提问会增加用户负担，MAQuA旨在通过智能问题选择优化诊断信息。

Method: 结合多结果建模、IRT和因子分析，动态选择最具信息量的问题。

Result: MAQuA减少50-87%的提问量，在不同症状领域表现稳健。

Conclusion: MAQuA为LLM在临床工作流中的集成提供了高效工具。

Abstract: Recent advances in large language models (LLMs) offer new opportunities for
scalable, interactive mental health assessment, but excessive querying by LLMs
burdens users and is inefficient for real-world screening across
transdiagnostic symptom profiles. We introduce MAQuA, an adaptive
question-asking framework for simultaneous, multidimensional mental health
screening. Combining multi-outcome modeling on language responses with item
response theory (IRT) and factor analysis, MAQuA selects the questions with
most informative responses across multiple dimensions at each turn to optimize
diagnostic information, improving accuracy and potentially reducing response
burden. Empirical results on a novel dataset reveal that MAQuA reduces the
number of assessment questions required for score stabilization by 50-87%
compared to random ordering (e.g., achieving stable depression scores with 71%
fewer questions and eating disorder scores with 85% fewer questions). MAQuA
demonstrates robust performance across both internalizing (depression, anxiety)
and externalizing (substance use, eating disorder) domains, with early stopping
strategies further reducing patient time and burden. These findings position
MAQuA as a powerful and efficient tool for scalable, nuanced, and interactive
mental health screening, advancing the integration of LLM-based agents into
real-world clinical workflows.

</details>


### [72] [Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking](https://arxiv.org/abs/2508.07286)
*Jian Chen,Jinbao Tian,Yankui Li,Zhou Li*

Main category: cs.CL

Relevance: 60.0

TL;DR: 论文提出ARCE方法，利用LLM生成简单解释（Cote）来增强RoBERTa模型，在AEC领域的NER任务中取得SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 解决AEC领域NER任务中预训练模型因领域术语和复杂关系导致的性能限制，避免高成本的人工标注。

Method: 使用LLM生成简单解释（Cote），并基于此增量预训练RoBERTa，再微调下游任务。

Result: 在AEC基准数据集上达到77.20%的Macro-F1分数，证明简单解释比复杂逻辑更有效。

Conclusion: ARCE通过LLM生成的知识增强小模型，为领域适应性问题提供了高效解决方案。

Abstract: Accurate information extraction from specialized texts is a critical
challenge, particularly for named entity recognition (NER) in the architecture,
engineering, and construction (AEC) domain to support automated rule checking
(ARC). The performance of standard pre-trained models is often constrained by
the domain gap, as they struggle to interpret the specialized terminology and
complex relational contexts inherent in AEC texts. Although this issue can be
mitigated by further pre-training on large, human-curated domain corpora, as
exemplified by methods like ARCBERT, this approach is both labor-intensive and
cost-prohibitive. Consequently, leveraging large language models (LLMs) for
automated knowledge generation has emerged as a promising alternative. However,
the optimal strategy for generating knowledge that can genuinely enhance
smaller, efficient models remains an open question. To address this, we propose
ARCE (augmented RoBERTa with contextualized elucidations), a novel approach
that systematically explores and optimizes this generation process. ARCE
employs an LLM to first generate a corpus of simple, direct explanations, which
we term Cote, and then uses this corpus to incrementally pre-train a RoBERTa
model prior to its fine-tuning on the downstream task. Our extensive
experiments show that ARCE establishes a new state-of-the-art on a benchmark
AEC dataset, achieving a Macro-F1 score of 77.20%. This result also reveals a
key finding: simple, explanation-based knowledge proves surprisingly more
effective than complex, role-based rationales for this task. The code is
publicly available at:https://github.com/nxcc-lab/ARCE.

</details>


### [73] [HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways](https://arxiv.org/abs/2508.07308)
*Cristian Cosentino,Annamaria Defilippo,Marco Dossena,Christopher Irwin,Sara Joubbi,Pietro Liò*

Main category: cs.CL

Relevance: 60.0

TL;DR: HealthBranches是一个专为评估大型语言模型（LLMs）在医学问答中的复杂推理能力而设计的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够评估LLMs在临床推理和结构化检索增强生成（RAG）中表现的数据集，以推动更可信、可解释的医学LLMs发展。

Method: 通过半自动化流程将医学来源的决策路径转化为真实的患者案例，包含问题和答案，覆盖17个医疗主题的4,063个案例。

Result: 数据集支持开放式和多项选择题格式，并包含完整的推理路径，可用于评估LLMs的多步推理能力。

Conclusion: HealthBranches为高风险领域中的可信赖、可解释LLMs开发奠定了基础，并可作为教育资源。

Abstract: HealthBranches is a novel benchmark dataset for medical Question-Answering
(Q&A), specifically designed to evaluate complex reasoning in Large Language
Models (LLMs). This dataset is generated through a semi-automated pipeline that
transforms explicit decision pathways from medical source into realistic
patient cases with associated questions and answers. Covering 4,063 case
studies across 17 healthcare topics, each data point is based on clinically
validated reasoning chains. HealthBranches supports both open-ended and
multiple-choice question formats and uniquely includes the full reasoning path
for each Q&A. Its structured design enables robust evaluation of LLMs'
multi-step inference capabilities, including their performance in structured
Retrieval-Augmented Generation (RAG) contexts. HealthBranches establishes a
foundation for the development of more trustworthy, interpretable, and
clinically reliable LLMs in high-stakes domains while also serving as a
valuable resource for educational purposes.

</details>


### [74] [SASST: Leveraging Syntax-Aware Chunking and LLMs for Simultaneous Speech Translation](https://arxiv.org/abs/2508.07781)
*Zeyu Yang,Lai Wei,Roman Koshkin,Xi Chen,Satoshi Nakamura*

Main category: cs.CL

Relevance: 60.0

TL;DR: 提出了一种基于语法的分块策略，通过解析依赖关系和标点特征将输入流分割为语义完整的单元，并在此基础上构建了SASST框架，结合Whisper编码器和仅解码器LLM，显著提升了多语言翻译质量。


<details>
  <summary>Details</summary>
Motivation: 解决输入流语义分割问题，优化同步语音翻译（SimulST）系统的翻译质量和时间安排。

Method: 使用语法分块策略确保语义连贯性，结合Whisper编码器和仅解码器LLM，动态输出翻译或等待符号。

Result: 在CoVoST2多语言语料库上验证了翻译质量的显著提升。

Conclusion: 语法结构在LLM驱动的SimulST系统中具有显著效果。

Abstract: This work proposes a grammar-based chunking strategy that segments input
streams into semantically complete units by parsing dependency relations (e.g.,
noun phrase boundaries, verb-object structures) and punctuation features. The
method ensures chunk coherence and minimizes semantic fragmentation. Building
on this mechanism, we present SASST (Syntax-Aware Simultaneous Speech
Translation), an end-to-end framework integrating frozen Whisper encoder and
decoder-only LLM. The unified architecture dynamically outputs translation
tokens or <WAIT> symbols to jointly optimize translation timing and content,
with target-side reordering addressing word-order divergence. Experiments on
CoVoST2 multilingual corpus En-{De, Zh, Ja} demonstrate significant translation
quality improvements across languages and validate the effectiveness of
syntactic structures in LLM-driven SimulST systems.

</details>


### [75] [Large Language Models for Czech Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2508.07860)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

Relevance: 60.0

TL;DR: 本文评估了19种不同规模和架构的大语言模型（LLMs）在捷克语方面情感分析（ABSA）中的表现，发现领域特定的小模型在零样本和少样本设置中优于通用LLMs，而微调后的LLMs达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在捷克语ABSA任务中的能力，填补现有研究的空白。

Method: 对19种LLMs进行零样本、少样本和微调场景下的全面评估，分析多语言性、模型规模和时效性对性能的影响。

Result: 领域特定小模型在零样本和少样本中表现更好，微调后的LLMs达到最优；多语言性和模型规模对性能有显著影响。

Conclusion: LLMs在捷克语ABSA中具有潜力，但需结合领域特定优化；研究为未来工作提供了指导。

Abstract: Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis
task that aims to identify sentiment toward specific aspects of an entity.
While large language models (LLMs) have shown strong performance in various
natural language processing (NLP) tasks, their capabilities for Czech ABSA
remain largely unexplored. In this work, we conduct a comprehensive evaluation
of 19 LLMs of varying sizes and architectures on Czech ABSA, comparing their
performance in zero-shot, few-shot, and fine-tuning scenarios. Our results show
that small domain-specific models fine-tuned for ABSA outperform
general-purpose LLMs in zero-shot and few-shot settings, while fine-tuned LLMs
achieve state-of-the-art results. We analyze how factors such as
multilingualism, model size, and recency influence performance and present an
error analysis highlighting key challenges, particularly in aspect term
prediction. Our findings provide insights into the suitability of LLMs for
Czech ABSA and offer guidance for future research in this area.

</details>


### [76] [Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens](https://arxiv.org/abs/2508.07143)
*Anna Seo Gyeong Choi,Hoon Choi*

Main category: cs.CL

Relevance: 50.0

TL;DR: 论文探讨了自动语音识别（ASR）系统中的偏见问题，指出其对非标准方言的误识别不仅是技术问题，更是对边缘化语言社区的不尊重。作者区分了道德中立的分类与有害歧视，并提出了ASR偏见的三个独特伦理维度。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于揭示ASR系统对非标准方言的误识别如何加剧历史不公，并探讨其伦理影响，以推动更公平的技术设计。

Method: 通过哲学视角分析ASR偏见的伦理维度，区分分类与歧视，并探讨语言标准化与多元化的矛盾。

Result: 研究发现ASR偏见涉及时间负担、对话流中断和身份认同等独特伦理问题，现有技术指标未能充分捕捉。

Conclusion: 解决ASR偏见需超越技术干预，承认语言多样性，并尊重说话者自主权。

Abstract: Automatic Speech Recognition (ASR) systems now mediate countless
human-technology interactions, yet research on their fairness implications
remains surprisingly limited. This paper examines ASR bias through a
philosophical lens, arguing that systematic misrecognition of certain speech
varieties constitutes more than a technical limitation -- it represents a form
of disrespect that compounds historical injustices against marginalized
linguistic communities. We distinguish between morally neutral classification
(discriminate1) and harmful discrimination (discriminate2), demonstrating how
ASR systems can inadvertently transform the former into the latter when they
consistently misrecognize non-standard dialects. We identify three unique
ethical dimensions of speech technologies that differentiate ASR bias from
other algorithmic fairness concerns: the temporal burden placed on speakers of
non-standard varieties ("temporal taxation"), the disruption of conversational
flow when systems misrecognize speech, and the fundamental connection between
speech patterns and personal/cultural identity. These factors create asymmetric
power relationships that existing technical fairness metrics fail to capture.
The paper analyzes the tension between linguistic standardization and pluralism
in ASR development, arguing that current approaches often embed and reinforce
problematic language ideologies. We conclude that addressing ASR bias requires
more than technical interventions; it demands recognition of diverse speech
varieties as legitimate forms of expression worthy of technological
accommodation. This philosophical reframing offers new pathways for developing
ASR systems that respect linguistic diversity and speaker autonomy.

</details>


### [77] [Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction](https://arxiv.org/abs/2508.06495)
*Juliana Resplande Sant'anna Gomes,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文提出了一种半自动化事实核查（SAFC）系统，针对葡萄牙语新闻语料库（Fake.Br、COVID19.BR、MuMiN-PT）进行外部证据的丰富，利用LLM（Gemini 1.5 Flash）提取主要声明并通过搜索引擎API检索相关证据。


<details>
  <summary>Details</summary>
Motivation: 解决葡萄牙语环境下缺乏整合外部证据的公开数据集的问题，以支持更强大的自动事实核查系统。

Method: 使用LLM提取文本中的主要声明，结合搜索引擎API检索外部证据，并引入数据验证和预处理框架（如近重复检测）提升语料库质量。

Result: 开发了一种方法，能够为葡萄牙语新闻语料库添加外部证据，模拟用户验证过程。

Conclusion: 该方法填补了葡萄牙语SAFC系统的数据空白，为未来研究提供了基础。

Abstract: The accelerated dissemination of disinformation often outpaces the capacity
for manual fact-checking, highlighting the urgent need for Semi-Automated
Fact-Checking (SAFC) systems. Within the Portuguese language context, there is
a noted scarcity of publicly available datasets that integrate external
evidence, an essential component for developing robust AFC systems, as many
existing resources focus solely on classification based on intrinsic text
features. This dissertation addresses this gap by developing, applying, and
analyzing a methodology to enrich Portuguese news corpora (Fake.Br, COVID19.BR,
MuMiN-PT) with external evidence. The approach simulates a user's verification
process, employing Large Language Models (LLMs, specifically Gemini 1.5 Flash)
to extract the main claim from texts and search engine APIs (Google Search API,
Google FactCheck Claims Search API) to retrieve relevant external documents
(evidence). Additionally, a data validation and preprocessing framework,
including near-duplicate detection, is introduced to enhance the quality of the
base corpora.

</details>


### [78] [ESNERA: Empirical and semantic named entity alignment for named entity dataset merging](https://arxiv.org/abs/2508.06877)
*Xiaobo Zhang,Congqing He,Ying He,Jian Peng,Dajie Fu,Tien-Ping Tan*

Main category: cs.CL

Relevance: 40.0

TL;DR: 提出了一种基于标签相似性的自动标签对齐方法，用于合并多源NER数据集，提升低资源领域的性能。


<details>
  <summary>Details</summary>
Motivation: 解决NER研究中依赖大规模标注数据的问题，当前数据集合并方法缺乏可解释性和可扩展性。

Method: 结合经验和语义相似性，采用贪心成对合并策略统一不同数据集的标签空间。

Result: 成功合并三个NER数据集，并在金融领域低资源场景中提升性能。

Conclusion: 该方法为多源NER语料库整合提供了高效、可解释且可扩展的解决方案。

Abstract: Named Entity Recognition (NER) is a fundamental task in natural language
processing. It remains a research hotspot due to its wide applicability across
domains. Although recent advances in deep learning have significantly improved
NER performance, they rely heavily on large, high-quality annotated datasets.
However, building these datasets is expensive and time-consuming, posing a
major bottleneck for further research. Current dataset merging approaches
mainly focus on strategies like manual label mapping or constructing label
graphs, which lack interpretability and scalability. To address this, we
propose an automatic label alignment method based on label similarity. The
method combines empirical and semantic similarities, using a greedy pairwise
merging strategy to unify label spaces across different datasets. Experiments
are conducted in two stages: first, merging three existing NER datasets into a
unified corpus with minimal impact on NER performance; second, integrating this
corpus with a small-scale, self-built dataset in the financial domain. The
results show that our method enables effective dataset merging and enhances NER
performance in the low-resource financial domain. This study presents an
efficient, interpretable, and scalable solution for integrating multi-source
NER corpora.

</details>


### [79] [The ReQAP System for Question Answering over Personal Information](https://arxiv.org/abs/2508.06880)
*Philipp Christmann,Gerhard Weikum*

Main category: cs.CL

Relevance: 40.0

TL;DR: ReQAP系统利用轻量级语言模型递归分解复杂问题并构建操作树，支持异构数据源的查询和聚合，增强用户信任。


<details>
  <summary>Details</summary>
Motivation: 解决用户设备上结构化与非结构化数据的复杂查询问题，提升查询效率和用户信任。

Method: 递归分解问题并构建操作树，利用轻量级语言模型进行问题解释和操作执行。

Result: 系统支持高级用户查询，并能追踪答案来源，提升可解释性和用户信任。

Conclusion: ReQAP通过递归分解和轻量级语言模型实现了高效且可解释的复杂查询系统。

Abstract: Personal information is abundant on users' devices, from structured data in
calendar, shopping records or fitness tools, to unstructured contents in mail
and social media posts. This works presents the ReQAP system that supports
users with answers for complex questions that involve filters, joins and
aggregation over heterogeneous sources. The unique trait of ReQAP is that it
recursively decomposes questions and incrementally builds an operator tree for
execution. Both the question interpretation and the individual operators make
smart use of light-weight language models, with judicious fine-tuning. The demo
showcases the rich functionality for advanced user questions, and also offers
detailed tracking of how the answers are computed by the operators in the
execution tree. Being able to trace answers back to the underlying sources is
vital for human comprehensibility and user trust in the system.

</details>


### [80] [Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction](https://arxiv.org/abs/2508.06971)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Khaled Shaban,Hozaifa Kassab*

Main category: cs.CL

Relevance: 40.0

TL;DR: 提出了一种两阶段框架，结合微调的语言模型和指令调优的大语言模型，在低资源领域的问答任务中取得最优结果。


<details>
  <summary>Details</summary>
Motivation: 解决古典阿拉伯语和宗教文本的复杂性带来的问答挑战。

Method: 两阶段框架：1) 使用微调的阿拉伯语言模型进行段落检索；2) 使用指令调优的大语言模型进行答案提取。

Result: 在Quran QA 2023任务中取得最优成绩（MAP@10=0.3128，MRR@10=0.5763，pAP@10=0.669）。

Conclusion: 模型集成和指令调优的结合有效解决了低资源领域问答的挑战。

Abstract: Quranic Question Answering presents unique challenges due to the linguistic
complexity of Classical Arabic and the semantic richness of religious texts. In
this paper, we propose a novel two-stage framework that addresses both passage
retrieval and answer extraction. For passage retrieval, we ensemble fine-tuned
Arabic language models to achieve superior ranking performance. For answer
extraction, we employ instruction-tuned large language models with few-shot
prompting to overcome the limitations of fine-tuning on small datasets. Our
approach achieves state-of-the-art results on the Quran QA 2023 Shared Task,
with a MAP@10 of 0.3128 and MRR@10 of 0.5763 for retrieval, and a pAP@10 of
0.669 for extraction, substantially outperforming previous methods. These
results demonstrate that combining model ensembling and instruction-tuned
language models effectively addresses the challenges of low-resource question
answering in specialized domains.

</details>


### [81] [SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages](https://arxiv.org/abs/2508.07069)
*Muhammad Dehan Al Kautsar,Aswin Candra,Muhammad Alif Al Hakim,Maxalmina Satria Kahfi,Fajri Koto,Alham Fikri Aji,Peerat Limkonchotiwat,Ekapol Chuangsuwanich,Genta Indra Winata*

Main category: cs.CL

Relevance: 40.0

TL;DR: SEADialogues是一个针对东南亚文化的多语言对话数据集，填补了现有数据集在文化多样性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有对话数据集缺乏文化多样性，尤其是东南亚地区的文化背景。

Method: 收集了六国八种语言的对话数据，包含人物属性和文化相关主题。

Result: 发布了SEADialogues数据集，支持多轮对话研究。

Conclusion: 该数据集有助于推动文化感知和以人为本的大语言模型研究。

Abstract: Although numerous datasets have been developed to support dialogue systems,
most existing chit-chat datasets overlook the cultural nuances inherent in
natural human conversations. To address this gap, we introduce SEADialogues, a
culturally grounded dialogue dataset centered on Southeast Asia, a region with
over 700 million people and immense cultural diversity. Our dataset features
dialogues in eight languages from six Southeast Asian countries, many of which
are low-resource despite having sizable speaker populations. To enhance
cultural relevance and personalization, each dialogue includes persona
attributes and two culturally grounded topics that reflect everyday life in the
respective communities. Furthermore, we release a multi-turn dialogue dataset
to advance research on culturally aware and human-centric large language
models, including conversational dialogue agents.

</details>


### [82] [Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback](https://arxiv.org/abs/2508.07178)
*Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文提出了一种去噪个性化标题生成框架PHG-DIF，通过双阶段过滤和多级时间融合解决点击流噪声问题，并在新数据集DT-PENS上取得SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视点击流中的噪声，导致生成的标题偏离用户真实兴趣，影响个性化生成质量。

Method: PHG-DIF采用双阶段过滤去除噪声（短停留时间和异常点击爆发），并通过多级时间融合动态建模用户兴趣。

Result: PHG-DIF显著减少噪声影响，在DT-PENS数据集上实现SOTA效果。

Conclusion: PHG-DIF通过去噪和动态建模用户兴趣，显著提升个性化标题生成质量。

Abstract: Accurate personalized headline generation hinges on precisely capturing user
interests from historical behaviors. However, existing methods neglect
personalized-irrelevant click noise in entire historical clickstreams, which
may lead to hallucinated headlines that deviate from genuine user preferences.
In this paper, we reveal the detrimental impact of click noise on personalized
generation quality through rigorous analysis in both user and news dimensions.
Based on these insights, we propose a novel Personalized Headline Generation
framework via Denoising Fake Interests from Implicit Feedback (PHG-DIF).
PHG-DIF first employs dual-stage filtering to effectively remove clickstream
noise, identified by short dwell times and abnormal click bursts, and then
leverages multi-level temporal fusion to dynamically model users' evolving and
multi-faceted interests for precise profiling. Moreover, we release DT-PENS, a
new benchmark dataset comprising the click behavior of 1,000 carefully curated
users and nearly 10,000 annotated personalized headlines with historical dwell
time annotations. Extensive experiments demonstrate that PHG-DIF substantially
mitigates the adverse effects of click noise and significantly improves
headline quality, achieving state-of-the-art (SOTA) results on DT-PENS. Our
framework implementation and dataset are available at
https://github.com/liukejin-up/PHG-DIF.

</details>


### [83] [Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks](https://arxiv.org/abs/2508.07179)
*Jiaqi Yin,Yi-Wei Chen,Meng-Lung Lee,Xiya Liu*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文提出了一种自动化提取多语言企业数据管道脚本中细粒度模式谱系的新框架，解决了语义漂移问题，并引入了SLiCE评估指标和新的基准。实验表明，模型规模和提示技术的复杂度对性能有显著影响。


<details>
  <summary>Details</summary>
Motivation: 解决企业数据管道中的语义漂移问题，提升数据可重现性和治理能力，尤其是对RAG和文本到SQL系统的支持。

Method: 提出自动化提取模式谱系的框架，识别源模式、源表、转换逻辑和聚合操作，并引入SLiCE评估指标和新基准。

Result: 实验表明，模型规模和提示技术的复杂度显著影响性能，32B开源模型在标准提示下性能接近GPT系列。

Conclusion: 该方法为实际应用中部署模式感知代理提供了一种可扩展且经济的解决方案。

Abstract: Enterprise data pipelines, characterized by complex transformations across
multiple programming languages, often cause a semantic disconnect between
original metadata and downstream data. This "semantic drift" compromises data
reproducibility and governance, and impairs the utility of services like
retrieval-augmented generation (RAG) and text-to-SQL systems. To address this,
a novel framework is proposed for the automated extraction of fine-grained
schema lineage from multilingual enterprise pipeline scripts. This method
identifies four key components: source schemas, source tables, transformation
logic, and aggregation operations, creating a standardized representation of
data transformations. For the rigorous evaluation of lineage quality, this
paper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that
assesses both structural correctness and semantic fidelity. A new benchmark is
also presented, comprising 1,700 manually annotated lineages from real-world
industrial scripts. Experiments were conducted with 12 language models, from
1.3B to 32B small language models (SLMs) to large language models (LLMs) like
GPT-4o and GPT-4.1. The results demonstrate that the performance of schema
lineage extraction scales with model size and the sophistication of prompting
techniques. Specially, a 32B open-source model, using a single reasoning trace,
can achieve performance comparable to the GPT series under standard prompting.
This finding suggests a scalable and economical approach for deploying
schema-aware agents in practical applications.

</details>


### [84] [How Does a Deep Neural Network Look at Lexical Stress?](https://arxiv.org/abs/2508.07229)
*Itai Allouche,Itay Asael,Rotem Rousso,Vered Dassa,Ann Bradlow,Seung-Eun Kim,Matthew Goldrick,Joseph Keshet*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文研究了CNN在预测英语双音节词重音位置时的表现，并通过LRP技术分析了其决策依据，发现重音元音的频谱特性是关键因素。


<details>
  <summary>Details</summary>
Motivation: 探究神经网络在语音处理中的决策依据，特别是在预测词重音位置时的可解释性。

Method: 构建英语双音节词数据集，训练多个CNN模型预测重音位置，使用LRP技术分析模型决策。

Result: 模型在测试数据上达到92%准确率，LRP分析显示重音元音的频谱特性（如第一和第二共振峰）对预测影响最大。

Conclusion: 深度学习能从自然数据中学习分布式重音线索，扩展了传统语音学研究的范围。

Abstract: Despite their success in speech processing, neural networks often operate as
black boxes, prompting the question: what informs their decisions, and how can
we interpret them? This work examines this issue in the context of lexical
stress. A dataset of English disyllabic words was automatically constructed
from read and spontaneous speech. Several Convolutional Neural Network (CNN)
architectures were trained to predict stress position from a spectrographic
representation of disyllabic words lacking minimal stress pairs (e.g., initial
stress WAllet, final stress exTEND), achieving up to 92% accuracy on held-out
test data. Layerwise Relevance Propagation (LRP), a technique for CNN
interpretability analysis, revealed that predictions for held-out minimal pairs
(PROtest vs. proTEST ) were most strongly influenced by information in stressed
versus unstressed syllables, particularly the spectral properties of stressed
vowels. However, the classifiers also attended to information throughout the
word. A feature-specific relevance analysis is proposed, and its results
suggest that our best-performing classifier is strongly influenced by the
stressed vowel's first and second formants, with some evidence that its pitch
and third formant also contribute. These results reveal deep learning's ability
to acquire distributed cues to stress from naturally occurring data, extending
traditional phonetic work based around highly controlled stimuli.

</details>


### [85] [Strategies of Code-switching in Human-Machine Dialogs](https://arxiv.org/abs/2508.07325)
*Dean Geckt,Melinda Fricke,Shuly Wintner*

Main category: cs.CL

Relevance: 40.0

TL;DR: 研究探讨了多语言代码切换的特性，通过开发一个能完成地图任务的聊天机器人，测试不同代码切换策略对双语使用的影响。


<details>
  <summary>Details</summary>
Motivation: 理解代码切换在多语言交流中的特性及其对用户体验的影响。

Method: 开发了一个能代码切换的聊天机器人，进行两项实验，测试不同代码切换策略的可行性和用户反应。

Result: 用户对可预测的代码切换行为反应积极，但对随机或不符语法的切换行为感到不适。

Conclusion: 未充分开发的多语言技术可能带来负面影响，但也展示了其在双语研究中的潜力。

Abstract: Most people are multilingual, and most multilinguals code-switch, yet the
characteristics of code-switched language are not fully understood. We
developed a chatbot capable of completing a Map Task with human participants
using code-switched Spanish and English. In two experiments, we prompted the
bot to code-switch according to different strategies, examining (1) the
feasibility of such experiments for investigating bilingual language use, and
(2) whether participants would be sensitive to variations in discourse and
grammatical patterns. Participants generally enjoyed code-switching with our
bot as long as it produced predictable code-switching behavior; when
code-switching was random or ungrammatical (as when producing unattested
incongruent mixed-language noun phrases, such as `la fork'), participants
enjoyed the task less and were less successful at completing it. These results
underscore the potential downsides of deploying insufficiently developed
multilingual language technology, while also illustrating the promise of such
technology for conducting research on bilingual language use.

</details>


### [86] [Word Clouds as Common Voices: LLM-Assisted Visualization of Participant-Weighted Themes in Qualitative Interviews](https://arxiv.org/abs/2508.07517)
*Joseph T. Colonel,Baihan Lin*

Main category: cs.CL

Relevance: 40.0

TL;DR: ThemeClouds是一个基于LLM的开源工具，用于从对话转录中生成主题词云，解决了传统频率方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统词频方法在对话语境中效果不佳，无法捕捉语义关联和参与者权重。

Method: 使用LLM识别概念级主题，并按参与者提及次数生成词云。

Result: ThemeClouds比传统方法（如LDA、BERTopic）更能发现实际设备问题。

Conclusion: ThemeClouds为定性分析提供了更透明、可控的LLM辅助工具。

Abstract: Word clouds are a common way to summarize qualitative interviews, yet
traditional frequency-based methods often fail in conversational contexts: they
surface filler words, ignore paraphrase, and fragment semantically related
ideas. This limits their usefulness in early-stage analysis, when researchers
need fast, interpretable overviews of what participant actually said. We
introduce ThemeClouds, an open-source visualization tool that uses large
language models (LLMs) to generate thematic, participant-weighted word clouds
from dialogue transcripts. The system prompts an LLM to identify concept-level
themes across a corpus and then counts how many unique participants mention
each topic, yielding a visualization grounded in breadth of mention rather than
raw term frequency. Researchers can customize prompts and visualization
parameters, providing transparency and control. Using interviews from a user
study comparing five recording-device configurations (31 participants; 155
transcripts, Whisper ASR), our approach surfaces more actionable device
concerns than frequency clouds and topic-modeling baselines (e.g., LDA,
BERTopic). We discuss design trade-offs for integrating LLM assistance into
qualitative workflows, implications for interpretability and researcher agency,
and opportunities for interactive analyses such as per-condition contrasts
(``diff clouds'').

</details>


### [87] [IBPS: Indian Bail Prediction System](https://arxiv.org/abs/2508.07592)
*Puspesh Kumar Srivastava,Uddeshya Raj,Praveen Patel,/Shubham Kumar Nigam,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文提出了一种基于AI的印度保释预测系统（IBPS），通过微调大语言模型，利用法律条文背景预测保释结果并生成法律依据，旨在解决印度司法系统中的保释决策问题。


<details>
  <summary>Details</summary>
Motivation: 印度保释决策存在主观性、延迟和不一致问题，且大量未审判囚犯导致司法积压和人权问题。IBPS旨在通过AI提供透明、可扩展的解决方案。

Method: 收集并标注15万份高等法院保释判决数据，利用参数高效技术微调大语言模型，结合法律条文背景（RAG）进行预测和解释生成。

Result: 结合法律条文背景的模型显著优于基线，表现出高准确性和解释质量，并能泛化到专家标注的测试集。

Conclusion: IBPS为印度司法系统提供了一种透明、可扩展的解决方案，支持数据驱动的法律辅助，减少保释延迟并促进程序公平。

Abstract: Bail decisions are among the most frequently adjudicated matters in Indian
courts, yet they remain plagued by subjectivity, delays, and inconsistencies.
With over 75% of India's prison population comprising undertrial prisoners,
many from socioeconomically disadvantaged backgrounds, the lack of timely and
fair bail adjudication exacerbates human rights concerns and contributes to
systemic judicial backlog. In this paper, we present the Indian Bail Prediction
System (IBPS), an AI-powered framework designed to assist in bail
decision-making by predicting outcomes and generating legally sound rationales
based solely on factual case attributes and statutory provisions. We curate and
release a large-scale dataset of 150,430 High Court bail judgments, enriched
with structured annotations such as age, health, criminal history, crime
category, custody duration, statutes, and judicial reasoning. We fine-tune a
large language model using parameter-efficient techniques and evaluate its
performance across multiple configurations, with and without statutory context,
and with RAG. Our results demonstrate that models fine-tuned with statutory
knowledge significantly outperform baselines, achieving strong accuracy and
explanation quality, and generalize well to a test set independently annotated
by legal experts. IBPS offers a transparent, scalable, and reproducible
solution to support data-driven legal assistance, reduce bail delays, and
promote procedural fairness in the Indian judicial system.

</details>


### [88] [InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information](https://arxiv.org/abs/2508.07630)
*Anirudh Iyengar Kaniyar Narayana Iyengar,Srija Mukhopadhyay,Adnan Qidwai,Shubhankar Singh,Dan Roth,Vivek Gupta*

Main category: cs.CL

Relevance: 40.0

TL;DR: InterChart是一个评估视觉语言模型（VLMs）在多图表推理任务中表现的诊断基准，涵盖从简单事实推理到复杂语义推理的多个难度层级。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注单一图表，而InterChart旨在填补多图表推理任务的空白，适用于科学、金融和政策等实际应用场景。

Method: InterChart分为三个难度层级：1）单一图表的事实推理；2）合成对齐图表集的综合分析；3）复杂真实图表对的语义推理。

Result: 实验表明，随着图表复杂度增加，VLMs的准确性显著下降，且模型在分解多实体图表时表现更好。

Conclusion: InterChart揭示了VLMs在多图表推理中的系统性局限，为复杂多视觉环境下的多模态推理研究提供了框架。

Abstract: We introduce InterChart, a diagnostic benchmark that evaluates how well
vision-language models (VLMs) reason across multiple related charts, a task
central to real-world applications such as scientific reporting, financial
analysis, and public policy dashboards. Unlike prior benchmarks focusing on
isolated, visually uniform charts, InterChart challenges models with diverse
question types ranging from entity inference and trend correlation to numerical
estimation and abstract multi-step reasoning grounded in 2-3 thematically or
structurally related charts. We organize the benchmark into three tiers of
increasing difficulty: (1) factual reasoning over individual charts, (2)
integrative analysis across synthetically aligned chart sets, and (3) semantic
inference over visually complex, real-world chart pairs. Our evaluation of
state-of-the-art open and closed-source VLMs reveals consistent and steep
accuracy declines as chart complexity increases. We find that models perform
better when we decompose multi-entity charts into simpler visual units,
underscoring their struggles with cross-chart integration. By exposing these
systematic limitations, InterChart provides a rigorous framework for advancing
multimodal reasoning in complex, multi-visual environments.

</details>


### [89] [Few-shot Cross-lingual Aspect-Based Sentiment Analysis with Sequence-to-Sequence Models](https://arxiv.org/abs/2508.07866)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文研究了在低资源语言中，通过添加少量目标语言示例到训练集，显著提升跨语言方面情感分析（ABSA）性能的效果。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言中ABSA任务因标注数据稀缺而面临的挑战，探索利用少量目标语言示例提升模型性能的可行性。

Method: 在四个ABSA任务、六种目标语言和两种序列到序列模型上，评估添加少量目标语言示例对性能的影响。

Result: 添加十个目标语言示例即可显著优于零样本设置，结合1000个示例甚至能超越单语基线。

Conclusion: 少量高质量标注示例对提升跨语言ABSA性能既可行又高效。

Abstract: Aspect-based sentiment analysis (ABSA) has received substantial attention in
English, yet challenges remain for low-resource languages due to the scarcity
of labelled data. Current cross-lingual ABSA approaches often rely on external
translation tools and overlook the potential benefits of incorporating a small
number of target language examples into training. In this paper, we evaluate
the effect of adding few-shot target language examples to the training set
across four ABSA tasks, six target languages, and two sequence-to-sequence
models. We show that adding as few as ten target language examples
significantly improves performance over zero-shot settings and achieves a
similar effect to constrained decoding in reducing prediction errors.
Furthermore, we demonstrate that combining 1,000 target language examples with
English data can even surpass monolingual baselines. These findings offer
practical insights for improving cross-lingual ABSA in low-resource and
domain-specific settings, as obtaining ten high-quality annotated examples is
both feasible and highly effective.

</details>


### [90] [Toward Machine Interpreting: Lessons from Human Interpreting Studies](https://arxiv.org/abs/2508.07964)
*Matthias Sperber,Maureen de Seyssel,Jiajun Bao,Matthias Paulik*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文探讨如何通过借鉴人类口译原则改进语音翻译系统，以缩小其与真实口译体验的差距。


<details>
  <summary>Details</summary>
Motivation: 当前语音翻译系统行为静态，缺乏人类口译的适应性，研究旨在提升其实用性。

Method: 结合机器翻译领域视角分析人类口译文献，提出改进语音翻译系统的建模方法。

Result: 发现通过现代建模技术可以采纳人类口译原则，潜力巨大。

Conclusion: 研究为缩小语音翻译系统与真实口译的可用性差距提供了启发。

Abstract: Current speech translation systems, while having achieved impressive
accuracies, are rather static in their behavior and do not adapt to real-world
situations in ways human interpreters do. In order to improve their practical
usefulness and enable interpreting-like experiences, a precise understanding of
the nature of human interpreting is crucial. To this end, we discuss human
interpreting literature from the perspective of the machine translation field,
while considering both operational and qualitative aspects. We identify
implications for the development of speech translation systems and argue that
there is great potential to adopt many human interpreting principles using
recent modeling techniques. We hope that our findings provide inspiration for
closing the perceived usability gap, and can motivate progress toward true
machine interpreting.

</details>


### [91] [Iterative refinement, not training objective, makes HuBERT behave differently from wav2vec 2.0](https://arxiv.org/abs/2508.08110)
*Robin Huo,Ewan Dunbar*

Main category: cs.CL

Relevance: 40.0

TL;DR: 研究比较了HuBERT和wav2vec 2.0两种自监督语音表示学习模型，发现训练迭代次数（而非训练目标）对隐藏表示中语言信息的编码有显著影响。


<details>
  <summary>Details</summary>
Motivation: 探讨模型架构对自监督语音表示学习中语言信息编码的影响，填补相关研究的空白。

Method: 比较HuBERT和wav2vec 2.0的训练目标和迭代伪标签精炼过程，分析隐藏表示与语言信息（如词、音素、说话者）的相关性。

Result: 训练迭代次数是影响语言信息编码的主要因素，而非训练目标。

Conclusion: 建议未来研究探索迭代精炼在自监督语音表示中编码语言信息的有效性原因。

Abstract: Self-supervised models for speech representation learning now see widespread
use for their versatility and performance on downstream tasks, but the effect
of model architecture on the linguistic information learned in their
representations remains under-studied. This study investigates two such models,
HuBERT and wav2vec 2.0, and minimally compares two of their architectural
differences: training objective and iterative pseudo-label refinement through
multiple training iterations. We find that differences in canonical correlation
of hidden representations to word identity, phoneme identity, and speaker
identity are explained by training iteration, not training objective. We
suggest that future work investigate the reason for the effectiveness of
iterative refinement in encoding linguistic information in self-supervised
speech representations.

</details>


### [92] [LPI-RIT at LeWiDi-2025: Improving Distributional Predictions via Metadata and Loss Reweighting with DisCo](https://arxiv.org/abs/2508.08163)
*Mandira Sawkar,Samay U. Shetty,Deepak Pandita,Tharindu Cyril Weerasooriya,Christopher M. Homan*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文提出了一种改进的DisCo模型，通过整合标注者元数据和优化损失函数，更好地捕捉标注分歧，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决标注分歧问题，通过建模标注者的软标签分布和视角评估，提升模型对复杂人工标注数据的理解。

Method: 方法包括扩展DisCo架构，整合标注者元数据、优化输入表示和修改损失函数，以更好地捕捉分歧模式。

Result: 实验表明，改进后的模型在软标签和视角评估指标上均有显著提升，并通过误差和校准分析揭示了改进条件。

Conclusion: 结论强调了分歧感知建模的价值，并提供了系统组件与复杂标注数据交互的见解。

Abstract: The Learning With Disagreements (LeWiDi) 2025 shared task is to model
annotator disagreement through soft label distribution prediction and
perspectivist evaluation, modeling annotators. We adapt DisCo (Distribution
from Context), a neural architecture that jointly models item-level and
annotator-level label distributions, and present detailed analysis and
improvements. In this paper, we extend the DisCo by incorporating annotator
metadata, enhancing input representations, and modifying the loss functions to
capture disagreement patterns better. Through extensive experiments, we
demonstrate substantial improvements in both soft and perspectivist evaluation
metrics across three datasets. We also conduct in-depth error and calibration
analyses, highlighting the conditions under which improvements occur. Our
findings underscore the value of disagreement-aware modeling and offer insights
into how system components interact with the complexity of human-annotated
data.

</details>


### [93] [Story Ribbons: Reimagining Storyline Visualizations with Large Language Models](https://arxiv.org/abs/2508.06772)
*Catherine Yeh,Tara Menon,Robin Singh Arya,Helen He,Moira Weigel,Fernanda Viégas,Martin Wattenberg*

Main category: cs.HC

Relevance: 40.0

TL;DR: 论文提出了一种基于LLM的数据解析管道，用于从小说和剧本中提取叙事信息，并开发了交互式可视化系统Story Ribbons，展示了LLM在叙事可视化中的潜力。


<details>
  <summary>Details</summary>
Motivation: 利用LLM的文本处理能力改进现有的故事情节可视化技术，解决从非结构化故事数据中提取结构化信息的挑战。

Method: 引入LLM驱动的数据解析管道，自动提取叙事信息，并开发Story Ribbons可视化系统。

Result: 通过36部文学作品的评估和用户研究，证明了LLM在简化叙事可视化创建和揭示新见解方面的潜力。

Conclusion: LLM可以增强叙事可视化，但仍存在局限性，需通过交互设计解决。

Abstract: Analyzing literature involves tracking interactions between characters,
locations, and themes. Visualization has the potential to facilitate the
mapping and analysis of these complex relationships, but capturing structured
information from unstructured story data remains a challenge. As large language
models (LLMs) continue to advance, we see an opportunity to use their text
processing and analysis capabilities to augment and reimagine existing
storyline visualization techniques. Toward this goal, we introduce an
LLM-driven data parsing pipeline that automatically extracts relevant narrative
information from novels and scripts. We then apply this pipeline to create
Story Ribbons, an interactive visualization system that helps novice and expert
literary analysts explore detailed character and theme trajectories at multiple
narrative levels. Through pipeline evaluations and user studies with Story
Ribbons on 36 literary works, we demonstrate the potential of LLMs to
streamline narrative visualization creation and reveal new insights about
familiar stories. We also describe current limitations of AI-based systems, and
interaction motifs designed to address these issues.

</details>


### [94] [Towards Real-World Rumor Detection: Anomaly Detection Framework with Graph Supervised Contrastive Learning](https://arxiv.org/abs/2508.07205)
*Chaoqun Cui,Caiyan Jia*

Main category: cs.SI

Relevance: 40.0

TL;DR: 论文提出了一种基于图监督对比学习的异常检测框架（AD-GSCL），用于解决社交媒体中谣言检测的数据稀缺和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现实社交媒体数据中谣言占比极低，传统方法假设类别平衡且依赖有限标注数据，无法有效处理数据不平衡问题。

Method: 构建了两个大规模对话数据集（Weibo和Twitter），提出AD-GSCL框架，将未标注数据视为非谣言，利用图对比学习进行异常检测。

Result: AD-GSCL在类别平衡、不平衡和少样本条件下均表现出优越性能。

Conclusion: 研究为现实世界中数据不平衡的谣言检测提供了新思路。

Abstract: Current rumor detection methods based on propagation structure learning
predominately treat rumor detection as a class-balanced classification task on
limited labeled data. However, real-world social media data exhibits an
imbalanced distribution with a minority of rumors among massive regular posts.
To address the data scarcity and imbalance issues, we construct two large-scale
conversation datasets from Weibo and Twitter and analyze the domain
distributions. We find obvious differences between rumor and non-rumor
distributions, with non-rumors mostly in entertainment domains while rumors
concentrate in news, indicating the conformity of rumor detection to an anomaly
detection paradigm. Correspondingly, we propose the Anomaly Detection framework
with Graph Supervised Contrastive Learning (AD-GSCL). It heuristically treats
unlabeled data as non-rumors and adapts graph contrastive learning for rumor
detection. Extensive experiments demonstrate AD-GSCL's superiority under
class-balanced, imbalanced, and few-shot conditions. Our findings provide
valuable insights for real-world rumor detection featuring imbalanced data
distributions.

</details>


### [95] [Improving Document Retrieval Coherence for Semantically Equivalent Queries](https://arxiv.org/abs/2508.07975)
*Stefano Campese,Alessandro Moschitti,Ivano Lauriola*

Main category: cs.IR

Relevance: 40.0

TL;DR: 提出了一种改进的多负排名损失方法，用于训练密集检索模型，以提高模型在语义相似查询下检索文档的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有密集检索模型对查询和文档词汇敏感，微小变化可能导致检索结果显著不同，因此需要提高模型的一致性。

Method: 提出了一种改进的多负排名损失，惩罚语义相似查询下检索文档的不一致性。

Result: 实验表明，优化后的模型具有更低的敏感性和更高的准确性。

Conclusion: 该方法有效提升了密集检索模型的一致性和性能。

Abstract: Dense Retrieval (DR) models have proven to be effective for Document
Retrieval and Information Grounding tasks. Usually, these models are trained
and optimized for improving the relevance of top-ranked documents for a given
query. Previous work has shown that popular DR models are sensitive to the
query and document lexicon: small variations of it may lead to a significant
difference in the set of retrieved documents. In this paper, we propose a
variation of the Multi-Negative Ranking loss for training DR that improves the
coherence of models in retrieving the same documents with respect to
semantically similar queries. The loss penalizes discrepancies between the
top-k ranked documents retrieved for diverse but semantic equivalent queries.
We conducted extensive experiments on various datasets, MS-MARCO, Natural
Questions, BEIR, and TREC DL 19/20. The results show that (i) models optimizes
by our loss are subject to lower sensitivity, and, (ii) interestingly, higher
accuracy.

</details>


### [96] [Exploring Procedural Data Generation for Automatic Acoustic Guitar Fingerpicking Transcription](https://arxiv.org/abs/2508.07987)
*Sebastian Murgul,Michael Heizmann*

Main category: cs.SD

Relevance: 40.0

TL;DR: 论文探讨了通过合成数据训练吉他指弹转录模型的方法，结合了知识库生成的指弹谱、MIDI渲染、物理建模和音频增强，证明了合成数据的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决吉他指弹转录任务中标注数据稀缺和法律限制的问题。

Method: 采用四阶段合成数据生成流程（指弹谱生成、MIDI渲染、物理建模、音频增强），并训练CRNN模型进行音符追踪。

Result: 合成数据训练模型表现合理，少量真实数据微调后效果优于仅用真实数据训练的模型。

Conclusion: 合成数据在数据稀缺的音乐信息检索任务中具有潜力。

Abstract: Automatic transcription of acoustic guitar fingerpicking performances remains
a challenging task due to the scarcity of labeled training data and legal
constraints connected with musical recordings. This work investigates a
procedural data generation pipeline as an alternative to real audio recordings
for training transcription models. Our approach synthesizes training data
through four stages: knowledge-based fingerpicking tablature composition, MIDI
performance rendering, physical modeling using an extended Karplus-Strong
algorithm, and audio augmentation including reverb and distortion. We train and
evaluate a CRNN-based note-tracking model on both real and synthetic datasets,
demonstrating that procedural data can be used to achieve reasonable
note-tracking results. Finetuning with a small amount of real data further
enhances transcription accuracy, improving over models trained exclusively on
real recordings. These results highlight the potential of procedurally
generated audio for data-scarce music information retrieval tasks.

</details>


### [97] [Text to Speech System for Meitei Mayek Script](https://arxiv.org/abs/2508.06870)
*Gangular Singh Irengbam,Nirvash Singh Wahengbam,Lanthoiba Meitei Khumanthem,Paikhomba Oinam*

Main category: cs.CL

Relevance: 30.0

TL;DR: 开发了一个基于Tacotron 2和HiFi-GAN的曼尼普尔语TTS系统，支持音调语音学和低资源语言环境。


<details>
  <summary>Details</summary>
Motivation: 为曼尼普尔语开发TTS系统，促进语言保护和技术包容。

Method: 使用Tacotron 2和HiFi-GAN架构，开发音素映射，并构建单说话人数据集。

Result: 系统通过主客观指标验证，实现了清晰自然的语音合成。

Conclusion: 该系统为曼尼普尔语的语言保护和技术应用奠定了基础。

Abstract: This paper presents the development of a Text-to-Speech (TTS) system for the
Manipuri language using the Meitei Mayek script. Leveraging Tacotron 2 and
HiFi-GAN, we introduce a neural TTS architecture adapted to support tonal
phonology and under-resourced linguistic environments. We develop a phoneme
mapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and
demonstrate intelligible and natural speech synthesis, validated through
subjective and objective metrics. This system lays the groundwork for
linguistic preservation and technological inclusion of Manipuri.

</details>


### [98] [Evaluating Compositional Approaches for Focus and Sentiment Analysis](https://arxiv.org/abs/2508.07810)
*Olga Kellert,Muhammad Imran,Nicholas Hill Matlis,Mahmud Uz Zaman,Carlos Gómez-Rodríguez*

Main category: cs.CL

Relevance: 30.0

TL;DR: 论文探讨了语言学中的焦点分析（FA）与自然语言处理（NLP）中的情感分析（SA）的组合方法，填补了FA领域定量评估的空白，并验证了组合规则在SA中的适用性。


<details>
  <summary>Details</summary>
Motivation: 填补语言学中焦点分析（FA）的定量评估空白，并验证情感分析（SA）的组合规则是否适用于FA。

Method: 利用通用依赖（UDs）形式化的基本句法规则（如修饰、协调和否定）进行组合分析，并与非组合方法VADER对比。

Result: 组合方法在SA中表现出更高的准确性和可解释性，且结果可推广至FA。

Conclusion: 组合规则在SA和FA中均适用，组合方法优于非组合方法。

Abstract: This paper summarizes the results of evaluating a compositional approach for
Focus Analysis (FA) in Linguistics and Sentiment Analysis (SA) in Natural
Language Processing (NLP). While quantitative evaluations of compositional and
non-compositional approaches in SA exist in NLP, similar quantitative
evaluations are very rare in FA in Linguistics that deal with linguistic
expressions representing focus or emphasis such as "it was John who left". We
fill this gap in research by arguing that compositional rules in SA also apply
to FA because FA and SA are closely related meaning that SA is part of FA. Our
compositional approach in SA exploits basic syntactic rules such as rules of
modification, coordination, and negation represented in the formalism of
Universal Dependencies (UDs) in English and applied to words representing
sentiments from sentiment dictionaries. Some of the advantages of our
compositional analysis method for SA in contrast to non-compositional analysis
methods are interpretability and explainability. We test the accuracy of our
compositional approach and compare it with a non-compositional approach VADER
that uses simple heuristic rules to deal with negation, coordination and
modification. In contrast to previous related work that evaluates
compositionality in SA on long reviews, this study uses more appropriate
datasets to evaluate compositionality. In addition, we generalize the results
of compositional approaches in SA to compositional approaches in FA.

</details>


### [99] [The Medical Metaphors Corpus (MCC)](https://arxiv.org/abs/2508.07993)
*Anna Sofia Lippolis,Andrea Giovanni Nuzzolese,Aldo Gangemi*

Main category: cs.CL

Relevance: 30.0

TL;DR: 论文介绍了医学隐喻语料库（MCC），一个包含792个标注的科学概念隐喻的数据集，用于医学和生物学领域。


<details>
  <summary>Details</summary>
Motivation: 填补领域特定隐喻检测资源的空白，支持科学隐喻的计算研究。

Method: 收集并标注来自同行评审文献、新闻媒体、社交媒体和众包的隐喻表达，提供二元和分级隐喻性判断。

Result: 现有语言模型在科学隐喻检测上表现一般，显示领域特定隐喻理解的改进空间。

Conclusion: MCC支持隐喻检测基准测试、质量感知生成系统和以患者为中心的沟通工具。

Abstract: Metaphor is a fundamental cognitive mechanism that shapes scientific
understanding, enabling the communication of complex concepts while potentially
constraining paradigmatic thinking. Despite the prevalence of figurative
language in scientific discourse, existing metaphor detection resources
primarily focus on general-domain text, leaving a critical gap for
domain-specific applications. In this paper, we present the Medical Metaphors
Corpus (MCC), a comprehensive dataset of 792 annotated scientific conceptual
metaphors spanning medical and biological domains. MCC aggregates metaphorical
expressions from diverse sources including peer-reviewed literature, news
media, social media discourse, and crowdsourced contributions, providing both
binary and graded metaphoricity judgments validated through human annotation.
Each instance includes source-target conceptual mappings and perceived
metaphoricity scores on a 0-7 scale, establishing the first annotated resource
for computational scientific metaphor research. Our evaluation demonstrates
that state-of-the-art language models achieve modest performance on scientific
metaphor detection, revealing substantial room for improvement in
domain-specific figurative language understanding. MCC enables multiple
research applications including metaphor detection benchmarking, quality-aware
generation systems, and patient-centered communication tools.

</details>


### [100] [9th Workshop on Sign Language Translation and Avatar Technologies (SLTAT 2025)](https://arxiv.org/abs/2508.08050)
*Fabrizio Nunnari,Cristina Luna Jiménez,Rosalee Wolfe,John C. McDonald,Michael Filhol,Eleni Efthimiou,Evita Fotinea,Thomas Hanke*

Main category: cs.CL

Relevance: 30.0

TL;DR: SLTAT 2025研讨会聚焦于通过非侵入性手段改善聋人/人类交流，涵盖手语翻译、虚拟化身技术、数据收集与分析等领域。


<details>
  <summary>Details</summary>
Motivation: 改善聋人与人类的交流，促进数字人类技术在手语翻译和交互式对话代理中的应用。

Method: 结合手语识别、虚拟化身技术、数据分析和伦理研究等多领域方法。

Result: 研讨会汇集了手语识别、数据工具、伦理和情感计算等多方面的研究成果。

Conclusion: SLTAT 2025推动了手语技术与虚拟人类技术的交叉研究，为聋人交流提供了更多可能性。

Abstract: The Sign Language Translation and Avatar Technology (SLTAT) workshops
continue a series of gatherings to share recent advances in improving deaf /
human communication through non-invasive means. This 2025 edition, the 9th
since its first appearance in 2011, is hosted by the International Conference
on Intelligent Virtual Agents (IVA), giving the opportunity for contamination
between two research communities, using digital humans as either virtual
interpreters or as interactive conversational agents. As presented in this
summary paper, SLTAT sees contributions beyond avatar technologies, with a
consistent number of submissions on sign language recognition, and other work
on data collection, data analysis, tools, ethics, usability, and affective
computing.

</details>


### [101] [Czech Dataset for Complex Aspect-Based Sentiment Analysis Tasks](https://arxiv.org/abs/2508.08125)
*Jakub Šmíd,Pavel Přibáň,Ondřej Pražák,Pavel Král*

Main category: cs.CL

Relevance: 30.0

TL;DR: 论文介绍了一个捷克语的新数据集，用于基于方面的情感分析（ABSA），包含3.1K手动标注的餐厅评论，支持更复杂的任务（如目标-方面-类别检测），并提供了24M未标注评论。


<details>
  <summary>Details</summary>
Motivation: 为捷克语提供更复杂的ABSA任务数据集，填补现有数据集的不足，并支持跨语言比较。

Method: 基于旧捷克语数据集扩展，采用统一标注格式（类似SemEval-2016），由两名标注者完成，标注一致性达90%。

Result: 提供了数据集和基线结果（基于Transformer模型），并进行了错误分析。

Conclusion: 新数据集支持复杂ABSA任务和跨语言研究，代码和数据公开。

Abstract: In this paper, we introduce a novel Czech dataset for aspect-based sentiment
analysis (ABSA), which consists of 3.1K manually annotated reviews from the
restaurant domain. The dataset is built upon the older Czech dataset, which
contained only separate labels for the basic ABSA tasks such as aspect term
extraction or aspect polarity detection. Unlike its predecessor, our new
dataset is specifically designed for more complex tasks, e.g.
target-aspect-category detection. These advanced tasks require a unified
annotation format, seamlessly linking sentiment elements (labels) together. Our
dataset follows the format of the well-known SemEval-2016 datasets. This design
choice allows effortless application and evaluation in cross-lingual scenarios,
ultimately fostering cross-language comparisons with equivalent counterpart
datasets in other languages. The annotation process engaged two trained
annotators, yielding an impressive inter-annotator agreement rate of
approximately 90%. Additionally, we provide 24M reviews without annotations
suitable for unsupervised learning. We present robust monolingual baseline
results achieved with various Transformer-based models and insightful error
analysis to supplement our contributions. Our code and dataset are freely
available for non-commercial research purposes.

</details>


### [102] [Challenges and opportunities in portraying emotion in generated sign language](https://arxiv.org/abs/2508.07937)
*John C. McDonald,Rosalee Wolfe,Fabrizio Nunnari*

Main category: cs.CL

Relevance: 20.0

TL;DR: 论文提出了一种双参数表示方法，用于改进手语虚拟角色Paula的情感非手动信号表达，通过EASIER文本表示实现更一致的情感控制。


<details>
  <summary>Details</summary>
Motivation: 解决手语虚拟角色在情感表达上的标准化问题，提升情感非手动信号的连贯性和一致性。

Method: 采用双参数表示法，通过EASIER文本表示控制虚拟角色的情感表达。

Result: 该方法能更一致地指定情感非手动信号，并实现更细腻的情感状态表达。

Conclusion: 双参数表示法为手语虚拟角色的情感表达提供了一种更直观和一致的方法。

Abstract: Non-manual signals in sign languages continue to be a challenge for signing
avatars. More specifically, emotional content has been difficult to incorporate
because of a lack of a standard method of specifying the avatar's emotional
state. This paper explores the application of an intuitive two-parameter
representation for emotive non-manual signals to the Paula signing avatar that
shows promise for facilitating the linguistic specification of emotional facial
expressions in a more coherent manner than previous methods. Users can apply
these parameters to control Paula's emotional expressions through a textual
representation called the EASIER notation. The representation can allow avatars
to express more nuanced emotional states using two numerical parameters. It
also has the potential to enable more consistent specification of emotional
non-manual signals in linguistic annotations which drive signing avatars.

</details>


### [103] [Joint Transcription of Acoustic Guitar Strumming Directions and Chords](https://arxiv.org/abs/2508.07973)
*Sebastian Murgul,Johannes Schimper,Michael Heizmann*

Main category: cs.SD

Relevance: 20.0

TL;DR: 该论文提出了一种基于深度学习的吉他扫弦转录方法，结合了真实世界和合成数据集，显著提升了扫弦动作检测和和弦分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 吉他扫弦转录在音乐信息检索中是一个具有挑战性且研究不足的任务，现有方法因数据集有限而效果受限。

Method: 使用ESP32智能手表运动传感器收集90分钟真实吉他录音，并生成4小时合成数据集，训练卷积循环神经网络（CRNN）模型进行扫弦事件检测、方向分类及和弦识别。

Result: 混合使用合成和真实数据的方法在扫弦动作检测与和弦分类上取得了最高准确率，显著优于基线算法。

Conclusion: 深度学习在吉他扫弦转录中具有潜力，为自动节奏吉他分析开辟了新途径。

Abstract: Automatic transcription of guitar strumming is an underrepresented and
challenging task in Music Information Retrieval (MIR), particularly for
extracting both strumming directions and chord progressions from audio signals.
While existing methods show promise, their effectiveness is often hindered by
limited datasets. In this work, we extend a multimodal approach to guitar
strumming transcription by introducing a novel dataset and a deep
learning-based transcription model. We collect 90 min of real-world guitar
recordings using an ESP32 smartwatch motion sensor and a structured recording
protocol, complemented by a synthetic dataset of 4h of labeled strumming audio.
A Convolutional Recurrent Neural Network (CRNN) model is trained to detect
strumming events, classify their direction, and identify the corresponding
chords using only microphone audio. Our evaluation demonstrates significant
improvements over baseline onset detection algorithms, with a hybrid method
combining synthetic and real-world data achieving the highest accuracy for both
strumming action detection and chord classification. These results highlight
the potential of deep learning for robust guitar strumming transcription and
open new avenues for automatic rhythm guitar analysis.

</details>


### [104] [The 2D+ Dynamic Articulatory Model DYNARTmo: Tongue-Palate Contact Area Estimation](https://arxiv.org/abs/2508.07262)
*Bernd J. Kröger*

Main category: cs.CL

Relevance: 10.0

TL;DR: 本文扩展了二维动态发音模型DYNARTmo，通过整合三维腭穹内部表示，从中矢舌轮廓估计舌-腭接触区域。实现了两种穹顶几何形状（半椭圆和基于余弦的轮廓）以模拟冠状面的侧向曲率，并计算侧向接触点，生成类似电腭图的2D+可视化。模型支持三种同步视图（矢状、声门和腭视图），适用于语音科学教育和治疗。未来工作包括添加面部（唇）视图和实现发音-声学合成以评估模型真实性。


<details>
  <summary>Details</summary>
Motivation: 改进发音模型的舌-腭接触区域估计能力，为语音科学和教育提供更直观的工具。

Method: 整合三维腭穹表示，实现两种几何形状（半椭圆和余弦轮廓）计算侧向接触点，支持多视图同步显示。

Result: 增强了模型的舌-腭接触区域估计能力，并提供了多视图动态显示功能。

Conclusion: 扩展的DYNARTmo模型在语音科学和教育中具有应用潜力，未来将进一步优化和扩展功能。

Abstract: This paper describes an extension of the two-dimensional dynamic articulatory
model DYNARTmo by integrating an internal three-dimensional representation of
the palatal dome to estimate tongue-palate contact areas from midsagittal
tongue contours. Two alternative dome geometries - a half-ellipse and a cosine
based profile - are implemented to model lateral curvature in the coronal
plane. Using these geometries, lateral contact points are analytically computed
for each anterior-posterior position, enabling the generation of
electropalatography-like visualizations within the 2D+ framework. The enhanced
model supports three synchronized views (sagittal, glottal, and palatal) for
static and dynamic (animated) articulation displays, suitable for speech
science education and speech therapy. Future work includes adding a facial
(lip) view and implementing articulatory-to-acoustic synthesis to
quantitatively evaluate model realism.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [105] [What Makes "Good" Distractors for Object Hallucination Evaluation in Large Vision-Language Models?](https://arxiv.org/abs/2508.06530)
*Ming-Kun Xie,Jia-Hao Xiao,Gang Niu,Lei Feng,Zhiqiang Kou,Min-Ling Zhang,Masashi Sugiyama*

Main category: cs.CV

Relevance: 85.0

TL;DR: 论文提出了HOPE基准，用于更严格评估大型视觉语言模型（LVLM）的幻觉问题，通过生成误导性干扰项来暴露模型的弱点。


<details>
  <summary>Details</summary>
Motivation: 现有POPE基准在评估LVLM的幻觉问题时效果下降，因其采样策略简单且忽略图像特定信息。

Method: HOPE利用CLIP选择高预测似然的负对象作为干扰项，并通过真实对象与虚假描述配对构建误导性干扰项。

Result: HOPE导致多种LVLM的精度下降9%至23%，显著优于POPE。

Conclusion: HOPE是一种更有效的幻觉评估基准，能更严格测试LVLM的鲁棒性。

Abstract: Large Vision-Language Models (LVLMs), empowered by the success of Large
Language Models (LLMs), have achieved impressive performance across domains.
Despite the great advances in LVLMs, they still suffer from the unavailable
object hallucination issue, which tends to generate objects inconsistent with
the image content. The most commonly used Polling-based Object Probing
Evaluation (POPE) benchmark evaluates this issue by sampling negative
categories according to category-level statistics, \textit{e.g.}, category
frequencies and co-occurrence. However, with the continuous advancement of
LVLMs, the POPE benchmark has shown diminishing effectiveness in assessing
object hallucination, as it employs a simplistic sampling strategy that
overlooks image-specific information and restricts distractors to negative
object categories only. In this paper, we introduce the Hallucination
searching-based Object Probing Evaluation (HOPE) benchmark, aiming to generate
the most misleading distractors (\textit{i.e.}, non-existent objects or
incorrect image descriptions) that can trigger hallucination in LVLMs, which
serves as a means to more rigorously assess their immunity to hallucination. To
explore the image-specific information, the content-aware hallucination
searching leverages Contrastive Language-Image Pre-Training (CLIP) to
approximate the predictive behavior of LVLMs by selecting negative objects with
the highest predicted likelihood as distractors. To expand the scope of
hallucination assessment, the description-based hallucination searching
constructs highly misleading distractors by pairing true objects with false
descriptions. Experimental results show that HOPE leads to a precision drop of
at least 9\% and up to 23\% across various state-of-the-art LVLMs,
significantly outperforming POPE in exposing hallucination vulnerabilities. The
code is available at https://github.com/xiemk/HOPE.

</details>


### [106] [BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models](https://arxiv.org/abs/2508.06895)
*Jianting Tang,Yubo Wang,Haoyu Cao,Linli Xu*

Main category: cs.CV

Relevance: 85.0

TL;DR: 论文提出BASIC方法，通过直接监督视觉嵌入提升多模态大语言模型（MLLMs）性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法仅对文本输出进行自回归监督，忽略了视觉嵌入的直接监督，限制了视觉理解的精细对齐。

Method: 利用LLM浅层中优化的视觉嵌入作为监督，从嵌入方向和语义匹配两个角度直接指导投影器生成初始视觉嵌入。

Result: BASIC显著提升了MLLMs在多个基准测试中的表现。

Conclusion: 直接视觉监督是提升MLLMs性能的有效方法。

Abstract: Mainstream Multimodal Large Language Models (MLLMs) achieve visual
understanding by using a vision projector to bridge well-pretrained vision
encoders and large language models (LLMs). The inherent gap between visual and
textual modalities makes the embeddings from the vision projector critical for
visual comprehension. However, current alignment approaches treat visual
embeddings as contextual cues and merely apply auto-regressive supervision to
textual outputs, neglecting the necessity of introducing equivalent direct
visual supervision, which hinders the potential finer alignment of visual
embeddings. In this paper, based on our analysis of the refinement process of
visual embeddings in the LLM's shallow layers, we propose BASIC, a method that
utilizes refined visual embeddings within the LLM as supervision to directly
guide the projector in generating initial visual embeddings. Specifically, the
guidance is conducted from two perspectives: (i) optimizing embedding
directions by reducing angles between initial and supervisory embeddings in
semantic space; (ii) improving semantic matching by minimizing disparities
between the logit distributions of both visual embeddings. Without additional
supervisory models or artificial annotations, BASIC significantly improves the
performance of MLLMs across a wide range of benchmarks, demonstrating the
effectiveness of our introduced direct visual supervision.

</details>


### [107] [DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding](https://arxiv.org/abs/2508.07313)
*Junyu Xiong,Yonghui Wang,Weichao Zhao,Chenyu Liu,Bing Yin,Wengang Zhou,Houqiang Li*

Main category: cs.CV

Relevance: 85.0

TL;DR: 论文提出DocR1模型，通过强化学习框架EviGRPO提升多页文档理解能力，结合证据感知奖励机制和两阶段标注流程，构建高质量数据集EviBench和ArxivFullQA，实验显示DocR1在多页任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 多页文档理解对多模态大语言模型（MLLMs）具有挑战性，现有强化学习方法在此领域研究不足。

Method: 提出EviGRPO框架，结合证据感知奖励机制和课程学习策略，构建两阶段标注流程和数据集EviBench与ArxivFullQA。

Result: DocR1在多页任务中达到SOTA性能，同时在单页任务中表现稳定。

Conclusion: EviGRPO框架有效提升多页文档理解能力，DocR1模型性能优越。

Abstract: Understanding multi-page documents poses a significant challenge for
multimodal large language models (MLLMs), as it requires fine-grained visual
comprehension and multi-hop reasoning across pages. While prior work has
explored reinforcement learning (RL) for enhancing advanced reasoning in MLLMs,
its application to multi-page document understanding remains underexplored. In
this paper, we introduce DocR1, an MLLM trained with a novel RL framework,
Evidence Page-Guided GRPO (EviGRPO). EviGRPO incorporates an evidence-aware
reward mechanism that promotes a coarse-to-fine reasoning strategy, guiding the
model to first retrieve relevant pages before generating answers. This training
paradigm enables us to build high-quality models with limited supervision. To
support this, we design a two-stage annotation pipeline and a curriculum
learning strategy, based on which we construct two datasets: EviBench, a
high-quality training set with 4.8k examples, and ArxivFullQA, an evaluation
benchmark with 8.6k QA pairs based on scientific papers. Extensive experiments
across a wide range of benchmarks demonstrate that DocR1 achieves
state-of-the-art performance on multi-page tasks, while consistently
maintaining strong results on single-page benchmarks.

</details>


### [108] [Towards Robust Red-Green Watermarking for Autoregressive Image Generators](https://arxiv.org/abs/2508.06656)
*Denis Lukovnikov,Andreas Müller,Erwin Quiring,Asja Fischer*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文探讨了在自回归图像模型中应用生成内水印的方法，提出了两种基于视觉令牌聚类的新水印方案，提高了抗干扰性和检测能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于填补自回归图像模型中生成内水印的研究空白，并解决现有水印方法在图像扰动下检测能力下降的问题。

Method: 方法包括两种基于视觉令牌聚类的水印方案：一种是无训练方法，依赖聚类查找表；另一种是微调VAE编码器直接从扰动图像预测令牌聚类。

Result: 实验表明，聚类级水印显著提高了抗干扰性和再生攻击的鲁棒性，同时保持图像质量，检测能力优于基线方法。

Conclusion: 结论是提出的聚类级水印方法在自回归图像模型中有效，兼具快速验证和鲁棒性。

Abstract: In-generation watermarking for detecting and attributing generated content
has recently been explored for latent diffusion models (LDMs), demonstrating
high robustness. However, the use of in-generation watermarks in autoregressive
(AR) image models has not been explored yet. AR models generate images by
autoregressively predicting a sequence of visual tokens that are then decoded
into pixels using a vector-quantized decoder. Inspired by red-green watermarks
for large language models, we examine token-level watermarking schemes that
bias the next-token prediction based on prior tokens. We find that a direct
transfer of these schemes works in principle, but the detectability of the
watermarks decreases considerably under common image perturbations. As a
remedy, we propose two novel watermarking methods that rely on visual token
clustering to assign similar tokens to the same set. Firstly, we investigate a
training-free approach that relies on a cluster lookup table, and secondly, we
finetune VAE encoders to predict token clusters directly from perturbed images.
Overall, our experiments show that cluster-level watermarks improve robustness
against perturbations and regeneration attacks while preserving image quality.
Cluster classification further boosts watermark detectability, outperforming a
set of baselines. Moreover, our methods offer fast verification runtime,
comparable to lightweight post-hoc watermarking methods.

</details>


### [109] [VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding](https://arxiv.org/abs/2508.06869)
*Jianxiang He,Shaoguang Wang,Weiyu Guo,Meisheng Hong,Jungang Li,Yijie Xu,Ziyang Chen,Hui Xiong*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文提出了一种多模态关键帧搜索方法VSI，通过结合字幕和时间戳提升长视频理解任务中的关键帧定位精度。


<details>
  <summary>Details</summary>
Motivation: 解决长视频理解中多模态对齐不足和复杂时间语义信息捕捉的问题。

Method: 提出Visual-Subtitle Integration (VSI)，通过双流机制（视频搜索流和字幕匹配流）整合视觉和文本信息。

Result: 在LongVideoBench上关键帧定位准确率达40.00%，视频问答任务准确率达68.48%，显著超越基线。

Conclusion: VSI在长视频理解任务中表现出鲁棒性和泛化能力，达到SOTA水平。

Abstract: Long video understanding presents a significant challenge to multimodal large
language models (MLLMs) primarily due to the immense data scale. A critical and
widely adopted strategy for making this task computationally tractable is
keyframe retrieval, which seeks to identify a sparse set of video frames that
are most salient to a given textual query. However, the efficacy of this
approach is hindered by weak multimodal alignment between textual queries and
visual content and fails to capture the complex temporal semantic information
required for precise reasoning. To address this, we propose Visual-Subtitle
Integeration(VSI), a multimodal keyframe search method that integrates
subtitles, timestamps, and scene boundaries into a unified multimodal search
process. The proposed method captures the visual information of video frames as
well as the complementary textual information through a dual-stream search
mechanism by Video Search Stream as well as Subtitle Match Stream,
respectively, and improves the keyframe search accuracy through the interaction
of the two search streams. Experimental results show that VSI achieve 40.00%
key frame localization accuracy on the text-relevant subset of LongVideoBench
and 68.48% accuracy on downstream long Video-QA tasks, surpassing competitive
baselines by 20.35% and 15.79%, respectively. Furthermore, on the
LongVideoBench, VSI achieved state-of-the-art(SOTA) in medium-to-long video-QA
tasks, demonstrating the robustness and generalizability of the proposed
multimodal search strategy.

</details>


### [110] [MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark](https://arxiv.org/abs/2508.07307)
*Haiyang Guo,Fei Zhu,Hongbo Zhao,Fanhu Zeng,Wenzhuo Liu,Shijie Ma,Da-Han Wang,Xu-Yao Zhang*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文介绍了MCITlib，一个用于多模态大语言模型持续指令调优的代码库，包含8种算法并在2个基准上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 多模态持续学习任务的需求增加，传统方法难以应对跨模态交互和协调的挑战。

Method: 开发了MCITlib代码库，实现了8种多模态持续指令调优算法，并在2个基准上评估。

Result: MCITlib为多模态持续学习研究提供了工具支持，代码开源。

Conclusion: MCITlib将持续更新以反映领域进展，推动多模态持续学习研究。

Abstract: Continual learning aims to equip AI systems with the ability to continuously
acquire and adapt to new knowledge without forgetting previously learned
information, similar to human learning. While traditional continual learning
methods focusing on unimodal tasks have achieved notable success, the emergence
of Multimodal Large Language Models has brought increasing attention to
Multimodal Continual Learning tasks involving multiple modalities, such as
vision and language. In this setting, models are expected to not only mitigate
catastrophic forgetting but also handle the challenges posed by cross-modal
interactions and coordination. To facilitate research in this direction, we
introduce MCITlib, a comprehensive and constantly evolving code library for
continual instruction tuning of Multimodal Large Language Models. In MCITlib,
we have currently implemented 8 representative algorithms for Multimodal
Continual Instruction Tuning and systematically evaluated them on 2 carefully
selected benchmarks. MCITlib will be continuously updated to reflect advances
in the Multimodal Continual Learning field. The codebase is released at
https://github.com/Ghy0501/MCITlib.

</details>


### [111] [ForensicsSAM: Toward Robust and Unified Image Forgery Detection and Localization Resisting to Adversarial Attack](https://arxiv.org/abs/2508.07402)
*Rongxuan Peng,Shunquan Tan,Chenqi Kong,Anwei Luo,Alex C. Kot,Jiwu Huang*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文提出ForensicsSAM，一种针对图像伪造检测与定位（IFDL）的统一框架，具有内置的对抗鲁棒性，解决了现有参数高效微调（PEFT）方法在对抗攻击下的脆弱性问题。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法在对抗攻击下表现脆弱，论文旨在提升IFDL任务中的对抗鲁棒性。

Method: 1) 注入伪造专家增强图像编码器；2) 设计轻量级对抗检测器；3) 注入对抗专家修正特征偏移。

Result: ForensicsSAM在多个基准测试中表现出卓越的对抗攻击抵抗能力，并在IFDL任务中达到SOTA性能。

Conclusion: ForensicsSAM通过多专家注入和自适应机制，显著提升了IFDL任务的对抗鲁棒性和性能。

Abstract: Parameter-efficient fine-tuning (PEFT) has emerged as a popular strategy for
adapting large vision foundation models, such as the Segment Anything Model
(SAM) and LLaVA, to downstream tasks like image forgery detection and
localization (IFDL). However, existing PEFT-based approaches overlook their
vulnerability to adversarial attacks. In this paper, we show that highly
transferable adversarial images can be crafted solely via the upstream model,
without accessing the downstream model or training data, significantly
degrading the IFDL performance. To address this, we propose ForensicsSAM, a
unified IFDL framework with built-in adversarial robustness. Our design is
guided by three key ideas: (1) To compensate for the lack of forgery-relevant
knowledge in the frozen image encoder, we inject forgery experts into each
transformer block to enhance its ability to capture forgery artifacts. These
forgery experts are always activated and shared across any input images. (2) To
detect adversarial images, we design an light-weight adversary detector that
learns to capture structured, task-specific artifact in RGB domain, enabling
reliable discrimination across various attack methods. (3) To resist
adversarial attacks, we inject adversary experts into the global attention
layers and MLP modules to progressively correct feature shifts induced by
adversarial noise. These adversary experts are adaptively activated by the
adversary detector, thereby avoiding unnecessary interference with clean
images. Extensive experiments across multiple benchmarks demonstrate that
ForensicsSAM achieves superior resistance to various adversarial attack
methods, while also delivering state-of-the-art performance in image-level
forgery detection and pixel-level forgery localization. The resource is
available at https://github.com/siriusPRX/ForensicsSAM.

</details>


### [112] [Freeze and Reveal: Exposing Modality Bias in Vision-Language Models](https://arxiv.org/abs/2508.07432)
*Vivek Hruday Kavuri,Vysishtya Karanam,Venkata Jahnavi Venkamsetty,Kriti Madumadukala,Lakshmipathi Balaji Darur,Ponnurangam Kumaraguru*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文提出了一种针对视觉语言模型中性别偏见的新度量方法（DAUDoS）和去偏方法，通过实验发现视觉和文本编码器对偏见的贡献不同，并验证了去偏方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在训练数据中继承的性别偏见可能来自视觉和文本模态，需要针对性去偏方法。

Method: 采用反事实数据增强（CDA）和任务向量方法，并引入新度量（Degree of Stereotypicality）及去偏方法（DAUDoS）。

Result: CDA减少性别差距6%，DAUDoS减少3%且仅需三分之一数据；两种方法均提升性别识别准确率3%。

Conclusion: 视觉编码器（如CLIP）和文本编码器（如PaliGemma2）对偏见的贡献不同，未来可针对性优化。

Abstract: Vision Language Models achieve impressive multi-modal performance but often
inherit gender biases from their training data. This bias might be coming from
both the vision and text modalities. In this work, we dissect the contributions
of vision and text backbones to these biases by applying targeted debiasing
using Counterfactual Data Augmentation and Task Vector methods. Inspired by
data-efficient approaches in hate-speech classification, we introduce a novel
metric, Degree of Stereotypicality and a corresponding debiasing method, Data
Augmentation Using Degree of Stereotypicality - DAUDoS, to reduce bias with
minimal computational cost. We curate a gender annotated dataset and evaluate
all methods on VisoGender benchmark to quantify improvements and identify
dominant source of bias. Our results show that CDA reduces the gender gap by 6%
and DAUDoS by 3% but using only one-third of the data. Both methods also
improve the model's ability to correctly identify gender in images by 3%, with
DAUDoS achieving this improvement using only almost one-third of training data.
From our experiment's, we observed that CLIP's vision encoder is more biased
whereas PaliGemma2's text encoder is more biased. By identifying whether bias
stems more from vision or text encoders, our work enables more targeted and
effective bias mitigation strategies in future multi-modal systems.

</details>


### [113] [Exploring Multimodal Diffusion Transformers for Enhanced Prompt-based Image Editing](https://arxiv.org/abs/2508.07519)
*Joonghyuk Shin,Alchan Hwang,Yujin Kim,Daneul Kim,Jaesik Park*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文分析了基于Transformer的多模态扩散模型（MM-DiT）的注意力机制，提出了一种新的图像编辑方法。


<details>
  <summary>Details</summary>
Motivation: 传统U-Net架构被Transformer取代后，MM-DiT成为主流，但其双向注意力机制对现有编辑技术提出了挑战。

Method: 通过分解注意力矩阵为四个块，分析其特性，并提出一种基于提示的图像编辑方法。

Result: 提出了一种支持全局到局部编辑的鲁棒方法，适用于多种MM-DiT变体。

Conclusion: 研究填补了U-Net与新兴架构之间的差距，提供了对MM-DiT行为模式的深入理解。

Abstract: Transformer-based diffusion models have recently superseded traditional U-Net
architectures, with multimodal diffusion transformers (MM-DiT) emerging as the
dominant approach in state-of-the-art models like Stable Diffusion 3 and
Flux.1. Previous approaches have relied on unidirectional cross-attention
mechanisms, with information flowing from text embeddings to image latents. In
contrast, MMDiT introduces a unified attention mechanism that concatenates
input projections from both modalities and performs a single full attention
operation, allowing bidirectional information flow between text and image
branches. This architectural shift presents significant challenges for existing
editing techniques. In this paper, we systematically analyze MM-DiT's attention
mechanism by decomposing attention matrices into four distinct blocks,
revealing their inherent characteristics. Through these analyses, we propose a
robust, prompt-based image editing method for MM-DiT that supports global to
local edits across various MM-DiT variants, including few-step models. We
believe our findings bridge the gap between existing U-Net-based methods and
emerging architectures, offering deeper insights into MMDiT's behavioral
patterns.

</details>


### [114] [TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning](https://arxiv.org/abs/2508.08098)
*Junzhe Xu,Yuyang Yin,Xi Chen*

Main category: cs.CV

Relevance: 75.0

TL;DR: TBAC-UniImage提出了一种新型多模态统一模型，通过深度集成预训练的扩散模型和多模态大语言模型（MLLM），解决了现有方法中生成条件浅层连接或计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散统一模型要么仅利用MLLM的最终隐藏状态作为生成条件（连接浅层），要么从头预训练统一架构（计算成本高），限制了性能与可扩展性。

Method: 利用MLLM多层多样化的表示作为扩散模型的生成条件，将预训练生成器视为“梯子”，接收MLLM不同深度的理解指导。

Result: TBAC-UniImage实现了更深层次、更细粒度的理解与生成统一。

Conclusion: 该方法为多模态统一模型提供了一种高效且性能优越的新范式。

Abstract: This paper introduces TBAC-UniImage, a novel unified model for multimodal
understanding and generation. We achieve this by deeply integrating a
pre-trained Diffusion Model, acting as a generative ladder, with a Multimodal
Large Language Model (MLLM). Previous diffusion-based unified models face two
primary limitations. One approach uses only the MLLM's final hidden state as
the generative condition. This creates a shallow connection, as the generator
is isolated from the rich, hierarchical representations within the MLLM's
intermediate layers. The other approach, pretraining a unified generative
architecture from scratch, is computationally expensive and prohibitive for
many researchers. To overcome these issues, our work explores a new paradigm.
Instead of relying on a single output, we use representations from multiple,
diverse layers of the MLLM as generative conditions for the diffusion model.
This method treats the pre-trained generator as a ladder, receiving guidance
from various depths of the MLLM's understanding process. Consequently,
TBAC-UniImage achieves a much deeper and more fine-grained unification of
understanding and generation.

</details>


### [115] [Large Language Models Facilitate Vision Reflection in Image Classification](https://arxiv.org/abs/2508.06525)
*Guoyuan An,JaeYoon Kim,SungEui Yoon*

Main category: cs.CV

Relevance: 70.0

TL;DR: 本文研究了多模态大模型（LMMs）中视觉反射的可解释性，发现通过提示LMM验证专用视觉模型的预测可提高识别准确性，并揭示了视觉语言连接器将视觉特征映射为显式文本概念的机制。


<details>
  <summary>Details</summary>
Motivation: 探索LMMs在视觉任务中的表现及其内部机制，以提高其可解释性和性能。

Method: 通过实验分析LMMs的视觉反射行为，包括验证预测、分析内部机制和测试训练无关的连接器效果。

Result: 发现LMMs依赖紧凑的文本表示而非原始视觉特征，且训练无关的连接器可提升细粒度识别任务性能。

Conclusion: 视觉反射是提升LMMs鲁棒性和可解释性的有效策略。

Abstract: This paper presents several novel findings on the explainability of vision
reflection in large multimodal models (LMMs). First, we show that prompting an
LMM to verify the prediction of a specialized vision model can improve
recognition accuracy, even on benchmarks like ImageNet, despite prior evidence
that LMMs typically underperform dedicated vision encoders. Second, we analyze
the internal behavior of vision reflection and find that the vision-language
connector maps visual features into explicit textual concepts, allowing the
language model to reason about prediction plausibility using commonsense
knowledge. We further observe that replacing a large number of vision tokens
with only a few text tokens still enables LLaVA to generate similar answers,
suggesting that LMMs may rely primarily on a compact set of distilled textual
representations rather than raw vision features. Third, we show that a
training-free connector can enhance LMM performance in fine-grained recognition
tasks, without extensive feature-alignment training. Together, these findings
offer new insights into the explainability of vision-language models and
suggest that vision reflection is a promising strategy for achieving robust and
interpretable visual recognition.

</details>


### [116] [SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding](https://arxiv.org/abs/2508.06763)
*Zihao Sheng,Zilin Huang,Yen-Jung Chen,Yansong Qu,Yuhao Luo,Yue Leng,Sikai Chen*

Main category: cs.CV

Relevance: 70.0

TL;DR: SafePLUG是一个多模态大语言模型框架，专注于交通事故的细粒度视觉和时序理解，支持像素级分割和区域感知问答。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在交通事故理解中缺乏对细粒度视觉细节和时序事件的处理能力，限制了其应用。

Method: 提出SafePLUG框架，结合像素级理解和时序定位，并构建包含多模态问答对的新数据集。

Result: SafePLUG在区域问答、像素分割、时序事件定位等任务中表现优异。

Conclusion: SafePLUG为复杂交通场景的细粒度理解奠定基础，有望提升智能交通系统的安全性。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress
across a range of vision-language tasks and demonstrate strong potential for
traffic accident understanding. However, existing MLLMs in this domain
primarily focus on coarse-grained image-level or video-level comprehension and
often struggle to handle fine-grained visual details or localized scene
components, limiting their applicability in complex accident scenarios. To
address these limitations, we propose SafePLUG, a novel framework that empowers
MLLMs with both Pixel-Level Understanding and temporal Grounding for
comprehensive traffic accident analysis. SafePLUG supports both
arbitrary-shaped visual prompts for region-aware question answering and
pixel-level segmentation based on language instructions, while also enabling
the recognition of temporally anchored events in traffic accident scenarios. To
advance the development of MLLMs for traffic accident understanding, we curate
a new dataset containing multimodal question-answer pairs centered on diverse
accident scenarios, with detailed pixel-level annotations and temporal event
boundaries. Experimental results show that SafePLUG achieves strong performance
on multiple tasks, including region-based question answering, pixel-level
segmentation, temporal event localization, and accident event understanding.
These capabilities lay a foundation for fine-grained understanding of complex
traffic scenes, with the potential to improve driving safety and enhance
situational awareness in smart transportation systems. The code, dataset, and
model checkpoints will be made publicly available at:
https://zihaosheng.github.io/SafePLUG

</details>


### [117] [AR-GRPO: Training Autoregressive Image Generation Models via Reinforcement Learning](https://arxiv.org/abs/2508.06924)
*Shihao Yuan,Yahui Liu,Yang Yue,Jingyuan Zhang,Wangmeng Zuo,Qi Wang,Fuzheng Zhang,Guorui Zhou*

Main category: cs.CV

Relevance: 70.0

TL;DR: 论文提出AR-GRPO方法，将在线强化学习（RL）整合到自回归（AR）图像生成模型中，通过精心设计的奖励函数提升生成图像的质量。


<details>
  <summary>Details</summary>
Motivation: 受RL在优化大语言模型（LLMs）中的成功启发，作者探索了RL在AR图像生成模型中的应用潜力。

Method: 采用Group Relative Policy Optimization（GRPO）算法，设计多维度奖励函数（如感知质量、真实性和语义保真度）优化AR模型输出。

Result: 在类条件和文本条件图像生成任务中，RL增强的框架显著提升了图像质量和人类偏好，优于标准AR基线。

Conclusion: RL优化为AR图像生成提供了新途径，支持可控和高质量的图像合成。

Abstract: Inspired by the success of reinforcement learning (RL) in refining large
language models (LLMs), we propose AR-GRPO, an approach to integrate online RL
training into autoregressive (AR) image generation models. We adapt the Group
Relative Policy Optimization (GRPO) algorithm to refine the vanilla
autoregressive models' outputs by carefully designed reward functions that
evaluate generated images across multiple quality dimensions, including
perceptual quality, realism, and semantic fidelity. We conduct comprehensive
experiments on both class-conditional (i.e., class-to-image) and
text-conditional (i.e., text-to-image) image generation tasks, demonstrating
that our RL-enhanced framework significantly improves both the image quality
and human preference of generated images compared to the standard AR baselines.
Our results show consistent improvements across various evaluation metrics,
establishing the viability of RL-based optimization for AR image generation and
opening new avenues for controllable and high-quality image synthesis. The
source codes and models are available at:
https://github.com/Kwai-Klear/AR-GRPO.

</details>


### [118] [Representation Understanding via Activation Maximization](https://arxiv.org/abs/2508.07281)
*Hongbo Zhu,Angelo Cangelosi*

Main category: cs.CV

Relevance: 70.0

TL;DR: 提出了一种统一的特征可视化框架，适用于CNN和ViT，扩展了中间层的可视化，并探讨了AM在生成对抗样本中的应用。


<details>
  <summary>Details</summary>
Motivation: 理解DNN的内部特征表示是模型可解释性的关键步骤，现有方法主要关注CNN的输出层神经元，缺乏对中间层和ViT的研究。

Method: 采用激活最大化（AM）方法，扩展特征可视化至中间层，并研究其在生成对抗样本中的应用。

Result: 实验证明该方法在CNN和ViT中均有效，揭示了模型的潜在脆弱性和决策边界。

Conclusion: 该框架具有通用性和解释价值，为模型可解释性和安全性研究提供了新视角。

Abstract: Understanding internal feature representations of deep neural networks (DNNs)
is a fundamental step toward model interpretability. Inspired by neuroscience
methods that probe biological neurons using visual stimuli, recent deep
learning studies have employed Activation Maximization (AM) to synthesize
inputs that elicit strong responses from artificial neurons. In this work, we
propose a unified feature visualization framework applicable to both
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). Unlike
prior efforts that predominantly focus on the last output-layer neurons in
CNNs, we extend feature visualization to intermediate layers as well, offering
deeper insights into the hierarchical structure of learned feature
representations. Furthermore, we investigate how activation maximization can be
leveraged to generate adversarial examples, revealing potential vulnerabilities
and decision boundaries of DNNs. Our experiments demonstrate the effectiveness
of our approach in both traditional CNNs and modern ViT, highlighting its
generalizability and interpretive value.

</details>


### [119] [CoAR: Concept Injection into Autoregressive Models for Personalized Text-to-Image Generation](https://arxiv.org/abs/2508.07341)
*Fangtai Wu,Mushui Liu,Weijie He,Wanggui He,Hao Jiang,Zhao Wang,Yunlong Yu*

Main category: cs.CV

Relevance: 70.0

TL;DR: CoAR是一种新颖的框架，通过冻结预训练参数，仅调整极少量参数（<0.05%），实现定制化图像生成，解决了现有方法的过拟合和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有定制化生成方法依赖全微调或适配器，成本高且易过拟合或遗忘。CoAR旨在以高效方式注入主题概念。

Method: 采用分层多模态上下文学习策略，学习特定主题表示，并引入正则化防止语言漂移和过拟合。

Result: CoAR在主题和风格个性化任务中表现优异，计算和内存效率显著提升。

Conclusion: CoAR通过极少量参数调整，实现了高效且高质量的定制化生成。

Abstract: The unified autoregressive (AR) model excels at multimodal understanding and
generation, but its potential for customized image generation remains
underexplored. Existing customized generation methods rely on full fine-tuning
or adapters, making them costly and prone to overfitting or catastrophic
forgetting. In this paper, we propose \textbf{CoAR}, a novel framework for
injecting subject concepts into the unified AR models while keeping all
pre-trained parameters completely frozen. CoAR learns effective, specific
subject representations with only a minimal number of parameters using a
Layerwise Multimodal Context Learning strategy. To address overfitting and
language drift, we further introduce regularization that preserves the
pre-trained distribution and anchors context tokens to improve subject fidelity
and re-contextualization. Additionally, CoAR supports training-free subject
customization in a user-provided style. Experiments demonstrate that CoAR
achieves superior performance on both subject-driven personalization and style
personalization, while delivering significant gains in computational and memory
efficiency. Notably, CoAR tunes less than \textbf{0.05\%} of the parameters
while achieving competitive performance compared to recent Proxy-Tuning. Code:
https://github.com/KZF-kzf/CoAR

</details>


### [120] [LET-US: Long Event-Text Understanding of Scenes](https://arxiv.org/abs/2508.07401)
*Rui Chen,Xingyu Chen,Shaoan Wang,Shihan Kong,Junzhi Yu*

Main category: cs.CV

Relevance: 70.0

TL;DR: LET-US是一个用于长事件流-文本理解的框架，通过自适应压缩机制减少输入事件量，同时保留关键视觉细节，实现了跨模态推理的新突破。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在RGB视频内容理解上成功，但对事件流的解释能力有限或仅适用于短序列。LET-US旨在填补这一空白。

Method: 采用两阶段优化范式，结合文本引导的跨模态查询、分层聚类和相似性计算，以及大规模事件-文本对齐数据集训练。

Result: 实验表明，LET-US在长事件流的描述准确性和语义理解上优于现有MLLMs。

Conclusion: LET-US为长事件流与文本的跨模态理解设定了新标准，提供了全面的基准测试和公开资源。

Abstract: Event cameras output event streams as sparse, asynchronous data with
microsecond-level temporal resolution, enabling visual perception with low
latency and a high dynamic range. While existing Multimodal Large Language
Models (MLLMs) have achieved significant success in understanding and analyzing
RGB video content, they either fail to interpret event streams effectively or
remain constrained to very short sequences. In this paper, we introduce LET-US,
a framework for long event-stream--text comprehension that employs an adaptive
compression mechanism to reduce the volume of input events while preserving
critical visual details. LET-US thus establishes a new frontier in cross-modal
inferential understanding over extended event sequences. To bridge the
substantial modality gap between event streams and textual representations, we
adopt a two-stage optimization paradigm that progressively equips our model
with the capacity to interpret event-based scenes. To handle the voluminous
temporal information inherent in long event streams, we leverage text-guided
cross-modal queries for feature reduction, augmented by hierarchical clustering
and similarity computation to distill the most representative event features.
Moreover, we curate and construct a large-scale event-text aligned dataset to
train our model, achieving tighter alignment of event features within the LLM
embedding space. We also develop a comprehensive benchmark covering a diverse
set of tasks -- reasoning, captioning, classification, temporal localization
and moment retrieval. Experimental results demonstrate that LET-US outperforms
prior state-of-the-art MLLMs in both descriptive accuracy and semantic
comprehension on long-duration event streams. All datasets, codes, and models
will be publicly available.

</details>


### [121] [Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification](https://arxiv.org/abs/2508.07577)
*Zhaorui Tan,Tan Pan,Kaizhu Huang,Weimiao Yu,Kai Yao,Chen Jiang,Qiufeng Wang,Anh Nguyen,Xin Guo,Yuan Cheng,Xi Yang*

Main category: cs.CV

Relevance: 70.0

TL;DR: 本文研究了LayerNorm在Vision Transformers（ViTs）中的微调动态，特别是在数据稀缺和领域转移的情况下。提出了Fine-tuning Shift Ratio（FSR）和一种简单的重新缩放机制，通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索LayerNorm在ViTs中的微调动态，尤其是在数据稀缺和领域转移下的表现，填补了这一领域的空白。

Method: 提出了FSR量化目标训练样本的代表性，并设计了一个基于标量λ的重新缩放机制和一个循环框架来优化LayerNorm微调。

Result: 实验表明，OOD任务通常具有较低的FSR和较高的λ，而病理数据微调更接近ID设置。提出的方法在多种设置下均有效。

Conclusion: 揭示了LayerNorm在迁移学习中的动态特性，并提供了实用的微调策略。

Abstract: LayerNorm is pivotal in Vision Transformers (ViTs), yet its fine-tuning
dynamics under data scarcity and domain shifts remain underexplored. This paper
shows that shifts in LayerNorm parameters after fine-tuning (LayerNorm shifts)
are indicative of the transitions between source and target domains; its
efficacy is contingent upon the degree to which the target training samples
accurately represent the target domain, as quantified by our proposed
Fine-tuning Shift Ratio ($FSR$). Building on this, we propose a simple yet
effective rescaling mechanism using a scalar $\lambda$ that is negatively
correlated to $FSR$ to align learned LayerNorm shifts with those ideal shifts
achieved under fully representative data, combined with a cyclic framework that
further enhances the LayerNorm fine-tuning. Extensive experiments across
natural and pathological images, in both in-distribution (ID) and
out-of-distribution (OOD) settings, and various target training sample regimes
validate our framework. Notably, OOD tasks tend to yield lower $FSR$ and higher
$\lambda$ in comparison to ID cases, especially with scarce data, indicating
under-represented target training samples. Moreover, ViTFs fine-tuned on
pathological data behave more like ID settings, favoring conservative LayerNorm
updates. Our findings illuminate the underexplored dynamics of LayerNorm in
transfer learning and provide practical strategies for LayerNorm fine-tuning.

</details>


### [122] [Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP](https://arxiv.org/abs/2508.07819)
*Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Yueyi Luo*

Main category: cs.CV

Relevance: 70.0

TL;DR: 论文提出了一种架构协同设计框架，通过Conv-LoRA适配器和动态融合网关（DFG）解决视觉语言模型在零样本异常检测中的适应性问题。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉语言模型在零样本异常检测中存在适应性问题，主要源于缺乏局部归纳偏置和特征融合的灵活性不足。

Method: 结合参数高效的Conv-LoRA适配器注入局部归纳偏置，并引入DFG动态调整文本提示以实现双向融合。

Result: 在工业和医学基准测试中表现出更高的准确性和鲁棒性。

Conclusion: 协同设计框架是适应密集感知任务的关键。

Abstract: Pre-trained Vision-Language Models (VLMs) face a significant adaptation gap
when applied to Zero-Shot Anomaly Detection (ZSAD), stemming from their lack of
local inductive biases for dense prediction and their reliance on inflexible
feature fusion paradigms. We address these limitations through an Architectural
Co-Design framework that jointly refines feature representation and cross-modal
fusion. Our method integrates a parameter-efficient Convolutional Low-Rank
Adaptation (Conv-LoRA) adapter to inject local inductive biases for
fine-grained representation, and introduces a Dynamic Fusion Gateway (DFG) that
leverages visual context to adaptively modulate text prompts, enabling a
powerful bidirectional fusion. Extensive experiments on diverse industrial and
medical benchmarks demonstrate superior accuracy and robustness, validating
that this synergistic co-design is critical for robustly adapting foundation
models to dense perception tasks.

</details>


### [123] [MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization](https://arxiv.org/abs/2508.07833)
*Animesh Jain,Alexandros Stergiou*

Main category: cs.CV

Relevance: 70.0

TL;DR: 提出了一种名为MIMIC的多模态反演框架，用于可视化视觉语言模型（VLM）的内部表示，以增强透明度和信任。


<details>
  <summary>Details</summary>
Motivation: 由于VLM的多模态输入编码复杂且难以解释，限制了模型的透明度和信任，因此需要一种方法来可视化其内部表示。

Method: MIMIC框架结合了基于VLM的反演和特征对齐目标，并引入了三种正则化器（空间对齐、自然图像平滑性和语义真实性）。

Result: 通过定量和定性评估，MIMIC成功反演了不同长度自由文本的视觉概念，并报告了视觉质量和语义文本指标。

Conclusion: MIMIC是首个针对VLM视觉概念解释的模型反演方法，为模型透明性提供了新工具。

Abstract: Vision Language Models (VLMs) encode multimodal inputs over large, complex,
and difficult-to-interpret architectures, which limit transparency and trust.
We propose a Multimodal Inversion for Model Interpretation and
Conceptualization (MIMIC) framework to visualize the internal representations
of VLMs by synthesizing visual concepts corresponding to internal encodings.
MIMIC uses a joint VLM-based inversion and a feature alignment objective to
account for VLM's autoregressive processing. It additionally includes a triplet
of regularizers for spatial alignment, natural image smoothness, and semantic
realism. We quantitatively and qualitatively evaluate MIMIC by inverting visual
concepts over a range of varying-length free-form VLM output texts. Reported
results include both standard visual quality metrics as well as semantic
text-based metrics. To the best of our knowledge, this is the first model
inversion approach addressing visual interpretations of VLM concepts.

</details>


### [124] [CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning](https://arxiv.org/abs/2508.07871)
*Yanshu Li,Jianjiang Yang,Zhennan Shen,Ligong Han,Haoyan Xu,Ruixiang Tang*

Main category: cs.CV

Relevance: 70.0

TL;DR: 论文提出了一种针对多模态上下文学习（ICL）的图像令牌剪枝方法CATP，解决了现有方法在ICL中性能下降的问题，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像令牌剪枝方法主要针对单图像任务，忽视了多模态ICL中更大的冗余和效率需求，导致性能不稳定。

Method: 提出CATP，一种无需训练的两阶段渐进式剪枝方法，充分考虑了输入序列中的跨模态交互。

Result: 剪除77.8%的图像令牌后，CATP在四个LVLM和八个基准测试中平均性能提升0.6%，推理延迟降低10.78%。

Conclusion: CATP提升了多模态ICL的实用价值，为未来图像-文本交互场景的研究奠定了基础。

Abstract: Modern large vision-language models (LVLMs) convert each input image into a
large set of tokens, far outnumbering the text tokens. Although this improves
visual perception, it introduces severe image token redundancy. Because image
tokens carry sparse information, many add little to reasoning, yet greatly
increase inference cost. The emerging image token pruning methods tackle this
issue by identifying the most important tokens and discarding the rest. These
methods can raise efficiency with only modest performance loss. However, most
of them only consider single-image tasks and overlook multimodal in-context
learning (ICL), where redundancy is greater and efficiency is more critical.
Redundant tokens weaken the advantage of multimodal ICL for rapid domain
adaptation and cause unstable performance. Applying existing pruning methods in
this setting leads to large accuracy drops, exposing a clear gap and the need
for new techniques. Thus, we propose Contextually Adaptive Token Pruning
(CATP), a training-free pruning method targeted at multimodal ICL. CATP
consists of two stages that perform progressive pruning to fully account for
the complex cross-modal interactions in the input sequence. After removing
77.8\% of the image tokens, CATP produces an average performance gain of 0.6\%
over the vanilla model on four LVLMs and eight benchmarks, exceeding all
baselines remarkably. Meanwhile, it effectively improves efficiency by
achieving an average reduction of 10.78\% in inference latency. CATP enhances
the practical value of multimodal ICL and lays the groundwork for future
progress in interleaved image-text scenarios.

</details>


### [125] [The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility](https://arxiv.org/abs/2508.07989)
*Xiantao Zhang*

Main category: cs.CV

Relevance: 70.0

TL;DR: 论文指出多模态大语言模型（MLLMs）在感知连续运动（如电梯方向）方面存在缺陷，称为“隐式运动盲区”，并呼吁从语义识别转向物理感知，开发更安全的基准。


<details>
  <summary>Details</summary>
Motivation: 研究MLLMs在盲人和视障群体中的应用时，发现其在感知连续运动（如电梯方向）上的缺陷，影响实际应用的可信度。

Method: 通过分析现有视频理解框架（基于帧采样）的局限性，提出“隐式运动盲区”概念，并探讨其对用户信任的影响。

Result: 发现MLLMs在低信号连续运动感知上的不足，可能导致安全问题。

Conclusion: 呼吁范式转变，从语义识别转向物理感知，开发更注重安全和用户需求的新基准。

Abstract: Multimodal Large Language Models (MLLMs) hold immense promise as assistive
technologies for the blind and visually impaired (BVI) community. However, we
identify a critical failure mode that undermines their trustworthiness in
real-world applications. We introduce the Escalator Problem -- the inability of
state-of-the-art models to perceive an escalator's direction of travel -- as a
canonical example of a deeper limitation we term Implicit Motion Blindness.
This blindness stems from the dominant frame-sampling paradigm in video
understanding, which, by treating videos as discrete sequences of static
images, fundamentally struggles to perceive continuous, low-signal motion. As a
position paper, our contribution is not a new model but rather to: (I) formally
articulate this blind spot, (II) analyze its implications for user trust, and
(III) issue a call to action. We advocate for a paradigm shift from purely
semantic recognition towards robust physical perception and urge the
development of new, human-centered benchmarks that prioritize safety,
reliability, and the genuine needs of users in dynamic environments.

</details>


### [126] [MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision](https://arxiv.org/abs/2508.08177)
*Zhonghao Yan,Muxi Diao,Yuxuan Yang,Jiayuan Xu,Kaizhou Zhang,Ruoyan Jing,Lele Yang,Yanxi Liu,Kongming Liang,Zhanyu Ma*

Main category: cs.CV

Relevance: 70.0

TL;DR: 论文提出了一种新的医学视觉语言任务UMRG，并发布了数据集U-MRG-14K，同时提出了MedReasoner框架，通过强化学习优化MLLM，实现了医学图像的高效定位。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像中基于临床推理的隐式查询定位问题，当前方法依赖显式空间提示，无法满足实际需求。

Method: 1. 定义UMRG任务；2. 发布U-MRG-14K数据集；3. 提出MedReasoner框架，分离推理与分割，通过强化学习优化MLLM。

Result: MedReasoner在U-MRG-14K上达到SOTA性能，并展示了对未见临床查询的强泛化能力。

Conclusion: 强化学习在可解释医学定位中具有显著潜力。

Abstract: Accurately grounding regions of interest (ROIs) is critical for diagnosis and
treatment planning in medical imaging. While multimodal large language models
(MLLMs) combine visual perception with natural language, current
medical-grounding pipelines still rely on supervised fine-tuning with explicit
spatial hints, making them ill-equipped to handle the implicit queries common
in clinical practice. This work makes three core contributions. We first define
Unified Medical Reasoning Grounding (UMRG), a novel vision-language task that
demands clinical reasoning and pixel-level grounding. Second, we release
U-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside
implicit clinical queries and reasoning traces, spanning 10 modalities, 15
super-categories, and 108 specific categories. Finally, we introduce
MedReasoner, a modular framework that distinctly separates reasoning from
segmentation: an MLLM reasoner is optimized with reinforcement learning, while
a frozen segmentation expert converts spatial prompts into masks, with
alignment achieved through format and accuracy rewards. MedReasoner achieves
state-of-the-art performance on U-MRG-14K and demonstrates strong
generalization to unseen clinical queries, underscoring the significant promise
of reinforcement learning for interpretable medical grounding.

</details>


### [127] [Reinforcement Learning in Vision: A Survey](https://arxiv.org/abs/2508.08189)
*Weijia Wu,Chen Gao,Joya Chen,Kevin Qinghong Lin,Qingwei Meng,Yiming Zhang,Yuke Qiu,Hong Zhou,Mike Zheng Shou*

Main category: cs.CV

Relevance: 70.0

TL;DR: 该论文是一篇关于视觉强化学习（Visual RL）的综述，总结了从RLHF到可验证奖励范式的策略优化演变，并将200多篇代表性工作分为四大主题支柱。


<details>
  <summary>Details</summary>
Motivation: 为研究人员和实践者提供视觉RL领域的全面概览，并指出未来研究方向。

Method: 通过分类和分析200多篇论文，总结视觉RL的算法设计、奖励工程和基准进展。

Result: 提出了四大主题支柱（多模态LLM、视觉生成、统一模型框架、视觉-语言-动作模型）和趋势（如课程驱动训练、偏好对齐扩散）。

Conclusion: 视觉RL领域发展迅速，但仍面临样本效率、泛化和安全部署等挑战。

Abstract: Recent advances at the intersection of reinforcement learning (RL) and visual
intelligence have enabled agents that not only perceive complex visual scenes
but also reason, generate, and act within them. This survey offers a critical
and up-to-date synthesis of the field. We first formalize visual RL problems
and trace the evolution of policy-optimization strategies from RLHF to
verifiable reward paradigms, and from Proximal Policy Optimization to Group
Relative Policy Optimization. We then organize more than 200 representative
works into four thematic pillars: multi-modal large language models, visual
generation, unified model frameworks, and vision-language-action models. For
each pillar we examine algorithmic design, reward engineering, benchmark
progress, and we distill trends such as curriculum-driven training,
preference-aligned diffusion, and unified reward modeling. Finally, we review
evaluation protocols spanning set-level fidelity, sample-level preference, and
state-level stability, and we identify open challenges that include sample
efficiency, generalization, and safe deployment. Our goal is to provide
researchers and practitioners with a coherent map of the rapidly expanding
landscape of visual RL and to highlight promising directions for future
inquiry. Resources are available at:
https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.

</details>


### [128] [Learning User Preferences for Image Generation Model](https://arxiv.org/abs/2508.08220)
*Wenyi Mo,Ying Ba,Tianyu Zhang,Yalong Bai,Biye Li*

Main category: cs.CV

Relevance: 70.0

TL;DR: 提出了一种基于多模态大语言模型的方法，通过对比偏好损失和偏好标记学习个性化用户偏好，显著提升了偏好预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖通用人类偏好或静态用户画像，忽略了用户偏好的动态性和多样性。本文旨在解决这一问题。

Method: 采用多模态大语言模型，引入对比偏好损失和偏好标记，从历史交互中学习个性化偏好。

Result: 实验表明，该方法在偏好预测准确性上优于其他方法，并能识别相似审美倾向的用户。

Conclusion: 该方法能更精准地生成符合个人口味的图像，为个性化推荐提供了新思路。

Abstract: User preference prediction requires a comprehensive and accurate
understanding of individual tastes. This includes both surface-level
attributes, such as color and style, and deeper content-related aspects, such
as themes and composition. However, existing methods typically rely on general
human preferences or assume static user profiles, often neglecting individual
variability and the dynamic, multifaceted nature of personal taste. To address
these limitations, we propose an approach built upon Multimodal Large Language
Models, introducing contrastive preference loss and preference tokens to learn
personalized user preferences from historical interactions. The contrastive
preference loss is designed to effectively distinguish between user ''likes''
and ''dislikes'', while the learnable preference tokens capture shared interest
representations among existing users, enabling the model to activate
group-specific preferences and enhance consistency across similar users.
Extensive experiments demonstrate our model outperforms other methods in
preference prediction accuracy, effectively identifying users with similar
aesthetic inclinations and providing more precise guidance for generating
images that align with individual tastes. The project page is
\texttt{https://learn-user-pref.github.io/}.

</details>


### [129] [Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM](https://arxiv.org/abs/2508.07260)
*Sihan Yang,Huitong Ji,Shaolin Lu,Jiayi Chen,Binxiao Xu,Ming Lu,Yuanxing Zhang,Wenhui Dong,Wentao Zhang*

Main category: cs.CV

Relevance: 65.0

TL;DR: 论文提出了一种名为Small-Large Collaboration (SLC)的协作框架，用于个性化大型视觉语言模型（VLMs）。小型VLM生成个性化信息，大型VLM整合信息以提供准确响应，并通过测试时反射策略避免幻觉。该框架训练高效，支持开源和闭源大型VLMs。


<details>
  <summary>Details</summary>
Motivation: 大型VLMs训练成本高且访问受限，小型VLMs易个性化但缺乏推理能力，因此需要一种高效协作框架。

Method: 提出SLC框架，小型VLM生成个性化信息，大型VLM整合信息；采用测试时反射策略防止幻觉；仅需训练小型VLM元模型。

Result: 实验证明SLC在多个基准测试和大型VLMs中有效。

Conclusion: SLC是首个训练高效且支持开源和闭源大型VLMs的个性化框架，具有广泛实际应用潜力。

Abstract: Personalizing Vision-Language Models (VLMs) to transform them into daily
assistants has emerged as a trending research direction. However, leading
companies like OpenAI continue to increase model size and develop complex
designs such as the chain of thought (CoT). While large VLMs are proficient in
complex multi-modal understanding, their high training costs and limited access
via paid APIs restrict direct personalization. Conversely, small VLMs are
easily personalized and freely available, but they lack sufficient reasoning
capabilities. Inspired by this, we propose a novel collaborative framework
named Small-Large Collaboration (SLC) for large VLM personalization, where the
small VLM is responsible for generating personalized information, while the
large model integrates this personalized information to deliver accurate
responses. To effectively incorporate personalized information, we develop a
test-time reflection strategy, preventing the potential hallucination of the
small VLM. Since SLC only needs to train a meta personalized small VLM for the
large VLMs, the overall process is training-efficient. To the best of our
knowledge, this is the first training-efficient framework that supports both
open-source and closed-source large VLMs, enabling broader real-world
personalized applications. We conduct thorough experiments across various
benchmarks and large VLMs to demonstrate the effectiveness of the proposed SLC
framework. The code will be released at https://github.com/Hhankyangg/SLC.

</details>


### [130] [Med-GRIM: Enhanced Zero-Shot Medical VQA using prompt-embedded Multimodal Graph RAG](https://arxiv.org/abs/2508.06496)
*Rakesh Raj Madavan,Akshat Kaimal,Hashim Faisal,Chandrakala S*

Main category: cs.CV

Relevance: 60.0

TL;DR: BIND和Med-GRIM提出了一种高效的多模态视觉问答（VQA）方法，特别针对医学领域，通过密集编码和模块化工作流程实现高性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有VQA模型在复杂领域（如医学）中缺乏详细精度的问题。

Method: 结合密集编码（BIND）和图检索（Med-GRIM），利用小语言模型（SLMs）和动态知识注入。

Result: Med-GRIM在低计算成本下实现大语言模型性能，并发布DermaGraph数据集支持零样本研究。

Conclusion: 该方法为医学VQA提供了高效、模块化的解决方案，并推动了多模态医学研究。

Abstract: An ensemble of trained multimodal encoders and vision-language models (VLMs)
has become a standard approach for visual question answering (VQA) tasks.
However, such models often fail to produce responses with the detailed
precision necessary for complex, domain-specific applications such as medical
VQA. Our representation model, BIND: BLIVA Integrated with Dense Encoding,
extends prior multimodal work by refining the joint embedding space through
dense, query-token-based encodings inspired by contrastive pretraining
techniques. This refined encoder powers Med-GRIM, a model designed for medical
VQA tasks that leverages graph-based retrieval and prompt engineering to
integrate domain-specific knowledge. Rather than relying on compute-heavy
fine-tuning of vision and language models on specific datasets, Med-GRIM
applies a low-compute, modular workflow with small language models (SLMs) for
efficiency. Med-GRIM employs prompt-based retrieval to dynamically inject
relevant knowledge, ensuring both accuracy and robustness in its responses. By
assigning distinct roles to each agent within the VQA system, Med-GRIM achieves
large language model performance at a fraction of the computational cost.
Additionally, to support scalable research in zero-shot multimodal medical
applications, we introduce DermaGraph, a novel Graph-RAG dataset comprising
diverse dermatological conditions. This dataset facilitates both multimodal and
unimodal querying. The code and dataset are available at:
https://github.com/Rakesh-123-cryp/Med-GRIM.git

</details>


### [131] [Slice or the Whole Pie? Utility Control for AI Models](https://arxiv.org/abs/2508.06551)
*Ye Tao*

Main category: cs.CV

Relevance: 60.0

TL;DR: NNObfuscator提出了一种动态调整AI模型性能的机制，避免了为不同需求训练多个模型的低效问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法中需要为不同用户需求训练和维护多个模型的低效问题。

Method: 通过NNObfuscator机制，允许单个模型实时动态调整性能，支持分层访问控制。

Result: 实验表明，NNObfuscator使单个模型能够适应多种任务需求，减少计算资源浪费。

Conclusion: NNObfuscator提高了资源分配效率，支持可持续的AI部署商业模式。

Abstract: Training deep neural networks (DNNs) has become an increasingly
resource-intensive task, requiring large volumes of labeled data, substantial
computational power, and considerable fine-tuning efforts to achieve optimal
performance across diverse use cases. Although pre-trained models offer a
useful starting point, adapting them to meet specific user needs often demands
extensive customization, and infrastructure overhead. This challenge grows when
a single model must support diverse appli-cations with differing requirements
for performance. Traditional solutions often involve training multiple model
versions to meet varying requirements, which can be inefficient and difficult
to maintain. In order to overcome this challenge, we propose NNObfuscator, a
novel utility control mechanism that enables AI models to dynamically modify
their performance according to predefined conditions. It is different from
traditional methods that need separate models for each user. Instead,
NNObfuscator allows a single model to be adapted in real time, giving you
controlled access to multiple levels of performance. This mechanism enables
model owners set up tiered access, ensuring that free-tier users receive a
baseline level of performance while premium users benefit from enhanced
capabilities. The approach improves resource allocation, reduces unnecessary
computation, and supports sustainable business models in AI deployment. To
validate our approach, we conducted experiments on multiple tasks, including
image classification, semantic segmentation, and text to image generation,
using well-established models such as ResNet, DeepLab, VGG16, FCN and Stable
Diffusion. Experimental results show that NNObfuscator successfully makes model
more adaptable, so that a single trained model can handle a broad range of
tasks without requiring a lot of changes.

</details>


### [132] [OctreeNCA: Single-Pass 184 MP Segmentation on Consumer Hardware](https://arxiv.org/abs/2508.06993)
*Nick Lemke,John Kalkhof,Niklas Babendererde,Anirban Mukhopadhyay*

Main category: cs.CV

Relevance: 60.0

TL;DR: OctreeNCA提出了一种基于八叉树数据结构的NCA改进方法，用于高效分割高分辨率医学图像和视频，显著降低VRAM消耗并提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 医学图像和视频分割需要全局上下文，但现有方法（如UNet或Vision Transformers）因VRAM消耗高而被迫采用分块处理，影响全局一致性和速度。NCA虽轻量但缺乏全局知识。

Method: 通过八叉树数据结构扩展NCA的邻域定义，实现全局知识的高效传递，并开发了优化的CUDA实现以减少VRAM需求和加速推理。

Result: OctreeNCA在高分辨率图像和视频分割中VRAM占用比UNet减少90%，可一次性处理184兆像素病理切片或1分钟手术视频。

Conclusion: OctreeNCA在医学图像分割中实现了高效、全局一致的推理，解决了VRAM瓶颈问题。

Abstract: Medical applications demand segmentation of large inputs, like prostate MRIs,
pathology slices, or videos of surgery. These inputs should ideally be inferred
at once to provide the model with proper spatial or temporal context. When
segmenting large inputs, the VRAM consumption of the GPU becomes the
bottleneck. Architectures like UNets or Vision Transformers scale very poorly
in VRAM consumption, resulting in patch- or frame-wise approaches that
compromise global consistency and inference speed. The lightweight Neural
Cellular Automaton (NCA) is a bio-inspired model that is by construction
size-invariant. However, due to its local-only communication rules, it lacks
global knowledge. We propose OctreeNCA by generalizing the neighborhood
definition using an octree data structure. Our generalized neighborhood
definition enables the efficient traversal of global knowledge. Since deep
learning frameworks are mainly developed for large multi-layer networks, their
implementation does not fully leverage the advantages of NCAs. We implement an
NCA inference function in CUDA that further reduces VRAM demands and increases
inference speed. Our OctreeNCA segments high-resolution images and videos
quickly while occupying 90% less VRAM than a UNet during evaluation. This
allows us to segment 184 Megapixel pathology slices or 1-minute surgical videos
at once.

</details>


### [133] [DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents](https://arxiv.org/abs/2508.07021)
*Kun Qian,Wenjie Li,Tianyu Sun,Wenhong Wang,Wenhan Luo*

Main category: cs.CV

Relevance: 60.0

TL;DR: DocRefine是一个基于多智能体系统的框架，用于科学PDF文档的智能理解、内容优化和自动摘要，结合了先进的LVLMs（如GPT-4o），在语义一致性和视觉保真度方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长需要高效、精准的文档处理工具，传统方法和直接应用LLMs/LVLMs在复杂编辑任务中表现不足。

Method: DocRefine采用六种协作智能体（如布局分析、多模态内容理解等）的闭环反馈架构，结合LVLMs。

Result: 在DocEditBench数据集上，DocRefine在语义一致性（86.7%）、布局保真度（93.9%）和指令遵循率（85.0%）上优于现有方法。

Conclusion: DocRefine在复杂多模态文档编辑中表现出色，是科学文档自动化处理的重要进展。

Abstract: The exponential growth of scientific literature in PDF format necessitates
advanced tools for efficient and accurate document understanding,
summarization, and content optimization. Traditional methods fall short in
handling complex layouts and multimodal content, while direct application of
Large Language Models (LLMs) and Vision-Language Large Models (LVLMs) lacks
precision and control for intricate editing tasks. This paper introduces
DocRefine, an innovative framework designed for intelligent understanding,
content refinement, and automated summarization of scientific PDF documents,
driven by natural language instructions. DocRefine leverages the power of
advanced LVLMs (e.g., GPT-4o) by orchestrating a sophisticated multi-agent
system comprising six specialized and collaborative agents: Layout & Structure
Analysis, Multimodal Content Understanding, Instruction Decomposition, Content
Refinement, Summarization & Generation, and Fidelity & Consistency
Verification. This closed-loop feedback architecture ensures high semantic
accuracy and visual fidelity. Evaluated on the comprehensive DocEditBench
dataset, DocRefine consistently outperforms state-of-the-art baselines across
various tasks, achieving overall scores of 86.7% for Semantic Consistency Score
(SCS), 93.9% for Layout Fidelity Index (LFI), and 85.0% for Instruction
Adherence Rate (IAR). These results demonstrate DocRefine's superior capability
in handling complex multimodal document editing, preserving semantic integrity,
and maintaining visual consistency, marking a significant advancement in
automated scientific document processing.

</details>


### [134] [MV-CoRe: Multimodal Visual-Conceptual Reasoning for Complex Visual Question Answering](https://arxiv.org/abs/2508.07023)
*Jingwei Peng,Jiehao Chen,Mateo Alejandro Rojas,Meilin Zhang*

Main category: cs.CV

Relevance: 60.0

TL;DR: MV-CoRe模型通过深度融合视觉和语言信息，提升复杂视觉问答任务的性能，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 解决现有大型视觉语言模型在复杂视觉问答任务中依赖高层全局特征的局限性。

Method: 结合预训练视觉和语言模型的全局嵌入与细粒度语义视觉特征，通过多模态融合Transformer实现跨模态注意力。

Result: 在GQA、A-OKVQA和OKVQA基准测试中表现优异，GQA准确率达77.5%。

Conclusion: MV-CoRe在深度视觉和概念理解方面表现出色，验证了其多模态融合的有效性。

Abstract: Complex Visual Question Answering (Complex VQA) tasks, which demand
sophisticated multi-modal reasoning and external knowledge integration, present
significant challenges for existing large vision-language models (LVLMs) often
limited by their reliance on high-level global features. To address this, we
propose MV-CoRe (Multimodal Visual-Conceptual Reasoning), a novel model
designed to enhance Complex VQA performance through the deep fusion of diverse
visual and linguistic information. MV-CoRe meticulously integrates global
embeddings from pre-trained Vision Large Models (VLMs) and Language Large
Models (LLMs) with fine-grained semantic-aware visual features, including
object detection characteristics and scene graph representations. An innovative
Multimodal Fusion Transformer then processes and deeply integrates these
diverse feature sets, enabling rich cross-modal attention and facilitating
complex reasoning. We evaluate MV-CoRe on challenging Complex VQA benchmarks,
including GQA, A-OKVQA, and OKVQA, after training on VQAv2. Our experimental
results demonstrate that MV-CoRe consistently outperforms established LVLM
baselines, achieving an overall accuracy of 77.5% on GQA. Ablation studies
confirm the critical contribution of both object and scene graph features, and
human evaluations further validate MV-CoRe's superior factual correctness and
reasoning depth, underscoring its robust capabilities for deep visual and
conceptual understanding.

</details>


### [135] [Consistent and Controllable Image Animation with Motion Linear Diffusion Transformers](https://arxiv.org/abs/2508.07246)
*Xin Ma,Yaohui Wang,Genyun Jia,Xinyuan Chen,Tien-Tsin Wong,Cunjian Chen*

Main category: cs.CV

Relevance: 60.0

TL;DR: MiraMo框架通过高效线性注意力、运动残差学习和DCT噪声优化，提升图像动画的效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决图像动画中外观一致性和运动平滑性的挑战，同时降低计算开销。

Method: 1. 使用高效线性注意力替代标准自注意力；2. 运动残差学习建模动态；3. DCT噪声优化和动态控制模块。

Result: 实验证明MiraMo在生成一致性、平滑性和速度上优于现有方法。

Conclusion: MiraMo为图像动画提供了高效且高质量的解决方案，并适用于多种任务。

Abstract: Image animation has seen significant progress, driven by the powerful
generative capabilities of diffusion models. However, maintaining appearance
consistency with static input images and mitigating abrupt motion transitions
in generated animations remain persistent challenges. While text-to-video (T2V)
generation has demonstrated impressive performance with diffusion transformer
models, the image animation field still largely relies on U-Net-based diffusion
models, which lag behind the latest T2V approaches. Moreover, the quadratic
complexity of vanilla self-attention mechanisms in Transformers imposes heavy
computational demands, making image animation particularly resource-intensive.
To address these issues, we propose MiraMo, a framework designed to enhance
efficiency, appearance consistency, and motion smoothness in image animation.
Specifically, MiraMo introduces three key elements: (1) A foundational
text-to-video architecture replacing vanilla self-attention with efficient
linear attention to reduce computational overhead while preserving generation
quality; (2) A novel motion residual learning paradigm that focuses on modeling
motion dynamics rather than directly predicting frames, improving temporal
consistency; and (3) A DCT-based noise refinement strategy during inference to
suppress sudden motion artifacts, complemented by a dynamics control module to
balance motion smoothness and expressiveness. Extensive experiments against
state-of-the-art methods validate the superiority of MiraMo in generating
consistent, smooth, and controllable animations with accelerated inference
speed. Additionally, we demonstrate the versatility of MiraMo through
applications in motion transfer and video editing tasks.

</details>


### [136] [AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning](https://arxiv.org/abs/2508.07470)
*Siminfar Samakoush Galougah,Rishie Raj,Sanjoy Chowdhury,Sayan Nag,Ramani Duraiswami*

Main category: cs.CV

Relevance: 60.0

TL;DR: AURA是一个新的音频-视觉基准测试，旨在评估多模态语言模型的跨模态推理能力，填补了现有测试仅关注答案准确性的不足。


<details>
  <summary>Details</summary>
Motivation: 现有音频-视觉基准测试仅关注最终答案准确性，忽略了推理过程，无法区分真实理解与通过错误推理得出的正确答案。

Method: AURA包含六个认知领域的题目，强制模型基于音频和视频构建逻辑路径。提出新指标AuraScore，评估推理的感知一致性和逻辑有效性。

Result: 评估显示，尽管模型在某些任务上准确率高达92%，但其推理一致性和逻辑有效性低于45%，表明模型常通过错误逻辑得出正确答案。

Conclusion: AURA揭示了多模态模型的推理缺陷，为更鲁棒的评估提供了工具。

Abstract: Current audio-visual (AV) benchmarks focus on final answer accuracy,
overlooking the underlying reasoning process. This makes it difficult to
distinguish genuine comprehension from correct answers derived through flawed
reasoning or hallucinations. To address this, we introduce AURA (Audio-visual
Understanding and Reasoning Assessment), a benchmark for evaluating the
cross-modal reasoning capabilities of Audio-Visual Large Language Models
(AV-LLMs) and Omni-modal Language Models (OLMs). AURA includes questions across
six challenging cognitive domains, such as causality, timbre and pitch, tempo
and AV synchronization, unanswerability, implicit distractions, and skill
profiling, explicitly designed to be unanswerable from a single modality. This
forces models to construct a valid logical path grounded in both audio and
video, setting AURA apart from AV datasets that allow uni-modal shortcuts. To
assess reasoning traces, we propose a novel metric, AuraScore, which addresses
the lack of robust tools for evaluating reasoning fidelity. It decomposes
reasoning into two aspects: (i) Factual Consistency - whether reasoning is
grounded in perceptual evidence, and (ii) Core Inference - the logical validity
of each reasoning step. Evaluations of SOTA models on AURA reveal a critical
reasoning gap: although models achieve high accuracy (up to 92% on some tasks),
their Factual Consistency and Core Inference scores fall below 45%. This
discrepancy highlights that models often arrive at correct answers through
flawed logic, underscoring the need for our benchmark and paving the way for
more robust multimodal evaluation.

</details>


### [137] [Investigating the Design Space of Visual Grounding in Multimodal Large Language Model](https://arxiv.org/abs/2508.08066)
*Weitai Kang,Weiming Zhuang,Zhizhong Li,Yan Yan,Lingjuan Lyu*

Main category: cs.CV

Relevance: 60.0

TL;DR: 本文系统研究了多模态大语言模型（MLLMs）中视觉定位（VG）任务的设计选择，通过LLaVA-1.5验证了不同设计对性能的影响，最终提升了VG任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在VG任务中设计选择分散且缺乏系统验证，本文旨在填补这一空白。

Method: 使用LLaVA-1.5分析不同视觉定位范式和数据设计，进行消融研究。

Result: 优化后的MLLM在RefCOCO/+/g数据集上性能提升了5.6%/6.9%/7.0%。

Conclusion: 系统验证设计选择可显著提升MLLMs在VG任务中的性能。

Abstract: Fine-grained multimodal capability in Multimodal Large Language Models
(MLLMs) has emerged as a critical research direction, particularly for tackling
the visual grounding (VG) problem. Despite the strong performance achieved by
existing approaches, they often employ disparate design choices when
fine-tuning MLLMs for VG, lacking systematic verification to support these
designs. To bridge this gap, this paper presents a comprehensive study of
various design choices that impact the VG performance of MLLMs. We conduct our
analysis using LLaVA-1.5, which has been widely adopted in prior empirical
studies of MLLMs. While more recent models exist, we follow this convention to
ensure our findings remain broadly applicable and extendable to other
architectures. We cover two key aspects: (1) exploring different visual
grounding paradigms in MLLMs, identifying the most effective design, and
providing our insights; and (2) conducting ablation studies on the design of
grounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our
findings contribute to a stronger MLLM for VG, achieving improvements of +5.6%
/ +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.

</details>


### [138] [Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2508.07570)
*Khanh-Binh Nguyen,Phuoc-Nguyen Bui,Hyunseung Choo,Duc Thanh Nguyen*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了一种名为ACE的框架，通过动态缓存高置信度或低熵图像嵌入，优化视觉语言模型在分布偏移下的测试时适应性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在零样本泛化方面表现优异，但在分布偏移下性能下降，尤其是在无标注数据的情况下。测试时适应方法通过在线优化模型解决这一问题，但现有方法存在置信度不可靠和决策边界僵化的问题。

Method: 提出ACE框架，动态构建缓存，存储每类的高置信度或低熵图像嵌入，并使用动态阈值和指数移动平均优化决策边界。

Result: 在15个基准数据集上的实验表明，ACE在分布偏移场景下优于现有测试时适应方法，具有更强的鲁棒性和泛化能力。

Conclusion: ACE通过自适应缓存和动态决策边界，显著提升了视觉语言模型在分布偏移下的性能。

Abstract: Vision-language models (VLMs) exhibit remarkable zero-shot generalization but
suffer performance degradation under distribution shifts in downstream tasks,
particularly in the absence of labeled data. Test-Time Adaptation (TTA)
addresses this challenge by enabling online optimization of VLMs during
inference, eliminating the need for annotated data. Cache-based TTA methods
exploit historical knowledge by maintaining a dynamic memory cache of
low-entropy or high-confidence samples, promoting efficient adaptation to
out-of-distribution data. Nevertheless, these methods face two critical
challenges: (1) unreliable confidence metrics under significant distribution
shifts, resulting in error accumulation within the cache and degraded
adaptation performance; and (2) rigid decision boundaries that fail to
accommodate substantial distributional variations, leading to suboptimal
predictions. To overcome these limitations, we introduce the Adaptive Cache
Enhancement (ACE) framework, which constructs a robust cache by selectively
storing high-confidence or low-entropy image embeddings per class, guided by
dynamic, class-specific thresholds initialized from zero-shot statistics and
iteratively refined using an exponential moving average and
exploration-augmented updates. This approach enables adaptive, class-wise
decision boundaries, ensuring robust and accurate predictions across diverse
visual distributions. Extensive experiments on 15 diverse benchmark datasets
demonstrate that ACE achieves state-of-the-art performance, delivering superior
robustness and generalization compared to existing TTA methods in challenging
out-of-distribution scenarios.

</details>


### [139] [Grouped Speculative Decoding for Autoregressive Image Generation](https://arxiv.org/abs/2508.07747)
*Junhyuk So,Juncheol Shin,Hyunho Kook,Eunhyeok Park*

Main category: cs.CV

Relevance: 60.0

TL;DR: 提出了一种名为Grouped Speculative Decoding (GSD)的无训练加速方法，用于自回归图像模型，通过动态评估视觉有效令牌集群，平均加速3.7倍且保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 自回归图像模型因序列性导致推理时间长，现有方法加速效果有限或需额外训练。

Method: 提出GSD方法，动态评估令牌集群而非单一目标令牌，利用图像令牌的冗余性和多样性。

Result: 实验显示GSD平均加速3.7倍，且无需额外训练。

Conclusion: GSD为自回归图像模型提供了一种高效且无需训练的加速方案。

Abstract: Recently, autoregressive (AR) image models have demonstrated remarkable
generative capabilities, positioning themselves as a compelling alternative to
diffusion models. However, their sequential nature leads to long inference
times, limiting their practical scalability. In this work, we introduce Grouped
Speculative Decoding (GSD), a novel, training-free acceleration method for AR
image models. While recent studies have explored Speculative Decoding (SD) as a
means to speed up AR image generation, existing approaches either provide only
modest acceleration or require additional training. Our in-depth analysis
reveals a fundamental difference between language and image tokens: image
tokens exhibit inherent redundancy and diversity, meaning multiple tokens can
convey valid semantics. However, traditional SD methods are designed to accept
only a single most-likely token, which fails to leverage this difference,
leading to excessive false-negative rejections. To address this, we propose a
new SD strategy that evaluates clusters of visually valid tokens rather than
relying on a single target token. Additionally, we observe that static
clustering based on embedding distance is ineffective, which motivates our
dynamic GSD approach. Extensive experiments show that GSD accelerates AR image
models by an average of 3.7x while preserving image quality-all without
requiring any additional training. The source code is available at
https://github.com/junhyukso/GSD

</details>


### [140] [UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models](https://arxiv.org/abs/2508.07766)
*Jinke Li,Jiarui Yu,Chenxing Wei,Hande Dong,Qiang Lin,Liangjing Yang,Zhicai Wang,Yanbin Hao*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出UniSVG数据集，用于多模态大语言模型（MLLMs）在SVG理解和生成任务中的训练与评估，提升模型性能并超越GPT-4V等闭源模型。


<details>
  <summary>Details</summary>
Motivation: SVG在AI驱动的理解和生成任务中面临高精度和多模态处理的挑战，而MLLMs的快速发展为解决这些问题提供了潜力。

Method: 构建UniSVG数据集（525k数据项），支持文本提示和图像到SVG的生成任务，以及SVG理解任务。

Result: 开源MLLMs在UniSVG数据集训练后，性能超越GPT-4V等闭源模型。

Conclusion: UniSVG数据集为MLLMs在SVG领域的应用提供了统一解决方案，推动了AI在SVG任务中的进展。

Abstract: Unlike bitmap images, scalable vector graphics (SVG) maintain quality when
scaled, frequently employed in computer vision and artistic design in the
representation of SVG code. In this era of proliferating AI-powered systems,
enabling AI to understand and generate SVG has become increasingly urgent.
However, AI-driven SVG understanding and generation (U&G) remain significant
challenges. SVG code, equivalent to a set of curves and lines controlled by
floating-point parameters, demands high precision in SVG U&G. Besides, SVG
generation operates under diverse conditional constraints, including textual
prompts and visual references, which requires powerful multi-modal processing
for condition-to-SVG transformation. Recently, the rapid growth of Multi-modal
Large Language Models (MLLMs) have demonstrated capabilities to process
multi-modal inputs and generate complex vector controlling parameters,
suggesting the potential to address SVG U&G tasks within a unified model. To
unlock MLLM's capabilities in the SVG area, we propose an SVG-centric dataset
called UniSVG, comprising 525k data items, tailored for MLLM training and
evaluation. To our best knowledge, it is the first comprehensive dataset
designed for unified SVG generation (from textual prompts and images) and SVG
understanding (color, category, usage, etc.). As expected, learning on the
proposed dataset boosts open-source MLLMs' performance on various SVG U&G
tasks, surpassing SOTA close-source MLLMs like GPT-4V. We release dataset,
benchmark, weights, codes and experiment details on
https://ryanlijinke.github.io/.

</details>


### [141] [Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.07804)
*Bao Li,Xiaomei Zhang,Miao Xu,Zhaoxin Fan,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

Relevance: 60.0

TL;DR: Pose-RFT提出了一种基于强化学习的多模态大语言模型（MLLMs）微调框架，用于3D人体姿态生成，通过混合动作强化学习优化语言预测和姿态生成。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在3D姿态生成任务中因监督目标（如SMPL参数回归）难以建模模糊性和任务对齐，限制了性能。

Method: 提出Pose-RFT框架，采用混合动作强化学习（HyGRPO算法）联合优化离散语言预测和连续姿态生成，并设计任务特定奖励函数。

Result: 在多个姿态生成基准测试中，Pose-RFT显著优于现有方法。

Conclusion: 混合动作强化学习微调对3D姿态生成任务有效。

Abstract: Generating 3D human poses from multimodal inputs such as images or text
requires models to capture both rich spatial and semantic correspondences.
While pose-specific multimodal large language models (MLLMs) have shown promise
in this task, they are typically trained with supervised objectives such as
SMPL parameter regression or token-level prediction, which struggle to model
the inherent ambiguity and achieve task-specific alignment required for
accurate 3D pose generation. To address these limitations, we propose Pose-RFT,
a reinforcement fine-tuning framework tailored for 3D human pose generation in
MLLMs. We formulate the task as a hybrid action reinforcement learning problem
that jointly optimizes discrete language prediction and continuous pose
generation. To this end, we introduce HyGRPO, a hybrid reinforcement learning
algorithm that performs group-wise reward normalization over sampled responses
to guide joint optimization of discrete and continuous actions. Pose-RFT
further incorporates task-specific reward functions to guide optimization
towards spatial alignment in image-to-pose generation and semantic consistency
in text-to-pose generation. Extensive experiments on multiple pose generation
benchmarks demonstrate that Pose-RFT significantly improves performance over
existing pose-specific MLLMs, validating the effectiveness of hybrid action
reinforcement fine-tuning for 3D pose generation.

</details>


### [142] [Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model](https://arxiv.org/abs/2508.07863)
*Bin Cao,Sipeng Zheng,Ye Wang,Lujie Xia,Qianshan Wei,Qin Jin,Jing Liu,Zongqing Lu*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了Being-M0.5，一种实时可控的视觉语言运动模型（VLMM），解决了现有模型在可控性方面的五大限制，并基于HuMo100M数据集实现了多任务运动生成的最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言运动模型（VLMMs）在可控性方面存在显著不足，包括对多样化命令的响应不足、姿势初始化能力有限、长序列性能差、对未知场景处理不足以及缺乏对单个身体部位的细粒度控制。

Method: 基于HuMo100M数据集（包含500万自收集运动序列和1亿多任务指令实例），提出了一种新颖的部分感知残差量化技术，用于运动标记化，以实现对单个身体部位的精确控制。

Result: Being-M0.5在多种运动生成任务中实现了最先进的性能，并通过效率分析验证了其实时能力。

Conclusion: HuMo100M数据集和Being-M0.5模型是运动生成技术在实际应用中的重大进步。

Abstract: Human motion generation has emerged as a critical technology with
transformative potential for real-world applications. However, existing
vision-language-motion models (VLMMs) face significant limitations that hinder
their practical deployment. We identify controllability as a main bottleneck,
manifesting in five key aspects: inadequate response to diverse human commands,
limited pose initialization capabilities, poor performance on long-term
sequences, insufficient handling of unseen scenarios, and lack of fine-grained
control over individual body parts. To overcome these limitations, we present
Being-M0.5, the first real-time, controllable VLMM that achieves
state-of-the-art performance across multiple motion generation tasks. Our
approach is built upon HuMo100M, the largest and most comprehensive human
motion dataset to date, comprising over 5 million self-collected motion
sequences, 100 million multi-task instructional instances, and detailed
part-level annotations that address a critical gap in existing datasets. We
introduce a novel part-aware residual quantization technique for motion
tokenization that enables precise, granular control over individual body parts
during generation. Extensive experimental validation demonstrates Being-M0.5's
superior performance across diverse motion benchmarks, while comprehensive
efficiency analysis confirms its real-time capabilities. Our contributions
include design insights and detailed computational analysis to guide future
development of practical motion generators. We believe that HuMo100M and
Being-M0.5 represent significant advances that will accelerate the adoption of
motion generation technologies in real-world applications. The project page is
available at https://beingbeyond.github.io/Being-M0.5.

</details>


### [143] [Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2508.08165)
*Yan Wang,Da-Wei Zhou,Han-Jia Ye*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了一种结合任务特定和通用适配器（TUNA）的方法，用于类增量学习（CIL），通过熵选择机制和适配器融合策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有预训练模型在CIL中模块选择错误和忽略共享知识的问题。

Method: 训练任务特定适配器捕获关键特征，引入熵选择机制，并通过适配器融合构建通用适配器。

Result: 在多个基准数据集上实现了最先进的性能。

Conclusion: TUNA方法有效结合了任务特定和通用知识，提升了CIL性能。

Abstract: Class-Incremental Learning (CIL) requires a learning system to continually
learn new classes without forgetting. Existing pre-trained model-based CIL
methods often freeze the pre-trained network and adapt to incremental tasks
using additional lightweight modules such as adapters. However, incorrect
module selection during inference hurts performance, and task-specific modules
often overlook shared general knowledge, leading to errors on distinguishing
between similar classes across tasks. To address the aforementioned challenges,
we propose integrating Task-Specific and Universal Adapters (TUNA) in this
paper. Specifically, we train task-specific adapters to capture the most
crucial features relevant to their respective tasks and introduce an
entropy-based selection mechanism to choose the most suitable adapter.
Furthermore, we leverage an adapter fusion strategy to construct a universal
adapter, which encodes the most discriminative features shared across tasks. We
combine task-specific and universal adapter predictions to harness both
specialized and general knowledge during inference. Extensive experiments on
various benchmark datasets demonstrate the state-of-the-art performance of our
approach. Code is available at: https://github.com/LAMDA-CL/ICCV2025-TUNA

</details>


### [144] [ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks](https://arxiv.org/abs/2508.08240)
*Kaijun Wang,Liqin Lu,Mingyu Liu,Jianuo Jiang,Zeju Li,Bolin Zhang,Wancai Zheng,Xinyi Yu,Hao Chen,Chunhua Shen*

Main category: cs.RO

Relevance: 60.0

TL;DR: ODYSSEY是一个统一的移动操作框架，结合了高级任务规划和低级全身控制，解决了语言引导的移动操作中的感知、泛化和控制问题。


<details>
  <summary>Details</summary>
Motivation: 解决移动平台在语言引导任务中的感知限制、泛化不足以及高机动性与精确控制的双重要求问题。

Method: 引入分层规划器（基于视觉语言模型）和新型全身策略，实现任务分解和协调控制。

Result: 通过模拟到现实的迁移，展示了系统在真实环境中的泛化能力和鲁棒性。

Conclusion: ODYSSEY提升了腿式机器人在非结构化环境中执行复杂动态任务的可行性。

Abstract: Language-guided long-horizon mobile manipulation has long been a grand
challenge in embodied semantic reasoning, generalizable manipulation, and
adaptive locomotion. Three fundamental limitations hinder progress: First,
although large language models have improved spatial reasoning and task
planning through semantic priors, existing implementations remain confined to
tabletop scenarios, failing to address the constrained perception and limited
actuation ranges of mobile platforms. Second, current manipulation strategies
exhibit insufficient generalization when confronted with the diverse object
configurations encountered in open-world environments. Third, while crucial for
practical deployment, the dual requirement of maintaining high platform
maneuverability alongside precise end-effector control in unstructured settings
remains understudied.
  In this work, we present ODYSSEY, a unified mobile manipulation framework for
agile quadruped robots equipped with manipulators, which seamlessly integrates
high-level task planning with low-level whole-body control. To address the
challenge of egocentric perception in language-conditioned tasks, we introduce
a hierarchical planner powered by a vision-language model, enabling
long-horizon instruction decomposition and precise action execution. At the
control level, our novel whole-body policy achieves robust coordination across
challenging terrains. We further present the first benchmark for long-horizon
mobile manipulation, evaluating diverse indoor and outdoor scenarios. Through
successful sim-to-real transfer, we demonstrate the system's generalization and
robustness in real-world deployments, underscoring the practicality of legged
manipulators in unstructured environments. Our work advances the feasibility of
generalized robotic assistants capable of complex, dynamic tasks. Our project
page: https://kaijwang.github.io/odyssey.github.io/

</details>


### [145] [BigTokDetect: A Clinically-Informed Vision-Language Model Framework for Detecting Pro-Bigorexia Videos on TikTok](https://arxiv.org/abs/2508.06515)
*Minh Duc Chu,Kshitij Pawar,Zihao He,Roxanna Sharifi,Ross Sonnenblick,Magdalayna Curry,Laura D'Adamo,Lindsay Young,Stuart B Murray,Kristina Lerman*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了BigTokDetect框架，用于检测TikTok上的pro-bigorexia有害内容，并创建了首个专家标注的多模态数据集BigTok。通过微调视觉语言模型，实现了高准确率的多模态分类。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上pro-bigorexia有害内容难以通过传统文本检测系统识别，亟需多模态检测方法。

Method: 开发BigTokDetect框架，使用专家标注的多模态数据集BigTok，并通过微调视觉语言模型进行分类。

Result: 在主要类别分类上达到0.829%准确率，子类别检测达到0.690%，多模态融合比纯文本方法性能提升5-10%。

Conclusion: 研究为多模态有害内容检测设立了新基准，提供了可扩展的内容审核工具和方法框架。

Abstract: Social media platforms increasingly struggle to detect harmful content that
promotes muscle dysmorphic behaviors, particularly pro-bigorexia content that
disproportionately affects adolescent males. Unlike traditional eating disorder
detection focused on the "thin ideal," pro-bigorexia material masquerades as
legitimate fitness content through complex multimodal combinations of visual
displays, coded language, and motivational messaging that evade text-based
detection systems. We address this challenge by developing BigTokDetect, a
clinically-informed detection framework for identifying pro-bigorexia content
on TikTok. We introduce BigTok, the first expert-annotated multimodal dataset
of over 2,200 TikTok videos labeled by clinical psychologists and psychiatrists
across five primary categories spanning body image, nutrition, exercise,
supplements, and masculinity. Through a comprehensive evaluation of
state-of-the-art vision language models, we achieve 0.829% accuracy on primary
category classification and 0.690% on subcategory detection via domain-specific
finetuning. Our ablation studies demonstrate that multimodal fusion improves
performance by 5-10% over text-only approaches, with video features providing
the most discriminative signals. These findings establish new benchmarks for
multimodal harmful content detection and provide both the computational tools
and methodological framework needed for scalable content moderation in
specialized mental health domains.

</details>


### [146] [A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition](https://arxiv.org/abs/2508.06528)
*Xiuliang Zhang,Tadiwa Elisha Nyamasvisva,Chuntao Liu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种结合3D CNN和Transformer的混合框架，用于视频行为识别，解决了传统方法在长程依赖和高计算成本上的问题。


<details>
  <summary>Details</summary>
Motivation: 视频行为识别在公共安全等领域至关重要，但传统3D CNN难以建模长程依赖，而Transformer计算成本高。

Method: 混合框架中，3D CNN提取低层时空特征，Transformer捕获长程依赖，通过融合机制整合两者。

Result: 在基准数据集上表现优于传统3D CNN和独立Transformer，识别精度更高且复杂度可控。

Conclusion: 混合框架为视频行为识别提供了高效且可扩展的解决方案。

Abstract: Video-based behavior recognition is essential in fields such as public
safety, intelligent surveillance, and human-computer interaction. Traditional
3D Convolutional Neural Network (3D CNN) effectively capture local
spatiotemporal features but struggle with modeling long-range dependencies.
Conversely, Transformers excel at learning global contextual information but
face challenges with high computational costs. To address these limitations, we
propose a hybrid framework combining 3D CNN and Transformer architectures. The
3D CNN module extracts low-level spatiotemporal features, while the Transformer
module captures long-range temporal dependencies, with a fusion mechanism
integrating both representations. Evaluated on benchmark datasets, the proposed
model outperforms traditional 3D CNN and standalone Transformers, achieving
higher recognition accuracy with manageable complexity. Ablation studies
further validate the complementary strengths of the two modules. This hybrid
framework offers an effective and scalable solution for video-based behavior
recognition.

</details>


### [147] [RMT-PPAD: Real-time Multi-task Learning for Panoptic Perception in Autonomous Driving](https://arxiv.org/abs/2508.06529)
*Jiayuan Wang,Q. M. Jonathan Wu,Katsuya Suto,Ning Zhang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于Transformer的多任务模型RMT-PPAD，用于自动驾驶中的目标检测、可行驶区域分割和车道线分割，通过轻量级模块和自适应解码器优化性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要高精度和实时性的全景驾驶感知，现有方法在多任务处理中存在负迁移和标签不一致问题。

Method: 设计了门控适配器模块自适应融合共享和任务特定特征，并引入自适应分割解码器自动学习多尺度特征权重。

Result: 在BDD100K数据集上，RMT-PPAD在目标检测、可行驶区域分割和车道线分割任务中均达到SOTA性能，推理速度为32.6 FPS。

Conclusion: RMT-PPAD通过优化多任务处理和标签一致性，实现了高效且稳定的自动驾驶感知性能。

Abstract: Autonomous driving systems rely on panoptic driving perception that requires
both precision and real-time performance. In this work, we propose RMT-PPAD, a
real-time, transformer-based multi-task model that jointly performs object
detection, drivable area segmentation, and lane line segmentation. We introduce
a lightweight module, a gate control with an adapter to adaptively fuse shared
and task-specific features, effectively alleviating negative transfer between
tasks. Additionally, we design an adaptive segmentation decoder to learn the
weights over multi-scale features automatically during the training stage. This
avoids the manual design of task-specific structures for different segmentation
tasks. We also identify and resolve the inconsistency between training and
testing labels in lane line segmentation. This allows fairer evaluation.
Experiments on the BDD100K dataset demonstrate that RMT-PPAD achieves
state-of-the-art results with mAP50 of 84.9% and Recall of 95.4% for object
detection, mIoU of 92.6% for drivable area segmentation, and IoU of 56.8% and
accuracy of 84.7% for lane line segmentation. The inference speed reaches 32.6
FPS. Moreover, we introduce real-world scenarios to evaluate RMT-PPAD
performance in practice. The results show that RMT-PPAD consistently delivers
stable performance. The source codes and pre-trained models are released at
https://github.com/JiayuanWang-JW/RMT-PPAD.

</details>


### [148] [MILD: Multi-Layer Diffusion Strategy for Complex and Precise Multi-IP Aware Human Erasing](https://arxiv.org/abs/2508.06543)
*Jinghan Yu,Zhiyuan Ma,Yue Ma,Kaiqi Liu,Yuhan Wang,Jianjun Li*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为MILD的新方法，用于解决复杂多实例场景下的人类擦除任务，通过分层扩散和空间解耦技术显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂多实例场景（如人类遮挡、物体纠缠和背景干扰）中表现不佳，主要由于数据集限制和缺乏空间解耦能力。

Method: 提出Multi-Layer Diffusion (MILD)策略，将生成过程分解为语义分离的路径，并引入Human Morphology Guidance和Spatially-Modulated Attention。

Result: MILD在挑战性的人类擦除基准测试中优于现有方法。

Conclusion: MILD通过分层生成和空间解耦技术有效解决了复杂场景中的问题。

Abstract: Recent years have witnessed the success of diffusion models in
image-customized tasks. Prior works have achieved notable progress on
human-oriented erasing using explicit mask guidance and semantic-aware
inpainting. However, they struggle under complex multi-IP scenarios involving
human-human occlusions, human-object entanglements, and background
interferences. These challenges are mainly due to: 1) Dataset limitations, as
existing datasets rarely cover dense occlusions, camouflaged backgrounds, and
diverse interactions; 2) Lack of spatial decoupling, where foreground instances
cannot be effectively disentangled, limiting clean background restoration. In
this work, we introduce a high-quality multi-IP human erasing dataset with
diverse pose variations and complex backgrounds. We then propose Multi-Layer
Diffusion (MILD), a novel strategy that decomposes generation into semantically
separated pathways for each instance and the background. To enhance
human-centric understanding, we introduce Human Morphology Guidance,
integrating pose, parsing, and spatial relations. We further present
Spatially-Modulated Attention to better guide attention flow. Extensive
experiments show that MILD outperforms state-of-the-art methods on challenging
human erasing benchmarks.

</details>


### [149] [Static and Plugged: Make Embodied Evaluation Simple](https://arxiv.org/abs/2508.06553)
*Jiahao Xiao,Jianbo Zhang,BoWen Yan,Shengyu Guo,Tongrui Ye,Kaiwei Zhang,Zicheng Zhang,Xiaohong Liu,Zhengxue Cheng,Lei Fan,Chuyi Li,Guangtao Zhai*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了StaticEmbodiedBench，一个基于静态场景表示的评估基准，用于高效、统一地评估具身智能。


<details>
  <summary>Details</summary>
Motivation: 当前具身智能评估依赖昂贵且难以扩展的交互式模拟或真实环境，亟需一种高效、统一的解决方案。

Method: 设计了StaticEmbodiedBench，覆盖42个场景和8个核心维度，支持通过简单接口进行可扩展的评估。

Result: 评估了19个视觉语言模型和11个视觉语言动作模型，并发布了首个统一的静态排行榜。

Conclusion: StaticEmbodiedBench为具身智能提供了高效、统一的评估工具，并发布了部分样本以促进研究发展。

Abstract: Embodied intelligence is advancing rapidly, driving the need for efficient
evaluation. Current benchmarks typically rely on interactive simulated
environments or real-world setups, which are costly, fragmented, and hard to
scale. To address this, we introduce StaticEmbodiedBench, a plug-and-play
benchmark that enables unified evaluation using static scene representations.
Covering 42 diverse scenarios and 8 core dimensions, it supports scalable and
comprehensive assessment through a simple interface. Furthermore, we evaluate
19 Vision-Language Models (VLMs) and 11 Vision-Language-Action models (VLAs),
establishing the first unified static leaderboard for Embodied intelligence.
Moreover, we release a subset of 200 samples from our benchmark to accelerate
the development of embodied intelligence.

</details>


### [150] [From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets](https://arxiv.org/abs/2508.06556)
*Sarina Penquitt,Jonathan Klees,Rinor Cakaj,Daniel Kondermann,Matthias Rottmann,Lars Schmarje*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种半自动化的标签错误修正框架REC✓D，通过结合现有错误检测方法和众包微任务，系统性提升数据集标签质量。


<details>
  <summary>Details</summary>
Motivation: 现有数据集中的标签错误（如缺失、分类错误或定位不准确）严重影响训练和评估结果，但目前缺乏系统性修正方法。

Method: REC✓D框架结合现有错误检测器和众包微任务，通过多标注者独立验证候选边界框，聚合响应以估计模糊性并改进标签质量。

Result: 在KITTI数据集中，REC✓D发现至少24%的原始标注存在缺失或不准确问题，并生成高质量修正标注。

Conclusion: REC✓D显著提升标签修正效率，但现有方法仍遗漏大量错误，需进一步研究。

Abstract: Object detection has advanced rapidly in recent years, driven by increasingly
large and diverse datasets. However, label errors, defined as missing labels,
incorrect classification or inaccurate localization, often compromise the
quality of these datasets. This can have a significant impact on the outcomes
of training and benchmark evaluations. Although several methods now exist for
detecting label errors in object detection datasets, they are typically
validated only on synthetic benchmarks or limited manual inspection. How to
correct such errors systemically and at scale therefore remains an open
problem. We introduce a semi-automated framework for label-error correction
called REC$\checkmark$D (Rechecked). Building on existing detectors, the
framework pairs their error proposals with lightweight, crowd-sourced
microtasks. These tasks enable multiple annotators to independently verify each
candidate bounding box, and their responses are aggregated to estimate
ambiguity and improve label quality. To demonstrate the effectiveness of
REC$\checkmark$D, we apply it to the class pedestrian in the KITTI dataset. Our
crowdsourced review yields high-quality corrected annotations, which indicate a
rate of at least 24% of missing and inaccurate annotations in original
annotations. This validated set will be released as a new real-world benchmark
for label error detection and correction. We show that current label error
detection methods, when combined with our correction framework, can recover
hundreds of errors in the time it would take a human to annotate bounding boxes
from scratch. However, even the best methods still miss up to 66% of the true
errors and with low quality labels introduce more errors than they find. This
highlights the urgent need for further research, now enabled by our released
benchmark.

</details>


### [151] [On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications](https://arxiv.org/abs/2508.06558)
*Simon Baur,Alexandra Benova,Emilio Dolgener Cantú,Jackie Ma*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种多模态特权知识蒸馏（MMPKD）方法，利用训练时额外的模态数据指导单模态视觉模型，提升注意力图的零样本能力，但效果不跨域。


<details>
  <summary>Details</summary>
Motivation: 临床实践中需要多模态数据支持决策，但推理时可能缺失某些模态。研究旨在利用训练时额外的模态数据提升单模态模型的性能。

Method: 提出MMPKD方法，使用文本和表格元数据作为教师模型，指导视觉Transformer学生模型。实验基于胸部X光（MIMIC-CXR）和乳腺X光（CBIS-DDSM）数据集。

Result: MMPKD提升了注意力图的零样本定位能力，但效果不跨域。

Conclusion: MMPKD在单模态模型上有效，但跨域泛化能力有限。

Abstract: Deploying deep learning models in clinical practice often requires leveraging
multiple data modalities, such as images, text, and structured data, to achieve
robust and trustworthy decisions. However, not all modalities are always
available at inference time. In this work, we propose multimodal privileged
knowledge distillation (MMPKD), a training strategy that utilizes additional
modalities available solely during training to guide a unimodal vision model.
Specifically, we used a text-based teacher model for chest radiographs
(MIMIC-CXR) and a tabular metadata-based teacher model for mammography
(CBIS-DDSM) to distill knowledge into a vision transformer student model. We
show that MMPKD can improve the resulting attention maps' zero-shot
capabilities of localizing ROI in input images, while this effect does not
generalize across domains, as contrarily suggested by prior research.

</details>


### [152] [ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos](https://arxiv.org/abs/2508.06570)
*Mohammad Zia Ur Rehman,Anukriti Bhatnagar,Omkar Kabde,Shubhi Bansal,Nagendra Kumar*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种用于视频中隐含仇恨言论检测的新数据集ImpliHateVid，并设计了一个两阶段对比学习框架，结合多模态特征提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于文本和图像中的仇恨言论检测，视频领域的隐含仇恨言论检测尚未充分探索。

Method: 提出两阶段对比学习框架：第一阶段训练模态特定编码器（音频、文本、图像），第二阶段通过对比学习训练跨模态编码器，并结合情感、情绪和字幕特征。

Result: 在ImpliHateVid和HateMM数据集上验证了方法的有效性，证明了多模态对比学习在视频仇恨内容检测中的优势。

Conclusion: 论文填补了视频隐含仇恨言论检测的空白，提出的数据集和方法为未来研究提供了重要基础。

Abstract: The existing research has primarily focused on text and image-based hate
speech detection, video-based approaches remain underexplored. In this work, we
introduce a novel dataset, ImpliHateVid, specifically curated for implicit hate
speech detection in videos. ImpliHateVid consists of 2,009 videos comprising
509 implicit hate videos, 500 explicit hate videos, and 1,000 non-hate videos,
making it one of the first large-scale video datasets dedicated to implicit
hate detection. We also propose a novel two-stage contrastive learning
framework for hate speech detection in videos. In the first stage, we train
modality-specific encoders for audio, text, and image using contrastive loss by
concatenating features from the three encoders. In the second stage, we train
cross-encoders using contrastive learning to refine multimodal representations.
Additionally, we incorporate sentiment, emotion, and caption-based features to
enhance implicit hate detection. We evaluate our method on two datasets,
ImpliHateVid for implicit hate speech detection and another dataset for general
hate speech detection in videos, HateMM dataset, demonstrating the
effectiveness of the proposed multimodal contrastive learning for hateful
content detection in videos and the significance of our dataset.

</details>


### [153] [ContextGuard-LVLM: Enhancing News Veracity through Fine-grained Cross-modal Contextual Consistency Verification](https://arxiv.org/abs/2508.06623)
*Sihan Ma,Qiming Wu,Ruotong Jiang,Frank Burns*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出ContextGuard-LVLM框架，基于视觉-语言大模型（LVLM），通过多阶段上下文推理机制和强化/对抗学习，解决细粒度跨模态一致性（FCCC）问题，显著优于现有零样本基线。


<details>
  <summary>Details</summary>
Motivation: 数字新闻媒体的普及需要验证内容真实性，尤其是视觉与文本信息的细粒度一致性。传统方法难以解决FCCC问题，需更深入的跨模态对齐。

Method: 基于LVLM构建ContextGuard-LVLM框架，结合多阶段上下文推理和强化/对抗学习，扩展并标注三个数据集，引入CTXT实体类型。

Result: ContextGuard-LVLM在细粒度一致性任务中显著优于InstructBLIP和LLaVA 1.5，尤其在复杂逻辑推理和上下文理解上表现优异，且对扰动更鲁棒。

Conclusion: ContextGuard-LVLM能有效检测复杂上下文脱节，优于现有方法，适用于新闻真实性验证。

Abstract: The proliferation of digital news media necessitates robust methods for
verifying content veracity, particularly regarding the consistency between
visual and textual information. Traditional approaches often fall short in
addressing the fine-grained cross-modal contextual consistency (FCCC) problem,
which encompasses deeper alignment of visual narrative, emotional tone, and
background information with text, beyond mere entity matching. To address this,
we propose ContextGuard-LVLM, a novel framework built upon advanced
Vision-Language Large Models (LVLMs) and integrating a multi-stage contextual
reasoning mechanism. Our model is uniquely enhanced through reinforced or
adversarial learning paradigms, enabling it to detect subtle contextual
misalignments that evade zero-shot baselines. We extend and augment three
established datasets (TamperedNews-Ent, News400-Ent, MMG-Ent) with new
fine-grained contextual annotations, including "contextual sentiment," "visual
narrative theme," and "scene-event logical coherence," and introduce a
comprehensive CTXT (Contextual Coherence) entity type. Extensive experiments
demonstrate that ContextGuard-LVLM consistently outperforms state-of-the-art
zero-shot LVLM baselines (InstructBLIP and LLaVA 1.5) across nearly all
fine-grained consistency tasks, showing significant improvements in complex
logical reasoning and nuanced contextual understanding. Furthermore, our model
exhibits superior robustness to subtle perturbations and a higher agreement
rate with human expert judgments on challenging samples, affirming its efficacy
in discerning sophisticated forms of context detachment.

</details>


### [154] [VL-MedGuide: A Visual-Linguistic Large Model for Intelligent and Explainable Skin Disease Auxiliary Diagnosis](https://arxiv.org/abs/2508.06624)
*Kexin Yu,Zihan Xu,Jialei Xie,Carter Adams*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出VL-MedGuide框架，利用视觉-语言大模型（LVLMs）进行皮肤病的智能辅助诊断，实现高性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决皮肤病诊断中视觉特征复杂多样及现有模型缺乏可解释性的问题。

Method: 采用两阶段框架：多模态概念感知模块和可解释疾病推理模块，结合提示工程和链式思维提示。

Result: 在Derm7pt数据集上达到疾病诊断（83.55% BACC）和概念检测（76.10% BACC）的SOTA性能。

Conclusion: VL-MedGuide通过可解释的诊断结果提升了AI在皮肤病临床实践中的实用性。

Abstract: Accurate diagnosis of skin diseases remains a significant challenge due to
the complex and diverse visual features present in dermatoscopic images, often
compounded by a lack of interpretability in existing purely visual diagnostic
models. To address these limitations, this study introduces VL-MedGuide
(Visual-Linguistic Medical Guide), a novel framework leveraging the powerful
multi-modal understanding and reasoning capabilities of Visual-Language Large
Models (LVLMs) for intelligent and inherently interpretable auxiliary diagnosis
of skin conditions. VL-MedGuide operates in two interconnected stages: a
Multi-modal Concept Perception Module, which identifies and linguistically
describes dermatologically relevant visual features through sophisticated
prompt engineering, and an Explainable Disease Reasoning Module, which
integrates these concepts with raw visual information via Chain-of-Thought
prompting to provide precise disease diagnoses alongside transparent
rationales. Comprehensive experiments on the Derm7pt dataset demonstrate that
VL-MedGuide achieves state-of-the-art performance in both disease diagnosis
(83.55% BACC, 80.12% F1) and concept detection (76.10% BACC, 67.45% F1),
surpassing existing baselines. Furthermore, human evaluations confirm the high
clarity, completeness, and trustworthiness of its generated explanations,
bridging the gap between AI performance and clinical utility by offering
actionable, explainable insights for dermatological practice.

</details>


### [155] [Learning More by Seeing Less: Line Drawing Pretraining for Efficient, Transferable, and Human-Aligned Vision](https://arxiv.org/abs/2508.06696)
*Tianqin Li,George Liu,Tai Sing Lee*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出用线描作为结构优先的预训练模态，以生成更紧凑和泛化的视觉表示。实验表明，线描预训练模型在分类、检测和分割任务中表现更优，且具有更低的内在维度。


<details>
  <summary>Details</summary>
Motivation: 现代视觉系统依赖冗余的视觉输入，而人类能轻松理解稀疏的线描。研究旨在探索结构优先的视觉学习是否能提升效率和泛化能力。

Method: 使用线描作为预训练模态，提出无监督方法“学习绘制”，并验证其在分类、检测和分割任务中的效果。

Result: 线描预训练模型表现出更强的形状偏好、更集中的注意力、更高的数据效率，且表示更易压缩。

Conclusion: 结构优先的视觉学习能提升效率、泛化能力和人类对齐的归纳偏差，为构建更鲁棒的视觉系统提供策略。

Abstract: Despite remarkable progress in computer vision, modern recognition systems
remain limited by their dependence on rich, redundant visual inputs. In
contrast, humans can effortlessly understand sparse, minimal representations
like line drawings - suggesting that structure, rather than appearance,
underlies efficient visual understanding. In this work, we propose using line
drawings as a structure-first pretraining modality to induce more compact and
generalizable visual representations. We show that models pretrained on line
drawings develop stronger shape bias, more focused attention, and greater data
efficiency across classification, detection, and segmentation tasks. Notably,
these models also exhibit lower intrinsic dimensionality, requiring
significantly fewer principal components to capture representational variance -
echoing the similar observation in low dimensional efficient representation in
the brain. Beyond performance improvements, line drawing pretraining produces
more compressible representations, enabling better distillation into
lightweight student models. Students distilled from line-pretrained teachers
consistently outperform those trained from color-supervised teachers,
highlighting the benefits of structurally compact knowledge. Finally, we
demonstrate that the pretraining with line-drawing can also be extended to
unsupervised setting via our proposed method "learning to draw". Together, our
results support the view that structure-first visual learning fosters
efficiency, generalization, and human-aligned inductive biases - offering a
simple yet powerful strategy for building more robust and adaptable vision
systems.

</details>


### [156] [MMFformer: Multimodal Fusion Transformer Network for Depression Detection](https://arxiv.org/abs/2508.06701)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

Relevance: 40.0

TL;DR: MMFformer是一种多模态抑郁症检测网络，通过从社交媒体信息中提取时空模式，结合视频和音频数据，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 抑郁症的早期检测对治疗至关重要，但传统方法依赖主观评估。社交媒体数据提供了新的检测途径，但多模态信息的融合和时空特征提取是挑战。

Method: 采用带有残差连接的Transformer网络提取视频空间特征，利用Transformer编码器捕捉音频时间动态，并通过晚期和中期融合策略整合多模态特征。

Result: 在两个大规模抑郁症检测数据集上，MMFformer显著优于现有方法，F1-Score分别提升13.92%和7.74%。

Conclusion: MMFformer在多模态抑郁症检测中表现出色，为社交媒体数据的分析提供了有效工具。

Abstract: Depression is a serious mental health illness that significantly affects an
individual's well-being and quality of life, making early detection crucial for
adequate care and treatment. Detecting depression is often difficult, as it is
based primarily on subjective evaluations during clinical interviews. Hence,
the early diagnosis of depression, thanks to the content of social networks,
has become a prominent research area. The extensive and diverse nature of
user-generated information poses a significant challenge, limiting the accurate
extraction of relevant temporal information and the effective fusion of data
across multiple modalities. This paper introduces MMFformer, a multimodal
depression detection network designed to retrieve depressive spatio-temporal
high-level patterns from multimodal social media information. The transformer
network with residual connections captures spatial features from videos, and a
transformer encoder is exploited to design important temporal dynamics in
audio. Moreover, the fusion architecture fused the extracted features through
late and intermediate fusion strategies to find out the most relevant
intermodal correlations among them. Finally, the proposed network is assessed
on two large-scale depression detection datasets, and the results clearly
reveal that it surpasses existing state-of-the-art approaches, improving the
F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is
made available publicly at
https://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.

</details>


### [157] [Restage4D: Reanimating Deformable 3D Reconstruction from a Single Video](https://arxiv.org/abs/2508.06715)
*Jixuan He,Chieh Hubert Lin,Lu Qi,Ming-Hsuan Yang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为Restage4D的方法，利用真实视频的运动先验生成物理一致的4D内容，通过视频重放训练策略和几何保持管道改进合成运动的几何一致性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像和图像到视频生成模型在捕捉物理真实性和运动动态方面表现不足，而真实视频能提供物理基础的几何和运动线索。

Method: 提出Restage4D，采用视频重放训练策略，结合遮挡感知刚性损失和去遮挡回溯机制，提升几何一致性。

Result: 在DAVIS和PointOdyssey数据集上验证，展示了改进的几何一致性、运动质量和3D跟踪性能。

Conclusion: Restage4D不仅保留了可变形结构，还能自动纠正生成模型引入的错误，展示了视频先验在4D重演任务中的潜力。

Abstract: Creating deformable 3D content has gained increasing attention with the rise
of text-to-image and image-to-video generative models. While these models
provide rich semantic priors for appearance, they struggle to capture the
physical realism and motion dynamics needed for authentic 4D scene synthesis.
In contrast, real-world videos can provide physically grounded geometry and
articulation cues that are difficult to hallucinate. One question is raised:
\textit{Can we generate physically consistent 4D content by leveraging the
motion priors of the real-world video}? In this work, we explore the task of
reanimating deformable 3D scenes from a single video, using the original
sequence as a supervisory signal to correct artifacts from synthetic motion. We
introduce \textbf{Restage4D}, a geometry-preserving pipeline for
video-conditioned 4D restaging. Our approach uses a video-rewinding training
strategy to temporally bridge a real base video and a synthetic driving video
via a shared motion representation. We further incorporate an occlusion-aware
rigidity loss and a disocclusion backtracing mechanism to improve structural
and geometry consistency under challenging motion. We validate Restage4D on
DAVIS and PointOdyssey, demonstrating improved geometry consistency, motion
quality, and 3D tracking performance. Our method not only preserves deformable
structure under novel motion, but also automatically corrects errors introduced
by generative models, revealing the potential of video prior in 4D restaging
task. Source code and trained models will be released.

</details>


### [158] [Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification](https://arxiv.org/abs/2508.06831)
*Taha Mustapha Nehdi,Nairouz Mrabah,Atif Belal,Marco Pedersoli,Eric Granger*

Main category: cs.CV

Relevance: 40.0

TL;DR: SAGE-reID是一种高效的多源域自适应方法，通过低秩适配器和轻量级门控网络实现跨域知识迁移，减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决多源域自适应（MSDA）方法中参数和计算成本高的问题，同时保持高准确性和鲁棒性。

Method: 使用源自由UDA训练低秩适配器（LoRA），并通过门控网络动态融合适配器，实现高效知识迁移。

Result: 在Market-1501、DukeMTMC-reID和MSMT17基准测试中表现优于现有方法，且计算高效。

Conclusion: SAGE-reID是一种计算高效、性能优越的MSDA方法，适用于跨域任务。

Abstract: Adapting person re-identification (reID) models to new target environments
remains a challenging problem that is typically addressed using unsupervised
domain adaptation (UDA) methods. Recent works show that when labeled data
originates from several distinct sources (e.g., datasets and cameras),
considering each source separately and applying multi-source domain adaptation
(MSDA) typically yields higher accuracy and robustness compared to blending the
sources and performing conventional UDA. However, state-of-the-art MSDA methods
learn domain-specific backbone models or require access to source domain data
during adaptation, resulting in significant growth in training parameters and
computational cost. In this paper, a Source-free Adaptive Gated Experts
(SAGE-reID) method is introduced for person reID. Our SAGE-reID is a
cost-effective, source-free MSDA method that first trains individual
source-specific low-rank adapters (LoRA) through source-free UDA. Next, a
lightweight gating network is introduced and trained to dynamically assign
optimal merging weights for fusion of LoRA experts, enabling effective
cross-domain knowledge transfer. While the number of backbone parameters
remains constant across source domains, LoRA experts scale linearly but remain
negligible in size (<= 2% of the backbone), reducing both the memory
consumption and risk of overfitting. Extensive experiments conducted on three
challenging benchmarks: Market-1501, DukeMTMC-reID, and MSMT17 indicate that
SAGE-reID outperforms state-of-the-art methods while being computationally
efficient.

</details>


### [159] [eMotions: A Large-Scale Dataset and Audio-Visual Fusion Network for Emotion Analysis in Short-form Videos](https://arxiv.org/abs/2508.06902)
*Xuecheng Wu,Dingkang Yang,Danlei Huang,Xinyi Yin,Yifan Wang,Jia Zhang,Jiayu Nie,Liangyu Fu,Yang Liu,Junxiao Xue,Hadi Amirpour,Wei Zhou*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了eMotions数据集和AV-CANet网络，用于短视频情感分析，解决了多模态复杂性和局部偏差问题。


<details>
  <summary>Details</summary>
Motivation: 短视频情感分析面临多模态复杂性和数据稀缺的挑战，需要新的数据集和方法。

Method: 提出eMotions数据集和AV-CANet网络，结合视频Transformer和局部-全局融合模块，优化EP-CE Loss。

Result: 在多个数据集上验证了AV-CANet的有效性，并通过消融实验分析了关键组件。

Conclusion: AV-CANet为短视频情感分析提供了新思路，数据集和代码将开源。

Abstract: Short-form videos (SVs) have become a vital part of our online routine for
acquiring and sharing information. Their multimodal complexity poses new
challenges for video analysis, highlighting the need for video emotion analysis
(VEA) within the community. Given the limited availability of SVs emotion data,
we introduce eMotions, a large-scale dataset consisting of 27,996 videos with
full-scale annotations. To ensure quality and reduce subjective bias, we
emphasize better personnel allocation and propose a multi-stage annotation
procedure. Additionally, we provide the category-balanced and test-oriented
variants through targeted sampling to meet diverse needs. While there have been
significant studies on videos with clear emotional cues (e.g., facial
expressions), analyzing emotions in SVs remains a challenging task. The
challenge arises from the broader content diversity, which introduces more
distinct semantic gaps and complicates the representations learning of
emotion-related features. Furthermore, the prevalence of audio-visual
co-expressions in SVs leads to the local biases and collective information gaps
caused by the inconsistencies in emotional expressions. To tackle this, we
propose AV-CANet, an end-to-end audio-visual fusion network that leverages
video transformer to capture semantically relevant representations. We further
introduce the Local-Global Fusion Module designed to progressively capture the
correlations of audio-visual features. Besides, EP-CE Loss is constructed to
globally steer optimizations with tripolar penalties. Extensive experiments
across three eMotions-related datasets and four public VEA datasets demonstrate
the effectiveness of our proposed AV-CANet, while providing broad insights for
future research. Moreover, we conduct ablation studies to examine the critical
components of our method. Dataset and code will be made available at Github.

</details>


### [160] [A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation](https://arxiv.org/abs/2508.06904)
*Chao Yin,Jide Li,Xiaoqiang Li*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种无需训练的实例感知提示框架（IAPF），用于解决伪装物体分割（COS）问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有训练免费的COS方法依赖粗粒度语义提示，无法有效处理多实例场景，需改进。

Method: IAPF通过多模态大语言模型生成图像特定标签，结合实例级边界框提示和自一致性投票，生成精细实例掩码。

Result: 在标准COS基准测试中，IAPF显著优于现有训练免费方法。

Conclusion: IAPF为训练免费的COS提供了一种高效且精确的解决方案。

Abstract: Camouflaged Object Segmentation (COS) remains highly challenging due to the
intrinsic visual similarity between target objects and their surroundings.
While training-based COS methods achieve good performance, their performance
degrades rapidly with increased annotation sparsity. To circumvent this
limitation, recent studies have explored training-free COS methods, leveraging
the Segment Anything Model (SAM) by automatically generating visual prompts
from a single task-generic prompt (\textit{e.g.}, "\textit{camouflaged
animal}") uniformly applied across all test images. However, these methods
typically produce only semantic-level visual prompts, causing SAM to output
coarse semantic masks and thus failing to handle scenarios with multiple
discrete camouflaged instances effectively. To address this critical
limitation, we propose a simple yet powerful \textbf{I}nstance-\textbf{A}ware
\textbf{P}rompting \textbf{F}ramework (IAPF), the first training-free COS
pipeline that explicitly converts a task-generic prompt into fine-grained
instance masks. Specifically, the IAPF comprises three steps: (1) Text Prompt
Generator, utilizing task-generic queries to prompt a Multimodal Large Language
Model (MLLM) for generating image-specific foreground and background tags; (2)
\textbf{Instance Mask Generator}, leveraging Grounding DINO to produce precise
instance-level bounding box prompts, alongside the proposed Single-Foreground
Multi-Background Prompting strategy to sample region-constrained point prompts
within each box, enabling SAM to yield a candidate instance mask; (3)
Self-consistency Instance Mask Voting, which selects the final COS prediction
by identifying the candidate mask most consistent across multiple candidate
instance masks. Extensive evaluations on standard COS benchmarks demonstrate
that the proposed IAPF significantly surpasses existing state-of-the-art
training-free COS methods.

</details>


### [161] [MultiRef: Controllable Image Generation with Multiple Visual References](https://arxiv.org/abs/2508.06905)
*Ruoxi Chen,Dongping Chen,Siyuan Wu,Sinan Wang,Shiyun Lang,Petr Sushko,Gaoyang Jiang,Yao Wan,Ranjay Krishna*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种基于多视觉参考的可控图像生成任务，并引入了MultiRef-bench评估框架和MultiRef数据集，发现现有模型在多参考条件下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前图像生成框架主要依赖单源输入（文本或单张参考图像），而设计师通常需要从多源视觉参考中获取灵感，因此需要开发更灵活的工具。

Method: 提出MultiRef-bench评估框架和RefBlend数据引擎生成合成样本，构建MultiRef数据集（38k高质量图像），并测试了多种图像-文本模型和代理框架。

Result: 现有模型在多参考条件下表现较差，最佳模型OmniGen在合成样本和真实样本中分别仅达到66.6%和79.0%的准确率。

Conclusion: 研究为开发能有效整合多源视觉灵感的工具提供了方向，数据集已公开。

Abstract: Visual designers naturally draw inspiration from multiple visual references,
combining diverse elements and aesthetic principles to create artwork. However,
current image generative frameworks predominantly rely on single-source inputs
-- either text prompts or individual reference images. In this paper, we focus
on the task of controllable image generation using multiple visual references.
We introduce MultiRef-bench, a rigorous evaluation framework comprising 990
synthetic and 1,000 real-world samples that require incorporating visual
content from multiple reference images. The synthetic samples are synthetically
generated through our data engine RefBlend, with 10 reference types and 33
reference combinations. Based on RefBlend, we further construct a dataset
MultiRef containing 38k high-quality images to facilitate further research. Our
experiments across three interleaved image-text models (i.e., OmniGen, ACE, and
Show-o) and six agentic frameworks (e.g., ChatDiT and LLM + SD) reveal that
even state-of-the-art systems struggle with multi-reference conditioning, with
the best model OmniGen achieving only 66.6% in synthetic samples and 79.0% in
real-world cases on average compared to the golden answer. These findings
provide valuable directions for developing more flexible and human-like
creative tools that can effectively integrate multiple sources of visual
inspiration. The dataset is publicly available at: https://multiref.github.io/.

</details>


### [162] [MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification](https://arxiv.org/abs/2508.06908)
*Jinhao Li,Zijian Chen,Lirong Deng,Changbo Wang,Guangtao Zhai*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出MMReID-Bench，首个多任务多模态行人重识别基准，利用多模态大语言模型（MLLMs）提升跨模态理解能力。


<details>
  <summary>Details</summary>
Motivation: 传统行人重识别模型在多模态数据中泛化能力差，MLLMs的潜力未被充分挖掘。

Method: 构建包含20,710个多模态查询和库图像的MMReID-Bench，覆盖10个任务，评估MLLMs能力。

Result: MLLMs在多模态行人重识别中表现优异，但在处理热成像和红外数据时有局限。

Conclusion: MMReID-Bench有望推动更鲁棒的多模态基础模型发展。

Abstract: Person re-identification (ReID) aims to retrieve the images of an interested
person in the gallery images, with wide applications in medical rehabilitation,
abnormal behavior detection, and public security. However, traditional person
ReID models suffer from uni-modal capability, leading to poor generalization
ability in multi-modal data, such as RGB, thermal, infrared, sketch images,
textual descriptions, etc. Recently, the emergence of multi-modal large
language models (MLLMs) shows a promising avenue for addressing this problem.
Despite this potential, existing methods merely regard MLLMs as feature
extractors or caption generators, which do not fully unleash their reasoning,
instruction-following, and cross-modal understanding capabilities. To bridge
this gap, we introduce MMReID-Bench, the first multi-task multi-modal benchmark
specifically designed for person ReID. The MMReID-Bench includes 20,710
multi-modal queries and gallery images covering 10 different person ReID tasks.
Comprehensive experiments demonstrate the remarkable capabilities of MLLMs in
delivering effective and versatile person ReID. Nevertheless, they also have
limitations in handling a few modalities, particularly thermal and infrared
data. We hope MMReID-Bench can facilitate the community to develop more robust
and generalizable multimodal foundation models for person ReID.

</details>


### [163] [Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing](https://arxiv.org/abs/2508.06916)
*Shichao Ma,Yunhe Guo,Jiahao Su,Qihe Huang,Zhengyang Zhou,Yang Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: Talk2Image是一个多代理系统，用于多轮对话场景中的交互式图像生成和编辑，解决了单代理系统的意图漂移和编辑不连贯问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成任务多关注单轮场景，难以处理多轮迭代创作任务，而现有的对话系统存在意图漂移和编辑不连贯的局限性。

Method: 提出Talk2Image系统，包含三个关键组件：对话历史意图解析、任务分解与协作执行、基于多视图评估的反馈驱动优化。

Result: 实验表明，Talk2Image在可控性、连贯性和用户满意度上优于现有基线。

Conclusion: Talk2Image通过多代理协作和反馈机制，实现了用户意图的逐步对齐和一致的图像编辑。

Abstract: Text-to-image generation tasks have driven remarkable advances in diverse
media applications, yet most focus on single-turn scenarios and struggle with
iterative, multi-turn creative tasks. Recent dialogue-based systems attempt to
bridge this gap, but their single-agent, sequential paradigm often causes
intention drift and incoherent edits. To address these limitations, we present
Talk2Image, a novel multi-agent system for interactive image generation and
editing in multi-turn dialogue scenarios. Our approach integrates three key
components: intention parsing from dialogue history, task decomposition and
collaborative execution across specialized agents, and feedback-driven
refinement based on a multi-view evaluation mechanism. Talk2Image enables
step-by-step alignment with user intention and consistent image editing.
Experiments demonstrate that Talk2Image outperforms existing baselines in
controllability, coherence, and user satisfaction across iterative image
generation and editing tasks.

</details>


### [164] [CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing](https://arxiv.org/abs/2508.06937)
*Weiyan Xie,Han Gao,Didan Deng,Kaican Li,April Hua Liu,Yongxiang Huang,Nevin L. Zhang*

Main category: cs.CV

Relevance: 40.0

TL;DR: CannyEdit是一种无需训练的框架，通过选择性Canny控制和双提示引导，解决了文本到图像模型在区域编辑中文本依从性和上下文保真度的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在区域图像编辑中难以平衡文本依从性、上下文保真度和编辑的无缝集成，因此需要一种更高效的解决方案。

Method: CannyEdit采用选择性Canny控制（保留未编辑区域细节）和双提示引导（结合局部和全局提示），实现精确编辑。

Result: CannyEdit在真实图像编辑任务中表现优于现有方法，文本依从性和上下文保真度平衡提升2.93%至10.49%，编辑无缝性显著提高。

Conclusion: CannyEdit通过创新方法解决了区域编辑中的关键挑战，为文本到图像模型提供了更高效的编辑工具。

Abstract: Recent advances in text-to-image (T2I) models have enabled training-free
regional image editing by leveraging the generative priors of foundation
models. However, existing methods struggle to balance text adherence in edited
regions, context fidelity in unedited areas, and seamless integration of edits.
We introduce CannyEdit, a novel training-free framework that addresses these
challenges through two key innovations: (1) Selective Canny Control, which
masks the structural guidance of Canny ControlNet in user-specified editable
regions while strictly preserving details of the source images in unedited
areas via inversion-phase ControlNet information retention. This enables
precise, text-driven edits without compromising contextual integrity. (2)
Dual-Prompt Guidance, which combines local prompts for object-specific edits
with a global target prompt to maintain coherent scene interactions. On
real-world image editing tasks (addition, replacement, removal), CannyEdit
outperforms prior methods like KV-Edit, achieving a 2.93 to 10.49 percent
improvement in the balance of text adherence and context fidelity. In terms of
editing seamlessness, user studies reveal only 49.2 percent of general users
and 42.0 percent of AIGC experts identified CannyEdit's results as AI-edited
when paired with real images without edits, versus 76.08 to 89.09 percent for
competitor methods.

</details>


### [165] [SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work](https://arxiv.org/abs/2508.06951)
*Harry Walsh,Ed Fish,Ozge Mercanoglu Sincan,Mohamed Ilyes Lakhal,Richard Bowden,Neil Fox,Bencie Woll,Kepeng Wu,Zecheng Li,Weichao Zhao,Haodong Wang,Wengang Zhou,Houqiang Li,Shengeng Tang,Jiayi He,Xu Wang,Ruobei Zhang,Yaxiong Wang,Lechao Cheng,Meryem Tasyurek,Tugce Kiziltepe,Hacer Yalim Keles*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文介绍了首个手语生成挑战赛，旨在通过标准化评估指标比较不同系统的性能，并发布了高质量骨架提取关键点作为基准。


<details>
  <summary>Details</summary>
Motivation: 解决手语生成领域缺乏标准化评估指标的问题，促进系统间的比较。

Method: 设计挑战赛，使用RWTH-PHOENIX-Weather-2014T数据集和自定义测试集，评估文本到姿势（T2P）翻译架构。

Result: 33名参与者提交231个解决方案，最佳团队BLEU-1得分31.40，DTW-MJE 0.0574。

Conclusion: 挑战赛和标准化评估网络的发布为手语生成领域提供了基准，促进未来研究。

Abstract: Sign Language Production (SLP) is the task of generating sign language video
from spoken language inputs. The field has seen a range of innovations over the
last few years, with the introduction of deep learning-based approaches
providing significant improvements in the realism and naturalness of generated
outputs. However, the lack of standardized evaluation metrics for SLP
approaches hampers meaningful comparisons across different systems. To address
this, we introduce the first Sign Language Production Challenge, held as part
of the third SLRTP Workshop at CVPR 2025. The competition's aims are to
evaluate architectures that translate from spoken language sentences to a
sequence of skeleton poses, known as Text-to-Pose (T2P) translation, over a
range of metrics. For our evaluation data, we use the
RWTH-PHOENIX-Weather-2014T dataset, a German Sign Language - Deutsche
Gebardensprache (DGS) weather broadcast dataset. In addition, we curate a
custom hidden test set from a similar domain of discourse. This paper presents
the challenge design and the winning methodologies. The challenge attracted 33
participants who submitted 231 solutions, with the top-performing team
achieving BLEU-1 scores of 31.40 and DTW-MJE of 0.0574. The winning approach
utilized a retrieval-based framework and a pre-trained language model. As part
of the workshop, we release a standardized evaluation network, including
high-quality skeleton extraction-based keypoints establishing a consistent
baseline for the SLP field, which will enable future researchers to compare
their work against a broader range of methods.

</details>


### [166] [Adversarial Video Promotion Against Text-to-Video Retrieval](https://arxiv.org/abs/2508.06964)
*Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Qian Li,Shuai Liu,Chao Shen*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了针对文本到视频检索（T2VR）的首个对抗性视频推广攻击（ViPro），并提出了模态细化（MoRe）方法以增强黑盒可迁移性。实验表明ViPro在白盒、灰盒和黑盒设置中均显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有T2VR攻击主要关注降低视频排名，而提升视频排名的攻击未被充分研究，这种攻击可能带来更大的财务和信息传播影响。

Method: 提出ViPro攻击方法，通过模态细化（MoRe）捕捉视觉和文本模态的细粒度交互以增强攻击效果。

Result: ViPro在白盒、灰盒和黑盒设置中平均分别超越基线30%、10%和4%。

Conclusion: 研究揭示了T2VR的潜在漏洞，提供了攻击的上下界分析，并探讨了可能的防御策略。

Abstract: Thanks to the development of cross-modal models, text-to-video retrieval
(T2VR) is advancing rapidly, but its robustness remains largely unexamined.
Existing attacks against T2VR are designed to push videos away from queries,
i.e., suppressing the ranks of videos, while the attacks that pull videos
towards selected queries, i.e., promoting the ranks of videos, remain largely
unexplored. These attacks can be more impactful as attackers may gain more
views/clicks for financial benefits and widespread (mis)information. To this
end, we pioneer the first attack against T2VR to promote videos adversarially,
dubbed the Video Promotion attack (ViPro). We further propose Modal Refinement
(MoRe) to capture the finer-grained, intricate interaction between visual and
textual modalities to enhance black-box transferability. Comprehensive
experiments cover 2 existing baselines, 3 leading T2VR models, 3 prevailing
datasets with over 10k videos, evaluated under 3 scenarios. All experiments are
conducted in a multi-target setting to reflect realistic scenarios where
attackers seek to promote the video regarding multiple queries simultaneously.
We also evaluated our attacks for defences and imperceptibility. Overall, ViPro
surpasses other baselines by over $30/10/4\%$ for white/grey/black-box settings
on average. Our work highlights an overlooked vulnerability, provides a
qualitative analysis on the upper/lower bound of our attacks, and offers
insights into potential counterplays. Code will be publicly available at
https://github.com/michaeltian108/ViPro.

</details>


### [167] [WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering](https://arxiv.org/abs/2508.06982)
*Yixin Zhu,Zuoliang Zhu,Miloš Hašan,Jian Yang,Jin Xie,Beibei Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: WeatherDiffusion是一个基于扩散模型的框架，用于自动驾驶场景中的正向和逆向渲染，支持天气和光照编辑，并通过Intrinsic map-aware attention提高渲染质量。


<details>
  <summary>Details</summary>
Motivation: 复杂天气和光照条件对自动驾驶场景的理解和重建提出了挑战，现有扩散模型难以控制和缺乏鲁棒性。

Method: 提出WeatherDiffusion框架，结合文本引导的预测本征图和Intrinsic map-aware attention技术，实现高质量逆向渲染。

Result: 在多个基准测试中优于现有方法，并提升下游任务（如目标检测和图像分割）的鲁棒性。

Conclusion: WeatherDiffusion在自动驾驶场景中表现出色，为复杂天气和光照条件下的渲染任务提供了有效解决方案。

Abstract: Forward and inverse rendering have emerged as key techniques for enabling
understanding and reconstruction in the context of autonomous driving (AD).
However, complex weather and illumination pose great challenges to this task.
The emergence of large diffusion models has shown promise in achieving
reasonable results through learning from 2D priors, but these models are
difficult to control and lack robustness. In this paper, we introduce
WeatherDiffusion, a diffusion-based framework for forward and inverse rendering
on AD scenes with various weather and lighting conditions. Our method enables
authentic estimation of material properties, scene geometry, and lighting, and
further supports controllable weather and illumination editing through the use
of predicted intrinsic maps guided by text descriptions. We observe that
different intrinsic maps should correspond to different regions of the original
image. Based on this observation, we propose Intrinsic map-aware attention
(MAA) to enable high-quality inverse rendering. Additionally, we introduce a
synthetic dataset (\ie WeatherSynthetic) and a real-world dataset (\ie
WeatherReal) for forward and inverse rendering on AD scenes with diverse
weather and lighting. Extensive experiments show that our WeatherDiffusion
outperforms state-of-the-art methods on several benchmarks. Moreover, our
method demonstrates significant value in downstream tasks for AD, enhancing the
robustness of object detection and image segmentation in challenging weather
scenarios.

</details>


### [168] [S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision](https://arxiv.org/abs/2508.06995)
*Huihui Xu,Jin Ye,Hongqiu Wang,Changkai Ji,Jiashi Lin,Ming Hu,Ziyan Huang,Ying Chen,Chenglong Ma,Tianbin Li,Lihao Liu,Junjun He,Lei Zhu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种名为UniAP的快速伪掩码算法，并基于此开发了S2-UniSeg模型，通过连续预训练和QuerySD任务，显著提升了图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有自监督图像分割模型预训练过程多阶段、耗时的伪掩码生成问题，提高效率和性能。

Method: 提出Fast Universal Agglomerative Pooling (UniAP)算法，快速生成多粒度伪掩码；设计S2-UniSeg模型，采用师生框架和QuerySD任务进行连续预训练。

Result: 在多个基准测试中显著优于现有SOTA模型，如COCO上AP+6.9，UVO上AR+11.1等，并在更大数据集上进一步验证了性能提升。

Conclusion: S2-UniSeg通过高效算法和连续预训练框架，显著提升了自监督图像分割的性能和可扩展性。

Abstract: Recent self-supervised image segmentation models have achieved promising
performance on semantic segmentation and class-agnostic instance segmentation.
However, their pretraining schedule is multi-stage, requiring a time-consuming
pseudo-masks generation process between each training epoch. This
time-consuming offline process not only makes it difficult to scale with
training dataset size, but also leads to sub-optimal solutions due to its
discontinuous optimization routine. To solve these, we first present a novel
pseudo-mask algorithm, Fast Universal Agglomerative Pooling (UniAP). Each layer
of UniAP can identify groups of similar nodes in parallel, allowing to generate
both semantic-level and instance-level and multi-granular pseudo-masks within
ens of milliseconds for one image. Based on the fast UniAP, we propose the
Scalable Self-Supervised Universal Segmentation (S2-UniSeg), which employs a
student and a momentum teacher for continuous pretraining. A novel
segmentation-oriented pretext task, Query-wise Self-Distillation (QuerySD), is
proposed to pretrain S2-UniSeg to learn the local-to-global correspondences.
Under the same setting, S2-UniSeg outperforms the SOTA UnSAM model, achieving
notable improvements of AP+6.9 on COCO, AR+11.1 on UVO, PixelAcc+4.5 on
COCOStuff-27, RQ+8.0 on Cityscapes. After scaling up to a larger 2M-image
subset of SA-1B, S2-UniSeg further achieves performance gains on all four
benchmarks. Our code and pretrained models are available at
https://github.com/bio-mlhui/S2-UniSeg

</details>


### [169] [HiMat: DiT-based Ultra-High Resolution SVBRDF Generation](https://arxiv.org/abs/2508.07011)
*Zixiong Wang,Jian Yang,Yiwei Hu,Milos Hasan,Beibei Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: HiMat是一个高效扩散框架，用于生成4K SVBRDF，通过轻量级CrossStitch模块保持多图一致性。


<details>
  <summary>Details</summary>
Motivation: 利用扩散变换器（DiT）生成高分辨率SVBRDF，解决多图对齐和一致性的挑战。

Method: 引入CrossStitch模块，轻量级卷积模块捕获图间依赖，保持DiT主干不变。

Result: 成功生成4K SVBRDF，具有结构一致性和高频细节。

Conclusion: HiMat适用于4K SVBRDF生成，并可推广至其他任务如本征分解。

Abstract: Creating highly detailed SVBRDFs is essential for 3D content creation. The
rise of high-resolution text-to-image generative models, based on diffusion
transformers (DiT), suggests an opportunity to finetune them for this task.
However, retargeting the models to produce multiple aligned SVBRDF maps instead
of just RGB images, while achieving high efficiency and ensuring consistency
across different maps, remains a challenge. In this paper, we introduce HiMat:
a memory- and computation-efficient diffusion-based framework capable of
generating native 4K-resolution SVBRDFs. A key challenge we address is
maintaining consistency across different maps in a lightweight manner, without
relying on training new VAEs or significantly altering the DiT backbone (which
would damage its prior capabilities). To tackle this, we introduce the
CrossStitch module, a lightweight convolutional module that captures inter-map
dependencies through localized operations. Its weights are initialized such
that the DiT backbone operation is unchanged before finetuning starts. HiMat
enables generation with strong structural coherence and high-frequency details.
Results with a large set of text prompts demonstrate the effectiveness of our
approach for 4K SVBRDF generation. Further experiments suggest generalization
to tasks such as intrinsic decomposition.

</details>


### [170] [TerraMAE: Learning Spatial-Spectral Representations from Hyperspectral Earth Observation Data via Adaptive Masked Autoencoders](https://arxiv.org/abs/2508.07020)
*Tanjim Bin Faruk,Abdul Matin,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

Relevance: 40.0

TL;DR: TerraMAE是一种专为高光谱图像设计的自监督编码框架，通过自适应通道分组和增强的重建损失函数，显著提升了空间-光谱信息的表示能力。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督Masked Autoencoders在处理200+波段的高光谱图像时表现不佳，无法有效利用复杂的空间-光谱相关性。

Method: 提出TerraMAE框架，包括基于统计反射特性的自适应通道分组策略和结合空间-光谱质量指标的增强重建损失函数。

Result: TerraMAE在高保真图像重建中表现出卓越的空间-光谱信息保留能力，并在作物识别、土地覆盖分类和土壤纹理预测等下游任务中表现优异。

Conclusion: TerraMAE为高光谱图像分析提供了一种高效的自监督学习框架，显著提升了表示能力和实际应用效果。

Abstract: Hyperspectral satellite imagery offers sub-30 m views of Earth in hundreds of
contiguous spectral bands, enabling fine-grained mapping of soils, crops, and
land cover. While self-supervised Masked Autoencoders excel on RGB and low-band
multispectral data, they struggle to exploit the intricate spatial-spectral
correlations in 200+ band hyperspectral images. We introduce TerraMAE, a novel
HSI encoding framework specifically designed to learn highly representative
spatial-spectral embeddings for diverse geospatial analyses. TerraMAE features
an adaptive channel grouping strategy, based on statistical reflectance
properties to capture spectral similarities, and an enhanced reconstruction
loss function that incorporates spatial and spectral quality metrics. We
demonstrate TerraMAE's effectiveness through superior spatial-spectral
information preservation in high-fidelity image reconstruction. Furthermore, we
validate its practical utility and the quality of its learned representations
through strong performance on three key downstream geospatial tasks: crop
identification, land cover classification, and soil texture prediction.

</details>


### [171] [Large Language Model Evaluated Stand-alone Attention-Assisted Graph Neural Network with Spatial and Structural Information Interaction for Precise Endoscopic Image Segmentation](https://arxiv.org/abs/2508.07028)
*Juntong Fan,Shuyi Fan,Debesh Jha,Changsheng Fang,Tieyong Zeng,Hengyong Yu,Dayang Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: FOCUS-Med是一种用于内窥镜图像中息肉分割的新方法，结合了双图卷积网络和自注意力机制，首次引入LLM进行定性评估，在多个指标上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决内窥镜图像中息肉分割的挑战，如低对比度、高光和模糊边界，以提高早期结直肠癌检测的准确性。

Method: 提出FOCUS-Med，整合双图卷积网络（Dual-GCN）捕捉空间和拓扑依赖，使用自注意力增强全局上下文，并采用多尺度融合策略。

Result: 在公开基准测试中，FOCUS-Med在五个关键指标上达到最优性能。

Conclusion: FOCUS-Med展示了在AI辅助结肠镜检查中的临床潜力。

Abstract: Accurate endoscopic image segmentation on the polyps is critical for early
colorectal cancer detection. However, this task remains challenging due to low
contrast with surrounding mucosa, specular highlights, and indistinct
boundaries. To address these challenges, we propose FOCUS-Med, which stands for
Fusion of spatial and structural graph with attentional context-aware polyp
segmentation in endoscopic medical imaging. FOCUS-Med integrates a Dual Graph
Convolutional Network (Dual-GCN) module to capture contextual spatial and
topological structural dependencies. This graph-based representation enables
the model to better distinguish polyps from background tissues by leveraging
topological cues and spatial connectivity, which are often obscured in raw
image intensities. It enhances the model's ability to preserve boundaries and
delineate complex shapes typical of polyps. In addition, a location-fused
stand-alone self-attention is employed to strengthen global context
integration. To bridge the semantic gap between encoder-decoder layers, we
incorporate a trainable weighted fast normalized fusion strategy for efficient
multi-scale aggregation. Notably, we are the first to introduce the use of a
Large Language Model (LLM) to provide detailed qualitative evaluations of
segmentation quality. Extensive experiments on public benchmarks demonstrate
that FOCUS-Med achieves state-of-the-art performance across five key metrics,
underscoring its effectiveness and clinical potential for AI-assisted
colonoscopy.

</details>


### [172] [Dynamic Pattern Alignment Learning for Pretraining Lightweight Human-Centric Vision Models](https://arxiv.org/abs/2508.07144)
*Xuanhan Wang,Huimin Deng,Ke Liu,Jun Wang,Lianli Gao,Jingkuan Song*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为DPAL的蒸馏预训练框架，用于高效训练轻量级人中心视觉模型（HVM），使其从大型HVM中获得强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决大型HVM依赖大规模预训练数据和复杂架构的问题，提升轻量级HVM的实用性。

Method: 设计了动态模式解码器（D-PaDe）和三级对齐目标，分别从全局、局部和实例关系层面对齐轻量级与大型HVM。

Result: DPAL-ViT/Ti（5M参数）在15个数据集上表现优异，泛化能力接近大型HVM（如PATH-B和Sapiens-L），并显著优于其他蒸馏方法。

Conclusion: DPAL通过动态模式对齐学习，显著提升了轻量级HVM的泛化能力，适用于多种人中心视觉任务。

Abstract: Human-centric vision models (HVMs) have achieved remarkable generalization
due to large-scale pretraining on massive person images. However, their
dependence on large neural architectures and the restricted accessibility of
pretraining data significantly limits their practicality in real-world
applications. To address this limitation, we propose Dynamic Pattern Alignment
Learning (DPAL), a novel distillation-based pretraining framework that
efficiently trains lightweight HVMs to acquire strong generalization from large
HVMs. In particular, human-centric visual perception are highly dependent on
three typical visual patterns, including global identity pattern, local shape
pattern and multi-person interaction pattern. To achieve generalizable
lightweight HVMs, we firstly design a dynamic pattern decoder (D-PaDe), acting
as a dynamic Mixture of Expert (MoE) model. It incorporates three specialized
experts dedicated to adaptively extract typical visual patterns, conditioned on
both input image and pattern queries. And then, we present three levels of
alignment objectives, which aims to minimize generalization gap between
lightweight HVMs and large HVMs at global image level, local pixel level, and
instance relation level. With these two deliberate designs, the DPAL
effectively guides lightweight model to learn all typical human visual patterns
from large HVMs, which can generalize to various human-centric vision tasks.
Extensive experiments conducted on 15 challenging datasets demonstrate the
effectiveness of the DPAL. Remarkably, when employing PATH-B as the teacher,
DPAL-ViT/Ti (5M parameters) achieves surprising generalizability similar to
existing large HVMs such as PATH-B (84M) and Sapiens-L (307M), and outperforms
previous distillation-based pretraining methods including Proteus-ViT/Ti (5M)
and TinyMiM-ViT/Ti (5M) by a large margin.

</details>


### [173] [Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2508.07146)
*Yu Liu,Zhijie Liu,Xiao Ren,You-Fu Li,He Kong*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于扩散模型的行人轨迹预测框架，结合短期和长期意图建模，通过自适应指导和残差噪声预测提高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型缺乏显式语义建模行人意图的问题，以提高预测准确性。

Method: 使用残差极坐标表示建模短期意图，基于可学习的端点预测器建模长期意图，并引入自适应指导和残差噪声预测优化扩散过程。

Result: 在ETH、UCY和SDD基准测试中表现优于现有方法。

Conclusion: 结合意图建模和优化的扩散过程能有效提升行人轨迹预测性能。

Abstract: Predicting pedestrian motion trajectories is critical for the path planning
and motion control of autonomous vehicles. Recent diffusion-based models have
shown promising results in capturing the inherent stochasticity of pedestrian
behavior for trajectory prediction. However, the absence of explicit semantic
modelling of pedestrian intent in many diffusion-based methods may result in
misinterpreted behaviors and reduced prediction accuracy. To address the above
challenges, we propose a diffusion-based pedestrian trajectory prediction
framework that incorporates both short-term and long-term motion intentions.
Short-term intent is modelled using a residual polar representation, which
decouples direction and magnitude to capture fine-grained local motion
patterns. Long-term intent is estimated through a learnable, token-based
endpoint predictor that generates multiple candidate goals with associated
probabilities, enabling multimodal and context-aware intention modelling.
Furthermore, we enhance the diffusion process by incorporating adaptive
guidance and a residual noise predictor that dynamically refines denoising
accuracy. The proposed framework is evaluated on the widely used ETH, UCY, and
SDD benchmarks, demonstrating competitive results against state-of-the-art
methods.

</details>


### [174] [CoopDiff: Anticipating 3D Human-object Interactions via Contact-consistent Decoupled Diffusion](https://arxiv.org/abs/2508.07162)
*Xiaotong Lin,Tianming Liang,Jian-Fang Hu,Kun-Yu Lin,Yulei Kang,Chunwei Tian,Jianhuang Lai,Wei-Shi Zheng*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为CoopDiff的解耦扩散框架，通过分离建模人类和物体的运动，利用接触点作为共享锚点，实现了更准确的人-物交互预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常用一个模型同时预测人类和物体的运动，忽略了它们不同的物理特性。本文旨在通过解耦建模和接触点一致性约束，提升预测效果。

Method: 采用双分支结构：人类动态分支预测结构化运动，物体动态分支处理刚体运动。通过共享接触点和一致性约束桥接两分支，并引入人类驱动模块增强一致性。

Result: 在BEHAVE和人-物交互数据集上，CoopDiff优于现有方法。

Conclusion: 解耦建模和接触点一致性显著提升了人-物交互预测的准确性。

Abstract: 3D human-object interaction (HOI) anticipation aims to predict the future
motion of humans and their manipulated objects, conditioned on the historical
context. Generally, the articulated humans and rigid objects exhibit different
motion patterns, due to their distinct intrinsic physical properties. However,
this distinction is ignored by most of the existing works, which intend to
capture the dynamics of both humans and objects within a single prediction
model. In this work, we propose a novel contact-consistent decoupled diffusion
framework CoopDiff, which employs two distinct branches to decouple human and
object motion modeling, with the human-object contact points as shared anchors
to bridge the motion generation across branches. The human dynamics branch is
aimed to predict highly structured human motion, while the object dynamics
branch focuses on the object motion with rigid translations and rotations.
These two branches are bridged by a series of shared contact points with
consistency constraint for coherent human-object motion prediction. To further
enhance human-object consistency and prediction reliability, we propose a
human-driven interaction module to guide object motion modeling. Extensive
experiments on the BEHAVE and Human-object Interaction datasets demonstrate
that our CoopDiff outperforms state-of-the-art methods.

</details>


### [175] [Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization](https://arxiv.org/abs/2508.07216)
*Songlin Li,Zhiqing Guo,Yuanman Li,Zeyu Li,Yunfeng Diao,Gaobo Yang,Liejun Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 本文提出了一种基于认知启发的多模态边界保持网络（CMB-Net），利用LLMs分析图像中的篡改区域并生成提示文本，弥补视觉信息中语义关系的不足。通过ITCAM和ITIM模块优化文本与图像特征的交互，并通过RED模块保留边界信息。实验表明CMB-Net优于现有IML模型。


<details>
  <summary>Details</summary>
Motivation: 现有图像篡改定位（IML）模型主要依赖视觉线索，忽略了内容特征的语义逻辑关系。篡改技术破坏了内容特征的内部关系，为IML提供了语义线索。

Method: 1. 利用LLMs分析篡改区域并生成提示文本；2. 提出ITCAM模块量化文本与图像特征的模糊性；3. 提出ITIM模块对齐视觉与文本特征；4. 提出RED模块保留边界信息。

Result: CMB-Net在实验中表现优于大多数现有IML模型。

Conclusion: CMB-Net通过结合LLMs和多模态交互，显著提升了IML的性能。

Abstract: The existing image manipulation localization (IML) models mainly relies on
visual cues, but ignores the semantic logical relationships between content
features. In fact, the content semantics conveyed by real images often conform
to human cognitive laws. However, image manipulation technology usually
destroys the internal relationship between content features, thus leaving
semantic clues for IML. In this paper, we propose a cognition-inspired
multimodal boundary-preserving network (CMB-Net). Specifically, CMB-Net
utilizes large language models (LLMs) to analyze manipulated regions within
images and generate prompt-based textual information to compensate for the lack
of semantic relationships in the visual information. Considering that the
erroneous texts induced by hallucination from LLMs will damage the accuracy of
IML, we propose an image-text central ambiguity module (ITCAM). It assigns
weights to the text features by quantifying the ambiguity between text and
image features, thereby ensuring the beneficial impact of textual information.
We also propose an image-text interaction module (ITIM) that aligns visual and
text features using a correlation matrix for fine-grained interaction. Finally,
inspired by invertible neural networks, we propose a restoration edge decoder
(RED) that mutually generates input and output features to preserve boundary
information in manipulated regions without loss. Extensive experiments show
that CMB-Net outperforms most existing IML models.

</details>


### [176] [Landmark Guided Visual Feature Extractor for Visual Speech Recognition with Limited Resource](https://arxiv.org/abs/2508.07233)
*Lei Yang,Junshan Jin,Mingyuan Zhang,Yi He,Bofan Chen,Shilin Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于面部关键点的视觉特征提取方法，结合时空多图卷积网络和多级唇动态融合框架，以在有限数据下提升视觉语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语音识别中因视觉干扰（如光照、皮肤纹理）和用户特定特征导致的性能下降问题，同时减少对大规模数据和计算资源的需求。

Method: 使用面部关键点作为辅助信息训练视觉特征提取器，设计时空多图卷积网络提取关键点的时空特征，并引入多级唇动态融合框架结合原始视频帧的视觉特征。

Result: 实验表明，该方法在有限数据下表现良好，并提高了模型对未见说话者的识别准确率。

Conclusion: 该方法有效减少了用户特定特征的影响，提升了视觉语音识别的鲁棒性和准确性。

Abstract: Visual speech recognition is a technique to identify spoken content in silent
speech videos, which has raised significant attention in recent years.
Advancements in data-driven deep learning methods have significantly improved
both the speed and accuracy of recognition. However, these deep learning
methods can be effected by visual disturbances, such as lightning conditions,
skin texture and other user-specific features. Data-driven approaches could
reduce the performance degradation caused by these visual disturbances using
models pretrained on large-scale datasets. But these methods often require
large amounts of training data and computational resources, making them costly.
To reduce the influence of user-specific features and enhance performance with
limited data, this paper proposed a landmark guided visual feature extractor.
Facial landmarks are used as auxiliary information to aid in training the
visual feature extractor. A spatio-temporal multi-graph convolutional network
is designed to fully exploit the spatial locations and spatio-temporal features
of facial landmarks. Additionally, a multi-level lip dynamic fusion framework
is introduced to combine the spatio-temporal features of the landmarks with the
visual features extracted from the raw video frames. Experimental results show
that this approach performs well with limited data and also improves the
model's accuracy on unseen speakers.

</details>


### [177] [ASM-UNet: Adaptive Scan Mamba Integrating Group Commonalities and Individual Variations for Fine-Grained Segmentation](https://arxiv.org/abs/2508.07237)
*Bo Wang,Mengyuan Xu,Yue Yan,Yuqun Yang,Kechen Shu,Wei Ping,Xu Tang,Wei Jiang,Zheng You*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种基于Mamba的新型架构ASM-UNet，用于医学图像中的细粒度分割（FGS），通过自适应扫描顺序解决了现有方法在个体差异上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于Mamba的模型在细粒度分割（FGS）中依赖固定扫描顺序，无法适应个体差异，限制了其临床应用。

Method: 提出ASM-UNet，引入自适应扫描分数，动态调整扫描顺序，结合群体共性和个体差异。

Result: 在ACDC、Synapse和BTMS数据集上，ASM-UNet在粗粒度和细粒度分割任务中均表现优异。

Conclusion: ASM-UNet通过动态扫描顺序提升了细粒度分割的适应性，具有临床应用潜力。

Abstract: Precise lesion resection depends on accurately identifying fine-grained
anatomical structures. While many coarse-grained segmentation (CGS) methods
have been successful in large-scale segmentation (e.g., organs), they fall
short in clinical scenarios requiring fine-grained segmentation (FGS), which
remains challenging due to frequent individual variations in small-scale
anatomical structures. Although recent Mamba-based models have advanced medical
image segmentation, they often rely on fixed manually-defined scanning orders,
which limit their adaptability to individual variations in FGS. To address
this, we propose ASM-UNet, a novel Mamba-based architecture for FGS. It
introduces adaptive scan scores to dynamically guide the scanning order,
generated by combining group-level commonalities and individual-level
variations. Experiments on two public datasets (ACDC and Synapse) and a newly
proposed challenging biliary tract FGS dataset, namely BTMS, demonstrate that
ASM-UNet achieves superior performance in both CGS and FGS tasks. Our code and
dataset are available at https://github.com/YqunYang/ASM-UNet.

</details>


### [178] [Understanding Dynamic Scenes in Ego Centric 4D Point Clouds](https://arxiv.org/abs/2508.07251)
*Junsheng Huang,Shengyu Hao,Bocheng Hu,Gaoang Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了EgoDynamic4D，一个用于动态4D场景理解的QA基准，包含丰富的标注和任务设计，并提出了一个端到端的时空推理框架。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏统一的4D标注和任务驱动的评估协议，无法支持细粒度的时空推理，尤其是物体和人的运动及其交互。

Method: 提出了EgoDynamic4D基准，包含RGB-D视频、相机位姿、实例掩码和4D边界框，设计了12个动态QA任务。提出端到端时空推理框架，结合动态和静态信息，使用实例感知特征编码、时间和相机编码等技术。

Result: 实验表明，该方法在EgoDynamic4D上优于基线，验证了多模态时间建模的有效性。

Conclusion: EgoDynamic4D和提出的框架为动态4D场景理解提供了新工具，展示了多模态时间建模的潜力。

Abstract: Understanding dynamic 4D scenes from an egocentric perspective-modeling
changes in 3D spatial structure over time-is crucial for human-machine
interaction, autonomous navigation, and embodied intelligence. While existing
egocentric datasets contain dynamic scenes, they lack unified 4D annotations
and task-driven evaluation protocols for fine-grained spatio-temporal
reasoning, especially on motion of objects and human, together with their
interactions. To address this gap, we introduce EgoDynamic4D, a novel QA
benchmark on highly dynamic scenes, comprising RGB-D video, camera poses,
globally unique instance masks, and 4D bounding boxes. We construct 927K QA
pairs accompanied by explicit Chain-of-Thought (CoT), enabling verifiable,
step-by-step spatio-temporal reasoning. We design 12 dynamic QA tasks covering
agent motion, human-object interaction, trajectory prediction, relation
understanding, and temporal-causal reasoning, with fine-grained,
multidimensional metrics. To tackle these tasks, we propose an end-to-end
spatio-temporal reasoning framework that unifies dynamic and static scene
information, using instance-aware feature encoding, time and camera encoding,
and spatially adaptive down-sampling to compress large 4D scenes into token
sequences manageable by LLMs. Experiments on EgoDynamic4D show that our method
consistently outperforms baselines, validating the effectiveness of multimodal
temporal modeling for egocentric dynamic scene understanding.

</details>


### [179] [OpenHAIV: A Framework Towards Practical Open-World Learning](https://arxiv.org/abs/2508.07270)
*Xiang Xiang,Qinhao Zhou,Zhuo Xu,Jing Ma,Jiaxin Dai,Yifan Liang,Hanlin Li*

Main category: cs.CV

Relevance: 40.0

TL;DR: OpenHAIV是一个统一框架，结合了OOD检测、新类发现和增量持续微调，以解决开放世界场景中的知识更新问题。


<details>
  <summary>Details</summary>
Motivation: 开放世界场景中，现有方法（如OOD检测和增量学习）存在局限性，无法自主更新知识或依赖监督条件。

Method: 提出OpenHAIV框架，整合OOD检测、新类发现和增量持续微调，实现模型在开放世界中的自主知识获取与更新。

Result: OpenHAIV框架成功实现了模型在开放世界环境中的知识自主更新。

Conclusion: OpenHAIV为开放世界场景提供了一种有效的解决方案，支持模型的持续学习和知识扩展。

Abstract: Substantial progress has been made in various techniques for open-world
recognition. Out-of-distribution (OOD) detection methods can effectively
distinguish between known and unknown classes in the data, while incremental
learning enables continuous model knowledge updates. However, in open-world
scenarios, these approaches still face limitations. Relying solely on OOD
detection does not facilitate knowledge updates in the model, and incremental
fine-tuning typically requires supervised conditions, which significantly
deviate from open-world settings. To address these challenges, this paper
proposes OpenHAIV, a novel framework that integrates OOD detection, new class
discovery, and incremental continual fine-tuning into a unified pipeline. This
framework allows models to autonomously acquire and update knowledge in
open-world environments. The proposed framework is available at
https://haiv-lab.github.io/openhaiv .

</details>


### [180] [BEVANet: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation](https://arxiv.org/abs/2508.07300)
*Ping-Mao Huang,I-Tien Chao,Ping-Chia Huang,Jia-Wei Liao,Yung-Yu Chuang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为BEVANet的双边高效视觉注意力网络，通过大核注意力机制（LKA）和动态适应感受野的综合核选择（CKS）机制，实现了高效的实时语义分割。


<details>
  <summary>Details</summary>
Motivation: 解决实时语义分割中高效架构设计和大感受野捕获的挑战，同时优化细节轮廓。

Method: 引入大核注意力（LKA）机制，设计BEVANet网络，结合稀疏分解大分离核注意力（SDLSKA）、综合核选择（CKS）机制和大核金字塔池化模块（DLKPPM），并通过边界引导自适应融合（BGAF）模块增强边界划分。

Result: BEVANet在实时分割中达到33 FPS，mIoU为79.3%（无预训练）和81.0%（ImageNet预训练），性能领先。

Conclusion: BEVANet通过创新的注意力机制和动态适应策略，实现了高效的实时语义分割，性能优越。

Abstract: Real-time semantic segmentation presents the dual challenge of designing
efficient architectures that capture large receptive fields for semantic
understanding while also refining detailed contours. Vision transformers model
long-range dependencies effectively but incur high computational cost. To
address these challenges, we introduce the Large Kernel Attention (LKA)
mechanism. Our proposed Bilateral Efficient Visual Attention Network (BEVANet)
expands the receptive field to capture contextual information and extracts
visual and structural features using Sparse Decomposed Large Separable Kernel
Attentions (SDLSKA). The Comprehensive Kernel Selection (CKS) mechanism
dynamically adapts the receptive field to further enhance performance.
Furthermore, the Deep Large Kernel Pyramid Pooling Module (DLKPPM) enriches
contextual features by synergistically combining dilated convolutions and large
kernel attention. The bilateral architecture facilitates frequent branch
communication, and the Boundary Guided Adaptive Fusion (BGAF) module enhances
boundary delineation by integrating spatial and semantic features under
boundary guidance. BEVANet achieves real-time segmentation at 33 FPS, yielding
79.3% mIoU without pretraining and 81.0% mIoU on Cityscapes after ImageNet
pretraining, demonstrating state-of-the-art performance. The code and model is
available at https://github.com/maomao0819/BEVANet.

</details>


### [181] [MobileViCLIP: An Efficient Video-Text Model for Mobile Devices](https://arxiv.org/abs/2508.07312)
*Min Yang,Zihan Jia,Zhilin Dai,Sheng Guo,Limin Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 本文提出了一种高效的视频-文本模型MobileViCLIP，通过时间结构重参数化技术，在移动设备上实现快速推理和零样本分类与检索。


<details>
  <summary>Details</summary>
Motivation: 现有视频预训练模型多基于高延迟的ViT架构，缺乏针对移动设备的高效设计。本文旨在填补这一空白。

Method: 将时间结构重参数化引入高效的图像-文本模型，并在大规模高质量视频-文本数据集上训练。

Result: MobileViCLIP-Small在移动设备上推理速度显著提升（55.4倍于InternVideo2-L14，6.7倍于InternVideo2-S14），零样本检索性能接近或优于对比模型。

Conclusion: MobileViCLIP是一种高效的视频-文本模型，适用于移动设备，具有快速推理和强大的零样本能力。

Abstract: Efficient lightweight neural networks are with increasing attention due to
their faster reasoning speed and easier deployment on mobile devices. However,
existing video pre-trained models still focus on the common ViT architecture
with high latency, and few works attempt to build efficient architecture on
mobile devices. This paper bridges this gap by introducing temporal structural
reparameterization into an efficient image-text model and training it on a
large-scale high-quality video-text dataset, resulting in an efficient
video-text model that can run on mobile devices with strong zero-shot
classification and retrieval capabilities, termed as MobileViCLIP. In
particular, in terms of inference speed on mobile devices, our
MobileViCLIP-Small is 55.4x times faster than InternVideo2-L14 and 6.7x faster
than InternVideo2-S14. In terms of zero-shot retrieval performance, our
MobileViCLIP-Small obtains similar performance as InternVideo2-L14 and obtains
6.9\% better than InternVideo2-S14 on MSR-VTT. The code is available at
https://github.com/MCG-NJU/MobileViCLIP.

</details>


### [182] [RORPCap: Retrieval-based Objects and Relations Prompt for Image Captioning](https://arxiv.org/abs/2508.07318)
*Jinjing Gu,Tianbao Qin,Yuanyuan Pu,Zhengpeng Zhao*

Main category: cs.CV

Relevance: 40.0

TL;DR: RORPCap提出了一种基于检索的对象和关系提示方法，用于图像描述生成，避免了传统方法的冗余检测和高训练成本，采用Mamba网络和GPT-2实现高效性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统图像描述方法中对象检测冗余、GCN构建困难和训练成本高的问题。

Method: 通过检索提取对象和关系词，结合Mamba网络映射图像嵌入，生成文本增强特征嵌入，输入GPT-2生成描述。

Result: 在MS-COCO数据集上，训练时间仅2.6小时，CIDEr和SPICE分数分别为120.5%和22.0%。

Conclusion: RORPCap在性能和效率上均优于传统方法，展示了其作为图像描述替代方案的潜力。

Abstract: Image captioning aims to generate natural language descriptions for input
images in an open-form manner. To accurately generate descriptions related to
the image, a critical step in image captioning is to identify objects and
understand their relations within the image. Modern approaches typically
capitalize on object detectors or combine detectors with Graph Convolutional
Network (GCN). However, these models suffer from redundant detection
information, difficulty in GCN construction, and high training costs. To
address these issues, a Retrieval-based Objects and Relations Prompt for Image
Captioning (RORPCap) is proposed, inspired by the fact that image-text
retrieval can provide rich semantic information for input images. RORPCap
employs an Objects and relations Extraction Model to extract object and
relation words from the image. These words are then incorporate into predefined
prompt templates and encoded as prompt embeddings. Next, a Mamba-based mapping
network is designed to quickly map image embeddings extracted by CLIP to
visual-text embeddings. Finally, the resulting prompt embeddings and
visual-text embeddings are concatenated to form textual-enriched feature
embeddings, which are fed into a GPT-2 model for caption generation. Extensive
experiments conducted on the widely used MS-COCO dataset show that the RORPCap
requires only 2.6 hours under cross-entropy loss training, achieving 120.5%
CIDEr score and 22.0% SPICE score on the "Karpathy" test split. RORPCap
achieves comparable performance metrics to detector-based and GCN-based models
with the shortest training time and demonstrates its potential as an
alternative for image captioning.

</details>


### [183] [Planner-Refiner: Dynamic Space-Time Refinement for Vision-Language Alignment in Videos](https://arxiv.org/abs/2508.07330)
*Tuyen Tran,Thao Minh Le,Quang-Hung Le,Truyen Tran*

Main category: cs.CV

Relevance: 40.0

TL;DR: Planner-Refiner框架通过迭代优化视觉元素的时空表示来缩小视频与语言间的语义鸿沟，适用于复杂语言提示的视频语言对齐任务。


<details>
  <summary>Details</summary>
Motivation: 视频与语言对齐面临语言复杂性、动态交互实体及语义鸿沟等挑战，需高效框架解决。

Method: Planner模块分解复杂语言提示为短句链，Refiner模块通过自注意力机制优化视觉表示，实现单步高效对齐。

Result: 在Referring Video Object Segmentation和Temporal Grounding任务中表现优于现有方法，尤其擅长处理复杂提示。

Conclusion: Planner-Refiner在视频语言对齐任务中具有潜力，尤其在复杂语言场景下。

Abstract: Vision-language alignment in video must address the complexity of language,
evolving interacting entities, their action chains, and semantic gaps between
language and vision. This work introduces Planner-Refiner, a framework to
overcome these challenges. Planner-Refiner bridges the semantic gap by
iteratively refining visual elements' space-time representation, guided by
language until semantic gaps are minimal. A Planner module schedules language
guidance by decomposing complex linguistic prompts into short sentence chains.
The Refiner processes each short sentence, a noun-phrase and verb-phrase pair,
to direct visual tokens' self-attention across space then time, achieving
efficient single-step refinement. A recurrent system chains these steps,
maintaining refined visual token representations. The final representation
feeds into task-specific heads for alignment generation. We demonstrate
Planner-Refiner's effectiveness on two video-language alignment tasks:
Referring Video Object Segmentation and Temporal Grounding with varying
language complexity. We further introduce a new MeViS-X benchmark to assess
models' capability with long queries. Superior performance versus
state-of-the-art methods on these benchmarks shows the approach's potential,
especially for complex prompts.

</details>


### [184] [SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal](https://arxiv.org/abs/2508.07346)
*Tingyu Yang,Jue Gong,Jinpei Guo,Wenbo Li,Yong Guo,Yulun Zhang*

Main category: cs.CV

Relevance: 40.0

TL;DR: SODiff是一种新颖的语义导向一步扩散模型，用于JPEG伪影去除，通过语义对齐的图像提示提取器和质量因子感知时间预测器，显著提升了恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在JPEG高压缩比下难以恢复复杂纹理细节，导致输出过度平滑，SODiff旨在通过语义导向的扩散模型解决这一问题。

Method: SODiff结合语义对齐图像提示提取器（SAIPE）和质量因子感知时间预测器，利用预训练扩散模型的生成先验进行高效恢复。

Result: 实验表明，SODiff在视觉质量和定量指标上均优于现有领先方法。

Conclusion: SODiff通过语义导向和自适应时间预测，显著提升了JPEG伪影去除的效果。

Abstract: JPEG, as a widely used image compression standard, often introduces severe
visual artifacts when achieving high compression ratios. Although existing deep
learning-based restoration methods have made considerable progress, they often
struggle to recover complex texture details, resulting in over-smoothed
outputs. To overcome these limitations, we propose SODiff, a novel and
efficient semantic-oriented one-step diffusion model for JPEG artifacts
removal. Our core idea is that effective restoration hinges on providing
semantic-oriented guidance to the pre-trained diffusion model, thereby fully
leveraging its powerful generative prior. To this end, SODiff incorporates a
semantic-aligned image prompt extractor (SAIPE). SAIPE extracts rich features
from low-quality (LQ) images and projects them into an embedding space
semantically aligned with that of the text encoder. Simultaneously, it
preserves crucial information for faithful reconstruction. Furthermore, we
propose a quality factor-aware time predictor that implicitly learns the
compression quality factor (QF) of the LQ image and adaptively selects the
optimal denoising start timestep for the diffusion process. Extensive
experimental results show that our SODiff outperforms recent leading methods in
both visual quality and quantitative metrics. Code is available at:
https://github.com/frakenation/SODiff

</details>


### [185] [CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization](https://arxiv.org/abs/2508.07413)
*Youqi Wang,Shunquan Tan,Rongxuan Peng,Bin Li,Jiwu Huang*

Main category: cs.CV

Relevance: 40.0

TL;DR: CLUE是一个利用LoRA调整Stable Diffusion 3（SD3）和Segment Anything Model（SAM）的框架，用于高保真伪造定位，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着图像编辑工具和生成式AI的普及，数字媒体的真实性受到威胁，需要更高效的伪造检测工具。

Method: 通过LoRA参数高效调整SD3和SAM，利用SD3的Rectified Flow机制注入噪声，并结合SAM的语义上下文和空间细节。

Result: CLUE在泛化性能和鲁棒性上显著优于现有方法，并能抵抗常见后处理攻击和社交网络干扰。

Conclusion: CLUE为伪造检测提供了高效且鲁棒的解决方案，代码已开源。

Abstract: The increasing accessibility of image editing tools and generative AI has led
to a proliferation of visually convincing forgeries, compromising the
authenticity of digital media. In this paper, in addition to leveraging
distortions from conventional forgeries, we repurpose the mechanism of a
state-of-the-art (SOTA) text-to-image synthesis model by exploiting its
internal generative process, turning it into a high-fidelity forgery
localization tool. To this end, we propose CLUE (Capture Latent Uncovered
Evidence), a framework that employs Low- Rank Adaptation (LoRA) to
parameter-efficiently reconfigure Stable Diffusion 3 (SD3) as a forensic
feature extractor. Our approach begins with the strategic use of SD3's
Rectified Flow (RF) mechanism to inject noise at varying intensities into the
latent representation, thereby steering the LoRAtuned denoising process to
amplify subtle statistical inconsistencies indicative of a forgery. To
complement the latent analysis with high-level semantic context and precise
spatial details, our method incorporates contextual features from the image
encoder of the Segment Anything Model (SAM), which is parameter-efficiently
adapted to better trace the boundaries of forged regions. Extensive evaluations
demonstrate CLUE's SOTA generalization performance, significantly outperforming
prior methods. Furthermore, CLUE shows superior robustness against common
post-processing attacks and Online Social Networks (OSNs). Code is publicly
available at https://github.com/SZAISEC/CLUE.

</details>


### [186] [VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding](https://arxiv.org/abs/2508.07493)
*Jian Chen,Ming Li,Jihyung Kil,Chenguang Wang,Tong Yu,Ryan Rossi,Tianyi Zhou,Changyou Chen,Ruiyi Zhang*

Main category: cs.CV

Relevance: 40.0

TL;DR: VisR-Bench是一个多语言视觉检索基准，用于长文档中的问答驱动多模态检索，涵盖16种语言和3种问题类型，评估了多种检索模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注英文文档检索或单页图像的多语言问答，缺乏对多语言长文档多模态检索的评估。

Method: 引入VisR-Bench基准，包含35K QA对和1.2K文档，评估文本、多模态编码器和MLLM模型的性能。

Result: MLLM显著优于文本和多模态编码器模型，但在结构化表格和低资源语言上仍有挑战。

Conclusion: VisR-Bench填补了多语言长文档多模态检索的空白，揭示了MLLM的局限性和改进方向。

Abstract: Most organizational data in this world are stored as documents, and visual
retrieval plays a crucial role in unlocking the collective intelligence from
all these documents. However, existing benchmarks focus on English-only
document retrieval or only consider multilingual question-answering on a
single-page image. To bridge this gap, we introduce VisR-Bench, a multilingual
benchmark designed for question-driven multimodal retrieval in long documents.
Our benchmark comprises over 35K high-quality QA pairs across 1.2K documents,
enabling fine-grained evaluation of multimodal retrieval. VisR-Bench spans
sixteen languages with three question types (figures, text, and tables),
offering diverse linguistic and question coverage. Unlike prior datasets, we
include queries without explicit answers, preventing models from relying on
superficial keyword matching. We evaluate various retrieval models, including
text-based methods, multimodal encoders, and MLLMs, providing insights into
their strengths and limitations. Our results show that while MLLMs
significantly outperform text-based and multimodal encoder models, they still
struggle with structured tables and low-resource languages, highlighting key
challenges in multilingual visual retrieval.

</details>


### [187] [Enhancing Reliability of Medical Image Diagnosis through Top-rank Learning with Rejection Module](https://arxiv.org/abs/2508.07528)
*Xiaotong Ji,Ryoma Bise,Seiichi Uchida*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种结合拒绝模块的top-rank学习方法，用于解决医学图像处理中的噪声标签和类别模糊问题，提高了诊断的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 医学图像诊断的准确性至关重要，但噪声标签和类别模糊实例会干扰top-rank学习的目标。

Method: 提出了一种结合拒绝模块的方法，该模块与top-rank损失协同优化，识别并减轻异常值的影响。

Result: 在医学数据集上的实验验证表明，该方法能有效检测和减轻异常值，提高诊断的可靠性和准确性。

Conclusion: 该方法通过集成拒绝模块，显著提升了top-rank学习在医学图像诊断中的性能。

Abstract: In medical image processing, accurate diagnosis is of paramount importance.
Leveraging machine learning techniques, particularly top-rank learning, shows
significant promise by focusing on the most crucial instances. However,
challenges arise from noisy labels and class-ambiguous instances, which can
severely hinder the top-rank objective, as they may be erroneously placed among
the top-ranked instances. To address these, we propose a novel approach that
enhances toprank learning by integrating a rejection module. Cooptimized with
the top-rank loss, this module identifies and mitigates the impact of outliers
that hinder training effectiveness. The rejection module functions as an
additional branch, assessing instances based on a rejection function that
measures their deviation from the norm. Through experimental validation on a
medical dataset, our methodology demonstrates its efficacy in detecting and
mitigating outliers, improving the reliability and accuracy of medical image
diagnoses.

</details>


### [188] [CoT-Pose: Chain-of-Thought Reasoning for 3D Pose Generation from Abstract Prompts](https://arxiv.org/abs/2508.07540)
*Junuk Cha,Jihyeon Kim*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种结合链式思维（CoT）推理的3D人体姿态生成框架，解决了现有模型依赖低层次提示的问题，通过数据合成管道生成抽象提示与姿态的三元组，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到姿态生成模型依赖低层次提示，而人类通常使用抽象语言描述动作，导致实际应用中的不匹配。

Method: 提出CoT-Pose框架，将CoT推理融入姿态生成过程，并设计数据合成管道生成抽象提示、详细提示和对应3D姿态的三元组。

Result: 实验表明，CoT-Pose能从抽象文本输入生成语义对齐的合理姿态。

Conclusion: 该工作强调了高层次理解在姿态生成中的重要性，为推理增强方法开辟了新方向。

Abstract: Recent advances in multi-modal large language models (MLLMs) and
chain-of-thought (CoT) reasoning have led to significant progress in image and
text generation tasks. However, the field of 3D human pose generation still
faces critical limitations. Most existing text-to-pose models rely heavily on
detailed (low-level) prompts that explicitly describe joint configurations. In
contrast, humans tend to communicate actions and intentions using abstract
(high-level) language. This mismatch results in a practical challenge for
deploying pose generation systems in real-world scenarios. To bridge this gap,
we introduce a novel framework that incorporates CoT reasoning into the pose
generation process, enabling the interpretation of abstract prompts into
accurate 3D human poses. We further propose a data synthesis pipeline that
automatically generates triplets of abstract prompts, detailed prompts, and
corresponding 3D poses for training process. Experimental results demonstrate
that our reasoning-enhanced model, CoT-Pose, can effectively generate plausible
and semantically aligned poses from abstract textual inputs. This work
highlights the importance of high-level understanding in pose generation and
opens new directions for reasoning-enhanced approach for human pose generation.

</details>


### [189] [Commentary Generation for Soccer Highlights](https://arxiv.org/abs/2508.07543)
*Chidaksh Ravuru*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文扩展了MatchVoice模型，用于足球集锦的评论生成，探索了训练配置和硬件限制的影响，并提出了整合视频-语言领域技术的需求。


<details>
  <summary>Details</summary>
Motivation: 解决足球视频内容与评论细粒度对齐的挑战，提升实时评论生成的性能。

Method: 扩展MatchVoice模型，使用GOAL数据集进行实验，评估不同训练配置和窗口大小对零样本性能的影响。

Result: MatchVoice展现出良好的泛化能力，但需整合更广泛的视频-语言技术以进一步提升性能。

Conclusion: 通过实验验证了MatchVoice的潜力，并指出未来改进方向。

Abstract: Automated soccer commentary generation has evolved from template-based
systems to advanced neural architectures, aiming to produce real-time
descriptions of sports events. While frameworks like SoccerNet-Caption laid
foundational work, their inability to achieve fine-grained alignment between
video content and commentary remains a significant challenge. Recent efforts
such as MatchTime, with its MatchVoice model, address this issue through coarse
and fine-grained alignment techniques, achieving improved temporal
synchronization. In this paper, we extend MatchVoice to commentary generation
for soccer highlights using the GOAL dataset, which emphasizes short clips over
entire games. We conduct extensive experiments to reproduce the original
MatchTime results and evaluate our setup, highlighting the impact of different
training configurations and hardware limitations. Furthermore, we explore the
effect of varying window sizes on zero-shot performance. While MatchVoice
exhibits promising generalization capabilities, our findings suggest the need
for integrating techniques from broader video-language domains to further
enhance performance. Our code is available at
https://github.com/chidaksh/SoccerCommentary.

</details>


### [190] [Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring](https://arxiv.org/abs/2508.07552)
*Ludan Zhang,Sihan Wang,Yuqi Dai,Shuofei Qiao,Lei He*

Main category: cs.CV

Relevance: 40.0

TL;DR: 该研究提出了一种基于特征图收敛分数（FMCS）的独立评估方法，用于评估自动驾驶感知和规划中的功能模块生成的特征图质量，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于端到端模型中缺乏对中间功能模块的显式监督信号，导致其机制不透明且可解释性有限，传统方法难以独立评估和训练这些模块。

Method: 研究构建了双粒度动态加权评分系统（DG-DWSS），并提出统一的定量指标——特征图质量分数，同时开发了基于CLIP的特征图质量评估网络（CLIP-FMQE-Net）。

Result: 在NuScenes数据集上的实验表明，该方法将3D目标检测性能提升了3.89%（NDS指标）。

Conclusion: 该方法有效提升了特征表示质量和整体模型性能。

Abstract: End-to-end models are emerging as the mainstream in autonomous driving
perception and planning. However, the lack of explicit supervision signals for
intermediate functional modules leads to opaque operational mechanisms and
limited interpretability, making it challenging for traditional methods to
independently evaluate and train these modules. Pioneering in the issue, this
study builds upon the feature map-truth representation similarity-based
evaluation framework and proposes an independent evaluation method based on
Feature Map Convergence Score (FMCS). A Dual-Granularity Dynamic Weighted
Scoring System (DG-DWSS) is constructed, formulating a unified quantitative
metric - Feature Map Quality Score - to enable comprehensive evaluation of the
quality of feature maps generated by functional modules. A CLIP-based Feature
Map Quality Evaluation Network (CLIP-FMQE-Net) is further developed, combining
feature-truth encoders and quality score prediction heads to enable real-time
quality analysis of feature maps generated by functional modules. Experimental
results on the NuScenes dataset demonstrate that integrating our evaluation
module into the training improves 3D object detection performance, achieving a
3.89 percent gain in NDS. These results verify the effectiveness of our method
in enhancing feature representation quality and overall model performance.

</details>


### [191] [From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users](https://arxiv.org/abs/2508.07596)
*Shahroz Tariq,Simon S. Woo,Priyanka Singh,Irena Irmalasari,Saakshi Gupta,Dev Gupta*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出DF-P2E框架，通过视觉、语义和叙述层解释，提升深度伪造检测的可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度伪造检测系统缺乏透明度和可解释性的问题，尤其针对非专家用户。

Method: 结合Grad-CAM可视化、视觉描述生成和LLM驱动的叙述细化模块。

Result: 在DF40数据集上实现竞争性检测性能，并提供高质量解释。

Conclusion: DF-P2E为可解释的深度伪造检测提供了可扩展方案，推动可信AI的发展。

Abstract: The proliferation of deepfake technologies poses urgent challenges and
serious risks to digital integrity, particularly within critical sectors such
as forensics, journalism, and the legal system. While existing detection
systems have made significant progress in classification accuracy, they
typically function as black-box models, offering limited transparency and
minimal support for human reasoning. This lack of interpretability hinders
their usability in real-world decision-making contexts, especially for
non-expert users. In this paper, we present DF-P2E (Deepfake: Prediction to
Explanation), a novel multimodal framework that integrates visual, semantic,
and narrative layers of explanation to make deepfake detection interpretable
and accessible. The framework consists of three modular components: (1) a
deepfake classifier with Grad-CAM-based saliency visualisation, (2) a visual
captioning module that generates natural language summaries of manipulated
regions, and (3) a narrative refinement module that uses a fine-tuned Large
Language Model (LLM) to produce context-aware, user-sensitive explanations. We
instantiate and evaluate the framework on the DF40 benchmark, the most diverse
deepfake dataset to date. Experiments demonstrate that our system achieves
competitive detection performance while providing high-quality explanations
aligned with Grad-CAM activations. By unifying prediction and explanation in a
coherent, human-aligned pipeline, this work offers a scalable approach to
interpretable deepfake detection, advancing the broader vision of trustworthy
and transparent AI systems in adversarial media environments.

</details>


### [192] [LaVieID: Local Autoregressive Diffusion Transformers for Identity-Preserving Video Creation](https://arxiv.org/abs/2508.07603)
*Wenhui Song,Hanhui Li,Jiehui Huang,Panwen Hu,Yuhao Cheng,Long Chen,Yiqiang Yan,Xiaodan Liang*

Main category: cs.CV

Relevance: 40.0

TL;DR: LaVieID是一种局部自回归视频扩散框架，旨在解决身份保持的文本到视频任务，通过空间和时间视角优化扩散变换器（DiTs）的身份信息保留。


<details>
  <summary>Details</summary>
Motivation: 解决扩散变换器在全局生成过程中身份信息丢失的问题，提升文本到视频生成的身份一致性。

Method: 引入局部路由器显式表示细粒度局部面部结构的潜在状态，并集成时间自回归模块以增强帧间身份一致性。

Result: LaVieID能够生成高保真个性化视频，并实现最先进的性能。

Conclusion: LaVieID通过空间和时间优化显著提升了身份保持能力，适用于高保真视频生成任务。

Abstract: In this paper, we present LaVieID, a novel \underline{l}ocal
\underline{a}utoregressive \underline{vi}d\underline{e}o diffusion framework
designed to tackle the challenging \underline{id}entity-preserving
text-to-video task. The key idea of LaVieID is to mitigate the loss of identity
information inherent in the stochastic global generation process of diffusion
transformers (DiTs) from both spatial and temporal perspectives. Specifically,
unlike the global and unstructured modeling of facial latent states in existing
DiTs, LaVieID introduces a local router to explicitly represent latent states
by weighted combinations of fine-grained local facial structures. This
alleviates undesirable feature interference and encourages DiTs to capture
distinctive facial characteristics. Furthermore, a temporal autoregressive
module is integrated into LaVieID to refine denoised latent tokens before video
decoding. This module divides latent tokens temporally into chunks, exploiting
their long-range temporal dependencies to predict biases for rectifying tokens,
thereby significantly enhancing inter-frame identity consistency. Consequently,
LaVieID can generate high-fidelity personalized videos and achieve
state-of-the-art performance. Our code and models are available at
https://github.com/ssugarwh/LaVieID.

</details>


### [193] [X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning](https://arxiv.org/abs/2508.07607)
*Jian Ma,Xujie Zhu,Zihao Pan,Qirong Peng,Xu Guo,Chen Chen,Haonan Lu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了X2Edit数据集和任务感知的MoE-LoRA训练方法，用于图像编辑任务，性能优于现有开源数据集和方法。


<details>
  <summary>Details</summary>
Motivation: 现有开源图像编辑数据集不足，且缺乏与主流生成模型兼容的插件式编辑模块。

Method: 1. 构建X2Edit数据集（3.7M高质量数据）；2. 设计基于FLUX.1的任务感知MoE-LoRA训练方法；3. 引入对比学习优化性能。

Result: 模型编辑性能优异，数据集显著优于现有开源数据集。

Conclusion: X2Edit数据集和训练方法为图像编辑任务提供了高效解决方案。

Abstract: Existing open-source datasets for arbitrary-instruction image editing remain
suboptimal, while a plug-and-play editing module compatible with
community-prevalent generative models is notably absent. In this paper, we
first introduce the X2Edit Dataset, a comprehensive dataset covering 14 diverse
editing tasks, including subject-driven generation. We utilize the
industry-leading unified image generation models and expert models to construct
the data. Meanwhile, we design reasonable editing instructions with the VLM and
implement various scoring mechanisms to filter the data. As a result, we
construct 3.7 million high-quality data with balanced categories. Second, to
better integrate seamlessly with community image generation models, we design
task-aware MoE-LoRA training based on FLUX.1, with only 8\% of the parameters
of the full model. To further improve the final performance, we utilize the
internal representations of the diffusion model and define positive/negative
samples based on image editing types to introduce contrastive learning.
Extensive experiments demonstrate that the model's editing performance is
competitive among many excellent models. Additionally, the constructed dataset
exhibits substantial advantages over existing open-source datasets. The
open-source code, checkpoints, and datasets for X2Edit can be found at the
following link: https://github.com/OPPO-Mente-Lab/X2Edit.

</details>


### [194] [Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction](https://arxiv.org/abs/2508.07624)
*Vishakha Lall,Yisi Liu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于图神经网络的后期处理流程，利用空间关系改进目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 在静态环境中，物体的空间布局通常一致，但现有目标检测模型未能有效利用这一先验，导致预测不一致或错误。

Method: 使用图神经网络（GNN）建模物体间的空间关系，修正检测异常。

Result: 实验显示，该方法显著提升检测性能，mAP@50最高提升4%。

Conclusion: 利用环境空间结构可提升目标检测系统的可靠性。

Abstract: In many real-world applications involving static environments, the spatial
layout of objects remains consistent across instances. However,
state-of-the-art object detection models often fail to leverage this spatial
prior, resulting in inconsistent predictions, missed detections, or
misclassifications, particularly in cluttered or occluded scenes. In this work,
we propose a graph-based post-processing pipeline that explicitly models the
spatial relationships between objects to correct detection anomalies in
egocentric frames. Using a graph neural network (GNN) trained on manually
annotated data, our model identifies invalid object class labels and predicts
corrected class labels based on their neighbourhood context. We evaluate our
approach both as a standalone anomaly detection and correction framework and as
a post-processing module for standard object detectors such as YOLOv7 and
RT-DETR. Experiments demonstrate that incorporating this spatial reasoning
significantly improves detection performance, with mAP@50 gains of up to 4%.
This method highlights the potential of leveraging the environment's spatial
structure to improve reliability in object detection systems.

</details>


### [195] [A Trustworthy Method for Multimodal Emotion Recognition](https://arxiv.org/abs/2508.07625)
*Junxiao Xue,Xiaozhen Liu,Jie Wang,Xuecheng Wu,Bin Wu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于不确定性估计的可信情感识别方法（TER），通过多模态置信度结合输出可信预测，并引入新评估标准衡量可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有情感识别方法通常通过复杂模型提升性能，但忽视了噪声和分布外数据的可靠性问题。

Method: 结合不确定性估计计算预测置信值，基于置信值融合多模态结果，提出可信精度和召回率等新评估标准。

Result: TER在Music-video上达到82.40%准确率，在IEMOCAP和Music-video上的可信F1分数分别为0.7511和0.9035。

Conclusion: TER通过置信模块提升了模型的可靠性和鲁棒性，在性能和可信度上均优于现有方法。

Abstract: Existing emotion recognition methods mainly focus on enhancing performance by
employing complex deep models, typically resulting in significantly higher
model complexity. Although effective, it is also crucial to ensure the
reliability of the final decision, especially for noisy, corrupted and
out-of-distribution data. To this end, we propose a novel emotion recognition
method called trusted emotion recognition (TER), which utilizes uncertainty
estimation to calculate the confidence value of predictions. TER combines the
results from multiple modalities based on their confidence values to output the
trusted predictions. We also provide a new evaluation criterion to assess the
reliability of predictions. Specifically, we incorporate trusted precision and
trusted recall to determine the trusted threshold and formulate the trusted
Acc. and trusted F1 score to evaluate the model's trusted performance. The
proposed framework combines the confidence module that accordingly endows the
model with reliability and robustness against possible noise or corruption. The
extensive experimental results validate the effectiveness of our proposed
model. The TER achieves state-of-the-art performance on the Music-video,
achieving 82.40% Acc. In terms of trusted performance, TER outperforms other
methods on the IEMOCAP and Music-video, achieving trusted F1 scores of 0.7511
and 0.9035, respectively.

</details>


### [196] [AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning](https://arxiv.org/abs/2508.07626)
*Dejie Yang,Zijing Zhao,Yang Liu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种基于类比推理的视觉机器人操纵方法（AR-VRM），通过从人类动作视频中学习手部关键点，显式模仿人类动作，解决了机器人数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法利用大规模视觉语言预训练数据，但数据与机器人任务不匹配或训练方式隐式，导致泛化能力有限。AR-VRM旨在通过显式模仿人类动作提升性能。

Method: 提出关键点视觉语言模型（VLM）预训练方案，学习人类动作知识并预测手部关键点；在机器人数据微调时，通过类比推理映射人类手部关键点到机器人组件。

Result: 在CALVIN基准测试和真实实验中表现领先，尤其在少样本场景中显著优于现有方法。

Conclusion: 显式模仿人类动作能有效解决机器人数据稀缺问题，提升泛化能力。

Abstract: Visual Robot Manipulation (VRM) aims to enable a robot to follow natural
language instructions based on robot states and visual observations, and
therefore requires costly multi-modal data. To compensate for the deficiency of
robot data, existing approaches have employed vision-language pretraining with
large-scale data. However, they either utilize web data that differs from
robotic tasks, or train the model in an implicit way (e.g., predicting future
frames at the pixel level), thus showing limited generalization ability under
insufficient robot data. In this paper, we propose to learn from large-scale
human action video datasets in an explicit way (i.e., imitating human actions
from hand keypoints), introducing Visual Robot Manipulation with Analogical
Reasoning (AR-VRM). To acquire action knowledge explicitly from human action
videos, we propose a keypoint Vision-Language Model (VLM) pretraining scheme,
enabling the VLM to learn human action knowledge and directly predict human
hand keypoints. During fine-tuning on robot data, to facilitate the robotic arm
in imitating the action patterns of human motions, we first retrieve human
action videos that perform similar manipulation tasks and have similar
historical observations , and then learn the Analogical Reasoning (AR) map
between human hand keypoints and robot components. Taking advantage of focusing
on action keypoints instead of irrelevant visual cues, our method achieves
leading performance on the CALVIN benchmark {and real-world experiments}. In
few-shot scenarios, our AR-VRM outperforms previous methods by large margins ,
underscoring the effectiveness of explicitly imitating human actions under data
scarcity.

</details>


### [197] [TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding](https://arxiv.org/abs/2508.07683)
*Chaohong Guo,Xun Mo,Yongwei Nie,Xuemiao Xu,Chao Xu,Fei Yu,Chengjiang Long*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种名为TAR-TVG的新框架，通过引入时间戳锚点来强化推理过程的监督，并结合自蒸馏训练策略提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法未能显式约束推理过程，影响最终时间预测质量，因此提出TAR-TVG以解决这一问题。

Method: 1) 引入时间戳锚点作为中间验证点；2) 自蒸馏训练策略（GRPO训练、SFT微调、GRPO优化）。

Result: 模型在性能上达到最优，同时生成可解释、可验证的推理链。

Conclusion: TAR-TVG通过显式监督和自蒸馏策略，显著提升了时间视频定位任务的效果。

Abstract: Temporal Video Grounding (TVG) aims to precisely localize video segments
corresponding to natural language queries, which is a critical capability for
long-form video understanding. Although existing reinforcement learning
approaches encourage models to generate reasoning chains before predictions,
they fail to explicitly constrain the reasoning process to ensure the quality
of the final temporal predictions. To address this limitation, we propose
Timestamp Anchor-constrained Reasoning for Temporal Video Grounding (TAR-TVG),
a novel framework that introduces timestamp anchors within the reasoning
process to enforce explicit supervision to the thought content. These anchors
serve as intermediate verification points. More importantly, we require each
reasoning step to produce increasingly accurate temporal estimations, thereby
ensuring that the reasoning process contributes meaningfully to the final
prediction. To address the challenge of low-probability anchor generation in
models (e.g., Qwen2.5-VL-3B), we develop an efficient self-distillation
training strategy: (1) initial GRPO training to collect 30K high-quality
reasoning traces containing multiple timestamp anchors, (2) supervised
fine-tuning (SFT) on distilled data, and (3) final GRPO optimization on the
SFT-enhanced model. This three-stage training strategy enables robust anchor
generation while maintaining reasoning quality. Experiments show that our model
achieves state-of-the-art performance while producing interpretable, verifiable
reasoning chains with progressively refined temporal estimations.

</details>


### [198] [Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting](https://arxiv.org/abs/2508.07723)
*Ting Xiang,Changjian Chen,Zhuo Tang,Qifeng Zhang,Fei Lyu,Li Yang,Jiapeng Zhang,Kenli Li*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出TriReWeight方法，通过三重连接样本重加权解决生成数据增强中的噪声问题，理论证明其性能不降，实验验证优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决生成数据增强中因不可控生成过程和自然语言模糊性导致的噪声问题。

Method: 提出TriReWeight，基于三重连接的样本重加权方法，理论分析三种监督方式。

Result: 实验显示TriReWeight在自然和医学图像数据集上平均优于现有方法7.9%和3.4%。

Conclusion: TriReWeight可提升生成数据增强性能，理论最优且通用性强。

Abstract: The performance of computer vision models in certain real-world applications,
such as medical diagnosis, is often limited by the scarcity of available
images. Expanding datasets using pre-trained generative models is an effective
solution. However, due to the uncontrollable generation process and the
ambiguity of natural language, noisy images may be generated. Re-weighting is
an effective way to address this issue by assigning low weights to such noisy
images. We first theoretically analyze three types of supervision for the
generated images. Based on the theoretical analysis, we develop TriReWeight, a
triplet-connection-based sample re-weighting method to enhance generative data
augmentation. Theoretically, TriReWeight can be integrated with any generative
data augmentation methods and never downgrade their performance. Moreover, its
generalization approaches the optimal in the order $O(\sqrt{d\ln (n)/n})$. Our
experiments validate the correctness of the theoretical analysis and
demonstrate that our method outperforms the existing SOTA methods by $7.9\%$ on
average over six natural image datasets and by $3.4\%$ on average over three
medical datasets. We also experimentally validate that our method can enhance
the performance of different generative data augmentation methods.

</details>


### [199] [Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion](https://arxiv.org/abs/2508.07755)
*Minseo Kim,Minchan Kwon,Dongyeun Lee,Yunho Jeon,Junmo Kim*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种无需额外信息的对比学习方法（Contrastive Inversion），用于从少量图像中提取共同概念，并通过解耦注意力微调提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖额外指导（如文本提示或空间掩码）可能导致辅助特征分离不完整，影响生成质量。

Method: 通过对比学习训练目标标记和图像辅助文本标记，提取解耦的真实语义，并应用解耦交叉注意力微调。

Result: 在概念表示和编辑方面均优于现有技术，实现了平衡的高性能。

Conclusion: Contrastive Inversion是一种高效且无需额外指导的共同概念提取方法。

Abstract: The recent demand for customized image generation raises a need for
techniques that effectively extract the common concept from small sets of
images. Existing methods typically rely on additional guidance, such as text
prompts or spatial masks, to capture the common target concept. Unfortunately,
relying on manually provided guidance can lead to incomplete separation of
auxiliary features, which degrades generation quality.In this paper, we propose
Contrastive Inversion, a novel approach that identifies the common concept by
comparing the input images without relying on additional information. We train
the target token along with the image-wise auxiliary text tokens via
contrastive learning, which extracts the well-disentangled true semantics of
the target. Then we apply disentangled cross-attention fine-tuning to improve
concept fidelity without overfitting. Experimental results and analysis
demonstrate that our method achieves a balanced, high-level performance in both
concept representation and editing, outperforming existing techniques.

</details>


### [200] [Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild](https://arxiv.org/abs/2508.07759)
*Haoran Wang,Zekun Li,Jian Zhang,Lei Qi,Yinghuan Shi*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出CAV-SAM方法，通过将参考-目标图像对的对应关系表示为伪视频，利用SAM2的iVOS能力轻量级适应下游任务，性能提升超5%。


<details>
  <summary>Details</summary>
Motivation: 现有参考分割方法依赖元学习，计算成本高，需探索更轻量级的方法。

Method: 将参考-目标图像对表示为伪视频，利用SAM2的iVOS能力，结合DBST和TTGA模块实现轻量级适应。

Result: 在广泛使用的数据集上，分割性能提升超5%。

Conclusion: CAV-SAM为视觉模型适应下游任务提供了一种高效轻量级解决方案。

Abstract: Large vision models like the Segment Anything Model (SAM) exhibit significant
limitations when applied to downstream tasks in the wild. Consequently,
reference segmentation, which leverages reference images and their
corresponding masks to impart novel knowledge to the model, emerges as a
promising new direction for adapting vision models. However, existing reference
segmentation approaches predominantly rely on meta-learning, which still
necessitates an extensive meta-training process and brings massive data and
computational cost. In this study, we propose a novel approach by representing
the inherent correspondence between reference-target image pairs as a pseudo
video. This perspective allows the latest version of SAM, known as SAM2, which
is equipped with interactive video object segmentation (iVOS) capabilities, to
be adapted to downstream tasks in a lightweight manner. We term this approach
Correspondence As Video for SAM (CAV-SAM). CAV-SAM comprises two key modules:
the Diffusion-Based Semantic Transition (DBST) module employs a diffusion model
to construct a semantic transformation sequence, while the Test-Time Geometric
Alignment (TTGA) module aligns the geometric changes within this sequence
through test-time fine-tuning. We evaluated CAVSAM on widely-used datasets,
achieving segmentation performance improvements exceeding 5% over SOTA methods.
Implementation is provided in the supplementary materials.

</details>


### [201] [Prototype-Guided Curriculum Learning for Zero-Shot Learning](https://arxiv.org/abs/2508.07771)
*Lei Wang,Shiming Chen,Guo-Sen Xie,Ziming Hong,Chaojian Yu,Qinmu Peng,Xinge You*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种原型引导的课程学习框架（CLZSL），通过PCL模块减少实例级不匹配，PUP模块动态更新语义原型，提升零样本学习效果。


<details>
  <summary>Details</summary>
Motivation: 解决零样本学习中语义原型的噪声问题，包括实例级不匹配和类级不精确，以提高知识迁移效果。

Method: 使用原型引导的课程学习（PCL）模块逐步学习样本，PUP模块动态更新语义原型。

Result: 在AWA2、SUN和CUB数据集上验证了方法的有效性。

Conclusion: CLZSL框架通过减少噪声监督，显著提升了零样本学习的性能。

Abstract: In Zero-Shot Learning (ZSL), embedding-based methods enable knowledge
transfer from seen to unseen classes by learning a visual-semantic mapping from
seen-class images to class-level semantic prototypes (e.g., attributes).
However, these semantic prototypes are manually defined and may introduce noisy
supervision for two main reasons: (i) instance-level mismatch: variations in
perspective, occlusion, and annotation bias will cause discrepancies between
individual sample and the class-level semantic prototypes; and (ii) class-level
imprecision: the manually defined semantic prototypes may not accurately
reflect the true semantics of the class. Consequently, the visual-semantic
mapping will be misled, reducing the effectiveness of knowledge transfer to
unseen classes. In this work, we propose a prototype-guided curriculum learning
framework (dubbed as CLZSL), which mitigates instance-level mismatches through
a Prototype-Guided Curriculum Learning (PCL) module and addresses class-level
imprecision via a Prototype Update (PUP) module. Specifically, the PCL module
prioritizes samples with high cosine similarity between their visual mappings
and the class-level semantic prototypes, and progressively advances to
less-aligned samples, thereby reducing the interference of instance-level
mismatches to achieve accurate visual-semantic mapping. Besides, the PUP module
dynamically updates the class-level semantic prototypes by leveraging the
visual mappings learned from instances, thereby reducing class-level
imprecision and further improving the visual-semantic mapping. Experiments were
conducted on standard benchmark datasets-AWA2, SUN, and CUB-to verify the
effectiveness of our method.

</details>


### [202] [Anatomy-Aware Low-Dose CT Denoising via Pretrained Vision Models and Semantic-Guided Contrastive Learning](https://arxiv.org/abs/2508.07788)
*Runze Wang,Zeli Chen,Zhiyun Song,Wei Fang,Jiajin Zhang,Danyang Tu,Yuxing Tang,Minfeng Xu,Xianghua Ye,Le Lu,Dakai Jin*

Main category: eess.IV

Relevance: 40.0

TL;DR: ALDEN是一种结合预训练视觉模型语义特征的LDCT去噪方法，通过对抗学习和对比学习提高解剖学一致性。


<details>
  <summary>Details</summary>
Motivation: 现有LDCT去噪方法忽略解剖学语义，导致去噪效果不佳。

Method: ALDEN整合预训练视觉模型的语义特征，采用解剖感知判别器和语义引导对比学习模块。

Result: 在LDCT去噪任务中达到SOTA性能，显著减少过平滑问题，并在下游分割任务中验证解剖学一致性。

Conclusion: ALDEN通过解剖学感知设计显著提升LDCT去噪效果。

Abstract: To reduce radiation exposure and improve the diagnostic efficacy of low-dose
computed tomography (LDCT), numerous deep learning-based denoising methods have
been developed to mitigate noise and artifacts. However, most of these
approaches ignore the anatomical semantics of human tissues, which may
potentially result in suboptimal denoising outcomes. To address this problem,
we propose ALDEN, an anatomy-aware LDCT denoising method that integrates
semantic features of pretrained vision models (PVMs) with adversarial and
contrastive learning. Specifically, we introduce an anatomy-aware discriminator
that dynamically fuses hierarchical semantic features from reference
normal-dose CT (NDCT) via cross-attention mechanisms, enabling tissue-specific
realism evaluation in the discriminator. In addition, we propose a
semantic-guided contrastive learning module that enforces anatomical
consistency by contrasting PVM-derived features from LDCT, denoised CT and
NDCT, preserving tissue-specific patterns through positive pairs and
suppressing artifacts via dual negative pairs. Extensive experiments conducted
on two LDCT denoising datasets reveal that ALDEN achieves the state-of-the-art
performance, offering superior anatomy preservation and substantially reducing
over-smoothing issue of previous work. Further validation on a downstream
multi-organ segmentation task (encompassing 117 anatomical structures) affirms
the model's ability to maintain anatomical awareness.

</details>


### [203] [Boosting Active Defense Persistence: A Two-Stage Defense Framework Combining Interruption and Poisoning Against Deepfake](https://arxiv.org/abs/2508.07795)
*Hongrui Zheng,Yuezun Li,Liejun Wang,Yunfeng Diao,Zhiqing Guo*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种两阶段防御框架（TSDF），通过双功能对抗扰动来持久防御深度伪造攻击，既直接扭曲伪造结果，又通过数据投毒阻止攻击者模型适应。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造防御策略缺乏持久性，攻击者可通过重新训练模型绕过防御。TSDF旨在通过双功能扰动实现长期有效防御。

Method: 提出TSDF框架，利用强度分离机制设计双功能对抗扰动，直接扭曲伪造结果并投毒攻击者的数据源。

Result: 实验表明TSDF具有强双重防御能力，显著提升防御持久性，优于传统中断方法。

Conclusion: TSDF通过双功能扰动实现了对深度伪造攻击的持久防御，解决了现有防御策略的短期有效性问题。

Abstract: Active defense strategies have been developed to counter the threat of
deepfake technology. However, a primary challenge is their lack of persistence,
as their effectiveness is often short-lived. Attackers can bypass these
defenses by simply collecting protected samples and retraining their models.
This means that static defenses inevitably fail when attackers retrain their
models, which severely limits practical use. We argue that an effective defense
not only distorts forged content but also blocks the model's ability to adapt,
which occurs when attackers retrain their models on protected images. To
achieve this, we propose an innovative Two-Stage Defense Framework (TSDF).
Benefiting from the intensity separation mechanism designed in this paper, the
framework uses dual-function adversarial perturbations to perform two roles.
First, it can directly distort the forged results. Second, it acts as a
poisoning vehicle that disrupts the data preparation process essential for an
attacker's retraining pipeline. By poisoning the data source, TSDF aims to
prevent the attacker's model from adapting to the defensive perturbations, thus
ensuring the defense remains effective long-term. Comprehensive experiments
show that the performance of traditional interruption methods degrades sharply
when it is subjected to adversarial retraining. However, our framework shows a
strong dual defense capability, which can improve the persistence of active
defense. Our code will be available at https://github.com/vpsg-research/TSDF.

</details>


### [204] [MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks](https://arxiv.org/abs/2508.07803)
*Yushen Xu,Xiaosong Li,Zhenyu Kuang,Xiaoqi Cheng,Haishu Tan,Huafeng Li*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出MambaTrans，一种多模态融合图像模态翻译器，通过结合多模态大语言模型描述和语义分割掩码，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 多模态融合图像与可见图像像素分布差异大，导致下游任务性能下降，需适应预训练模型。

Method: MambaTrans利用多模态大语言模型描述和语义分割掩码，结合Multi-Model State Space Block，优化视觉能力。

Result: 实验表明，MambaTrans有效提升多模态图像在下游任务中的性能。

Conclusion: MambaTrans在不调整预训练模型参数的情况下，显著提升多模态融合图像的下游任务表现。

Abstract: The goal of multimodal image fusion is to integrate complementary information
from infrared and visible images, generating multimodal fused images for
downstream tasks. Existing downstream pre-training models are typically trained
on visible images. However, the significant pixel distribution differences
between visible and multimodal fusion images can degrade downstream task
performance, sometimes even below that of using only visible images. This paper
explores adapting multimodal fused images with significant modality differences
to object detection and semantic segmentation models trained on visible images.
To address this, we propose MambaTrans, a novel multimodal fusion image
modality translator. MambaTrans uses descriptions from a multimodal large
language model and masks from semantic segmentation models as input. Its core
component, the Multi-Model State Space Block, combines mask-image-text
cross-attention and a 3D-Selective Scan Module, enhancing pure visual
capabilities. By leveraging object detection prior knowledge, MambaTrans
minimizes detection loss during training and captures long-term dependencies
among text, masks, and images. This enables favorable results in pre-trained
models without adjusting their parameters. Experiments on public datasets show
that MambaTrans effectively improves multimodal image performance in downstream
tasks.

</details>


### [205] [DiTVR: Zero-Shot Diffusion Transformer for Video Restoration](https://arxiv.org/abs/2508.07811)
*Sicheng Gao,Nancy Mehta,Zongwei Wu,Radu Timofte*

Main category: cs.CV

Relevance: 40.0

TL;DR: DiTVR是一个零样本视频修复框架，结合扩散变换器和轨迹感知注意力机制，通过光流轨迹对齐令牌，提升时间一致性和细节保留。


<details>
  <summary>Details</summary>
Motivation: 传统回归方法生成不真实细节且需大量配对数据，生成扩散模型难以保证时间一致性。DiTVR旨在解决这些问题。

Method: 采用扩散变换器与轨迹感知注意力机制，结合光流轨迹对齐令牌，并使用小波引导的流一致采样器。

Result: 在视频修复基准测试中达到零样本最优性能，时间一致性和细节保留表现优异，且对光流噪声和遮挡鲁棒。

Conclusion: DiTVR通过创新的注意力机制和采样器设计，显著提升了视频修复的质量和效率。

Abstract: Video restoration aims to reconstruct high quality video sequences from low
quality inputs, addressing tasks such as super resolution, denoising, and
deblurring. Traditional regression based methods often produce unrealistic
details and require extensive paired datasets, while recent generative
diffusion models face challenges in ensuring temporal consistency. We introduce
DiTVR, a zero shot video restoration framework that couples a diffusion
transformer with trajectory aware attention and a wavelet guided, flow
consistent sampler. Unlike prior 3D convolutional or frame wise diffusion
approaches, our attention mechanism aligns tokens along optical flow
trajectories, with particular emphasis on vital layers that exhibit the highest
sensitivity to temporal dynamics. A spatiotemporal neighbour cache dynamically
selects relevant tokens based on motion correspondences across frames. The flow
guided sampler injects data consistency only into low-frequency bands,
preserving high frequency priors while accelerating convergence. DiTVR
establishes a new zero shot state of the art on video restoration benchmarks,
demonstrating superior temporal consistency and detail preservation while
remaining robust to flow noise and occlusions.

</details>


### [206] [Effortless Vision-Language Model Specialization in Histopathology without Annotation](https://arxiv.org/abs/2508.07835)
*Jingna Qiu,Nishanth Jain,Jonas Ammeling,Marc Aubreville,Katharina Breininger*

Main category: cs.CV

Relevance: 40.0

TL;DR: 该论文研究了通过无标注的领域和任务相关图像-文本对继续预训练视觉语言模型（VLMs），以提升其在组织病理学任务中的零样本和小样本性能。


<details>
  <summary>Details</summary>
Motivation: 尽管通用视觉语言模型（如CONCH和QuiltNet）在组织病理学中表现出色，但其通用设计可能导致在特定任务中性能不佳。现有监督微调方法需要手动标注样本，而本文旨在探索无需标注的适应方法。

Method: 通过从现有数据库中提取领域和任务相关的图像-文本对，对VLMs进行继续预训练，以提升其在零样本和小样本任务中的性能。

Result: 实验表明，这种无标注的继续预训练方法显著提升了两种VLMs在三个下游任务中的性能，且在大规模训练时能与小样本方法相媲美。

Conclusion: 无标注的继续预训练是一种有效的、任务无关的方法，为VLMs在组织病理学任务中的适应提供了新途径。

Abstract: Recent advances in Vision-Language Models (VLMs) in histopathology, such as
CONCH and QuiltNet, have demonstrated impressive zero-shot classification
capabilities across various tasks. However, their general-purpose design may
lead to suboptimal performance in specific downstream applications. While
supervised fine-tuning methods address this issue, they require manually
labeled samples for adaptation. This paper investigates annotation-free
adaptation of VLMs through continued pretraining on domain- and task-relevant
image-caption pairs extracted from existing databases. Our experiments on two
VLMs, CONCH and QuiltNet, across three downstream tasks reveal that these pairs
substantially enhance both zero-shot and few-shot performance. Notably, with
larger training sizes, continued pretraining matches the performance of
few-shot methods while eliminating manual labeling. Its effectiveness,
task-agnostic design, and annotation-free workflow make it a promising pathway
for adapting VLMs to new histopathology tasks. Code is available at
https://github.com/DeepMicroscopy/Annotation-free-VLM-specialization.

</details>


### [207] [CBDES MoE: Hierarchically Decoupled Mixture-of-Experts for Functional Modules in Autonomous Driving](https://arxiv.org/abs/2508.07838)
*Qi Xiang,Kunsong Shi,Zhigui Lin,Lei He*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种名为CBDES MoE的分层解耦混合专家架构，用于解决多模态BEV感知系统中的输入适应性、建模能力和泛化性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有BEV感知系统在多模态输入适应性、建模能力和泛化性能方面存在不足，需要一种更高效的架构。

Method: 采用分层解耦的混合专家架构（CBDES MoE），结合轻量级自注意力路由机制（SAR），实现动态专家路径选择和稀疏推理。

Result: 在nuScenes数据集上，CBDES MoE在3D目标检测中表现优于单专家模型，mAP提升1.6点，NDS提升4.1点。

Conclusion: CBDES MoE是一种有效的模块化混合专家框架，适用于自动驾驶领域。

Abstract: Bird's Eye View (BEV) perception systems based on multi-sensor feature fusion
have become a fundamental cornerstone for end-to-end autonomous driving.
However, existing multi-modal BEV methods commonly suffer from limited input
adaptability, constrained modeling capacity, and suboptimal generalization. To
address these challenges, we propose a hierarchically decoupled
Mixture-of-Experts architecture at the functional module level, termed
Computing Brain DEvelopment System Mixture-of-Experts (CBDES MoE). CBDES MoE
integrates multiple structurally heterogeneous expert networks with a
lightweight Self-Attention Router (SAR) gating mechanism, enabling dynamic
expert path selection and sparse, input-aware efficient inference. To the best
of our knowledge, this is the first modular Mixture-of-Experts framework
constructed at the functional module granularity within the autonomous driving
domain. Extensive evaluations on the real-world nuScenes dataset demonstrate
that CBDES MoE consistently outperforms fixed single-expert baselines in 3D
object detection. Compared to the strongest single-expert model, CBDES MoE
achieves a 1.6-point increase in mAP and a 4.1-point improvement in NDS,
demonstrating the effectiveness and practical advantages of the proposed
approach.

</details>


### [208] [Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images](https://arxiv.org/abs/2508.07847)
*Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于深度状态空间模型的太阳耀斑预测方法Deep SWM，结合稀疏掩码自编码器预训练策略，并构建了FlareBench基准测试，性能优于基线方法和人类专家。


<details>
  <summary>Details</summary>
Motivation: 解决现有太阳耀斑预测方法在表征学习和长程时空依赖性建模上的不足，提升预测准确性和可靠性。

Method: 使用多深度状态空间模型处理十通道太阳图像和长程时空依赖性，结合两阶段掩码稀疏自编码器预训练策略。

Result: 在FlareBench基准测试中，性能优于基线方法和人类专家。

Conclusion: Deep SWM在太阳耀斑预测中表现出色，为空间天气预测提供了新工具。

Abstract: Accurate, reliable solar flare prediction is crucial for mitigating potential
disruptions to critical infrastructure, while predicting solar flares remains a
significant challenge. Existing methods based on heuristic physical features
often lack representation learning from solar images. On the other hand,
end-to-end learning approaches struggle to model long-range temporal
dependencies in solar images. In this study, we propose Deep Space Weather
Model (Deep SWM), which is based on multiple deep state space models for
handling both ten-channel solar images and long-range spatio-temporal
dependencies. Deep SWM also features a sparse masked autoencoder, a novel
pretraining strategy that employs a two-phase masking approach to preserve
crucial regions such as sunspots while compressing spatial information.
Furthermore, we built FlareBench, a new public benchmark for solar flare
prediction covering a full 11-year solar activity cycle, to validate our
method. Our method outperformed baseline methods and even human expert
performance on standard metrics in terms of performance and reliability. The
project page can be found at https://keio-smilab25.github.io/DeepSWM.

</details>


### [209] [Selective Contrastive Learning for Weakly Supervised Affordance Grounding](https://arxiv.org/abs/2508.07877)
*WonJun Moon,Hyun Seok Seong,Jae-Pil Heo*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种选择性原型和像素对比学习方法，用于弱监督功能接地（WSAG），通过多视角学习和CLIP模型挖掘功能相关线索。


<details>
  <summary>Details</summary>
Motivation: 解决现有WSAG方法依赖分类器而忽略功能相关部分的问题，提出更精确的功能接地方法。

Method: 结合选择性原型和像素对比学习，利用CLIP模型从多视角图像中挖掘功能相关对象和部分线索。

Result: 实验证明该方法能有效激活功能相关区域，减少无关背景干扰。

Conclusion: 该方法在多视角功能接地任务中表现优越，代码已开源。

Abstract: Facilitating an entity's interaction with objects requires accurately
identifying parts that afford specific actions. Weakly supervised affordance
grounding (WSAG) seeks to imitate human learning from third-person
demonstrations, where humans intuitively grasp functional parts without needing
pixel-level annotations. To achieve this, grounding is typically learned using
a shared classifier across images from different perspectives, along with
distillation strategies incorporating part discovery process. However, since
affordance-relevant parts are not always easily distinguishable, models
primarily rely on classification, often focusing on common class-specific
patterns that are unrelated to affordance. To address this limitation, we move
beyond isolated part-level learning by introducing selective prototypical and
pixel contrastive objectives that adaptively learn affordance-relevant cues at
both the part and object levels, depending on the granularity of the available
information. Initially, we find the action-associated objects in both
egocentric (object-focused) and exocentric (third-person example) images by
leveraging CLIP. Then, by cross-referencing the discovered objects of
complementary views, we excavate the precise part-level affordance clues in
each perspective. By consistently learning to distinguish affordance-relevant
regions from affordance-irrelevant background context, our approach effectively
shifts activation from irrelevant areas toward meaningful affordance cues.
Experimental results demonstrate the effectiveness of our method. Codes are
available at github.com/hynnsk/SelectiveCL.

</details>


### [210] [TAP: Parameter-efficient Task-Aware Prompting for Adverse Weather Removal](https://arxiv.org/abs/2508.07878)
*Hanting Wang,Shengpeng Ji,Shulei Wang,Hai Huang,Xiao Jin,Qifei Zhang,Tao Jin*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种参数高效的一体化图像修复框架，通过任务感知增强提示处理多种恶劣天气退化问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常为每种退化类型设计专用网络模块或参数，导致参数冗余，且忽略了任务间的相关性。

Method: 采用两阶段训练范式（预训练和提示调优），利用低秩分解和对比约束增强任务感知提示。

Result: 实验表明，该方法仅用2.75M参数即可实现优越性能。

Conclusion: 该方法通过任务感知提示提高了参数效率和任务建模准确性。

Abstract: Image restoration under adverse weather conditions has been extensively
explored, leading to numerous high-performance methods. In particular, recent
advances in All-in-One approaches have shown impressive results by training on
multi-task image restoration datasets. However, most of these methods rely on
dedicated network modules or parameters for each specific degradation type,
resulting in a significant parameter overhead. Moreover, the relatedness across
different restoration tasks is often overlooked. In light of these issues, we
propose a parameter-efficient All-in-One image restoration framework that
leverages task-aware enhanced prompts to tackle various adverse weather
degradations.Specifically, we adopt a two-stage training paradigm consisting of
a pretraining phase and a prompt-tuning phase to mitigate parameter conflicts
across tasks. We first employ supervised learning to acquire general
restoration knowledge, and then adapt the model to handle specific degradation
via trainable soft prompts. Crucially, we enhance these task-specific prompts
in a task-aware manner. We apply low-rank decomposition to these prompts to
capture both task-general and task-specific characteristics, and impose
contrastive constraints to better align them with the actual inter-task
relatedness. These enhanced prompts not only improve the parameter efficiency
of the restoration model but also enable more accurate task modeling, as
evidenced by t-SNE analysis. Experimental results on different restoration
tasks demonstrate that the proposed method achieves superior performance with
only 2.75M parameters.

</details>


### [211] [Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation](https://arxiv.org/abs/2508.07901)
*Bowen Xue,Qixin Yan,Wenjing Wang,Hao Liu,Chen Li*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种轻量级、即插即用的视频生成框架Stand-In，通过条件图像分支和受限自注意力实现身份保持，仅需少量参数和训练数据。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法参数过多且与其他AIGC工具不兼容的问题，实现高效身份保持的视频生成。

Method: 在预训练视频生成模型中引入条件图像分支，通过受限自注意力和条件位置映射实现身份控制，仅需2000对数据快速训练。

Result: 仅增加约1%参数，视频质量和身份保持效果优于全参数训练方法，且可无缝集成其他任务。

Conclusion: Stand-In框架高效、灵活，适用于多种视频生成任务。

Abstract: Generating high-fidelity human videos that match user-specified identities is
important yet challenging in the field of generative AI. Existing methods often
rely on an excessive number of training parameters and lack compatibility with
other AIGC tools. In this paper, we propose Stand-In, a lightweight and
plug-and-play framework for identity preservation in video generation.
Specifically, we introduce a conditional image branch into the pre-trained
video generation model. Identity control is achieved through restricted
self-attentions with conditional position mapping, and can be learned quickly
with only 2000 pairs. Despite incorporating and training just $\sim$1\%
additional parameters, our framework achieves excellent results in video
quality and identity preservation, outperforming other full-parameter training
methods. Moreover, our framework can be seamlessly integrated for other tasks,
such as subject-driven video generation, pose-referenced video generation,
stylization, and face swapping.

</details>


### [212] [RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering](https://arxiv.org/abs/2508.07918)
*Xing Zi,Jinghao Xiao,Yunxiao Shi,Xian Tao,Jun Li,Ali Braytee,Mukesh Prasad*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文介绍了RSVLM-QA数据集，一个用于遥感视觉问答（VQA）的大规模、内容丰富的数据集，通过LLM生成注释和自动化计数流程构建，旨在评估和挑战当前VLMs的理解与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有遥感VQA数据集在注释丰富性、问题多样性和特定推理能力评估方面存在局限，RSVLM-QA旨在填补这一空白。

Method: 利用GPT-4.1生成详细注释（如图像描述、空间关系）和自动化计数流程构建VQA对，整合多个遥感数据集。

Result: RSVLM-QA包含13,820张图像和162,373个VQA对，统计分析和基准实验显示其注释深度和广度优于现有数据集。

Conclusion: RSVLM-QA将成为遥感VQA和VLM研究的重要资源，推动领域发展。

Abstract: Visual Question Answering (VQA) in remote sensing (RS) is pivotal for
interpreting Earth observation data. However, existing RS VQA datasets are
constrained by limitations in annotation richness, question diversity, and the
assessment of specific reasoning capabilities. This paper introduces RSVLM-QA
dataset, a new large-scale, content-rich VQA dataset for the RS domain.
RSVLM-QA is constructed by integrating data from several prominent RS
segmentation and detection datasets: WHU, LoveDA, INRIA, and iSAID. We employ
an innovative dual-track annotation generation pipeline. Firstly, we leverage
Large Language Models (LLMs), specifically GPT-4.1, with meticulously designed
prompts to automatically generate a suite of detailed annotations including
image captions, spatial relations, and semantic tags, alongside complex
caption-based VQA pairs. Secondly, to address the challenging task of object
counting in RS imagery, we have developed a specialized automated process that
extracts object counts directly from the original segmentation data; GPT-4.1
then formulates natural language answers from these counts, which are paired
with preset question templates to create counting QA pairs. RSVLM-QA comprises
13,820 images and 162,373 VQA pairs, featuring extensive annotations and
diverse question types. We provide a detailed statistical analysis of the
dataset and a comparison with existing RS VQA benchmarks, highlighting the
superior depth and breadth of RSVLM-QA's annotations. Furthermore, we conduct
benchmark experiments on Six mainstream Vision Language Models (VLMs),
demonstrating that RSVLM-QA effectively evaluates and challenges the
understanding and reasoning abilities of current VLMs in the RS domain. We
believe RSVLM-QA will serve as a pivotal resource for the RS VQA and VLM
research communities, poised to catalyze advancements in the field.

</details>


### [213] [Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection](https://arxiv.org/abs/2508.07923)
*Jakub Binda,Valentina Paneta,Vasileios Eleftheriadis,Hongkyou Chung,Panagiotis Papadimitroulas,Neo Christopher Chung*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种混合异常检测框架，用于增强生成式AI在生物医学成像中的可靠性和安全性，展示了两个应用案例。


<details>
  <summary>Details</summary>
Motivation: 生物医学影像的高风险性要求对生成式AI模型的异常行为进行检测和管理，以确保其可靠性和安全性。

Method: 开发并实现了一种混合异常检测框架，应用于Pose2Xray和DosimetrEYE两个生成式AI系统。

Result: 该框架提高了系统的可靠性，减少了人工监督需求，并支持实时质量控制。

Conclusion: 该方法增强了生成式AI在临床前环境中的工业可行性，提高了鲁棒性、可扩展性和合规性。

Abstract: Generative AI holds great potentials to automate and enhance data synthesis
in nuclear medicine. However, the high-stakes nature of biomedical imaging
necessitates robust mechanisms to detect and manage unexpected or erroneous
model behavior. We introduce development and implementation of a hybrid anomaly
detection framework to safeguard GenAI models in BIOEMTECH's eyes(TM) systems.
Two applications are demonstrated: Pose2Xray, which generates synthetic X-rays
from photographic mouse images, and DosimetrEYE, which estimates 3D radiation
dose maps from 2D SPECT/CT scans. In both cases, our outlier detection (OD)
enhances reliability, reduces manual oversight, and supports real-time quality
control. This approach strengthens the industrial viability of GenAI in
preclinical settings by increasing robustness, scalability, and regulatory
compliance.

</details>


### [214] [TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding](https://arxiv.org/abs/2508.07925)
*Jin-Seop Lee,SungJoon Lee,Jaehan Ahn,YunSeok Choi,Jee-Hyong Lee*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为TAG的零样本视频时间定位方法，通过时间池化、时间相干性聚类和相似性调整，解决了现有方法中的语义碎片化和相似性分布偏差问题，无需依赖LLMs。


<details>
  <summary>Details</summary>
Motivation: 现有零样本视频时间定位方法存在语义碎片化和相似性分布偏差问题，且依赖昂贵的LLMs推理。

Method: 提出TAG方法，结合时间池化、时间相干性聚类和相似性调整，无需训练即可捕捉视频时间上下文并修正相似性分布。

Result: 在Charades-STA和ActivityNet Captions数据集上取得最先进结果。

Conclusion: TAG是一种简单有效的零样本视频时间定位方法，解决了现有方法的局限性。

Abstract: Video Temporal Grounding (VTG) aims to extract relevant video segments based
on a given natural language query. Recently, zero-shot VTG methods have gained
attention by leveraging pretrained vision-language models (VLMs) to localize
target moments without additional training. However, existing approaches suffer
from semantic fragmentation, where temporally continuous frames sharing the
same semantics are split across multiple segments. When segments are
fragmented, it becomes difficult to predict an accurate target moment that
aligns with the text query. Also, they rely on skewed similarity distributions
for localization, making it difficult to select the optimal segment.
Furthermore, they heavily depend on the use of LLMs which require expensive
inferences. To address these limitations, we propose a \textit{TAG}, a simple
yet effective Temporal-Aware approach for zero-shot video temporal Grounding,
which incorporates temporal pooling, temporal coherence clustering, and
similarity adjustment. Our proposed method effectively captures the temporal
context of videos and addresses distorted similarity distributions without
training. Our approach achieves state-of-the-art results on Charades-STA and
ActivityNet Captions benchmark datasets without rely on LLMs. Our code is
available at https://github.com/Nuetee/TAG

</details>


### [215] [VOIDFace: A Privacy-Preserving Multi-Network Face Recognition With Enhanced Security](https://arxiv.org/abs/2508.07960)
*Ajnas Muhammed,Iurri Medvedev,Nuno Gonçalves*

Main category: cs.CV

Relevance: 40.0

TL;DR: VOIDFace是一个新颖的面部识别框架，通过视觉秘密共享和基于补丁的多训练网络，解决了数据复制和隐私问题，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现代面部识别系统需要大量数据复制，导致隐私和伦理问题。VOIDFace旨在消除数据复制并增强数据控制。

Method: 使用视觉秘密共享存储训练数据，提出基于补丁的多训练网络。

Result: 在VGGFace2数据集上，VOIDFace实现了数据控制、安全和隐私，同时保持竞争性性能。

Conclusion: VOIDFace提升了面部识别系统的隐私、安全和效率，同时支持用户的数据控制权。

Abstract: Advancement of machine learning techniques, combined with the availability of
large-scale datasets, has significantly improved the accuracy and efficiency of
facial recognition. Modern facial recognition systems are trained using large
face datasets collected from diverse individuals or public repositories.
However, for training, these datasets are often replicated and stored in
multiple workstations, resulting in data replication, which complicates
database management and oversight. Currently, once a user submits their face
for dataset preparation, they lose control over how their data is used, raising
significant privacy and ethical concerns. This paper introduces VOIDFace, a
novel framework for facial recognition systems that addresses two major issues.
First, it eliminates the need of data replication and improves data control to
securely store training face data by using visual secret sharing. Second, it
proposes a patch-based multi-training network that uses this novel training
data storage mechanism to develop a robust, privacy-preserving facial
recognition system. By integrating these advancements, VOIDFace aims to improve
the privacy, security, and efficiency of facial recognition training, while
ensuring greater control over sensitive personal face data. VOIDFace also
enables users to exercise their Right-To-Be-Forgotten property to control their
personal data. Experimental evaluations on the VGGFace2 dataset show that
VOIDFace provides Right-To-Be-Forgotten, improved data control, security, and
privacy while maintaining competitive facial recognition performance. Code is
available at: https://github.com/ajnasmuhammed89/VOIDFace

</details>


### [216] [Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models](https://arxiv.org/abs/2508.07996)
*Thinesh Thiyakesan Ponbagavathi,Chengzheng Yang,Alina Roitberg*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出Prompt-driven Group Activity Detection (ProGraD)，通过可学习的群体提示和轻量级GroupContext Transformer，改进Vision Foundation Models在群体活动检测中的表现。


<details>
  <summary>Details</summary>
Motivation: Vision Foundation Models (VFMs)在群体活动检测中表现不佳，需要结构化、群体感知的推理方法。

Method: 1) 可学习的群体提示引导VFM注意力；2) 轻量级GroupContext Transformer推断参与者-群体关联和集体行为。

Result: 在Cafe和Social-CAD基准测试中超越现有方法，尤其在多群体场景中提升显著（Group mAP@1.0提升6.5%，Group mAP@0.5提升8.2%）。

Conclusion: ProGraD不仅性能优越，还能生成可解释的注意力图，为群体推理提供洞见。

Abstract: Group Activity Detection (GAD) involves recognizing social groups and their
collective behaviors in videos. Vision Foundation Models (VFMs), like DinoV2,
offer excellent features, but are pretrained primarily on object-centric data
and remain underexplored for modeling group dynamics. While they are a
promising alternative to highly task-specific GAD architectures that require
full fine-tuning, our initial investigation reveals that simply swapping CNN
backbones used in these methods with VFMs brings little gain, underscoring the
need for structured, group-aware reasoning on top.
  We introduce Prompt-driven Group Activity Detection (ProGraD) -- a method
that bridges this gap through 1) learnable group prompts to guide the VFM
attention toward social configurations, and 2) a lightweight two-layer
GroupContext Transformer that infers actor-group associations and collective
behavior. We evaluate our approach on two recent GAD benchmarks: Cafe, which
features multiple concurrent social groups, and Social-CAD, which focuses on
single-group interactions. While we surpass state-of-the-art in both settings,
our method is especially effective in complex multi-group scenarios, where we
yield a gain of 6.5\% (Group mAP\@1.0) and 8.2\% (Group mAP\@0.5) using only
10M trainable parameters. Furthermore, our experiments reveal that ProGraD
produces interpretable attention maps, offering insights into actor-group
reasoning. Code and models will be released.

</details>


### [217] [Membership Inference Attacks with False Discovery Rate Control](https://arxiv.org/abs/2508.07066)
*Chenxu Zhao,Wei Qian,Aobo Chen,Mengdi Huai*

Main category: stat.ML

Relevance: 40.0

TL;DR: 论文提出了一种新型的成员推断攻击方法，能够提供虚假发现率（FDR）保证，并可作为现有方法的包装器使用。


<details>
  <summary>Details</summary>
Motivation: 现有成员推断攻击方法缺乏对虚假发现率的保证，且分布未知和概率依赖性增加了挑战。

Method: 设计了一种新型成员推断攻击方法，提供FDR保证，并可作为现有方法的包装器。

Result: 理论分析和实验验证表明，该方法在多种设置下表现优异。

Conclusion: 该方法解决了现有成员推断攻击方法的局限性，提供了FDR保证。

Abstract: Recent studies have shown that deep learning models are vulnerable to
membership inference attacks (MIAs), which aim to infer whether a data record
was used to train a target model or not. To analyze and study these
vulnerabilities, various MIA methods have been proposed. Despite the
significance and popularity of MIAs, existing works on MIAs are limited in
providing guarantees on the false discovery rate (FDR), which refers to the
expected proportion of false discoveries among the identified positive
discoveries. However, it is very challenging to ensure the false discovery rate
guarantees, because the underlying distribution is usually unknown, and the
estimated non-member probabilities often exhibit interdependence. To tackle the
above challenges, in this paper, we design a novel membership inference attack
method, which can provide the guarantees on the false discovery rate.
Additionally, we show that our method can also provide the marginal probability
guarantee on labeling true non-member data as member data. Notably, our method
can work as a wrapper that can be seamlessly integrated with existing MIA
methods in a post-hoc manner, while also providing the FDR control. We perform
the theoretical analysis for our method. Extensive experiments in various
settings (e.g., the black-box setting and the lifelong learning setting) are
also conducted to verify the desirable performance of our method.

</details>


### [218] [Mitigating Biases in Surgical Operating Rooms with Geometry](https://arxiv.org/abs/2508.08028)
*Tony Danjun Wang,Tobias Czempiel,Nassir Navab,Lennart Bastian*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文通过梯度显著性分析揭示CNN模型在手术室场景中易受虚假相关性影响，提出基于3D点云序列的方法以分离身份相关特征，实验证明几何表示更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 解决手术室场景中深度模型因标准化服装导致的虚假相关性学习问题，提升智能辅助系统的准确性。

Method: 使用梯度显著性分析揭示CNN的虚假相关性，提出基于3D点云序列的方法分离形状和运动特征。

Result: RGB模型在临床场景中性能下降12%，几何表示表现更稳定。

Conclusion: 几何表示能更有效地捕捉生物特征，为手术室场景的鲁棒建模提供新思路。

Abstract: Deep neural networks are prone to learning spurious correlations, exploiting
dataset-specific artifacts rather than meaningful features for prediction. In
surgical operating rooms (OR), these manifest through the standardization of
smocks and gowns that obscure robust identifying landmarks, introducing model
bias for tasks related to modeling OR personnel. Through gradient-based
saliency analysis on two public OR datasets, we reveal that CNN models succumb
to such shortcuts, fixating on incidental visual cues such as footwear beneath
surgical gowns, distinctive eyewear, or other role-specific identifiers.
Avoiding such biases is essential for the next generation of intelligent
assistance systems in the OR, which should accurately recognize personalized
workflow traits, such as surgical skill level or coordination with other staff
members. We address this problem by encoding personnel as 3D point cloud
sequences, disentangling identity-relevant shape and motion patterns from
appearance-based confounders. Our experiments demonstrate that while RGB and
geometric methods achieve comparable performance on datasets with apparent
simulation artifacts, RGB models suffer a 12% accuracy drop in realistic
clinical settings with decreased visual diversity due to standardizations. This
performance gap confirms that geometric representations capture more meaningful
biometric features, providing an avenue to developing robust methods of
modeling humans in the OR.

</details>


### [219] [TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation](https://arxiv.org/abs/2508.08038)
*Huawei Sun,Zixu Wang,Hao Feng,Julius Ott,Lorenzo Servadei,Robert Wille*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出TRIDE算法，结合雷达和相机特征，并引入天气感知融合块，提升深度估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有雷达-相机融合算法未考虑天气影响，且语言描述在多模态深度估计中未被充分利用。

Method: 提出文本生成策略和特征融合技术，结合雷达点信息增强文本特征提取，并设计天气感知融合块。

Result: 在nuScenes数据集上，MAE和RMSE分别提升12.87%和9.08%。

Conclusion: TRIDE算法通过多模态融合和天气适应性设计，显著提升深度估计性能。

Abstract: Depth estimation, essential for autonomous driving, seeks to interpret the 3D
environment surrounding vehicles. The development of radar sensors, known for
their cost-efficiency and robustness, has spurred interest in radar-camera
fusion-based solutions. However, existing algorithms fuse features from these
modalities without accounting for weather conditions, despite radars being
known to be more robust than cameras under adverse weather. Additionally, while
Vision-Language models have seen rapid advancement, utilizing language
descriptions alongside other modalities for depth estimation remains an open
challenge. This paper first introduces a text-generation strategy along with
feature extraction and fusion techniques that can assist monocular depth
estimation pipelines, leading to improved accuracy across different algorithms
on the KITTI dataset. Building on this, we propose TRIDE, a radar-camera fusion
algorithm that enhances text feature extraction by incorporating radar point
information. To address the impact of weather on sensor performance, we
introduce a weather-aware fusion block that adaptively adjusts radar weighting
based on current weather conditions. Our method, benchmarked on the nuScenes
dataset, demonstrates performance gains over the state-of-the-art, achieving a
12.87% improvement in MAE and a 9.08% improvement in RMSE. Code:
https://github.com/harborsarah/TRIDE

</details>


### [220] [S^2VG: 3D Stereoscopic and Spatial Video Generation via Denoising Frame Matrix](https://arxiv.org/abs/2508.08048)
*Peng Dai,Feitong Tan,Qiangeng Xu,Yihua Huang,David Futschik,Ruofei Du,Sean Fanello,Yinda Zhang,Xiaojuan Qi*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种无需训练的方法，利用现成的单目视频生成模型生成沉浸式3D视频，通过深度估计和帧矩阵修复框架实现空间和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 解决3D立体和空间视频生成在沉浸式应用中的未充分探索问题。

Method: 利用深度信息将单目视频变形到预定义视角，采用帧矩阵修复框架合成缺失内容，并通过双更新方案提升修复质量。

Result: 在多视角视频生成中显著优于先前方法，支持立体对或4D高斯优化的空间视频合成。

Conclusion: 该方法无需额外训练，有效提升了3D视频生成的质量和一致性。

Abstract: While video generation models excel at producing high-quality monocular
videos, generating 3D stereoscopic and spatial videos for immersive
applications remains an underexplored challenge. We present a pose-free and
training-free method that leverages an off-the-shelf monocular video generation
model to produce immersive 3D videos. Our approach first warps the generated
monocular video into pre-defined camera viewpoints using estimated depth
information, then applies a novel \textit{frame matrix} inpainting framework.
This framework utilizes the original video generation model to synthesize
missing content across different viewpoints and timestamps, ensuring spatial
and temporal consistency without requiring additional model fine-tuning.
Moreover, we develop a \dualupdate~scheme that further improves the quality of
video inpainting by alleviating the negative effects propagated from
disoccluded areas in the latent space. The resulting multi-view videos are then
adapted into stereoscopic pairs or optimized into 4D Gaussians for spatial
video synthesis. We validate the efficacy of our proposed method by conducting
experiments on videos from various generative models, such as Sora, Lumiere,
WALT, and Zeroscope. The experiments demonstrate that our method has a
significant improvement over previous methods. Project page at:
https://daipengwa.github.io/S-2VG_ProjectPage/

</details>


### [221] [Sensory robustness through top-down feedback and neural stochasticity in recurrent vision models](https://arxiv.org/abs/2508.07115)
*Antonino Greco,Marco D'Alessandro,Karl J. Friston,Giovanni Pezzulo,Markus Siegel*

Main category: q-bio.NC

Relevance: 40.0

TL;DR: 研究探讨了在卷积循环神经网络（ConvRNN）中引入自上而下的反馈机制对图像分类任务的影响，发现结合随机神经元失活（dropout）能显著提升模型的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 探索生物视觉系统中自上而下反馈的功能意义，并验证其在人工视觉模型中的潜在价值。

Method: 训练带有或不带有自上而下反馈的ConvRNN，结合dropout模拟神经随机性，分析其对模型性能的影响。

Result: 反馈机制结合dropout显著提升了模型的抗噪能力、对抗攻击鲁棒性，并优化了表征几何和低维流形编码。

Conclusion: 自上而下反馈与神经随机性共同作用，通过稳定网络动态和高效编码实现鲁棒感知。

Abstract: Biological systems leverage top-down feedback for visual processing, yet most
artificial vision models succeed in image classification using purely
feedforward or recurrent architectures, calling into question the functional
significance of descending cortical pathways. Here, we trained convolutional
recurrent neural networks (ConvRNN) on image classification in the presence or
absence of top-down feedback projections to elucidate the specific
computational contributions of those feedback pathways. We found that ConvRNNs
with top-down feedback exhibited remarkable speed-accuracy trade-off and
robustness to noise perturbations and adversarial attacks, but only when they
were trained with stochastic neural variability, simulated by randomly
silencing single units via dropout. By performing detailed analyses to identify
the reasons for such benefits, we observed that feedback information
substantially shaped the representational geometry of the post-integration
layer, combining the bottom-up and top-down streams, and this effect was
amplified by dropout. Moreover, feedback signals coupled with dropout optimally
constrained network activity onto a low-dimensional manifold and encoded object
information more efficiently in out-of-distribution regimes, with top-down
information stabilizing the representational dynamics at the population level.
Together, these findings uncover a dual mechanism for resilient sensory coding.
On the one hand, neural stochasticity prevents unit-level co-adaptation albeit
at the cost of more chaotic dynamics. On the other hand, top-down feedback
harnesses high-level information to stabilize network activity on compact
low-dimensional manifolds.

</details>


### [222] [Information Bottleneck-based Causal Attention for Multi-label Medical Image Recognition](https://arxiv.org/abs/2508.08069)
*Xiaoxiao Cui,Yiran Li,Kai He,Shanzhi Jiang,Mengli Xue,Wentao Li,Junhong Leng,Zhi Liu,Lizhen Cui,Shuo Li*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于信息瓶颈的因果注意力方法（IBCA），用于医学图像的多标签分类，通过高斯混合多标签空间注意力过滤无关信息，并通过对比增强因果干预减少虚假注意力。


<details>
  <summary>Details</summary>
Motivation: 当前方法在医学图像多标签分类中难以区分因果和无关特征，导致诊断准确性不足。

Method: 使用高斯混合多标签空间注意力捕捉类别特异性注意力模式，并通过对比增强因果干预减少虚假注意力。

Result: 在Endo和MuReD数据集上，IBCA在多项指标上显著优于其他方法，如CR、OR和mAP。

Conclusion: IBCA能有效学习类别特异性注意力，提升医学图像多标签分类的性能和可解释性。

Abstract: Multi-label classification (MLC) of medical images aims to identify multiple
diseases and holds significant clinical potential. A critical step is to learn
class-specific features for accurate diagnosis and improved interpretability
effectively. However, current works focus primarily on causal attention to
learn class-specific features, yet they struggle to interpret the true cause
due to the inadvertent attention to class-irrelevant features. To address this
challenge, we propose a new structural causal model (SCM) that treats
class-specific attention as a mixture of causal, spurious, and noisy factors,
and a novel Information Bottleneck-based Causal Attention (IBCA) that is
capable of learning the discriminative class-specific attention for MLC of
medical images. Specifically, we propose learning Gaussian mixture multi-label
spatial attention to filter out class-irrelevant information and capture each
class-specific attention pattern. Then a contrastive enhancement-based causal
intervention is proposed to gradually mitigate the spurious attention and
reduce noise information by aligning multi-head attention with the Gaussian
mixture multi-label spatial. Quantitative and ablation results on Endo and
MuReD show that IBCA outperforms all methods. Compared to the second-best
results for each metric, IBCA achieves improvements of 6.35\% in CR, 7.72\% in
OR, and 5.02\% in mAP for MuReD, 1.47\% in CR, and 1.65\% in CF1, and 1.42\% in
mAP for Endo.

</details>


### [223] [ME-TST+: Micro-expression Analysis via Temporal State Transition with ROI Relationship Awareness](https://arxiv.org/abs/2508.08082)
*Zizheng Guo,Bochao Zou,Junbao Zhuo,Huimin Ma*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出两种基于状态空间模型的架构（ME-TST和ME-TST+），用于微表情（ME）的检测和识别，通过视频级回归和多粒度ROI建模提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有滑动窗口分类方法在微表情分析中的局限性，如固定窗口长度和硬分类问题，并整合检测与识别任务。

Method: 提出ME-TST和ME-TST+架构，利用时间状态转移机制和多粒度ROI建模，结合慢快Mamba框架。

Result: 实验表明，所提方法在性能上达到最先进水平。

Conclusion: 状态空间模型和多任务协同策略显著提升了微表情分析的准确性和灵活性。

Abstract: Micro-expressions (MEs) are regarded as important indicators of an
individual's intrinsic emotions, preferences, and tendencies. ME analysis
requires spotting of ME intervals within long video sequences and recognition
of their corresponding emotional categories. Previous deep learning approaches
commonly employ sliding-window classification networks. However, the use of
fixed window lengths and hard classification presents notable limitations in
practice. Furthermore, these methods typically treat ME spotting and
recognition as two separate tasks, overlooking the essential relationship
between them. To address these challenges, this paper proposes two state space
model-based architectures, namely ME-TST and ME-TST+, which utilize temporal
state transition mechanisms to replace conventional window-level classification
with video-level regression. This enables a more precise characterization of
the temporal dynamics of MEs and supports the modeling of MEs with varying
durations. In ME-TST+, we further introduce multi-granularity ROI modeling and
the slowfast Mamba framework to alleviate information loss associated with
treating ME analysis as a time-series task. Additionally, we propose a synergy
strategy for spotting and recognition at both the feature and result levels,
leveraging their intrinsic connection to enhance overall analysis performance.
Extensive experiments demonstrate that the proposed methods achieve
state-of-the-art performance. The codes are available at
https://github.com/zizheng-guo/ME-TST.

</details>


### [224] [Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control](https://arxiv.org/abs/2508.08134)
*Zeqian Long,Mingzhe Zheng,Kunyu Feng,Xinhua Zhang,Hongyu Liu,Harry Yang,Linfeng Zhang,Qifeng Chen,Yue Ma*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为Follow-Your-Shape的训练无关、掩码无关框架，用于精确控制物体形状编辑，同时严格保护非目标内容。通过轨迹差异图（TDM）和预定的KV注入机制，实现了稳定且忠实的编辑。还提出了ReShapeBench基准测试用于评估。


<details>
  <summary>Details</summary>
Motivation: 现有基于流的图像编辑模型在涉及大规模形状变换的挑战性场景中表现不佳，要么无法实现预期形状变化，要么意外改变非目标区域。

Method: 提出Follow-Your-Shape框架，利用轨迹差异图（TDM）定位可编辑区域，并通过预定的KV注入机制实现稳定编辑。

Result: 实验表明，该方法在大规模形状替换任务中表现出卓越的编辑能力和视觉保真度。

Conclusion: Follow-Your-Shape框架在形状编辑任务中具有显著优势，同时保持了非目标内容的完整性。

Abstract: While recent flow-based image editing models demonstrate general-purpose
capabilities across diverse tasks, they often struggle to specialize in
challenging scenarios -- particularly those involving large-scale shape
transformations. When performing such structural edits, these methods either
fail to achieve the intended shape change or inadvertently alter non-target
regions, resulting in degraded background quality. We propose
Follow-Your-Shape, a training-free and mask-free framework that supports
precise and controllable editing of object shapes while strictly preserving
non-target content. Motivated by the divergence between inversion and editing
trajectories, we compute a Trajectory Divergence Map (TDM) by comparing
token-wise velocity differences between the inversion and denoising paths. The
TDM enables precise localization of editable regions and guides a Scheduled KV
Injection mechanism that ensures stable and faithful editing. To facilitate a
rigorous evaluation, we introduce ReShapeBench, a new benchmark comprising 120
new images and enriched prompt pairs specifically curated for shape-aware
editing. Experiments demonstrate that our method achieves superior editability
and visual fidelity, particularly in tasks requiring large-scale shape
replacement.

</details>


### [225] [Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization](https://arxiv.org/abs/2508.08141)
*Nicholas Klein,Hemlata Tak,James Fullwood,Krishna Regmi,Leonidas Spinoulas,Ganesh Sivaraman,Tianxiang Chen,Elie Khoury*

Main category: cs.CV

Relevance: 40.0

TL;DR: 该论文提出了针对深度伪造视频分类和定位的解决方案，在ACM 1M Deepfakes Detection Challenge中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着视觉和音频生成技术的快速发展，检测合成内容的需求日益迫切，尤其是针对局部细微修改的挑战。

Method: 论文方法参与了ACM 1M Deepfakes Detection Challenge，专注于视频分类和定位任务。

Result: 在时间定位任务中表现最佳，分类任务中排名前四。

Conclusion: 论文展示了在深度伪造检测中的有效性，尤其是在处理细微修改时的能力。

Abstract: The field of visual and audio generation is burgeoning with new
state-of-the-art methods. This rapid proliferation of new techniques
underscores the need for robust solutions for detecting synthetic content in
videos. In particular, when fine-grained alterations via localized
manipulations are performed in visual, audio, or both domains, these subtle
modifications add challenges to the detection algorithms. This paper presents
solutions for the problems of deepfake video classification and localization.
The methods were submitted to the ACM 1M Deepfakes Detection Challenge,
achieving the best performance in the temporal localization task and a top four
ranking in the classification task for the TestA split of the evaluation
dataset.

</details>


### [226] [ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction](https://arxiv.org/abs/2508.08170)
*Chaojun Ni,Guosheng Zhao,Xiaofeng Wang,Zheng Zhu,Wenkang Qin,Xinze Chen,Guanghong Jia,Guan Huang,Wenjun Mei*

Main category: cs.CV

Relevance: 40.0

TL;DR: ReconDreamer-RL利用视频扩散先验和物理模型缩小自动驾驶训练中的模拟与现实差距，通过动态对抗代理和轨迹生成器提升训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有模拟环境与真实世界差异大，导致模拟到现实的差距（sim2real gap），限制了自动驾驶模型的训练效果。

Method: 结合视频扩散先验和运动学模型构建ReconSimulator，引入动态对抗代理（DAA）生成极端场景，提出Cousin轨迹生成器（CTG）解决数据分布偏差。

Result: 实验表明ReconDreamer-RL在端到端自动驾驶训练中优于模仿学习方法，碰撞率降低5倍。

Conclusion: ReconDreamer-RL有效缩小sim2real差距，提升自动驾驶模型的训练效果和鲁棒性。

Abstract: Reinforcement learning for training end-to-end autonomous driving models in
closed-loop simulations is gaining growing attention. However, most simulation
environments differ significantly from real-world conditions, creating a
substantial simulation-to-reality (sim2real) gap. To bridge this gap, some
approaches utilize scene reconstruction techniques to create photorealistic
environments as a simulator. While this improves realistic sensor simulation,
these methods are inherently constrained by the distribution of the training
data, making it difficult to render high-quality sensor data for novel
trajectories or corner case scenarios. Therefore, we propose ReconDreamer-RL, a
framework designed to integrate video diffusion priors into scene
reconstruction to aid reinforcement learning, thereby enhancing end-to-end
autonomous driving training. Specifically, in ReconDreamer-RL, we introduce
ReconSimulator, which combines the video diffusion prior for appearance
modeling and incorporates a kinematic model for physical modeling, thereby
reconstructing driving scenarios from real-world data. This narrows the
sim2real gap for closed-loop evaluation and reinforcement learning. To cover
more corner-case scenarios, we introduce the Dynamic Adversary Agent (DAA),
which adjusts the trajectories of surrounding vehicles relative to the ego
vehicle, autonomously generating corner-case traffic scenarios (e.g., cut-in).
Finally, the Cousin Trajectory Generator (CTG) is proposed to address the issue
of training data distribution, which is often biased toward simple
straight-line movements. Experiments show that ReconDreamer-RL improves
end-to-end autonomous driving training, outperforming imitation learning
methods with a 5x reduction in the Collision Ratio.

</details>


### [227] [CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data](https://arxiv.org/abs/2508.08173)
*Chongke Bi,Xin Gao,Jiangkang Deng,Guan*

Main category: cs.CV

Relevance: 40.0

TL;DR: CD-TVD结合对比学习和改进的扩散模型，从有限的高分辨率数据中实现3D超分辨率，减少对大规模数据集的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决科学模拟中高分辨率数据生成成本高的问题，现有方法依赖大量HR训练数据，限制了多样性应用。

Method: 结合对比学习编码器和改进的扩散模型，预训练学习降级模式，微调时仅需一个新HR时间步。

Result: 在流体和大气模拟数据集上验证了CD-TVD的准确性和资源效率。

Conclusion: CD-TVD为大规模科学模拟的数据增强提供了显著进展。

Abstract: Large-scale scientific simulations require significant resources to generate
high-resolution time-varying data (TVD). While super-resolution is an efficient
post-processing strategy to reduce costs, existing methods rely on a large
amount of HR training data, limiting their applicability to diverse simulation
scenarios. To address this constraint, we proposed CD-TVD, a novel framework
that combines contrastive learning and an improved diffusion-based
super-resolution model to achieve accurate 3D super-resolution from limited
time-step high-resolution data. During pre-training on historical simulation
data, the contrastive encoder and diffusion superresolution modules learn
degradation patterns and detailed features of high-resolution and
low-resolution samples. In the training phase, the improved diffusion model
with a local attention mechanism is fine-tuned using only one newly generated
high-resolution timestep, leveraging the degradation knowledge learned by the
encoder. This design minimizes the reliance on large-scale high-resolution
datasets while maintaining the capability to recover fine-grained details.
Experimental results on fluid and atmospheric simulation datasets confirm that
CD-TVD delivers accurate and resource-efficient 3D super-resolution, marking a
significant advancement in data augmentation for large-scale scientific
simulations. The code is available at
https://github.com/Xin-Gao-private/CD-TVD.

</details>


### [228] [PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation](https://arxiv.org/abs/2508.08179)
*Sihan Zhao,Zixuan Wang,Tianyu Luan,Jia Jia,Wentao Zhu,Jiebo Luo,Junsong Yuan,Nan Xi*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种物理标注方法PP-Motion，用于评估人体运动的物理和感知保真度，结合物理对齐和人类感知损失，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动生成评估方法在物理可行性和人类感知之间存在差距，且主观标注不够鲁棒。

Method: 通过计算运动与物理定律对齐的最小修改量生成连续物理标注，结合Pearson相关损失和人类感知损失训练PP-Motion。

Result: PP-Motion在物理对齐和人类感知保真度上均优于先前工作。

Conclusion: PP-Motion提供了一种更全面的运动保真度评估方法，兼顾物理和感知。

Abstract: Human motion generation has found widespread applications in AR/VR, film,
sports, and medical rehabilitation, offering a cost-effective alternative to
traditional motion capture systems. However, evaluating the fidelity of such
generated motions is a crucial, multifaceted task. Although previous approaches
have attempted at motion fidelity evaluation using human perception or physical
constraints, there remains an inherent gap between human-perceived fidelity and
physical feasibility. Moreover, the subjective and coarse binary labeling of
human perception further undermines the development of a robust data-driven
metric. We address these issues by introducing a physical labeling method. This
method evaluates motion fidelity by calculating the minimum modifications
needed for a motion to align with physical laws. With this approach, we are
able to produce fine-grained, continuous physical alignment annotations that
serve as objective ground truth. With these annotations, we propose PP-Motion,
a novel data-driven metric to evaluate both physical and perceptual fidelity of
human motion. To effectively capture underlying physical priors, we employ
Pearson's correlation loss for the training of our metric. Additionally, by
incorporating a human-based perceptual fidelity loss, our metric can capture
fidelity that simultaneously considers both human perception and physical
alignment. Experimental results demonstrate that our metric, PP-Motion, not
only aligns with physical laws but also aligns better with human perception of
motion fidelity than previous work.

</details>


### [229] [THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening](https://arxiv.org/abs/2508.08183)
*Hongkun Jin,Hongcheng Jiang,Zejun Zhang,Yuan Zhang,Jia Fu,Tingfeng Li,Kai Luo*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为THAT的Transformer框架，通过改进高频特征表示和令牌选择，解决了Vision Transformers在超光谱图像融合中的局限性。


<details>
  <summary>Details</summary>
Motivation: 超光谱图像融合中，Vision Transformers存在高频信号丢失和冗余令牌问题，影响了重建精度。

Method: THAT框架引入了Pivotal Token Selective Attention（PTSA）和Multi-level Variance-aware Feed-forward Network（MVFN），以优化令牌选择和增强高频细节学习。

Result: 实验表明，THAT在标准基准测试中实现了最先进的性能，提高了重建质量和效率。

Conclusion: THAT通过改进高频特征表示和令牌选择，显著提升了超光谱图像融合的性能。

Abstract: Transformer-based methods have demonstrated strong potential in hyperspectral
pansharpening by modeling long-range dependencies. However, their effectiveness
is often limited by redundant token representations and a lack of multi-scale
feature modeling. Hyperspectral images exhibit intrinsic spectral priors (e.g.,
abundance sparsity) and spatial priors (e.g., non-local similarity), which are
critical for accurate reconstruction. From a spectral-spatial perspective,
Vision Transformers (ViTs) face two major limitations: they struggle to
preserve high-frequency components--such as material edges and texture
transitions--and suffer from attention dispersion across redundant tokens.
These issues stem from the global self-attention mechanism, which tends to
dilute high-frequency signals and overlook localized details. To address these
challenges, we propose the Token-wise High-frequency Augmentation Transformer
(THAT), a novel framework designed to enhance hyperspectral pansharpening
through improved high-frequency feature representation and token selection.
Specifically, THAT introduces: (1) Pivotal Token Selective Attention (PTSA) to
prioritize informative tokens and suppress redundancy; (2) a Multi-level
Variance-aware Feed-forward Network (MVFN) to enhance high-frequency detail
learning. Experiments on standard benchmarks show that THAT achieves
state-of-the-art performance with improved reconstruction quality and
efficiency. The source code is available at https://github.com/kailuo93/THAT.

</details>


### [230] [Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model](https://arxiv.org/abs/2508.08199)
*Peiqi He,Zhenhao Zhang,Yixiang Zhang,Xiongjun Zhao,Shaoliang Peng*

Main category: cs.CV

Relevance: 40.0

TL;DR: Spatial-ORMLLM是一个用于手术室3D空间推理的大型视觉语言模型，仅使用RGB模态推断体积和语义线索，无需额外传感器或专家标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略MLLM的3D能力，且手术室多模态数据难以获取，2D数据无法捕捉复杂场景细节。

Method: 提出Spatial-ORMLLM，结合2D输入与3D空间知识，通过端到端MLLM框架实现3D场景推理。

Result: 在多个临床数据集上达到SOTA性能，泛化能力强。

Conclusion: Spatial-ORMLLM为手术室任务提供了详细且全面的空间上下文。

Abstract: Precise spatial modeling in the operating room (OR) is foundational to many
clinical tasks, supporting intraoperative awareness, hazard avoidance, and
surgical decision-making. While existing approaches leverage large-scale
multimodal datasets for latent-space alignment to implicitly learn spatial
relationships, they overlook the 3D capabilities of MLLMs. However, this
approach raises two issues: (1) Operating rooms typically lack multiple video
and audio sensors, making multimodal 3D data difficult to obtain; (2) Training
solely on readily available 2D data fails to capture fine-grained details in
complex scenes. To address this gap, we introduce Spatial-ORMLLM, the first
large vision-language model for 3D spatial reasoning in operating rooms using
only RGB modality to infer volumetric and semantic cues, enabling downstream
medical tasks with detailed and holistic spatial context. Spatial-ORMLLM
incorporates a Spatial-Enhanced Feature Fusion Block, which integrates 2D
modality inputs with rich 3D spatial knowledge extracted by the estimation
algorithm and then feeds the combined features into the visual tower. By
employing a unified end-to-end MLLM framework, it combines powerful spatial
features with textual features to deliver robust 3D scene reasoning without any
additional expert annotations or sensor inputs. Experiments on multiple
benchmark clinical datasets demonstrate that Spatial-ORMLLM achieves
state-of-the-art performance and generalizes robustly to previously unseen
surgical scenarios and downstream tasks.

</details>


### [231] [OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution](https://arxiv.org/abs/2508.08227)
*Zhiqiang Wu,Zhaomang Sun,Tong Zhou,Bingtao Fu,Ji Cong,Yitong Dong,Huaqi Zhang,Xuan Tang,Mingsong Chen,Xian Wei*

Main category: cs.CV

Relevance: 40.0

TL;DR: OMGSR提出了一种基于DDPM/FM的一步式真实图像超分辨率框架，通过在中时间步注入低质量图像潜在分布，优化生成效果。


<details>
  <summary>Details</summary>
Motivation: 解决低质量图像潜在分布与高斯噪声潜在分布之间的差距问题，以更有效利用生成先验。

Method: 提出OMGSR框架，包括中时间步注入、潜在分布细化损失和重叠分块LPIPS/GAN损失。

Result: OMGSR-S/F在512分辨率下表现优异，OMGSR-F在所有参考指标中占优，1k和2k分辨率下也取得优秀结果。

Conclusion: OMGSR框架有效提升了一步式真实图像超分辨率的性能，尤其在细节生成上表现突出。

Abstract: Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM)
generative models show promising potential for one-step Real-World Image
Super-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a
Low-Quality (LQ) image latent distribution at the initial timestep. However, a
fundamental gap exists between the LQ image latent distribution and the
Gaussian noisy latent distribution, limiting the effective utilization of
generative priors. We observe that the noisy latent distribution at DDPM/FM
mid-timesteps aligns more closely with the LQ image latent distribution. Based
on this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a
universal framework applicable to DDPM/FM-based generative models. OMGSR
injects the LQ image latent distribution at a pre-computed mid-timestep,
incorporating the proposed Latent Distribution Refinement loss to alleviate the
latent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to
eliminate checkerboard artifacts in image generation. Within this framework, we
instantiate OMGSR for DDPM/FM-based generative models with two variants:
OMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate
that OMGSR-S/F achieves balanced/excellent performance across quantitative and
qualitative metrics at 512-resolution. Notably, OMGSR-F establishes
overwhelming dominance in all reference metrics. We further train a
1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which
yields excellent results, especially in the details of the image generation. We
also generate 2k-resolution images by the 1k-resolution OMGSR-F using our
two-stage Tiled VAE & Diffusion.

</details>


### [232] [Cut2Next: Generating Next Shot via In-Context Tuning](https://arxiv.org/abs/2508.08244)
*Jingwen He,Hongbo Liu,Jiajun Li,Ziqi Huang,Yu Qiao,Wanli Ouyang,Ziwei Liu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了Next Shot Generation (NSG)框架Cut2Next，利用Diffusion Transformer (DiT)生成符合专业编辑模式和电影连续性的高质量镜头。


<details>
  <summary>Details</summary>
Motivation: 当前方法仅关注视觉一致性，忽略了叙事流畅性和电影完整性，Cut2Next旨在解决这一问题。

Method: 采用Hierarchical Multi-Prompting策略和Diffusion Transformer，结合Context-Aware Condition Injection (CACI)和Hierarchical Attention Mask (HAM)架构创新。

Result: 实验表明Cut2Next在视觉一致性和文本保真度上表现优异，用户研究显示其更符合编辑意图和电影连续性。

Conclusion: Cut2Next能生成高质量、叙事性强且电影连贯的镜头。

Abstract: Effective multi-shot generation demands purposeful, film-like transitions and
strict cinematic continuity. Current methods, however, often prioritize basic
visual consistency, neglecting crucial editing patterns (e.g., shot/reverse
shot, cutaways) that drive narrative flow for compelling storytelling. This
yields outputs that may be visually coherent but lack narrative sophistication
and true cinematic integrity. To bridge this, we introduce Next Shot Generation
(NSG): synthesizing a subsequent, high-quality shot that critically conforms to
professional editing patterns while upholding rigorous cinematic continuity.
Our framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs
in-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This
strategy uses Relational Prompts to define overall context and inter-shot
editing styles. Individual Prompts then specify per-shot content and
cinematographic attributes. Together, these guide Cut2Next to generate
cinematically appropriate next shots. Architectural innovations, Context-Aware
Condition Injection (CACI) and Hierarchical Attention Mask (HAM), further
integrate these diverse signals without introducing new parameters. We
construct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with
hierarchical prompts, and introduce CutBench for evaluation. Experiments show
Cut2Next excels in visual consistency and text fidelity. Crucially, user
studies reveal a strong preference for Cut2Next, particularly for its adherence
to intended editing patterns and overall cinematic continuity, validating its
ability to generate high-quality, narratively expressive, and cinematically
coherent subsequent shots.

</details>


### [233] [StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation](https://arxiv.org/abs/2508.08248)
*Shuyuan Tu,Yueming Pan,Yinming Huang,Xintong Han,Zhen Xing,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

Relevance: 40.0

TL;DR: StableAvatar是一种端到端的视频扩散变换器，能够生成无限长度的高质量视频，解决了现有模型在音频同步和身份一致性上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动的虚拟化身视频生成模型难以生成长视频且音频同步和身份一致性不佳。

Method: StableAvatar结合了定制训练和推理模块，引入时间步感知音频适配器和音频原生引导机制，以及动态加权滑动窗口策略。

Result: 实验证明StableAvatar在质量和数量上均优于现有方法。

Conclusion: StableAvatar通过改进音频建模和推理策略，显著提升了长视频生成的质量和一致性。

Abstract: Current diffusion models for audio-driven avatar video generation struggle to
synthesize long videos with natural audio synchronization and identity
consistency. This paper presents StableAvatar, the first end-to-end video
diffusion transformer that synthesizes infinite-length high-quality videos
without post-processing. Conditioned on a reference image and audio,
StableAvatar integrates tailored training and inference modules to enable
infinite-length video generation. We observe that the main reason preventing
existing models from generating long videos lies in their audio modeling. They
typically rely on third-party off-the-shelf extractors to obtain audio
embeddings, which are then directly injected into the diffusion model via
cross-attention. Since current diffusion backbones lack any audio-related
priors, this approach causes severe latent distribution error accumulation
across video clips, leading the latent distribution of subsequent segments to
drift away from the optimal distribution gradually. To address this,
StableAvatar introduces a novel Time-step-aware Audio Adapter that prevents
error accumulation via time-step-aware modulation. During inference, we propose
a novel Audio Native Guidance Mechanism to further enhance the audio
synchronization by leveraging the diffusion's own evolving joint audio-latent
prediction as a dynamic guidance signal. To enhance the smoothness of the
infinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy
that fuses latent over time. Experiments on benchmarks show the effectiveness
of StableAvatar both qualitatively and quantitatively.

</details>


### [234] [ReferSplat: Referring Segmentation in 3D Gaussian Splatting](https://arxiv.org/abs/2508.08252)
*Shuting He,Guangquan Jie,Changshuo Wang,Yun Zhou,Shuming Hu,Guanbin Li,Henghui Ding*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种新任务R3DGS，旨在通过自然语言描述在3D高斯场景中分割目标物体，并构建了首个数据集Ref-LERF。提出的ReferSplat框架在R3DGS任务和3D开放词汇分割基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 推动具身AI的发展，解决3D多模态理解和空间关系建模的挑战。

Method: 提出ReferSplat框架，显式建模3D高斯点与自然语言表达的空间关系。

Result: ReferSplat在R3DGS任务和3D开放词汇分割基准上达到最先进性能。

Conclusion: R3DGS任务和ReferSplat框架为3D多模态理解提供了新方向。

Abstract: We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task
that aims to segment target objects in a 3D Gaussian scene based on natural
language descriptions, which often contain spatial relationships or object
attributes. This task requires the model to identify newly described objects
that may be occluded or not directly visible in a novel view, posing a
significant challenge for 3D multi-modal understanding. Developing this
capability is crucial for advancing embodied AI. To support research in this
area, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that
3D multi-modal understanding and spatial relationship modeling are key
challenges for R3DGS. To address these challenges, we propose ReferSplat, a
framework that explicitly models 3D Gaussian points with natural language
expressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art
performance on both the newly proposed R3DGS task and 3D open-vocabulary
segmentation benchmarks. Dataset and code are available at
https://github.com/heshuting555/ReferSplat.

</details>


### [235] [Learning an Implicit Physics Model for Image-based Fluid Simulation](https://arxiv.org/abs/2508.08254)
*Emily Yue-Ting Jia,Jiageng Mao,Zhiyuan Gao,Yajie Zhao,Yue Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于物理约束的神经网络方法，从单张图像生成物理一致的4D场景动画。


<details>
  <summary>Details</summary>
Motivation: 人类能够从静态图像想象4D场景，但现有方法生成的动画常违背物理规律。本文旨在通过物理约束提升动画的真实性。

Method: 使用物理信息神经网络预测运动，结合Navier-Stokes方程约束，并通过3D高斯特征渲染动画。

Result: 实验表明，该方法显著提升了动画的物理一致性，优于现有方法。

Conclusion: 通过物理约束和神经网络结合，实现了更真实的4D场景生成。

Abstract: Humans possess an exceptional ability to imagine 4D scenes, encompassing both
motion and 3D geometry, from a single still image. This ability is rooted in
our accumulated observations of similar scenes and an intuitive understanding
of physics. In this paper, we aim to replicate this capacity in neural
networks, specifically focusing on natural fluid imagery. Existing methods for
this task typically employ simplistic 2D motion estimators to animate the
image, leading to motion predictions that often defy physical principles,
resulting in unrealistic animations. Our approach introduces a novel method for
generating 4D scenes with physics-consistent animation from a single image. We
propose the use of a physics-informed neural network that predicts motion for
each surface point, guided by a loss term derived from fundamental physical
principles, including the Navier-Stokes equations. To capture appearance, we
predict feature-based 3D Gaussians from the input image and its estimated
depth, which are then animated using the predicted motions and rendered from
any desired camera perspective. Experimental results highlight the
effectiveness of our method in producing physically plausible animations,
showcasing significant performance improvements over existing methods. Our
project page is https://physfluid.github.io/ .

</details>


### [236] [KLASSify to Verify: Audio-Visual Deepfake Detection Using SSL-based Audio and Handcrafted Visual Features](https://arxiv.org/abs/2508.07337)
*Ivan Kukanov,Jun Wah Ng*

Main category: eess.AS

Relevance: 40.0

TL;DR: 论文提出了一种多模态方法用于AV-Deepfake1M 2025挑战，结合手工特征和自监督学习提升检测鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着音频驱动的人脸生成器和TTS模型的快速发展，需要更鲁棒的深度伪造检测方法，尤其是在面对新型攻击时。

Method: 视觉模态采用手工特征提升可解释性；音频模态结合自监督学习骨干和图注意力网络捕获丰富表示。

Result: 在AV-Deepfake1M++数据集上，多模态系统在分类任务中AUC达92.78%，音频模态下时序定位IoU为0.3536。

Conclusion: 该方法在性能和实际部署间取得平衡，注重鲁棒性和可解释性。

Abstract: The rapid development of audio-driven talking head generators and advanced
Text-To-Speech (TTS) models has led to more sophisticated temporal deepfakes.
These advances highlight the need for robust methods capable of detecting and
localizing deepfakes, even under novel, unseen attack scenarios. Current
state-of-the-art deepfake detectors, while accurate, are often computationally
expensive and struggle to generalize to novel manipulation techniques. To
address these challenges, we propose multimodal approaches for the
AV-Deepfake1M 2025 challenge. For the visual modality, we leverage handcrafted
features to improve interpretability and adaptability. For the audio modality,
we adapt a self-supervised learning (SSL) backbone coupled with graph attention
networks to capture rich audio representations, improving detection robustness.
Our approach strikes a balance between performance and real-world deployment,
focusing on resilience and potential interpretability. On the AV-Deepfake1M++
dataset, our multimodal system achieves AUC of 92.78% for deepfake
classification task and IoU of 0.3536 for temporal localization using only the
audio modality.

</details>


### [237] [AD-AVSR: Asymmetric Dual-stream Enhancement for Robust Audio-Visual Speech Recognition](https://arxiv.org/abs/2508.07608)
*Junxiao Xue,Xiaozhen Liu,Xuecheng Wu,Xinyi Yin,Danlei Huang,Fei Yu*

Main category: cs.MM

Relevance: 40.0

TL;DR: 论文提出了一种双向模态增强的AVSR框架AD-AVSR，通过音频双流编码和跨模态噪声抑制模块提升语音识别性能，尤其在噪声环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有AVSR方法在非对称信息条件下难以捕捉音频-视觉数据的异质性和互补性，限制了性能。

Method: 采用音频双流编码策略和双向模态增强模块（音频感知视觉优化模块和跨模态噪声抑制掩码模块），结合阈值选择机制过滤弱相关数据。

Result: 在LRS2和LRS3数据集上，AD-AVSR性能优于现有方法，噪声鲁棒性显著提升。

Conclusion: AD-AVSR框架通过双向信息流和噪声抑制设计，有效提升了AVSR的性能和鲁棒性。

Abstract: Audio-visual speech recognition (AVSR) combines audio-visual modalities to
improve speech recognition, especially in noisy environments. However, most
existing methods deploy the unidirectional enhancement or symmetric fusion
manner, which limits their capability to capture heterogeneous and
complementary correlations of audio-visual data-especially under asymmetric
information conditions. To tackle these gaps, we introduce a new AVSR framework
termed AD-AVSR based on bidirectional modality enhancement. Specifically, we
first introduce the audio dual-stream encoding strategy to enrich audio
representations from multiple perspectives and intentionally establish
asymmetry to support subsequent cross-modal interactions. The enhancement
process involves two key components, Audio-aware Visual Refinement Module for
enhanced visual representations under audio guidance, and Cross-modal Noise
Suppression Masking Module which refines audio representations using visual
cues, collaboratively leading to the closed-loop and bidirectional information
flow. To further enhance correlation robustness, we adopt a threshold-based
selection mechanism to filter out irrelevant or weakly correlated audio-visual
pairs. Extensive experimental results on the LRS2 and LRS3 datasets indicate
that our AD-AVSR consistently surpasses SOTA methods in both performance and
noise robustness, highlighting the effectiveness of our model design.

</details>


### [238] [IPBA: Imperceptible Perturbation Backdoor Attack in Federated Self-Supervised Learning](https://arxiv.org/abs/2508.08031)
*Jiayao Wang,Yang Song,Zhendong Zhao,Jiale Zhang,Qilin Wu,Junwu Zhu,Dongfang Zhao*

Main category: cs.CR

Relevance: 40.0

TL;DR: 论文提出了一种针对联邦自监督学习（FSSL）的隐蔽后门攻击方法IPBA，解决了传统方法在隐蔽性和实用性上的不足。


<details>
  <summary>Details</summary>
Motivation: FSSL因其可扩展性和隐私保护潜力受到关注，但研究表明其易受后门攻击。现有方法隐蔽性不足，难以满足实际需求。

Method: IPBA通过解耦后门样本与增强样本的特征分布，并引入Sliced-Wasserstein距离优化触发生成，提升攻击效果和隐蔽性。

Result: 实验表明IPBA在多种FSSL场景和数据集中显著优于现有方法，且对防御机制具有强鲁棒性。

Conclusion: IPBA为FSSL中的后门攻击提供了更隐蔽和有效的解决方案。

Abstract: Federated self-supervised learning (FSSL) combines the advantages of
decentralized modeling and unlabeled representation learning, serving as a
cutting-edge paradigm with strong potential for scalability and privacy
preservation. Although FSSL has garnered increasing attention, research
indicates that it remains vulnerable to backdoor attacks. Existing methods
generally rely on visually obvious triggers, which makes it difficult to meet
the requirements for stealth and practicality in real-world deployment. In this
paper, we propose an imperceptible and effective backdoor attack method against
FSSL, called IPBA. Our empirical study reveals that existing imperceptible
triggers face a series of challenges in FSSL, particularly limited
transferability, feature entanglement with augmented samples, and
out-of-distribution properties. These issues collectively undermine the
effectiveness and stealthiness of traditional backdoor attacks in FSSL. To
overcome these challenges, IPBA decouples the feature distributions of backdoor
and augmented samples, and introduces Sliced-Wasserstein distance to mitigate
the out-of-distribution properties of backdoor samples, thereby optimizing the
trigger generation process. Our experimental results on several FSSL scenarios
and datasets show that IPBA significantly outperforms existing backdoor attack
methods in performance and exhibits strong robustness under various defense
mechanisms.

</details>


### [239] [DiTalker: A Unified DiT-based Framework for High-Quality and Speaking Styles Controllable Portrait Animation](https://arxiv.org/abs/2508.06511)
*He Feng,Yongjia Ma,Donglin Di,Lei Fan,Tonghua Su,Xiangqian Wu*

Main category: cs.CV

Relevance: 30.0

TL;DR: DiTalker是一个基于DiT的统一框架，用于可控说话风格的人像动画，通过分离音频和说话风格，优化唇同步和细节保留。


<details>
  <summary>Details</summary>
Motivation: 现有扩散基人像动画方法主要关注唇同步或静态情感变换，忽略了动态风格（如头部运动），且计算开销大。

Method: 设计风格-情感编码模块和音频-风格融合模块，通过并行交叉注意力层解耦音频与说话风格，并采用优化约束提升结果质量。

Result: 实验表明DiTalker在唇同步和说话风格可控性上表现优越。

Conclusion: DiTalker提供了一种高效且可控的人像动画解决方案。

Abstract: Portrait animation aims to synthesize talking videos from a static reference
face, conditioned on audio and style frame cues (e.g., emotion and head poses),
while ensuring precise lip synchronization and faithful reproduction of
speaking styles. Existing diffusion-based portrait animation methods primarily
focus on lip synchronization or static emotion transformation, often
overlooking dynamic styles such as head movements. Moreover, most of these
methods rely on a dual U-Net architecture, which preserves identity consistency
but incurs additional computational overhead. To this end, we propose DiTalker,
a unified DiT-based framework for speaking style-controllable portrait
animation. We design a Style-Emotion Encoding Module that employs two separate
branches: a style branch extracting identity-specific style information (e.g.,
head poses and movements), and an emotion branch extracting identity-agnostic
emotion features. We further introduce an Audio-Style Fusion Module that
decouples audio and speaking styles via two parallel cross-attention layers,
using these features to guide the animation process. To enhance the quality of
results, we adopt and modify two optimization constraints: one to improve lip
synchronization and the other to preserve fine-grained identity and background
details. Extensive experiments demonstrate the superiority of DiTalker in terms
of lip synchronization and speaking style controllability. Project Page:
https://thenameishope.github.io/DiTalker/

</details>


### [240] [Frequency Prior Guided Matching: A Data Augmentation Approach for Generalizable Semi-Supervised Polyp Segmentation](https://arxiv.org/abs/2508.06517)
*Haoran Xi,Chen Liu,Xiaolin Li*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种名为FPGM的频率先验引导匹配框架，用于解决息肉分割中的领域适应问题，通过利用息肉边缘的频率特征提升模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于标注数据有限和领域偏移导致的性能下降，开发鲁棒的息肉分割模型具有挑战性。现有半监督学习方法忽视息肉的结构特性，泛化能力不足。

Method: FPGM通过两阶段过程：首先学习标记息肉边缘区域的域不变频率先验，然后对未标记图像进行频谱扰动，对齐其振幅谱以保留结构完整性。

Result: 在六个公共数据集上验证，FPGM优于十种竞争方法，在零样本泛化场景中Dice分数提升超过10%。

Conclusion: FPGM显著提升了跨领域鲁棒性，为临床部署提供了有效的解决方案。

Abstract: Automated polyp segmentation is essential for early diagnosis of colorectal
cancer, yet developing robust models remains challenging due to limited
annotated data and significant performance degradation under domain shift.
Although semi-supervised learning (SSL) reduces annotation requirements,
existing methods rely on generic augmentations that ignore polyp-specific
structural properties, resulting in poor generalization to new imaging centers
and devices. To address this, we introduce Frequency Prior Guided Matching
(FPGM), a novel augmentation framework built on a key discovery: polyp edges
exhibit a remarkably consistent frequency signature across diverse datasets.
FPGM leverages this intrinsic regularity in a two-stage process. It first
learns a domain-invariant frequency prior from the edge regions of labeled
polyps. Then, it performs principled spectral perturbations on unlabeled
images, aligning their amplitude spectra with this learned prior while
preserving phase information to maintain structural integrity. This targeted
alignment normalizes domain-specific textural variations, thereby compelling
the model to learn the underlying, generalizable anatomical structure.
Validated on six public datasets, FPGM establishes a new state-of-the-art
against ten competing methods. It demonstrates exceptional zero-shot
generalization capabilities, achieving over 10% absolute gain in Dice score in
data-scarce scenarios. By significantly enhancing cross-domain robustness, FPGM
presents a powerful solution for clinically deployable polyp segmentation under
limited supervision.

</details>


### [241] [Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset](https://arxiv.org/abs/2508.06537)
*Shantanusinh Parmar*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一个智能手机天文摄影数据集MobilTelesco，用于评估目标检测模型在稀疏特征条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测数据集（如ImageNet、COCO）缺乏非商业领域的稀疏信号特征，MobilTelesco填补了这一空白。

Method: 在MobilTelesco数据集上对多个目标检测模型进行基准测试。

Result: 揭示了模型在特征不足条件下的挑战。

Conclusion: MobilTelesco为稀疏特征场景下的目标检测研究提供了新工具。

Abstract: Object detection models are typically trained on datasets like ImageNet,
COCO, and PASCAL VOC, which focus on everyday objects. However, these lack
signal sparsity found in non-commercial domains. MobilTelesco, a
smartphone-based astrophotography dataset, addresses this by providing sparse
night-sky images. We benchmark several detection models on it, highlighting
challenges under feature-deficient conditions.

</details>


### [242] [Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection](https://arxiv.org/abs/2508.06552)
*Unisha Joshi*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种解决深度伪造数据集中年龄偏见的年龄多样化数据集，并通过实验验证其公平性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造数据集存在年龄偏见，影响检测模型的公平性。

Method: 通过整合现有数据集（Celeb-DF、FaceForensics++、UTKFace）和生成合成数据，构建年龄多样化数据集，并使用XceptionNet、EfficientNet和LipForensics模型评估其效果。

Result: 模型在年龄多样化数据集上表现更公平，整体准确率和跨数据集泛化能力提升。

Conclusion: 研究提供了一个可复现的公平性深度伪造数据集和模型流程，为未来研究奠定基础。

Abstract: The challenges associated with deepfake detection are increasing
significantly with the latest advancements in technology and the growing
popularity of deepfake videos and images. Despite the presence of numerous
detection models, demographic bias in the deepfake dataset remains largely
unaddressed. This paper focuses on the mitigation of age-specific bias in the
deepfake dataset by introducing an age-diverse deepfake dataset that will
improve fairness across age groups. The dataset is constructed through a
modular pipeline incorporating the existing deepfake datasets Celeb-DF,
FaceForensics++, and UTKFace datasets, and the creation of synthetic data to
fill the age distribution gaps. The effectiveness and generalizability of this
dataset are evaluated using three deepfake detection models: XceptionNet,
EfficientNet, and LipForensics. Evaluation metrics, including AUC, pAUC, and
EER, revealed that models trained on the age-diverse dataset demonstrated
fairer performance across age groups, improved overall accuracy, and higher
generalization across datasets. This study contributes a reproducible,
fairness-aware deepfake dataset and model pipeline that can serve as a
foundation for future research in fairer deepfake detection. The complete
dataset and implementation code are available at
https://github.com/unishajoshi/age-diverse-deepfake-detection.

</details>


### [243] [StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback](https://arxiv.org/abs/2508.06555)
*Hongbo Ma,Fei Shen,Hongbin Xu,Xiaoce Wang,Gang Xu,Jinkai Zheng,Liangqiong Qu,Ming Li*

Main category: cs.CV

Relevance: 30.0

TL;DR: StyleTailor是一个协作代理框架，通过多级负面反馈驱动的视觉细化范式，实现个性化时尚设计和推荐。


<details>
  <summary>Details</summary>
Motivation: 个性化时尚设计领域尚未充分探索，StyleTailor旨在通过协作代理框架提升购物体验。

Method: 采用多级负面反馈驱动的视觉细化范式，核心包括Designer和Consultant两个代理，通过分层视觉语言模型反馈逐步优化输出。

Result: 在风格一致性、视觉质量等方面表现优异，超越无负面反馈的基线方法。

Conclusion: StyleTailor为智能时尚系统设定了新基准。

Abstract: The advancement of intelligent agents has revolutionized problem-solving
across diverse domains, yet solutions for personalized fashion styling remain
underexplored, which holds immense promise for promoting shopping experiences.
In this work, we present StyleTailor, the first collaborative agent framework
that seamlessly unifies personalized apparel design, shopping recommendation,
virtual try-on, and systematic evaluation into a cohesive workflow. To this
end, StyleTailor pioneers an iterative visual refinement paradigm driven by
multi-level negative feedback, enabling adaptive and precise user alignment.
Specifically, our framework features two core agents, i.e., Designer for
personalized garment selection and Consultant for virtual try-on, whose outputs
are progressively refined via hierarchical vision-language model feedback
spanning individual items, complete outfits, and try-on efficacy.
Counterexamples are aggregated into negative prompts, forming a closed-loop
mechanism that enhances recommendation quality.To assess the performance, we
introduce a comprehensive evaluation suite encompassing style consistency,
visual quality, face similarity, and artistic appraisal. Extensive experiments
demonstrate StyleTailor's superior performance in delivering personalized
designs and recommendations, outperforming strong baselines without negative
feedback and establishing a new benchmark for intelligent fashion systems.

</details>


### [244] [Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC](https://arxiv.org/abs/2508.06564)
*Guanyu Hu,Dimitrios Kollias,Xinyu Yang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于CLIP的视觉情感引导锚定（VEGA）机制，通过引入情感类别视觉语义提升多模态情感识别性能。


<details>
  <summary>Details</summary>
Motivation: 多模态情感识别任务中，现有模型缺乏心理学先验指导多模态对齐，导致性能受限。

Method: 利用CLIP的图像编码器构建情感视觉锚点，结合双分支架构和自蒸馏策略。

Result: 在IEMOCAP和MELD数据集上达到最优性能。

Conclusion: VEGA机制通过心理学理论指导多模态对齐，显著提升识别效果。

Abstract: Multimodal Emotion Recognition in Conversations remains a challenging task
due to the complex interplay of textual, acoustic and visual signals. While
recent models have improved performance via advanced fusion strategies, they
often lack psychologically meaningful priors to guide multimodal alignment. In
this paper, we revisit the use of CLIP and propose a novel Visual Emotion
Guided Anchoring (VEGA) mechanism that introduces class-level visual semantics
into the fusion and classification process. Distinct from prior work that
primarily utilizes CLIP's textual encoder, our approach leverages its image
encoder to construct emotion-specific visual anchors based on facial exemplars.
These anchors guide unimodal and multimodal features toward a perceptually
grounded and psychologically aligned representation space, drawing inspiration
from cognitive theories (prototypical emotion categories and multisensory
integration). A stochastic anchor sampling strategy further enhances robustness
by balancing semantic stability and intra-class diversity. Integrated into a
dual-branch architecture with self-distillation, our VEGA-augmented model
achieves sota performance on IEMOCAP and MELD. Code is available at:
https://github.com/dkollias/VEGA.

</details>


### [245] [Bridging Brain Connectomes and Clinical Reports for Early Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.06565)
*Jing Zhang,Xiaowei Yu,Minheng Chen,Lu Zhang,Tong Chen,Yan Zhuang,Chao Cao,Yanjun Lyu,Li Su,Tianming Liu,Dajiang Zhu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种将脑成像数据与临床报告对齐的新框架，通过共享跨模态潜在空间增强表征学习，用于轻度认知障碍（MCI）的诊断。


<details>
  <summary>Details</summary>
Motivation: 解决如何有效链接客观成像数据与主观文本报告（如医生笔记）的挑战，以提升临床诊断效果。

Method: 将脑网络子网络视为成像数据的标记，与临床报告中的词标记对齐，构建共享跨模态潜在空间。

Result: 在ADNI数据集上实现了最先进的预测性能，并识别出有临床意义的连接组-文本对。

Conclusion: 该方法为阿尔茨海默病的早期机制提供了新见解，支持开发临床有用的多模态生物标志物。

Abstract: Integrating brain imaging data with clinical reports offers a valuable
opportunity to leverage complementary multimodal information for more effective
and timely diagnosis in practical clinical settings. This approach has gained
significant attention in brain disorder research, yet a key challenge remains:
how to effectively link objective imaging data with subjective text-based
reports, such as doctors' notes. In this work, we propose a novel framework
that aligns brain connectomes with clinical reports in a shared cross-modal
latent space at both the subject and connectome levels, thereby enhancing
representation learning. The key innovation of our approach is that we treat
brain subnetworks as tokens of imaging data, rather than raw image patches, to
align with word tokens in clinical reports. This enables a more efficient
identification of system-level associations between neuroimaging findings and
clinical observations, which is critical since brain disorders often manifest
as network-level abnormalities rather than isolated regional alterations. We
applied our method to mild cognitive impairment (MCI) using the ADNI dataset.
Our approach not only achieves state-of-the-art predictive performance but also
identifies clinically meaningful connectome-text pairs, offering new insights
into the early mechanisms of Alzheimer's disease and supporting the development
of clinically useful multimodal biomarkers.

</details>


### [246] [Surformer v1: Transformer-Based Surface Classification Using Tactile and Vision Features](https://arxiv.org/abs/2508.06566)
*Manish Kansana,Elias Hossain,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.CV

Relevance: 30.0

TL;DR: Surformer v1是一种基于Transformer的架构，用于结合触觉和视觉输入进行表面材料分类，在准确性和效率之间取得了平衡。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过结合触觉和视觉输入，提升机器人感知和物理交互中的表面材料识别能力。

Method: 提出Surformer v1架构，结合模态特定编码器和跨模态注意力层，对比了触觉单模态和多模态（触觉+视觉）分类的性能。

Result: Surformer v1在触觉单模态分类中表现最佳，多模态下达到99.4%准确率，推理时间0.77毫秒。

Conclusion: Surformer v1在准确性和计算效率之间提供了优越的平衡，适用于实时应用。

Abstract: Surface material recognition is a key component in robotic perception and
physical interaction, particularly when leveraging both tactile and visual
sensory inputs. In this work, we propose Surformer v1, a transformer-based
architecture designed for surface classification using structured tactile
features and PCA-reduced visual embeddings extracted via ResNet-50. The model
integrates modality-specific encoders with cross-modal attention layers,
enabling rich interactions between vision and touch. Currently,
state-of-the-art deep learning models for vision tasks have achieved remarkable
performance. With this in mind, our first set of experiments focused
exclusively on tactile-only surface classification. Using feature engineering,
we trained and evaluated multiple machine learning models, assessing their
accuracy and inference time. We then implemented an encoder-only Transformer
model tailored for tactile features. This model not only achieved the highest
accuracy but also demonstrated significantly faster inference time compared to
other evaluated models, highlighting its potential for real-time applications.
To extend this investigation, we introduced a multimodal fusion setup by
combining vision and tactile inputs. We trained both Surformer v1 (using
structured features) and Multimodal CNN (using raw images) to examine the
impact of feature-based versus image-based multimodal learning on
classification accuracy and computational efficiency. The results showed that
Surformer v1 achieved 99.4% accuracy with an inference time of 0.77 ms, while
the Multimodal CNN achieved slightly higher accuracy but required significantly
more inference time. These findings suggest Surformer v1 offers a compelling
balance between accuracy, efficiency, and computational cost for surface
material recognition.

</details>


### [247] [CycleDiff: Cycle Diffusion Models for Unpaired Image-to-image Translation](https://arxiv.org/abs/2508.06625)
*Shilong Zou,Yuhang Huang,Renjiao Yi,Chenyang Zhu,Kai Xu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于扩散模型的跨域图像翻译方法，通过联合学习框架对齐扩散和翻译过程，提升了全局最优性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型中扩散过程与翻译过程未对齐的问题，避免局部最优，提升翻译效果。

Method: 提出联合学习框架，提取图像成分表示干净信号，并引入时间依赖的翻译网络，实现端到端学习。

Result: 在多种跨域和跨模态翻译任务中表现优于现有方法，生成效果更优。

Conclusion: 联合学习框架有效提升了扩散模型在图像翻译中的全局最优性和性能。

Abstract: We introduce a diffusion-based cross-domain image translator in the absence
of paired training data. Unlike GAN-based methods, our approach integrates
diffusion models to learn the image translation process, allowing for more
coverable modeling of the data distribution and performance improvement of the
cross-domain translation. However, incorporating the translation process within
the diffusion process is still challenging since the two processes are not
aligned exactly, i.e., the diffusion process is applied to the noisy signal
while the translation process is conducted on the clean signal. As a result,
recent diffusion-based studies employ separate training or shallow integration
to learn the two processes, yet this may cause the local minimal of the
translation optimization, constraining the effectiveness of diffusion models.
To address the problem, we propose a novel joint learning framework that aligns
the diffusion and the translation process, thereby improving the global
optimality. Specifically, we propose to extract the image components with
diffusion models to represent the clean signal and employ the translation
process with the image components, enabling an end-to-end joint learning
manner. On the other hand, we introduce a time-dependent translation network to
learn the complex translation mapping, resulting in effective translation
learning and significant performance improvement. Benefiting from the design of
joint learning, our method enables global optimization of both processes,
enhancing the optimality and achieving improved fidelity and structural
consistency. We have conducted extensive experiments on RGB$\leftrightarrow$RGB
and diverse cross-modality translation tasks including
RGB$\leftrightarrow$Edge, RGB$\leftrightarrow$Semantics and
RGB$\leftrightarrow$Depth, showcasing better generative performances than the
state of the arts.

</details>


### [248] [Rethinking Key-frame-based Micro-expression Recognition: A Robust and Accurate Framework Against Key-frame Errors](https://arxiv.org/abs/2508.06640)
*Zheyuan Zhang,Weihao Tang,Hong Chen*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出CausalNet框架，用于在关键帧索引错误情况下实现稳健的微表情识别（MER），同时保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖准确的关键帧索引，但实际中获取准确索引困难且存在误差，限制了实用性。

Method: CausalNet利用完整微表情序列输入，通过CMPLM模块定位肌肉运动区域，CAB模块学习肌肉运动的因果关系。

Result: 在噪声环境下实现稳健MER，并在标准基准上超越SOTA方法。

Conclusion: CausalNet解决了关键帧索引误差问题，提升了MER的实用性和性能。

Abstract: Micro-expression recognition (MER) is a highly challenging task in affective
computing. With the reduced-sized micro-expression (ME) input that contains key
information based on key-frame indexes, key-frame-based methods have
significantly improved the performance of MER. However, most of these methods
focus on improving the performance with relatively accurate key-frame indexes,
while ignoring the difficulty of obtaining accurate key-frame indexes and the
objective existence of key-frame index errors, which impedes them from moving
towards practical applications. In this paper, we propose CausalNet, a novel
framework to achieve robust MER facing key-frame index errors while maintaining
accurate recognition. To enhance robustness, CausalNet takes the representation
of the entire ME sequence as the input. To address the information redundancy
brought by the complete ME range input and maintain accurate recognition,
first, the Causal Motion Position Learning Module (CMPLM) is proposed to help
the model locate the muscle movement areas related to Action Units (AUs),
thereby reducing the attention to other redundant areas. Second, the Causal
Attention Block (CAB) is proposed to deeply learn the causal relationships
between the muscle contraction and relaxation movements in MEs. Empirical
experiments have demonstrated that on popular ME benchmarks, the CausalNet has
achieved robust MER under different levels of key-frame index noise. Meanwhile,
it has surpassed state-of-the-art (SOTA) methods on several standard MER
benchmarks when using the provided annotated key-frames. Code is available at
https://github.com/tony19980810/CausalNet.

</details>


### [249] [FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI](https://arxiv.org/abs/2508.06756)
*Somayeh Farahani,Marjaneh Hejazi,Antonio Di Ieva,Sidong Liu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于基础模型的生物标志物网络（FoundBioNet），用于从多参数MRI中无创预测IDH突变状态，性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖侵入性组织采样，无法捕捉肿瘤空间异质性，而现有深度学习模型因标注数据稀缺性能受限。基础深度学习模型提供了更通用的解决方案。

Method: 采用SWIN-UNETR架构，结合肿瘤感知特征编码（TAFE）和跨模态差异（CMD）模块，利用多中心数据集训练和验证。

Result: 在多个独立测试集上AUC达65.41%-90.58%，显著优于基线方法（p <= 0.05）。

Conclusion: FoundBioNet通过大规模预训练和任务微调，实现了可泛化的胶质瘤特征分析，提升诊断准确性和可解释性。

Abstract: Accurate, noninvasive detection of isocitrate dehydrogenase (IDH) mutation is
essential for effective glioma management. Traditional methods rely on invasive
tissue sampling, which may fail to capture a tumor's spatial heterogeneity.
While deep learning models have shown promise in molecular profiling, their
performance is often limited by scarce annotated data. In contrast, foundation
deep learning models offer a more generalizable approach for glioma imaging
biomarkers. We propose a Foundation-based Biomarker Network (FoundBioNet) that
utilizes a SWIN-UNETR-based architecture to noninvasively predict IDH mutation
status from multi-parametric MRI. Two key modules are incorporated: Tumor-Aware
Feature Encoding (TAFE) for extracting multi-scale, tumor-focused features, and
Cross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch
signals associated with IDH mutation. The model was trained and validated on a
diverse, multi-center cohort of 1705 glioma patients from six public datasets.
Our model achieved AUCs of 90.58%, 88.08%, 65.41%, and 80.31% on independent
test sets from EGD, TCGA, Ivy GAP, RHUH, and UPenn, consistently outperforming
baseline approaches (p <= 0.05). Ablation studies confirmed that both the TAFE
and CMD modules are essential for improving predictive accuracy. By integrating
large-scale pretraining and task-specific fine-tuning, FoundBioNet enables
generalizable glioma characterization. This approach enhances diagnostic
accuracy and interpretability, with the potential to enable more personalized
patient care.

</details>


### [250] [VOccl3D: A Video Benchmark Dataset for 3D Human Pose and Shape Estimation under real Occlusions](https://arxiv.org/abs/2508.06757)
*Yash Garg,Saketh Bachu,Arindam Dutta,Rohit Lal,Sarosij Bose,Calvin-Khang Ta,M. Salman Asif,Amit Roy-Chowdhury*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一个名为VOccl3D的新基准数据集，用于解决3D人体姿态和形状估计在真实遮挡场景中的挑战。通过计算机图形渲染技术构建数据集，并展示了在现有方法上的改进效果。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态估计方法在复杂姿态或严重遮挡场景中表现不佳，且现有遮挡数据集缺乏真实性。VOccl3D旨在填补这一空白，提供更真实的遮挡数据。

Method: 使用计算机图形渲染技术构建VOccl3D数据集，包含多样化的真实遮挡场景和人体动作。对CLIFF和BEDLAM-CLIFF方法进行微调，并评估其性能。

Result: 微调后的方法在多个公共数据集和VOccl3D测试集上表现出显著改进，同时提升了遮挡下的人体检测性能。

Conclusion: VOccl3D为未来研究提供了更真实的遮挡基准数据集，推动了遮挡场景下人体姿态估计的发展。

Abstract: Human pose and shape (HPS) estimation methods have been extensively studied,
with many demonstrating high zero-shot performance on in-the-wild images and
videos. However, these methods often struggle in challenging scenarios
involving complex human poses or significant occlusions. Although some studies
address 3D human pose estimation under occlusion, they typically evaluate
performance on datasets that lack realistic or substantial occlusions, e.g.,
most existing datasets introduce occlusions with random patches over the human
or clipart-style overlays, which may not reflect real-world challenges. To
bridge this gap in realistic occlusion datasets, we introduce a novel benchmark
dataset, VOccl3D, a Video-based human Occlusion dataset with 3D body pose and
shape annotations. Inspired by works such as AGORA and BEDLAM, we constructed
this dataset using advanced computer graphics rendering techniques,
incorporating diverse real-world occlusion scenarios, clothing textures, and
human motions. Additionally, we fine-tuned recent HPS methods, CLIFF and
BEDLAM-CLIFF, on our dataset, demonstrating significant qualitative and
quantitative improvements across multiple public datasets, as well as on the
test split of our dataset, while comparing its performance with other
state-of-the-art methods. Furthermore, we leveraged our dataset to enhance
human detection performance under occlusion by fine-tuning an existing object
detector, YOLO11, thus leading to a robust end-to-end HPS estimation system
under occlusions. Overall, this dataset serves as a valuable resource for
future research aimed at benchmarking methods designed to handle occlusions,
offering a more realistic alternative to existing occlusion datasets. See the
Project page for code and dataset:https://yashgarg98.github.io/VOccl3D-dataset/

</details>


### [251] [DiffUS: Differentiable Ultrasound Rendering from Volumetric Imaging](https://arxiv.org/abs/2508.06768)
*Noe Bertramo,Gabriel Duguey,Vivek Gopalakrishnan*

Main category: cs.CV

Relevance: 30.0

TL;DR: DiffUS是一个基于物理的可微分超声渲染器，用于从MRI数据生成逼真的B模式超声图像，支持下游优化任务。


<details>
  <summary>Details</summary>
Motivation: 解决术中超声图像与术前高分辨率MRI/CT扫描之间的对齐问题，提供实时引导。

Method: 1. 使用机器学习将MRI 3D扫描转换为声阻抗体积；2. 基于射线追踪模拟超声束传播；3. 通过稀疏线性系统捕捉多次内部反射；4. 重建B模式图像，包含噪声和伪影。

Result: 在ReMIND数据集上验证了DiffUS生成解剖学准确超声图像的能力。

Conclusion: DiffUS为术中超声图像生成和优化提供了有效工具。

Abstract: Intraoperative ultrasound imaging provides real-time guidance during numerous
surgical procedures, but its interpretation is complicated by noise, artifacts,
and poor alignment with high-resolution preoperative MRI/CT scans. To bridge
the gap between reoperative planning and intraoperative guidance, we present
DiffUS, a physics-based, differentiable ultrasound renderer that synthesizes
realistic B-mode images from volumetric imaging. DiffUS first converts MRI 3D
scans into acoustic impedance volumes using a machine learning approach. Next,
we simulate ultrasound beam propagation using ray tracing with coupled
reflection-transmission equations. DiffUS formulates wave propagation as a
sparse linear system that captures multiple internal reflections. Finally, we
reconstruct B-mode images via depth-resolved echo extraction across fan-shaped
acquisition geometry, incorporating realistic artifacts including speckle noise
and depth-dependent degradation. DiffUS is entirely implemented as
differentiable tensor operations in PyTorch, enabling gradient-based
optimization for downstream applications such as slice-to-volume registration
and volumetric reconstruction. Evaluation on the ReMIND dataset demonstrates
DiffUS's ability to generate anatomically accurate ultrasound images from brain
MRI data.

</details>


### [252] [Edge Detection for Organ Boundaries via Top Down Refinement and SubPixel Upsampling](https://arxiv.org/abs/2508.06805)
*Aarav Mehta,Priya Deshmukh,Vikram Singh,Siddharth Malhotra,Krishnan Menon Iyer,Tanvi Iyer*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种针对医学图像的精确边缘检测方法，通过反向细化架构提升边界定位精度，显著改善医学图像任务。


<details>
  <summary>Details</summary>
Motivation: 医学图像中器官边界的精确定位对临床任务至关重要，但现有卷积网络在毫米级精度上表现不足。

Method: 采用自上而下的反向细化架构，融合高层语义特征与低层细节，并扩展至各向异性体积处理。

Result: 在CT和MRI数据集上显著提升边界定位精度，并改善下游任务（如分割和配准）。

Conclusion: 该方法生成的精确边缘对医学图像任务具有临床价值。

Abstract: Accurate localization of organ boundaries is critical in medical imaging for
segmentation, registration, surgical planning, and radiotherapy. While deep
convolutional networks (ConvNets) have advanced general-purpose edge detection
to near-human performance on natural images, their outputs often lack precise
localization, a limitation that is particularly harmful in medical applications
where millimeter-level accuracy is required. Building on a systematic analysis
of ConvNet edge outputs, we propose a medically focused crisp edge detector
that adapts a novel top-down backward refinement architecture to medical images
(2D and volumetric). Our method progressively upsamples and fuses high-level
semantic features with fine-grained low-level cues through a backward
refinement pathway, producing high-resolution, well-localized organ boundaries.
We further extend the design to handle anisotropic volumes by combining 2D
slice-wise refinement with light 3D context aggregation to retain computational
efficiency. Evaluations on several CT and MRI organ datasets demonstrate
substantially improved boundary localization under strict criteria (boundary
F-measure, Hausdorff distance) compared to baseline ConvNet detectors and
contemporary medical edge/contour methods. Importantly, integrating our crisp
edge maps into downstream pipelines yields consistent gains in organ
segmentation (higher Dice scores, lower boundary errors), more accurate image
registration, and improved delineation of lesions near organ interfaces. The
proposed approach produces clinically valuable, crisp organ edges that
materially enhance common medical-imaging tasks.

</details>


### [253] [DualResolution Residual Architecture with Artifact Suppression for Melanocytic Lesion Segmentation](https://arxiv.org/abs/2508.06816)
*Vikram Singh,Kabir Malhotra,Rohan Desai,Ananya Shankaracharya,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种用于黑色素瘤分割的双分辨率架构，结合边界感知和通道注意力模块，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 解决皮肤镜图像中黑色素瘤分割的挑战，如细微纹理变化、伪影和精确边界定位需求。

Method: 采用双分辨率架构（全分辨率流和池化流），结合边界感知残差连接和通道注意力模块，辅以轻量级伪影抑制块和多任务训练目标。

Result: 在公共基准测试中显著提升了边界贴合度和临床相关分割指标。

Conclusion: 该方法为自动化黑色素瘤评估系统提供了实用组件。

Abstract: Accurate segmentation of melanocytic tumors in dermoscopic images is a
critical step for automated skin cancer screening and clinical decision
support. Unlike natural scene segmentation, lesion delineation must reconcile
subtle texture and color variations, frequent artifacts (hairs, rulers,
bubbles), and a strong need for precise boundary localization to support
downstream diagnosis. In this paper we introduce Our method, a novel ResNet
inspired dual resolution architecture specifically designed for melanocytic
tumor segmentation. Our method maintains a full resolution stream that
preserves fine grained boundary information while a complementary pooled stream
aggregates multi scale contextual cues for robust lesion recognition. The
streams are tightly coupled by boundary aware residual connections that inject
high frequency edge information into deep feature maps, and by a channel
attention module that adapts color and texture sensitivity to dermoscopic
appearance. To further address common imaging artifacts and the limited size of
clinical datasets, we propose a lightweight artifact suppression block and a
multi task training objective that combines a Dice Tversky segmentation loss
with an explicit boundary loss and a contrastive regularizer for feature
stability. The combined design yields pixel accurate masks without requiring
heavy post processing or complex pre training protocols. Extensive experiments
on public dermoscopic benchmarks demonstrate that Our method significantly
improves boundary adherence and clinically relevant segmentation metrics
compared to standard encoder decoder baselines, making it a practical building
block for automated melanoma assessment systems.

</details>


### [254] [VesselRW: Weakly Supervised Subcutaneous Vessel Segmentation via Learned Random Walk Propagation](https://arxiv.org/abs/2508.06819)
*Ayaan Nooruddin Siddiqui,Mahnoor Zaidi,Ayesha Nazneen Shahbaz,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种弱监督训练框架，用于皮下血管分割，利用稀疏标注生成密集监督，结合不确定性加权损失和拓扑感知正则化，显著减少标注负担并提升性能。


<details>
  <summary>Details</summary>
Motivation: 临床图像中皮下血管分割因标注稀缺、图像对比度低和噪声问题而困难，需要一种减少标注负担且提升分割准确性的方法。

Method: 通过可微分随机游走标签传播模型将稀疏标注扩展为密集概率监督，结合图像驱动的血管特征和连续性先验，联合训练CNN分割预测器，并引入拓扑感知正则化。

Result: 在临床数据集上表现优于稀疏标注和传统伪标注方法，生成更完整的血管图并提供更好的不确定性校准。

Conclusion: 该方法显著减少标注需求，同时保持临床相关的血管拓扑结构，适用于下游决策。

Abstract: Accurate segmentation of subcutaneous vessels from clinical images is
hampered by scarce, expensive ground truth and by low contrast, noisy
appearance of vessels across patients and modalities. We present a novel weakly
supervised training framework tailored for subcutaneous vessel segmentation
that leverages inexpensive sparse annotations (e.g., centerline traces, dot
markers, or short scribbles). Sparse labels are expanded into dense,
probabilistic supervision via a differentiable random walk label propagation
model whose transition weights incorporate image driven vesselness cues and
tubular continuity priors. The propagation yields per-pixel hitting
probabilities together with calibrated uncertainty estimates; these are
incorporated into an uncertainty weighted loss to avoid over fitting to
ambiguous regions. Crucially, the label-propagator is learned jointly with a
CNN based segmentation predictor, enabling the system to discover vessel edges
and continuity constraints without explicit edge supervision. We further
introduce a topology aware regularizer that encourages centerline connectivity
and penalizes spurious branches, improving clinical usability. In experiments
on clinical subcutaneous imaging datasets, our method consistently outperforms
naive training on sparse labels and conventional dense pseudo-labeling,
producing more complete vascular maps and better calibrated uncertainty for
downstream decision making. The approach substantially reduces annotation
burden while preserving clinically relevant vessel topology.

</details>


### [255] [AGIC: Attention-Guided Image Captioning to Improve Caption Relevance](https://arxiv.org/abs/2508.06853)
*L. D. M. S. Sai Teja,Ashok Urlana,Pruthwik Mishra*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种注意力引导的图像描述生成方法（AGIC），通过增强视觉特征空间中的显著区域来指导生成，并采用混合解码策略平衡流畅性和多样性。实验表明AGIC在性能上优于或匹配现有模型，且推理速度更快。


<details>
  <summary>Details</summary>
Motivation: 尽管图像描述生成取得进展，但生成准确且描述性强的标题仍具挑战性。

Method: AGIC通过增强视觉特征空间中的显著区域来引导标题生成，并采用混合解码策略（确定性与概率性采样结合）。

Result: 在Flickr8k和Flickr30k数据集上，AGIC性能优于或匹配现有模型，且推理速度更快。

Conclusion: AGIC提供了一种可扩展且可解释的图像描述生成解决方案。

Abstract: Despite significant progress in image captioning, generating accurate and
descriptive captions remains a long-standing challenge. In this study, we
propose Attention-Guided Image Captioning (AGIC), which amplifies salient
visual regions directly in the feature space to guide caption generation. We
further introduce a hybrid decoding strategy that combines deterministic and
probabilistic sampling to balance fluency and diversity. To evaluate AGIC, we
conduct extensive experiments on the Flickr8k and Flickr30k datasets. The
results show that AGIC matches or surpasses several state-of-the-art models
while achieving faster inference. Moreover, AGIC demonstrates strong
performance across multiple evaluation metrics, offering a scalable and
interpretable solution for image captioning.

</details>


### [256] [NS-FPN: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective](https://arxiv.org/abs/2508.06878)
*Maoxun Yuan,Duanni Meng,Ziteng Xi,Tianyi Zhao,Shiji Zhao,Yimian Dai,Xingxing Wei*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种新型噪声抑制特征金字塔网络（NS-FPN），通过低频引导特征纯化（LFP）模块和螺旋感知特征采样（SFS）模块，显著减少红外小目标检测中的误报问题。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测（IRSTDS）因目标暗淡、形状模糊和背景噪声严重而具有挑战性。现有CNN方法虽提升了特征表示，但未能有效抑制噪声，导致误报增加。本文从频域角度出发，提出噪声抑制视角的性能提升方案。

Method: 提出NS-FPN，包含LFP模块（通过纯化高频成分抑制噪声）和SFS模块（螺旋采样融合目标相关特征），轻量且易于集成到现有框架。

Result: 在公开数据集上，NS-FPN显著减少误报，性能优于现有方法。

Conclusion: NS-FPN通过噪声抑制和特征融合，为IRSTDS任务提供了高效解决方案。

Abstract: Infrared small target detection and segmentation (IRSTDS) is a critical yet
challenging task in defense and civilian applications, owing to the dim,
shapeless appearance of targets and severe background clutter. Recent CNN-based
methods have achieved promising target perception results, but they only focus
on enhancing feature representation to offset the impact of noise, which
results in the increased false alarms problem. In this paper, through analyzing
the problem from the frequency domain, we pioneer in improving performance from
noise suppression perspective and propose a novel noise-suppression feature
pyramid network (NS-FPN), which integrates a low-frequency guided feature
purification (LFP) module and a spiral-aware feature sampling (SFS) module into
the original FPN structure. The LFP module suppresses the noise features by
purifying high-frequency components to achieve feature enhancement devoid of
noise interference, while the SFS module further adopts spiral sampling to fuse
target-relevant features in feature fusion process. Our NS-FPN is designed to
be lightweight yet effective and can be easily plugged into existing IRSTDS
frameworks. Extensive experiments on the public IRSTDS datasets demonstrate
that our method significantly reduces false alarms and achieves superior
performance on IRSTDS tasks.

</details>


### [257] [Fusion-Based Brain Tumor Classification Using Deep Learning and Explainable AI, and Rule-Based Reasoning](https://arxiv.org/abs/2508.06891)
*Melika Filvantorkaman,Mohsen Piri,Maral Filvan Torkaman,Ashkan Zabihi,Hamidreza Moradi*

Main category: eess.IV

Relevance: 30.0

TL;DR: 该研究提出了一种基于MobileNetV2和DenseNet121的集成深度学习框架，用于MRI脑肿瘤分类，结合可解释AI模块和临床决策规则，取得了高准确性和临床信任。


<details>
  <summary>Details</summary>
Motivation: 提高脑肿瘤MRI分类的准确性和可解释性，以支持临床诊断和治疗规划。

Method: 使用MobileNetV2和DenseNet121的集成模型，结合Grad-CAM++和临床决策规则，进行5折交叉验证。

Result: 集成模型准确率达91.7%，Grad-CAM++可视化与专家标注区域高度一致，临床评估显示高解释性。

Conclusion: 该框架为脑肿瘤分类提供了准确且可解释的解决方案，具有临床推广潜力。

Abstract: Accurate and interpretable classification of brain tumors from magnetic
resonance imaging (MRI) is critical for effective diagnosis and treatment
planning. This study presents an ensemble-based deep learning framework that
combines MobileNetV2 and DenseNet121 convolutional neural networks (CNNs) using
a soft voting strategy to classify three common brain tumor types: glioma,
meningioma, and pituitary adenoma. The models were trained and evaluated on the
Figshare dataset using a stratified 5-fold cross-validation protocol. To
enhance transparency and clinical trust, the framework integrates an
Explainable AI (XAI) module employing Grad-CAM++ for class-specific saliency
visualization, alongside a symbolic Clinical Decision Rule Overlay (CDRO) that
maps predictions to established radiological heuristics. The ensemble
classifier achieved superior performance compared to individual CNNs, with an
accuracy of 91.7%, precision of 91.9%, recall of 91.7%, and F1-score of 91.6%.
Grad-CAM++ visualizations revealed strong spatial alignment between model
attention and expert-annotated tumor regions, supported by Dice coefficients up
to 0.88 and IoU scores up to 0.78. Clinical rule activation further validated
model predictions in cases with distinct morphological features. A
human-centered interpretability assessment involving five board-certified
radiologists yielded high Likert-scale scores for both explanation usefulness
(mean = 4.4) and heatmap-region correspondence (mean = 4.0), reinforcing the
framework's clinical relevance. Overall, the proposed approach offers a robust,
interpretable, and generalizable solution for automated brain tumor
classification, advancing the integration of deep learning into clinical
neurodiagnostics.

</details>


### [258] [Advancements in Chinese font generation since deep learning era: A survey](https://arxiv.org/abs/2508.06900)
*Weiran Chen,Guiqian Zhu,Ying Li,Yi Ji,Chunping Liu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 本文综述了基于深度学习的汉字字体生成方法，包括多参考样本和少参考样本生成技术，并探讨了其挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 提高生成汉字图像的整体质量是当前研究的难点，本文旨在通过综述现有方法为研究者提供有价值的参考。

Method: 通过文献选择与分析，分类综述多参考样本和少参考样本的字体生成方法，并讨论其优缺点。

Result: 总结了代表性方法的优势与局限，提出了未来研究方向。

Conclusion: 汉字字体生成领域仍面临挑战，未来需进一步优化生成质量与效率。

Abstract: Chinese font generation aims to create a new Chinese font library based on
some reference samples. It is a topic of great concern to many font designers
and typographers. Over the past years, with the rapid development of deep
learning algorithms, various new techniques have achieved flourishing and
thriving progress. Nevertheless, how to improve the overall quality of
generated Chinese character images remains a tough issue. In this paper, we
conduct a holistic survey of the recent Chinese font generation approaches
based on deep learning. To be specific, we first illustrate the research
background of the task. Then, we outline our literature selection and analysis
methodology, and review a series of related fundamentals, including classical
deep learning architectures, font representation formats, public datasets, and
frequently-used evaluation metrics. After that, relying on the number of
reference samples required to generate a new font, we categorize the existing
methods into two major groups: many-shot font generation and few-shot font
generation methods. Within each category, representative approaches are
summarized, and their strengths and limitations are also discussed in detail.
Finally, we conclude our paper with the challenges and future directions, with
the expectation to provide some valuable illuminations for the researchers in
this field.

</details>


### [259] [Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification](https://arxiv.org/abs/2508.06959)
*Qin Xu,Lili Zhu,Xiaoxia Cheng,Bo Jiang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种名为SCOPE的新方法，通过自适应增强空间域中的低层细节和高层语义表示能力，解决了细粒度视觉分类（FGVC）中固定频率域方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有频率域方法基于固定基函数，缺乏对图像内容的适应性，无法动态调整特征提取。

Method: SCOPE包含两个模块：Subtle Detail Extractor（SDE）动态增强浅层特征中的细节，Salient Semantic Refiner（SSR）从高层特征中学习语义一致的细化特征。

Result: 在四个流行的细粒度图像分类基准上达到了新的最先进水平。

Conclusion: SCOPE突破了频率域固定尺度的限制，提高了多尺度融合的灵活性。

Abstract: The crux of resolving fine-grained visual classification (FGVC) lies in
capturing discriminative and class-specific cues that correspond to subtle
visual characteristics. Recently, frequency decomposition/transform based
approaches have attracted considerable interests since its appearing
discriminative cue mining ability. However, the frequency-domain methods are
based on fixed basis functions, lacking adaptability to image content and
unable to dynamically adjust feature extraction according to the discriminative
requirements of different images. To address this, we propose a novel method
for FGVC, named Subtle-Cue Oriented Perception Engine (SCOPE), which adaptively
enhances the representational capability of low-level details and high-level
semantics in the spatial domain, breaking through the limitations of fixed
scales in the frequency domain and improving the flexibility of multi-scale
fusion. The core of SCOPE lies in two modules: the Subtle Detail Extractor
(SDE), which dynamically enhances subtle details such as edges and textures
from shallow features, and the Salient Semantic Refiner (SSR), which learns
semantically coherent and structure-aware refinement features from the
high-level features guided by the enhanced shallow features. The SDE and SSR
are cascaded stage-by-stage to progressively combine local details with global
semantics. Extensive experiments demonstrate that our method achieves new
state-of-the-art on four popular fine-grained image classification benchmarks.

</details>


### [260] [Evaluating Fisheye-Compatible 3D Gaussian Splatting Methods on Real Images Beyond 180 Degree Field of View](https://arxiv.org/abs/2508.06968)
*Ulas Gunes,Matias Turkulainen,Juho Kannala,Esa Rahtu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文评估了两种基于鱼眼镜头的3D高斯溅射方法（Fisheye-GS和3DGUT）在真实图像上的表现，研究了极端畸变下的处理能力，并提出了一种基于深度的初始化策略。


<details>
  <summary>Details</summary>
Motivation: 研究鱼眼镜头在3D重建中的实际应用，解决极端畸变和稀疏输入下的挑战。

Method: 评估Fisheye-GS和3DGUT在不同视场角下的性能，提出基于UniK3D的深度初始化策略。

Result: Fisheye-GS在160度视场角下表现最佳，3DGUT在200度下仍保持高质量；UniK3D初始化效果接近SfM。

Conclusion: 鱼眼3DGS方法在宽角度3D重建中具有实际可行性。

Abstract: We present the first evaluation of fisheye-based 3D Gaussian Splatting
methods, Fisheye-GS and 3DGUT, on real images with fields of view exceeding 180
degree. Our study covers both indoor and outdoor scenes captured with 200
degree fisheye cameras and analyzes how each method handles extreme distortion
in real world settings. We evaluate performance under varying fields of view
(200 degree, 160 degree, and 120 degree) to study the tradeoff between
peripheral distortion and spatial coverage. Fisheye-GS benefits from field of
view (FoV) reduction, particularly at 160 degree, while 3DGUT remains stable
across all settings and maintains high perceptual quality at the full 200
degree view. To address the limitations of SfM-based initialization, which
often fails under strong distortion, we also propose a depth-based strategy
using UniK3D predictions from only 2-3 fisheye images per scene. Although
UniK3D is not trained on real fisheye data, it produces dense point clouds that
enable reconstruction quality on par with SfM, even in difficult scenes with
fog, glare, or sky. Our results highlight the practical viability of
fisheye-based 3DGS methods for wide-angle 3D reconstruction from sparse and
distortion-heavy image inputs.

</details>


### [261] [Spatio-Temporal Conditional Diffusion Models for Forecasting Future Multiple Sclerosis Lesion Masks Conditioned on Treatments](https://arxiv.org/abs/2508.07006)
*Gian Mario Favero,Ge Ya Luo,Nima Fathi,Justin Szeto,Douglas L. Arnold,Brennan Nichyporuk,Chris Pal,Tal Arbel*

Main category: eess.IV

Relevance: 30.0

TL;DR: 论文提出了一种基于扩散模型的个性化医疗方法，用于预测多发性硬化症（MS）患者的病灶演化。


<details>
  <summary>Details</summary>
Motivation: 多发性硬化症的异质性进展需要个性化医疗，而现有方法难以准确预测病灶演化。

Method: 采用治疗感知的时空扩散模型，结合多模态患者数据（MRI和治疗信息），预测未来病灶。

Result: 模型在2131名患者的3D MRI数据上表现优异，能准确预测六种不同治疗的病灶演化，并支持多种下游任务。

Conclusion: 该因果图像生成模型为MS的数据驱动预后提供了强大工具。

Abstract: Image-based personalized medicine has the potential to transform healthcare,
particularly for diseases that exhibit heterogeneous progression such as
Multiple Sclerosis (MS). In this work, we introduce the first treatment-aware
spatio-temporal diffusion model that is able to generate future masks
demonstrating lesion evolution in MS. Our voxel-space approach incorporates
multi-modal patient data, including MRI and treatment information, to forecast
new and enlarging T2 (NET2) lesion masks at a future time point. Extensive
experiments on a multi-centre dataset of 2131 patient 3D MRIs from randomized
clinical trials for relapsing-remitting MS demonstrate that our generative
model is able to accurately predict NET2 lesion masks for patients across six
different treatments. Moreover, we demonstrate our model has the potential for
real-world clinical applications through downstream tasks such as future lesion
count and location estimation, binary lesion activity classification, and
generating counterfactual future NET2 masks for several treatments with
different efficacies. This work highlights the potential of causal, image-based
generative models as powerful tools for advancing data-driven prognostics in
MS.

</details>


### [262] [3DGS-VBench: A Comprehensive Video Quality Evaluation Benchmark for 3DGS Compression](https://arxiv.org/abs/2508.07038)
*Yuke Xing,William Gordon,Qi Yang,Kaifa Yang,Jiarui Wang,Yiling Xu*

Main category: eess.IV

Relevance: 30.0

TL;DR: 论文提出了3DGS-VBench，一个用于评估3D高斯溅射（3DGS）压缩算法视觉质量的大规模数据集和基准测试，包含660个压缩模型和视频序列，并评估了15种质量评估指标。


<details>
  <summary>Details</summary>
Motivation: 3DGS的高存储需求限制了实际应用，现有压缩方法缺乏系统性的质量评估研究，因此需要建立专门的评估框架。

Method: 构建了包含660个压缩3DGS模型和视频序列的数据集，来自11个场景和6种SOTA压缩算法，并通过50名参与者标注MOS分数。

Result: 数据集验证了可靠性，并评估了6种压缩算法的存储效率和视觉质量，以及15种质量评估指标的性能。

Conclusion: 3DGS-VBench为3DGS压缩和质量评估研究提供了专门工具，推动了相关领域的发展。

Abstract: 3D Gaussian Splatting (3DGS) enables real-time novel view synthesis with high
visual fidelity, but its substantial storage requirements hinder practical
deployment, prompting state-of-the-art (SOTA) 3DGS methods to incorporate
compression modules. However, these 3DGS generative compression techniques
introduce unique distortions lacking systematic quality assessment research. To
this end, we establish 3DGS-VBench, a large-scale Video Quality Assessment
(VQA) Dataset and Benchmark with 660 compressed 3DGS models and video sequences
generated from 11 scenes across 6 SOTA 3DGS compression algorithms with
systematically designed parameter levels. With annotations from 50
participants, we obtained MOS scores with outlier removal and validated dataset
reliability. We benchmark 6 3DGS compression algorithms on storage efficiency
and visual quality, and evaluate 15 quality assessment metrics across multiple
paradigms. Our work enables specialized VQA model training for 3DGS, serving as
a catalyst for compression and quality assessment research. The dataset is
available at https://github.com/YukeXing/3DGS-VBench.

</details>


### [263] [ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting](https://arxiv.org/abs/2508.07089)
*Sandro Papais,Letian Wang,Brian Cheong,Steven L. Waslander*

Main category: cs.CV

Relevance: 30.0

TL;DR: ForeSight是一个用于自动驾驶3D感知的联合检测与预测框架，通过多任务流式和双向学习方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法将检测与预测分开处理，无法充分利用时序信息，ForeSight旨在解决这一问题。

Method: 采用多任务流式与双向学习，结合检测与预测的查询内存，利用轨迹预测增强空间推理，并通过流式预测变换器提升时序一致性。

Result: 在nuScenes数据集上，ForeSight以54.9%的EPA超越先前方法9.3%，并在mAP和minADE上表现最佳。

Conclusion: ForeSight通过联合检测与预测，无需显式对象关联，实现了高效且可扩展的3D感知。

Abstract: We introduce ForeSight, a novel joint detection and forecasting framework for
vision-based 3D perception in autonomous vehicles. Traditional approaches treat
detection and forecasting as separate sequential tasks, limiting their ability
to leverage temporal cues. ForeSight addresses this limitation with a
multi-task streaming and bidirectional learning approach, allowing detection
and forecasting to share query memory and propagate information seamlessly. The
forecast-aware detection transformer enhances spatial reasoning by integrating
trajectory predictions from a multiple hypothesis forecast memory queue, while
the streaming forecast transformer improves temporal consistency using past
forecasts and refined detections. Unlike tracking-based methods, ForeSight
eliminates the need for explicit object association, reducing error propagation
with a tracking-free model that efficiently scales across multi-frame
sequences. Experiments on the nuScenes dataset show that ForeSight achieves
state-of-the-art performance, achieving an EPA of 54.9%, surpassing previous
methods by 9.3%, while also attaining the best mAP and minADE among multi-view
detection and forecasting models.

</details>


### [264] [Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration](https://arxiv.org/abs/2508.07092)
*Yue Hu,Juntong Peng,Yunqiao Yang,Siheng Chen*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种名为HyComm的通信高效LiDAR协作3D检测系统，通过自适应整合两种通信消息（感知输出和原始观测）来优化性能与带宽的权衡。


<details>
  <summary>Details</summary>
Motivation: 解决协作3D检测中性能与通信带宽之间的固有矛盾，提升检测效率和适应性。

Method: 提出混合协作方法，自适应选择关键消息（感知输出和原始观测），并设计HyComm系统支持灵活压缩和标准化数据格式。

Result: 在DAIR-V2X和OPV2V数据集上，HyComm显著优于现有方法，通信量降低2006倍以上，AP50性能仍优于Where2comm。

Conclusion: HyComm通过自适应消息选择和标准化格式，实现了高效的协作检测，适用于多种通信场景和代理配置。

Abstract: Collaborative 3D detection can substantially boost detection performance by
allowing agents to exchange complementary information. It inherently results in
a fundamental trade-off between detection performance and communication
bandwidth. To tackle this bottleneck issue, we propose a novel hybrid
collaboration that adaptively integrates two types of communication messages:
perceptual outputs, which are compact, and raw observations, which offer richer
information. This approach focuses on two key aspects: i) integrating
complementary information from two message types and ii) prioritizing the most
critical data within each type. By adaptively selecting the most critical set
of messages, it ensures optimal perceptual information and adaptability,
effectively meeting the demands of diverse communication scenarios.Building on
this hybrid collaboration, we present \texttt{HyComm}, a
communication-efficient LiDAR-based collaborative 3D detection system.
\texttt{HyComm} boasts two main benefits: i) it facilitates adaptable
compression rates for messages, addressing various communication requirements,
and ii) it uses standardized data formats for messages. This ensures they are
independent of specific detection models, fostering adaptability across
different agent configurations. To evaluate HyComm, we conduct experiments on
both real-world and simulation datasets: DAIR-V2X and OPV2V. HyComm
consistently outperforms previous methods and achieves a superior
performance-bandwidth trade-off regardless of whether agents use the same or
varied detection models. It achieves a lower communication volume of more than
2,006$\times$ and still outperforms Where2comm on DAIR-V2X in terms of AP50.
The related code will be released.

</details>


### [265] [AugLift: Boosting Generalization in Lifting-based 3D Human Pose Estimation](https://arxiv.org/abs/2508.07112)
*Nikolai Warner,Wenjin Zhang,Irfan Essa,Apaar Sadhwani*

Main category: cs.CV

Relevance: 30.0

TL;DR: AugLift通过增强2D关键点输入（添加置信度分数和深度估计）提升3D人体姿态估计的泛化能力，无需额外数据或传感器。


<details>
  <summary>Details</summary>
Motivation: 解决基于提升的3D姿态估计方法在新数据集和实际场景中泛化能力差的问题。

Method: 在标准2D关键点输入基础上，稀疏地添加关键点检测置信度和深度估计，利用预训练模型计算这些信号。

Result: 在四个数据集上，跨数据集性能平均提升10.1%，内部数据集性能提升4.0%。

Conclusion: AugLift是一种模块化方法，可显著提升基于提升的3D姿态估计模型的泛化能力。

Abstract: Lifting-based methods for 3D Human Pose Estimation (HPE), which predict 3D
poses from detected 2D keypoints, often generalize poorly to new datasets and
real-world settings. To address this, we propose \emph{AugLift}, a simple yet
effective reformulation of the standard lifting pipeline that significantly
improves generalization performance without requiring additional data
collection or sensors. AugLift sparsely enriches the standard input -- the 2D
keypoint coordinates $(x, y)$ -- by augmenting it with a keypoint detection
confidence score $c$ and a corresponding depth estimate $d$. These additional
signals are computed from the image using off-the-shelf, pre-trained models
(e.g., for monocular depth estimation), thereby inheriting their strong
generalization capabilities. Importantly, AugLift serves as a modular add-on
and can be readily integrated into existing lifting architectures.
  Our extensive experiments across four datasets demonstrate that AugLift
boosts cross-dataset performance on unseen datasets by an average of $10.1\%$,
while also improving in-distribution performance by $4.0\%$. These gains are
consistent across various lifting architectures, highlighting the robustness of
our method. Our analysis suggests that these sparse, keypoint-aligned cues
provide robust frame-level context, offering a practical way to significantly
improve the generalization of any lifting-based pose estimation model. Code
will be made publicly available.

</details>


### [266] [Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays](https://arxiv.org/abs/2508.07128)
*Gregory Schuit,Denis Parra,Cecilia Besa*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文评估了GAN和扩散模型在合成胸部X光片中的效果，发现扩散模型整体更真实，但GAN在某些条件下更准确。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像数据稀缺问题，尤其是低发病率异常，同时评估合成图像的临床实用性。

Method: 使用MIMIC-CXR数据集，通过GAN和扩散模型生成合成图像，并由三位放射科医生进行读者研究。

Result: 扩散模型生成图像更真实，但GAN在特定条件下（如无ECS）更准确。

Conclusion: GAN和扩散模型各有优势，需进一步改进以可靠增强AI诊断系统的训练数据。

Abstract: Generative image models have achieved remarkable progress in both natural and
medical imaging. In the medical context, these techniques offer a potential
solution to data scarcity-especially for low-prevalence anomalies that impair
the performance of AI-driven diagnostic and segmentation tools. However,
questions remain regarding the fidelity and clinical utility of synthetic
images, since poor generation quality can undermine model generalizability and
trust. In this study, we evaluate the effectiveness of state-of-the-art
generative models-Generative Adversarial Networks (GANs) and Diffusion Models
(DMs)-for synthesizing chest X-rays conditioned on four abnormalities:
Atelectasis (AT), Lung Opacity (LO), Pleural Effusion (PE), and Enlarged
Cardiac Silhouette (ECS). Using a benchmark composed of real images from the
MIMIC-CXR dataset and synthetic images from both GANs and DMs, we conducted a
reader study with three radiologists of varied experience. Participants were
asked to distinguish real from synthetic images and assess the consistency
between visual features and the target abnormality. Our results show that while
DMs generate more visually realistic images overall, GANs can report better
accuracy for specific conditions, such as absence of ECS. We further identify
visual cues radiologists use to detect synthetic images, offering insights into
the perceptual gaps in current models. These findings underscore the
complementary strengths of GANs and DMs and point to the need for further
refinement to ensure generative models can reliably augment training datasets
for AI diagnostic systems.

</details>


### [267] [Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection](https://arxiv.org/abs/2508.07170)
*Yunpeng Shi,Lei Chen,Xiaolu Shen,Yanju Guo*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文提出了一种轻量级多尺度特征提取层（LMF层），并构建了LMFNet网络，用于显著目标检测，在保持性能的同时大幅减少参数量。


<details>
  <summary>Details</summary>
Motivation: 解决轻量级网络中多尺度特征提取的效率与性能权衡问题。

Method: 采用深度可分离扩张卷积构建LMF层，并集成多个LMF层形成LMFNet。

Result: LMFNet在五个基准数据集上达到SOTA或可比性能，仅需0.81M参数。

Conclusion: LMFNet不仅解决了轻量级网络的多尺度学习问题，还展示了在图像处理任务中的广泛应用潜力。

Abstract: In the domain of computer vision, multi-scale feature extraction is vital for
tasks such as salient object detection. However, achieving this capability in
lightweight networks remains challenging due to the trade-off between
efficiency and performance. This paper proposes a novel lightweight multi-scale
feature extraction layer, termed the LMF layer, which employs depthwise
separable dilated convolutions in a fully connected structure. By integrating
multiple LMF layers, we develop LMFNet, a lightweight network tailored for
salient object detection. Our approach significantly reduces the number of
parameters while maintaining competitive performance. Here, we show that LMFNet
achieves state-of-the-art or comparable results on five benchmark datasets with
only 0.81M parameters, outperforming several traditional and lightweight models
in terms of both efficiency and accuracy. Our work not only addresses the
challenge of multi-scale learning in lightweight networks but also demonstrates
the potential for broader applications in image processing tasks. The related
code files are available at https://github.com/Shi-Yun-peng/LMFNet

</details>


### [268] [EventRR: Event Referential Reasoning for Referring Video Object Segmentation](https://arxiv.org/abs/2508.07171)
*Huihui Xu,Jiashi Lin,Haoyu Chen,Junjun He,Lei Zhu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出EventRR框架，通过解耦视频对象分割为对象总结和引用推理两部分，利用Referential Event Graph（REG）表达语义事件结构，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视表达式的语义结构，而视频引用表达式比图像更复杂，包含事件属性和时间关系，传统方法难以处理。

Method: EventRR框架分为对象总结和引用推理两部分，总结阶段生成瓶颈令牌，推理阶段通过REG图进行时间概念-角色推理。

Result: 在四个基准数据集上，EventRR在定量和定性上均优于现有方法。

Conclusion: EventRR通过结构化语义事件推理，显著提升了视频对象分割的性能。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment out the object in
a video referred by an expression. Current RVOS methods view referring
expressions as unstructured sequences, neglecting their crucial semantic
structure essential for referent reasoning. Besides, in contrast to
image-referring expressions whose semantics focus only on object attributes and
object-object relations, video-referring expressions also encompass event
attributes and event-event temporal relations. This complexity challenges
traditional structured reasoning image approaches. In this paper, we propose
the Event Referential Reasoning (EventRR) framework. EventRR decouples RVOS
into object summarization part and referent reasoning part. The summarization
phase begins by summarizing each frame into a set of bottleneck tokens, which
are then efficiently aggregated in the video-level summarization step to
exchange the global cross-modal temporal context. For reasoning part, EventRR
extracts semantic eventful structure of a video-referring expression into
highly expressive Referential Event Graph (REG), which is a single-rooted
directed acyclic graph. Guided by topological traversal of REG, we propose
Temporal Concept-Role Reasoning (TCRR) to accumulate the referring score of
each temporal query from REG leaf nodes to root node. Each reasoning step can
be interpreted as a question-answer pair derived from the concept-role
relations in REG. Extensive experiments across four widely recognized benchmark
datasets, show that EventRR quantitatively and qualitatively outperforms
state-of-the-art RVOS methods. Code is available at
https://github.com/bio-mlhui/EventRR

</details>


### [269] [Similarity Matters: A Novel Depth-guided Network for Image Restoration and A New Dataset](https://arxiv.org/abs/2508.07211)
*Junyi He,Liuling Chen,Hongyang Zhou,Zhang xiaoxing,Xiaobin Zhu,Shengxiang Yu,Jingyan Qin,Xu-Cheng Yin*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种深度引导网络（DGN）用于图像修复，结合了深度估计和图像修复的双分支交互设计，并通过新的大规模高分辨率数据集验证其性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像修复方法常忽略深度信息，导致相似性匹配不佳、注意力分散或背景过度增强。DGN旨在通过深度引导解决这些问题。

Method: DGN包含深度估计分支和图像修复分支，利用渐进窗口自注意力和稀疏非局部注意力捕捉对象内和对象间相似性。

Result: 实验表明，DGN在多个标准基准上达到最优性能，并能泛化到未见过的植物图像。

Conclusion: DGN通过深度引导和双分支设计显著提升了图像修复质量，同时新数据集支持了方法的有效性。

Abstract: Image restoration has seen substantial progress in recent years. However,
existing methods often neglect depth information, which hurts similarity
matching, results in attention distractions in shallow depth-of-field (DoF)
scenarios, and excessive enhancement of background content in deep DoF
settings. To overcome these limitations, we propose a novel Depth-Guided
Network (DGN) for image restoration, together with a novel large-scale
high-resolution dataset. Specifically, the network consists of two interactive
branches: a depth estimation branch that provides structural guidance, and an
image restoration branch that performs the core restoration task. In addition,
the image restoration branch exploits intra-object similarity through
progressive window-based self-attention and captures inter-object similarity
via sparse non-local attention. Through joint training, depth features
contribute to improved restoration quality, while the enhanced visual features
from the restoration branch in turn help refine depth estimation. Notably, we
also introduce a new dataset for training and evaluation, consisting of 9,205
high-resolution images from 403 plant species, with diverse depth and texture
variations. Extensive experiments show that our method achieves
state-of-the-art performance on several standard benchmarks and generalizes
well to unseen plant images, demonstrating its effectiveness and robustness.

</details>


### [270] [Unsupervised Real-World Super-Resolution via Rectified Flow Degradation Modelling](https://arxiv.org/abs/2508.07214)
*Hongyang Zhou,Xiaobin Zhu,Liuling Chen,Junyi He,Jingyan Qin,Xu-Cheng Yin,Zhang xiaoxing*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于校正流的无监督真实世界超分辨率方法，通过建模连续可逆的退化轨迹，生成更真实的低分辨率图像，提升超分辨率网络性能。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界超分辨率中复杂未知退化分布导致的泛化问题，弥补合成数据与真实数据的域差距。

Method: 设计了校正流退化模块（RFDM）和傅里叶先验引导退化模块（FGDM），分别建模退化轨迹和利用傅里叶相位信息，生成真实退化低分辨率图像。

Result: 在真实世界数据集上的实验表明，该方法显著提升了现有超分辨率方法的性能。

Conclusion: 通过建模真实退化，该方法有效解决了真实世界超分辨率的挑战。

Abstract: Unsupervised real-world super-resolution (SR) faces critical challenges due
to the complex, unknown degradation distributions in practical scenarios.
Existing methods struggle to generalize from synthetic low-resolution (LR) and
high-resolution (HR) image pairs to real-world data due to a significant domain
gap. In this paper, we propose an unsupervised real-world SR method based on
rectified flow to effectively capture and model real-world degradation,
synthesizing LR-HR training pairs with realistic degradation. Specifically,
given unpaired LR and HR images, we propose a novel Rectified Flow Degradation
Module (RFDM) that introduces degradation-transformed LR (DT-LR) images as
intermediaries. By modeling the degradation trajectory in a continuous and
invertible manner, RFDM better captures real-world degradation and enhances the
realism of generated LR images. Additionally, we propose a Fourier Prior Guided
Degradation Module (FGDM) that leverages structural information embedded in
Fourier phase components to ensure more precise modeling of real-world
degradation. Finally, the LR images are processed by both FGDM and RFDM,
producing final synthetic LR images with real-world degradation. The synthetic
LR images are paired with the given HR images to train the off-the-shelf SR
networks. Extensive experiments on real-world datasets demonstrate that our
method significantly enhances the performance of existing SR approaches in
real-world scenarios.

</details>


### [271] [Generic Calibration: Pose Ambiguity/Linear Solution and Parametric-hybrid Pipeline](https://arxiv.org/abs/2508.07217)
*Yuqi Han,Qi Cai,Yuanxin Wu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种结合通用和参数化相机模型的混合标定方法，解决了通用标定中的姿态模糊问题，并提高了标定精度。


<details>
  <summary>Details</summary>
Motivation: 传统参数化模型依赖用户经验，而通用标定方法复杂且无法提供传统内参。论文揭示了通用标定中的姿态模糊问题，并提出解决方案。

Method: 提出线性求解器和非线性优化解决姿态模糊问题，并引入全局优化的混合标定方法，结合通用和参数化模型。

Result: 混合方法在模拟和实际实验中表现优异，适用于多种镜头类型和噪声环境。

Conclusion: 混合标定方法为复杂场景提供了可靠且精确的相机标定解决方案。

Abstract: Offline camera calibration techniques typically employ parametric or generic
camera models. Selecting parametric models relies heavily on user experience,
and an inappropriate camera model can significantly affect calibration
accuracy. Meanwhile, generic calibration methods involve complex procedures and
cannot provide traditional intrinsic parameters. This paper reveals a pose
ambiguity in the pose solutions of generic calibration methods that
irreversibly impacts subsequent pose estimation. A linear solver and a
nonlinear optimization are proposed to address this ambiguity issue. Then a
global optimization hybrid calibration method is introduced to integrate
generic and parametric models together, which improves extrinsic parameter
accuracy of generic calibration and mitigates overfitting and numerical
instability in parametric calibration. Simulation and real-world experimental
results demonstrate that the generic-parametric hybrid calibration method
consistently excels across various lens types and noise contamination,
hopefully serving as a reliable and accurate solution for camera calibration in
complex scenarios.

</details>


### [272] [HaDM-ST: Histology-Assisted Differential Modeling for Spatial Transcriptomics Generation](https://arxiv.org/abs/2508.07225)
*Xuepeng Liu,Zheng Jiang,Pinan Zhu,Hanyu Liu,Chao Li*

Main category: eess.IV

Relevance: 30.0

TL;DR: HaDM-ST是一种基于H&E图像和低分辨率空间转录组学（ST）的高分辨率ST生成框架，通过语义蒸馏、空间对齐和通道感知对抗学习解决现有挑战。


<details>
  <summary>Details</summary>
Motivation: 解决空间转录组学（ST）分辨率受限的问题，克服从H&E图像提取表达相关特征、多模态对齐和基因特异性建模的挑战。

Method: 包括语义蒸馏网络、空间对齐模块和通道感知对抗学习器，分别用于提取H&E图像特征、实现像素级对齐和基因级建模。

Result: 在200个基因的实验中，HaDM-ST在空间保真度和基因一致性上优于现有方法。

Conclusion: HaDM-ST为高分辨率ST生成提供了有效解决方案，显著提升了性能。

Abstract: Spatial transcriptomics (ST) reveals spatial heterogeneity of gene
expression, yet its resolution is limited by current platforms. Recent methods
enhance resolution via H&E-stained histology, but three major challenges
persist: (1) isolating expression-relevant features from visually complex H&E
images; (2) achieving spatially precise multimodal alignment in diffusion-based
frameworks; and (3) modeling gene-specific variation across expression
channels. We propose HaDM-ST (Histology-assisted Differential Modeling for ST
Generation), a high-resolution ST generation framework conditioned on H&E
images and low-resolution ST. HaDM-ST includes: (i) a semantic distillation
network to extract predictive cues from H&E; (ii) a spatial alignment module
enforcing pixel-wise correspondence with low-resolution ST; and (iii) a
channel-aware adversarial learner for fine-grained gene-level modeling.
Experiments on 200 genes across diverse tissues and species show HaDM-ST
consistently outperforms prior methods, enhancing spatial fidelity and
gene-level coherence in high-resolution ST predictions.

</details>


### [273] [SUIT: Spatial-Spectral Union-Intersection Interaction Network for Hyperspectral Object Tracking](https://arxiv.org/abs/2508.07250)
*Fengchao Xiong,Zhenxing Wu,Sen Jia,Yuntao Qian*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于Transformer和集合论的光谱交互建模方法，用于提升高光谱视频跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注空间交互，忽略了光谱交互，导致性能不佳。

Method: 通过Transformer建立频带间的长程空间关系，并利用集合论的包含-排除原理建模光谱交互；引入光谱损失以增强鲁棒性。

Result: 实验表明，该方法实现了最先进的跟踪性能。

Conclusion: 光谱交互建模显著提升了跟踪性能，代码和模型已开源。

Abstract: Hyperspectral videos (HSVs), with their inherent spatial-spectral-temporal
structure, offer distinct advantages in challenging tracking scenarios such as
cluttered backgrounds and small objects. However, existing methods primarily
focus on spatial interactions between the template and search regions, often
overlooking spectral interactions, leading to suboptimal performance. To
address this issue, this paper investigates spectral interactions from both the
architectural and training perspectives. At the architectural level, we first
establish band-wise long-range spatial relationships between the template and
search regions using Transformers. We then model spectral interactions using
the inclusion-exclusion principle from set theory, treating them as the union
of spatial interactions across all bands. This enables the effective
integration of both shared and band-specific spatial cues. At the training
level, we introduce a spectral loss to enforce material distribution alignment
between the template and predicted regions, enhancing robustness to shape
deformation and appearance variations. Extensive experiments demonstrate that
our tracker achieves state-of-the-art tracking performance. The source code,
trained models and results will be publicly available via
https://github.com/bearshng/suit to support reproducibility.

</details>


### [274] [SynMatch: Rethinking Consistency in Medical Image Segmentation with Sparse Annotations](https://arxiv.org/abs/2508.07298)
*Zhiqiang Shen,Peng Cao,Xiaoli Liu,Jinzhu Yang,Osmar R. Zaiane*

Main category: cs.CV

Relevance: 30.0

TL;DR: SynMatch提出了一种通过合成图像来匹配伪标签的新框架，解决了医学图像分割中伪标签与未标记图像不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中标签稀缺和伪标签与未标记图像不一致的问题。

Method: 利用分割模型提取纹理和形状特征，合成与伪标签高度一致的图像，无需额外训练参数。

Result: 在SSL、WSL和BSL设置下表现优异，尤其在BSL中显著优于现有方法。

Conclusion: SynMatch通过合成图像匹配伪标签，显著提升了医学图像分割的性能。

Abstract: Label scarcity remains a major challenge in deep learning-based medical image
segmentation. Recent studies use strong-weak pseudo supervision to leverage
unlabeled data. However, performance is often hindered by inconsistencies
between pseudo labels and their corresponding unlabeled images. In this work,
we propose \textbf{SynMatch}, a novel framework that sidesteps the need for
improving pseudo labels by synthesizing images to match them instead.
Specifically, SynMatch synthesizes images using texture and shape features
extracted from the same segmentation model that generates the corresponding
pseudo labels for unlabeled images. This design enables the generation of
highly consistent synthesized-image-pseudo-label pairs without requiring any
training parameters for image synthesis. We extensively evaluate SynMatch
across diverse medical image segmentation tasks under semi-supervised learning
(SSL), weakly-supervised learning (WSL), and barely-supervised learning (BSL)
settings with increasingly limited annotations. The results demonstrate that
SynMatch achieves superior performance, especially in the most challenging BSL
setting. For example, it outperforms the recent strong-weak pseudo
supervision-based method by 29.71\% and 10.05\% on the polyp segmentation task
with 5\% and 10\% scribble annotations, respectively. The code will be released
at https://github.com/Senyh/SynMatch.

</details>


### [275] [GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building Reconstruction](https://arxiv.org/abs/2508.07355)
*Qilin Zhang,Olaf Wysocki,Boris Jutzi*

Main category: cs.CV

Relevance: 30.0

TL;DR: GS4Buildings提出了一种基于语义3D建筑模型的先验引导高斯泼溅方法，用于大规模复杂城市场景的鲁棒建筑表面重建。


<details>
  <summary>Details</summary>
Motivation: 传统2D高斯泼溅方法在复杂城市场景中性能下降，导致建筑重建不完整。

Method: 利用低细节语义3D建筑模型初始化高斯分布，并结合先验深度和法线图优化重建过程。

Result: 在城市场景数据集中，重建完整度提升20.5%，几何精度提升32.8%。

Conclusion: 语义建筑模型的整合可推动高斯泼溅重建技术在实际城市场景中的应用。

Abstract: Recent advances in Gaussian Splatting (GS) have demonstrated its
effectiveness in photo-realistic rendering and 3D reconstruction. Among these,
2D Gaussian Splatting (2DGS) is particularly suitable for surface
reconstruction due to its flattened Gaussian representation and integrated
normal regularization. However, its performance often degrades in large-scale
and complex urban scenes with frequent occlusions, leading to incomplete
building reconstructions. We propose GS4Buildings, a novel prior-guided
Gaussian Splatting method leveraging the ubiquity of semantic 3D building
models for robust and scalable building surface reconstruction. Instead of
relying on traditional Structure-from-Motion (SfM) pipelines, GS4Buildings
initializes Gaussians directly from low-level Level of Detail (LoD)2 semantic
3D building models. Moreover, we generate prior depth and normal maps from the
planar building geometry and incorporate them into the optimization process,
providing strong geometric guidance for surface consistency and structural
accuracy. We also introduce an optional building-focused mode that limits
reconstruction to building regions, achieving a 71.8% reduction in Gaussian
primitives and enabling a more efficient and compact representation.
Experiments on urban datasets demonstrate that GS4Buildings improves
reconstruction completeness by 20.5% and geometric accuracy by 32.8%. These
results highlight the potential of semantic building model integration to
advance GS-based reconstruction toward real-world urban applications such as
smart cities and digital twins. Our project is available:
https://github.com/zqlin0521/GS4Buildings.

</details>


### [276] [Training and Inference within 1 Second -- Tackle Cross-Sensor Degradation of Real-World Pansharpening with Efficient Residual Feature Tailoring](https://arxiv.org/abs/2508.07369)
*Tianyu Xin,Jin-Liang Xiao,Zeyu Xia,Shan Yin,Liang-Jian Deng*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种针对跨传感器泛化问题的特征级调整方法，显著提升了泛化能力并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在跨传感器数据上泛化能力差的问题，避免耗时的高成本方法。

Method: 通过模块化分解和特征调整器（Feature Tailor）在特征层面处理跨传感器退化，采用物理感知的无监督损失进行高效训练。

Result: 在跨传感器情况下显著提升性能，训练和推理速度极快（如512x512x8图像仅需0.2秒）。

Conclusion: 该方法在质量和效率上均达到最优，适用于实际大规模应用。

Abstract: Deep learning methods for pansharpening have advanced rapidly, yet models
pretrained on data from a specific sensor often generalize poorly to data from
other sensors. Existing methods to tackle such cross-sensor degradation include
retraining model or zero-shot methods, but they are highly time-consuming or
even need extra training data. To address these challenges, our method first
performs modular decomposition on deep learning-based pansharpening models,
revealing a general yet critical interface where high-dimensional fused
features begin mapping to the channel space of the final image. % may need
revisement A Feature Tailor is then integrated at this interface to address
cross-sensor degradation at the feature level, and is trained efficiently with
physics-aware unsupervised losses. Moreover, our method operates in a
patch-wise manner, training on partial patches and performing parallel
inference on all patches to boost efficiency. Our method offers two key
advantages: (1) $\textit{Improved Generalization Ability}$: it significantly
enhance performance in cross-sensor cases. (2) $\textit{Low Generalization
Cost}$: it achieves sub-second training and inference, requiring only partial
test inputs and no external data, whereas prior methods often take minutes or
even hours. Experiments on the real-world data from multiple datasets
demonstrate that our method achieves state-of-the-art quality and efficiency in
tackling cross-sensor degradation. For example, training and inference of
$512\times512\times8$ image within $\textit{0.2 seconds}$ and
$4000\times4000\times8$ image within $\textit{3 seconds}$ at the fastest
setting on a commonly used RTX 3090 GPU, which is over 100 times faster than
zero-shot methods.

</details>


### [277] [Levarging Learning Bias for Noisy Anomaly Detection](https://arxiv.org/abs/2508.07441)
*Yuxin Zhang,Yunkang Cao,Yuqi Cheng,Yihan Sun,Weiming Shen*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种两阶段框架，利用模型的学习偏置解决无监督图像异常检测中训练数据可能包含未标记异常的问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法假设训练数据无异常而实际数据可能受污染的问题。

Method: 两阶段框架：第一阶段利用学习偏置过滤异常数据，第二阶段在净化数据上训练最终检测器。

Result: 在Real-IAD基准测试中表现出优异的异常检测和定位性能。

Conclusion: 框架具有模型无关性，适用于实际场景中不完美的训练数据。

Abstract: This paper addresses the challenge of fully unsupervised image anomaly
detection (FUIAD), where training data may contain unlabeled anomalies.
Conventional methods assume anomaly-free training data, but real-world
contamination leads models to absorb anomalies as normal, degrading detection
performance. To mitigate this, we propose a two-stage framework that
systematically exploits inherent learning bias in models. The learning bias
stems from: (1) the statistical dominance of normal samples, driving models to
prioritize learning stable normal patterns over sparse anomalies, and (2)
feature-space divergence, where normal data exhibit high intra-class
consistency while anomalies display high diversity, leading to unstable model
responses. Leveraging the learning bias, stage 1 partitions the training set
into subsets, trains sub-models, and aggregates cross-model anomaly scores to
filter a purified dataset. Stage 2 trains the final detector on this dataset.
Experiments on the Real-IAD benchmark demonstrate superior anomaly detection
and localization performance under different noise conditions. Ablation studies
further validate the framework's contamination resilience, emphasizing the
critical role of learning bias exploitation. The model-agnostic design ensures
compatibility with diverse unsupervised backbones, offering a practical
solution for real-world scenarios with imperfect training data. Code is
available at https://github.com/hustzhangyuxin/LLBNAD.

</details>


### [278] [FormCoach: Lift Smarter, Not Harder](https://arxiv.org/abs/2508.07501)
*Xiaoye Zuo,Nikos Athanasiou,Ginger Delmas,Yiming Huang,Xingyu Fu,Lingjie Liu*

Main category: cs.CV

Relevance: 30.0

TL;DR: FormCoach利用视觉语言模型（VLMs）将普通摄像头转化为实时交互式AI健身教练，通过数据集和评估流程推动AI驱动教练研究。


<details>
  <summary>Details</summary>
Motivation: 为居家健身爱好者提供专家级实时反馈，解决专业指导难以获取的问题。

Method: 利用VLMs分析用户动作，开发数据集和自动化评估流程，比较模型性能。

Result: 基准测试显示AI与人类教练水平存在显著差距，但揭示了AI在动作分析中的潜力。

Conclusion: FormCoach为AI与人类协作的具身智能开辟了新方向。

Abstract: Good form is the difference between strength and strain, yet for the
fast-growing community of at-home fitness enthusiasts, expert feedback is often
out of reach. FormCoach transforms a simple camera into an always-on,
interactive AI training partner, capable of spotting subtle form errors and
delivering tailored corrections in real time, leveraging vision-language models
(VLMs). We showcase this capability through a web interface and benchmark
state-of-the-art VLMs on a dataset of 1,700 expert-annotated user-reference
video pairs spanning 22 strength and mobility exercises. To accelerate research
in AI-driven coaching, we release both the dataset and an automated,
rubric-based evaluation pipeline, enabling standardized comparison across
models. Our benchmarks reveal substantial gaps compared to human-level
coaching, underscoring both the challenges and opportunities in integrating
nuanced, context-aware movement analysis into interactive AI systems. By
framing form correction as a collaborative and creative process between humans
and machines, FormCoach opens a new frontier in embodied AI.

</details>


### [279] [Enhanced Generative Structure Prior for Chinese Text Image Super-resolution](https://arxiv.org/abs/2508.07537)
*Xiaoming Li,Wangmeng Zuo,Chen Change Loy*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于结构先验的高质量中文文本图像超分辨率框架，结合StyleGAN生成能力和代码本机制，实现精确笔画恢复。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对英文文本，对复杂脚本（如中文）关注不足，需解决字符结构多样性和字体风格问题。

Method: 利用结构先验指导StyleGAN生成，通过代码本机制限制生成空间，结合字符结构和风格控制。

Result: 实验表明，该方法能准确恢复低分辨率中文文本的笔画，适应不规则布局。

Conclusion: 结构先验为复杂脚本超分辨率提供了有效指导，提升了视觉质量。

Abstract: Faithful text image super-resolution (SR) is challenging because each
character has a unique structure and usually exhibits diverse font styles and
layouts. While existing methods primarily focus on English text, less attention
has been paid to more complex scripts like Chinese. In this paper, we introduce
a high-quality text image SR framework designed to restore the precise strokes
of low-resolution (LR) Chinese characters. Unlike methods that rely on
character recognition priors to regularize the SR task, we propose a novel
structure prior that offers structure-level guidance to enhance visual quality.
Our framework incorporates this structure prior within a StyleGAN model,
leveraging its generative capabilities for restoration. To maintain the
integrity of character structures while accommodating various font styles and
layouts, we implement a codebook-based mechanism that restricts the generative
space of StyleGAN. Each code in the codebook represents the structure of a
specific character, while the vector $w$ in StyleGAN controls the character's
style, including typeface, orientation, and location. Through the collaborative
interaction between the codebook and style, we generate a high-resolution
structure prior that aligns with LR characters both spatially and structurally.
Experiments demonstrate that this structure prior provides robust,
character-specific guidance, enabling the accurate restoration of clear strokes
in degraded characters, even for real-world LR Chinese text with irregular
layouts. Our code and pre-trained models will be available at
https://github.com/csxmli2016/MARCONetPlusPlus

</details>


### [280] [Domain Generalization of Pathological Image Segmentation by Patch-Level and WSI-Level Contrastive Learning](https://arxiv.org/abs/2508.07539)
*Yuki Shigeyasu,Shota Harada,Akihiko Yoshizawa,Kazuhiro Terada,Naoki Nakazima,Mariyo Kurata,Hiroyuki Abe,Tetsuo Ushiku,Ryoma Bise*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种针对病理图像中域偏移的新方法，通过聚类非肿瘤区域的WSI级特征并利用对比学习减少特征差异。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖多医院数据，但数据收集困难，因此提出利用医院内域偏移的方法。

Method: 采用两阶段对比学习（WSI级和patch级）来减少不同聚类间的特征差异。

Result: 方法有效减少了域偏移，提升了模型泛化能力。

Conclusion: 该方法为病理图像分析提供了一种更实用的域泛化解决方案。

Abstract: In this paper, we address domain shifts in pathological images by focusing on
shifts within whole slide images~(WSIs), such as patient characteristics and
tissue thickness, rather than shifts between hospitals. Traditional approaches
rely on multi-hospital data, but data collection challenges often make this
impractical. Therefore, the proposed domain generalization method captures and
leverages intra-hospital domain shifts by clustering WSI-level features from
non-tumor regions and treating these clusters as domains. To mitigate domain
shift, we apply contrastive learning to reduce feature gaps between WSI pairs
from different clusters. The proposed method introduces a two-stage contrastive
learning approach WSI-level and patch-level contrastive learning to minimize
these gaps effectively.

</details>


### [281] [Adaptive Pseudo Label Selection for Individual Unlabeled Data by Positive and Unlabeled Learning](https://arxiv.org/abs/2508.07548)
*Takehiro Yamane,Itaru Tsuge,Susumu Saito,Ryoma Bise*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出一种基于PU学习的医学图像分割伪标签方法，通过单张图像学习选择有效伪标签。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中伪标签选择问题，利用PU学习优化前景与背景区域的判别。

Method: 引入PU学习（仅使用正样本和未标记数据），设计适用于未标记图像的判别指标。

Result: 实验证明该方法能有效选择伪标签，适用于多样化背景区域。

Conclusion: 该方法在医学图像分割中表现优异，为伪标签选择提供了新思路。

Abstract: This paper proposes a novel pseudo-labeling method for medical image
segmentation that can perform learning on ``individual images'' to select
effective pseudo-labels. We introduce Positive and Unlabeled Learning (PU
learning), which uses only positive and unlabeled data for binary
classification problems, to obtain the appropriate metric for discriminating
foreground and background regions on each unlabeled image. Our PU learning
makes us easy to select pseudo-labels for various background regions. The
experimental results show the effectiveness of our method.

</details>


### [282] [Splat4D: Diffusion-Enhanced 4D Gaussian Splatting for Temporally and Spatially Consistent Content Creation](https://arxiv.org/abs/2508.07557)
*Minghao Yin,Yukang Cao,Songyou Peng,Kai Han*

Main category: cs.CV

Relevance: 30.0

TL;DR: Splat4D是一个从单目视频生成高质量4D内容的新框架，通过多视角渲染、不一致性识别、视频扩散模型和非对称U-Net优化，实现了时空一致性和高保真度。


<details>
  <summary>Details</summary>
Motivation: 解决从单目视频生成4D内容时面临的时空一致性、细节保留和用户指导等挑战。

Method: 结合多视角渲染、不一致性识别、视频扩散模型和非对称U-Net进行优化。

Result: 在公开基准测试中表现优异，支持多种应用如文本/图像条件生成和内容编辑。

Conclusion: Splat4D在4D内容生成中表现出色，具有广泛的应用潜力。

Abstract: Generating high-quality 4D content from monocular videos for applications
such as digital humans and AR/VR poses challenges in ensuring temporal and
spatial consistency, preserving intricate details, and incorporating user
guidance effectively. To overcome these challenges, we introduce Splat4D, a
novel framework enabling high-fidelity 4D content generation from a monocular
video. Splat4D achieves superior performance while maintaining faithful
spatial-temporal coherence by leveraging multi-view rendering, inconsistency
identification, a video diffusion model, and an asymmetric U-Net for
refinement. Through extensive evaluations on public benchmarks, Splat4D
consistently demonstrates state-of-the-art performance across various metrics,
underscoring the efficacy of our approach. Additionally, the versatility of
Splat4D is validated in various applications such as text/image conditioned 4D
generation, 4D human generation, and text-guided content editing, producing
coherent outcomes following user instructions.

</details>


### [283] [GAPNet: A Lightweight Framework for Image and Video Salient Object Detection via Granularity-Aware Paradigm](https://arxiv.org/abs/2508.07585)
*Yu-Huan Wu,Wei Liu,Zi-Xuan Zhu,Zizhou Wang,Yong Liu,Liangli Zhen*

Main category: cs.CV

Relevance: 30.0

TL;DR: GAPNet是一种轻量级网络，基于粒度感知范式，用于图像和视频显著性目标检测（SOD），通过多尺度监督和高效特征融合实现高性能。


<details>
  <summary>Details</summary>
Motivation: 现有SOD模型依赖重型骨干网络，计算成本高，限制了在边缘设备上的应用。GAPNet旨在提供轻量级解决方案。

Method: 采用粒度感知范式，设计粒度金字塔卷积（GPC）和跨尺度注意力（CSA）模块，结合自注意力模块优化特征利用。

Result: 在轻量级图像和视频SOD模型中达到最新性能。

Conclusion: GAPNet通过高效特征融合和粒度感知监督，显著提升了轻量级SOD模型的性能。

Abstract: Recent salient object detection (SOD) models predominantly rely on
heavyweight backbones, incurring substantial computational cost and hindering
their practical application in various real-world settings, particularly on
edge devices. This paper presents GAPNet, a lightweight network built on the
granularity-aware paradigm for both image and video SOD. We assign saliency
maps of different granularities to supervise the multi-scale decoder
side-outputs: coarse object locations for high-level outputs and fine-grained
object boundaries for low-level outputs. Specifically, our decoder is built
with granularity-aware connections which fuse high-level features of low
granularity and low-level features of high granularity, respectively. To
support these connections, we design granular pyramid convolution (GPC) and
cross-scale attention (CSA) modules for efficient fusion of low-scale and
high-scale features, respectively. On top of the encoder, a self-attention
module is built to learn global information, enabling accurate object
localization with negligible computational cost. Unlike traditional U-Net-based
approaches, our proposed method optimizes feature utilization and semantic
interpretation while applying appropriate supervision at each processing stage.
Extensive experiments show that the proposed method achieves a new
state-of-the-art performance among lightweight image and video SOD models. Code
is available at https://github.com/yuhuan-wu/GAPNet.

</details>


### [284] [Voice Pathology Detection Using Phonation](https://arxiv.org/abs/2508.07587)
*Sri Raksha Siva,Nived Suthahar,Prakash Boominathan,Uma Ranjan*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于机器学习的非侵入性框架，用于通过语音数据检测声音病理。


<details>
  <summary>Details</summary>
Motivation: 传统的声音病理诊断方法（如喉镜检查）具有侵入性、主观性且难以普及，因此需要一种非侵入性、自动化的诊断工具。

Method: 利用声学特征（如MFCCs、chroma特征和Mel频谱图）分析语音数据，使用RNN（包括LSTM和注意力机制）进行分类，并通过数据增强和预处理提高模型泛化能力。

Result: 该框架能够有效分类正常和病理声音样本。

Conclusion: 该研究为声音病理的早期检测提供了一种非侵入性、自动化的诊断工具，推动了AI驱动的医疗保健发展。

Abstract: Voice disorders significantly affect communication and quality of life,
requiring an early and accurate diagnosis. Traditional methods like
laryngoscopy are invasive, subjective, and often inaccessible. This research
proposes a noninvasive, machine learning-based framework for detecting voice
pathologies using phonation data.
  Phonation data from the Saarbr\"ucken Voice Database are analyzed using
acoustic features such as Mel Frequency Cepstral Coefficients (MFCCs), chroma
features, and Mel spectrograms. Recurrent Neural Networks (RNNs), including
LSTM and attention mechanisms, classify samples into normal and pathological
categories. Data augmentation techniques, including pitch shifting and Gaussian
noise addition, enhance model generalizability, while preprocessing ensures
signal quality. Scale-based features, such as H\"older and Hurst exponents,
further capture signal irregularities and long-term dependencies.
  The proposed framework offers a noninvasive, automated diagnostic tool for
early detection of voice pathologies, supporting AI-driven healthcare, and
improving patient outcomes.

</details>


### [285] [SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation](https://arxiv.org/abs/2508.07621)
*Yunsung Chung,Chanho Lim,Ghassan Bidaoui,Christian Massad,Nassir Marrouche,Jihun Hamm*

Main category: cs.CV

Relevance: 30.0

TL;DR: SOFA是一个深度学习框架，用于模拟和优化心房颤动消融手术的效果，预测复发风险并优化手术参数。


<details>
  <summary>Details</summary>
Motivation: 心房颤动消融手术效果差异大，需个性化优化以提高疗效。

Method: SOFA通过模拟消融后的瘢痕形成图像，结合患者术前LGE-MRI和手术参数，预测复发风险并优化参数。

Result: SOFA能准确合成术后图像，优化方案使模型预测的复发风险降低22.18%。

Conclusion: SOFA首次整合了手术效果模拟、复发预测和参数优化，为个性化治疗提供了新工具。

Abstract: Atrial fibrillation (AF) is a prevalent cardiac arrhythmia often treated with
catheter ablation procedures, but procedural outcomes are highly variable.
Evaluating and improving ablation efficacy is challenging due to the complex
interaction between patient-specific tissue and procedural factors. This paper
asks two questions: Can AF recurrence be predicted by simulating the effects of
procedural parameters? How should we ablate to reduce AF recurrence? We propose
SOFA (Simulating and Optimizing Atrial Fibrillation Ablation), a novel
deep-learning framework that addresses these questions. SOFA first simulates
the outcome of an ablation strategy by generating a post-ablation image
depicting scar formation, conditioned on a patient's pre-ablation LGE-MRI and
the specific procedural parameters used (e.g., ablation locations, duration,
temperature, power, and force). During this simulation, it predicts AF
recurrence risk. Critically, SOFA then introduces an optimization scheme that
refines these procedural parameters to minimize the predicted risk. Our method
leverages a multi-modal, multi-view generator that processes 2.5D
representations of the atrium. Quantitative evaluations show that SOFA
accurately synthesizes post-ablation images and that our optimization scheme
leads to a 22.18\% reduction in the model-predicted recurrence risk. To the
best of our knowledge, SOFA is the first framework to integrate the simulation
of procedural effects, recurrence prediction, and parameter optimization,
offering a novel tool for personalizing AF ablation.

</details>


### [286] [LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering](https://arxiv.org/abs/2508.07647)
*Xiaohang Zhan,Dingming Liu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种无需训练的图像生成算法，通过体积渲染原理在潜在空间中控制物体遮挡关系，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成方法依赖提示或布局控制遮挡，但缺乏精确性，需要一种无需重新训练的方法实现精确遮挡控制。

Method: 利用预训练扩散模型，基于体积渲染原理在潜在空间中渲染场景，通过遮挡关系和物体透射率指导生成。

Result: 实验表明，该方法在遮挡准确性上显著优于现有方法，并能通过调整物体透明度等实现多种效果。

Conclusion: 该方法无需重新训练扩散模型，实现了精确的遮挡控制和多样化的图像效果。

Abstract: We propose a novel training-free image generation algorithm that precisely
controls the occlusion relationships between objects in an image. Existing
image generation methods typically rely on prompts to influence occlusion,
which often lack precision. While layout-to-image methods provide control over
object locations, they fail to address occlusion relationships explicitly.
Given a pre-trained image diffusion model, our method leverages volume
rendering principles to "render" the scene in latent space, guided by occlusion
relationships and the estimated transmittance of objects. This approach does
not require retraining or fine-tuning the image diffusion model, yet it enables
accurate occlusion control due to its physics-grounded foundation. In extensive
experiments, our method significantly outperforms existing approaches in terms
of occlusion accuracy. Furthermore, we demonstrate that by adjusting the
opacities of objects or concepts during rendering, our method can achieve a
variety of effects, such as altering the transparency of objects, the density
of mass (e.g., forests), the concentration of particles (e.g., rain, fog), the
intensity of light, and the strength of lens effects, etc.

</details>


### [287] [Collaborative Learning of Scattering and Deep Features for SAR Target Recognition with Noisy Labels](https://arxiv.org/abs/2508.07656)
*Yimin Fu,Zhunga Liu,Dongxiu Guo,Longfei Wang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种结合散射和深度特征的协作学习方法（CLSDF），用于处理SAR自动目标识别中的噪声标签问题，通过多模型特征融合和半监督学习实现高性能。


<details>
  <summary>Details</summary>
Motivation: SAR数据的高质量标注困难且易受噪声影响，现有方法主要针对图像数据，无法直接适用于SAR数据。

Method: 设计多模型特征融合框架，将散射特征与深度特征结合；通过GMM建模损失分布划分干净和噪声样本；采用半监督学习和联合分布对齐策略。

Result: 在MSTAR数据集上验证，CLSDF方法在不同噪声条件下均达到最优性能。

Conclusion: CLSDF方法有效解决了SAR数据噪声标签问题，提升了识别性能。

Abstract: The acquisition of high-quality labeled synthetic aperture radar (SAR) data
is challenging due to the demanding requirement for expert knowledge.
Consequently, the presence of unreliable noisy labels is unavoidable, which
results in performance degradation of SAR automatic target recognition (ATR).
Existing research on learning with noisy labels mainly focuses on image data.
However, the non-intuitive visual characteristics of SAR data are insufficient
to achieve noise-robust learning. To address this problem, we propose
collaborative learning of scattering and deep features (CLSDF) for SAR ATR with
noisy labels. Specifically, a multi-model feature fusion framework is designed
to integrate scattering and deep features. The attributed scattering centers
(ASCs) are treated as dynamic graph structure data, and the extracted physical
characteristics effectively enrich the representation of deep image features.
Then, the samples with clean and noisy labels are divided by modeling the loss
distribution with multiple class-wise Gaussian Mixture Models (GMMs).
Afterward, the semi-supervised learning of two divergent branches is conducted
based on the data divided by each other. Moreover, a joint distribution
alignment strategy is introduced to enhance the reliability of co-guessed
labels. Extensive experiments have been done on the Moving and Stationary
Target Acquisition and Recognition (MSTAR) dataset, and the results show that
the proposed method can achieve state-of-the-art performance under different
operating conditions with various label noises.

</details>


### [288] [Undress to Redress: A Training-Free Framework for Virtual Try-On](https://arxiv.org/abs/2508.07680)
*Zhiying Li,Junhao Wu,Yeying Jin,Daiheng Gao,Yun Ji,Kaichuan Kong,Lei Yu,Hao Xu,Kai Chen,Bruce Gu,Nana Wang,Zhaoxin Fan*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出UR-VTON框架，解决虚拟试衣中长袖转短袖的挑战，通过“脱衣-穿衣”机制提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试衣方法在长袖转短袖场景中效果不佳，主要因皮肤还原不准确。

Method: 提出UR-VTON框架，分两步完成转换：先虚拟“脱衣”露出躯干，再“穿衣”；结合动态分类器自由引导和结构细化器。

Result: UR-VTON在细节保留和图像质量上优于现有方法。

Conclusion: UR-VTON为虚拟试衣提供了一种高效且无需训练的解决方案。

Abstract: Virtual try-on (VTON) is a crucial task for enhancing user experience in
online shopping by generating realistic garment previews on personal photos.
Although existing methods have achieved impressive results, they struggle with
long-sleeve-to-short-sleeve conversions-a common and practical scenario-often
producing unrealistic outputs when exposed skin is underrepresented in the
original image. We argue that this challenge arises from the ''majority''
completion rule in current VTON models, which leads to inaccurate skin
restoration in such cases. To address this, we propose UR-VTON (Undress-Redress
Virtual Try-ON), a novel, training-free framework that can be seamlessly
integrated with any existing VTON method. UR-VTON introduces an
''undress-to-redress'' mechanism: it first reveals the user's torso by
virtually ''undressing,'' then applies the target short-sleeve garment,
effectively decomposing the conversion into two more manageable steps.
Additionally, we incorporate Dynamic Classifier-Free Guidance scheduling to
balance diversity and image quality during DDPM sampling, and employ Structural
Refiner to enhance detail fidelity using high-frequency cues. Finally, we
present LS-TON, a new benchmark for long-sleeve-to-short-sleeve try-on.
Extensive experiments demonstrate that UR-VTON outperforms state-of-the-art
methods in both detail preservation and image quality. Code will be released
upon acceptance.

</details>


### [289] [DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework](https://arxiv.org/abs/2508.07682)
*Wenzhuo Ma,Zhenzhong Chen*

Main category: eess.IV

Relevance: 30.0

TL;DR: DiffVC-OSD是一种基于单步扩散的感知神经视频压缩框架，通过结合时间上下文和潜在表示提升感知质量，并在解码速度和比特率上显著优于多步扩散方法。


<details>
  <summary>Details</summary>
Motivation: 传统多步扩散方法计算成本高且效率低，DiffVC-OSD旨在通过单步扩散提升视频压缩的感知质量和效率。

Method: 提出单步扩散模型，结合时间上下文适配器和端到端微调策略，优化潜在表示的解码过程。

Result: DiffVC-OSD在感知压缩性能上达到SOTA，解码速度提升20倍，比特率降低86.92%。

Conclusion: DiffVC-OSD为高效视频压缩提供了新思路，显著提升了性能和效率。

Abstract: In this work, we first propose DiffVC-OSD, a One-Step Diffusion-based
Perceptual Neural Video Compression framework. Unlike conventional multi-step
diffusion-based methods, DiffVC-OSD feeds the reconstructed latent
representation directly into a One-Step Diffusion Model, enhancing perceptual
quality through a single diffusion step guided by both temporal context and the
latent itself. To better leverage temporal dependencies, we design a Temporal
Context Adapter that encodes conditional inputs into multi-level features,
offering more fine-grained guidance for the Denoising Unet. Additionally, we
employ an End-to-End Finetuning strategy to improve overall compression
performance. Extensive experiments demonstrate that DiffVC-OSD achieves
state-of-the-art perceptual compression performance, offers about 20$\times$
faster decoding and a 86.92\% bitrate reduction compared to the corresponding
multi-step diffusion-based variant.

</details>


### [290] [Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing](https://arxiv.org/abs/2508.07700)
*Weitao Wang,Haoran Xu,Jun Meng,Haoqian Wang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种无需调优的即插即用方案，用于在3D生成中保持编辑内容与原始几何的对齐。


<details>
  <summary>Details</summary>
Motivation: 随着3D生成技术的普及，用户对个性化内容的需求增加，但现有2D编辑工具直接应用于3D生成会导致信息丢失。

Method: 通过几何保留模块和注入切换器，在单次推理中实现编辑内容与原始几何的对齐。

Result: 实验表明，该方法显著提升了编辑3D资源的多视图一致性和网格质量。

Conclusion: 该方法在多种多视图扩散模型和编辑方法的组合中均表现优异。

Abstract: As 3D generation techniques continue to flourish, the demand for generating
personalized content is rapidly rising. Users increasingly seek to apply
various editing methods to polish generated 3D content, aiming to enhance its
color, style, and lighting without compromising the underlying geometry.
However, most existing editing tools focus on the 2D domain, and directly
feeding their results into 3D generation methods (like multi-view diffusion
models) will introduce information loss, degrading the quality of the final 3D
assets. In this paper, we propose a tuning-free, plug-and-play scheme that
aligns edited assets with their original geometry in a single inference run.
Central to our approach is a geometry preservation module that guides the
edited multi-view generation with original input normal latents. Besides, an
injection switcher is proposed to deliberately control the supervision extent
of the original normals, ensuring the alignment between the edited color and
normal views. Extensive experiments show that our method consistently improves
both the multi-view consistency and mesh quality of edited 3D assets, across
multiple combinations of multi-view diffusion models and editing methods.

</details>


### [291] [Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction](https://arxiv.org/abs/2508.07701)
*Bo Jia,Yanan Guo,Ying Chang,Benkui Zhang,Ying Xie,Kangning Du,Lin Cao*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种多视角距离和法线引导的高斯泼溅方法，解决了3D高斯泼溅在多视角场景中的几何深度统一和高精度重建问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯泼溅在单视角投影平面中几何表现合理，但在切换视角时可能出现偏差，因此需要解决多视角场景中的距离和全局匹配问题。

Method: 设计了多视角距离重投影正则化模块和法线增强模块，通过约束邻近深度图和对齐3D法线实现几何深度统一。

Result: 实验结果表明，该方法在定量和定性评估中均优于基线，显著提升了3D高斯泼溅的表面重建能力。

Conclusion: 该方法在多视角场景中实现了高精度重建，解决了3D高斯泼溅的视角偏差问题。

Abstract: 3D Gaussian Splatting (3DGS) achieves remarkable results in the field of
surface reconstruction. However, when Gaussian normal vectors are aligned
within the single-view projection plane, while the geometry appears reasonable
in the current view, biases may emerge upon switching to nearby views. To
address the distance and global matching challenges in multi-view scenes, we
design multi-view normal and distance-guided Gaussian splatting. This method
achieves geometric depth unification and high-accuracy reconstruction by
constraining nearby depth maps and aligning 3D normals. Specifically, for the
reconstruction of small indoor and outdoor scenes, we propose a multi-view
distance reprojection regularization module that achieves multi-view Gaussian
alignment by computing the distance loss between two nearby views and the same
Gaussian surface. Additionally, we develop a multi-view normal enhancement
module, which ensures consistency across views by matching the normals of pixel
points in nearby views and calculating the loss. Extensive experimental results
demonstrate that our method outperforms the baseline in both quantitative and
qualitative evaluations, significantly enhancing the surface reconstruction
capability of 3DGS.

</details>


### [292] [DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models](https://arxiv.org/abs/2508.07714)
*Licheng Zhang,Bach Le,Naveed Akhtar,Tuan Ngo*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种结合深度学习和大语言模型（LLM）的半自动化流程，用于构建多类别门检测数据集，显著降低了标注成本。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集稀缺，难以支持细粒度多类别门检测任务，因此需要一种高效的数据集构建方法。

Method: 使用深度目标检测模型统一检测门，再通过LLM基于视觉和上下文特征分类，最后人工校验确保质量。

Result: 构建了一个适用于地板图分析的数据集，显著减少了标注工作量。

Conclusion: 结合深度学习和多模态推理可高效构建复杂领域的数据集。

Abstract: Accurate detection and classification of diverse door types in floor plans
drawings is critical for multiple applications, such as building compliance
checking, and indoor scene understanding. Despite their importance, publicly
available datasets specifically designed for fine-grained multi-class door
detection remain scarce. In this work, we present a semi-automated pipeline
that leverages a state-of-the-art object detector and a large language model
(LLM) to construct a multi-class door detection dataset with minimal manual
effort. Doors are first detected as a unified category using a deep object
detection model. Next, an LLM classifies each detected instance based on its
visual and contextual features. Finally, a human-in-the-loop stage ensures
high-quality labels and bounding boxes. Our method significantly reduces
annotation cost while producing a dataset suitable for benchmarking neural
models in floor plan analysis. This work demonstrates the potential of
combining deep learning and multimodal reasoning for efficient dataset
construction in complex real-world domains.

</details>


### [293] [Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation](https://arxiv.org/abs/2508.07769)
*Xiaoyan Liu,Kangrui Li,Jiaxin Liu*

Main category: cs.CV

Relevance: 30.0

TL;DR: Dream4D结合可控视频生成与神经4D重建，通过两阶段架构生成时空一致的4D内容，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决计算机视觉中4D内容合成的挑战，特别是保持视角一致性和处理复杂场景动态。

Method: 两阶段架构：1) 从单图像预测最优相机轨迹；2) 通过姿态条件扩散生成多视角序列，并转换为持久4D表示。

Result: 在质量指标（如mPSNR、mSSIM）上优于现有方法。

Conclusion: Dream4D首次结合视频扩散模型的时间先验与重建模型的几何感知，显著提升4D生成质量。

Abstract: The synthesis of spatiotemporally coherent 4D content presents fundamental
challenges in computer vision, requiring simultaneous modeling of high-fidelity
spatial representations and physically plausible temporal dynamics. Current
approaches often struggle to maintain view consistency while handling complex
scene dynamics, particularly in large-scale environments with multiple
interacting elements. This work introduces Dream4D, a novel framework that
bridges this gap through a synergy of controllable video generation and neural
4D reconstruction. Our approach seamlessly combines a two-stage architecture:
it first predicts optimal camera trajectories from a single image using
few-shot learning, then generates geometrically consistent multi-view sequences
via a specialized pose-conditioned diffusion process, which are finally
converted into a persistent 4D representation. This framework is the first to
leverage both rich temporal priors from video diffusion models and geometric
awareness of the reconstruction models, which significantly facilitates 4D
generation and shows higher quality (e.g., mPSNR, mSSIM) over existing methods.

</details>


### [294] [Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models](https://arxiv.org/abs/2508.07818)
*Chenyue Song,Chen Hui,Haiqi Zhu,Feng Jiang,Yachun Mi,Wei Zhang,Shaohui Liu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种细粒度图像质量评估模型RSFIQA，结合区域级失真信息和多模态大语言模型（MLLM）来提升质量感知能力，并通过区域感知语义注意力机制（RSA）整合局部特征。


<details>
  <summary>Details</summary>
Motivation: 现有无参考图像质量评估（NR-IQA）方法在全局表示或区域特征均匀加权上存在局限性，无法充分捕捉语义显著区域或局部质量变化。

Method: 利用Segment Anything Model（SAM）动态分割图像为语义区域，结合MLLM提取区域描述和感知失真，并通过RSA机制整合局部特征。

Result: 实验表明RSFIQA在多个基准数据集上具有竞争性的质量预测性能。

Conclusion: RSFIQA是一种灵活且高效的方法，能够全面理解局部语义和质量退化。

Abstract: No-reference image quality assessment (NR-IQA) aims to simulate the process
of perceiving image quality aligned with subjective human perception. However,
existing NR-IQA methods either focus on global representations that leads to
limited insights into the semantically salient regions or employ a uniform
weighting for region features that weakens the sensitivity to local quality
variations. In this paper, we propose a fine-grained image quality assessment
model, named RSFIQA, which integrates region-level distortion information to
perceive multi-dimensional quality discrepancies. To enhance regional quality
awareness, we first utilize the Segment Anything Model (SAM) to dynamically
partition the input image into non-overlapping semantic regions. For each
region, we teach a powerful Multi-modal Large Language Model (MLLM) to extract
descriptive content and perceive multi-dimensional distortions, enabling a
comprehensive understanding of both local semantics and quality degradations.
To effectively leverage this information, we introduce Region-Aware Semantic
Attention (RSA) mechanism, which generates a global attention map by
aggregating fine-grained representations from local regions. In addition,
RSFIQA is backbone-agnostic and can be seamlessly integrated into various deep
neural network architectures. Extensive experiments demonstrate the robustness
and effectiveness of the proposed method, which achieves competitive quality
prediction performance across multiple benchmark datasets.

</details>


### [295] [NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction](https://arxiv.org/abs/2508.07897)
*Tianle Zeng,Junlei Hu,Gerardo Loza Galindo,Sharib Ali,Duygu Sarikaya,Pietro Valdastri,Dominic Jones*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种动态高斯Splatting技术，用于解决手术图像数据稀缺问题，生成高质量合成数据，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于数据驱动的手术自动化技术需要大量高质量标注数据，但手术图像数据稀缺，限制了其应用。

Method: 提出动态高斯模型表示动态手术场景，结合动态训练调整策略和自动标注方法，生成合成数据。

Result: 实验显示，该方法生成的合成数据质量高（PSNR 29.87），且使用合成数据训练的模型性能优于传统数据增强方法（提升15%）。

Conclusion: 动态高斯Splatting技术能有效缓解手术图像数据稀缺问题，提升模型性能。

Abstract: Computer vision-based technologies significantly enhance surgical automation
by advancing tool tracking, detection, and localization. However, Current
data-driven approaches are data-voracious, requiring large, high-quality
labeled image datasets, which limits their application in surgical data
science. Our Work introduces a novel dynamic Gaussian Splatting technique to
address the data scarcity in surgical image datasets. We propose a dynamic
Gaussian model to represent dynamic surgical scenes, enabling the rendering of
surgical instruments from unseen viewpoints and deformations with real tissue
backgrounds. We utilize a dynamic training adjustment strategy to address
challenges posed by poorly calibrated camera poses from real-world scenarios.
Additionally, we propose a method based on dynamic Gaussians for automatically
generating annotations for our synthetic data. For evaluation, we constructed a
new dataset featuring seven scenes with 14,000 frames of tool and camera motion
and tool jaw articulation, with a background of an ex-vivo porcine model. Using
this dataset, we synthetically replicate the scene deformation from the ground
truth data, allowing direct comparisons of synthetic image quality.
Experimental results illustrate that our method generates photo-realistic
labeled image datasets with the highest values in Peak-Signal-to-Noise Ratio
(29.87). We further evaluate the performance of medical-specific neural
networks trained on real and synthetic images using an unseen real-world image
dataset. Our results show that the performance of models trained on synthetic
images generated by the proposed method outperforms those trained with
state-of-the-art standard data augmentation by 10%, leading to an overall
improvement in model performances by nearly 15%.

</details>


### [296] [CTC Transcription Alignment of the Bullinger Letters: Automatic Improvement of Annotation Quality](https://arxiv.org/abs/2508.07904)
*Marco Peer,Anna Scius-Bertrand,Andreas Fischer*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于CTC对齐算法的自训练方法，用于解决历史文档手写文本识别中的标注错误问题，特别是连字符问题。该方法通过动态规划和模型输出概率匹配转录文本与图像行，提高了识别性能和对齐准确性。


<details>
  <summary>Details</summary>
Motivation: 历史文档手写文本识别因手写变异性、文档退化和缺乏布局感知标注而具有挑战性。本文旨在解决Bullinger信件集中的标注错误问题，尤其是连字符问题。

Method: 采用基于CTC对齐算法的自训练方法，利用动态规划和模型输出概率将完整转录与文本行图像匹配。

Result: 方法提高了识别性能（如CER提升1.1个百分点）和对齐准确性。有趣的是，较弱的模型反而能提供更准确的对齐，支持迭代训练策略。

Conclusion: 该方法可迭代应用于文本识别流程，进一步提升CER和对齐质量。作者发布了手动校正的100页Bullinger数据集子集及代码。

Abstract: Handwritten text recognition for historical documents remains challenging due
to handwriting variability, degraded sources, and limited layout-aware
annotations. In this work, we address annotation errors - particularly
hyphenation issues - in the Bullinger correspondence, a large 16th-century
letter collection. We introduce a self-training method based on a CTC alignment
algorithm that matches full transcriptions to text line images using dynamic
programming and model output probabilities trained with the CTC loss. Our
approach improves performance (e.g., by 1.1 percentage points CER with PyLaia)
and increases alignment accuracy. Interestingly, we find that weaker models
yield more accurate alignments, enabling an iterative training strategy. We
release a new manually corrected subset of 100 pages from the Bullinger
dataset, along with our code and benchmarks. Our approach can be applied
iteratively to further improve the CER as well as the alignment quality for
text recognition pipelines. Code and data are available via
https://github.com/andreas-fischer-unifr/nntp.

</details>


### [297] [Generative Video Matting](https://arxiv.org/abs/2508.07905)
*Yongtao Ge,Kangyang Xie,Guangkai Xu,Mingyu Liu,Li Ke,Longtao Huang,Hui Xue,Hao Chen,Chunhua Shen*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种视频抠图方法，通过大规模预训练和合成数据生成，结合视频扩散模型的先验知识，显著提升了真实场景的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决视频抠图领域因缺乏高质量真实数据导致的泛化能力不足问题。

Method: 1. 利用大规模合成和伪标签分割数据集进行预训练；2. 开发可扩展的合成数据生成流程；3. 提出基于视频扩散模型的新方法，确保时间一致性。

Result: 在三个基准数据集上表现优异，展示了强泛化能力。

Conclusion: 结合预训练和视频扩散模型的方法显著提升了视频抠图性能。

Abstract: Video matting has traditionally been limited by the lack of high-quality
ground-truth data. Most existing video matting datasets provide only
human-annotated imperfect alpha and foreground annotations, which must be
composited to background images or videos during the training stage. Thus, the
generalization capability of previous methods in real-world scenarios is
typically poor. In this work, we propose to solve the problem from two
perspectives. First, we emphasize the importance of large-scale pre-training by
pursuing diverse synthetic and pseudo-labeled segmentation datasets. We also
develop a scalable synthetic data generation pipeline that can render diverse
human bodies and fine-grained hairs, yielding around 200 video clips with a
3-second duration for fine-tuning. Second, we introduce a novel video matting
approach that can effectively leverage the rich priors from pre-trained video
diffusion models. This architecture offers two key advantages. First, strong
priors play a critical role in bridging the domain gap between synthetic and
real-world scenes. Second, unlike most existing methods that process video
matting frame-by-frame and use an independent decoder to aggregate temporal
information, our model is inherently designed for video, ensuring strong
temporal consistency. We provide a comprehensive quantitative evaluation across
three benchmark datasets, demonstrating our approach's superior performance,
and present comprehensive qualitative results in diverse real-world scenes,
illustrating the strong generalization capability of our method. The code is
available at https://github.com/aim-uofa/GVM.

</details>


### [298] [Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.07908)
*Xudong Cai,Shuo Wang,Peng Wang,Yongcai Wang,Zhaoxin Fan,Wanting Li,Tianbao Zhang,Jianrong Tao,Yeying Jin,Deying Li*

Main category: cs.CV

Relevance: 30.0

TL;DR: Mem4D提出了一种双记忆架构，分别处理静态结构和动态运动，解决了动态场景重建中的内存需求矛盾。


<details>
  <summary>Details</summary>
Motivation: 动态场景的单目视频重建存在内存需求矛盾，现有方法在静态结构的长期稳定性和动态运动的高保真细节保留之间难以平衡。

Method: 设计了双记忆架构：瞬态动态记忆（TDM）捕获高频运动细节，持久结构记忆（PSM）保留长期空间信息。

Result: 在基准测试中表现优异，实现了静态几何的全局一致性和动态元素的高保真重建。

Conclusion: Mem4D通过解耦静态和动态建模，显著提升了动态场景重建的性能和效率。

Abstract: Reconstructing dense geometry for dynamic scenes from a monocular video is a
critical yet challenging task. Recent memory-based methods enable efficient
online reconstruction, but they fundamentally suffer from a Memory Demand
Dilemma: The memory representation faces an inherent conflict between the
long-term stability required for static structures and the rapid, high-fidelity
detail retention needed for dynamic motion. This conflict forces existing
methods into a compromise, leading to either geometric drift in static
structures or blurred, inaccurate reconstructions of dynamic objects. To
address this dilemma, we propose Mem4D, a novel framework that decouples the
modeling of static geometry and dynamic motion. Guided by this insight, we
design a dual-memory architecture: 1) The Transient Dynamics Memory (TDM)
focuses on capturing high-frequency motion details from recent frames, enabling
accurate and fine-grained modeling of dynamic content; 2) The Persistent
Structure Memory (PSM) compresses and preserves long-term spatial information,
ensuring global consistency and drift-free reconstruction for static elements.
By alternating queries to these specialized memories, Mem4D simultaneously
maintains static geometry with global consistency and reconstructs dynamic
elements with high fidelity. Experiments on challenging benchmarks demonstrate
that our method achieves state-of-the-art or competitive performance while
maintaining high efficiency. Codes will be publicly available.

</details>


### [299] [TrackOR: Towards Personalized Intelligent Operating Rooms Through Robust Tracking](https://arxiv.org/abs/2508.07968)
*Tony Danjun Wang,Christian Heiliger,Nassir Navab,Lennart Bastian*

Main category: cs.CV

Relevance: 30.0

TL;DR: TrackOR是一个用于手术室中长期多人员跟踪和重识别的框架，利用3D几何特征实现高性能跟踪，并支持离线轨迹恢复。


<details>
  <summary>Details</summary>
Motivation: 为手术团队提供智能支持，提升患者治疗效果，需解决长期多人跟踪的挑战。

Method: 使用3D几何特征进行在线跟踪和离线轨迹恢复。

Result: 跟踪性能提升11%，支持更精细的人员分析。

Conclusion: 3D几何信息使持久身份跟踪成为可能，为个性化智能系统铺路。

Abstract: Providing intelligent support to surgical teams is a key frontier in
automated surgical scene understanding, with the long-term goal of improving
patient outcomes. Developing personalized intelligence for all staff members
requires maintaining a consistent state of who is located where for long
surgical procedures, which still poses numerous computational challenges. We
propose TrackOR, a framework for tackling long-term multi-person tracking and
re-identification in the operating room. TrackOR uses 3D geometric signatures
to achieve state-of-the-art online tracking performance (+11% Association
Accuracy over the strongest baseline), while also enabling an effective offline
recovery process to create analysis-ready trajectories. Our work shows that by
leveraging 3D geometric information, persistent identity tracking becomes
attainable, enabling a critical shift towards the more granular, staff-centric
analyses required for personalized intelligent systems in the operating room.
This new capability opens up various applications, including our proposed
temporal pathway imprints that translate raw tracking data into actionable
insights for improving team efficiency and safety and ultimately providing
personalized support.

</details>


### [300] [Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation](https://arxiv.org/abs/2508.07981)
*Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了Omni-Effects框架，解决视频生成模型中多效果空间可控的挑战，通过LoRA-MoE和SAP技术实现多样效果生成与精确空间控制。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型受限于单效果训练，无法满足多效果空间可控的需求，阻碍了复合效果的应用。

Method: 采用LoRA-MoE（专家LoRA组）和SAP（空间感知提示）技术，结合IIF模块防止信号干扰。

Result: Omni-Effects实现了多效果的空间可控生成，并通过实验验证了其性能。

Conclusion: 该框架为多效果视频生成提供了统一解决方案，具有实际应用潜力。

Abstract: Visual effects (VFX) are essential visual enhancements fundamental to modern
cinematic production. Although video generation models offer cost-efficient
solutions for VFX production, current methods are constrained by per-effect
LoRA training, which limits generation to single effects. This fundamental
limitation impedes applications that require spatially controllable composite
effects, i.e., the concurrent generation of multiple effects at designated
locations. However, integrating diverse effects into a unified framework faces
major challenges: interference from effect variations and spatial
uncontrollability during multi-VFX joint training. To tackle these challenges,
we propose Omni-Effects, a first unified framework capable of generating
prompt-guided effects and spatially controllable composite effects. The core of
our framework comprises two key innovations: (1) LoRA-based Mixture of Experts
(LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects
within a unified model while effectively mitigating cross-task interference.
(2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the
text token, enabling precise spatial control. Furthermore, we introduce an
Independent-Information Flow (IIF) module integrated within the SAP, isolating
the control signals corresponding to individual effects to prevent any unwanted
blending. To facilitate this research, we construct a comprehensive VFX dataset
Omni-VFX via a novel data collection pipeline combining image editing and
First-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX
evaluation framework for validating model performance. Extensive experiments
demonstrate that Omni-Effects achieves precise spatial control and diverse
effect generation, enabling users to specify both the category and location of
desired effects.

</details>


### [301] [Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition](https://arxiv.org/abs/2508.08004)
*Anqi Xiao,Weichen Yu,Hongyuan Yu*

Main category: cs.CV

Relevance: 30.0

TL;DR: SRA是一种无需搜索的自动数据增强方法，通过动态调整增强策略和启发式评分模块，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决主流AutoDA方法搜索耗时或性能不足的问题。

Method: 提出Sample-aware RandAugment (SRA)，结合启发式评分模块和非对称增强策略。

Result: 在ImageNet上达到78.31%的Top-1准确率，兼容性强且无需调参。

Conclusion: SRA为更简单、有效和实用的AutoDA设计提供了新方向。

Abstract: Automatic data augmentation (AutoDA) plays an important role in enhancing the
generalization of neural networks. However, mainstream AutoDA methods often
encounter two challenges: either the search process is excessively
time-consuming, hindering practical application, or the performance is
suboptimal due to insufficient policy adaptation during training. To address
these issues, we propose Sample-aware RandAugment (SRA), an asymmetric,
search-free AutoDA method that dynamically adjusts augmentation policies while
maintaining straightforward implementation. SRA incorporates a heuristic
scoring module that evaluates the complexity of the original training data,
enabling the application of tailored augmentations for each sample.
Additionally, an asymmetric augmentation strategy is employed to maximize the
potential of this scoring module. In multiple experimental settings, SRA
narrows the performance gap between search-based and search-free AutoDA
methods, achieving a state-of-the-art Top-1 accuracy of 78.31\% on ImageNet
with ResNet-50. Notably, SRA demonstrates good compatibility with existing
augmentation pipelines and solid generalization across new tasks, without
requiring hyperparameter tuning. The pretrained models leveraging SRA also
enhance recognition in downstream object detection tasks. SRA represents a
promising step towards simpler, more effective, and practical AutoDA designs
applicable to a variety of future tasks. Our code is available at
\href{https://github.com/ainieli/Sample-awareRandAugment}{https://github.com/ainieli/Sample-awareRandAugment

</details>


### [302] [Matrix-3D: Omnidirectional Explorable 3D World Generation](https://arxiv.org/abs/2508.08086)
*Zhongqi Yang,Wenhang Ge,Yuqi Li,Jiaqi Chen,Haoyuan Li,Mengyin An,Fei Kang,Hua Xue,Baixin Xu,Yuyang Yin,Eric Li,Yang Liu,Yikai Wang,Hao-Xiang Guo,Yahui Zhou*

Main category: cs.CV

Relevance: 30.0

TL;DR: Matrix-3D是一个利用全景表示生成可探索3D世界的框架，结合了条件视频生成和全景3D重建，通过两种方法提升3D场景重建质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D世界生成方法场景范围有限的问题，提出一种更广泛覆盖的全景3D生成方法。

Method: 1. 训练轨迹引导的全景视频扩散模型；2. 提出前馈式大范围全景重建模型和优化管道。

Result: 在全景视频生成和3D世界生成上达到最先进性能。

Conclusion: Matrix-3D框架在3D世界生成中表现优异，具有广泛的应用潜力。

Abstract: Explorable 3D world generation from a single image or text prompt forms a
cornerstone of spatial intelligence. Recent works utilize video model to
achieve wide-scope and generalizable 3D world generation. However, existing
approaches often suffer from a limited scope in the generated scenes. In this
work, we propose Matrix-3D, a framework that utilize panoramic representation
for wide-coverage omnidirectional explorable 3D world generation that combines
conditional video generation and panoramic 3D reconstruction. We first train a
trajectory-guided panoramic video diffusion model that employs scene mesh
renders as condition, to enable high-quality and geometrically consistent scene
video generation. To lift the panorama scene video to 3D world, we propose two
separate methods: (1) a feed-forward large panorama reconstruction model for
rapid 3D scene reconstruction and (2) an optimization-based pipeline for
accurate and detailed 3D scene reconstruction. To facilitate effective
training, we also introduce the Matrix-Pano dataset, the first large-scale
synthetic collection comprising 116K high-quality static panoramic video
sequences with depth and trajectory annotations. Extensive experiments
demonstrate that our proposed framework achieves state-of-the-art performance
in panoramic video generation and 3D world generation. See more in
https://matrix-3d.github.io.

</details>


### [303] [MDD-Net: Multimodal Depression Detection through Mutual Transformer](https://arxiv.org/abs/2508.08093)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于多模态数据的抑郁症检测网络（MDD-Net），利用声学和视觉数据，通过互变压器高效提取和融合特征，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 抑郁症严重影响身心健康，社交媒体数据易于收集，但如何有效利用这些数据进行心理健康研究是一个挑战。

Method: MDD-Net包含声学特征提取、视觉特征提取、互变压器融合多模态特征及检测层四个模块。

Result: 在D-Vlog数据集上实验显示，MDD-Net的F1-Score比现有方法高17.37%。

Conclusion: MDD-Net在多模态抑郁症检测中表现出色，验证了其有效性。

Abstract: Depression is a major mental health condition that severely impacts the
emotional and physical well-being of individuals. The simple nature of data
collection from social media platforms has attracted significant interest in
properly utilizing this information for mental health research. A Multimodal
Depression Detection Network (MDD-Net), utilizing acoustic and visual data
obtained from social media networks, is proposed in this work where mutual
transformers are exploited to efficiently extract and fuse multimodal features
for efficient depression detection. The MDD-Net consists of four core modules:
an acoustic feature extraction module for retrieving relevant acoustic
attributes, a visual feature extraction module for extracting significant
high-level patterns, a mutual transformer for computing the correlations among
the generated features and fusing these features from multiple modalities, and
a detection layer for detecting depression using the fused feature
representations. The extensive experiments are performed using the multimodal
D-Vlog dataset, and the findings reveal that the developed multimodal
depression detection network surpasses the state-of-the-art by up to 17.37% for
F1-Score, demonstrating the greater performance of the proposed system. The
source code is accessible at
https://github.com/rezwanh001/Multimodal-Depression-Detection.

</details>


### [304] [GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking](https://arxiv.org/abs/2508.08117)
*Xudong Han,Pengcheng Fang,Yueying Tian,Jianhui Yu,Xiaohao Cai,Daniel Roggen,Philip Birch*

Main category: cs.CV

Relevance: 30.0

TL;DR: GRASPTrack是一种新颖的深度感知多目标跟踪框架，通过结合单目深度估计和实例分割，生成3D点云以实现几何感知，提升了复杂场景下的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统跟踪方法因缺乏几何感知而难以应对遮挡和深度模糊的问题。

Method: 集成单目深度估计和实例分割，生成3D点云并基于体素的3D IoU进行空间关联；引入深度自适应噪声补偿和深度增强的动量方法。

Result: 在MOT17、MOT20和DanceTrack基准测试中表现出色，显著提升了复杂场景下的跟踪鲁棒性。

Conclusion: GRASPTrack通过几何感知和动态噪声补偿，有效解决了遮挡和深度模糊问题，提升了跟踪性能。

Abstract: Multi-object tracking (MOT) in monocular videos is fundamentally challenged
by occlusions and depth ambiguity, issues that conventional
tracking-by-detection (TBD) methods struggle to resolve owing to a lack of
geometric awareness. To address these limitations, we introduce GRASPTrack, a
novel depth-aware MOT framework that integrates monocular depth estimation and
instance segmentation into a standard TBD pipeline to generate high-fidelity 3D
point clouds from 2D detections, thereby enabling explicit 3D geometric
reasoning. These 3D point clouds are then voxelized to enable a precise and
robust Voxel-Based 3D Intersection-over-Union (IoU) for spatial association. To
further enhance tracking robustness, our approach incorporates Depth-aware
Adaptive Noise Compensation, which dynamically adjusts the Kalman filter
process noise based on occlusion severity for more reliable state estimation.
Additionally, we propose a Depth-enhanced Observation-Centric Momentum, which
extends the motion direction consistency from the image plane into 3D space to
improve motion-based association cues, particularly for objects with complex
trajectories. Extensive experiments on the MOT17, MOT20, and DanceTrack
benchmarks demonstrate that our method achieves competitive performance,
significantly improving tracking robustness in complex scenes with frequent
occlusions and intricate motion patterns.

</details>


### [305] [FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting](https://arxiv.org/abs/2508.08136)
*Yitong Yang,Yinglin Wang,Changshuo Wang,Huajie Wang,Shuting He*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于3D高斯散射（3DGS）的风格迁移框架FantasyStyle，通过扩散模型蒸馏解决多视角不一致性和VGG特征依赖问题。


<details>
  <summary>Details</summary>
Motivation: 当前3DGS风格迁移方法存在多视角不一致导致风格冲突和VGG特征难以分离内容与风格的问题，需要更高效的解决方案。

Method: 提出Multi-View Frequency Consistency增强视角一致性，Controllable Stylized Distillation利用负引导抑制内容泄漏，并优化扩散模型蒸馏。

Result: 实验表明FantasyStyle在风格迁移质量和视觉真实感上优于现有方法。

Conclusion: FantasyStyle通过扩散模型蒸馏和优化技术显著提升了3DGS风格迁移的效果。

Abstract: The success of 3DGS in generative and editing applications has sparked
growing interest in 3DGS-based style transfer. However, current methods still
face two major challenges: (1) multi-view inconsistency often leads to style
conflicts, resulting in appearance smoothing and distortion; and (2) heavy
reliance on VGG features, which struggle to disentangle style and content from
style images, often causing content leakage and excessive stylization. To
tackle these issues, we introduce \textbf{FantasyStyle}, a 3DGS-based style
transfer framework, and the first to rely entirely on diffusion model
distillation. It comprises two key components: (1) \textbf{Multi-View Frequency
Consistency}. We enhance cross-view consistency by applying a 3D filter to
multi-view noisy latent, selectively reducing low-frequency components to
mitigate stylized prior conflicts. (2) \textbf{Controllable Stylized
Distillation}. To suppress content leakage from style images, we introduce
negative guidance to exclude undesired content. In addition, we identify the
limitations of Score Distillation Sampling and Delta Denoising Score in 3D
style transfer and remove the reconstruction term accordingly. Building on
these insights, we propose a controllable stylized distillation that leverages
negative guidance to more effectively optimize the 3D Gaussians. Extensive
experiments demonstrate that our method consistently outperforms
state-of-the-art approaches, achieving higher stylization quality and visual
realism across various scenes and styles.

</details>


### [306] [3D Human Mesh Estimation from Single View RGBD](https://arxiv.org/abs/2508.08178)
*Ozhan Suat,Bedirhan Uguz,Batuhan Karagoz,Muhammed Can Keles,Emre Akbas*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种利用RGBD相机数据进行3D人体网格估计的方法M$^3$，通过模拟单视角深度数据并训练掩码自编码器补全网格，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: RGBD相机虽提供深度数据，但在3D人体网格估计中未充分利用。现有数据集小且多样性不足，需解决数据稀缺问题。

Method: 利用MoCap数据集生成单视角模拟深度数据，训练掩码自编码器补全网格。推理时匹配深度数据与模板网格。

Result: 在SURREAL、CAPE和BEHAVE数据集上表现优异，PVE分别为16.8 mm、22.0 mm和70.9 mm，优于现有方法。

Conclusion: M$^3$方法有效利用深度数据提升3D人体网格估计精度，适用于实际应用。

Abstract: Despite significant progress in 3D human mesh estimation from RGB images;
RGBD cameras, offering additional depth data, remain underutilized. In this
paper, we present a method for accurate 3D human mesh estimation from a single
RGBD view, leveraging the affordability and widespread adoption of RGBD cameras
for real-world applications. A fully supervised approach for this problem,
requires a dataset with RGBD image and 3D mesh label pairs. However, collecting
such a dataset is costly and challenging, hence, existing datasets are small,
and limited in pose and shape diversity. To overcome this data scarcity, we
leverage existing Motion Capture (MoCap) datasets. We first obtain complete 3D
meshes from the body models found in MoCap datasets, and create partial,
single-view versions of them by projection to a virtual camera. This simulates
the depth data provided by an RGBD camera from a single viewpoint. Then, we
train a masked autoencoder to complete the partial, single-view mesh. During
inference, our method, which we name as M$^3$ for ``Masked Mesh Modeling'',
matches the depth values coming from the sensor to vertices of a template human
mesh, which creates a partial, single-view mesh. We effectively recover parts
of the 3D human body mesh model that are not visible, resulting in a full body
mesh. M$^3$ achieves 16.8 mm and 22.0 mm per-vertex-error (PVE) on the SURREAL
and CAPE datasets, respectively; outperforming existing methods that use
full-body point clouds as input. We obtain a competitive 70.9 PVE on the BEHAVE
dataset, outperforming a recently published RGB based method by 18.4 mm,
highlighting the usefulness of depth data. Code will be released.

</details>


### [307] [KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning](https://arxiv.org/abs/2508.08186)
*Md Meftahul Ferdaus,Mahdi Abdelguerfi,Elias Ioup,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

Relevance: 30.0

TL;DR: KARMA是一种高效的语义分割框架，用于基础设施缺陷检测，通过低参数和高效计算实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 解决基础设施缺陷检测中因复杂外观、恶劣成像条件和类别不平衡导致的挑战，同时减少参数需求以实现实时应用。

Method: 采用Tiny Kolmogorov-Arnold Network (TiKAN)模块、优化的特征金字塔结构和静态-动态原型机制，减少参数并提升性能。

Result: KARMA在参数减少97%的情况下，性能与现有方法相当或更优，推理速度适合实时部署。

Conclusion: KARMA为基础设施缺陷检测提供了一种高效、实用的解决方案。

Abstract: Semantic segmentation of structural defects in civil infrastructure remains
challenging due to variable defect appearances, harsh imaging conditions, and
significant class imbalance. Current deep learning methods, despite their
effectiveness, typically require millions of parameters, rendering them
impractical for real-time inspection systems. We introduce KARMA
(Kolmogorov-Arnold Representation Mapping Architecture), a highly efficient
semantic segmentation framework that models complex defect patterns through
compositions of one-dimensional functions rather than conventional
convolutions. KARMA features three technical innovations: (1) a
parameter-efficient Tiny Kolmogorov-Arnold Network (TiKAN) module leveraging
low-rank factorization for KAN-based feature transformation; (2) an optimized
feature pyramid structure with separable convolutions for multi-scale defect
analysis; and (3) a static-dynamic prototype mechanism that enhances feature
representation for imbalanced classes. Extensive experiments on benchmark
infrastructure inspection datasets demonstrate that KARMA achieves competitive
or superior mean IoU performance compared to state-of-the-art approaches, while
using significantly fewer parameters (0.959M vs. 31.04M, a 97% reduction).
Operating at 0.264 GFLOPS, KARMA maintains inference speeds suitable for
real-time deployment, enabling practical automated infrastructure inspection
systems without compromising accuracy. The source code can be accessed at the
following URL: https://github.com/faeyelab/karma.

</details>


### [308] [SAGOnline: Segment Any Gaussians Online](https://arxiv.org/abs/2508.08219)
*Wentao Sun,Quanyun Wu,Hanqing Xu,Kyle Gao,Zhengsen Xu,Yiping Chen,Dedong Zhang,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

Relevance: 30.0

TL;DR: SAGOnline是一个轻量级、零样本的实时3D分割框架，通过视频基础模型和GPU加速算法实现高效的多目标跟踪与分割。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D高斯场景分割方法计算成本高、空间推理能力有限及无法同时跟踪多目标的问题。

Method: 结合视频基础模型（如SAM2）进行2D掩码传播，并采用GPU加速的3D掩码生成与高斯级实例标记算法。

Result: 在NVOS和Spin-NeRF基准测试中表现优异（92.7%和95.2% mIoU），推理速度提升15-1500倍（27 ms/帧）。

Conclusion: SAGOnline为实时3D场景理解提供了高效解决方案，适用于AR/VR和机器人应用。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful paradigm for explicit
3D scene representation, yet achieving efficient and consistent 3D segmentation
remains challenging. Current methods suffer from prohibitive computational
costs, limited 3D spatial reasoning, and an inability to track multiple objects
simultaneously. We present Segment Any Gaussians Online (SAGOnline), a
lightweight and zero-shot framework for real-time 3D segmentation in Gaussian
scenes that addresses these limitations through two key innovations: (1) a
decoupled strategy that integrates video foundation models (e.g., SAM2) for
view-consistent 2D mask propagation across synthesized views; and (2) a
GPU-accelerated 3D mask generation and Gaussian-level instance labeling
algorithm that assigns unique identifiers to 3D primitives, enabling lossless
multi-object tracking and segmentation across views. SAGOnline achieves
state-of-the-art performance on NVOS (92.7% mIoU) and Spin-NeRF (95.2% mIoU)
benchmarks, outperforming Feature3DGS, OmniSeg3D-gs, and SA3D by 15--1500 times
in inference speed (27 ms/frame). Qualitative results demonstrate robust
multi-object segmentation and tracking in complex scenes. Our contributions
include: (i) a lightweight and zero-shot framework for 3D segmentation in
Gaussian scenes, (ii) explicit labeling of Gaussian primitives enabling
simultaneous segmentation and tracking, and (iii) the effective adaptation of
2D video foundation models to the 3D domain. This work allows real-time
rendering and 3D scene understanding, paving the way for practical AR/VR and
robotic applications.

</details>


### [309] [Fading the Digital Ink: A Universal Black-Box Attack Framework for 3DGS Watermarking Systems](https://arxiv.org/abs/2508.07263)
*Qingyuan Zeng,Shu Jiang,Jiajing Lin,Zhenzhong Wang,Kay Chen Tan,Min Jiang*

Main category: cs.CR

Relevance: 30.0

TL;DR: 该论文提出了首个针对3D高斯泼溅（3DGS）水印技术的通用黑盒攻击框架GMEA，通过多目标优化平衡水印去除与视觉质量，揭示了现有水印系统的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 随着3DGS的兴起，数字水印技术用于版权保护，但其对抗攻击的鲁棒性尚未充分研究。

Method: 提出GMEA框架，将攻击建模为大规模多目标优化问题，采用分组优化策略处理3DGS模型的大搜索空间。

Result: 实验表明GMEA能有效去除主流3DGS水印方法中的1D和2D水印，同时保持高视觉保真度。

Conclusion: 揭示了现有3DGS版权保护方案的关键漏洞，呼吁开发更鲁棒的水印系统。

Abstract: With the rise of 3D Gaussian Splatting (3DGS), a variety of digital
watermarking techniques, embedding either 1D bitstreams or 2D images, are used
for copyright protection. However, the robustness of these watermarking
techniques against potential attacks remains underexplored. This paper
introduces the first universal black-box attack framework, the Group-based
Multi-objective Evolutionary Attack (GMEA), designed to challenge these
watermarking systems. We formulate the attack as a large-scale multi-objective
optimization problem, balancing watermark removal with visual quality. In a
black-box setting, we introduce an indirect objective function that blinds the
watermark detector by minimizing the standard deviation of features extracted
by a convolutional network, thus rendering the feature maps uninformative. To
manage the vast search space of 3DGS models, we employ a group-based
optimization strategy to partition the model into multiple, independent
sub-optimization problems. Experiments demonstrate that our framework
effectively removes both 1D and 2D watermarks from mainstream 3DGS watermarking
methods while maintaining high visual fidelity. This work reveals critical
vulnerabilities in existing 3DGS copyright protection schemes and calls for the
development of more robust watermarking systems.

</details>


### [310] [Progressive Bird's Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey](https://arxiv.org/abs/2508.07560)
*Yan Gong,Naibang Wang,Jianli Lu,Xinyu Zhang,Yongsheng Gao,Jie Zhao,Zifan Huang,Haozhi Bai,Nanxin Zeng,Nayu Su,Lei Yang,Ziying Song,Xiaoxi Hu,Xinmin Jiang,Xiaojuan Zhang,Susanto Rahardja*

Main category: cs.RO

Relevance: 30.0

TL;DR: 该论文首次从安全关键视角全面综述了BEV感知技术，分析了单模态、多模态及多智能体协作感知的框架与策略，并探讨了公开数据集及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶从受控环境转向实际部署，确保BEV感知在复杂场景中的安全性和可靠性成为关键挑战。

Method: 系统分析了BEV感知的三个阶段：单模态车载、多模态车载及多智能体协作感知，并评估了相关数据集。

Result: 总结了BEV感知的现状，并识别了开放世界中的关键挑战，如开放集识别、传感器退化等。

Conclusion: 提出了未来研究方向，包括与端到端自动驾驶系统、具身智能和大语言模型的结合。

Abstract: Bird's-Eye-View (BEV) perception has become a foundational paradigm in
autonomous driving, enabling unified spatial representations that support
robust multi-sensor fusion and multi-agent collaboration. As autonomous
vehicles transition from controlled environments to real-world deployment,
ensuring the safety and reliability of BEV perception in complex scenarios -
such as occlusions, adverse weather, and dynamic traffic - remains a critical
challenge. This survey provides the first comprehensive review of BEV
perception from a safety-critical perspective, systematically analyzing
state-of-the-art frameworks and implementation strategies across three
progressive stages: single-modality vehicle-side, multimodal vehicle-side, and
multi-agent collaborative perception. Furthermore, we examine public datasets
encompassing vehicle-side, roadside, and collaborative settings, evaluating
their relevance to safety and robustness. We also identify key open-world
challenges - including open-set recognition, large-scale unlabeled data, sensor
degradation, and inter-agent communication latency - and outline future
research directions, such as integration with end-to-end autonomous driving
systems, embodied intelligence, and large language models.

</details>


### [311] [MSPT: A Lightweight Face Image Quality Assessment Method with Multi-stage Progressive Training](https://arxiv.org/abs/2508.07590)
*Xiongwei Xiao,Baoying Chen,Jishen Zeng,Jianquan Yang*

Main category: cs.MM

Relevance: 30.0

TL;DR: 提出了一种轻量级人脸质量评估网络MSPT，通过多阶段渐进训练策略，在保持高效推理的同时达到高性能。


<details>
  <summary>Details</summary>
Motivation: 传统人脸质量评估方法泛化性差，学习型方法虽性能优越但计算和存储成本高，难以实际部署。

Method: 采用三阶段渐进训练策略，逐步引入多样化数据样本并提高输入图像分辨率。

Result: 在VQualA 2025基准测试中排名第二，性能与最先进方法相当或更好。

Conclusion: MSPT在轻量级网络中有效学习复杂质量特征，同时显著减轻灾难性遗忘。

Abstract: Accurately assessing the perceptual quality of face images is crucial,
especially with the rapid progress in face restoration and generation.
Traditional quality assessment methods often struggle with the unique
characteristics of face images, limiting their generalizability. While
learning-based approaches demonstrate superior performance due to their strong
fitting capabilities, their high complexity typically incurs significant
computational and storage costs, hindering practical deployment. To address
this, we propose a lightweight face quality assessment network with Multi-Stage
Progressive Training (MSPT). Our network employs a three-stage progressive
training strategy that gradually introduces more diverse data samples and
increases input image resolution. This novel approach enables lightweight
networks to achieve high performance by effectively learning complex quality
features while significantly mitigating catastrophic forgetting. Our MSPT
achieved the second highest score on the VQualA 2025 face image quality
assessment benchmark dataset, demonstrating that MSPT achieves comparable or
better performance than state-of-the-art methods while maintaining efficient
inference.

</details>


### [312] [Sea-Undistort: A Dataset for Through-Water Image Restoration in High Resolution Airborne Bathymetric Mapping](https://arxiv.org/abs/2508.07760)
*Maximilian Kromer,Panagiotis Agrafiotis,Begüm Demir*

Main category: eess.IV

Relevance: 30.0

TL;DR: 论文提出了Sea-Undistort数据集，用于解决浅水区图像测深中的光学失真问题，并评估了两种图像恢复方法和一种改进的扩散模型。


<details>
  <summary>Details</summary>
Motivation: 浅水区图像测深因水面动态、水柱特性和太阳光照导致的光学失真（如波浪、散射和太阳耀斑）而具有挑战性。

Method: 使用Blender渲染了1200对512x512的图像（无失真和失真视图），并提供了每张图像的元数据。评估了两种现有方法和一种改进的扩散模型。

Result: 改进的扩散模型在真实航空数据中表现更优，能更完整地恢复海底数字表面模型（DSM），减少测深误差，抑制耀斑和散射，并恢复细节。

Conclusion: Sea-Undistort数据集为浅水区图像测深提供了有效的训练和评估工具，改进的扩散模型显著提升了性能。

Abstract: Accurate image-based bathymetric mapping in shallow waters remains
challenging due to the complex optical distortions such as wave induced
patterns, scattering and sunglint, introduced by the dynamic water surface, the
water column properties, and solar illumination. In this work, we introduce
Sea-Undistort, a comprehensive synthetic dataset of 1200 paired 512x512
through-water scenes rendered in Blender. Each pair comprises a distortion-free
and a distorted view, featuring realistic water effects such as sun glint,
waves, and scattering over diverse seabeds. Accompanied by per-image metadata
such as camera parameters, sun position, and average depth, Sea-Undistort
enables supervised training that is otherwise infeasible in real environments.
We use Sea-Undistort to benchmark two state-of-the-art image restoration
methods alongside an enhanced lightweight diffusion-based framework with an
early-fusion sun-glint mask. When applied to real aerial data, the enhanced
diffusion model delivers more complete Digital Surface Models (DSMs) of the
seabed, especially in deeper areas, reduces bathymetric errors, suppresses
glint and scattering, and crisply restores fine seabed details. Dataset,
weights, and code are publicly available at
https://www.magicbathy.eu/Sea-Undistort.html.

</details>


### [313] [Learned Regularization for Microwave Tomography](https://arxiv.org/abs/2508.08114)
*Bowen Tong,Hao Chen,Shaorui Guo,Dong Liu*

Main category: eess.IV

Relevance: 30.0

TL;DR: 提出了一种基于扩散模型的物理信息混合框架（SSD-Reg），用于微波断层扫描中的逆问题求解，无需配对数据即可恢复复杂结构。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法难以恢复精细结构，深度学习需要大量配对数据且泛化能力有限。

Method: 结合扩散模型作为学习正则化，嵌入迭代重建过程（SSD-Reg）。

Result: SSD-Reg提高了重建的准确性、稳定性和鲁棒性。

Conclusion: SSD-Reg为功能图像重建中的不适定问题提供了灵活有效的解决方案。

Abstract: Microwave Tomography (MWT) aims to reconstruct the dielectric properties of
tissues from measured scattered electromagnetic fields. This inverse problem is
highly nonlinear and ill-posed, posing significant challenges for conventional
optimization-based methods, which, despite being grounded in physical models,
often fail to recover fine structural details. Recent deep learning strategies,
including end-to-end and post-processing networks, have improved reconstruction
quality but typically require large paired training datasets and may struggle
to generalize. To overcome these limitations, we propose a physics-informed
hybrid framework that integrates diffusion models as learned regularization
within a data-consistency-driven variational scheme. Specifically, we introduce
Single-Step Diffusion Regularization (SSD-Reg), a novel approach that embeds
diffusion priors into the iterative reconstruction process, enabling the
recovery of complex anatomical structures without the need for paired data.
SSD-Reg maintains fidelity to both the governing physics and learned structural
distributions, improving accuracy, stability, and robustness. Extensive
experiments demonstrate that SSD-Reg, implemented as a Plug-and-Play (PnP)
module, provides a flexible and effective solution for tackling the
ill-posedness inherent in functional image reconstruction.

</details>


### [314] [Transfer Learning with EfficientNet for Accurate Leukemia Cell Classification](https://arxiv.org/abs/2508.06535)
*Faisal Ahmed*

Main category: eess.IV

Relevance: 20.0

TL;DR: 该论文研究了使用预训练的卷积神经网络（CNN）进行迁移学习，以提高急性淋巴细胞白血病（ALL）的分类准确性。通过数据增强技术平衡数据集，并评估了多种模型，其中EfficientNet-B3表现最佳。


<details>
  <summary>Details</summary>
Motivation: 提高ALL的早期诊断准确性，为治疗规划提供支持。

Method: 使用迁移学习和数据增强技术，评估了ResNet50、ResNet101和EfficientNet等模型。

Result: EfficientNet-B3表现最佳，F1分数为94.30%，准确率为92.02%，AUC为94.79%。

Conclusion: 结合数据增强和迁移学习（尤其是EfficientNet-B3）可有效开发ALL诊断工具。

Abstract: Accurate classification of Acute Lymphoblastic Leukemia (ALL) from peripheral
blood smear images is essential for early diagnosis and effective treatment
planning. This study investigates the use of transfer learning with pretrained
convolutional neural networks (CNNs) to improve diagnostic performance. To
address the class imbalance in the dataset of 3,631 Hematologic and 7,644 ALL
images, we applied extensive data augmentation techniques to create a balanced
training set of 10,000 images per class. We evaluated several models, including
ResNet50, ResNet101, and EfficientNet variants B0, B1, and B3. EfficientNet-B3
achieved the best results, with an F1-score of 94.30%, accuracy of 92.02%,
andAUCof94.79%,outperformingpreviouslyreported methods in the C-NMCChallenge.
Thesefindings demonstrate the effectiveness of combining data augmentation with
advanced transfer learning models, particularly EfficientNet-B3, in developing
accurate and robust diagnostic tools for hematologic malignancy detection.

</details>


### [315] [Statistical Confidence Rescoring for Robust 3D Scene Graph Generation from Multi-View Images](https://arxiv.org/abs/2508.06546)
*Qi Xun Yeo,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种仅使用多视角RGB图像进行3D语义场景图估计的方法，通过语义掩码和邻域信息增强特征，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在缺乏3D标注的情况下，利用多视角RGB图像实现准确的3D语义场景图估计。

Method: 利用语义掩码过滤背景噪声，设计邻域节点信息融合方法，并结合统计先验优化预测。

Result: 实验表明，该方法在仅使用多视角图像输入时优于现有方法。

Conclusion: 通过语义和空间信息增强特征，结合邻域统计先验，显著提升了场景图估计的准确性。

Abstract: Modern 3D semantic scene graph estimation methods utilize ground truth 3D
annotations to accurately predict target objects, predicates, and
relationships. In the absence of given 3D ground truth representations, we
explore leveraging only multi-view RGB images to tackle this task. To attain
robust features for accurate scene graph estimation, we must overcome the noisy
reconstructed pseudo point-based geometry from predicted depth maps and reduce
the amount of background noise present in multi-view image features. The key is
to enrich node and edge features with accurate semantic and spatial information
and through neighboring relations. We obtain semantic masks to guide feature
aggregation to filter background features and design a novel method to
incorporate neighboring node information to aid robustness of our scene graph
estimates. Furthermore, we leverage on explicit statistical priors calculated
from the training summary statistics to refine node and edge predictions based
on their one-hop neighborhood. Our experiments show that our method outperforms
current methods purely using multi-view images as the initial input. Our
project page is available at https://qixun1.github.io/projects/SCRSSG.

</details>


### [316] [CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition](https://arxiv.org/abs/2508.06632)
*Wenpeng Xing,Jie Chen,Zaifeng Yang,Tiancheng Zhao,Gaolei Li,Changting Lin,Yike Guo,Meng Han*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出了一种基于动态系数分解的神经渲染框架，用于改进复杂视依赖外观的建模，特别是在处理镜面反射和高光时表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂镜面反射和高光时可能产生模糊反射或优化不稳定，因此需要一种更灵活的建模方法。

Method: 通过动态系数分解，将复杂外观分解为共享的静态神经基和由系数网络生成的动态系数，再通过动态辐射积分器合成最终辐射。

Result: 在多个挑战性基准测试中，该方法能够生成比现有技术更锐利和逼真的镜面高光。

Conclusion: 这种分解范式为神经场景表示中复杂外观的建模提供了灵活有效的方向。

Abstract: Neural Radiance Fields (NeRF) have shown impressive performance in novel view
synthesis, but challenges remain in rendering scenes with complex specular
reflections and highlights. Existing approaches may produce blurry reflections
due to entanglement between lighting and material properties, or encounter
optimization instability when relying on physically-based inverse rendering. In
this work, we present a neural rendering framework based on dynamic coefficient
decomposition, aiming to improve the modeling of view-dependent appearance. Our
approach decomposes complex appearance into a shared, static neural basis that
encodes intrinsic material properties, and a set of dynamic coefficients
generated by a Coefficient Network conditioned on view and illumination. A
Dynamic Radiance Integrator then combines these components to synthesize the
final radiance. Experimental results on several challenging benchmarks suggest
that our method can produce sharper and more realistic specular highlights
compared to existing techniques. We hope that this decomposition paradigm can
provide a flexible and effective direction for modeling complex appearance in
neural scene representations.

</details>


### [317] [Fourier Optics and Deep Learning Methods for Fast 3D Reconstruction in Digital Holography](https://arxiv.org/abs/2508.06703)
*Justin London*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种高效快速的计算机生成全息图（CGH）合成框架，基于点云和MRI数据，通过非凸傅里叶光学优化算法生成相位全息图（POH）和复全息图（CH），并比较了其与深度学习方法的性能。


<details>
  <summary>Details</summary>
Motivation: 计算机生成全息图（CGH）是一种有前景的技术，但现有方法在效率和性能上存在不足，需要优化算法和去噪方法来提升质量。

Method: 使用点云和MRI数据重建体积对象，通过交替投影、随机梯度下降（SGD）和拟牛顿方法优化生成POH和CH，并与深度学习方法HoloNet进行比较。

Result: 优化算法在MSE、RMSE和PSNR指标上表现优于深度学习方法，且通过2D中值滤波进一步提升了性能。

Conclusion: 提出的框架在CGH生成中表现出高效性和性能优势，为实际应用提供了可行方案。

Abstract: Computer-generated holography (CGH) is a promising method that modulates
user-defined waveforms with digital holograms. An efficient and fast pipeline
framework is proposed to synthesize CGH using initial point cloud and MRI data.
This input data is reconstructed into volumetric objects that are then input
into non-convex Fourier optics optimization algorithms for phase-only hologram
(POH) and complex-hologram (CH) generation using alternating projection, SGD,
and quasi-Netwton methods. Comparison of reconstruction performance of these
algorithms as measured by MSE, RMSE, and PSNR is analyzed as well as to HoloNet
deep learning CGH. Performance metrics are shown to be improved by using 2D
median filtering to remove artifacts and speckled noise during optimization.

</details>


### [318] [Hybrid Machine Learning Framework for Predicting Geometric Deviations from 3D Surface Metrology](https://arxiv.org/abs/2508.06845)
*Hamidreza Samadi,Md Manjurul Ahsan,Shivakumar Raman*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种结合3D扫描和混合机器学习框架的方法，用于预测制造组件的几何偏差，显著提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现代制造中复杂几何形状的尺寸精度难以保持，需要更准确的预测方法。

Method: 使用高分辨率3D扫描仪采集多角度表面数据，结合卷积神经网络和梯度提升决策树进行预测建模。

Result: 预测精度达到0.012 mm（95%置信水平），比传统方法提升73%，并揭示了制造参数与几何偏差的隐藏关联。

Conclusion: 该方法为自动化质量控制、预测性维护和设计优化提供了潜力，数据集对未来研究有重要价值。

Abstract: This study addresses the challenge of accurately forecasting geometric
deviations in manufactured components using advanced 3D surface analysis.
Despite progress in modern manufacturing, maintaining dimensional precision
remains difficult, particularly for complex geometries. We present a
methodology that employs a high-resolution 3D scanner to acquire multi-angle
surface data from 237 components produced across different batches. The data
were processed through precise alignment, noise reduction, and merging
techniques to generate accurate 3D representations. A hybrid machine learning
framework was developed, combining convolutional neural networks for feature
extraction with gradient-boosted decision trees for predictive modeling. The
proposed system achieved a prediction accuracy of 0.012 mm at a 95% confidence
level, representing a 73% improvement over conventional statistical process
control methods. In addition to improved accuracy, the model revealed hidden
correlations between manufacturing parameters and geometric deviations. This
approach offers significant potential for automated quality control, predictive
maintenance, and design optimization in precision manufacturing, and the
resulting dataset provides a strong foundation for future predictive modeling
research.

</details>


### [319] [A Joint Sparse Self-Representation Learning Method for Multiview Clustering](https://arxiv.org/abs/2508.06857)
*Mengxue Jia,Zhihua Allen-Zhao,You Zhao,Sanyang Liu*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种基于联合稀疏自表示学习的多视图聚类方法，通过引入基数约束替代图拉普拉斯正则化，提取视图特定的局部信息，并结合低秩约束揭示全局结构。为解决非凸非光滑模型的收敛问题，开发了具有全局收敛性的交替二次惩罚方法。


<details>
  <summary>Details</summary>
Motivation: 多视图聚类（MC）旨在利用多视图的一致性和互补信息进行样本分组，子空间聚类作为其基础技术受到广泛关注。现有方法在提取局部信息和保证模型收敛性方面存在不足，因此需要一种更有效的方法。

Method: 提出联合稀疏自表示学习模型，引入基数（ℓ0-范数）约束提取视图特定局部信息，低秩约束揭示全局结构。为解决非凸非光滑模型的收敛问题，开发交替二次惩罚（AQP）方法。

Result: 在六个标准数据集上的实验表明，所提模型和AQP方法优于八种最先进算法。

Conclusion: 该方法通过基数约束和低秩约束有效提取多视图的局部和全局结构信息，AQP方法解决了收敛性问题，提升了泛化能力。

Abstract: Multiview clustering (MC) aims to group samples using consistent and
complementary information across various views. The subspace clustering, as a
fundamental technique of MC, has attracted significant attention. In this
paper, we propose a novel joint sparse self-representation learning model for
MC, where a featured difference is the extraction of view-specific local
information by introducing cardinality (i.e., $\ell_0$-norm) constraints
instead of Graph-Laplacian regularization. Specifically, under each view,
cardinality constraints directly restrict the samples used in the
self-representation stage to extract reliable local and global structure
information, while the low-rank constraint aids in revealing a global coherent
structure in the consensus affinity matrix during merging. The attendant
challenge is that Augmented Lagrange Method (ALM)-based alternating
minimization algorithms cannot guarantee convergence when applied directly to
our nonconvex, nonsmooth model, thus resulting in poor generalization ability.
To address it, we develop an alternating quadratic penalty (AQP) method with
global convergence, where two subproblems are iteratively solved by closed-form
solutions. Empirical results on six standard datasets demonstrate the
superiority of our model and AQP method, compared to eight state-of-the-art
algorithms.

</details>


### [320] [LWT-ARTERY-LABEL: A Lightweight Framework for Automated Coronary Artery Identification](https://arxiv.org/abs/2508.06874)
*Shisheng Zhang,Ramtin Gharleghi,Sonit Singh,Daniel Moses,Dona Adikari,Arcot Sowmya,Susann Beier*

Main category: eess.IV

Relevance: 20.0

TL;DR: 提出了一种轻量级方法，结合解剖学知识和基于规则的拓扑约束，用于冠状动脉自动标记，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉疾病诊断中，CTCA分析耗时且劳动密集，现有方法（知识驱动或深度学习）各有不足，需更高效解决方案。

Method: 集成解剖学知识与基于规则的拓扑约束，设计轻量级方法进行冠状动脉自动标记。

Result: 在基准数据集上达到最先进性能。

Conclusion: 该方法为冠状动脉自动标记提供了高效替代方案。

Abstract: Coronary artery disease (CAD) remains the leading cause of death globally,
with computed tomography coronary angiography (CTCA) serving as a key
diagnostic tool. However, coronary arterial analysis using CTCA, such as
identifying artery-specific features from computational modelling, is
labour-intensive and time-consuming. Automated anatomical labelling of coronary
arteries offers a potential solution, yet the inherent anatomical variability
of coronary trees presents a significant challenge. Traditional knowledge-based
labelling methods fall short in leveraging data-driven insights, while recent
deep-learning approaches often demand substantial computational resources and
overlook critical clinical knowledge. To address these limitations, we propose
a lightweight method that integrates anatomical knowledge with rule-based
topology constraints for effective coronary artery labelling. Our approach
achieves state-of-the-art performance on benchmark datasets, providing a
promising alternative for automated coronary artery labelling.

</details>


### [321] [TADoc: Robust Time-Aware Document Image Dewarping](https://arxiv.org/abs/2508.06988)
*Fangmin Zhao,Weichao Zeng,Zhenhang Li,Dongbao Yang,Yu Zhou*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种动态建模文档图像去扭曲任务的方法，并设计了轻量级框架TADoc，同时提出了新的评估指标DLS。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂文档结构和高度变形时效果不佳，作者认为去扭曲是一个渐进过程而非一步变换。

Method: 将任务重新建模为动态过程，设计TADoc框架，并提出DLS评估指标。

Result: 实验表明TADoc在多种文档类型和变形程度下表现优越。

Conclusion: 动态建模和TADoc框架显著提升了文档去扭曲的效果，DLS指标补充了现有评估的不足。

Abstract: Flattening curved, wrinkled, and rotated document images captured by portable
photographing devices, termed document image dewarping, has become an
increasingly important task with the rise of digital economy and online
working. Although many methods have been proposed recently, they often struggle
to achieve satisfactory results when confronted with intricate document
structures and higher degrees of deformation in real-world scenarios. Our main
insight is that, unlike other document restoration tasks (e.g., deblurring),
dewarping in real physical scenes is a progressive motion rather than a
one-step transformation. Based on this, we have undertaken two key initiatives.
Firstly, we reformulate this task, modeling it for the first time as a dynamic
process that encompasses a series of intermediate states. Secondly, we design a
lightweight framework called TADoc (Time-Aware Document Dewarping Network) to
address the geometric distortion of document images. In addition, due to the
inadequacy of OCR metrics for document images containing sparse text, the
comprehensiveness of evaluation is insufficient. To address this shortcoming,
we propose a new metric -- DLS (Document Layout Similarity) -- to evaluate the
effectiveness of document dewarping in downstream tasks. Extensive experiments
and in-depth evaluations have been conducted and the results indicate that our
model possesses strong robustness, achieving superiority on several benchmarks
with different document types and degrees of distortion.

</details>


### [322] [SAGCNet: Spatial-Aware Graph Completion Network for Missing Slice Imputation in Population CMR Imaging](https://arxiv.org/abs/2508.07041)
*Junkai Liu,Nay Aung,Theodoros N. Arvanitis,Stefan K. Piechnik,Joao A C Lima,Steffen E. Petersen,Le Zhang*

Main category: eess.IV

Relevance: 20.0

TL;DR: 论文提出了一种用于MRI缺失切片合成的空间感知图补全网络（SAGCNet），通过图结构和3D空间适配器解决局部和全局依赖性问题。


<details>
  <summary>Details</summary>
Motivation: MRI数据中缺失或不可用的切片影响诊断准确性，现有方法难以建模3D数据的局部和全局依赖关系。

Method: SAGCNet结合了切片图补全模块和3D空间适配器，以捕获和利用3D空间上下文信息。

Result: 在心脏MRI数据集上，SAGCNet在定量和定性上均优于现有方法，且在数据有限时表现优异。

Conclusion: SAGCNet有效解决了MRI缺失切片合成问题，具有实际应用潜力。

Abstract: Magnetic resonance imaging (MRI) provides detailed soft-tissue
characteristics that assist in disease diagnosis and screening. However, the
accuracy of clinical practice is often hindered by missing or unusable slices
due to various factors. Volumetric MRI synthesis methods have been developed to
address this issue by imputing missing slices from available ones. The inherent
3D nature of volumetric MRI data, such as cardiac magnetic resonance (CMR),
poses significant challenges for missing slice imputation approaches, including
(1) the difficulty of modeling local inter-slice correlations and dependencies
of volumetric slices, and (2) the limited exploration of crucial 3D spatial
information and global context. In this study, to mitigate these issues, we
present Spatial-Aware Graph Completion Network (SAGCNet) to overcome the
dependency on complete volumetric data, featuring two main innovations: (1) a
volumetric slice graph completion module that incorporates the inter-slice
relationships into a graph structure, and (2) a volumetric spatial adapter
component that enables our model to effectively capture and utilize various
forms of 3D spatial context. Extensive experiments on cardiac MRI datasets
demonstrate that SAGCNet is capable of synthesizing absent CMR slices,
outperforming competitive state-of-the-art MRI synthesis methods both
quantitatively and qualitatively. Notably, our model maintains superior
performance even with limited slice data.

</details>


### [323] [CMAMRNet: A Contextual Mask-Aware Network Enhancing Mural Restoration Through Comprehensive Mask Guidance](https://arxiv.org/abs/2508.07140)
*Yingtie Lei,Fanghai Yi,Yihang Dong,Weihuang Liu,Xiaofeng Zhang,Zimeng Li,Chi-Man Pun,Xuhang Chen*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种名为CMAMRNet的壁画修复网络，通过多尺度特征提取和掩码感知技术，解决了现有方法在修复质量和艺术真实性上的不足。


<details>
  <summary>Details</summary>
Motivation: 壁画作为文化遗产易受环境与人为破坏，现有修复方法难以保持修复区域的连贯性和艺术真实性。

Method: 提出CMAMRNet网络，包含掩码感知上下采样器（MAUDS）和共特征聚合器（CFA），实现多尺度特征提取和掩码引导修复。

Result: 在基准数据集上，CMAMRNet优于现有方法，能有效保留壁画的结构和艺术细节。

Conclusion: CMAMRNet为壁画修复提供了高效解决方案，兼顾修复质量和艺术真实性。

Abstract: Murals, as invaluable cultural artifacts, face continuous deterioration from
environmental factors and human activities. Digital restoration of murals faces
unique challenges due to their complex degradation patterns and the critical
need to preserve artistic authenticity. Existing learning-based methods
struggle with maintaining consistent mask guidance throughout their networks,
leading to insufficient focus on damaged regions and compromised restoration
quality. We propose CMAMRNet, a Contextual Mask-Aware Mural Restoration Network
that addresses these limitations through comprehensive mask guidance and
multi-scale feature extraction. Our framework introduces two key components:
(1) the Mask-Aware Up/Down-Sampler (MAUDS), which ensures consistent mask
sensitivity across resolution scales through dedicated channel-wise feature
selection and mask-guided feature fusion; and (2) the Co-Feature Aggregator
(CFA), operating at both the highest and lowest resolutions to extract
complementary features for capturing fine textures and global structures in
degraded regions. Experimental results on benchmark datasets demonstrate that
CMAMRNet outperforms state-of-the-art methods, effectively preserving both
structural integrity and artistic details in restored murals. The code is
available
at~\href{https://github.com/CXH-Research/CMAMRNet}{https://github.com/CXH-Research/CMAMRNet}.

</details>


### [324] [SketchAnimator: Animate Sketch via Motion Customization of Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.07149)
*Ruolin Yang,Da Li,Honggang Zhang,Yi-Zhe Song*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出了一种名为SketchAnimator的草图动画模型，通过三个阶段（外观学习、运动学习和视频先验蒸馏）将静态草图转化为动态视频，保留原始外观并模仿参考视频的运动。


<details>
  <summary>Details</summary>
Motivation: 草图动画通常需要专业技能和时间，对业余用户不友好。本文旨在简化这一过程，使非专业人士也能轻松为草图添加动态效果。

Method: 分为三个阶段：1) 外观学习，2) 运动学习（使用LoRA整合预训练T2V模型），3) 视频先验蒸馏（使用SDS更新Bezier曲线参数）。

Result: 模型能够生成保留草图外观并模仿参考视频动态的视频，在单次运动定制任务中表现优于其他方法。

Conclusion: SketchAnimator为草图动画提供了一种高效且用户友好的解决方案。

Abstract: Sketching is a uniquely human tool for expressing ideas and creativity. The
animation of sketches infuses life into these static drawings, opening a new
dimension for designers. Animating sketches is a time-consuming process that
demands professional skills and extensive experience, often proving daunting
for amateurs. In this paper, we propose a novel sketch animation model
SketchAnimator, which enables adding creative motion to a given sketch, like "a
jumping car''. Namely, given an input sketch and a reference video, we divide
the sketch animation into three stages: Appearance Learning, Motion Learning
and Video Prior Distillation. In stages 1 and 2, we utilize LoRA to integrate
sketch appearance information and motion dynamics from the reference video into
the pre-trained T2V model. In the third stage, we utilize Score Distillation
Sampling (SDS) to update the parameters of the Bezier curves in each sketch
frame according to the acquired motion information. Consequently, our model
produces a sketch video that not only retains the original appearance of the
sketch but also mirrors the dynamic movements of the reference video. We
compare our method with alternative approaches and demonstrate that it
generates the desired sketch video under the challenge of one-shot motion
customization.

</details>


### [325] [DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery](https://arxiv.org/abs/2508.07372)
*Rajaei Khatib,Raja Giryes*

Main category: cs.CV

Relevance: 20.0

TL;DR: DIP-GS是一种基于深度图像先验（DIP）的3D高斯泼溅（3DGS）方法，解决了稀疏视图重建问题，无需预训练模型，取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 3DGS在多视图场景下表现优异，但在稀疏视图重建中表现不佳。本文旨在通过DIP先验改进3DGS，提升其在稀疏视图场景下的性能。

Method: 提出DIP-GS，结合DIP先验和3DGS，采用由粗到精的方式学习场景表示，仅依赖输入帧，无需预训练模型。

Result: DIP-GS在稀疏视图重建任务中取得了SOTA性能，展示了其有效性。

Conclusion: DIP-GS通过DIP先验显著提升了3DGS在稀疏视图场景下的性能，且无需外部预训练模型。

Abstract: 3D Gaussian Splatting (3DGS) is a leading 3D scene reconstruction method,
obtaining high-quality reconstruction with real-time rendering runtime
performance. The main idea behind 3DGS is to represent the scene as a
collection of 3D gaussians, while learning their parameters to fit the given
views of the scene. While achieving superior performance in the presence of
many views, 3DGS struggles with sparse view reconstruction, where the input
views are sparse and do not fully cover the scene and have low overlaps. In
this paper, we propose DIP-GS, a Deep Image Prior (DIP) 3DGS representation. By
using the DIP prior, which utilizes internal structure and patterns, with
coarse-to-fine manner, DIP-based 3DGS can operate in scenarios where vanilla
3DGS fails, such as sparse view recovery. Note that our approach does not use
any pre-trained models such as generative models and depth estimation, but
rather relies only on the input frames. Among such methods, DIP-GS obtains
state-of-the-art (SOTA) competitive results on various sparse-view
reconstruction tasks, demonstrating its capabilities.

</details>


### [326] [CharacterShot: Controllable and Consistent 4D Character Animation](https://arxiv.org/abs/2508.07409)
*Junyao Gao,Jiaxing Li,Wenran Liu,Yanhong Zeng,Fei Shen,Kai Chen,Yanan Sun,Cairong Zhao*

Main category: cs.CV

Relevance: 20.0

TL;DR: CharacterShot是一个可控且一致的4D角色动画框架，通过单张参考图像和2D姿态序列生成动态3D角色。结合DiT模型、双注意力模块和4D高斯溅射优化，实现了高质量的4D角色表现。


<details>
  <summary>Details</summary>
Motivation: 为设计师提供一种简单高效的方法，从单张图像和2D姿态序列生成动态3D角色动画。

Method: 1. 基于DiT的2D角色动画预训练模型；2. 通过双注意力模块和相机先验将2D动画提升到3D；3. 使用4D高斯溅射优化生成连续稳定的4D角色表现。

Result: 在CharacterBench基准测试中优于现有方法，并发布了大规模数据集Character4D。

Conclusion: CharacterShot为4D角色动画提供了一种高效可控的解决方案。

Abstract: In this paper, we propose \textbf{CharacterShot}, a controllable and
consistent 4D character animation framework that enables any individual
designer to create dynamic 3D characters (i.e., 4D character animation) from a
single reference character image and a 2D pose sequence. We begin by
pretraining a powerful 2D character animation model based on a cutting-edge
DiT-based image-to-video model, which allows for any 2D pose sequnce as
controllable signal. We then lift the animation model from 2D to 3D through
introducing dual-attention module together with camera prior to generate
multi-view videos with spatial-temporal and spatial-view consistency. Finally,
we employ a novel neighbor-constrained 4D gaussian splatting optimization on
these multi-view videos, resulting in continuous and stable 4D character
representations. Moreover, to improve character-centric performance, we
construct a large-scale dataset Character4D, containing 13,115 unique
characters with diverse appearances and motions, rendered from multiple
viewpoints. Extensive experiments on our newly constructed benchmark,
CharacterBench, demonstrate that our approach outperforms current
state-of-the-art methods. Code, models, and datasets will be publicly available
at https://github.com/Jeoyal/CharacterShot.

</details>


### [327] [Novel View Synthesis with Gaussian Splatting: Impact on Photogrammetry Model Accuracy and Resolution](https://arxiv.org/abs/2508.07483)
*Pranav Chougule*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文比较了摄影测量与高斯泼溅技术在3D模型重建和视图合成中的表现，开发了改进的高斯泼溅库，并展示了其提升摄影测量质量的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在比较两种3D重建技术的性能，并探索高斯泼溅在生成高质量新视图和改进摄影测量模型中的应用。

Method: 创建真实场景图像数据集，使用两种方法构建3D模型，通过SSIM、PSNR等指标评估性能，并开发改进的高斯泼溅库。

Result: 高斯泼溅能生成高质量新视图，并提升摄影测量模型的质量。

Conclusion: 高斯泼溅在3D重建和视图合成中具有潜力，为扩展现实和自动驾驶模拟提供参考。

Abstract: In this paper, I present a comprehensive study comparing Photogrammetry and
Gaussian Splatting techniques for 3D model reconstruction and view synthesis. I
created a dataset of images from a real-world scene and constructed 3D models
using both methods. To evaluate the performance, I compared the models using
structural similarity index (SSIM), peak signal-to-noise ratio (PSNR), learned
perceptual image patch similarity (LPIPS), and lp/mm resolution based on the
USAF resolution chart. A significant contribution of this work is the
development of a modified Gaussian Splatting repository, which I forked and
enhanced to enable rendering images from novel camera poses generated in the
Blender environment. This innovation allows for the synthesis of high-quality
novel views, showcasing the flexibility and potential of Gaussian Splatting. My
investigation extends to an augmented dataset that includes both original
ground images and novel views synthesized via Gaussian Splatting. This
augmented dataset was employed to generate a new photogrammetry model, which
was then compared against the original photogrammetry model created using only
the original images. The results demonstrate the efficacy of using Gaussian
Splatting to generate novel high-quality views and its potential to improve
photogrammetry-based 3D reconstructions. The comparative analysis highlights
the strengths and limitations of both approaches, providing valuable
information for applications in extended reality (XR), photogrammetry, and
autonomous vehicle simulations. Code is available at
https://github.com/pranavc2255/gaussian-splatting-novel-view-render.git.

</details>


### [328] [From Field to Drone: Domain Drift Tolerant Automated Multi-Species and Damage Plant Semantic Segmentation for Herbicide Trials](https://arxiv.org/abs/2508.07514)
*Artzai Picon,Itziar Eguskiza,Daniel Mugica,Javier Romero,Carlos Javier Jimenez,Eric White,Gabriel Do-Lago-Junqueira,Christian Klukas,Ramon Navarra-Mestre*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种结合自监督视觉模型和植物分类层次推理的改进分割模型，用于自动化作物和杂草识别，显著提升了性能并验证了跨设备鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的手动视觉评估耗时、费力且主观，自动化识别可提高效率和一致性。

Method: 结合自监督视觉模型和植物分类层次推理，训练于多国多年数据集，测试跨设备性能。

Result: 模型显著提升了物种识别和损害分类的F1分数和R-squared值，并在跨设备测试中表现稳健。

Conclusion: 模型具有实际应用价值，已部署于大规模自动化作物监测系统。

Abstract: Field trials are vital in herbicide research and development to assess
effects on crops and weeds under varied conditions. Traditionally, evaluations
rely on manual visual assessments, which are time-consuming, labor-intensive,
and subjective. Automating species and damage identification is challenging due
to subtle visual differences, but it can greatly enhance efficiency and
consistency.
  We present an improved segmentation model combining a general-purpose
self-supervised visual model with hierarchical inference based on botanical
taxonomy. Trained on a multi-year dataset (2018-2020) from Germany and Spain
using digital and mobile cameras, the model was tested on digital camera data
(year 2023) and drone imagery from the United States, Germany, and Spain (year
2024) to evaluate robustness under domain shift. This cross-device evaluation
marks a key step in assessing generalization across platforms of the model.
  Our model significantly improved species identification (F1-score: 0.52 to
0.85, R-squared: 0.75 to 0.98) and damage classification (F1-score: 0.28 to
0.44, R-squared: 0.71 to 0.87) over prior methods. Under domain shift (drone
images), it maintained strong performance with moderate degradation (species:
F1-score 0.60, R-squared 0.80; damage: F1-score 0.41, R-squared 0.62), where
earlier models failed.
  These results confirm the model's robustness and real-world applicability. It
is now deployed in BASF's phenotyping pipeline, enabling large-scale, automated
crop and weed monitoring across diverse geographies.

</details>


### [329] [A DICOM Image De-identification Algorithm in the MIDI-B Challenge](https://arxiv.org/abs/2508.07538)
*Hongzhu Jiang,Sihan Xie,Zhiyu Wan*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文介绍了医学图像去标识化的重要性，提出了MIDI-B挑战赛及其结果，并探讨了当前方法的局限性和未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 医学图像共享需遵守隐私法规（如HIPAA），去标识化是保护患者隐私的关键。

Method: 采用像素掩码、日期偏移、文本识别与替换等方法处理DICOM图像。

Result: 算法在MIDI-B挑战赛中正确执行99.92%的任务，排名第二。

Conclusion: 当前方法有效但仍有限制，未来需进一步优化。

Abstract: Image de-identification is essential for the public sharing of medical
images, particularly in the widely used Digital Imaging and Communications in
Medicine (DICOM) format as required by various regulations and standards,
including Health Insurance Portability and Accountability Act (HIPAA) privacy
rules, the DICOM PS3.15 standard, and best practices recommended by the Cancer
Imaging Archive (TCIA). The Medical Image De-Identification Benchmark (MIDI-B)
Challenge at the 27th International Conference on Medical Image Computing and
Computer Assisted Intervention (MICCAI 2024) was organized to evaluate
rule-based DICOM image de-identification algorithms with a large dataset of
clinical DICOM images. In this report, we explore the critical challenges of
de-identifying DICOM images, emphasize the importance of removing personally
identifiable information (PII) to protect patient privacy while ensuring the
continued utility of medical data for research, diagnostics, and treatment, and
provide a comprehensive overview of the standards and regulations that govern
this process. Additionally, we detail the de-identification methods we applied
- such as pixel masking, date shifting, date hashing, text recognition, text
replacement, and text removal - to process datasets during the test phase in
strict compliance with these standards. According to the final leaderboard of
the MIDI-B challenge, the latest version of our solution algorithm correctly
executed 99.92% of the required actions and ranked 2nd out of 10 teams that
completed the challenge (from a total of 22 registered teams). Finally, we
conducted a thorough analysis of the resulting statistics and discussed the
limitations of current approaches and potential avenues for future improvement.

</details>


### [330] [ShoulderShot: Generating Over-the-Shoulder Dialogue Videos](https://arxiv.org/abs/2508.07597)
*Yuang Zhang,Junqi Cheng,Haoyu Zhao,Jiaxi Gu,Fangyuan Zou,Zenghui Lu,Peng Shu*

Main category: cs.CV

Relevance: 20.0

TL;DR: ShoulderShot框架结合双镜头生成与循环视频，解决了对话视频生成中的角色一致性和空间连续性挑战。


<details>
  <summary>Details</summary>
Motivation: 对话视频在影视中重要但研究不足，需解决角色一致性、空间连续性和计算预算限制问题。

Method: 结合双镜头生成与循环视频技术，支持长对话生成。

Result: 在镜头切换布局、空间连续性和对话长度灵活性上优于现有方法。

Conclusion: ShoulderShot为实用对话视频生成开辟了新可能。

Abstract: Over-the-shoulder dialogue videos are essential in films, short dramas, and
advertisements, providing visual variety and enhancing viewers' emotional
connection. Despite their importance, such dialogue scenes remain largely
underexplored in video generation research. The main challenges include
maintaining character consistency across different shots, creating a sense of
spatial continuity, and generating long, multi-turn dialogues within limited
computational budgets. Here, we present ShoulderShot, a framework that combines
dual-shot generation with looping video, enabling extended dialogues while
preserving character consistency. Our results demonstrate capabilities that
surpass existing methods in terms of shot-reverse-shot layout, spatial
continuity, and flexibility in dialogue length, thereby opening up new
possibilities for practical dialogue video generation. Videos and comparisons
are available at https://shouldershot.github.io.

</details>


### [331] [A Registration-Based Star-Shape Segmentation Model and Fast Algorithms](https://arxiv.org/abs/2508.07721)
*Daoping Zhang,Xue-Cheng Tai,Lok Ming Lui*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出了一种基于配准框架的星形分割模型，结合水平集表示和配准框架，实现了完整和部分星形分割，并通过数值实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决图像分割中因遮挡、模糊或噪声导致的准确性挑战，利用星形先验信息提升分割效果。

Method: 结合水平集表示与配准框架，对变形水平集函数施加约束，支持单中心或多中心的星形分割，并通过交替方向乘子法求解模型。

Result: 在合成和真实图像上的实验表明，该方法能有效实现精确的星形分割。

Conclusion: 提出的模型在星形分割任务中表现出色，尤其适用于复杂场景下的图像分割需求。

Abstract: Image segmentation plays a crucial role in extracting objects of interest and
identifying their boundaries within an image. However, accurate segmentation
becomes challenging when dealing with occlusions, obscurities, or noise in
corrupted images. To tackle this challenge, prior information is often
utilized, with recent attention on star-shape priors. In this paper, we propose
a star-shape segmentation model based on the registration framework. By
combining the level set representation with the registration framework and
imposing constraints on the deformed level set function, our model enables both
full and partial star-shape segmentation, accommodating single or multiple
centers. Additionally, our approach allows for the enforcement of identified
boundaries to pass through specified landmark locations. We tackle the proposed
models using the alternating direction method of multipliers. Through numerical
experiments conducted on synthetic and real images, we demonstrate the efficacy
of our approach in achieving accurate star-shape segmentation.

</details>


### [332] [Forecasting Continuous Non-Conservative Dynamical Systems in SO(3)](https://arxiv.org/abs/2508.07775)
*Lennart Bastian,Mohammad Rashed,Nassir Navab,Tolga Birdal*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种基于神经控制微分方程和SO(3) Savitzky-Golay路径的方法，用于建模3D旋转的轨迹，解决了传统方法在非保守力场景下的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决SO(3)外推中的挑战，如未知物理量、非保守力及噪声观测下的状态估计。

Method: 利用神经控制微分方程和SO(3) Savitzky-Golay路径建模旋转轨迹，不依赖能量或动量守恒假设。

Result: 模型在仿真和实际场景中表现出鲁棒的外推能力，适用于未知物理参数的轨迹。

Conclusion: 该方法为复杂非惯性系统提供了一种通用且鲁棒的旋转轨迹建模方案。

Abstract: Modeling the rotation of moving objects is a fundamental task in computer
vision, yet $SO(3)$ extrapolation still presents numerous challenges: (1)
unknown quantities such as the moment of inertia complicate dynamics, (2) the
presence of external forces and torques can lead to non-conservative
kinematics, and (3) estimating evolving state trajectories under sparse, noisy
observations requires robustness. We propose modeling trajectories of noisy
pose estimates on the manifold of 3D rotations in a physically and
geometrically meaningful way by leveraging Neural Controlled Differential
Equations guided with $SO(3)$ Savitzky-Golay paths. Existing extrapolation
methods often rely on energy conservation or constant velocity assumptions,
limiting their applicability in real-world scenarios involving non-conservative
forces. In contrast, our approach is agnostic to energy and momentum
conservation while being robust to input noise, making it applicable to
complex, non-inertial systems. Our approach is easily integrated as a module in
existing pipelines and generalizes well to trajectories with unknown physical
parameters. By learning to approximate object dynamics from noisy states during
training, our model attains robust extrapolation capabilities in simulation and
various real-world settings. Code is available at
https://github.com/bastianlb/forecasting-rotational-dynamics

</details>


### [333] [GaitSnippet: Gait Recognition Beyond Unordered Sets and Ordered Sequences](https://arxiv.org/abs/2508.07782)
*Saihui Hou,Chenye Wang,Wenpeng Lang,Zhengxiang Lan,Yongzhen Huang*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种基于“片段”的步态识别方法，通过多尺度时间上下文提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于集合或序列的步态识别方法在短范围和长范围时间依赖上的局限性。

Method: 将步态视为个性化动作的组合，提出片段采样和片段建模的关键组件。

Result: 在Gait3D和GREW数据集上分别达到77.5%和81.7%的rank-1准确率。

Conclusion: 片段方法有效提升了步态识别性能，展示了多尺度时间上下文的潜力。

Abstract: Recent advancements in gait recognition have significantly enhanced
performance by treating silhouettes as either an unordered set or an ordered
sequence. However, both set-based and sequence-based approaches exhibit notable
limitations. Specifically, set-based methods tend to overlook short-range
temporal context for individual frames, while sequence-based methods struggle
to capture long-range temporal dependencies effectively. To address these
challenges, we draw inspiration from human identification and propose a new
perspective that conceptualizes human gait as a composition of individualized
actions. Each action is represented by a series of frames, randomly selected
from a continuous segment of the sequence, which we term a snippet.
Fundamentally, the collection of snippets for a given sequence enables the
incorporation of multi-scale temporal context, facilitating more comprehensive
gait feature learning. Moreover, we introduce a non-trivial solution for
snippet-based gait recognition, focusing on Snippet Sampling and Snippet
Modeling as key components. Extensive experiments on four widely-used gait
datasets validate the effectiveness of our proposed approach and, more
importantly, highlight the potential of gait snippets. For instance, our method
achieves the rank-1 accuracy of 77.5% on Gait3D and 81.7% on GREW using a 2D
convolution-based backbone.

</details>


### [334] [Semi-supervised Multiscale Matching for SAR-Optical Image](https://arxiv.org/abs/2508.07812)
*Jingze Gai,Changchun Li*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出了一种半监督SAR-光学图像匹配方法（S2M2-SAR），利用伪标签和无监督特征增强模块，显著减少对标注数据的依赖，性能接近全监督方法。


<details>
  <summary>Details</summary>
Motivation: 解决SAR-光学图像匹配中标注数据稀缺且标注成本高的问题。

Method: 结合伪标签和跨模态特征增强模块，利用少量标注数据和大量无标注数据训练匹配模型。

Result: S2M2-SAR在基准数据集上优于半监督方法，性能接近全监督SOTA。

Conclusion: S2M2-SAR高效且实用，减少了对标注数据的依赖。

Abstract: Driven by the complementary nature of optical and synthetic aperture radar
(SAR) images, SAR-optical image matching has garnered significant interest.
Most existing SAR-optical image matching methods aim to capture effective
matching features by employing the supervision of pixel-level matched
correspondences within SAR-optical image pairs, which, however, suffers from
time-consuming and complex manual annotation, making it difficult to collect
sufficient labeled SAR-optical image pairs. To handle this, we design a
semi-supervised SAR-optical image matching pipeline that leverages both scarce
labeled and abundant unlabeled image pairs and propose a semi-supervised
multiscale matching for SAR-optical image matching (S2M2-SAR). Specifically, we
pseudo-label those unlabeled SAR-optical image pairs with pseudo ground-truth
similarity heatmaps by combining both deep and shallow level matching results,
and train the matching model by employing labeled and pseudo-labeled similarity
heatmaps. In addition, we introduce a cross-modal feature enhancement module
trained using a cross-modality mutual independence loss, which requires no
ground-truth labels. This unsupervised objective promotes the separation of
modality-shared and modality-specific features by encouraging statistical
independence between them, enabling effective feature disentanglement across
optical and SAR modalities. To evaluate the effectiveness of S2M2-SAR, we
compare it with existing competitors on benchmark datasets. Experimental
results demonstrate that S2M2-SAR not only surpasses existing semi-supervised
methods but also achieves performance competitive with fully supervised SOTA
methods, demonstrating its efficiency and practical potential.

</details>


### [335] [Tracking Any Point Methods for Markerless 3D Tissue Tracking in Endoscopic Stereo Images](https://arxiv.org/abs/2508.07851)
*Konrad Reuter,Suresh Guttikonda,Sarah Latus,Lennart Maack,Christian Betz,Tobias Maurer,Alexander Schlaefer*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出了一种基于2D TAP网络的无标记3D组织追踪方法，结合两个CoTracker模型，用于从立体内窥镜图像中估计3D运动。


<details>
  <summary>Details</summary>
Motivation: 微创手术中动态组织运动和有限视野带来挑战，准确的追踪可提升手术安全性并支持机器人辅助。

Method: 结合两个CoTracker模型（时间追踪和立体匹配），利用立体内窥镜图像估计3D运动。

Result: 在鸡组织模型上追踪误差低至1.1 mm（速度10 mm/s），验证了方法的可靠性。

Conclusion: TAP模型在复杂手术场景中具有无标记3D追踪的潜力。

Abstract: Minimally invasive surgery presents challenges such as dynamic tissue motion
and a limited field of view. Accurate tissue tracking has the potential to
support surgical guidance, improve safety by helping avoid damage to sensitive
structures, and enable context-aware robotic assistance during complex
procedures. In this work, we propose a novel method for markerless 3D tissue
tracking by leveraging 2D Tracking Any Point (TAP) networks. Our method
combines two CoTracker models, one for temporal tracking and one for stereo
matching, to estimate 3D motion from stereo endoscopic images. We evaluate the
system using a clinical laparoscopic setup and a robotic arm simulating tissue
motion, with experiments conducted on a synthetic 3D-printed phantom and a
chicken tissue phantom. Tracking on the chicken tissue phantom yielded more
reliable results, with Euclidean distance errors as low as 1.1 mm at a velocity
of 10 mm/s. These findings highlight the potential of TAP-based models for
accurate, markerless 3D tracking in challenging surgical scenarios.

</details>


### [336] [PrIINeR: Towards Prior-Informed Implicit Neural Representations for Accelerated MRI](https://arxiv.org/abs/2508.08058)
*Ziad Al-Haj Hemidi,Eytan Kats,Mattias P. Heinrich*

Main category: cs.CV

Relevance: 20.0

TL;DR: PrIINeR是一种结合预训练深度学习模型和隐式神经表示（INR）的MRI重建方法，显著提升图像质量并减少伪影。


<details>
  <summary>Details</summary>
Motivation: 解决高加速因子下INR方法因弱先验约束导致的图像质量下降问题。

Method: 整合预训练模型的先验知识到INR框架，结合实例优化和双重数据一致性。

Result: 在NYU fastMRI数据集上优于现有INR和部分学习型方法，提升结构保留和保真度。

Conclusion: PrIINeR为高质量加速MRI重建提供了可靠方案，结合了深度学习和INR技术。

Abstract: Accelerating Magnetic Resonance Imaging (MRI) reduces scan time but often
degrades image quality. While Implicit Neural Representations (INRs) show
promise for MRI reconstruction, they struggle at high acceleration factors due
to weak prior constraints, leading to structural loss and aliasing artefacts.
To address this, we propose PrIINeR, an INR-based MRI reconstruction method
that integrates prior knowledge from pre-trained deep learning models into the
INR framework. By combining population-level knowledge with instance-based
optimization and enforcing dual data consistency, PrIINeR aligns both with the
acquired k-space data and the prior-informed reconstruction. Evaluated on the
NYU fastMRI dataset, our method not only outperforms state-of-the-art INR-based
approaches but also improves upon several learning-based state-of-the-art
methods, significantly improving structural preservation and fidelity while
effectively removing aliasing artefacts.PrIINeR bridges deep learning and
INR-based techniques, offering a more reliable solution for high-quality,
accelerated MRI reconstruction. The code is publicly available on
https://github.com/multimodallearning/PrIINeR.

</details>


### [337] [Hyperspectral Imaging](https://arxiv.org/abs/2508.08107)
*Danfeng Hong,Chenyu Li,Naoto Yokoya,Bing Zhang,Xiuping Jia,Antonio Plaza,Paolo Gamba,Jon Atli Benediktsson,Jocelyn Chanussot*

Main category: cs.CV

Relevance: 20.0

TL;DR: 本文综述了高光谱成像（HSI）的原理、技术、应用及未来发展方向，强调了其在多领域的潜力及当前挑战。


<details>
  <summary>Details</summary>
Motivation: HSI作为一种非侵入性、无标记的分析技术，能够同时捕捉空间和光谱信息，具有广泛的应用前景。本文旨在全面介绍HSI的物理原理、数据处理方法及其在多个领域的应用。

Method: 文章总结了HSI的数据结构、经典与现代分析方法（如降维、分类、光谱解混及深度学习），并讨论了硬件限制、数据复杂性等挑战的解决方案。

Result: HSI在遥感、农业、生物医学等领域展现出强大的潜力，未来可能通过传感器小型化和自监督学习实现实时嵌入式系统。

Conclusion: HSI有望成为跨学科通用平台，推动科学、技术和社会的变革。

Abstract: Hyperspectral imaging (HSI) is an advanced sensing modality that
simultaneously captures spatial and spectral information, enabling
non-invasive, label-free analysis of material, chemical, and biological
properties. This Primer presents a comprehensive overview of HSI, from the
underlying physical principles and sensor architectures to key steps in data
acquisition, calibration, and correction. We summarize common data structures
and highlight classical and modern analysis methods, including dimensionality
reduction, classification, spectral unmixing, and AI-driven techniques such as
deep learning. Representative applications across Earth observation, precision
agriculture, biomedicine, industrial inspection, cultural heritage, and
security are also discussed, emphasizing HSI's ability to uncover sub-visual
features for advanced monitoring, diagnostics, and decision-making. Persistent
challenges, such as hardware trade-offs, acquisition variability, and the
complexity of high-dimensional data, are examined alongside emerging solutions,
including computational imaging, physics-informed modeling, cross-modal fusion,
and self-supervised learning. Best practices for dataset sharing,
reproducibility, and metadata documentation are further highlighted to support
transparency and reuse. Looking ahead, we explore future directions toward
scalable, real-time, and embedded HSI systems, driven by sensor
miniaturization, self-supervised learning, and foundation models. As HSI
evolves into a general-purpose, cross-disciplinary platform, it holds promise
for transformative applications in science, technology, and society.

</details>


### [338] [A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images](https://arxiv.org/abs/2508.08123)
*Lingjing Chen,Chengxiu Zhang,Yinqiao Yi,Yida Wang,Yang Song,Xu Yan,Shengfang Xu,Dalin Zhu,Mengqiu Cao,Yan Zhou,Chenglong Wang,Guang Yang*

Main category: eess.IV

Relevance: 20.0

TL;DR: 提出了一种基于深度学习的MRI图像合成方法，通过嵌入MRI序列参数提升定量图像合成的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提高临床加权MRI定量图像合成的准确性和泛化性，以加速定量MRI的临床应用。

Method: 设计了一种物理驱动的神经网络，嵌入MRI序列参数（TR、TE、TI），输入T1、T2和T2-FLAIR图像，合成T1、T2和PD定量图。

Result: 在内部和外部测试数据集上表现优异，PSNR超过34 dB，SSIM高于0.92，泛化能力强，适用于未见过的病理区域。

Conclusion: 通过参数嵌入学习MRI信号的物理特性，显著提升了定量MRI合成的性能和可靠性，具有临床应用潜力。

Abstract: We propose a deep learning-based approach that integrates MRI sequence
parameters to improve the accuracy and generalizability of quantitative image
synthesis from clinical weighted MRI. Our physics-driven neural network embeds
MRI sequence parameters -- repetition time (TR), echo time (TE), and inversion
time (TI) -- directly into the model via parameter embedding, enabling the
network to learn the underlying physical principles of MRI signal formation.
The model takes conventional T1-weighted, T2-weighted, and T2-FLAIR images as
input and synthesizes T1, T2, and proton density (PD) quantitative maps.
Trained on healthy brain MR images, it was evaluated on both internal and
external test datasets. The proposed method achieved high performance with PSNR
values exceeding 34 dB and SSIM values above 0.92 for all synthesized parameter
maps. It outperformed conventional deep learning models in accuracy and
robustness, including data with previously unseen brain structures and lesions.
Notably, our model accurately synthesized quantitative maps for these unseen
pathological regions, highlighting its superior generalization capability.
Incorporating MRI sequence parameters via parameter embedding allows the neural
network to better learn the physical characteristics of MR signals,
significantly enhancing the performance and reliability of quantitative MRI
synthesis. This method shows great potential for accelerating qMRI and
improving its clinical utility.

</details>


### [339] [TeSO: Representing and Compressing 3D Point Cloud Scenes with Textured Surfel Octree](https://arxiv.org/abs/2508.07083)
*Yueyu Hu,Ran Gong,Tingyu Fan,Yao Wang*

Main category: cs.CV

Relevance: 10.0

TL;DR: 论文提出了一种名为Textured Surfel Octree (TeSO)的新型3D表示方法，用于解决现有3D表示在渲染质量、表面定义和压缩性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有3D表示（如点云、网格和3D高斯）在渲染质量、表面定义和压缩性方面存在不足，需要一种更高效的3D表示方法以支持3D视觉内容流媒体应用。

Method: TeSO通过将3D场景表示为基于八叉树组织的立方体边界曲面元（surfel），每个曲面元关联一个纹理贴图，从而减少表示所需的图元数量并保留高频纹理细节。同时提出了一种基于八叉树的高效压缩方案。

Result: TeSO结合压缩方案在较低比特率下实现了比点云和3D高斯基线更高的渲染质量。

Conclusion: TeSO是一种高效的3D表示方法，适用于3D视觉内容流媒体应用。

Abstract: 3D visual content streaming is a key technology for emerging 3D telepresence
and AR/VR applications. One fundamental element underlying the technology is a
versatile 3D representation that is capable of producing high-quality renders
and can be efficiently compressed at the same time. Existing 3D representations
like point clouds, meshes and 3D Gaussians each have limitations in terms of
rendering quality, surface definition, and compressibility. In this paper, we
present the Textured Surfel Octree (TeSO), a novel 3D representation that is
built from point clouds but addresses the aforementioned limitations. It
represents a 3D scene as cube-bounded surfels organized on an octree, where
each surfel is further associated with a texture patch. By approximating a
smooth surface with a large surfel at a coarser level of the octree, it reduces
the number of primitives required to represent the 3D scene, and yet retains
the high-frequency texture details through the texture map attached to each
surfel. We further propose a compression scheme to encode the geometry and
texture efficiently, leveraging the octree structure. The proposed textured
surfel octree combined with the compression scheme achieves higher rendering
quality at lower bit-rates compared to multiple point cloud and 3D
Gaussian-based baselines.

</details>


### [340] [DragonFruitQualityNet: A Lightweight Convolutional Neural Network for Real-Time Dragon Fruit Quality Inspection on Mobile Devices](https://arxiv.org/abs/2508.07306)
*Md Zahurul Haquea,Yeahyea Sarker,Muhammed Farhan Sadique Mahi,Syed Jubayer Jaman,Md Robiul Islam*

Main category: cs.CV

Relevance: 10.0

TL;DR: 该论文提出了一种轻量级CNN模型DragonFruitQualityNet，用于火龙果的实时质量检测，准确率达93.98%，并嵌入移动应用以支持实际农业应用。


<details>
  <summary>Details</summary>
Motivation: 火龙果种植扩展需要高效的品质检测技术，以提高农业生产效率并减少收获后损失。

Method: 使用13,789张火龙果图像数据集，训练轻量级CNN模型，并嵌入移动应用实现实时检测。

Result: 模型准确率达93.98%，优于现有方法，并成功应用于移动设备。

Conclusion: 研究为火龙果品质控制提供了高效、可扩展的AI解决方案，支持数字农业和可持续种植。

Abstract: Dragon fruit, renowned for its nutritional benefits and economic value, has
experienced rising global demand due to its affordability and local
availability. As dragon fruit cultivation expands, efficient pre- and
post-harvest quality inspection has become essential for improving agricultural
productivity and minimizing post-harvest losses. This study presents
DragonFruitQualityNet, a lightweight Convolutional Neural Network (CNN)
optimized for real-time quality assessment of dragon fruits on mobile devices.
We curated a diverse dataset of 13,789 images, integrating self-collected
samples with public datasets (dataset from Mendeley Data), and classified them
into four categories: fresh, immature, mature, and defective fruits to ensure
robust model training. The proposed model achieves an impressive 93.98%
accuracy, outperforming existing methods in fruit quality classification. To
facilitate practical adoption, we embedded the model into an intuitive mobile
application, enabling farmers and agricultural stakeholders to conduct
on-device, real-time quality inspections. This research provides an accurate,
efficient, and scalable AI-driven solution for dragon fruit quality control,
supporting digital agriculture and empowering smallholder farmers with
accessible technology. By bridging the gap between research and real-world
application, our work advances post-harvest management and promotes sustainable
farming practices.

</details>


### [341] [Health Care Waste Classification Using Deep Learning Aligned with Nepal's Bin Color Guidelines](https://arxiv.org/abs/2508.07450)
*Suman Kunwar,Prabesh Rai*

Main category: cs.CV

Relevance: 10.0

TL;DR: 论文研究了尼泊尔医疗废物分类问题，比较了多种模型性能，发现YOLOv5-s准确率最高但推理速度稍慢，最终部署为Web工具。


<details>
  <summary>Details</summary>
Motivation: 解决尼泊尔医疗废物管理中的分类挑战，以减少污染和疾病传播风险。

Method: 使用Stratified K-fold技术对比ResNeXt-50、EfficientNet-B0、MobileNetV3-S、YOLOv8-n和YOLOv5-s模型，并进行重复ANOVA分析。

Result: YOLOv5-s以95.06%准确率表现最佳，但推理速度略慢于YOLOv8-n；EfficientNet-B0准确率93.22%，但推理时间最长。

Conclusion: YOLOv5-s被部署为Web工具，未来需优化数据和本地化上下文。

Abstract: The increasing number of Health Care facilities in Nepal has also added up
the challenges on managing health care waste (HCW). Improper segregation and
disposal of HCW leads to the contamination, spreading of infectious diseases
and puts a risk of waste handlers. This study benchmarks the state of the art
waste classification models: ResNeXt-50, EfficientNet-B0, MobileNetV3-S,
YOLOv8-n and YOLOv5-s using Stratified K-fold techniques where we use 5 folds
on combined HCW data, and found that the YOLOv5-s achieved higher of 95.06%
accuracy but fell short few milliseconds in inference speed with YOLOv8-n
model. The EfficientNet-B0 showed promising results of 93.22% accuracy but took
the highest inference time. A repetitive ANOVA was performed to see statistical
significance and the best performing model (YOLOv5-s) was deployed to the web
with mapped bin color using Nepal's HCW management standards for public usage.
Further work on the data was suggested along with localized context.

</details>


### [342] [An Iterative Reconstruction Method for Dental Cone-Beam Computed Tomography with a Truncated Field of View](https://arxiv.org/abs/2508.07618)
*Hyoung Suk Park,Kiwan Jeon*

Main category: cs.CV

Relevance: 10.0

TL;DR: 论文提出一种两阶段方法，通过隐式神经表示（INR）生成先验图像，校正投影数据，以减少牙科CBCT中的截断伪影，提升图像质量。


<details>
  <summary>Details</summary>
Motivation: 小型探测器导致牙科CBCT的视场截断，传统迭代重建方法因截断误差累积而图像质量下降。

Method: 两阶段方法：1）使用INR生成覆盖患者头部的先验图像；2）校正投影数据后，进行常规迭代重建。

Result: 数值结果显示，该方法有效抑制截断伪影，提升CBCT图像质量。

Conclusion: 两阶段方法通过INR和迭代重建结合，显著改善截断问题。

Abstract: In dental cone-beam computed tomography (CBCT), compact and cost-effective
system designs often use small detectors, resulting in a truncated field of
view (FOV) that does not fully encompass the patient's head. In iterative
reconstruction approaches, the discrepancy between the actual projection and
the forward projection within the truncated FOV accumulates over iterations,
leading to significant degradation in the reconstructed image quality. In this
study, we propose a two-stage approach to mitigate truncation artifacts in
dental CBCT. In the first stage, we employ Implicit Neural Representation
(INR), leveraging its superior representation power, to generate a prior image
over an extended region so that its forward projection fully covers the
patient's head. To reduce computational and memory burdens, INR reconstruction
is performed with a coarse voxel size. The forward projection of this prior
image is then used to estimate the discrepancy due to truncated FOV in the
measured projection data. In the second stage, the discrepancy-corrected
projection data is utilized in a conventional iterative reconstruction process
within the truncated region. Our numerical results demonstrate that the
proposed two-grid approach effectively suppresses truncation artifacts, leading
to improved CBCT image quality.

</details>


### [343] [Power Battery Detection](https://arxiv.org/abs/2508.07797)
*Xiaoqi Zhao,Peiqian Cao,Lihe Zhang,Zonglei Feng,Hanqi Liu,Jiaming Zuo,Youwei Pang,Weisi Lin,Georges El Fakhri,Huchuan Lu,Xiaofeng Liu*

Main category: cs.CV

Relevance: 10.0

TL;DR: 本文提出了一种用于电力电池X射线图像检测的新任务PBD，并发布了首个大规模基准数据集PBD5K。通过设计MDCNeXt模型，结合多维结构线索和状态空间模块，解决了传统视觉算法在密集、低对比度场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 电力电池内部结构缺陷可能导致严重安全隐患，传统人工检测效率低且易出错，现有视觉算法难以应对密集、低对比度等问题。

Method: 提出PBD5K数据集，开发智能标注流程；将PBD任务建模为点级分割问题，设计MDCNeXt模型，整合点、线、计数等多维信息，并引入两个状态空间模块。

Result: MDCNeXt模型在PBD任务中表现出色，能够有效区分电池板并抑制视觉干扰。

Conclusion: PBD5K和MDCNeXt为电力电池检测提供了高效解决方案，推动了该领域的研究。

Abstract: Power batteries are essential components in electric vehicles, where internal
structural defects can pose serious safety risks. We conduct a comprehensive
study on a new task, power battery detection (PBD), which aims to localize the
dense endpoints of cathode and anode plates from industrial X-ray images for
quality inspection. Manual inspection is inefficient and error-prone, while
traditional vision algorithms struggle with densely packed plates, low
contrast, scale variation, and imaging artifacts. To address this issue and
drive more attention into this meaningful task, we present PBD5K, the first
large-scale benchmark for this task, consisting of 5,000 X-ray images from nine
battery types with fine-grained annotations and eight types of real-world
visual interference. To support scalable and consistent labeling, we develop an
intelligent annotation pipeline that combines image filtering, model-assisted
pre-labeling, cross-verification, and layered quality evaluation. We formulate
PBD as a point-level segmentation problem and propose MDCNeXt, a model designed
to extract and integrate multi-dimensional structure clues including point,
line, and count information from the plate itself. To improve discrimination
between plates and suppress visual interference, MDCNeXt incorporates two state
space modules. The first is a prompt-filtered module that learns contrastive
relationships guided by task-specific prompts. The second is a density-aware
reordering module that refines segmentation in regions with high plate density.
In addition, we propose a distance-adaptive mask generation strategy to provide
robust supervision under varying spatial distributions of anode and cathode
positions. The source code and datasets will be publicly available at
\href{https://github.com/Xiaoqi-Zhao-DLUT/X-ray-PBD}{PBD5K}.

</details>


### [344] [Morphological Analysis of Semiconductor Microstructures using Skeleton Graphs](https://arxiv.org/abs/2508.07850)
*Noriko Nitta,Rei Miyata,Naoto Oishi*

Main category: cs.CV

Relevance: 10.0

TL;DR: 论文通过图卷积网络处理Ge表面微结构的电子显微镜图像，提取拓扑特征并分析，发现辐照角度比辐照通量对形态影响更大。


<details>
  <summary>Details</summary>
Motivation: 研究Ge表面微结构的形态变化，探索辐照参数（角度和通量）对拓扑特征的影响。

Method: 使用图卷积网络提取拓扑特征，通过主成分分析和Davies-Bouldin指数评估聚类分离性。

Result: 辐照角度对Ge表面形态的影响显著大于辐照通量。

Conclusion: 辐照参数中角度是形态变化的主要驱动因素。

Abstract: In this paper, electron microscopy images of microstructures formed on Ge
surfaces by ion beam irradiation were processed to extract topological features
as skeleton graphs, which were then embedded using a graph convolutional
network. The resulting embeddings were analyzed using principal component
analysis, and cluster separability in the resulting PCA space was evaluated
using the Davies-Bouldin index. The results indicate that variations in
irradiation angle have a more significant impact on the morphological
properties of Ge surfaces than variations in irradiation fluence.

</details>


### [345] [3D Plant Root Skeleton Detection and Extraction](https://arxiv.org/abs/2508.08094)
*Jiakai Lin,Jinchang Zhang,Ge Jin,Wenzhan Song,Tianming Liu,Guoyu Lu*

Main category: cs.CV

Relevance: 10.0

TL;DR: 提出了一种从少量图像中高效提取植物根系3D骨架的方法，用于自动化育种机器人。


<details>
  <summary>Details</summary>
Motivation: 植物根系结构复杂且缺乏纹理信息，传统2D研究无法满足3D空间生长的需求，3D表型信息对遗传性状研究至关重要。

Method: 包括侧根检测与匹配、三角测量提取侧根骨架结构、以及侧根与主根整合。

Result: 在复杂根系数据集上测试，提取的3D骨架与真实结构高度相似。

Conclusion: 该方法可提升育种效率，减少人工干预，推动现代农业智能化。

Abstract: Plant roots typically exhibit a highly complex and dense architecture,
incorporating numerous slender lateral roots and branches, which significantly
hinders the precise capture and modeling of the entire root system.
Additionally, roots often lack sufficient texture and color information, making
it difficult to identify and track root traits using visual methods. Previous
research on roots has been largely confined to 2D studies; however, exploring
the 3D architecture of roots is crucial in botany. Since roots grow in real 3D
space, 3D phenotypic information is more critical for studying genetic traits
and their impact on root development. We have introduced a 3D root skeleton
extraction method that efficiently derives the 3D architecture of plant roots
from a few images. This method includes the detection and matching of lateral
roots, triangulation to extract the skeletal structure of lateral roots, and
the integration of lateral and primary roots. We developed a highly complex
root dataset and tested our method on it. The extracted 3D root skeletons
showed considerable similarity to the ground truth, validating the
effectiveness of the model. This method can play a significant role in
automated breeding robots. Through precise 3D root structure analysis, breeding
robots can better identify plant phenotypic traits, especially root structure
and growth patterns, helping practitioners select seeds with superior root
systems. This automated approach not only improves breeding efficiency but also
reduces manual intervention, making the breeding process more intelligent and
efficient, thus advancing modern agriculture.

</details>


### [346] [Vibration-Based Energy Metric for Restoring Needle Alignment in Autonomous Robotic Ultrasound](https://arxiv.org/abs/2508.06921)
*Zhongyu Chen,Chenyang Li,Xuesong Li,Dianye Huang,Zhongliang Jiang,Stefanie Speidel,Xiangyu Chu,K. W. Samuel Au*

Main category: cs.RO

Relevance: 10.0

TL;DR: 该论文提出了一种通过周期性振动针头来恢复超声引导下针头对齐的方法，即使在针头完全脱离平面时仍有效。


<details>
  <summary>Details</summary>
Motivation: 在超声引导的针插入过程中，针头对齐至关重要，但噪声和低分辨率图像使其难以检测。现有方法依赖针头可见性，而本方法利用振动特征提高鲁棒性。

Method: 通过机械系统周期性振动针头，提出一种基于振动的能量度量，并开发控制策略调整超声探头位置以纠正平移和旋转偏差。

Result: 在离体猪组织实验中，平移误差为0.41±0.27 mm，旋转误差为0.51±0.19度。

Conclusion: 该方法在针头对齐恢复中表现优异，适用于超声引导的针插入场景。

Abstract: Precise needle alignment is essential for percutaneous needle insertion in
robotic ultrasound-guided procedures. However, inherent challenges such as
speckle noise, needle-like artifacts, and low image resolution make robust
needle detection difficult, particularly when visibility is reduced or lost. In
this paper, we propose a method to restore needle alignment when the ultrasound
imaging plane and the needle insertion plane are misaligned. Unlike many
existing approaches that rely heavily on needle visibility in ultrasound
images, our method uses a more robust feature by periodically vibrating the
needle using a mechanical system. Specifically, we propose a vibration-based
energy metric that remains effective even when the needle is fully out of
plane. Using this metric, we develop a control strategy to reposition the
ultrasound probe in response to misalignments between the imaging plane and the
needle insertion plane in both translation and rotation. Experiments conducted
on ex-vivo porcine tissue samples using a dual-arm robotic ultrasound-guided
needle insertion system demonstrate the effectiveness of the proposed approach.
The experimental results show the translational error of 0.41$\pm$0.27 mm and
the rotational error of 0.51$\pm$0.19 degrees.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [347] [Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape](https://arxiv.org/abs/2508.07334)
*Quan Shi,Wang Xi,Zenghui Ding,Jianqing Gao,Xianjun Yang*

Main category: cs.AI

Relevance: 90.0

TL;DR: 论文研究了LLM中的幻觉现象，通过计算必要性层次和新的"学习者泵引理"证明了其不可避免性，并提出两种解决方案：RAG作为预言机模型和连续学习的神经博弈论框架。


<details>
  <summary>Details</summary>
Motivation: 解决LLM幻觉现象对可靠部署的核心障碍。

Method: 1. 将LLM形式化为概率图灵机，构建计算必要性层次；2. 提出两种"逃逸路径"：RAG作为预言机模型和连续学习的神经博弈论框架。

Result: 证明了幻觉现象的不可避免性，并提供了两种理论支持的解决方案。

Conclusion: 通过形式化理论和实践框架，为LLM的可靠部署提供了新思路。

Abstract: The illusion phenomenon of large language models (LLMs) is the core obstacle
to their reliable deployment. This article formalizes the large language model
as a probabilistic Turing machine by constructing a "computational necessity
hierarchy", and for the first time proves the illusions are inevitable on
diagonalization, incomputability, and information theory boundaries supported
by the new "learner pump lemma". However, we propose two "escape routes": one
is to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving
their absolute escape through "computational jumps", providing the first formal
theory for the effectiveness of RAGs; The second is to formalize continuous
learning as an "internalized oracle" mechanism and implement this path through
a novel neural game theory framework.Finally, this article proposes a

</details>


### [348] [Pushing the Envelope of LLM Inference on AI-PC](https://arxiv.org/abs/2508.06753)
*Evangelos Georganas,Dhiraj Kalamkar,Alexander Heinecke*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文提出了一种针对1/1.58/2位超低比特LLM模型的优化推理运行时，通过设计高效的微内核并集成到PyTorch-TPP框架中，显著提升了推理速度和效率。


<details>
  <summary>Details</summary>
Motivation: 超低比特LLM模型在资源受限环境（如边缘设备和AI PC）中具有潜力，但现有推理运行时的计算效率尚未充分探索。

Method: 设计并实现了针对现代CPU优化的1位和2位微内核，集成到PyTorch-TPP框架中。

Result: 2位模型推理速度比当前SOTA运行时bitnet.cpp快2.2倍，比16位模型快7倍。

Conclusion: 优化后的运行时推动了超低比特LLM模型在边缘设备和AI PC上的高效部署。

Abstract: The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the
perplexity and end-task performance of their full-precision counterparts using
the same model size, is ushering in a new era of LLM inference for
resource-constrained environments such as edge devices and AI PCs. While these
quantization advances promise models that are more cost-effective in terms of
latency, memory, throughput, and energy consumption, the computational
efficiency of state-of-the-art (SOTA) inference runtimes (e.g., bitnet.cpp)
used to deploy them remains underexplored. In this work, we take a bottom-up
approach: we first design and implement 1-bit and 2-bit microkernels optimized
for modern CPUs, achieving peak computational efficiency across a variety of
CPU platforms. We integrate these microkernels into a state-of-the-art LLM
inference framework, namely PyTorch-TPP, and present end-to-end inference
results with 2-bit models that outperform the current SOTA runtime bitnet.cpp
by up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model
inference. Our optimized runtime advances the state of LLM inference on AI PCs
and edge devices, paving the way for efficient deployment of ultra-low-bit LLM
models.

</details>


### [349] [A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks](https://arxiv.org/abs/2508.06754)
*Vanessa Figueiredo*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出了一种模块化提示框架，支持在动态、以用户为中心的任务中更安全、更自适应地使用大语言模型（LLMs）。


<details>
  <summary>Details</summary>
Motivation: 基于人类学习理论（如最近发展区ZPD），旨在提升LLMs在动态任务中的适应性和安全性。

Method: 结合自然语言边界提示和模糊支架逻辑的控制模式，无需微调或外部协调。

Result: 在模拟智能辅导环境中，框架在支架质量、适应性和教学对齐方面优于标准提示基线。

Conclusion: 该框架为结构化、可解释且目标对齐的LLM行为提供了可重复的方法，适用于不确定或动态变化的场景。

Abstract: We introduce a modular prompting framework that supports safer and more
adaptive use of large language models (LLMs) across dynamic, user-centered
tasks. Grounded in human learning theory, particularly the Zone of Proximal
Development (ZPD), our method combines a natural language boundary prompt with
a control schema encoded with fuzzy scaffolding logic and adaptation rules.
This architecture enables LLMs to modulate behavior in response to user state
without requiring fine-tuning or external orchestration. In a simulated
intelligent tutoring setting, the framework improves scaffolding quality,
adaptivity, and instructional alignment across multiple models, outperforming
standard prompting baselines. Evaluation is conducted using rubric-based LLM
graders at scale. While initially developed for education, the framework has
shown promise in other interaction-heavy domains, such as procedural content
generation for games. Designed for safe deployment, it provides a reusable
methodology for structuring interpretable, goal-aligned LLM behavior in
uncertain or evolving contexts.

</details>


### [350] [DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery](https://arxiv.org/abs/2508.06960)
*Keyu Li,Mohan Jiang,Dayuan Fu,Yunze Wu,Xiangkun Hu,Dequan Wang,Pengfei Liu*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文提出了DatasetResearch基准，评估AI代理在发现和合成数据集方面的能力，揭示了当前技术与完美数据集发现之间的巨大差距。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，数据可用性成为AI开发的瓶颈。论文旨在评估AI代理是否能自主发现满足特定需求的数据集。

Method: 引入DatasetResearch基准，包含208个真实需求任务，采用三维评估框架分析AI代理的表现。

Result: 当前先进系统在挑战性子集上仅得22分，显示搜索代理在知识任务上表现优异，合成代理在推理任务上占优，但两者在极端案例上均失败。

Conclusion: 研究为数据集发现代理建立了首个严格基准，为下一代自改进AI系统奠定了基础。

Abstract: The rapid advancement of large language models has fundamentally shifted the
bottleneck in AI development from computational power to data availability-with
countless valuable datasets remaining hidden across specialized repositories,
research appendices, and domain platforms. As reasoning capabilities and deep
research methodologies continue to evolve, a critical question emerges: can AI
agents transcend conventional search to systematically discover any dataset
that meets specific user requirements, enabling truly autonomous demand-driven
data curation? We introduce DatasetResearch, the first comprehensive benchmark
evaluating AI agents' ability to discover and synthesize datasets from 208
real-world demands across knowledge-intensive and reasoning-intensive tasks.
Our tri-dimensional evaluation framework reveals a stark reality: even advanced
deep research systems achieve only 22% score on our challenging
DatasetResearch-pro subset, exposing the vast gap between current capabilities
and perfect dataset discovery. Our analysis uncovers a fundamental
dichotomy-search agents excel at knowledge tasks through retrieval breadth,
while synthesis agents dominate reasoning challenges via structured
generation-yet both catastrophically fail on "corner cases" outside existing
distributions. These findings establish the first rigorous baseline for dataset
discovery agents and illuminate the path toward AI systems capable of finding
any dataset in the digital universe. Our benchmark and comprehensive analysis
provide the foundation for the next generation of self-improving AI systems and
are publicly available at https://github.com/GAIR-NLP/DatasetResearch.

</details>


### [351] [MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair](https://arxiv.org/abs/2508.06963)
*Changqing Li,Tianlin Li,Xiaohan Zhang,Aishan Liu,Li Pan*

Main category: cs.AI

Relevance: 85.0

TL;DR: MASteer是一个基于表示工程的端到端框架，用于修复LLM的可信性问题，通过自动生成多样化样本和自适应策略选择，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: LLM的可信性问题需要自动化、灵活的修复方法，现有方法成本高且缺乏鲁棒性。

Method: MASteer结合AutoTester（多智能体生成样本）和AutoRepairer（自适应策略选择），实现轻量级修复。

Result: 在LLaMA-3.1-8B-Chat和Qwen-3-8B-Chat上分别提升15.36%和4.21%的指标。

Conclusion: MASteer具有鲁棒性、泛化性和实用价值，适用于高效可信性修复。

Abstract: Large Language Models (LLMs) face persistent and evolving trustworthiness
issues, motivating developers to seek automated and flexible repair methods
that enable convenient deployment across diverse scenarios. Existing repair
methods like supervised fine-tuning (SFT) and reinforcement learning with human
feedback (RLHF) are costly and slow, while prompt engineering lacks robustness
and scalability. Representation engineering, which steers model behavior by
injecting targeted concept vectors during inference, offers a lightweight,
training-free alternative. However, current approaches depend on manually
crafted samples and fixed steering strategies, limiting automation and
adaptability. To overcome these challenges, we propose MASteer, the first
end-to-end framework for trustworthiness repair in LLMs based on representation
engineering. MASteer integrates two core components: AutoTester, a multi-agent
system that generates diverse, high-quality steer samples tailored to developer
needs; and AutoRepairer, which constructs adaptive steering strategies with
anchor vectors for automated, context-aware strategy selection during
inference. Experiments on standard and customized trustworthiness tasks show
MASteer consistently outperforms baselines, improving metrics by 15.36% on
LLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model
capabilities. MASteer demonstrates strong robustness, generalization, and
practical value for scalable, efficient trustworthiness repair.

</details>


### [352] [MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA](https://arxiv.org/abs/2508.07022)
*Shengtao Wen,Haodong Chen,Yadong Wang,Zhongying Pan,Xiang Chen,Yu Tian,Bo Qian,Dong Liang,Sheng-Jun Huang*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文提出了MultiMedEdit，首个针对临床多模态任务的知识编辑（KE）基准，填补了多模态医学场景中KE的研究空白。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法主要针对文本领域，缺乏对多模态医学场景的关注，而医学KE需要结合视觉推理以支持临床决策的安全性和可解释性。

Method: 提出MultiMedEdit基准，涵盖理解和推理任务类型，定义三维度量标准（可靠性、通用性和局部性），支持跨范式比较。

Result: 实验表明当前方法在泛化和长尾推理方面表现不佳，尤其是在复杂临床工作流中。效率分析揭示了实际部署中的权衡。

Conclusion: MultiMedEdit揭示了当前方法的局限性，并为未来开发临床鲁棒的知识编辑技术奠定了基础。

Abstract: Knowledge editing (KE) provides a scalable approach for updating factual
knowledge in large language models without full retraining. While previous
studies have demonstrated effectiveness in general domains and medical QA
tasks, little attention has been paid to KE in multimodal medical scenarios.
Unlike text-only settings, medical KE demands integrating updated knowledge
with visual reasoning to support safe and interpretable clinical decisions. To
address this gap, we propose MultiMedEdit, the first benchmark tailored to
evaluating KE in clinical multimodal tasks. Our framework spans both
understanding and reasoning task types, defines a three-dimensional metric
suite (reliability, generality, and locality), and supports cross-paradigm
comparisons across general and domain-specific models. We conduct extensive
experiments under single-editing and lifelong-editing settings. Results suggest
that current methods struggle with generalization and long-tail reasoning,
particularly in complex clinical workflows. We further present an efficiency
analysis (e.g., edit latency, memory footprint), revealing practical trade-offs
in real-world deployment across KE paradigms. Overall, MultiMedEdit not only
reveals the limitations of current approaches but also provides a solid
foundation for developing clinically robust knowledge editing techniques in the
future.

</details>


### [353] [Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach](https://arxiv.org/abs/2508.07063)
*Naseem Machlovi,Maryam Saleki,Innocent Ababio,Ruhul Amin*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文探讨了LLMs在内容审核中的局限性，提出了一个评估框架和微调模型SafePhi，表现优于现有基准。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统融入日常生活，对安全可靠的内容审核需求增加，但LLMs在道德推理和偏见检测方面存在不足。

Method: 开发了一个基于SOTA模型的实验框架，评估人类情感和攻击性行为，并引入统一基准数据集和微调模型SafePhi。

Result: SafePhi在Macro F1得分上优于OpenAI Moderator和Llama Guard，达到0.89。

Conclusion: LLMs在内容审核中仍有不足，需结合更多异构数据和人类参与以提高鲁棒性和可解释性。

Abstract: As AI systems become more integrated into daily life, the need for safer and
more reliable moderation has never been greater. Large Language Models (LLMs)
have demonstrated remarkable capabilities, surpassing earlier models in
complexity and performance. Their evaluation across diverse tasks has
consistently showcased their potential, enabling the development of adaptive
and personalized agents. However, despite these advancements, LLMs remain prone
to errors, particularly in areas requiring nuanced moral reasoning. They
struggle with detecting implicit hate, offensive language, and gender biases
due to the subjective and context-dependent nature of these issues. Moreover,
their reliance on training data can inadvertently reinforce societal biases,
leading to inconsistencies and ethical concerns in their outputs. To explore
the limitations of LLMs in this role, we developed an experimental framework
based on state-of-the-art (SOTA) models to assess human emotions and offensive
behaviors. The framework introduces a unified benchmark dataset encompassing 49
distinct categories spanning the wide spectrum of human emotions, offensive and
hateful text, and gender and racial biases. Furthermore, we introduced SafePhi,
a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and
outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where
OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This
research also highlights the critical domains where LLM moderators consistently
underperformed, pressing the need to incorporate more heterogeneous and
representative data with human-in-the-loop, for better model robustness and
explainability.

</details>


### [354] [Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach](https://arxiv.org/abs/2508.07353)
*Rubing Chen,Jiaxin Wu,Jian Wang,Xulu Zhang,Wenqi Fan,Chenghua Lin,Xiao-Yong Wei,Qing Li*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文提出Comp-Comp框架，基于全面性和紧凑性原则构建领域特定基准测试，挑战了传统依赖规模扩展的方法。


<details>
  <summary>Details</summary>
Motivation: 现有领域特定基准测试主要依赖规模扩展，但语料和QA集设计对模型精度和召回率的影响尚未研究。

Method: 提出Comp-Comp框架，通过全面性确保语义召回，紧凑性提升精度，指导语料和QA集构建。

Result: 案例研究中构建了XUBench，验证了框架的有效性，并展示了其跨领域扩展潜力。

Conclusion: Comp-Comp框架为领域特定基准测试提供了新思路，适用于多领域。

Abstract: Numerous benchmarks have been built to evaluate the domain-specific abilities
of large language models (LLMs), highlighting the need for effective and
efficient benchmark construction. Existing domain-specific benchmarks primarily
focus on the scaling law, relying on massive corpora for supervised fine-tuning
or generating extensive question sets for broad coverage. However, the impact
of corpus and question-answer (QA) set design on the precision and recall of
domain-specific LLMs remains unexplored. In this paper, we address this gap and
demonstrate that the scaling law is not always the optimal principle for
benchmark construction in specific domains. Instead, we propose Comp-Comp, an
iterative benchmarking framework based on a comprehensiveness-compactness
principle. Here, comprehensiveness ensures semantic recall of the domain, while
compactness enhances precision, guiding both corpus and QA set construction. To
validate our framework, we conducted a case study in a well-renowned
university, resulting in the creation of XUBench, a large-scale and
comprehensive closed-domain benchmark. Although we use the academic domain as
the case in this work, our Comp-Comp framework is designed to be extensible
beyond academia, providing valuable insights for benchmark construction across
various domains.

</details>


### [355] [Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs](https://arxiv.org/abs/2508.07466)
*Dom Huh,Prasant Mohapatra*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出了一种多智能体大语言模型（LLM）系统框架，结合了多智能体决策算法，重点关注提示工程、记忆架构、多模态处理和微调对齐。


<details>
  <summary>Details</summary>
Motivation: 语言是协作和推理的基础，通过多智能体LLM提升沟通与协调能力。

Method: 集成多智能体决策算法，设计提示工程、记忆架构、多模态处理和微调对齐策略。

Result: 在经典游戏场景中通过消融实验验证了设计选择的有效性。

Conclusion: 多智能体LLM框架能有效提升协作与决策能力。

Abstract: Language is a ubiquitous tool that is foundational to reasoning and
collaboration, ranging from everyday interactions to sophisticated
problem-solving tasks. The establishment of a common language can serve as a
powerful asset in ensuring clear communication and understanding amongst
agents, facilitating desired coordination and strategies. In this work, we
extend the capabilities of large language models (LLMs) by integrating them
with advancements in multi-agent decision-making algorithms. We propose a
systematic framework for the design of multi-agentic large language models
(LLMs), focusing on key integration practices. These include advanced prompt
engineering techniques, the development of effective memory architectures,
multi-modal information processing, and alignment strategies through
fine-tuning algorithms. We evaluate these design choices through extensive
ablation studies on classic game settings with significant underlying social
dilemmas and game-theoretic considerations.

</details>


### [356] [Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy](https://arxiv.org/abs/2508.07485)
*Alexander Duffy,Samuel J Paech,Ishana Shastri,Elizabeth Karpinski,Baptiste Alloui-Cros,Tyler Marques,Matthew Lyle Olson*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出了一种无需微调即可评估LLMs在复杂游戏Diplomacy中表现的工具，并分析了模型表现。


<details>
  <summary>Details</summary>
Motivation: 解决Diplomacy游戏的高复杂性和信息密度导致的研究障碍，无需依赖前沿LLMs或微调。

Method: 通过数据驱动优化游戏状态表示，开发工具支持假设测试和统计分析，并引入Critical State Analysis协议。

Result: 较大模型表现最佳，但较小模型仍能胜任；提供了对战略推理能力的自然涌现的洞察。

Conclusion: 该工具为LLMs战略推理评估提供了民主化方法，并揭示了能力的自然形成。

Abstract: We present the first evaluation harness that enables any out-of-the-box,
local, Large Language Models (LLMs) to play full-press Diplomacy without
fine-tuning or specialized training. Previous work required frontier LLMs, or
fine-tuning, due to the high complexity and information density of Diplomacy's
game state. Combined with the high variance of matches, these factors made
Diplomacy prohibitive for study. In this work, we used data-driven iteration to
optimize a textual game state representation such that a 24B model can reliably
complete matches without any fine tuning. We develop tooling to facilitate
hypothesis testing and statistical analysis, and we present case studies on
persuasion, aggressive playstyles, and performance across a range of models. We
conduct a variety of experiments across many popular LLMs, finding the larger
models perform the best, but the smaller models still play adequately. We also
introduce Critical State Analysis: an experimental protocol for rapidly
iterating and analyzing key moments in a game at depth. Our harness
democratizes the evaluation of strategic reasoning in LLMs by eliminating the
need for fine-tuning, and it provides insights into how these capabilities
emerge naturally from widely used LLMs. Our code is available in the supplement
and will be open sourced.

</details>


### [357] [MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark](https://arxiv.org/abs/2508.07575)
*Shiqing Fan,Xichen Ding,Liang Zhang,Linjian Mo*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出MCPToolBench++，一个用于评估LLMs调用MCP工具能力的大规模多领域基准。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法缺乏全面数据集和统一标准，且MCP工具调用成功率不稳定，需解决这些问题。

Method: 构建基于4000多个MCP服务器的多领域数据集，涵盖单步和多步工具调用。

Result: 评估了具备代理能力的SOTA LLMs，并报告结果。

Conclusion: MCPToolBench++为评估LLMs的MCP工具调用能力提供了有效基准。

Abstract: LLMs' capabilities are enhanced by using function calls to integrate various
data sources or API results into the context window. Typical tools include
search, web crawlers, maps, financial data, file systems, and browser usage,
etc. Integrating these data sources or functions requires a standardized
method. The Model Context Protocol (MCP) provides a standardized way to supply
context to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use
abilities suffer from several issues. First, there's a lack of comprehensive
datasets or benchmarks to evaluate various MCP tools. Second, the diverse
formats of response from MCP tool call execution further increase the
difficulty of evaluation. Additionally, unlike existing tool-use benchmarks
with high success rates in functions like programming and math functions, the
success rate of real-world MCP tool is not guaranteed and varies across
different MCP servers. Furthermore, the LLMs' context window also limits the
number of available tools that can be called in a single run, because the
textual descriptions of tool and the parameters have long token length for an
LLM to process all at once. To help address the challenges of evaluating LLMs'
performance on calling MCP tools, we propose MCPToolBench++, a large-scale,
multi-domain AI Agent tool use benchmark. As of July 2025, this benchmark is
build upon marketplace of over 4k MCP servers from more than 40 categories,
collected from the MCP marketplaces and GitHub communities. The datasets
consist of both single-step and multi-step tool calls across different
categories. We evaluated SOTA LLMs with agentic abilities on this benchmark and
reported the results.

</details>


### [358] [HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol](https://arxiv.org/abs/2508.07602)
*Wenpeng Xing,Zhipeng Chen,Changting Lin,Meng Han*

Main category: cs.AI

Relevance: 85.0

TL;DR: HGMF是一种概率剪枝方法，通过分层高斯混合模型提高LLM工具选择的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在大规模、分层结构工具库中选择正确工具的挑战，减少噪声和计算成本。

Method: HGMF将查询和工具描述映射到统一语义空间，分两阶段进行高斯混合模型聚类和过滤，生成高相关性候选集。

Result: 实验表明HGMF显著提高工具选择准确性并降低推理延迟。

Conclusion: HGMF适用于大规模工具库，具有可扩展性和高效性。

Abstract: Invoking external tools enables Large Language Models (LLMs) to perform
complex, real-world tasks, yet selecting the correct tool from large,
hierarchically-structured libraries remains a significant challenge. The
limited context windows of LLMs and noise from irrelevant options often lead to
low selection accuracy and high computational costs. To address this, we
propose the Hierarchical Gaussian Mixture Framework (HGMF), a probabilistic
pruning method for scalable tool invocation. HGMF first maps the user query and
all tool descriptions into a unified semantic space. The framework then
operates in two stages: it clusters servers using a Gaussian Mixture Model
(GMM) and filters them based on the query's likelihood. Subsequently, it
applies the same GMM-based clustering and filtering to the tools associated
with the selected servers. This hierarchical process produces a compact,
high-relevance candidate set, simplifying the final selection task for the LLM.
Experiments on a public dataset show that HGMF significantly improves tool
selection accuracy while reducing inference latency, confirming the framework's
scalability and effectiveness for large-scale tool libraries.

</details>


### [359] [ThinkTuning: Instilling Cognitive Reflections without Distillation](https://arxiv.org/abs/2508.07616)
*Aswin RRV,Jacob Dineen,Divij Handa,Md Nayem Uddin,Mihir Parmar,Chitta Baral,Ben Zhou*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文提出ThinkTuning方法，通过教师模型对学生模型的反馈指导，提升其推理能力，实验显示在多任务基准上有显著改进。


<details>
  <summary>Details</summary>
Motivation: 研究发现RL仅能激发基模型已有的推理行为，而无法真正赋予新能力，因此探索如何训练不具备此类行为的模型。

Method: 采用GRPO框架，教师模型通过反馈指导学生模型，类似课堂互动，逐步提升学生模型的推理能力。

Result: 在多个基准测试中，ThinkTuning平均提升3.85%，在MATH-500、AIME和GPQA-Diamond上分别提升2.08%、2.23%和3.99%。

Conclusion: ThinkTuning通过教师模型的反馈指导，有效提升了学生模型的推理能力。

Abstract: Recent advances in test-time scaling have led to the emergence of thinking
LLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL
drives this self-improvement paradigm, a recent study (Gandhi et al., 2025)
shows that RL alone does not truly instill these new reasoning abilities - it
merely draws out behaviors already present in the base models. This raises a
question: How can we train the models that don't exhibit such thinking behavior
to develop it in the first place? To this end, we propose ThinkTuning, a
GRPO-based interactive training approach where we augment the rollouts of a
student model with the guidance from a teacher model. A simple idea from
classroom practice inspires our method: a teacher poses a problem, lets the
student try an answer, then gives corrective feedback -- enough to point the
mind in the right direction and then show the solution. Each piece of feedback
reshapes the student's thoughts, leading them to arrive at the correct
solution. Similarly, we find that this type of implicit supervision through
feedback from a teacher model of the same size improves the reasoning
capabilities of the student model. In particular, on average, our method shows
a 3.85% improvement over zero-shot baselines across benchmarks, and on
MATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements
over the vanilla-GRPO baseline. Source code is available at
https://github.com/3rdAT/ThinkTuning.

</details>


### [360] [1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning](https://arxiv.org/abs/2508.07667)
*Wenkai Li,Liwen Sun,Zhenxiang Guan,Xuhui Zhou,Maarten Sap*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出了一种多智能体框架，通过分解隐私推理任务减少信息负载，显著降低隐私信息泄露。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在多源信息处理中的上下文隐私问题。

Method: 采用多智能体框架分解隐私推理任务，并进行信息流拓扑的系统消融实验。

Result: 在ConfAIde和PrivacyLens基准测试中，隐私泄露减少18%-19%，且保持公共内容保真度。

Conclusion: 多智能体系统的信息流设计在LLM上下文隐私中具有潜力。

Abstract: Addressing contextual privacy concerns remains challenging in interactive
settings where large language models (LLMs) process information from multiple
sources (e.g., summarizing meetings with private and public information). We
introduce a multi-agent framework that decomposes privacy reasoning into
specialized subtasks (extraction, classification), reducing the information
load on any single agent while enabling iterative validation and more reliable
adherence to contextual privacy norms. To understand how privacy errors emerge
and propagate, we conduct a systematic ablation over information-flow
topologies, revealing when and why upstream detection mistakes cascade into
downstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with
several open-source and closed-sourced LLMs demonstrate that our best
multi-agent configuration substantially reduces private information leakage
(\textbf{18\%} on ConfAIde and \textbf{19\%} on PrivacyLens with GPT-4o) while
preserving the fidelity of public content, outperforming single-agent
baselines. These results highlight the promise of principled information-flow
design in multi-agent systems for contextual privacy with LLMs.

</details>


### [361] [AdaptFlow: Adaptive Workflow Optimization via Meta-Learning](https://arxiv.org/abs/2508.08053)
*Runchuan Zhu,Bowen Jiang,Lingrui Mei,Fangkai Yang,Lu Wang,Haoxiang Gao,Fengshuo Bai,Pu Zhao,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

Relevance: 85.0

TL;DR: AdaptFlow是一个基于自然语言的元学习框架，通过学习可泛化的工作流初始化，快速适应不同子任务，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有代理工作流方法依赖静态模板或手动设计，适应性差且难以扩展。

Method: 采用双层次优化：内层通过LLM反馈优化子任务工作流，外层更新共享初始化以实现跨任务泛化。

Result: 在问答、代码生成和数学推理任务中表现优异，优于手动和自动基线。

Conclusion: AdaptFlow通过语言引导的修改实现强泛化能力，适用于多种任务和模型。

Abstract: Recent advances in large language models (LLMs) have sparked growing interest
in agentic workflows, which are structured sequences of LLM invocations
intended to solve complex tasks. However, existing approaches often rely on
static templates or manually designed workflows, which limit adaptability to
diverse tasks and hinder scalability. We propose AdaptFlow, a natural
language-based meta-learning framework inspired by model-agnostic meta-learning
(MAML). AdaptFlow learns a generalizable workflow initialization that enables
rapid subtask-level adaptation. It employs a bi-level optimization scheme: the
inner loop refines the workflow for a specific subtask using LLM-generated
feedback, while the outer loop updates the shared initialization to perform
well across tasks. This setup allows AdaptFlow to generalize effectively to
unseen tasks by adapting the initialized workflow through language-guided
modifications. Evaluated across question answering, code generation, and
mathematical reasoning benchmarks, AdaptFlow consistently outperforms both
manually crafted and automatically searched baselines, achieving
state-of-the-art results with strong generalization across tasks and models.
The source code and data are available at
https://github.com/microsoft/DKI_LLM/tree/AdaptFlow/AdaptFlow.

</details>


### [362] [TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork](https://arxiv.org/abs/2508.08115)
*Pranav Pushkar Mishra,Mohammad Arvan,Mohan Zalake*

Main category: cs.AI

Relevance: 85.0

TL;DR: TeamMedAgents将人类团队合作的心理学模型应用于医疗决策中的多智能体LLM系统，通过六个核心团队合作组件提升性能，在多个医疗基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 将人类团队合作的理论应用于多智能体LLM系统，以提升医疗决策的协作效果。

Method: 基于Salas的'Big Five'模型，实现六个团队合作组件（如团队领导力、共享心智模型等），并通过模块化架构评估不同任务和领域下的多智能体协作效果。

Result: 在8个医疗基准测试中，7个表现提升，并通过消融实验揭示了不同任务和领域的最优协作配置。

Conclusion: TeamMedAgents为关键决策领域的多智能体系统设计提供了基于证据的方法。

Abstract: We present TeamMedAgents, a novel multi-agent approach that systematically
integrates evidence-based teamwork components from human-human collaboration
into medical decision-making with large language models (LLMs). Our approach
validates an organizational psychology teamwork model from human collaboration
to computational multi-agent medical systems by operationalizing six core
teamwork components derived from Salas et al.'s "Big Five" model: team
leadership, mutual performance monitoring, team orientation, shared mental
models, closed-loop communication, and mutual trust. We implement and evaluate
these components as modular, configurable mechanisms within an adaptive
collaboration architecture while assessing the effect of the number of agents
involved based on the task's requirements and domain. Systematic evaluation of
computational implementations of teamwork behaviors across eight medical
benchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets,
Path-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8
evaluated datasets. Controlled ablation studies conducted on 50 questions per
configuration across 3 independent runs provide mechanistic insights into
individual component contributions, revealing optimal teamwork configurations
that vary by reasoning task complexity and domain-specific requirements. Our
ablation analyses reveal dataset-specific optimal teamwork configurations,
indicating that different medical reasoning modalities benefit from distinct
collaborative patterns. TeamMedAgents represents an advancement in
collaborative AI by providing a systematic translation of established teamwork
theories from human collaboration into agentic collaboration, establishing a
foundation for evidence-based multi-agent system design in critical
decision-making domains.

</details>


### [363] [BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks](https://arxiv.org/abs/2508.08127)
*Rui Miao,Yixin Liu,Yili Wang,Xu Shen,Yue Tan,Yiwei Dai,Shirui Pan,Xin Wang*

Main category: cs.AI

Relevance: 85.0

TL;DR: BlindGuard是一种无监督防御方法，用于检测LLM多智能体系统中的恶意代理，无需依赖标记数据或攻击先验知识。


<details>
  <summary>Details</summary>
Motivation: 现有监督防御方法依赖标记数据，实际应用中不切实际，因此提出无监督解决方案。

Method: 采用分层代理编码器捕捉个体、邻域和全局交互模式，结合噪声注入和对比学习训练检测模型。

Result: 实验表明BlindGuard能有效检测多种攻击类型，且泛化能力优于监督基线。

Conclusion: BlindGuard为多智能体系统提供了一种实用且通用的安全防御方案。

Abstract: The security of LLM-based multi-agent systems (MAS) is critically threatened
by propagation vulnerability, where malicious agents can distort collective
decision-making through inter-agent message interactions. While existing
supervised defense methods demonstrate promising performance, they may be
impractical in real-world scenarios due to their heavy reliance on labeled
malicious agents to train a supervised malicious detection model. To enable
practical and generalizable MAS defenses, in this paper, we propose BlindGuard,
an unsupervised defense method that learns without requiring any
attack-specific labels or prior knowledge of malicious behaviors. To this end,
we establish a hierarchical agent encoder to capture individual, neighborhood,
and global interaction patterns of each agent, providing a comprehensive
understanding for malicious agent detection. Meanwhile, we design a
corruption-guided detector that consists of directional noise injection and
contrastive learning, allowing effective detection model training solely on
normal agent behaviors. Extensive experiments show that BlindGuard effectively
detects diverse attack types (i.e., prompt injection, memory poisoning, and
tool attack) across MAS with various communication patterns while maintaining
superior generalizability compared to supervised baselines. The code is
available at: https://github.com/MR9812/BlindGuard.

</details>


### [364] [PiKV: KV Cache Management System for Mixture of Experts](https://arxiv.org/abs/2508.06526)
*Dong Liu,Yanxuan Yu,Ben Lengerich,Ying Nian Wu,Xuhong Wang*

Main category: cs.DC

Relevance: 85.0

TL;DR: PiKV是一个针对MoE架构的并行分布式KV缓存框架，通过专家分片存储、路由优化和调度策略减少KV缓存开销，并集成压缩模块降低内存使用。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模和上下文长度的增加，KV缓存的存储和通信成本成为多GPU和多节点推理的主要瓶颈，尤其是在MoE架构中。

Method: PiKV采用专家分片KV存储、PiKV路由减少访问、PiKV调度保留相关条目，并集成压缩模块优化内存。

Result: PiKV已开源，实验结果显示其能有效减少KV缓存开销，并与Nvidia kvpress集成加速。

Conclusion: PiKV旨在成为MoE架构的全面KV缓存管理系统，未来将继续优化。

Abstract: As large language models continue to scale up in both size and context
length, the memory and communication cost of key-value (KV) cache storage has
become a major bottleneck in multi-GPU and multi-node inference. While
MoE-based architectures sparsify computation across experts, the corresponding
KV caches remain dense and globally synchronized, resulting in significant
overhead.
  We introduce \textbf{PiKV}, a parallel and distributed KV cache serving
framework tailored for MoE architecture. PiKV leverages \textit{expert-sharded
KV storage} to partition caches across GPUs, \textit{PiKV routing} to reduce
token-to-KV access, and a \textit{PiKV Scheduling} to adaptively retain
query-relevant entries. To further reduce memory usage, PiKV integrates
\textit{PiKV Compression} modules the caching pipeline for acceleration.
  PiKV is recently publicly available as an open-source software library:
\href{https://github.com/NoakLiu/PiKV}{https://github.com/NoakLiu/PiKV}.
Experiments details is recorded at:
\href{https://github.com/NoakLiu/PiKV/blob/main/downstream_tasks/README.md}{https://github.com/NoakLiu/PiKV/Experimental\_Results}.
We also have PiKV integrated with Nvidia kvpress for acceleration, details see
\href{https://github.com/NoakLiu/PiKVpress}{https://github.com/NoakLiu/PiKVpress}.
PiKV is still a living project, aiming to become a comprehesive KV Cache
management system for MoE Architectures.

</details>


### [365] [Towards Integrated Alignment](https://arxiv.org/abs/2508.06592)
*Ben Y. Reis,William La Cava*

Main category: cs.CY

Relevance: 85.0

TL;DR: 论文提出了一种整合行为与表征方法的AI对齐框架，借鉴免疫学和网络安全经验，强调战略多样性和跨领域合作。


<details>
  <summary>Details</summary>
Motivation: 解决AI模型与人类偏好对齐的挑战，避免因方法分裂导致的模型脆弱性。

Method: 提出集成对齐框架设计原则，结合多种对齐方法的优势，强调战略多样性和自适应协同进化。

Result: 提出了一种整合行为与表征方法的对齐框架，并建议通过跨领域合作和资源共享统一研究领域。

Conclusion: 整合行为与表征方法的对齐框架能提升AI模型的鲁棒性，需通过跨领域合作推动研究统一。

Abstract: As AI adoption expands across human society, the problem of aligning AI
models to match human preferences remains a grand challenge. Currently, the AI
alignment field is deeply divided between behavioral and representational
approaches, resulting in narrowly aligned models that are more vulnerable to
increasingly deceptive misalignment threats. In the face of this fragmentation,
we propose an integrated vision for the future of the field. Drawing on related
lessons from immunology and cybersecurity, we lay out a set of design
principles for the development of Integrated Alignment frameworks that combine
the complementary strengths of diverse alignment approaches through deep
integration and adaptive coevolution. We highlight the importance of strategic
diversity - deploying orthogonal alignment and misalignment detection
approaches to avoid homogeneous pipelines that may be "doomed to success". We
also recommend steps for greater unification of the AI alignment research field
itself, through cross-collaboration, open model weights and shared community
resources.

</details>


### [366] [ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability](https://arxiv.org/abs/2508.07050)
*Wenhan Liu,Xinyu Ma,Weiwei Sun,Yutao Zhu,Yuchen Li,Dawei Yin,Zhicheng Dou*

Main category: cs.IR

Relevance: 85.0

TL;DR: 论文提出了一种自动化合成推理密集型训练数据的框架，并设计了两阶段的后训练方法（SFT和RL），显著提升了列表排序性能。


<details>
  <summary>Details</summary>
Motivation: 现有重排序器在复杂排序场景中表现不佳，主要因缺乏推理密集型训练数据。

Method: 1. 自动化合成推理密集型训练数据；2. 两阶段后训练（SFT和RL），设计多视图排序奖励。

Result: 提出的ReasonRank在BRIGHT排行榜上达到SOTA性能40.6，延迟显著低于基线。

Conclusion: 通过数据合成和两阶段训练，显著提升了推理密集型排序器的性能。

Abstract: Large Language Model (LLM) based listwise ranking has shown superior
performance in many passage ranking tasks. With the development of Large
Reasoning Models, many studies have demonstrated that step-by-step reasoning
during test-time helps improve listwise ranking performance. However, due to
the scarcity of reasoning-intensive training data, existing rerankers perform
poorly in many complex ranking scenarios and the ranking ability of
reasoning-intensive rerankers remains largely underdeveloped. In this paper, we
first propose an automated reasoning-intensive training data synthesis
framework, which sources training queries and passages from diverse domains and
applies DeepSeek-R1 to generate high-quality training labels. A
self-consistency data filtering mechanism is designed to ensure the data
quality. To empower the listwise reranker with strong reasoning ability, we
further propose a two-stage post-training approach, which includes a cold-start
supervised fine-tuning (SFT) stage for reasoning pattern learning and a
reinforcement learning (RL) stage for further ranking ability enhancement.
During the RL stage, based on the nature of listwise ranking, we design a
multi-view ranking reward, which is more effective than a ranking metric-based
reward. Extensive experiments demonstrate that our trained reasoning-intensive
reranker \textbf{ReasonRank} outperforms existing baselines significantly and
also achieves much lower latency than pointwise reranker Rank1. \textbf{Through
further experiments, our ReasonRank has achieved state-of-the-art (SOTA)
performance 40.6 on the BRIGHT
leaderboard\footnote{https://brightbenchmark.github.io/}.} Our codes are
available at https://github.com/8421BCD/ReasonRank.

</details>


### [367] [Anatomy of a Machine Learning Ecosystem: 2 Million Models on Hugging Face](https://arxiv.org/abs/2508.06811)
*Benjamin Laufer,Hamidah Oderinwale,Jon Kleinberg*

Main category: cs.SI

Relevance: 85.0

TL;DR: 分析Hugging Face上186万个模型的微调谱系，发现模型家族内相似性高，但突变快速且定向，揭示了开源机器学习生态的演化趋势。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI模型的微调谱系及其演化模式，填补对模型家族结构和互动的实证研究空白。

Method: 利用Hugging Face平台数据，构建模型家族树，分析模型元数据和模型卡，测量遗传相似性和突变特征。

Result: 模型家族内相似性高，但突变快速且定向；开源生态中许可证、语言兼容性和模型卡内容呈现特定演化趋势。

Conclusion: 生态学方法可用于理解模型微调，揭示了开源机器学习生态的独特演化模式。

Abstract: Many have observed that the development and deployment of generative machine
learning (ML) and artificial intelligence (AI) models follow a distinctive
pattern in which pre-trained models are adapted and fine-tuned for specific
downstream tasks. However, there is limited empirical work that examines the
structure of these interactions. This paper analyzes 1.86 million models on
Hugging Face, a leading peer production platform for model development. Our
study of model family trees -- networks that connect fine-tuned models to their
base or parent -- reveals sprawling fine-tuning lineages that vary widely in
size and structure. Using an evolutionary biology lens to study ML models, we
use model metadata and model cards to measure the genetic similarity and
mutation of traits over model families. We find that models tend to exhibit a
family resemblance, meaning their genetic markers and traits exhibit more
overlap when they belong to the same model family. However, these similarities
depart in certain ways from standard models of asexual reproduction, because
mutations are fast and directed, such that two `sibling' models tend to exhibit
more similarity than parent/child pairs. Further analysis of the directional
drifts of these mutations reveals qualitative insights about the open machine
learning ecosystem: Licenses counter-intuitively drift from restrictive,
commercial licenses towards permissive or copyleft licenses, often in violation
of upstream license's terms; models evolve from multi-lingual compatibility
towards english-only compatibility; and model cards reduce in length and
standardize by turning, more often, to templates and automatically generated
text. Overall, this work takes a step toward an empirically grounded
understanding of model fine-tuning and suggests that ecological models and
methods can yield novel scientific insights.

</details>


### [368] [Highlight All the Phrases: Enhancing LLM Transparency through Visual Factuality Indicators](https://arxiv.org/abs/2508.06846)
*Hyo Jin Do,Rachel Ostrand,Werner Geyer,Keerthiram Murugesan,Dennis Wei,Justin Weisz*

Main category: cs.HC

Relevance: 85.0

TL;DR: 研究探讨了如何通过设计策略有效传达LLM生成内容的真实性评分，发现用户更信任并偏好基于真实性评分的颜色编码设计。


<details>
  <summary>Details</summary>
Motivation: LLM易生成虚假信息，但现有研究较少关注如何向用户有效传达这些信息的真实性。

Method: 通过两项场景实验（共208名参与者），比较不同设计策略对用户信任、验证准确性和偏好的影响。

Result: 用户更信任且偏好颜色编码设计，认为其更易验证准确性。

Conclusion: 研究为LLM应用开发者提供了实用设计指南，旨在校准用户信任并增强对输出的审查能力。

Abstract: Large language models (LLMs) are susceptible to generating inaccurate or
false information, often referred to as "hallucinations" or "confabulations."
While several technical advancements have been made to detect hallucinated
content by assessing the factuality of the model's responses, there is still
limited research on how to effectively communicate this information to users.
To address this gap, we conducted two scenario-based experiments with a total
of 208 participants to systematically compare the effects of various design
strategies for communicating factuality scores by assessing participants'
ratings of trust, ease in validating response accuracy, and preference. Our
findings reveal that participants preferred and trusted a design in which all
phrases within a response were color-coded based on factuality scores.
Participants also found it easier to validate accuracy of the response in this
style compared to a baseline with no style applied. Our study offers practical
design guidelines for LLM application developers and designers, aimed at
calibrating user trust, aligning with user preferences, and enhancing users'
ability to scrutinize LLM outputs.

</details>


### [369] [CLAP: Coreference-Linked Augmentation for Passage Retrieval](https://arxiv.org/abs/2508.06941)
*Huanwei Xu,Lin Xu,Liang Yuan*

Main category: cs.IR

Relevance: 85.0

TL;DR: CLAP是一种基于LLM的轻量级段落扩展框架，通过解决指代链和生成局部伪查询来提升密集检索器的性能，尤其在跨域场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LLM扩展方法在密集检索器中因语义漂移和与预训练语义空间不对齐而表现不佳，且段落中仅部分内容与查询相关，其余部分引入噪声。

Method: CLAP将段落分割为连贯块，解析指代链，生成与密集检索器表示对齐的局部伪查询，并融合全局和细粒度信号。

Result: CLAP显著提升密集检索器性能，尤其在跨域场景中，nDCG@10绝对提升达20.68%。

Conclusion: CLAP通过逻辑中心化流程实现稳健、领域无关的泛化，优于传统依赖领域知识的LLM扩展方法。

Abstract: Large Language Model (LLM)-based passage expansion has shown promise for
enhancing first-stage retrieval, but often underperforms with dense retrievers
due to semantic drift and misalignment with their pretrained semantic space.
Beyond this, only a portion of a passage is typically relevant to a query,
while the rest introduces noise--an issue compounded by chunking techniques
that break coreference continuity. We propose Coreference-Linked Augmentation
for Passage Retrieval (CLAP), a lightweight LLM-based expansion framework that
segments passages into coherent chunks, resolves coreference chains, and
generates localized pseudo-queries aligned with dense retriever
representations. A simple fusion of global topical signals and fine-grained
subtopic signals achieves robust performance across domains. CLAP yields
consistent gains even as retriever strength increases, enabling dense
retrievers to match or surpass second-stage rankers such as BM25 + MonoT5-3B,
with up to 20.68% absolute nDCG@10 improvement. These improvements are
especially notable in out-of-domain settings, where conventional LLM-based
expansion methods relying on domain knowledge often falter. CLAP instead adopts
a logic-centric pipeline that enables robust, domain-agnostic generalization.

</details>


### [370] [When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust "APIs'' for Human-AI Interaction](https://arxiv.org/abs/2508.06942)
*Zhenchang Xing,Yang Liu,Zhuo Cheng,Qing Huang,Dehai Zhao,Daniel Sun,Chenhua Liu*

Main category: cs.SE

Relevance: 85.0

TL;DR: 论文提出了一种名为CNL-P的受控自然语言提示方法，结合了提示工程和软件工程原则，以提高LLM输出的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM能力的提升，其在多个领域的应用日益广泛，但自然语言提示的模糊性限制了其效果。CNL-P旨在通过结构化语法和语义规范消除这种模糊性。

Method: CNL-P引入了精确的语法结构和严格的语义规范，并开发了NL2CNL-P转换工具和语法检查工具。

Result: 实验表明，CNL-P显著提升了LLM响应的质量，通过结合提示工程和软件工程实现了新颖的协同效应。

Conclusion: CNL-P为以自然语言为中心的新编程范式奠定了基础，弥合了提示工程与传统软件工程之间的差距。

Abstract: With the growing capabilities of large language models (LLMs), they are
increasingly applied in areas like intelligent customer service, code
generation, and knowledge management. Natural language (NL) prompts act as the
``APIs'' for human-LLM interaction. To improve prompt quality, best practices
for prompt engineering (PE) have been developed, including writing guidelines
and templates. Building on this, we propose Controlled NL for Prompt (CNL-P),
which not only incorporates PE best practices but also draws on key principles
from software engineering (SE). CNL-P introduces precise grammar structures and
strict semantic norms, further eliminating NL's ambiguity, allowing for a
declarative but structured and accurate expression of user intent. This helps
LLMs better interpret and execute the prompts, leading to more consistent and
higher-quality outputs. We also introduce an NL2CNL-P conversion tool based on
LLMs, enabling users to write prompts in NL, which are then transformed into
CNL-P format, thus lowering the learning curve of CNL-P. In particular, we
develop a linting tool that checks CNL-P prompts for syntactic and semantic
accuracy, applying static analysis techniques to NL for the first time.
Extensive experiments demonstrate that CNL-P enhances the quality of LLM
responses through the novel and organic synergy of PE and SE. We believe that
CNL-P can bridge the gap between emerging PE and traditional SE, laying the
foundation for a new programming paradigm centered around NL.

</details>


### [371] [Hide or Highlight: Understanding the Impact of Factuality Expression on User Trust](https://arxiv.org/abs/2508.07095)
*Hyo Jin Do,Werner Geyer*

Main category: cs.HC

Relevance: 85.0

TL;DR: 研究了四种披露AI生成内容事实性评估的方式对用户信任的影响，发现隐藏或模糊不准确内容能提高信任。


<details>
  <summary>Details</summary>
Motivation: 防止用户因盲目信任AI而做出错误决策，探索如何有效传达事实性评估。

Method: 测试四种披露策略（透明、关注、不透明、模糊）与基线对比，通过148人实验评估信任和答案质量。

Result: 不透明和模糊策略在保持答案质量的同时提高了用户信任。

Conclusion: 隐藏或模糊不准确内容有助于增强用户对AI的信任。

Abstract: Large language models are known to produce outputs that are plausible but
factually incorrect. To prevent people from making erroneous decisions by
blindly trusting AI, researchers have explored various ways of communicating
factuality estimates in AI-generated outputs to end-users. However, little is
known about whether revealing content estimated to be factually incorrect
influences users' trust when compared to hiding it altogether. We tested four
different ways of disclosing an AI-generated output with factuality
assessments: transparent (highlights less factual content), attention
(highlights factual content), opaque (removes less factual content), ambiguity
(makes less factual content vague), and compared them with a baseline response
without factuality information. We conducted a human subjects research (N =
148) using the strategies in question-answering scenarios. We found that the
opaque and ambiguity strategies led to higher trust while maintaining perceived
answer quality, compared to the other strategies. We discuss the efficacy of
hiding presumably less factual content to build end-user trust.

</details>


### [372] [A Real-Time, Self-Tuning Moderator Framework for Adversarial Prompt Detection](https://arxiv.org/abs/2508.07139)
*Ivan Zhang*

Main category: cs.CR

Relevance: 85.0

TL;DR: 论文提出了一种实时自调优（RTST）的调节框架，用于防御对抗性攻击，同时保持轻量级训练。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型的广泛应用，确保LLM的对齐性对信息安全至关重要。现有防御方法难以快速适应新攻击，或影响模型对良性提示的响应。

Method: 引入RTST调节框架，实时自适应防御对抗性攻击，并保持轻量级训练。

Result: 在Google的Gemini模型上实证评估，证明其优于传统微调或分类器模型。

Conclusion: 自适应、低侵入性的框架在防御越狱攻击方面具有优势。

Abstract: Ensuring LLM alignment is critical to information security as AI models
become increasingly widespread and integrated in society. Unfortunately, many
defenses against adversarial attacks and jailbreaking on LLMs cannot adapt
quickly to new attacks, degrade model responses to benign prompts, or introduce
significant barriers to scalable implementation. To mitigate these challenges,
we introduce a real-time, self-tuning (RTST) moderator framework to defend
against adversarial attacks while maintaining a lightweight training footprint.
We empirically evaluate its effectiveness using Google's Gemini models against
modern, effective jailbreaks. Our results demonstrate the advantages of an
adaptive, minimally intrusive framework for jailbreak defense over traditional
fine-tuning or classifier models.

</details>


### [373] [Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes](https://arxiv.org/abs/2508.07180)
*Zhe Zhang,Runlin Liu,Aishan Liu,Xingyu Liu,Xiang Gao,Hailong Sun*

Main category: cs.SE

Relevance: 85.0

TL;DR: CODE2BENCH是一个动态构建代码生成基准测试的端到端管道，解决了现有基准测试中的数据污染和测试严格性不足问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在软件开发中的广泛应用，需要更严格的评估方法以揭示模型在复杂代码生成任务中的真实性能。

Method: CODE2BENCH通过自动化动态更新、基于Scope Graph的依赖分析和属性测试（PBT）构建污染抵抗的基准测试。

Result: 评估16个LLMs显示，模型在跨语言任务中表现较差，但在Python任务中表现较好。

Conclusion: CODE2BENCH提供了一种动态、语言无关的基准测试构建方法，为LLMs在真实软件开发任务中的评估奠定了基础。

Abstract: As large language models LLMs) become increasingly integrated into software
development workflows, rigorously evaluating their performance on complex,
real-world code generation tasks has become essential. However, existing
benchmarks often suffer from data contamination and limited test rigor,
constraining their ability to reveal model failures effectively. To address
these, we present CODE2BENCH, a end-to-end pipeline for dynamically
constructing robust and contamination-resistant benchmarks from real-world
GitHub repositories. Specifically, CODE2BENCH introduces three key innovations:
(1) Automated Dynamism, achieved through periodic ingestion of recent code to
minimize training data contamination; (2) Scope Graph-based dependency
analysis, which enables structured classification of functions into benchmark
instances with controlled dependency levels (distinguishing between
Self-Contained (SC) tasks for cross-language evaluation and Weakly
Self-Contained (WSC) tasks involving permitted library usage); and (3)
Property-Based Testing (PBT) for the automated synthesis of rigorous test
suites to enable thorough functional verification. Using this pipeline, we
construct CODE2BENCH-2505, the first benchmark derived from 880 recent Python
projects spanning diverse domains, comprising 1,163 code generation tasks with
100% average branch coverage on ground-truth implementations. Extensive
evaluation of 16 LLMs using CODE2BENCH-2505 reveals that models consistently
struggle with SC tasks requiring complex, non-standard logic and cross-language
transfer, while showing relatively stronger performance on WSC tasks in Python.
Our work introduces a contamination-resistant, language-agnostic methodology
for dynamic benchmark construction, offering a principled foundation for the
comprehensive and realistic evaluation of LLMs on real-world software
development tasks.

</details>


### [374] [Can Smaller Large Language Models Evaluate Research Quality?](https://arxiv.org/abs/2508.07196)
*Mike Thelwall*

Main category: cs.DL

Relevance: 85.0

TL;DR: 论文评估了小型LLM（Gemma-3-27b-it）在研究质量评分中的表现，发现其与专家评分相关性较高，但不及大型LLM（如ChatGPT 4o）。结果表明，研究评分能力并非仅限最大型LLM。


<details>
  <summary>Details</summary>
Motivation: 探讨小型LLM是否具备与大型LLM类似的研究质量评分能力，以验证该能力是否为大型LLM的“涌现特性”。

Method: 使用Gemma-3-27b-it对104,187篇文章进行评分，并与专家评分及大型LLM（ChatGPT 4o和4o-mini）结果对比。

Result: Gemma-3-27b-it的评分与专家评分相关性为大型LLM的83.8%-94.7%，但评分较低且风格单一。重复评分未显著提升相关性。

Conclusion: 小型LLM可用于研究评分，适合成本敏感或离线处理需求场景，但大型LLM仍表现更优。

Abstract: Although both Google Gemini (1.5 Flash) and ChatGPT (4o and 4o-mini) give
research quality evaluation scores that correlate positively with expert scores
in nearly all fields, and more strongly that citations in most, it is not known
whether this is true for smaller Large Language Models (LLMs). In response,
this article assesses Google's Gemma-3-27b-it, a downloadable LLM (60Gb). The
results for 104,187 articles show that Gemma-3-27b-it scores correlate
positively with an expert research quality score proxy for all 34 Units of
Assessment (broad fields) from the UK Research Excellence Framework 2021. The
Gemma-3-27b-it correlations have 83.8% of the strength of ChatGPT 4o and 94.7%
of the strength of ChatGPT 4o-mini correlations. Differently from the two
larger LLMs, the Gemma-3-27b-it correlations do not increase substantially when
the scores are averaged across five repetitions, its scores tend to be lower,
and its reports are relatively uniform in style. Overall, the results show that
research quality score estimation can be conducted by offline LLMs, so this
capability is not an emergent property of the largest LLMs. Moreover, score
improvement through repetition is not a universal feature of LLMs. In
conclusion, although the largest LLMs still have the highest research
evaluation score estimation capability, smaller ones can also be used for this
task, and this can be helpful for cost saving or when secure offline processing
is needed.

</details>


### [375] [\(X\)-evolve: Solution space evolution powered by large language models](https://arxiv.org/abs/2508.07932)
*Yi Zhai,Zhiqiang Wei,Ruohan Li,Keyu Pan,Shuo Liu,Lu Zhang,Jianmin Ji,Wuyang Zhang,Yu Zhang,Yanyong Zhang*

Main category: cs.AI

Relevance: 80.0

TL;DR: 论文提出了一种名为X-evolve的新方法，通过进化解决方案空间而非单个解决方案，显著减少LLM调用成本，并在多个优化问题中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前结合LLM和进化算法的方法通常进化单个解决方案，导致高LLM调用成本，X-evolve旨在通过进化解决方案空间来解决这一问题。

Method: X-evolve通过LLM生成可调程序，定义可调解决方案空间，并使用基于分数的搜索算法高效探索该空间。

Result: 在三个优化问题中表现突出：发现更大的部分可容许集（cap set问题）、更大的独立集（信息论问题）以及生成更优启发式（在线装箱问题）。

Conclusion: X-evolve通过进化解决方案空间显著提高了搜索效率，适用于高维问题。

Abstract: While combining large language models (LLMs) with evolutionary algorithms
(EAs) shows promise for solving complex optimization problems, current
approaches typically evolve individual solutions, often incurring high LLM call
costs. We introduce \(X\)-evolve, a paradigm-shifting method that instead
evolves solution spaces \(X\) (sets of individual solutions) - subsets of the
overall search space \(S\). In \(X\)-evolve, LLMs generate tunable programs
wherein certain code snippets, designated as parameters, define a tunable
solution space. A score-based search algorithm then efficiently explores this
parametrically defined space, guided by feedback from objective function
scores. This strategy enables broader and more efficient exploration, which can
potentially accelerate convergence at a much lower search cost, requiring up to
two orders of magnitude fewer LLM calls than prior leading methods. We
demonstrate \(X\)-evolve's efficacy across three distinct hard optimization
problems. For the cap set problem, we discover a larger partial admissible set,
establishing a new tighter asymptotic lower bound for the cap set constant (\(C
\ge 2.2203\)). In information theory, we uncover a larger independent set for
the 15-vertex cycle graph (\(\mathcal{C}_{15}^{\boxtimes 5}\), size 19,946),
thereby raising the known lower bound on its Shannon capacity. Furthermore, for
the NP-hard online bin packing problem, we generate heuristics that
consistently outperform standard strategies across established benchmarks. By
evolving solution spaces, our method considerably improves search
effectiveness, making it possible to tackle high-dimensional problems that were
previously computationally prohibitive.

</details>


### [376] [A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems](https://arxiv.org/abs/2508.07407)
*Jinyuan Fang,Yanwen Peng,Xi Zhang,Yingxu Wang,Xinhao Yi,Guibin Zhang,Yi Xu,Bin Wu,Siwei Liu,Zihao Li,Zhaochun Ren,Nikos Aletras,Xi Wang,Han Zhou,Zaiqiao Meng*

Main category: cs.AI

Relevance: 75.0

TL;DR: 该论文综述了自进化AI代理系统的技术，提出了一个统一框架，并探讨了评估、安全性和伦理问题。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统依赖静态配置，无法适应动态环境，因此需要研究自进化技术以实现持续适应性。

Method: 提出一个包含系统输入、代理系统、环境和优化器的统一框架，并系统回顾了针对不同组件的自进化技术。

Result: 总结了自进化代理系统的多种技术，并讨论了领域特定策略及评估、安全和伦理问题。

Conclusion: 自进化AI代理系统为开发更具适应性和自主性的代理系统奠定了基础。

Abstract: Recent advances in large language models have sparked growing interest in AI
agents capable of solving complex, real-world tasks. However, most existing
agent systems rely on manually crafted configurations that remain static after
deployment, limiting their ability to adapt to dynamic and evolving
environments. To this end, recent research has explored agent evolution
techniques that aim to automatically enhance agent systems based on interaction
data and environmental feedback. This emerging direction lays the foundation
for self-evolving AI agents, which bridge the static capabilities of foundation
models with the continuous adaptability required by lifelong agentic systems.
In this survey, we provide a comprehensive review of existing techniques for
self-evolving agentic systems. Specifically, we first introduce a unified
conceptual framework that abstracts the feedback loop underlying the design of
self-evolving agentic systems. The framework highlights four key components:
System Inputs, Agent System, Environment, and Optimisers, serving as a
foundation for understanding and comparing different strategies. Based on this
framework, we systematically review a wide range of self-evolving techniques
that target different components of the agent system. We also investigate
domain-specific evolution strategies developed for specialised fields such as
biomedicine, programming, and finance, where optimisation objectives are
tightly coupled with domain constraints. In addition, we provide a dedicated
discussion on the evaluation, safety, and ethical considerations for
self-evolving agentic systems, which are critical to ensuring their
effectiveness and reliability. This survey aims to provide researchers and
practitioners with a systematic understanding of self-evolving AI agents,
laying the foundation for the development of more adaptive, autonomous, and
lifelong agentic systems.

</details>


### [377] [Ethics2vec: aligning automatic agents and human preferences](https://arxiv.org/abs/2508.07673)
*Gianluca Bontempi*

Main category: cs.AI

Relevance: 75.0

TL;DR: 论文提出Ethics2Vec方法，通过向量化AI代理的决策策略来评估其与人类价值观的对齐，解决了伦理价值难以量化的问题。


<details>
  <summary>Details</summary>
Motivation: 解决AI系统与人类价值观对齐的挑战，尤其是在伦理价值难以量化的领域（如医疗决策）。

Method: 扩展Anything2vec方法，将代理的决策策略映射为多元向量表示，用于比较和评估与人类价值观的对齐。

Result: 提出了Ethics2Vec方法，适用于二元决策和自动控制场景（如自动驾驶）。

Conclusion: Ethics2Vec为伦理对齐提供了一种可量化的方法，适用于多种AI决策场景。

Abstract: Though intelligent agents are supposed to improve human experience (or make
it more efficient), it is hard from a human perspective to grasp the ethical
values which are explicitly or implicitly embedded in an agent behaviour. This
is the well-known problem of alignment, which refers to the challenge of
designing AI systems that align with human values, goals and preferences. This
problem is particularly challenging since most human ethical considerations
refer to \emph{incommensurable} (i.e. non-measurable and/or incomparable)
values and criteria. Consider, for instance, a medical agent prescribing a
treatment to a cancerous patient. How could it take into account (and/or weigh)
incommensurable aspects like the value of a human life and the cost of the
treatment? Now, the alignment between human and artificial values is possible
only if we define a common space where a metric can be defined and used. This
paper proposes to extend to ethics the conventional Anything2vec approach,
which has been successful in plenty of similar and hard-to-quantify domains
(ranging from natural language processing to recommendation systems and graph
analysis). This paper proposes a way to map an automatic agent decision-making
(or control law) strategy to a multivariate vector representation, which can be
used to compare and assess the alignment with human values. The Ethics2Vec
method is first introduced in the case of an automatic agent performing binary
decision-making. Then, a vectorisation of an automatic control law (like in the
case of a self-driving car) is discussed to show how the approach can be
extended to automatic control settings.

</details>


### [378] [Symmetry-Aware Transformer Training for Automated Planning](https://arxiv.org/abs/2508.07743)
*Markus Fritzsche,Elliot Gestrin,Jendrik Seipp*

Main category: cs.AI

Relevance: 75.0

TL;DR: 提出了一种对比学习目标，使Transformer能够感知对称性，从而解决其在自动规划任务中的局限性，并展示了其在多个规划领域的有效性。


<details>
  <summary>Details</summary>
Motivation: Transformer在自动规划领域的应用受限，尤其是面对问题对称性时表现不佳，导致难以从简单问题推广到复杂问题。

Method: 提出了一种新颖的对比学习目标，结合架构改进，使Transformer能够感知对称性，适用于规划生成或启发式预测。

Result: 在多个规划领域中，对称感知训练有效解决了PlanGPT的局限性。

Conclusion: 通过对称感知训练，Transformer在自动规划任务中的性能显著提升。

Abstract: While transformers excel in many settings, their application in the field of
automated planning is limited. Prior work like PlanGPT, a state-of-the-art
decoder-only transformer, struggles with extrapolation from easy to hard
planning problems. This in turn stems from problem symmetries: planning tasks
can be represented with arbitrary variable names that carry no meaning beyond
being identifiers. This causes a combinatorial explosion of equivalent
representations that pure transformers cannot efficiently learn from. We
propose a novel contrastive learning objective to make transformers
symmetry-aware and thereby compensate for their lack of inductive bias.
Combining this with architectural improvements, we show that transformers can
be efficiently trained for either plan-generation or heuristic-prediction. Our
results across multiple planning domains demonstrate that our symmetry-aware
training effectively and efficiently addresses the limitations of PlanGPT.

</details>


### [379] [AuthPrint: Fingerprinting Generative Models Against Malicious Model Providers](https://arxiv.org/abs/2508.05691)
*Kai Yao,Marc Juarez*

Main category: cs.CR

Relevance: 75.0

TL;DR: 论文提出了一种对抗性模型指纹技术，用于验证生成模型输出的来源，即使在模型提供者可能对抗的情况下也能有效工作。


<details>
  <summary>Details</summary>
Motivation: 生成模型在高风险领域应用广泛，但缺乏验证输出来源的机制。本文填补了这一空白，首次在对抗性威胁模型下评估指纹技术的有效性。

Method: 通过可信验证器从模型输出空间中提取秘密指纹，并训练模型预测和验证这些指纹。

Result: 实验表明，该方法在GAN和扩散模型上实现了接近零的FPR@95%TPR，即使对原始架构和训练数据进行微小修改也有效，且能抵抗对抗性攻击。

Conclusion: 该方法为生成模型输出来源验证提供了高效且鲁棒的解决方案。

Abstract: Generative models are increasingly adopted in high-stakes domains, yet
current deployments offer no mechanisms to verify the origin of model outputs.
We address this gap by extending model fingerprinting techniques beyond the
traditional collaborative setting to one where the model provider may act
adversarially. To our knowledge, this is the first work to evaluate
fingerprinting for provenance attribution under such a threat model. The
methods rely on a trusted verifier that extracts secret fingerprints from the
model's output space, unknown to the provider, and trains a model to predict
and verify them. Our empirical evaluation shows that our methods achieve
near-zero FPR@95%TPR for instances of GAN and diffusion models, even when
tested on small modifications to the original architecture and training data.
Moreover, the methods remain robust against adversarial attacks that actively
modify the outputs to bypass detection. Source codes are available at
https://github.com/PSMLab/authprint.

</details>


### [380] [HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches](https://arxiv.org/abs/2508.08088)
*Jiejun Tan,Zhicheng Dou,Yan Yu,Jiehan Cheng,Qiang Ju,Jian Xie,Ji-Rong Wen*

Main category: cs.IR

Relevance: 75.0

TL;DR: 提出了一种分层强化学习框架HierSearch，用于结合本地和Web搜索工具，提升深度搜索的性能。


<details>
  <summary>Details</summary>
Motivation: 企业需要结合本地和Web知识源的私有深度搜索系统，但现有方法效率低且难以掌握复杂工具。

Method: 采用分层强化学习，低层训练本地和Web搜索代理，高层由规划代理协调，并设计知识精炼器过滤错误信息。

Result: 在六个基准测试中优于平面强化学习和现有深度搜索方法。

Conclusion: HierSearch通过分层设计和知识精炼有效提升了多源深度搜索的性能。

Abstract: Recently, large reasoning models have demonstrated strong mathematical and
coding abilities, and deep search leverages their reasoning capabilities in
challenging information retrieval tasks. Existing deep search works are
generally limited to a single knowledge source, either local or the Web.
However, enterprises often require private deep search systems that can
leverage search tools over both local and the Web corpus. Simply training an
agent equipped with multiple search tools using flat reinforcement learning
(RL) is a straightforward idea, but it has problems such as low training data
efficiency and poor mastery of complex tools. To address the above issue, we
propose a hierarchical agentic deep search framework, HierSearch, trained with
hierarchical RL. At the low level, a local deep search agent and a Web deep
search agent are trained to retrieve evidence from their corresponding domains.
At the high level, a planner agent coordinates low-level agents and provides
the final answer. Moreover, to prevent direct answer copying and error
propagation, we design a knowledge refiner that filters out hallucinations and
irrelevant evidence returned by low-level agents. Experiments show that
HierSearch achieves better performance compared to flat RL, and outperforms
various deep search and multi-source retrieval-augmented generation baselines
in six benchmarks across general, finance, and medical domains.

</details>


### [381] [CROP: Integrating Topological and Spatial Structures via Cross-View Prefixes for Molecular LLMs](https://arxiv.org/abs/2508.06917)
*Jianting Tang,Yubo Wang,Haoyu Cao,Linli Xu*

Main category: q-bio.QM

Relevance: 75.0

TL;DR: 论文提出CROP方法，通过多视角整合提升LLM在分子科学中的理解能力，结合拓扑和空间结构视图，高效且有效。


<details>
  <summary>Details</summary>
Motivation: 分子科学中LLM仅依赖分子序列效果有限，需结合拓扑和空间结构视图以提升理解能力。

Method: 提出CROP框架，包含SMILES Guided Resampler和Structural Embedding Gate，整合多视图信息生成固定长度前缀。

Result: 实验表明CROP在分子描述、IUPAC命名和分子属性预测任务中表现优越。

Conclusion: CROP通过高效多视图整合显著提升LLM的分子理解能力。

Abstract: Recent advances in molecular science have been propelled significantly by
large language models (LLMs). However, their effectiveness is limited when
relying solely on molecular sequences, which fail to capture the complex
structures of molecules. Beyond sequence representation, molecules exhibit two
complementary structural views: the first focuses on the topological
relationships between atoms, as exemplified by the graph view; and the second
emphasizes the spatial configuration of molecules, as represented by the image
view. The two types of views provide unique insights into molecular structures.
To leverage these views collaboratively, we propose the CROss-view Prefixes
(CROP) to enhance LLMs' molecular understanding through efficient multi-view
integration. CROP possesses two advantages: (i) efficiency: by jointly
resampling multiple structural views into fixed-length prefixes, it avoids
excessive consumption of the LLM's limited context length and allows easy
expansion to more views; (ii) effectiveness: by utilizing the LLM's
self-encoded molecular sequences to guide the resampling process, it boosts the
quality of the generated prefixes. Specifically, our framework features a
carefully designed SMILES Guided Resampler for view resampling, and a
Structural Embedding Gate for converting the resulting embeddings into LLM's
prefixes. Extensive experiments demonstrate the superiority of CROP in tasks
including molecule captioning, IUPAC name prediction and molecule property
prediction.

</details>


### [382] [Selection and Exploitation of High-Quality Knowledge from Large Language Models for Recommendation](https://arxiv.org/abs/2508.07223)
*Guanchen Wang,Mingming Ha,Tianbao Ma,Linxun Chen,Zhaojie Liu,Guorui Zhou,Kun Gai*

Main category: cs.IR

Relevance: 75.0

TL;DR: 论文提出KSER框架，通过知识过滤和嵌入对齐模块，优化LLM生成的世界知识在推荐系统中的应用，解决幻觉和冗余问题。


<details>
  <summary>Details</summary>
Motivation: 利用LLM的泛化和推理能力提升推荐系统性能，但直接使用LLM生成的知识会导致性能下降。

Method: 设计了知识过滤模块（ESFNet）和嵌入对齐模块，并提出两种训练策略（全参数训练和提取器训练）。

Result: 实验验证了知识过滤和对齐模块的必要性，提取器训练策略表现出高效性和有效性。

Conclusion: KSER框架有效解决了LLM知识在推荐系统中的问题，为知识增强推荐提供了新视角。

Abstract: In recent years, there has been growing interest in leveraging the impressive
generalization capabilities and reasoning ability of large language models
(LLMs) to improve the performance of recommenders. With this operation,
recommenders can access and learn the additional world knowledge and reasoning
information via LLMs. However, in general, for different users and items, the
world knowledge derived from LLMs suffers from issues of hallucination, content
redundant, and information homogenization. Directly feeding the generated
response embeddings into the recommendation model can lead to unavoidable
performance deterioration. To address these challenges, we propose a Knowledge
Selection \& Exploitation Recommendation (KSER) framework, which effectively
select and extracts the high-quality knowledge from LLMs. The framework
consists of two key components: a knowledge filtering module and a embedding
spaces alignment module. In the knowledge filtering module, a Embedding
Selection Filter Network (ESFNet) is designed to assign adaptive weights to
different knowledge chunks in different knowledge fields. In the space
alignment module, an attention-based architecture is proposed to align the
semantic embeddings from LLMs with the feature space used to train the
recommendation models. In addition, two training
strategies--\textbf{all-parameters training} and \textbf{extractor-only
training}--are proposed to flexibly adapt to different downstream tasks and
application scenarios, where the extractor-only training strategy offers a
novel perspective on knowledge-augmented recommendation. Experimental results
validate the necessity and effectiveness of both the knowledge filtering and
alignment modules, and further demonstrate the efficiency and effectiveness of
the extractor-only training strategy.

</details>


### [383] [On the Limits of Selective AI Prediction: A Case Study in Clinical Decision Making](https://arxiv.org/abs/2508.07617)
*Sarah Jabbour,David Fouhey,Nikola Banovic,Stephanie D. Shepard,Ella Kazerooni,Michael W. Sjoding,Jenna Wiens*

Main category: cs.HC

Relevance: 75.0

TL;DR: 研究探讨了选择性预测（隐藏不可靠的AI预测）对临床决策的影响，发现其能减少不准确AI的负面影响，但会改变错误模式。


<details>
  <summary>Details</summary>
Motivation: 解决AI预测不准确和自动化偏差导致人类决策质量下降的问题。

Method: 在临床环境中对259名医生进行用户研究，比较无AI辅助、AI辅助及选择性预测下的决策准确性。

Result: 选择性预测恢复了决策准确性（64% vs. 无AI的66%），但增加了漏诊（18%）和漏治（35%）。

Conclusion: 需实证验证人类与AI交互的假设，选择性预测虽有效但需权衡错误模式变化。

Abstract: AI has the potential to augment human decision making. However, even
high-performing models can produce inaccurate predictions when deployed. These
inaccuracies, combined with automation bias, where humans overrely on AI
predictions, can result in worse decisions. Selective prediction, in which
potentially unreliable model predictions are hidden from users, has been
proposed as a solution. This approach assumes that when AI abstains and informs
the user so, humans make decisions as they would without AI involvement. To
test this assumption, we study the effects of selective prediction on human
decisions in a clinical context. We conducted a user study of 259 clinicians
tasked with diagnosing and treating hospitalized patients. We compared their
baseline performance without any AI involvement to their AI-assisted accuracy
with and without selective prediction. Our findings indicate that selective
prediction mitigates the negative effects of inaccurate AI in terms of decision
accuracy. Compared to no AI assistance, clinician accuracy declined when shown
inaccurate AI predictions (66% [95% CI: 56%-75%] vs. 56% [95% CI: 46%-66%]),
but recovered under selective prediction (64% [95% CI: 54%-73%]). However,
while selective prediction nearly maintains overall accuracy, our results
suggest that it alters patterns of mistakes: when informed the AI abstains,
clinicians underdiagnose (18% increase in missed diagnoses) and undertreat (35%
increase in missed treatments) compared to no AI input at all. Our findings
underscore the importance of empirically validating assumptions about how
humans engage with AI within human-AI systems.

</details>


### [384] [DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval](https://arxiv.org/abs/2508.07995)
*Meixiu Long,Duolin Sun,Dan Yang,Junjie Wang,Yue Shen,Jian Wang,Peng Wei,Jinjie Gu,Jiahai Wang*

Main category: cs.IR

Relevance: 75.0

TL;DR: DIVER是一个针对推理密集型信息检索的检索管道，通过改进输入质量、LLM驱动的查询扩展、推理增强的检索器和重排序器，显著提升了复杂任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有检索方法在抽象推理、类比思考或多步推理任务中的不足。

Method: 包括文档处理、LLM驱动的查询扩展、推理增强的检索器和结合LLM评分的重排序器。

Result: 在BRIGHT基准测试中，DIVER的nDCG@10得分达到41.6和28.9，优于其他推理感知模型。

Conclusion: 推理感知的检索策略在复杂任务中有效。

Abstract: Retrieval-augmented generation has achieved strong performance on
knowledge-intensive tasks where query-document relevance can be identified
through direct lexical or semantic matches. However, many real-world queries
involve abstract reasoning, analogical thinking, or multi-step inference, which
existing retrievers often struggle to capture. To address this challenge, we
present \textbf{DIVER}, a retrieval pipeline tailored for reasoning-intensive
information retrieval. DIVER consists of four components: document processing
to improve input quality, LLM-driven query expansion via iterative document
interaction, a reasoning-enhanced retriever fine-tuned on synthetic
multi-domain data with hard negatives, and a pointwise reranker that combines
LLM-assigned helpfulness scores with retrieval scores. On the BRIGHT benchmark,
DIVER achieves state-of-the-art nDCG@10 scores of 41.6 and 28.9 on original
queries, consistently outperforming competitive reasoning-aware models. These
results demonstrate the effectiveness of reasoning-aware retrieval strategies
in complex real-world tasks. Our code and retrieval model will be released
soon.

</details>


### [385] [LL3M: Large Language 3D Modelers](https://arxiv.org/abs/2508.08228)
*Sining Lu,Guan Chen,Nam Anh Dinh,Itai Lang,Ari Holtzman,Rana Hanocka*

Main category: cs.GR

Relevance: 75.0

TL;DR: LL3M是一个多智能体系统，利用预训练大语言模型（LLMs）通过编写可解释的Python代码在Blender中生成3D资产，将形状生成重新定义为代码编写任务。


<details>
  <summary>Details</summary>
Motivation: 传统生成方法依赖3D数据学习，而LL3M通过代码生成实现更高的模块化、可编辑性和与艺术家工作流的集成。

Method: LL3M协调多个专门化的LLM智能体，通过规划、检索、编写、调试和优化Blender脚本来生成和编辑几何与外观。

Result: 生成的代码作为高层次、可解释、人类可读的场景和对象表示，支持多样化的形状、材质和场景生成。

Conclusion: 代码作为生成和可解释的媒介在3D资产创建中具有强大潜力，支持智能体和用户的协同创作。

Abstract: We present LL3M, a multi-agent system that leverages pretrained large
language models (LLMs) to generate 3D assets by writing interpretable Python
code in Blender. We break away from the typical generative approach that learns
from a collection of 3D data. Instead, we reformulate shape generation as a
code-writing task, enabling greater modularity, editability, and integration
with artist workflows. Given a text prompt, LL3M coordinates a team of
specialized LLM agents to plan, retrieve, write, debug, and refine Blender
scripts that generate and edit geometry and appearance. The generated code
works as a high-level, interpretable, human-readable, well-documented
representation of scenes and objects, making full use of sophisticated Blender
constructs (e.g. B-meshes, geometry modifiers, shader nodes) for diverse,
unconstrained shapes, materials, and scenes. This code presents many avenues
for further agent and human editing and experimentation via code tweaks or
procedural parameters. This medium naturally enables a co-creative loop in our
system: agents can automatically self-critique using code and visuals, while
iterative user instructions provide an intuitive way to refine assets. A shared
code context across agents enables awareness of previous attempts, and a
retrieval-augmented generation knowledge base built from Blender API
documentation, BlenderRAG, equips agents with examples, types, and functions
empowering advanced modeling operations and code correctness. We demonstrate
the effectiveness of LL3M across diverse shape categories, style and material
edits, and user-driven refinements. Our experiments showcase the power of code
as a generative and interpretable medium for 3D asset creation. Our project
page is at https://threedle.github.io/ll3m.

</details>


### [386] [IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model](https://arxiv.org/abs/2508.06571)
*Anqing Jiang,Yu Gao,Yiru Wang,Zhigang Sun,Shuo Wang,Yuwen Heng,Hao Sun,Shichen Tang,Lijuan Zhu,Jinhao Chai,Jijun Wang,Zichong Gu,Hao Jiang,Li Sun*

Main category: cs.AI

Relevance: 70.0

TL;DR: 提出IRL-VLA框架，通过逆强化学习奖励世界模型和自建VLA方法解决自动驾驶中VLA模型的闭环训练挑战，在NAVSIM v2和CVPR2025竞赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLA模型在自动驾驶中因开环模仿学习和闭环训练依赖高保真模拟而导致的性能受限问题。

Method: 三阶段框架：1) 预训练VLA策略；2) 构建轻量级奖励世界模型；3) 通过PPO优化规划性能。

Result: 在NAVSIM v2和CVPR2025竞赛中取得领先成绩。

Conclusion: IRL-VLA框架为闭环自动驾驶的VLA研究提供了高效解决方案。

Abstract: Vision-Language-Action (VLA) models have demonstrated potential in autonomous
driving. However, two critical challenges hinder their development: (1)
Existing VLA architectures are typically based on imitation learning in
open-loop setup which tends to capture the recorded behaviors in the dataset,
leading to suboptimal and constrained performance, (2) Close-loop training
relies heavily on high-fidelity sensor simulation, where domain gaps and
computational inefficiencies pose significant barriers. In this paper, we
introduce IRL-VLA, a novel close-loop Reinforcement Learning via
\textbf{I}nverse \textbf{R}einforcement \textbf{L}earning reward world model
with a self-built VLA approach. Our framework proceeds in a three-stage
paradigm: In the first stage, we propose a VLA architecture and pretrain the
VLA policy via imitation learning. In the second stage, we construct a
lightweight reward world model via inverse reinforcement learning to enable
efficient close-loop reward computation. To further enhance planning
performance, finally, we design specialized reward world model guidence
reinforcement learning via PPO(Proximal Policy Optimization) to effectively
balance the safety incidents, comfortable driving, and traffic efficiency. Our
approach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving
benchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that
our framework will accelerate VLA research in close-loop autonomous driving.

</details>


### [387] [CountQA: How Well Do MLLMs Count in the Wild?](https://arxiv.org/abs/2508.06585)
*Jayant Sravan Tamarapalli,Rynaa Grover,Nilay Pande,Sahiti Yerramilli*

Main category: cs.AI

Relevance: 70.0

TL;DR: 论文提出了CountQA基准测试，用于评估多模态大语言模型（MLLMs）在复杂场景中的物体计数能力，揭示了当前模型的不足。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在物体计数能力上存在严重缺陷，限制了其在实际应用中的可靠性。现有基准测试未能充分测试复杂场景下的计数能力。

Method: 引入CountQA基准测试，包含1,500多个问答对，覆盖高密度、遮挡和杂乱的现实场景图像，并评估了15种主流MLLMs。

Result: 表现最佳的模型准确率仅为42.9%，且随着物体数量增加，性能下降。

Conclusion: CountQA为改进MLLMs的计数能力提供了诊断工具，推动模型在数值和空间感知上的进步。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in
understanding visual scenes, yet they exhibit a critical lack in a fundamental
cognitive skill: object counting. This blind spot severely limits their
reliability in real-world applications. To date, this capability has been
largely unevaluated in complex scenarios, as existing benchmarks either feature
sparse object densities or are confined to specific visual domains, failing to
test models under realistic conditions. Addressing this gap, we introduce
CountQA, a challenging new benchmark designed to probe this deficiency.
Comprising over 1,500 question-answer pairs, CountQA features real-world images
with high object density, clutter, and occlusion. We investigate this weakness
by evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the
top-performing model achieves a mere 42.9% accuracy, with performance declining
as object counts rise. By providing a dedicated benchmark to diagnose and
rectify this core weakness, CountQA paves the way for a new generation of MLLMs
that are not only descriptively fluent but also numerically grounded and
spatially aware. We will open-source the dataset and code upon paper acceptance
to foster further research.

</details>


### [388] [MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams](https://arxiv.org/abs/2508.06851)
*Pengfei Zhou,Xiaopeng Peng,Fanrui Zhang,Zhaopan Xu,Jiaxin Ai,Yansheng Qiu,Chuanhao Li,Zhen Li,Ming Li,Yukang Feng,Jianwen Sun,Haoquan Zhang,Zizhen Li,Xiaofeng Mao,Zekai Li,Wangbo Zhao,Kai Wang,Xiaojun Chang,Wenqi Shao,Yang You,Kaipeng Zhang*

Main category: cs.AI

Relevance: 70.0

TL;DR: MDK12-Bench是一个多学科的大规模基准测试，用于评估多模态大语言模型（MLLMs）的性能，覆盖141K实例和6,225个知识点，支持动态评估和知识驱动的推理。


<details>
  <summary>Details</summary>
Motivation: 当前MLLM的评测基准存在规模小、覆盖窄、知识无结构化等问题，无法全面评估模型性能。

Method: 提出MDK12-Bench基准和动态评估框架，结合知识增强生成（KP-RAG）分析模型表现。

Result: 发现当前MLLMs在多个维度上存在局限性，为模型鲁棒性和可解释性改进提供指导。

Conclusion: MDK12-Bench为MLLM的全面评测和AI辅助教育提供了新工具和方向。

Abstract: Multimodal large language models (MLLMs), which integrate language and visual
cues for problem-solving, are crucial for advancing artificial general
intelligence (AGI). However, current benchmarks for measuring the intelligence
of MLLMs suffer from limited scale, narrow coverage, and unstructured
knowledge, offering only static and undifferentiated evaluations. To bridge
this gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark
built from real-world K-12 exams spanning six disciplines with 141K instances
and 6,225 knowledge points organized in a six-layer taxonomy. Covering five
question formats with difficulty and year annotations, it enables comprehensive
evaluation to capture the extent to which MLLMs perform over four dimensions:
1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts,
and 4) knowledge-driven reasoning. We propose a novel dynamic evaluation
framework that introduces unfamiliar visual, textual, and question form shifts
to challenge model generalization while improving benchmark objectivity and
longevity by mitigating data contamination. We further evaluate knowledge-point
reference-augmented generation (KP-RAG) to examine the role of knowledge in
problem-solving. Key findings reveal limitations in current MLLMs in multiple
aspects and provide guidance for enhancing model robustness, interpretability,
and AI-assisted education.

</details>


### [389] [Pushdown Reward Machines for Reinforcement Learning](https://arxiv.org/abs/2508.06894)
*Giovanni Varricchione,Toryn Q. Klassen,Natasha Alechina,Mehdi Dastani,Brian Logan,Sheila A. McIlraith*

Main category: cs.AI

Relevance: 70.0

TL;DR: 论文提出了基于确定性下推自动机的奖励机器（pdRMs），扩展了传统奖励机器的表达能力，能够识别和奖励确定性上下文无关语言表示的行为。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机器（RMs）只能处理正则语言表示的行为，限制了其在复杂任务中的应用。pdRMs的提出旨在解决这一问题，提升强化学习在更广泛任务中的样本效率。

Method: 提出两种pdRM策略：一种可以访问整个堆栈，另一种仅能访问堆栈顶部的k个符号。提供了理论分析和实验验证。

Result: 理论证明了pdRMs的表达能力，实验展示了其在确定性上下文无关语言任务中的有效性。

Conclusion: pdRMs扩展了RMs的表达能力，为强化学习在复杂任务中的应用提供了新工具。

Abstract: Reward machines (RMs) are automata structures that encode (non-Markovian)
reward functions for reinforcement learning (RL). RMs can reward any behaviour
representable in regular languages and, when paired with RL algorithms that
exploit RM structure, have been shown to significantly improve sample
efficiency in many domains. In this work, we present pushdown reward machines
(pdRMs), an extension of reward machines based on deterministic pushdown
automata. pdRMs can recognize and reward temporally extended behaviours
representable in deterministic context-free languages, making them more
expressive than reward machines. We introduce two variants of pdRM-based
policies, one which has access to the entire stack of the pdRM, and one which
can only access the top $k$ symbols (for a given constant $k$) of the stack. We
propose a procedure to check when the two kinds of policies (for a given
environment, pdRM, and constant $k$) achieve the same optimal expected reward.
We then provide theoretical results establishing the expressive power of pdRMs,
and space complexity results about the proposed learning problems. Finally, we
provide experimental results showing how agents can be trained to perform tasks
representable in deterministic context-free languages using pdRMs.

</details>


### [390] [Automated Formalization via Conceptual Retrieval-Augmented LLMs](https://arxiv.org/abs/2508.06931)
*Wangyue Lu,Lun Du,Sirui Li,Ke Weng,Haozhe Sun,Hengyu Liu,Minghe Yu,Tiancheng Zhang,Ge Yu*

Main category: cs.AI

Relevance: 70.0

TL;DR: CRAMF是一个基于检索增强的数学形式化框架，通过检索核心数学概念的定义，提升LLM在自动形式化中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决自动形式化中的模型幻觉和语义鸿沟问题。

Method: 利用Mathlib4构建概念定义知识库，提出上下文查询增强和双通道混合检索策略。

Result: 在多个基准测试中，CRAMF显著提升了翻译准确率，最高达62.1%。

Conclusion: CRAMF有效提升了LLM在数学形式化中的表现，解决了关键挑战。

Abstract: Interactive theorem provers (ITPs) require manual formalization, which is
labor-intensive and demands expert knowledge. While automated formalization
offers a potential solution, it faces two major challenges: model hallucination
(e.g., undefined predicates, symbol misuse, and version incompatibility) and
the semantic gap caused by ambiguous or missing premises in natural language
descriptions. To address these issues, we propose CRAMF, a Concept-driven
Retrieval-Augmented Mathematical Formalization framework. CRAMF enhances
LLM-based autoformalization by retrieving formal definitions of core
mathematical concepts, providing contextual grounding during code generation.
However, applying retrieval-augmented generation (RAG) in this setting is
non-trivial due to the lack of structured knowledge bases, the polymorphic
nature of mathematical concepts, and the high precision required in formal
retrieval. We introduce a framework for automatically constructing a
concept-definition knowledge base from Mathlib4, the standard mathematical
library for the Lean 4 theorem prover, indexing over 26,000 formal definitions
and 1,000+ core mathematical concepts. To address conceptual polymorphism, we
propose contextual query augmentation with domain- and application-level
signals. In addition, we design a dual-channel hybrid retrieval strategy with
reranking to ensure accurate and relevant definition retrieval. Experiments on
miniF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that
CRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding
consistent improvements in translation accuracy, achieving up to 62.1% and an
average of 29.9% relative improvement.

</details>


### [391] [Large Language Models Do Not Simulate Human Psychology](https://arxiv.org/abs/2508.06950)
*Sarah Schröder,Thekla Morgenroth,Ulrike Kuhl,Valerie Vaquet,Benjamin Paaßen*

Main category: cs.AI

Relevance: 70.0

TL;DR: 论文警告不要用LLMs模拟人类心理学，并通过概念和实证证据表明LLMs与人类反应存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否能替代人类参与者进行心理学研究，并提出反对观点。

Method: 通过概念论证和实证分析，比较LLMs与人类对心理学问题的反应差异。

Result: LLMs与人类反应存在显著差异，且不同LLMs对新问题的反应不一致。

Conclusion: LLMs不能模拟人类心理学，心理学研究需验证其可靠性。

Abstract: Large Language Models (LLMs),such as ChatGPT, are increasingly used in
research, ranging from simple writing assistance to complex data annotation
tasks. Recently, some research has suggested that LLMs may even be able to
simulate human psychology and can, hence, replace human participants in
psychological studies. We caution against this approach. We provide conceptual
arguments against the hypothesis that LLMs simulate human psychology. We then
present empiric evidence illustrating our arguments by demonstrating that
slight changes to wording that correspond to large changes in meaning lead to
notable discrepancies between LLMs' and human responses, even for the recent
CENTAUR model that was specifically fine-tuned on psychological responses.
Additionally, different LLMs show very different responses to novel items,
further illustrating their lack of reliability. We conclude that LLMs do not
simulate human psychology and recommend that psychological researchers should
treat LLMs as useful but fundamentally unreliable tools that need to be
validated against human responses for every new application.

</details>


### [392] [Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables](https://arxiv.org/abs/2508.07186)
*Amit Dhanda*

Main category: cs.AI

Relevance: 70.0

TL;DR: 提出了一种基于LLM的多智能体框架，用于企业数据的多维度摘要生成，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统表格到文本模型在业务报告任务中缺乏跨层次结构和上下文感知差异的推理能力。

Method: 采用多智能体管道，包括数据切片、方差检测、上下文构建和LLM生成。

Result: 框架在数据忠实度（83%）、显著变化覆盖率和决策关键见解相关性（4.4/5）上表现优异。

Conclusion: 该方法在复杂业务场景中显著提升摘要质量，尤其在细微权衡类别中表现突出。

Abstract: We propose a novel framework for summarizing structured enterprise data
across multiple dimensions using large language model (LLM)-based agents.
Traditional table-to-text models often lack the capacity to reason across
hierarchical structures and context-aware deltas, which are essential in
business reporting tasks. Our method introduces a multi-agent pipeline that
extracts, analyzes, and summarizes multi-dimensional data using agents for
slicing, variance detection, context construction, and LLM-based generation.
Our results show that the proposed framework outperforms traditional
approaches, achieving 83\% faithfulness to underlying data, superior coverage
of significant changes, and high relevance scores (4.4/5) for decision-critical
insights. The improvements are especially pronounced in categories involving
subtle trade-offs, such as increased revenue due to price changes amid
declining unit volumes, which competing methods either overlook or address with
limited specificity. We evaluate the framework on Kaggle datasets and
demonstrate significant improvements in faithfulness, relevance, and insight
quality over baseline table summarization approaches.

</details>


### [393] [Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning](https://arxiv.org/abs/2508.07382)
*He Kong,Die Hu,Jingguo Ge,Liangxiong Li,Hui Li,Tong Li*

Main category: cs.AI

Relevance: 70.0

TL;DR: Pentest-R1是一个通过两阶段强化学习优化LLM在渗透测试中推理能力的框架，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在渗透测试中表现不佳，如错误处理能力差、推理效率低和无法自主完成复杂任务。

Method: 采用两阶段强化学习：离线RL学习基础攻击逻辑，在线RL在CTF环境中微调，学习自我纠正和适应策略。

Result: 在AutoPenBench上成功率24.2%，Cybench上15.0%，达到开源LLM的新SOTA。

Conclusion: 两阶段训练协同是关键，Pentest-R1在渗透测试中表现出色。

Abstract: Automating penetration testing is crucial for enhancing cybersecurity, yet
current Large Language Models (LLMs) face significant limitations in this
domain, including poor error handling, inefficient reasoning, and an inability
to perform complex end-to-end tasks autonomously. To address these challenges,
we introduce Pentest-R1, a novel framework designed to optimize LLM reasoning
capabilities for this task through a two-stage reinforcement learning pipeline.
We first construct a dataset of over 500 real-world, multi-step walkthroughs,
which Pentest-R1 leverages for offline reinforcement learning (RL) to instill
foundational attack logic. Subsequently, the LLM is fine-tuned via online RL in
an interactive Capture The Flag (CTF) environment, where it learns directly
from environmental feedback to develop robust error self-correction and
adaptive strategies. Our extensive experiments on the Cybench and AutoPenBench
benchmarks demonstrate the framework's effectiveness. On AutoPenBench,
Pentest-R1 achieves a 24.2\% success rate, surpassing most state-of-the-art
models and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a
15.0\% success rate in unguided tasks, establishing a new state-of-the-art for
open-source LLMs and matching the performance of top proprietary models.
Ablation studies confirm that the synergy of both training stages is critical
to its success.

</details>


### [394] [From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework](https://arxiv.org/abs/2508.08147)
*Yunkai Hu,Tianqiao Zhao,Meng Yue*

Main category: cs.AI

Relevance: 70.0

TL;DR: 提出了一种结合LLM和优化求解器的代理，将自然语言描述转换为可求解的数学公式，并通过验证和修复确保可行性，显著提升解决方案的可靠性。


<details>
  <summary>Details</summary>
Motivation: 直接使用LLM生成解决方案常导致不可行或次优结果，因其缺乏数值精度和约束处理能力。通过结合LLM与优化求解器，填补高层问题描述与可执行数学模型之间的鸿沟。

Method: 集成领域感知提示与LLM，通过系统验证和迭代修复确保可行性，生成可求解的数学模型和用户友好结果。

Result: 以机组组合问题为例，代理生成了最优或接近最优的调度方案及相关成本，验证了方法的可靠性。

Conclusion: 结合AI与传统优化框架，能更高效地将高层问题描述转化为可执行数学模型，提升能源系统决策效率。

Abstract: This paper introduces a novel Large Language Models (LLMs)-assisted agent
that automatically converts natural-language descriptions of power system
optimization scenarios into compact, solver-ready formulations and generates
corresponding solutions. In contrast to approaches that rely solely on LLM to
produce solutions directly, the proposed method focuses on discovering a
mathematically compatible formulation that can be efficiently solved by
off-the-shelf optimization solvers. Directly using LLMs to produce solutions
often leads to infeasible or suboptimal results, as these models lack the
numerical precision and constraint-handling capabilities of established
optimization solvers. The pipeline integrates a domain-aware prompt and schema
with an LLM, enforces feasibility through systematic validation and iterative
repair, and returns both solver-ready models and user-facing results. Using the
unit commitment problem as a representative case study, the agent produces
optimal or near-optimal schedules along with the associated objective costs.
Results demonstrate that coupling the solver with task-specific validation
significantly enhances solution reliability. This work shows that combining AI
with established optimization frameworks bridges high-level problem
descriptions and executable mathematical models, enabling more efficient
decision-making in energy systems

</details>


### [395] [BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation](https://arxiv.org/abs/2508.06781)
*Christos Tsirigotis,Vaibhav Adlakha,Joao Monteiro,Aaron Courville,Perouz Taslakian*

Main category: cs.IR

Relevance: 70.0

TL;DR: BiXSE是一种基于LLM生成的分级相关性标签的点式训练方法，通过优化二元交叉熵（BCE）实现细粒度监督，显著降低标注和计算成本，并在多个基准测试中优于对比学习方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的相关性通常是连续的，而传统方法依赖二元标签。LLM的进步使得生成细粒度标签成为可能，BiXSE旨在利用这一点提升密集检索模型的性能。

Method: BiXSE通过将LLM生成的分级相关性分数解释为概率目标，使用二元交叉熵进行点式训练，并利用批内负样本减少标注和计算需求。

Result: 在MMTEB、BEIR和TREC-DL等基准测试中，BiXSE优于InfoNCE，并与强排序基线相当或超越。

Conclusion: BiXSE为密集检索模型提供了一种高效且可扩展的训练方法，尤其适用于分级相关性监督的场景。

Abstract: Neural sentence embedding models for dense retrieval typically rely on binary
relevance labels, treating query-document pairs as either relevant or
irrelevant. However, real-world relevance often exists on a continuum, and
recent advances in large language models (LLMs) have made it feasible to scale
the generation of fine-grained graded relevance labels. In this work, we
propose BiXSE, a simple and effective pointwise training method that optimizes
binary cross-entropy (BCE) over LLM-generated graded relevance scores. BiXSE
interprets these scores as probabilistic targets, enabling granular supervision
from a single labeled query-document pair per query. Unlike pairwise or
listwise losses that require multiple annotated comparisons per query, BiXSE
achieves strong performance with reduced annotation and compute costs by
leveraging in-batch negatives. Extensive experiments across sentence embedding
(MMTEB) and retrieval benchmarks (BEIR, TREC-DL) show that BiXSE consistently
outperforms softmax-based contrastive learning (InfoNCE), and matches or
exceeds strong pairwise ranking baselines when trained on LLM-supervised data.
BiXSE offers a robust, scalable alternative for training dense retrieval models
as graded relevance supervision becomes increasingly accessible.

</details>


### [396] [LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning](https://arxiv.org/abs/2508.06799)
*Naiyi Li,Zihui Ma,Runlong Yu,Lingyao Li*

Main category: cs.ET

Relevance: 70.0

TL;DR: 提出LSDTs框架，利用LLM从非结构化文档中提取规划知识并构建本体，增强数字孪生的语义能力，应用于风电场规划案例。


<details>
  <summary>Details</summary>
Motivation: 数字孪生在复杂基础设施管理中的应用受限于非结构化知识的整合，LLM的进展为解决这一问题提供了新可能。

Method: 提出LSDTs框架，利用LLM提取非结构化文档（如法规、指南）中的知识，构建本体作为数字孪生的语义层。

Result: 案例研究表明LSDTs支持可解释的、符合法规的布局优化，高保真模拟和适应性规划。

Conclusion: 结合生成式AI与数字孪生可支持复杂的知识驱动规划任务。

Abstract: Digital Twins (DTs) offer powerful tools for managing complex infrastructure
systems, but their effectiveness is often limited by challenges in integrating
unstructured knowledge. Recent advances in Large Language Models (LLMs) bring
new potential to address this gap, with strong abilities in extracting and
organizing diverse textual information. We therefore propose LSDTs
(LLM-Augmented Semantic Digital Twins), a framework that helps LLMs extract
planning knowledge from unstructured documents like environmental regulations
and technical guidelines, and organize it into a formal ontology. This ontology
forms a semantic layer that powers a digital twin-a virtual model of the
physical system-allowing it to simulate realistic, regulation-aware planning
scenarios. We evaluate LSDTs through a case study of offshore wind farm
planning in Maryland, including its application during Hurricane Sandy. Results
demonstrate that LSDTs support interpretable, regulation-aware layout
optimization, enable high-fidelity simulation, and enhance adaptability in
infrastructure planning. This work shows the potential of combining generative
AI with digital twins to support complex, knowledge-driven planning tasks.

</details>


### [397] [ChatGPT on the Road: Leveraging Large Language Model-Powered In-vehicle Conversational Agents for Safer and More Enjoyable Driving Experience](https://arxiv.org/abs/2508.08101)
*Yeana Lee Bond,Mungyeong Choe,Baker Kasim Hasan,Arsh Siddiqui,Myounghoon Jeon*

Main category: cs.HC

Relevance: 70.0

TL;DR: 研究探讨了基于ChatGPT的车载对话代理在提升驾驶安全和用户体验方面的潜力，结果显示其优于传统预设代理。


<details>
  <summary>Details</summary>
Motivation: 传统车载对话代理依赖预设提示或有限语音命令，限制了自然交互。研究旨在探索基于ChatGPT的代理是否能改善这一问题。

Method: 40名驾驶员在驾驶模拟器中测试三种条件（无代理、预设代理、ChatGPT代理），比较驾驶性能和主观评价。

Result: ChatGPT代理在驾驶稳定性（如加速度、车道偏离）和主观评价（能力、信任等）上表现最佳。

Conclusion: 基于LLM的车载代理可通过自然交互提升驾驶安全和用户体验。

Abstract: Studies on in-vehicle conversational agents have traditionally relied on
pre-scripted prompts or limited voice commands, constraining natural
driver-agent interaction. To resolve this issue, the present study explored the
potential of a ChatGPT-based in-vehicle agent capable of carrying continuous,
multi-turn dialogues. Forty drivers participated in our experiment using a
motion-based driving simulator, comparing three conditions (No agent,
Pre-scripted agent, and ChatGPT-based agent) as a within-subjects variable.
Results showed that the ChatGPT-based agent condition led to more stable
driving performance across multiple metrics. Participants demonstrated lower
variability in longitudinal acceleration, lateral acceleration, and lane
deviation compared to the other two conditions. In subjective evaluations, the
ChatGPT-based agent also received significantly higher ratings in competence,
animacy, affective trust, and preference compared to the Pre-scripted agent.
Our thematic analysis of driver-agent conversations revealed diverse
interaction patterns in topics, including driving assistance/questions,
entertainment requests, and anthropomorphic interactions. Our results highlight
the potential of LLM-powered in-vehicle conversational agents to enhance
driving safety and user experience through natural, context-rich interactions.

</details>


### [398] [Street-Level AI: Are Large Language Models Ready for Real-World Judgments?](https://arxiv.org/abs/2508.08193)
*Gaurab Pokharel,Shafkat Farabi,Patrick J. Fowler,Sanmay Das*

Main category: cs.CY

Relevance: 70.0

TL;DR: 论文探讨了LLM在道德判断和社会资源分配中的表现，发现其与人类判断和现有评分系统存在不一致性，质疑其在高风险决策中的适用性。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在道德和社会资源分配中的表现，评估其与人类判断和现有系统的对齐程度。

Method: 使用真实数据（保护隐私）分析LLM在无家可归资源分配中的判断，比较其内部、跨模型及与人类和评分系统的一致性。

Result: LLM的判断在内部、跨模型及与评分系统间极不一致，但与人类判断在成对测试中表现一致。

Conclusion: 当前AI系统尚未准备好直接用于高风险社会决策。

Abstract: A surge of recent work explores the ethical and societal implications of
large-scale AI models that make "moral" judgments. Much of this literature
focuses either on alignment with human judgments through various thought
experiments or on the group fairness implications of AI judgments. However, the
most immediate and likely use of AI is to help or fully replace the so-called
street-level bureaucrats, the individuals deciding to allocate scarce social
resources or approve benefits. There is a rich history underlying how
principles of local justice determine how society decides on prioritization
mechanisms in such domains. In this paper, we examine how well LLM judgments
align with human judgments, as well as with socially and politically determined
vulnerability scoring systems currently used in the domain of homelessness
resource allocation. Crucially, we use real data on those needing services
(maintaining strict confidentiality by only using local large models) to
perform our analyses. We find that LLM prioritizations are extremely
inconsistent in several ways: internally on different runs, between different
LLMs, and between LLMs and the vulnerability scoring systems. At the same time,
LLMs demonstrate qualitative consistency with lay human judgments in pairwise
testing. Findings call into question the readiness of current generation AI
systems for naive integration in high-stakes societal decision-making.

</details>


### [399] [Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges](https://arxiv.org/abs/2508.06832)
*Haifeng Li,Wang Guo,Haiyang Wu,Mengwei Wu,Jipeng Zhang,Qing Zhu,Yu Liu,Xin Huang,Chao Tao*

Main category: cs.AI

Relevance: 60.0

TL;DR: 该论文提出了一种从视觉为中心转向语言为中心的遥感图像解释框架，利用大语言模型（LLMs）作为认知中心，整合感知、任务、知识和动作空间，以实现统一的理解、推理和决策。


<details>
  <summary>Details</summary>
Motivation: 现有遥感图像解释主要依赖视觉特征，缺乏多模态推理和语义抽象能力。引入LLMs作为认知中心，旨在解决这些局限性。

Method: 基于全局工作空间理论（GWT），提出语言为中心的框架，探讨LLMs在遥感中的认知角色，并解决多模态表示、知识关联和推理决策等挑战。

Result: 构建了全局工作空间驱动的解释机制，总结了语言为中心的解决方案，并提出了未来研究方向。

Conclusion: 该研究为下一代遥感解释系统提供了理论基础，并为认知驱动的智能地理空间分析制定了路线图。

Abstract: The mainstream paradigm of remote sensing image interpretation has long been
dominated by vision-centered models, which rely on visual features for semantic
understanding. However, these models face inherent limitations in handling
multi-modal reasoning, semantic abstraction, and interactive decision-making.
While recent advances have introduced Large Language Models (LLMs) into remote
sensing workflows, existing studies primarily focus on downstream applications,
lacking a unified theoretical framework that explains the cognitive role of
language. This review advocates a paradigm shift from vision-centered to
language-centered remote sensing interpretation. Drawing inspiration from the
Global Workspace Theory (GWT) of human cognition, We propose a
language-centered framework for remote sensing interpretation that treats LLMs
as the cognitive central hub integrating perceptual, task, knowledge and action
spaces to enable unified understanding, reasoning, and decision-making. We
first explore the potential of LLMs as the central cognitive component in
remote sensing interpretation, and then summarize core technical challenges,
including unified multimodal representation, knowledge association, and
reasoning and decision-making. Furthermore, we construct a global
workspace-driven interpretation mechanism and review how language-centered
solutions address each challenge. Finally, we outline future research
directions from four perspectives: adaptive alignment of multimodal data, task
understanding under dynamic knowledge constraints, trustworthy reasoning, and
autonomous interaction. This work aims to provide a conceptual foundation for
the next generation of remote sensing interpretation systems and establish a
roadmap toward cognition-driven intelligent geospatial analysis.

</details>


### [400] [Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction](https://arxiv.org/abs/2508.06939)
*Hiba Najjar,Deepak Pathak,Marlon Nuske,Andreas Dengel*

Main category: cs.AI

Relevance: 60.0

TL;DR: 论文利用Transformer模型的可解释性分析多模态学习网络，用于子田级作物产量预测，并比较了两种注意力方法（AR和GA）与Shapley方法（SVS）的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态学习在农业中应用广泛，但模型可解释性常被忽视。本研究旨在通过Transformer的注意力机制提升多模态学习的可解释性。

Method: 使用自注意力机制（AR和GA）和Shapley方法（SVS）估计特征归因，并提出加权模态激活（WMA）方法评估模态归因。

Result: Transformer模型在子田和田间级别上优于卷积和循环网络，R2分数分别高出0.10和0.04；AR在时间归因上更可靠。

Conclusion: Transformer模型在多模态学习中表现优异，AR方法提供更可靠的解释，模态归因方法比较揭示了不同模式。

Abstract: Multimodal learning enables various machine learning tasks to benefit from
diverse data sources, effectively mimicking the interplay of different factors
in real-world applications, particularly in agriculture. While the
heterogeneous nature of involved data modalities may necessitate the design of
complex architectures, the model interpretability is often overlooked. In this
study, we leverage the intrinsic explainability of Transformer-based models to
explain multimodal learning networks, focusing on the task of crop yield
prediction at the subfield level. The large datasets used cover various crops,
regions, and years, and include four different input modalities: multispectral
satellite and weather time series, terrain elevation maps and soil properties.
Based on the self-attention mechanism, we estimate feature attributions using
two methods, namely the Attention Rollout (AR) and Generic Attention (GA), and
evaluate their performance against Shapley-based model-agnostic estimations,
Shapley Value Sampling (SVS). Additionally, we propose the Weighted Modality
Activation (WMA) method to assess modality attributions and compare it with SVS
attributions. Our findings indicate that Transformer-based models outperform
other architectures, specifically convolutional and recurrent networks,
achieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field
levels, respectively. AR is shown to provide more robust and reliable temporal
attributions, as confirmed through qualitative and quantitative evaluation,
compared to GA and SVS values. Information about crop phenology stages was
leveraged to interpret the explanation results in the light of established
agronomic knowledge. Furthermore, modality attributions revealed varying
patterns across the two methods compared.[...]

</details>


### [401] [DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning](https://arxiv.org/abs/2508.06972)
*Dan Ivanov,Tristan Freiberg,Haruna Isah*

Main category: cs.AI

Relevance: 60.0

TL;DR: DSperse是一个模块化框架，用于分布式机器学习推理，通过加密验证实现信任最小化。


<details>
  <summary>Details</summary>
Motivation: 解决分布式机器学习中全模型电路化的高成本和僵化问题，提供灵活的验证策略。

Method: 采用目标验证策略，选择关键子计算进行加密验证，支持切片配置。

Result: 实验评估了多种证明系统，展示了内存使用、运行时间和电路行为的性能。

Conclusion: DSperse通过灵活调整验证边界，支持可扩展的、针对性的验证策略。

Abstract: DSperse is a modular framework for distributed machine learning inference
with strategic cryptographic verification. Operating within the emerging
paradigm of distributed zero-knowledge machine learning, DSperse avoids the
high cost and rigidity of full-model circuitization by enabling targeted
verification of strategically chosen subcomputations. These verifiable
segments, or "slices", may cover part or all of the inference pipeline, with
global consistency enforced through audit, replication, or economic incentives.
This architecture supports a pragmatic form of trust minimization, localizing
zero-knowledge proofs to the components where they provide the greatest value.
We evaluate DSperse using multiple proving systems and report empirical results
on memory usage, runtime, and circuit behavior under sliced and unsliced
configurations. By allowing proof boundaries to align flexibly with the model's
logical structure, DSperse supports scalable, targeted verification strategies
suited to diverse deployment needs.

</details>


### [402] [K-Dense Analyst: Towards Fully Automated Scientific Analysis](https://arxiv.org/abs/2508.07043)
*Orion Li,Vinayak Agarwal,Summer Zhou,Ashwin Gopinath,Timothy Kassis*

Main category: cs.AI

Relevance: 60.0

TL;DR: K-Dense Analyst是一个分层多智能体系统，通过双循环架构实现自主生物信息学分析，性能超过最佳语言模型GPT-5。


<details>
  <summary>Details</summary>
Motivation: 现代生物信息学分析的复杂性导致数据生成与科学洞察之间存在巨大鸿沟，现有LLMs在迭代计算和工具集成方面表现不足。

Method: 采用分层多智能体系统，结合规划与验证执行，将复杂目标分解为可执行任务。

Result: 在BixBench基准测试中，K-Dense Analyst准确率达29.2%，超过GPT-5 6.3个百分点。

Conclusion: 自主科学推理需要专门构建的系统，而不仅仅是增强的语言模型。

Abstract: The complexity of modern bioinformatics analysis has created a critical gap
between data generation and developing scientific insights. While large
language models (LLMs) have shown promise in scientific reasoning, they remain
fundamentally limited when dealing with real-world analytical workflows that
demand iterative computation, tool integration and rigorous validation. We
introduce K-Dense Analyst, a hierarchical multi-agent system that achieves
autonomous bioinformatics analysis through a dual-loop architecture. K-Dense
Analyst, part of the broader K-Dense platform, couples planning with validated
execution using specialized agents to decompose complex objectives into
executable, verifiable tasks within secure computational environments. On
BixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense
Analyst achieves 29.2% accuracy, surpassing the best-performing language model
(GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what
is widely considered the most powerful LLM available. Remarkably, K-Dense
Analyst achieves this performance using Gemini 2.5 Pro, which attains only
18.3% accuracy when used directly, demonstrating that our architectural
innovations unlock capabilities far beyond the underlying model's baseline
performance. Our insights demonstrate that autonomous scientific reasoning
requires more than enhanced language models, it demands purpose-built systems
that can bridge the gap between high-level scientific objectives and low-level
computational execution. These results represent a significant advance toward
fully autonomous computational biologists capable of accelerating discovery
across the life sciences.

</details>


### [403] [Generative AI for Strategic Plan Development](https://arxiv.org/abs/2508.07405)
*Jesse Ponnock*

Main category: cs.AI

Relevance: 60.0

TL;DR: 本文提出了一种模块化模型，利用生成式人工智能（GAI）为大型政府组织制定战略计划，并评估了BERTopic和NMF在主题建模中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用GAI和LLMs自动化政府战略计划的制定，以应对多亿美元的行业需求和监管要求。

Method: 使用BERTopic和NMF对政府问责办公室（GAO）的大量报告进行主题建模，生成与战略计划中“愿景要素”相似的主题，并比较两种技术的表现。

Result: BERTopic和NMF均能生成与100%的愿景要素相似的主题，其中BERTopic表现更优，超过一半的主题达到“中等”或“强”相关性。

Conclusion: GAI在战略计划制定中具有潜力，BERTopic是更优选择。未来工作将聚焦于模型的操作化和剩余模块的可行性验证。

Abstract: Given recent breakthroughs in Generative Artificial Intelligence (GAI) and
Large Language Models (LLMs), more and more professional services are being
augmented through Artificial Intelligence (AI), which once seemed impossible to
automate. This paper presents a modular model for leveraging GAI in developing
strategic plans for large scale government organizations and evaluates leading
machine learning techniques in their application towards one of the identified
modules. Specifically, the performance of BERTopic and Non-negative Matrix
Factorization (NMF) are evaluated in their ability to use topic modeling to
generate themes representative of Vision Elements within a strategic plan. To
accomplish this, BERTopic and NMF models are trained using a large volume of
reports from the Government Accountability Office (GAO). The generated topics
from each model are then scored for similarity against the Vision Elements of a
published strategic plan and the results are compared. Our results show that
these techniques are capable of generating themes similar to 100% of the
elements being evaluated against. Further, we conclude that BERTopic performs
best in this application with more than half of its correlated topics achieving
a "medium" or "strong" correlation. A capability of GAI-enabled strategic plan
development impacts a multi-billion dollar industry and assists the federal
government in overcoming regulatory requirements which are crucial to the
public good. Further work will focus on the operationalization of the concept
proven in this study as well as viability of the remaining modules in the
proposed model for GAI-generated strategic plans.

</details>


### [404] [Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities](https://arxiv.org/abs/2508.07031)
*Anindya Bijoy Das,Shahnewaz Karim Sakib,Shibbir Ahmed*

Main category: eess.IV

Relevance: 60.0

TL;DR: 该研究探讨了大型语言模型（LLMs）在医学影像任务中的幻觉问题，分析了图像到文本和文本到图像两种方向中的错误，并提出了改进安全性和可信度的建议。


<details>
  <summary>Details</summary>
Motivation: LLMs在医学影像应用中常产生幻觉（自信但错误的输出），可能误导临床决策，因此需要系统研究其错误模式和原因。

Method: 研究分析了图像到文本（生成报告）和文本到图像（生成影像）任务中的幻觉，使用专家标准评估错误。

Result: 发现了幻觉在解释性和生成性任务中的常见模式，并探讨了模型架构和训练数据等因素的影响。

Conclusion: 通过系统研究，为提升LLM驱动的医学影像系统的安全性和可信度提供了见解。

Abstract: Large Language Models (LLMs) are increasingly applied to medical imaging
tasks, including image interpretation and synthetic image generation. However,
these models often produce hallucinations, which are confident but incorrect
outputs that can mislead clinical decisions. This study examines hallucinations
in two directions: image to text, where LLMs generate reports from X-ray, CT,
or MRI scans, and text to image, where models create medical images from
clinical prompts. We analyze errors such as factual inconsistencies and
anatomical inaccuracies, evaluating outputs using expert informed criteria
across imaging modalities. Our findings reveal common patterns of hallucination
in both interpretive and generative tasks, with implications for clinical
reliability. We also discuss factors contributing to these failures, including
model architecture and training data. By systematically studying both image
understanding and generation, this work provides insights into improving the
safety and trustworthiness of LLM driven medical imaging systems.

</details>


### [405] [Computing with Canonical Microcircuits](https://arxiv.org/abs/2508.06501)
*PK Douglas*

Main category: q-bio.NC

Relevance: 60.0

TL;DR: 论文提出了一种基于大脑中典型微电路（CMCs）的计算架构，通过神经ODE实现，展示了在MNIST等任务上的高效性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 受大脑高效学习和自适应决策的启发，探索基于生物神经网络的参数高效架构。

Method: 采用神经ODE实现CMCs，包括8维动态系统和生物合理的循环连接，构建分层配置。

Result: 单个CMC节点在MNIST上达到97.8%准确率，分层配置在复杂任务上表现更优，且参数更少。

Conclusion: 神经形态计算方法可提升人工神经网络的效率和可解释性，为参数高效架构提供新方向。

Abstract: The human brain represents the only known example of general intelligence
that naturally aligns with human values. On a mere 20-watt power budget, the
brain achieves robust learning and adaptive decision-making in ways that
continue to elude advanced AI systems. Inspired by the brain, we present a
computational architecture based on canonical microcircuits (CMCs) -
stereotyped patterns of neurons found ubiquitously throughout the cortex. We
implement these circuits as neural ODEs comprising spiny stellate, inhibitory,
and pyramidal neurons, forming an 8-dimensional dynamical system with
biologically plausible recurrent connections. Our experiments show that even a
single CMC node achieves 97.8 percent accuracy on MNIST, while hierarchical
configurations - with learnable inter-regional connectivity and recurrent
connections - yield improved performance on more complex image benchmarks.
Notably, our approach achieves competitive results using substantially fewer
parameters than conventional deep learning models. Phase space analysis
revealed distinct dynamical trajectories for different input classes,
highlighting interpretable, emergent behaviors observed in biological systems.
These findings suggest that neuromorphic computing approaches can improve both
efficiency and interpretability in artificial neural networks, offering new
directions for parameter-efficient architectures grounded in the computational
principles of the human brain.

</details>


### [406] [Understanding Human Limits in Pattern Recognition: A Computational Model of Sequential Reasoning in Rock, Paper, Scissors](https://arxiv.org/abs/2508.06503)
*Logan Cross,Erik Brockbank,Tobias Gerstenberg,Judith E. Fan,Daniel L. K. Yamins,Nick Haber*

Main category: q-bio.NC

Relevance: 60.0

TL;DR: 论文研究了人类如何通过行为模式预测他人行为及其计算限制，使用基于LLM的代理Hypothetical Minds（HM）模拟人类行为，发现HM在类似实验条件下与人类表现相似，并通过干预实验揭示假设生成是主要认知瓶颈。


<details>
  <summary>Details</summary>
Motivation: 探索人类预测他人行为的能力及其认知限制，利用LLM代理HM模拟人类行为以理解其机制。

Method: 使用HM代理模拟人类在重复剪刀石头布游戏中的行为，通过干预实验（如提供对手策略描述）分析其表现。

Result: HM在提供对手策略描述后能高效击败6/7的机器人对手（胜率>80%），表明假设生成是主要瓶颈。干预实验还显示HM能显著更新对对手行为的因果理解。

Conclusion: HM成功模拟了人类行为模式，揭示了假设生成在认知中的关键作用，为人类认知研究提供了可测试的假设。

Abstract: How do we predict others from patterns in their behavior and what are the
computational constraints that limit this ability? We investigate these
questions by modeling human behavior over repeated games of rock, paper,
scissors from Brockbank & Vul (2024). Against algorithmic opponents that varied
in strategic sophistication, people readily exploit simple transition patterns
(e.g., consistently playing rock after paper) but struggle to detect more
complex sequential dependencies. To understand the cognitive mechanisms
underlying these abilities and their limitations, we deploy Hypothetical Minds
(HM), a large language model-based agent that generates and tests hypotheses
about opponent strategies, as a cognitive model of this behavior (Cross et al.,
2024). We show that when applied to the same experimental conditions, HM
closely mirrors human performance patterns, succeeding and failing in similar
ways. To better understand the source of HM's failures and whether people might
face similar cognitive bottlenecks in this context, we performed a series of
ablations and augmentations targeting different components of the system. When
provided with natural language descriptions of the opponents' strategies, HM
successfully exploited 6/7 bot opponents with win rates >80% suggesting that
accurate hypothesis generation is the primary cognitive bottleneck in this
task. Further, by systematically manipulating the model's hypotheses through
pedagogically-inspired interventions, we find that the model substantially
updates its causal understanding of opponent behavior, revealing how
model-based analyses can produce testable hypotheses about human cognition.

</details>


### [407] [Generative AI for Intent-Driven Network Management in 6G: A Case Study on Hierarchical Learning Approach](https://arxiv.org/abs/2508.06616)
*Md Arafat Habib,Medhat Elsayed,Yigit Ozcan,Pedro Enrique Iturria-Rivera,Majid Bavand,Melike Erol-Kantarci*

Main category: cs.NI

Relevance: 60.0

TL;DR: 论文综述了基于LLM的意图驱动网络（IDN）架构在6G异构移动网络中的应用，提出了一种分层框架，将GenAI集成到IDN的三个关键阶段，并通过Mamba架构的案例研究验证了其性能优势。


<details>
  <summary>Details</summary>
Motivation: 6G移动网络的异构性和动态性需要更智能的自动化管理，LLM能够理解复杂指令以提升IDN的适应性。

Method: 提出分层框架，将GenAI应用于IDN的意图处理、验证和执行三个阶段，并通过Mamba架构进行案例研究。

Result: 案例研究表明，提出的GenAI驱动架构在性能上优于传统IDN架构。

Conclusion: GenAI在IDN中的全面应用能够显著提升网络性能，为6G网络管理提供新思路。

Abstract: With the emergence of 6G, mobile networks are becoming increasingly
heterogeneous and dynamic, necessitating advanced automation for efficient
management. Intent-Driven Networks (IDNs) address this by translating
high-level intents into optimization policies. Large Language Models (LLMs) can
enhance this process by understanding complex human instructions to enable
adaptive, intelligent automation. Given the rapid advancements in Generative AI
(GenAI), a comprehensive survey of LLM-based IDN architectures in disaggregated
Radio Access Network (RAN) environments is both timely and critical. This
article provides such a survey, along with a case study on a hierarchical
learning-enabled IDN architecture that integrates GenAI across three key
stages: intent processing, intent validation, and intent execution. Unlike most
existing approaches that apply GenAI in the form of LLMs for intent processing
only, we propose a hierarchical framework that introduces GenAI across all
three stages of IDN. To demonstrate the effectiveness of the proposed IDN
management architecture, we present a case study based on the latest GenAI
architecture named Mamba. The case study shows how the proposed GenAI-driven
architecture enhances network performance through intelligent automation,
surpassing the performance of the conventional IDN architectures.

</details>


### [408] [Towards Experience-Centered AI: A Framework for Integrating Lived Experience in Design and Development](https://arxiv.org/abs/2508.06849)
*Sanjana Gautam,Mohit Chandra,Ankolika De,Tatiana Chakravorti,Girik Malik,Munmun De Choudhury*

Main category: cs.CY

Relevance: 60.0

TL;DR: 提出了一个将生活经验融入AI系统设计与评估的框架，强调其对安全性、信任和可用性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对生活经验的系统性理解，无法将其有效融入AI开发生命周期。

Method: 综合跨学科文献，提出生活经验的分类法，并在教育、医疗和文化对齐三个领域验证框架。

Result: 展示了生活经验如何影响用户目标、系统期望和伦理考量，并提出了开发经验中心AI系统的建议。

Conclusion: 为未来研究提供了技术开发与生活经验结合的基础。

Abstract: Lived experiences fundamentally shape how individuals interact with AI
systems, influencing perceptions of safety, trust, and usability. While prior
research has focused on developing techniques to emulate human preferences, and
proposed taxonomies to categorize risks (such as psychological harms and
algorithmic biases), these efforts have provided limited systematic
understanding of lived human experiences or actionable strategies for embedding
them meaningfully into the AI development lifecycle. This work proposes a
framework for meaningfully integrating lived experience into the design and
evaluation of AI systems. We synthesize interdisciplinary literature across
lived experience philosophy, human-centered design, and human-AI interaction,
arguing that centering lived experience can lead to models that more accurately
reflect the retrospective, emotional, and contextual dimensions of human
cognition. Drawing from a wide body of work across psychology, education,
healthcare, and social policy, we present a targeted taxonomy of lived
experiences with specific applicability to AI systems. To ground our framework,
we examine three application domains (i) education, (ii) healthcare, and (iii)
cultural alignment, illustrating how lived experience informs user goals,
system expectations, and ethical considerations in each context. We further
incorporate insights from AI system operators and human-AI partnerships to
highlight challenges in responsibility allocation, mental model calibration,
and long-term system adaptation. We conclude with actionable recommendations
for developing experience-centered AI systems that are not only technically
robust but also empathetic, context-aware, and aligned with human realities.
This work offers a foundation for future research that bridges technical
development with the lived experiences of those impacted by AI systems.

</details>


### [409] [Explainability-in-Action: Enabling Expressive Manipulation and Tacit Understanding by Bending Diffusion Models in ComfyUI](https://arxiv.org/abs/2508.07183)
*Ahmed M. Abuzuraiq,Philippe Pasquier*

Main category: cs.HC

Relevance: 60.0

TL;DR: 论文提出了一种基于手工艺的解释性AI方法，通过暴露和操作大型生成模型的内部结构，支持艺术家的创意实践。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决大型生成模型（如文本到图像扩散系统）在创意场景中缺乏透明度和可控性的问题，以增强艺术家的参与感和控制力。

Method: 采用基于手工艺的方法，结合长期实践和交互式操作，开发了一个模型弯曲和检查插件，集成到ComfyUI的节点界面中。

Result: 艺术家通过交互式操作模型的不同部分，能够直观理解每个组件对输出的影响。

Conclusion: 研究表明，大型模型可以通过暴露和操作内部结构成为创意材料，为艺术实践提供新的可能性。

Abstract: Explainable AI (XAI) in creative contexts can go beyond transparency to
support artistic engagement, modifiability, and sustained practice. While
curated datasets and training human-scale models can offer artists greater
agency and control, large-scale generative models like text-to-image diffusion
systems often obscure these possibilities. We suggest that even large models
can be treated as creative materials if their internal structure is exposed and
manipulable. We propose a craft-based approach to explainability rooted in
long-term, hands-on engagement akin to Sch\"on's "reflection-in-action" and
demonstrate its application through a model-bending and inspection plugin
integrated into the node-based interface of ComfyUI. We demonstrate that by
interactively manipulating different parts of a generative model, artists can
develop an intuition about how each component influences the output.

</details>


### [410] [Fine-Tuning Large Language Models Using EEG Microstate Features for Mental Workload Assessment](https://arxiv.org/abs/2508.07283)
*Bujar Raufi*

Main category: cs.HC

Relevance: 60.0

TL;DR: 该研究结合脑电图（EEG）微状态与大语言模型（LLMs），通过微调LLMs提升认知负荷状态的预测能力。


<details>
  <summary>Details</summary>
Motivation: 探索EEG微状态与LLMs的结合，以改进认知负荷状态的评估，推动认知神经科学与认知AI的发展。

Method: 分四阶段实验设计：数据收集与预处理、微状态分割与EEG拟合、特征提取与提示工程、LLM模型选择与微调。

Result: 微调后的LLM在认知负荷状态识别上表现显著提升。

Conclusion: EEG-informed LLMs在认知神经科学与认知AI领域具有潜力。

Abstract: This study explores the intersection of electroencephalography (EEG)
microstates and Large Language Models (LLMs) to enhance the assessment of
cognitive load states. By utilizing EEG microstate features, the research aims
to fine-tune LLMs for improved predictions of distinct cognitive states,
specifically 'Rest' and 'Load'. The experimental design is delineated in four
comprehensive stages: dataset collection and preprocessing, microstate
segmentation and EEG backfitting, feature extraction paired with prompt
engineering, and meticulous LLM model selection and refinement. Employing a
supervised learning paradigm, the LLM is trained to identify cognitive load
states based on EEG microstate features integrated into prompts, producing
accurate discrimination of cognitive load. A curated dataset, linking EEG
features to specified cognitive load conditions, underpins the experimental
framework. The results indicate a significant improvement in model performance
following the proposed fine-tuning, showcasing the potential of EEG-informed
LLMs in cognitive neuroscience and cognitive AI applications. This approach not
only contributes to the understanding of brain dynamics but also paves the way
for advancements in machine learning techniques applicable to cognitive load
and cognitive AI research.

</details>


### [411] [Exploring the Challenges and Opportunities of AI-assisted Codebase Generation](https://arxiv.org/abs/2508.07966)
*Philipp Eibl,Sadra Sabouri,Souti Chattopadhyay*

Main category: cs.SE

Relevance: 60.0

TL;DR: 论文研究了代码库AI助手（CBAs）的使用情况，发现开发者对其生成的代码库满意度较低，主要问题包括功能不足、代码质量差和沟通问题。


<details>
  <summary>Details</summary>
Motivation: 尽管CBAs在处理复杂上下文和生成完整代码库方面有所进步，但其采用率仍低于片段级代码助手。研究旨在了解开发者如何与CBAs互动及其不足之处。

Method: 通过用户研究（n=16）和访谈，分析开发者使用CBAs时的提示策略和满意度，并识别挑战和障碍。

Result: 满意度较低（均值2.8/5），功能不足（77%）、代码质量差（42%）和沟通问题（25%）是主要问题。研究还总结了六项挑战和五项障碍。

Conclusion: 研究揭示了CBAs的局限性，并提出了改进设计的机会。

Abstract: Recent AI code assistants have significantly improved their ability to
process more complex contexts and generate entire codebases based on a textual
description, compared to the popular snippet-level generation. These codebase
AI assistants (CBAs) can also extend or adapt codebases, allowing users to
focus on higher-level design and deployment decisions. While prior work has
extensively studied the impact of snippet-level code generation, this new class
of codebase generation models is relatively unexplored. Despite initial
anecdotal reports of excitement about these agents, they remain less frequently
adopted compared to snippet-level code assistants. To utilize CBAs better, we
need to understand how developers interact with CBAs, and how and why CBAs fall
short of developers' needs. In this paper, we explored these gaps through a
counterbalanced user study and interview with (n = 16) students and developers
working on coding tasks with CBAs. We found that participants varied the
information in their prompts, like problem description (48% of prompts),
required functionality (98% of prompts), code structure (48% of prompts), and
their prompt writing process. Despite various strategies, the overall
satisfaction score with generated codebases remained low (mean = 2.8, median =
3, on a scale of one to five). Participants mentioned functionality as the most
common factor for dissatisfaction (77% of instances), alongside poor code
quality (42% of instances) and communication issues (25% of instances). We
delve deeper into participants' dissatisfaction to identify six underlying
challenges that participants faced when using CBAs, and extracted five barriers
to incorporating CBAs into their workflows. Finally, we surveyed 21 commercial
CBAs to compare their capabilities with participant challenges and present
design opportunities for more efficient and useful CBAs.

</details>


### [412] [Can AI Explanations Make You Change Your Mind?](https://arxiv.org/abs/2508.08158)
*Laura Spillner,Rachel Ringe,Robert Porzel,Rainer Malaka*

Main category: cs.HC

Relevance: 60.0

TL;DR: 研究发现，用户在使用可解释决策支持系统时，往往不会详细阅读解释，影响了其对AI建议的信任和决策调整。


<details>
  <summary>Details</summary>
Motivation: 探讨用户如何利用AI解释来判断是否信任AI建议，以及解释的详细程度如何影响决策。

Method: 通过在线研究，分析用户对AI解释的关注程度及其对决策的影响。

Result: 许多用户未详细阅读解释，导致未能有效利用解释来调整决策。

Conclusion: 需改进解释设计以提高用户对AI建议的信任和决策质量。

Abstract: In the context of AI-based decision support systems, explanations can help
users to judge when to trust the AI's suggestion, and when to question it. In
this way, human oversight can prevent AI errors and biased decision-making.
However, this rests on the assumption that users will consider explanations in
enough detail to be able to catch such errors. We conducted an online study on
trust in explainable DSS, and were surprised to find that in many cases,
participants spent little time on the explanation and did not always consider
it in detail. We present an exploratory analysis of this data, investigating
what factors impact how carefully study participants consider AI explanations,
and how this in turn impacts whether they are open to changing their mind based
on what the AI suggests.

</details>


### [413] [Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization](https://arxiv.org/abs/2508.06559)
*Sina Baghal*

Main category: cs.AI

Relevance: 40.0

TL;DR: 论文介绍了一种基于CUDA加速的计算框架，用于模拟Pasur纸牌游戏，并通过CFR算法计算近纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 解决Pasur游戏规则复杂和游戏树庞大的挑战，为类似回合制游戏提供高效计算框架。

Method: 使用PyTorch CUDA张量处理规则，分解游戏树为状态和继承分数，采用轮次逆向训练策略。

Result: 构建了包含超过10^9节点的完整游戏树，训练了基于树的策略预测模型。

Conclusion: 框架可扩展至其他强化学习算法，适用于回合制策略游戏或金融市场决策。

Abstract: Pasur is a fishing card game played over six rounds and is played similarly
to games such as Cassino and Scopa, and Bastra. This paper introduces a
CUDA-accelerated computational framework for simulating Pasur, emphasizing
efficient memory management. We use our framework to compute near-Nash
equilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm
for solving large imperfect-information games.
  Solving Pasur presents unique challenges due to its intricate rules and the
large size of its game tree. We handle rule complexity using PyTorch CUDA
tensors and to address the memory-intensive nature of the game, we decompose
the game tree into two key components: (1) actual game states, and (2)
inherited scores from previous rounds. We construct the Full Game Tree by
pairing card states with accumulated scores in the Unfolding Process. This
design reduces memory overhead by storing only essential strategy values and
node connections. To further manage computational complexity, we apply a
round-by-round backward training strategy, starting from the final round and
recursively propagating average utilities to earlier stages. Our approach
constructs the complete game tree, which on average consists of over $10^9$
nodes. We provide detailed implementation snippets.
  After computing a near-Nash equilibrium strategy, we train a tree-based model
to predict these strategies for use during gameplay. We then estimate the fair
value of each deck through large-scale self-play between equilibrium strategies
by simulating, for instance, 10,000 games per matchup, executed in parallel
using GPU acceleration.
  Similar frameworks can be extended to other reinforcement learning algorithms
where the action tree naturally decomposes into multiple rounds such as
turn-based strategy games or sequential trading decisions in financial markets.

</details>


### [414] [Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop](https://arxiv.org/abs/2508.06569)
*Lance Yao,Suman Samantray,Ayana Ghosh,Kevin Roccapriore,Libor Kovarik,Sarah Allec,Maxim Ziatdinov*

Main category: cs.AI

Relevance: 40.0

TL;DR: SciLink是一个开源的多智能体AI框架，旨在通过自动化链接实验观察、新颖性评估和理论模拟，在材料研究中实现偶然发现。


<details>
  <summary>Details</summary>
Motivation: 现代自主实验室虽然能高效验证假设，但可能忽略偶然发现。SciLink填补了这一空白，旨在通过AI系统化地促进材料研究中的偶然发现。

Method: 采用混合AI策略：专用机器学习模型分析实验数据，大语言模型处理高级推理。系统将原始数据转化为可验证的科学主张，并根据文献评估新颖性。

Result: SciLink在多种研究场景中表现出色，包括原子分辨率和超光谱数据处理、实时整合专家指导，以及提出后续实验建议。

Conclusion: SciLink不仅提高了研究效率，还通过系统化分析所有观察结果，为偶然发现创造了有利环境，填补了自动化实验与开放科学探索之间的空白。

Abstract: The history of science is punctuated by serendipitous discoveries, where
unexpected observations, rather than targeted hypotheses, opened new fields of
inquiry. While modern autonomous laboratories excel at accelerating hypothesis
testing, their optimization for efficiency risks overlooking these crucial,
unplanned findings. To address this gap, we introduce SciLink, an open-source,
multi-agent artificial intelligence framework designed to operationalize
serendipity in materials research by creating a direct, automated link between
experimental observation, novelty assessment, and theoretical simulations. The
framework employs a hybrid AI strategy where specialized machine learning
models perform quantitative analysis of experimental data, while large language
models handle higher-level reasoning. These agents autonomously convert raw
data from materials characterization techniques into falsifiable scientific
claims, which are then quantitatively scored for novelty against the published
literature. We demonstrate the framework's versatility across diverse research
scenarios, showcasing its application to atomic-resolution and hyperspectral
data, its capacity to integrate real-time human expert guidance, and its
ability to close the research loop by proposing targeted follow-up experiments.
By systematically analyzing all observations and contextualizing them, SciLink
provides a practical framework for AI-driven materials research that not only
enhances efficiency but also actively cultivates an environment ripe for
serendipitous discoveries, thereby bridging the gap between automated
experimentation and open-ended scientific exploration.

</details>


### [415] [Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets](https://arxiv.org/abs/2508.06706)
*Jaikrishna Manojkumar Patil,Nathaniel Lee,Al Mehdi Saadat Chowdhury,YooJung Choi,Paulo Shakarian*

Main category: cs.AI

Relevance: 40.0

TL;DR: 提出了一种基于规则上下文和概率电路的知识图谱补全方法，显著减少规则数量并保持高性能。


<details>
  <summary>Details</summary>
Motivation: 解决规则方法中规则数量过多导致解释性下降的问题，同时提升性能。

Method: 从训练数据中发现规则上下文，利用概率电路分布快速达到全规则集性能。

Result: 规则数量减少70-96%，性能提升31倍，保留91%峰值性能。

Conclusion: 方法在8个基准数据集上验证有效，对概率推理有潜在影响。

Abstract: Rule-based methods for knowledge graph completion provide explainable results
but often require a significantly large number of rules to achieve competitive
performance. This can hinder explainability due to overwhelmingly large rule
sets. We discover rule contexts (meaningful subsets of rules that work
together) from training data and use learned probability distribution (i.e.
probabilistic circuits) over these rule contexts to more rapidly achieve
performance of the full rule set. Our approach achieves a 70-96% reduction in
number of rules used while outperforming baseline by up to 31$\times$ when
using equivalent minimal number of rules and preserves 91% of peak baseline
performance even when comparing our minimal rule sets against baseline's full
rule sets. We show that our framework is grounded in well-known semantics of
probabilistic logic, does not require independence assumptions, and that our
tractable inference procedure provides both approximate lower bounds and exact
probability of a given query. The efficacy of our method is validated by
empirical studies on 8 standard benchmark datasets where we show competitive
performance by using only a fraction of the rules required by AnyBURL's
standard inference method, the current state-of-the-art for rule-based
knowledge graph completion. This work may have further implications for general
probabilistic reasoning over learned sets of rules.

</details>


### [416] [GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning](https://arxiv.org/abs/2508.06716)
*Blair Johnson,Clayton Kerce,Faramarz Fekri*

Main category: cs.AI

Relevance: 40.0

TL;DR: GLIDR是一种可微分的规则学习方法，通过更灵活的语法和推理算法提升知识图谱任务的性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有链式规则结构的局限性影响了知识图谱任务的性能和可解释性，GLIDR旨在通过更灵活的规则表达解决这一问题。

Method: GLIDR采用可微分消息传递推理算法，支持分支和循环等复杂规则结构，并允许从模型权重中提取显式逻辑规则。

Result: GLIDR在知识图谱补全任务中显著优于现有规则学习方法，甚至可与嵌入方法竞争，且对训练数据噪声具有高鲁棒性。

Conclusion: GLIDR为规则学习提供了更灵活和强大的工具，并能与深度神经网络结合进行端到端优化。

Abstract: Differentiable inductive logic programming (ILP) techniques have proven
effective at finding approximate rule-based solutions to link prediction and
node classification problems on knowledge graphs; however, the common
assumption of chain-like rule structure can hamper the performance and
interpretability of existing approaches. We introduce GLIDR, a differentiable
rule learning method that models the inference of logic rules with more
expressive syntax than previous methods. GLIDR uses a differentiable message
passing inference algorithm that generalizes previous chain-like rule learning
methods to allow rules with features like branches and cycles. GLIDR has a
simple and expressive rule search space which is parameterized by a limit on
the maximum number of free variables that may be included in a rule. Explicit
logic rules can be extracted from the weights of a GLIDR model for use with
symbolic solvers. We demonstrate that GLIDR can significantly outperform
existing rule learning methods on knowledge graph completion tasks and even
compete with embedding methods despite the inherent disadvantage of being a
structure-only prediction method. We show that rules extracted from GLIDR
retain significant predictive performance, and that GLIDR is highly robust to
training data noise. Finally, we demonstrate that GLIDR can be chained with
deep neural networks and optimized end-to-end for rule learning on arbitrary
data modalities.

</details>


### [417] [Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.06836)
*Xutong Zhao,Yaqi Xie*

Main category: cs.AI

Relevance: 40.0

TL;DR: 论文提出了一种多级优势信用分配方法（MACA），用于解决多智能体强化学习中的信用分配问题，通过显式反事实推理评估不同协作级别下智能体的贡献。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）中的信用分配是一个关键挑战，尤其是在任务多样性和智能体协作级别共存的情况下。

Method: MACA通过多级优势公式和注意力框架，评估个体、联合和相关动作的贡献，并进行反事实推理。

Result: 在Starcraft任务上的实验表明，MACA在复杂信用分配场景中表现优异。

Conclusion: MACA能有效解决多级协作下的信用分配问题，适用于复杂任务。

Abstract: Cooperative multi-agent reinforcement learning (MARL) aims to coordinate
multiple agents to achieve a common goal. A key challenge in MARL is credit
assignment, which involves assessing each agent's contribution to the shared
reward. Given the diversity of tasks, agents may perform different types of
coordination, with rewards attributed to diverse and often overlapping agent
subsets. In this work, we formalize the credit assignment level as the number
of agents cooperating to obtain a reward, and address scenarios with multiple
coexisting levels. We introduce a multi-level advantage formulation that
performs explicit counterfactual reasoning to infer credits across distinct
levels. Our method, Multi-level Advantage Credit Assignment (MACA), captures
agent contributions at multiple levels by integrating advantage functions that
reason about individual, joint, and correlated actions. Utilizing an
attention-based framework, MACA identifies correlated agent relationships and
constructs multi-level advantages to guide policy learning. Comprehensive
experiments on challenging Starcraft v1\&v2 tasks demonstrate MACA's superior
performance, underscoring its efficacy in complex credit assignment scenarios.

</details>


### [418] [MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction](https://arxiv.org/abs/2508.06859)
*Shuo Tang,Jian Xu,Jiadong Zhang,Yi Chen,Qizhao Jin,Lingdong Shen,Chenglin Liu,Shiming Xiang*

Main category: cs.AI

Relevance: 40.0

TL;DR: 论文提出MP-Bench数据集和MMLM模型，解决AI气象预测中的样本稀缺、数据对齐和多模态处理问题。


<details>
  <summary>Details</summary>
Motivation: 当前气象预警依赖人工，存在主观性和效率问题，AI端到端预测是趋势，但面临样本稀缺、数据对齐和多模态处理三大挑战。

Method: 构建MP-Bench数据集（42万对气象数据与文本），开发MMLM模型，支持4D气象输入，并设计自适应融合模块处理时空特征。

Result: MMLM在MP-Bench上表现优异，验证了其在气象预测中的有效性。

Conclusion: MMLM为自动化AI气象预测迈出关键一步，代码和数据集将公开。

Abstract: Timely and accurate severe weather warnings are critical for disaster
mitigation. However, current forecasting systems remain heavily reliant on
manual expert interpretation, introducing subjectivity and significant
operational burdens. With the rapid development of AI technologies, the
end-to-end "AI weather station" is gradually emerging as a new trend in
predicting severe weather events. Three core challenges impede the development
of end-to-end AI severe weather system: (1) scarcity of severe weather event
samples; (2) imperfect alignment between high-dimensional meteorological data
and textual warnings; (3) existing multimodal language models are unable to
handle high-dimensional meteorological data and struggle to fully capture the
complex dependencies across temporal sequences, vertical pressure levels, and
spatial dimensions. To address these challenges, we introduce MP-Bench, the
first large-scale temporal multimodal dataset for severe weather events
prediction, comprising 421,363 pairs of raw multi-year meteorological data and
corresponding text caption, covering a wide range of severe weather scenarios
across China. On top of this dataset, we develop a meteorology multimodal large
model (MMLM) that directly ingests 4D meteorological inputs. In addition, it is
designed to accommodate the unique characteristics of 4D meteorological data
flow, incorporating three plug-and-play adaptive fusion modules that enable
dynamic feature extraction and integration across temporal sequences, vertical
pressure layers, and spatial dimensions. Extensive experiments on MP-Bench
demonstrate that MMLM performs exceptionally well across multiple tasks,
highlighting its effectiveness in severe weather understanding and marking a
key step toward realizing automated, AI-driven weather forecasting systems. Our
source code and dataset will be made publicly available.

</details>


### [419] [Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model](https://arxiv.org/abs/2508.06980)
*Aswin Paul,Moein Khajehnejad,Forough Habibollahi,Brett J. Kagan,Adeel Razi*

Main category: cs.AI

Relevance: 40.0

TL;DR: 提出了一种基于主动推理的框架，用于模拟具身代理的决策过程，结合生物神经元网络，探索可解释和高效的AI模型。


<details>
  <summary>Details</summary>
Motivation: 探索生物启发的AI系统，以提高模型的解释性和数据效率，同时为理解自主代理的有目的行为提供基础。

Method: 采用主动推理理论和实验启发生成模型，在模拟游戏环境中模拟决策过程。

Result: 展示了代理的学习能力，揭示了基于记忆的学习和预测规划在智能决策中的作用。

Conclusion: 为可解释AI领域提供了生物基础和可扩展的方法，以理解代理的有目的行为。

Abstract: With recent and rapid advancements in artificial intelligence (AI),
understanding the foundation of purposeful behaviour in autonomous agents is
crucial for developing safe and efficient systems. While artificial neural
networks have dominated the path to AI, recent studies are exploring the
potential of biologically based systems, such as networks of living biological
neuronal networks. Along with promises of high power and data efficiency, these
systems may also inform more explainable and biologically plausible models. In
this work, we propose a framework rooted in active inference, a general theory
of behaviour, to model decision-making in embodied agents. Using
experiment-informed generative models, we simulate decision-making processes in
a simulated game-play environment, mirroring experimental setups that use
biological neurons. Our results demonstrate learning in these agents, providing
insights into the role of memory-based learning and predictive planning in
intelligent decision-making. This work contributes to the growing field of
explainable AI by offering a biologically grounded and scalable approach to
understanding purposeful behaviour in agents.

</details>


### [420] [EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning](https://arxiv.org/abs/2508.07292)
*Yi Tang,Kaini Wang,Yang Chen,Guangquan Zhou*

Main category: cs.AI

Relevance: 40.0

TL;DR: EndoAgent是一种基于双记忆设计的AI代理，用于内窥镜图像诊断，结合迭代推理与自适应工具选择，优于现有通用和医学多模态模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于大规模预训练的方法缺乏任务间的统一协调，难以处理复杂临床工作流的多步骤过程。

Method: 提出EndoAgent，采用双记忆设计（短期动作跟踪和长期经验学习），集成专家设计工具，并引入EndoAgentBench基准测试。

Result: EndoAgent在实验中对通用和医学多模态模型表现优异，展示了强大的灵活性和推理能力。

Conclusion: EndoAgent为内窥镜诊断提供了高效、灵活的AI解决方案，填补了AI代理在该领域的空白。

Abstract: Developing general artificial intelligence (AI) systems to support endoscopic
image diagnosis is an emerging research priority. Existing methods based on
large-scale pretraining often lack unified coordination across tasks and
struggle to handle the multi-step processes required in complex clinical
workflows. While AI agents have shown promise in flexible instruction parsing
and tool integration across domains, their potential in endoscopy remains
underexplored. To address this gap, we propose EndoAgent, the first
memory-guided agent for vision-to-decision endoscopic analysis that integrates
iterative reasoning with adaptive tool selection and collaboration. Built on a
dual-memory design, it enables sophisticated decision-making by ensuring
logical coherence through short-term action tracking and progressively
enhancing reasoning acuity through long-term experiential learning. To support
diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools
within a unified reasoning loop. We further introduce EndoAgentBench, a
benchmark of 5,709 visual question-answer pairs that assess visual
understanding and language generation capabilities in realistic scenarios.
Extensive experiments show that EndoAgent consistently outperforms both general
and medical multimodal models, exhibiting its strong flexibility and reasoning
capabilities.

</details>


### [421] [Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding](https://arxiv.org/abs/2508.07388)
*Zhaoyu Chen,Hongnan Lin,Yongwei Nie,Fei Ma,Xuemiao Xu,Fei Yu,Chengjiang Long*

Main category: cs.AI

Relevance: 40.0

TL;DR: 论文提出Invert4TVG框架，通过三个反转任务增强视频片段定位和语义理解，结合强化学习优化性能，实验显示显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前TVG方法过度优化IoU指标，牺牲语义理解，影响鲁棒性。

Method: 引入三个反转任务（动词补全、动作识别、视频描述），结合强化学习框架。

Result: 在Charades-STA上R1@0.7提升7.1%。

Conclusion: 反转任务增强语义理解，显著提高定位精度上限。

Abstract: Temporal Video Grounding (TVG) seeks to localize video segments matching a
given textual query. Current methods, while optimizing for high temporal
Intersection-over-Union (IoU), often overfit to this metric, compromising
semantic action understanding in the video and query, a critical factor for
robust TVG. To address this, we introduce Inversion Tasks for TVG (Invert4TVG),
a novel framework that enhances both localization accuracy and action
understanding without additional data. Our approach leverages three inversion
tasks derived from existing TVG annotations: (1) Verb Completion, predicting
masked action verbs in queries from video segments; (2) Action Recognition,
identifying query-described actions; and (3) Video Description, generating
descriptions of video segments that explicitly embed query-relevant actions.
These tasks, integrated with TVG via a reinforcement learning framework with
well-designed reward functions, ensure balanced optimization of localization
and semantics. Experiments show our method outperforms state-of-the-art
approaches, achieving a 7.1\% improvement in R1@0.7 on Charades-STA for a 3B
model compared to Time-R1. By inverting TVG to derive query-related actions
from segments, our approach strengthens semantic understanding, significantly
raising the ceiling of localization accuracy.

</details>


### [422] [CP-Agent: Agentic Constraint Programming](https://arxiv.org/abs/2508.07468)
*Stefan Szeider*

Main category: cs.AI

Relevance: 40.0

TL;DR: 提出了一种基于纯代理策略的方法，利用通用Python编码代理（基于ReAct原则）解决约束编程问题，无需固定流程，成功解决了CP-Bench基准集中的所有101个问题。


<details>
  <summary>Details</summary>
Motivation: 自然语言问题描述到形式约束模型的转换需要领域和建模框架的深厚专业知识，现有固定流程方法在基准问题上表现不佳。

Method: 开发了基于ReAct原则的通用Python编码代理，利用持久IPython内核进行状态化代码执行和迭代开发，通过项目提示注入领域知识。

Result: 该方法成功解决了CP-Bench基准集中的所有101个问题。

Conclusion: 约束建模任务需要通用编码工具与提示编码的领域知识结合，而非专用代理架构或预定义流程。

Abstract: Translating natural language problem descriptions into formal constraint
models remains a fundamental challenge in constraint programming, requiring
deep expertise in both the problem domain and modeling frameworks. Previous
approaches to automating this translation have employed fixed workflows with
predetermined modeling steps, failing on a significant number of benchmark
problems. We present a new approach using a pure agentic strategy without any
fixed pipeline. We developed a general-purpose Python coding agent based on the
ReAct (Reason and Act) principle, utilizing a persistent IPython kernel for
stateful code execution and iterative development. Rather than embedding
constraint programming logic into the agent architecture, domain-specific
expertise is injected solely through a carefully crafted project prompt. The
agent combines this prompt-encoded knowledge with access to file operations and
code execution tools, enabling it to test hypotheses, debug failures, and
verify solutions dynamically. Implemented in just a few hundred lines of code,
this architecture successfully solves all 101 problems of the CP-Bench
constraint programming benchmark set. The results suggest that constraint
modeling tasks require the combination of general coding tools and domain
expertise encoded in prompts, rather than specialized agent architectures or
predefined workflows.

</details>


### [423] [Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method](https://arxiv.org/abs/2508.07586)
*Wenjing Zhang,Ye Hu,Tao Luo,Zhilong Zhang,Mingzhe Chen*

Main category: cs.AI

Relevance: 40.0

TL;DR: 论文提出了一种新型隐蔽语义通信框架，通过友好干扰器和服务器联合优化传输策略，提升隐私和语义信息传输质量。


<details>
  <summary>Details</summary>
Motivation: 研究动机是保护语义通信中的隐私，防止攻击者窃取图像数据的语义信息。

Method: 采用优先采样辅助的双延迟深度确定性策略梯度算法，联合优化语义信息和传输功率。

Result: 仿真结果显示，相比传统强化学习方法，隐私和传输质量分别提升77.8%和14.3%。

Conclusion: 提出的算法有效解决了无通信干扰器下的联合优化问题，显著提升了性能。

Abstract: In this paper, a novel covert semantic communication framework is
investigated. Within this framework, a server extracts and transmits the
semantic information, i.e., the meaning of image data, to a user over several
time slots. An attacker seeks to detect and eavesdrop the semantic transmission
to acquire details of the original image. To avoid data meaning being
eavesdropped by an attacker, a friendly jammer is deployed to transmit jamming
signals to interfere the attacker so as to hide the transmitted semantic
information. Meanwhile, the server will strategically select time slots for
semantic information transmission. Due to limited energy, the jammer will not
communicate with the server and hence the server does not know the transmit
power of the jammer. Therefore, the server must jointly optimize the semantic
information transmitted at each time slot and the corresponding transmit power
to maximize the privacy and the semantic information transmission quality of
the user. To solve this problem, we propose a prioritised sampling assisted
twin delayed deep deterministic policy gradient algorithm to jointly determine
the transmitted semantic information and the transmit power per time slot
without the communications between the server and the jammer. Compared to
standard reinforcement learning methods, the propose method uses an additional
Q network to estimate Q values such that the agent can select the action with a
lower Q value from the two Q networks thus avoiding local optimal action
selection and estimation bias of Q values. Simulation results show that the
proposed algorithm can improve the privacy and the semantic information
transmission quality by up to 77.8% and 14.3% compared to the traditional
reinforcement learning methods.

</details>


### [424] [Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents](https://arxiv.org/abs/2508.07642)
*Tianyi Ma,Yue Zhang,Zehao Wang,Parisa Kordjamshidi*

Main category: cs.AI

Relevance: 40.0

TL;DR: SkillNav是一个模块化框架，通过将导航任务分解为可解释的原子技能，并利用VLM路由动态选择最佳技能代理，提升了Transformer-based VLN代理的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前VLN方法在复杂空间和时间推理场景中泛化能力不足，需要更结构化的方法。

Method: 提出SkillNav框架，将导航任务分解为原子技能，每个技能由专门代理处理，并使用VLM路由动态选择代理。

Result: 在R2R和GSA-R2R基准测试中达到新SOTA，展示了强大的泛化能力。

Conclusion: SkillNav通过结构化技能和动态路由显著提升了VLN任务的性能和泛化能力。

Abstract: Vision-and-Language Navigation (VLN) poses significant challenges in enabling
agents to interpret natural language instructions and navigate complex 3D
environments. While recent progress has been driven by large-scale pre-training
and data augmentation, current methods still struggle to generalize to unseen
scenarios, particularly when complex spatial and temporal reasoning is
required. In this work, we propose SkillNav, a modular framework that
introduces structured, skill-based reasoning into Transformer-based VLN agents.
Our method decomposes navigation into a set of interpretable atomic skills
(e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each
handled by a specialized agent. We then introduce a novel zero-shot
Vision-Language Model (VLM)-based router, which dynamically selects the most
suitable agent at each time step by aligning sub-goals with visual observations
and historical actions. SkillNav achieves a new state-of-the-art performance on
the R2R benchmark and demonstrates strong generalization to the GSA-R2R
benchmark that includes novel instruction styles and unseen environments.

</details>


### [425] [EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration](https://arxiv.org/abs/2508.07671)
*Mohamed Rayan Barhdadi,Mehmet Tuncel,Erchin Serpedin,Hasan Kurban*

Main category: cs.AI

Relevance: 40.0

TL;DR: EMPATHIA是一个多智能体框架，用于难民整合，结合文化、情感和伦理因素，提供透明且可解释的决策支持。


<details>
  <summary>Details</summary>
Motivation: 当前AI方法在难民整合中过于关注狭窄目标（如就业），而忽略了文化、情感和伦理维度。EMPATHIA旨在解决如何在机器参与重大决策时保持人类尊严的问题。

Method: 基于Kegan的建构发展理论，EMPATHIA分为三个模块：SEED（初始安置）、RISE（早期独立）和THRIVE（持续成果）。SEED采用选择器-验证器架构，由情感、文化和伦理三个智能体透明决策。

Result: 在UN Kakuma数据集上，EMPATHIA实现了87.4%的验证收敛，并在五个东道国提供了可解释的评估。

Conclusion: EMPATHIA通过平衡文化、情感和伦理因素，为多价值协调的AI驱动任务提供了通用框架。

Abstract: Current AI approaches to refugee integration optimize narrow objectives such
as employment and fail to capture the cultural, emotional, and ethical
dimensions critical for long-term success. We introduce EMPATHIA (Enriched
Multimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance),
a multi-agent framework addressing the central Creative AI question: how do we
preserve human dignity when machines participate in life-altering decisions?
Grounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes
integration into three modules: SEED (Socio-cultural Entry and Embedding
Decision) for initial placement, RISE (Rapid Integration and Self-sufficiency
Engine) for early independence, and THRIVE (Transcultural Harmony and
Resilience through Integrated Values and Engagement) for sustained outcomes.
SEED employs a selector-validator architecture with three specialized agents -
emotional, cultural, and ethical - that deliberate transparently to produce
interpretable recommendations. Experiments on the UN Kakuma dataset (15,026
individuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and
implementation on 6,359 working-age refugees (15+) with 150+ socioeconomic
variables achieved 87.4% validation convergence and explainable assessments
across five host countries. EMPATHIA's weighted integration of cultural,
emotional, and ethical factors balances competing value systems while
supporting practitioner-AI collaboration. By augmenting rather than replacing
human expertise, EMPATHIA provides a generalizable framework for AI-driven
allocation tasks where multiple values must be reconciled.

</details>


### [426] [Best-Effort Policies for Robust Markov Decision Processes](https://arxiv.org/abs/2508.07790)
*Alessandro Abate,Thom Badings,Giuseppe De Giacomo,Francesco Fabiano*

Main category: cs.AI

Relevance: 40.0

TL;DR: 该论文提出了一种新的策略选择标准ORBE（最优鲁棒最佳努力策略），用于在鲁棒马尔可夫决策过程（RMDPs）中打破最优鲁棒策略的平局，同时考虑非对抗性转移概率下的表现。


<details>
  <summary>Details</summary>
Motivation: 在RMDPs中，存在多个最优鲁棒策略，这些策略在最坏情况下表现相同，但在非对抗性情况下表现不同。因此，需要一种更精细的策略选择标准。

Method: 提出ORBE策略，结合了博弈论中的支配和最佳努力概念，通过算法计算ORBE策略。

Result: 证明了ORBE策略的存在性，并展示了其计算可行性。

Conclusion: ORBE策略为RMDPs提供了一种更全面的策略选择方法。

Abstract: We study the common generalization of Markov decision processes (MDPs) with
sets of transition probabilities, known as robust MDPs (RMDPs). A standard goal
in RMDPs is to compute a policy that maximizes the expected return under an
adversarial choice of the transition probabilities. If the uncertainty in the
probabilities is independent between the states, known as s-rectangularity,
such optimal robust policies can be computed efficiently using robust value
iteration. However, there might still be multiple optimal robust policies,
which, while equivalent with respect to the worst-case, reflect different
expected returns under non-adversarial choices of the transition probabilities.
Hence, we propose a refined policy selection criterion for RMDPs, drawing
inspiration from the notions of dominance and best-effort in game theory.
Instead of seeking a policy that only maximizes the worst-case expected return,
we additionally require the policy to achieve a maximal expected return under
different (i.e., not fully adversarial) transition probabilities. We call such
a policy an optimal robust best-effort (ORBE) policy. We prove that ORBE
policies always exist, characterize their structure, and present an algorithm
to compute them with a small overhead compared to standard robust value
iteration. ORBE policies offer a principled tie-breaker among optimal robust
policies. Numerical experiments show the feasibility of our approach.

</details>


### [427] [FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis](https://arxiv.org/abs/2508.07950)
*Chen Shen,Wanqing Zhang,Kehan Li,Erwen Huang,Haitao Bi,Aiying Fan,Yiwen Shen,Hongmei Dong,Ji Zhang,Yuming Shao,Zengjia Liu,Xinshe Liu,Tao Li,Chunxia Yan,Shuanliang Fan,Di Wu,Jianhua Ma,Bin Cong,Zhenyuan Wang,Chunfeng Lian*

Main category: cs.AI

Relevance: 40.0

TL;DR: FEAT是一个基于多智能体AI框架的LLM系统，用于自动化和标准化法医死因调查，通过任务分解、证据分析、迭代优化和结论合成，显著提升了法医诊断的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决法医死因诊断中的劳动力短缺和诊断差异问题，特别是在高负荷的法医系统中。

Method: FEAT采用多智能体架构，包括任务规划器、本地求解器、记忆与反思模块和全局求解器，结合工具增强推理、层次化检索增强生成和法医调优的LLM。

Result: 在多样化的中国案例中，FEAT优于现有AI系统，表现出强大的泛化能力和专家级一致性。

Conclusion: FEAT是首个基于LLM的法医AI系统，结合AI效率和人类监督，可提升法医服务的公平性和可靠性。

Abstract: Forensic cause-of-death determination faces systemic challenges, including
workforce shortages and diagnostic variability, particularly in high-volume
systems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic
AgenT), a multi-agent AI framework that automates and standardizes death
investigations through a domain-adapted large language model. FEAT's
application-oriented architecture integrates: (i) a central Planner for task
decomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a
Memory & Reflection module for iterative refinement, and (iv) a Global Solver
for conclusion synthesis. The system employs tool-augmented reasoning,
hierarchical retrieval-augmented generation, forensic-tuned LLMs, and
human-in-the-loop feedback to ensure legal and medical validity. In evaluations
across diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI
systems in both long-form autopsy analyses and concise cause-of-death
conclusions. It demonstrated robust generalization across six geographic
regions and achieved high expert concordance in blinded validations. Senior
pathologists validated FEAT's outputs as comparable to those of human experts,
with improved detection of subtle evidentiary nuances. To our knowledge, FEAT
is the first LLM-based AI agent system dedicated to forensic medicine, offering
scalable, consistent death certification while maintaining expert-level rigor.
By integrating AI efficiency with human oversight, this work could advance
equitable access to reliable medicolegal services while addressing critical
capacity constraints in forensic systems.

</details>


### [428] [Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths](https://arxiv.org/abs/2508.08001)
*Rui Yao,Qi Chai,Jinhai Yao,Siyuan Li,Junhao Chen,Qi Zhang,Hao Wang*

Main category: cs.AI

Relevance: 40.0

TL;DR: 本文提出了一种基于LLM的框架，用于解析Fedspeak并分类其货币政策立场，结合领域特定推理和动态不确定性解码模块，取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: Fedspeak作为美联储的政策信号工具，对金融市场和经济预测有重要影响，自动解析Fedspeak具有高价值。

Method: 结合货币政策传导机制的领域特定推理，并引入动态不确定性解码模块，提升分类准确性和模型可靠性。

Result: 实验表明，该框架在政策立场分析任务中达到最先进性能，且感知不确定性与模型错误率显著正相关。

Conclusion: 该框架有效提升了Fedspeak解析的准确性和可靠性，感知不确定性可作为诊断信号。

Abstract: "Fedspeak", the stylized and often nuanced language used by the U.S. Federal
Reserve, encodes implicit policy signals and strategic stances. The Federal
Open Market Committee strategically employs Fedspeak as a communication tool to
shape market expectations and influence both domestic and global economic
conditions. As such, automatically parsing and interpreting Fedspeak presents a
high-impact challenge, with significant implications for financial forecasting,
algorithmic trading, and data-driven policy analysis. In this paper, we propose
an LLM-based, uncertainty-aware framework for deciphering Fedspeak and
classifying its underlying monetary policy stance. Technically, to enrich the
semantic and contextual representation of Fedspeak texts, we incorporate
domain-specific reasoning grounded in the monetary policy transmission
mechanism. We further introduce a dynamic uncertainty decoding module to assess
the confidence of model predictions, thereby enhancing both classification
accuracy and model reliability. Experimental results demonstrate that our
framework achieves state-of-the-art performance on the policy stance analysis
task. Moreover, statistical analysis reveals a significant positive correlation
between perceptual uncertainty and model error rates, validating the
effectiveness of perceptual uncertainty as a diagnostic signal.

</details>


### [429] [Forecasting Commodity Price Shocks Using Temporal and Semantic Fusion of Prices Signals and Agentic Generative AI Extracted Economic News](https://arxiv.org/abs/2508.06497)
*Mohammed-Khalil Ghali,Cecil Pang,Oscar Molina,Carlos Gershenson-Garcia,Daehan Won*

Main category: q-fin.CP

Relevance: 40.0

TL;DR: 论文提出了一种结合历史商品价格数据和全球经济新闻语义信号的混合预测框架，使用生成式AI管道，显著提升了商品价格波动的预测性能。


<details>
  <summary>Details</summary>
Motivation: 商品价格波动对经济缓冲有限的国家至关重要，传统方法预测效果不佳，因此需要结合语义信号提升预测准确性。

Method: 采用双流LSTM网络与注意力机制，融合时间序列数据和语义嵌入的新闻摘要，评估了64年数据集。

Result: 模型AUC达0.94，准确率0.91，远超传统方法；新闻信号的去除导致性能大幅下降。

Conclusion: 生成式AI与深度学习的结合可有效提升商品价格波动预测，为经济规划提供实用工具。

Abstract: Accurate forecasting of commodity price spikes is vital for countries with
limited economic buffers, where sudden increases can strain national budgets,
disrupt import-reliant sectors, and undermine food and energy security. This
paper introduces a hybrid forecasting framework that combines historical
commodity price data with semantic signals derived from global economic news,
using an agentic generative AI pipeline. The architecture integrates
dual-stream Long Short-Term Memory (LSTM) networks with attention mechanisms to
fuse structured time-series inputs with semantically embedded, fact-checked
news summaries collected from 1960 to 2023. The model is evaluated on a 64-year
dataset comprising normalized commodity price series and temporally aligned
news embeddings. Results show that the proposed approach achieves a mean AUC of
0.94 and an overall accuracy of 0.91 substantially outperforming traditional
baselines such as logistic regression (AUC = 0.34), random forest (AUC = 0.57),
and support vector machines (AUC = 0.47). Additional ablation studies reveal
that the removal of attention or dimensionality reduction leads to moderate
declines in performance, while eliminating the news component causes a steep
drop in AUC to 0.46, underscoring the critical value of incorporating
real-world context through unstructured text. These findings demonstrate that
integrating agentic generative AI with deep learning can meaningfully improve
early detection of commodity price shocks, offering a practical tool for
economic planning and risk mitigation in volatile market environments while
saving the very high costs of operating a full generative AI agents pipeline.

</details>


### [430] [MetAdv: A Unified and Interactive Adversarial Testing Platform for Autonomous Driving](https://arxiv.org/abs/2508.06534)
*Aishan Liu,Jiakai Wang,Tianyuan Zhang,Hainan Li,Jiangfan Liu,Siyuan Liang,Yilong Ren,Xianglong Liu,Dacheng Tao*

Main category: cs.RO

Relevance: 40.0

TL;DR: MetAdv是一个新型对抗测试平台，用于评估自动驾驶系统的对抗鲁棒性，通过虚拟仿真与物理车辆反馈的紧密结合实现动态评估。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的对抗鲁棒性评估是一个关键但未解决的挑战，需要一种动态且交互式的测试方法。

Method: MetAdv采用三层闭环测试环境设计，结合虚拟仿真与物理车辆反馈，支持多种自动驾驶任务和算法范式，并具备人机交互能力。

Result: MetAdv提供了一个可扩展的统一对抗评估框架，支持从高层对抗生成到低层物理执行的端到端评估。

Conclusion: MetAdv为自动驾驶系统的对抗鲁棒性评估提供了创新解决方案，有望推动更安全的自动驾驶技术发展。

Abstract: Evaluating and ensuring the adversarial robustness of autonomous driving (AD)
systems is a critical and unresolved challenge. This paper introduces MetAdv, a
novel adversarial testing platform that enables realistic, dynamic, and
interactive evaluation by tightly integrating virtual simulation with physical
vehicle feedback. At its core, MetAdv establishes a hybrid virtual-physical
sandbox, within which we design a three-layer closed-loop testing environment
with dynamic adversarial test evolution. This architecture facilitates
end-to-end adversarial evaluation, ranging from high-level unified adversarial
generation, through mid-level simulation-based interaction, to low-level
execution on physical vehicles. Additionally, MetAdv supports a broad spectrum
of AD tasks, algorithmic paradigms (e.g., modular deep learning pipelines,
end-to-end learning, vision-language models). It supports flexible 3D vehicle
modeling and seamless transitions between simulated and physical environments,
with built-in compatibility for commercial platforms such as Apollo and Tesla.
A key feature of MetAdv is its human-in-the-loop capability: besides flexible
environmental configuration for more customized evaluation, it enables
real-time capture of physiological signals and behavioral feedback from
drivers, offering new insights into human-machine trust under adversarial
conditions. We believe MetAdv can offer a scalable and unified framework for
adversarial assessment, paving the way for safer AD.

</details>


### [431] [Omni Geometry Representation Learning vs Large Language Models for Geospatial Entity Resolution](https://arxiv.org/abs/2508.06584)
*Kalana Wijegunarathna,Kristin Stock,Christopher B. Jones*

Main category: cs.DB

Relevance: 40.0

TL;DR: 论文提出Omni模型，解决地理空间实体解析中多样几何形状嵌入问题，结合Transformer预训练语言模型，性能提升12%。同时探索LLM在地理空间解析中的潜力。


<details>
  <summary>Details</summary>
Motivation: 地理空间实体解析中多样几何形状的嵌入问题未被充分解决，现有方法简化几何形状导致信息丢失。

Method: 提出Omni模型，包含全几何编码器，支持多种几何形状嵌入，并结合Transformer预训练语言模型处理文本属性。

Result: Omni在现有数据集上性能提升12%，并验证LLM在地理空间解析中的竞争力。

Conclusion: Omni解决了多样几何形状嵌入问题，LLM在地理空间解析中具有潜力。

Abstract: The development, integration, and maintenance of geospatial databases rely
heavily on efficient and accurate matching procedures of Geospatial Entity
Resolution (ER). While resolution of points-of-interest (POIs) has been widely
addressed, resolution of entities with diverse geometries has been largely
overlooked. This is partly due to the lack of a uniform technique for embedding
heterogeneous geometries seamlessly into a neural network framework. Existing
neural approaches simplify complex geometries to a single point, resulting in
significant loss of spatial information. To address this limitation, we propose
Omni, a geospatial ER model featuring an omni-geometry encoder. This encoder is
capable of embedding point, line, polyline, polygon, and multi-polygon
geometries, enabling the model to capture the complex geospatial intricacies of
the places being compared. Furthermore, Omni leverages transformer-based
pre-trained language models over individual textual attributes of place records
in an Attribute Affinity mechanism. The model is rigorously tested on existing
point-only datasets and a new diverse-geometry geospatial ER dataset. Omni
produces up to 12% (F1) improvement over existing methods.
  Furthermore, we test the potential of Large Language Models (LLMs) to conduct
geospatial ER, experimenting with prompting strategies and learning scenarios,
comparing the results of pre-trained language model-based methods with LLMs.
Results indicate that LLMs show competitive results.

</details>


### [432] [Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody](https://arxiv.org/abs/2508.06890)
*Jinsung Yoon,Wooyeol Jeong,Jio Gim,Young-Joo Suh*

Main category: cs.SD

Relevance: 40.0

TL;DR: Maestro-EVC是一个可控的情感语音转换框架，能够独立控制内容、说话者身份和情感，并通过时间情感表示和显式韵律建模捕捉情感动态。


<details>
  <summary>Details</summary>
Motivation: 现有方法在解耦说话者身份和情感风格时存在困难，且难以建模细粒度情感表达（如时间动态）。

Method: 提出Maestro-EVC框架，通过解耦属性、时间情感表示和显式韵律建模（包括韵律增强）实现独立控制。

Result: 实验证明Maestro-EVC能生成高质量、可控且情感丰富的语音合成。

Conclusion: Maestro-EVC在情感语音转换中实现了高可控性和情感表达力。

Abstract: Emotional voice conversion (EVC) aims to modify the emotional style of speech
while preserving its linguistic content. In practical EVC, controllability, the
ability to independently control speaker identity and emotional style using
distinct references, is crucial. However, existing methods often struggle to
fully disentangle these attributes and lack the ability to model fine-grained
emotional expressions such as temporal dynamics. We propose Maestro-EVC, a
controllable EVC framework that enables independent control of content, speaker
identity, and emotion by effectively disentangling each attribute from separate
references. We further introduce a temporal emotion representation and an
explicit prosody modeling with prosody augmentation to robustly capture and
transfer the temporal dynamics of the target emotion, even under
prosody-mismatched conditions. Experimental results confirm that Maestro-EVC
achieves high-quality, controllable, and emotionally expressive speech
synthesis.

</details>


### [433] [TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree](https://arxiv.org/abs/2508.07014)
*Andrei Andrusenko,Vladimir Bataev,Lilit Grigoryan,Vitaly Lavrukhin,Boris Ginsburg*

Main category: eess.AS

Relevance: 40.0

TL;DR: 提出了一种通用的ASR上下文偏置框架，支持所有主要ASR模型类型，无需额外训练，且解码速度无明显下降。


<details>
  <summary>Details</summary>
Motivation: 现有上下文偏置方法需额外训练、解码速度慢或限制ASR系统类型，亟需一种通用高效解决方案。

Method: 基于GPU加速的单词提升树，支持浅融合模式，适用于贪婪和束搜索解码。

Result: 在20K关键词下仍保持高效，准确率和解码速度优于现有开源方法。

Conclusion: 该框架作为NeMo工具包的一部分开源，为ASR上下文偏置提供了高效通用方案。

Abstract: Recognizing specific key phrases is an essential task for contextualized
Automatic Speech Recognition (ASR). However, most existing context-biasing
approaches have limitations associated with the necessity of additional model
training, significantly slow down the decoding process, or constrain the choice
of the ASR system type. This paper proposes a universal ASR context-biasing
framework that supports all major types: CTC, Transducers, and Attention
Encoder-Decoder models. The framework is based on a GPU-accelerated word
boosting tree, which enables it to be used in shallow fusion mode for greedy
and beam search decoding without noticeable speed degradation, even with a vast
number of key phrases (up to 20K items). The obtained results showed high
efficiency of the proposed method, surpassing the considered open-source
context-biasing approaches in accuracy and decoding speed. Our context-biasing
framework is open-sourced as a part of the NeMo toolkit.

</details>


### [434] [SQL-Exchange: Transforming SQL Queries Across Domains](https://arxiv.org/abs/2508.07087)
*Mohammadreza Daviran,Brian Lin,Davood Rafiei*

Main category: cs.DB

Relevance: 40.0

TL;DR: SQL-Exchange框架通过保留源查询结构并调整领域特定元素，实现不同数据库模式间的SQL查询映射，提升文本到SQL系统的上下文学习性能。


<details>
  <summary>Details</summary>
Motivation: 研究不同数据库模式间SQL查询映射的可行性和益处，及其对文本到SQL系统性能的影响。

Method: 提出SQL-Exchange框架，评估其在多种模型和数据集上的结构对齐、执行有效性和语义正确性。

Result: SQL-Exchange在多种模式和查询类型中有效，映射查询作为上下文示例优于源模式查询。

Conclusion: SQL-Exchange为跨模式SQL查询映射提供了有效解决方案，并提升了文本到SQL系统的性能。

Abstract: We introduce SQL-Exchange, a framework for mapping SQL queries across
different database schemas by preserving the source query structure while
adapting domain-specific elements to align with the target schema. We
investigate the conditions under which such mappings are feasible and
beneficial, and examine their impact on enhancing the in-context learning
performance of text-to-SQL systems as a downstream task. Our comprehensive
evaluation across multiple model families and benchmark datasets--assessing
structural alignment with source queries, execution validity on target
databases, and semantic correctness--demonstrates that SQL-Exchange is
effective across a wide range of schemas and query types. Our results further
show that using mapped queries as in-context examples consistently improves
text-to-SQL performance over using queries from the source schema.

</details>


### [435] [Propagation Tree Is Not Deep: Adaptive Graph Contrastive Learning Approach for Rumor Detection](https://arxiv.org/abs/2508.07201)
*Chaoqun Cui,Caiyan Jia*

Main category: cs.SI

Relevance: 40.0

TL;DR: 论文提出了一种针对社交媒体谣言检测的图对比学习方法（RAGCL），通过自适应视图增强和节点中心性指导，解决了现有方法对谣言传播树（RPTs）深度结构的假设问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的谣言检测模型假设RPTs具有深度结构，但实际数据统计显示RPTs多为宽结构。论文旨在通过自适应学习集中子结构来解决这一问题。

Method: 提出RAGCL方法，基于节点中心性进行自适应视图增强（节点丢弃、属性掩码、边丢弃），并通过图对比目标学习鲁棒的谣言表示。

Result: 在四个基准数据集上的实验表明，RAGCL优于现有方法。

Conclusion: 论文揭示了RPTs的宽结构特性，并提出了一种有效的图对比学习方法，其自适应增强原则可推广至其他树结构图应用。

Abstract: Rumor detection on social media has become increasingly important. Most
existing graph-based models presume rumor propagation trees (RPTs) have deep
structures and learn sequential stance features along branches. However,
through statistical analysis on real-world datasets, we find RPTs exhibit wide
structures, with most nodes being shallow 1-level replies. To focus learning on
intensive substructures, we propose Rumor Adaptive Graph Contrastive Learning
(RAGCL) method with adaptive view augmentation guided by node centralities. We
summarize three principles for RPT augmentation: 1) exempt root nodes, 2)
retain deep reply nodes, 3) preserve lower-level nodes in deep sections. We
employ node dropping, attribute masking and edge dropping with probabilities
from centrality-based importance scores to generate views. A graph contrastive
objective then learns robust rumor representations. Extensive experiments on
four benchmark datasets demonstrate RAGCL outperforms state-of-the-art methods.
Our work reveals the wide-structure nature of RPTs and contributes an effective
graph contrastive learning approach tailored for rumor detection through
principled adaptive augmentation. The proposed principles and augmentation
techniques can potentially benefit other applications involving tree-structured
graphs.

</details>


### [436] [Learning Causal Structure Distributions for Robust Planning](https://arxiv.org/abs/2508.06742)
*Alejandro Murillo-Gonzalez,Junhong Xu,Lantao Liu*

Main category: cs.RO

Relevance: 40.0

TL;DR: 论文提出了一种通过学习功能关系并考虑结构信息不确定性的方法，以提高机器人系统的鲁棒性动态模型，同时减少计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 传统模型学习方法忽略因果结构，未能利用机器人系统中交互的稀疏性，导致模型鲁棒性和效率不足。

Method: 通过估计因果结构分布，采样因果图以指导编码器-多解码器概率模型中的潜在空间表示。

Result: 模型能够学习机器人动态，结合采样规划器在新环境中执行任务，并验证了其对输入损坏和环境变化的适应性及鲁棒性。

Conclusion: 该方法显著提升了机器人动态模型的鲁棒性和效率，适用于复杂现实场景。

Abstract: Structural causal models describe how the components of a robotic system
interact. They provide both structural and functional information about the
relationships that are present in the system. The structural information
outlines the variables among which there is interaction. The functional
information describes how such interactions work, via equations or learned
models. In this paper we find that learning the functional relationships while
accounting for the uncertainty about the structural information leads to more
robust dynamics models which improves downstream planning, while using
significantly lower computational resources. This in contrast with common
model-learning methods that ignore the causal structure and fail to leverage
the sparsity of interactions in robotic systems. We achieve this by estimating
a causal structure distribution that is used to sample causal graphs that
inform the latent-space representations in an encoder-multidecoder
probabilistic model. We show that our model can be used to learn the dynamics
of a robot, which together with a sampling-based planner can be used to perform
new tasks in novel environments, provided an objective function for the new
requirement is available. We validate our method using manipulators and mobile
robots in both simulation and the real-world. Additionally, we validate the
learned dynamics' adaptability and increased robustness to corrupted inputs and
changes in the environment, which is highly desirable in challenging real-world
robotics scenarios. Video: https://youtu.be/X6k5t7OOnNc.

</details>


### [437] [FlexCTC: GPU-powered CTC Beam Decoding with advanced Contextual Abilities](https://arxiv.org/abs/2508.07315)
*Lilit Grigoryan,Vladimir Bataev,Nikolay Karpov,Andrei Andrusenko,Vitaly Lavrukhin,Boris Ginsburg*

Main category: eess.AS

Relevance: 40.0

TL;DR: 论文介绍了FlexCTC，一个基于GPU的快速、用户友好的CTC模型解码工具包，支持高级上下文技术。


<details>
  <summary>Details</summary>
Motivation: 传统CTC解码实现速度慢且受限于CPU，无法充分利用现代硬件性能。

Method: 开发了完全基于Python和PyTorch的FlexCTC工具包，采用高性能GPU实现，消除CPU-GPU同步，支持N-gram语言模型融合和短语级提升。

Result: 实现了高效、准确的解码，适用于研究和生产环境。

Conclusion: FlexCTC为CTC模型提供了快速、可扩展的解码解决方案。

Abstract: While beam search improves speech recognition quality over greedy decoding,
standard implementations are slow, often sequential, and CPU-bound. To fully
leverage modern hardware capabilities, we present a novel open-source FlexCTC
toolkit for fully GPU-based beam decoding, designed for Connectionist Temporal
Classification (CTC) models. Developed entirely in Python and PyTorch, it
offers a fast, user-friendly, and extensible alternative to traditional C++,
CUDA, or WFST-based decoders. The toolkit features a high-performance, fully
batched GPU implementation with eliminated CPU-GPU synchronization and
minimized kernel launch overhead via CUDA Graphs. It also supports advanced
contextualization techniques, including GPU-powered N-gram language model
fusion and phrase-level boosting. These features enable accurate and efficient
decoding, making them suitable for both research and production use.

</details>


### [438] [Conversational DNA: A New Visual Language for Understanding Dialogue Structure in Human and AI](https://arxiv.org/abs/2508.07520)
*Baihan Lin*

Main category: cs.HC

Relevance: 40.0

TL;DR: 提出了一种名为Conversational DNA的新视觉语言，通过生物隐喻揭示对话的时空结构，用于可视化、比较和理解对话。


<details>
  <summary>Details</summary>
Motivation: 传统对话分析将丰富的互动简化为统计摘要，无法充分揭示对话的深层结构和意义。本文旨在通过生物隐喻和可视化方法，揭示对话中的隐藏模式。

Method: 引入Conversational DNA，通过生物隐喻（如链厚度表示语言复杂性、颜色梯度表示情感轨迹）可视化对话结构，并应用于治疗对话和人类-AI对话的分析。

Result: 该方法揭示了传统方法忽略的互动模式，为理解对话提供了新的框架。

Conclusion: Conversational DNA为沟通理解提供了创新框架，结合了数据可视化、人机交互和对话意义的探索。

Abstract: What if the patterns hidden within dialogue reveal more about communication
than the words themselves? We introduce Conversational DNA, a novel visual
language that treats any dialogue -- whether between humans, between human and
AI, or among groups -- as a living system with interpretable structure that can
be visualized, compared, and understood. Unlike traditional conversation
analysis that reduces rich interaction to statistical summaries, our approach
reveals the temporal architecture of dialogue through biological metaphors.
Linguistic complexity flows through strand thickness, emotional trajectories
cascade through color gradients, conversational relevance forms through
connecting elements, and topic coherence maintains structural integrity through
helical patterns. Through exploratory analysis of therapeutic conversations and
historically significant human-AI dialogues, we demonstrate how this
visualization approach reveals interaction patterns that traditional methods
miss. Our work contributes a new creative framework for understanding
communication that bridges data visualization, human-computer interaction, and
the fundamental question of what makes dialogue meaningful in an age where
humans increasingly converse with artificial minds.

</details>


### [439] [Geometry-Aware Spiking Graph Neural Network](https://arxiv.org/abs/2508.06793)
*Bowen Zhang,Genan Dai,Hu Huang,Long Lan*

Main category: cs.NE

Relevance: 40.0

TL;DR: 提出了一种几何感知的脉冲图神经网络（GSG），结合脉冲神经动力学与黎曼流形上的自适应表示学习，显著提升了复杂图结构的建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有脉冲图神经网络主要基于欧几里得空间和固定几何假设，难以建模复杂图结构（如层次和循环）。GSG旨在解决这一限制。

Method: GSG包含三个关键组件：黎曼嵌入层、流形脉冲层和流形学习目标，通过黎曼SGD训练，无需时间反向传播。

Result: 实验表明，GSG在准确性、鲁棒性和能效上优于欧几里得脉冲神经网络和基于流形的图神经网络。

Conclusion: GSG为曲率感知、高效能的图学习建立了新范式。

Abstract: Graph Neural Networks (GNNs) have demonstrated impressive capabilities in
modeling graph-structured data, while Spiking Neural Networks (SNNs) offer high
energy efficiency through sparse, event-driven computation. However, existing
spiking GNNs predominantly operate in Euclidean space and rely on fixed
geometric assumptions, limiting their capacity to model complex graph
structures such as hierarchies and cycles. To overcome these limitations, we
propose \method{}, a novel Geometry-Aware Spiking Graph Neural Network that
unifies spike-based neural dynamics with adaptive representation learning on
Riemannian manifolds. \method{} features three key components: a Riemannian
Embedding Layer that projects node features into a pool of constant-curvature
manifolds, capturing non-Euclidean structures; a Manifold Spiking Layer that
models membrane potential evolution and spiking behavior in curved spaces via
geometry-consistent neighbor aggregation and curvature-based attention; and a
Manifold Learning Objective that enables instance-wise geometry adaptation
through jointly optimized classification and link prediction losses defined
over geodesic distances. All modules are trained using Riemannian SGD,
eliminating the need for backpropagation through time. Extensive experiments on
multiple benchmarks show that GSG achieves superior accuracy, robustness, and
energy efficiency compared to both Euclidean SNNs and manifold-based GNNs,
establishing a new paradigm for curvature-aware, energy-efficient graph
learning.

</details>


### [440] [Balancing Privacy and Efficiency: Music Information Retrieval via Additive Homomorphic Encryption](https://arxiv.org/abs/2508.07044)
*William Zerong Wang,Dongfang Zhao*

Main category: cs.DB

Relevance: 40.0

TL;DR: 论文提出了一种基于加法同态加密（AHE）的音乐嵌入向量隐私保护相似性搜索方法，解决了传统加密和全同态加密（FHE）在性能和实用性上的不足。


<details>
  <summary>Details</summary>
Motivation: 音乐数据的时空性和多模态特性使其向量嵌入易被模型学习或滥用，传统保护方法（如版权许可和数字水印）效果有限，需要更强的加密手段。

Method: 通过分析音乐信息检索系统的威胁模型，提出基于AHE的向量相似性搜索方案，利用音乐嵌入的内积实现隐私保护。

Result: 实验表明，该方法在真实MP3文件上比FHE方案更高效实用。

Conclusion: AHE为音乐嵌入隐私保护提供了一种可行的解决方案，平衡了安全性和计算效率。

Abstract: In the era of generative AI, ensuring the privacy of music data presents
unique challenges: unlike static artworks such as images, music data is
inherently temporal and multimodal, and it is sampled, transformed, and remixed
at an unprecedented scale. These characteristics make its core vector
embeddings, i.e, the numerical representations of the music, highly susceptible
to being learned, misused, or even stolen by models without accessing the
original audio files. Traditional methods like copyright licensing and digital
watermarking offer limited protection for these abstract mathematical
representations, thus necessitating a stronger, e.g., cryptographic, approach
to safeguarding the embeddings themselves. Standard encryption schemes, such as
AES, render data unintelligible for computation, making such searches
impossible. While Fully Homomorphic Encryption (FHE) provides a plausible
solution by allowing arbitrary computations on ciphertexts, its substantial
performance overhead remains impractical for large-scale vector similarity
searches. Given this trade-off, we propose a more practical approach using
Additive Homomorphic Encryption (AHE) for vector similarity search. The primary
contributions of this paper are threefold: we analyze threat models unique to
music information retrieval systems; we provide a theoretical analysis and
propose an efficient AHE-based solution through inner products of music
embeddings to deliver privacy-preserving similarity search; and finally, we
demonstrate the efficiency and practicality of the proposed approach through
empirical evaluation and comparison to FHE schemes on real-world MP3 files.

</details>


### [441] [Whisfusion: Parallel ASR Decoding via a Diffusion Transformer](https://arxiv.org/abs/2508.07048)
*Taeyoun Kwon,Junhyuk Ahn,Taegeun Yun,Heeju Jwa,Yoonchae Choi,Siwon Park,Nam-Joon Kim,Jangchan Kim,Hyun Gon Ryu,Hyuk-Jae Lee*

Main category: cs.SD

Relevance: 40.0

TL;DR: Whisfusion框架结合Whisper编码器和文本扩散解码器，解决了自动语音识别（ASR）中的延迟问题，实现了并行解码，显著提升了长音频的处理速度。


<details>
  <summary>Details</summary>
Motivation: 解决AR解码器在ASR中的顺序生成延迟问题，以及NAR方法的上下文限制，提出一种高效的并行解码方案。

Method: 融合预训练的Whisper编码器和文本扩散解码器，通过轻量级跨注意力适配器连接两者，并采用批并行多步解码策略。

Result: 在LibriSpeech上微调后，Whisfusion的WER低于Whisper-tiny（8.3% vs. 9.7%），长音频处理速度提升2.6倍。

Conclusion: Whisfusion为长音频ASR提供了一种高效的新方法，显著降低了延迟。

Abstract: Fast Automatic Speech Recognition (ASR) is critical for latency-sensitive
applications such as real-time captioning and meeting transcription. However,
truly parallel ASR decoding remains challenging due to the sequential nature of
autoregressive (AR) decoders and the context limitations of non-autoregressive
(NAR) methods. While modern ASR encoders can process up to 30 seconds of audio
at once, AR decoders still generate tokens sequentially, creating a latency
bottleneck. We propose Whisfusion, the first framework to fuse a pre-trained
Whisper encoder with a text diffusion decoder. This NAR architecture resolves
the AR latency bottleneck by processing the entire acoustic context in parallel
at every decoding step. A lightweight cross-attention adapter trained via
parameter-efficient fine-tuning (PEFT) bridges the two modalities. We also
introduce a batch-parallel, multi-step decoding strategy that improves accuracy
by increasing the number of candidates with minimal impact on speed. Fine-tuned
solely on LibriSpeech (960h), Whisfusion achieves a lower WER than Whisper-tiny
(8.3% vs. 9.7%), and offers comparable latency on short audio. For longer
utterances (>20s), it is up to 2.6x faster than the AR baseline, establishing a
new, efficient operating point for long-form ASR. The implementation and
training scripts are available at https://github.com/taeyoun811/Whisfusion.

</details>


### [442] [Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey](https://arxiv.org/abs/2508.07163)
*Kamal Acharya,Iman Sharifi,Mehul Lad,Liang Sun,Houbing Song*

Main category: cs.RO

Relevance: 40.0

TL;DR: 该综述探讨了神经符号AI在先进空中交通（AAM）中的应用，分析了其潜力与挑战，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 结合神经网络的适应性和符号推理能力，解决AAM中的复杂监管、操作和安全问题。

Method: 综述了神经符号AI在AAM中的应用，包括需求预测、飞机设计和实时交通管理，并分类了当前进展。

Result: 揭示了研究领域的碎片化，神经符号强化学习等方法在动态优化中显示潜力，但仍面临可扩展性、鲁棒性和合规性挑战。

Conclusion: 提出了未来研究方向，旨在将神经符号AI整合到可靠、透明的AAM系统中。

Abstract: Neurosymbolic AI combines neural network adaptability with symbolic
reasoning, promising an approach to address the complex regulatory,
operational, and safety challenges in Advanced Air Mobility (AAM). This survey
reviews its applications across key AAM domains such as demand forecasting,
aircraft design, and real-time air traffic management. Our analysis reveals a
fragmented research landscape where methodologies, including Neurosymbolic
Reinforcement Learning, have shown potential for dynamic optimization but still
face hurdles in scalability, robustness, and compliance with aviation
standards. We classify current advancements, present relevant case studies, and
outline future research directions aimed at integrating these approaches into
reliable, transparent AAM systems. By linking advanced AI techniques with AAM's
operational demands, this work provides a concise roadmap for researchers and
practitioners developing next-generation air mobility solutions.

</details>


### [443] [Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models](https://arxiv.org/abs/2508.07903)
*Johanna P. Müller,Anika Knupfer,Pedro Blöss,Edoardo Berardi Vittur,Bernhard Kainz,Jana Hutter*

Main category: eess.IV

Relevance: 40.0

TL;DR: 论文提出了一种基于扩散模型的框架，用于生成高质量的合成女性盆腔MRI图像，解决了现有模型在解剖学精确性上的不足。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在生成女性盆腔图像时解剖学精确性不足的问题，以应对妇科影像学中数据稀缺和隐私问题的挑战。

Method: 结合无条件与条件Denoising Diffusion Probabilistic Models (DDPMs)和Latent Diffusion Models (LDMs)，在2D和3D中生成合成图像。

Result: 生成的图像在解剖学上一致且高保真，显著提升了诊断任务的准确性，并通过专家评估验证了临床真实性。

Conclusion: 该框架为妇科影像学提供了有价值的合成数据资源，支持可重复研究和公平AI的发展。

Abstract: Despite significant progress in generative modelling, existing diffusion
models often struggle to produce anatomically precise female pelvic images,
limiting their application in gynaecological imaging, where data scarcity and
patient privacy concerns are critical. To overcome these barriers, we introduce
a novel diffusion-based framework for uterine MRI synthesis, integrating both
unconditional and conditioned Denoising Diffusion Probabilistic Models (DDPMs)
and Latent Diffusion Models (LDMs) in 2D and 3D. Our approach generates
anatomically coherent, high fidelity synthetic images that closely mimic real
scans and provide valuable resources for training robust diagnostic models. We
evaluate generative quality using advanced perceptual and distributional
metrics, benchmarking against standard reconstruction methods, and demonstrate
substantial gains in diagnostic accuracy on a key classification task. A
blinded expert evaluation further validates the clinical realism of our
synthetic images. We release our models with privacy safeguards and a
comprehensive synthetic uterine MRI dataset to support reproducible research
and advance equitable AI in gynaecology.

</details>


### [444] [SocRipple: A Two-Stage Framework for Cold-Start Video Recommendations](https://arxiv.org/abs/2508.07241)
*Amit Jaspal,Kapil Dalwani,Ajantha Ramineni*

Main category: cs.IR

Relevance: 40.0

TL;DR: SocRipple是一个两阶段检索框架，用于解决社交图平台中冷启动物品分发问题，通过社交连接和KNN搜索提升分发效率。


<details>
  <summary>Details</summary>
Motivation: 解决推荐系统中冷启动物品因缺乏交互历史而难以个性化分发的问题。

Method: 两阶段框架：第一阶段利用创作者社交连接进行初始曝光，第二阶段基于早期交互信号和用户嵌入通过KNN搜索扩展分发。

Result: 在大型视频平台上，SocRipple将冷启动物品分发提升了36%，同时保持用户参与率。

Conclusion: SocRipple有效平衡了新物品曝光与个性化推荐。

Abstract: Most industry scale recommender systems face critical cold start challenges
new items lack interaction history, making it difficult to distribute them in a
personalized manner. Standard collaborative filtering models underperform due
to sparse engagement signals, while content only approaches lack user specific
relevance. We propose SocRipple, a novel two stage retrieval framework tailored
for coldstart item distribution in social graph based platforms. Stage 1
leverages the creators social connections for targeted initial exposure. Stage
2 builds on early engagement signals and stable user embeddings learned from
historical interactions to "ripple" outwards via K Nearest Neighbor (KNN)
search. Large scale experiments on a major video platform show that SocRipple
boosts cold start item distribution by +36% while maintaining user engagement
rate on cold start items, effectively balancing new item exposure with
personalized recommendations.

</details>


### [445] [AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation](https://arxiv.org/abs/2508.07371)
*Yi Zhong,Hongchao Liu,Di ZHao*

Main category: cs.SE

Relevance: 40.0

TL;DR: 提出了一种基于HDL的断言生成方法，结合轻量级可调参LLM与Unsloth平台，自动生成测试用例，显著降低训练成本且保持性能。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂性增加，对自动化测试工具的需求急剧上升。

Method: 结合轻量级可调参LLM与Unsloth平台，自动生成测试用例。

Result: 能高效生成严格符合硬件逻辑的断言。

Conclusion: 该框架为现代软件测试与维护提供了灵活解决方案。

Abstract: As the complexity of software systems continues to increase, the demand for
automated testing and maintenance tools is growing exponentially. To meet this
urgent need, we propose a new assertion generation method based on Hardware
Description Language (HDL). This method combines a lightweight,
parameter-adjustable large language model (LLM) with the Unsloth platform to
automatically generate test cases, thereby significantly reducing training
costs without sacrificing accuracy or generalization performance. Empirical
evaluation shows that our method can efficiently generate assertions that
strictly conform to the hardware logic. This framework provides a robust and
flexible solution to modern software testing and maintenance challenges.
https://github.com/liusu-orange/AutoAssert-1 and
https://gitee.com/OpenBPU/auto-assert1 are the locations of the source code.

</details>


### [446] [Urbanite: A Dataflow-Based Framework for Human-AI Interactive Alignment in Urban Visual Analytics](https://arxiv.org/abs/2508.07390)
*Gustavo Moreira,Leonardo Ferreira,Carolina Veiga,Maryam Hosseini,Fabio Miranda*

Main category: cs.HC

Relevance: 40.0

TL;DR: Urbanite是一个用于城市视觉分析的人机协作框架，利用基于数据流的模型和大型语言模型，帮助用户通过意图指定而非精确计算操作降低分析系统的构建门槛。


<details>
  <summary>Details</summary>
Motivation: 城市数据分析复杂且需要多领域专业知识，现有工具对非技术用户不友好。大型语言模型提供了降低门槛的潜力，但需解决意图与系统行为对齐的挑战。

Method: 提出Urbanite框架，采用数据流模型支持多范围意图指定，并整合解释性、多分辨率任务定义和交互溯源功能。

Result: 通过与城市专家合作的场景验证了Urbanite的有效性。

Conclusion: Urbanite通过人机协作降低了城市视觉分析的门槛，提升了意图与系统行为的对齐。

Abstract: With the growing availability of urban data and the increasing complexity of
societal challenges, visual analytics has become essential for deriving
insights into pressing real-world problems. However, analyzing such data is
inherently complex and iterative, requiring expertise across multiple domains.
The need to manage diverse datasets, distill intricate workflows, and integrate
various analytical methods presents a high barrier to entry, especially for
researchers and urban experts who lack proficiency in data management, machine
learning, and visualization. Advancements in large language models offer a
promising solution to lower the barriers to the construction of analytics
systems by enabling users to specify intent rather than define precise
computational operations. However, this shift from explicit operations to
intent-based interaction introduces challenges in ensuring alignment throughout
the design and development process. Without proper mechanisms, gaps can emerge
between user intent, system behavior, and analytical outcomes. To address these
challenges, we propose Urbanite, a framework for human-AI collaboration in
urban visual analytics. Urbanite leverages a dataflow-based model that allows
users to specify intent at multiple scopes, enabling interactive alignment
across the specification, process, and evaluation stages of urban analytics.
Based on findings from a survey to uncover challenges, Urbanite incorporates
features to facilitate explainability, multi-resolution definition of tasks
across dataflows, nodes, and parameters, while supporting the provenance of
interactions. We demonstrate Urbanite's effectiveness through usage scenarios
created in collaboration with urban experts. Urbanite is available at
https://urbantk.org/urbanite.

</details>


### [447] [A Spin Glass Characterization of Neural Networks](https://arxiv.org/abs/2508.07397)
*Jun Li*

Main category: cond-mat.dis-nn

Relevance: 40.0

TL;DR: 该论文提出了一种基于统计力学的神经网络分析方法，通过构建Hopfield型自旋玻璃模型来描述前馈神经网络的结构特性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是借鉴自旋玻璃中的复制对称破缺现象，为单个神经网络实例提供可计算的描述符，揭示传统指标（如损失或准确率）无法捕捉的非平凡结构特性。

Method: 方法是通过模拟复制样本之间的重叠作为前馈神经网络的描述符，并研究其与数据拟合、容量、泛化性和鲁棒性等常见性质的联系。

Result: 结果表明，该方法能够揭示神经网络的非平凡结构特性，并初步展示了在模型检查、安全验证和隐藏漏洞检测等实际应用中的潜力。

Conclusion: 结论是该方法为单个神经网络实例提供了新的分析工具，可能对模型的可解释性和安全性研究有重要价值。

Abstract: This work presents a statistical mechanics characterization of neural
networks, motivated by the replica symmetry breaking (RSB) phenomenon in spin
glasses. A Hopfield-type spin glass model is constructed from a given
feedforward neural network (FNN). Overlaps between simulated replica samples
serve as a characteristic descriptor of the FNN. The connection between the
spin-glass description and commonly studied properties of the FNN -- such as
data fitting, capacity, generalization, and robustness -- has been investigated
and empirically demonstrated. Unlike prior analytical studies that focus on
model ensembles, this method provides a computable descriptor for individual
network instances, which reveals nontrivial structural properties that are not
captured by conventional metrics such as loss or accuracy. Preliminary results
suggests its potential for practical applications such as model inspection,
safety verification, and detection of hidden vulnerabilities.

</details>


### [448] [Intersectoral Knowledge in AI and Urban Studies: A Framework for Transdisciplinary Research](https://arxiv.org/abs/2508.07507)
*Rashid Mushkani*

Main category: cs.CY

Relevance: 40.0

TL;DR: 本文提出了一个六维框架，用于评估和加强AI与城市研究中的跨学科知识有效性，基于对高引用研究的分析。


<details>
  <summary>Details</summary>
Motivation: 解决跨学科知识整合的困难，特别是在AI和城市研究领域。

Method: 分析2014-2024年高引用研究，提出六维框架（本体论、认识论、方法论、目的论、价值论和增值维度）。

Result: 发现研究主要倾向于批判现实主义、实证主义、分析方法等，但也探讨了较少见的立场（如理想主义、混合方法）。

Conclusion: 框架可帮助早期研究者和跨学科团队整合不同观点，促进社会责任感强的成果。

Abstract: Transdisciplinary approaches are increasingly essential for addressing grand
societal challenges, particularly in complex domains such as Artificial
Intelligence (AI), urban planning, and social sciences. However, effectively
validating and integrating knowledge across distinct epistemic and ontological
perspectives poses significant difficulties. This article proposes a
six-dimensional framework for assessing and strengthening transdisciplinary
knowledge validity in AI and city studies, based on an extensive analysis of
the most cited research (2014--2024). Specifically, the framework classifies
research orientations according to ontological, epistemological,
methodological, teleological, axiological, and valorization dimensions. Our
findings show a predominance of perspectives aligned with critical realism
(ontological), positivism (epistemological), analytical methods
(methodological), consequentialism (teleological), epistemic values
(axiological), and social/economic valorization. Less common stances, such as
idealism, mixed methods, and cultural valorization, are also examined for their
potential to enrich knowledge production. We highlight how early career
researchers and transdisciplinary teams can leverage this framework to
reconcile divergent disciplinary viewpoints and promote socially accountable
outcomes.

</details>


### [449] [Codebook-enabled Generative End-to-end Semantic Communication Powered by Transformer](https://arxiv.org/abs/2402.16868)
*Peigen Ye,Yaping Sun,Shumin Yao,Hao Chen,Xiaodong Xu,Shuguang Cui*

Main category: cs.IT

Relevance: 40.0

TL;DR: 论文提出了一种基于码本的鲁棒图像语义通信系统，通过联合构建语义编解码器和码本，并设计向量到索引的转换器来消除信道噪声影响，生成高质量图像。


<details>
  <summary>Details</summary>
Motivation: 码本生成语义通信中，码向量语义关系与索引距离无关，系统性能易受信道噪声影响，需提升鲁棒性。

Method: 联合构建语义编解码器和码本，设计向量到索引转换器以消除噪声，实现图像生成。

Result: 生成的图像在视觉感知上优于JPEG+LDPC和传统JSCC方法。

Conclusion: 该方法通过码本辅助Transformer，显著提升了语义通信系统的鲁棒性和图像生成质量。

Abstract: Codebook-based generative semantic communication attracts increasing
attention, since only indices are required to be transmitted when the codebook
is shared between transmitter and receiver. However, due to the fact that the
semantic relations among code vectors are not necessarily related to the
distance of the corresponding code indices, the performance of the
codebook-enabled semantic communication system is susceptible to the channel
noise. Thus, how to improve the system robustness against the noise requires
careful design. This paper proposes a robust codebook-assisted image semantic
communication system, where semantic codec and codebook are first jointly
constructed, and then vector-to-index transformer is designed guided by the
codebook to eliminate the effects of channel noise, and achieve image
generation. Thanks to the assistance of the high-quality codebook to the
Transformer, the generated images at the receiver outperform those of the
compared methods in terms of visual perception. In the end, numerical results
and generated images demonstrate the advantages of the generative semantic
communication method over JPEG+LDPC and traditional joint source channel coding
(JSCC) methods.

</details>


### [450] [Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation](https://arxiv.org/abs/2508.07745)
*Jiongchi Yu,Xiaofei Xie,Qiang Hu,Yuhan Ma,Ziming Zhao*

Main category: cs.CR

Relevance: 40.0

TL;DR: Chimera是一个基于LLM的多智能体框架，用于模拟企业内部威胁活动并生成高质量数据集ChimeraLog。


<details>
  <summary>Details</summary>
Motivation: 解决企业内部威胁检测（ITD）研究中高质量数据稀缺的问题。

Method: 使用LLM模拟员工行为，包括角色特定行为、组织动态和15种内部攻击类型，生成多样化日志。

Result: 生成的数据集ChimeraLog在多样性和真实性上表现优异，现有ITD方法在其上的F1分数（0.83）显著低于CERT数据集（0.99）。

Conclusion: ChimeraLog为ITD研究提供了更具挑战性和实用性的数据资源。

Abstract: Insider threats, which can lead to severe losses, remain a major security
concern. While machine learning-based insider threat detection (ITD) methods
have shown promising results, their progress is hindered by the scarcity of
high-quality data. Enterprise data is sensitive and rarely accessible, while
publicly available datasets, when limited in scale due to cost, lack sufficient
real-world coverage; and when purely synthetic, they fail to capture rich
semantics and realistic user behavior. To address this, we propose Chimera, the
first large language model (LLM)-based multi-agent framework that automatically
simulates both benign and malicious insider activities and collects diverse
logs across diverse enterprise environments. Chimera models each employee with
agents that have role-specific behavior and integrates modules for group
meetings, pairwise interactions, and autonomous scheduling, capturing realistic
organizational dynamics. It incorporates 15 types of insider attacks (e.g., IP
theft, system sabotage) and has been deployed to simulate activities in three
sensitive domains: technology company, finance corporation, and medical
institution, producing a new dataset, ChimeraLog. We assess ChimeraLog via
human studies and quantitative analysis, confirming its diversity, realism, and
presence of explainable threat patterns. Evaluations of existing ITD methods
show an average F1-score of 0.83, which is significantly lower than 0.99 on the
CERT dataset, demonstrating ChimeraLog's higher difficulty and utility for
advancing ITD research.

</details>


### [451] [Advancing Knowledge Tracing by Exploring Follow-up Performance Trends](https://arxiv.org/abs/2508.08019)
*Hengyu Liu,Yushuai Li,Minghe Yu,Tiancheng Zhang,Ge Yu,Torben Bach Pedersen,Kristian Torp,Christian S. Jensen,Tianyi Li*

Main category: cs.CY

Relevance: 40.0

TL;DR: 论文提出了一种名为FINER的知识追踪方法，通过结合历史学习序列和后续表现趋势（FPTs）来提高学生未来表现的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有知识追踪方法在分析历史学习序列与未来表现关系时存在相关性冲突，需要更准确的预测方法。

Method: FINER方法提取FPTs，构建学习模式，并采用相似性感知注意力机制结合FPTs与历史序列。

Result: 在六个真实数据集上，FINER优于十种最先进方法，准确率提升8.74%至84.85%。

Conclusion: FINER通过结合FPTs显著提升了知识追踪的准确性。

Abstract: Intelligent Tutoring Systems (ITS), such as Massive Open Online Courses,
offer new opportunities for human learning. At the core of such systems,
knowledge tracing (KT) predicts students' future performance by analyzing their
historical learning activities, enabling an accurate evaluation of students'
knowledge states over time. We show that existing KT methods often encounter
correlation conflicts when analyzing the relationships between historical
learning sequences and future performance. To address such conflicts, we
propose to extract so-called Follow-up Performance Trends (FPTs) from
historical ITS data and to incorporate them into KT. We propose a method called
Forward-Looking Knowledge Tracing (FINER) that combines historical learning
sequences with FPTs to enhance student performance prediction accuracy. FINER
constructs learning patterns that facilitate the retrieval of FPTs from
historical ITS data in linear time; FINER includes a novel similarity-aware
attention mechanism that aggregates FPTs based on both frequency and contextual
similarity; and FINER offers means of combining FPTs and historical learning
sequences to enable more accurate prediction of student future performance.
Experiments on six real-world datasets show that FINER can outperform ten
state-of-the-art KT methods, increasing accuracy by 8.74% to 84.85%.

</details>


### [452] [Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning](https://arxiv.org/abs/2508.07885)
*Shoaib Ahmmad,Zubayer Ahmed Aditto,Md Mehrab Hossain,Noushin Yeasmin,Shorower Hossain*

Main category: cs.RO

Relevance: 40.0

TL;DR: 论文提出了一种基于AI的感知系统，用于GPS缺失的室内环境中自主四轴飞行器导航，结合云计算的LLM进行决策。


<details>
  <summary>Details</summary>
Motivation: 解决GPS缺失环境下无人机导航的挑战，通过云计算的LLM和高效传感器设计提升性能。

Method: 系统整合YOLOv11、Depth Anything V2、ToF传感器、IMU和云LLM，采用多线程架构和虚拟安全包络。

Result: 实验显示mAP50为0.6，深度估计MAE为7.2 cm，42次试验中仅16次安全包络突破，延迟低于1秒。

Conclusion: 该框架为GPS缺失环境提供了高效辅助导航系统。

Abstract: This paper introduces an advanced AI-driven perception system for autonomous
quadcopter navigation in GPS-denied indoor environments. The proposed framework
leverages cloud computing to offload computationally intensive tasks and
incorporates a custom-designed printed circuit board (PCB) for efficient sensor
data acquisition, enabling robust navigation in confined spaces. The system
integrates YOLOv11 for object detection, Depth Anything V2 for monocular depth
estimation, a PCB equipped with Time-of-Flight (ToF) sensors and an Inertial
Measurement Unit (IMU), and a cloud-based Large Language Model (LLM) for
context-aware decision-making. A virtual safety envelope, enforced by
calibrated sensor offsets, ensures collision avoidance, while a multithreaded
architecture achieves low-latency processing. Enhanced spatial awareness is
facilitated by 3D bounding box estimation with Kalman filtering. Experimental
results in an indoor testbed demonstrate strong performance, with object
detection achieving a mean Average Precision (mAP50) of 0.6, depth estimation
Mean Absolute Error (MAE) of 7.2 cm, only 16 safety envelope breaches across 42
trials over approximately 11 minutes, and end-to-end system latency below 1
second. This cloud-supported, high-intelligence framework serves as an
auxiliary perception and navigation system, complementing state-of-the-art
drone autonomy for GPS-denied confined spaces.

</details>


### [453] [DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts](https://arxiv.org/abs/2508.07842)
*Yutong Shen,Hangxu Liu,Penghui Liu,Ruizhe Xia,Tianyi Yao,Yitong Sun,Tongtong Feng*

Main category: cs.RO

Relevance: 40.0

TL;DR: DETACH是一个基于生物启发的双流解耦框架，用于解决跨领域长时程任务的泛化问题，通过环境学习和技能学习模块分别处理空间理解和任务执行，显著提升了任务成功率和执行效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长时程任务中依赖预训练子任务的串联，缺乏对新环境和技能组合的泛化能力，DETACH旨在通过双流解耦机制解决这一问题。

Method: DETACH包含环境学习模块（空间理解）和技能学习模块（任务执行），分别实现环境-自我解耦和独立运动模式编码。

Result: 在多种长时程任务中，DETACH平均子任务成功率提升23%，执行效率提升29%。

Conclusion: DETACH通过双流解耦机制显著提升了跨领域长时程任务的泛化能力和执行效率。

Abstract: Long-Horizon (LH) tasks in Human-Scene Interaction (HSI) are complex
multi-step tasks that require continuous planning, sequential decision-making,
and extended execution across domains to achieve the final goal. However,
existing methods heavily rely on skill chaining by concatenating pre-trained
subtasks, with environment observations and self-state tightly coupled, lacking
the ability to generalize to new combinations of environments and skills,
failing to complete various LH tasks across domains. To solve this problem,
this paper presents DETACH, a cross-domain learning framework for LH tasks via
biologically inspired dual-stream disentanglement. Inspired by the brain's
"where-what" dual pathway mechanism, DETACH comprises two core modules: i) an
environment learning module for spatial understanding, which captures object
functions, spatial relationships, and scene semantics, achieving cross-domain
transfer through complete environment-self disentanglement; ii) a skill
learning module for task execution, which processes self-state information
including joint degrees of freedom and motor patterns, enabling cross-skill
transfer through independent motor pattern encoding. We conducted extensive
experiments on various LH tasks in HSI scenes. Compared with existing methods,
DETACH can achieve an average subtasks success rate improvement of 23% and
average execution efficiency improvement of 29%.

</details>


### [454] [SCDF: A Speaker Characteristics DeepFake Speech Dataset for Bias Analysis](https://arxiv.org/abs/2508.07944)
*Vojtěch Staněk,Karel Srna,Anton Firc,Kamil Malinka*

Main category: cs.SD

Relevance: 40.0

TL;DR: 论文介绍了SCDF数据集，用于系统评估深度伪造语音检测中的偏见，发现性别、语言、年龄等因素显著影响检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度伪造语音检测中偏见和公平性研究的不足。

Method: 构建SCDF数据集，包含237,000条语音，覆盖性别、语言、年龄等多样性，并评估多种先进检测器。

Result: 检测性能受说话者特征显著影响，存在性别、语言、年龄和合成器类型的差异。

Conclusion: 需开发偏见感知的检测系统，以符合伦理和监管标准。

Abstract: Despite growing attention to deepfake speech detection, the aspects of bias
and fairness remain underexplored in the speech domain. To address this gap, we
introduce the Speaker Characteristics Deepfake (SCDF) dataset: a novel, richly
annotated resource enabling systematic evaluation of demographic biases in
deepfake speech detection. SCDF contains over 237,000 utterances in a balanced
representation of both male and female speakers spanning five languages and a
wide age range. We evaluate several state-of-the-art detectors and show that
speaker characteristics significantly influence detection performance,
revealing disparities across sex, language, age, and synthesizer type. These
findings highlight the need for bias-aware development and provide a foundation
for building non-discriminatory deepfake detection systems aligned with ethical
and regulatory standards.

</details>


### [455] [Bridging ASR and LLMs for Dysarthric Speech Recognition: Benchmarking Self-Supervised and Generative Approaches](https://arxiv.org/abs/2508.08027)
*Ahmed Aboeitta,Ahmed Sharshar,Youssef Nafea,Shady Shehata*

Main category: cs.SD

Relevance: 40.0

TL;DR: 论文研究了自监督ASR模型（如Wav2Vec、HuBERT、Whisper）在构音障碍语音识别中的表现，并引入LLM增强解码（如BART、GPT-2、Vicuna）提升性能。


<details>
  <summary>Details</summary>
Motivation: 构音障碍语音因音素失真和高变异性导致识别困难，现有自监督ASR模型的效果尚不明确，需系统评估和改进。

Method: 通过CTC、seq2seq和LLM增强解码策略，对不同ASR架构进行基准测试，并分析跨数据集的泛化能力和错误模式。

Result: LLM增强解码通过利用语言约束修复音素和语法纠正，显著提升了构音障碍语音识别效果。

Conclusion: LLM增强解码是改进构音障碍ASR的有效方法，未来可进一步优化模型泛化能力。

Abstract: Speech Recognition (ASR) due to phoneme distortions and high variability.
While self-supervised ASR models like Wav2Vec, HuBERT, and Whisper have shown
promise, their effectiveness in dysarthric speech remains unclear. This study
systematically benchmarks these models with different decoding strategies,
including CTC, seq2seq, and LLM-enhanced decoding (BART,GPT-2, Vicuna). Our
contributions include (1) benchmarking ASR architectures for dysarthric speech,
(2) introducing LLM-based decoding to improve intelligibility, (3) analyzing
generalization across datasets, and (4) providing insights into recognition
errors across severity levels. Findings highlight that LLM-enhanced decoding
improves dysarthric ASR by leveraging linguistic constraints for phoneme
restoration and grammatical correction.

</details>


### [456] [Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation](https://arxiv.org/abs/2508.08042)
*Van-Khang Nguyen,Duc-Hoang Pham,Huy-Son Nguyen,Cam-Van Thi Nguyen,Hoang-Quynh Le,Duc-Trong Le*

Main category: cs.IR

Relevance: 40.0

TL;DR: 论文提出了一种名为MAMEX的新型混合专家（MoE）框架，用于多模态冷启动推荐系统，通过动态利用不同模态的潜在表示提升推荐效果。


<details>
  <summary>Details</summary>
Motivation: 解决冷启动场景下新物品推荐的问题，现有方法在多模态数据整合上过于简单，无法捕捉模态间复杂关系。

Method: 采用模态特定专家网络和可学习的门控机制，动态调整各模态权重。

Result: 在基准数据集上，MAMEX在冷启动场景中表现优于现有方法，具有更高的准确性和适应性。

Conclusion: MAMEX通过动态多模态整合显著提升了冷启动推荐的效果，代码已开源。

Abstract: Recommendation systems have faced significant challenges in cold-start
scenarios, where new items with a limited history of interaction need to be
effectively recommended to users. Though multimodal data (e.g., images, text,
audio, etc.) offer rich information to address this issue, existing approaches
often employ simplistic integration methods such as concatenation, average
pooling, or fixed weighting schemes, which fail to capture the complex
relationships between modalities. Our study proposes a novel Mixture of Experts
(MoE) framework for multimodal cold-start recommendation, named MAMEX, which
dynamically leverages latent representation from different modalities. MAMEX
utilizes modality-specific expert networks and introduces a learnable gating
mechanism that adaptively weights the contribution of each modality based on
its content characteristics. This approach enables MAMEX to emphasize the most
informative modalities for each item while maintaining robustness when certain
modalities are less relevant or missing. Extensive experiments on benchmark
datasets show that MAMEX outperforms state-of-the-art methods in cold-start
scenarios, with superior accuracy and adaptability. For reproducibility, the
code has been made available on Github https://github.com/L2R-UET/MAMEX.

</details>


### [457] [COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models](https://arxiv.org/abs/2508.08144)
*Ganesh Sundaram,Jonas Ulmen,Amjad Haider,Daniel Görges*

Main category: cs.RO

Relevance: 40.0

TL;DR: 论文提出了一种基于组件感知结构化剪枝的模型压缩方法，用于资源受限设备上的神经网络控制器（NNCs），确保压缩与稳定性的平衡。


<details>
  <summary>Details</summary>
Motivation: 资源受限设备（如移动机器人、可穿戴设备）需要高效神经网络控制器，但传统DNN计算复杂度和内存需求高，难以部署。

Method: 采用组件感知结构化剪枝，结合数学稳定性保证（如Lyapunov准则），在TD-MPC（模型强化学习算法）上验证。

Result: 方法成功降低模型复杂度，保持控制性能和稳定性，并量化安全压缩比边界。

Conclusion: 为压缩NNCs在资源受限环境中的部署提供了理论框架和实践指导。

Abstract: The rapid growth of resource-constrained mobile platforms, including mobile
robots, wearable systems, and Internet-of-Things devices, has increased the
demand for computationally efficient neural network controllers (NNCs) that can
operate within strict hardware limitations. While deep neural networks (DNNs)
demonstrate superior performance in control applications, their substantial
computational complexity and memory requirements present significant barriers
to practical deployment on edge devices. This paper introduces a comprehensive
model compression methodology that leverages component-aware structured pruning
to determine the optimal pruning magnitude for each pruning group, ensuring a
balance between compression and stability for NNC deployment. Our approach is
rigorously evaluated on Temporal Difference Model Predictive Control (TD-MPC),
a state-of-the-art model-based reinforcement learning algorithm, with a
systematic integration of mathematical stability guarantee properties,
specifically Lyapunov criteria. The key contribution of this work lies in
providing a principled framework for determining the theoretical limits of
model compression while preserving controller stability. Experimental
validation demonstrates that our methodology successfully reduces model
complexity while maintaining requisite control performance and stability
characteristics. Furthermore, our approach establishes a quantitative boundary
for safe compression ratios, enabling practitioners to systematically determine
the maximum permissible model reduction before violating critical stability
properties, thereby facilitating the confident deployment of compressed NNCs in
resource-limited environments.

</details>


### [458] [PyVeritas: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C](https://arxiv.org/abs/2508.08171)
*Pedro Orvalho,Marta Kwiatkowska*

Main category: cs.SE

Relevance: 40.0

TL;DR: PyVeritas利用LLMs将Python代码转换为C代码，结合模型检查和MaxSAT进行故障定位，为Python提供形式化验证支持。


<details>
  <summary>Details</summary>
Motivation: Python缺乏形式化验证工具，而PyVeritas通过LLM和现有C工具填补这一空白。

Method: 使用LLMs进行Python到C的高级转译，结合有界模型检查和MaxSAT进行故障定位。

Result: 实验表明，LLM转译准确率达80-90%，支持小规模Python程序的验证和故障诊断。

Conclusion: PyVeritas为Python程序提供了有效的形式化验证和故障定位方法。

Abstract: Python has become the dominant language for general-purpose programming, yet
it lacks robust tools for formal verification. In contrast, programmers working
in languages such as C benefit from mature model checkers, for example CBMC,
which enable exhaustive symbolic reasoning and fault localisation. The inherent
complexity of Python, coupled with the verbosity and low-level nature of
existing transpilers (e.g., Cython), have historically limited the
applicability of formal verification to Python programs.
  In this paper, we propose PyVeritas, a novel framework that leverages Large
Language Models (LLMs) for high-level transpilation from Python to C, followed
by bounded model checking and MaxSAT-based fault localisation in the generated
C code. PyVeritas enables verification and bug localisation for Python code
using existing model checking tools for C. Our empirical evaluation on two
Python benchmarks demonstrates that LLM-based transpilation can achieve a high
degree of accuracy, up to 80--90% for some LLMs, enabling effective development
environment that supports assertion-based verification and interpretable fault
diagnosis for small yet non-trivial Python programs.

</details>


### [459] [VGGSounder: Audio-Visual Evaluations for Foundation Models](https://arxiv.org/abs/2508.08237)
*Daniil Zverev,Thaddäus Wiedemer,Ameya Prabhu,Matthias Bethge,Wieland Brendel,A. Sophia Koepke*

Main category: cs.MM

Relevance: 40.0

TL;DR: 论文提出了VGGSounder，一个重新标注的多标签测试集，用于更准确地评估音频-视觉基础模型的多模态理解能力。


<details>
  <summary>Details</summary>
Motivation: VGGSounder数据集作为音频-视觉分类的基准存在标签不完整、类别重叠和模态不对齐等问题，导致评估失真。

Method: 通过重新标注VGGSound数据集，创建VGGSounder，并引入模态混淆度量来分析模型性能。

Result: VGGSounder提供了详细的模态注释，揭示了模型在多模态输入下的性能退化。

Conclusion: VGGSounder为音频-视觉基础模型的评估提供了更可靠的基准。

Abstract: The emergence of audio-visual foundation models underscores the importance of
reliably assessing their multi-modal understanding. The VGGSounder dataset is
commonly used as a benchmark for evaluation audio-visual classification.
However, our analysis identifies several limitations of VGGSounder, including
incomplete labelling, partially overlapping classes, and misaligned modalities.
These lead to distorted evaluations of auditory and visual capabilities. To
address these limitations, we introduce VGGSounder, a comprehensively
re-annotated, multi-label test set that extends VGGSound and is specifically
designed to evaluate audio-visual foundation models. VGGSounder features
detailed modality annotations, enabling precise analyses of modality-specific
performance. Furthermore, we reveal model limitations by analysing performance
degradation when adding another input modality with our new modality confusion
metric.

</details>


### [460] [Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis](https://arxiv.org/abs/2508.06668)
*Jessie Galasso*

Main category: cs.AI

Relevance: 30.0

TL;DR: 论文探讨了形式概念分析（FCA）在变异性分析中的关键性质及其应用方法。


<details>
  <summary>Details</summary>
Motivation: FCA在知识表示和发现方面具有潜力，但其数学性质使得在变异性任务中的应用不够直观。本文旨在填补这一空白。

Method: 通过选择和总结FCA框架中与变异性分析相关的关键性质，并展示如何利用这些性质解释变异性信息。

Result: 提出了一套FCA性质，可用于有效分析和解释变异性信息。

Conclusion: FCA的性质在变异性分析中具有重要价值，本文为实际应用提供了指导。

Abstract: Formal Concept Analysis (FCA) is a mathematical framework for knowledge
representation and discovery. It performs a hierarchical clustering over a set
of objects described by attributes, resulting in conceptual structures in which
objects are organized depending on the attributes they share. These conceptual
structures naturally highlight commonalities and variabilities among similar
objects by categorizing them into groups which are then arranged by similarity,
making it particularly appropriate for variability extraction and analysis.
Despite the potential of FCA, determining which of its properties can be
leveraged for variability-related tasks (and how) is not always
straightforward, partly due to the mathematical orientation of its foundational
literature. This paper attempts to bridge part of this gap by gathering a
selection of properties of the framework which are essential to variability
analysis, and how they can be used to interpret diverse variability information
within the resulting conceptual structures.

</details>


### [461] [Zero-Shot Cellular Trajectory Map Matching](https://arxiv.org/abs/2508.06674)
*Weijie Shi,Yue Cui,Hao Chen,Jiaming Li,Mengze Li,Jia Zhu,Jiajie Xu,Xiaofang Zhou*

Main category: cs.AI

Relevance: 30.0

TL;DR: 提出了一种基于像素的轨迹校准辅助方法，用于零样本蜂窝轨迹地图匹配（CTMM），通过可转移的地理空间知识校准轨迹，并在道路网络层面指导路径查找。


<details>
  <summary>Details</summary>
Motivation: 解决现有CTMM方法依赖区域特定数据和ID特征的局限性，实现无需目标区域额外训练的高精度匹配。

Method: 结合高斯混合模型的变分自编码器（VAE）识别场景自适应专家，设计时空感知模块捕获序列特征和位置不确定性，采用约束路径查找算法重构道路ID序列。

Result: 实验表明，该方法在零样本CTMM中优于现有方法16.8%。

Conclusion: 提出的方法通过知识共享和时空感知显著提升了零样本CTMM的准确性和适应性。

Abstract: Cellular Trajectory Map-Matching (CTMM) aims to align cellular location
sequences to road networks, which is a necessary preprocessing in
location-based services on web platforms like Google Maps, including navigation
and route optimization. Current approaches mainly rely on ID-based features and
region-specific data to learn correlations between cell towers and roads,
limiting their adaptability to unexplored areas. To enable high-accuracy CTMM
without additional training in target regions, Zero-shot CTMM requires to
extract not only region-adaptive features, but also sequential and location
uncertainty to alleviate positioning errors in cellular data. In this paper, we
propose a pixel-based trajectory calibration assistant for zero-shot CTMM,
which takes advantage of transferable geospatial knowledge to calibrate
pixelated trajectory, and then guide the path-finding process at the road
network level. To enhance knowledge sharing across similar regions, a Gaussian
mixture model is incorporated into VAE, enabling the identification of
scenario-adaptive experts through soft clustering. To mitigate high positioning
errors, a spatial-temporal awareness module is designed to capture sequential
features and location uncertainty, thereby facilitating the inference of
approximate user positions. Finally, a constrained path-finding algorithm is
employed to reconstruct the road ID sequence, ensuring topological validity
within the road network. This process is guided by the calibrated trajectory
while optimizing for the shortest feasible path, thus minimizing unnecessary
detours. Extensive experiments demonstrate that our model outperforms existing
methods in zero-shot CTMM by 16.8\%.

</details>


### [462] [ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search](https://arxiv.org/abs/2508.06736)
*Alican Yilmaz,Junyang Cai,Serdar Kadioglu,Bistra Dilkina*

Main category: cs.AI

Relevance: 30.0

TL;DR: 该论文提出了ParBalans，一种并行化扩展的Balans方法，用于加速混合整数规划（MIP）问题的求解。


<details>
  <summary>Details</summary>
Motivation: 混合整数规划问题的计算资源需求高，并行化是加速求解的关键策略。

Method: 通过结合求解器级和算法级并行化，扩展Balans方法（基于多臂老虎机的自适应大邻域搜索）。

Result: 实验表明，ParBalans在硬优化基准上表现优于商业求解器Gurobi。

Conclusion: ParBalans展示了并行化在MIP求解中的潜力，尤其在复杂实例中表现突出。

Abstract: Solving Mixed-Integer Programming (MIP) problems often requires substantial
computational resources due to their combinatorial nature. Parallelization has
emerged as a critical strategy to accelerate solution times and enhance
scalability to tackle large, complex instances. This paper investigates the
parallelization capabilities of Balans, a recently proposed multi-armed
bandits-based adaptive large neighborhood search for MIPs. While Balans's
modular architecture inherently supports parallel exploration of diverse
parameter configurations, this potential has not been thoroughly examined. To
address this gap, we introduce ParBalans, an extension that leverages both
solver-level and algorithmic-level parallelism to improve performance on
challenging MIP instances. Our experimental results demonstrate that ParBalans
exhibits competitive performance compared to the state-of-the-art commercial
solver Gurobi, particularly on hard optimization benchmarks.

</details>


### [463] [Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism](https://arxiv.org/abs/2508.06746)
*Xin Tang,Qian Chen,Fengshun Li,Youchun Gong,Yinqiu Liu,Wen Tian,Shaowen Qin,Xiaohuan Li*

Main category: cs.AI

Relevance: 30.0

TL;DR: 本文提出了一种结合图扩散策略优化（GDPO）和Stackelberg博弈（SG）的自组织无人机网络框架，用于提升隐蔽通信和可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着无人机网络在敏感应用中的需求增长，动态移动性和暴露风险成为主要挑战，需要可靠且隐蔽的通信解决方案。

Method: 采用GDPO方法生成稀疏但连接良好的拓扑结构，并结合SG博弈激励机制引导无人机协作。

Result: 实验验证了框架在模型收敛性、拓扑生成质量和隐蔽通信性能方面的有效性。

Conclusion: 提出的框架能有效应对无人机网络的动态性和隐蔽通信需求。

Abstract: With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in
sensitive applications, such as urban monitoring, emergency response, and
secure sensing, ensuring reliable connectivity and covert communication has
become increasingly vital. However, dynamic mobility and exposure risks pose
significant challenges. To tackle these challenges, this paper proposes a
self-organizing UAV network framework combining Graph Diffusion-based Policy
Optimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The
GDPO method uses generative AI to dynamically generate sparse but
well-connected topologies, enabling flexible adaptation to changing node
distributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game
(SG)-based incentive mechanism guides self-interested UAVs to choose relay
behaviors and neighbor links that support cooperation and enhance covert
communication. Extensive experiments are conducted to validate the
effectiveness of the proposed framework in terms of model convergence, topology
generation quality, and enhancement of covert communication performance.

</details>


### [464] [Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation](https://arxiv.org/abs/2508.06823)
*Xuan Zhao,Jun Tao*

Main category: cs.AI

Relevance: 30.0

TL;DR: 提出了一种利用自然语言交互增强体积数据探索的框架，结合CLIP Score和强化学习优化视角选择。


<details>
  <summary>Details</summary>
Motivation: 解决非专业用户在3D导航中选择最佳视角的挑战，提升科学数据解释效率。

Method: 将体积块编码以区分结构，结合CLIP Score提供语义信息，并通过强化学习框架搜索最佳视角。

Result: 自动化视角选择提高了导航效率，并增强了复杂科学现象的可解释性。

Conclusion: 该方法通过自然语言交互和强化学习显著改善了体积数据探索的效果。

Abstract: Exploring volumetric data is crucial for interpreting scientific datasets.
However, selecting optimal viewpoints for effective navigation can be
challenging, particularly for users without extensive domain expertise or
familiarity with 3D navigation. In this paper, we propose a novel framework
that leverages natural language interaction to enhance volumetric data
exploration. Our approach encodes volumetric blocks to capture and
differentiate underlying structures. It further incorporates a CLIP Score
mechanism, which provides semantic information to the blocks to guide
navigation. The navigation is empowered by a reinforcement learning framework
that leverage these semantic cues to efficiently search for and identify
desired viewpoints that align with the user's intent. The selected viewpoints
are evaluated using CLIP Score to ensure that they best reflect the user
queries. By automating viewpoint selection, our method improves the efficiency
of volumetric data navigation and enhances the interpretability of complex
scientific phenomena.

</details>


### [465] [GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization](https://arxiv.org/abs/2508.06899)
*Yanchen Deng,Xinrun Wang,Bo An*

Main category: cs.AI

Relevance: 30.0

TL;DR: 论文提出了一种分布式引导局部搜索（DGLS）方法，解决了分布式约束优化问题（DCOP）中局部搜索算法收敛到次优解的问题，通过自适应约束违反条件、惩罚蒸发机制和同步方案提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有GDBA方法在解决DCOP问题时性能不佳，主要由于过度激进的约束违反条件、无限制的惩罚积累和不协调的惩罚更新。

Method: 提出DGLS框架，包括自适应约束违反条件、惩罚蒸发机制和同步方案。

Result: DGLS在标准基准测试中显著优于现有方法，尤其在结构化问题上表现突出。

Conclusion: DGLS通过改进约束处理和惩罚机制，显著提升了DCOP问题的求解性能。

Abstract: Local search is an important class of incomplete algorithms for solving
Distributed Constraint Optimization Problems (DCOPs) but it often converges to
poor local optima. While GDBA provides a comprehensive rule set to escape
premature convergence, its empirical benefits remain marginal on general-valued
problems. In this work, we systematically examine GDBA and identify three
factors that potentially lead to its inferior performance, i.e.,
over-aggressive constraint violation conditions, unbounded penalty
accumulation, and uncoordinated penalty updates. To address these issues, we
propose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs
that incorporates an adaptive violation condition to selectively penalize
constraints with high cost, a penalty evaporation mechanism to control the
magnitude of penalization, and a synchronization scheme for coordinated penalty
updates. We theoretically show that the penalty values are bounded, and agents
play a potential game in our DGLS. Our extensive empirical results on various
standard benchmarks demonstrate the great superiority of DGLS over
state-of-the-art baselines. Particularly, compared to Damped Max-sum with high
damping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance
on general-valued problems, and outperforms it by significant margins
(\textbf{3.77\%--66.3\%}) on structured problems in terms of anytime results.

</details>


### [466] [Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach](https://arxiv.org/abs/2508.07015)
*Hannes Ihalainen,Dieter Vandesande,André Schidler,Jeremias Berg,Bart Bogaerts,Matti Järvisalo*

Main category: cs.AI

Relevance: 30.0

TL;DR: 论文探讨了隐式击中集（IHS）框架的替代优化技术，比较了伪布尔推理和随机局部搜索方法，发现商业整数规划求解器效率高但存在数值不稳定性问题，而基于伪布尔推理的方法在准确性和可验证性上表现更好。


<details>
  <summary>Details</summary>
Motivation: 研究隐式击中集框架中优化技术的替代方案，以解决现有方法（如整数规划）在效率和可靠性上的不足。

Method: 采用伪布尔推理和随机局部搜索作为优化技术，并与商业整数规划求解器进行比较。

Result: 商业整数规划求解器效率最高但存在数值不稳定性；伪布尔推理方法在准确性和可验证性上表现优异。

Conclusion: 伪布尔推理方法在隐式击中集优化中具有竞争力，并能提供计算正确性证明。

Abstract: The implicit hitting set (IHS) approach offers a general framework for
solving computationally hard combinatorial optimization problems declaratively.
IHS iterates between a decision oracle used for extracting sources of
inconsistency and an optimizer for computing so-called hitting sets (HSs) over
the accumulated sources of inconsistency. While the decision oracle is
language-specific, the optimizers is usually instantiated through integer
programming.
  We explore alternative algorithmic techniques for hitting set optimization
based on different ways of employing pseudo-Boolean (PB) reasoning as well as
stochastic local search. We extensively evaluate the practical feasibility of
the alternatives in particular in the context of pseudo-Boolean (0-1 IP)
optimization as one of the most recent instantiations of IHS. Highlighting a
trade-off between efficiency and reliability, while a commercial IP solver
turns out to remain the most effective way to instantiate HS computations, it
can cause correctness issues due to numerical instability; in fact, we show
that exact HS computations instantiated via PB reasoning can be made
competitive with a numerically exact IP solver. Furthermore, the use of PB
reasoning as a basis for HS computations allows for obtaining certificates for
the correctness of IHS computations, generally applicable to any IHS
instantiation in which reasoning in the declarative language at hand can be
captured in the PB-based proof format we employ.

</details>


### [467] [Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention](https://arxiv.org/abs/2508.07107)
*Timothy Oluwapelumi Adeyemi,Nadiah Fahad AlOtaibi*

Main category: cs.AI

Relevance: 30.0

TL;DR: 论文提出了一种反馈驱动的决策支持系统（DSS），通过闭环架构实现持续模型优化，用于动态预测学生表现。


<details>
  <summary>Details</summary>
Motivation: 现有教育领域的机器学习模型多为静态，无法适应新数据（如干预后结果）。本文旨在解决这一局限性。

Method: 系统结合LightGBM回归器和增量训练，支持实时更新模型；提供基于Flask的Web界面和SHAP解释性工具。

Result: 实验显示RMSE降低10.7%，干预学生预测分数持续提升。

Conclusion: 该方法将静态预测器转化为自优化系统，推动教育分析向以人为本、数据驱动和响应式AI发展。

Abstract: Accurate prediction of student performance is essential for timely academic
intervention. However, most machine learning models in education are static and
cannot adapt when new data, such as post-intervention outcomes, become
available. To address this limitation, we propose a Feedback-Driven Decision
Support System (DSS) with a closed-loop architecture that enables continuous
model refinement. The system integrates a LightGBM-based regressor with
incremental retraining, allowing educators to input updated student results,
which automatically trigger model updates. This adaptive mechanism improves
prediction accuracy by learning from real-world academic progress. The platform
features a Flask-based web interface for real-time interaction and incorporates
SHAP for explainability, ensuring transparency. Experimental results show a
10.7\% reduction in RMSE after retraining, with consistent upward adjustments
in predicted scores for intervened students. By transforming static predictors
into self-improving systems, our approach advances educational analytics toward
human-centered, data-driven, and responsive AI. The framework is designed for
integration into LMS and institutional dashboards.

</details>


### [468] [Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation](https://arxiv.org/abs/2508.07649)
*Jie Li,Haoye Dong,Zhengyang Wu,Zetao Zheng,Mingrong Lin*

Main category: cs.AI

Relevance: 30.0

TL;DR: 论文提出DiMuST模型，通过解耦表示学习解决POI推荐中时空转换的冗余信息问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有POI推荐方法将时空转换分开建模，导致信息冗余和模型不确定性增加，DiMuST旨在解决这一问题。

Method: 使用解耦变分多图自编码器（DAE），通过多图策略分离共享和私有分布，并利用PoE机制融合共享特征，对比约束去噪私有特征。

Result: 在两个数据集上，DiMuST在多项指标上显著优于现有方法。

Conclusion: DiMuST有效捕捉POI的时空转换表示，同时保持其内在关联性。

Abstract: Next Point-of-Interest (POI) recommendation is a research hotspot in business
intelligence, where users' spatial-temporal transitions and social
relationships play key roles. However, most existing works model spatial and
temporal transitions separately, leading to misaligned representations of the
same spatial-temporal key nodes. This misalignment introduces redundant
information during fusion, increasing model uncertainty and reducing
interpretability. To address this issue, we propose DiMuST, a socially enhanced
POI recommendation model based on disentangled representation learning over
multiplex spatial-temporal transition graphs. The model employs a novel
Disentangled variational multiplex graph Auto-Encoder (DAE), which first
disentangles shared and private distributions using a multiplex
spatial-temporal graph strategy. It then fuses the shared features via a
Product of Experts (PoE) mechanism and denoises the private features through
contrastive constraints. The model effectively captures the spatial-temporal
transition representations of POIs while preserving the intrinsic correlation
of their spatial-temporal relationships. Experiments on two challenging
datasets demonstrate that our DiMuST significantly outperforms existing methods
across multiple metrics.

</details>


### [469] [KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations](https://arxiv.org/abs/2508.07834)
*Mubaris Nadeem,Johannes Zenkert,Lisa Bender,Christian Weber,Madjid Fathi*

Main category: cs.AI

Relevance: 30.0

TL;DR: 本文提出了一种基于知识图谱的AI系统，用于在紧急救援中为急救人员提供智能治疗建议。


<details>
  <summary>Details</summary>
Motivation: 全球救援需求增加，急救人员需快速提供个性化医疗，但时间紧迫难以全面评估患者状况，需要AI辅助。

Method: 使用知识图谱作为核心知识表示，结合AI预识别技术，为急救人员提供智能治疗建议。

Result: 系统能够快速处理患者数据并提供优化治疗建议，提升急救效率。

Conclusion: 知识图谱和AI技术的结合在紧急救援中具有潜力，可改善急救效果。

Abstract: Over the years, the need for rescue operations throughout the world has
increased rapidly. Demographic changes and the resulting risk of injury or
health disorders form the basis for emergency calls. In such scenarios, first
responders are in a rush to reach the patient in need, provide first aid, and
save lives. In these situations, they must be able to provide personalized and
optimized healthcare in the shortest possible time and estimate the patients
condition with the help of freshly recorded vital data in an emergency
situation. However, in such a timedependent situation, first responders and
medical experts cannot fully grasp their knowledge and need assistance and
recommendation for further medical treatments. To achieve this, on the spot
calculated, evaluated, and processed knowledge must be made available to
improve treatments by first responders. The Knowledge Graph presented in this
article as a central knowledge representation provides first responders with an
innovative knowledge management that enables intelligent treatment
recommendations with an artificial intelligence-based pre-recognition of the
situation.

</details>


### [470] [Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots](https://arxiv.org/abs/2508.07941)
*Olivier Poulet,Frédéric Guinand,François Guérin*

Main category: cs.AI

Relevance: 30.0

TL;DR: 提出了一种基于LSTM短期预测的碰撞风险预判方法，通过动态调整DQN的奖励来减少机器人碰撞。


<details>
  <summary>Details</summary>
Motivation: 在无通信或标识的受限环境中，减少机器人碰撞并提高稳定性。

Method: 使用LSTM预测机器人位置，动态调整DQN奖励。

Result: 在1Hz采样频率下，碰撞次数显著减少，稳定性提高。

Conclusion: 该方法计算成本低，适合嵌入式系统实现。

Abstract: This article proposes a collision risk anticipation method based on
short-term prediction of the agents position. A Long Short-Term Memory (LSTM)
model, trained on past trajectories, is used to estimate the next position of
each robot. This prediction allows us to define an anticipated collision risk
by dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent.
The approach is tested in a constrained environment, where two robots move
without communication or identifiers. Despite a limited sampling frequency (1
Hz), the results show a significant decrease of the collisions number and a
stability improvement. The proposed method, which is computationally
inexpensive, appears particularly attractive for implementation on embedded
systems.

</details>


### [471] [FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence](https://arxiv.org/abs/2508.08075)
*Meishen He,Wenjun Ma,Jiao Wang,Huijun Yue,Xiaoma Fan*

Main category: cs.AI

Relevance: 30.0

TL;DR: 提出了一种基于Dempster-Shafer理论的开放世界信息融合方法FNBT，解决异构框架下的信息融合问题。


<details>
  <summary>Details</summary>
Motivation: 现实场景中，数据或模型常来自不同区域或组织，导致异构框架，传统融合方法效果不佳。

Method: 引入标准判断任务是否属于开放世界，扩展框架以容纳异构元素，采用全否定机制转换质量函数。

Result: FNBT在真实数据集上表现优越，解决了Zadeh反例，满足质量函数不变性、遗传性和本质冲突消除。

Conclusion: FNBT为异构框架下的信息融合提供了有效解决方案。

Abstract: The Dempster-Shafer theory of evidence has been widely applied in the field
of information fusion under uncertainty. Most existing research focuses on
combining evidence within the same frame of discernment. However, in real-world
scenarios, trained algorithms or data often originate from different regions or
organizations, where data silos are prevalent. As a result, using different
data sources or models to generate basic probability assignments may lead to
heterogeneous frames, for which traditional fusion methods often yield
unsatisfactory results. To address this challenge, this study proposes an
open-world information fusion method, termed Full Negation Belief
Transformation (FNBT), based on the Dempster-Shafer theory. More specially, a
criterion is introduced to determine whether a given fusion task belongs to the
open-world setting. Then, by extending the frames, the method can accommodate
elements from heterogeneous frames. Finally, a full negation mechanism is
employed to transform the mass functions, so that existing combination rules
can be applied to the transformed mass functions for such information fusion.
Theoretically, the proposed method satisfies three desirable properties, which
are formally proven: mass function invariance, heritability, and essential
conflict elimination. Empirically, FNBT demonstrates superior performance in
pattern classification tasks on real-world datasets and successfully resolves
Zadeh's counterexample, thereby validating its practical effectiveness.

</details>


### [472] [Network-Specific Models for Multimodal Brain Response Prediction](https://arxiv.org/abs/2508.06499)
*Andrea Corsico,Giorgia Rigamonti,Simone Zini,Luigi Celona,Paolo Napoletano*

Main category: q-bio.NC

Relevance: 30.0

TL;DR: 提出了一种基于大脑功能网络分组的预测方法，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 通过分组优化大脑功能网络，提高对复杂多模态电影的大脑响应预测能力。

Method: 将七个功能网络分为四组，为每组训练独立的多层感知机模型，支持特定优化和自适应记忆建模。

Result: 预测准确性显著提升，在Algonauts Project 2025 Challenge中排名第八，OOD相关性分数是基线模型的两倍。

Conclusion: 分组策略有效提升了大脑响应预测的准确性，支持功能网络特异性优化。

Abstract: In this work, we present a network-specific approach for predicting brain
responses to complex multimodal movies, leveraging the Yeo 7-network
parcellation of the Schaefer atlas. Rather than treating the brain as a
homogeneous system, we grouped the seven functional networks into four clusters
and trained separate multi-subject, multi-layer perceptron (MLP) models for
each. This architecture supports cluster-specific optimization and adaptive
memory modeling, allowing each model to adjust temporal dynamics and modality
weighting based on the functional role of its target network. Our results
demonstrate that this clustered strategy significantly enhances prediction
accuracy across the 1,000 cortical regions of the Schaefer atlas. The final
model achieved an eighth-place ranking in the Algonauts Project 2025 Challenge,
with out-of-distribution (OOD) correlation scores nearly double those of the
baseline model used in the selection phase. Code is available at
https://github.com/Corsi01/algo2025.

</details>


### [473] [Teaching Introduction to Programming in the times of AI: A case study of a course re-design](https://arxiv.org/abs/2508.06572)
*Nikolaos Avouris,Kyriakos Sgarbas,George Caridakis,Christos Sintoris*

Main category: cs.CY

Relevance: 30.0

TL;DR: 该论文综述了编程教育中AI工具的应用现状，探讨了课程设计、学习目标、评估方式及学生滥用工具的挑战，并提出了重新设计课程和教学法的建议。


<details>
  <summary>Details</summary>
Motivation: 研究动机是应对AI工具在编程教育中的普及及其带来的挑战，如课程设计和学生滥用问题。

Method: 方法包括文献综述和案例分析，提出课程重新设计和教学法调整的建议。

Result: 结果为针对AI工具的课程设计指南，帮助教育机构最大化AI工具的益处。

Conclusion: 结论是AI工具在编程教育中具有潜力，但需通过政策调整和教学法优化来应对挑战。

Abstract: The integration of AI tools into programming education has become
increasingly prevalent in recent years, transforming the way programming is
taught and learned. This paper provides a review of the state-of-the-art AI
tools available for teaching and learning programming, particularly in the
context of introductory courses. It highlights the challenges on course design,
learning objectives, course delivery and formative and summative assessment, as
well as the misuse of such tools by the students. We discuss ways of
re-designing an existing course, re-shaping assignments and pedagogy to address
the current AI technologies challenges. This example can serve as a guideline
for policies for institutions and teachers involved in teaching programming,
aiming to maximize the benefits of AI tools while addressing the associated
challenges and concerns.

</details>


### [474] [Efficient Safety Testing of Autonomous Vehicles via Adaptive Search over Crash-Derived Scenarios](https://arxiv.org/abs/2508.06575)
*Rui Zhou*

Main category: cs.RO

Relevance: 30.0

TL;DR: 该论文提出了一种加速测试算法（ALVNS-SA），用于验证自动驾驶车辆在安全关键场景中的安全性，显著提高了测试效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆的安全性至关重要，尤其是在安全关键场景中。需要高效的测试方法来快速验证其驾驶能力。

Method: 1. 从真实事故数据库中提取典型逻辑场景；2. 集成百度Apollo自动驾驶系统；3. 提出ALVNS-SA算法加速测试。

Result: ALVNS-SA显著提升了测试效率，覆盖了84.00%的安全关键场景，其中碰撞场景覆盖率为96.83%，接近碰撞场景覆盖率为92.07%。

Conclusion: ALVNS-SA在安全关键场景中的表现优于其他算法，为自动驾驶车辆的安全测试提供了高效解决方案。

Abstract: Ensuring the safety of autonomous vehicles (AVs) is paramount in their
development and deployment. Safety-critical scenarios pose more severe
challenges, necessitating efficient testing methods to validate AVs safety.
This study focuses on designing an accelerated testing algorithm for AVs in
safety-critical scenarios, enabling swift recognition of their driving
capabilities. First, typical logical scenarios were extracted from real-world
crashes in the China In-depth Mobility Safety Study-Traffic Accident (CIMSS-TA)
database, obtaining pre-crash features through reconstruction. Second, Baidu
Apollo, an advanced black-box automated driving system (ADS) is integrated to
control the behavior of the ego vehicle. Third, we proposed an adaptive
large-variable neighborhood-simulated annealing algorithm (ALVNS-SA) to
expedite the testing process. Experimental results demonstrate a significant
enhancement in testing efficiency when utilizing ALVNS-SA. It achieves an
84.00% coverage of safety-critical scenarios, with crash scenario coverage of
96.83% and near-crash scenario coverage of 92.07%. Compared to genetic
algorithm (GA), adaptive large neighborhood-simulated annealing algorithm
(ALNS-SA), and random testing, ALVNS-SA exhibits substantially higher coverage
in safety-critical scenarios.

</details>


### [475] [Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications](https://arxiv.org/abs/2508.07165)
*Zelin Qiu,Xi Wang,Zhuoyao Xie,Juan Zhou,Yu Wang,Lingjie Yang,Xinrui Jiang,Juyoung Bae,Moo Hyun Son,Qiang Ye,Dexuan Chen,Rui Zhang,Tao Li,Neeraj Ramesh Mahboobani,Varut Vardhanabhuti,Xiaohui Duan,Yinghua Zhao,Hao Chen*

Main category: eess.IV

Relevance: 30.0

TL;DR: PRISM是一个基于大规模多序列MRI预训练的基础模型，旨在解决MRI序列异质性对深度学习模型泛化能力的挑战。


<details>
  <summary>Details</summary>
Motivation: MRI序列的异质性限制了深度学习模型的临床适用性，PRISM旨在通过预训练学习稳健且可泛化的表示。

Method: PRISM通过解耦解剖不变特征和序列特异性变化进行预训练，并在44个下游任务上评估。

Result: PRISM在39/44任务中表现最佳，显著优于非预训练模型和其他基础模型。

Conclusion: PRISM为多序列MRI分析提供了可扩展框架，增强了AI在放射学中的转化潜力。

Abstract: Multi-sequence Magnetic Resonance Imaging (MRI) offers remarkable
versatility, enabling the distinct visualization of different tissue types.
Nevertheless, the inherent heterogeneity among MRI sequences poses significant
challenges to the generalization capability of deep learning models. These
challenges undermine model performance when faced with varying acquisition
parameters, thereby severely restricting their clinical utility. In this study,
we present PRISM, a foundation model PRe-trained with large-scale
multI-Sequence MRI. We collected a total of 64 datasets from both public and
private sources, encompassing a wide range of whole-body anatomical structures,
with scans spanning diverse MRI sequences. Among them, 336,476 volumetric MRI
scans from 34 datasets (8 public and 26 private) were curated to construct the
largest multi-organ multi-sequence MRI pretraining corpus to date. We propose a
novel pretraining paradigm that disentangles anatomically invariant features
from sequence-specific variations in MRI, while preserving high-level semantic
representations. We established a benchmark comprising 44 downstream tasks,
including disease diagnosis, image segmentation, registration, progression
prediction, and report generation. These tasks were evaluated on 32 public
datasets and 5 private cohorts. PRISM consistently outperformed both
non-pretrained models and existing foundation models, achieving first-rank
results in 39 out of 44 downstream benchmarks with statistical significance
improvements. These results underscore its ability to learn robust and
generalizable representations across unseen data acquired under diverse MRI
protocols. PRISM provides a scalable framework for multi-sequence MRI analysis,
thereby enhancing the translational potential of AI in radiology. It delivers
consistent performance across diverse imaging protocols, reinforcing its
clinical applicability.

</details>


### [476] [Leveraging LLMs for Privacy-Aware Predictions in Participatory Budgeting](https://arxiv.org/abs/2508.06577)
*Juan Zambrano,Clément Contet,Jairo Gudiño,Felipe Garrido-Lucero,Umberto Grandi,Cesar A Hidalgo*

Main category: cs.CY

Relevance: 30.0

TL;DR: 论文提出了一种隐私保护方法，利用文本描述和历史投票数据预测参与式预算（PB）提案的资助可能性，评估了GPT-4 Turbo的性能，发现需结合历史数据才能准确预测。


<details>
  <summary>Details</summary>
Motivation: 参与式预算（PB）因低参与率限制了其民主潜力，论文旨在通过支持提案者和组织者提升PB选举的透明度和效率。

Method: 使用提案的文本描述和匿名历史投票数据，提出隐私保护方法预测提案资助可能性，并评估GPT-4 Turbo的性能。

Result: GPT-4 Turbo需结合历史投票数据才能准确预测提案结果，反映真实投票行为。

Conclusion: AI工具可提升PB过程的透明度、规划效率和公民参与度。

Abstract: Participatory Budgeting (PB) empowers citizens to propose and vote on public
investment projects. Yet, despite its democratic potential, PB initiatives
often suffer from low participation rates, limiting their visibility and
perceived legitimacy. In this work, we aim to strengthen PB elections in two
key ways: by supporting project proposers in crafting better proposals, and by
helping PB organizers manage large volumes of submissions in a transparent
manner. We propose a privacy-preserving approach to predict which PB proposals
are likely to be funded, using only their textual descriptions and anonymous
historical voting records -- without relying on voter demographics or
personally identifiable information. We evaluate the performance of GPT 4 Turbo
in forecasting proposal outcomes across varying contextual scenarios, observing
that the LLM's prior knowledge needs to be complemented by past voting data to
obtain predictions reflecting real-world PB voting behavior. Our findings
highlight the potential of AI-driven tools to support PB processes by improving
transparency, planning efficiency, and civic engagement.

</details>


### [477] [Neural Beam Field for Spatial Beam RSRP Prediction](https://arxiv.org/abs/2508.06956)
*Keqiang Guo,Yuheng Zhong,Xin Tong,Jiangbin Lyu,Rui Zhang*

Main category: cs.IT

Relevance: 30.0

TL;DR: 该论文提出了一种名为Neural Beam Field (NBF)的混合神经物理框架，用于高效且可解释的空间波束RSRP预测，结合了Transformer网络和物理建模。


<details>
  <summary>Details</summary>
Motivation: 在密集多用户无线网络中，准确预测波束级RSRP对波束管理至关重要，但高测量开销和快速信道变化使其具有挑战性。

Method: 采用混合设计：Transformer网络学习多径条件功率分布（MCPP），物理模块推断波束RSRP统计；引入预训练和校准策略（PaC）。

Result: NBF在预测精度、训练效率和泛化能力上显著优于传统方法，同时保持紧凑模型大小。

Conclusion: NBF为下一代密集无线网络提供了可扩展且基于物理的智能波束管理解决方案。

Abstract: Accurately predicting beam-level reference signal received power (RSRP) is
essential for beam management in dense multi-user wireless networks, yet
challenging due to high measurement overhead and fast channel variations. This
paper proposes Neural Beam Field (NBF), a hybrid neural-physical framework for
efficient and interpretable spatial beam RSRP prediction. Central to our
approach is the introduction of the Multi-path Conditional Power Profile
(MCPP), which bridges site-specific multipath propagation with antenna/beam
configurations via closed-form analytical modeling. We adopt a decoupled
``blackbox-whitebox" design: a Transformer-based deep neural network (DNN)
learns the MCPP from sparse user measurements and positions, while a
physics-inspired module analytically infers beam RSRP statistics. To improve
convergence and adaptivity, we further introduce a Pretrain-and-Calibrate (PaC)
strategy that leverages ray-tracing priors and on-site calibration using RSRP
data. Extensive simulations results demonstrate that NBF significantly
outperforms conventional table-based channel knowledge maps (CKMs) and pure
blackbox DNNs in prediction accuracy, training efficiency, and generalization,
while maintaining a compact model size. The proposed framework offers a
scalable and physically grounded solution for intelligent beam management in
next-generation dense wireless networks.

</details>


### [478] [Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization](https://arxiv.org/abs/2508.07001)
*Myeung Suk Oh,Zhiyao Zhang,FNU Hairi,Alvaro Velasquez,Jia Liu*

Main category: cs.NI

Relevance: 30.0

TL;DR: 论文提出了一种完全去中心化的多智能体强化学习（MARL）架构，用于优化无线网络中的随机接入（RA）性能，通过基于共识的信息交换和仅交换局部奖励来减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 设计有效的RA协议以减少碰撞并确保传输公平性是无线网络中的关键挑战。现有基于集中式训练的MARL方法在实际应用中存在局限性。

Method: 采用完全去中心化的MARL架构，基于演员-评论家（AC）网络设计算法，仅交换局部奖励以减少通信开销，并提供全局收敛的理论证明。

Result: 数值实验表明，所提出的MARL算法显著优于其他基线方法，提升了RA网络性能。

Conclusion: 完全去中心化的MARL架构在优化RA性能方面具有潜力，且通信开销更低。

Abstract: With wireless devices increasingly forming a unified smart network for
seamless, user-friendly operations, random access (RA) medium access control
(MAC) design is considered a key solution for handling unpredictable data
traffic from multiple terminals. However, it remains challenging to design an
effective RA-based MAC protocol to minimize collisions and ensure transmission
fairness across the devices. While existing multi-agent reinforcement learning
(MARL) approaches with centralized training and decentralized execution (CTDE)
have been proposed to optimize RA performance, their reliance on centralized
training and the significant overhead required for information collection can
make real-world applications unrealistic. In this work, we adopt a fully
decentralized MARL architecture, where policy learning does not rely on
centralized tasks but leverages consensus-based information exchanges across
devices. We design our MARL algorithm over an actor-critic (AC) network and
propose exchanging only local rewards to minimize communication overhead.
Furthermore, we provide a theoretical proof of global convergence for our
approach. Numerical experiments show that our proposed MARL algorithm can
significantly improve RA network performance compared to other baselines.

</details>


### [479] [Neural Channel Knowledge Map Assisted Scheduling Optimization of Active IRSs in Multi-User Systems](https://arxiv.org/abs/2508.07009)
*Xintong Chen,Zhenyu Jiang,Jiangbin Lyu,Liqun Fu*

Main category: cs.IT

Relevance: 30.0

TL;DR: 该论文提出了一种基于神经通道知识图（CKM）的新型调度框架，利用Transformer架构预测频谱效率，并结合低复杂度调度算法优化多用户系统性能。


<details>
  <summary>Details</summary>
Motivation: 解决智能反射面（IRS）在无线网络中因硬件限制导致的双路径损耗和多用户调度复杂性问题。

Method: 设计了两级Transformer网络（LPS-Net和SE-Net）预测链路功率统计和频谱效率，并提出了低复杂度的SM-IB调度算法。

Result: 神经CKM显著提高了预测精度和计算效率，SM-IB算法以低复杂度实现了接近最优的吞吐量。

Conclusion: 该方法为多IRS多用户系统提供了高效的调度解决方案。

Abstract: Intelligent Reflecting Surfaces (IRSs) have potential for significant
performance gains in next-generation wireless networks but face key challenges,
notably severe double-pathloss and complex multi-user scheduling due to
hardware constraints. Active IRSs partially address pathloss but still require
efficient scheduling in cell-level multi-IRS multi-user systems, whereby the
overhead/delay of channel state acquisition and the scheduling complexity both
rise dramatically as the user density and channel dimensions increase.
Motivated by these challenges, this paper proposes a novel scheduling framework
based on neural Channel Knowledge Map (CKM), designing Transformer-based deep
neural networks (DNNs) to predict ergodic spectral efficiency (SE) from
historical channel/throughput measurements tagged with user positions.
Specifically, two cascaded networks, LPS-Net and SE-Net, are designed to
predict link power statistics (LPS) and ergodic SE accurately. We further
propose a low-complexity Stable Matching-Iterative Balancing (SM-IB) scheduling
algorithm. Numerical evaluations verify that the proposed neural CKM
significantly enhances prediction accuracy and computational efficiency, while
the SM-IB algorithm effectively achieves near-optimal max-min throughput with
greatly reduced complexity.

</details>


### [480] [Making Effective Decisions: Machine Learning and the Ecogame in 1970](https://arxiv.org/abs/2508.07027)
*Catherine Mason*

Main category: cs.CY

Relevance: 30.0

TL;DR: Ecogame是1970年代的一个创新艺术项目，结合了视觉艺术与控制论概念，通过模拟和早期机器学习技术探索行为对系统的影响，为当代AI艺术提供了历史参考。


<details>
  <summary>Details</summary>
Motivation: 研究Ecogame项目，探讨其如何通过艺术与技术结合提出更人性化的AI应用愿景。

Method: 使用模拟和早期机器学习技术，结合控制论的适应、反馈和控制概念。

Result: Ecogame展示了行为对系统的影响，为当代AI艺术提供了历史先例。

Conclusion: Ecogame为现代AI艺术的人性化应用提供了早期范例。

Abstract: This paper considers Ecogame, an innovative art project of 1970, whose
creators believed in a positive vision of a technological future; an
understanding, posited on cybernetics, of a future that could be participatory
via digital means, and therefore more democratised. Using simulation and early
machine learning techniques over a live network, Ecogame combined the power of
visual art with cybernetic concepts of adaptation, feedback, and control to
propose that behaviour had implications for the total system. It provides an
historical precedent for contemporary AI-driven art about using AI in a more
human-centred way.

</details>


### [481] [Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction](https://arxiv.org/abs/2508.07079)
*Mohamed Parvez Aslam,Bojan Derajic,Mohamed-Khalil Bouzidi,Sebastian Bernhard,Jan Oliver Ringert*

Main category: cs.RO

Relevance: 30.0

TL;DR: 论文研究了在行人密集环境中，将基于深度学习的Social-Implicit（SI）行人轨迹预测器与模型预测控制（MPC）框架结合，以提升自主机器人的导航安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 解决自主机器人在行人密集环境中的安全导航问题，通过结合SI预测器和MPC框架，提高轨迹预测精度和导航性能。

Method: 在物理机器人上测试SI-MPC系统，并与传统恒定速度（CV）模型在开环预测和闭环导航中进行对比。

Result: SI模型在低密度环境中减少轨迹预测误差达76%，并在拥挤场景中提升安全性和运动平滑性。

Conclusion: SI-MPC框架在动态行人环境中表现出更高的安全性和适应性，强调了系统级评估的重要性。

Abstract: Safe navigation in pedestrian-rich environments remains a key challenge for
autonomous robots. This work evaluates the integration of a deep learning-based
Social-Implicit (SI) pedestrian trajectory predictor within a Model Predictive
Control (MPC) framework on the physical Continental Corriere robot. Tested
across varied pedestrian densities, the SI-MPC system is compared to a
traditional Constant Velocity (CV) model in both open-loop prediction and
closed-loop navigation. Results show that SI improves trajectory prediction -
reducing errors by up to 76% in low-density settings - and enhances safety and
motion smoothness in crowded scenes. Moreover, real-world deployment reveals
discrepancies between open-loop metrics and closed-loop performance, as the SI
model yields broader, more cautious predictions. These findings emphasize the
importance of system-level evaluation and highlight the SI-MPC framework's
promise for safer, more adaptive navigation in dynamic, human-populated
environments.

</details>


### [482] [An Evolutionary Game-Theoretic Merging Decision-Making Considering Social Acceptance for Autonomous Driving](https://arxiv.org/abs/2508.07080)
*Haolin Liu,Zijun Guo,Yanbo Chen,Jiaqi Chen,Huilong Yu,Junqiang Xi*

Main category: cs.RO

Relevance: 30.0

TL;DR: 论文提出了一种基于进化博弈论（EGT）的自动驾驶车辆（AVs）高速入口合并决策框架，通过动态平衡AVs和主路车辆（MVs）的利益，优化合并决策的效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有决策算法未能充分应对动态复杂性和AVs的社会接受度，导致合并决策次优或不安全。

Method: 采用进化博弈论框架，结合人类驾驶员的有限理性，设计多目标收益函数，并通过求解复制动态方程得到最优合并时机。

Result: 实验结果表明，该方法在效率、舒适性和安全性上优于现有博弈论和传统规划方法。

Conclusion: EGT框架有效提升了AVs和MVs的合并决策性能，平衡了多方利益。

Abstract: Highway on-ramp merging is of great challenge for autonomous vehicles (AVs),
since they have to proactively interact with surrounding vehicles to enter the
main road safely within limited time. However, existing decision-making
algorithms fail to adequately address dynamic complexities and social
acceptance of AVs, leading to suboptimal or unsafe merging decisions. To
address this, we propose an evolutionary game-theoretic (EGT) merging
decision-making framework, grounded in the bounded rationality of human
drivers, which dynamically balances the benefits of both AVs and main-road
vehicles (MVs). We formulate the cut-in decision-making process as an EGT
problem with a multi-objective payoff function that reflects human-like driving
preferences. By solving the replicator dynamic equation for the evolutionarily
stable strategy (ESS), the optimal cut-in timing is derived, balancing
efficiency, comfort, and safety for both AVs and MVs. A real-time driving style
estimation algorithm is proposed to adjust the game payoff function online by
observing the immediate reactions of MVs. Empirical results demonstrate that we
improve the efficiency, comfort and safety of both AVs and MVs compared with
existing game-theoretic and traditional planning approaches across multi-object
metrics.

</details>


### [483] [Toward AI Matching Policies in Homeless Services: A Qualitative Study with Policymakers](https://arxiv.org/abs/2508.07129)
*Caroline M. Johnston,Olga Koumoundouros,Angel Hsing-Chi Hwang,Laura Onasch-Vera,Eric Rice,Phebe Vayanos*

Main category: cs.HC

Relevance: 30.0

TL;DR: 研究探讨了无家可归者住房资源匹配中AI算法的接受度，发现政策制定者欢迎AI工具，但需与人类决策结合。


<details>
  <summary>Details</summary>
Motivation: 探讨AI算法在住房资源匹配中的实际应用和接受度。

Method: 通过半结构化访谈，调查洛杉矶13位政策制定者对AI匹配工具的看法。

Result: 政策制定者支持AI工具，但强调需与人类决策结合，并关注效率、公平和透明度。

Conclusion: AI工具在低资源场景中有潜力，但需谨慎设计和结合人类决策。

Abstract: Artificial intelligence researchers have proposed various data-driven
algorithms to improve the processes that match individuals experiencing
homelessness to scarce housing resources. It remains unclear whether and how
these algorithms are received or adopted by practitioners and what their
corresponding consequences are. Through semi-structured interviews with 13
policymakers in homeless services in Los Angeles, we investigate whether such
change-makers are open to the idea of integrating AI into the housing resource
matching process, identifying where they see potential gains and drawbacks from
such a system in issues of efficiency, fairness, and transparency. Our
qualitative analysis indicates that, even when aware of various complicating
factors, policymakers welcome the idea of an AI matching tool if thoughtfully
designed and used in tandem with human decision-makers. Though there is no
consensus as to the exact design of such an AI system, insights from
policymakers raise open questions and design considerations that can be
enlightening for future researchers and practitioners who aim to build
responsible algorithmic systems to support decision-making in low-resource
scenarios.

</details>


### [484] ["Draw me a curator" Examining the visual stereotyping of a cultural services profession by generative AI](https://arxiv.org/abs/2508.07132)
*Dirk HR Spennemann*

Main category: cs.CY

Relevance: 30.0

TL;DR: 论文分析了ChatGPT4o生成的博物馆策展人图像，发现其存在性别、年龄和种族的严重偏差，与实际情况不符。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示生成式AI模型在图像生成中的偏见问题，特别是对博物馆策展人这一职业的刻板印象和偏差。

Method: 基于230个AI生成的视觉化图像，对比现实世界中的策展人人口统计数据。

Result: AI生成的图像中女性（3.5%）和少数族裔（0%）严重不足，年轻人（79%）过度代表，且呈现刻板化特征（如胡须、手持剪贴板）。

Conclusion: 生成式AI的数据集存在偏见，可能导致对博物馆策展人的不准确描述。

Abstract: Based on 230 visualisations, this paper examines the depiction of museum
curators by the popular generative Artificial Intelligence (AI) model,
ChatGPT4o. While the AI-generated representations do not reiterate popular
stereotypes of curators as nerdy, conservative in dress and stuck in time
rummaging through collections, they contrast sharply with real-world
demographics. AI-generated imagery extremely underrepresents women (3.5% vs 49%
to 72% in reality) and disregards ethnic communities other than Caucasian (0%
vs 18% to 36%). It only over-represents young curators (79% vs approx. 27%) but
also renders curators to resemble yuppie professionals or people featuring in
fashion advertising. Stereotypical attributes are prevalent, with curators
widely depicted as wearing beards and holding clipboards or digital tablets.
The findings highlight biases in the generative AI image creation dataset,
which is poised to shape an inaccurate portrayal of museum professionals if the
images were to be taken uncritically at face value.

</details>


### [485] [Presburger Functional Synthesis: Complexity and Tractable Normal Forms](https://arxiv.org/abs/2508.07207)
*S. Akshay,A. R. Balasubramanian,Supratik Chakraborty,Georg Zetzsche*

Main category: cs.LO

Relevance: 30.0

TL;DR: 本文研究了Presburger算术理论中的功能合成问题（PFnS），证明了其EXPTIME复杂度，并提出了PSyNF形式以高效解决PFnS。


<details>
  <summary>Details</summary>
Motivation: 功能合成问题在多种逻辑理论中已有研究，但在Presburger算术理论中尚未深入探索。本文旨在填补这一空白。

Method: 通过理论分析，证明了PFnS的EXPTIME复杂度，并提出了PSyNF形式及其编译方法。

Result: PFnS在EXPTIME内可解，PSyNF形式能保证多项式时间和空间复杂度。

Conclusion: PSyNF形式为高效解决PFnS提供了有效途径，并揭示了其与其他形式的关联。

Abstract: Given a relational specification between inputs and outputs as a logic
formula, the problem of functional synthesis is to automatically synthesize a
function from inputs to outputs satisfying the relation. Recently, a rich line
of work has emerged tackling this problem for specifications in different
theories, from Boolean to general first-order logic. In this paper, we launch
an investigation of this problem for the theory of Presburger Arithmetic, that
we call Presburger Functional Synthesis (PFnS). We show that PFnS can be solved
in EXPTIME and provide a matching exponential lower bound. This is unlike the
case for Boolean functional synthesis (BFnS), where only conditional
exponential lower bounds are known. Further, we show that PFnS for one input
and one output variable is as hard as BFnS in general. We then identify a
special normal form, called PSyNF, for the specification formula that
guarantees poly-time and poly-size solvability of PFnS. We prove several
properties of PSyNF, including how to check and compile to this form, and
conditions under which any other form that guarantees poly-time solvability of
PFnS can be compiled in poly-time to PSyNF. Finally, we identify a syntactic
normal form that is easier to check but is exponentially less succinct than
PSyNF.

</details>


### [486] [Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images](https://arxiv.org/abs/2508.07875)
*Shuo Han,Ahmed Karam Eldaly,Solomon Sunday Oyelere*

Main category: eess.IV

Relevance: 30.0

TL;DR: 论文提出了一种人机交互（HITL）深度学习系统，用于检测乳腺癌中的浸润性导管癌（IDC），结合AI和医学专家反馈以提高诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 早期准确诊断IDC对提高患者生存率至关重要，结合AI与医学专家可以提升诊断的精确性和效率。

Method: 使用EfficientNetV2S模型进行初步诊断，医学专家修正误分类图像并反馈给模型，形成迭代优化循环。

Result: EfficientNetV2S模型准确率达93.65%，结合HITL系统后进一步提升了性能。

Conclusion: 人机协作方法为AI辅助医疗诊断提供了高效、准确的解决方案。

Abstract: Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer,
and early, accurate diagnosis is critical to improving patient survival rates
by guiding treatment decisions. Combining medical expertise with artificial
intelligence (AI) holds significant promise for enhancing the precision and
efficiency of IDC detection. In this work, we propose a human-in-the-loop
(HITL) deep learning system designed to detect IDC in histopathology images.
The system begins with an initial diagnosis provided by a high-performance
EfficientNetV2S model, offering feedback from AI to the human expert. Medical
professionals then review the AI-generated results, correct any misclassified
images, and integrate the revised labels into the training dataset, forming a
feedback loop from the human back to the AI. This iterative process refines the
model's performance over time. The EfficientNetV2S model itself achieves
state-of-the-art performance compared to existing methods in the literature,
with an overall accuracy of 93.65\%. Incorporating the human-in-the-loop system
further improves the model's accuracy using four experimental groups with
misclassified images. These results demonstrate the potential of this
collaborative approach to enhance AI performance in diagnostic systems. This
work contributes to advancing automated, efficient, and highly accurate methods
for IDC detection through human-AI collaboration, offering a promising
direction for future AI-assisted medical diagnostics.

</details>


### [487] [From Knowledge to Conjectures: A Modal Framework for Reasoning about Hypotheses](https://arxiv.org/abs/2508.07304)
*Fabio Vitali*

Main category: cs.LO

Relevance: 30.0

TL;DR: 本文提出了一种新的认知模态逻辑家族，用于形式化推测性推理，通过假设扩展已知事实以探索其后果。不同于传统信念和认知系统，该系统采用Axiom C避免模态崩溃，并在弱Kleene逻辑或描述逻辑的框架下定义新模态系统KC和KDC，证明其完备性、可判定性及在部分知识下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统模态逻辑在推测性推理中存在局限性，尤其是Axiom C导致的模态崩溃问题。本文旨在解决这一问题，提出一种新的逻辑框架，以支持更灵活的认知推理。

Method: 采用弱Kleene逻辑或描述逻辑的语义框架，避免Axiom T，定义新模态系统KC和KDC，并引入动态操作settle(φ)以形式化从推测到事实的过渡。

Result: 新系统KC和KDC被证明是完备、可判定的，且在部分知识下具有鲁棒性。动态操作settle(φ)成功捕捉了认知状态更新的过程。

Conclusion: 本文提出的认知模态逻辑框架有效解决了传统系统中的模态崩溃问题，为推测性推理提供了更灵活的工具。

Abstract: This paper introduces a new family of cognitive modal logics designed to
formalize conjectural reasoning: a modal system in which cognitive contexts
extend known facts with hypothetical assumptions to explore their consequences.
Unlike traditional doxastic and epistemic systems, conjectural logics rely on a
principle, called Axiom C ($\varphi \rightarrow \Box\varphi$), that ensures
that all established facts are preserved across hypothetical layers. While
Axiom C was dismissed in the past due to its association with modal collapse,
we show that the collapse only arises under classical and bivalent assumptions,
and specifically in the presence of Axiom T. Hence we avoid Axiom T and adopt a
paracomplete semantic framework, grounded in Weak Kleene logic or Description
Logic, where undefined propositions coexist with modal assertions. This
prevents the modal collapse and guarantees a layering to distinguish between
factual and conjectural statements. Under this framework we define new modal
systems, e.g., KC and KDC, and show that they are complete, decidable, and
robust under partial knowledge. Finally, we introduce a dynamic operation,
$\mathsf{settle}(\varphi)$, which formalizes the transition from conjecture to
accepted fact, capturing the event of the update of a world's cognitive state
through the resolution of uncertainty.

</details>


### [488] [AgriVLN: Vision-and-Language Navigation for Agricultural Robots](https://arxiv.org/abs/2508.07406)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

Relevance: 30.0

TL;DR: 论文提出了农业场景下的视觉与语言导航（VLN）基准A2A和基线方法AgriVLN，解决了现有VLN方法在农业领域的不足，并通过指令分解模块提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法未针对农业场景设计，限制了农业机器人的导航能力。论文旨在填补这一空白。

Method: 提出A2A基准和基于VLM的AgriVLN方法，并引入Subtask List（STL）模块分解指令。

Result: AgriVLN在短指令上表现良好，但长指令执行较差；STL模块将成功率从0.33提升至0.47。

Conclusion: AgriVLN在农业领域表现最优，STL模块显著提升了长指令的执行能力。

Abstract: Agricultural robots have emerged as powerful members in agricultural tasks,
nevertheless, still heavily rely on manual operation or untransportable railway
for movement, resulting in limited mobility and poor adaptability.
Vision-and-Language Navigation (VLN) enables robots to navigate to the target
destinations following natural language instructions, demonstrating strong
performance on several domains. However, none of the existing benchmarks or
methods is specifically designed for agricultural scenes. To bridge this gap,
we propose Agriculture to Agriculture (A2A) benchmark, containing 1,560
episodes across six diverse agricultural scenes, in which all realistic RGB
videos are captured by front-facing camera on a quadruped robot at a height of
0.38 meters, aligning with the practical deployment conditions. Meanwhile, we
propose Vision-and-Language Navigation for Agricultural Robots (AgriVLN)
baseline based on Vision-Language Model (VLM) prompted with carefully crafted
templates, which can understand both given instructions and agricultural
environments to generate appropriate low-level actions for robot control. When
evaluated on A2A, AgriVLN performs well on short instructions but struggles
with long instructions, because it often fails to track which part of the
instruction is currently being executed. To address this, we further propose
Subtask List (STL) instruction decomposition module and integrate it into
AgriVLN, improving Success Rate (SR) from 0.33 to 0.47. We additionally compare
AgriVLN with several existing VLN methods, demonstrating the state-of-the-art
performance in the agricultural domain.

</details>


### [489] [Leveraging GNN to Enhance MEF Method in Predicting ENSO](https://arxiv.org/abs/2508.07410)
*Saghar Ganji,Mohammad Naisipour*

Main category: physics.ao-ph

Relevance: 30.0

TL;DR: 论文提出了一种基于图分析的改进框架，用于优化ENSO预测中的多模态集成模型，通过相似性聚类和社区检测选择最优子集，提升预测稳定性和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有MEF模型在集成预测中未充分利用高表现但分散的预测成员的问题，提升长期ENSO预测的可靠性。

Method: 构建无向图表示集成成员间的相似性（通过RMSE和相关性），使用社区检测方法选择最优子集（20个成员）进行平均预测。

Result: 改进方法通过噪声去除和强调集成一致性提升了预测技能，尤其在复杂长期预测中表现更稳定。

Conclusion: 图分析方法不仅提升了ENSO预测性能，还具有模型无关性，可推广到其他大规模集成预测问题。

Abstract: Reliable long-lead forecasting of the El Nino Southern Oscillation (ENSO)
remains a long-standing challenge in climate science. The previously developed
Multimodal ENSO Forecast (MEF) model uses 80 ensemble predictions by two
independent deep learning modules: a 3D Convolutional Neural Network (3D-CNN)
and a time-series module. In their approach, outputs of the two modules are
combined using a weighting strategy wherein one is prioritized over the other
as a function of global performance. Separate weighting or testing of
individual ensemble members did not occur, however, which may have limited the
model to optimize the use of high-performing but spread-out forecasts. In this
study, we propose a better framework that employs graph-based analysis to
directly model similarity between all 80 members of the ensemble. By
constructing an undirected graph whose vertices are ensemble outputs and whose
weights on edges measure similarity (via RMSE and correlation), we identify and
cluster structurally similar and accurate predictions. From which we obtain an
optimized subset of 20 members using community detection methods. The final
prediction is then obtained by averaging this optimized subset. This method
improves the forecast skill through noise removal and emphasis on ensemble
coherence. Interestingly, our graph-based selection shows robust statistical
characteristics among top performers, offering new ensemble behavior insights.
In addition, we observe that while the GNN-based approach does not always
outperform the baseline MEF under every scenario, it produces more stable and
consistent outputs, particularly in compound long-lead situations. The approach
is model-agnostic too, suggesting that it can be applied directly to other
forecasting models with gargantuan ensemble outputs, such as statistical,
physical, or hybrid models.

</details>


### [490] [Real-Time Analysis of Unstructured Data with Machine Learning on Heterogeneous Architectures](https://arxiv.org/abs/2508.07423)
*Fotis I. Giasemis*

Main category: hep-ex

Relevance: 30.0

TL;DR: 该论文探讨了如何在粒子物理实验的高频数据处理环境中高效部署机器学习模型，特别是图神经网络（GNN），以优化计算资源使用和能耗。


<details>
  <summary>Details</summary>
Motivation: 随着粒子物理实验数据量的激增，传统数据处理方法难以满足实时性和能耗需求，需要现代硬件和算法支持。

Method: 开发了一个基于GNN的管道，用于LHCb实验中的带电粒子轨迹重建，并在GPU和FPGA上实现和优化。

Result: GNN管道在GPU和FPGA上的性能优于传统算法，尤其在处理速度和能耗方面表现突出。

Conclusion: 机器学习模型（如GNN）在高能物理实验的实时数据处理中具有潜力，但需结合现代硬件优化。

Abstract: As the particle physics community needs higher and higher precisions in order
to test our current model of the subatomic world, larger and larger datasets
are necessary. With upgrades scheduled for the detectors of colliding-beam
experiments around the world, and specifically at the Large Hadron Collider at
CERN, more collisions and more complex interactions are expected. This directly
implies an increase in data produced and consequently in the computational
resources needed to process them. At CERN, the amount of data produced is
gargantuan. This is why the data have to be heavily filtered and selected in
real time before being permanently stored. This data can then be used to
perform physics analyses, in order to expand our current understanding of the
universe and improve the Standard Model of physics. This real-time filtering,
known as triggering, involves complex processing happening often at frequencies
as high as 40 MHz. This thesis contributes to understanding how machine
learning models can be efficiently deployed in such environments, in order to
maximize throughput and minimize energy consumption. Inevitably, modern
hardware designed for such tasks and contemporary algorithms are needed in
order to meet the challenges posed by the stringent, high-frequency data rates.
In this work, I present our graph neural network-based pipeline, developed for
charged particle track reconstruction at the LHCb experiment at CERN. The
pipeline was implemented end-to-end inside LHCb's first-level trigger, entirely
on GPUs. Its performance was compared against the classical tracking algorithms
currently in production at LHCb. The pipeline was also accelerated on the FPGA
architecture, and its performance in terms of power consumption and processing
speed was compared against the GPU implementation.

</details>


### [491] [Noise-Aware Generative Microscopic Traffic Simulation](https://arxiv.org/abs/2508.07453)
*Vindula Jayawardana,Catherine Tang,Junyi Ji,Jonah Philion,Xue Bin Peng,Cathy Wu*

Main category: eess.SY

Relevance: 30.0

TL;DR: 论文提出了一种标准化、真实反映传感器噪声的交通数据集I24-MSD，并采用噪声感知学习方法改进生成模型，以提升微观交通仿真的真实性。


<details>
  <summary>Details</summary>
Motivation: 传统交通仿真模型因简化复杂性而缺乏真实性，而现有数据集过于理想化。I24-MSD旨在保留真实传感器噪声，推动更贴近实际的仿真研究。

Method: 利用基础设施摄像头提取车辆轨迹数据，构建I24-MSD数据集，并采用噪声感知损失函数改进生成模型。

Result: 噪声感知模型在真实性上优于传统基线，且能有效利用数据中的噪声。

Conclusion: I24-MSD为微观交通仿真提供了更贴近实际的数据和方法，推动了该领域的实用化发展。

Abstract: Accurately modeling individual vehicle behavior in microscopic traffic
simulation remains a key challenge in intelligent transportation systems, as it
requires vehicles to realistically generate and respond to complex traffic
phenomena such as phantom traffic jams. While traditional human driver
simulation models offer computational tractability, they do so by abstracting
away the very complexity that defines human driving. On the other hand, recent
advances in infrastructure-mounted camera-based roadway sensing have enabled
the extraction of vehicle trajectory data, presenting an opportunity to shift
toward generative, agent-based models. Yet, a major bottleneck remains: most
existing datasets are either overly sanitized or lack standardization, failing
to reflect the noisy, imperfect nature of real-world sensing. Unlike data from
vehicle-mounted sensors-which can mitigate sensing artifacts like occlusion
through overlapping fields of view and sensor fusion-infrastructure-based
sensors surface a messier, more practical view of challenges that traffic
engineers encounter. To this end, we present the I-24 MOTION Scenario Dataset
(I24-MSD)-a standardized, curated dataset designed to preserve a realistic
level of sensor imperfection, embracing these errors as part of the learning
problem rather than an obstacle to overcome purely from preprocessing. Drawing
from noise-aware learning strategies in computer vision, we further adapt
existing generative models in the autonomous driving community for I24-MSD with
noise-aware loss functions. Our results show that such models not only
outperform traditional baselines in realism but also benefit from explicitly
engaging with, rather than suppressing, data imperfection. We view I24-MSD as a
stepping stone toward a new generation of microscopic traffic simulation that
embraces the real-world challenges and is better aligned with practical needs.

</details>


### [492] [Extracting Overlapping Microservices from Monolithic Code via Deep Semantic Embeddings and Graph Neural Network-Based Soft Clustering](https://arxiv.org/abs/2508.07486)
*Morteza Ziabakhsh,Kiyan Rezaee,Sadegh Eskandari,Seyed Amir Hossein Tabatabaei,Mohammad M. Ghassemi*

Main category: cs.SE

Relevance: 30.0

TL;DR: Mo2oM框架通过软聚类方法将单体应用分解为重叠微服务，结合语义嵌入和结构依赖，显著提升模块化和通信效率。


<details>
  <summary>Details</summary>
Motivation: 解决硬聚类方法在微服务提取中导致的服务间耦合高、内聚性低的问题。

Method: 结合深度语义嵌入和结构依赖，使用图神经网络进行软聚类。

Result: 在四个基准测试中，Mo2oM在模块化、通信开销等方面显著优于基线方法。

Conclusion: Mo2oM提供了一种更灵活的微服务提取方法，显著提升了系统性能。

Abstract: Modern software systems are increasingly shifting from monolithic
architectures to microservices to enhance scalability, maintainability, and
deployment flexibility. Existing microservice extraction methods typically rely
on hard clustering, assigning each software component to a single microservice.
This approach often increases inter-service coupling and reduces intra-service
cohesion. We propose Mo2oM (Monolithic to Overlapping Microservices), a
framework that formulates microservice extraction as a soft clustering problem,
allowing components to belong probabilistically to multiple microservices. This
approach is inspired by expert-driven decompositions, where practitioners
intentionally replicate certain software components across services to reduce
communication overhead. Mo2oM combines deep semantic embeddings with structural
dependencies extracted from methodcall graphs to capture both functional and
architectural relationships. A graph neural network-based soft clustering
algorithm then generates the final set of microservices. We evaluate Mo2oM on
four open-source monolithic benchmarks and compare it against eight
state-of-the-art baselines. Our results demonstrate that Mo2oM achieves
improvements of up to 40.97% in structural modularity (balancing cohesion and
coupling), 58% in inter-service call percentage (communication overhead),
26.16% in interface number (modularity and decoupling), and 38.96% in
non-extreme distribution (service size balance) across all benchmarks.

</details>


### [493] [From Product Hilbert Spaces to the Generalized Koopman Operator and the Nonlinear Fundamental Lemma](https://arxiv.org/abs/2508.07494)
*Mircea Lazar*

Main category: math.OC

Relevance: 30.0

TL;DR: 本文提出了一种基于正交展开的新方法，解决了Koopman算子在控制系统中的推广问题，并推导了非线性基本引理。


<details>
  <summary>Details</summary>
Motivation: 解决Koopman算子在控制系统中的推广和非线性基本引理的推导问题，为非线性系统的数据驱动控制方法提供理论基础。

Method: 通过构造状态和输入可观测函数Hilbert空间的张量积，提出了一种无限维线性算子的新解法，并开发了可扩展的数据驱动方法。

Result: 证明了广义Koopman算子的存在性，并提出了有限维近似计算方法。通过Van der Pol振荡器验证了方法的有效性。

Conclusion: 提出的方法为非线性系统的数据驱动控制提供了新的理论基础和实用工具。

Abstract: The generalization of the Koopman operator to systems with control input and
the derivation of a nonlinear fundamental lemma are two open problems that play
a key role in the development of data-driven control methods for nonlinear
systems. Both problems hinge on the construction of observable or basis
functions and their corresponding Hilbert space that enable an
infinite-dimensional, linear system representation. In this paper we derive a
novel solution to these problems based on orthonormal expansion in a product
Hilbert space constructed as the tensor product between the Hilbert spaces of
the state and input observable functions, respectively. We prove that there
exists an infinite-dimensional linear operator, i.e. the generalized Koopman
operator, from the constructed product Hilbert space to the Hilbert space
corresponding to the lifted state propagated forward in time. A scalable
data-driven method for computing finite-dimensional approximations of
generalized Koopman operators and several choices of observable functions are
also presented. Moreover, we derive a nonlinear fundamental lemma by exploiting
the bilinear structure of the infinite-dimensional generalized Koopman model.
The effectiveness of the developed generalized Koopman embedding is illustrated
on the Van der Pol oscillator.

</details>


### [494] [VA-Blueprint: Uncovering Building Blocks for Visual Analytics System Design](https://arxiv.org/abs/2508.07497)
*Leonardo Ferreira,Gustavo Moreira,Fabio Miranda*

Main category: cs.HC

Relevance: 30.0

TL;DR: 提出VA-Blueprint方法，系统化构建视觉分析系统的知识库，利用LLM自动化扩展知识库，并通过专家访谈和定量分析评估其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉分析系统开发缺乏结构化知识库指导，导致设计开发效率低。

Method: 提出VA-Blueprint方法，系统化分类视觉分析系统核心组件，并利用LLM自动化扩展知识库。

Result: 构建了包含101篇论文的知识库，并通过专家访谈和定量分析验证了方法的有效性。

Conclusion: VA-Blueprint为视觉分析系统开发提供了结构化、可复用的基础。

Abstract: Designing and building visual analytics (VA) systems is a complex, iterative
process that requires the seamless integration of data processing, analytics
capabilities, and visualization techniques. While prior research has
extensively examined the social and collaborative aspects of VA system
authoring, the practical challenges of developing these systems remain
underexplored. As a result, despite the growing number of VA systems, there are
only a few structured knowledge bases to guide their design and development. To
tackle this gap, we propose VA-Blueprint, a methodology and knowledge base that
systematically reviews and categorizes the fundamental building blocks of urban
VA systems, a domain particularly rich and representative due to its intricate
data and unique problem sets. Applying this methodology to an initial set of 20
systems, we identify and organize their core components into a multi-level
structure, forming an initial knowledge base with a structured blueprint for VA
system development. To scale this effort, we leverage a large language model to
automate the extraction of these components for other 81 papers (completing a
corpus of 101 papers), assessing its effectiveness in scaling knowledge base
construction. We evaluate our method through interviews with experts and a
quantitative analysis of annotation metrics. Our contributions provide a deeper
understanding of VA systems' composition and establish a practical foundation
to support more structured, reproducible, and efficient system development.
VA-Blueprint is available at https://urbantk.org/va-blueprint.

</details>


### [495] [RedDino: A foundation model for red blood cell analysis](https://arxiv.org/abs/2508.08180)
*Luca Zedda,Andrea Loddo,Cecilia Di Ruberto,Carsten Marr*

Main category: eess.IV

Relevance: 30.0

TL;DR: RedDino是一个针对红细胞图像分析的自监督基础模型，基于DINOv2框架，在125万张红细胞图像上训练，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在医学诊断中有潜力，但针对红细胞分析的全面AI解决方案仍稀缺。

Method: 采用DINOv2自监督学习框架的RBC特定适配版本，训练于多源RBC图像数据集。

Result: RedDino在红细胞形状分类上表现优于现有模型，具有强特征表示和泛化能力。

Conclusion: RedDino解决了计算血液学中的关键挑战，推动了可靠诊断工具的发展。

Abstract: Red blood cells (RBCs) are essential to human health, and their precise
morphological analysis is important for diagnosing hematological disorders.
Despite the promise of foundation models in medical diagnostics, comprehensive
AI solutions for RBC analysis remain scarce. We present RedDino, a
self-supervised foundation model designed for RBC image analysis. RedDino uses
an RBC-specific adaptation of the DINOv2 self-supervised learning framework and
is trained on a curated dataset of 1.25 million RBC images from diverse
acquisition modalities and sources. Extensive evaluations show that RedDino
outperforms existing state-of-the-art models on RBC shape classification.
Through assessments including linear probing and nearest neighbor
classification, we confirm its strong feature representations and
generalization ability. Our main contributions are: (1) a foundation model
tailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations
for RBC modeling, and (3) a detailed evaluation of generalization performance.
RedDino addresses key challenges in computational hematology by capturing
nuanced morphological features, advancing the development of reliable
diagnostic tools. The source code and pretrained models for RedDino are
available at https://github.com/Snarci/RedDino, and the pretrained models can
be downloaded from our Hugging Face collection at
https://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc

</details>


### [496] [A Small-footprint Acoustic Echo Cancellation Solution for Mobile Full-Duplex Speech Interactions](https://arxiv.org/abs/2508.07561)
*Yiheng Jiang,Tian Biao*

Main category: cs.SD

Relevance: 30.0

TL;DR: 该论文提出了一种基于神经网络的声学回声消除（AEC）方法，适用于移动场景，通过数据增强和渐进学习提升鲁棒性，并引入后处理策略优化下游任务。


<details>
  <summary>Details</summary>
Motivation: 解决移动场景中因硬件差异、非线性失真和高延迟导致的声学回声消除问题。

Method: 结合数据增强和渐进学习，设计小模型支持流式推理，并引入后处理策略优化VAD和ASR任务。

Result: 在回声损失增强和语音质量感知评估上表现优异，同时显著提升VAD和ASR效果。

Conclusion: 该方法在移动设备上实现了高效的声学回声消除，并优化了下游任务性能。

Abstract: In full-duplex speech interaction systems, effective Acoustic Echo
Cancellation (AEC) is crucial for recovering echo-contaminated speech. This
paper presents a neural network-based AEC solution to address challenges in
mobile scenarios with varying hardware, nonlinear distortions and long latency.
We first incorporate diverse data augmentation strategies to enhance the
model's robustness across various environments. Moreover, progressive learning
is employed to incrementally improve AEC effectiveness, resulting in a
considerable improvement in speech quality. To further optimize AEC's
downstream applications, we introduce a novel post-processing strategy
employing tailored parameters designed specifically for tasks such as Voice
Activity Detection (VAD) and Automatic Speech Recognition (ASR), thus enhancing
their overall efficacy. Finally, our method employs a small-footprint model
with streaming inference, enabling seamless deployment on mobile devices.
Empirical results demonstrate effectiveness of the proposed method in Echo
Return Loss Enhancement and Perceptual Evaluation of Speech Quality, alongside
significant improvements in both VAD and ASR results.

</details>


### [497] [Retrieval-Augmented Multi-Agent System for Rapid Statement of Work Generation](https://arxiv.org/abs/2508.07569)
*Amulya Suravarjhula,Rashi Chandrashekhar Agrawal,Sakshi Jayesh Patel,Rahul Gupta*

Main category: cs.MA

Relevance: 30.0

TL;DR: 论文提出了一种基于AI的自动化系统，用于快速、准确起草工作说明书（SOW），通过三个智能代理分别处理起草、法律合规检查和格式化，显著提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统SOW起草过程缓慢、复杂且易出错，需要多人参与和长时间完成，亟需自动化解决方案。

Method: 系统采用三个智能代理：一个负责起草初稿，一个检查法律合规性，一个负责格式化和最终检查。系统能理解内容含义并定制SOW，而非简单填充模板。

Result: 测试显示，系统能在三分钟内完成SOW起草，远快于传统人工方法（数小时或数天），且准确性和质量表现优异。

Conclusion: 该系统展示了AI如何支持法律和商业专业人士，通过自动化常规工作提高效率和可靠性。

Abstract: Drafting a Statement of Work (SOW) is a vital part of business and legal
projects. It outlines key details like deliverables, timelines,
responsibilities, and legal terms. However, creating these documents is often a
slow and complex process. It usually involves multiple people, takes several
days, and leaves room for errors or outdated content. This paper introduces a
new AI-driven automation system that makes the entire SOW drafting process
faster, easier, and more accurate. Instead of relying completely on humans, the
system uses three intelligent components or 'agents' that each handle a part of
the job. One agent writes the first draft, another checks if everything is
legally correct, and the third agent formats the document and ensures
everything is in order. Unlike basic online tools that just fill in templates,
this system understands the meaning behind the content and customizes the SOW
to match the needs of the project. It also checks legal compliance and
formatting so that users can trust the result. The system was tested using real
business examples. It was able to create a full SOW in under three minutes,
compared to several hours or days using manual methods. It also performed well
in accuracy and quality, showing that it can reduce legal risks and save a lot
of time. This solution shows how artificial intelligence can be used to support
legal and business professionals by taking care of routine work and helping
them focus on more important decisions. It's a step toward making legal
processes smarter, faster, and more reliable.

</details>


### [498] [MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer](https://arxiv.org/abs/2508.07817)
*Tao Tang,Chengxu Yang*

Main category: eess.IV

Relevance: 30.0

TL;DR: 本文提出了一种结合多尺度卷积和Transformer架构的医学图像自适应去噪模型（MI-ND），通过噪声感知驱动实现了图像质量的显著提升，并在下游诊断任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 医学图像质量直接影响临床诊断准确性，但常受噪声干扰。本文旨在解决这一问题，提升图像质量和诊断效果。

Method: 提出MI-ND模型，集成多尺度卷积和Transformer架构，引入噪声水平估计器（NLE）和噪声自适应注意力模块（NAAB），实现噪声感知驱动的特征融合。

Result: 在PSNR、SSIM等指标上显著优于对比方法，提升了下游诊断任务的F1分数和ROC-AUC。

Conclusion: MI-ND模型在结构恢复、诊断敏感性和跨模态鲁棒性方面表现突出，为医学图像增强和AI辅助诊疗提供了有效解决方案。

Abstract: The core role of medical images in disease diagnosis makes their quality
directly affect the accuracy of clinical judgment. However, due to factors such
as low-dose scanning, equipment limitations and imaging artifacts, medical
images are often accompanied by non-uniform noise interference, which seriously
affects structure recognition and lesion detection. This paper proposes a
medical image adaptive denoising model (MI-ND) that integrates multi-scale
convolutional and Transformer architecture, introduces a noise level estimator
(NLE) and a noise adaptive attention module (NAAB), and realizes
channel-spatial attention regulation and cross-modal feature fusion driven by
noise perception. Systematic testing is carried out on multimodal public
datasets. Experiments show that this method significantly outperforms the
comparative methods in image quality indicators such as PSNR, SSIM, and LPIPS,
and improves the F1 score and ROC-AUC in downstream diagnostic tasks, showing
strong prac-tical value and promotional potential. The model has outstanding
benefits in structural recovery, diagnostic sensitivity, and cross-modal
robustness, and provides an effective solution for medical image enhancement
and AI-assisted diagnosis and treatment.

</details>


### [499] [CognitiveArm: Enabling Real-Time EEG-Controlled Prosthetic Arm Using Embodied Machine Learning](https://arxiv.org/abs/2508.07731)
*Abdul Basit,Maha Nawaz,Saim Rehman,Muhammad Shafique*

Main category: cs.HC

Relevance: 30.0

TL;DR: CognitiveArm是一个基于EEG的脑控假肢系统，通过优化深度学习模型和嵌入式AI硬件实现实时操作，分类准确率达90%。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限设备上实现实时EEG处理和动作预测的挑战，平衡模型复杂性和计算效率。

Method: 结合BrainFlow库和优化深度学习模型，使用进化搜索确定Pareto最优配置，并应用模型压缩技术（如剪枝和量化）。

Result: 在OpenBCI UltraCortex Mark IV EEG头戴设备上实现90%的动作分类准确率，支持语音命令和多自由度控制。

Conclusion: CognitiveArm展示了在嵌入式硬件上实现高效脑控假肢系统的潜力，适用于日常任务。

Abstract: Efficient control of prosthetic limbs via non-invasive brain-computer
interfaces (BCIs) requires advanced EEG processing, including pre-filtering,
feature extraction, and action prediction, performed in real time on edge AI
hardware. Achieving this on resource-constrained devices presents challenges in
balancing model complexity, computational efficiency, and latency. We present
CognitiveArm, an EEG-driven, brain-controlled prosthetic system implemented on
embedded AI hardware, achieving real-time operation without compromising
accuracy. The system integrates BrainFlow, an open-source library for EEG data
acquisition and streaming, with optimized deep learning (DL) models for precise
brain signal classification. Using evolutionary search, we identify
Pareto-optimal DL configurations through hyperparameter tuning, optimizer
analysis, and window selection, analyzed individually and in ensemble
configurations. We apply model compression techniques such as pruning and
quantization to optimize models for embedded deployment, balancing efficiency
and accuracy. We collected an EEG dataset and designed an annotation pipeline
enabling precise labeling of brain signals corresponding to specific intended
actions, forming the basis for training our optimized DL models. CognitiveArm
also supports voice commands for seamless mode switching, enabling control of
the prosthetic arm's 3 degrees of freedom (DoF). Running entirely on embedded
hardware, it ensures low latency and real-time responsiveness. A full-scale
prototype, interfaced with the OpenBCI UltraCortex Mark IV EEG headset,
achieved up to 90% accuracy in classifying three core actions (left, right,
idle). Voice integration enables multiplexed, variable movement for everyday
tasks (e.g., handshake, cup picking), enhancing real-world performance and
demonstrating CognitiveArm's potential for advanced prosthetic control.

</details>


### [500] [A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases](https://arxiv.org/abs/2508.07742)
*Meghyn Bienvenu,Camille Bourgaux,Katsumi Inoue,Robin Jean*

Main category: cs.LO

Relevance: 30.0

TL;DR: 论文提出了一个基于声明的规则框架，用于指定和计算冲突事实之间的优先级关系，并探讨了如何处理偏好规则中的循环问题。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过优先级关系选择最优修复不一致知识库（KBs）的方法，填补了偏好规则指定方面的空白。

Method: 引入声明性规则框架，利用答案集编程评估偏好规则，应用循环移除技术获取优先级关系，并在优先修复语义下回答查询。

Result: 提出了一个初步实现和实验评估，展示了框架的可行性和有效性。

Conclusion: 该框架为不一致知识库的查询提供了一种端到端的解决方案，特别是在处理优先级关系和循环问题时表现出实用性。

Abstract: Repair-based semantics have been extensively studied as a means of obtaining
meaningful answers to queries posed over inconsistent knowledge bases (KBs).
While several works have considered how to exploit a priority relation between
facts to select optimal repairs, the question of how to specify such
preferences remains largely unaddressed. This motivates us to introduce a
declarative rule-based framework for specifying and computing a priority
relation between conflicting facts. As the expressed preferences may contain
undesirable cycles, we consider the problem of determining when a set of
preference rules always yields an acyclic relation, and we also explore a
pragmatic approach that extracts an acyclic relation by applying various cycle
removal techniques. Towards an end-to-end system for querying inconsistent KBs,
we present a preliminary implementation and experimental evaluation of the
framework, which employs answer set programming to evaluate the preference
rules, apply the desired cycle resolution techniques to obtain a priority
relation, and answer queries under prioritized-repair semantics.

</details>


### [501] [Exploring Strategies for Personalized Radiation Therapy: Part III Identifying genetic determinants for Radiation Response with Meta Learning](https://arxiv.org/abs/2508.08030)
*Hao Peng,Yuanyuan Zhang,Steve Jiang,Robert Timmerman,John Minna*

Main category: physics.med-ph

Relevance: 30.0

TL;DR: 该研究提出了一种元学习框架，用于基于基因表达数据一次性预测癌症的放射敏感性，解决了现有静态模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前癌症放射治疗策略未考虑肿瘤异质性，静态模型（如RSI）假设基因贡献均匀，忽略了表达量和基因互作。

Method: 采用元学习框架，通过微调使每个基因的重要性随样本变化，从而适应肿瘤异质性。

Result: 元学习模型在未见样本上表现出强泛化能力，尤其在放射敏感性变异高的肿瘤亚型中表现优异。

Conclusion: 该方法通过样本特异性适应提高了预测准确性，并为个性化治疗提供了基因影响的上下文模式。

Abstract: Radiation response in cancer is shaped by complex, patient specific biology,
yet current treatment strategies often rely on uniform dose prescriptions
without accounting for tumor heterogeneity. In this study, we introduce a meta
learning framework for one-shot prediction of radiosensitivity measured by SF2
using cell line level gene expression data. Unlike the widely used
Radiosensitivity Index RSI a rank-based linear model trained on a fixed 10-gene
signature, our proposed meta-learned model allows the importance of each gene
to vary by sample through fine tuning. This flexibility addresses key
limitations of static models like RSI, which assume uniform gene contributions
across tumor types and discard expression magnitude and gene gene interactions.
Our results show that meta learning offers robust generalization to unseen
samples and performs well in tumor subgroups with high radiosensitivity
variability, such as adenocarcinoma and large cell carcinoma. By learning
transferable structure across tasks while preserving sample specific
adaptability, our approach enables rapid adaptation to individual samples,
improving predictive accuracy across diverse tumor subtypes while uncovering
context dependent patterns of gene influence that may inform personalized
therapy.

</details>


### [502] [Auditory Intelligence: Understanding the World Through Sound](https://arxiv.org/abs/2508.07829)
*Hyeonuk Nam*

Main category: eess.AS

Relevance: 30.0

TL;DR: 论文提出了一种新的听觉智能框架，强调感知、推理和交互的多层次理解，而非仅表面识别。


<details>
  <summary>Details</summary>
Motivation: 现有听觉智能系统局限于表面识别，缺乏对声音事件背后原因、含义和上下文的理解。

Method: 提出了四种认知启发的任务范式（ASPIRE、SODA、AUX、AUGMENT），分别涵盖时间-频率模式描述、层次化事件/场景描述、因果解释和目标驱动解释。

Result: 这些范式为更通用、可解释且与人类对齐的听觉智能提供了路线图。

Conclusion: 论文旨在推动机器对声音理解的更广泛讨论。

Abstract: Recent progress in auditory intelligence has yielded high-performing systems
for sound event detection (SED), acoustic scene classification (ASC), automated
audio captioning (AAC), and audio question answering (AQA). Yet these tasks
remain largely constrained to surface-level recognition-capturing what happened
but not why, what it implies, or how it unfolds in context. I propose a
conceptual reframing of auditory intelligence as a layered, situated process
that encompasses perception, reasoning, and interaction. To instantiate this
view, I introduce four cognitively inspired task paradigms-ASPIRE, SODA, AUX,
and AUGMENT-those structure auditory understanding across time-frequency
pattern captioning, hierarchical event/scene description, causal explanation,
and goal-driven interpretation, respectively. Together, these paradigms provide
a roadmap toward more generalizable, explainable, and human-aligned auditory
intelligence, and are intended to catalyze a broader discussion of what it
means for machines to understand sound.

</details>


### [503] [Vertex Features for Neural Global Illumination](https://arxiv.org/abs/2508.07852)
*Rui Su,Honghao Dong,Haojie Jin,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

Relevance: 30.0

TL;DR: 提出了一种基于网格顶点的可学习特征表示方法，用于神经渲染任务，显著减少内存占用并保持渲染质量。


<details>
  <summary>Details</summary>
Motivation: 传统特征网格表示在3D场景重建和神经渲染中内存占用高，限制了并行计算的效率。

Method: 将可学习特征直接存储在网格顶点上，利用几何结构作为紧凑表示，减少内存使用。

Result: 内存消耗降至网格表示的五分之一以下，同时保持渲染质量并降低推理开销。

Conclusion: 神经顶点特征是一种高效且紧凑的表示方法，适用于神经渲染任务。

Abstract: Recent research on learnable neural representations has been widely adopted
in the field of 3D scene reconstruction and neural rendering applications.
However, traditional feature grid representations often suffer from substantial
memory footprint, posing a significant bottleneck for modern parallel computing
hardware. In this paper, we present neural vertex features, a generalized
formulation of learnable representation for neural rendering tasks involving
explicit mesh surfaces. Instead of uniformly distributing neural features
throughout 3D space, our method stores learnable features directly at mesh
vertices, leveraging the underlying geometry as a compact and structured
representation for neural processing. This not only optimizes memory
efficiency, but also improves feature representation by aligning compactly with
the surface using task-specific geometric priors. We validate our neural
representation across diverse neural rendering tasks, with a specific emphasis
on neural radiosity. Experimental results demonstrate that our method reduces
memory consumption to only one-fifth (or even less) of grid-based
representations, while maintaining comparable rendering quality and lowering
inference overhead.

</details>


### [504] [Rethinking Self-Replication: Detecting Distributed Selfhood in the Outlier Cellular Automaton](https://arxiv.org/abs/2508.08047)
*Arend Hintze,Clifford Bohm*

Main category: nlin.CG

Relevance: 30.0

TL;DR: 论文证明在细胞自动机中，自复制行为可以自发出现且无需人工干预，并通过因果分析方法验证了多组件协同复制的现象。


<details>
  <summary>Details</summary>
Motivation: 探索细胞自动机中自复制行为的自发性和多组件协同复制的可能性，挑战传统人工生命系统中对个体性和复制的理解。

Method: 基于Outlier规则，开发数据驱动的因果分析框架，重建细胞自动机中模式的完整因果谱系，识别自复制结构。

Result: 发现Outlier CA中的自复制结构不仅自发且稳健，还常由多个独立集群协同完成，挑战传统个体性概念。

Conclusion: 研究为人工生命系统中自复制行为的自发性和复杂性提供了新证据，对理解生命本质有启示意义。

Abstract: Spontaneous self-replication in cellular automata has long been considered
rare, with most known examples requiring careful design or artificial
initialization. In this paper, we present formal, causal evidence that such
replication can emerge unassisted -- and that it can do so in a distributed,
multi-component form. Building on prior work identifying complex dynamics in
the Outlier rule, we introduce a data-driven framework that reconstructs the
full causal ancestry of patterns in a deterministic cellular automaton. This
allows us to rigorously identify self-replicating structures via explicit
causal lineages. Our results show definitively that self-replicators in the
Outlier CA are not only spontaneous and robust, but are also often composed of
multiple disjoint clusters working in coordination, raising questions about
some conventional notions of individuality and replication in artificial life
systems.

</details>


### [505] [Growing Reservoirs with Developmental Graph Cellular Automata](https://arxiv.org/abs/2508.08091)
*Matias Barandiaran,James Stovold*

Main category: cs.NE

Relevance: 30.0

TL;DR: DGCA模型用于生长有向图，训练后可生成用于解决任务的专用结构，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 探索DGCA模型在生长任务驱动和任务无关的储层方面的能力，为功能性和适应性形态发生建模奠定基础。

Method: 使用DGCA模型训练生长储层，目标分为任务驱动（NARMA任务）和任务无关（储层指标）。

Result: DGCA生成的专用结构在基准任务中表现优于传统储层。

Conclusion: DGCA为塑性储层系统和适应性形态发生建模提供了基础。

Abstract: Developmental Graph Cellular Automata (DGCA) are a novel model for
morphogenesis, capable of growing directed graphs from single-node seeds. In
this paper, we show that DGCAs can be trained to grow reservoirs. Reservoirs
are grown with two types of targets: task-driven (using the NARMA family of
tasks) and task-independent (using reservoir metrics).
  Results show that DGCAs are able to grow into a variety of specialized,
life-like structures capable of effectively solving benchmark tasks,
statistically outperforming `typical' reservoirs on the same task. Overall,
these lay the foundation for the development of DGCA systems that produce
plastic reservoirs and for modeling functional, adaptive morphogenesis.

</details>


### [506] [Fitting Description Logic Ontologies to ABox and Query Examples](https://arxiv.org/abs/2508.08007)
*Maurice Funk,Marvin Grosser,Carsten Lutz*

Main category: cs.AI

Relevance: 20.0

TL;DR: 论文研究了一个基于本体介导查询的拟合问题，探讨了在不同查询语言下是否存在满足条件的本体，并分析了其计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决本体介导查询中的拟合问题，即如何找到一个本体，使得在给定正负示例下满足查询条件。

Method: 方法包括使用描述逻辑ALC和ALCI作为本体语言，以及多种查询语言（如AQs、CQs、UCQs），并通过理论分析确定问题的计算复杂度。

Result: 结果表明，对于AQs和完整CQs，问题属于CO-NP复杂度；对于CQs和UCQs，问题为2EXPTIME完全。

Conclusion: 结论是不同查询语言下的拟合问题具有不同的计算复杂度，且结果适用于ALC和ALCI。

Abstract: We study a fitting problem inspired by ontology-mediated querying: given a
collection
  of positive and negative examples of
  the form $(\mathcal{A},q)$ with
  $\mathcal{A}$ an ABox and $q$ a Boolean query, we seek
  an ontology $\mathcal{O}$ that satisfies $\mathcal{A} \cup \mathcal{O} \vDash
q$ for all positive examples and $\mathcal{A} \cup \mathcal{O}\not\vDash q$ for
all negative examples.
  We consider the description logics $\mathcal{ALC}$ and $\mathcal{ALCI}$ as
ontology languages and
  a range of query languages that
  includes atomic queries (AQs), conjunctive queries (CQs), and unions thereof
(UCQs).
  For all of the resulting fitting problems,
  we provide
  effective characterizations and determine the computational complexity
  of deciding whether a fitting ontology exists. This problem turns out to be
${\small CO}NP$ for AQs and full CQs
  and $2E{\small XP}T{\small IME}$-complete for CQs and UCQs.
  These results hold for both $\mathcal{ALC}$ and $\mathcal{ALCI}$.

</details>


### [507] [UPP: Unified Path Planner with Adaptive Safety and Optimality](https://arxiv.org/abs/2505.23197)
*Jatin Kumar Arora,Shubhendu Bhasin*

Main category: cs.RO

Relevance: 20.0

TL;DR: 提出了一种统一路径规划器（UPP），通过改进启发式和动态安全成本函数，平衡安全性与最优性。


<details>
  <summary>Details</summary>
Motivation: 机器人路径规划中，现有算法通常仅关注最优性或安全性，缺乏同时兼顾两者的研究。

Method: 使用改进的启发式和动态安全成本函数，通过可调参数调整安全级别。

Result: 在仿真和TurtleBot实验中验证了UPP的性能，展示了参数变化对结果的影响，并与传统算法进行了对比。

Conclusion: UPP能够有效平衡安全性与最优性，适用于多种场景。

Abstract: We are surrounded by robots helping us perform complex tasks. Robots have a
wide range of applications, from industrial automation to personalized
assistance. However, with great technological innovation come significant
challenges. One of the major challenges in robotics is path planning. Despite
advancements such as graph search, sampling, and potential field methods, most
path planning algorithms focus either on optimality or on safety. Very little
research addresses both simultaneously. We propose a Unified Path Planner (UPP)
that uses modified heuristics and a dynamic safety cost function to balance
safety and optimality. The level of safety can be adjusted via tunable
parameters, trading off against computational complexity. We demonstrate the
planner's performance in simulations, showing how parameter variation affects
results. UPP is compared with various traditional and safe-optimal planning
algorithms across different scenarios. We also validate it on a TurtleBot,
where the robot successfully finds safe and sub-optimal paths.

</details>


### [508] [Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots](https://arxiv.org/abs/2508.06538)
*Gioele Buriani,Jingyue Liu,Maximilian Stölzle,Cosimo Della Santina,Jiatao Ding*

Main category: cs.RO

Relevance: 20.0

TL;DR: 本文提出了一种结合SINDy和物理结构先验的新方法，用于四足机器人跳跃的可解释动态建模，优于传统aSLIP模型。


<details>
  <summary>Details</summary>
Motivation: 四足机器人运动规划需要简化复杂动力学的降阶模型，同时保留关键行为。

Method: 提出了一种结合Sparse Identification of Nonlinear Dynamics (SINDy) 和物理结构先验的学习架构，用于低维潜在空间中建模跳跃动力学。

Result: 新方法在模拟和硬件实验中表现出比传统aSLIP模型更高的准确性。

Conclusion: 该方法为四足机器人跳跃提供了更准确的动态模型，具有实际应用潜力。

Abstract: Reduced-order models are essential for motion planning and control of
quadruped robots, as they simplify complex dynamics while preserving critical
behaviors. This paper introduces a novel methodology for deriving such
interpretable dynamic models, specifically for jumping. We capture the
high-dimensional, nonlinear jumping dynamics in a low-dimensional latent space
by proposing a learning architecture combining Sparse Identification of
Nonlinear Dynamics (SINDy) with physical structural priors on the jump
dynamics. Our approach demonstrates superior accuracy to the traditional
actuated Spring-loaded Inverted Pendulum (aSLIP) model and is validated through
simulation and hardware experiments across different jumping strategies.

</details>


### [509] [Optimizing Districting Plans to Maximize Majority-Minority Districts via IPs and Local Search](https://arxiv.org/abs/2508.07446)
*Daniel Brous,David Shmoys*

Main category: cs.DS

Relevance: 20.0

TL;DR: 论文提出了一种基于整数规划的选区划分方法，优于现有的启发式算法，能生成更多少数族裔占多数的选区。


<details>
  <summary>Details</summary>
Motivation: 在选区划分诉讼中，需要提供比当前提案更多少数族裔占多数的选区方案。现有启发式算法（如短脉冲法）效果有限，因此提出更优的整数规划方法。

Method: 基于整数规划和列生成算法，结合随机分层分区算法，设计新的局部优化算法以提高选区方案的公平性和紧凑性。

Result: 新方法在多个数据集上表现优于短脉冲法，能生成更多少数族裔占多数的选区，同时保持选区紧凑性。

Conclusion: 整数规划方法在选区划分中更有效，为法律诉讼提供了更优的工具。

Abstract: In redistricting litigation, effective enforcement of the Voting Rights Act
has often involved providing the court with districting plans that display a
larger number of majority-minority districts than the current proposal (as was
true, for example, in what followed Allen v. Milligan concerning the
congressional districting plan for Alabama in 2023). Recent work by Cannon et
al. proposed a heuristic algorithm for generating plans to optimize
majority-minority districts, which they called short bursts; that algorithm
relies on a sophisticated random walk over the space of all plans,
transitioning in bursts, where the initial plan for each burst is the most
successful plan from the previous burst. We propose a method based on integer
programming, where we build upon another previous work, the stochastic
hierarchical partitioning algorithm, which heuristically generates a robust set
of potential districts (viewed as columns in a standard set partitioning
formulation); that approach was designed to optimize a different notion of
fairness across a statewide plan. We design a new column generation algorithm
to find plans via integer programming that outperforms short bursts on multiple
data sets in generating statewide plans with significantly more
majority-minority districts. These results also rely on a new local
re-optimization algorithm to iteratively improve on any baseline solution, as
well as an algorithm to increase the compactness of districts in plans
generated (without impacting the number of majority-minority districts).

</details>


### [510] [Grasp-HGN: Grasping the Unexpected](https://arxiv.org/abs/2508.07648)
*Mehrshad Zandigohar,Mallesham Dasari,Gunar Schirner*

Main category: cs.RO

Relevance: 20.0

TL;DR: 论文提出Grasp-LLaVA和HGN，解决假肢手抓取模型在未见物体上表现差的问题，提升泛化能力和实时性。


<details>
  <summary>Details</summary>
Motivation: 现有抓取模型在未见物体上表现不佳，影响假肢用户的独立性和生活质量。

Method: 1. 提出Grasp-LLaVA，利用视觉语言模型进行推理；2. 设计HGN，结合边缘和云端计算优化性能与延迟。

Result: Grasp-LLaVA在未见物体上准确率50.2%，HGN进一步提升至42.3%，速度提升3.5倍。

Conclusion: Grasp-LLaVA和HGN显著提升假肢手抓取模型的泛化能力和实时性。

Abstract: For transradial amputees, robotic prosthetic hands promise to regain the
capability to perform daily living activities. To advance next-generation
prosthetic hand control design, it is crucial to address current shortcomings
in robustness to out of lab artifacts, and generalizability to new
environments. Due to the fixed number of object to interact with in existing
datasets, contrasted with the virtually infinite variety of objects encountered
in the real world, current grasp models perform poorly on unseen objects,
negatively affecting users' independence and quality of life.
  To address this: (i) we define semantic projection, the ability of a model to
generalize to unseen object types and show that conventional models like YOLO,
despite 80% training accuracy, drop to 15% on unseen objects. (ii) we propose
Grasp-LLaVA, a Grasp Vision Language Model enabling human-like reasoning to
infer the suitable grasp type estimate based on the object's physical
characteristics resulting in a significant 50.2% accuracy over unseen object
types compared to 36.7% accuracy of an SOTA grasp estimation model.
  Lastly, to bridge the performance-latency gap, we propose Hybrid Grasp
Network (HGN), an edge-cloud deployment infrastructure enabling fast grasp
estimation on edge and accurate cloud inference as a fail-safe, effectively
expanding the latency vs. accuracy Pareto. HGN with confidence calibration (DC)
enables dynamic switching between edge and cloud models, improving semantic
projection accuracy by 5.6% (to 42.3%) with 3.5x speedup over the unseen object
types. Over a real-world sample mix, it reaches 86% average accuracy (12.2%
gain over edge-only), and 2.2x faster inference than Grasp-LLaVA alone.

</details>


### [511] [PCA-Guided Autoencoding for Structured Dimensionality Reduction in Active Infrared Thermography](https://arxiv.org/abs/2508.07773)
*Mohammed Salah,Numan Saeed,Davor Svetinovic,Stefano Sfarra,Mohammed Omar,Yusra Abdulrahman*

Main category: eess.IV

Relevance: 20.0

TL;DR: 提出了一种基于PCA引导的自编码框架，用于结构化降维，以改进红外热成像数据的缺陷表征。


<details>
  <summary>Details</summary>
Motivation: 现有非线形自编码器在红外热成像数据降维中缺乏结构化潜在空间，限制了缺陷表征效果。

Method: 引入PCA蒸馏损失函数，引导自编码器在降维时对齐结构化PCA成分，同时捕捉非线性特征。

Result: 在PVC、CFRP和PLA样本上，PCA引导的自编码器在对比度、信噪比和神经网络指标上优于现有方法。

Conclusion: PCA引导的自编码框架有效提升了红外热成像数据的结构化降维和缺陷表征能力。

Abstract: Active Infrared thermography (AIRT) is a widely adopted non-destructive
testing (NDT) technique for detecting subsurface anomalies in industrial
components. Due to the high dimensionality of AIRT data, current approaches
employ non-linear autoencoders (AEs) for dimensionality reduction. However, the
latent space learned by AIRT AEs lacks structure, limiting their effectiveness
in downstream defect characterization tasks. To address this limitation, this
paper proposes a principal component analysis guided (PCA-guided) autoencoding
framework for structured dimensionality reduction to capture intricate,
non-linear features in thermographic signals while enforcing a structured
latent space. A novel loss function, PCA distillation loss, is introduced to
guide AIRT AEs to align the latent representation with structured PCA
components while capturing the intricate, non-linear patterns in thermographic
signals. To evaluate the utility of the learned, structured latent space, we
propose a neural network-based evaluation metric that assesses its suitability
for defect characterization. Experimental results show that the proposed
PCA-guided AE outperforms state-of-the-art dimensionality reduction methods on
PVC, CFRP, and PLA samples in terms of contrast, signal-to-noise ratio (SNR),
and neural network-based metrics.

</details>


### [512] [Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization](https://arxiv.org/abs/2508.07628)
*Daniel Essien,Suresh Neethirajan*

Main category: cs.AI

Relevance: 10.0

TL;DR: 论文探讨了利用多模态AI技术改进家禽福利监测，提出了一种中间融合策略和两个新评估工具（DTS和DRI），并设计了一个模块化部署框架。


<details>
  <summary>Details</summary>
Motivation: 传统家禽福利监测依赖主观人工观察和单传感器数据，无法全面捕捉现代农场中复杂的福利动态，多模态AI提供了突破性解决方案。

Method: 采用中间融合策略整合视觉、声学、环境和生理数据，并引入DTS和DRI评估工具，提出模块化部署框架。

Result: 中间融合策略在鲁棒性和性能上表现最佳，新工具和框架提升了模型适应性和数据可靠性。

Conclusion: 多模态AI为家禽福利监测提供了从被动到主动的转变基础，结合了生产效率和科学伦理。

Abstract: The future of poultry production depends on a paradigm shift replacing
subjective, labor-intensive welfare checks with data-driven, intelligent
monitoring ecosystems. Traditional welfare assessments-limited by human
observation and single-sensor data-cannot fully capture the complex,
multidimensional nature of laying hen welfare in modern farms. Multimodal
Artificial Intelligence (AI) offers a breakthrough, integrating visual,
acoustic, environmental, and physiological data streams to reveal deeper
insights into avian welfare dynamics. This investigation highlights multimodal
As transformative potential, showing that intermediate (feature-level) fusion
strategies achieve the best balance between robustness and performance under
real-world poultry conditions, and offer greater scalability than early or late
fusion approaches. Key adoption barriers include sensor fragility in harsh farm
environments, high deployment costs, inconsistent behavioral definitions, and
limited cross-farm generalizability. To address these, we introduce two novel
evaluation tools - the Domain Transfer Score (DTS) to measure model
adaptability across diverse farm settings, and the Data Reliability Index (DRI)
to assess sensor data quality under operational constraints. We also propose a
modular, context-aware deployment framework designed for laying hen
environments, enabling scalable and practical integration of multimodal
sensing. This work lays the foundation for a transition from reactive, unimodal
monitoring to proactive, precision-driven welfare systems that unite
productivity with ethical, science based animal care.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [513] [PROPS: Progressively Private Self-alignment of Large Language Models](https://arxiv.org/abs/2508.06783)
*Noel Teku,Fengwei Tian,Payel Bhattacharjee,Souradip Chakraborty,Amrit Singh Bedi,Ravi Tandon*

Main category: cs.LG

Relevance: 90.0

TL;DR: 论文提出PROPS框架，用于在LLM对齐中实现偏好级隐私保护，通过多阶段自对齐提升模型效用，同时保障隐私。


<details>
  <summary>Details</summary>
Motivation: 依赖人类反馈的LLM对齐可能泄露标注者的隐私，现有方法（如DP-SGD）虽提供隐私保障但可能过度牺牲模型效用。

Method: 提出PROPS框架，通过多阶段自对齐，利用前一阶段的私有模型为后续阶段提供标注数据。

Result: 在相同隐私预算下，PROPS的胜率比DP-SGD高3倍，比基于随机响应的对齐高2.5倍。

Conclusion: PROPS在隐私保护和模型效用之间取得了更好平衡，适用于LLM对齐任务。

Abstract: Alignment is a key step in developing Large Language Models (LLMs) using
human feedback to ensure adherence to human values and societal norms.
Dependence on human feedback raises privacy concerns about how much a labeler's
preferences may reveal about their personal values, beliefs, and personality
traits. Existing approaches, such as Differentially Private SGD (DP-SGD),
provide rigorous privacy guarantees by privatizing gradients during fine-tuning
and alignment but can provide more privacy than necessary as human preferences
are tied only to labels of (prompt, response) pairs and can degrade model
utility. This work focuses on LLM alignment with preference-level privacy,
which preserves the privacy of preference labels provided by humans. We propose
PROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving
alignment framework where privately aligned models in previous stages can serve
as labelers for supplementing training data in the subsequent stages of
alignment. We present theoretical guarantees for PROPS as well as comprehensive
validation using multiple models (Pythia and GPT) and datasets (AlpacaEval,
Anthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over
existing methods while still providing high privacy. For the same privacy
budget, alignment via PROPS can achieve up to 3x higher win-rates compared to
DP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based
alignment.

</details>


### [514] [AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance](https://arxiv.org/abs/2508.06944)
*Lixuan He,Jie Feng,Yong Li*

Main category: cs.LG

Relevance: 90.0

TL;DR: 论文提出了一种名为AMFT的单阶段算法，通过隐式奖励理论动态平衡监督微调（SFT）和强化学习（RL），解决了传统两阶段方法的灾难性遗忘和探索-模仿权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统两阶段微调方法（SFT+RL）存在灾难性遗忘和探索-模仿权衡问题，而现有单阶段方法缺乏动态平衡机制。

Method: 提出了AMFT算法，通过元梯度自适应权重控制器动态优化SFT和RL的平衡，并结合策略熵正则化以提高稳定性。

Result: 在数学推理、抽象视觉推理和视觉语言导航等任务上，AMFT均达到新SOTA，并表现出更强的泛化能力。

Conclusion: AMFT提供了一种更原则化且有效的LLM对齐范式，其元学习控制器对稳定性、样本效率和性能至关重要。

Abstract: Large Language Models (LLMs) are typically fine-tuned for reasoning tasks
through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by
Reinforcement Learning (RL), a process fraught with catastrophic forgetting and
suboptimal trade-offs between imitation and exploration. Recent single-stage
methods attempt to unify SFT and RL using heuristics, but lack a principled
mechanism for dynamically balancing the two paradigms. In this paper, we
reframe this challenge through the theoretical lens of \textbf{implicit
rewards}, viewing SFT and RL not as distinct methods but as complementary
reward signals. We introduce \textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel
single-stage algorithm that learns the optimal balance between SFT's implicit,
path-level reward and RL's explicit, outcome-based reward. The core of AMFT is
a \textbf{meta-gradient adaptive weight controller} that treats the SFT-RL
balance as a learnable parameter, dynamically optimizing it to maximize
long-term task performance. This forward-looking approach, regularized by
policy entropy for stability, autonomously discovers an effective training
curriculum. We conduct a comprehensive evaluation on challenging benchmarks
spanning mathematical reasoning, abstract visual reasoning (General Points),
and vision-language navigation (V-IRL). AMFT consistently establishes a new
state-of-the-art and demonstrats superior generalization on out-of-distribution
(OOD) tasks. Ablation studies and training dynamic analysis confirm that the
meta-learning controller is crucial for AMFT's stability, sample efficiency,
and performance, offering a more principled and effective paradigm for LLM
alignment.Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.

</details>


### [515] [Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation](https://arxiv.org/abs/2508.07075)
*Stanley Ngugi*

Main category: cs.LG

Relevance: 90.0

TL;DR: 论文提出了一种基于参数高效微调（PEFT）技术的“先遗忘后学习”策略，用于解决LLMs动态知识更新中的冲突问题，显著提高了新知识的准确性和旧知识的遗忘率。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在动态知识更新中因新旧知识冲突导致的抵抗新知识和灾难性遗忘问题。

Method: 采用两阶段策略：1）通过电路定位阶段识别冲突知识的内部组件；2）利用Infused Adapter（$IA^3$）进行参数高效微调。

Result: 实验显示，该方法在微软Phi-3模型上实现了98.50%的新知识准确率和96.00%的旧知识遗忘率，同时显著减轻了灾难性遗忘。

Conclusion: 该方法为紧凑型LLMs提供了精确、局部化和安全的知识管理方案。

Abstract: Large Language Models (LLMs) struggle with dynamic knowledge updates,
especially when new information conflicts with deeply embedded facts. Such
conflicting factual edits often lead to two critical issues: resistance to
adopting the new fact and severe catastrophic forgetting of unrelated
knowledge. This paper introduces and evaluates a novel "unlearn-then-learn"
strategy for precise knowledge editing in LLMs, leveraging the
parameter-efficient fine-tuning (PEFT) technique, Infused Adapter by Inhibiting
and Amplifying Inner Activations ($IA^3$). Crucially, this two-stage approach
is powered by an initial circuit localization phase that identifies and targets
the specific internal components responsible for encoding the conflicting fact.
Through a rigorous experimental methodology on
microsoft/Phi-3-mini-4k-instruct, we demonstrate that this mechanistically
informed two-stage approach achieves near-perfect accuracy (98.50%) for the
new, modulated fact while simultaneously effectively suppressing the original
conflicting fact (96.00% forget rate). Critically, our strategy exhibits
unprecedented localization (72.00% F_control accuracy), dramatically mitigating
catastrophic forgetting observed in direct fine-tuning approaches (which showed
as low as ~20% F_control accuracy), a direct benefit of our targeted
interpretability-guided intervention. Furthermore, qualitative analysis reveals
a nuanced mechanism of "soft forgetting," where original knowledge is
suppressed from default retrieval but remains latent and conditionally
accessible, enhancing model safety and control. These findings represent a
significant advancement towards precise, localized, and safe knowledge
management in compact LLMs.

</details>


### [516] [Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning](https://arxiv.org/abs/2508.07126)
*Zhengran Ji,Boyuan Chen*

Main category: cs.LG

Relevance: 90.0

TL;DR: Pref-GUIDE框架将实时标量反馈转化为偏好数据，提升在线强化学习中的奖励模型学习效果。


<details>
  <summary>Details</summary>
Motivation: 在在线学习场景中，标量反馈通常噪声大且不一致，限制了奖励模型的准确性和泛化能力。

Method: Pref-GUIDE通过短窗口内比较行为并过滤模糊反馈（Individual），以及聚合用户群体的奖励模型形成共识偏好（Voting）。

Result: 在三个挑战性环境中，Pref-GUIDE显著优于标量反馈基线，Voting变体甚至超过专家设计的密集奖励。

Conclusion: Pref-GUIDE通过将标量反馈重构为结构化偏好，为在线强化学习中利用人类输入提供了可扩展且原则性的方法。

Abstract: Training reinforcement learning agents with human feedback is crucial when
task objectives are difficult to specify through dense reward functions. While
prior methods rely on offline trajectory comparisons to elicit human
preferences, such data is unavailable in online learning scenarios where agents
must adapt on the fly. Recent approaches address this by collecting real-time
scalar feedback to guide agent behavior and train reward models for continued
learning after human feedback becomes unavailable. However, scalar feedback is
often noisy and inconsistent, limiting the accuracy and generalization of
learned rewards. We propose Pref-GUIDE, a framework that transforms real-time
scalar feedback into preference-based data to improve reward model learning for
continual policy training. Pref-GUIDE Individual mitigates temporal
inconsistency by comparing agent behaviors within short windows and filtering
ambiguous feedback. Pref-GUIDE Voting further enhances robustness by
aggregating reward models across a population of users to form consensus
preferences. Across three challenging environments, Pref-GUIDE significantly
outperforms scalar-feedback baselines, with the voting variant exceeding even
expert-designed dense rewards. By reframing scalar feedback as structured
preferences with population feedback, Pref-GUIDE offers a scalable and
principled approach for harnessing human input in online reinforcement
learning.

</details>


### [517] [A Stable and Principled Loss Function for Direct Language Model Alignment](https://arxiv.org/abs/2508.07137)
*Yuandong Tan*

Main category: cs.LG

Relevance: 90.0

TL;DR: 论文提出了一种新的损失函数，用于改进RLHF中的DPO方法，解决了其理论不一致性和训练不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: DPO方法在RLHF中存在理论不一致性，可能导致训练不稳定和奖励攻击。本文旨在提出一种更稳定的损失函数。

Method: 从RLHF最优性条件直接推导出新的损失函数，目标是设定有限的logits差值，而非最大化。

Result: 新方法在Qwen2.5-7B模型上显著优于标准DPO基线，性能接近Llama-3.1-8B。

Conclusion: 提出的损失函数更稳定且有效，避免了DPO的问题，提升了模型对齐效果。

Abstract: The alignment of large language models (LLMs) with human preferences is
commonly achieved through Reinforcement Learning from Human Feedback (RLHF).
Direct Preference Optimization (DPO) simplified this paradigm by establishing a
direct mapping between the optimal policy and a reward function, eliminating
the need for an explicit reward model. However, we argue that the DPO loss
function is theoretically misaligned with its own derivation, as it promotes
the indefinite maximization of a logits difference, which can lead to training
instability and reward hacking. In this paper, we propose a novel loss function
derived directly from the RLHF optimality condition. Our proposed loss targets
a specific, finite value for the logits difference, which is dictated by the
underlying reward, rather than its maximization. We provide a theoretical
analysis, including a gradient-based comparison, to demonstrate that our method
avoids the large gradients that plague DPO when the probability of dispreferred
responses approaches zero. This inherent stability prevents reward hacking and
leads to more effective alignment. We validate our approach by fine-tuning a
Qwen2.5-7B model, showing significant win-rate improvements over a standard DPO
baseline and achieving competitive performance against larger models like
Llama-3.1-8B.

</details>


### [518] [Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals](https://arxiv.org/abs/2508.07638)
*Jia Zhang,Yao Liu,Chen-Xi Zhang,Yi Liu,Yi-Xuan Jin,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.LG

Relevance: 90.0

TL;DR: 论文提出了一种名为DMPO的方法，通过量化偏好冲突（PD项）并选择高共识数据子集，优化LLM对齐效果，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如DPO）在处理细粒度偏好数据时面临噪声和冲突问题，需要更高效的数据选择策略。

Method: 提出DMPO目标，利用PD项量化冲突，设计数据选择原则，选择高共识数据子集进行训练。

Result: 在UltraFeedback数据集上，DMPO相对标准方法提升10%以上，同时提高训练效率。

Conclusion: DMPO通过数据选择策略有效解决了偏好冲突问题，为LLM对齐提供了新思路。

Abstract: Aligning Large Language Models (LLMs) with diverse human values requires
moving beyond a single holistic "better-than" preference criterion. While
collecting fine-grained, aspect-specific preference data is more reliable and
scalable, existing methods like Direct Preference Optimization (DPO) struggle
with the severe noise and conflicts inherent in such aggregated datasets. In
this paper, we tackle this challenge from a data-centric perspective. We first
derive the Direct Multi-Preference Optimization (DMPO) objective, and uncover a
key Preference Divergence (PD) term that quantifies inter-aspect preference
conflicts. Instead of using this term for direct optimization, we leverage it
to formulate a novel, theoretically-grounded data selection principle. Our
principle advocates for selecting a subset of high-consensus data-identified by
the most negative PD values-for efficient DPO training. We prove the optimality
of this strategy by analyzing the loss bounds of the DMPO objective in the
selection problem. To operationalize our approach, we introduce practical
methods of PD term estimation and length bias mitigation, thereby proposing our
PD selection method. Evaluation on the UltraFeedback dataset with three varying
conflict levels shows that our simple yet effective strategy achieves over 10%
relative improvement against both the standard holistic preference and a
stronger oracle using aggregated preference signals, all while boosting
training efficiency and obviating the need for intractable holistic preference
annotating, unlocking the potential of robust LLM alignment via fine-grained
preference signals.

</details>


### [519] [Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment](https://arxiv.org/abs/2508.07750)
*Haowen Wang,Yun Yue,Zhiling Ye,Shuowen Zhang,Lei Fan,Jiaxin Liang,Jiadi Jiang,Cheng Wei,Jingyuan Deng,Xudong Han,Ji Li,Chunxiao Guo,Peng Wei,Jian Wang,Jinjie Gu*

Main category: cs.LG

Relevance: 90.0

TL;DR: 提出了一种名为GRAO的统一框架，结合了SFT和RL的优势，通过多样本生成、组内相对优势加权和参考感知参数更新，显著提升了语言模型的对齐能力。


<details>
  <summary>Details</summary>
Motivation: 解决SFT和RL在语言模型对齐中的局限性，SFT受限于离线策略轨迹，而RL样本效率低且依赖高质量基础模型。

Method: GRAO框架结合SFT和RL，采用多样本生成策略、组内相对优势加权和参考感知参数更新。

Result: 在复杂人类对齐任务中，GRAO比SFT、DPO、PPO和GRPO基线分别提升了57.70%、17.65%、7.95%和5.18%。

Conclusion: GRAO提供了一个理论支持的对齐框架，并实证了语言模型能力的高效进化。

Abstract: Alignment methodologies have emerged as a critical pathway for enhancing
language model alignment capabilities. While SFT (supervised fine-tuning)
accelerates convergence through direct token-level loss intervention, its
efficacy is constrained by offline policy trajectory. In contrast,
RL(reinforcement learning) facilitates exploratory policy optimization, but
suffers from low sample efficiency and stringent dependency on high-quality
base models. To address these dual challenges, we propose GRAO (Group Relative
Alignment Optimization), a unified framework that synergizes the respective
strengths of SFT and RL through three key innovations: 1) A multi-sample
generation strategy enabling comparative quality assessment via reward
feedback; 2) A novel Group Direct Alignment Loss formulation leveraging
intra-group relative advantage weighting; 3) Reference-aware parameter updates
guided by pairwise preference dynamics. Our theoretical analysis establishes
GRAO's convergence guarantees and sample efficiency advantages over
conventional approaches. Comprehensive evaluations across complex human
alignment tasks demonstrate GRAO's superior performance, achieving
57.70\%,17.65\% 7.95\% and 5.18\% relative improvements over SFT, DPO, PPO and
GRPO baselines respectively. This work provides both a theoretically grounded
alignment framework and empirical evidence for efficient capability evolution
in language models.

</details>


### [520] [Pareto Multi-Objective Alignment for Language Models](https://arxiv.org/abs/2508.07768)
*Qiang He,Setareh Maghsudi*

Main category: cs.LG

Relevance: 90.0

TL;DR: 论文提出PAMA算法，解决LLM多目标对齐问题，显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前RLHF方法仅优化单一奖励函数，无法满足复杂多样的人类偏好需求，限制了LLM的实用性。

Method: 提出PAMA算法，将多目标RLHF转化为凸优化问题，提供闭式解，复杂度从O(n^2*d)降至O(n)。

Result: 实验证明PAMA在125M至7B参数模型上高效实现多目标对齐，理论保证收敛到Pareto稳定点。

Conclusion: PAMA为多目标对齐提供了高效且理论可靠的方法，推动LLM在现实中的灵活应用。

Abstract: Large language models (LLMs) are increasingly deployed in real-world
applications that require careful balancing of multiple, often conflicting,
objectives, such as informativeness versus conciseness, or helpfulness versus
creativity. However, current alignment methods, primarily based on RLHF,
optimize LLMs toward a single reward function, resulting in rigid behavior that
fails to capture the complexity and diversity of human preferences. This
limitation hinders the adaptability of LLMs to practical scenarios, making
multi-objective alignment (MOA) a critical yet underexplored area. To bridge
this gap, we propose Pareto Multi-Objective Alignment (PAMA), a principled and
computationally efficient algorithm designed explicitly for MOA in LLMs. In
contrast to computationally prohibitive multi-objective optimization (MOO)
methods, PAMA transforms multi-objective RLHF into a convex optimization with a
closed-form solution, significantly enhancing scalability. Traditional MOO
approaches suffer from prohibitive O(n^2*d) complexity, where d represents the
number of model parameters, typically in the billions for LLMs, rendering
direct optimization infeasible. PAMA reduces this complexity to O(n) where n is
the number of objectives, enabling optimization to be completed within
milliseconds. We provide theoretical guarantees that PAMA converges to a Pareto
stationary point, where no objective can be improved without degrading at least
one other. Extensive experiments across language models ranging from 125M to 7B
parameters demonstrate PAMA's robust and effective MOA capabilities, aligning
with its theoretical advantages. PAMA provides a highly efficient solution to
the MOA problem that was previously considered intractable, offering a
practical and theoretically grounded approach to aligning LLMs with diverse
human values, paving the way for versatile and adaptable real-world AI
deployments.

</details>


### [521] [EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning](https://arxiv.org/abs/2508.07809)
*Huanyu Liu,Jia Li,Chang Yu,Taozhi Chen,Yihong Dong,Lecheng Wang,Hu XiaoLong,Ge Li*

Main category: cs.LG

Relevance: 90.0

TL;DR: EvoCoT提出了一种基于两阶段思维链推理优化的自进化课程学习框架，用于解决强化学习中奖励稀疏的问题，提升LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在硬问题上因奖励稀疏导致的学习效率低和探索瓶颈问题。

Method: 通过自生成和验证思维链轨迹，逐步缩短轨迹以扩展探索空间，实现稳定学习。

Result: EvoCoT使LLM能够解决之前未解决的问题，提升推理能力，且无需外部思维链监督。

Conclusion: EvoCoT是一种可扩展且兼容多种RL微调方法的高效框架。

Abstract: Reinforcement learning with verifiable reward (RLVR) has become a promising
paradigm for post-training large language models (LLMs) to improve their
reasoning capability. However, when the rollout accuracy is low on hard
problems, the reward becomes sparse, limiting learning efficiency and causing
exploration bottlenecks. Existing approaches either rely on stronger LLMs for
distillation or filter out difficult problems, which limits scalability or
restricts reasoning improvement through exploration.
  We propose EvoCoT, a self-evolving curriculum learning framework based on
two-stage chain-of-thought (CoT) reasoning optimization. EvoCoT constrains the
exploration space by self-generating and verifying CoT trajectories, then
gradually shortens them to expand the space in a controlled way. This enables
LLMs to stably learn from initially unsolved hard problems under sparse
rewards. We apply EvoCoT to multiple LLM families, including Qwen, DeepSeek,
and Llama. Experiments show that EvoCoT enables LLMs to solve previously
unsolved problems, improves reasoning capability without external CoT
supervision, and is compatible with various RL fine-tuning methods. We release
the source code to support future research.

</details>


### [522] [WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer](https://arxiv.org/abs/2508.07970)
*Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao*

Main category: cs.LG

Relevance: 90.0

TL;DR: WeChat-YATT是一个简单、可扩展且平衡的RLHF训练框架，解决了现有框架在复杂多模态工作流和动态负载下的控制器可扩展性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF训练框架在复杂多模态工作流和动态负载下存在控制器可扩展性和效率的挑战。

Method: 提出WeChat-YATT框架，采用并行控制器编程模型和动态资源分配策略。

Result: WeChat-YATT在吞吐量上显著优于现有RLHF框架，并已成功应用于微信产品。

Conclusion: WeChat-YATT有效解决了RLHF训练中的可扩展性和效率问题，适用于实际应用。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent
paradigm for training large language models and multimodal systems. Despite
notable advances enabled by existing RLHF training frameworks, significant
challenges remain in scaling to complex multimodal workflows and adapting to
dynamic workloads. In particular, current systems often encounter limitations
related to controller scalability when managing large models, as well as
inefficiencies in orchestrating intricate RLHF pipelines, especially in
scenarios that require dynamic sampling and resource allocation. In this paper,
we introduce WeChat-YATT (Yet Another Transformer Trainer in WeChat), a simple,
scalable, and balanced RLHF training framework specifically designed to address
these challenges. WeChat-YATT features a parallel controller programming model
that enables flexible and efficient orchestration of complex RLHF workflows,
effectively mitigating the bottlenecks associated with centralized controller
architectures and facilitating scalability in large-scale data scenarios. In
addition, we propose a dynamic placement schema that adaptively partitions
computational resources and schedules workloads, thereby significantly reducing
hardware idle time and improving GPU utilization under variable training
conditions. We evaluate WeChat-YATT across a range of experimental scenarios,
demonstrating that it achieves substantial improvements in throughput compared
to state-of-the-art RLHF training frameworks. Furthermore, WeChat-YATT has been
successfully deployed to train models supporting WeChat product features for a
large-scale user base, underscoring its effectiveness and robustness in
real-world applications.

</details>


### [523] [Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning](https://arxiv.org/abs/2508.08221)
*Zihe Liu,Jiashun Liu,Yancheng He,Weixun Wang,Jiaheng Liu,Ling Pan,Xinyu Hu,Shaopan Xiong,Ju Huang,Jian Hu,Shengyi Huang,Siran Yang,Jiamang Wang,Wenbo Su,Bo Zheng*

Main category: cs.LG

Relevance: 90.0

TL;DR: 本文系统综述了LLM推理中的强化学习技术，通过统一框架下的实验分析，提出了技术选择指南，并发现了一种简单组合方法能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前RL在LLM推理中的应用缺乏标准化指南，实验设置和数据不一致导致结论冲突，亟需系统性研究。

Method: 通过统一框架下的严格复现和孤立评估，分析不同RL技术的机制、适用场景和核心原则。

Result: 发现一种简单组合方法（基于PPO损失的无评论策略）能超越现有策略（如GRPO和DAPO）。

Conclusion: 提供了RL技术选择的清晰指南和可靠路线图，为LLM领域的RL应用提供了实用指导。

Abstract: Reinforcement learning for LLM reasoning has rapidly emerged as a prominent
research area, marked by a significant surge in related studies on both
algorithmic innovations and practical applications. Despite this progress,
several critical challenges remain, including the absence of standardized
guidelines for employing RL techniques and a fragmented understanding of their
underlying mechanisms. Additionally, inconsistent experimental settings,
variations in training data, and differences in model initialization have led
to conflicting conclusions, obscuring the key characteristics of these
techniques and creating confusion among practitioners when selecting
appropriate techniques. This paper systematically reviews widely adopted RL
techniques through rigorous reproductions and isolated evaluations within a
unified open-source framework. We analyze the internal mechanisms, applicable
scenarios, and core principles of each technique through fine-grained
experiments, including datasets of varying difficulty, model sizes, and
architectures. Based on these insights, we present clear guidelines for
selecting RL techniques tailored to specific setups, and provide a reliable
roadmap for practitioners navigating the RL for the LLM domain. Finally, we
reveal that a minimalist combination of two techniques can unlock the learning
capability of critic-free policies using vanilla PPO loss. The results
demonstrate that our simple combination consistently improves performance,
surpassing strategies like GRPO and DAPO.

</details>


### [524] [Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs](https://arxiv.org/abs/2508.06601)
*Kyle O'Brien,Stephen Casper,Quentin Anthony,Tomek Korbak,Robert Kirk,Xander Davies,Ishan Mishra,Geoffrey Irving,Yarin Gal,Stella Biderman*

Main category: cs.LG

Relevance: 85.0

TL;DR: 研究探讨通过过滤训练数据中的双用途主题文本，防止开放权重AI模型被篡改攻击，提出一种多阶段数据过滤方法，显著提升模型对抗攻击的能力。


<details>
  <summary>Details</summary>
Motivation: 开放权重AI系统虽具透明性和开放性，但易受篡改攻击，现有安全微调方法难以抵御。研究旨在探索数据过滤是否可作为更有效的防篡改手段。

Method: 提出多阶段数据过滤管道，预训练多个6.9B参数模型，测试其对10,000步和3亿令牌生物威胁文本的抵抗能力。

Result: 过滤模型显著优于现有基线，抵抗能力提升一个数量级，且不影响无关能力。但模型仍可通过上下文利用危险信息。

Conclusion: 预训练数据筛选是开放权重AI系统的有效防御层，但需结合多层次防御策略。

Abstract: Open-weight AI systems offer unique benefits, including enhanced
transparency, open research, and decentralized access. However, they are
vulnerable to tampering attacks which can efficiently elicit harmful behaviors
by modifying weights or activations. Currently, there is not yet a robust
science of open-weight model risk management. Existing safety fine-tuning
methods and other post-training techniques have struggled to make LLMs
resistant to more than a few dozen steps of adversarial fine-tuning. In this
paper, we investigate whether filtering text about dual-use topics from
training data can prevent unwanted capabilities and serve as a more
tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable
data filtering and show that it offers a tractable and effective method for
minimizing biothreat proxy knowledge in LLMs. We pretrain multiple
6.9B-parameter models from scratch and find that they exhibit substantial
resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M
tokens of biothreat-related text -- outperforming existing post-training
baselines by over an order of magnitude -- with no observed degradation to
unrelated capabilities. However, while filtered models lack internalized
dangerous knowledge, we find that they can still leverage such information when
it is provided in context (e.g., via search tool augmentation), demonstrating a
need for a defense-in-depth approach. Overall, these findings help to establish
pretraining data curation as a promising layer of defense for open-weight AI
systems.

</details>


### [525] [Generalizing Scaling Laws for Dense and Sparse Large Language Models](https://arxiv.org/abs/2508.06617)
*Md Arafat Hossain,Xingfu Wu,Valerie Taylor,Ali Jannesari*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出了一种适用于密集和稀疏大型语言模型的通用扩展定律，以优化训练效率和资源分配。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型规模和计算成本的快速增长，需要更高效的训练技术和资源分配方法。现有的扩展定律多为特定架构设计，缺乏通用性。

Method: 重新审视现有扩展定律，提出一种通用扩展定律框架，适用于密集和稀疏模型，并通过实验评估其有效性。

Result: 提出的通用扩展定律在密集和稀疏模型上均表现出色，优于现有特定架构的扩展定律。

Conclusion: 通用扩展定律为大型语言模型的训练和资源分配提供了更灵活和高效的解决方案。

Abstract: Over the past few years, the size of language models has grown exponentially,
as has the computational cost to train these large models. This rapid growth
has motivated researchers to develop new techniques aimed at enhancing the
efficiency of the training process. Despite these advancements, optimally
predicting the model size or allocating optimal resources remains a challenge.
Several efforts have addressed the challenge by proposing different scaling
laws, but almost all of them are architecture-specific (dense or sparse). In
this work we revisit existing scaling laws and propose a generalized scaling
law to provide a unified framework that is applicable to both dense and sparse
large language models. We evaluate and compare our proposed scaling law with
existing scaling laws to demonstrate its effectiveness.

</details>


### [526] [In-Context Reinforcement Learning via Communicative World Models](https://arxiv.org/abs/2508.06659)
*Fernando Martinez-Lopez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

Relevance: 85.0

TL;DR: CORAL框架通过将表征学习与控制解耦，提升强化学习代理的上下文适应能力，实现零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习代理在新任务和上下文中的泛化问题，避免参数更新导致的过拟合。

Method: 提出CORAL框架，分为信息代理（IA）和控制代理（CA），通过因果影响损失训练通信协议。

Result: 实验表明，CORAL显著提升样本效率，并在未见过的稀疏奖励环境中实现零样本适应。

Conclusion: 学习可迁移的通信表征有效提升强化学习代理的上下文适应能力。

Abstract: Reinforcement learning (RL) agents often struggle to generalize to new tasks
and contexts without updating their parameters, mainly because their learned
representations and policies are overfit to the specifics of their training
environments. To boost agents' in-context RL (ICRL) ability, this work
formulates ICRL as a two-agent emergent communication problem and introduces
CORAL (Communicative Representation for Adaptive RL), a framework that learns a
transferable communicative context by decoupling latent representation learning
from control. In CORAL, an Information Agent (IA) is pre-trained as a world
model on a diverse distribution of tasks. Its objective is not to maximize task
reward, but to build a world model and distill its understanding into concise
messages. The emergent communication protocol is shaped by a novel Causal
Influence Loss, which measures the effect that the message has on the next
action. During deployment, the previously trained IA serves as a fixed
contextualizer for a new Control Agent (CA), which learns to solve tasks by
interpreting the provided communicative context. Our experiments demonstrate
that this approach enables the CA to achieve significant gains in sample
efficiency and successfully perform zero-shot adaptation with the help of
pre-trained IA in entirely unseen sparse-reward environments, validating the
efficacy of learning a transferable communicative representation.

</details>


### [527] [Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning](https://arxiv.org/abs/2508.06765)
*Xingke Yang,Liang Li,Sicong Li,Liwei Guan,Hao Wang,Xiaoqi Qi,Jiang Liu,Xin Fu,Miao Pan*

Main category: cs.LG

Relevance: 85.0

TL;DR: Fed MobiLLM提出了一种高效的联邦学习方法，用于在异构移动设备上微调大型语言模型（LLMs），显著降低了计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习方法在移动设备上微调LLMs时的高计算、内存负担和同步协议导致的效率问题。

Method: 采用服务器辅助的联邦侧调优范式，设备仅进行轻量级前向传播，服务器训练共享侧网络，并通过自适应层特征对齐方法处理模型异构性。

Result: 实验显示，Fed MobiLLM在保持性能的同时，计算开销减少95.2%，通信成本降低93.2%，收敛速度提升5.1倍。

Conclusion: Fed MobiLLM为异构移动设备上的LLM微调提供了高效且实用的解决方案。

Abstract: Collaboratively fine-tuning (FT) large language models (LLMs) over
heterogeneous mobile devices fosters immense potential applications of
personalized intelligence. However, such a vision faces critical system
challenges. Conventional federated LLM FT approaches place prohibitive
computational and memory burdens on mobile hardware, and their synchronous
model aggregation protocols stall for slower devices. In this paper, we propose
Fed MobiLLM, a novel design to facilitate efficient federated LLM FT across
mobile devices with diverse computing/communication speeds and local model
architectures. In particular, Fed MobiLLM implements a pioneering
server-assisted federated side-tuning paradigm. Briefly, mobile devices perform
lightweight forward propagation computations on local data using their frozen
pre-scaled backbone LLMs, and then upload selected intermediate activations.
The server trains a shared side-network independently, eliminating client-side
backpropagation and enabling asynchronous updates. To bridge model
heterogeneity across different devices, we introduce an adaptive layer-wise
feature alignment method, which ensures consistent representations for
collaboratively tuning a shared side network. Extensive experimental results
demonstrate that Fed MobiLLM can maintain robust fine-tuning performance while
achieving extremely low on-device memory, with at least 95.2% reduction in
computation overhead, 93.2% reduction in communication costs and 5.1x faster
convergence compared to existing methods, validating its efficacy for practical
LLM adaptation over heterogeneous mobile devices.

</details>


### [528] [Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift](https://arxiv.org/abs/2508.06776)
*Amit Pandey*

Main category: cs.LG

Relevance: 85.0

TL;DR: Zero-Direction Probing (ZDP) 是一种无需任务标签或输出评估的理论框架，通过检测 Transformer 激活的零方向来发现模型漂移。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于无需依赖任务标签或输出评估的情况下，检测模型在表示层面的变化。

Method: 基于假设 A1-A6，提出了方差泄漏定理、Fisher 零守恒、低秩更新的秩泄漏边界，以及在线零空间跟踪器的对数遗憾保证。

Result: 提出了谱零泄漏 (SNL) 度量，并给出了非渐近尾部边界和集中不等式，提供了高斯零模型下的漂移阈值。

Conclusion: 监控层激活的左右零空间及其 Fisher 几何可以提供关于表示变化的具体、可测试的保证。

Abstract: We present Zero-Direction Probing (ZDP), a theory-only framework for
detecting model drift from null directions of transformer activations without
task labels or output evaluations. Under assumptions A1--A6, we prove: (i) the
Variance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound
for low-rank updates, and (iv) a logarithmic-regret guarantee for online
null-space trackers. We derive a Spectral Null-Leakage (SNL) metric with
non-asymptotic tail bounds and a concentration inequality, yielding a-priori
thresholds for drift under a Gaussian null model. These results show that
monitoring right/left null spaces of layer activations and their Fisher
geometry provides concrete, testable guarantees on representational change.

</details>


### [529] [Technical Report: Full-Stack Fine-Tuning for the Q Programming Language](https://arxiv.org/abs/2508.06813)
*Brendan R. Hogan,Will Brown,Adel Boyarsky,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出了一种针对小众编程语言Q的LLM适配方法，通过预训练、监督微调和强化学习训练了一系列模型，并在Q语言任务上显著优于主流前沿模型。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在小众编程语言和私有领域任务中的表现不足问题，特别是针对Q语言。

Method: 构建Q语言的Leetcode风格评测数据集，基于Qwen-2.5系列进行预训练、监督微调和强化学习，训练了不同参数规模的模型。

Result: 最佳模型在Q语言任务上的pass@1准确率达到59%，优于Claude Opus-4和GPT-4.1。

Conclusion: 方法具有广泛适用性，可推广至其他依赖软性或主观信号的任务。

Abstract: Even though large language models are becoming increasingly capable, it is
still unreasonable to expect them to excel at tasks that are under-represented
on the Internet. Leveraging LLMs for specialized applications, particularly in
niche programming languages and private domains, remains challenging and
largely unsolved. In this work, we address this gap by presenting a
comprehensive, open-source approach for adapting LLMs to the Q programming
language, a popular tool in quantitative finance that is much less present on
the Internet compared to Python, C, Java, and other ``mainstream" languages and
is therefore not a strong suit of general-purpose AI models. We introduce a new
Leetcode style evaluation dataset for Q, benchmark major frontier models on the
dataset, then do pretraining, supervised fine tuning, and reinforcement
learning to train a suite of reasoning and non-reasoning models based on the
Qwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B). Our
best model achieves a pass@1 accuracy of 59 percent on our Q benchmark,
surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent.
Additionally, all models, even our 1.5B model, outperform GPT-4.1 on this task.
In addition to releasing models, code, and data, we provide a detailed
blueprint for dataset construction, model pretraining, supervised fine-tuning,
and reinforcement learning. Our methodology is broadly applicable, and we
discuss how these techniques can be extended to other tasks, including those
where evaluation may rely on soft or subjective signals.

</details>


### [530] [BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity](https://arxiv.org/abs/2508.06953)
*Shiwei Li,Xiandi Luo,Haozhao Wang,Xing Tang,Ziqiang Cui,Dugang Liu,Yuhua Li,Xiuqiang He,Ruixuan Li*

Main category: cs.LG

Relevance: 85.0

TL;DR: BoRA是一种改进的低秩适应方法，通过块矩阵乘法和块对角矩阵提升LoRA权重秩，仅需少量额外参数。


<details>
  <summary>Details</summary>
Motivation: LoRA在LLM中广泛使用，但增加秩会显著增加参数数量，BoRA旨在以更少的参数提升性能。

Method: 将LoRA的BA分解为块矩阵乘法，引入块对角矩阵增强多样性，提升秩。

Result: 实验证明BoRA优于传统LoRA，且具有可扩展性。

Conclusion: BoRA是一种高效的低秩适应方法，适用于LLM微调。

Abstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method
widely used in large language models (LLMs). It approximates the update of a
pretrained weight matrix $W\in\mathbb{R}^{m\times n}$ by the product of two
low-rank matrices, $BA$, where $A \in\mathbb{R}^{r\times n}$ and
$B\in\mathbb{R}^{m\times r} (r\ll\min\{m,n\})$. Increasing the dimension $r$
can raise the rank of LoRA weights (i.e., $BA$), which typically improves
fine-tuning performance but also significantly increases the number of
trainable parameters. In this paper, we propose Block Diversified Low-Rank
Adaptation (BoRA), which improves the rank of LoRA weights with a small number
of additional parameters. Specifically, BoRA treats the product $BA$ as a block
matrix multiplication, where $A$ and $B$ are partitioned into $b$ blocks along
the columns and rows, respectively (i.e., $A=[A_1,\dots,A_b]$ and
$B=[B_1,\dots,B_b]^\top$). Consequently, the product $BA$ becomes the
concatenation of the block products $B_iA_j$ for $i,j\in[b]$. To enhance the
diversity of different block products, BoRA introduces a unique diagonal matrix
$\Sigma_{i,j} \in \mathbb{R}^{r\times r}$ for each block multiplication,
resulting in $B_i \Sigma_{i,j} A_j$. By leveraging these block-wise diagonal
matrices, BoRA increases the rank of LoRA weights by a factor of $b$ while only
requiring $b^2r$ additional parameters. Extensive experiments across multiple
datasets and models demonstrate the superiority of BoRA, and ablation studies
further validate its scalability.

</details>


### [531] [Membership and Memorization in LLM Knowledge Distillation](https://arxiv.org/abs/2508.07054)
*Ziqi Zhang,Ali Shahin Shamsabadi,Hanxiao Lu,Yifeng Cai,Hamed Haddadi*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文研究了知识蒸馏（KD）技术在大型语言模型（LLMs）中的隐私风险，发现所有现有KD方法均存在成员和记忆隐私风险，但风险程度因技术而异。


<details>
  <summary>Details</summary>
Motivation: 解决知识蒸馏过程中从教师模型到学生模型的隐私泄露问题，尤其是在教师模型训练数据包含隐私内容时。

Method: 系统评估了六种LLM KD技术，涵盖七个NLP任务、三种教师模型家族（GPT-2、LLAMA-2、OPT）和不同规模的学生模型。

Result: 所有KD方法均存在隐私风险，但风险程度因技术、目标函数、训练数据和任务而异。记忆和成员隐私风险之间存在显著差异。

Conclusion: KD技术的隐私风险因技术细节而异，需进一步优化以降低风险。

Abstract: Recent advances in Knowledge Distillation (KD) aim to mitigate the high
computational demands of Large Language Models (LLMs) by transferring knowledge
from a large ''teacher'' to a smaller ''student'' model. However, students may
inherit the teacher's privacy when the teacher is trained on private data. In
this work, we systematically characterize and investigate membership and
memorization privacy risks inherent in six LLM KD techniques. Using
instruction-tuning settings that span seven NLP tasks, together with three
teacher model families (GPT-2, LLAMA-2, and OPT), and various size student
models, we demonstrate that all existing LLM KD approaches carry membership and
memorization privacy risks from the teacher to its students. However, the
extent of privacy risks varies across different KD techniques. We
systematically analyse how key LLM KD components (KD objective functions,
student training data and NLP tasks) impact such privacy risks. We also
demonstrate a significant disagreement between memorization and membership
privacy risks of LLM KD techniques. Finally, we characterize per-block privacy
risk and demonstrate that the privacy risk varies across different blocks by a
large margin.

</details>


### [532] [What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains](https://arxiv.org/abs/2508.07208)
*Chanakya Ekbote,Marco Bondaschi,Nived Rajaraman,Jason D. Lee,Michael Gastpar,Ashok Vardhan Makkuva,Paul Pu Liang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文探讨了两层单头Transformer是否能表示任何k阶马尔可夫过程，并证明其可行性，深化了对Transformer基于上下文学习能力的理解。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer的深度与马尔可夫阶数之间的关系，以揭示浅层架构在结构化序列建模任务中的上下文学习能力。

Method: 通过理论分析，证明两层单头Transformer可以表示任何条件k-gram，并简化变体分析学习动态。

Result: 证明了两层单头Transformer能表示任何k阶马尔可夫过程，提供了Transformer深度与马尔可夫阶数的最紧表征。

Conclusion: 浅层Transformer架构在结构化序列任务中表现出强大的上下文学习能力，扩展了对Transformer的理解。

Abstract: In-context learning (ICL) is a hallmark capability of transformers, through
which trained models learn to adapt to new tasks by leveraging information from
the input context. Prior work has shown that ICL emerges in transformers due to
the presence of special circuits called induction heads. Given the equivalence
between induction heads and conditional k-grams, a recent line of work modeling
sequential inputs as Markov processes has revealed the fundamental impact of
model depth on its ICL capabilities: while a two-layer transformer can
efficiently represent a conditional 1-gram model, its single-layer counterpart
cannot solve the task unless it is exponentially large. However, for higher
order Markov sources, the best known constructions require at least three
layers (each with a single attention head) - leaving open the question: can a
two-layer single-head transformer represent any kth-order Markov process? In
this paper, we precisely address this and theoretically show that a two-layer
transformer with one head per layer can indeed represent any conditional
k-gram. Thus, our result provides the tightest known characterization of the
interplay between transformer depth and Markov order for ICL. Building on this,
we further analyze the learning dynamics of our two-layer construction,
focusing on a simplified variant for first-order Markov chains, illustrating
how effective in-context representations emerge during training. Together,
these results deepen our current understanding of transformer-based ICL and
illustrate how even shallow architectures can surprisingly exhibit strong ICL
capabilities on structured sequence modeling tasks.

</details>


### [533] [Efficient Edge LLMs Deployment via HessianAware Quantization and CPU GPU Collaborative](https://arxiv.org/abs/2508.07329)
*Tuo Zhang,Ning Li,Xin Yuan,Wenchao Xu,Quan Chen,Song Guo,Haijun Zhang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出了一种基于Hessian感知量化（HAQ）和CPU-GPU协同推理的高效MoE边缘部署方案，解决了量化精度和内存限制问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在多模态任务中的突破性进展，如何在资源受限的边缘设备上高效部署成为关键挑战。MoE架构因稀疏激活增强模型能力，但面临量化精度和内存效率问题。

Method: 1. 引入平滑Hessian矩阵量化，实现8位量化；2. 设计专家级协同卸载和推理机制，优化CPU-GPU调度。

Result: 在OPT系列和Mixtral 8*7B等模型上验证，量化模型精度接近全精度模型，GPU内存减少60%，推理延迟显著改善。

Conclusion: 该方法有效解决了MoE边缘部署中的量化精度和内存效率问题，为LLMs在资源受限设备上的应用提供了可行方案。

Abstract: With the breakthrough progress of large language models (LLMs) in natural
language processing and multimodal tasks, efficiently deploying them on
resource-constrained edge devices has become a critical challenge. The Mixture
of Experts (MoE) architecture enhances model capacity through sparse
activation, but faces two major difficulties in practical deployment: (1) The
presence of numerous outliers in activation distributions leads to severe
degradation in quantization accuracy for both activations and weights,
significantly impairing inference performance; (2) Under limited memory,
efficient offloading and collaborative inference of expert modules struggle to
balance latency and throughput. To address these issues, this paper proposes an
efficient MoE edge deployment scheme based on Hessian-Aware Quantization (HAQ)
and CPU-GPU collaborative inference. First, by introducing smoothed Hessian
matrix quantization, we achieve joint 8-bit quantization of activations and
weights, which significantly alleviates the accuracy loss caused by outliers
while ensuring efficient implementation on mainstream hardware. Second, we
design an expert-level collaborative offloading and inference mechanism, which,
combined with expert activation path statistics, enables efficient deployment
and scheduling of expert modules between CPU and GPU, greatly reducing memory
footprint and inference latency. Extensive experiments validate the
effectiveness of our method on mainstream large models such as the OPT series
and Mixtral 8*7B: on datasets like Wikitext2 and C4, the inference accuracy of
the low-bit quantized model approaches that of the full-precision model, while
GPU memory usage is reduced by about 60%, and inference latency is
significantly improved.

</details>


### [534] [Parity Requires Unified Input Dependence and Negative Eigenvalues in SSMs](https://arxiv.org/abs/2508.07395)
*Behnoush Khavari,Mehran Shakerinava,Jayesh Khullar,Jerry Huang,François Rivest,Siamak Ravanbakhsh,Sarath Chandar*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文探讨了LRNN模型（如S4D、Mamba和DeltaNet）在状态跟踪任务中的局限性，并提出输入依赖的转移矩阵可能提升性能。研究发现，多层SSM即使结合输入独立和非负SSM仍无法解决简单任务（如奇偶校验），表明需要输入依赖和负特征值的递归层。


<details>
  <summary>Details</summary>
Motivation: 现有LRNN模型因时间不变转移矩阵或受限特征值范围而缺乏状态跟踪能力，需探索输入依赖转移矩阵的潜力。

Method: 研究多层SSM（结合输入独立和非负SSM）在简单任务（如奇偶校验）中的表现，并通过实验分析S4D和Mamba层的组合模型。

Result: 多层SSM即使结合输入独立和非负SSM仍无法解决奇偶校验任务，表明需要输入依赖和负特征值的递归层。

Conclusion: 递归层需同时具备输入依赖性和负特征值才能有效解决状态跟踪任务。

Abstract: Recent work has shown that LRNN models such as S4D, Mamba, and DeltaNet lack
state-tracking capability due to either time-invariant transition matrices or
restricted eigenvalue ranges. To address this, input-dependent transition
matrices, particularly those that are complex or non-triangular, have been
proposed to enhance SSM performance on such tasks. While existing theorems
demonstrate that both input-independent and non-negative SSMs are incapable of
solving simple state-tracking tasks, such as parity, regardless of depth, they
do not explore whether combining these two types in a multilayer SSM could
help. We investigate this question for efficient SSMs with diagonal transition
matrices and show that such combinations still fail to solve parity. This
implies that a recurrence layer must both be input-dependent and include
negative eigenvalues. Our experiments support this conclusion by analyzing an
SSM model that combines S4D and Mamba layers.

</details>


### [535] [Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning](https://arxiv.org/abs/2508.07556)
*Stephan Rabanser*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文研究了如何通过不确定性估计提升机器学习系统的安全性和可信度，重点探讨了选择性预测方法。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域部署机器学习系统时，可靠性和不确定性估计至关重要。论文旨在通过选择性预测提升模型的信任度。

Method: 提出了一种轻量级的事后弃权方法，利用模型训练轨迹中的不确定性信号，并结合差分隐私研究隐私与不确定性的权衡。

Result: 方法在选择性预测任务中表现优异，且在差分隐私下保持鲁棒性。同时揭示了选择性分类误差的来源，并设计了防御对抗攻击的策略。

Conclusion: 论文通过改进、评估和保护不确定性估计，推动了可靠机器学习的发展，使模型能够更明智地决定何时放弃预测。

Abstract: Machine learning (ML) systems are increasingly deployed in high-stakes
domains where reliability is paramount. This thesis investigates how
uncertainty estimation can enhance the safety and trustworthiness of ML,
focusing on selective prediction -- where models abstain when confidence is
low.
  We first show that a model's training trajectory contains rich uncertainty
signals that can be exploited without altering its architecture or loss. By
ensembling predictions from intermediate checkpoints, we propose a lightweight,
post-hoc abstention method that works across tasks, avoids the cost of deep
ensembles, and achieves state-of-the-art selective prediction performance.
Crucially, this approach is fully compatible with differential privacy (DP),
allowing us to study how privacy noise affects uncertainty quality. We find
that while many methods degrade under DP, our trajectory-based approach remains
robust, and we introduce a framework for isolating the privacy-uncertainty
trade-off. Next, we then develop a finite-sample decomposition of the selective
classification gap -- the deviation from the oracle accuracy-coverage curve --
identifying five interpretable error sources and clarifying which interventions
can close the gap. This explains why calibration alone cannot fix ranking
errors, motivating methods that improve uncertainty ordering. Finally, we show
that uncertainty signals can be adversarially manipulated to hide errors or
deny service while maintaining high accuracy, and we design defenses combining
calibration audits with verifiable inference.
  Together, these contributions advance reliable ML by improving, evaluating,
and safeguarding uncertainty estimation, enabling models that not only make
accurate predictions -- but also know when to say "I do not know".

</details>


### [536] [Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization](https://arxiv.org/abs/2508.07629)
*Zhenpeng Su,Leiyu Pan,Xue Bai,Dening Liu,Guanting Dong,Jiaming Huang,Wenping Hu,Guorui Zhou*

Main category: cs.LG

Relevance: 85.0

TL;DR: Klear-Reasoner是一个具有长推理能力的模型，通过详细的训练流程分析和改进的强化学习方法（GPPO），在数学和编程任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前高性能推理模型的复现问题源于训练细节披露不完整，本文旨在提供完整的训练流程分析和改进方法。

Method: 包括数据准备、长链思维监督微调（long CoT SFT）和强化学习（RL），并提出GPPO解决当前RL中的裁剪机制问题。

Result: 在多个基准测试中表现突出，如AIME 2024（90.5%）和LiveCodeBench V6（58.1%）。

Conclusion: 高质量数据和小样本难例对SFT更有效，GPPO提升了模型的探索能力和学习效率。

Abstract: We present Klear-Reasoner, a model with long reasoning capabilities that
demonstrates careful deliberation during problem solving, achieving outstanding
performance across multiple benchmarks. Although there are already many
excellent works related to inference models in the current community, there are
still many problems with reproducing high-performance inference models due to
incomplete disclosure of training details. This report provides an in-depth
analysis of the reasoning model, covering the entire post-training workflow
from data preparation and long Chain-of-Thought supervised fine-tuning (long
CoT SFT) to reinforcement learning (RL), along with detailed ablation studies
for each experimental component. For SFT data, our experiments show that a
small number of high-quality data sources are more effective than a large
number of diverse data sources, and that difficult samples can achieve better
results without accuracy filtering. In addition, we investigate two key issues
with current clipping mechanisms in RL: Clipping suppresses critical
exploration signals and ignores suboptimal trajectories. To address these
challenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO)
that gently backpropagates gradients from clipped tokens. GPPO not only
enhances the model's exploration capacity but also improves its efficiency in
learning from negative samples. Klear-Reasoner exhibits exceptional reasoning
abilities in mathematics and programming, scoring 90.5\% on AIME 2024, 83.2\%
on AIME 2025, 66.0\% on LiveCodeBench V5 and 58.1\% on LiveCodeBench V6.

</details>


### [537] [Multi-Turn Jailbreaks Are Simpler Than They Seem](https://arxiv.org/abs/2508.07646)
*Xiaoxue Yang,Jaeha Lee,Anna-Katharina Dick,Jasper Timm,Fei Xie,Diogo Cruz*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文分析了多轮越狱攻击对大型语言模型（LLMs）的有效性，发现其成功率与单轮攻击多次重采样相当，且攻击成功率在类似模型间相关。高推理努力反而可能增加攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 研究多轮越狱攻击对LLMs的威胁，挑战其复杂性假设，并为AI安全评估和防御设计提供依据。

Method: 使用StrongREJECT基准对GPT-4、Claude和Gemini等先进模型进行多轮越狱攻击的实证分析。

Result: 多轮攻击成功率与单轮攻击多次重采样相当；攻击成功率在类似模型间相关；高推理努力可能增加攻击成功率。

Conclusion: 多轮越狱攻击的实际威胁可能被高估，需重新评估AI安全设计和防御策略。

Abstract: While defenses against single-turn jailbreak attacks on Large Language Models
(LLMs) have improved significantly, multi-turn jailbreaks remain a persistent
vulnerability, often achieving success rates exceeding 70% against models
optimized for single-turn protection. This work presents an empirical analysis
of automated multi-turn jailbreak attacks across state-of-the-art models
including GPT-4, Claude, and Gemini variants, using the StrongREJECT benchmark.
Our findings challenge the perceived sophistication of multi-turn attacks: when
accounting for the attacker's ability to learn from how models refuse harmful
requests, multi-turn jailbreaking approaches are approximately equivalent to
simply resampling single-turn attacks multiple times. Moreover, attack success
is correlated among similar models, making it easier to jailbreak newly
released ones. Additionally, for reasoning models, we find surprisingly that
higher reasoning effort often leads to higher attack success rates. Our results
have important implications for AI safety evaluation and the design of
jailbreak-resistant systems. We release the source code at
https://github.com/diogo-cruz/multi_turn_simpler

</details>


### [538] [Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation](https://arxiv.org/abs/2508.07675)
*Xutong Liu,Baran Atalar,Xiangxiang Dai,Jinhang Zuo,Siwei Wang,John C. S. Lui,Wei Chen,Carlee Joe-Wong*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出了一种基于学习的语义缓存淘汰框架，解决了传统缓存方法无法处理语义相似性和动态系统参数的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的高推理成本带来了可扩展性和可持续性挑战，传统缓存方法无法有效处理语义相似性，且缺乏理论支持。

Method: 提出了一种基于学习的框架，包括离线优化和在线学习变体，并开发了高效的算法。

Result: 在合成数据集上的实验表明，所提算法性能优于或与基线方法相当。

Conclusion: 该框架为语义缓存提供了理论基础，并能适应动态环境。

Abstract: Large Language Models (LLMs) are revolutionizing how users interact with
information systems, yet their high inference cost poses serious scalability
and sustainability challenges. Caching inference responses, allowing them to be
retrieved without another forward pass through the LLM, has emerged as one
possible solution. Traditional exact-match caching, however, overlooks the
semantic similarity between queries, leading to unnecessary recomputation.
Semantic caching addresses this by retrieving responses based on semantic
similarity, but introduces a fundamentally different cache eviction problem:
one must account for mismatch costs between incoming queries and cached
responses. Moreover, key system parameters, such as query arrival probabilities
and serving costs, are often unknown and must be learned over time. Existing
semantic caching methods are largely ad-hoc, lacking theoretical foundations
and unable to adapt to real-world uncertainty. In this paper, we present a
principled, learning-based framework for semantic cache eviction under unknown
query and cost distributions. We formulate both offline optimization and online
learning variants of the problem, and develop provably efficient algorithms
with state-of-the-art guarantees. We also evaluate our framework on a synthetic
dataset, showing that our proposed algorithms perform matching or superior
performance compared with baselines.

</details>


### [539] [Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent](https://arxiv.org/abs/2508.08222)
*Tong Yang,Yu Huang,Yingbin Liang,Yuejie Chi*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文研究了Transformer如何通过训练学习解决符号多步推理任务，特别是树中的路径查找问题，并通过理论分析证明了其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer如何通过训练获得多步推理能力，尤其是从理论角度分析其机制。

Method: 分析两个任务：反向推理和更复杂的前向推理，基于梯度下降动态的理论分析。

Result: 训练后的一层Transformer可以解决任务并泛化到未见过的树，揭示了注意力头的专业化与协作机制。

Conclusion: 任务结构化和中间思维链步骤使浅层Transformer能解决通常需要深层架构的问题。

Abstract: Transformers have demonstrated remarkable capabilities in multi-step
reasoning tasks. However, understandings of the underlying mechanisms by which
they acquire these abilities through training remain limited, particularly from
a theoretical standpoint. This work investigates how transformers learn to
solve symbolic multi-step reasoning problems through chain-of-thought
processes, focusing on path-finding in trees. We analyze two intertwined tasks:
a backward reasoning task, where the model outputs a path from a goal node to
the root, and a more complex forward reasoning task, where the model implements
two-stage reasoning by first identifying the goal-to-root path and then
reversing it to produce the root-to-goal path. Our theoretical analysis,
grounded in the dynamics of gradient descent, shows that trained one-layer
transformers can provably solve both tasks with generalization guarantees to
unseen trees. In particular, our multi-phase training dynamics for forward
reasoning elucidate how different attention heads learn to specialize and
coordinate autonomously to solve the two subtasks in a single autoregressive
path. These results provide a mechanistic explanation of how trained
transformers can implement sequential algorithmic procedures. Moreover, they
offer insights into the emergence of reasoning abilities, suggesting that when
tasks are structured to take intermediate chain-of-thought steps, even shallow
multi-head transformers can effectively solve problems that would otherwise
require deeper architectures.

</details>


### [540] [Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials](https://arxiv.org/abs/2508.06591)
*Rachel K. Luu,Jingyu Deng,Mohammed Shahrudin Ibrahim,Nam-Joon Cho,Ming Dao,Subra Suresh,Markus J. Buehler*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文提出了一种结合生成式AI与多学科文献的框架，用于材料科学中的实验设计和知识提取，验证了AI辅助材料设计的可行性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在多学科材料科学中的应用，解决其在该领域应用受限的问题。

Method: 结合微调模型（BioinspiredLLM）、检索增强生成（RAG）、代理系统和分层采样策略，提取结构-性能关系并设计新材料。

Result: 成功验证了AI生成的材料设计和预测，并制造出一种新型花粉基粘合剂。

Conclusion: AI辅助设计可推动实际材料创新，促进人机协作。

Abstract: Large language models (LLMs) have reshaped the research landscape by enabling
new approaches to knowledge retrieval and creative ideation. Yet their
application in discipline-specific experimental science, particularly in highly
multi-disciplinary domains like materials science, remains limited. We present
a first-of-its-kind framework that integrates generative AI with literature
from hitherto-unconnected fields such as plant science, biomimetics, and
materials engineering to extract insights and design experiments for materials.
We focus on humidity-responsive systems such as pollen-based materials and
Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and
adaptive performance. Using a suite of AI tools, including a fine-tuned model
(BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a
Hierarchical Sampling strategy, we extract structure-property relationships and
translate them into new classes of bioinspired materials. Structured inference
protocols generate and evaluate hundreds of hypotheses from a single query,
surfacing novel and experimentally tractable ideas. We validate our approach
through real-world implementation: LLM-generated procedures, materials designs,
and mechanical predictions were tested in the laboratory, culminating in the
fabrication of a novel pollen-based adhesive with tunable morphology and
measured shear strength, establishing a foundation for future plant-derived
adhesive design. This work demonstrates how AI-assisted ideation can drive
real-world materials design and enable effective human-AI collaboration.

</details>


### [541] [Who's the Evil Twin? Differential Auditing for Undesired Behavior](https://arxiv.org/abs/2508.06827)
*Ishwar Balappanawar,Venkata Hasith Vattikuti,Greta Kintzley,Ronan Azimi-Mancel,Satvik Golechha*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文提出了一种通过对抗游戏检测神经网络中隐藏行为的方法，实验表明基于对抗攻击的方法效果最佳，但LLM的检测方法仍需改进。


<details>
  <summary>Details</summary>
Motivation: 检测神经网络中的隐藏行为具有挑战性，尤其是在缺乏先验知识和对抗性混淆的情况下。

Method: 通过红队和蓝队的对抗游戏框架，红队训练两个模型（一个良性，一个含隐藏行为），蓝队尝试识别异常模型。实验使用了多种蓝队策略。

Result: 基于对抗攻击的方法在提示下达到100%准确率，其他方法表现不一。LLM的检测方法需要额外提示。

Conclusion: 对抗攻击方法高效，但LLM检测需改进。开源了审计游戏框架以促进未来研究。

Abstract: Detecting hidden behaviors in neural networks poses a significant challenge
due to minimal prior knowledge and potential adversarial obfuscation. We
explore this problem by framing detection as an adversarial game between two
teams: the red team trains two similar models, one trained solely on benign
data and the other trained on data containing hidden harmful behavior, with the
performance of both being nearly indistinguishable on the benign dataset. The
blue team, with limited to no information about the harmful behaviour, tries to
identify the compromised model. We experiment using CNNs and try various blue
team strategies, including Gaussian noise analysis, model diffing, integrated
gradients, and adversarial attacks under different levels of hints provided by
the red team. Results show high accuracy for adversarial-attack-based methods
(100\% correct prediction, using hints), which is very promising, whilst the
other techniques yield more varied performance. During our LLM-focused rounds,
we find that there are not many parallel methods that we could apply from our
study with CNNs. Instead, we find that effective LLM auditing methods require
some hints about the undesired distribution, which can then used in standard
black-box and open-weight methods to probe the models further and reveal their
misalignment. We open-source our auditing games (with the model and data) and
hope that our findings contribute to designing better audits.

</details>


### [542] [Efficient Reward Identification In Max Entropy Reinforcement Learning with Sparsity and Rank Priors](https://arxiv.org/abs/2508.07400)
*Mohamad Louai Shehab,Alperen Tercan,Necmiye Ozay*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文研究了从最优策略或演示中恢复时变奖励函数的问题，提出了两种奖励先验假设，并分别转化为稀疏化和秩最小化问题，设计了高效的优化算法。


<details>
  <summary>Details</summary>
Motivation: 在最大熵强化学习中，从策略或演示中恢复奖励函数是一个高度不适定问题，但实际应用中奖励通常具有稀疏性或低维表示，因此研究如何利用先验信息高效恢复奖励函数具有重要意义。

Method: 1) 假设奖励函数稀疏变化，将其转化为带线性约束的稀疏化问题，提出多项式时间精确算法；2) 假设奖励函数为少量特征的线性组合，转化为带线性约束的秩最小化问题，利用凸松弛求解。

Result: 提出的算法能高效恢复奖励函数，并通过实验验证了恢复的准确性和泛化能力。

Conclusion: 通过合理先验假设，奖励函数恢复问题可转化为高效优化问题，为强化学习中的逆向强化学习提供了新思路。

Abstract: In this paper, we consider the problem of recovering time-varying reward
functions from either optimal policies or demonstrations coming from a max
entropy reinforcement learning problem. This problem is highly ill-posed
without additional assumptions on the underlying rewards. However, in many
applications, the rewards are indeed parsimonious, and some prior information
is available. We consider two such priors on the rewards: 1) rewards are mostly
constant and they change infrequently, 2) rewards can be represented by a
linear combination of a small number of feature functions. We first show that
the reward identification problem with the former prior can be recast as a
sparsification problem subject to linear constraints. Moreover, we give a
polynomial-time algorithm that solves this sparsification problem exactly.
Then, we show that identifying rewards representable with the minimum number of
features can be recast as a rank minimization problem subject to linear
constraints, for which convex relaxations of rank can be invoked. In both
cases, these observations lead to efficient optimization-based reward
identification algorithms. Several examples are given to demonstrate the
accuracy of the recovered rewards as well as their generalizability.

</details>


### [543] [Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression](https://arxiv.org/abs/2508.07571)
*Xingwu Chen,Miao Lu,Beining Wu,Difan Zou*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文通过结合随机性和采样，分析了语言模型推理中的测试时计算，提出了一个理论框架，并展示了其在实际模型中的潜力。


<details>
  <summary>Details</summary>
Motivation: 弥合实际语言模型推理与理论分析之间的差距，通过随机性和采样研究推理行为。

Method: 采用噪声注入和二元系数采样的框架，模拟语言模型解码，分析推理技术。

Result: 理论框架和实证结果表明，该方法能提供对实际语言模型推理行为的新见解。

Conclusion: 该研究为理解语言模型推理行为提供了新的理论工具和实证支持。

Abstract: Using more test-time computation during language model inference, such as
generating more intermediate thoughts or sampling multiple candidate answers,
has proven effective in significantly improving model performance. This paper
takes an initial step toward bridging the gap between practical language model
inference and theoretical transformer analysis by incorporating randomness and
sampling. We focus on in-context linear regression with continuous/binary
coefficients, where our framework simulates language model decoding through
noise injection and binary coefficient sampling. Through this framework, we
provide detailed analyses of widely adopted inference techniques. Supported by
empirical results, our theoretical framework and analysis demonstrate the
potential for offering new insights into understanding inference behaviors in
real-world language models.

</details>


### [544] [When and how can inexact generative models still sample from the data manifold?](https://arxiv.org/abs/2508.07581)
*Nisha Chandramoorthy,Adriaan de Clercq*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文研究了生成模型中学习误差导致样本沿数据分布支撑移动而非偏离的现象，揭示了支持鲁棒性的动态机制。


<details>
  <summary>Details</summary>
Motivation: 探索生成模型中学习误差对样本分布的影响，特别是支持鲁棒性的动态机制。

Method: 采用动态系统方法分析生成过程的扰动，提出Lyapunov向量与数据流形切空间对齐的条件。

Result: 发现学习误差仅影响数据流形上的预测密度，对齐条件可高效计算并准确估计数据流形切丛。

Conclusion: 研究为生成模型提供了理论保证，适用于多种动态生成模型和目标分布。

Abstract: A curious phenomenon observed in some dynamical generative models is the
following: despite learning errors in the score function or the drift vector
field, the generated samples appear to shift \emph{along} the support of the
data distribution but not \emph{away} from it. In this work, we investigate
this phenomenon of \emph{robustness of the support} by taking a dynamical
systems approach on the generating stochastic/deterministic process. Our
perturbation analysis of the probability flow reveals that infinitesimal
learning errors cause the predicted density to be different from the target
density only on the data manifold for a wide class of generative models.
Further, what is the dynamical mechanism that leads to the robustness of the
support? We show that the alignment of the top Lyapunov vectors (most sensitive
infinitesimal perturbation directions) with the tangent spaces along the
boundary of the data manifold leads to robustness and prove a sufficient
condition on the dynamics of the generating process to achieve this alignment.
Moreover, the alignment condition is efficient to compute and, in practice, for
robust generative models, automatically leads to accurate estimates of the
tangent bundle of the data manifold. Using a finite-time linear perturbation
analysis on samples paths as well as probability flows, our work complements
and extends existing works on obtaining theoretical guarantees for generative
models from a stochastic analysis, statistical learning and uncertainty
quantification points of view. Our results apply across different dynamical
generative models, such as conditional flow-matching and score-based generative
models, and for different target distributions that may or may not satisfy the
manifold hypothesis.

</details>


### [545] [Using Imperfect Synthetic Data in Downstream Inference Tasks](https://arxiv.org/abs/2508.06635)
*Yewon Byun,Shantanu Gupta,Zachary C. Lipton,Rachel Leah Childers,Bryan Wilder*

Main category: cs.LG

Relevance: 70.0

TL;DR: 提出一种基于广义矩方法的新估计器，用于结合合成数据和真实数据，以在计算社会科学中生成统计有效的结论。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用大语言模型生成的合成数据与真实数据结合，以在有限数据条件下支持社会科学研究。

Method: 基于广义矩方法的超参数无关估计器，利用合成数据与真实数据之间的矩残差交互改进参数估计。

Result: 实证验证表明，该方法在计算社会科学的不同回归任务中显著提升了参数估计的准确性。

Conclusion: 新估计器为合成数据与真实数据的结合提供了理论保证和实际性能提升。

Abstract: Predictions and generations from large language models are increasingly being
explored as an aid to computational social science and human subject research
in limited data regimes. While previous technical work has explored the
potential to use model-predicted labels for unlabeled data in a principled
manner, there is increasing interest in using large language models to generate
entirely new synthetic samples (also termed as synthetic simulations), such as
in responses to surveys. However, it is not immediately clear by what means
practitioners can combine such data with real data and yet produce
statistically valid conclusions upon them. In this work, we introduce a new
estimator based on generalized method of moments, providing a
hyperparameter-free solution with strong theoretical guarantees to address the
challenge at hand. Surprisingly, we find that interactions between the moment
residuals of synthetic data and those of real data can improve estimates of the
target parameter. We empirically validate the finite-sample performance of our
estimator across different regression tasks in computational social science
applications, demonstrating large empirical gains.

</details>


### [546] [Fractal Language Modelling by Universal Sequence Maps (USM)](https://arxiv.org/abs/2508.06641)
*Jonas S Almeida,Daniel E Russ,Susana Vinga,Ines Duarte,Lee Mason,Praphulla Bhawsar,Aaron Ge,Arlindo Oliveira,Jeya Balaji Balasubramanian*

Main category: cs.LG

Relevance: 70.0

TL;DR: 本文提出了一种基于通用序列映射（USM）的双射分形编码方法，解决了迭代过程中的种子偏差问题，揭示了USM作为一种高效数值过程的特性。


<details>
  <summary>Details</summary>
Motivation: 探索多尺度和嵌入维度下符号序列的数值表示方法，以保留上下文信息。

Method: 使用前向和后向混沌游戏表示（CGR）构建USM，并将其投影到频域（FCGR），计算切比雪夫距离和k-mer频率。

Result: 解决了种子偏差问题，实现了数值定位与序列身份的全匹配，并发现USM是一种收敛于稳态序列嵌入的高效数值过程。

Conclusion: USM方法适用于任意基数字母表，尤其在基因组序列中表现出高效性。

Abstract: Motivation: With the advent of Language Models using Transformers,
popularized by ChatGPT, there is a renewed interest in exploring encoding
procedures that numerically represent symbolic sequences at multiple scales and
embedding dimensions. The challenge that encoding addresses is the need for
mechanisms that uniquely retain contextual information about the succession of
individual symbols, which can then be modeled by nonlinear formulations such as
neural networks.
  Context: Universal Sequence Maps(USM) are iterated functions that bijectively
encode symbolic sequences onto embedded numerical spaces. USM is composed of
two Chaos Game Representations (CGR), iterated forwardly and backwardly, that
can be projected into the frequency domain (FCGR). The corresponding USM
coordinates can be used to compute a Chebyshev distance metric as well as k-mer
frequencies, without having to recompute the embedded numeric coordinates, and,
paradoxically, allowing for non-integers values of k.
  Results: This report advances the bijective fractal encoding by Universal
Sequence Maps (USM) by resolving seeding biases affecting the iterated process.
The resolution had two results, the first expected, the second an intriguing
outcome: 1) full reconciliation of numeric positioning with sequence identity;
and 2) uncovering the nature of USM as an efficient numeric process converging
towards a steady state sequence embedding solution. We illustrate these results
for genomic sequences because of the convenience of a planar representation
defined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless,
the application to alphabet of arbitrary cardinality was found to be
straightforward.

</details>


### [547] [Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation](https://arxiv.org/abs/2508.06806)
*Xiao Huang,Xu Liu,Enze Zhang,Tong Yu,Shuai Li*

Main category: cs.LG

Relevance: 70.0

TL;DR: 提出了一种新的数据增强方法CFDG，用于离线到在线强化学习（O2O RL），通过无分类器扩散生成提升数据质量，显著提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成的离线数据与在线数据分布存在差距，限制了性能。CFDG旨在缩小这一差距，提升生成数据质量。

Method: 使用无分类器扩散生成（CFDG）增强数据，结合重加权方法使生成数据更接近在线数据分布。

Result: 在D4RL基准测试中，CFDG比现有方法平均提升15%性能。

Conclusion: CFDG是一种通用且高效的方法，可集成到现有O2O RL算法中，显著提升性能。

Abstract: Offline-to-online Reinforcement Learning (O2O RL) aims to perform online
fine-tuning on an offline pre-trained policy to minimize costly online
interactions. Existing work used offline datasets to generate data that conform
to the online data distribution for data augmentation. However, generated data
still exhibits a gap with the online data, limiting overall performance. To
address this, we propose a new data augmentation approach, Classifier-Free
Diffusion Generation (CFDG). Without introducing additional classifier training
overhead, CFDG leverages classifier-free guidance diffusion to significantly
enhance the generation quality of offline and online data with different
distributions. Additionally, it employs a reweighting method to enable more
generated data to align with the online data, enhancing performance while
maintaining the agent's stability. Experimental results show that CFDG
outperforms replaying the two data types or using a standard diffusion model to
generate new data. Our method is versatile and can be integrated with existing
offline-to-online RL algorithms. By implementing CFDG to popular methods IQL,
PEX and APL, we achieve a notable 15% average improvement in empirical
performance on the D4RL benchmark such as MuJoCo and AntMaze.

</details>


### [548] [Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning](https://arxiv.org/abs/2508.06871)
*Aleksandar Todorov,Juan Cardenas-Cartagena,Rafael F. Cunha,Marco Zullich,Matthia Sabatelli*

Main category: cs.LG

Relevance: 70.0

TL;DR: 论文研究了深度强化学习中塑性损失的问题，通过稀疏化方法（GMP和SET）提升多任务强化学习（MTRL）的可塑性，并验证其在多种架构上的有效性。


<details>
  <summary>Details</summary>
Motivation: 塑性损失是深度强化学习中的关键挑战，尤其在多任务学习中，更高的表示灵活性对处理多样任务至关重要。

Method: 采用Gradual Magnitude Pruning (GMP)和Sparse Evolutionary Training (SET)两种稀疏化方法，评估其在共享主干、混合专家和正交专家混合等MTRL架构中的效果。

Result: GMP和SET有效缓解了塑性退化（如神经元休眠和表示崩溃），并提升了多任务性能，稀疏模型常优于密集模型。

Conclusion: 动态稀疏化是提升MTRL系统适应性的有效工具，但其效果依赖于具体情境。

Abstract: Plasticity loss, a diminishing capacity to adapt as training progresses, is a
critical challenge in deep reinforcement learning. We examine this issue in
multi-task reinforcement learning (MTRL), where higher representational
flexibility is crucial for managing diverse and potentially conflicting task
demands. We systematically explore how sparsification methods, particularly
Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance
plasticity and consequently improve performance in MTRL agents. We evaluate
these approaches across distinct MTRL architectures (shared backbone, Mixture
of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks,
comparing against dense baselines, and a comprehensive range of alternative
plasticity-inducing or regularization methods. Our results demonstrate that
both GMP and SET effectively mitigate key indicators of plasticity degradation,
such as neuron dormancy and representational collapse. These plasticity
improvements often correlate with enhanced multi-task performance, with sparse
agents frequently outperforming dense counterparts and achieving competitive
results against explicit plasticity interventions. Our findings offer insights
into the interplay between plasticity, network sparsity, and MTRL designs,
highlighting dynamic sparsification as a robust but context-sensitive tool for
developing more adaptable MTRL systems.

</details>


### [549] [Conformal Prediction and Trustworthy AI](https://arxiv.org/abs/2508.06885)
*Anthony Bellotti,Xindi Zhao*

Main category: cs.LG

Relevance: 70.0

TL;DR: 本文回顾了共形预测（Conformal Prediction）在可信AI中的潜力，探讨了其如何解决泛化风险和AI治理问题，并通过实验展示了其在偏差识别和缓解中的应用。


<details>
  <summary>Details</summary>
Motivation: 共形预测能提供具有置信度保证的集合预测，适用于可信AI的开发，尤其在不确定性量化和偏差缓解方面具有潜力。

Method: 通过理论分析和实验验证，探讨共形预测在可信AI中的应用，包括偏差识别和泛化风险控制。

Result: 共形预测被证明是一种校准良好的预测方法，并能有效识别和缓解偏差。

Conclusion: 共形预测在可信AI领域具有重要价值，尤其在泛化风险和AI治理方面。

Abstract: Conformal predictors are machine learning algorithms developed in the 1990's
by Gammerman, Vovk, and their research team, to provide set predictions with
guaranteed confidence level. Over recent years, they have grown in popularity
and have become a mainstream methodology for uncertainty quantification in the
machine learning community. From its beginning, there was an understanding that
they enable reliable machine learning with well-calibrated uncertainty
quantification. This makes them extremely beneficial for developing trustworthy
AI, a topic that has also risen in interest over the past few years, in both
the AI community and society more widely. In this article, we review the
potential for conformal prediction to contribute to trustworthy AI beyond its
marginal validity property, addressing problems such as generalization risk and
AI governance. Experiments and examples are also provided to demonstrate its
use as a well-calibrated predictor and for bias identification and mitigation.

</details>


### [550] [Revisiting Data Attribution for Influence Functions](https://arxiv.org/abs/2508.07297)
*Hongbo Zhu,Angelo Cangelosi*

Main category: cs.LG

Relevance: 70.0

TL;DR: 该论文综述了影响函数在深度学习中的数据归因能力，包括理论基础、算法改进及其在数据调试和误标签检测中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究目标是理解训练数据如何影响模型预测，以提升模型可解释性、数据调试和模型问责。

Method: 利用影响函数（源自稳健统计学）作为一阶近似方法，估算数据点对模型参数和预测的影响，避免昂贵的重新训练。

Result: 论文评估了影响函数在数据归因和误标签检测中的有效性，并讨论了其在大规模深度学习中的潜力与挑战。

Conclusion: 影响函数在数据归因方面具有潜力，但仍需解决大规模应用中的挑战。

Abstract: The goal of data attribution is to trace the model's predictions through the
learning algorithm and back to its training data. thereby identifying the most
influential training samples and understanding how the model's behavior leads
to particular predictions. Understanding how individual training examples
influence a model's predictions is fundamental for machine learning
interpretability, data debugging, and model accountability. Influence
functions, originating from robust statistics, offer an efficient, first-order
approximation to estimate the impact of marginally upweighting or removing a
data point on a model's learned parameters and its subsequent predictions,
without the need for expensive retraining. This paper comprehensively reviews
the data attribution capability of influence functions in deep learning. We
discuss their theoretical foundations, recent algorithmic advances for
efficient inverse-Hessian-vector product estimation, and evaluate their
effectiveness for data attribution and mislabel detection. Finally,
highlighting current challenges and promising directions for unleashing the
huge potential of influence functions in large-scale, real-world deep learning
scenarios.

</details>


### [551] [Intrinsic training dynamics of deep neural networks](https://arxiv.org/abs/2508.07370)
*Sibylle Marcotte,Gabriel Peyré,Rémi Gribonval*

Main category: cs.LG

Relevance: 70.0

TL;DR: 论文研究了深度学习中的梯度流是否可以通过低维结构捕捉高维参数空间中的训练行为，提出了一个基于核包含的简单判据，并将其应用于ReLU网络和线性网络。


<details>
  <summary>Details</summary>
Motivation: 探索高维参数空间中梯度训练的隐含偏差，理解其是否可以通过低维结构简化。

Method: 提出基于核包含的判据，分析梯度流在低维变量上的动态特性，应用于ReLU网络和线性网络。

Result: 证明了ReLU网络和线性网络在特定初始化条件下可以实现低维动态表示。

Conclusion: 梯度流在高维空间中的行为可以通过低维结构简化，尤其在特定初始化条件下。

Abstract: A fundamental challenge in the theory of deep learning is to understand
whether gradient-based training in high-dimensional parameter spaces can be
captured by simpler, lower-dimensional structures, leading to so-called
implicit bias. As a stepping stone, we study when a gradient flow on a
high-dimensional variable $\theta$ implies an intrinsic gradient flow on a
lower-dimensional variable $z = \phi(\theta)$, for an architecture-related
function $\phi$. We express a so-called intrinsic dynamic property and show how
it is related to the study of conservation laws associated with the
factorization $\phi$. This leads to a simple criterion based on the inclusion
of kernels of linear maps which yields a necessary condition for this property
to hold. We then apply our theory to general ReLU networks of arbitrary depth
and show that, for any initialization, it is possible to rewrite the flow as an
intrinsic dynamic in a lower dimension that depends only on $z$ and the
initialization, when $\phi$ is the so-called path-lifting. In the case of
linear networks with $\phi$ the product of weight matrices, so-called balanced
initializations are also known to enable such a dimensionality reduction; we
generalize this result to a broader class of {\em relaxed balanced}
initializations, showing that, in certain configurations, these are the
\emph{only} initializations that ensure the intrinsic dynamic property.
Finally, for the linear neural ODE associated with the limit of infinitely deep
linear networks, with relaxed balanced initialization, we explicitly express
the corresponding intrinsic dynamics.

</details>


### [552] [Stackelberg Coupling of Online Representation Learning and Reinforcement Learning](https://arxiv.org/abs/2508.07452)
*Fernando Martinez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

Relevance: 70.0

TL;DR: SCORER框架通过博弈论动态结构化感知与控制网络的交互，提升强化学习性能，无需复杂辅助目标或架构。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏奖励信号下学习有效特征的挑战，避免复杂辅助目标或解耦带来的设计复杂性。

Method: 引入Stackelberg博弈动态，感知网络（领导者）学习特征以优化控制网络（追随者）的Bellman误差，采用两时间尺度算法近似均衡。

Result: 在标准DQN变体和基准任务上，SCORER提高了样本效率和最终性能。

Conclusion: 通过结构化感知与控制动态的算法设计，可实现性能提升，无需复杂辅助目标。

Abstract: Integrated, end-to-end learning of representations and policies remains a
cornerstone of deep reinforcement learning (RL). However, to address the
challenge of learning effective features from a sparse reward signal, recent
trends have shifted towards adding complex auxiliary objectives or fully
decoupling the two processes, often at the cost of increased design complexity.
This work proposes an alternative to both decoupling and naive end-to-end
learning, arguing that performance can be significantly improved by structuring
the interaction between distinct perception and control networks with a
principled, game-theoretic dynamic. We formalize this dynamic by introducing
the Stackelberg Coupled Representation and Reinforcement Learning (SCORER)
framework, which models the interaction between perception and control as a
Stackelberg game. The perception network (leader) strategically learns features
to benefit the control network (follower), whose own objective is to minimize
its Bellman error. We approximate the game's equilibrium with a practical
two-timescale algorithm. Applied to standard DQN variants on benchmark tasks,
SCORER improves sample efficiency and final performance. Our results show that
performance gains can be achieved through principled algorithmic design of the
perception-control dynamic, without requiring complex auxiliary objectives or
architectures.

</details>


### [553] [GLiClass: Generalist Lightweight Model for Sequence Classification Tasks](https://arxiv.org/abs/2508.07662)
*Ihor Stepanov,Mykhailo Shtopko,Dmytro Vodianytskyi,Oleksandr Lukashov,Alexander Yavorskyi,Mykyta Yaroshenko*

Main category: cs.LG

Relevance: 70.0

TL;DR: 论文提出GLiClass方法，基于GLiNER架构改进，用于序列分类任务，兼顾高效性和灵活性，支持零样本和小样本学习，并利用PPO优化多标签分类。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统需高效处理大规模数据分类任务，但现有方法（如生成式LLM、交叉编码器、嵌入方法）存在效率或灵活性不足的问题。

Method: 改进GLiNER架构用于序列分类，结合PPO优化多标签分类，支持数据稀疏或人类反馈训练。

Result: GLiClass在准确性和效率上与嵌入方法相当，同时保持零样本和小样本学习的灵活性。

Conclusion: GLiClass为动态分类需求提供高效灵活的解决方案，尤其适用于数据稀疏或复杂语义场景。

Abstract: Classification is one of the most widespread tasks in AI applications,
serving often as the first step in filtering, sorting, and categorizing data.
Since modern AI systems must handle large volumes of input data and early
pipeline stages can propagate errors downstream, achieving high efficiency and
accuracy is critical. Moreover, classification requirements can change
dynamically based on user needs, necessitating models with strong zero-shot
capabilities. While generative LLMs have become mainstream for zero-shot
classification due to their versatility, they suffer from inconsistent
instruction following and computational inefficiency. Cross-encoders, commonly
used as rerankers in RAG pipelines, face a different bottleneck: they must
process text-label pairs sequentially, significantly reducing efficiency with
large label sets. Embedding-based approaches offer good efficiency but struggle
with complex scenarios involving logical and semantic constraints. We propose
GLiClass, a novel method that adapts the GLiNER architecture for sequence
classification tasks. Our approach achieves strong accuracy and efficiency
comparable to embedding-based methods, while maintaining the flexibility needed
for zero-shot and few-shot learning scenarios. Additionally, we adapted
proximal policy optimization (PPO) for multi-label text classification,
enabling training classifiers in data-sparse conditions or from human feedback.

</details>


### [554] [Semantic-Enhanced Time-Series Forecasting via Large Language Models](https://arxiv.org/abs/2508.07697)
*Hao Liu,Chun Yang,Zhang xiaoxing,Xiaobin Zhu*

Main category: cs.LG

Relevance: 70.0

TL;DR: 提出了一种语义增强的大型语言模型（SE-LLM），通过嵌入时间序列的周期性和异常特征来增强语义表示，并设计了一个插件模块以同时建模长短期依赖关系，显著提升了时间序列分析的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究在将LLMs应用于时间序列预测时，仅关注模态对齐而忽略了语言知识与时间序列模式之间的本质差异，限制了语义表示能力。

Method: 提出了SE-LLM，通过嵌入时间序列的周期性和异常特征增强语义空间，并设计了一个插件模块以建模长短期依赖关系，同时冻结LLM并降低序列维度以减少计算消耗。

Result: 实验表明，SE-LLM在性能上优于现有最先进方法。

Conclusion: SE-LLM通过语义增强和依赖关系建模，显著提升了LLMs在时间序列分析中的表现。

Abstract: Time series forecasting plays a significant role in finance, energy,
meteorology, and IoT applications. Recent studies have leveraged the
generalization capabilities of large language models (LLMs) to adapt to time
series forecasting, achieving promising performance. However, existing studies
focus on token-level modal alignment, instead of bridging the intrinsic
modality gap between linguistic knowledge structures and time series data
patterns, greatly limiting the semantic representation. To address this issue,
we propose a novel Semantic-Enhanced LLM (SE-LLM) that explores the inherent
periodicity and anomalous characteristics of time series to embed into the
semantic space to enhance the token embedding. This process enhances the
interpretability of tokens for LLMs, thereby activating the potential of LLMs
for temporal sequence analysis. Moreover, existing Transformer-based LLMs excel
at capturing long-range dependencies but are weak at modeling short-term
anomalies in time-series data. Hence, we propose a plugin module embedded
within self-attention that models long-term and short-term dependencies to
effectively adapt LLMs to time-series analysis. Our approach freezes the LLM
and reduces the sequence dimensionality of tokens, greatly reducing
computational consumption. Experiments demonstrate the superiority performance
of our SE-LLM against the state-of-the-art (SOTA) methods.

</details>


### [555] [BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models](https://arxiv.org/abs/2508.08040)
*Maozhen Zhang,Mengnan Zhao,Bo Wang*

Main category: cs.LG

Relevance: 70.0

TL;DR: 论文提出了BadPromptFL，一种针对多模态对比模型中基于提示的联邦学习的后门攻击方法，揭示了提示聚合的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 研究基于提示的联邦学习在安全方面的不足，尤其是在多模态对比模型中的后门攻击风险。

Method: 通过联合优化本地后门触发器和提示嵌入，将中毒提示注入全局聚合过程，利用CLIP架构的上下文学习行为实现攻击。

Result: 攻击成功率超过90%，具有高隐蔽性和低客户端参与要求。

Conclusion: 提示聚合在联邦学习中存在严重的安全漏洞，需进一步研究其鲁棒性。

Abstract: Prompt-based tuning has emerged as a lightweight alternative to full
fine-tuning in large vision-language models, enabling efficient adaptation via
learned contextual prompts. This paradigm has recently been extended to
federated learning settings (e.g., PromptFL), where clients collaboratively
train prompts under data privacy constraints. However, the security
implications of prompt-based aggregation in federated multimodal learning
remain largely unexplored, leaving a critical attack surface unaddressed. In
this paper, we introduce \textbf{BadPromptFL}, the first backdoor attack
targeting prompt-based federated learning in multimodal contrastive models. In
BadPromptFL, compromised clients jointly optimize local backdoor triggers and
prompt embeddings, injecting poisoned prompts into the global aggregation
process. These prompts are then propagated to benign clients, enabling
universal backdoor activation at inference without modifying model parameters.
Leveraging the contextual learning behavior of CLIP-style architectures,
BadPromptFL achieves high attack success rates (e.g., \(>90\%\)) with minimal
visibility and limited client participation. Extensive experiments across
multiple datasets and aggregation protocols validate the effectiveness,
stealth, and generalizability of our attack, raising critical concerns about
the robustness of prompt-based federated learning in real-world deployments.

</details>


### [556] [FairFLRep: Fairness aware fault localization and repair of Deep Neural Networks](https://arxiv.org/abs/2508.08151)
*Moses Openja,Paolo Arcaini,Foutse Khomh,Fuyuki Ishikawa*

Main category: cs.LG

Relevance: 70.0

TL;DR: FairFLRep是一种自动化公平性感知的故障定位与修复技术，用于识别和修正DNN分类器中可能引发偏见的神经元。


<details>
  <summary>Details</summary>
Motivation: DNN在高风险决策应用中可能放大数据偏见，导致不公平行为。现有方法难以高效识别和修正这些偏见。

Method: 通过调整与敏感属性（如种族、性别）相关的神经元权重，FairFLRep分析输入输出关系以修正导致预测质量差异的神经元。

Result: 在多个数据集和模型上，FairFLRep在提升公平性同时保持准确性方面优于现有方法，且效率更高。

Conclusion: FairFLRep证明了在故障定位和修复阶段考虑公平性的重要性，并展示了其高效性。

Abstract: Deep neural networks (DNNs) are being utilized in various aspects of our
daily lives, including high-stakes decision-making applications that impact
individuals. However, these systems reflect and amplify bias from the data used
during training and testing, potentially resulting in biased behavior and
inaccurate decisions. For instance, having different misclassification rates
between white and black sub-populations. However, effectively and efficiently
identifying and correcting biased behavior in DNNs is a challenge. This paper
introduces FairFLRep, an automated fairness-aware fault localization and repair
technique that identifies and corrects potentially bias-inducing neurons in DNN
classifiers. FairFLRep focuses on adjusting neuron weights associated with
sensitive attributes, such as race or gender, that contribute to unfair
decisions. By analyzing the input-output relationships within the network,
FairFLRep corrects neurons responsible for disparities in predictive quality
parity. We evaluate FairFLRep on four image classification datasets using two
DNN classifiers, and four tabular datasets with a DNN model. The results show
that FairFLRep consistently outperforms existing methods in improving fairness
while preserving accuracy. An ablation study confirms the importance of
considering fairness during both fault localization and repair stages. Our
findings also show that FairFLRep is more efficient than the baseline
approaches in repairing the network.

</details>


### [557] [Role of Large Language Models and Retrieval-Augmented Generation for Accelerating Crystalline Material Discovery: A Systematic Review](https://arxiv.org/abs/2508.06691)
*Agada Joseph Oche,Arpan Biswas*

Main category: cond-mat.mtrl-sci

Relevance: 70.0

TL;DR: 该论文综述了大型语言模型（LLMs）和检索增强生成（RAG）在材料科学中的应用，包括加速材料发现、结构预测和文献挖掘等，并讨论了其性能、局限性和未来方向。


<details>
  <summary>Details</summary>
Motivation: LLMs和RAG在材料科学中具有潜力，可加速材料发现和减少实验成本，本文旨在系统回顾相关进展。

Method: 通过文献综述，分析LLMs和RAG在材料科学中的最新应用，包括晶体结构预测、缺陷分析和多模态检索等。

Result: LLMs与外部知识结合为材料科学提供了新能力，但仍存在局限性。

Conclusion: 未来需进一步优化LLMs在材料科学中的应用，以推动电子、光学和能源存储等领域的技术进步。

Abstract: Large language models (LLMs) have emerged as powerful tools for
knowledge-intensive tasks across domains. In materials science, to find novel
materials for various energy efficient devices for various real-world
applications, requires several time and cost expensive simulations and
experiments. In order to tune down the uncharted material search space,
minimizing the experimental cost, LLMs can play a bigger role to first provide
an accelerated search of promising known material candidates. Furthermore, the
integration of LLMs with domain-specific information via retrieval-augmented
generation (RAG) is poised to revolutionize how researchers predict materials
structures, analyze defects, discover novel compounds, and extract knowledge
from literature and databases. In motivation to the potentials of LLMs and RAG
in accelerating material discovery, this paper presents a broad and systematic
review to examine the recent advancements in applying LLMs and RAG to key
materials science problems. We survey state-of-the-art developments in crystal
structure prediction, defect analysis, materials discovery, literature mining,
database integration, and multi-modal retrieval, highlighting how combining
LLMs with external knowledge sources enables new capabilities. We discuss the
performance, limitations, and implications of these approaches, and outline
future directions for leveraging LLMs to accelerate materials research and
discovery for advancement in technologies in the area of electronics, optics,
biomedical, and energy storage.

</details>


### [558] [From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context](https://arxiv.org/abs/2508.07117)
*Peyman Baghershahi,Gregoire Fournier,Pranav Nyati,Sourav Medya*

Main category: cs.LG

Relevance: 60.0

TL;DR: LOGIC是一个轻量级框架，利用LLMs为GNN预测生成忠实且可解释的解释。


<details>
  <summary>Details</summary>
Motivation: GNNs在结构化数据上表现强大，但缺乏可解释性，尤其是在节点属性包含丰富自然语言时。

Method: LOGIC将GNN节点嵌入投影到LLM嵌入空间，构建混合提示，结合软提示和文本输入。

Result: 在四个真实TAG数据集上，LOGIC在忠实性和稀疏性之间取得了良好平衡，并显著提升了人类中心指标。

Conclusion: LOGIC为基于LLM的图学习可解释性设定了新方向。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning over
structured data, including text-attributed graphs, which are common in domains
such as citation networks, social platforms, and knowledge graphs. GNNs are not
inherently interpretable and thus, many explanation methods have been proposed.
However, existing explanation methods often struggle to generate interpretable,
fine-grained rationales, especially when node attributes include rich natural
language. In this work, we introduce LOGIC, a lightweight, post-hoc framework
that uses large language models (LLMs) to generate faithful and interpretable
explanations for GNN predictions. LOGIC projects GNN node embeddings into the
LLM embedding space and constructs hybrid prompts that interleave soft prompts
with textual inputs from the graph structure. This enables the LLM to reason
about GNN internal representations and produce natural language explanations
along with concise explanation subgraphs. Our experiments across four
real-world TAG datasets demonstrate that LOGIC achieves a favorable trade-off
between fidelity and sparsity, while significantly improving human-centric
metrics such as insightfulness. LOGIC sets a new direction for LLM-based
explainability in graph learning by aligning GNN internals with human
reasoning.

</details>


### [559] [Neural Bridge Processes](https://arxiv.org/abs/2508.07220)
*Jian Xu,Yican Liu,Qibin Zhao,John Paisley,Delu Zeng*

Main category: cs.LG

Relevance: 60.0

TL;DR: 提出了一种名为Neural Bridge Processes (NBPs)的新方法，用于建模随机函数，通过动态锚定输入x来增强扩散轨迹的耦合和终点一致性。


<details>
  <summary>Details</summary>
Motivation: 传统方法如高斯过程和神经过程在建模复杂、多模态目标分布时存在局限性，而神经扩散过程在输入耦合和终点语义匹配上表现不佳。

Method: 通过重新设计前向核使其显式依赖输入x，NBP强制约束路径严格终止于监督目标，提供更强的梯度信号和终点一致性。

Result: 在合成数据、EEG信号回归和图像回归任务中，NBP显著优于基线方法。

Conclusion: NBP通过DDPM风格的桥采样，在结构化预测任务中提升了性能和理论一致性。

Abstract: Learning stochastic functions from partially observed context-target pairs is
a fundamental problem in probabilistic modeling. Traditional models like
Gaussian Processes (GPs) face scalability issues with large datasets and assume
Gaussianity, limiting their applicability. While Neural Processes (NPs) offer
more flexibility, they struggle with capturing complex, multi-modal target
distributions. Neural Diffusion Processes (NDPs) enhance expressivity through a
learned diffusion process but rely solely on conditional signals in the
denoising network, resulting in weak input coupling from an unconditional
forward process and semantic mismatch at the diffusion endpoint. In this work,
we propose Neural Bridge Processes (NBPs), a novel method for modeling
stochastic functions where inputs x act as dynamic anchors for the entire
diffusion trajectory. By reformulating the forward kernel to explicitly depend
on x, NBP enforces a constrained path that strictly terminates at the
supervised target. This approach not only provides stronger gradient signals
but also guarantees endpoint coherence. We validate NBPs on synthetic data, EEG
signal regression and image regression tasks, achieving substantial
improvements over baselines. These results underscore the effectiveness of
DDPM-style bridge sampling in enhancing both performance and theoretical
consistency for structured prediction tasks.

</details>


### [560] [LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference](https://arxiv.org/abs/2508.07221)
*Po-Han Lee,Yu-Cheng Lin,Chan-Tung Ku,Chan Hsu,Pei-Cing Huang,Ping-Hsun Wu,Yihuang Kang*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种基于大语言模型（LLM）的代理方法，用于自动发现混杂变量和进行亚组分析，以提升因果机器学习在复杂环境中的效果。


<details>
  <summary>Details</summary>
Motivation: 观测数据中的混杂变量和结构偏差导致个体化治疗效果估计困难，现有因果ML方法在复杂环境中效果有限，且依赖专家标注成本高。

Method: 利用LLM代理模拟领域专家，自动发现混杂变量和亚组，减少人工依赖并保持可解释性。

Result: 在真实医疗数据集上，该方法缩小了置信区间并揭示了未识别的混杂偏差，提升了治疗效果估计的鲁棒性。

Conclusion: LLM代理为可扩展、可信赖且语义感知的因果推理提供了新途径。

Abstract: Estimating individualized treatment effects from observational data presents
a persistent challenge due to unmeasured confounding and structural bias.
Causal Machine Learning (causal ML) methods, such as causal trees and doubly
robust estimators, provide tools for estimating conditional average treatment
effects. These methods have limited effectiveness in complex real-world
environments due to the presence of latent confounders or those described in
unstructured formats. Moreover, reliance on domain experts for confounder
identification and rule interpretation introduces high annotation cost and
scalability concerns. In this work, we proposed Large Language Model-based
agents for automated confounder discovery and subgroup analysis that integrate
agents into the causal ML pipeline to simulate domain expertise. Our framework
systematically performs subgroup identification and confounding structure
discovery by leveraging the reasoning capabilities of LLM-based agents, which
reduces human dependency while preserving interpretability. Experiments on
real-world medical datasets show that our proposed approach enhances treatment
effect estimation robustness by narrowing confidence intervals and uncovering
unrecognized confounding biases. Our findings suggest that LLM-based agents
offer a promising path toward scalable, trustworthy, and semantically aware
causal inference.

</details>


### [561] [Policy Newton methods for Distortion Riskmetrics](https://arxiv.org/abs/2508.07249)
*Soumen Pachal,Mizhaan Prajit Maniyar,Prashanth L. A*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种基于强化学习的风险敏感控制方法，通过最大化失真风险度量（DRM）来找到最优策略，并提出了收敛到二阶稳定点的算法。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中风险敏感控制的问题，特别是在有限时间马尔可夫决策过程中优化DRM。

Method: 使用似然比方法推导DRM目标的策略Hessian定理，提出基于样本轨迹的Hessian估计器，并设计立方正则化策略牛顿算法。

Result: 算法收敛到DRM目标的二阶稳定点，样本复杂度为O(ε^{-3.5})，实验验证了理论结果。

Conclusion: 这是首个证明风险敏感目标收敛到二阶稳定点的工作，填补了现有文献的空白。

Abstract: We consider the problem of risk-sensitive control in a reinforcement learning
(RL) framework. In particular, we aim to find a risk-optimal policy by
maximizing the distortion riskmetric (DRM) of the discounted reward in a finite
horizon Markov decision process (MDP). DRMs are a rich class of risk measures
that include several well-known risk measures as special cases. We derive a
policy Hessian theorem for the DRM objective using the likelihood ratio method.
Using this result, we propose a natural DRM Hessian estimator from sample
trajectories of the underlying MDP. Next, we present a cubic-regularized policy
Newton algorithm for solving this problem in an on-policy RL setting using
estimates of the DRM gradient and Hessian. Our proposed algorithm is shown to
converge to an $\epsilon$-second-order stationary point ($\epsilon$-SOSP) of
the DRM objective, and this guarantee ensures the escaping of saddle points.
The sample complexity of our algorithms to find an $ \epsilon$-SOSP is
$\mathcal{O}(\epsilon^{-3.5})$. Our experiments validate the theoretical
findings. To the best of our knowledge, our is the first work to present
convergence to an $\epsilon$-SOSP of a risk-sensitive objective, while existing
works in the literature have either shown convergence to a first-order
stationary point of a risk-sensitive objective, or a SOSP of a risk-neutral
one.

</details>


### [562] [When Is Prior Knowledge Helpful? Exploring the Evaluation and Selection of Unsupervised Pretext Tasks from a Neuro-Symbolic Perspective](https://arxiv.org/abs/2508.07299)
*Lin-Han Jia,Si-Yu Han,Wen-Chao Hu,Jie-Jing Shao,Wen-Da Wei,Zhi Zhou,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种理论，将神经符号学习（Nesy）与半/自监督学习（SSL）统一起来，通过分析知识的可学习性、可靠性和完整性，预测无监督任务的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前无监督任务的选择缺乏理论依据，本文旨在通过统一Nesy和SSL的理论框架，提供一种预测无监督任务有效性的方法。

Method: 扩展Nesy理论至不可靠知识（假设）场景，提出三个理论指标（可学习性、可靠性、完整性），并设计预测方法。

Result: 实验验证了预测性能与实际性能的高度相关性，证明了理论和评估方法的有效性。

Conclusion: 本文为无监督任务选择提供了理论支持，改变了当前依赖启发式方法的现状。

Abstract: Neuro-symbolic (Nesy) learning improves the target task performance of models
by enabling them to satisfy knowledge, while semi/self-supervised learning
(SSL) improves the target task performance by designing unsupervised pretext
tasks for unlabeled data to make models satisfy corresponding assumptions. We
extend the Nesy theory based on reliable knowledge to the scenario of
unreliable knowledge (i.e., assumptions), thereby unifying the theoretical
frameworks of SSL and Nesy. Through rigorous theoretical analysis, we
demonstrate that, in theory, the impact of pretext tasks on target performance
hinges on three factors: knowledge learnability with respect to the model,
knowledge reliability with respect to the data, and knowledge completeness with
respect to the target. We further propose schemes to operationalize these
theoretical metrics, and thereby develop a method that can predict the
effectiveness of pretext tasks in advance. This will change the current status
quo in practical applications, where the selections of unsupervised tasks are
heuristic-based rather than theory-based, and it is difficult to evaluate the
rationality of unsupervised pretext task selection before testing the model on
the target task. In experiments, we verify a high correlation between the
predicted performance-estimated using minimal data-and the actual performance
achieved after large-scale semi-supervised or self-supervised learning, thus
confirming the validity of the theory and the effectiveness of the evaluation
method.

</details>


### [563] [Towards Unveiling Predictive Uncertainty Vulnerabilities in the Context of the Right to Be Forgotten](https://arxiv.org/abs/2508.07458)
*Wei Qian,Chenxu Zhao,Yangyi Li,Wenqian Ye,Mengdi Huai*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种针对预测不确定性的恶意遗忘攻击，填补了该领域的研究空白，并通过实验验证了攻击的有效性和现有防御的不足。


<details>
  <summary>Details</summary>
Motivation: 随着机器遗忘技术的发展，预测不确定性的安全性问题尚未被探索，论文旨在填补这一空白。

Method: 设计了针对预测不确定性的恶意遗忘攻击框架，包括优化方法和黑盒场景实验。

Result: 攻击在操纵预测不确定性上比传统标签误分类攻击更有效，现有防御措施无效。

Conclusion: 论文揭示了预测不确定性在恶意遗忘攻击下的脆弱性，为未来防御研究提供了方向。

Abstract: Currently, various uncertainty quantification methods have been proposed to
provide certainty and probability estimates for deep learning models' label
predictions. Meanwhile, with the growing demand for the right to be forgotten,
machine unlearning has been extensively studied as a means to remove the impact
of requested sensitive data from a pre-trained model without retraining the
model from scratch. However, the vulnerabilities of such generated predictive
uncertainties with regard to dedicated malicious unlearning attacks remain
unexplored. To bridge this gap, for the first time, we propose a new class of
malicious unlearning attacks against predictive uncertainties, where the
adversary aims to cause the desired manipulations of specific predictive
uncertainty results. We also design novel optimization frameworks for our
attacks and conduct extensive experiments, including black-box scenarios.
Notably, our extensive experiments show that our attacks are more effective in
manipulating predictive uncertainties than traditional attacks that focus on
label misclassifications, and existing defenses against conventional attacks
are ineffective against our attacks.

</details>


### [564] [FairDRL-ST: Disentangled Representation Learning for Fair Spatio-Temporal Mobility Prediction](https://arxiv.org/abs/2508.07518)
*Sichen Zhao,Wei Shao,Jeffrey Chan,Ziqi Xu,Flora Salim*

Main category: cs.LG

Relevance: 60.0

TL;DR: 提出了一种基于解耦表示学习的框架FairDRL-ST，用于解决时空预测中的公平性问题，特别关注移动需求预测。


<details>
  <summary>Details</summary>
Motivation: 时空预测方法在关键城市基础设施中的应用可能加剧社会经济不平等，因此需要关注公平性。

Method: 结合对抗学习和解耦表示学习，无监督地分离敏感信息属性。

Result: 在真实城市移动数据集上验证，能缩小公平性差距并保持预测性能。

Conclusion: FairDRL-ST在公平性和性能之间取得了平衡，适用于公共服务的AI部署。

Abstract: As deep spatio-temporal neural networks are increasingly utilised in urban
computing contexts, the deployment of such methods can have a direct impact on
users of critical urban infrastructure, such as public transport, emergency
services, and traffic management systems. While many spatio-temporal methods
focus on improving accuracy, fairness has recently gained attention due to
growing evidence that biased predictions in spatio-temporal applications can
disproportionately disadvantage certain demographic or geographic groups,
thereby reinforcing existing socioeconomic inequalities and undermining the
ethical deployment of AI in public services. In this paper, we propose a novel
framework, FairDRL-ST, based on disentangled representation learning, to
address fairness concerns in spatio-temporal prediction, with a particular
focus on mobility demand forecasting. By leveraging adversarial learning and
disentangled representation learning, our framework learns to separate
attributes that contain sensitive information. Unlike existing methods that
enforce fairness through supervised learning, which may lead to
overcompensation and degraded performance, our framework achieves fairness in
an unsupervised manner with minimal performance loss. We apply our framework to
real-world urban mobility datasets and demonstrate its ability to close
fairness gaps while delivering competitive predictive performance compared to
state-of-the-art fairness-aware methods.

</details>


### [565] [Attribution Explanations for Deep Neural Networks: A Theoretical Perspective](https://arxiv.org/abs/2508.07636)
*Huiqi Deng,Hongbin Pei,Quanshi Zhang,Mengnan Du*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文探讨了深度神经网络（DNNs）的归因解释方法的忠实性问题，总结了三个核心挑战，并提出了三个理论方向以解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 归因解释方法的忠实性问题影响了其可靠性和实用性，亟需理论上的统一和验证。

Method: 通过理论统一、理论基础和理论评估三个方向，系统分析和比较现有归因方法。

Result: 总结了现有理论进展，为归因方法的忠实性提供了理论基础和评估框架。

Conclusion: 论文为归因解释方法的理论发展提供了方向，并指出了未来研究的开放性问题。

Abstract: Attribution explanation is a typical approach for explaining deep neural
networks (DNNs), inferring an importance or contribution score for each input
variable to the final output. In recent years, numerous attribution methods
have been developed to explain DNNs. However, a persistent concern remains
unresolved, i.e., whether and which attribution methods faithfully reflect the
actual contribution of input variables to the decision-making process. The
faithfulness issue undermines the reliability and practical utility of
attribution explanations. We argue that these concerns stem from three core
challenges. First, difficulties arise in comparing attribution methods due to
their unstructured heterogeneity, differences in heuristics, formulations, and
implementations that lack a unified organization. Second, most methods lack
solid theoretical underpinnings, with their rationales remaining absent,
ambiguous, or unverified. Third, empirically evaluating faithfulness is
challenging without ground truth. Recent theoretical advances provide a
promising way to tackle these challenges, attracting increasing attention. We
summarize these developments, with emphasis on three key directions: (i)
Theoretical unification, which uncovers commonalities and differences among
methods, enabling systematic comparisons; (ii) Theoretical rationale,
clarifying the foundations of existing methods; (iii) Theoretical evaluation,
rigorously proving whether methods satisfy faithfulness principles. Beyond a
comprehensive review, we provide insights into how these studies help deepen
theoretical understanding, inform method selection, and inspire new attribution
methods. We conclude with a discussion of promising open problems for further
work.

</details>


### [566] [Detecting Mislabeled and Corrupted Data via Pointwise Mutual Information](https://arxiv.org/abs/2508.07713)
*Jinghan Yang,Jiayu Weng*

Main category: cs.LG

Relevance: 60.0

TL;DR: 提出了一种基于互信息的数据选择框架，用于处理混合噪声场景，通过量化输入与标签的统计依赖关系筛选低质量样本。


<details>
  <summary>Details</summary>
Motivation: 现实数据集中常存在标签和输入噪声，影响模型性能，需有效方法筛选高质量数据。

Method: 计算样本对整体互信息的点贡献，低贡献样本视为噪声或错误标签。

Result: 在MNIST数据集上验证，高互信息样本训练使分类准确率提升15%，且对良性输入修改鲁棒。

Conclusion: 该方法能有效过滤噪声数据，提升模型性能。

Abstract: Deep neural networks can memorize corrupted labels, making data quality
critical for model performance, yet real-world datasets are frequently
compromised by both label noise and input noise. This paper proposes a mutual
information-based framework for data selection under hybrid noise scenarios
that quantifies statistical dependencies between inputs and labels. We compute
each sample's pointwise contribution to the overall mutual information and find
that lower contributions indicate noisy or mislabeled instances. Empirical
validation on MNIST with different synthetic noise settings demonstrates that
the method effectively filters low-quality samples. Under label corruption,
training on high-MI samples improves classification accuracy by up to 15\%
compared to random sampling. Furthermore, the method exhibits robustness to
benign input modifications, preserving semantically valid data while filtering
truly corrupted samples.

</details>


### [567] [Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations](https://arxiv.org/abs/2508.07722)
*Pietro Talli,Federico Mason,Federico Chiariotti,Andrea Zanella*

Main category: cs.LG

Relevance: 60.0

TL;DR: 提出了一种名为HR3L的新架构，用于在非理想无线信道上训练远程RL代理，解决了传统RL在通信网络中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统RL代理在无线通信网络中因状态更新延迟或丢失而无法有效运行，现有解决方案计算负担大。

Method: HR3L架构包含编码环境信息的发射器和解码并执行动作的接收器，无需交换梯度信息。

Result: HR3L在样本效率和适应不同通信场景方面显著优于基线方法。

Conclusion: HR3L为远程RL训练提供了高效且适应性强的解决方案。

Abstract: In this work, we address the problem of training Reinforcement Learning (RL)
agents over communication networks. The RL paradigm requires the agent to
instantaneously perceive the state evolution to infer the effects of its
actions on the environment. This is impossible if the agent receives state
updates over lossy or delayed wireless systems and thus operates with partial
and intermittent information. In recent years, numerous frameworks have been
proposed to manage RL with imperfect feedback; however, they often offer
specific solutions with a substantial computational burden. To address these
limits, we propose a novel architecture, named Homomorphic Robust Remote
Reinforcement Learning (HR3L), that enables the training of remote RL agents
exchanging observations across a non-ideal wireless channel. HR3L considers two
units: the transmitter, which encodes meaningful representations of the
environment, and the receiver, which decodes these messages and performs
actions to maximize a reward signal. Importantly, HR3L does not require the
exchange of gradient information across the wireless channel, allowing for
quicker training and a lower communication overhead than state-of-the-art
solutions. Experimental results demonstrate that HR3L significantly outperforms
baseline methods in terms of sample efficiency and adapts to different
communication scenarios, including packet losses, delayed transmissions, and
capacity limitations.

</details>


### [568] [Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning](https://arxiv.org/abs/2508.07738)
*Jialu Zhou,Dianxi Shi,Shaowu Yang,Xinyu Wei,Mingyue Yang,Leqian Li,Mengzhu Wang,Chunping Qiu*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种名为TRGE的方法，通过动态扩展预训练模型和设计两级路由策略，解决了多领域持续学习中的灾难性遗忘和前瞻性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 多领域持续学习中，任务类别和分布的双重异质性导致灾难性遗忘和前瞻性遗忘问题，现有方法难以有效解决。

Method: TRGE方法动态扩展CLIP模型，为每个任务分配专家组，并设计两级路由策略（组内路由和组间路由）以优化任务协作。同时利用MLLM生成任务描述以识别任务标识符。

Result: 实验表明，TRGE在多种设置下优于其他先进方法，且参数效率更高。

Conclusion: TRGE通过动态扩展和路由策略，有效缓解了持续学习中的遗忘问题，提升了模型性能。

Abstract: Multi-Domain Continual Learning (MDCL) acquires knowledge from sequential
tasks with shifting class sets and distribution. Despite the
Parameter-Efficient Fine-Tuning (PEFT) methods can adapt for this dual
heterogeneity, they still suffer from catastrophic forgetting and forward
forgetting. To address these challenges, we propose a Two-Level Routing Grouped
Mixture-of-Experts (TRGE) method. Firstly, TRGE dynamically expands the
pre-trained CLIP model, assigning specific expert group for each task to
mitigate catastrophic forgetting. With the number of experts continually grows
in this process, TRGE maintains the static experts count within the group and
introduces the intra-group router to alleviate routing overfitting caused by
the increasing routing complexity. Meanwhile, we design an inter-group routing
policy based on task identifiers and task prototype distance, which dynamically
selects relevant expert groups and combines their outputs to enhance inter-task
collaboration. Secondly, to get the correct task identifiers, we leverage
Multimodal Large Language Models (MLLMs) which own powerful multimodal
comprehension capabilities to generate semantic task descriptions and recognize
the correct task identifier. Finally, to mitigate forward forgetting, we
dynamically fuse outputs for unseen samples from the frozen CLIP model and TRGE
adapter based on training progress, leveraging both pre-trained and learned
knowledge. Through extensive experiments across various settings, our method
outperforms other advanced methods with fewer trainable parameters.

</details>


### [569] [A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory](https://arxiv.org/abs/2508.07746)
*Fengdi Che*

Main category: cs.LG

Relevance: 60.0

TL;DR: 该综述探讨了离线强化学习的理论见解及其对算法设计的实际影响，分析了数据覆盖和函数表示条件、不可解案例及解决方案。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在理论和算法上进展迅速，但理论与实践的结合仍具挑战性。本文旨在通过理论直觉指导算法设计。

Method: 通过分析理论条件（如数据覆盖和函数表示）、不可解案例及解决方案，总结离线RL的可行条件。

Result: 明确了离线RL的局限性及可行条件，为算法设计提供了理论依据。

Conclusion: 理论条件不仅用于证明，也揭示了算法局限，需在条件不满足时寻找新方法。

Abstract: Offline reinforcement learning (RL) aims to optimize the return given a fixed
dataset of agent trajectories without additional interactions with the
environment. While algorithm development has progressed rapidly, significant
theoretical advances have also been made in understanding the fundamental
challenges of offline RL. However, bridging these theoretical insights with
practical algorithm design remains an ongoing challenge. In this survey, we
explore key intuitions derived from theoretical work and their implications for
offline RL algorithms.
  We begin by listing the conditions needed for the proofs, including function
representation and data coverage assumptions. Function representation
conditions tell us what to expect for generalization, and data coverage
assumptions describe the quality requirement of the data. We then examine
counterexamples, where offline RL is not solvable without an impractically
large amount of data. These cases highlight what cannot be achieved for all
algorithms and the inherent hardness of offline RL. Building on techniques to
mitigate these challenges, we discuss the conditions that are sufficient for
offline RL. These conditions are not merely assumptions for theoretical proofs,
but they also reveal the limitations of these algorithms and remind us to
search for novel solutions when the conditions cannot be satisfied.

</details>


### [570] [Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant](https://arxiv.org/abs/2508.07887)
*Sabrina Namazova,Alessandra Brondetta,Younes Strittmatter,Matthew Nassar,Sebastian Musslick*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文探讨了Centaur（一种基于LLM的参与者模拟器）在行为科学中的应用，评估其预测人类行为的准确性及生成行为的差异。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的参与者模拟器（如Centaur）可加速行为科学的实验设计和假设测试，类似于AlphaFold在化学中的作用。

Method: 评估Centaur在160个人类实验数据上的表现，分析其预测和生成行为的准确性。

Result: Centaur在预测准确性上表现良好，但生成行为与人类数据存在系统性差异。

Conclusion: Centaur虽在预测人类行为上迈出重要一步，但尚未达到可靠参与者模拟器的标准。

Abstract: Simulators have revolutionized scientific practice across the natural
sciences. By generating data that reliably approximate real-world phenomena,
they enable scientists to accelerate hypothesis testing and optimize
experimental designs. This is perhaps best illustrated by AlphaFold, a
Nobel-prize winning simulator in chemistry that predicts protein structures
from amino acid sequences, enabling rapid prototyping of molecular
interactions, drug targets, and protein functions. In the behavioral sciences,
a reliable participant simulator - a system capable of producing human-like
behavior across cognitive tasks - would represent a similarly transformative
advance. Recently, Binz et al. introduced Centaur, a large language model (LLM)
fine-tuned on human data from 160 experiments, proposing its use not only as a
model of cognition but also as a participant simulator for "in silico
prototyping of experimental studies", e.g., to advance automated cognitive
science. Here, we review the core criteria for a participant simulator and
assess how well Centaur meets them. Although Centaur demonstrates strong
predictive accuracy, its generative behavior - a critical criterion for a
participant simulator - systematically diverges from human data. This suggests
that, while Centaur is a significant step toward predicting human behavior, it
does not yet meet the standards of a reliable participant simulator or an
accurate model of cognition.

</details>


### [571] [On Understanding of the Dynamics of Model Capacity in Continual Learning](https://arxiv.org/abs/2508.08052)
*Supriyo Chakraborty,Krishnan Raghavan*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种称为CLEMC的指标，用于描述持续学习中稳定性与可塑性平衡的动态行为，并通过理论和实验验证了其非平稳性。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中的稳定性与可塑性平衡问题，探讨神经网络在不同任务分布下的表现能力。

Method: 提出CLEMC指标，建立差分方程建模任务、神经网络和优化过程的动态关系，并在多种架构上进行实验验证。

Result: 实验表明，无论架构或优化方法如何，神经网络对新任务的表示能力会随任务分布变化而下降。

Conclusion: CLEMC揭示了持续学习中有效容量的非平稳性，为未来研究提供了理论基础。

Abstract: The stability-plasticity dilemma, closely related to a neural network's (NN)
capacity-its ability to represent tasks-is a fundamental challenge in continual
learning (CL). Within this context, we introduce CL's effective model capacity
(CLEMC) that characterizes the dynamic behavior of the stability-plasticity
balance point. We develop a difference equation to model the evolution of the
interplay between the NN, task data, and optimization procedure. We then
leverage CLEMC to demonstrate that the effective capacity-and, by extension,
the stability-plasticity balance point is inherently non-stationary. We show
that regardless of the NN architecture or optimization method, a NN's ability
to represent new tasks diminishes when incoming task distributions differ from
previous ones. We conduct extensive experiments to support our theoretical
findings, spanning a range of architectures-from small feedforward network and
convolutional networks to medium-sized graph neural networks and
transformer-based large language models with millions of parameters.

</details>


### [572] [Unequal Uncertainty: Rethinking Algorithmic Interventions for Mitigating Discrimination from AI](https://arxiv.org/abs/2508.07872)
*Holli Sargeant,Mackenzie Jorgensen,Arina Shah,Adrian Weller,Umang Bhatt*

Main category: cs.CY

Relevance: 60.0

TL;DR: 论文分析了基于不确定性的AI预测干预措施（选择性弃权和选择性摩擦）的法律和伦理挑战，并通过案例研究展示了其潜在的歧视性影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决AI预测不确定性带来的法律和伦理问题，特别是在人类-AI协作中可能加剧的不公平现象。

Method: 通过两个案例研究（AI辅助信贷决策和内容审核），结合社会技术和法律分析，评估了选择性弃权和选择性摩擦的效果。

Result: 研究发现，基于不确定性的干预措施可能触发歧视性影响，但选择性摩擦更有利于公平和透明的决策。

Conclusion: 结论是选择性摩擦是一种更公平和可问责的AI辅助决策方法。

Abstract: Uncertainty in artificial intelligence (AI) predictions poses urgent legal
and ethical challenges for AI-assisted decision-making. We examine two
algorithmic interventions that act as guardrails for human-AI collaboration:
selective abstention, which withholds high-uncertainty predictions from human
decision-makers, and selective friction, which delivers those predictions
together with salient warnings or disclosures that slow the decision process.
Research has shown that selective abstention based on uncertainty can
inadvertently exacerbate disparities and disadvantage under-represented groups
that disproportionately receive uncertain predictions. In this paper, we
provide the first integrated socio-technical and legal analysis of
uncertainty-based algorithmic interventions. Through two case studies,
AI-assisted consumer credit decisions and AI-assisted content moderation, we
demonstrate how the seemingly neutral use of uncertainty thresholds can trigger
discriminatory impacts. We argue that, although both interventions pose risks
of unlawful discrimination under UK law, selective frictions offer a promising
pathway toward fairer and more accountable AI-assisted decision-making by
preserving transparency and encouraging more cautious human judgment.

</details>


### [573] [EFU: Enforcing Federated Unlearning via Functional Encryption](https://arxiv.org/abs/2508.07873)
*Samaneh Mohammadi,Vasileios Tsouvalas,Iraklis Symeonidis,Ali Balador,Tanir Ozcelebi,Francesco Flammini,Nirvana Meratnia*

Main category: cs.CR

Relevance: 60.0

TL;DR: EFU（Enforced Federated Unlearning）是一种加密强化的联邦遗忘框架，允许客户端在不暴露遗忘意图的情况下从协作模型中移除其数据影响。


<details>
  <summary>Details</summary>
Motivation: 现有联邦遗忘方法依赖服务器合作，可能泄露客户意图和身份，EFU旨在通过加密技术保护客户隐私和自主权。

Method: EFU利用功能加密绑定加密更新到特定聚合函数，防止服务器检测或跳过遗忘请求，并结合对抗样本和参数重要性正则化掩盖行为变化。

Result: 实验表明，EFU在遗忘数据上接近随机准确率，同时保持与完全重新训练相当的性能，且隐藏遗忘意图。

Conclusion: EFU支持任何客户端遗忘算法的安全、功能隐藏和可验证遗忘，适用于多种场景。

Abstract: Federated unlearning (FU) algorithms allow clients in federated settings to
exercise their ''right to be forgotten'' by removing the influence of their
data from a collaboratively trained model. Existing FU methods maintain data
privacy by performing unlearning locally on the client-side and sending
targeted updates to the server without exposing forgotten data; yet they often
rely on server-side cooperation, revealing the client's intent and identity
without enforcement guarantees - compromising autonomy and unlearning privacy.
In this work, we propose EFU (Enforced Federated Unlearning), a
cryptographically enforced FU framework that enables clients to initiate
unlearning while concealing its occurrence from the server. Specifically, EFU
leverages functional encryption to bind encrypted updates to specific
aggregation functions, ensuring the server can neither perform unauthorized
computations nor detect or skip unlearning requests. To further mask behavioral
and parameter shifts in the aggregated model, we incorporate auxiliary
unlearning losses based on adversarial examples and parameter importance
regularization. Extensive experiments show that EFU achieves near-random
accuracy on forgotten data while maintaining performance comparable to full
retraining across datasets and neural architectures - all while concealing
unlearning intent from the server. Furthermore, we demonstrate that EFU is
agnostic to the underlying unlearning algorithm, enabling secure,
function-hiding, and verifiable unlearning for any client-side FU mechanism
that issues targeted updates.

</details>


### [574] [Learning to Forget with Information Divergence Reweighted Objectives for Noisy Labels](https://arxiv.org/abs/2508.06622)
*Jeremiah Birrell,Reza Ebrahimi*

Main category: cs.LG

Relevance: 50.0

TL;DR: ANTIDOTE是一种针对噪声标签学习的新目标函数，通过信息散度邻域的松弛定义，并利用凸对偶性转化为对抗训练方法。它在减少噪声标签样本影响的同时，计算成本接近标准交叉熵损失。


<details>
  <summary>Details</summary>
Motivation: 解决训练数据中固有或由对手引入的噪声标签问题，提升模型在噪声环境下的鲁棒性。

Method: 通过信息散度邻域的松弛定义目标函数，利用凸对偶性转化为对抗训练方法。

Result: 在对称、非对称、人工标注和真实噪声标签环境下，ANTIDOTE优于同类方法，计算成本接近标准交叉熵损失。

Conclusion: ANTIDOTE是一种高效且鲁棒的噪声标签学习方法，适用于多种噪声场景。

Abstract: We introduce ANTIDOTE, a new class of objectives for learning under noisy
labels which are defined in terms of a relaxation over an
information-divergence neighborhood. Using convex duality, we provide a
reformulation as an adversarial training method that has similar computational
cost to training with standard cross-entropy loss. We show that our approach
adaptively reduces the influence of the samples with noisy labels during
learning, exhibiting a behavior that is analogous to forgetting those samples.
ANTIDOTE is effective in practical environments where label noise is inherent
in the training data or where an adversary can alter the training labels.
Extensive empirical evaluations on different levels of symmetric, asymmetric,
human annotation, and real-world label noise show that ANTIDOTE outperforms
leading comparable losses in the field and enjoys a time complexity that is
very close to that of the standard cross entropy loss.

</details>


### [575] [Sparse Probabilistic Graph Circuits](https://arxiv.org/abs/2508.07763)
*Martin Rektoris,Milan Papež,Václav Šmídl,Tomáš Pevný*

Main category: cs.LG

Relevance: 50.0

TL;DR: 论文提出了一种稀疏概率图电路（SPGCs），解决了传统深度生成模型（DGMs）在稀疏图上的计算复杂性问题，同时保持了精确推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统DGMs在图上具有高表达能力但计算复杂度高，而PGCs虽支持精确推理但复杂度仍为O(n²)。SPGCs旨在通过稀疏图表示降低复杂度至O(n + m)。

Method: 引入SPGCs，直接在稀疏图上操作，降低计算复杂度。在药物设计中验证其性能。

Result: SPGCs在保持精确推理的同时，提高了内存效率和推理速度，性能与不可行DGMs相当。

Conclusion: SPGCs为稀疏图提供了一种高效且可扩展的生成模型。

Abstract: Deep generative models (DGMs) for graphs achieve impressively high expressive
power thanks to very efficient and scalable neural networks. However, these
networks contain non-linearities that prevent analytical computation of many
standard probabilistic inference queries, i.e., these DGMs are considered
\emph{intractable}. While recently proposed Probabilistic Graph Circuits (PGCs)
address this issue by enabling \emph{tractable} probabilistic inference, they
operate on dense graph representations with $\mathcal{O}(n^2)$ complexity for
graphs with $n$ nodes and \emph{$m$ edges}. To address this scalability issue,
we introduce Sparse PGCs, a new class of tractable generative models that
operate directly on sparse graph representation, reducing the complexity to
$\mathcal{O}(n + m)$, which is particularly beneficial for $m \ll n^2$. In the
context of de novo drug design, we empirically demonstrate that SPGCs retain
exact inference capabilities, improve memory efficiency and inference speed,
and match the performance of intractable DGMs in key metrics.

</details>


### [576] [Communication-Learning Co-Design for Differentially Private Over-the-Air Federated Distillation](https://arxiv.org/abs/2508.06557)
*Zihao Hu,Jia Yan,Ying-Jun Angela Zhang*

Main category: cs.IT

Relevance: 50.0

TL;DR: 提出了一种基于差分隐私的无线联邦蒸馏框架，优化通信与学习的协同设计，提升隐私保护与学习效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习在大模型规模下通信效率低和隐私保护不足的问题。

Method: 利用多接入信道的叠加特性，设计差分隐私的无线联邦蒸馏框架，优化收发器设计和长期训练决策。

Result: 在降低通信开销的同时，实现了更好的学习-隐私权衡。

Conclusion: 该框架在隐私保护和通信效率上优于传统联邦学习方法。

Abstract: The ever-growing learning model size nowadays challenges the communication
efficiency and privacy preservation of the traditional federated learning (FL).
In this paper, we propose a novel differentially private (DP) over-the-air
federated distillation (FD) framework, where wireless devices (WDs)
periodically share noise-perturbed model outputs with the parameter server by
harnessing the superposition property of multi-access channels. Accordingly,
over-the-air FD enables the shared responsibility of the DP preservation on the
low-dimensional disclosed signals among WDs. We study the
communication-learning co-design problem in differentially private over-the-air
FD, aiming to maximize the learning convergence rate while meeting the transmit
power and DP requirements of WDs. The main challenge is rooted in the
intractable learning and privacy analysis in over-the-air FD, together with the
strong coupling among the decision variables spanning two timescales. To tackle
this problem, we first derive the analytical learning convergence rate and
privacy losses of WDs, based on which the optimal transceiver design per FD
round and long-term training rounds decision are obtained in the closed forms.
Numerical results demonstrate that the proposed differentially private
over-the-air FD approach achieves a better learning-privacy trade-off with
largely-reduced communication overhead than the conventional FL benchmarks.

</details>


### [577] [Hypergraph Neural Network with State Space Models for Node Classification](https://arxiv.org/abs/2508.06587)
*A. Quadir,M. Tanveer*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种新型超图神经网络HGMN，结合状态空间模型和角色感知表示，显著提升了节点分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统GNN主要关注节点间的邻接关系，忽略了角色特征的重要性，现有方法多为无监督且性能不足。

Method: HGMN通过超图构建技术建模高阶关系，结合角色和邻接表示，使用可学习的Mamba Transformer机制，并引入残差网络防止过平滑。

Result: 在多个数据集上，HGMN显著优于现有GNN方法，尤其在节点分类任务中表现突出。

Conclusion: HGMN通过有效融合角色特征和邻接信息，提供了更丰富的节点表示，适用于多种图学习任务。

Abstract: In recent years, graph neural networks (GNNs) have gained significant
attention for node classification tasks on graph-structured data. However,
traditional GNNs primarily focus on adjacency relationships between nodes,
often overlooking the rich role-based characteristics that are crucial for
learning more expressive node representations. Existing methods for capturing
role-based features are largely unsupervised and fail to achieve optimal
performance in downstream tasks. To address these limitations, we propose a
novel hypergraph neural network with state space model (HGMN) that effectively
integrates role-aware representations into GNNs and the state space model. HGMN
utilizes hypergraph construction techniques to model higher-order relationships
and combines role-based and adjacency-based representations through a learnable
mamba transformer mechanism. By leveraging two distinct hypergraph construction
methods-based on node degree and neighborhood levels, it strengthens the
connections among nodes with similar roles, enhancing the model's
representational power. Additionally, the inclusion of hypergraph convolution
layers enables the model to capture complex dependencies within hypergraph
structures. To mitigate the over-smoothing problem inherent in deep GNNs, we
incorporate a residual network, ensuring improved stability and better feature
propagation across layers. Extensive experiments conducted on one newly
introduced dataset and four benchmark datasets demonstrate the superiority of
HGMN. The model achieves significant performance improvements on node
classification tasks compared to state-of-the-art GNN methods. These results
highlight HGMN's ability to provide enriched node representations by
effectively embedding role-based features alongside adjacency information,
making it a versatile and powerful tool for a variety of graph-based learning
applications.

</details>


### [578] [Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning](https://arxiv.org/abs/2508.06588)
*Zian Zhai,Fan Li,Xingyu Tan,Xiaoyang Wang,Wenjie Zhang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文研究了图数据中向量量化（VQ）的代码本崩溃问题，提出了RGVQ框架，通过图拓扑和特征相似性作为正则化信号，提升代码本利用率和令牌多样性。


<details>
  <summary>Details</summary>
Motivation: 图数据中VQ的代码本崩溃问题限制了图令牌的表达能力和泛化性，但尚未被充分研究。

Method: 提出RGVQ框架，结合Gumbel-Softmax重参数化和结构感知对比正则化，优化代码本利用和令牌多样性。

Result: RGVQ显著提升了代码本利用率，并在多个下游任务中提升了性能。

Conclusion: RGVQ为图数据VQ提供了更高效和可迁移的令牌表示方法。

Abstract: Vector Quantization (VQ) has recently emerged as a promising approach for
learning discrete representations of graph-structured data. However, a
fundamental challenge, i.e., codebook collapse, remains underexplored in the
graph domain, significantly limiting the expressiveness and generalization of
graph tokens.In this paper, we present the first empirical study showing that
codebook collapse consistently occurs when applying VQ to graph data, even with
mitigation strategies proposed in vision or language domains. To understand why
graph VQ is particularly vulnerable to collapse, we provide a theoretical
analysis and identify two key factors: early assignment imbalances caused by
redundancy in graph features and structural patterns, and self-reinforcing
optimization loops in deterministic VQ. To address these issues, we propose
RGVQ, a novel framework that integrates graph topology and feature similarity
as explicit regularization signals to enhance codebook utilization and promote
token diversity. RGVQ introduces soft assignments via Gumbel-Softmax
reparameterization, ensuring that all codewords receive gradient updates. In
addition, RGVQ incorporates a structure-aware contrastive regularization to
penalize the token co-assignments among similar node pairs. Extensive
experiments demonstrate that RGVQ substantially improves codebook utilization
and consistently boosts the performance of state-of-the-art graph VQ backbones
across multiple downstream tasks, enabling more expressive and transferable
graph token representations.

</details>


### [579] [A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis](https://arxiv.org/abs/2508.06589)
*Xinglin Zhao,Yanwen Wang,Xiaobo Liu,Yanrong Hao,Rui Cao,Xin Wen*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种针对神经影像CAD系统的联邦学习框架，通过动态导航和元集成模块处理数据异质性和亚型混淆，显著提高了诊断准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决神经影像CAD系统中因小样本研究可重复性低和大规模数据集中亚型异质性导致的诊断挑战。

Method: 采用联邦学习框架，包括动态导航模块（基于潜在亚型表示路由样本）和元集成模块（整合异构局部模型的预测）。

Result: 在1300多名MDD患者和1100名健康对照的fMRI数据上测试，平均准确率达74.06%，显著优于传统方法。

Conclusion: 该框架通过处理数据异质性和亚型混淆，提升了神经影像CAD系统的可靠性和可重复性，具有临床应用潜力。

Abstract: Computer-aided diagnosis (CAD) systems play a crucial role in analyzing
neuroimaging data for neurological and psychiatric disorders. However,
small-sample studies suffer from low reproducibility, while large-scale
datasets introduce confounding heterogeneity due to multiple disease subtypes
being labeled under a single category. To address these challenges, we propose
a novel federated learning framework tailored for neuroimaging CAD systems. Our
approach includes a dynamic navigation module that routes samples to the most
suitable local models based on latent subtype representations, and a
meta-integration module that combines predictions from heterogeneous local
models into a unified diagnostic output. We evaluated our framework using a
comprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100
healthy controls across multiple study cohorts. Experimental results
demonstrate significant improvements in diagnostic accuracy and robustness
compared to traditional methods. Specifically, our framework achieved an
average accuracy of 74.06\% across all tested sites, showcasing its
effectiveness in handling subtype heterogeneity and enhancing model
generalizability. Ablation studies further confirmed the importance of both the
dynamic navigation and meta-integration modules in improving performance. By
addressing data heterogeneity and subtype confounding, our framework advances
reliable and reproducible neuroimaging CAD systems, offering significant
potential for personalized medicine and clinical decision-making in neurology
and psychiatry.

</details>


### [580] [Local Diffusion Models and Phases of Data Distributions](https://arxiv.org/abs/2508.06614)
*Fangjun Hu,Guangkuo Liu,Yifan Zhang,Xun Gao*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该论文提出了一种基于数据分布相位的视角，通过局部去噪器降低扩散模型的计算成本，并证明了局部去噪器在相位过渡时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现实数据（如图像）通常具有低维空间结构，但传统扩散模型忽略了这种局部结构，导致计算成本高昂。

Method: 定义了数据分布的相位概念，提出局部去噪器，并通过信息论边界和数值实验验证其有效性。

Result: 研究表明，在远离相位过渡点时，可以使用小型局部神经网络计算得分函数，仅在狭窄的相位过渡区间需要全局神经网络。

Conclusion: 该工作为扩散模型提供了更简单高效的架构设计思路，并启发了基于物理概念的神经网络研究。

Abstract: As a class of generative artificial intelligence frameworks inspired by
statistical physics, diffusion models have shown extraordinary performance in
synthesizing complicated data distributions through a denoising process
gradually guided by score functions. Real-life data, like images, is often
spatially structured in low-dimensional spaces. However, ordinary diffusion
models ignore this local structure and learn spatially global score functions,
which are often computationally expensive. In this work, we introduce a new
perspective on the phases of data distributions, which provides insight into
constructing local denoisers with reduced computational costs. We define two
distributions as belonging to the same data distribution phase if they can be
mutually connected via spatially local operations such as local denoisers.
Then, we show that the reverse denoising process consists of an early trivial
phase and a late data phase, sandwiching a rapid phase transition where local
denoisers must fail. To diagnose such phase transitions, we prove an
information-theoretic bound on the fidelity of local denoisers based on
conditional mutual information, and conduct numerical experiments in a
real-world dataset. This work suggests simpler and more efficient architectures
of diffusion models: far from the phase transition point, we can use small
local neural networks to compute the score function; global neural networks are
only necessary around the narrow time interval of phase transitions. This
result also opens up new directions for studying phases of data distributions,
the broader science of generative artificial intelligence, and guiding the
design of neural networks inspired by physics concepts.

</details>


### [581] [Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series](https://arxiv.org/abs/2508.06638)
*Muyan Anna Li,Aditi Gautam*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了两种自适应阈值框架（SCS和MACS），用于非平稳时间序列中的异常检测，显著提升了F1分数。


<details>
  <summary>Details</summary>
Motivation: 传统静态阈值在非平稳环境中容易失效，需要适应统计特性变化的动态方法。

Method: 基于统计在线学习和分段原理，设计了SCS和MACS两种自适应阈值框架。

Result: 在Wafer Manufacturing数据集上，F1分数显著优于传统方法。

Conclusion: 自适应阈值能实现可靠、可解释且及时的异常检测。

Abstract: As time series data become increasingly prevalent in domains such as
manufacturing, IT, and infrastructure monitoring, anomaly detection must adapt
to nonstationary environments where statistical properties shift over time.
Traditional static thresholds are easily rendered obsolete by regime shifts,
concept drift, or multi-scale changes. To address these challenges, we
introduce and empirically evaluate two novel adaptive thresholding frameworks:
Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence
Segments (MACS). Both leverage statistical online learning and segmentation
principles for local, contextually sensitive adaptation, maintaining guarantees
on false alarm rates even under evolving distributions. Our experiments across
Wafer Manufacturing benchmark datasets show significant F1-score improvement
compared to traditional percentile and rolling quantile approaches. This work
demonstrates that robust, statistically principled adaptive thresholds enable
reliable, interpretable, and timely detection of diverse real-world anomalies.

</details>


### [582] [Transferring Social Network Knowledge from Multiple GNN Teachers to Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.06663)
*Yuan-Hung Chao,Chia-Hsun Lu,Chih-Ya Shen*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出将KANs（Kolmogorov-Arnold Networks）集成到三种流行的GNN架构中，形成新模型KGAT、KSGC和KAPPNP，并通过多教师知识融合框架提升性能。实验显示新模型在节点分类任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: GNNs依赖图连接性，限制了可扩展性和效率。KANs具有强非线性表达能力和高效推理能力，因此探索其与GNN的结合潜力。

Method: 将KANs集成到GAT、SGC和APPNP中，形成KGAT、KSGC和KAPPNP，并采用多教师知识融合框架，将知识蒸馏到图无关的KAN学生模型中。

Result: 新模型在基准数据集上提升了节点分类准确率，知识融合方法显著提升了学生模型性能。

Conclusion: KANs能增强GNN的表达能力，并支持高效、无图推理。

Abstract: Graph Neural Networks (GNNs) have shown strong performance on
graph-structured data, but their reliance on graph connectivity often limits
scalability and efficiency. Kolmogorov-Arnold Networks (KANs), a recent
architecture with learnable univariate functions, offer strong nonlinear
expressiveness and efficient inference. In this work, we integrate KANs into
three popular GNN architectures-GAT, SGC, and APPNP-resulting in three new
models: KGAT, KSGC, and KAPPNP. We further adopt a multi-teacher knowledge
amalgamation framework, where knowledge from multiple KAN-based GNNs is
distilled into a graph-independent KAN student model. Experiments on benchmark
datasets show that the proposed models improve node classification accuracy,
and the knowledge amalgamation approach significantly boosts student model
performance. Our findings highlight the potential of KANs for enhancing GNN
expressiveness and for enabling efficient, graph-free inference.

</details>


### [583] [Watermarking Kolmogorov-Arnold Networks for Emerging Networked Applications via Activation Perturbation](https://arxiv.org/abs/2508.06676)
*Chia-Hsun Lu,Guan-Jhih Wu,Ya-Chi Ho,Chih-Ya Shen*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种针对Kolmogorov-Arnold Networks (KAN)的新型水印方法DCT-AW，通过离散余弦变换扰动激活输出，实现了任务无关性，并在实验中表现出对模型性能影响小且抗攻击性强。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习中知识产权保护的重要性增加，现有水印方法难以适应KAN的新型架构，因此需要一种专门针对KAN的水印方法。

Method: 利用KAN的可学习激活函数，通过离散余弦变换扰动激活输出嵌入水印。

Result: DCT-AW对模型性能影响小，且在抗微调、剪枝和剪枝后重训练等攻击中表现出优越的鲁棒性。

Conclusion: DCT-AW是一种适用于KAN的有效且鲁棒的水印方法。

Abstract: With the increasing importance of protecting intellectual property in machine
learning, watermarking techniques have gained significant attention. As
advanced models are increasingly deployed in domains such as social network
analysis, the need for robust model protection becomes even more critical.
While existing watermarking methods have demonstrated effectiveness for
conventional deep neural networks, they often fail to adapt to the novel
architecture, Kolmogorov-Arnold Networks (KAN), which feature learnable
activation functions. KAN holds strong potential for modeling complex
relationships in network-structured data. However, their unique design also
introduces new challenges for watermarking. Therefore, we propose a novel
watermarking method, Discrete Cosine Transform-based Activation Watermarking
(DCT-AW), tailored for KAN. Leveraging the learnable activation functions of
KAN, our method embeds watermarks by perturbing activation outputs using
discrete cosine transform, ensuring compatibility with diverse tasks and
achieving task independence. Experimental results demonstrate that DCT-AW has a
small impact on model performance and provides superior robustness against
various watermark removal attacks, including fine-tuning, pruning, and
retraining after pruning.

</details>


### [584] [Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select](https://arxiv.org/abs/2508.06692)
*Md. Akmol Masud,Md Abrar Jahin,Mahmud Hasan*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出HeteRo-Select框架，解决联邦学习中因数据异构性导致的训练不稳定问题，通过智能选择客户端子集提升性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据异构性导致训练不稳定，现有方法（如Oort）在后期训练中准确性下降显著。

Method: 提出HeteRo-Select框架，基于客户端有用性、公平性、更新速度和数据多样性进行评分，理论分析支持其在高异构性下的有效性。

Result: 在CIFAR-10数据集上，HeteRo-Select峰值准确率74.75%，最终准确率72.76%，稳定性下降仅1.99%，优于Oort。

Conclusion: HeteRo-Select为异构联邦学习提供了理论和实证支持的高效解决方案。

Abstract: Federated Learning (FL) is a machine learning technique that often suffers
from training instability due to the diverse nature of client data. Although
utility-based client selection methods like Oort are used to converge by
prioritizing high-loss clients, they frequently experience significant drops in
accuracy during later stages of training. We propose a theoretical
HeteRo-Select framework designed to maintain high performance and ensure
long-term training stability. We provide a theoretical analysis showing that
when client data is very different (high heterogeneity), choosing a smart
subset of client participation can reduce communication more effectively
compared to full participation. Our HeteRo-Select method uses a clear,
step-by-step scoring system that considers client usefulness, fairness, update
speed, and data variety. It also shows convergence guarantees under strong
regularization. Our experimental results on the CIFAR-10 dataset under
significant label skew ($\alpha=0.1$) support the theoretical findings. The
HeteRo-Select method performs better than existing approaches in terms of peak
accuracy, final accuracy, and training stability. Specifically, HeteRo-Select
achieves a peak accuracy of $74.75\%$, a final accuracy of $72.76\%$, and a
minimal stability drop of $1.99\%$. In contrast, Oort records a lower peak
accuracy of $73.98\%$, a final accuracy of $71.25\%$, and a larger stability
drop of $2.73\%$. The theoretical foundations and empirical performance in our
study make HeteRo-Select a reliable solution for real-world heterogeneous FL
problems.

</details>


### [585] [Analysis of Schedule-Free Nonconvex Optimization](https://arxiv.org/abs/2508.06743)
*Connor Brown*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种鲁棒的Lyapunov框架，用于分析Schedule-Free（SF）方法在非凸优化中的性能，证明了其无需依赖总步数T的超参数设置，并给出了多种收敛速率。


<details>
  <summary>Details</summary>
Motivation: 经典的一阶方法依赖于预先知道总步数T的步长调度，而SF方法通过插值Polyak-Ruppert平均和动量，实现了超参数与T无关的优化性能。然而，非凸分析仍有限或依赖强假设。本文旨在扩展SF方法的无T依赖保证至非凸优化。

Method: 引入鲁棒的Lyapunov框架，仅需L-平滑性和下界性假设，将SF分析简化为单步下降不等式。通过该框架，推导了多种收敛速率，并通过PEP实验验证。

Result: 在非凸设置下，证明了多种收敛速率：常数步长+PR平均为O(1/log T)，线性增长步长为O(log T/T)，多项式平均为O(T^{-(1-α)})。实验表明原始SF算法的O(1/log T)可能紧化为O(1/T)。

Conclusion: 本文扩展了SF方法的无T依赖保证至非凸优化，并提出了未来研究方向以实现最优非凸速率。

Abstract: First-order methods underpin most large-scale learning algorithms, yet their
classical convergence guarantees hinge on carefully scheduled step-sizes that
depend on the total horizon $T$, which is rarely known in advance. The
Schedule-Free (SF) method promises optimal performance with hyperparameters
that are independent of $T$ by interpolating between Polyak--Ruppert averaging
and momentum, but nonconvex analysis of SF has been limited or reliant on
strong global assumptions. We introduce a robust Lyapunov framework that, under
only $L$-smoothness and lower-boundedness, reduces SF analysis to a single-step
descent inequality. This yields horizon-agnostic bounds in the nonconvex
setting: $O(1/\log T)$ for constant step + PR averaging, $O(\log T/T)$ for a
linearly growing step-size, and a continuum of $O(T^{-(1-\alpha)})$ rates for
polynomial averaging. We complement these proofs with Performance Estimation
Problem (PEP) experiments that numerically validate our rates and suggest that
our $O(1/\log T)$ bound on the original nonconvex SF algorithm may tighten to
$O(1/T)$. Our work extends SF's horizon-free guarantees to smooth nonconvex
optimization and charts future directions for optimal nonconvex rates.

</details>


### [586] [PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems](https://arxiv.org/abs/2508.06767)
*Arman Dogru,R. Irem Bor-Yaliniz,Nimal Gamini Senarath*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出PANAMA算法，通过优先不对称性和网络感知的多智能体强化学习（MARL）优化多智能体路径规划（MAPF），提升自动化系统的数据共享和协调能力。


<details>
  <summary>Details</summary>
Motivation: 随着数字孪生（DTs）和自动化系统的发展，高效的数据共享框架和鲁棒算法变得至关重要。研究旨在解决网络感知决策与多智能体协调之间的鸿沟。

Method: 采用集中训练分散执行（CTDE）框架和异步执行者-学习者架构，提出PANAMA算法，结合优先不对称性和MARL优化MAPF。

Result: PANAMA在路径规划的准确性、速度和可扩展性上优于现有基准，并通过仿真验证了优化的数据共享策略。

Conclusion: PANAMA推动了数字孪生、无线网络和AI驱动自动化之间的协同，为复杂环境中的系统提供了鲁棒性。

Abstract: Digital Twins (DTs) are transforming industries through advanced data
processing and analysis, positioning the world of DTs, Digital World, as a
cornerstone of nextgeneration technologies including embodied AI. As robotics
and automated systems scale, efficient data-sharing frameworks and robust
algorithms become critical. We explore the pivotal role of data handling in
next-gen networks, focusing on dynamics between application and network
providers (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with
Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL)
based multi-agent path finding (MAPF). By adopting a Centralized Training with
Decentralized Execution (CTDE) framework and asynchronous actor-learner
architectures, PANAMA accelerates training while enabling autonomous task
execution by embodied AI. Our approach demonstrates superior pathfinding
performance in accuracy, speed, and scalability compared to existing
benchmarks. Through simulations, we highlight optimized data-sharing strategies
for scalable, automated systems, ensuring resilience in complex, real-world
environments. PANAMA bridges the gap between network-aware decision-making and
robust multi-agent coordination, advancing the synergy between DTs, wireless
networks, and AI-driven automation.

</details>


### [587] [Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning](https://arxiv.org/abs/2508.06784)
*Junjing Zheng,Chengliang Song,Weidong Jiang,Xinyu Zhang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种名为MA-NTAE的新型自监督学习方法，用于处理高维张量数据，解决了传统方法的维度灾难和非线性关系学习能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 高维张量数据在自监督学习中面临维度灾难和计算复杂度高的挑战，现有方法（如MLP-based AE和传统张量网络）在非线性关系学习和计算效率上表现不足。

Method: MA-NTAE通过非线性的Tucker分解框架和Pick-and-Unfold策略，实现了对高维张量的灵活编码，计算复杂度随张量阶数和维度线性增长。

Result: 实验表明，MA-NTAE在压缩和聚类任务中优于标准AE和现有张量网络，尤其在高阶高维张量上表现更显著。

Conclusion: MA-NTAE为高维张量数据的自监督学习提供了一种高效且灵活的方法。

Abstract: High-dimensional data, particularly in the form of high-order tensors,
presents a major challenge in self-supervised learning. While MLP-based
autoencoders (AE) are commonly employed, their dependence on flattening
operations exacerbates the curse of dimensionality, leading to excessively
large model sizes, high computational overhead, and challenging optimization
for deep structural feature capture. Although existing tensor networks
alleviate computational burdens through tensor decomposition techniques, most
exhibit limited capability in learning non-linear relationships. To overcome
these limitations, we introduce the Mode-Aware Non-linear Tucker Autoencoder
(MA-NTAE). MA-NTAE generalized classical Tucker decomposition to a non-linear
framework and employs a Pick-and-Unfold strategy, facilitating flexible
per-mode encoding of high-order tensors via recursive unfold-encode-fold
operations, effectively integrating tensor structural priors. Notably, MA-NTAE
exhibits linear growth in computational complexity with tensor order and
proportional growth with mode dimensions. Extensive experiments demonstrate
MA-NTAE's performance advantages over standard AE and current tensor networks
in compression and clustering tasks, which become increasingly pronounced for
higher-order, higher-dimensional tensors.

</details>


### [588] [Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities](https://arxiv.org/abs/2508.06800)
*Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种名为HARDY-MER的动态课程学习框架，用于解决多模态情感识别中缺失模态的问题，通过评估样本难度并动态调整训练重点，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 多模态情感识别中缺失模态是重要问题，现有方法因忽视样本间重建难度差异而表现不佳。

Method: 提出HARDY-MER框架，包括多视角难度评估机制和基于检索的动态课程学习策略。

Result: 在基准数据集上，HARDY-MER显著优于现有方法。

Conclusion: HARDY-MER通过动态调整训练重点，有效提升了模型对困难样本的处理能力。

Abstract: Missing modalities have recently emerged as a critical research direction in
multimodal emotion recognition (MER). Conventional approaches typically address
this issue through missing modality reconstruction. However, these methods fail
to account for variations in reconstruction difficulty across different
samples, consequently limiting the model's ability to handle hard samples
effectively. To overcome this limitation, we propose a novel Hardness-Aware
Dynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates
in two key stages: first, it estimates the hardness level of each sample, and
second, it strategically emphasizes hard samples during training to enhance
model performance on these challenging instances. Specifically, we first
introduce a Multi-view Hardness Evaluation mechanism that quantifies
reconstruction difficulty by considering both Direct Hardness (modality
reconstruction errors) and Indirect Hardness (cross-modal mutual information).
Meanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy
that dynamically adjusts the training curriculum by retrieving samples with
similar semantic information and balancing the learning focus between easy and
hard instances. Extensive experiments on benchmark datasets demonstrate that
HARDY-MER consistently outperforms existing methods in missing-modality
scenarios. Our code will be made publicly available at
https://github.com/HARDY-MER/HARDY-MER.

</details>


### [589] [QuiZSF: An efficient data-model interaction framework for zero-shot time-series forecasting](https://arxiv.org/abs/2508.06915)
*Shichao Ma,Zhengyang Zhou,Qihe Huang,Binwu Wang,Kuo Yang,Huan Li,Yang Wang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出QuiZSF框架，结合检索增强生成（RAG）与时间序列预训练模型（TSPMs），提升零样本时间序列预测（ZSF）性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统模型在数据稀缺场景（如领域迁移或极端条件）下ZSF的困难，并弥补TSPMs缺乏动态外部知识整合机制的不足。

Method: 1. 构建层次化树状ChronoRAG Base（CRB）存储和检索时间序列；2. 引入多粒度序列交互学习器（MSIL）提取特征；3. 开发双分支模型协作器（MCC）对齐检索知识与TSPMs（非LLM和LLM）。

Result: QuiZSF在75%（非LLM）和87.5%（LLM）的预测场景中排名Top1，同时保持高效内存和推理时间。

Conclusion: QuiZSF有效结合RAG与TSPMs，显著提升ZSF性能，尤其在数据稀缺场景。

Abstract: Time series forecasting has become increasingly important to empower diverse
applications with streaming data. Zero-shot time-series forecasting (ZSF),
particularly valuable in data-scarce scenarios, such as domain transfer or
forecasting under extreme conditions, is difficult for traditional models to
deal with. While time series pre-trained models (TSPMs) have demonstrated
strong performance in ZSF, they often lack mechanisms to dynamically
incorporate external knowledge. Fortunately, emerging retrieval-augmented
generation (RAG) offers a promising path for injecting such knowledge on
demand, yet they are rarely integrated with TSPMs. To leverage the strengths of
both worlds, we introduce RAG into TSPMs to enhance zero-shot time series
forecasting. In this paper, we propose QuiZSF (Quick Zero-Shot Time Series
Forecaster), a lightweight and modular framework that couples efficient
retrieval with representation learning and model adaptation for ZSF.
Specifically, we construct a hierarchical tree-structured ChronoRAG Base (CRB)
for scalable time-series storage and domain-aware retrieval, introduce a
Multi-grained Series Interaction Learner (MSIL) to extract fine- and
coarse-grained relational features, and develop a dual-branch Model Cooperation
Coherer (MCC) that aligns retrieved knowledge with two kinds of TSPMs: Non-LLM
based and LLM based. Compared with contemporary baselines, QuiZSF, with Non-LLM
based and LLM based TSPMs as base model, respectively, ranks Top1 in 75% and
87.5% of prediction settings, while maintaining high efficiency in memory and
inference time.

</details>


### [590] [Class Unbiasing for Generalization in Medical Diagnosis](https://arxiv.org/abs/2508.06943)
*Lishi Zuo,Man-Wai Mak,Lu Yi,Youzhi Tu*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种解决医学诊断中类别特征偏差和类别不平衡的方法，通过类别不平等损失和类别加权优化目标，提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 医学诊断中模型可能依赖与部分类别强相关的特征，导致偏差和泛化能力差。研究旨在同时解决类别不平衡和类别特征偏差。

Method: 提出类别不平等损失和类别加权分布鲁棒优化目标，优化模型训练。

Result: 实验证明类别特征偏差对模型性能有负面影响，所提方法有效缓解了偏差和不平衡，提升了泛化能力。

Conclusion: 该方法在合成和真实数据集上均有效，改善了模型的公平性和性能。

Abstract: Medical diagnosis might fail due to bias. In this work, we identified
class-feature bias, which refers to models' potential reliance on features that
are strongly correlated with only a subset of classes, leading to biased
performance and poor generalization on other classes. We aim to train a
class-unbiased model (Cls-unbias) that mitigates both class imbalance and
class-feature bias simultaneously. Specifically, we propose a class-wise
inequality loss which promotes equal contributions of classification loss from
positive-class and negative-class samples. We propose to optimize a class-wise
group distributionally robust optimization objective-a class-weighted training
objective that upweights underperforming classes-to enhance the effectiveness
of the inequality loss under class imbalance. Through synthetic and real-world
datasets, we empirically demonstrate that class-feature bias can negatively
impact model performance. Our proposed method effectively mitigates both
class-feature bias and class imbalance, thereby improving the model's
generalization ability.

</details>


### [591] [Can Multitask Learning Enhance Model Explainability?](https://arxiv.org/abs/2508.06966)
*Hiba Najjar,Bushra Alshbib,Andreas Dengel*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该研究通过多任务学习利用卫星数据的多模态性，以提升模型性能并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态学习网络复杂性导致的可解释性降低问题。

Method: 将某些模态作为额外预测目标，而非输入，利用卫星数据的丰富信息。

Result: 在数据稀缺时无需额外模态，性能与多模态基线相当或更好，预测误差可通过辅助任务解释。

Conclusion: 多任务学习在多模态卫星数据中有效提升性能和可解释性。

Abstract: Remote sensing provides satellite data in diverse types and formats. The
usage of multimodal learning networks exploits this diversity to improve model
performance, except that the complexity of such networks comes at the expense
of their interpretability. In this study, we explore how modalities can be
leveraged through multitask learning to intrinsically explain model behavior.
In particular, instead of additional inputs, we use certain modalities as
additional targets to be predicted along with the main task. The success of
this approach relies on the rich information content of satellite data, which
remains as input modalities. We show how this modeling context provides
numerous benefits: (1) in case of data scarcity, the additional modalities do
not need to be collected for model inference at deployment, (2) the model
performance remains comparable to the multimodal baseline performance, and in
some cases achieves better scores, (3) prediction errors in the main task can
be explained via the model behavior in the auxiliary task(s). We demonstrate
the efficiency of our approach on three datasets, including segmentation,
classification, and regression tasks. Code available at
git.opendfki.de/hiba.najjar/mtl_explainability/.

</details>


### [592] [UniMove: A Unified Model for Multi-city Human Mobility Prediction](https://arxiv.org/abs/2508.06986)
*Chonghua Han,Yuan Yuan,Yukun Liu,Jingtao Ding,Jie Feng,Yong Li*

Main category: cs.LG

Relevance: 40.0

TL;DR: UniMove是一个统一的多城市人类移动预测模型，通过双塔架构和MoE Transformer块解决城市间空间表示和移动模式异质性问题，显著提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 人类移动预测对城市规划等至关重要，但现有方法需为每个城市单独训练模型，缺乏统一性。UniMove旨在解决这一挑战。

Method: 采用轨迹-位置双塔架构，位置塔用于通用空间编码，轨迹塔用于序列建模，并设计MoE Transformer块自适应处理多样移动模式。

Result: 在多城市数据集上，UniMove通过联合训练和相互数据增强，预测准确性提升超过10.2%。

Conclusion: UniMove是实现人类移动预测基础模型的关键进展，具有统一架构优势。

Abstract: Human mobility prediction is vital for urban planning, transportation
optimization, and personalized services. However, the inherent randomness,
non-uniform time intervals, and complex patterns of human mobility, compounded
by the heterogeneity introduced by varying city structures, infrastructure, and
population densities, present significant challenges in modeling. Existing
solutions often require training separate models for each city due to distinct
spatial representations and geographic coverage. In this paper, we propose
UniMove, a unified model for multi-city human mobility prediction, addressing
two challenges: (1) constructing universal spatial representations for
effective token sharing across cities, and (2) modeling heterogeneous mobility
patterns from varying city characteristics. We propose a trajectory-location
dual-tower architecture, with a location tower for universal spatial encoding
and a trajectory tower for sequential mobility modeling. We also design MoE
Transformer blocks to adaptively select experts to handle diverse movement
patterns. Extensive experiments across multiple datasets from diverse cities
demonstrate that UniMove truly embodies the essence of a unified model. By
enabling joint training on multi-city data with mutual data enhancement, it
significantly improves mobility prediction accuracy by over 10.2\%. UniMove
represents a key advancement toward realizing a true foundational model with a
unified architecture for human mobility. We release the implementation at
https://github.com/tsinghua-fib-lab/UniMove/.

</details>


### [593] [A Comparative Study of Feature Selection in Tsetlin Machines](https://arxiv.org/abs/2508.06991)
*Vojtech Halenka,Ole-Christoffer Granmo,Lei Jiao,Per-Arne Andersen*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该论文研究了特征选择（FS）在Tsetlin机器（TM）中的应用，评估了多种FS技术，包括经典方法和后解释方法，并提出了一种基于TM内部评分的新方法。


<details>
  <summary>Details</summary>
Motivation: TM缺乏特征重要性评估工具，研究旨在填补这一空白，提升TM的模型解释性和实用性。

Method: 采用多种FS技术（如SHAP、LIME）和TM内部评分方法，在12个数据集上进行了基准测试。

Result: TM内部评分方法表现优异，同时利用子句解释性揭示特征交互模式，计算成本更低。

Conclusion: 研究为TM中的FS建立了首个全面基线，为开发专用解释技术奠定了基础。

Abstract: Feature Selection (FS) is crucial for improving model interpretability,
reducing complexity, and sometimes for enhancing accuracy. The recently
introduced Tsetlin machine (TM) offers interpretable clause-based learning, but
lacks established tools for estimating feature importance. In this paper, we
adapt and evaluate a range of FS techniques for TMs, including classical filter
and embedded methods as well as post-hoc explanation methods originally
developed for neural networks (e.g., SHAP and LIME) and a novel family of
embedded scorers derived from TM clause weights and Tsetlin automaton (TA)
states. We benchmark all methods across 12 datasets, using evaluation
protocols, like Remove and Retrain (ROAR) strategy and Remove and Debias
(ROAD), to assess causal impact. Our results show that TM-internal scorers not
only perform competitively but also exploit the interpretability of clauses to
reveal interacting feature patterns. Simpler TM-specific scorers achieve
similar accuracy retention at a fraction of the computational cost. This study
establishes the first comprehensive baseline for FS in TM and paves the way for
developing specialized TM-specific interpretability techniques.

</details>


### [594] [Conformal Set-based Human-AI Complementarity with Multiple Experts](https://arxiv.org/abs/2508.06997)
*Helbert Paat,Guohao Shen*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种基于预训练模型的多专家选择方法，利用贪心算法优化专家子集选择，提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 研究多专家场景下如何通过选择特定专家子集提升分类性能，弥补单专家研究的不足。

Method: 提出贪心算法，利用共形预测集选择实例相关的专家子集。

Result: 在CIFAR-10H和ImageNet-16H数据集上，贪心算法接近最优子集，显著提升分类性能。

Conclusion: 多专家选择和共形预测集的结合能有效提升分类任务性能。

Abstract: Decision support systems are designed to assist human experts in
classification tasks by providing conformal prediction sets derived from a
pre-trained model. This human-AI collaboration has demonstrated enhanced
classification performance compared to using either the model or the expert
independently. In this study, we focus on the selection of instance-specific
experts from a pool of multiple human experts, contrasting it with existing
research that typically focuses on single-expert scenarios. We characterize the
conditions under which multiple experts can benefit from the conformal sets.
With the insight that only certain experts may be relevant for each instance,
we explore the problem of subset selection and introduce a greedy algorithm
that utilizes conformal sets to identify the subset of expert predictions that
will be used in classifying an instance. This approach is shown to yield better
performance compared to naive methods for human subset selection. Based on real
expert predictions from the CIFAR-10H and ImageNet-16H datasets, our simulation
study indicates that our proposed greedy algorithm achieves near-optimal
subsets, resulting in improved classification performance among multiple
experts.

</details>


### [595] [TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations](https://arxiv.org/abs/2508.07016)
*Jianfei Wu,Wenmian Yang,Bingning Liu,Weijia Jia*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出TLCCSP框架，通过整合时间滞后交叉相关序列提升时间序列预测精度，使用SSDTW算法和对比学习编码器显著降低MSE。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型常忽略时间滞后交叉相关性，而这对捕捉复杂时序关系至关重要。

Method: 提出TLCCSP框架，结合SSDTW算法和对比学习编码器。

Result: 在天气、金融和房地产数据集上，SSDTW和CLE显著降低MSE，且计算时间减少99%。

Conclusion: TLCCSP框架有效提升预测精度并确保实时性。

Abstract: Time series forecasting is critical across various domains, such as weather,
finance and real estate forecasting, as accurate forecasts support informed
decision-making and risk mitigation. While recent deep learning models have
improved predictive capabilities, they often overlook time-lagged
cross-correlations between related sequences, which are crucial for capturing
complex temporal relationships. To address this, we propose the Time-Lagged
Cross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances
forecasting accuracy by effectively integrating time-lagged cross-correlated
sequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW)
algorithm to capture lagged correlations and a contrastive learning-based
encoder to efficiently approximate SSDTW distances.
  Experimental results on weather, finance and real estate time series datasets
demonstrate the effectiveness of our framework. On the weather dataset, SSDTW
reduces mean squared error (MSE) by 16.01% compared with single-sequence
methods, while the contrastive learning encoder (CLE) further decreases MSE by
17.88%. On the stock dataset, SSDTW achieves a 9.95% MSE reduction, and CLE
reduces it by 6.13%. For the real estate dataset, SSDTW and CLE reduce MSE by
21.29% and 8.62%, respectively. Additionally, the contrastive learning approach
decreases SSDTW computational time by approximately 99%, ensuring scalability
and real-time applicability across multiple time series forecasting tasks.

</details>


### [596] [From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving](https://arxiv.org/abs/2508.07029)
*Antonio Guillen-Perez*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种从静态专家数据中学习鲁棒驾驶策略的离线强化学习方法，通过对比行为克隆（BC）和保守Q学习（CQL），证明CQL在长期模拟中表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决行为克隆在自动驾驶中因闭环执行中的复合错误而表现脆弱的问题，探索离线强化学习在鲁棒策略学习中的潜力。

Method: 开发了一系列BC基线模型，包括基于Transformer的模型，并应用CQL算法优化策略，使用精心设计的奖励函数。

Result: 在Waymo Open Motion Dataset的1000个未见场景中，CQL代理的成功率比最强BC基线高3.2倍，碰撞率低7.4倍。

Conclusion: 离线强化学习方法（如CQL）对于从静态专家数据中学习鲁棒、长期的驾驶策略至关重要。

Abstract: Learning robust driving policies from large-scale, real-world datasets is a
central challenge in autonomous driving, as online data collection is often
unsafe and impractical. While Behavioral Cloning (BC) offers a straightforward
approach to imitation learning, policies trained with BC are notoriously
brittle and suffer from compounding errors in closed-loop execution. This work
presents a comprehensive pipeline and a comparative study to address this
limitation. We first develop a series of increasingly sophisticated BC
baselines, culminating in a Transformer-based model that operates on a
structured, entity-centric state representation. While this model achieves low
imitation loss, we show that it still fails in long-horizon simulations. We
then demonstrate that by applying a state-of-the-art Offline Reinforcement
Learning algorithm, Conservative Q-Learning (CQL), to the same data and
architecture, we can learn a significantly more robust policy. Using a
carefully engineered reward function, the CQL agent learns a conservative value
function that enables it to recover from minor errors and avoid
out-of-distribution states. In a large-scale evaluation on 1,000 unseen
scenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a
3.2x higher success rate and a 7.4x lower collision rate than the strongest BC
baseline, proving that an offline RL approach is critical for learning robust,
long-horizon driving policies from static expert data.

</details>


### [597] [Differentiable Adaptive Kalman Filtering via Optimal Transport](https://arxiv.org/abs/2508.07037)
*Yangguang He,Wenhao Li,Minzhe Li,Juan Zhang,Xiangfeng Wang,Bo Jin*

Main category: cs.LG

Relevance: 40.0

TL;DR: OTAKNet是一种在线解决方案，用于解决学习型自适应卡尔曼滤波中的噪声统计漂移问题，通过最优传输实现无需地面真值标签或重新训练的在线适应。


<details>
  <summary>Details</summary>
Motivation: 现实环境中，未观测到的噪声统计漂移会导致学习型方法性能显著下降，需要一种在线适应方案。

Method: OTAKNet通过一步预测测量似然建立状态估计与漂移之间的联系，并利用最优传输的几何感知成本和稳定梯度实现在线适应。

Result: 在合成和真实NCLT数据集上，OTAKNet表现优于传统模型自适应卡尔曼滤波和离线学习型滤波，尤其在训练数据有限时。

Conclusion: OTAKNet为解决噪声统计漂移问题提供了一种有效的在线适应方法，适用于实际部署场景。

Abstract: Learning-based filtering has demonstrated strong performance in non-linear
dynamical systems, particularly when the statistics of noise are unknown.
However, in real-world deployments, environmental factors, such as changing
wind conditions or electromagnetic interference, can induce unobserved
noise-statistics drift, leading to substantial degradation of learning-based
methods. To address this challenge, we propose OTAKNet, the first online
solution to noise-statistics drift within learning-based adaptive Kalman
filtering. Unlike existing learning-based methods that perform offline
fine-tuning using batch pointwise matching over entire trajectories, OTAKNet
establishes a connection between the state estimate and the drift via one-step
predictive measurement likelihood, and addresses it using optimal transport.
This leverages OT's geometry - aware cost and stable gradients to enable fully
online adaptation without ground truth labels or retraining. We compare OTAKNet
against classical model-based adaptive Kalman filtering and offline
learning-based filtering. The performance is demonstrated on both synthetic and
real-world NCLT datasets, particularly under limited training data.

</details>


### [598] [Improving Real-Time Concept Drift Detection using a Hybrid Transformer-Autoencoder Framework](https://arxiv.org/abs/2508.07085)
*N Harshit,K Mounvik*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种结合Transformer和Autoencoder的混合框架，用于在线检测概念漂移，并通过Trust Score方法提高敏感性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 概念漂移会显著降低模型性能，现有检测方法多为被动且对早期检测不敏感。

Method: 使用Transformer和Autoencoder建模时序动态，结合Trust Score（包括统计、重构、预测不确定性等指标）进行在线检测。

Result: 在航空乘客数据集中，该方法比基线方法更早、更敏感地检测到漂移，并减少了错误率和逻辑违规。

Conclusion: 开发了一个可靠的框架来实时监控概念漂移。

Abstract: In applied machine learning, concept drift, which is either gradual or abrupt
changes in data distribution, can significantly reduce model performance.
Typical detection methods,such as statistical tests or reconstruction-based
models,are generally reactive and not very sensitive to early detection. Our
study proposes a hybrid framework consisting of Transformers and Autoencoders
to model complex temporal dynamics and provide online drift detection. We
create a distinct Trust Score methodology, which includes signals on (1)
statistical and reconstruction-based drift metrics, more specifically, PSI,
JSD, Transformer-AE error, (2) prediction uncertainty, (3) rules violations,
and (4) trend of classifier error aligned with the combined metrics defined by
the Trust Score. Using a time sequenced airline passenger data set with
synthetic drift, our proposed model allows for a better detection of drift
using as a whole and at different detection thresholds for both sensitivity and
interpretability compared to baseline methods and provides a strong pipeline
for drift detection in real time for applied machine learning. We evaluated
performance using a time-sequenced airline passenger dataset having the
gradually injected stimulus of drift in expectations,e.g. permuted ticket
prices in later batches, broken into 10 time segments [1].In the data, our
results support that the Transformation-Autoencoder detected drift earlier and
with more sensitivity than the autoencoders commonly used in the literature,
and provided improved modeling over more error rates and logical violations.
Therefore, a robust framework was developed to reliably monitor concept drift.

</details>


### [599] [How Effectively Can Large Language Models Connect SNP Variants and ECG Phenotypes for Cardiovascular Risk Prediction?](https://arxiv.org/abs/2508.07127)
*Niranjana Arun Menon,Iqra Farooq,Yulong Li,Sara Ahmed,Yutong Xie,Muhammad Awais,Imran Razzak*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该论文探讨了如何通过微调大型语言模型（LLMs）来预测心血管疾病（CVD）风险，利用基因组数据生成疾病标签和临床推断。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病的预测具有挑战性，基因组数据的高维性和噪声问题使得提取有意义的信息困难。LLMs在生物序列分析中的成功应用激发了其在CVD预测中的潜力。

Method: 通过微调LLMs，将问题建模为链式推理（CoT）任务，从基因组数据中学习潜在生物学关系，并生成疾病标签和临床推断。

Result: 研究发现LLMs在心血管疾病早期检测和风险评估方面具有潜力，有助于推动个性化医疗的发展。

Conclusion: LLMs在心血管疾病预测和个性化医疗中展现出应用前景。

Abstract: Cardiovascular disease (CVD) prediction remains a tremendous challenge due to
its multifactorial etiology and global burden of morbidity and mortality.
Despite the growing availability of genomic and electrophysiological data,
extracting biologically meaningful insights from such high-dimensional, noisy,
and sparsely annotated datasets remains a non-trivial task. Recently, LLMs has
been applied effectively to predict structural variations in biological
sequences. In this work, we explore the potential of fine-tuned LLMs to predict
cardiac diseases and SNPs potentially leading to CVD risk using genetic markers
derived from high-throughput genomic profiling. We investigate the effect of
genetic patterns associated with cardiac conditions and evaluate how LLMs can
learn latent biological relationships from structured and semi-structured
genomic data obtained by mapping genetic aspects that are inherited from the
family tree. By framing the problem as a Chain of Thought (CoT) reasoning task,
the models are prompted to generate disease labels and articulate informed
clinical deductions across diverse patient profiles and phenotypes. The
findings highlight the promise of LLMs in contributing to early detection, risk
assessment, and ultimately, the advancement of personalized medicine in cardiac
care.

</details>


### [600] [Strategic Incentivization for Locally Differentially Private Federated Learning](https://arxiv.org/abs/2508.07138)
*Yashwant Krishna Pagoti,Arunesh Sinha,Shamik Sural*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文研究了联邦学习中的隐私-准确性权衡问题，提出了一种基于代币的激励机制，通过游戏理论分析优化噪声添加策略。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中因局部差分隐私（LDP）噪声添加导致的模型准确性下降问题，同时保护客户端隐私。

Method: 将隐私-准确性权衡建模为游戏，引入代币激励机制，客户端通过噪声程度获得代币，用于访问更新后的全局模型。

Result: 实验验证了激励机制的有效性，分析了不同参数对隐私和准确性的影响。

Conclusion: 代币激励机制在保护隐私的同时，显著提升了全局模型的准确性。

Abstract: In Federated Learning (FL), multiple clients jointly train a machine learning
model by sharing gradient information, instead of raw data, with a server over
multiple rounds. To address the possibility of information leakage in spite of
sharing only the gradients, Local Differential Privacy (LDP) is often used. In
LDP, clients add a selective amount of noise to the gradients before sending
the same to the server. Although such noise addition protects the privacy of
clients, it leads to a degradation in global model accuracy. In this paper, we
model this privacy-accuracy trade-off as a game, where the sever incentivizes
the clients to add a lower degree of noise for achieving higher accuracy, while
the clients attempt to preserve their privacy at the cost of a potential loss
in accuracy. A token based incentivization mechanism is introduced in which the
quantum of tokens credited to a client in an FL round is a function of the
degree of perturbation of its gradients. The client can later access a newly
updated global model only after acquiring enough tokens, which are to be
deducted from its balance. We identify the players, their actions and payoff,
and perform a strategic analysis of the game. Extensive experiments were
carried out to study the impact of different parameters.

</details>


### [601] [SGD Convergence under Stepsize Shrinkage in Low-Precision Training](https://arxiv.org/abs/2508.07142)
*Vincent-Daniel Yun*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文研究了低精度训练中梯度收缩对SGD收敛的影响，发现收缩会降低收敛速度并增加渐近误差。


<details>
  <summary>Details</summary>
Motivation: 低精度训练可减少计算和内存成本，但梯度量化和噪声会影响SGD的收敛行为，需深入研究其影响。

Method: 通过梯度收缩模型分析SGD的收敛性，量化梯度缩放和噪声对有效步长的影响。

Result: 低精度SGD仍收敛，但收敛速度降低且渐近误差增加，收缩因子q_min是关键因素。

Conclusion: 低精度训练通过梯度收缩减缓收敛，需权衡精度与效率。

Abstract: Low-precision training has become essential for reducing the computational
and memory costs of large-scale deep learning. However, quantization of
gradients introduces both magnitude shrinkage and additive noise, which can
alter the convergence behavior of stochastic gradient descent (SGD). In this
work, we study the convergence of SGD under a gradient shrinkage model, where
each stochastic gradient is scaled by a factor $q_k \in (0,1]$ and perturbed by
zero-mean quantization noise. We show that this shrinkage is equivalent to
replacing the nominal stepsize $\mu_k$ with an effective stepsize $\mu_k q_k$,
which slows convergence when $q_{\min} < 1$. Under standard smoothness and
bounded-variance assumptions, we prove that low-precision SGD still converges,
but at a reduced rate determined by $q_{\min}$, and with an increased
asymptotic error floor due to quantization noise. We theoretically analyze how
reduced numerical precision slows down training by modeling it as gradient
shrinkage in the standard SGD convergence framework.

</details>


### [602] [EDGE: A Theoretical Framework for Misconception-Aware Adaptive Learning](https://arxiv.org/abs/2508.07224)
*Ananda Prakash Verma*

Main category: cs.LG

Relevance: 40.0

TL;DR: EDGE是一个通用的、基于误解的自适应学习框架，包含评估、诊断、生成和练习四个阶段，结合了心理测量学、认知诊断和对比生成技术。


<details>
  <summary>Details</summary>
Motivation: 旨在通过自适应学习框架解决学习者的误解问题，提升学习效果。

Method: 结合IRT/Bayesian模型、认知诊断、对比生成和调度策略，提出EdgeScore和索引策略。

Result: 理论证明了EdgeScore的单调性和Lipschitz连续性，并展示了反事实项目在减少误解上的优势。

Conclusion: EDGE框架在理论上具有潜力，但需进一步实证研究验证。

Abstract: We present EDGE, a general-purpose, misconception-aware adaptive learning
framework composed of four stages: Evaluate (ability and state estimation),
Diagnose (posterior infer-ence of misconceptions), Generate (counterfactual
item synthesis), and Exercise (index-based retrieval scheduling). EDGE unifies
psychometrics (IRT/Bayesian state space models), cog-nitive diagnostics
(misconception discovery from distractor patterns and response latencies),
contrastive item generation (minimal perturbations that invalidate learner
shortcuts while pre-serving psychometric validity), and principled scheduling
(a restless bandit approximation to spaced retrieval). We formalize a composite
readiness metric, EdgeScore, prove its monotonicity and Lipschitz continuity,
and derive an index policy that is near-optimal under mild assumptions on
forgetting and learning gains. We further establish conditions under which
counterfactual items provably reduce the posterior probability of a targeted
misconception faster than standard practice. The paper focuses on theory and
implementable pseudocode; empirical study is left to future work.

</details>


### [603] [Causal Negative Sampling via Diffusion Model for Out-of-Distribution Recommendation](https://arxiv.org/abs/2508.07243)
*Chu Zhao,Eneng Yang,Yizhou Dang,Jianzhe Zhao,Guibing Guo,Xingwei Wang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种名为CNSDiff的新方法，通过扩散过程在潜在空间中合成负样本，避免了预定义候选池的偏差，并引入因果正则化以减少环境混杂因素的影响，从而提升推荐系统的OOD泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有启发式负采样方法可能因环境混杂因素（如曝光或流行度偏差）引入虚假硬负样本（FHNS），导致模型学习虚假相关性，影响泛化能力。

Method: 提出CNSDiff方法，通过条件扩散过程在潜在空间合成负样本，并加入因果正则化以减少混杂因素的影响。

Result: 在四种代表性分布偏移场景下，CNSDiff相比基线方法平均提升13.96%的性能。

Conclusion: CNSDiff有效减少了FHNS的生成，提升了推荐系统的OOD泛化能力。

Abstract: Heuristic negative sampling enhances recommendation performance by selecting
negative samples of varying hardness levels from predefined candidate pools to
guide the model toward learning more accurate decision boundaries. However, our
empirical and theoretical analyses reveal that unobserved environmental
confounders (e.g., exposure or popularity biases) in candidate pools may cause
heuristic sampling methods to introduce false hard negatives (FHNS). These
misleading samples can encourage the model to learn spurious correlations
induced by such confounders, ultimately compromising its generalization ability
under distribution shifts. To address this issue, we propose a novel method
named Causal Negative Sampling via Diffusion (CNSDiff). By synthesizing
negative samples in the latent space via a conditional diffusion process,
CNSDiff avoids the bias introduced by predefined candidate pools and thus
reduces the likelihood of generating FHNS. Moreover, it incorporates a causal
regularization term to explicitly mitigate the influence of environmental
confounders during the negative sampling process, leading to robust negatives
that promote out-of-distribution (OOD) generalization. Comprehensive
experiments under four representative distribution shift scenarios demonstrate
that CNSDiff achieves an average improvement of 13.96% across all evaluation
metrics compared to state-of-the-art baselines, verifying its effectiveness and
robustness in OOD recommendation tasks.

</details>


### [604] [Finite-Time Convergence Analysis of ODE-based Generative Models for Stochastic Interpolants](https://arxiv.org/abs/2508.07333)
*Yuhao Liu,Rui Hu,Yu Chen,Longbo Huang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该论文研究了随机插值在生成建模中的数值实现，分析了两种常用数值积分器（欧拉法和Heun法）的有限时间收敛性，并提出了优化计算效率的调度方案。


<details>
  <summary>Details</summary>
Motivation: 随机插值为数据分布间的连续变换提供了框架，但其数值实现的有限时间收敛性尚未充分研究。

Method: 通过分析随机插值构造的ODE数值实现，建立了欧拉法和Heun法的有限时间误差界限，并优化了迭代复杂度。

Result: 理论分析表明两种方法在有限时间内收敛，数值实验验证了误差界限和复杂度分析的准确性。

Conclusion: 该研究为随机插值在生成建模中的实际应用提供了理论支持和优化方案。

Abstract: Stochastic interpolants offer a robust framework for continuously
transforming samples between arbitrary data distributions, holding significant
promise for generative modeling. Despite their potential, rigorous finite-time
convergence guarantees for practical numerical schemes remain largely
unexplored. In this work, we address the finite-time convergence analysis of
numerical implementations for ordinary differential equations (ODEs) derived
from stochastic interpolants. Specifically, we establish novel finite-time
error bounds in total variation distance for two widely used numerical
integrators: the first-order forward Euler method and the second-order Heun's
method. Furthermore, our analysis on the iteration complexity of specific
stochastic interpolant constructions provides optimized schedules to enhance
computational efficiency. Our theoretical findings are corroborated by
numerical experiments, which validate the derived error bounds and complexity
analyses.

</details>


### [605] [Tight Bounds for Schrödinger Potential Estimation in Unpaired Image-to-Image Translation Problems](https://arxiv.org/abs/2508.07392)
*Nikita Puchkin,Denis Suchkov,Alexey Naumov,Denis Belomestny*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文研究了基于Schrödinger桥和随机最优控制理论的生成建模和无配对图像转换方法，通过Ornstein-Uhlenbeck过程估计Schrödinger势能，并推导了经验风险最小化器的泛化能力界限。


<details>
  <summary>Details</summary>
Motivation: 解决在仅能获取初始和最终分布样本的情况下，如何通过最优控制理论实现高效的生成建模和图像转换。

Method: 使用Ornstein-Uhlenbeck过程作为参考，估计Schrödinger势能，并通过Kullback-Leibler散度定义风险函数，推导泛化能力界限。

Result: 在有利场景下，几乎实现了快速收敛速率（忽略对数因子），并通过数值实验验证了方法的性能。

Conclusion: 提出的方法在生成建模和图像转换中具有潜力，尤其是在样本有限的情况下。

Abstract: Modern methods of generative modelling and unpaired image-to-image
translation based on Schr\"odinger bridges and stochastic optimal control
theory aim to transform an initial density to a target one in an optimal way.
In the present paper, we assume that we only have access to i.i.d. samples from
initial and final distributions. This makes our setup suitable for both
generative modelling and unpaired image-to-image translation. Relying on the
stochastic optimal control approach, we choose an Ornstein-Uhlenbeck process as
the reference one and estimate the corresponding Schr\"odinger potential.
Introducing a risk function as the Kullback-Leibler divergence between
couplings, we derive tight bounds on generalization ability of an empirical
risk minimizer in a class of Schr\"odinger potentials including Gaussian
mixtures. Thanks to the mixing properties of the Ornstein-Uhlenbeck process, we
almost achieve fast rates of convergence up to some logarithmic factors in
favourable scenarios. We also illustrate performance of the suggested approach
with numerical experiments.

</details>


### [606] [N-BEATS-MOE: N-BEATS with a Mixture-of-Experts Layer for Heterogeneous Time Series Forecasting](https://arxiv.org/abs/2508.07490)
*Ricardo Matos,Luis Roque,Vitor Cerqueira*

Main category: cs.LG

Relevance: 40.0

TL;DR: N-BEATS-MOE扩展了N-BEATS，引入混合专家层（MoE）和动态块加权策略，提升时间序列预测性能，并在异构数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 提升时间序列预测的适应性和可解释性，尤其是针对异构数据集。

Method: 基于N-BEATS架构，加入MoE层和动态块加权策略。

Result: 在12个基准数据集上表现优于其他方法，尤其在异构数据集上。

Conclusion: N-BEATS-MOE通过动态专家选择提升了性能和可解释性。

Abstract: Deep learning approaches are increasingly relevant for time series
forecasting tasks. Methods such as N-BEATS, which is built on stacks of
multilayer perceptrons (MLPs) blocks, have achieved state-of-the-art results on
benchmark datasets and competitions. N-BEATS is also more interpretable
relative to other deep learning approaches, as it decomposes forecasts into
different time series components, such as trend and seasonality. In this work,
we present N-BEATS-MOE, an extension of N-BEATS based on a Mixture-of-Experts
(MoE) layer. N-BEATS-MOE employs a dynamic block weighting strategy based on a
gating network which allows the model to better adapt to the characteristics of
each time series. We also hypothesize that the gating mechanism provides
additional interpretability by identifying which expert is most relevant for
each series. We evaluate our method across 12 benchmark datasets against
several approaches, achieving consistent improvements on several datasets,
especially those composed of heterogeneous time series.

</details>


### [607] [Enhancing Privacy in Decentralized Min-Max Optimization: A Differentially Private Approach](https://arxiv.org/abs/2508.07505)
*Yueyang Quan,Chang Wang,Shengjie Zhai,Minghong Fang,Zhuqing Liu*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种名为DPMixSGD的隐私保护算法，用于解决非凸分散式最小-最大优化问题，结合差分隐私技术，确保数据隐私同时不影响收敛性能。


<details>
  <summary>Details</summary>
Motivation: 分散式最小-最大优化中，模型更新共享可能导致隐私泄露，差分隐私虽能保护隐私，但噪声可能影响收敛性能，尤其在非凸场景下。

Method: 基于STORM算法，提出DPMixSGD，通过噪声注入保护隐私，并理论证明其对收敛性能影响有限。

Result: 实验验证了算法的有效性，噪声未显著影响收敛，同时提供了隐私保证的理论边界。

Conclusion: DPMixSGD在隐私保护和收敛性能间取得了平衡，适用于非凸分散式最小-最大优化问题。

Abstract: Decentralized min-max optimization allows multi-agent systems to
collaboratively solve global min-max optimization problems by facilitating the
exchange of model updates among neighboring agents, eliminating the need for a
central server. However, sharing model updates in such systems carry a risk of
exposing sensitive data to inference attacks, raising significant privacy
concerns. To mitigate these privacy risks, differential privacy (DP) has become
a widely adopted technique for safeguarding individual data. Despite its
advantages, implementing DP in decentralized min-max optimization poses
challenges, as the added noise can hinder convergence, particularly in
non-convex scenarios with complex agent interactions in min-max optimization
problems. In this work, we propose an algorithm called DPMixSGD (Differential
Private Minmax Hybrid Stochastic Gradient Descent), a novel privacy-preserving
algorithm specifically designed for non-convex decentralized min-max
optimization. Our method builds on the state-of-the-art STORM-based algorithm,
one of the fastest decentralized min-max solutions. We rigorously prove that
the noise added to local gradients does not significantly compromise
convergence performance, and we provide theoretical bounds to ensure privacy
guarantees. To validate our theoretical findings, we conduct extensive
experiments across various tasks and models, demonstrating the effectiveness of
our approach.

</details>


### [608] [Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning](https://arxiv.org/abs/2508.07536)
*Tasfiq E. Alam,Md Manjurul Ahsan,Shivakumar Raman*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于物理信息的多模态CNN模型，用于轴承故障分类，结合振动和电机电流信号，通过物理特征提取分支和损失函数提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决轴承故障分类在多变工况下因域偏移导致的性能下降问题，强调物理知识与数据驱动学习的结合。

Method: 采用多模态CNN架构，引入物理特征提取分支和物理损失函数，评估三种迁移学习策略。

Result: 在Paderborn和KAIST数据集上表现优异，最高准确率达98%，显著优于基线模型。

Conclusion: 物理信息与数据驱动结合可提升故障诊断的鲁棒性和泛化能力。

Abstract: Accurate and interpretable bearing fault classification is critical for
ensuring the reliability of rotating machinery, particularly under variable
operating conditions where domain shifts can significantly degrade model
performance. This study proposes a physics-informed multimodal convolutional
neural network (CNN) with a late fusion architecture, integrating vibration and
motor current signals alongside a dedicated physics-based feature extraction
branch. The model incorporates a novel physics-informed loss function that
penalizes physically implausible predictions based on characteristic bearing
fault frequencies - Ball Pass Frequency Outer (BPFO) and Ball Pass Frequency
Inner (BPFI) - derived from bearing geometry and shaft speed. Comprehensive
experiments on the Paderborn University dataset demonstrate that the proposed
physics-informed approach consistently outperforms a non-physics-informed
baseline, achieving higher accuracy, reduced false classifications, and
improved robustness across multiple data splits. To address performance
degradation under unseen operating conditions, three transfer learning (TL)
strategies - Target-Specific Fine-Tuning (TSFT), Layer-Wise Adaptation Strategy
(LAS), and Hybrid Feature Reuse (HFR) - are evaluated. Results show that LAS
yields the best generalization, with additional performance gains when combined
with physics-informed modeling. Validation on the KAIST bearing dataset
confirms the framework's cross-dataset applicability, achieving up to 98
percent accuracy. Statistical hypothesis testing further verifies significant
improvements (p < 0.01) in classification performance. The proposed framework
demonstrates the potential of integrating domain knowledge with data-driven
learning to achieve robust, interpretable, and generalizable fault diagnosis
for real-world industrial applications.

</details>


### [609] [Multimodal Remote Inference](https://arxiv.org/abs/2508.07555)
*Keyuan Zhang,Yin Sun,Bo Ji*

Main category: cs.LG

Relevance: 40.0

TL;DR: 研究多模态远程推理系统中的调度问题，提出一种基于索引的阈值策略以最小化推理误差，适用于非单调、非加性AoI函数和异构传输时间。


<details>
  <summary>Details</summary>
Motivation: 由于网络资源有限，多模态传感器数据的实时传输和推理面临挑战，需要优化调度策略以减少推理误差。

Method: 开发了一种基于索引的阈值策略，通过动态切换模态来优化AoI函数，适用于非单调、非加性AoI函数和异构传输时间。

Result: 策略显著优于轮询和随机策略，推理误差降低高达55%。

Conclusion: 优化任务导向的AoI函数可有效提升远程推理准确性。

Abstract: We consider a remote inference system with multiple modalities, where a
multimodal machine learning (ML) model performs real-time inference using
features collected from remote sensors. As sensor observations may change
dynamically over time, fresh features are critical for inference tasks.
However, timely delivering features from all modalities is often infeasible due
to limited network resources. To this end, we study a two-modality scheduling
problem to minimize the ML model's inference error, which is expressed as a
penalty function of AoI for both modalities. We develop an index-based
threshold policy and prove its optimality. Specifically, the scheduler switches
modalities when the current modality's index function exceeds a threshold. We
show that the two modalities share the same threshold, and both the index
functions and the threshold can be computed efficiently. The optimality of our
policy holds for (i) general AoI functions that are \emph{non-monotonic} and
\emph{non-additive} and (ii) \emph{heterogeneous} transmission times. Numerical
results show that our policy reduces inference error by up to 55% compared to
round-robin and uniform random policies, which are oblivious to the AoI-based
inference error function. Our results shed light on how to improve remote
inference accuracy by optimizing task-oriented AoI functions.

</details>


### [610] [Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo](https://arxiv.org/abs/2508.07631)
*Advait Parulekar,Litu Rout,Karthikeyan Shanmugam,Sanjay Shakkottai*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文研究了基于分数的生成模型中的后验采样问题，提出了一种在多项式时间内近似采样的方法，确保样本与测量和先验一致。


<details>
  <summary>Details</summary>
Motivation: 尽管后验采样在KL散度下是难解的，但实际应用中算法表现良好。本文旨在探索更通用的“倾斜”问题，而非局限于特定分布假设。

Method: 在最小假设下，提出了一种方法，能够从与噪声先验的KL散度和真实后验的Fisher散度同时接近的分布中采样。

Result: 首次在多项式时间内实现了（近似）后验采样的形式化结果。

Conclusion: 该方法为后验采样提供了理论支持，适用于图像超分辨率、风格化等任务。

Abstract: We study the problem of posterior sampling in the context of score based
generative models. We have a trained score network for a prior $p(x)$, a
measurement model $p(y|x)$, and are tasked with sampling from the posterior
$p(x|y)$. Prior work has shown this to be intractable in KL (in the worst case)
under well-accepted computational hardness assumptions. Despite this, popular
algorithms for tasks such as image super-resolution, stylization, and
reconstruction enjoy empirical success. Rather than establishing distributional
assumptions or restricted settings under which exact posterior sampling is
tractable, we view this as a more general "tilting" problem of biasing a
distribution towards a measurement. Under minimal assumptions, we show that one
can tractably sample from a distribution that is simultaneously close to the
posterior of a noised prior in KL divergence and the true posterior in Fisher
divergence. Intuitively, this combination ensures that the resulting sample is
consistent with both the measurement and the prior. To the best of our
knowledge these are the first formal results for (approximate) posterior
sampling in polynomial time.

</details>


### [611] [Extracting Complex Topology from Multivariate Functional Approximation: Contours, Jacobi Sets, and Ridge-Valley Graphs](https://arxiv.org/abs/2508.07637)
*Guanqun Ma,David Lenz,Hanqi Guo,Tom Peterka,Bei Wang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出首个直接从连续隐式模型（如MFA）中提取复杂拓扑特征的框架，无需离散化。


<details>
  <summary>Details</summary>
Motivation: 连续隐式模型在科学数据处理中具有潜力，但缺乏直接提取拓扑特征的方法。

Method: 基于多元函数逼近（MFA）模型，支持函数值和高阶导数查询，直接提取拓扑特征。

Result: 实现了从MFA模型中直接提取轮廓、雅可比集和脊谷图等拓扑特征。

Conclusion: 为连续隐式模型的拓扑数据分析和可视化奠定了基础。

Abstract: Implicit continuous models, such as functional models and implicit neural
networks, are an increasingly popular method for replacing discrete data
representations with continuous, high-order, and differentiable surrogates.
These models offer new perspectives on the storage, transfer, and analysis of
scientific data. In this paper, we introduce the first framework to directly
extract complex topological features -- contours, Jacobi sets, and ridge-valley
graphs -- from a type of continuous implicit model known as multivariate
functional approximation (MFA). MFA replaces discrete data with continuous
piecewise smooth functions. Given an MFA model as the input, our approach
enables direct extraction of complex topological features from the model,
without reverting to a discrete representation of the model. Our work is easily
generalizable to any continuous implicit model that supports the queries of
function values and high-order derivatives. Our work establishes the building
blocks for performing topological data analysis and visualization on implicit
continuous models.

</details>


### [612] [AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting](https://arxiv.org/abs/2508.07668)
*Hyobin Park,Jinwook Jung,Minseok Seo,Hyunsoo Choi,Deukjae Cho,Sekil Park,Dong-Geol Choi*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出AIS-LLM框架，结合时间序列AIS数据与大型语言模型（LLM），实现船舶轨迹预测、异常检测和碰撞风险评估的多任务处理。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理海事任务，难以全面考虑复杂海事情况，因此需要一种集成解决方案。

Method: AIS-LLM框架包括时间序列编码器、LLM提示编码器、跨模态对齐模块和LLM多任务解码器。

Result: 实验表明AIS-LLM在多个任务上优于现有方法，并能生成综合海事情况简报。

Conclusion: AIS-LLM为海事交通管理提供了更智能高效的解决方案。

Abstract: With the increase in maritime traffic and the mandatory implementation of the
Automatic Identification System (AIS), the importance and diversity of maritime
traffic analysis tasks based on AIS data, such as vessel trajectory prediction,
anomaly detection, and collision risk assessment, is rapidly growing. However,
existing approaches tend to address these tasks individually, making it
difficult to holistically consider complex maritime situations. To address this
limitation, we propose a novel framework, AIS-LLM, which integrates time-series
AIS data with a large language model (LLM). AIS-LLM consists of a Time-Series
Encoder for processing AIS sequences, an LLM-based Prompt Encoder, a
Cross-Modality Alignment Module for semantic alignment between time-series data
and textual prompts, and an LLM-based Multi-Task Decoder. This architecture
enables the simultaneous execution of three key tasks: trajectory prediction,
anomaly detection, and risk assessment of vessel collisions within a single
end-to-end system. Experimental results demonstrate that AIS-LLM outperforms
existing methods across individual tasks, validating its effectiveness.
Furthermore, by integratively analyzing task outputs to generate situation
summaries and briefings, AIS-LLM presents the potential for more intelligent
and efficient maritime traffic management.

</details>


### [613] [Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks](https://arxiv.org/abs/2508.07676)
*Chenchen Lin,Xuehe Wang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种社交感知的联邦学习隐私保护机制，通过多跳传播模型量化间接隐私泄漏，采用Stackelberg博弈优化激励策略，提升客户效用并降低服务器成本。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中社交网络引入的隐私外部性问题，即客户的隐私损失不仅取决于自身策略，还受他人决策影响。

Method: 设计了两阶段Stackelberg博弈，服务器优化激励政策，客户选择隐私预算；引入均值场估计器近似外部隐私风险。

Result: 实验证明该方法显著提升客户效用、降低服务器成本，同时保持模型性能。

Conclusion: 机制在客户激励视角下实现近似最优社会福利，优于社交无关基线和其他社交外部性方法。

Abstract: Federated learning (FL) enables collaborative model training across
decentralized clients without sharing local data, thereby enhancing privacy and
facilitating collaboration among clients connected via social networks.
However, these social connections introduce privacy externalities: a client's
privacy loss depends not only on its privacy protection strategy but also on
the privacy decisions of others, propagated through the network via multi-hop
interactions. In this work, we propose a socially-aware privacy-preserving FL
mechanism that systematically quantifies indirect privacy leakage through a
multi-hop propagation model. We formulate the server-client interaction as a
two-stage Stackelberg game, where the server, as the leader, optimizes
incentive policies, and clients, as followers, strategically select their
privacy budgets, which determine their privacy-preserving levels by controlling
the magnitude of added noise. To mitigate information asymmetry in networked
privacy estimation, we introduce a mean-field estimator to approximate the
average external privacy risk. We theoretically prove the existence and
convergence of the fixed point of the mean-field estimator and derive
closed-form expressions for the Stackelberg Nash Equilibrium. Despite being
designed from a client-centric incentive perspective, our mechanism achieves
approximately-optimal social welfare, as revealed by Price of Anarchy (PoA)
analysis. Experiments on diverse datasets demonstrate that our approach
significantly improves client utilities and reduces server costs while
maintaining model performance, outperforming both Social-Agnostic (SA)
baselines and methods that account for social externalities.

</details>


### [614] [MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation](https://arxiv.org/abs/2508.07681)
*Yooseok Lim,ByoungJun Jeon,Seong-A Park,Jisoo Lee,Sae Won Choi,Chang Wook Jeong,Ho-Geol Ryu,Hongyeol Lee,Hyun-Lim Yang*

Main category: cs.LG

Relevance: 40.0

TL;DR: MORE-CLEAR框架利用LLMs从临床笔记中提取语义信息，结合多模态数据提升脓毒症管理的强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 脓毒症早期检测和管理至关重要，现有RL方法依赖结构化数据，缺乏对患者全面状态的理解。

Method: 使用预训练LLMs提取临床笔记的语义表示，结合门控融合和跨模态注意力动态整合多模态数据。

Result: 在公开和私有数据集上验证，MORE-CLEAR显著提升生存率和策略性能。

Conclusion: 首次将LLMs用于多模态离线RL，提升医疗应用中的状态表示，有望优化脓毒症管理。

Abstract: Sepsis, a life-threatening inflammatory response to infection, causes organ
dysfunction, making early detection and optimal management critical. Previous
reinforcement learning (RL) approaches to sepsis management rely primarily on
structured data, such as lab results or vital signs, and on a dearth of a
comprehensive understanding of the patient's condition. In this work, we
propose a Multimodal Offline REinforcement learning for Clinical notes
Leveraged Enhanced stAte Representation (MORE-CLEAR) framework for sepsis
control in intensive care units. MORE-CLEAR employs pre-trained large-scale
language models (LLMs) to facilitate the extraction of rich semantic
representations from clinical notes, preserving clinical context and improving
patient state representation. Gated fusion and cross-modal attention allow
dynamic weight adjustment in the context of time and the effective integration
of multimodal data. Extensive cross-validation using two public (MIMIC-III and
MIMIC-IV) and one private dataset demonstrates that MORE-CLEAR significantly
improves estimated survival rate and policy performance compared to
single-modal RL approaches. To our knowledge, this is the first to leverage LLM
capabilities within a multimodal offline RL for better state representation in
medical applications. This approach can potentially expedite the treatment and
management of sepsis by enabling reinforcement learning models to propose
enhanced actions based on a more comprehensive understanding of patient
conditions.

</details>


### [615] [Energy Consumption in Parallel Neural Network Training](https://arxiv.org/abs/2508.07706)
*Philipp Huber,David Li,Juan Pedro Gutiérrez Hermosillo Muriedas,Deifilia Kieckhefen,Markus Götz,Achim Streit,Charlotte Debus*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文研究了数据并行训练中并行化参数对能源消耗的影响，发现能源消耗与GPU小时数近似线性相关，但具体比例因模型和硬件而异。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络训练对计算资源需求的增加，能源消耗问题日益突出，但并行化对能源消耗的影响尚未充分研究。

Method: 通过ResNet50和FourCastNet的数据并行训练实验，评估GPU数量、全局批次大小和本地批次大小对性能、训练时间和能源消耗的影响。

Result: 能源消耗与GPU小时数近似线性相关，但具体比例因模型和硬件而异，且受每GPU小时的样本和梯度更新数量影响。

Conclusion: 研究揭示了神经网络训练扩展与能源消耗的复杂关系，为可持续AI研究提供了参考。

Abstract: The increasing demand for computational resources of training neural networks
leads to a concerning growth in energy consumption. While parallelization has
enabled upscaling model and dataset sizes and accelerated training, its impact
on energy consumption is often overlooked. To close this research gap, we
conducted scaling experiments for data-parallel training of two models,
ResNet50 and FourCastNet, and evaluated the impact of parallelization
parameters, i.e., GPU count, global batch size, and local batch size, on
predictive performance, training time, and energy consumption. We show that
energy consumption scales approximately linearly with the consumed resources,
i.e., GPU hours; however, the respective scaling factor differs substantially
between distinct model trainings and hardware, and is systematically influenced
by the number of samples and gradient updates per GPU hour. Our results shed
light on the complex interplay of scaling up neural network training and can
inform future developments towards more sustainable AI research.

</details>


### [616] [Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer](https://arxiv.org/abs/2508.07710)
*Jingya Wang,Xin Deng,Wenjie Wei,Dehao Zhang,Shuai Wang,Qian Sun,Jieyuan Zhang,Hanwen Liu,Ning Xie,Malu Zhang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种针对Transformer架构的高性能、无需训练的ANN-to-SNN转换框架，通过MBE神经元高效逼近非线性操作，实现低延迟且接近无损的转换精度。


<details>
  <summary>Details</summary>
Motivation: 解决现有ANN-to-SNN转换方法在处理Transformer非线性操作和额外微调需求上的局限性。

Method: 引入Multi-basis Exponential Decay (MBE)神经元，采用指数衰减策略和多基编码方法，无需修改预训练ANN的权重。

Result: 在多种任务（CV、NLU、NLG）和主流Transformer架构（ViT、RoBERTa、GPT-2）上实现接近无损的转换精度和显著降低的延迟。

Conclusion: 为Spiking Transformer的高效和可扩展部署提供了可行方案。

Abstract: Leveraging the event-driven paradigm, Spiking Neural Networks (SNNs) offer a
promising approach for constructing energy-efficient Transformer architectures.
Compared to directly trained Spiking Transformers, ANN-to-SNN conversion
methods bypass the high training costs. However, existing methods still suffer
from notable limitations, failing to effectively handle nonlinear operations in
Transformer architectures and requiring additional fine-tuning processes for
pre-trained ANNs. To address these issues, we propose a high-performance and
training-free ANN-to-SNN conversion framework tailored for Transformer
architectures. Specifically, we introduce a Multi-basis Exponential Decay (MBE)
neuron, which employs an exponential decay strategy and multi-basis encoding
method to efficiently approximate various nonlinear operations. It removes the
requirement for weight modifications in pre-trained ANNs. Extensive experiments
across diverse tasks (CV, NLU, NLG) and mainstream Transformer architectures
(ViT, RoBERTa, GPT-2) demonstrate that our method achieves near-lossless
conversion accuracy with significantly lower latency. This provides a promising
pathway for the efficient and scalable deployment of Spiking Transformers in
real-world applications.

</details>


### [617] [Score Augmentation for Diffusion Models](https://arxiv.org/abs/2508.07926)
*Liang Hou,Yuan Gao,Boyuan Jiang,Xin Tao,Qi Yan,Renjie Liao,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种名为ScoreAug的新型数据增强框架，专门针对扩散模型在数据有限情况下的过拟合问题。通过将变换应用于噪声数据而非干净数据，并与去噪机制对齐，ScoreAug实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成建模中表现出色，但在数据有限时容易过拟合。为解决这一问题，作者提出了ScoreAug。

Method: ScoreAug在噪声数据上应用变换，要求去噪器预测原始目标的增强，从而建立等变学习目标。

Result: 在多个基准测试中，ScoreAug显著提升了性能，有效缓解了过拟合，且与传统数据增强方法结合效果更佳。

Conclusion: ScoreAug是一种有效的扩散模型数据增强方法，能够解决过拟合问题并提升性能。

Abstract: Diffusion models have achieved remarkable success in generative modeling.
However, this study confirms the existence of overfitting in diffusion model
training, particularly in data-limited regimes. To address this challenge, we
propose Score Augmentation (ScoreAug), a novel data augmentation framework
specifically designed for diffusion models. Unlike conventional augmentation
approaches that operate on clean data, ScoreAug applies transformations to
noisy data, aligning with the inherent denoising mechanism of diffusion.
Crucially, ScoreAug further requires the denoiser to predict the augmentation
of the original target. This design establishes an equivariant learning
objective, enabling the denoiser to learn scores across varied denoising
spaces, thereby realizing what we term score augmentation. We also
theoretically analyze the relationship between scores in different spaces under
general transformations. In experiments, we extensively validate ScoreAug on
multiple benchmarks including CIFAR-10, FFHQ, AFHQv2, and ImageNet, with
results demonstrating significant performance improvements over baselines.
Notably, ScoreAug effectively mitigates overfitting across diverse scenarios,
such as varying data scales and model capacities, while exhibiting stable
convergence properties. Another advantage of ScoreAug over standard data
augmentation lies in its ability to circumvent data leakage issues under
certain conditions. Furthermore, we show that ScoreAug can be synergistically
combined with traditional data augmentation techniques to achieve additional
performance gains.

</details>


### [618] [Shapley-Inspired Feature Weighting in $k$-means with No Additional Hyperparameters](https://arxiv.org/abs/2508.07952)
*Richard J. Fawley,Renato Cordeiro de Amorim*

Main category: cs.LG

Relevance: 40.0

TL;DR: SHARK是一种基于Shapley值的特征加权聚类算法，无需额外参数调整，通过分解k均值目标为Shapley值来量化特征相关性，实验表明其在噪声环境下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高维或噪声数据中，特征对聚类结构的贡献不均，现有特征加权方法需额外调参。SHARK旨在解决这一问题。

Method: 利用Shapley值量化特征相关性，将k均值目标分解为各特征的Shapley值，迭代调整特征权重。

Result: 在合成和真实数据集上，SHARK表现优于现有方法，尤其在噪声环境下更稳健和准确。

Conclusion: SHARK为无监督特征相关性提供了理论基础，并在实际应用中表现出色。

Abstract: Clustering algorithms often assume all features contribute equally to the
data structure, an assumption that usually fails in high-dimensional or noisy
settings. Feature weighting methods can address this, but most require
additional parameter tuning. We propose SHARK (Shapley Reweighted $k$-means), a
feature-weighted clustering algorithm motivated by the use of Shapley values
from cooperative game theory to quantify feature relevance, which requires no
additional parameters beyond those in $k$-means. We prove that the $k$-means
objective can be decomposed into a sum of per-feature Shapley values, providing
an axiomatic foundation for unsupervised feature relevance and reducing Shapley
computation from exponential to polynomial time. SHARK iteratively re-weights
features by the inverse of their Shapley contribution, emphasising informative
dimensions and down-weighting irrelevant ones. Experiments on synthetic and
real-world data sets show that SHARK consistently matches or outperforms
existing methods, achieving superior robustness and accuracy, particularly in
scenarios where noise may be present. Software:
https://github.com/rickfawley/shark.

</details>


### [619] [Communication-Efficient Zero-Order and First-Order Federated Learning Methods over Wireless Networks](https://arxiv.org/abs/2508.08013)
*Mohamad Assaad,Zeinab Nehme,Merouane Debbah*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了两种通信高效的联邦学习方法，通过减少通信开销和利用信道信息优化学习算法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在边缘设备协作训练时面临通信开销大的问题，本文旨在解决这一挑战。

Method: 1）使用零阶优化技术和两点梯度估计器；2）采用一阶梯度计算策略，并利用信道信息。

Result: 提供了两种方法的理论分析框架，证明了收敛性和性能界限。

Conclusion: 提出的方法有效减少了通信开销，同时利用了信道信息，适用于异步设备场景。

Abstract: Federated Learning (FL) is an emerging learning framework that enables edge
devices to collaboratively train ML models without sharing their local data. FL
faces, however, a significant challenge due to the high amount of information
that must be exchanged between the devices and the aggregator in the training
phase, which can exceed the limited capacity of wireless systems. In this
paper, two communication-efficient FL methods are considered where
communication overhead is reduced by communicating scalar values instead of
long vectors and by allowing high number of users to send information
simultaneously. The first approach employs a zero-order optimization technique
with two-point gradient estimator, while the second involves a first-order
gradient computation strategy. The novelty lies in leveraging channel
information in the learning algorithms, eliminating hence the need for
additional resources to acquire channel state information (CSI) and to remove
its impact, as well as in considering asynchronous devices. We provide a
rigorous analytical framework for the two methods, deriving convergence
guarantees and establishing appropriate performance bounds.

</details>


### [620] [Symbolic Quantile Regression for the Interpretable Prediction of Conditional Quantiles](https://arxiv.org/abs/2508.08080)
*Cas Oude Hoekstra,Floris den Hengst*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种符号分位数回归（SQR）方法，用于预测条件分位数并保持模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前符号回归（SR）主要用于预测结果的平均值，但在其他分布点（如中位数或极值）的变量关系估计方面研究不足，而这对高风险的领域尤为重要。

Method: 引入了符号分位数回归（SQR），通过符号回归预测条件分位数。

Result: SQR在透明模型中表现优异，与黑盒基线模型性能相当，同时保持了可解释性。

Conclusion: SQR适用于预测条件分位数，并能帮助理解不同分位数下的特征影响。

Abstract: Symbolic Regression (SR) is a well-established framework for generating
interpretable or white-box predictive models. Although SR has been successfully
applied to create interpretable estimates of the average of the outcome, it is
currently not well understood how it can be used to estimate the relationship
between variables at other points in the distribution of the target variable.
Such estimates of e.g. the median or an extreme value provide a fuller picture
of how predictive variables affect the outcome and are necessary in
high-stakes, safety-critical application domains. This study introduces
Symbolic Quantile Regression (SQR), an approach to predict conditional
quantiles with SR. In an extensive evaluation, we find that SQR outperforms
transparent models and performs comparably to a strong black-box baseline
without compromising transparency. We also show how SQR can be used to explain
differences in the target distribution by comparing models that predict extreme
and central outcomes in an airline fuel usage case study. We conclude that SQR
is suitable for predicting conditional quantiles and understanding interesting
feature influences at varying quantiles.

</details>


### [621] [Vision-Based Localization and LLM-based Navigation for Indoor Environments](https://arxiv.org/abs/2508.08120)
*Keyan Rahimi,Md. Wasiul Haque,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该研究提出了一种结合视觉定位和LLM导航的室内导航方法，定位准确率达96%，导航指令准确率为75%。


<details>
  <summary>Details</summary>
Motivation: 解决室内导航中GPS信号不可靠和建筑复杂性的问题。

Method: 使用ResNet-50进行视觉定位，结合LLM生成导航指令。

Result: 定位准确率96%，导航指令准确率75%。

Conclusion: 展示了利用现成设备和公开地图实现可扩展室内导航的潜力。

Abstract: Indoor navigation remains a complex challenge due to the absence of reliable
GPS signals and the architectural intricacies of large enclosed environments.
This study presents an indoor localization and navigation approach that
integrates vision-based localization with large language model (LLM)-based
navigation. The localization system utilizes a ResNet-50 convolutional neural
network fine-tuned through a two-stage process to identify the user's position
using smartphone camera input. To complement localization, the navigation
module employs an LLM, guided by a carefully crafted system prompt, to
interpret preprocessed floor plan images and generate step-by-step directions.
Experimental evaluation was conducted in a realistic office corridor with
repetitive features and limited visibility to test localization robustness. The
model achieved high confidence and an accuracy of 96% across all tested
waypoints, even under constrained viewing conditions and short-duration
queries. Navigation tests using ChatGPT on real building floor maps yielded an
average instruction accuracy of 75%, with observed limitations in zero-shot
reasoning and inference time. This research demonstrates the potential for
scalable, infrastructure-free indoor navigation using off-the-shelf cameras and
publicly available floor plans, particularly in resource-constrained settings
like hospitals, airports, and educational institutions.

</details>


### [622] [MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing](https://arxiv.org/abs/2508.08122)
*Mingrong Lin,Ke Deng,Zhengyang Wu,Zetao Zheng,Jie Li*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出memoryKT模型，通过三阶段记忆动态模拟（编码、存储、检索）提升知识追踪性能，并嵌入个性化遗忘模块。实验显示其优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有知识追踪模型依赖单一遗忘机制，忽略记忆过程的其他阶段及个性化遗忘模式，限制了性能和可解释性。

Method: 提出基于时序变分自编码器的memoryKT模型，模拟记忆动态：学习知识记忆特征分布、重构练习反馈、嵌入个性化遗忘模块。

Result: 在四个公开数据集上显著优于现有基线。

Conclusion: memoryKT通过完整记忆周期建模和个性化遗忘机制，提升了知识追踪的性能和个体差异感知能力。

Abstract: Knowledge Tracing (KT) is committed to capturing students' knowledge mastery
from their historical interactions. Simulating students' memory states is a
promising approach to enhance both the performance and interpretability of
knowledge tracing models. Memory consists of three fundamental processes:
encoding, storage, and retrieval. Although forgetting primarily manifests
during the storage stage, most existing studies rely on a single,
undifferentiated forgetting mechanism, overlooking other memory processes as
well as personalized forgetting patterns. To address this, this paper proposes
memoryKT, a knowledge tracing model based on a novel temporal variational
autoencoder. The model simulates memory dynamics through a three-stage process:
(i) Learning the distribution of students' knowledge memory features, (ii)
Reconstructing their exercise feedback, while (iii) Embedding a personalized
forgetting module within the temporal workflow to dynamically modulate memory
storage strength. This jointly models the complete encoding-storage-retrieval
cycle, significantly enhancing the model's perception capability for individual
differences. Extensive experiments on four public datasets demonstrate that our
proposed approach significantly outperforms state-of-the-art baselines.

</details>


### [623] [NeuroDx-LM: A Clinical Large-Scale Model for EEG-based Neurological Disorder Detection](https://arxiv.org/abs/2508.08124)
*Guanghao Jin,Yuan Liang,Yihan Ma,Jingpei Wu,Guoyang Liu*

Main category: cs.LG

Relevance: 40.0

TL;DR: NeuroDx-LM是一种专为EEG神经障碍检测设计的大规模模型，通过选择性时频嵌入和渐进特征感知训练策略，解决了EEG数据标注不足和临床性能不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 解决EEG大规模模型在实际部署中面临的标注数据有限和临床性能不足的挑战。

Method: 提出选择性时频嵌入机制和渐进特征感知训练策略，分两阶段优化特征表示。

Result: 在CHB-MIT和Schizophrenia数据集上达到SOTA性能。

Conclusion: EEG大规模模型在临床应用中具有巨大潜力。

Abstract: Large-scale models pre-trained on Electroencephalography (EEG) have shown
promise in clinical applications such as neurological disorder detection.
However, the practical deployment of EEG-based large-scale models faces
critical challenges such as limited labeled EEG data and suboptimal performance
in clinical scenarios. To address these issues, we propose NeuroDx-LM, a novel
large-scale model specifically designed for detecting EEG-based neurological
disorders. Our key contributions include (i) a Selective Temporal-Frequency
Embedding mechanism that adaptively captures complex temporal and spectral
patterns in EEG signals; and (ii) a Progressive Feature-Aware Training strategy
that refines feature representation in a two-stage process. In the first stage,
our model learns the fundamental discriminative features of EEG activities; in
the second stage, the model further extracts more specialized fine-grained
features for accurate diagnostic performance. We evaluated NeuroDx-LM on the
CHB-MIT and Schizophrenia datasets, achieving state-of-the-art performance in
EEG-based seizure and schizophrenia detection, respectively. These results
demonstrate the great potential of EEG-based large-scale models to advance
clinical applicability. Our code is available at
https://github.com/LetItBe12345/NeuroDx-LM.

</details>


### [624] [OFAL: An Oracle-Free Active Learning Framework](https://arxiv.org/abs/2508.08126)
*Hadi Khorsand,Vahid Pourahmadi*

Main category: cs.LG

Relevance: 40.0

TL;DR: OFAL是一种无需人工标注的主动学习方法，利用模型自身的不确定性生成信息丰富的样本，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统主动学习依赖人工标注（oracle），成本高且复杂。OFAL旨在通过模型不确定性实现无需人工标注的主动学习。

Method: 1. 分离和量化不确定性，使用蒙特卡洛Dropout近似贝叶斯神经网络；2. 通过变分自编码器生成新的不确定样本；3. 与其他主动学习方法对比和整合。

Result: OFAL能够生成信息丰富的样本，提升模型性能。

Conclusion: OFAL为主动学习提供了一种无需人工标注的高效方法。

Abstract: In the active learning paradigm, using an oracle to label data has always
been a complex and expensive task, and with the emersion of large unlabeled
data pools, it would be highly beneficial If we could achieve better results
without relying on an oracle. This research introduces OFAL, an oracle-free
active learning scheme that utilizes neural network uncertainty. OFAL uses the
model's own uncertainty to transform highly confident unlabeled samples into
informative uncertain samples. First, we start with separating and quantifying
different parts of uncertainty and introduce Monte Carlo Dropouts as an
approximation of the Bayesian Neural Network model. Secondly, by adding a
variational autoencoder, we go on to generate new uncertain samples by stepping
toward the uncertain part of latent space starting from a confidence seed
sample. By generating these new informative samples, we can perform active
learning and enhance the model's accuracy. Lastly, we try to compare and
integrate our method with other widely used active learning sampling methods.

</details>


### [625] [MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation](https://arxiv.org/abs/2508.08137)
*Pravallika Abbineni,Saoud Aldowaish,Colin Liechty,Soroosh Noorzad,Ali Ghazizadeh,Morteza Fayazi*

Main category: cs.LG

Relevance: 40.0

TL;DR: MuaLLM是一个用于电路设计辅助的多模态大型语言模型（LLM）代理，结合了检索增强生成（RAG）框架和自适应向量数据库，支持多步推理和高效检索。


<details>
  <summary>Details</summary>
Motivation: 电路设计领域的研究文献快速增长且数据表示不一致，传统方法难以高效处理复杂查询和优化目标。

Method: MuaLLM采用Reason + Act（ReAct）工作流，支持多模态数据处理和动态检索，解耦检索与推理以实现可扩展性。

Result: MuaLLM在RAG-250和Reas-100数据集上分别达到90.1%召回率和86.8%准确率，成本降低10倍且速度提升1.6倍。

Conclusion: MuaLLM为电路设计提供了一种高效、可扩展的辅助工具，克服了传统方法的局限性。

Abstract: Conducting a comprehensive literature review is crucial for advancing circuit
design methodologies. However, the rapid influx of state-of-the-art research,
inconsistent data representation, and the complexity of optimizing circuit
design objectives make this task significantly challenging. In this paper, we
propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for
circuit design assistance that integrates a hybrid Retrieval-Augmented
Generation (RAG) framework with an adaptive vector database of circuit design
research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason +
Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step
information retrieval. It functions as a question-answering design assistant,
capable of interpreting complex queries and providing reasoned responses
grounded in circuit literature. Its multimodal capabilities enable processing
of both textual and visual data, facilitating more efficient and comprehensive
analysis. The system dynamically adapts using intelligent search tools,
automated document retrieval from the internet, and real-time database updates.
Unlike conventional approaches constrained by model context limits, MuaLLM
decouples retrieval from inference, enabling scalable reasoning over
arbitrarily large corpora. At the maximum context length supported by standard
LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining
the same accuracy. This allows rapid, no-human-in-the-loop database generation,
overcoming the bottleneck of simulation-based dataset creation for circuits. To
evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval
and citation performance, and Reasoning-100 (Reas-100), focused on multistep
reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8%
accuracy on Reas-100.

</details>


### [626] [Neural Logic Networks for Interpretable Classification](https://arxiv.org/abs/2508.08172)
*Vincent Perreault,Katsumi Inoue,Richard Labib,Alain Hertz*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种可解释的神经网络（Neural Logic Networks），通过逻辑操作（AND、OR、NOT）和概率建模学习输入输出的关系，并改进了学习算法，提升了布尔网络发现的性能。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络缺乏可解释性，而逻辑网络可以通过逻辑操作实现透明化学习，尤其是在需要可解释性的领域（如医疗）中具有实际价值。

Method: 扩展了逻辑网络的功能（加入NOT操作和偏差项），提出了因子化的IF-THEN规则结构和改进的学习算法。

Result: 在布尔网络发现和表格分类任务中实现了性能提升，并能学习到相关且可解释的规则。

Conclusion: 该方法在可解释性和性能上优于现有技术，特别适用于需要透明化模型的领域。

Abstract: Traditional neural networks have an impressive classification performance,
but what they learn cannot be inspected, verified or extracted. Neural Logic
Networks on the other hand have an interpretable structure that enables them to
learn a logical mechanism relating the inputs and outputs with AND and OR
operations. We generalize these networks with NOT operations and biases that
take into account unobserved data and develop a rigorous logical and
probabilistic modeling in terms of concept combinations to motivate their use.
We also propose a novel factorized IF-THEN rule structure for the model as well
as a modified learning algorithm. Our method improves the state-of-the-art in
Boolean networks discovery and is able to learn relevant, interpretable rules
in tabular classification, notably on an example from the medical field where
interpretability has tangible value.

</details>


### [627] [Generative Bid Shading in Real-Time Bidding Advertising](https://arxiv.org/abs/2508.06550)
*Yinqiu Huang,Hao Ma,Wenshuai Chen,Shuli Wang,Yongqiang Zhang,Xue Wei,Yinhua Zhu,Haitao Wang,Xingxing Wang*

Main category: cs.GT

Relevance: 40.0

TL;DR: 论文提出了一种名为生成式竞价调整（GBS）的方法，通过端到端生成模型和奖励偏好对齐系统，解决了现有竞价调整方法中的问题。


<details>
  <summary>Details</summary>
Motivation: 现有竞价调整方法受限于单峰假设和离散化模型的依赖性，无法适应非凸剩余曲线，且易受级联误差影响。

Method: GBS包括两部分：1）端到端生成模型，通过逐步残差生成调整比例；2）奖励偏好对齐系统，利用CHNet作为奖励模型优化剩余。

Result: 离线和在线A/B测试验证了GBS的有效性，并已部署在美团DSP平台上。

Conclusion: GBS通过生成模型和奖励对齐系统，显著提升了竞价调整的效果。

Abstract: Bid shading plays a crucial role in Real-Time Bidding~(RTB) by adaptively
adjusting the bid to avoid advertisers overspending. Existing mainstream
two-stage methods, which first model bid landscapes and then optimize surplus
using operations research techniques, are constrained by unimodal assumptions
that fail to adapt for non-convex surplus curves and are vulnerable to
cascading errors in sequential workflows. Additionally, existing discretization
models of continuous values ignore the dependence between discrete intervals,
reducing the model's error correction ability, while sample selection bias in
bidding scenarios presents further challenges for prediction. To address these
issues, this paper introduces Generative Bid Shading~(GBS), which comprises two
primary components: (1) an end-to-end generative model that utilizes an
autoregressive approach to generate shading ratios by stepwise residuals,
capturing complex value dependencies without relying on predefined priors; and
(2) a reward preference alignment system, which incorporates a channel-aware
hierarchical dynamic network~(CHNet) as the reward model to extract
fine-grained features, along with modules for surplus optimization and
exploration utility reward alignment, ultimately optimizing both short-term and
long-term surplus using group relative policy optimization~(GRPO). Extensive
experiments on both offline and online A/B tests validate GBS's effectiveness.
Moreover, GBS has been deployed on the Meituan DSP platform, serving billions
of bid requests daily.

</details>


### [628] [ClimateSOM: A Visual Analysis Workflow for Climate Ensemble Datasets](https://arxiv.org/abs/2508.06732)
*Yuya Kawakami,Daniel Cayan,Dongyu Liu,Kwan-Liu Ma*

Main category: cs.HC

Relevance: 40.0

TL;DR: ClimateSOM是一个结合自组织映射（SOM）和大语言模型（LLMs）的可视化分析工作流，用于探索和解释气候集合数据集的变异性。


<details>
  <summary>Details</summary>
Motivation: 气候集合数据集的变异性分析对气候科学家至关重要，但传统方法难以直观理解。

Method: 利用SOM将气候集合模型运行抽象为2D空间分布，并通过LLMs辅助解释。

Result: ClimateSOM成功应用于降水预测数据集，并通过专家评审验证了其有效性。

Conclusion: ClimateSOM为气候集合数据分析提供了交互式探索和解释的新方法。

Abstract: Ensemble datasets are ever more prevalent in various scientific domains. In
climate science, ensemble datasets are used to capture variability in
projections under plausible future conditions including greenhouse and aerosol
emissions. Each ensemble model run produces projections that are fundamentally
similar yet meaningfully distinct. Understanding this variability among
ensemble model runs and analyzing its magnitude and patterns is a vital task
for climate scientists. In this paper, we present ClimateSOM, a visual analysis
workflow that leverages a self-organizing map (SOM) and Large Language Models
(LLMs) to support interactive exploration and interpretation of climate
ensemble datasets. The workflow abstracts climate ensemble model runs -
spatiotemporal time series - into a distribution over a 2D space that captures
the variability among the ensemble model runs using a SOM. LLMs are integrated
to assist in sensemaking of this SOM-defined 2D space, the basis for the visual
analysis tasks. In all, ClimateSOM enables users to explore the variability
among ensemble model runs, identify patterns, compare and cluster the ensemble
model runs. To demonstrate the utility of ClimateSOM, we apply the workflow to
an ensemble dataset of precipitation projections over California and the
Northwestern United States. Furthermore, we conduct a short evaluation of our
LLM integration, and conduct an expert review of the visual workflow and the
insights from the case studies with six domain experts to evaluate our approach
and its utility.

</details>


### [629] [Mitigating Distribution Shift in Graph-Based Android Malware Classification via Function Metadata and LLM Embeddings](https://arxiv.org/abs/2508.06734)
*Ngoc N. Tran,Anwar Said,Waseem Abbas,Tyler Derr,Xenofon D. Koutsoukos*

Main category: cs.CR

Relevance: 40.0

TL;DR: 论文提出了一种增强函数调用图语义的框架，通过引入上下文特征（如函数级元数据和代码嵌入）来提升恶意软件分类器的泛化能力，并在新基准测试中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的恶意软件分类器在未见过的恶意软件变体上泛化能力不足，准确性下降显著，表明现有方法无法捕捉深层语义模式。

Method: 提出了一种语义增强框架，通过整合函数级元数据和代码嵌入（如LLM生成）来丰富函数调用图，支持不一致特征可用性下的灵活集成。

Result: 实验表明，该方法在分布偏移下分类性能提升达8%，并能增强基于适应方法的鲁棒性。

Conclusion: 该框架为构建适应威胁环境变化的弹性恶意软件检测系统提供了实用路径。

Abstract: Graph-based malware classifiers can achieve over 94% accuracy on standard
Android datasets, yet we find they suffer accuracy drops of up to 45% when
evaluated on previously unseen malware variants from the same family - a
scenario where strong generalization would typically be expected. This
highlights a key limitation in existing approaches: both the model
architectures and their structure-only representations often fail to capture
deeper semantic patterns. In this work, we propose a robust semantic enrichment
framework that enhances function call graphs with contextual features,
including function-level metadata and, when available, code embeddings derived
from large language models. The framework is designed to operate under
real-world constraints where feature availability is inconsistent, and supports
flexible integration of semantic signals. To evaluate generalization under
realistic domain and temporal shifts, we introduce two new benchmarks:
MalNet-Tiny-Common and MalNet-Tiny-Distinct, constructed using malware family
partitioning to simulate cross-family generalization and evolving threat
behavior. Experiments across multiple graph neural network backbones show that
our method improves classification performance by up to 8% under distribution
shift and consistently enhances robustness when integrated with
adaptation-based methods. These results offer a practical path toward building
resilient malware detection systems in evolving threat environments.

</details>


### [630] [MOCA-HESP: Meta High-dimensional Bayesian Optimization for Combinatorial and Mixed Spaces via Hyper-ellipsoid Partitioning](https://arxiv.org/abs/2508.06847)
*Lam Ngo,Huong Ha,Jeffrey Chan,Hongyu Zhang*

Main category: stat.ML

Relevance: 40.0

TL;DR: 提出了一种名为MOCA-HESP的高维贝叶斯优化方法，适用于组合和混合变量，通过超椭球空间划分（HESP）技术和多臂老虎机选择最优编码器，显著提升了现有优化器的性能。


<details>
  <summary>Details</summary>
Motivation: 解决高维贝叶斯优化在组合和混合变量领域的挑战，现有方法主要针对连续域，组合和混合域仍具挑战性。

Method: 结合HESP技术和多臂老虎机选择最优编码器，设计为元算法以兼容其他优化器，提升性能。

Result: 在合成和实际基准测试中，MOCA-HESP结合现有优化器（标准BO、CASMOPOLITAN、Bounce）显著优于基线方法。

Conclusion: MOCA-HESP为高维组合和混合变量优化提供了有效解决方案，并展示了其兼容性和性能优势。

Abstract: High-dimensional Bayesian Optimization (BO) has attracted significant
attention in recent research. However, existing methods have mainly focused on
optimizing in continuous domains, while combinatorial (ordinal and categorical)
and mixed domains still remain challenging. In this paper, we first propose
MOCA-HESP, a novel high-dimensional BO method for combinatorial and mixed
variables. The key idea is to leverage the hyper-ellipsoid space partitioning
(HESP) technique with different categorical encoders to work with
high-dimensional, combinatorial and mixed spaces, while adaptively selecting
the optimal encoders for HESP using a multi-armed bandit technique. Our method,
MOCA-HESP, is designed as a \textit{meta-algorithm} such that it can
incorporate other combinatorial and mixed BO optimizers to further enhance the
optimizers' performance. Finally, we develop three practical BO methods by
integrating MOCA-HESP with state-of-the-art BO optimizers for combinatorial and
mixed variables: standard BO, CASMOPOLITAN, and Bounce. Our experimental
results on various synthetic and real-world benchmarks show that our methods
outperform existing baselines. Our code implementation can be found at
https://github.com/LamNgo1/moca-hesp

</details>


### [631] [Machine Learning Algorithms for Improving Exact Classical Solvers in Mixed Integer Continuous Optimization](https://arxiv.org/abs/2508.06906)
*Morteza Kimiaei,Vyacheslav Kungurtsev,Brian Olimba*

Main category: math.OC

Relevance: 40.0

TL;DR: 该论文探讨了如何利用机器学习和强化学习增强整数和非线性规划（INLP/MINLP）的精确优化方法，特别是分支定界法（BB），同时保持全局最优性。


<details>
  <summary>Details</summary>
Motivation: 整数和混合整数非线性规划在物流、能源和调度中至关重要，但计算复杂。研究旨在通过机器学习提升传统优化方法的效率。

Method: 提出统一的分支定界框架，将学习策略嵌入分支、割平面选择、节点排序和参数控制中，结合监督学习、模仿学习和强化学习。

Result: 展示了学习增强方法在机组调度、车辆路径和水电规划等应用中的加速效果，同时保证正确性。

Conclusion: 总结了不同求解器类别和学习范式的分类，并提出了泛化、混合和扩展智能求解器的开放挑战。

Abstract: Integer and mixed-integer nonlinear programming (INLP, MINLP) are central to
logistics, energy, and scheduling, but remain computationally challenging. This
survey examines how machine learning and reinforcement learning can enhance
exact optimization methods - particularly branch-and-bound (BB), without
compromising global optimality. We cover discrete, continuous, and
mixed-integer formulations, and highlight applications such as crew scheduling,
vehicle routing, and hydropower planning. We introduce a unified BB framework
that embeds learning-based strategies into branching, cut selection, node
ordering, and parameter control. Classical algorithms are augmented using
supervised, imitation, and reinforcement learning models to accelerate
convergence while maintaining correctness. We conclude with a taxonomy of
learning methods by solver class and learning paradigm, and outline open
challenges in generalization, hybridization, and scaling intelligent solvers.

</details>


### [632] [Statistical Inference for Autoencoder-based Anomaly Detection after Representation Learning-based Domain Adaptation](https://arxiv.org/abs/2508.07049)
*Tran Tuan Kiet,Nguyen Thang Loi,Vo Nguyen Le Duy*

Main category: stat.ML

Relevance: 40.0

TL;DR: STAND-DA是一个基于选择性推理的框架，用于在表示学习域适应后实现统计严格的异常检测，控制假阳性率。


<details>
  <summary>Details</summary>
Motivation: 解决域适应中异常检测结果统计有效性不足的问题，提供严格的统计保证。

Method: 结合表示学习域适应和选择性推理框架，开发GPU加速实现以提高计算效率。

Result: 实验验证了STAND-DA的理论有效性和计算效率。

Conclusion: STAND-DA为异常检测提供了统计严格的解决方案，适用于大规模深度学习模型。

Abstract: Anomaly detection (AD) plays a vital role across a wide range of domains, but
its performance might deteriorate when applied to target domains with limited
data. Domain Adaptation (DA) offers a solution by transferring knowledge from a
related source domain with abundant data. However, this adaptation process can
introduce additional uncertainty, making it difficult to draw statistically
valid conclusions from AD results. In this paper, we propose STAND-DA -- a
novel framework for statistically rigorous Autoencoder-based AD after
Representation Learning-based DA. Built on the Selective Inference (SI)
framework, STAND-DA computes valid $p$-values for detected anomalies and
rigorously controls the false positive rate below a pre-specified level
$\alpha$ (e.g., 0.05). To address the computational challenges of applying SI
to deep learning models, we develop the GPU-accelerated SI implementation,
significantly enhancing both scalability and runtime performance. This
advancement makes SI practically feasible for modern, large-scale deep
architectures. Extensive experiments on synthetic and real-world datasets
validate the theoretical results and computational efficiency of the proposed
STAND-DA method.

</details>


### [633] [SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization](https://arxiv.org/abs/2508.07086)
*Beilong Tang,Xiaoxiao Miao,Xin Wang,Ming Li*

Main category: cs.SD

Relevance: 40.0

TL;DR: SEF-MK提出了一种无需说话人嵌入的语音匿名化框架，通过随机选择多个k-means模型之一处理SSL表示，平衡了隐私保护与内容保留。


<details>
  <summary>Details</summary>
Motivation: 保护说话人隐私的同时保留语言和副语言内容，解决现有SSL表示中说话人特征泄露的问题。

Method: 提出SEF-MK框架，使用多个k-means模型（每个模型基于不同说话人子集训练）随机匿名化SSL表示。

Result: 从用户角度看，SEF-MK更好地保留了语言和情感内容；从攻击者角度看，多模型提升了隐私攻击效果。

Conclusion: SEF-MK为设计语音匿名化系统提供了新思路，需权衡隐私保护与攻击风险。

Abstract: Voice anonymization protects speaker privacy by concealing identity while
preserving linguistic and paralinguistic content. Self-supervised learning
(SSL) representations encode linguistic features but preserve speaker traits.
We propose a novel speaker-embedding-free framework called SEF-MK. Instead of
using a single k-means model trained on the entire dataset, SEF-MK anonymizes
SSL representations for each utterance by randomly selecting one of multiple
k-means models, each trained on a different subset of speakers. We explore this
approach from both attacker and user perspectives. Extensive experiments show
that, compared to a single k-means model, SEF-MK with multiple k-means models
better preserves linguistic and emotional content from the user's viewpoint.
However, from the attacker's perspective, utilizing multiple k-means models
boosts the effectiveness of privacy attacks. These insights can aid users in
designing voice anonymization systems to mitigate attacker threats.

</details>


### [634] [Nonparametric Reaction Coordinate Optimization with Histories: A Framework for Rare Event Dynamics](https://arxiv.org/abs/2508.07326)
*Polina V. Banushkina,Sergei V. Krivov*

Main category: physics.chem-ph

Relevance: 40.0

TL;DR: 论文提出了一种非参数反应坐标优化框架，用于分析复杂系统中的罕见事件动态，如蛋白质折叠和气候现象，无需详尽采样即可准确表征。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决高维随机动态系统中罕见事件（如蛋白质折叠）的准确反应坐标识别问题。

Method: 方法采用非参数优化框架，结合轨迹历史数据，适用于不规则或不完整数据。

Result: 结果显示该方法能准确估计蛋白质折叠的转换概率，并通过严格验证测试，生成高分辨率自由能剖面。

Conclusion: 结论表明该方法为复杂动态系统和纵向数据集分析提供了通用、灵活且稳健的框架。

Abstract: Rare but critical events in complex systems, such as protein folding,
chemical reactions, disease progression, and extreme weather or climate
phenomena, are governed by complex, high-dimensional, stochastic dynamics.
Identifying an optimal reaction coordinate (RC) that accurately captures the
progress of these dynamics is crucial for understanding and simulating such
processes. This work introduces a nonparametric RC optimization framework that
incorporates trajectory histories, enabling robust analysis even for irregular
or incomplete data. The power of the method is demonstrated through
increasingly challenging analyses of protein folding dynamics, where it
provides accurate committor estimates that pass a stringent validation test and
yield high-resolution free energy profiles. Its generality is further
illustrated through applications to dynamics in phase space, a conceptual ocean
circulation model, and a longitudinal clinical dataset. These results
demonstrate that rare event dynamics can be accurately characterized without
exhaustive sampling of the configuration space, establishing a general,
flexible, and robust framework for analyzing complex dynamical systems and
longitudinal datasets.

</details>


### [635] [G-IFT: A Gated Linear Unit adapter with Iterative Fine-Tuning for Low-Resource Children's Speaker Verification](https://arxiv.org/abs/2508.07836)
*Vishwas M. Shetty,Jiusi Zheng,Abeer Alwan*

Main category: eess.AS

Relevance: 40.0

TL;DR: 提出了一种名为G-IFT的创新框架，通过门控线性单元适配器和迭代微调，提升成人语音到儿童语音领域的知识迁移效率。


<details>
  <summary>Details</summary>
Motivation: 成人语音训练的说话人验证系统在儿童语音上表现不佳，且儿童语音数据有限，微调效果不显著。

Method: 在预训练的说话人嵌入模型和分类器之间插入门控线性单元适配器，并通过迭代方式依次优化分类器、适配器和预训练模型。

Result: 在ECAPA-TDNN、ResNet和X-vector架构上，G-IFT框架在OGI和MyST数据集上均显著降低了等错误率。

Conclusion: G-IFT框架是一种与底层架构无关的有效方法，能显著提升儿童语音的说话人验证性能。

Abstract: Speaker Verification (SV) systems trained on adults speech often underperform
on children's SV due to the acoustic mismatch, and limited children speech data
makes fine-tuning not very effective. In this paper, we propose an innovative
framework, a Gated Linear Unit adapter with Iterative Fine-Tuning (G-IFT), to
enhance knowledge transfer efficiency between the high-resource adults speech
domain and the low-resource children's speech domain. In this framework, a
Gated Linear Unit adapter is first inserted between the pre-trained speaker
embedding model and the classifier. Then the classifier, adapter, and
pre-trained speaker embedding model are optimized sequentially in an iterative
way. This framework is agnostic to the type of the underlying architecture of
the SV system. Our experiments on ECAPA-TDNN, ResNet, and X-vector
architectures using the OGI and MyST datasets demonstrate that the G-IFT
framework yields consistent reductions in Equal Error Rates compared to
baseline methods.

</details>


### [636] [Meta Off-Policy Estimation](https://arxiv.org/abs/2508.07914)
*Olivier Jeunen*

Main category: stat.ML

Relevance: 40.0

TL;DR: 本文提出了一种基于固定效应元分析框架的方法，用于结合多个离策略估计（OPE）方法及其置信区间，生成更准确的单一估计。


<details>
  <summary>Details</summary>
Motivation: 离策略估计方法在推荐系统中具有重要应用，但现有方法存在统计效率不足的问题。本文旨在通过结合多个估计器及其相关性，提升估计的准确性和效率。

Method: 采用固定效应元分析框架，显式考虑估计器之间的相关性（由共享数据引起），生成最佳线性无偏估计（BLUE）和保守的置信区间。

Result: 在模拟和真实数据上的实验表明，该方法比现有单个估计器具有更高的统计效率。

Conclusion: 本文提出的方法显著提升了离策略估计的准确性和效率，为推荐系统评估提供了更可靠的工具。

Abstract: Off-policy estimation (OPE) methods enable unbiased offline evaluation of
recommender systems, directly estimating the online reward some target policy
would have obtained, from offline data and with statistical guarantees. The
theoretical elegance of the framework combined with practical successes have
led to a surge of interest, with many competing estimators now available to
practitioners and researchers. Among these, Doubly Robust methods provide a
prominent strategy to combine value- and policy-based estimators.
  In this work, we take an alternative perspective to combine a set of OPE
estimators and their associated confidence intervals into a single, more
accurate estimate. Our approach leverages a correlated fixed-effects
meta-analysis framework, explicitly accounting for dependencies among
estimators that arise due to shared data. This yields a best linear unbiased
estimate (BLUE) of the target policy's value, along with an appropriately
conservative confidence interval that reflects inter-estimator correlation. We
validate our method on both simulated and real-world data, demonstrating
improved statistical efficiency over existing individual estimators.

</details>


### [637] [Gaussian Approximation for Two-Timescale Linear Stochastic Approximation](https://arxiv.org/abs/2508.07928)
*Bogdan Butyrin,Artemy Rubtsov,Alexey Naumov,Vladimir Ulyanov,Sergey Samsonov*

Main category: stat.ML

Relevance: 40.0

TL;DR: 本文为非渐近线性双时间尺度随机逼近（TTSA）算法的正态逼近精度建立了边界，分析了末次迭代和Polyak-Ruppert平均两种情形，揭示了时间尺度分离对逼近速率的影响。


<details>
  <summary>Details</summary>
Motivation: 研究线性TTSA算法的正态逼近精度，以填补理论空白并揭示时间尺度分离对逼近速率的影响。

Method: 通过凸距离分析概率分布，推导正态逼近边界，并研究末次迭代和Polyak-Ruppert平均两种情形。

Result: 发现时间尺度分离对末次迭代和平均情形的逼近速率有相反影响，并提供了高阶矩边界。

Conclusion: 研究为线性TTSA算法的正态逼近提供了理论支持，并揭示了时间尺度分离的非平凡作用。

Abstract: In this paper, we establish non-asymptotic bounds for accuracy of normal
approximation for linear two-timescale stochastic approximation (TTSA)
algorithms driven by martingale difference or Markov noise. Focusing on both
the last iterate and Polyak-Ruppert averaging regimes, we derive bounds for
normal approximation in terms of the convex distance between probability
distributions. Our analysis reveals a non-trivial interaction between the fast
and slow timescales: the normal approximation rate for the last iterate
improves as the timescale separation increases, while it decreases in the
Polyak-Ruppert averaged setting. We also provide the high-order moment bounds
for the error of linear TTSA algorithm, which may be of independent interest.

</details>


### [638] [Adaptive Source-Channel Coding for Semantic Communications](https://arxiv.org/abs/2508.07958)
*Dongxu Li,Kai Yuan,Jianhao Huang,Chuan Huang,Xiaoqi Qin,Shuguang Cui,Ping Zhang*

Main category: cs.IT

Relevance: 40.0

TL;DR: 提出了一种自适应源信道编码（ASCC）方案，用于并行高斯信道上的语义通信，结合了深度神经网络（DNN）的语义源编码和传统数字信道编码，优化了端到端失真。


<details>
  <summary>Details</summary>
Motivation: 解决当前语义通信中联合源信道编码（JSCC）与现有系统不兼容且无法适应源或信道变化的问题，同时避免分离源信道编码（SSCC）在有限块长下的次优性。

Method: 通过逻辑回归近似端到端失真与源编码率和误码率（BER）的关系，建模BER与信噪比（SNR）和信道编码率的关系，提出加权和失真最小化问题，并使用逐次凸逼近求解。

Result: 仿真结果表明，ASCC方案在单信道和并行信道场景下均优于典型的深度JSCC和SSCC方案，同时保持与实际数字系统的完全兼容性。

Conclusion: ASCC方案为语义通信提供了一种高效且兼容性强的编码方法，解决了现有技术的局限性。

Abstract: Semantic communications (SemComs) have emerged as a promising paradigm for
joint data and task-oriented transmissions, combining the demands for both the
bit-accurate delivery and end-to-end (E2E) distortion minimization. However,
current joint source-channel coding (JSCC) in SemComs is not compatible with
the existing communication systems and cannot adapt to the variations of the
sources or the channels, while separate source-channel coding (SSCC) is
suboptimal in the finite blocklength regime. To address these issues, we
propose an adaptive source-channel coding (ASCC) scheme for SemComs over
parallel Gaussian channels, where the deep neural network (DNN)-based semantic
source coding and conventional digital channel coding are separately deployed
and adaptively designed. To enable efficient adaptation between the source and
channel coding, we first approximate the E2E data and semantic distortions as
functions of source coding rate and bit error ratio (BER) via logistic
regression, where BER is further modeled as functions of signal-to-noise ratio
(SNR) and channel coding rate. Then, we formulate the weighted sum E2E
distortion minimization problem for joint source-channel coding rate and power
allocation over parallel channels, which is solved by the successive convex
approximation. Finally, simulation results demonstrate that the proposed ASCC
scheme outperforms typical deep JSCC and SSCC schemes for both the single- and
parallel-channel scenarios while maintaining full compatibility with practical
digital systems.

</details>


### [639] [Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks](https://arxiv.org/abs/2508.08029)
*Thusitha Dayaratne,Ngoc Duy Pham,Viet Vo,Shangqi Lai,Sharif Abuadbba,Hajime Suzuki,Xingliang Yuan,Carsten Rudolph*

Main category: cs.CR

Relevance: 40.0

TL;DR: 论文探讨了在5G和O-RAN架构中，恶意xApps通过Unicode篡改数据（hypoglyphs）绕过传统ML异常检测的问题，提出使用LLMs进行异常检测，并验证了其鲁棒性和低延迟性。


<details>
  <summary>Details</summary>
Motivation: 5G和O-RAN架构的开放性和复杂性带来了新的安全挑战，传统ML方法易受hypoglyphs攻击而崩溃，需要更鲁棒的解决方案。

Method: 采用LLMs进行异常检测，测试其在处理hypoglyphs数据时的表现，并评估检测延迟。

Result: LLMs能稳定处理篡改数据且不崩溃，检测延迟低于0.07秒，但初始检测精度需进一步提升。

Conclusion: LLMs在对抗hypoglyphs攻击中表现出鲁棒性和低延迟，适合O-RAN的Near-RT RIC部署，但需进一步优化精度。

Abstract: The introduction of 5G and the Open Radio Access Network (O-RAN) architecture
has enabled more flexible and intelligent network deployments. However, the
increased complexity and openness of these architectures also introduce novel
security challenges, such as data manipulation attacks on the semi-standardised
Shared Data Layer (SDL) within the O-RAN platform through malicious xApps. In
particular, malicious xApps can exploit this vulnerability by introducing
subtle Unicode-wise alterations (hypoglyphs) into the data that are being used
by traditional machine learning (ML)-based anomaly detection methods. These
Unicode-wise manipulations can potentially bypass detection and cause failures
in anomaly detection systems based on traditional ML, such as AutoEncoders,
which are unable to process hypoglyphed data without crashing. We investigate
the use of Large Language Models (LLMs) for anomaly detection within the O-RAN
architecture to address this challenge. We demonstrate that LLM-based xApps
maintain robust operational performance and are capable of processing
manipulated messages without crashing. While initial detection accuracy
requires further improvements, our results highlight the robustness of LLMs to
adversarial attacks such as hypoglyphs in input data. There is potential to use
their adaptability through prompt engineering to further improve the accuracy,
although this requires further research. Additionally, we show that LLMs
achieve low detection latency (under 0.07 seconds), making them suitable for
Near-Real-Time (Near-RT) RIC deployments.

</details>


### [640] [Adaptive Learning for IRS-Assisted Wireless Networks: Securing Opportunistic Communications Against Byzantine Eavesdroppers](https://arxiv.org/abs/2508.08206)
*Amirhossein Taherpour,Abbas Taherpour,Tamer Khattab*

Main category: eess.SP

Relevance: 40.0

TL;DR: 提出了一种联合学习框架，用于在信道状态信息（CSI）不确定的情况下实现拜占庭弹性的频谱感知和安全智能反射面（IRS）辅助的机会接入。


<details>
  <summary>Details</summary>
Motivation: 解决在存在拜占庭用户和CSI不确定性的情况下，如何实现高精度的频谱感知和安全通信的问题。

Method: 采用对数域贝叶斯更新与修剪聚合和注意力加权共识的感知阶段，基站通过保守最小规则融合网络信念。下行链路设计为在功率和泄漏约束下的总和均方误差（MSE）最小化问题，联合优化基站预编码器、IRS相位偏移和用户均衡器。

Result: 在多种网络条件下，仿真显示在对抗攻击下固定虚警率下更高的检测概率，诚实用户的总MSE显著降低，窃听者信号功率强抑制，以及快速收敛。

Conclusion: 该框架为适应CSI可用性并通过联合学习协调感知和传输的安全机会通信提供了实用路径。

Abstract: We propose a joint learning framework for Byzantine-resilient spectrum
sensing and secure intelligent reflecting surface (IRS)--assisted opportunistic
access under channel state information (CSI) uncertainty. The sensing stage
performs logit-domain Bayesian updates with trimmed aggregation and
attention-weighted consensus, and the base station (BS) fuses network beliefs
with a conservative minimum rule, preserving detection accuracy under a bounded
number of Byzantine users. Conditioned on the sensing outcome, we pose downlink
design as sum mean-squared error (MSE) minimization under transmit-power and
signal-leakage constraints and jointly optimize the BS precoder, IRS phase
shifts, and user equalizers. With partial (or known) CSI, we develop an
augmented-Lagrangian alternating algorithm with projected updates and provide
provable sublinear convergence, with accelerated rates under mild local
curvature. With unknown CSI, we perform constrained Bayesian optimization (BO)
in a geometry-aware low-dimensional latent space using Gaussian process (GP)
surrogates; we prove regret bounds for a constrained upper confidence bound
(UCB) variant of the BO module, and demonstrate strong empirical performance of
the implemented procedure. Simulations across diverse network conditions show
higher detection probability at fixed false-alarm rate under adversarial
attacks, large reductions in sum MSE for honest users, strong suppression of
eavesdropper signal power, and fast convergence. The framework offers a
practical path to secure opportunistic communication that adapts to CSI
availability while coherently coordinating sensing and transmission through
joint learning.

</details>


### [641] [Self-Organizing Survival Manifolds: A Theory for Unsupervised Discovery of Prognostic Structures in Biological Systems](https://arxiv.org/abs/2508.06539)
*Atahan Karagoz*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种新的生存建模理论，将生存视为生物状态空间几何特性的结果，而非传统的有监督学习任务。


<details>
  <summary>Details</summary>
Motivation: 传统生存建模依赖标注数据和固定协变量，而本研究认为生存是生物状态空间几何特性的自然结果，试图从几何和物理角度重新定义生存模型。

Method: 提出了自组织生存流形（SOSM）理论，基于低曲率测地流和生物约束构建生存能量函数，推导离散和连续目标公式，并证明其理论收敛性。

Result: 理论框架将生存与几何流稳定性对齐，连接了热力学效率、熵流、Ricci曲率和最优传输等物理概念，为生存建模提供了无标签的通用基础。

Conclusion: 研究将健康、疾病、衰老和死亡重新定义为流形结构的几何相变，为机器学习和生物物理学的交叉提供了新视角。

Abstract: Survival is traditionally modeled as a supervised learning task, reliant on
curated outcome labels and fixed covariates. This work rejects that premise. It
proposes that survival is not an externally annotated target but a geometric
consequence: an emergent property of the curvature and flow inherent in
biological state space. We develop a theory of Self-Organizing Survival
Manifolds (SOSM), in which survival-relevant dynamics arise from low-curvature
geodesic flows on latent manifolds shaped by internal biological constraints. A
survival energy functional based on geodesic curvature minimization is
introduced and shown to induce structures where prognosis aligns with geometric
flow stability. We derive discrete and continuous formulations of the objective
and prove theoretical results demonstrating the emergence and convergence of
survival-aligned trajectories under biologically plausible conditions. The
framework draws connections to thermodynamic efficiency, entropy flow, Ricci
curvature, and optimal transport, grounding survival modeling in physical law.
Health, disease, aging, and death are reframed as geometric phase transitions
in the manifold's structure. This theory offers a universal, label-free
foundation for modeling survival as a property of form, not annotation-bridging
machine learning, biophysics, and the geometry of life itself.

</details>


### [642] [Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering](https://arxiv.org/abs/2508.06574)
*Fatemeh Moradi,Mehran Tarif,Mohammadhossein Homaei*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种两阶段学习框架，结合无监督异常检测和半监督学习，用于供应链欺诈检测。


<details>
  <summary>Details</summary>
Motivation: 现代供应链欺诈检测面临数据稀疏和类别不平衡的挑战，传统方法效果有限。

Method: 第一阶段使用Isolation Forest进行无监督异常检测，第二阶段用自训练SVM结合标记和高置信度伪标记数据进行半监督学习。

Result: 在DataCo数据集上F1得分为0.817，假阳性率低于3.0%。

Conclusion: 该方法在真实供应链欺诈检测中有效，但需进一步解决概念漂移和与深度学习的对比。

Abstract: Detecting fraud in modern supply chains is a growing challenge, driven by the
complexity of global networks and the scarcity of labeled data. Traditional
detection methods often struggle with class imbalance and limited supervision,
reducing their effectiveness in real-world applications. This paper proposes a
novel two-phase learning framework to address these challenges. In the first
phase, the Isolation Forest algorithm performs unsupervised anomaly detection
to identify potential fraud cases and reduce the volume of data requiring
further analysis. In the second phase, a self-training Support Vector Machine
(SVM) refines the predictions using both labeled and high-confidence
pseudo-labeled samples, enabling robust semi-supervised learning. The proposed
method is evaluated on the DataCo Smart Supply Chain Dataset, a comprehensive
real-world supply chain dataset with fraud indicators. It achieves an F1-score
of 0.817 while maintaining a false positive rate below 3.0%. These results
demonstrate the effectiveness and efficiency of combining unsupervised
pre-filtering with semi-supervised refinement for supply chain fraud detection
under real-world constraints, though we acknowledge limitations regarding
concept drift and the need for comparison with deep learning approaches.

</details>


### [643] [GFlowNets for Learning Better Drug-Drug Interaction Representations](https://arxiv.org/abs/2508.06576)
*Azmine Toushik Wasi*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种结合生成流网络（GFlowNet）和变分图自编码器（VGAE）的框架，用于生成稀有类别的合成样本，以解决药物相互作用预测中的类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 药物相互作用（DDI）预测中，稀有但关键的相互作用类别在数据集中代表性不足，导致模型性能不佳。现有方法通常将问题简化为二分类，忽视了类别特异性，加剧了对常见类别的偏向。

Method: 提出了一种结合GFlowNet和VGAE的框架，生成稀有类别的合成样本，以平衡数据集并提高预测性能。

Result: 该方法显著提升了模型对各类药物相互作用的预测性能，增强了临床可靠性。

Conclusion: 通过生成稀有类别的合成数据，该方法有效解决了DDI预测中的类别不平衡问题，为临床提供了更可靠的预测结果。

Abstract: Drug-drug interactions pose a significant challenge in clinical pharmacology,
with severe class imbalance among interaction types limiting the effectiveness
of predictive models. Common interactions dominate datasets, while rare but
critical interactions remain underrepresented, leading to poor model
performance on infrequent cases. Existing methods often treat DDI prediction as
a binary problem, ignoring class-specific nuances and exacerbating bias toward
frequent interactions. To address this, we propose a framework combining
Generative Flow Networks (GFlowNet) with Variational Graph Autoencoders (VGAE)
to generate synthetic samples for rare classes, improving model balance and
generate effective and novel DDI pairs. Our approach enhances predictive
performance across interaction types, ensuring better clinical reliability.

</details>


### [644] [Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN](https://arxiv.org/abs/2508.06647)
*Andrey Sidorenko,Paul Tiwald*

Main category: cs.LG

Relevance: 30.0

TL;DR: TabularARGN是一种用于生成高质量合成表格数据的神经网络架构，具有高数据保真度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统匿名化技术无法充分保护隐私，需要更有效的合成数据生成方法。

Method: 采用基于离散化的自回归方法设计TabularARGN。

Result: 在统计相似性、机器学习实用性和检测鲁棒性方面表现优异，隐私评估显示其具有稳健的隐私-效用平衡。

Conclusion: TabularARGN是一种高效且隐私保护的合成数据生成方法。

Abstract: Synthetic data generation has become essential for securely sharing and
analyzing sensitive data sets. Traditional anonymization techniques, however,
often fail to adequately preserve privacy. We introduce the Tabular
Auto-Regressive Generative Network (TabularARGN), a neural network architecture
specifically designed for generating high-quality synthetic tabular data. Using
a discretization-based auto-regressive approach, TabularARGN achieves high data
fidelity while remaining computationally efficient. We evaluate TabularARGN
against existing synthetic data generation methods, showing competitive results
in statistical similarity, machine learning utility, and detection robustness.
We further perform an in-depth privacy evaluation using systematic
membership-inference attacks, highlighting the robustness and effective
privacy-utility balance of our approach.

</details>


### [645] [Discovery Learning accelerates battery design evaluation](https://arxiv.org/abs/2508.06985)
*Jiawei Zhang,Yifei Zhang,Baozhao Yi,Yao Ren,Qi Jiao,Hanyu Bai,Weiran Jiang,Ziyou Song*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种名为Discovery Learning（DL）的科学机器学习范式，用于快速评估电池设计寿命，显著减少时间和能源成本。


<details>
  <summary>Details</summary>
Motivation: 电池研发因高成本的原型设计和寿命测试而受限，现有数据驱动方法需目标设计的标记数据且效率不足。

Method: DL结合主动学习、物理引导学习和零样本学习，利用历史电池设计数据减少原型需求。

Result: 在123个工业级锂离子电池上测试，DL仅用公开数据集即实现7.2%的测试误差，节省98%时间和95%能源。

Conclusion: DL为高效数据驱动建模提供关键进展，加速科学发现和工程创新。

Abstract: Fast and reliable validation of novel designs in complex physical systems
such as batteries is critical to accelerating technological innovation.
However, battery research and development remain bottlenecked by the
prohibitively high time and energy costs required to evaluate numerous new
design candidates, particularly in battery prototyping and life testing.
Despite recent progress in data-driven battery lifetime prediction, existing
methods require labeled data of target designs to improve accuracy and cannot
make reliable predictions until after prototyping, thus falling far short of
the efficiency needed to enable rapid feedback for battery design. Here, we
introduce Discovery Learning (DL), a scientific machine-learning paradigm that
integrates active learning, physics-guided learning, and zero-shot learning
into a human-like reasoning loop, drawing inspiration from learning theories in
educational psychology. DL can learn from historical battery designs and
actively reduce the need for prototyping, thus enabling rapid lifetime
evaluation for unobserved material-design combinations without requiring
additional data labeling. To test DL, we present 123 industrial-grade
large-format lithium-ion pouch cells, spanning eight material-design
combinations and diverse cycling protocols. Trained solely on public datasets
of small-capacity cylindrical cells, DL achieves 7.2% test error in predicting
the average cycle life under unknown device variability. This results in
savings of 98% in time and 95% in energy compared to industrial practices. This
work highlights the potential of uncovering insights from historical designs to
inform and accelerate the development of next-generation battery technologies.
DL represents a key advance toward efficient data-driven modeling and helps
realize the promise of machine learning for accelerating scientific discovery
and engineering innovation.

</details>


### [646] [A Stage-Aware Mixture of Experts Framework for Neurodegenerative Disease Progression Modelling](https://arxiv.org/abs/2508.07032)
*Tiantian He,Keyue Jiang,An Zhao,Anna Schroder,Elinor Thompson,Sonja Soskic,Frederik Barkhof,Daniel C. Alexander*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种基于阶段感知的混合专家框架（IGND-MoE），用于建模神经退行性疾病的动态进展，结合了图神经扩散和局部反应模块。


<details>
  <summary>Details</summary>
Motivation: 解决神经退行性疾病进展建模中的挑战，包括纵向数据稀缺和病理机制的复杂动态变化。

Method: 使用阶段感知的混合专家框架（MoE）和时间依赖的专家权重，结合非均匀图神经扩散模型（IGND）和局部神经反应模块。

Result: 模型能够动态捕捉不同疾病阶段的病理机制，提供了与文献一致的临床见解。

Conclusion: IGND-MoE为理解神经退行性疾病的动态进展提供了新方法。

Abstract: The long-term progression of neurodegenerative diseases is commonly
conceptualized as a spatiotemporal diffusion process that consists of a graph
diffusion process across the structural brain connectome and a localized
reaction process within brain regions. However, modeling this progression
remains challenging due to 1) the scarcity of longitudinal data obtained
through irregular and infrequent subject visits and 2) the complex interplay of
pathological mechanisms across brain regions and disease stages, where
traditional models assume fixed mechanisms throughout disease progression. To
address these limitations, we propose a novel stage-aware Mixture of Experts
(MoE) framework that explicitly models how different contributing mechanisms
dominate at different disease stages through time-dependent expert
weighting.Data-wise, we utilize an iterative dual optimization method to
properly estimate the temporal position of individual observations,
constructing a co hort-level progression trajectory from irregular snapshots.
Model-wise, we enhance the spatial component with an inhomogeneous graph neural
diffusion model (IGND) that allows diffusivity to vary based on node states and
time, providing more flexible representations of brain networks. We also
introduce a localized neural reaction module to capture complex dynamics beyond
standard processes.The resulting IGND-MoE model dynamically integrates these
components across temporal states, offering a principled way to understand how
stage-specific pathological mechanisms contribute to progression. The
stage-wise weights yield novel clinical insights that align with literature,
suggesting that graph-related processes are more influential at early stages,
while other unknown physical processes become dominant later on.

</details>


### [647] [BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation](https://arxiv.org/abs/2508.07106)
*Yiran Huang,Amirhossein Nouranizadeh,Christine Ahrends,Mengjia Xu*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种名为BrainATCL的无监督非参数框架，用于动态fMRI数据的自适应时间脑连接学习，结合GINE-Mamba2架构优化时空建模。


<details>
  <summary>Details</summary>
Motivation: 传统GNN难以捕捉动态fMRI数据中的长程时间依赖性，需要一种自适应方法来建模功能性连接动态。

Method: 采用自适应回溯窗口调整策略，结合GINE-Mamba2架构和脑结构功能属性，学习时空表示。

Result: 在功能连接预测和年龄估计任务中表现优异，具有强泛化能力。

Conclusion: BrainATCL为动态脑连接建模提供了一种有效方法，适用于行为与神经精神疾病研究。

Abstract: Functional Magnetic Resonance Imaging (fMRI) is an imaging technique widely
used to study human brain activity. fMRI signals in areas across the brain
transiently synchronise and desynchronise their activity in a highly structured
manner, even when an individual is at rest. These functional connectivity
dynamics may be related to behaviour and neuropsychiatric disease. To model
these dynamics, temporal brain connectivity representations are essential, as
they reflect evolving interactions between brain regions and provide insight
into transient neural states and network reconfigurations. However,
conventional graph neural networks (GNNs) often struggle to capture long-range
temporal dependencies in dynamic fMRI data. To address this challenge, we
propose BrainATCL, an unsupervised, nonparametric framework for adaptive
temporal brain connectivity learning, enabling functional link prediction and
age estimation. Our method dynamically adjusts the lookback window for each
snapshot based on the rate of newly added edges. Graph sequences are
subsequently encoded using a GINE-Mamba2 backbone to learn spatial-temporal
representations of dynamic functional connectivity in resting-state fMRI data
of 1,000 participants from the Human Connectome Project. To further improve
spatial modeling, we incorporate brain structure and function-informed edge
attributes, i.e., the left/right hemispheric identity and subnetwork membership
of brain regions, enabling the model to capture biologically meaningful
topological patterns. We evaluate our BrainATCL on two tasks: functional link
prediction and age estimation. The experimental results demonstrate superior
performance and strong generalization, including in cross-session prediction
scenarios.

</details>


### [648] [Approaching Maximal Information Extraction in Low-Signal Regimes via Multiple Instance Learning](https://arxiv.org/abs/2508.07114)
*Atakan Azakli,Bernd Stelzer*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种新的机器学习方法，通过多实例学习（MIL）提高预测精度和判别力，并验证了其理论优势。


<details>
  <summary>Details</summary>
Motivation: 解决现有分类器在极端情况下预测准确性不足的问题，并系统性地减少预测误差。

Method: 采用多实例学习（MIL）方法，分析其在不同实例数量下的缩放行为。

Result: 在特定条件下，可能从数据集中提取理论上的最大Fisher信息。

Conclusion: MIL在预测精度和判别力上优于单实例方法，适用于高挑战性任务。

Abstract: In this work, we propose a new machine learning (ML) methodology to obtain
more precise predictions for some parameters of interest in a given hypotheses
testing problem. Our proposed method also allows ML models to have more
discriminative power in cases where it is extremely challenging for
state-of-the-art classifiers to have any level of accurate predictions. This
method can also allow us to systematically decrease the error from ML models in
their predictions. In this paper, we provide a mathematical motivation why
Multiple Instance Learning (MIL) would have more predictive power over their
single-instance counterparts. We support our theoretical claims by analyzing
the behavior of the MIL models through their scaling behaviors with respect to
the number of instances on which the model makes predictions. As a concrete
application, we constrain Wilson coefficients of the Standard Model Effective
Field Theory (SMEFT) using kinematic information from subatomic particle
collision events at the Large Hadron Collider (LHC). We show that under certain
circumstances, it might be possible to extract the theoretical maximum Fisher
Information latent in a dataset.

</details>


### [649] [Multi-Level Service Performance Forecasting via Spatiotemporal Graph Neural Networks](https://arxiv.org/abs/2508.07122)
*Zhihao Xue,Yun Zi,Nia Qi,Ming Gong,Yujun Zou*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种基于时空图神经网络的性能预测算法，用于分布式后端系统的性能波动预测。


<details>
  <summary>Details</summary>
Motivation: 解决多级服务调用结构的分布式后端系统性能波动预测的挑战。

Method: 将系统状态抽象为图结构序列，结合运行时特征和服务调用关系，构建统一的时空建模框架，使用图卷积网络和高门控循环网络提取信息。

Result: 在MAE、RMSE和R2等关键指标上优于现有方法，且在负载和结构变化下表现稳健。

Conclusion: 模型在服务性能管理任务中具有实际应用潜力。

Abstract: This paper proposes a spatiotemporal graph neural network-based performance
prediction algorithm to address the challenge of forecasting performance
fluctuations in distributed backend systems with multi-level service call
structures. The method abstracts system states at different time slices into a
sequence of graph structures. It integrates the runtime features of service
nodes with the invocation relationships among services to construct a unified
spatiotemporal modeling framework. The model first applies a graph
convolutional network to extract high-order dependency information from the
service topology. Then it uses a gated recurrent network to capture the dynamic
evolution of performance metrics over time. A time encoding mechanism is also
introduced to enhance the model's ability to represent non-stationary temporal
sequences. The architecture is trained in an end-to-end manner, optimizing the
multi-layer nested structure to achieve high-precision regression of future
service performance metrics. To validate the effectiveness of the proposed
method, a large-scale public cluster dataset is used. A series of
multi-dimensional experiments are designed, including variations in time
windows and concurrent load levels. These experiments comprehensively evaluate
the model's predictive performance and stability. The experimental results show
that the proposed model outperforms existing representative methods across key
metrics such as MAE, RMSE, and R2. It maintains strong robustness under varying
load intensities and structural complexities. These results demonstrate the
model's practical potential for backend service performance management tasks.

</details>


### [650] [A Globally Optimal Analytic Solution for Semi-Nonnegative Matrix Factorization with Nonnegative or Mixed Inputs](https://arxiv.org/abs/2508.07134)
*Lu Chenggang*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种新的半非负矩阵分解方法，通过正交分解实现全局最优解，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有半非负矩阵分解算法多为迭代、非凸且易陷入局部最优，需改进。

Method: 基于输入数据的散布矩阵进行正交分解，得到全局最优解。

Result: 在合成数据和UCI Wine数据集上表现优于现有方法，重建误差更低。

Conclusion: 该方法提供了理论保证和实际优势，为矩阵分解优化提供了新视角。

Abstract: Semi-Nonnegative Matrix Factorization (semi-NMF) extends classical
Nonnegative Matrix Factorization (NMF) by allowing the basis matrix to contain
both positive and negative entries, making it suitable for decomposing data
with mixed signs. However, most existing semi-NMF algorithms are iterative,
non-convex, and prone to local minima. In this paper, we propose a novel method
that yields a globally optimal solution to the semi-NMF problem under the
Frobenius norm, through an orthogonal decomposition derived from the scatter
matrix of the input data. We rigorously prove that our solution attains the
global minimum of the reconstruction error. Furthermore, we demonstrate that
when the input matrix is nonnegative, our method often achieves lower
reconstruction error than standard NMF algorithms, although unfortunately the
basis matrix may not satisfy nonnegativity. In particular, in low-rank cases
such as rank 1 or 2, our solution reduces exactly to a nonnegative
factorization, recovering the NMF structure. We validate our approach through
experiments on both synthetic data and the UCI Wine dataset, showing that our
method consistently outperforms existing NMF and semi-NMF methods in terms of
reconstruction accuracy. These results confirm that our globally optimal,
non-iterative formulation offers both theoretical guarantees and empirical
advantages, providing a new perspective on matrix factorization in optimization
and data analysis.

</details>


### [651] [PySeizure: A single machine learning classifier framework to detect seizures in diverse datasets](https://arxiv.org/abs/2508.07253)
*Bartlomiej Chybowski,Shima Abdullateef,Hollan Haule,Alfredo Gonzalez-Sulser,Javier Escudero*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种开源机器学习框架，用于跨不同临床数据集的可靠癫痫发作检测，通过自动预处理和多数投票机制提高了模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有癫痫检测方法依赖数据集特定优化、缺乏泛化性和可重复性的问题。

Method: 开发了一个包含自动预处理和多数投票机制的开源框架，并在两个公开EEG数据集上评估模型的跨数据集泛化能力。

Result: 模型在数据集内表现优异（AUC 0.904和0.864），跨数据集泛化能力较强（AUC 0.615和0.762），且后处理进一步提升了性能。

Conclusion: 该框架为临床可行的、数据集无关的癫痫检测系统提供了基础，具有广泛应用的潜力。

Abstract: Reliable seizure detection is critical for diagnosing and managing epilepsy,
yet clinical workflows remain dependent on time-consuming manual EEG
interpretation. While machine learning has shown promise, existing approaches
often rely on dataset-specific optimisations, limiting their real-world
applicability and reproducibility. Here, we introduce an innovative,
open-source machine-learning framework that enables robust and generalisable
seizure detection across varied clinical datasets. We evaluate our approach on
two publicly available EEG datasets that differ in patient populations and
electrode configurations. To enhance robustness, the framework incorporates an
automated pre-processing pipeline to standardise data and a majority voting
mechanism, in which multiple models independently assess each second of EEG
before reaching a final decision. We train, tune, and evaluate models within
each dataset, assessing their cross-dataset transferability. Our models achieve
high within-dataset performance (AUC 0.904+/-0.059 for CHB-MIT and
0.864+/-0.060 for TUSZ) and demonstrate strong generalisation across datasets
despite differences in EEG setups and populations (AUC 0.615+/-0.039 for models
trained on CHB-MIT and tested on TUSZ and 0.762+/-0.175 in the reverse case)
without any post-processing. Furthermore, a mild post-processing improved the
within-dataset results to 0.913+/-0.064 and 0.867+/-0.058 and cross-dataset
results to 0.619+/-0.036 and 0.768+/-0.172. These results underscore the
potential of, and essential considerations for, deploying our framework in
diverse clinical settings. By making our methodology fully reproducible, we
provide a foundation for advancing clinically viable, dataset-agnostic seizure
detection systems. This approach has the potential for widespread adoption,
complementing rather than replacing expert interpretation, and accelerating
clinical integration.

</details>


### [652] [Unsupervised operator learning approach for dissipative equations via Onsager principle](https://arxiv.org/abs/2508.07440)
*Zhipeng Chang,Zhenye Wen,Xiaofei Zhao*

Main category: cs.LG

Relevance: 30.0

TL;DR: DOOL是一种无监督框架，用于解决耗散方程，无需标记数据，通过时空解耦策略提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高保真模拟数据，计算成本高，DOOL旨在解决这一问题。

Method: 基于Onsager变分原理，直接最小化Rayleighian函数，采用时空解耦策略。

Result: 数值实验验证了DOOL的有效性，性能优于监督方法DeepONet和MIONet。

Conclusion: DOOL为耗散方程提供了一种高效的无监督解决方案。

Abstract: Existing operator learning methods rely on supervised training with
high-fidelity simulation data, introducing significant computational cost. In
this work, we propose the deep Onsager operator learning (DOOL) method, a novel
unsupervised framework for solving dissipative equations. Rooted in the Onsager
variational principle (OVP), DOOL trains a deep operator network by directly
minimizing the OVP-defined Rayleighian functional, requiring no labeled data,
and then proceeds in time explicitly through conservation/change laws for the
solution. Another key innovation here lies in the spatiotemporal decoupling
strategy: the operator's trunk network processes spatial coordinates
exclusively, thereby enhancing training efficiency, while integrated external
time stepping enables temporal extrapolation. Numerical experiments on typical
dissipative equations validate the effectiveness of the DOOL method, and
systematic comparisons with supervised DeepONet and MIONet demonstrate its
enhanced performance. Extensions are made to cover the second-order wave models
with dissipation that do not directly follow OVP.

</details>


### [653] [Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications](https://arxiv.org/abs/2508.07473)
*Zijian Liu*

Main category: cs.LG

Relevance: 30.0

TL;DR: 该论文研究了在线凸优化（OCO）中梯度估计具有重尾分布时的性能，证明了经典算法无需修改即可实现最优遗憾界，并扩展了其在非光滑非凸优化中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决OCO中梯度估计具有重尾分布时的性能问题，填补现有理论空白。

Method: 分析了经典OCO算法（如在线梯度下降）在重尾梯度下的性能，无需算法修改。

Result: 证明了这些算法在重尾梯度下仍能实现最优遗憾界，并扩展了其在非光滑非凸优化中的应用。

Conclusion: 结论表明OCO在重尾梯度下无需额外操作（如梯度裁剪）即可有效解决，且结果具有广泛适用性。

Abstract: In Online Convex Optimization (OCO), when the stochastic gradient has a
finite variance, many algorithms provably work and guarantee a sublinear
regret. However, limited results are known if the gradient estimate has a heavy
tail, i.e., the stochastic gradient only admits a finite $\mathsf{p}$-th
central moment for some $\mathsf{p}\in\left(1,2\right]$. Motivated by it, this
work examines different old algorithms for OCO (e.g., Online Gradient Descent)
in the more challenging heavy-tailed setting. Under the standard bounded domain
assumption, we establish new regrets for these classical methods without any
algorithmic modification. Remarkably, these regret bounds are fully optimal in
all parameters (can be achieved even without knowing $\mathsf{p}$), suggesting
that OCO with heavy tails can be solved effectively without any extra operation
(e.g., gradient clipping). Our new results have several applications. A
particularly interesting one is the first provable convergence result for
nonsmooth nonconvex optimization under heavy-tailed noise without gradient
clipping. Furthermore, we explore broader settings (e.g., smooth OCO) and
extend our ideas to optimistic algorithms to handle different cases
simultaneously.

</details>


### [654] [Topological Feature Compression for Molecular Graph Neural Networks](https://arxiv.org/abs/2508.07807)
*Rahul Khorana*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种新型图神经网络（GNN）架构，结合高阶拓扑信号与标准分子特征，以平衡预测准确性、可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决分子表示学习中提取通用化学洞察的挑战，同时兼顾准确性、可解释性和计算效率。

Method: 采用压缩高阶拓扑信号与标准分子特征结合的GNN架构，捕获全局几何信息并保持计算可处理性和可解释性。

Result: 在多个基准测试中表现优异，包括小分子和复杂材料数据集，实现了最佳准确性和鲁棒性。

Conclusion: 提出的GNN架构在分子表示学习中表现出色，同时开源了代码。

Abstract: Recent advances in molecular representation learning have produced highly
effective encodings of molecules for numerous cheminformatics and
bioinformatics tasks. However, extracting general chemical insight while
balancing predictive accuracy, interpretability, and computational efficiency
remains a major challenge. In this work, we introduce a novel Graph Neural
Network (GNN) architecture that combines compressed higher-order topological
signals with standard molecular features. Our approach captures global
geometric information while preserving computational tractability and
human-interpretable structure. We evaluate our model across a range of
benchmarks, from small-molecule datasets to complex material datasets, and
demonstrate superior performance using a parameter-efficient architecture. We
achieve the best performing results in both accuracy and robustness across
almost all benchmarks. We open source all code \footnote{All code and results
can be found on Github https://github.com/rahulkhorana/TFC-PACT-Net}.

</details>


### [655] [Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow](https://arxiv.org/abs/2508.07841)
*Carlo Cena,Mauro Martini,Marcello Chiaberge*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文研究了将物理信息神经网络（PINNs）引入航天器姿态动力学学习，与纯数据驱动方法相比，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 在航天器姿态控制中，物理模型可能不完整或计算昂贵，纯数据驱动方法泛化性和稳定性不足，因此探索PINNs的潜力。

Method: 使用带自注意力机制的Real NVP神经网络架构，基于Basilisk模拟器生成数据，比较纯数据驱动和物理信息变体的训练策略。

Result: 物理信息方法将最佳架构的平均相对误差降低了27.08%，在MPC框架中控制精度和鲁棒性提升高达42.86%。

Conclusion: PINNs显著提升航天器姿态动力学学习的性能，尤其在MPC中表现优越。

Abstract: Attitude control is a fundamental aspect of spacecraft operations. Model
Predictive Control (MPC) has emerged as a powerful strategy for these tasks,
relying on accurate models of the system dynamics to optimize control actions
over a prediction horizon. In scenarios where physics models are incomplete,
difficult to derive, or computationally expensive, machine learning offers a
flexible alternative by learning the system behavior directly from data.
However, purely data-driven models often struggle with generalization and
stability, especially when applied to inputs outside their training domain. To
address these limitations, we investigate the benefits of incorporating
Physics-Informed Neural Networks (PINNs) into the learning of spacecraft
attitude dynamics, comparing their performance with that of purely data-driven
approaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network
architecture with a self-attention mechanism, we trained several models on
simulated data generated with the Basilisk simulator. Two training strategies
were considered: a purely data-driven baseline and a physics-informed variant
to improve robustness and stability. Our results demonstrate that the inclusion
of physics-based information significantly enhances the performance in terms of
the mean relative error of the best architectures found by 27.08%. These
advantages are particularly evident when the learned models are integrated into
an MPC framework, where PINN-based models consistently outperform their purely
data-driven counterparts in terms of control accuracy and robustness, yielding
improvements of up to 42.86% in performance stability error and increased
robustness-to-noise.

</details>


### [656] [Adaptive Fine-Tuning via Pattern Specialization for Deep Time Series Forecasting](https://arxiv.org/abs/2508.07927)
*Amal Saadallah,Abdulaziz Al-Ademi*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种通过模型适应和选择增强DNN性能的新框架，用于非平稳环境中的时间序列预测。


<details>
  <summary>Details</summary>
Motivation: 解决非平稳环境中时间序列预测的挑战，适应随时间变化的模式。

Method: 离线训练基础DNN，通过聚类识别模式并微调专用模型，结合概念漂移检测。

Result: 在GluonTS库中实现，显著提升了传统和先进DNN架构的性能。

Conclusion: 框架通用性强，适用于多种DNN架构，能有效应对非平稳性。

Abstract: Time series forecasting poses significant challenges in non-stationary
environments where underlying patterns evolve over time. In this work, we
propose a novel framework that enhances deep neural network (DNN) performance
by leveraging specialized model adaptation and selection. Initially, a base DNN
is trained offline on historical time series data. A reserved validation subset
is then segmented to extract and cluster the most dominant patterns within the
series, thereby identifying distinct regimes. For each identified cluster, the
base DNN is fine-tuned to produce a specialized version that captures unique
pattern characteristics. At inference, the most recent input is matched against
the cluster centroids, and the corresponding fine-tuned version is deployed
based on the closest similarity measure. Additionally, our approach integrates
a concept drift detection mechanism to identify and adapt to emerging patterns
caused by non-stationary behavior. The proposed framework is generalizable
across various DNN architectures and has demonstrated significant performance
gains on both traditional DNNs and recent advanced architectures implemented in
the GluonTS library.

</details>


### [657] [A Physics-informed Deep Operator for Real-Time Freeway Traffic State Estimation](https://arxiv.org/abs/2508.08002)
*Hongxin Yu,Yibing Wang,Fengyue Jin,Meng Zhang,Anni Chen*

Main category: cs.LG

Relevance: 30.0

TL;DR: 本文提出了一种基于物理信息的深度算子网络（PI-DeepONet）的实时高速公路交通状态估计方法，通过扩展架构支持2D数据输入、引入非线性扩展层和注意力机制，并实现了高精度的流量和速度估计。


<details>
  <summary>Details</summary>
Motivation: 交通状态估计（TSE）通常分为模型驱动、数据驱动和模型-数据双驱动三类。本文旨在结合物理模型和数据驱动方法的优势，提出一种更准确的TSE方法。

Method: 扩展了PI-DeepONet架构，支持2D数据输入（CNN计算）、引入非线性扩展层、注意力机制和MIMO机制，并设计了自适应识别交通流模型参数的神经网络。

Result: 在NGSIM短高速公路段和中国大规模城市快速路的评估中，该方法在流量和平均速度估计上优于四种基线方法。

Conclusion: 基于扩展PI-DeepONet架构的TSE方法显著提升了交通状态估计的精度。

Abstract: Traffic state estimation (TSE) falls methodologically into three categories:
model-driven, data-driven, and model-data dual-driven. Model-driven TSE relies
on macroscopic traffic flow models originated from hydrodynamics. Data-driven
TSE leverages historical sensing data and employs statistical models or machine
learning methods to infer traffic state. Model-data dual-driven traffic state
estimation attempts to harness the strengths of both aspects to achieve more
accurate TSE. From the perspective of mathematical operator theory, TSE can be
viewed as a type of operator that maps available measurements of inerested
traffic state into unmeasured traffic state variables in real time. For the
first time this paper proposes to study real-time freeway TSE in the idea of
physics-informed deep operator network (PI-DeepONet), which is an
operator-oriented architecture embedding traffic flow models based on deep
neural networks. The paper has developed an extended architecture from the
original PI-DeepONet. The extended architecture is featured with: (1) the
acceptance of 2-D data input so as to support CNN-based computations; (2) the
introduction of a nonlinear expansion layer, an attention mechanism, and a MIMO
mechanism; (3) dedicated neural network design for adaptive identification of
traffic flow model parameters. A traffic state estimator built on the basis of
this extended PI-DeepONet architecture was evaluated with respect to a short
freeway stretch of NGSIM and a large-scale urban expressway in China, along
with other four baseline TSE methods. The evaluation results demonstrated that
this novel TSE method outperformed the baseline methods with high-precision
estimation results of flow and mean speed.

</details>


### [658] [Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP](https://arxiv.org/abs/2508.08005)
*Xiang Li,Shanshan Wang,Chenglong Xiao*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种基于学习的框架，结合传统机器学习和图神经网络，用于解决最大团问题的算法选择问题。通过实验验证，随机森林表现稳定，而提出的双通道模型GAT-MLP在所有指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏针对最大团问题的算法选择方法，因此需要一种能够根据图实例特征自动选择最优算法的框架。

Method: 构建了一个标注数据集，使用四种传统分类器（SVM、RF、DT、KNN）进行评估，并开发了结合GAT和MLP的双通道模型GAT-MLP。

Result: 随机森林表现稳定，GAT-MLP在所有指标上表现最优，证明了双通道架构和图神经网络在算法选择中的有效性。

Conclusion: 双通道架构和图神经网络在组合算法选择中具有潜力，为解决类似问题提供了新思路。

Abstract: Extensive experiments and prior studies show that no single maximum clique
algorithm consistently performs best across all instances, highlighting the
importance of selecting suitable algorithms based on instance features. Through
an extensive analysis of relevant studies, it is found that there is a lack of
research work concerning algorithm selection oriented toward the Maximum Clique
Problem (MCP). In this work, we propose a learning-based framework that
integrates both traditional machine learning and graph neural networks to
address this gap. We construct a labeled dataset by running four exact MCP
algorithms on a diverse collection of graph instances, accompanied by
structural and global statistical features extracted from each graph. We first
evaluate four conventional classifiers: Support Vector Machine (SVM), Random
Forest (RF), Decision Tree (DT), and K-Nearest Neighbors (KNN), across multiple
dataset variants. Experimental results show that RF consistently shows strong
performance across metrics and dataset variants, making it a reliable baseline.
In addition, feature importance analysis indicates that connectivity and
topological structure are strong predictors of algorithm performance. Building
on these findings, we develop a dual-channel model named GAT-MLP, which
combines a Graph Attention Network (GAT) for local structural encoding with a
Multilayer Perceptron (MLP) for global feature modeling. The GAT-MLP model
shows strong and consistent performance across all metrics. Our results
highlight the effectiveness of dual-channel architectures and the promise of
graph neural networks in combinatorial algorithm selection.

</details>


### [659] [From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations](https://arxiv.org/abs/2508.08061)
*Sven Weinzierl,Sandra Zilker,Annina Liessmann,Martin Käppel,Weixin Wang,Martin Matzner*

Main category: cs.LG

Relevance: 30.0

TL;DR: 该论文提出了一种基于迁移学习的预测过程监控（PPM）技术，帮助缺乏足够事件数据或资源的组织实现有效的决策支持。


<details>
  <summary>Details</summary>
Motivation: 现有PPM技术需要大量事件数据或其他资源，限制了部分组织的应用。本文旨在通过迁移学习解决这一问题。

Method: 提出了一种迁移学习技术，并在两个实际案例中进行了实验，使用IT服务管理过程的事件日志。

Result: 实验结果表明，可以将一个业务流程的知识迁移到类似业务流程中，实现有效的PPM。

Conclusion: 该技术使组织能够在内部和跨组织环境中利用迁移学习，提升PPM效果。

Abstract: Event logs reflect the behavior of business processes that are mapped in
organizational information systems. Predictive process monitoring (PPM)
transforms these data into value by creating process-related predictions that
provide the insights required for proactive interventions at process runtime.
Existing PPM techniques require sufficient amounts of event data or other
relevant resources that might not be readily available, preventing some
organizations from utilizing PPM. The transfer learning-based PPM technique
presented in this paper allows organizations without suitable event data or
other relevant resources to implement PPM for effective decision support. The
technique is instantiated in two real-life use cases, based on which numerical
experiments are performed using event logs for IT service management processes
in an intra- and inter-organizational setting. The results of the experiments
suggest that knowledge of one business process can be transferred to a similar
business process in the same or a different organization to enable effective
PPM in the target context. With the proposed technique, organizations can
benefit from transfer learning in an intra- and inter-organizational setting,
where resources like pre-trained models are transferred within and across
organizational boundaries.

</details>


### [660] [Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles](https://arxiv.org/abs/2508.08034)
*Roksana Yahyaabadi,Ghazal Farhani,Taufiq Rahman,Soodeh Nikan,Abdullah Jirjees,Fadi Araji*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种基于数据驱动的方法，结合传统机器学习和深度神经网络，用于预测内燃机、电动车和混合动力车的瞬时和累计功率消耗。结果显示该方法在不同车型上均有效。


<details>
  <summary>Details</summary>
Motivation: 传统功率消耗预测方法依赖专用仪器或物理模型，难以大规模部署，因此需要一种更实用的数据驱动方法。

Method: 使用动力系统动态特征集，结合传统机器学习和深度神经网络（如Transformer和LSTM）进行预测。

Result: 内燃机模型的瞬时误差极低（$10^{-3}$量级），累计误差低于3%；电动车和混合动力车的累计误差分别低于4.1%和2.1%。

Conclusion: 该方法在不同车型上均表现良好，但电动车和混合动力车的数据变异性更高，需更鲁棒的模型。

Abstract: Accurate power consumption prediction is crucial for improving efficiency and
reducing environmental impact, yet traditional methods relying on specialized
instruments or rigid physical models are impractical for large-scale,
real-world deployment. This study introduces a scalable data-driven method
using powertrain dynamic feature sets and both traditional machine learning and
deep neural networks to estimate instantaneous and cumulative power consumption
in internal combustion engine (ICE), electric vehicle (EV), and hybrid electric
vehicle (HEV) platforms. ICE models achieved high instantaneous accuracy with
mean absolute error and root mean squared error on the order of $10^{-3}$, and
cumulative errors under 3%. Transformer and long short-term memory models
performed best for EVs and HEVs, with cumulative errors below 4.1% and 2.1%,
respectively. Results confirm the approach's effectiveness across vehicles and
models. Uncertainty analysis revealed greater variability in EV and HEV
datasets than ICE, due to complex power management, emphasizing the need for
robust models for advanced powertrains.

</details>


### [661] [C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction](https://arxiv.org/abs/2508.08071)
*Yunqing Li,Zixiang Tang,Jiaying Zhuang,Zhenyu Yang,Farhad Ameri,Jianbang Zhang*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了PMGraph基准和C-MAG架构，用于供应链中的多模态图链接预测。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉供应链中复杂的多模态数据，需要更高效的解决方案。

Method: 提出C-MAG架构，分两阶段对齐多模态属性并通过异构图传播信息。

Result: C-MAG提高了链接预测的准确性，并提供了噪声环境下的实用指南。

Conclusion: C-MAG为供应链中的多模态图学习提供了有效框架。

Abstract: Connecting an ever-expanding catalogue of products with suitable
manufacturers and suppliers is critical for resilient, efficient global supply
chains, yet traditional methods struggle to capture complex capabilities,
certifications, geographic constraints, and rich multimodal data of real-world
manufacturer profiles. To address these gaps, we introduce PMGraph, a public
benchmark of bipartite and heterogeneous multimodal supply-chain graphs linking
8,888 manufacturers, over 70k products, more than 110k manufacturer-product
edges, and over 29k product images. Building on this benchmark, we propose the
Cascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first
aligns and aggregates textual and visual attributes into intermediate group
embeddings, then propagates them through a manufacturer-product hetero-graph
via multiscale message passing to enhance link prediction accuracy. C-MAG also
provides practical guidelines for modality-aware fusion, preserving predictive
performance in noisy, real-world settings.

</details>


### [662] [Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation](https://arxiv.org/abs/2508.08087)
*Amir Ali Panahi,Daniel Luder,Billy Wu,Gregory Offer,Dirk Uwe Sauer,Weihan Li*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种参数嵌入傅里叶神经算子（PE-FNO），用于锂离子电池的高保真数字孪生，在速度和精度上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 实现锂离子电池高保真且快速的数字孪生模型，满足实时电池管理和实验设计的需求。

Method: 比较了DeepONet、FNO和新提出的PE-FNO在模拟数据上的表现，PE-FNO通过参数嵌入实现泛化能力。

Result: PE-FNO在速度和精度上优于传统方法，电压误差低于1.7 mV，执行速度比传统求解器快200倍。

Conclusion: PE-FNO为电池管理提供了高保真、高速度的解决方案，优于现有神经代理方法。

Abstract: Reliable digital twins of lithium-ion batteries must achieve high physical
fidelity with sub-millisecond speed. In this work, we benchmark three
operator-learning surrogates for the Single Particle Model (SPM): Deep Operator
Networks (DeepONets), Fourier Neural Operators (FNOs) and a newly proposed
parameter-embedded Fourier Neural Operator (PE-FNO), which conditions each
spectral layer on particle radius and solid-phase diffusivity. Models are
trained on simulated trajectories spanning four current families (constant,
triangular, pulse-train, and Gaussian-random-field) and a full range of
State-of-Charge (SOC) (0 % to 100 %). DeepONet accurately replicates
constant-current behaviour but struggles with more dynamic loads. The basic FNO
maintains mesh invariance and keeps concentration errors below 1 %, with
voltage mean-absolute errors under 1.7 mV across all load types. Introducing
parameter embedding marginally increases error, but enables generalisation to
varying radii and diffusivities. PE-FNO executes approximately 200 times faster
than a 16-thread SPM solver. Consequently, PE-FNO's capabilities in inverse
tasks are explored in a parameter estimation task with Bayesian optimisation,
recovering anode and cathode diffusivities with 1.14 % and 8.4 % mean absolute
percentage error, respectively, and 0.5918 percentage points higher error in
comparison with classical methods. These results pave the way for neural
operators to meet the accuracy, speed and parametric flexibility demands of
real-time battery management, design-of-experiments and large-scale inference.
PE-FNO outperforms conventional neural surrogates, offering a practical path
towards high-speed and high-fidelity electrochemical digital twins.

</details>


### [663] [Grid2Guide: A* Enabled Small Language Model for Indoor Navigation](https://arxiv.org/abs/2508.08100)
*Md. Wasiul Haque,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.LG

Relevance: 30.0

TL;DR: Grid2Guide结合A*算法和小型语言模型（SLM），为复杂室内环境提供轻量级、无基础设施的导航解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决复杂室内环境中无外部定位信号和专用基础设施的可靠导航问题。

Method: 使用A*算法生成最优路径，并通过SLM将路径转换为自然语言指令。

Result: 实验证明该方法能生成准确、实时的导航指导。

Conclusion: Grid2Guide是一种有效的轻量级室内导航解决方案。

Abstract: Reliable indoor navigation remains a significant challenge in complex
environments, particularly where external positioning signals and dedicated
infrastructures are unavailable. This research presents Grid2Guide, a hybrid
navigation framework that combines the A* search algorithm with a Small
Language Model (SLM) to generate clear, human-readable route instructions. The
framework first conducts a binary occupancy matrix from a given indoor map.
Using this matrix, the A* algorithm computes the optimal path between origin
and destination, producing concise textual navigation steps. These steps are
then transformed into natural language instructions by the SLM, enhancing
interpretability for end users. Experimental evaluations across various indoor
scenarios demonstrate the method's effectiveness in producing accurate and
timely navigation guidance. The results validate the proposed approach as a
lightweight, infrastructure-free solution for real-time indoor navigation
support.

</details>


### [664] [Federated Learning for Epileptic Seizure Prediction Across Heterogeneous EEG Datasets](https://arxiv.org/abs/2508.08159)
*Cem Ata Baykara,Saurav Raj Pandey,Ali Burak Ünal,Harlin Lee,Mete Akgün*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种基于联邦学习的癫痫发作预测方法，通过随机子集聚合策略解决数据异构性问题，提升了模型在隐私保护下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多临床中心的EEG数据因隐私和异构性难以共享，传统联邦学习方法在非IID数据下表现不佳。

Method: 采用隐私保护的全局归一化和随机子集聚合策略，确保各客户端在聚合中贡献均衡。

Result: 随机子集聚合显著提升了弱势客户端的性能，宏观平均准确率达77.1%，优于传统加权FedAvg。

Conclusion: 平衡的联邦学习方法在异构多中心环境中有效且公平，同时保护数据隐私。

Abstract: Developing accurate and generalizable epileptic seizure prediction models
from electroencephalography (EEG) data across multiple clinical sites is
hindered by patient privacy regulations and significant data heterogeneity
(non-IID characteristics). Federated Learning (FL) offers a privacy-preserving
framework for collaborative training, but standard aggregation methods like
Federated Averaging (FedAvg) can be biased by dominant datasets in
heterogeneous settings. This paper investigates FL for seizure prediction using
a single EEG channel across four diverse public datasets (Siena, CHB-MIT,
Helsinki, NCH), representing distinct patient populations (adult, pediatric,
neonate) and recording conditions. We implement privacy-preserving global
normalization and propose a Random Subset Aggregation strategy, where each
client trains on a fixed-size random subset of its data per round, ensuring
equal contribution during aggregation. Our results show that locally trained
models fail to generalize across sites, and standard weighted FedAvg yields
highly skewed performance (e.g., 89.0% accuracy on CHB-MIT but only 50.8% on
Helsinki and 50.6% on NCH). In contrast, Random Subset Aggregation
significantly improves performance on under-represented clients (accuracy
increases to 81.7% on Helsinki and 68.7% on NCH) and achieves a superior
macro-average accuracy of 77.1% and pooled accuracy of 80.0% across all sites,
demonstrating a more robust and fair global model. This work highlights the
potential of balanced FL approaches for building effective and generalizable
seizure prediction systems in realistic, heterogeneous multi-hospital
environments while respecting data privacy.

</details>


### [665] [Benchmarking Self-Driving Labs](https://arxiv.org/abs/2508.06642)
*Adedire D. Adesiji,Jiashuo Wang,Cheng-Shu Kuo,Keith A. Brown*

Main category: physics.comp-ph

Relevance: 30.0

TL;DR: 该论文综述了自驱动实验室（SDLs）在加速材料发现中的作用，量化了其相对于传统方法的实验减少效果，并提出了两种关键指标（AF和EF）来衡量其性能。


<details>
  <summary>Details</summary>
Motivation: 加速材料发现是现代材料科学的关键目标，SDLs通过机器学习和自动化实现更快速、更智能的实验执行。

Method: 综述了SDLs的理论基础，量化了AF和EF指标，并通过文献综述和模拟实验分析了其性能。

Result: 研究发现AF的中位数为6，且随空间维度增加而提高；EF值波动较大，但通常在10-20实验/维度达到峰值。

Conclusion: SDL在多种材料参数空间中表现出显著加速效果，为量化其性能提供了通用语言。

Abstract: A key goal of modern materials science is accelerating the pace of materials
discovery. Self-driving labs, or systems that select experiments using machine
learning and then execute them using automation, are designed to fulfil this
promise by performing experiments faster, more intelligently, more reliably,
and with richer metadata than conventional means. This review summarizes
progress in understanding the degree to which SDLs accelerate learning by
quantifying how much they reduce the number of experiments required for a given
goal. The review begins by summarizing the theory underlying two key metrics,
namely acceleration factor AF and enhancement factor EF, which quantify how
much faster and better an algorithm is relative to a reference strategy. Next,
we provide a comprehensive review of the literature, which reveals a wide range
of AFs with a median of 6, and that tends to increase with the dimensionality
of the space, reflecting an interesting blessing of dimensionality. In
contrast, reported EF values vary by over two orders of magnitude, although
they consistently peak at 10-20 experiments per dimension. To understand these
results, we perform a series of simulated Bayesian optimization campaigns that
reveal how EF depends upon the statistical properties of the parameter space
while AF depends on its complexity. Collectively, these results reinforce the
motivation for using SDLs by revealing their value across a wide range of
material parameter spaces and provide a common language for quantifying and
understanding this acceleration.

</details>


### [666] [Federated Online Learning for Heterogeneous Multisource Streaming Data](https://arxiv.org/abs/2508.06652)
*Jingmao Li,Yuanxing Chen,Shuangge Ma,Kuangnan Fang*

Main category: stat.ML

Relevance: 30.0

TL;DR: 提出了一种联邦在线学习（FOL）方法，用于分布式多源流数据分析，结合个性化模型和子组假设，确保隐私并减少存储需求。


<details>
  <summary>Details</summary>
Motivation: 解决现有联邦学习方法在流数据场景下的局限性，特别是高维数据下的存储和算法设计挑战。

Method: 采用惩罚可再生估计方法和高效近端梯度下降进行模型训练，结合个性化模型和子组假设。

Result: 理论证明了模型估计、变量选择和子组结构恢复的一致性，仿真和实际数据应用显示优越性能。

Conclusion: FOL方法在隐私保护和存储效率方面表现优异，适用于流数据场景。

Abstract: Federated learning has emerged as an essential paradigm for distributed
multi-source data analysis under privacy concerns. Most existing federated
learning methods focus on the ``static" datasets. However, in many real-world
applications, data arrive continuously over time, forming streaming datasets.
This introduces additional challenges for data storage and algorithm design,
particularly under high-dimensional settings. In this paper, we propose a
federated online learning (FOL) method for distributed multi-source streaming
data analysis. To account for heterogeneity, a personalized model is
constructed for each data source, and a novel ``subgroup" assumption is
employed to capture potential similarities, thereby enhancing model
performance. We adopt the penalized renewable estimation method and the
efficient proximal gradient descent for model training. The proposed method
aligns with both federated and online learning frameworks: raw data are not
exchanged among sources, ensuring data privacy, and only summary statistics of
previous data batches are required for model updates, significantly reducing
storage demands. Theoretically, we establish the consistency properties for
model estimation, variable selection, and subgroup structure recovery,
demonstrating optimal statistical efficiency. Simulations illustrate the
effectiveness of the proposed method. Furthermore, when applied to the
financial lending data and the web log data, the proposed method also exhibits
advantageous prediction performance. Results of the analysis also provide some
practical insights.

</details>


### [667] [Machines Learn Number Fields, But How? The Case of Galois Groups](https://arxiv.org/abs/2508.06670)
*Kyu-Hwan Lee,Seewoo Lee*

Main category: math.NT

Relevance: 30.0

TL;DR: 论文通过可解释机器学习方法（如决策树）研究如何利用Dedekind zeta系数分类Galois群，并揭示了zeta系数分布与Galois群的关系。


<details>
  <summary>Details</summary>
Motivation: 探索机器学习在数学研究中的应用，特别是分类Galois群的新方法。

Method: 使用决策树等可解释机器学习方法，分析Dedekind zeta系数以分类Galois群。

Result: 揭示了zeta系数分布与Galois群的关系，并提出了新的分类标准。

Conclusion: 机器学习为数学研究提供了新范式，推动了Galois群分类的进展。

Abstract: By applying interpretable machine learning methods such as decision trees, we
study how simple models can classify the Galois groups of Galois extensions
over $\mathbb{Q}$ of degrees 4, 6, 8, 9, and 10, using Dedekind zeta
coefficients. Our interpretation of the machine learning results allows us to
understand how the distribution of zeta coefficients depends on the Galois
group, and to prove new criteria for classifying the Galois groups of these
extensions. Combined with previous results, this work provides another example
of a new paradigm in mathematical research driven by machine learning.

</details>


### [668] [A Tight Lower Bound for the Approximation Guarantee of Higher-Order Singular Value Decomposition](https://arxiv.org/abs/2508.06693)
*Matthew Fahrbach,Mehrdad Ghadiri*

Main category: cs.DS

Relevance: 30.0

TL;DR: 论文证明了高阶奇异值分解（HOSVD）的经典近似保证是紧的，并构造了一个张量使得HOSVD的近似比达到$N/(1+\varepsilon)$。此外，还证明了ST-HOSVD和HOOI算法的近似保证也是紧的。


<details>
  <summary>Details</summary>
Motivation: 研究高阶奇异值分解及其变体算法的近似性能极限，验证其理论边界是否紧致。

Method: 通过构造特定张量，验证HOSVD、ST-HOSVD和HOOI算法在最坏情况下的近似比。

Result: 证明了HOSVD、ST-HOSVD和HOOI的近似比均为$N/(1+\varepsilon)$，表明其理论边界无法改进。

Conclusion: 高阶奇异值分解及其变体算法的近似性能已达到理论极限，无法进一步优化。

Abstract: We prove that the classic approximation guarantee for the higher-order
singular value decomposition (HOSVD) is tight by constructing a tensor for
which HOSVD achieves an approximation ratio of $N/(1+\varepsilon)$, for any
$\varepsilon > 0$. This matches the upper bound of De Lathauwer et al. (2000a)
and shows that the approximation ratio of HOSVD cannot be improved. Using a
more advanced construction, we also prove that the approximation guarantees for
the ST-HOSVD algorithm of Vannieuwenhoven et al. (2012) and higher-order
orthogonal iteration (HOOI) of De Lathauwer et al. (2000b) are tight by showing
that they can achieve their worst-case approximation ratio of $N / (1 +
\varepsilon)$, for any $\varepsilon > 0$.

</details>


### [669] [Energy Efficient Task Offloading in UAV-Enabled MEC Using a Fully Decentralized Deep Reinforcement Learning Approach](https://arxiv.org/abs/2508.06863)
*Hamidreza Asadian-Rad,Hossein Soleimani,Shahrokh Farahmand*

Main category: cs.MA

Relevance: 30.0

TL;DR: 论文提出了一种完全去中心化的无人机轨迹优化方法，利用图注意力层和经验共享的强化学习算法，解决了集中式方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 集中式无人机轨迹优化存在通信开销、瓶颈和鲁棒性问题，需要一种去中心化的解决方案。

Method: 采用图注意力层（GAT）和经验共享近端策略优化（EPS-PPO）的深度强化学习算法，实现无人机间的局部通信与协作。

Result: 相比现有方法（如MADDPG），性能显著提升，同时仅需局部通信。

Conclusion: 去中心化方法在性能和灵活性上优于集中式方法，适用于动态环境。

Abstract: Unmanned aerial vehicles (UAVs) have been recently utilized in multi-access
edge computing (MEC) as edge servers. It is desirable to design UAVs'
trajectories and user to UAV assignments to ensure satisfactory service to the
users and energy efficient operation simultaneously. The posed optimization
problem is challenging to solve because: (i) The formulated problem is
non-convex, (ii) Due to the mobility of ground users, their future positions
and channel gains are not known in advance, (iii) Local UAVs' observations
should be communicated to a central entity that solves the optimization
problem. The (semi-) centralized processing leads to communication overhead,
communication/processing bottlenecks, lack of flexibility and scalability, and
loss of robustness to system failures. To simultaneously address all these
limitations, we advocate a fully decentralized setup with no centralized
entity. Each UAV obtains its local observation and then communicates with its
immediate neighbors only. After sharing information with neighbors, each UAV
determines its next position via a locally run deep reinforcement learning
(DRL) algorithm. None of the UAVs need to know the global communication graph.
Two main components of our proposed solution are (i) Graph attention layers
(GAT), and (ii) Experience and parameter sharing proximal policy optimization
(EPS-PPO). Our proposed approach eliminates all the limitations of
semi-centralized MADRL methods such as MAPPO and MA deep deterministic policy
gradient (MADDPG), while guaranteeing a better performance than independent
local DRLs such as in IPPO. Numerical results reveal notable performance gains
in several different criteria compared to the existing MADDPG algorithm,
demonstrating the potential for offering a better performance, while utilizing
local communications only.

</details>


### [670] [Taking the Garbage Out of Data-Driven Prediction Across Climate Timescales](https://arxiv.org/abs/2508.07062)
*Jason C. Furtado,Maria J. Molina,Marybeth C. Arcodia,Weston Anderson,Tom Beucler,John A. Callahan,Laura M. Ciasto,Vittorio A. Gensini,Michelle L'Heureux,Kathleen Pegion,Jhayron S. Pérez-Carrasquilla,Maike Sonnewald,Ken Takahashi,Baoqiang Xiang,Brian G. Zimmerman*

Main category: physics.data-an

Relevance: 30.0

TL;DR: 论文讨论了AI/ML在气候预测中的应用，重点强调了数据预处理的重要性，并提出了标准化预处理协议以提高预测的稳健性和透明度。


<details>
  <summary>Details</summary>
Motivation: 随着AI/ML在气候预测中的广泛应用，数据预处理对模型性能的影响日益凸显。本文旨在解决这一问题，提供标准化预处理方法以提升预测质量。

Method: 文章提出了数据预处理的标准化协议，包括异常处理、非平稳性和时空相关性处理、极端值处理等，并通过案例研究验证其效果。

Result: 研究表明，不同的预处理技术会导致同一模型产生不同的预测结果，标准化预处理能显著提升模型的稳健性和透明度。

Conclusion: 通过实施推荐的预处理实践，可以增强AI/ML在气候预测中的可靠性和用户信任度。

Abstract: Artificial intelligence (AI) -- and specifically machine learning (ML) --
applications for climate prediction across timescales are proliferating
quickly. The emergence of these methods prompts a revisit to the impact of data
preprocessing, a topic familiar to the climate community, as more traditional
statistical models work with relatively small sample sizes. Indeed, the skill
and confidence in the forecasts produced by data-driven models are directly
influenced by the quality of the datasets and how they are treated during model
development, thus yielding the colloquialism "garbage in, garbage out." As
such, this article establishes protocols for the proper preprocessing of input
data for AI/ML models designed for climate prediction (i.e., subseasonal to
decadal and longer). The three aims are to: (1) educate researchers,
developers, and end users on the effects that preprocessing has on climate
predictions; (2) provide recommended practices for data preprocessing for such
applications; and (3) empower end users to decipher whether the models they are
using are properly designed for their objectives. Specific topics covered in
this article include the creation of (standardized) anomalies, dealing with
non-stationarity and the spatiotemporally correlated nature of climate data,
and handling of extreme values and variables with potentially complex
distributions. Case studies will illustrate how using different preprocessing
techniques can produce different predictions from the same model, which can
create confusion and decrease confidence in the overall process. Ultimately,
implementing the recommended practices set forth in this article will enhance
the robustness and transparency of AI/ML in climate prediction studies.

</details>


### [671] [BIGBOY1.2: Generating Realistic Synthetic Data for Disease Outbreak Modelling and Analytics](https://arxiv.org/abs/2508.07239)
*Raunak Narwal,Syed Abbas*

Main category: q-bio.PE

Relevance: 30.0

TL;DR: BIGBOY1.2是一个开放的合成数据集生成器，用于生成可配置的流行病时间序列和人口级轨迹，适用于建模、预测和可视化的基准测试。


<details>
  <summary>Details</summary>
Motivation: 由于监测数据不完整、噪声多且标准化数据集有限，疾病爆发模型建模具有挑战性。

Method: 支持SEIR和SIR类逻辑、自定义季节性和噪声注入，以模拟真实报告中的伪影。

Result: 生成具有多样化特征的数据集，适用于比较传统流行病学模型（如SIR、SEIR）与现代机器学习方法（如SVM、神经网络）。

Conclusion: BIGBOY1.2为流行病学建模提供了灵活且可配置的数据生成工具。

Abstract: Modelling disease outbreak models remains challenging due to incomplete
surveillance data, noise, and limited access to standardized datasets. We have
created BIGBOY1.2, an open synthetic dataset generator that creates
configurable epidemic time series and population-level trajectories suitable
for benchmarking modelling, forecasting, and visualisation. The framework
supports SEIR and SIR-like compartmental logic, custom seasonality, and noise
injection to mimic real reporting artifacts. BIGBOY1.2 can produce datasets
with diverse characteristics, making it suitable for comparing traditional
epidemiological models (e.g., SIR, SEIR) with modern machine learning
approaches (e.g., SVM, neural networks).

</details>


### [672] [Statistical Theory of Multi-stage Newton Iteration Algorithm for Online Continual Learning](https://arxiv.org/abs/2508.07419)
*Xinjia Lu,Chuhan Wang,Qian Zhao,Lixing Zhu,Xuehu Zhu*

Main category: stat.ME

Relevance: 30.0

TL;DR: 提出了一种新的持续学习框架，从统计角度分析灾难性遗忘问题，并开发了一种高效的多步牛顿迭代算法。


<details>
  <summary>Details</summary>
Motivation: 解决在线持续学习环境中非稳态数据流的挑战，特别是存储限制导致的灾难性遗忘问题。

Method: 提出了一种统计视角的持续学习框架，引入随机效应并允许参数维度无限扩展，同时开发了多步牛顿迭代算法以降低计算成本。

Result: 理论证明了估计量的渐近正态性，实验验证了方法的有效性。

Conclusion: 该方法在理论和实验上均表现出色，为持续学习问题提供了通用解决方案。

Abstract: We focus on the critical challenge of handling non-stationary data streams in
online continual learning environments, where constrained storage capacity
prevents complete retention of historical data, leading to catastrophic
forgetting during sequential task training. To more effectively analyze and
address the problem of catastrophic forgetting in continual learning, we
propose a novel continual learning framework from a statistical perspective.
Our approach incorporates random effects across all model parameters and allows
the dimension of parameters to diverge to infinity, offering a general
formulation for continual learning problems. To efficiently process streaming
data, we develop a Multi-step Newton Iteration algorithm that significantly
reduces computational costs in certain scenarios by alleviating the burden of
matrix inversion. Theoretically, we derive the asymptotic normality of the
estimator, enabling subsequent statistical inference. Comprehensive validation
through synthetic data experiments and two real datasets analyses demonstrates
the effectiveness of our proposed method.

</details>


### [673] [Structured Superposition of Autoencoders for UEP Codes at Intermediate Blocklengths](https://arxiv.org/abs/2508.07487)
*Vukan Ninkovic,Dejan Vukobratovic*

Main category: cs.IT

Relevance: 30.0

TL;DR: 提出了一种基于自动编码器（AE）的结构化架构，用于扩展不等错误保护（UEP）编码到更大块长度，同时保持高效训练。


<details>
  <summary>Details</summary>
Motivation: 现代通信系统需要不同可靠性级别的消息传输，但现有基于AE的UEP编码在中等块长度下复杂度高，应用受限。

Method: 采用叠加编码和连续干扰消除（SIC）解码的结构化AE架构，将编码和解码分解为更小的AE子块。

Result: 数值结果表明，该方法优于随机叠加编码的UEP方案，提升了可扩展性和效率。

Conclusion: 结构化AE-based UEP编码为下一代网络提供了高效且可扩展的解决方案。

Abstract: Unequal error protection (UEP) coding that enables differentiated reliability
levels within a transmitted message is essential for modern communication
systems. Autoencoder (AE)-based code designs have shown promise in the context
of learned equal error protection (EEP) coding schemes. However, their
application to UEP remains largely unexplored, particularly at intermediate
blocklengths, due to the increasing complexity of AE-based models. Inspired by
the proven effectiveness of superposition coding and successive interference
cancellation (SIC) decoding in conventional UEP schemes, we propose a
structured AE-based architecture that extends AE-based UEP codes to
substantially larger blocklengths while maintaining efficient training. By
structuring encoding and decoding into smaller AE subblocks, our method
provides a flexible framework for fine-tuning UEP reliability levels while
adapting to diverse system parameters. Numerical results show that the proposed
approach improves over established achievability bounds of randomized
superposition coding-based UEP schemes with SIC decoding, making the proposed
structured AE-based UEP codes a scalable and efficient solution for
next-generation networks.

</details>


### [674] [Recommendation Is a Dish Better Served Warm](https://arxiv.org/abs/2508.07856)
*Danil Gusak,Nikita Sukhorukov,Evgeny Frolov*

Main category: cs.IR

Relevance: 30.0

TL;DR: 论文探讨了推荐系统中冷启动阈值的设定问题，发现不一致的阈值选择会影响评估结果的可靠性和可比性。


<details>
  <summary>Details</summary>
Motivation: 研究冷启动阈值的设定对推荐系统评估的影响，解决阈值选择不一致导致的比较和可靠性问题。

Method: 通过实验逐步改变训练中物品的交互次数和推断中用户交互历史的长度，分析不同数据集和基线推荐系统中的阈值影响。

Result: 发现不一致的冷启动阈值选择会导致数据浪费或冷实例误分类为热实例，增加系统噪声。

Conclusion: 冷启动阈值的设定需要更系统化和一致化的方法，以提高推荐系统评估的可靠性。

Abstract: In modern recommender systems, experimental settings typically include
filtering out cold users and items based on a minimum interaction threshold.
However, these thresholds are often chosen arbitrarily and vary widely across
studies, leading to inconsistencies that can significantly affect the
comparability and reliability of evaluation results. In this paper, we
systematically explore the cold-start boundary by examining the criteria used
to determine whether a user or an item should be considered cold. Our
experiments incrementally vary the number of interactions for different items
during training, and gradually update the length of user interaction histories
during inference. We investigate the thresholds across several widely used
datasets, commonly represented in recent papers from top-tier conferences, and
on multiple established recommender baselines. Our findings show that
inconsistent selection of cold-start thresholds can either result in the
unnecessary removal of valuable data or lead to the misclassification of cold
instances as warm, introducing more noise into the system.

</details>


### [675] [Stochastic dynamics learning with state-space systems](https://arxiv.org/abs/2508.07876)
*Juan-Pablo Ortega,Florian Rossmannek*

Main category: stat.ML

Relevance: 30.0

TL;DR: 本文通过统一处理确定性和随机性设置中的衰减记忆和回声状态特性，推进了储层计算的理论基础。


<details>
  <summary>Details</summary>
Motivation: 研究储层计算（RC）的理论基础，解释其经验成功的原因，尤其是在缺乏严格收缩条件的情况下。

Method: 分析状态空间系统，提出一种基于概率分布吸引子动力学的新分布视角。

Result: 证明了衰减记忆和解决方案稳定性在一般情况下成立，扩展了非自治动力系统的理论。

Conclusion: 为确定性及随机性时间序列数据的可靠生成建模奠定了基础。

Abstract: This work advances the theoretical foundations of reservoir computing (RC) by
providing a unified treatment of fading memory and the echo state property
(ESP) in both deterministic and stochastic settings. We investigate state-space
systems, a central model class in time series learning, and establish that
fading memory and solution stability hold generically -- even in the absence of
the ESP -- offering a robust explanation for the empirical success of RC models
without strict contractivity conditions. In the stochastic case, we critically
assess stochastic echo states, proposing a novel distributional perspective
rooted in attractor dynamics on the space of probability distributions, which
leads to a rich and coherent theory. Our results extend and generalize previous
work on non-autonomous dynamical systems, offering new insights into causality,
stability, and memory in RC models. This lays the groundwork for reliable
generative modeling of temporal data in both deterministic and stochastic
regimes.

</details>


### [676] [Sharper Perturbed-Kullback-Leibler Exponential Tail Bounds for Beta and Dirichlet Distributions](https://arxiv.org/abs/2508.07991)
*Pierre Perrault*

Main category: math.PR

Relevance: 30.0

TL;DR: 本文改进了Beta分布的指数尾界，通过引入扰动η优化KL散度界，并将结果推广到Dirichlet分布和Dirichlet过程。


<details>
  <summary>Details</summary>
Motivation: 改进Beta分布的尾界，以提供更紧的统计界限，并扩展至更复杂的分布。

Method: 将现有KL散度界解释为常规形式，引入扰动η调整Beta分布均值，从而优化界限。

Result: 成功证明了更大的扰动η可进一步收紧尾界，并将结果推广到Dirichlet分布和DP。

Conclusion: 提出的方法显著优化了Beta和Dirichlet分布的尾界，具有潜在的理论和应用价值。

Abstract: This paper presents an improved exponential tail bound for Beta
distributions, refining a result in [15]. This improvement is achieved by
interpreting their bound as a regular Kullback-Leibler (KL) divergence one,
while introducing a specific perturbation $\eta$ that shifts the mean of the
Beta distribution closer to zero within the KL bound. Our contribution is to
show that a larger perturbation can be chosen, thereby tightening the bound. We
then extend this result from the Beta distribution to Dirichlet distributions
and Dirichlet processes (DPs).

</details>


### [677] [Prediction error certification for PINNs: Theory, computation, and application to Stokes flow](https://arxiv.org/abs/2508.07994)
*Birgit Hillebrecht,Benjamin Unger*

Main category: math.NA

Relevance: 30.0

TL;DR: 本文扩展了基于半群的PINN误差估计框架，使其适用于更广泛的问题，并通过数值策略近似稳定性参数，验证了在斯托克斯流中的实际应用。


<details>
  <summary>Details</summary>
Motivation: 随着PINNs在偏微分方程求解中的应用增多，需要更通用的误差估计方法以验证其预测准确性。

Method: 修改误差界限并提出数值策略近似稳定性参数，扩展了基于半群的误差估计框架。

Result: 扩展后的框架能够验证更实际场景中的PINN预测，如斯托克斯流问题。

Conclusion: 该研究提升了PINN误差估计的实用性，适用于更复杂的现实问题。

Abstract: Rigorous error estimation is a fundamental topic in numerical analysis. With
the increasing use of physics-informed neural networks (PINNs) for solving
partial differential equations, several approaches have been developed to
quantify the associated prediction error. In this work, we build upon a
semigroup-based framework previously introduced by the authors for estimating
the PINN error. While this estimator has so far been limited to academic
examples - due to the need to compute quantities related to input-to-state
stability - we extend its applicability to a significantly broader class of
problems. This is accomplished by modifying the error bound and proposing
numerical strategies to approximate the required stability parameters. The
extended framework enables the certification of PINN predictions in more
realistic scenarios, as demonstrated by a numerical study of Stokes flow around
a cylinder.

</details>


### [678] [Optimizing Federated Learning for Scalable Power-demand Forecasting in Microgrids](https://arxiv.org/abs/2508.08022)
*Roopkatha Banerjee,Sampath Koti,Gyanendra Singh,Anirban Chakraborty,Gurunath Gurrala,Bhushan Jagyasi,Yogesh Simmhan*

Main category: cs.DC

Relevance: 30.0

TL;DR: 论文提出了一种基于联邦学习（FL）的优化方法，用于城市和微电网的实时电力需求预测，解决了非独立同分布数据和高计算成本的问题。


<details>
  <summary>Details</summary>
Motivation: 通过物联网（IoT）实时监测电力消耗数据时，将数据集中到云端会暴露用户隐私。联邦学习可以保护隐私，但面临非独立同分布数据和高计算成本的挑战。

Method: 开发了多种FL优化方法，包括指数加权损失函数，用于时间序列需求预测的DNN训练，并在伪分布式和边缘集群环境中验证。

Result: 在OpenEIA数据集上验证了1000多个客户，结果显示提出的方法优于ARIMA和单用户DNN基线，具有更高的预测精度和可扩展性。

Conclusion: 提出的FL优化方法在保护隐私的同时，实现了高精度和低成本的需求预测。

Abstract: Real-time monitoring of power consumption in cities and micro-grids through
the Internet of Things (IoT) can help forecast future demand and optimize grid
operations. But moving all consumer-level usage data to the cloud for
predictions and analysis at fine time scales can expose activity patterns.
Federated Learning~(FL) is a privacy-sensitive collaborative DNN training
approach that retains data on edge devices, trains the models on private data
locally, and aggregates the local models in the cloud. But key challenges
exist: (i) clients can have non-independently identically distributed~(non-IID)
data, and (ii) the learning should be computationally cheap while scaling to
1000s of (unseen) clients. In this paper, we develop and evaluate several
optimizations to FL training across edge and cloud for time-series demand
forecasting in micro-grids and city-scale utilities using DNNs to achieve a
high prediction accuracy while minimizing the training cost. We showcase the
benefit of using exponentially weighted loss while training and show that it
further improves the prediction of the final model. Finally, we evaluate these
strategies by validating over 1000s of clients for three states in the US from
the OpenEIA corpus, and performing FL both in a pseudo-distributed setting and
a Pi edge cluster. The results highlight the benefits of the proposed methods
over baselines like ARIMA and DNNs trained for individual consumers, which are
not scalable.

</details>


### [679] [An effective potential for generative modelling with active matter](https://arxiv.org/abs/2508.08146)
*Adrian Baule*

Main category: cond-mat.stat-mech

Relevance: 30.0

TL;DR: 论文提出了一种基于活性粒子过程的生成扩散模型，通过施加有效时间依赖势能实现时间反转。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过活性粒子过程实现扩散模型的时间反转，以简化生成扩散模型的实现。

Method: 利用有效时间依赖势能作用于位置坐标，仅需标准得分函数及其二阶导数确定力场。

Result: 数值实验验证了有效势能的正确性。

Conclusion: 该方法为生成扩散模型提供了一种新的实现途径。

Abstract: Score-based diffusion models generate samples from a complex underlying data
distribution by time-reversal of a diffusion process and represent the
state-of-the-art in many generative AI applications such as artificial image
synthesis. Here, I show how a generative diffusion model can be implemented
based on an underlying active particle process with finite correlation time. In
contrast to previous approaches that use a score function acting on the
velocity coordinate of the active particle, time reversal is here achieved by
imposing an effective time-dependent potential on the position coordinate only.
The effective potential is valid to first order in the persistence time and
leads to a force field that is fully determined by the standard score function
and its derivatives up to 2nd order. Numerical experiments for artificial data
distributions confirm the validity of the effective potential.

</details>


### [680] [Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record](https://arxiv.org/abs/2508.06627)
*Mosbah Aouad,Anirudh Choudhary,Awais Farooq,Steven Nevers,Lusine Demirkhanyan,Bhrandon Harris,Suguna Pappu,Christopher Gondi,Ravishankar Iyer*

Main category: cs.LG

Relevance: 20.0

TL;DR: 提出了一种多模态方法，结合电子健康记录中的诊断代码和实验室数据，用于早期检测胰腺导管腺癌（PDAC），性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: PDAC早期检测困难，缺乏可靠生物标志物，需开发新方法。

Method: 结合神经控制微分方程建模不规则实验室时间序列，预训练语言模型和循环网络学习诊断代码轨迹表示，交叉注意力机制捕捉模态交互。

Result: 在4700名患者数据集上，AUC提升6.5%-15.5%，并识别出新的高风险生物标志物。

Conclusion: 多模态方法显著提升PDAC早期检测性能，并发现新生物标志物。

Abstract: Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and
early detection remains a major clinical challenge due to the absence of
specific symptoms and reliable biomarkers. In this work, we propose a new
multimodal approach that integrates longitudinal diagnosis code histories and
routinely collected laboratory measurements from electronic health records to
detect PDAC up to one year prior to clinical diagnosis. Our method combines
neural controlled differential equations to model irregular lab time series,
pretrained language models and recurrent networks to learn diagnosis code
trajectory representations, and cross-attention mechanisms to capture
interactions between the two modalities. We develop and evaluate our approach
on a real-world dataset of nearly 4,700 patients and achieve significant
improvements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods.
Furthermore, our model identifies diagnosis codes and laboratory panels
associated with elevated PDAC risk, including both established and new
biomarkers. Our code is available at
https://github.com/MosbahAouad/EarlyPDAC-MML.

</details>


### [681] [Structure-Preserving Digital Twins via Conditional Neural Whitney Forms](https://arxiv.org/abs/2508.06981)
*Brooks Kinch,Benjamin Shaffer,Elizabeth Armstrong,Michael Meehan,John Hewson,Nathaniel Trask*

Main category: cs.LG

Relevance: 20.0

TL;DR: 提出了一种基于结构保持降阶有限元模型的实时数字孪生框架，利用条件注意力机制学习降阶基和非线性守恒律。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀疏或优化误差下的数值适定性和守恒量精确保持问题，支持实时校准和闭环推理。

Method: 结合条件注意力机制和有限元外微积分（FEEC），学习降阶基和非线性守恒律，支持复杂几何和与传统有限元方法无缝集成。

Result: 在复杂几何和稀疏数据（25次LES模拟）下实现准确预测，实时推理速度提升3.1×10^8倍。

Conclusion: 框架在复杂问题中表现优异，支持实时数字孪生构建。

Abstract: We present a framework for constructing real-time digital twins based on
structure-preserving reduced finite element models conditioned on a latent
variable Z. The approach uses conditional attention mechanisms to learn both a
reduced finite element basis and a nonlinear conservation law within the
framework of finite element exterior calculus (FEEC). This guarantees numerical
well-posedness and exact preservation of conserved quantities, regardless of
data sparsity or optimization error. The conditioning mechanism supports
real-time calibration to parametric variables, allowing the construction of
digital twins which support closed loop inference and calibration to sensor
data. The framework interfaces with conventional finite element machinery in a
non-invasive manner, allowing treatment of complex geometries and integration
of learned models with conventional finite element techniques.
  Benchmarks include advection diffusion, shock hydrodynamics, electrostatics,
and a complex battery thermal runaway problem. The method achieves accurate
predictions on complex geometries with sparse data (25 LES simulations),
including capturing the transition to turbulence and achieving real-time
inference ~0.1s with a speedup of 3.1x10^8 relative to LES. An open-source
implementation is available on GitHub.

</details>


### [682] [ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis](https://arxiv.org/abs/2508.07345)
*Samiha Afaf Neha,Abir Ahammed Bhuiyan,Md. Ishrak Khan*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种基于图像的蛋白质序列编码方法ProteoKnight，用于噬菌体病毒蛋白（PVP）分类，并通过蒙特卡洛Dropout评估预测不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在空间信息处理上存在局限，需要更有效的序列编码技术以提升PVP分类性能。

Method: ProteoKnight改进DNA-Walk算法，结合像素颜色和步长调整，使用预训练CNN进行分类，并通过MCD评估不确定性。

Result: 二元分类准确率达90.8%，多分类表现欠佳；不确定性分析显示预测置信度受蛋白类别和序列长度影响。

Conclusion: ProteoKnight优于现有方法，提供高精度PVP预测并识别低置信度结果。

Abstract: \textbf{Introduction:} Accurate prediction of Phage Virion Proteins (PVP) is
essential for genomic studies due to their crucial role as structural elements
in bacteriophages. Computational tools, particularly machine learning, have
emerged for annotating phage protein sequences from high-throughput sequencing.
However, effective annotation requires specialized sequence encodings. Our
paper introduces ProteoKnight, a new image-based encoding method that addresses
spatial constraints in existing techniques, yielding competitive performance in
PVP classification using pre-trained convolutional neural networks.
Additionally, our study evaluates prediction uncertainty in binary PVP
classification through Monte Carlo Dropout (MCD). \textbf{Methods:}
ProteoKnight adapts the classical DNA-Walk algorithm for protein sequences,
incorporating pixel colors and adjusting walk distances to capture intricate
protein features. Encoded sequences were classified using multiple pre-trained
CNNs. Variance and entropy measures assessed prediction uncertainty across
proteins of various classes and lengths. \textbf{Results:} Our experiments
achieved 90.8% accuracy in binary classification, comparable to
state-of-the-art methods. Multi-class classification accuracy remains
suboptimal. Our uncertainty analysis unveils variability in prediction
confidence influenced by protein class and sequence length.
\textbf{Conclusions:} Our study surpasses frequency chaos game representation
(FCGR) by introducing novel image encoding that mitigates spatial information
loss limitations. Our classification technique yields accurate and robust PVP
predictions while identifying low-confidence predictions.

</details>


### [683] [MOTGNN: Interpretable Graph Neural Networks for Multi-Omics Disease Classification](https://arxiv.org/abs/2508.07465)
*Tiantian Yang,Zhiqian Chen*

Main category: cs.LG

Relevance: 20.0

TL;DR: 提出了一种名为MOTGNN的多组学数据集成框架，用于疾病分类，结合XGBoost和GNN提升预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 多组学数据的高维性和复杂性对疾病建模提出了挑战，需要一种既能提升预测性能又能保持可解释性的方法。

Method: 使用XGBoost构建组学特定图，结合模态特定GNN进行分层表示学习，最后通过深度前馈网络实现跨组学集成。

Result: 在三个真实疾病数据集上，MOTGNN在准确性、ROC-AUC和F1分数上优于基线5-10%，且在类别不平衡时表现稳健。

Conclusion: MOTGNN在多组学疾病建模中显著提升了预测准确性和可解释性。

Abstract: Integrating multi-omics data, such as DNA methylation, mRNA expression, and
microRNA (miRNA) expression, offers a comprehensive view of the biological
mechanisms underlying disease. However, the high dimensionality and complex
interactions among omics layers present major challenges for predictive
modeling. We propose Multi-Omics integration with Tree-generated Graph Neural
Network (MOTGNN), a novel and interpretable framework for binary disease
classification. MOTGNN employs eXtreme Gradient Boosting (XGBoost) to perform
omics-specific supervised graph construction, followed by modality-specific
Graph Neural Networks (GNNs) for hierarchical representation learning, and a
deep feedforward network for cross-omics integration. On three real-world
disease datasets, MOTGNN outperforms state-of-the-art baselines by 5-10% in
accuracy, ROC-AUC, and F1-score, and remains robust to severe class imbalance
(e.g., 87.2% vs. 33.4% F1 on imbalanced data). The model maintains
computational efficiency through sparse graphs (2.1-2.8 edges per node) and
provides built-in interpretability, revealing both top-ranked biomarkers and
the relative contributions of each omics modality. These results highlight
MOTGNN's potential to improve both predictive accuracy and interpretability in
multi-omics disease modeling.

</details>


### [684] [Discovering Spatial Correlations between Earth Observations in Global Atmospheric State Estimation by using Adaptive Graph Structure Learning](https://arxiv.org/abs/2508.07659)
*Hyeon-Ju Jeon,Jeon-Ho Kang,In-Hyuk Kwon,O-Joun Lee*

Main category: cs.LG

Relevance: 20.0

TL;DR: 该研究利用时空图神经网络（STGNNs）和结构学习改进全球大气状态估计的预测精度，通过自适应调节边采样解决结构信息丢失和过平滑问题。


<details>
  <summary>Details</summary>
Motivation: 传统数值天气预报（NWP）系统在固定网格点上预测大气状态，但地球观测数据位置不固定，导致时空相关性复杂。研究旨在动态捕捉这些相关性以提高预测精度。

Method: 采用STGNNs结合结构学习，通过自适应确定节点度和考虑空间距离来调节边采样，避免信息丢失和过平滑问题。

Result: 在东亚真实数据上验证，该方法在高变异性区域优于现有STGNN模型。

Conclusion: 提出的方法有效解决了动态时空相关性问题，提升了大气状态预测的准确性。

Abstract: This study aims to discover spatial correlations between Earth observations
and atmospheric states to improve the forecasting accuracy of global
atmospheric state estimation, which are usually conducted using conventional
numerical weather prediction (NWP) systems and is the beginning of weather
forecasting. NWP systems predict future atmospheric states at fixed locations,
which are called NWP grid points, by analyzing previous atmospheric states and
newly acquired Earth observations without fixed locations. Thus, surrounding
meteorological context and the changing locations of the observations make
spatial correlations between atmospheric states and observations over time. To
handle complicated spatial correlations, which change dynamically, we employ
spatiotemporal graph neural networks (STGNNs) with structure learning. However,
structure learning has an inherent limitation that this can cause structural
information loss and over-smoothing problem by generating excessive edges. To
solve this problem, we regulate edge sampling by adaptively determining node
degrees and considering the spatial distances between NWP grid points and
observations. We validated the effectiveness of the proposed method by using
real-world atmospheric state and observation data from East Asia. Even in areas
with high atmospheric variability, the proposed method outperformed existing
STGNN models with and without structure learning.

</details>


### [685] [ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring](https://arxiv.org/abs/2508.08073)
*Dimitris Tsaras,Xing Li,Lei Chen,Zhiyao Xie,Mingxuan Yuan*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种利用分类器预剪枝无效切割的方法，以加速逻辑优化，相比现有技术实现了3.9倍的提速。


<details>
  <summary>Details</summary>
Motivation: 逻辑优化操作在电子设计自动化中计算成本高，传统方法失败率高（98%），需要更高效的解决方案。

Method: 使用分类器预剪枝无效切割，避免不必要的重合成操作。

Result: 在EPFL基准套件和10个大型工业设计上，实现了平均3.9倍的加速。

Conclusion: 该方法显著提升了逻辑优化的效率，适用于大规模设计。

Abstract: In electronic design automation, logic optimization operators play a crucial
role in minimizing the gate count of logic circuits. However, their computation
demands are high. Operators such as refactor conventionally form iterative cuts
for each node, striving for a more compact representation - a task which often
fails 98% on average. Prior research has sought to mitigate computational cost
through parallelization. In contrast, our approach leverages a classifier to
prune unsuccessful cuts preemptively, thus eliminating unnecessary resynthesis
operations. Experiments on the refactor operator using the EPFL benchmark suite
and 10 large industrial designs demonstrate that this technique can speedup
logic optimization by 3.9x on average compared with the state-of-the-art ABC
implementation.

</details>


### [686] [Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion](https://arxiv.org/abs/2508.08216)
*Nicole Lai-Tan,Xiao Gu,Marios G. Philiastides,Fani Deligianni*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种名为ITSA的新方法，用于改进脑机接口（BCI）在个性化音乐干预中的跨主体泛化能力，通过结合主题特定的重新中心化、分布匹配和监督旋转对齐，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 脑机接口在个性化音乐干预中具有潜力，但主体间EEG信号的变异性、运动伪影和运动规划差异限制了其泛化能力，需要长时间校准。

Method: 提出了ITSA预对齐策略，结合主题特定的重新中心化、分布匹配和监督旋转对齐，并采用混合架构融合RCSP和黎曼几何。

Result: ITSA在跨主体和条件下显著提升了性能，并行融合方法表现最佳。

Conclusion: ITSA是一种有效的跨主体泛化策略，适用于脑机接口的个性化音乐干预。

Abstract: Personalised music-based interventions offer a powerful means of supporting
motor rehabilitation by dynamically tailoring auditory stimuli to provide
external timekeeping cues, modulate affective states, and stabilise gait
patterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for
adapting these interventions across individuals. However, inter-subject
variability in EEG signals, further compounded by movement-induced artefacts
and motor planning differences, hinders the generalisability of BCIs and
results in lengthy calibration processes. We propose Individual Tangent Space
Alignment (ITSA), a novel pre-alignment strategy incorporating subject-specific
recentering, distribution matching, and supervised rotational alignment to
enhance cross-subject generalisation. Our hybrid architecture fuses Regularised
Common Spatial Patterns (RCSP) with Riemannian geometry in parallel and
sequential configurations, improving class separability while maintaining the
geometric structure of covariance matrices for robust statistical computation.
Using leave-one-subject-out cross-validation, `ITSA' demonstrates significant
performance improvements across subjects and conditions. The parallel fusion
approach shows the greatest enhancement over its sequential counterpart, with
robust performance maintained across varying data conditions and electrode
configurations. The code will be made publicly available at the time of
publication.

</details>


### [687] [A Score-based Diffusion Model Approach for Adaptive Learning of Stochastic Partial Differential Equation Solutions](https://arxiv.org/abs/2508.06834)
*Toan Huynh,Ruth Lopez Fajardo,Guannan Zhang,Lili Ju,Feng Bao*

Main category: stat.CO

Relevance: 20.0

TL;DR: 提出了一种基于扩散模型的递归贝叶斯推理框架，用于自适应学习随机偏微分方程（SPDEs）的时间演化解。


<details>
  <summary>Details</summary>
Motivation: SPDEs在复杂物理系统建模中至关重要，但数值解常因模型误差和环境变化而精度不足。

Method: 将物理规律编码到扩散模型的评分函数中，并通过基于似然的修正结合观测数据，实现自适应学习。

Result: 在稀疏和噪声观测下，数值实验验证了方法的准确性和鲁棒性。

Conclusion: 该方法为SPDEs的高效求解提供了新思路。

Abstract: We propose a novel framework for adaptively learning the time-evolving
solutions of stochastic partial differential equations (SPDEs) using
score-based diffusion models within a recursive Bayesian inference setting.
SPDEs play a central role in modeling complex physical systems under
uncertainty, but their numerical solutions often suffer from model errors and
reduced accuracy due to incomplete physical knowledge and environmental
variability. To address these challenges, we encode the governing physics into
the score function of a diffusion model using simulation data and incorporate
observational information via a likelihood-based correction in a reverse-time
stochastic differential equation. This enables adaptive learning through
iterative refinement of the solution as new data becomes available. To improve
computational efficiency in high-dimensional settings, we introduce the
ensemble score filter, a training-free approximation of the score function
designed for real-time inference. Numerical experiments on benchmark SPDEs
demonstrate the accuracy and robustness of the proposed method under sparse and
noisy observations.

</details>


### [688] [Explainable AI for Curie Temperature Prediction in Magnetic Materials](https://arxiv.org/abs/2508.06996)
*M. Adeel Ajaib,Fariha Nasir,Abdul Rehman*

Main category: cond-mat.mtrl-sci

Relevance: 20.0

TL;DR: 论文探讨了利用NEMAD数据库预测磁性材料居里温度的机器学习方法，通过增强数据集和评估多种模型，发现Extra Trees Regressor表现最佳，并采用SHAP分析提升模型解释性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过机器学习方法预测磁性材料的居里温度，并结合解释性AI技术提升科学可解释性。

Method: 使用NEMAD数据库，结合成分和领域感知描述符增强数据集，评估多种机器学习模型，并采用k-means聚类和SHAP分析。

Result: Extra Trees Regressor表现最佳，R^2得分达0.85±0.01，SHAP分析揭示了居里行为的关键物理化学驱动因素。

Conclusion: 研究通过机器学习与解释性AI技术，为磁性材料居里温度的预测提供了高效且可解释的方法。

Abstract: We explore machine learning techniques for predicting Curie temperatures of
magnetic materials using the NEMAD database. By augmenting the dataset with
composition-based and domain-aware descriptors, we evaluate the performance of
several machine learning models. We find that the Extra Trees Regressor
delivers the best performance reaching an R^2 score of up to 0.85 $\pm$ 0.01
(cross-validated) for a balanced dataset. We employ the k-means clustering
algorithm to gain insights into the performance of chemically distinct material
groups. Furthermore, we perform the SHAP analysis to identify key
physicochemical drivers of Curie behavior, such as average atomic number and
magnetic moment. By employing explainable AI techniques, this analysis offers
insights into the model's predictive behavior, thereby advancing scientific
interpretability.

</details>


### [689] [QuProFS: An Evolutionary Training-free Approach to Efficient Quantum Feature Map Search](https://arxiv.org/abs/2508.07104)
*Yaswitha Gujju,Romain Harang,Chao Li,Tetsuo Shibuya,Qibin Zhao*

Main category: quant-ph

Relevance: 20.0

TL;DR: 论文提出了一种基于进化算法的免训练量子架构搜索（QAS）框架，用于优化量子特征映射的数据编码，解决了参数化量子电路的训练难题。


<details>
  <summary>Details</summary>
Motivation: 解决参数化量子电路训练中的平坦训练景观和长训练时间问题。

Method: 采用进化算法和电路启发式方法，通过代理指标评估电路架构，并结合硬件感知设计提升抗噪性。

Result: 在模拟器和真实量子硬件上实现了竞争性准确度，采样效率和架构搜索速度显著提升。

Conclusion: 该方法在量子支持向量机分类任务中表现优异，优于现有QAS方法。

Abstract: The quest for effective quantum feature maps for data encoding presents
significant challenges, particularly due to the flat training landscapes and
lengthy training processes associated with parameterised quantum circuits. To
address these issues, we propose an evolutionary training-free quantum
architecture search (QAS) framework that employs circuit-based heuristics
focused on trainability, hardware robustness, generalisation ability,
expressivity, complexity, and kernel-target alignment. By ranking circuit
architectures with various proxies, we reduce evaluation costs and incorporate
hardware-aware circuits to enhance robustness against noise. We evaluate our
approach on classification tasks (using quantum support vector machine) across
diverse datasets using both artificial and quantum-generated datasets. Our
approach demonstrates competitive accuracy on both simulators and real quantum
hardware, surpassing state-of-the-art QAS methods in terms of sampling
efficiency and achieving up to a 2x speedup in architecture search runtime.

</details>


### [690] [Barron Space Representations for Elliptic PDEs with Homogeneous Boundary Conditions](https://arxiv.org/abs/2508.07559)
*Ziang Chen,Liqiang Huang*

Main category: math.NA

Relevance: 20.0

TL;DR: 该论文研究了高维二阶椭圆PDE在Barron空间中的近似复杂度，证明在特定条件下，浅层神经网络能高效逼近解，避免维度灾难。


<details>
  <summary>Details</summary>
Motivation: 探索高维PDE在神经网络中的高效近似方法，以克服传统方法的维度灾难问题。

Method: 在Barron空间框架下，假设系数满足特定条件，使用两层神经网络逼近PDE解。

Result: 证明浅层神经网络能高效逼近高维PDE解，避免维度灾难。

Conclusion: 浅层神经网络在适当结构假设下具有强大的表达能力，适用于高维PDE问题。

Abstract: We study the approximation complexity of high-dimensional second-order
elliptic PDEs with homogeneous boundary conditions on the unit hypercube,
within the framework of Barron spaces. Under the assumption that the
coefficients belong to suitably defined Barron spaces, we prove that the
solution can be efficiently approximated by two-layer neural networks,
circumventing the curse of dimensionality. Our results demonstrate the
expressive power of shallow networks in capturing high-dimensional PDE
solutions under appropriate structural assumptions.

</details>


### [691] [Likelihood Ratio Tests by Kernel Gaussian Embedding](https://arxiv.org/abs/2508.07982)
*Leonardo V. Santoro,Victor M. Panaretos*

Main category: stat.ML

Relevance: 20.0

TL;DR: 提出了一种基于核的非参数双样本检验方法，结合核均值和核协方差嵌入，利用高斯嵌入的相对熵构造检验统计量，显著提升了高维和弱信号场景下的检测能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统双样本检验方法在高维和弱信号场景下性能不足的问题。

Method: 结合核均值和核协方差嵌入，构造基于高斯嵌入相对熵的检验统计量，并通过正则化和排列校准实现。

Result: 在合成和真实数据上表现出优于现有方法的检测能力，尤其在高维和弱信号场景下。

Conclusion: 该方法统一并扩展了基于谱正则化MMD的先前方法，具有一致性和均匀功率保证。

Abstract: We propose a novel kernel-based nonparametric two-sample test, employing the
combined use of kernel mean and kernel covariance embedding. Our test builds on
recent results showing how such combined embeddings map distinct probability
measures to mutually singular Gaussian measures on the kernel's RKHS.
Leveraging this result, we construct a test statistic based on the relative
entropy between the Gaussian embeddings, i.e.\ the likelihood ratio. The
likelihood ratio is specifically tailored to detect equality versus singularity
of two Gaussians, and satisfies a ``$0/\infty$" law, in that it vanishes under
the null and diverges under the alternative. To implement the test in finite
samples, we introduce a regularised version, calibrated by way of permutation.
We prove consistency, establish uniform power guarantees under mild conditions,
and discuss how our framework unifies and extends prior approaches based on
spectrally regularized MMD. Empirical results on synthetic and real data
demonstrate remarkable gains in power compared to state-of-the-art methods,
particularly in high-dimensional and weak-signal regimes.

</details>


### [692] [CISO: Species Distribution Modeling Conditioned on Incomplete Species Observations](https://arxiv.org/abs/2508.06704)
*Hager Radi Abdelwahed,Mélisande Teng,Robin Zbinden,Laura Pollock,Hugo Larochelle,Devis Tuia,David Rolnick*

Main category: cs.LG

Relevance: 10.0

TL;DR: 论文提出了一种基于深度学习的物种分布模型CISO，能够结合不完整的物种观测数据与环境变量进行预测，提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有物种分布模型（SDMs）通常忽略物种间的生物相互作用，且依赖对称的成对关系假设和完整的共现数据。CISO旨在解决这些限制。

Method: CISO是一种深度学习方法，允许预测基于不完整物种观测数据与环境变量，适用于不同数据集（植物、鸟类、蝴蝶）。

Result: CISO在空间分离测试集上表现优于其他方法，尤其在结合多数据集观测时性能进一步提升。

Conclusion: CISO是一种有前景的生态工具，能够整合不完整生物信息并识别跨类群物种间潜在相互作用。

Abstract: Species distribution models (SDMs) are widely used to predict species'
geographic distributions, serving as critical tools for ecological research and
conservation planning. Typically, SDMs relate species occurrences to
environmental variables representing abiotic factors, such as temperature,
precipitation, and soil properties. However, species distributions are also
strongly influenced by biotic interactions with other species, which are often
overlooked. While some methods partially address this limitation by
incorporating biotic interactions, they often assume symmetrical pairwise
relationships between species and require consistent co-occurrence data. In
practice, species observations are sparse, and the availability of information
about the presence or absence of other species varies significantly across
locations. To address these challenges, we propose CISO, a deep learning-based
method for species distribution modeling Conditioned on Incomplete Species
Observations. CISO enables predictions to be conditioned on a flexible number
of species observations alongside environmental variables, accommodating the
variability and incompleteness of available biotic data. We demonstrate our
approach using three datasets representing different species groups: sPlotOpen
for plants, SatBird for birds, and a new dataset, SatButterfly, for
butterflies. Our results show that including partial biotic information
improves predictive performance on spatially separate test sets. When
conditioned on a subset of species within the same dataset, CISO outperforms
alternative methods in predicting the distribution of the remaining species.
Furthermore, we show that combining observations from multiple datasets can
improve performance. CISO is a promising ecological tool, capable of
incorporating incomplete biotic information and identifying potential
interactions between species from disparate taxa.

</details>


### [693] [Lightning Prediction under Uncertainty: DeepLight with Hazy Loss](https://arxiv.org/abs/2508.07428)
*Md Sultanul Arifin,Abu Nowshed Sakib,Yeasir Rayhan,Tanzima Hashem*

Main category: cs.LG

Relevance: 10.0

TL;DR: DeepLight是一种新型深度学习架构，用于预测闪电发生，通过多源气象数据和双编码器架构提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 闪电预测对减少人员和财产损失至关重要，现有模型在动态空间上下文捕捉和数据利用上存在不足。

Method: 利用多源气象数据（如雷达反射率和云属性），通过双编码器架构和多分支卷积技术动态捕捉空间相关性，并使用Hazy Loss函数处理不确定性。

Result: 实验表明，DeepLight在公平威胁评分（ETS）上比现有方法提升18%-30%。

Conclusion: DeepLight是一种鲁棒的闪电预测解决方案，显著优于现有方法。

Abstract: Lightning, a common feature of severe meteorological conditions, poses
significant risks, from direct human injuries to substantial economic losses.
These risks are further exacerbated by climate change. Early and accurate
prediction of lightning would enable preventive measures to safeguard people,
protect property, and minimize economic losses. In this paper, we present
DeepLight, a novel deep learning architecture for predicting lightning
occurrences. Existing prediction models face several critical limitations: they
often struggle to capture the dynamic spatial context and inherent uncertainty
of lightning events, underutilize key observational data, such as radar
reflectivity and cloud properties, and rely heavily on Numerical Weather
Prediction (NWP) systems, which are both computationally expensive and highly
sensitive to parameter settings. To overcome these challenges, DeepLight
leverages multi-source meteorological data, including radar reflectivity, cloud
properties, and historical lightning occurrences through a dual-encoder
architecture. By employing multi-branch convolution techniques, it dynamically
captures spatial correlations across varying extents. Furthermore, its novel
Hazy Loss function explicitly addresses the spatio-temporal uncertainty of
lightning by penalizing deviations based on proximity to true events, enabling
the model to better learn patterns amidst randomness. Extensive experiments
show that DeepLight improves the Equitable Threat Score (ETS) by 18%-30% over
state-of-the-art methods, establishing it as a robust solution for lightning
prediction.

</details>


### [694] [Do Streetscapes Still Matter for Customer Ratings of Eating and Drinking Establishments in Car-Dependent Cities?](https://arxiv.org/abs/2508.06513)
*Chaeyeon Han,Seung Jae Lieu,Uijeong Hwang,Subhrajit Guhathakurta*

Main category: physics.soc-ph

Relevance: 10.0

TL;DR: 研究探讨了室内外美学、街景和社区特征如何影响不同城市环境中餐饮场所的顾客满意度，发现室内外环境对评分有显著影响，而街景质量在依赖汽车的地区影响较小。


<details>
  <summary>Details</summary>
Motivation: 探究城市环境中餐饮场所顾客满意度的驱动因素，特别是室内外美学和街景的作用。

Method: 使用计算机视觉模型量化感知安全和视觉吸引力，并通过有序逻辑回归分析其对Yelp评分的影响。

Result: 室内外环境显著影响餐饮场所评分，而街景质量在依赖汽车的地区影响较小。

Conclusion: 需根据不同城市环境整合室内外因素，以提升顾客体验。

Abstract: This study examines how indoor and outdoor aesthetics, streetscapes, and
neighborhood features shape customer satisfaction at eating and dining
establishments (EDEs) across different urban contexts, varying in car
dependency, in Washington, DC. Using review photos and street view images,
computer vision models quantified perceived safety and visual appeal. Ordinal
logistic regression analyzed their effects on Yelp ratings. Findings reveal
that both indoor and outdoor environments significantly impact EDE ratings,
while streetscape quality's influence diminishes in car-dependent areas. The
study highlights the need for context-sensitive planning that integrates indoor
and outdoor factors to enhance customer experiences in diverse settings.

</details>


### [695] [Reconstruction of Solar EUV Irradiance Using CaII K Images and SOHO/SEM Data with Bayesian Deep Learning and Uncertainty Quantification](https://arxiv.org/abs/2508.07065)
*Haodi Jiang,Qin Li,Jason T. L. Wang,Haimin Wang,Serena Criscuoli*

Main category: astro-ph.SR

Relevance: 10.0

TL;DR: 论文提出了一种名为SEMNet的贝叶斯深度学习模型，用于填补太阳极紫外（EUV）辐射长期数据的空白，并通过CaII K图像重建历史EUV辐射。


<details>
  <summary>Details</summary>
Motivation: 长期EUV辐射数据缺失，影响对地球气候变化的全面理解。

Method: 使用贝叶斯深度学习模型SEMNet，基于CaII K图像重建EUV辐射数据。

Result: SEMNet成功重建了1998-2014年和1950-1960年的EUV辐射数据，并提供了不确定性估计。

Conclusion: CaII K图像可作为长期EUV辐射的可靠代理，有助于理解太阳对地球气候的长期影响。

Abstract: Solar extreme ultraviolet (EUV) irradiance plays a crucial role in heating
the Earth's ionosphere, thermosphere, and mesosphere, affecting atmospheric
dynamics over varying time scales. Although significant effort has been spent
studying short-term EUV variations from solar transient events, there is little
work to explore the long-term evolution of the EUV flux over multiple solar
cycles. Continuous EUV flux measurements have only been available since 1995,
leaving significant gaps in earlier data. In this study, we propose a Bayesian
deep learning model, named SEMNet, to fill the gaps. We validate our approach
by applying SEMNet to construct SOHO/SEM EUV flux measurements in the period
between 1998 and 2014 using CaII K images from the Precision Solar Photometric
Telescope. We then extend SEMNet through transfer learning to reconstruct solar
EUV irradiance in the period between 1950 and 1960 using CaII K images from the
Kodaikanal Solar Observatory. Experimental results show that SEMNet provides
reliable predictions along with uncertainty bounds, demonstrating the
feasibility of CaII K images as a robust proxy for long-term EUV fluxes. These
findings contribute to a better understanding of solar influences on Earth's
climate over extended periods.

</details>


### [696] [Channel Charting in Smart Radio Environments](https://arxiv.org/abs/2508.07305)
*Mahdi Maleki,Reza Agahzadeh Ayoubi,Marouan Mizmizi,Umberto Spagnolini*

Main category: eess.SP

Relevance: 10.0

TL;DR: 论文提出了一种利用静态电磁皮肤（EMS）增强城市环境中设备定位性能的方法，通过优化EMS配置显著降低了定位误差。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决城市环境中非视距（NLoS）条件下的设备定位问题，利用EMS提升定位的鲁棒性和准确性。

Method: 方法包括开发一个基于代码本的优化框架，设计EMS相位剖面以增强信道差异性和空间指纹特征，并通过3D射线追踪仿真验证。

Result: 结果显示，优化后的EMS配置将90%分位数的定位误差从60米以上降至25米以下，同时显著提升了定位的可信度和连续性。

Conclusion: 结论表明，静态EMS在智能无线电环境（SRE）中的应用能有效提升信道图（CC）性能，尤其是在复杂NLoS条件下。

Abstract: This paper introduces the use of static electromagnetic skins (EMSs) to
enable robust device localization via channel charting (CC) in realistic urban
environments. We develop a rigorous optimization framework that leverages EMS
to enhance channel dissimilarity and spatial fingerprinting, formulating EMS
phase profile design as a codebook-based problem targeting the upper quantiles
of key embedding metric, localization error, trustworthiness, and continuity.
Through 3D ray-traced simulations of a representative city scenario, we
demonstrate that optimized EMS configurations, in addition to significant
improvement of the average positioning error, reduce the 90th-percentile
localization error from over 60 m (no EMS) to less than 25 m, while drastically
improving trustworthiness and continuity. To the best of our knowledge, this is
the first work to exploit Smart Radio Environment (SRE) with static EMS for
enhancing CC, achieving substantial gains in localization performance under
challenging None-Line-of-Sight (NLoS) conditions.

</details>


### [697] [Generative Inversion for Property-Targeted Materials Design: Application to Shape Memory Alloys](https://arxiv.org/abs/2508.07798)
*Cheng Li,Pengfei Danga,Yuehui Xiana,Yumei Zhou,Bofeng Shi,Xiangdong Ding,Jun Suna,Dezhen Xue*

Main category: cond-mat.mtrl-sci

Relevance: 10.0

TL;DR: 该论文提出了一种基于GAN反演的数据驱动框架，用于高性能形状记忆合金（SMAs）的逆向设计，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 设计具有高转变温度和大机械功输出的形状记忆合金是功能材料工程中的长期挑战。

Method: 通过将预训练的GAN与属性预测模型结合，进行基于梯度的潜在空间优化，生成满足用户定义属性目标的合金成分和加工参数。

Result: 实验合成的NiTi基合金中，Ni$_{49.8}$Ti$_{26.4}$Hf$_{18.6}$Zr$_{5.2}$表现出优异的性能，包括高转变温度（404°C）、大机械功输出（9.9 J/cm$^3$）等。

Conclusion: GAN反演为复杂合金的性能目标发现提供了高效且通用的途径。

Abstract: The design of shape memory alloys (SMAs) with high transformation
temperatures and large mechanical work output remains a longstanding challenge
in functional materials engineering. Here, we introduce a data-driven framework
based on generative adversarial network (GAN) inversion for the inverse design
of high-performance SMAs. By coupling a pretrained GAN with a property
prediction model, we perform gradient-based latent space optimization to
directly generate candidate alloy compositions and processing parameters that
satisfy user-defined property targets. The framework is experimentally
validated through the synthesis and characterization of five NiTi-based SMAs.
Among them, the Ni$_{49.8}$Ti$_{26.4}$Hf$_{18.6}$Zr$_{5.2}$ alloy achieves a
high transformation temperature of 404 $^\circ$C, a large mechanical work
output of 9.9 J/cm$^3$, a transformation enthalpy of 43 J/g , and a thermal
hysteresis of 29 {\deg}C, outperforming existing NiTi alloys. The enhanced
performance is attributed to a pronounced transformation volume change and a
finely dispersed of Ti$_2$Ni-type precipitates, enabled by sluggish Zr and Hf
diffusion, and semi-coherent interfaces with localized strain fields. This
study demonstrates that GAN inversion offers an efficient and generalizable
route for the property-targeted discovery of complex alloys.

</details>


### [698] [Towards High-Order Mean Flow Generative Models: Feasibility, Expressivity, and Provably Efficient Criteria](https://arxiv.org/abs/2508.07102)
*Yang Cao,Yubin Chen,Zhao Song,Jiahao Zhang*

Main category: cs.LG

Relevance: 1.0

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Generative modelling has seen significant advances through simulation-free
paradigms such as Flow Matching, and in particular, the MeanFlow framework,
which replaces instantaneous velocity fields with average velocities to enable
efficient single-step sampling. In this work, we introduce a theoretical study
on Second-Order MeanFlow, a novel extension that incorporates average
acceleration fields into the MeanFlow objective. We first establish the
feasibility of our approach by proving that the average acceleration satisfies
a generalized consistency condition analogous to first-order MeanFlow, thereby
supporting stable, one-step sampling and tractable loss functions. We then
characterize its expressivity via circuit complexity analysis, showing that
under mild assumptions, the Second-Order MeanFlow sampling process can be
implemented by uniform threshold circuits within the $\mathsf{TC}^0$ class.
Finally, we derive provably efficient criteria for scalable implementation by
leveraging fast approximate attention computations: we prove that attention
operations within the Second-Order MeanFlow architecture can be approximated to
within $1/\mathrm{poly}(n)$ error in time $n^{2+o(1)}$. Together, these results
lay the theoretical foundation for high-order flow matching models that combine
rich dynamics with practical sampling efficiency.

</details>


### [699] [Near-Optimal Convergence of Accelerated Gradient Methods under Generalized and $(L_0, L_1)$-Smoothness](https://arxiv.org/abs/2508.06884)
*Alexander Tyurin*

Main category: math.OC

Relevance: 1.0

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study first-order methods for convex optimization problems with functions
$f$ satisfying the recently proposed $\ell$-smoothness condition
$||\nabla^{2}f(x)|| \le \ell\left(||\nabla f(x)||\right),$ which generalizes
the $L$-smoothness and $(L_{0},L_{1})$-smoothness. While accelerated gradient
descent AGD is known to reach the optimal complexity $O(\sqrt{L} R /
\sqrt{\varepsilon})$ under $L$-smoothness, where $\varepsilon$ is an error
tolerance and $R$ is the distance between a starting and an optimal point,
existing extensions to $\ell$-smoothness either incur extra dependence on the
initial gradient, suffer exponential factors in $L_{1} R$, or require costly
auxiliary sub-routines, leaving open whether an AGD-type $O(\sqrt{\ell(0)} R /
\sqrt{\varepsilon})$ rate is possible for small-$\varepsilon$, even in the
$(L_{0},L_{1})$-smoothness case.
  We resolve this open question. Leveraging a new Lyapunov function and
designing new algorithms, we achieve $O(\sqrt{\ell(0)} R / \sqrt{\varepsilon})$
oracle complexity for small-$\varepsilon$ and virtually any $\ell$. For
instance, for $(L_{0},L_{1})$-smoothness, our bound $O(\sqrt{L_0} R /
\sqrt{\varepsilon})$ is provably optimal in the small-$\varepsilon$ regime and
removes all non-constant multiplicative factors present in prior accelerated
algorithms.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [700] [Digital generation of the 3-D pore architecture of isotropic membranes using 2-D cross-sectional scanning electron microscopy images](https://arxiv.org/abs/2508.06664)
*Sima Zeinali Danalou,Hooman Chamani,Arash Rabbani,Patrick C. Lee,Jason Hattrick Simpers,Jay R Werber*

Main category: cond-mat.mtrl-sci

Relevance: 10.0

TL;DR: 论文提出了一种改进的算法，从单张2D SEM图像重建3D孔网络，解决了传统方法的局限性，并在商业膜上验证了其高保真度。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D重建技术昂贵且技术复杂的问题，同时提升对真实膜中多样孔几何形状的还原能力。

Method: 开发了一种增强的重建算法，保持统计特性并准确还原复杂孔形态。

Result: 在商业膜上生成高保真3D重建，验证显示与X射线断层扫描数据高度一致。

Conclusion: 该方法适用于各向同性多孔膜结构，未来需扩展至各向异性膜。

Abstract: A major limitation of two-dimensional scanning electron microscopy (SEM) in
imaging porous membranes is its inability to resolve three-dimensional pore
architecture and interconnectivity, which are critical factors governing
membrane performance. Although conventional tomographic 3-D reconstruction
techniques can address this limitation, they are often expensive, technically
challenging, and not widely accessible. We previously introduced a
proof-of-concept method for reconstructing a membrane's 3-D pore network from a
single 2-D SEM image, yielding statistically equivalent results to those
obtained from 3-D tomography. However, this initial approach struggled to
replicate the diverse pore geometries commonly observed in real membranes. In
this study, we advance the methodology by developing an enhanced reconstruction
algorithm that not only maintains essential statistical properties (e.g., pore
size distribution), but also accurately reproduces intricate pore morphologies.
Applying this technique to a commercial microfiltration membrane, we generated
a high-fidelity 3-D reconstruction and derived key membrane properties.
Validation with X-ray tomography data revealed excellent agreement in
structural metrics, with our SEM-based approach achieving superior resolution
in resolving fine pore features. The tool can be readily applied to isotropic
porous membrane structures of any pore size, as long as those pores can be
visualized by SEM. Further work is needed for 3-D structure generation of
anisotropic membranes.

</details>


<div id='q-bio.OT'></div>

# q-bio.OT [[Back]](#toc)

### [701] [Frequency-Domain Analysis of Time-Dependent Multiomic Data in Progressive Neurodegenerative Diseases: A Proposed Quantum-Classical Hybrid Approach with Quaternionic Extensions](https://arxiv.org/abs/2508.07948)
*John D. Mayfield*

Main category: q-bio.OT

Relevance: 20.0

TL;DR: 论文提出了一种基于量子计算的数学框架，用于分析神经退行性疾病的复杂轨迹，结合傅里叶和拉普拉斯变换、哈密顿动力学及量子-经典混合计算。


<details>
  <summary>Details</summary>
Motivation: 传统时间域分析方法难以捕捉神经退行性疾病的非线性轨迹和隐藏振荡模式，限制了预测准确性。

Method: 将时间序列数据转换为频域或s域，利用哈密顿动力学建模神经元动态，并采用变分量子本征求解器（VQE）进行模式检测。

Result: 理论框架为量子增强的神经退行性疾病分析奠定了基础，并展示了在阿尔茨海默病分类中高达99.89%的准确性潜力。

Conclusion: 该框架为未来通过量子机器学习重新定义神经退行性疾病的精准医学提供了理论基础。

Abstract: Progressive neurodegenerative diseases, including Alzheimer's disease (AD),
multiple sclerosis (MS), Parkinson's disease (PD), and amyotrophic lateral
sclerosis (ALS), exhibit complex, nonlinear trajectories that challenge
deterministic modeling. Traditional time-domain analyses of multiomic and
neuroimaging data often fail to capture hidden oscillatory patterns, limiting
predictive accuracy. We propose a theoretical mathematical framework that
transforms time-series data into frequency or s-domain using Fourier and
Laplace transforms, models neuronal dynamics via Hamiltonian formulations, and
employs quantum-classical hybrid computing with variational quantum
eigensolvers (VQE) for enhanced pattern detection. This theoretical construct
serves as a foundation for future empirical works in quantum-enhanced analysis
of neurodegenerative diseases. We extend this to quaternionic representations
with three imaginary axes ($i, j, k$) to model multistate Hamiltonians in
multifaceted disorders, drawing from quantum neuromorphic computing to capture
entangled neural dynamics \citep{Pehle2020, Emani2019}. This approach leverages
quantum advantages in handling high-dimensional amplitude-phase data, enabling
outlier detection and frequency signature analysis. Potential clinical
applications include identifying high-risk patients with rapid progression or
therapy resistance using s-domain biomarkers, supported by quantum machine
learning (QML) precedents achieving up to 99.89% accuracy in Alzheimer's
classification \citep{Belay2024, Bhowmik2025}. This framework aims to lay the
groundwork for redefining precision medicine for neurodegenerative diseases
through future validations.

</details>
