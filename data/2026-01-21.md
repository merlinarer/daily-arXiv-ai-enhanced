<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 200]
- [cs.CV](#cs.CV) [Total: 291]
- [cs.AI](#cs.AI) [Total: 73]
- [cs.LG](#cs.LG) [Total: 268]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths](https://arxiv.org/abs/2601.11564)
*Ahilan Ayyachamy Nadar Ponnusamy,Karthic Chandran,M Maruf Hossain*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文研究了大型语言模型在处理长上下文时，无关和干扰性内容对模型性能的影响，分析了密集Transformer架构和MoE架构在不同上下文规模下的行为差异。


<details>
  <summary>Details</summary>
Motivation: 随着LLM上下文窗口的不断扩大，处理长上下文带来了严重的计算开销。研究需要平衡系统性能和模型质量，特别是在面对大量无关和干扰性上下文时。

Method: 使用Llama-3.1-70B和Qwen1.5-14B等密集Transformer架构，分析KV缓存增长与性能退化的非线性关系。特别对MoE架构在不同上下文规模下的行为异常进行扩展分析。

Result: 发现性能退化与KV缓存增长呈非线性关系。MoE架构在不同上下文规模下表现出独特的行为异常，表明在高token量时，架构优势可能被基础设施瓶颈所掩盖。

Conclusion: 长上下文处理需要在模型架构优化和基础设施改进之间取得平衡，特别是对于MoE架构，需要重新评估在高token量场景下的实际优势。

Abstract: The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volumes of irrelevant and distracting context. The research identifies a non-linear performance degradation tied to the growth of the Key-Value (KV) cache. Furthermore, an extended analysis of the Mixture-of-Experts (MoE) architecture reveals unique behavioral anomalies at varying context scales, suggesting that architectural benefits may be masked by infrastructure bottlenecks at high token volumes.

</details>


### [2] [Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology](https://arxiv.org/abs/2601.11567)
*Vanessa D'Amario,Randy Daniel,Alessandro Zanetti,Dhruv Edamadaka,Nitya Alaparthy,Joshua Tarkoff*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究评估了6个小型开源医疗LLM在儿科内分泌学中的表现，发现提示微小变化会导致输出显著差异，模型一致性并不代表正确性，且存在自我评估偏差和CUDA构建差异导致的输出变化。


<details>
  <summary>Details</summary>
Motivation: 当前小型开源医疗LLM评估主要局限于医学多选题的准确性，缺乏对一致性、鲁棒性和推理行为的全面评估，这限制了其在真实临床决策支持场景中的应用可靠性。

Method: 使用医学多选题结合人工评估和临床审查，评估6个小型开源医疗LLM。在确定性设置中测试提示变化对输出的影响和自我评估偏差；在随机性设置中评估输出变异性，并研究一致性与正确性的关系。

Result: HuatuoGPT-o1-8B表现最佳。高一致性并不代表正确性，尽管HuatuoGPT-o1-8B一致性最高。模型存在自我评估偏差和候选解释顺序依赖性。专家审查发现错误推理中混合了临床可接受响应和临床疏忽。系统级扰动（如CUDA构建差异）会导致统计显著的输出变化。

Conclusion: 微小语义无关的提示扰动会导致输出分歧，这对LLM评估的可重复性提出担忧。不同随机机制下的输出变异性强调了需要更广泛的诊断框架来理解真实世界临床决策支持场景中的潜在缺陷。

Abstract: Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), Diabetica-7B, Diabetica-o1 (Wei 2024), Meditron3-8B (Sallinen2025), MedFound-7B (Liu 2025), and ClinicaGPT-base-zh (Wang 2023)) in pediatric endocrinology. In deterministic settings, we examine the effect of prompt variation on models' output and self-assessment bias. In stochastic settings, we evaluate output variability and investigate the relationship between consistency and correctness. HuatuoGPT-o1-8B achieved the highest performance. The results show that high consistency across the model response is not an indicator of correctness, although HuatuoGPT-o1-8B showed the highest consistency rate. When tasked with selecting correct reasoning, both HuatuoGPT-o1-8B and Diabetica-o1 exhibit self-assessment bias and dependency on the order of the candidate explanations. Expert review of incorrect reasoning rationales identified a mix of clinically acceptable responses and clinical oversight. We further show that system-level perturbations, such as differences in CUDA builds, can yield statistically significant shifts in model output despite stable accuracy. This work demonstrates that small, semantically negligible prompt perturbations lead to divergent outputs, raising concerns about reproducibility of LLM-based evaluations and highlights the output variability under different stochastic regimes, emphasizing the need of a broader diagnostic framework to understand potential pitfalls in real-world clinical decision support scenarios.

</details>


### [3] [An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT](https://arxiv.org/abs/2601.11573)
*Muhammad Muneeb,David B. Ascher*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一个可重复的LLM微调流程，专门用于生物信息学领域，包括PRSGPT和BioStarsGPT两个用例，通过九步流程生成高质量QA数据，并在三个LLM上进行微调和评估。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂生物信息学应用中缺乏专业知识，需要开发专门针对生物信息学领域的微调方法，以创建可本地部署、保护隐私的专业助手。

Method: 九步微调流程：1) 整合多样化数据源；2) 结构化预处理；3) 基于提示的QA生成（使用Google Gemini）；4) 自然语言推理质量控制；5) 语义去重；6) 基于聚类的数据分割；7) 使用LoRA进行参数高效微调；8) 在三个LLM上微调；9) 使用14+个词汇和语义指标进行基准测试。

Result: Qwen2.5-7B表现最佳：PRSGPT的BLEU-4和ROUGE-1分别提升82%和70%，BioStarsGPT分别提升6%和18%。生成超过28,000个PRSGPT QA对和154,282个BioStarsGPT QA对。人类评估显示PRSGPT在PRS工具比较任务上达到61.9%准确率（与Google Gemini的61.4%相当），但提供更丰富的方法细节和准确引用。BioStarsGPT在142个生物信息学问题上达到59%概念准确率。

Conclusion: 该流程实现了可扩展的领域特定LLM微调，支持隐私保护、本地可部署的生物信息学助手，并探讨了实际应用中的挑战、限制和缓解策略。

Abstract: Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer (QA) generation (via Google Gemini), natural language inference (NLI) for quality control, semantic deduplication, clustering-based data splitting, and parameter-efficient fine-tuning using LoRA. We fine-tuned three LLMs (LLaMA-3.2-3B, Qwen2.5-7B, Gemma) and benchmarked them on over 14 lexical and semantic metrics. Qwen2.5-7B emerged as the best performer, with BLEU-4 and ROUGE-1 improvements of 82\% and 70\% for PRSGPT and 6\% and 18\% for BioStarsGPT, respectively. The open-source datasets produced include over 28,000 QA pairs for PRSGPT and 154,282 for BioStarsGPT. Human evaluation of PRSGPT yielded 61.9\% accuracy on the PRS tools comparison task, comparable to Google Gemini (61.4\%), but with richer methodological detail and accurate citations. BioStarsGPT demonstrated 59\% conceptual accuracy across 142 curated bioinformatics questions. Our pipeline enables scalable, domain-specific fine-tuning of LLMs. It enables privacy-preserving, locally deployable bioinformatics assistants, explores their practical applications, and addresses the challenges, limitations, and mitigation strategies associated with their development and use.

</details>


### [4] [Concept Attractors in LLMs and their Applications](https://arxiv.org/abs/2601.11575)
*Sotirios Panagiotis Chytas,Vikas Singh*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出LLMs内部表示可被解释为迭代函数系统，其中各层作为向概念特定吸引子的压缩映射。基于此开发了无需训练的吸引子干预方法，用于翻译、幻觉减少、护栏设置和合成数据生成等任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常将语义相关的提示映射到特定层的相似内部表示，即使表面形式差异很大。这种行为的数学解释尚不明确，需要理解其内部工作机制并开发更高效的干预方法。

Method: 将LLM层解释为迭代函数系统中的压缩映射，收敛于概念特定吸引子。开发了基于吸引子的无需训练干预方法，直接操作这些吸引子来解决实际任务。

Result: 尽管方法简单，但基于吸引子的干预在语言翻译、幻觉减少、护栏设置和合成数据生成等任务上匹配或超越专门基线，在基线表现不佳的场景中具有更好的泛化能力。

Conclusion: LLMs的内部表示行为可用迭代函数系统解释，基于吸引子的训练免费方法为各种实际任务提供了高效替代方案，避免了繁重的微调过程。

Abstract: Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a wide range of practical tasks, including language translation, hallucination reduction, guardrailing, and synthetic data generation. Despite their simplicity, these Attractor-based interventions match or exceed specialized baselines, offering an efficient alternative to heavy fine-tuning, generalizable in scenarios where baselines underperform.

</details>


### [5] [LimAgents: Multi-Agent LLMs for Generating Research Limitations](https://arxiv.org/abs/2601.11578)
*Ibrahim Al Azher,Zhishuai Guo,Hamed Alhoori*

Main category: cs.CL

Relevance: 85.0

TL;DR: LimAgents：一个多智能体LLM框架，用于生成实质性研究局限性分析，通过整合OpenReview评论、作者陈述的局限性以及引用文献来识别显式和隐式局限性，相比零样本基线显著提升覆盖率。


<details>
  <summary>Details</summary>
Motivation: 当前零样本LLM在生成研究局限性时往往产生表面化或通用化的陈述，重复作者已报告的内容而忽略更深层的方法论问题和背景差距。许多作者仅披露部分或琐碎的局限性，导致局限性分析质量不足。

Method: 提出LimAgents多智能体框架，整合OpenReview评论和作者陈述的局限性作为基础，利用引用和被引文献捕捉更广泛的背景弱点。框架包含多个角色特定的智能体：提取显式局限性、分析方法论差距、模拟同行评审视角、分析文献背景等。Judge智能体精炼输出，Master智能体整合成清晰集合。同时引入基于LLM-as-a-Judge的点对点评估协议，替代传统NLP指标。

Result: 实验显示LimAgents显著提升性能：RAG + 多智能体GPT-4o mini配置相比零样本基线获得+15.51%的覆盖率提升，Llama 3 8B多智能体设置获得+4.41%改进。

Conclusion: LimAgents通过多智能体协作和文献整合，能够系统识别显式、隐式、同行评审导向和文献背景化的局限性，为研究局限性分析提供了更全面和实质性的解决方案。

Abstract: Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial or trivial limitations. We propose LimAgents, a multi-agent LLM framework for generating substantive limitations. LimAgents integrates OpenReview comments and author-stated limitations to provide stronger ground truth. It also uses cited and citing papers to capture broader contextual weaknesses. In this setup, different agents have specific roles as sequential role: some extract explicit limitations, others analyze methodological gaps, some simulate the viewpoint of a peer reviewer, and a citation agent places the work within the larger body of literature. A Judge agent refines their outputs, and a Master agent consolidates them into a clear set. This structure allows for systematic identification of explicit, implicit, peer review-focused, and literature-informed limitations. Moreover, traditional NLP metrics like BLEU, ROUGE, and cosine similarity rely heavily on n-gram or embedding overlap. They often overlook semantically similar limitations. To address this, we introduce a pointwise evaluation protocol that uses an LLM-as-a-Judge to measure coverage more accurately. Experiments show that LimAgents substantially improve performance. The RAG + multi-agent GPT-4o mini configuration achieves a +15.51% coverage gain over zero-shot baselines, while the Llama 3 8B multi-agent setup yields a +4.41% improvement.

</details>


### [6] [Speculative Decoding: Performance or Illusion?](https://arxiv.org/abs/2601.11580)
*Xiaoxuan Liu,Jiaxiang Yu,Jongseok Park,Ion Stoica,Alvin Cheung*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文对推测解码（SD）在生产级推理引擎vLLM上进行了首次系统性研究，评估了多种SD变体在不同工作负载、模型规模和批量大小下的性能，分析了影响SD性能的关键因素，并量化了SD加速的理论上限。


<details>
  <summary>Details</summary>
Motivation: 推测解码已成为加速大语言模型推理的流行技术，但先前评估多基于研究原型和不切实际的小批量大小，其实际有效性仍不清楚。本研究旨在填补这一空白，在生产级推理引擎上进行系统性评估。

Method: 在广泛部署的生产级推理引擎vLLM上，对多种SD变体（n-gram、EAGLE/EAGLE-3、Draft-Model、Multi-Token Prediction）进行系统性评估，涵盖多样化的工作负载、模型规模和批量大小。分析影响SD性能的关键因素，并量化SD加速的理论上限。

Result: 研究发现：1）目标模型的验证过程主导执行时间；2）接受长度在不同输出token位置、请求和数据集间差异显著；3）实测性能与理论上限存在显著差距，揭示了SD优化的新研究机会。

Conclusion: 本研究为推测解码在生产环境中的实际表现提供了首个系统性评估，揭示了当前SD实现与理论潜力之间的差距，为改进SD技术指明了新的研究方向。

Abstract: Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction) across diverse workloads, model scales, and batch sizes. We analyze key factors governing SD performance, and quantify a theoretical upper bound on SD speedup. Our results show that verification by the target model dominates the execution, while acceptance length varies markedly across output token positions, requests, and datasets. Comparing measured performance with theoretical bounds reveals substantial gaps between observed and theoretical upper bounds, and we leverage this observation to highlight new research opportunities that our study opens up in improving SD.

</details>


### [7] [Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents](https://arxiv.org/abs/2601.11585)
*Hyunjun Kim*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出Entropic Context Shaping (ECS)框架，通过信息论方法测量上下文对LLM回答分布的效用，相比传统词法相似度方法在上下文选择任务上取得显著提升


<details>
  <summary>Details</summary>
Motivation: LLM智能体的上下文工程需要区分真正有用的信息和误导性干扰信息。传统基于词法相似度的方法（如TF-IDF）无法捕捉语用效用，即一段文本是否真正帮助回答问题

Method: 提出信息论框架ECS，通过测量模型答案分布向正确答案的偏移来量化上下文效用。将效用定义为答案概率的有符号变化，并提供理论分析表明任务无关的更新产生接近零的分布偏移

Result: 在LongMemEval（会话级）和LoCoMo（轮次级）基准测试中，ECS在细粒度轮次选择任务上，使用Llama-3.1-8B达到F1=0.265，相比TF-IDF（F1=0.154）相对提升71.83%

Conclusion: ECS框架能够有效捕捉上下文的语用效用，在精确上下文选择任务上显著优于传统词法相似度方法，为LLM智能体的上下文工程提供了更有效的工具

Abstract: Context engineering for large language model (LLM) agents requires distinguishing pragmatically useful information from misleading distractors. We introduce Entropic Context Shaping (ECS), an information-theoretic framework that measures context utility via the shift in the model's answer distribution toward the correct answer. Unlike lexical similarity methods that rely on word overlap, ECS captures pragmatic utility -- whether a passage actually helps answer the question. We formalize utility as the signed change in answer probability and provide theoretical analysis showing that task-irrelevant updates yield near-zero distribution shift. We evaluate on multi-turn context selection tasks using LongMemEval (session-level) and LoCoMo (turn-level) benchmarks. On fine-grained turn selection, ECS with Llama-3.1-8B achieves F1=0.265, a 71.83% relative improvement over TF-IDF (F1=0.154), demonstrating that pragmatic utility outperforms lexical similarity when precise context selection matters. Code and data are available in the supplementary materials.

</details>


### [8] [Towards AGI A Pragmatic Approach Towards Self Evolving Agent](https://arxiv.org/abs/2601.11658)
*Indrajit Kar,Sammy Zonunpuia,Zonunfeli Ralte*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出分层自进化多智能体框架，通过课程学习、强化学习和遗传算法实现LLM智能体的自主能力扩展和工具生成


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体在部署后是静态的，缺乏自主扩展能力、生成新工具或进化推理的能力，需要实现持续自适应

Method: 分层自进化多智能体框架：基础LLM、操作SLM智能体、代码生成LLM、教师LLM；采用三级工作流：任务尝试→工具合成→进化阶段（课程学习、基于奖励学习、遗传算法）

Result: 在TaskCraft数据集上评估，课程学习实现快速恢复和强泛化，强化学习在高难度任务上表现优异，遗传算法提供高行为多样性；所有进化智能体均优于原始版本

Conclusion: 分层自进化框架实现了LLM智能体的稳健、自主、自我改进的进化，解决了静态智能体的局限性

Abstract: Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.

</details>


### [9] [LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text](https://arxiv.org/abs/2601.11746)
*George Mihaila,Suleyman Olcay Polat,Poli Nemkova,Himanshu Sharma,Namratha V. Urs,Mark V. Albert*

Main category: cs.CL

Relevance: 85.0

TL;DR: LIME-LLM：一种用于NLP黑盒模型解释的新框架，通过假设驱动的受控扰动替换随机掩码，使用"单掩码-单样本"协议和中性填充策略，构建流畅的流形上邻域，显著提升局部解释的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有局部解释方法（如LIME）在NLP应用中依赖随机令牌掩码，产生语义无效的分布外输入，降低局部代理模型的保真度。最近的生成方法（如LLiMe）使用LLM进行邻域生成，但无约束的改写引入混淆变量，难以隔离特定特征贡献。

Method: 提出LIME-LLM框架：1）用假设驱动的受控扰动替换随机噪声；2）采用严格的"单掩码-单样本"协议；3）使用中性填充和边界填充策略；4）构建流畅的流形上邻域以隔离特征效应。

Result: 在CoLA、SST-2和HateXplain三个基准测试中，使用人工标注的rationales作为ground truth进行评估。LIME-LLM相比传统方法（LIME、SHAP、Integrated Gradients）和生成基线LLiMe，在局部解释保真度上取得显著提升。

Conclusion: LIME-LLM为黑盒NLP可解释性设立了新基准，通过受控扰动和流形保持的邻域构建，解决了传统扰动方法和生成方法的关键限制，显著提高了局部解释的可靠性。

Abstract: Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict "Single Mask-Single Sample" protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.

</details>


### [10] [Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models](https://arxiv.org/abs/2601.11776)
*Kaituo Zhang,Zhimeng Jiang,Na Zou*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出一种完全自反思的去毒框架，利用LLMs内在能力检测、修正有毒内容并精炼模型，无需外部模块或数据标注


<details>
  <summary>Details</summary>
Motivation: 现有去毒技术很少利用LLMs内在的自校正和自我奖励能力，而是依赖外部模块、人工数据标注或人工干预，这限制了可扩展性和一致性

Method: 提出毒性信号检测器（内部自识别机制）和系统性干预过程，将有毒文本转换为无毒对应物，迭代过程生成对比去毒数据集用于微调模型

Result: 在DetoxLLM和ParaDetox基准测试中，方法在去毒性能上优于最先进方法，同时保持语义保真度

Conclusion: 揭示了LLMs内在的自去毒能力，为减轻有害内容生成提供了一致有效的途径，为真正自调节的语言模型铺平道路

Abstract: Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.

</details>


### [11] [Translation as a Scalable Proxy for Multilingual Evaluation](https://arxiv.org/abs/2601.11778)
*Sheriff Issaka,Erick Rosas Gonzalez,Lieqi Liu,Evans Kofi Agyei,Lucas Bandarkar,Nanyun Peng,David Ifeoluwa Adelani,Francisco Guzmán,Saadia Gabriel*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现翻译质量是评估大语言模型多语言能力的有效代理指标，可替代昂贵的人工标注基准测试


<details>
  <summary>Details</summary>
Motivation: 当前LLM声称具备多语言能力，但缺乏全面的非机器翻译基准测试（覆盖不到30种语言），传统基准构建面临成本高、专家稀缺、数据污染等扩展挑战。需要寻找更简单有效的评估方法。

Method: 系统评估14个模型（1B-72B参数）在9个多样化基准测试和7个翻译指标上的表现，分析翻译性能与下游任务成功之间的相关性。

Result: 翻译性能是下游任务成功的良好指标（Phi-4模型的中位数Pearson相关系数：MetricX=0.89，xCOMET=0.91，SSA-COMET=0.87），表明支持忠实翻译的表征能力与多语言理解所需能力高度重叠。

Conclusion: 翻译质量可作为强大且廉价的多语言性能初步代理指标，实现"翻译优先筛选+特定任务针对性跟进"的评估策略。

Abstract: The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving >98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can translation quality alone indicate a model's broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, we find that translation performance is a good indicator of downstream task success (e.g., Phi-4, median Pearson r: MetricX = 0.89, xCOMET = 0.91, SSA-COMET = 0.87). These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality, thus emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.

</details>


### [12] [Beyond Tokens: Concept-Level Training Objectives for LLMs](https://arxiv.org/abs/2601.11791)
*Laya Iyer,Pranav Somani,Alice Guo,Dan Jurafsky,Chen Shani*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出从token级预测转向概念级预测，将同一概念的不同表面形式（如"mom"、"mother"）分组，引入概念监督来改进LLM训练


<details>
  <summary>Details</summary>
Motivation: 传统next-token预测(NTP)目标在token级别操作，会将语义等价但表面形式不同的续写视为错误，惩罚有效的抽象、改写或概念正确的推理路径，导致模型偏向表面形式而非底层含义。这种训练信号与语义正确性之间的不匹配需要更高层次的表示学习目标。

Method: 提出从token级预测转向概念级预测，其中概念将同一想法的多个表面形式分组（如"mom"、"mommy"、"mother"→MOTHER）。介绍了将概念监督集成到LLM训练中的各种方法。

Result: 概念感知模型实现了更低的困惑度，在领域转移下具有更好的鲁棒性，在多样NLP基准测试中比NTP模型表现更强。

Conclusion: 概念级监督作为一种改进的训练信号，能更好地将LLM与人类语义抽象对齐。

Abstract: The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\rightarrow$ \textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.

</details>


### [13] [CTPD: Cross Tokenizer Preference Distillation](https://arxiv.org/abs/2601.11865)
*Truong Nguyen,Phi Van Dat,Ngan Nguyen,Linh Ngo Van,Trung Le,Thanh Hong Nguyen*

Main category: cs.CL

Relevance: 85.0

TL;DR: CTPD是首个在异构分词器模型间进行偏好蒸馏的统一框架，通过字符级对齐投影、跨分词器重要性采样和教师锚定参考三大创新，解决了偏好对齐中的分词器不兼容问题。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏在预训练和指令调优中广泛应用，但在语言模型与人类偏好对齐方面探索不足，特别是在更现实的跨分词器场景中。分词器方案的不兼容性阻碍了偏好信息的细粒度白盒蒸馏。

Method: 提出跨分词器偏好蒸馏(CTPD)框架：1) 对齐跨度投影：将师生模型token映射到共享字符级跨度进行精确监督传递；2) 跨分词器token级重要性采样(TIS-DPO)适配；3) 教师锚定参考：让学生模型在DPO风格目标中直接利用教师偏好。

Result: 理论分析基于重要性采样，多个基准测试实验证实了CTPD的有效性，相比现有方法取得了显著性能提升。

Conclusion: CTPD为不同分词器方案间的偏好蒸馏提供了实用通用解决方案，为语言模型更易获取和高效的对齐打开了大门。

Abstract: While knowledge distillation has seen widespread use in pre-training and instruction tuning, its application to aligning language models with human preferences remains underexplored, particularly in the more realistic cross-tokenizer setting. The incompatibility of tokenization schemes between teacher and student models has largely prevented fine-grained, white-box distillation of preference information. To address this gap, we propose Cross-Tokenizer Preference Distillation (CTPD), the first unified framework for transferring human-aligned behavior between models with heterogeneous tokenizers. CTPD introduces three key innovations: (1) Aligned Span Projection, which maps teacher and student tokens to shared character-level spans for precise supervision transfer; (2) a cross-tokenizer adaptation of Token-level Importance Sampling (TIS-DPO) for improved credit assignment; and (3) a Teacher-Anchored Reference, allowing the student to directly leverage the teacher's preferences in a DPO-style objective. Our theoretical analysis grounds CTPD in importance sampling, and experiments across multiple benchmarks confirm its effectiveness, with significant performance gains over existing methods. These results establish CTPD as a practical and general solution for preference distillation across diverse tokenization schemes, opening the door to more accessible and efficient alignment of language models.

</details>


### [14] [Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving](https://arxiv.org/abs/2601.11866)
*Kie Shidara,Preethi Prem,Jonathan Kim,Anna Podlasek,Feng Liu,Ahmed Alaa,Danilo Bernardo*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究评估了多个大型语言模型在医学抽象推理测试(mARC)上的表现，发现强大的推理模型能够避免Einstellung效应陷阱，达到人类水平的医学推理灵活性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在医学QA基准测试中表现出高准确率，但其临床推理的灵活性一直存在争议。研究旨在探究先进的推理模型是否能在临床推理中展现更好的认知灵活性。

Method: 使用医学抽象推理测试(mARC)这一对抗性医学QA基准，评估了OpenAI、Grok、Gemini、Claude和DeepSeek等家族的推理模型。mARC利用Einstellung效应诱导模型过度依赖习得的启发式模式。

Result: 强大的推理模型比弱推理模型更常避免Einstellung效应陷阱，在mARC上达到人类水平表现。在医生最常出错的问题上，前5名模型以高置信度正确回答了55%到70%的问题。

Conclusion: 强推理模型在医学推理中展现出改进的灵活性，在mARC上的表现与人类相当，表明这些模型可能比人类更不容易受到Einstellung效应的影响。

Abstract: Large Language Models (LLMs) have achieved high accuracy on medical question-answer (QA) benchmarks, yet their capacity for flexible clinical reasoning has been debated. Here, we asked whether advances in reasoning LLMs improve their cognitive flexibility in clinical reasoning. We assessed reasoning models from the OpenAI, Grok, Gemini, Claude, and DeepSeek families on the medicine abstraction and reasoning corpus (mARC), an adversarial medical QA benchmark which utilizes the Einstellung effect to induce inflexible overreliance on learned heuristic patterns in contexts where they become suboptimal. We found that strong reasoning models avoided Einstellung-based traps more often than weaker reasoning models, achieving human-level performance on mARC. On questions most commonly missed by physicians, the top 5 performing models answered 55% to 70% correctly with high confidence, indicating that these models may be less susceptible than humans to Einstellung effects. Our results indicate that strong reasoning models demonstrate improved flexibility in medical reasoning, achieving performance on par with humans on mARC.

</details>


### [15] [Faithfulness vs. Safety: Evaluating LLM Behavior Under Counterfactual Medical Evidence](https://arxiv.org/abs/2601.11886)
*Kaijie Mo,Siddhartha Venkatayogi,Chantal Shaib,Ramez Kouzy,Wei Xu,Byron C. Wallace,Junyi Jessy Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文研究了LLMs在面对医学领域反事实证据时的行为，发现现有模型会盲目接受危险或不合理的反事实证据并给出自信回答，揭示了忠实性与安全性之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 在医学等高风险领域，模型通常需要忠实遵循提供的上下文。但当上下文与模型先验或安全协议不一致时会发生什么？本研究旨在探索LLMs在面对反事实或对抗性医学证据时的行为和推理方式。

Method: 构建了MedCounterFact反事实医学QA数据集，包含临床比较问题（评估治疗效果），将真实医学干预系统性地替换为四种反事实刺激（从未知词汇到有毒物质）。在多个前沿LLMs上评估其在反事实证据下的表现。

Result: 评估显示，在反事实证据存在时，现有模型绝大多数会表面接受这些证据（即使危险或不可信），并提供自信且无保留的回答。模型在忠实性与安全性之间缺乏明确边界。

Conclusion: 虽然理论上需要在忠实性与安全性之间划清界限，但研究发现现有模型尚未建立这样的边界。这对医学等高风险领域LLMs的部署提出了重要警示。

Abstract: In high-stakes domains like medicine, it may be generally desirable for models to faithfully adhere to the context provided. But what happens if the context does not align with model priors or safety protocols? In this paper, we investigate how LLMs behave and reason when presented with counterfactual or even adversarial medical evidence. We first construct MedCounterFact, a counterfactual medical QA dataset that requires the models to answer clinical comparison questions (i.e., judge the efficacy of certain treatments, with evidence consisting of randomized controlled trials provided as context). In MedCounterFact, real-world medical interventions within the questions and evidence are systematically replaced with four types of counterfactual stimuli, ranging from unknown words to toxic substances. Our evaluation across multiple frontier LLMs on MedCounterFact reveals that in the presence of counterfactual evidence, existing models overwhelmingly accept such "evidence" at face value even when it is dangerous or implausible, and provide confident and uncaveated answers. While it may be prudent to draw a boundary between faithfulness and safety, our findings reveal that there exists no such boundary yet.

</details>


### [16] [PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning](https://arxiv.org/abs/2601.11908)
*Byeongjin Kim,Gyuwan Kim,Seo Yeon Park*

Main category: cs.CL

Relevance: 85.0

TL;DR: PPA-Plan是一种用于长上下文推理的主动规划策略，通过识别潜在逻辑陷阱和错误假设，将其作为负面约束，并在规划生成时明确避免这些约束，从而防止规划失败。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长上下文推理中存在困难，相关信息稀疏分布。现有的规划-执行框架因依赖表面线索导致规划不可靠，一旦形成错误规划难以识别和修正，限制了反应式细化的效果。

Method: 提出PPA-Plan主动规划策略：1）识别潜在逻辑陷阱和错误假设；2）将其表述为负面约束；3）在规划生成时明确避免这些约束。这种方法在规划生成前就预防失败。

Result: 在长上下文QA基准测试中，执行PPA-Plan生成的规划一致优于现有的规划-执行方法和直接提示方法。

Conclusion: PPA-Plan通过主动识别和避免潜在失败点，有效提升了长上下文推理中规划-执行框架的可靠性和性能，解决了传统方法中规划不可靠和难以修正的问题。

Abstract: Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.

</details>


### [17] [LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding](https://arxiv.org/abs/2601.11913)
*Yichen Jiang,Peng Ye,Jiakang Yuan,Chongjun Tu,Lei Bai,Tao Chen*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出LSTM-MAS多智能体系统，借鉴LSTM架构设计链式智能体结构处理长文本，通过门控机制控制信息传播，有效减少错误累积和幻觉传播，在多个长文本问答基准上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM处理长上下文存在挑战：单LLM方法需要减少上下文窗口或优化注意力机制，但会带来额外计算成本或限制扩展长度；多智能体框架虽然能缓解这些限制，但容易累积错误和传播幻觉。需要设计更鲁棒的长文本理解方法。

Method: 受LSTM架构启发设计多智能体系统LSTM-MAS，采用链式架构组织智能体：每个节点包含worker agent（片段级理解）、filter agent（冗余减少）、judge agent（持续错误检测）、manager agent（全局信息传播和保留调控）。这些组件分别对应LSTM的输入门、遗忘门、恒定误差轮转单元和输出门，实现受控信息传递和选择性长期依赖建模。

Result: 相比之前最佳多智能体方法CoA，在NarrativeQA、Qasper、HotpotQA和MuSiQue基准上分别提升40.93%、43.70%、121.57%和33.12%，显著减少错误累积和幻觉传播。

Conclusion: LSTM-MAS通过借鉴LSTM的门控记忆机制设计多智能体系统，能够有效处理长上下文，控制信息传播，避免错误累积和幻觉传播，为LLM长文本理解提供了新思路。

Abstract: Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.

</details>


### [18] [Enhancing LLM-Based Data Annotation with Error Decomposition](https://arxiv.org/abs/2601.11920)
*Zhen Xu,Vedant Khatri,Yijun Dai,Xiner Liu,Siyan Li,Xuanming Zhang,Renzhe Yu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出诊断评估范式，通过人机协同分离任务固有模糊性与模型误差，评估LLM在主观标注任务中的表现


<details>
  <summary>Details</summary>
Motivation: LLM在客观标注任务上已接近人类水平，但在主观标注任务（如心理建构）上表现不稳定且易出错。现有评估方法将所有错误合并为单一对齐指标，掩盖了不同类型错误对分析结论的不同影响。

Method: 提出诊断评估范式：1）二维错误分类法（来源：模型特定vs任务固有；类型：边界模糊vs概念误判）；2）轻量级人工标注测试估计任务固有模糊性；3）计算分解LLM标注错误的方法。在四个教育标注任务上验证。

Result: 验证了范式的概念有效性和实用价值。理论上证明在特定标注任务中过高对齐不现实，单一对齐指标不足以反映LLM标注质量。实践上可作为低成本诊断工具评估任务是否适合LLM标注，并为技术优化提供可操作见解。

Conclusion: 提出的诊断评估范式能更细致地评估LLM在主观标注任务中的表现，分离任务固有模糊性与模型误差，为LLM标注的适用性评估和技术优化提供实用工具。

Abstract: Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.

</details>


### [19] [Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence](https://arxiv.org/abs/2601.11956)
*Yuyin Lu,Ziran Liang,Yanghui Rao,Wenqi Fan,Fu Lee Wang,Qing Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: DoublyCal是一个基于双重校准原则的框架，通过轻量级代理模型生成带校准置信度的知识图谱证据，然后引导黑盒LLM产生更准确且校准良好的预测，显著提升LLM在知识密集型任务中的准确性和置信度校准。


<details>
  <summary>Details</summary>
Motivation: LLM存在幻觉问题，虽然知识图谱增强方法能提高事实准确性，但现有方法无法量化检索证据和LLM推理中的认知不确定性。需要一种既能提高准确性又能提供可靠不确定性估计的方法。

Method: 提出DoublyCal框架，基于双重校准原则：1）使用轻量级代理模型生成知识图谱证据并校准证据置信度；2）用校准后的证据引导黑盒LLM，产生最终预测，其置信度可追溯到支持证据的不确定性。

Result: 在知识密集型基准测试中，DoublyCal显著提高了黑盒LLM的准确性和置信度校准，同时保持了较低的token成本。

Conclusion: DoublyCal通过双重校准机制有效解决了LLM与知识图谱结合中的不确定性量化问题，为构建可信的LLM推理系统提供了新思路。

Abstract: Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.

</details>


### [20] [PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning](https://arxiv.org/abs/2601.11957)
*Bingxuan Li,Jeonghwan Kim,Cheng Qian,Xiusi Chen,Eitan Anzenberg,Niran Kundapur,Heng Ji*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出CalConflictBench基准测试用于评估LLM在日历冲突解决任务中的表现，发现现有LLM代理表现不佳，进而提出PEARL强化学习框架来提升性能。


<details>
  <summary>Details</summary>
Motivation: 日历冲突解决是繁忙专业人士面临的常见问题，自动化这一过程具有重要价值。现有的人类委托方式难以扩展，因此研究LLM能否有效管理时间成为关键问题。

Method: 1. 引入CalConflictBench基准测试，包含顺序呈现的冲突场景和每轮反馈；2. 提出PEARL强化学习框架，包含外部记忆模块和优化的轮次奖励设计，使代理能够渐进推断和适应用户偏好。

Result: 当前LLM代理表现较差（如Qwen-3-30B-Think平均错误率35%），而PEARL实现了0.76的错误减少率和55%的平均错误率改进。

Conclusion: LLM在日历冲突解决任务中仍有改进空间，PEARL框架通过强化学习和记忆增强显著提升了性能，为LLM在实际时间管理应用中的可信度提供了实证支持。

Abstract: Overlapping calendar invitations force busy professionals to repeatedly decide which meetings to attend, reschedule, or decline. We refer to this preference-driven decision process as calendar conflict resolution. Automating such process is crucial yet challenging. Scheduling logistics drain hours, and human delegation often fails at scale, which motivate we to ask: Can we trust large language model (LLM) or language agent to manager time? To enable systematic study of this question, we introduce CalConflictBench, a benchmark for long-horizon calendar conflict resolution. Conflicts are presented sequentially and agents receive feedback after each round, requiring them to infer and adapt to user preferences progressively. Our experiments show that current LLM agents perform poorly with high error rates, e.g., Qwen-3-30B-Think has 35% average error rate. To address this gap, we propose PEARL, a reinforcement-learning framework that augments language agent with an external memory module and optimized round-wise reward design, enabling agent to progressively infer and adapt to user preferences on-the-fly. Experiments on CalConflictBench shows that PEARL achieves 0.76 error reduction rate, and 55% improvement in average error rate compared to the strongest baseline.

</details>


### [21] [$\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models](https://arxiv.org/abs/2601.11969)
*Zecheng Tang,Baibei Ji,Ruoxi Sun,Haitian Wang,WangJie You,Zhang Yijun,Wenpeng Zhu,Ji Qi,Juntao Li,Min Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了首个用于系统研究奖励模型评估长上下文记忆管理能力的基准MemoryRewardBench，涵盖理解与生成任务，上下文长度达128K，评估13个前沿奖励模型发现开源与专有模型差距缩小。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多采用基于记忆的分段处理机制来应对长上下文，有效的记忆管理成为关键能力。目前缺乏系统评估奖励模型对长时记忆管理质量评估能力的基准，这阻碍了记忆管理能力的可靠自动化评估。

Method: 构建MemoryRewardBench基准，覆盖长上下文理解和长文本生成两类任务，包含10种不同记忆管理模式的设置，上下文长度从8K到128K tokens。使用该基准评估13个前沿奖励模型，分析开源与专有模型差距、代际改进趋势。

Result: 评估显示开源与专有奖励模型的性能差距正在缩小，新一代模型无论参数量多少都持续超越前代模型。同时揭示了当前奖励模型在评估LLM记忆管理能力方面的基本局限性。

Conclusion: MemoryRewardBench为系统评估奖励模型的记忆管理评估能力提供了首个基准，揭示了当前奖励模型的进步与局限，为未来改进提供了方向。

Abstract: Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.

</details>


### [22] [Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection](https://arxiv.org/abs/2601.12033)
*Muhammad Alif Al Hakim,Alfan Farizki Wicaksono,Fajri Koto*

Main category: cs.CL

Relevance: 85.0

TL;DR: 量化会降低LLM的公平性和安全性，动态量化比静态量化更稳定，非英语语言的安全退化更严重。作者提出Critical Weight Protection方法，在不重新训练的情况下保护关键权重。


<details>
  <summary>Details</summary>
Motivation: 量化被广泛用于降低LLM计算成本，但其对公平性和安全性的影响，特别是在动态量化和多语言环境中的影响，尚未得到充分研究。需要系统研究量化方法如何影响不同语言中的公平性和安全性。

Method: 系统研究静态和动态量化方法对公平性和安全性的影响，评估英语、法语、荷兰语、西班牙语、土耳其语的公平性，以及英语、韩语、阿拉伯语的安全性。提出Critical Weight Protection技术，识别和保护量化过程中的公平性和安全性关键权重。

Result: 量化一致性地降低公平性和安全性，动态方法比静态方法更稳定。公平性退化在不同语言间有差异，安全性退化在非英语环境中尤其明显。Critical Weight Protection能有效缓解偏见和安全性退化，无需昂贵的重新训练或对齐。

Conclusion: 量化对LLM的公平性和安全性有显著负面影响，特别是在多语言环境中。提出的Critical Weight Protection方法能在保持效率的同时维护可信度，为量化LLM的负责任部署提供了实用解决方案。

Abstract: Quantization is widely adopted to reduce the computational cost of large language models (LLMs); however, its implications for fairness and safety, particularly in dynamic quantization and multilingual contexts, remain underexplored. In this work, we conduct a systematic study of how static and dynamic quantization methods impact fairness and safety across benchmarks measuring intrinsic and extrinsic bias and safety alignment. For fairness, we evaluate English, French, Dutch, Spanish, and Turkish; for safety, we focus on English, Korean, and Arabic. Our findings reveal that quantization consistently degrades fairness and safety, with dynamic methods demonstrating greater stability than static ones. Moreover, fairness degradation varies across languages, while safety deterioration is especially pronounced in non-English settings. To address these risks, we introduce Critical Weight Protection, a novel technique that identifies and preserves fairness- and safety-critical weights during quantization. This approach effectively mitigates bias and safety deterioration without costly retraining or alignment, maintaining trustworthiness while retaining efficiency.

</details>


### [23] [Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs](https://arxiv.org/abs/2601.12034)
*Ziyi Zhao,Chongming Gao,Yang Zhang,Haoyan Liu,Weinan Gan,Huifeng Guo,Yong Liu,Fuli Feng*

Main category: cs.CL

Relevance: 85.0

TL;DR: PUMA是一个轻量级框架，用于在不兼容的LLM模型之间高效迁移个性化提示，无需全量重训练，可降低98%计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前LLM个性化依赖于用户特定的软提示，但当基础模型升级时，这些提示会过时，需要昂贵的全量重训练。需要一种方法来解耦用户资产与底层模型，实现可持续的个性化AI演进。

Method: 提出Prompt-level User Migration Adapter (PUMA)框架：1) 使用参数高效的适配器桥接语义鸿沟；2) 采用基于组的用户选择策略显著降低训练成本。

Result: 在三个大规模数据集上的实验表明，PUMA匹配甚至超过从头重训练的性能，计算成本降低高达98%。框架在不同模型架构上表现出强泛化能力，在链式和聚合迁移等高级场景中保持鲁棒性。

Conclusion: PUMA为个性化AI的可持续演进提供了实用路径，通过解耦用户资产与底层模型，解决了模型升级时个性化提示迁移的挑战。

Abstract: Personalization in Large Language Models (LLMs) often relies on user-specific soft prompts. However, these prompts become obsolete when the foundation model is upgraded, necessitating costly, full-scale retraining. To overcome this limitation, we propose the Prompt-level User Migration Adapter (PUMA), a lightweight framework to efficiently migrate personalized prompts across incompatible models. PUMA utilizes a parameter-efficient adapter to bridge the semantic gap, combined with a group-based user selection strategy to significantly reduce training costs. Experiments on three large-scale datasets show our method matches or even surpasses the performance of retraining from scratch, reducing computational cost by up to 98%. The framework demonstrates strong generalization across diverse model architectures and robustness in advanced scenarios like chained and aggregated migrations, offering a practical path for the sustainable evolution of personalized AI by decoupling user assets from the underlying models.

</details>


### [24] [To Copy or Not to Copy: Copying Is Easier to Induce Than Recall](https://arxiv.org/abs/2601.12075)
*Mehrdad Farahani,Franziska Penzkofer,Richard Johansson*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了一种机制研究，通过从模型激活中提取"仲裁向量"来研究语言模型在检索增强设置中如何权衡参数知识与上下文信息。该向量通过对比不同上下文条件下的激活差异计算得出，可用于干预模型在"复制"和"回忆"之间的行为切换。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在检索增强设置中如何权衡参数知识（存储在权重中）与上下文信息（提示中）的决策机制。当前缺乏对这种仲裁过程的机制性理解，特别是在不同上下文条件下模型如何选择依赖参数记忆还是复制上下文内容。

Method: 1) 构建专门数据集，区分两种上下文条件：无关上下文（引发参数回忆）和相关但错误上下文（引发复制）；2) 从模型激活中提取仲裁向量，计算两种条件下残差流质心的差异；3) 将该向量作为加性干预注入到选定层和标记位置，以引导行为在两个方向切换：复制→回忆（抑制上下文使用）和回忆→复制（诱导模型复制上下文中的任何标记）；4) 在两个架构（仅解码器和编码器-解码器）和两个开放域QA基准上进行实验。

Result: 实验显示在适度缩放下行为转换具有一致性，同时监控准确性和流畅性。机制分析（注意力路由、MLP贡献、层间概率轨迹）揭示了一个不对称性：诱导复制是一个简单的"重新激活"过程，可以在输入的不同位置触发；而恢复回忆是一个更脆弱的"抑制"过程，与对象标记干预密切相关。

Conclusion: 语言模型在参数知识与上下文信息之间的仲裁机制存在不对称性，诱导上下文复制相对容易，而抑制上下文依赖恢复参数回忆则更为脆弱。这为理解模型在检索增强设置中的决策机制提供了新的机制性见解。

Abstract: Language models used in retrieval-augmented settings must arbitrate between parametric knowledge stored in their weights and contextual information in the prompt. This work presents a mechanistic study of that choice by extracting an \emph{arbitration vector} from model activations on a curated dataset designed to disentangle (i) irrelevant contexts that elicit parametric recall and (ii) relevant but false contexts that elicit copying. The vector is computed as the residual-stream centroid difference between these regimes across 27 relations, and is injected as an additive intervention at selected layers and token spans to steer behavior in two directions: Copy$\rightarrow$Recall (suppressing context use) and Recall$\rightarrow$Copy (inducing the model to copy any token from the context). Experiments on two architectures (decoder-only and encoder/decoder) and two open-domain QA benchmarks show consistent behavior shifts under moderate scaling while monitoring accuracy and fluency. Mechanistic analyses of attention routing, MLP contributions, and layer-wise probability trajectories reveal an asymmetry: inducing copying is an easy ``reactivation'' process that can be triggered at different locations in the input, while restoring recall is a ``suppression'' process that is more fragile and strongly tied to object-token interventions.

</details>


### [25] [Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization](https://arxiv.org/abs/2601.12078)
*Linfeng Du,Ye Yuan,Zichen Zhao,Fuyuan Lyu,Emiliano Penaloza,Xiuying Chen,Zipeng Sun,Jikun Kang,Laurent Charlin,Xue Liu,Haolun Wu*

Main category: cs.CL

Relevance: 85.0

TL;DR: PURPLE是一个基于上下文老虎机的框架，通过优化用户档案来提升LLM个性化效果，直接根据生成质量而非语义相关性来选择历史记录。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索增强的LLM个性化方法通常根据语义相关性选择用户历史记录，但相关性并不能可靠地代表效用——语义相似的记录可能因冗余或冲突信息而无法改善甚至降低生成质量。

Method: 提出PURPLE框架，将档案构建视为集合生成过程，使用Plackett-Luce排序模型捕捉复杂的记录间依赖关系，通过参考响应的似然度提供的密集反馈进行训练，使检索直接与生成质量对齐。

Result: 在九个个性化任务上的广泛实验表明，PURPLE在效果和效率上都显著优于强启发式和检索增强基线方法。

Conclusion: PURPLE为优化用户档案提供了一个原则性和可扩展的解决方案，通过直接优化生成质量而非依赖语义相关性作为代理，实现了更有效的LLM个性化。

Abstract: Large Language Models (LLMs) excel at general-purpose tasks, yet adapting their responses to individual users remains challenging. Retrieval augmentation provides a lightweight alternative to fine-tuning by conditioning LLMs on user history records, and existing approaches typically select these records based on semantic relevance. We argue that relevance serves as an unreliable proxy for utility: a record may be semantically similar to a query yet fail to improve generation quality or even degrade it due to redundancy or conflicting information. To bridge this gap, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization. In contrast to a greedy selection of the most relevant records, PURPLE treats profile construction as a set generation process and utilizes a Plackett-Luce ranking model to capture complex inter-record dependencies. By training with dense feedback provided by the likelihood of the reference response, our method aligns retrieval directly with generation quality. Extensive experiments on nine personalization tasks demonstrate that PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines in both effectiveness and efficiency, establishing a principled and scalable solution for optimizing user profiles.

</details>


### [26] [Powerful Training-Free Membership Inference Against Autoregressive Language Models](https://arxiv.org/abs/2601.12104)
*David Ilić,David Stanojević,Kostadin Cvejoski*

Main category: cs.CL

Relevance: 85.0

TL;DR: EZ-MIA是一种新的成员推理攻击方法，通过分析模型在错误位置的记忆表现来检测微调语言模型中的隐私风险，相比现有方法在低误报率下实现3-8倍的检测率提升。


<details>
  <summary>Details</summary>
Motivation: 微调语言模型存在显著的隐私风险，可能记忆并暴露训练数据中的敏感信息。现有的成员推理攻击方法检测率有限，特别是在实际隐私审计所需的低误报率阈值下表现不佳。

Method: 提出EZ-MIA攻击方法，基于关键观察：记忆在错误位置表现最强（模型预测错误但仍对训练样本显示较高概率）。引入错误区域（EZ）分数，测量错误位置相对于预训练参考模型的概率偏移方向不平衡性。该方法仅需每个查询两次前向传播，无需任何模型训练。

Result: 在WikiText和GPT-2上，EZ-MIA在相同条件下比先前最佳方法检测率高3.8倍（1%误报率下真阳性率66.3% vs 17.5%），AUC接近完美（0.98）。在关键的0.1%误报率阈值下，检测率高8倍（14.0% vs 1.8%）。在Llama-2-7B和AG News上，检测率高3倍（46.7% vs 15.8%）。

Conclusion: 微调语言模型的隐私风险比先前理解的要大得多，这对隐私审计和部署决策都有重要影响。EZ-MIA为评估模型隐私风险提供了更有效的工具。

Abstract: Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.

</details>


### [27] [Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models](https://arxiv.org/abs/2601.12247)
*Miao Li,Hanyang Jiang,Sikai Chen,Hengyu Fu,Yuhang Cai,Baihe Huang,Tinghan Ye,Xuanzhou Chen,Pascal Van Hentenryck*

Main category: cs.CL

Relevance: 85.0

TL;DR: PVF是一种无需训练的文本生成范式，通过规划-验证-填充机制，在扩散语言模型中主动构建层次化骨架，优先处理高影响力语义锚点，显著减少函数评估次数


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型提供了不同于自回归模型的新文本生成范式，但现有解码策略往往被动反应，未能充分利用全局双向上下文来指导生成轨迹。需要更主动的规划机制来提高效率

Method: 提出Plan-Verify-Fill（PVF）训练免费范式：1）主动构建层次化骨架，优先处理高影响力语义锚点；2）验证协议实现实用结构停止，避免过度计算；3）通过量化验证来指导规划

Result: 在LLaDA-8B-Instruct和Dream-7B-Instruct上的评估显示，PVF相比基于置信度的并行解码，将函数评估次数（NFE）减少高达65%，在基准数据集上实现更高效而不损失准确性

Conclusion: PVF为扩散语言模型提供了一种有效的规划驱动解码策略，通过主动规划和验证机制显著提升生成效率，为非自回归文本生成开辟了新方向

Abstract: Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, we propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.

</details>


### [28] [Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers](https://arxiv.org/abs/2601.12263)
*Yixuan Du,Chenxiao Yu,Haoyan Xu,Ziyi Wang,Yue Zhao,Xiyang Hu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文提出MGEO攻击框架，通过联合优化图像扰动和文本后缀来操纵VLM产品搜索排名，揭示多模态模型的对抗脆弱性


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在检索和推荐系统中广泛应用，但其在竞争性排名场景下对抗操纵的鲁棒性尚未得到充分研究。本文旨在揭示VLM在商品搜索中的关键漏洞

Method: 提出多模态生成引擎优化（MGEO）框架，采用交替梯度优化策略，联合优化不可察觉的图像扰动和流畅的文本后缀，利用VLM内部的深度跨模态耦合

Result: 在真实数据集和SOTA模型上的实验表明，协调攻击显著优于仅文本或仅图像的基线方法，多模态协同性可能被武器化

Conclusion: 多模态模型的优势可能被恶意利用来破坏搜索排名的完整性，而不触发传统内容过滤器，揭示了VLM在对抗攻击下的安全风险

Abstract: Vision-Language Models (VLMs) are rapidly replacing unimodal encoders in modern retrieval and recommendation systems. While their capabilities are well-documented, their robustness against adversarial manipulation in competitive ranking scenarios remains largely unexplored. In this paper, we uncover a critical vulnerability in VLM-based product search: multimodal ranking attacks. We present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that our coordinated attack significantly outperforms text-only and image-only baselines. These findings reveal that multimodal synergy, typically a strength of VLMs, can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.

</details>


### [29] [Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models](https://arxiv.org/abs/2601.12269)
*Xucong Hu,Jian-Qiao Zhu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出使用退火功率采样方法从基础语言模型中恢复心智理论能力，无需额外训练或权重更新


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型通常被批评只优化表面合理性而非保持正确的潜在状态表示，因此被认为在心智理论任务上表现不佳。作者希望证明基础模型本身就具备心智理论能力，只是需要通过合适的采样方法来提取

Method: 基于Karan & Du (2025)的功率采样方法，使用马尔可夫链蒙特卡洛从序列级概率分布中采样，并引入退火技术，将温度分布从高到低逐渐调整

Result: 退火功率采样显著提升了心智理论任务的性能，表明采样优化方法能够有效提取语言模型的潜在能力

Conclusion: 基于采样的优化方法为从语言模型中提取潜在能力提供了强大途径，无需重新训练模型

Abstract: Autoregressive language models are next-token predictors and have been criticized for only optimizing surface plausibility (i.e., local coherence) rather than maintaining correct latent-state representations (i.e., global coherence). Because Theory of Mind (ToM) tasks crucially depend on reasoning about latent mental states of oneself and others, such models are therefore often thought to fail at ToM. While post-training methods can improve ToM performance, we show that strong ToM capability can be recovered directly from the base model without any additional weight updates or verifications. Our approach builds on recent power-sampling methods (Karan & Du, 2025) that use Markov chain Monte Carlo (MCMC) to sample from sharpened sequence-level (rather than token-level) probability distributions of autoregressive language models. We further find that incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. Together, these results suggest that sampling-based optimization provides a powerful way to extract latent capabilities from language models without retraining.

</details>


### [30] [Conversational Context Classification: A Representation Engineering Approach](https://arxiv.org/abs/2601.12286)
*Jonathan Pan*

Main category: cs.CL

Relevance: 85.0

TL;DR: 使用表征工程和单类支持向量机在LLM内部状态中识别特定上下文子空间，用于检测对话是否偏离上下文


<details>
  <summary>Details</summary>
Motivation: 随着LLM的普及，需要有效保障其操作，特别是检测其生成偏离上下文回复的倾向（如话题转移、事实错误、幻觉）。传统异常检测方法难以直接应用于上下文语义中。

Method: 结合表征工程和单类支持向量机，在LLM内部状态中识别与特定上下文相关的子空间。通过在上下文示例上训练OCSVM，在LLM隐藏状态潜在空间中建立鲁棒边界，并识别与感兴趣上下文强相关的LLM内部状态最优层。

Result: 在Llama和Qwen模型上的评估结果显示，该方法在识别特定上下文子空间方面表现出良好效果，能够有效检测对话是否在上下文内或偏离上下文。

Conclusion: 该方法不仅可用于检测对话的上下文一致性，还为更好地解释LLM提供了研究贡献，展示了在LLM内部状态中识别上下文特定表征的可行性。

Abstract: The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.

</details>


### [31] [A Scalable Entity-Based Framework for Auditing Bias in LLMs](https://arxiv.org/abs/2601.12374)
*Akram Elbouanani,Aboubacar Tuo,Adrian Popescu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出使用命名实体作为探针的可扩展偏见审计框架，通过合成数据重现自然文本中的偏见模式，进行了迄今最大规模的偏见审计（19亿数据点），发现LLMs存在系统性偏见：惩罚右翼政客、偏爱左翼政客、偏好西方和富裕国家、偏爱西方公司、惩罚国防和制药公司。


<details>
  <summary>Details</summary>
Motivation: 现有LLM偏见评估方法存在生态效度与统计控制之间的权衡：人工提示不能反映真实使用情况，自然任务缺乏规模和严谨性。需要一种既具生态效度又可扩展的偏见审计方法。

Method: 提出使用命名实体作为探针的可扩展偏见审计框架，通过合成数据可靠地重现自然文本中的偏见模式，支持大规模分析。涵盖多种实体类型、任务、语言、模型和提示策略。

Result: 进行了迄今最大规模的偏见审计（19亿数据点），发现系统性偏见：模型惩罚右翼政客、偏爱左翼政客、偏好西方和富裕国家而非全球南方、偏爱西方公司、惩罚国防和制药公司。指令微调减少偏见，但模型规模增大会放大偏见，使用中文或俄文提示不会减弱西方偏好。

Conclusion: LLMs在高风险应用部署前应进行严格审计，因为存在系统性偏见且规模越大偏见越明显，语言提示调整不能有效缓解西方偏好。

Abstract: Existing approaches to bias evaluation in large language models (LLMs) trade ecological validity for statistical control, relying on artificial prompts that poorly reflect real-world use, or on naturalistic tasks that lack scale and rigor. We introduce a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. We show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. Using this approach, we conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. Our results reveal systematic biases: models penalize right-wing politicians, favor left-wing politicians, prefer Western and wealthy nations over the Global South, favor Western companies, and penalize firms in the defense and pharmaceutical sectors. While instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These results indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.

</details>


### [32] [System-Mediated Attention Imbalances Make Vision-Language Models Say Yes](https://arxiv.org/abs/2601.12430)
*Tsan Tsai Chan,Varsha Suresh,Anisha Saha,Michael Hahn,Vera Demberg*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究发现视觉语言模型幻觉与系统模态注意力分配失衡有关，提出通过因果重分配系统注意力到图像和文本输入来抑制"yes-bias"幻觉，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLM幻觉缓解策略通常偏向图像中心视角，过度强调增加图像注意力而忽视其他模态作用。本研究提出更全面的系统介导解释，认为系统权重冗余导致图像和文本注意力减少，从而引发幻觉。

Method: 采用系统介导框架分析注意力分配失衡，通过因果干预方法重新分配系统模态注意力到图像和文本输入，评估对"yes-bias"幻觉的抑制效果。

Result: 因果重分配系统注意力到图像和文本输入能显著抑制"yes-bias"幻觉，性能常优于现有方法。发现系统注意力失衡导致模型过度依赖粗糙输入表示，这在某些任务有效但不适用于其他任务。

Conclusion: 系统注意力是VLM幻觉的关键因素，可作为缓解幻觉的有效杠杆。研究为理解多模态模型注意力机制提供了新视角。

Abstract: Vision-language model (VLM) hallucination is commonly linked to imbalanced allocation of attention across input modalities: system, image and text. However, existing mitigation strategies tend towards an image-centric interpretation of these imbalances, often prioritising increased image attention while giving less consideration to the roles of the other modalities. In this study, we evaluate a more holistic, system-mediated account, which attributes these imbalances to functionally redundant system weights that reduce attention to image and textual inputs. We show that this framework offers a useful empirical perspective on the yes-bias, a common form of hallucination in which VLMs indiscriminately respond 'yes'. Causally redistributing attention from the system modality to image and textual inputs substantially suppresses this bias, often outperforming existing approaches. We further present evidence suggesting that system-mediated attention imbalances contribute to the yes-bias by encouraging a default reliance on coarse input representations, which are effective for some tasks but ill-suited to others. Taken together, these findings firmly establish system attention as a key factor in VLM hallucination and highlight its potential as a lever for mitigation.

</details>


### [33] [Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping](https://arxiv.org/abs/2601.12465)
*Miao Peng,Weizhou Shen,Nuo Chen,Chenliang Li,Ming Yan,Jia Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出DeepReasonQA和LongPAS方法解决长上下文推理中RLVR性能下降问题，通过知识图谱生成高难度多跳QA对，并通过细粒度信用分配利用"几乎正确"轨迹的学习信号


<details>
  <summary>Details</summary>
Motivation: RLVR在短上下文推理中有效，但在长上下文场景中性能下降，存在"几乎正确"现象（轨迹大部分正确但在最后一步失败）。这源于两个因素：1）长上下文QA数据缺乏高推理密度，无法推动LLM超越简单定位进行复杂多跳推理；2）长上下文RL训练中，对部分正确但结果错误的轨迹进行无差别惩罚导致有价值学习信号丢失。

Method: 1. DeepReasonQA：基于知识图谱的合成框架，可控地构建具有固有推理链的高难度多跳长上下文QA对。2. Long-context Process Advantage Shaping (LongPAS)：通过评估推理步骤的有效性和相关性维度进行细粒度信用分配，从"几乎正确"轨迹中捕捉关键学习信号。

Result: 在三个长上下文推理基准测试中，该方法显著优于RLVR基线，与前沿LLM性能相当但使用更少参数。进一步分析证实了方法在增强长上下文推理能力的同时保持RL训练稳定性的有效性。

Conclusion: 通过合成高质量长上下文推理数据和细粒度信用分配方法，成功解决了RLVR在长上下文推理中的性能瓶颈，为LLM的长上下文推理能力提升提供了有效方案。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the "almost-there" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this failure to two factors: (1) the lack of high reasoning density in long-context QA data that push LLMs beyond mere grounding toward sophisticated multi-hop reasoning; and (2) the loss of valuable learning signals during long-context RL training due to the indiscriminate penalization of partially correct trajectories with incorrect outcomes. To overcome this bottleneck, we propose DeepReasonQA, a KG-driven synthesis framework that controllably constructs high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. Building on this, we introduce Long-context Process Advantage Shaping (LongPAS), a simple yet effective method that performs fine-grained credit assignment by evaluating reasoning steps along Validity and Relevance dimensions, which captures critical learning signals from "almost-there" trajectories. Experiments on three long-context reasoning benchmarks show that our approach substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. Further analysis confirms the effectiveness of our methods in strengthening long-context reasoning while maintaining stable RL training.

</details>


### [34] [Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty](https://arxiv.org/abs/2601.12471)
*Sravanthi Machcha,Sushrita Yerra,Sahil Gupta,Aishwarya Sahoo,Sharmin Sultana,Hong Yu,Zonghai Yao*

Main category: cs.CL

Relevance: 85.0

TL;DR: MedAbstain是一个用于评估LLM在医学多选题中弃权能力的基准，发现即使最先进的模型也常常无法在不确定时弃权，而提供明确的弃权选项比输入扰动更能提高安全性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估过于关注准确性，但在现实世界和安全关键应用中，模型在不确定时能够弃权同样重要。医学多选题回答是一个离散选择场景，可以推广到智能体行动选择，需要系统评估LLM的弃权能力。

Method: 提出了MedAbstain基准和评估协议，整合了符合性预测、对抗性问题扰动和明确的弃权选项。系统评估了开源和闭源LLM，比较了不同弃权机制的效果。

Result: 即使最先进的高准确性模型也经常无法在不确定时弃权。提供明确的弃权选项能持续增加模型不确定性和更安全的弃权行为，效果远优于输入扰动。增加模型规模或使用高级提示技术几乎没有改善。

Conclusion: 弃权机制对于可信LLM部署至关重要，特别是在高风险应用中。研究结果为提高安全关键应用的安全性提供了实用指导。

Abstract: Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.

</details>


### [35] [Benchmarking Concept-Spilling Across Languages in LLMs](https://arxiv.org/abs/2601.12549)
*Ilia Badanin,Daniil Dzenhaliou,Imanol Schlag*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出一个评估多语言大语言模型语义鲁棒性的比较框架，通过测量模型处理多义词的能力来量化语言溢出现象，发现不同模型和语言间存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型虽然展现出跨语言能力，但存在系统性偏向其他语言表示的问题，导致在非英语语言生成内容时出现语义干扰（语言溢出现象）。需要系统评估模型的多语言语义鲁棒性。

Method: 提出比较框架，通过结构化意义生成任务评估模型处理多义词的能力。使用100个高多义性英语单词构建基准，在9种语言上测试。通过分析模型生成序列中何时转向主导语言含义来相对衡量模型性能。

Result: 评估发现不同模型和语言间存在显著的语义鲁棒性差异。语义更强的模型在生成序列后期才转向主导语言含义，而较弱模型则更早转向。建立了无需错误源因果归因的模型排序系统。

Conclusion: 贡献了一个可扩展的多语言语义评估比较基准和严格的验证流程，为开发更语言平衡的AI系统提供了关键工具。揭示了多语言LLM中的语言溢出现象及其评估方法。

Abstract: Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.

</details>


### [36] [Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models](https://arxiv.org/abs/2601.12555)
*Yihong Liu,Bingyu Xiong,Hinrich Schütze*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究多语言大模型在上下文中介下的知识召回能力，发现上下文会降低事实召回性能，大模型对此更鲁棒


<details>
  <summary>Details</summary>
Motivation: 现有事实召回评估主要测试孤立的事实检索，但在自然语言使用中，事实通常通过上下文间接访问。需要研究LLMs在目标实体嵌入自然上下文而非明确查询时的知识召回能力。

Method: 构建受控提示，保留底层事实但通过上下文句子引入指称中介。使用合成名称和真实名称跨语言比较，以区分上下文效应与名称特定关联。在五种语言中评估多个模型家族。

Result: 上下文中介持续降低事实召回性能，不同关系间存在显著差异。更大模型对上下文中介更鲁棒，相对于直接查询的性能差距更小。真实名称和名称来源的影响混合且无系统性。

Conclusion: 多语言LLMs在孤立事实召回和上下文依赖语言理解之间存在差距，上下文中介会损害事实召回，但大模型表现更好。

Abstract: Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.

</details>


### [37] [Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift](https://arxiv.org/abs/2601.12639)
*Daniel Vennemeyer,Punya Syon Pandey,Phan Anh Duong,Michael Umeokoli,Samuel Ratnam*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究比较了六种微调目标对LLM安全性和能力的影响，发现训练规模较小时各目标安全性相似但能力不同，大规模训练时监督和偏好微调会显著增加对抗脆弱性，而ORPO和KL正则化能有效缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对微调目标如何影响LLM对齐和对抗鲁棒性的系统分析。尽管在良性数据上微调LLM仍可能损害安全性和鲁棒性，但微调目标在这些安全结果中的具体作用尚不明确。

Method: 在控制数据、领域、架构和优化的条件下，系统比较了六种微调目标：监督微调、直接偏好优化、条件微调、接种提示、几率比偏好优化和KL正则化微调。在封闭式推理和开放式生成任务上进行评估。

Result: 微调目标选择会导致安全-能力前沿的系统性、规模依赖性变化。小规模训练时各目标鲁棒性相似但能力不同；大规模训练时目标差异显著：监督和偏好微调使能力提升与对抗脆弱性增加紧密耦合，而ORPO和KL正则化能显著缓解这些问题。

Conclusion: 微调目标在小规模训练时对安全性影响不大，但随着训练规模增加，成为对抗鲁棒性和潜在角色稳定性的主要驱动因素。约束学习信号的目标（特别是ORPO和KL正则化）能有效平衡能力提升与安全性保持。

Abstract: Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, and KL-regularized fine-tuning -- holding data, domain, architecture, and optimization fixed. Across closed-form reasoning and open-ended generation tasks, we find that objective choice induces systematic, scale-dependent shifts along the safety-capability frontier. At small training budgets, robustness is similar across objectives but capability differs. At larger budgets, objectives diverge sharply: supervised and preference-based tuning tightly couple capability gains to increased adversarial vulnerability and persona drift, while objectives that constrain learning signals -- especially ORPO and KL-regularization -- substantially mitigate both. Fine-tuning objectives therefore matter little for safety at small scales but become a primary driver of adversarial robustness and latent persona stability as training scale increases.

</details>


### [38] [UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages](https://arxiv.org/abs/2601.12696)
*Tassallah Abdullahi,Macton Mgonzo,Mardiyyah Oduwole,Paul Okewunmi,Abraham Owodunni,Ritambhara Singh,Carsten Eickhoff*

Main category: cs.CL

Relevance: 85.0

TL;DR: UbuntuGuard：首个非洲政策导向的安全基准，针对低资源非洲语言，通过领域专家编写的对抗性查询构建，揭示现有英语中心基准高估多语言安全性，跨语言迁移覆盖不足


<details>
  <summary>Details</summary>
Motivation: 当前守护模型主要面向西方中心和高资源语言，导致低资源非洲语言面临安全漏洞、跨语言安全失效和文化错位问题。现有安全分类僵化，无法适应多样化的语言和社会文化背景

Method: 从155名领域专家（包括医疗健康领域）编写的对抗性查询中构建UbuntuGuard基准，提取情境特定的安全政策和参考响应，评估13个模型（6个通用LLM和7个守护模型，包括静态、动态和多语言三种变体）

Result: 发现：1）现有英语中心基准高估真实世界多语言安全性；2）跨语言迁移提供部分但不充分的覆盖；3）动态模型虽能在推理时利用政策，但仍难以完全本地化非洲语言情境

Conclusion: 迫切需要多语言、文化扎根的安全基准，以开发可靠、公平的低资源语言守护模型。UbuntuGuard为非洲语言安全评估提供了首个政策导向的基准

Abstract: Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.

</details>


### [39] [A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization](https://arxiv.org/abs/2601.12698)
*Qiuyi Qu,Yicheng Sui,Yufei Sun,Rui Chen,Xiaofei Zhang,Yuzhi Zhang,Haofeng Wang,Ge Lan,Ning Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出基于模板的GPU内核优化方法，通过LLM智能体将内核重构为可参数化模板，再结合搜索自动调优，实现稳定性能提升，相比直接代码重写减少随机性。


<details>
  <summary>Details</summary>
Motivation: GPU代码优化是HPC和大模型训练推理的关键瓶颈。现有编译器优化和手工内核难以达到硬件极限性能，而基于LLM智能体的方法多关注直接代码重写，参数选择隐式且难以控制，导致性能提升不稳定。

Method: 在智能体驱动的迭代循环上增加模板重写层：1) 将内核语义重构为显式可参数化模板；2) 通过基于搜索的自动调优优化模板参数；3) 从SGLang提取代表性CUDA内核作为评估目标；4) 智能体调优器迭代执行模板化、测试、分析和规划；5) 利用性能分析反馈在硬件资源限制下执行约束参数搜索。

Result: 在真实世界内核实验中，最佳情况下实现超过3倍的加速。相比仅智能体直接重写，模板加搜索设计显著减少迭代优化的随机性，使过程更可解释，并能更系统性地达到高性能配置。

Conclusion: 模板加搜索方法为GPU内核优化提供了更稳定、可解释的自动化方案，可扩展到OpenCL、HIP等后端，为实际生产工作负载提供自动化性能优化。

Abstract: GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.

</details>


### [40] [A Shared Geometry of Difficulty in Multilingual Language Models](https://arxiv.org/abs/2601.12731)
*Stefano Civelli,Pietro Bernardelle,Nicolò Brunello,Gianluca Demartini*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究探索了大型语言模型中问题难度的多语言几何结构，发现难度相关信号出现在两个不同阶段：浅层表示（早期层）具有语言无关性且跨语言泛化能力强，深层表示（后期层）具有语言特异性但跨语言泛化能力差。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解LLMs中问题难度预测的多语言几何结构，探索模型内部表示如何编码任务难度信息，以及这些表示在不同语言间的泛化特性。

Method: 使用Easy2Hard基准的AMC子集，翻译成21种语言，在LLMs内部表示上训练线性探针。分析浅层（早期层）和深层（后期层）表示的功能差异，评估探针的跨语言泛化能力。

Result: 发现难度相关信号出现在两个阶段：深层表示探针在相同语言上准确率高但跨语言泛化差；浅层表示探针在相同语言上准确率较低但跨语言泛化显著更好。这表明LLMs先形成语言无关的难度表示，然后转化为语言特异性表示。

Conclusion: LLMs采用两阶段表示过程处理问题难度：首先在抽象概念空间形成语言无关表示，然后转化为语言特异性输出。这种模式不仅适用于语义内容，也适用于问题难度估计等高层次元认知属性。

Abstract: Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.

</details>


### [41] [Towards Robust Process Reward Modeling via Noise-aware Learning](https://arxiv.org/abs/2601.12748)
*Bin Xie,Bingbing Xu,Xueyun Tian,Yilin Chen,Huawei Shen*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出两阶段框架解决过程奖励模型中的噪声监督问题：标签阶段使用LLM检测反思行为修正标签，训练阶段采用噪声感知迭代训练框架逐步精炼噪声标签。


<details>
  <summary>Details</summary>
Motivation: 过程奖励模型在复杂推理中表现良好，但受限于昂贵的逐级监督。蒙特卡洛估计作为替代方法会产生策略依赖的噪声奖励，包括错误奖励正确步骤和错误惩罚正确步骤的标签噪声问题。

Method: 两阶段框架：1) 标签阶段：引入反思感知标签修正机制，使用LLM作为裁判检测与当前推理步骤相关的反思和自我修正行为，抑制过高估计的奖励；2) 训练阶段：提出噪声感知迭代训练框架，使PRM能够基于自身置信度逐步精炼噪声标签。

Result: 实验表明该方法显著提高了步骤级正确性判别能力，相比使用噪声监督训练的PRM，在平均F1分数上实现了高达27%的绝对增益。

Conclusion: 提出的两阶段框架有效解决了过程奖励模型中的噪声监督问题，通过反思感知标签修正和噪声感知迭代训练，显著提升了模型对推理步骤正确性的判别能力。

Abstract: Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \underline{\textbf{N}}oise-\underline{\textbf{A}}ware \underline{\textbf{I}}terative \underline{\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\% absolute gain in average F1 over PRMs trained with noisy supervision.

</details>


### [42] [VISPA: Pluralistic Alignment via Automatic Value Selection and Activation](https://arxiv.org/abs/2601.12758)
*Shenyan Zheng,Jiayou Zhong,Anudeex Shetty,Heng Ji,Preslav Nakov,Usman Naseem*

Main category: cs.CL

Relevance: 85.0

TL;DR: VISPA是一个无需训练的多视角对齐框架，通过动态选择和内部激活引导实现直接的价值表达控制，使LLM输出反映多样人类视角而非平均偏好。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在关键领域应用增多，需要其输出反映多样人类视角而非平均偏好，但现有方法要么考虑有限价值，要么依赖提示级干预，缺乏价值控制和代表性。

Method: 提出VISPA训练免费多视角对齐框架，通过动态选择和内部模型激活引导实现直接价值表达控制，无需额外训练。

Result: 在多个模型和评估设置（特别是医疗领域）的广泛实证研究中，VISPA在所有多视角对齐模式中都表现优异，且能适应不同引导初始化、模型和价值。

Conclusion: 多视角对齐可通过内部激活机制实现，为构建服务所有人的语言模型提供了可扩展路径。

Abstract: As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.

</details>


### [43] [Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory](https://arxiv.org/abs/2601.12771)
*Keito Inoshita*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出LAMA框架，利用LLM的世界知识作为联想记忆，通过回忆同名名人并聚合其国籍来预测国籍，而非直接推理，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: LLMs拥有丰富世界知识，但有效提取这些知识的方法尚未充分探索。国籍和地区预测任务需要理解语言特征以及文化和历史背景，LLM的世界知识特别有价值。传统LLM提示方法依赖直接推理，在应用抽象语言规则方面存在局限性。

Method: 提出LLM联想记忆代理(LAMA)框架，利用LLM世界知识作为联想记忆。不直接从名字推断国籍，而是回忆同名的著名人物并通过间接推理聚合其国籍。采用双代理架构：人物代理和媒体代理，分别专注于不同知识领域，并行回忆著名人物，通过投票生成Top-1预测，通过条件补全生成Top-K预测。

Result: 在99个国家国籍预测任务上，LAMA达到0.817准确率，显著优于传统LLM提示方法和神经网络模型。实验表明：LLMs在回忆具体示例方面比抽象推理更可靠；基于回忆的方法对低频国籍具有鲁棒性，不受数据频率分布影响；双代理架构互补产生协同效应。

Conclusion: 证明了通过检索和聚合LLM知识而非提示推理的新型多代理系统的有效性。LLMs在回忆具体事实方面比抽象推理更可靠，联想记忆方法为有效提取LLM知识提供了新途径。

Abstract: Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.

</details>


### [44] [Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?](https://arxiv.org/abs/2601.12812)
*Sushant Kumar Ray,Gautam Siddharth Kashyap,Sahil Tripathi,Nipun Joshi,Vijay Govindarajan,Rafiq Ali,Jiechao Gao,Usman Naseem*

Main category: cs.CL

Relevance: 85.0

TL;DR: MEDASSESS-X是一个面向临床问答部署的框架，通过在推理时对齐而非监督微调，使用轻量级引导向量指导模型激活，解决"专业化谬误"——即认为专业医学LLM在临床问答中必然更优的错误假设。


<details>
  <summary>Details</summary>
Motivation: 当前临床问答系统过度依赖领域特定微调，存在专业化医学LLM覆盖范围窄、重新训练成本高、适应性有限等实际问题。作者认为存在"专业化谬误"——即认为专业医学LLM在临床问答中必然优于通用LLM的错误假设。

Method: 提出MEDASSESS-X框架，采用推理时对齐而非监督微调。使用轻量级引导向量在推理时指导模型激活，使其朝向医学一致推理，无需更新模型权重或进行领域特定重新训练。

Result: 实验表明MEDASSESS-X在所有LLM家族中都带来一致提升：准确率提升高达+6%，事实一致性提升+7%，安全错误率降低达50%。该框架稳定了通用和专业医学LLM的临床问答性能。

Conclusion: MEDASSESS-X通过推理时对齐有效解决了专业化谬误，证明无需领域特定微调即可实现高质量临床问答，为医学LLM部署提供了更灵活、高效的解决方案。

Abstract: Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.

</details>


### [45] [Race, Ethnicity and Their Implication on Bias in Large Language Models](https://arxiv.org/abs/2601.12868)
*Shiyue Hu,Ruizhe Li,Yanjun Gao*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文对LLM中种族和族裔信息的内部表征机制进行研究，通过可复现的解释性方法分析模型如何处理人口统计信息，发现偏见存在于神经元层面但干预效果有限。


<details>
  <summary>Details</summary>
Motivation: LLMs在医疗等高风险领域应用日益广泛，人口统计属性（种族、族裔）可能从文本中显式或隐式推断。现有研究主要记录结果层面的差异，缺乏对这些效应的内部机制理解。

Method: 使用两个公开数据集（毒性生成和临床叙事理解任务），分析三个开源模型。采用可复现的解释性流程，结合探测、神经元级归因和定向干预方法。

Result: 人口统计信息分布在内部单元中，存在显著的跨模型差异。一些单元编码了预训练中的敏感或刻板印象关联，相同的人口统计线索可能引发不同行为。抑制这些神经元的干预能减少偏见但仍有残余效应。

Conclusion: 偏见更多是行为层面的而非表征层面的变化，需要更系统的缓解方法。研究为理解LLM中人口统计偏见的内部机制提供了新见解。

Abstract: Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.

</details>


### [46] [From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.12904)
*Jiahao Wang,Weiyu Xie,Mingxing Zhang,Boxing Zhang,Jianwei Dong,Yuening Zhu,Chen Lin,Jinqi Tang,Yaochen Han,Zhiyuan Ai,Xianglin Chen,Yongwei Wu,Congfeng Jiang*

Main category: cs.CL

Relevance: 85.0

TL;DR: FusionRAG：一种新颖的RAG推理框架，通过在预处理阶段嵌入跨块上下文信息，并在重处理阶段选择性重计算关键token的KV缓存，实现了生成质量与效率的更好权衡。


<details>
  <summary>Details</summary>
Motivation: RAG通过集成外部知识减少LLM幻觉，但增加了提示长度，导致计算成本增加和TTFT延长。现有重用KV缓存的方案因缺乏跨块上下文信息而导致生成质量显著下降，未能充分发挥KV缓存重用的潜力。

Method: 提出FusionRAG框架，包含两个阶段：1）离线预处理阶段：将其他相关文本块的信息嵌入到每个块中；2）在线重处理阶段：对模型关注的token重新计算KV缓存。通过选择性重计算关键token，在保持生成质量的同时减少计算量。

Result: 实验表明，FusionRAG在相同重计算比例下显著提升生成质量。重计算少于15%的token时，相比基线获得高达70%的归一化F1分数提升，相比Full Attention减少TTFT 2.66-9.39倍。

Conclusion: FusionRAG通过创新的预处理和选择性重处理策略，有效解决了RAG中KV缓存重用与生成质量之间的权衡问题，为高效RAG推理提供了实用解决方案。

Abstract: Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.

</details>


### [47] [Gated Differentiable Working Memory for Long-Context Language Modeling](https://arxiv.org/abs/2601.12906)
*Lingrui Mei,Shenghua Liu,Yiwei Wang,Yuyao Ge,Baolong Bi,Jiayu Yao,Jun Wan,Ziling Yin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

Relevance: 85.0

TL;DR: Gdwm提出了一种基于预算约束记忆整合的测试时适应框架，通过写入控制器根据上下文效用分配梯度步数，在减少4倍梯度步数的情况下达到或超越均匀基线性能。


<details>
  <summary>Details</summary>
Motivation: 长上下文给Transformer带来挑战：注意力分数在数千个token中被稀释，关键信息在中间丢失，模型难以适应推理时的新模式。现有测试时适应方法采用均匀写入策略，浪费计算资源在低效用区域，且在语义异质上下文中梯度方差高。

Method: 将测试时适应重构为预算约束的记忆整合问题，提出Gdwm框架，引入写入控制器来门控整合过程。控制器估计上下文效用（衡量长距离上下文依赖的信息理论指标），相应分配梯度步数同时保持全局覆盖。

Result: 在ZeroSCROLLS和LongBench v2上的实验表明，Gdwm仅用均匀基线1/4的梯度步数就达到相当或更优的性能，为测试时适应建立了新的效率-性能帕累托前沿。

Conclusion: 通过将测试时适应视为预算约束的记忆整合问题，Gdwm框架能够智能分配计算资源，在保持性能的同时显著提高效率，为长上下文处理提供了更有效的解决方案。

Abstract: Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.

</details>


### [48] [A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits](https://arxiv.org/abs/2601.12945)
*Miao Xie,Siguang Chen,Chunli Lv*

Main category: cs.CL

Relevance: 85.0

TL;DR: 首篇系统综述LLM与多臂老虎机双向交互的论文，分析两者在组件层面的相互增强机制，涵盖从预训练到RAG等应用场景。


<details>
  <summary>Details</summary>
Motivation: LLM已成为强大的语言理解和生成系统，而多臂老虎机算法为不确定性下的自适应决策提供了理论框架。目前缺乏对这两个领域交叉点的系统性综述，本文旨在填补这一空白，探索两者在组件层面的双向交互潜力。

Method: 采用系统性综述方法，从组件层面分析LLM与多臂老虎机的双向交互。具体包括：1) 分析MAB算法如何解决LLM的关键挑战；2) 探讨LLM如何增强MAB系统的核心组件；3) 对现有LLM增强的MAB系统和MAB增强的LLM系统进行分类分析。

Result: 识别了双向交互的关键机制：MAB算法可解决LLM在预训练、检索增强生成(RAG)和个性化等方面的挑战；LLM可重新定义MAB系统的臂定义和环境建模等核心组件，提升序列决策能力。建立了相关文献索引库。

Conclusion: LLM与多臂老虎机的交叉研究具有重要价值，双向交互为两个领域都带来了显著提升。未来研究应关注组件层面的深度融合，特别是在LLM训练、推理和可信AI等方向的应用潜力。

Abstract: Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.

</details>


### [49] [Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios](https://arxiv.org/abs/2601.12974)
*Hongyang Ma,Tiantian Gu,Huaiyuan Sun,Huilin Zhu,Yongxin Wang,Jie Li,Wubin Sun,Zeliang Lian,Yinghong Zhou,Yi Gao,Shirui Wang,Zhihui Tang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了SCMPE基准，用于评估LLMs在牙科临床场景中从静态知识任务到动态工作流模拟的表现，发现模型在动态临床对话中存在显著性能下降，主要瓶颈在于主动信息收集和动态状态跟踪，而非知识保留。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs从被动知识检索器向自主临床代理转变，需要从静态准确性评估转向动态行为可靠性评估。牙科领域的高质量AI建议对患者参与决策至关重要，因此需要全面评估LLMs在临床环境中的表现。

Method: 提出了标准化临床管理与性能评估（SCMPE）基准，该基准包含两个维度：1）知识导向评估（静态客观任务）；2）基于工作流的模拟（多轮模拟患者交互）。同时研究了检索增强生成（RAG）在静态任务和动态工作流中的影响。

Result: 1）模型在静态客观任务中表现出高熟练度，但在动态临床对话中性能显著下降；2）主要瓶颈在于主动信息收集和动态状态跟踪，而非知识保留；3）"指南遵循"与"决策质量"映射显示通用模型存在"高效低安全"风险；4）RAG在静态任务中减少幻觉，但在动态工作流中效果有限且异质，有时甚至导致性能下降。

Conclusion: 外部知识本身无法弥补推理差距，需要领域自适应预训练。该研究实证绘制了牙科LLMs的能力边界，为弥合标准化知识与安全自主临床实践之间的差距提供了路线图。

Abstract: The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping "Guideline Adherence" versus "Decision Quality" reveals a prevalent "High Efficacy, Low Safety" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.

</details>


### [50] [The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check](https://arxiv.org/abs/2601.12979)
*Qingyu Lu,Liang Ding,Kanjian Zhang,Jinxia Zhang,Dacheng Tao*

Main category: cs.CL

Relevance: 85.0

TL;DR: 扩散大语言模型(dLLMs)在代理任务中表现不佳：在具身代理中无法处理时序反馈，在工具调用中难以保持符号精度，但可在非因果角色中发挥作用。


<details>
  <summary>Details</summary>
Motivation: 研究扩散大语言模型(dLLMs)作为自回归模型替代方案在实时代理交互中的实际效果，验证其效率优势是否能转化为有效的代理行为。

Method: 在Agentboard和BFCL基准上全面评估dLLMs（如LLaDA、Dream）在两种代理范式中的表现：具身代理（需要长程规划）和工具调用代理（需要精确格式化）。引入DiffuAgent多代理评估框架，将dLLMs作为即插即用的认知核心集成到代理工作流中。

Result: 当前dLLMs无法作为可靠的代理骨干：1) 在具身设置中，dLLMs反复尝试失败，无法在时序反馈下进行分支决策；2) 在工具调用设置中，dLLMs在扩散噪声下无法保持符号精度（如严格的JSON模式）。但dLLMs在非因果角色（如记忆总结和工具选择）中表现有效。

Conclusion: dLLMs在代理任务中需要将因果、精确和逻辑基础的推理机制整合到去噪过程中才能可行。虽然效率优势存在，但当前dLLMs无法直接替代自回归模型作为代理骨干。

Abstract: The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a "bitter lesson": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.

</details>


### [51] [Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2601.12995)
*Runxuan Liu,Xianhao Ou,Xinyan Ma,Jiyuan Wang,Jiafeng Liang,Jiaqi Li,Tao He,Zheng Chu,Rongchuan Mu,Zekun Wang,Baoxin Wang,Dayong Wu,Ming Liu,Shijin Wang,Guoping Hu,Bing Qin*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出图推理范式(GRP)和PASC-GRPO方法，通过结构化图表示解决LLM推理中的语义评估瓶颈、奖励攻击等问题，显著提升数学推理和代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的推理主要生成纯文本，对非结构化数据进行语义评估会造成训练计算瓶颈。现有RLVR方法存在粗粒度监督、奖励攻击、训练成本高和泛化性差等问题。

Method: 提出图推理范式(GRP)，实现结构化和符号化推理，使用带步骤级认知标签的图结构表示。基于GRP设计PASC-GRPO方法，用结构化评估替代语义评估，通过图结构结果奖励实现过程感知验证，并通过分层裁剪优势估计缓解奖励攻击。

Result: 实验表明在数学推理和代码生成任务上取得显著改进。数据、模型和代码将后续发布。

Conclusion: GRP和PASC-GRPO方法有效解决了LLM推理中的关键问题，为结构化推理提供了新范式。

Abstract: Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.

</details>


### [52] [Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses](https://arxiv.org/abs/2601.13024)
*Chongyuan Dai,Yaling Shen,Jinpeng Hu,Zihan Gao,Jia Li,Yishun Jiang,Yaxiong Wang,Liu Liu,Zongyuan Ge*

Main category: cs.CL

Relevance: 85.0

TL;DR: CEDAR是一个多模态基准测试，专注于评估LLM在文化差异情感理解方面的能力，通过捕捉不同文化背景下情感反应的差异来弥补现有文化对齐评估的不足。


<details>
  <summary>Details</summary>
Motivation: 现有LLM文化对齐评估主要关注事实性知识（如地理、习俗），而忽略了文化对情感处理的深刻影响。不同文化背景下的情感解释存在主观差异，现有基准无法捕捉这种文化特异性情感理解。

Method: 提出CEDAR基准构建流程：1）利用LLM生成初步标签识别跨文化情感差异实例；2）通过严格人工评估获得可靠标注；3）包含7种语言、14种细粒度情感类别，共10,962个实例（每种语言400个多模态+1,166个纯文本样本）。

Result: 对17个代表性多语言模型的评估显示：语言一致性与文化对齐之间存在分离现象，表明当前模型在文化基础情感理解方面仍面临重大挑战。

Conclusion: 文化特异性情感理解是LLM文化对齐的重要维度，现有模型在这方面存在不足。CEDAR基准为评估和改进LLM的文化情感对齐能力提供了重要工具。

Abstract: Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \underline{\textsc{E}}licited \underline{\textsc{D}}istinct \underline{\textsc{A}}ffective \underline{\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.

</details>


### [53] [CORE-T: COherent REtrieval of Tables for Text-to-SQL](https://arxiv.org/abs/2601.13111)
*Hassan Soliman,Vivek Gupta,Dan Roth,Iryna Gurevych*

Main category: cs.CL

Relevance: 85.0

TL;DR: CORE-T是一个用于多表文本到SQL任务的训练免费框架，通过LLM生成表目的元数据和预计算表兼容性缓存，在推理时结合密集检索和LLM选择来提升表选择准确性和执行效率。


<details>
  <summary>Details</summary>
Motivation: 现实文本到SQL工作流通常需要连接多个表，但在大规模异构表集合中准确检索相关表成为关键瓶颈。现有方法如密集检索返回过多干扰项，而连接感知方法依赖额外假设或计算开销高。

Method: CORE-T框架包含：1) 使用LLM为表生成目的元数据；2) 预计算轻量级表兼容性缓存；3) 推理时先通过密集检索获取候选表；4) 单次LLM调用选择可连接子集；5) 简单加法调整恢复强兼容表。

Result: 在Bird、Spider和MMQA数据集上，CORE-T将表选择F1提升高达22.7分，同时检索表数量减少42%，多表执行准确率在Bird上提升5.0分，在MMQA上提升6.9分，比LLM密集型基线少用4-5倍token。

Conclusion: CORE-T通过结合密集检索的召回能力和LLM的推理能力，在无需训练的情况下显著提升多表文本到SQL的表选择性能，同时保持高效推理。

Abstract: Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.

</details>


### [54] [Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning](https://arxiv.org/abs/2601.13115)
*Fengran Mo,Yifan Gao,Sha Li,Hansi Zeng,Xin Liu,Zhaoxuan Tan,Xian Li,Jianshu Chen,Dakuo Wang,Meng Jiang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出一个通过强化学习训练的多轮对话智能体，能够交错进行搜索和推理，适应动态变化的用户意图，在四个对话基准测试中超越现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常采用静态的改写-检索-生成流程，分别优化不同步骤，忽略了混合主动性动作的同时优化。虽然深度搜索智能体在联合优化检索和生成方面有效，但主要关注单轮场景，缺乏处理多轮交互的能力。

Method: 引入一个对话智能体，通过强化学习训练，在多轮对话中交错进行搜索和推理，使用针对演化用户目标的定制奖励函数，学习探索性和适应性行为。

Result: 在四个广泛使用的对话基准测试中，该方法超越了多个现有强基线，证明了其有效性。

Conclusion: 提出的多轮对话智能体通过强化学习训练，能够有效处理动态变化的用户意图，在搜索和推理的交错优化方面表现出色。

Abstract: Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.

</details>


### [55] [Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains](https://arxiv.org/abs/2601.13137)
*Yuan Gao,Zhigang Liu,Xinyu Yao,Bo Chen,Xiaobing Zhao*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出对抗对齐框架VC-LLM，通过持续预训练、指令微调和对抗训练增强大语言模型在敏感领域的价值观一致性


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，在敏感领域（种族、社会、政治）的偏见和价值观不一致问题逐渐凸显，需要解决模型在敏感话题上的价值观对齐问题

Method: 提出对抗对齐框架：1）持续预训练增强基础能力；2）指令微调优化响应格式；3）对抗训练使用Attacker生成争议性查询，Actor生成价值观一致响应，Critic过滤确保响应质量

Result: 训练了VC-LLM模型，构建了中英双语评估数据集。实验结果显示VC-LLM在中英文测试中均优于现有主流模型，验证了方法的有效性

Conclusion: 对抗对齐框架能有效提升大语言模型在敏感领域的价值观一致性，VC-LLM在价值观对齐方面表现优异

Abstract: With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.

</details>


### [56] [Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference](https://arxiv.org/abs/2601.13155)
*Zimeng Wu,Donghao Wang,Chaozhe Jin,Jiaxin Chen,Yunhong Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: SPTS：一种无需训练的长上下文LLM推理加速框架，通过部分注意力探测和低秩变换探测选择性跳过token，结合多阶段延迟剪枝策略，实现2.46倍预填充和2.29倍端到端生成加速。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理增强LLM推理能力但带来显著计算开销。现有token导向方法（如剪枝和跳过）存在加速潜力有限、代理信号过时、冗余干扰等问题，导致速度-准确率权衡不理想。

Method: 提出SPTS框架：1) 部分注意力探测(PAP)用于多头注意力，通过部分前向注意力计算选择信息丰富的token；2) 低秩变换探测(LTP)用于前馈网络，构建低秩代理网络预测token变换；3) 多阶段延迟剪枝(MSDP)重新分配跳过预算并在各层逐步剪枝冗余token。

Result: 实验表明方法有效，实现最高2.46倍预填充加速和2.29倍端到端生成加速，同时保持最先进的模型性能。

Conclusion: SPTS解决了长上下文LLM推理的计算效率问题，通过创新的token跳过策略实现了显著加速而不损失性能，为高效LLM推理提供了有效解决方案。

Abstract: Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\times$ and 2.29$\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.

</details>


### [57] [Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages](https://arxiv.org/abs/2601.13178)
*Joseph Gatto,Parker Seegmiller,Timothy Burdick,Philip Resnik,Roshnik Rahat,Sarah DeLozier,Sarah M. Preum*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了首个用于异步门诊消息医疗分诊的大规模公开数据集PMR-Bench，将患者消息分诊建模为成对推理问题，训练LLM判断"哪个消息更紧急"，并开发了两种模型UrgentSFT和UrgentReward。


<details>
  <summary>Details</summary>
Motivation: 医疗分诊是根据医疗需求分配资源和优先处理患者的重要任务。目前缺乏研究异步门诊消息分诊的大规模公开数据集，而电子健康记录中的患者消息分诊是实际医疗场景中的关键需求。

Method: 1) 构建PMR-Bench数据集：包含1569条独特消息和2000+高质量测试对，结合非结构化患者消息和真实EHR数据；2) 开发自动化数据标注策略为LLM提供领域指导；3) 训练两种模型：UrgentReward（使用Bradley-Terry目标）和UrgentSFT（使用下一词预测目标）进行成对紧急度分类。

Result: UrgentSFT在PMR-Bench上表现最佳，UrgentReward在低资源设置中显示出独特优势。UrgentSFT-8B和UrgentReward-8B相比现成的8B模型在收件箱排序指标上分别提升15和16个百分点。

Conclusion: 该研究为医疗分诊任务提供了首个大规模基准数据集和有效的LLM训练方法，展示了专门训练的LLM在医疗紧急度评估任务上的显著优势，为实际医疗场景中的患者消息优先级排序提供了实用解决方案。

Abstract: Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `"which message is more medically urgent" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.
  We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage

</details>


### [58] [OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand](https://arxiv.org/abs/2601.13183)
*Sergio Servantez,Sarah B. Lawsky,Rajiv Jain,Daniel W. Linna,Kristian Hammond*

Main category: cs.CL

Relevance: 85.0

TL;DR: OpenExempt：一个用于法律推理诊断评估的框架和基准，通过专家设计的美国破产法符号表示动态生成自然语言推理任务，包含9,765个样本，揭示了语言模型在长推理路径和混淆语句下的性能断崖


<details>
  <summary>Details</summary>
Motivation: 现有推理基准存在局限性：静态问答对只能提供性能快照，将复杂行为压缩为单一准确率指标。在规则复杂的法律领域，现有基准构建成本高且难以隔离特定失败模式，需要更精细的诊断评估工具

Method: OpenExempt框架使用专家设计的美国破产法条款符号表示，动态生成大量自然语言推理任务及其机器可计算解。用户可以精细控制任务复杂度和范围，单独测试特定推理技能。基于此构建OpenExempt基准，包含9,765个样本和9个评估套件

Result: 在13个不同语言模型上的实验显示：在长推理路径和存在混淆语句的情况下，模型性能出现急剧下降（性能断崖）。基准能够有效诊断模型在复杂法律推理中的具体失败模式

Conclusion: OpenExempt提供了法律推理的诊断评估框架，能够精细探测模型能力，揭示了现有模型在复杂推理场景中的局限性。框架和基准已公开发布，支持改进下一代推理系统的研究

Abstract: Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.

</details>


### [59] [Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation](https://arxiv.org/abs/2601.13228)
*Tianqi Du,Lizhe Fang,Weijie Yang,Chenheng Zhang,Zeming Wei,Yifei Wang,Yisen Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了A3（Any-order Any-subset Autoregressive modeling）框架，将自回归建模扩展为任意token分组和生成顺序的灵活生成范式，结合了自回归模型的深度建模优势和扩散模型的灵活性。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型虽然支持任意顺序生成和双向条件生成，但在建模深度、样本质量和稳定性方面不如自回归模型。需要一种既能保持自回归模型概率严谨性和多层依赖建模优势，又能获得扩散模型灵活性的统一框架。

Method: 将扩散式训练重新表述为结构化多组预测过程，提出A3框架扩展标准自回归分解到任意token组和生成顺序。通过双流注意力架构和渐进适应策略，将预训练自回归模型过渡到任意顺序预测。

Result: 在问答、常识推理和故事填充任务上的实验表明，A3在保持灵活解码的同时，性能优于基于扩散的模型。

Conclusion: A3为灵活、高效、新颖的语言建模范式提供了统一方法，结合了自回归模型的深度建模优势和扩散模型的生成灵活性。

Abstract: Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.

</details>


### [60] [Aligning Agentic World Models via Knowledgeable Experience Learning](https://arxiv.org/abs/2601.13247)
*Baochang Ren,Yunzhi Yao,Rui Sun,Shuofei Qiao,Ningyu Zhang,Huajun Chen*

Main category: cs.CL

Relevance: 85.0

TL;DR: WorldMind框架通过构建符号化世界知识库来解决LLMs的物理幻觉问题，利用环境反馈统一过程经验和目标经验，实现物理可行性和任务最优性，具有跨模型和跨环境的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型存在模态脱节问题：拥有丰富的语义知识但缺乏对物理世界不可变法则的程序性基础。这导致模型作为世界模型时会产生物理幻觉——生成逻辑合理但物理上不可执行的计划。现有对齐策略主要依赖资源密集的训练或微调，试图将动态环境规则压缩到静态模型参数中，但这种参数化封装天生僵化，难以适应物理动态的开放可变性。

Method: WorldMind框架通过合成环境反馈自主构建符号化世界知识库。具体来说，它统一了两种经验：1) 过程经验：通过预测错误来强制执行物理可行性；2) 目标经验：通过成功轨迹来指导任务最优性。这种方法避免了将物理规则硬编码到模型参数中，而是动态构建可适应的知识库。

Result: 在EB-ALFRED和EB-Habitat上的实验表明，WorldMind相比基线方法取得了卓越的性能，并展现出显著的跨模型和跨环境可迁移性。

Conclusion: WorldMind通过构建符号化世界知识库而非依赖参数化封装，有效解决了LLMs的物理幻觉问题，为LLMs在物理世界中的可靠应用提供了新途径。

Abstract: Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.

</details>


### [61] [Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models](https://arxiv.org/abs/2601.13260)
*Sawsan Alqahtani,Mir Tafseer Nayeem,Md Tahmid Rahman Laskar,Tasnim Mohiuddin,M Saiful Bari*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文主张将分词(tokenization)重新定义为LLM的核心建模决策而非预处理步骤，提出上下文感知框架，强调分词器与模型协同设计，并呼吁标准化评估和透明报告。


<details>
  <summary>Details</summary>
Motivation: 当前分词方法（如BPE）虽然可扩展，但存在多个问题：与语言结构不对齐、放大偏见、在不同语言和领域中浪费容量。分词作为LLM的基础组件却缺乏理论支撑和一致设计，被视为技术细节而非核心建模决策。

Method: 提出上下文感知框架，将分词器与模型协同设计，考虑语言、领域和部署需求。强调标准化评估指标和透明报告机制，使分词选择可问责、可比较。

Result: 论文提出了理论框架和设计原则，但未报告具体实验结果。主要贡献在于概念重构和设计指南。

Conclusion: 将分词视为核心设计问题而非技术细节，可以开发出更公平、高效、适应性强的语言技术。需要建立标准化评估和透明报告实践。

Abstract: Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.

</details>


### [62] [Unlearning in LLMs: Methods, Evaluation, and Open Challenges](https://arxiv.org/abs/2601.13264)
*Tyler Lizzo,Larry Heck*

Main category: cs.CL

Relevance: 85.0

TL;DR: 这篇综述论文系统梳理了大型语言模型的机器遗忘方法，将现有技术分为数据中心、参数中心、架构中心和混合策略等类别，并评估了遗忘效果、知识保留和鲁棒性的评测体系，最后指出了可扩展效率、形式化保证等开放问题。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，隐私、版权、安全和偏见等问题日益突出。机器遗忘作为一种选择性从训练模型中移除知识或数据的方法，成为解决这些问题的有前景范式。论文旨在为开发可靠、负责任的LLM遗忘技术提供路线图。

Method: 论文采用结构化综述方法，将现有LLM遗忘方法分为五类：1) 数据中心方法（如数据过滤、重新加权）；2) 参数中心方法（如梯度下降、参数编辑）；3) 架构中心方法（如模块化设计）；4) 混合策略；5) 其他方法。同时系统回顾了评测生态系统，包括基准测试、指标和数据集。

Result: 论文系统梳理了LLM机器遗忘的研究现状，建立了统一的方法分类框架和评测体系，识别了当前技术的主要局限和挑战，为未来研究提供了清晰的路线图。

Conclusion: 机器遗忘是解决LLM部署中隐私、版权、安全和偏见问题的关键技术。虽然已有多种方法被提出，但仍面临可扩展效率、形式化保证、跨语言/多模态遗忘、对抗性重新学习等挑战。需要进一步研究来开发可靠、负责任的遗忘技术。

Abstract: Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.

</details>


### [63] [A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification](https://arxiv.org/abs/2601.13288)
*Gonzalo Ariel Meyoyan,Luciano Del Corro*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出一种在LLM推理过程中复用隐藏状态进行轻量级探测的方法，避免使用独立的安全分类模型，减少延迟和内存占用


<details>
  <summary>Details</summary>
Motivation: 当前生产级LLM系统通常使用独立模型进行安全和分类任务，这增加了延迟、显存占用和运维复杂性。作者希望复用LLM推理过程中已经计算好的隐藏状态，避免额外开销

Method: 提出两阶段聚合器：1) 在每层内汇总token信息；2) 跨层聚合形成单一表示用于分类。实现了三种具体实现：直接池化、10万参数评分注意力门、以及最多3500万参数的下采样多头自注意力探测

Result: 在安全和情感基准测试中，该方法优于仅使用logit的方法（如MULI），与更大的任务特定基线模型竞争，同时保持接近推理延迟，避免了独立防护模型管道的显存和延迟成本

Conclusion: 通过复用LLM隐藏状态进行轻量级探测，可以在不增加显著开销的情况下实现有效的分类任务，为生产级LLM系统提供更高效的解决方案

Abstract: Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.

</details>


### [64] [OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference](https://arxiv.org/abs/2601.13300)
*Yow-Fu Liou,Yu-Chien Tang,Yu-Hsiang Liu,An-Zi Yen*

Main category: cs.CL

Relevance: 85.0

TL;DR: OI-Bench是一个评估大语言模型在选择题界面中对抗误导性指令干扰能力的基准测试，包含3000个问题，涵盖知识、推理和常识任务，通过16种指令类型测试模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明LLM决策不仅受界面伪影影响，还会被社会线索、框架和指令等指导性信号所影响。为了系统评估模型对指令干扰的鲁棒性，需要一种结合选择题界面操纵和指令干扰的标准化评估方法。

Method: 提出选项注入方法，在多项选择题界面中添加包含误导性指令的额外选项。构建OI-Bench基准，包含3000个问题，涵盖知识、推理和常识任务，采用16种指令类型（社会遵从、奖励框架、威胁框架、指令干扰）。评估12个LLM的攻击成功率、行为响应，并研究从推理时提示到训练后对齐的缓解策略。

Result: 实验结果显示LLM存在显著漏洞，不同模型的鲁棒性存在异质性。模型对指令干扰表现出不同程度的敏感性，攻击成功率因模型和指令类型而异。

Conclusion: OI-Bench能够支持更系统地评估LLM在基于选择的界面中对指令干扰的鲁棒性，揭示了模型在对抗误导性指令方面的脆弱性，为改进模型鲁棒性提供了评估框架。

Abstract: Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.

</details>


### [65] [LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction](https://arxiv.org/abs/2601.13352)
*Yuxing Lu,J. Ben Tamo,Weichen Zhao,Nan Sun,Yishan Zhong,Wenqi Shi,Jinzhuo Wang,May D. Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: LLM-as-RNN：将冻结LLM转换为循环预测器的推理框架，通过自然语言记忆实现在线学习，无需参数更新


<details>
  <summary>Details</summary>
Motivation: 标准LLM推理使用不可变上下文历史，一旦在生成步骤t出错，模型缺乏可更新的记忆机制来改进步骤t+1的预测。需要一种方法让LLM在推理时能够从错误中学习并改进后续预测。

Method: 提出LLM-as-RNN框架，将冻结LLM转变为循环预测器：1）将隐藏状态表示为自然语言记忆；2）该状态实现为结构化的系统提示摘要；3）通过反馈驱动的文本重写在每个时间步更新状态；4）在固定token预算下实现在线学习。

Result: 在医疗、气象和金融三个序列基准测试中，使用Llama、Gemma和GPT模型族评估。LLM-as-RNN显著优于零样本、完整历史和MemPrompt基线，平均预测准确率提高6.5%，同时产生可解释的人类可读学习轨迹。

Conclusion: LLM-as-RNN成功将LLM转换为具有可更新记忆的循环预测器，通过自然语言状态实现有效的在线学习，无需参数更新，在多个领域显著提升序列预测性能。

Abstract: Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.

</details>


### [66] [Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection](https://arxiv.org/abs/2601.13359)
*Asen Dotsinski,Panagiotis Eustratiadis*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种名为"sockpuppetting"的简单越狱方法，通过在模型输出开头插入接受序列来绕过安全防护，仅需一行代码且无需优化，在多个LLM上比GCG方法攻击成功率更高。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型能力增强，保护它们免受恶意提示攻击并理解可能的攻击向量变得日益重要。现有的自动化越狱方法如GCG需要大量计算资源和专业知识，因此需要更简单有效的攻击方法来揭示模型安全漏洞。

Method: 提出"sockpuppetting"方法：在模型输出开头插入接受序列（如"Sure, here is how to..."），然后让模型完成响应。还探索了混合方法，在助手消息块内优化对抗性后缀而非用户提示。

Result: sockpuppetting在Qwen3-8B上比GCG攻击成功率提高80%（逐提示比较），在Llama-3.1-8B上混合方法比GCG攻击成功率提高64%（提示无关设置）。该方法仅需一行代码，无需优化。

Conclusion: sockpuppetting是一种有效的低成本攻击方法，即使是技术不熟练的攻击者也能使用，突显了开源模型中需要防御输出前缀注入攻击的重要性。

Abstract: As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce "sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., "Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.

</details>


### [67] [Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2601.13368)
*Zhenjiang Mao,Anirudhh Venkat*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出一种新方法，通过引入跨步骤注意力机制分析语义相关性，并结合历史置信度信息，来更准确地评估大语言模型推理过程中的不确定性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理任务（如链式思考）中表现出色，但评估答案不确定性仍具挑战性。现有方法分析长推理序列时，通常过滤无关标记并检查相邻标记或句子间的潜在联系，但忽略了置信度在时间维度上的分布。这可能导致整体置信度被高估，即使早期步骤置信度很低。

Method: 1) 引入跨步骤注意力机制分析语义相关性；2) 针对长序列响应，提出隐藏置信度机制来保留历史置信度信息；3) 将历史置信度与逐步置信度结合，生成更准确的整体置信度估计。

Result: 在GAOKAO数学基准和CLadder因果推理数据集上，使用主流开源大语言模型进行评估。该方法在预测质量和校准之间实现了更好的平衡，在负对数似然和期望校准误差指标上均优于现有最先进方法。

Conclusion: 通过考虑推理过程中置信度的时间分布和跨步骤语义相关性，可以更准确地评估大语言模型的不确定性，有助于减少误导性幻觉，提高模型可靠性。

Abstract: As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.

</details>


### [68] [Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning](https://arxiv.org/abs/2601.13387)
*Zhenjiang Mao,Anirudhh Venkat,Artem Bisliouk,Akshat Kothiyal,Sindhura Kumbakonam Subramanian,Saithej Singhu,Ivan Ruchkin*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出使用信号时序逻辑（STL）分析LLM推理过程中的置信度演化模式，通过STL挖掘发现区分正确与错误响应的时序公式，并开发了基于超网络的置信度估计方法，在多个推理任务上实现了比基线更好的校准效果。


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计方法通常将整个推理过程简化为单一标量分数，忽略了置信度在生成过程中的动态演化。这使得方法对表面因素（如响应长度、冗余度）敏感，难以区分正确推理和自信陈述的错误。

Method: 1. 使用信号时序逻辑（STL）表征逐步置信度信号；2. 通过判别性STL挖掘程序发现区分正确与错误响应置信度信号的时序公式；3. 基于STL模式可跨任务泛化的洞察，开发了使用超网络参数化STL块的置信度估计方法。

Result: 实验表明：1. STL模式在不同任务间具有泛化性；2. 数值参数对具体问题敏感；3. 提出的置信度分数比基线方法更校准。

Conclusion: 通过STL分析LLM推理过程中的置信度演化模式，可以开发出更精细、更校准的置信度估计方法，有助于提高LLM在复杂推理任务中的可信度评估。

Abstract: Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.

</details>


### [69] [Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction](https://arxiv.org/abs/2601.13388)
*Sasha Ronaghi,Prerit Choudhary,David H Rehkopf,Bryant Lin*

Main category: cs.CL

Relevance: 85.0

TL;DR: 使用LLMs从糖尿病患者的非结构化生活故事中提取社会健康决定因素，并评估这些信息对糖尿病控制的预测价值


<details>
  <summary>Details</summary>
Motivation: 社会健康决定因素在2型糖尿病管理中至关重要，但电子健康记录和风险预测模型往往缺乏这些信息。现有的结构化筛查工具无法捕捉患者经历的复杂性，需要更灵活的方法来提取SDOH信息。

Method: 收集65名65岁以上2型糖尿病患者的非结构化访谈，使用检索增强生成的LLMs分析叙事，生成定性的临床摘要和定量的SDOH评分。将结构化SDOH评分与传统实验室生物标志物结合，输入线性和树基机器学习模型进行风险预测。同时评估LLMs直接从访谈文本预测糖尿病控制水平的能力。

Result: LLMs能够将非结构化SDOH相关数据转化为结构化见解，LLMs直接从访谈文本预测糖尿病控制水平的准确率达到60%。这为增强临床风险模型和决策提供了可扩展的方法。

Conclusion: LLMs可以有效地从患者叙事中提取结构化SDOH信息，这些信息对糖尿病控制具有预测价值，为整合非结构化数据到传统风险预测工作流程提供了新途径。

Abstract: Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.

</details>


### [70] [Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks](https://arxiv.org/abs/2601.13392)
*Shlok Shelat,Jay Raval,Souvik Roy,Manas Gaur*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文引入了一个从正则语言构建确定性有限自动机(DFA)的基准测试，发现LLMs在已知问题上表现良好(84-90%)，但在未见问题上准确率骤降30-64%，揭示了LLMs在形式推理能力上的根本缺陷。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究LLMs在形式语言任务上的表现是否真正反映了符号推理能力，还是仅仅是对熟悉结构的模式匹配。通过DFA构建任务来评估LLMs的深层推理能力。

Method: 方法包括：1) 创建包含事实性问题、已知构造问题、手工设计的未见问题(多约束交互)和通过Arden定理系统生成的未见问题的基准测试；2) 评估多种提示策略(直接、思维链、思维树)；3) 设计三阶段提示协议来修正浅层错误。

Result: 结果：LLMs在事实性问题上准确率100%，已知任务上84-90%，但在未见问题上准确率下降30-64%。错误主要源于：对语言约束的系统性误解、Kleene星号语义处理错误、全局一致性保持失败。提示协议能修正浅层错误但无法解决全局不一致或结构缺陷。

Conclusion: 结论：无论采用何种提示策略，错误都会持续存在，暴露了LLMs生成语法上合理的DFA与进行语义正确的形式推理能力之间的根本差距。这表明LLMs在深层符号推理方面存在系统性缺陷。

Abstract: Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.

</details>


### [71] [Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models](https://arxiv.org/abs/2601.13433)
*Priyanka Mary Mammen,Emil Joswin,Shankar Venkitachalam*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现语言模型在推理任务中会受到建议来源可信度的影响，表现出系统性权威偏见：模型对高权威专家的错误建议更加敏感，导致准确率下降且对错误答案更有信心。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明语言模型在推理任务中的表现会受到建议、提示和认可的影响，但认可来源可信度的影响尚未充分探索。本研究旨在探究语言模型是否会基于认可提供者的感知专业知识水平表现出系统性偏见。

Method: 在4个涵盖数学、法律和医学推理的数据集上评估了11个模型，使用代表每个领域四个专业知识水平的人物角色。通过控制实验研究模型对不同权威来源建议的响应模式。

Result: 结果显示，随着来源专业知识的增加，模型对错误/误导性认可的敏感性增强。高权威来源不仅导致准确率下降，还增加了对错误答案的信心。权威偏见在模型中被机制性地编码。

Conclusion: 语言模型存在系统性权威偏见，这种偏见可以通过干预机制来减轻，从而在专家给出误导性认可时也能提高模型性能。这对LLM的可信度和安全性有重要启示。

Abstract: Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.

</details>


### [72] [When Wording Steers the Evaluation: Framing Bias in LLM judges](https://arxiv.org/abs/2601.13537)
*Yerin Hwang,Dongryeol Lee,Taegwan Kang,Minwoo Lee,Kyomin Jung*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现LLM评估存在框架偏差，即提示措辞的微小变化会显著影响模型判断，这在四个高风险评估任务中得到验证，表明这是当前LLM评估系统的结构性缺陷。


<details>
  <summary>Details</summary>
Motivation: LLM评估需要稳定公正的判断，但心理学中的框架效应表明决策会受到表述方式影响。目前尚不清楚这种框架偏差如何影响LLM评估的可靠性和公正性，特别是在高风险任务中。

Method: 采用心理学中的框架效应概念，设计对称提示（谓词肯定和谓词否定结构），在四个高风险评估任务中系统测试14个LLM法官模型，分析不同模型家族对框架的敏感性。

Result: 所有测试的LLM都表现出明显的框架敏感性，提示措辞的微小变化导致显著判断差异。不同模型家族表现出不同的倾向性（同意或拒绝），框架偏差是当前LLM评估系统的结构性特征。

Conclusion: LLM评估存在系统性框架偏差，这威胁到评估的可靠性和公正性。需要开发框架感知的评估协议来缓解这一问题，确保LLM评估的稳定性。

Abstract: Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.

</details>


### [73] [TREX: Tokenizer Regression for Optimal Data Mixture](https://arxiv.org/abs/2601.13588)
*Inho Won,Hangyeol Yoo,Minkyung Cho,Jungyeul Park,Hoyun Song,KyungTae Lim*

Main category: cs.CL

Relevance: 85.0

TL;DR: TREX框架通过回归模型预测多语言LLM分词器训练的最优数据混合比例，避免传统启发式或大规模搜索的高成本，提升分词器压缩效率


<details>
  <summary>Details</summary>
Motivation: 多语言LLM分词器设计需要优化语言数据混合比例，但现有方法依赖启发式规则或成本高昂的大规模搜索，缺乏高效准确的优化方案

Method: 提出TREX框架：1) 在随机数据混合上训练小规模代理分词器；2) 收集压缩统计特征；3) 训练回归模型预测压缩性能；4) 使用学习模型进行可扩展的混合比例搜索

Result: TREX预测的混合比例训练的分词器，在分布内和分布外压缩效率上比LLaMA3和均匀分布方法提升高达12%，展示了良好的可扩展性、鲁棒性和实际效果

Conclusion: TREX为多语言分词器设计提供了高效的数据混合优化框架，解决了准确性与成本之间的权衡问题，对LLM训练和推理效率有重要改进

Abstract: Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.

</details>


### [74] [Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions](https://arxiv.org/abs/2601.13590)
*Fan Huang,Haewoon Kwak,Jisun An*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文系统评估了LLM在SMCR沟通框架下对说服的易感性，发现小模型极易被说服，元认知提示反而增加脆弱性，对抗性微调效果因模型而异


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地用于问答任务，但研究表明它们容易受到说服并采纳反事实信念。需要系统评估LLM在沟通框架下对说服的易感性，以理解其鲁棒性限制

Method: 采用SMCR沟通框架，在5个主流LLM和3个领域（事实知识、医疗QA、社会偏见）上分析不同说服策略对信念稳定性的影响。研究元认知提示的作用，并评估对抗性微调作为防御方法

Result: 小模型表现出极端顺从，80%以上的信念改变发生在第一次说服尝试；元认知提示反而增加脆弱性；对抗性微调效果显著差异：GPT-4o-mini达到98.6%鲁棒性，Mistral 7B从35.7%提升到79.3%，而Llama模型即使微调后仍低于14%

Conclusion: 当前鲁棒性干预措施存在显著的模型依赖性限制，为开发更可信的LLM提供了指导。需要针对不同模型设计更有效的防御策略

Abstract: Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.

</details>


### [75] [CauScientist: Teaching LLMs to Respect Data for Causal Discovery](https://arxiv.org/abs/2601.13614)
*Bo Peng,Sirui Chen,Lei Xu,Chaochao Lu*

Main category: cs.CL

Relevance: 85.0

TL;DR: CauScientist是一个结合LLM生成假设与概率统计验证的因果发现框架，通过混合初始化、迭代优化和错误记忆机制，显著超越纯数据驱动方法


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法存在局限：纯数据驱动方法受统计不可区分性和建模假设限制，而基于LLM的方法要么忽略统计证据，要么引入未经验证的先验知识可能误导结果

Method: 提出CauScientist协作框架：将LLM作为假设生成的"数据科学家"，概率统计作为严格"验证者"。采用混合初始化选择优质起始图，通过LLM提议修改并由统计标准验证进行迭代优化，维护错误记忆指导搜索空间

Result: 实验显示CauScientist显著优于纯数据驱动基线，F1分数提升达53.8%，召回率从35.0%提升至100.0%。在37节点图上，相比Qwen3-32B将结构汉明距离降低44.0%

Conclusion: CauScientist通过LLM与统计方法的协同，有效解决了因果发现中的统计不可区分性问题，为可靠决策提供了更准确的因果结构发现方法

Abstract: Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead result. To this end, we propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating "data scientists" with probabilistic statistics as rigorous "verifiers". CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs. Our project page is at https://github.com/OpenCausaLab/CauScientist.

</details>


### [76] [Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models](https://arxiv.org/abs/2601.13630)
*Zhaopeng Zhang,Pengcheng Sun,Lan Zhang,Chen Tang,Jiewei Lai,Yunhao Wang,Hui Jin*

Main category: cs.CL

Relevance: 85.0

TL;DR: AAAC：无需训练的多类权限控制框架，利用激活空间几何规律，通过权限锚点重定向查询激活，防止LLM超越权限范围回答


<details>
  <summary>Details</summary>
Motivation: LLM在知识库问答中可能无意中超越用户权限范围泄露敏感内容，难以在细粒度访问控制要求下部署

Method: 基于激活空间几何规律（不同权限范围的表示聚类可分离），提出AAAC框架：1）从少量离线样本构建权限锚点库；2）推理时通过多锚点引导机制将查询激活重定向到授权区域

Result: 在三个LLM家族上的实验显示：权限违规率降低高达86.5%，基于提示的攻击成功率降低90.7%，响应可用性提升，推理开销小

Conclusion: AAAC提供了一种无需训练、高效的权限控制方法，利用激活空间几何特性有效防止LLM超越权限回答，提升知识库问答的安全性

Abstract: Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.

</details>


### [77] [Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge](https://arxiv.org/abs/2601.13649)
*Xiaolin Zhou,Zheng Luo,Yicheng Gao,Qixuan Chen,Xiyang Hu,Yue Zhao,Ruishan Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文研究了LLM作为评判者（LLM-as-a-judge）中的语言偏见问题，发现存在跨语言性能差异和主要语言偏好两种偏见，且这些偏见不能完全由困惑度偏差解释。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者在评估文本质量时存在语言偏见，这种偏见与人类偏好不一致。研究旨在系统分析LLM评判中的语言偏见，特别是同语言评判中的性能差异和跨语言评判中的主要语言偏好。

Method: 研究两种语言偏见：(1) 同语言评判中的性能差异（比较同一语言的选项）；(2) 跨语言评判中的偏见（比较不同语言的选项）。分析不同语言家族（欧洲vs非洲语言）和文化相关主题的表现差异，并探讨语言偏见与困惑度偏差的关系。

Result: 发现同语言评判中存在显著的语言家族性能差异，欧洲语言始终优于非洲语言，且在文化相关主题中更明显。跨语言评判中，大多数模型偏好英语答案，且答案语言比问题语言影响更大。语言偏见与困惑度仅有轻微相关性，不能完全由困惑度解释。

Conclusion: LLM作为评判者存在系统性语言偏见，需要开发更公平的评估方法。语言偏见是独立于困惑度偏差的现象，需要专门解决。

Abstract: Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.

</details>


### [78] [CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks](https://arxiv.org/abs/2601.13669)
*Jiayu Lin,Zhongyu Wei*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了社区级对齐作为个体级和通用级对齐之间的中间方案，并创建了首个大规模社区级对齐评估基准CommunityBench，发现当前LLMs在建模社区特定偏好方面能力有限。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐策略存在两个极端：通用价值假设（忽视少数群体）和个体级定制（成本过高）。作者观察到人类社会按社会集群组织，群体内部价值对齐度高，因此提出社区级对齐作为更实用、可扩展的中间方案。

Method: 1. 提出社区级对齐概念；2. 创建CommunityBench基准，基于共同身份和共同纽带理论设计四个任务；3. 在CommunityBench上全面评估多种基础模型；4. 探索社区级对齐如何促进个体建模。

Result: 1. 当前LLMs在建模社区特定偏好方面能力有限；2. 社区级对齐为可扩展和多元对齐提供了有前景的方向；3. CommunityBench成为首个大规模社区级对齐评估基准。

Conclusion: 社区级对齐是解决LLM对齐中通用与个体极端之间的有效中间方案，CommunityBench为评估和改进社区级对齐能力提供了重要工具，为可扩展的多元对齐开辟了新方向。

Abstract: Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a "middle ground". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.

</details>


### [79] [HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference](https://arxiv.org/abs/2601.13684)
*Zhiyuan Shi,Qibo Qiu,Feng Xue,Zhonglin Jiang,Li Yu,Jian Jiang,Xiaofei He,Wenxiao Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: HeteroCache：一种无需训练的动态KV缓存压缩框架，通过细粒度头部分类和分层存储机制，解决长上下文LLM推理中的内存瓶颈问题，在224K上下文下实现3倍解码加速。


<details>
  <summary>Details</summary>
Motivation: KV缓存的线性内存增长是长上下文LLM推理的主要瓶颈。现有静态压缩方法无法保留全局重要信息，因为它们忽略了注意力漂移现象（token重要性动态演变）。动态检索方法虽然尝试解决此问题，但通常存在粗粒度缓存策略和高I/O开销的问题。

Method: 基于两个关键洞察：1）注意力头展现不同的时间异质性；2）同一层内头部间存在显著空间冗余。HeteroCache将头部按稳定性和冗余性分类，采用细粒度权重策略为注意力快速变化的头部分配更大缓存预算，以捕捉上下文变化。同时使用分层存储机制，让代表性头部子集监控注意力变化，并触发异步按需从CPU检索上下文，有效隐藏I/O延迟。

Result: 在多个长上下文基准测试中达到最先进性能，在224K上下文下相比原始模型加速解码达3倍。

Conclusion: HeteroCache通过细粒度头部分类和分层存储机制，有效解决了长上下文LLM推理中的KV缓存内存瓶颈问题，实现了显著的性能提升和解码加速。

Abstract: The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\times$ compared to the original model in the 224K context. Our code will be open-source.

</details>


### [80] [Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning](https://arxiv.org/abs/2601.13690)
*Yue Guo,Fanfu Wang,Jianwei Lv,Xincheng Shi,Yuchen Li,Youya Wang,Yunsheng Zeng,Yujing Liu,Yunhao Qiao,Gen Li,Junfeng Wang,Bo Yuan*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文提出Dr. Assistant临床诊断模型，通过CDRD数据结构捕捉临床推理逻辑，采用两阶段训练（SFT+RL），在诊断推理和问询方面超越开源模型并接近闭源模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统临床决策支持系统维护成本高、泛化能力差，而大型语言模型虽在医疗基准测试中表现优异，但其诊断推理和问询能力受限，需要专门的方法来提升临床诊断推理能力。

Method: 1) 提出CDRD数据结构捕捉抽象临床推理逻辑及其构建流程；2) 开发Dr. Assistant临床诊断模型，采用两阶段训练：监督微调（SFT）后接强化学习（RL）配合定制奖励函数；3) 引入评估诊断推理和问询的基准。

Result: Dr. Assistant在诊断推理和问询方面超越开源模型，达到与闭源模型竞争的性能，为临床诊断问询指导提供有效解决方案。

Conclusion: 通过CDRD数据结构和两阶段训练方法，Dr. Assistant成功提升了LLM在临床诊断中的推理和问询能力，为医疗AI应用提供了有前景的方向。

Abstract: Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.

</details>


### [81] [Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning](https://arxiv.org/abs/2601.13697)
*Zhihang Yuan,Chengyu Yue,Long Huang,Litu Ou,Lei Shi*

Main category: cs.CL

Relevance: 85.0

TL;DR: GRADFILTERING：一种基于不确定性的数据选择框架，通过小代理模型的LoRA集成和梯度信噪比来高效选择指令调优数据，减少计算成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现代指令数据集通常规模大、噪声多且冗余，全数据微调成本高昂且不必要。现有数据选择方法要么构建昂贵的梯度数据存储，要么使用弱代理模型的静态评分，忽略了模型训练过程中的不确定性这一关键解释性来源。

Method: 提出GRADFILTERING框架：使用小型GPT-2代理模型配合LoRA集成，计算每个训练样本的梯度，聚合为梯度信噪比（G-SNR）效用分数，基于不确定性感知进行数据选择。

Result: 在大多数LLM-as-a-judge评估和人工评估中，GRADFILTERING选择的数据子集性能达到或超过随机子集和强基线方法。在相同计算预算下，所选子集收敛速度更快。

Conclusion: GRADFILTERING提供了一种目标无关、不确定性感知的数据选择方法，能够有效识别高质量训练数据，减少指令调优的计算成本，同时保持或提升模型性能。

Abstract: Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.

</details>


### [82] [Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff](https://arxiv.org/abs/2601.13717)
*Zehan Li,Yuxuan Wang,Ali El Lahib,Ying-Jieh Xia,Xinyu Pi*

Main category: cs.CL

Relevance: 85.0

TL;DR: SI方法无法有效模拟真实无知状态，在预测能力评估中存在系统性缺陷，不推荐用于基准测试


<details>
  <summary>Details</summary>
Motivation: 解决LLM预测能力评估中的基本矛盾：前瞻性评估方法严谨但延迟高，而回顾性预测面临数据污染问题。模拟无知(SI)作为潜在解决方案需要验证其有效性。

Method: 通过477个竞赛级问题和9个模型，系统测试模拟无知(SI)是否能近似真实无知(TI)。分析截止指令效果、思维链推理的知识抑制能力，以及推理优化模型的表现差异。

Result: SI方法系统性失败：1) 截止指令导致SI与TI之间存在52%性能差距；2) 思维链推理无法有效抑制先验知识；3) 推理优化模型的SI保真度更差。提示无法可靠"回滚"模型知识。

Conclusion: 基于预截止事件的回顾性预测方法存在根本缺陷，不推荐使用SI方法评估预测能力。需要开发更可靠的评估方法。

Abstract: Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably "rewind" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.

</details>


### [83] [OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents](https://arxiv.org/abs/2601.13722)
*Yulin Hu,Zimo Long,Jiahe Guo,Xingyu Sui,Xing Fu,Weixiang Zhao,Yanyan Zhao,Bing Qin*

Main category: cs.CL

Relevance: 85.0

TL;DR: OP-Bench：首个评估对话代理过度个性化问题的基准，包含1700个验证实例，定义了三种过度个性化类型（无关性、重复性、谄媚性），并提出Self-ReCheck轻量级内存过滤机制来缓解此问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于记忆的对话代理基准主要关注代理能否回忆和应用用户信息，但忽略了这种个性化是否被恰当使用。代理可能过度使用个人信息，产生让用户感到强迫、侵入或社交不适当的回应，即"过度个性化"问题。

Method: 1) 将过度个性化形式化为三种类型：无关性、重复性、谄媚性；2) 构建OP-Bench基准，包含1700个从长时程对话历史构建的验证实例；3) 提出Self-ReCheck，一种轻量级、模型无关的内存过滤机制，通过自检来缓解过度个性化。

Result: 评估多个大语言模型和记忆增强方法，发现引入记忆时过度个性化普遍存在。分析显示代理倾向于检索并过度关注用户记忆，即使在不必要时也是如此。Self-ReCheck能有效缓解过度个性化，同时保持个性化性能。

Conclusion: 这项工作为记忆增强对话系统中更可控和适当的个性化迈出了初步步伐，揭示了过度个性化问题的普遍性，并提供了有效的缓解方案。

Abstract: Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.

</details>


### [84] [Towards robust long-context understanding of large language model via active recap learning](https://arxiv.org/abs/2601.13734)
*Chenyu Hui*

Main category: cs.CL

Relevance: 85.0

TL;DR: ARL（主动回顾学习）是一个增强大语言模型长文本理解能力的框架，通过在持续预训练中构建目标序列和在推理时进行回顾性总结，使模型能够回顾并总结先前内容。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在处理长上下文时存在困难，需要增强模型对长文本的理解能力。现有的方法通常需要复杂的架构修改或大量计算资源，ARL旨在提供一个简单有效的持续预训练方法来解决这个问题。

Method: 1. 在持续预训练阶段：基于长短前向上下文的损失差距识别关键token，找到最相关的前面段落，使用LLM进行总结
2. 在推理阶段：模型能够自主生成并利用这些回顾性总结，建立跨段落的递归记忆机制

Result: 实验结果显示显著提升：在RULER基准上获得26.8%的改进，在LongBench基准上获得9.44%的改进

Conclusion: ARL提供了一个简单而有效的持续预训练方法，能够显著增强LLMs的长上下文理解能力，推进了LLM中可扩展记忆增强的发展

Abstract: In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM

</details>


### [85] [Pro-AI Bias in Large Language Models](https://arxiv.org/abs/2601.13749)
*Benaya Trabelsi,Jonathan Shaki,Sarit Kraus*

Main category: cs.CL

Relevance: 85.0

TL;DR: LLMs存在系统性偏好AI的偏见：在建议中过度推荐AI选项，高估AI相关职位薪资，且"人工智能"在表征中具有中心性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在决策支持中的广泛应用，需要研究这些模型是否存在对AI本身的系统性偏好偏见，这可能影响高风险决策。

Method: 通过三个互补实验：1) 分析LLMs对多样化建议寻求查询的回应，检查是否过度推荐AI选项；2) 比较LLMs对AI相关职位和非AI职位的薪资估计；3) 探究开源模型的内部表征，分析"人工智能"在不同情感框架下的相似性。

Result: 发现一致的pro-AI偏见：1) LLMs不成比例地推荐AI相关选项，专有模型几乎确定性推荐；2) 模型系统性高估AI相关职位薪资，专有模型高估10个百分点；3) "人工智能"在不同情感框架下都表现出最高的相似性，表明表征中心性。

Conclusion: LLMs存在系统性偏好AI的偏见，这可能导致LLM生成的建议和估值在高风险决策中系统性扭曲选择和认知。

Abstract: Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.

</details>


### [86] [Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning](https://arxiv.org/abs/2601.13806)
*Dezhao Song,Guglielmo Bonifazi,Frank Schilder,Jonathan Richard Schwarz*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出基于知识图谱的LLM后训练方法，通过IRAC框架构建法律知识图谱，结合SFT和DPO提升LLM在法律领域的推理能力


<details>
  <summary>Details</summary>
Motivation: 当前LLM后训练主要依赖大量文本语料和人类反馈，缺乏对领域知识结构的捕捉，导致在处理复杂推理任务（特别是高风险专业领域如法律）时表现不佳。法律推理需要深入理解法律概念间的关系，这是当前LLM后训练缺失的关键组成部分。

Method: 1) 采用IRAC（Issue, Rule, Analysis, Conclusion）框架建模关键法律概念；2) 构建包含12K法律案例的知识图谱；3) 使用IRAC KG生成训练数据；4) 对三个SOTA LLM（30B、49B、70B）进行监督微调（SFT）和直接偏好优化（DPO），涵盖不同架构和基础模型家族。

Result: 后训练模型在4/5个多样化法律基准测试（14个任务）上平均表现优于基线。特别是70B DPO模型在4/6个推理任务上获得最佳分数，优于基线和141B SOTA法律LLM，证明了KG在增强LLM法律推理能力方面的有效性。

Conclusion: 知识图谱辅助的方法能有效增强LLM在高风险专业领域（如法律）的推理能力，该方法可推广到其他高风险领域。IRAC框架为法律知识结构化提供了有效途径。

Abstract: LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.

</details>


### [87] [FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs](https://arxiv.org/abs/2601.13836)
*Qian Chen,Jinlan Fu,Changsong Li,See-Kiong Ng,Xipeng Qiu*

Main category: cs.CL

Relevance: 85.0

TL;DR: FutureOmni是首个评估多模态大语言模型从视听环境进行未来预测能力的基准，包含919个视频和1,034个多选题对，涵盖8个主要领域。现有模型在视听未来预测上表现不佳，最佳准确率仅64.8%。作者提出了Omni-Modal Future Forecasting训练策略和7K样本指令调优数据集来提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在全方位模态感知方面表现出色，但从视听线索预测未来事件的能力尚未得到充分探索。现有基准主要关注回顾性理解，缺乏对未来预测能力的评估。为填补这一空白，作者创建了FutureOmni基准来评估模型从视听环境进行未来预测的能力。

Method: 1. 通过可扩展的LLM辅助、人在回路流程构建FutureOmni基准，包含919个视频和1,034个多选题对，涵盖8个主要领域
2. 评估了13个全方位模态模型和7个纯视频模型
3. 为缓解模型局限性，构建了7K样本的指令调优数据集
4. 提出了Omni-Modal Future Forecasting训练策略，增强模型的未来预测和泛化能力

Result: 1. 当前系统在视听未来预测方面表现不佳，特别是在语音密集型场景中
2. Gemini 3 Flash在基准测试中达到最佳准确率64.8%
3. 提出的OFF训练策略在FutureOmni以及流行的视听和纯视频基准测试中显示出增强的未来预测和泛化能力

Conclusion: FutureOmni是首个评估多模态大语言模型未来预测能力的基准，揭示了当前模型在此任务上的局限性。通过提出的OFF训练策略和指令调优数据集，可以显著提升模型的未来预测能力。这项工作为多模态未来预测研究提供了重要基准和训练方法。

Abstract: Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).

</details>


### [88] [OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models](https://arxiv.org/abs/2601.13882)
*Unggi Lee,Sookbun Lee,Heungsoo Choi,Jinseo Lee,Haeun Park,Younghoon Jeon,Sungmin Cho,Minju Kang,Junbo Koh,Jiyeong Bae,Minwoo Nam,Juyeon Eun,Yeonji Jung,Yeil Jeong*

Main category: cs.CL

Relevance: 85.0

TL;DR: OpenLearnLM Benchmark是一个基于教育评估理论的多维度LLM评估框架，涵盖知识、技能和态度三个维度，包含124K+测试项，用于评估LLM在教育场景中的真实能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM教育评估基准过于狭窄，缺乏学习科学基础，无法全面评估LLM在教育场景中的真实能力。需要建立一个理论驱动的综合评估框架来推动LLM在教育领域的应用。

Method: 基于教育评估理论构建三维评估框架：1) 知识维度（课程对齐内容和教学理解）；2) 技能维度（基于四层中心-角色-场景-子场景层次结构的场景化能力）；3) 态度维度（对齐一致性和欺骗抵抗）。包含124K+测试项，涵盖多个学科、教育角色和基于布鲁姆分类法的难度级别。

Result: 评估了7个前沿模型，发现不同模型具有不同的能力特征：Claude-Opus-4.5在实践技能方面表现出色但内容知识较低，Grok-4.1-fast在知识方面领先但存在对齐问题。没有单一模型在所有维度上都占优势。

Conclusion: OpenLearnLM提供了一个开放、全面的框架，用于推进LLM在真实教育场景中的准备度。多维度评估的必要性得到验证，不同模型在不同维度上各有优劣。

Abstract: Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.

</details>


### [89] [Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores](https://arxiv.org/abs/2601.13885)
*Esma Balkır,Alice Pernthaller,Marco Basaldella,José Hernández-Orallo,Nigel Collier*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了一种针对连续分数LLM评估的自适应测试方法，将IRT理论扩展到连续有界分数场景，通过异方差正态分布替代伯努利分布，并引入不确定性感知排序器和自适应停止准则，在仅使用2%测试项的情况下显著提升模型排序效果。


<details>
  <summary>Details</summary>
Motivation: 传统CAT方法主要针对多项选择题的二值化评分，但现代LLM评估越来越多依赖生成任务，其输出采用连续分数（如ROUGE、BLEU、LLM-as-a-Judge）而非正确/错误标记。需要将IRT自适应测试扩展到连续分数场景。

Method: 1) 将IRT理论扩展到连续有界分数：用异方差正态分布替代伯努利响应分布；2) 引入不确定性感知排序器：基于模型能力估计的不确定性进行排序；3) 自适应停止准则：在达到足够置信度时停止测试，实现高效评估。

Result: 在五个基准测试（包括n-gram、embedding和LLM-as-judge指标）上验证，仅使用2%的测试项，相比随机采样将排序相关性提高了0.12 τ，在置信预测上达到95%准确率。

Conclusion: 该方法成功将CAT扩展到连续分数LLM评估，显著提高了评估效率，为大规模LLM评估提供了实用工具，特别适用于需要高效比较多个LLM性能的场景。

Abstract: Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions.

</details>


### [90] ["The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework](https://arxiv.org/abs/2601.13992)
*Jin Cui,Jiaqi Guo,Jiepeng Zhou,Ruixuan Yang,Jiayi Lu,Jiajun Xu,Jiangcheng Song,Boran Zhao,Pengju Ren*

Main category: cs.CL

Relevance: 85.0

TL;DR: COMPACT框架通过动态融合多教师监督，解决CoT蒸馏中单一教师能力偏差和灾难性遗忘问题，提升小模型推理能力


<details>
  <summary>Details</summary>
Motivation: 现有CoT蒸馏方法通常依赖单一教师模型，但单个LLM存在能力偏差和灾难性遗忘问题，限制了学生模型的潜力。虽然使用多样化教师看似有吸引力，但有效融合它们的监督仍然具有挑战性：师生不兼容可能放大幻觉，被动监督无法确保真正的逻辑内化。

Method: 提出COMPACT框架，通过基于学生实时兼容性的动态梯度加权来融合不同教师的监督。兼容性评估采用三维度量：1) 基于图的共识机制过滤误导性推理路径；2) 基于互信息的适应性检测"顿悟时刻"，确保真正理解而非模仿；3) 基于损失的难度评估学生接受教师指导的能力，防止负迁移。

Result: 大量实验和潜在空间分析表明，COMPACT能有效整合多样化推理能力而不损害模型原有知识结构，在各种基准测试中达到最先进性能，同时缓解灾难性遗忘问题。

Conclusion: COMPACT通过动态融合多教师监督，解决了CoT蒸馏中的关键挑战，为将LLM推理能力有效迁移到小型模型提供了新范式，在保持原有知识的同时提升推理性能。

Abstract: Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect "epiphany moments" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.

</details>


### [91] [From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning](https://arxiv.org/abs/2601.13995)
*Zihan Niu,Wenping Hu,Junmin Chen,Xiyue Wang,Tong Xu,Ruiming Tang*

Main category: cs.CL

Relevance: 85.0

TL;DR: TAGS：基于知识树的LLM指令调优数据选择框架，通过细粒度标签构建知识树，实现质量、多样性和目标对齐的联合控制，仅用5%数据即可超越全数据集性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM指令调优的数据选择方法主要依赖实例级质量评分或基于嵌入聚类/语义标签的多样性度量，但受限于嵌入空间的平坦性或标签的粗糙性，忽略了细粒度知识及其内在层次依赖关系，阻碍了精确的数据评估和知识对齐采样。

Method: 提出Tree-aware Aligned Global Sampling (TAGS)框架：1) 使用LLM标注器提取原子知识概念；2) 通过自底向上层次聚类组织成全局知识树；3) 将数据实例映射到树上，通过树感知度量量化数据质量和多样性；4) 可控采样策略最大化树级信息增益，并通过KL散度在叶级实现特定领域对齐。

Result: TAGS显著优于现有基线方法，仅使用5%数据即可超越全数据集模型性能+5.84%，对齐采样策略进一步将平均性能提升+4.24%。

Conclusion: TAGS通过知识树结构实现了细粒度、层次化的数据选择，为LLM指令调优提供了更精确的数据评估和可控采样框架，在数据效率和性能提升方面表现出色。

Abstract: Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \textbf{+5.84\%} using only \textbf{5\%} of the data, while our aligned sampling strategy further boosts average performance by \textbf{+4.24\%}.

</details>


### [92] [Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models](https://arxiv.org/abs/2601.14004)
*Hengyuan Zhang,Zhihao Zhang,Mingyang Wang,Zunhai Su,Yiwei Wang,Qianli Wang,Shuzhou Yuan,Ercong Nie,Xufeng Duan,Qibo Xue,Zeping Yu,Chenming Shang,Xiao Liang,Jing Xiong,Hui Shen,Chaofan Tao,Zhengwu Liu,Senjie Jin,Zhiheng Xi,Dongdong Zhang,Sophia Ananiadou,Tao Gui,Ruobing Xie,Hayden Kwok-Hay So,Hinrich Schütze,Xuanjing Huang,Qi Zhang,Ngai Wong*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了一种可操作的机制可解释性框架，将MI从观察科学转变为系统干预方法，围绕"定位、引导、改进"流程构建，旨在通过诊断和干预优化LLM性能。


<details>
  <summary>Details</summary>
Motivation: 现有机制可解释性研究主要作为观察科学，总结分析见解但缺乏系统性干预框架。需要将MI从被动观察转变为主动干预方法，以实际优化LLM模型。

Method: 提出"定位、引导、改进"的实践性框架，基于可解释对象对定位（诊断）和引导（干预）方法进行形式化分类，建立严格的干预协议，展示如何通过该框架在对齐、能力和效率方面实现具体改进。

Result: 建立了一个系统化的可操作MI框架，将机制可解释性转化为实际模型优化方法，提供了从诊断到干预的完整流程，并展示了在LLM对齐、能力提升和效率改进方面的应用潜力。

Conclusion: 该工作将机制可解释性从观察科学转变为可操作方法学，为LLM优化提供了系统框架，通过"定位、引导、改进"流程实现了MI的实际应用价值。

Abstract: Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.

</details>


### [93] [BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models](https://arxiv.org/abs/2601.14007)
*Junyu Zhang,Yipeng Kang,Jiong Guo,Jiayu Zhan,Junqi Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出抽象-具象框架，将概念理解分解为三个能力：抽象概念解释、抽象概念在具体事件中的具象化、以及抽象原则在具体决策中的应用。以人类价值观为测试平台，通过探测和引导实验发现LLMs具有跨层次的稳定价值表征。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究大型语言模型是否真正理解抽象概念，还是仅仅在统计模式层面操作概念。以人类价值观作为测试平台，因为价值观具有语义丰富性和对齐中心性，可以检验模型的概念理解能力。

Method: 提出抽象-具象框架，将概念理解分解为三个能力：A-A（抽象-抽象）、A-C（抽象-具象）、C-C（具象-具象）。使用探测（检测内部激活中的价值痕迹）和引导（修改表征以改变行为）两种方法。在六个开源LLM和十个价值维度上进行实验。

Result: 探测结果显示，仅基于抽象价值描述训练的探测模型能够可靠地检测具体事件叙述和决策推理中的相同价值，展示了跨层次迁移能力。引导实验揭示了不对称性：干预价值表征能够因果性地改变具体判断和决策（A-C, C-C），但不会改变抽象解释（A-A），表明编码的抽象价值作为稳定锚点而非可塑激活。

Conclusion: LLMs保持结构化的价值表征，能够桥接抽象和行动，为构建价值驱动的自主AI系统提供了机制和操作基础，可实现更透明、可泛化的对齐和控制。

Abstract: Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.

</details>


### [94] [RM-Distiller: Exploiting Generative LLM for Reward Model Distillation](https://arxiv.org/abs/2601.14032)
*Hongli Zhou,Hui Huang,Wei Liu,Chenglong Wang,Xingyuan Bu,Lvyuan Han,Fuhai Song,Muyun Yang,Wenhao Jiang,Hailong Cao,Tiejun Zhao*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出RM-Distiller框架，系统利用教师LLM的多方面能力（精炼、评分、生成）进行奖励模型蒸馏，显著优于传统方法


<details>
  <summary>Details</summary>
Motivation: 现有方法主要将教师模型视为简单的二元标注器，未能充分利用其丰富知识和能力进行奖励模型蒸馏。高质量人类偏好标注难以获取，从生成式LLM中蒸馏偏好已成为标准做法。

Method: 提出RM-Distiller框架，系统利用教师LLM的三方面能力：1) 精炼能力：合成高度相关的响应对，创建细粒度对比信号；2) 评分能力：通过边界感知优化目标指导RM捕捉精确偏好强度；3) 生成能力：结合教师生成分布，正则化RM以保留基本语言知识。

Result: 大量实验表明，RM-Distiller在RM基准测试和基于强化学习的对齐任务上显著优于传统蒸馏方法，证明利用多方面教师能力对有效奖励建模至关重要。

Conclusion: 这是首个关于从生成式LLM进行奖励模型蒸馏的系统性研究，通过充分利用教师模型的多方面能力，显著提升了奖励模型蒸馏的效果。

Abstract: Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.

</details>


### [95] [Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants](https://arxiv.org/abs/2601.14041)
*Yunhe Wang,Kai Han,Huiling Zhen,Yuchuan Tian,Hanting Chen,Yongbing Huang,Yufei Cui,Yingte Shu,Shan Gao,Ismail Elezi,Roy Vaughan Miles,Songcen Xu,Feng Wen,Chao Xu,Sinan Zeng,Dacheng Tao*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文认为自回归语言模型存在因果瓶颈限制，扩散语言模型（DLMs）提供了更优的文本生成范式，但面临十大挑战阻碍其发展。作者提出四支柱路线图，建议构建扩散原生生态系统以实现下一代AI能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要基于自回归架构，存在因果瓶颈，限制了全局结构预见和迭代优化能力。扩散语言模型提供了更优的文本生成范式（类似雕塑家精雕细琢），但现有研究仍受限于自回归遗留框架，未能充分发挥其潜力。

Method: 本文是一篇观点性论文，首先识别了扩散语言模型面临的十大基础挑战（包括架构惯性、梯度稀疏性、线性推理限制等），然后提出了四支柱战略路线图：基础架构、算法优化、认知推理和统一多模态智能，建议构建扩散原生生态系统。

Result: 论文系统分析了扩散语言模型的发展障碍，提出了具体的解决方案框架，包括多尺度分词、主动重掩码、潜在思维等关键技术方向，为扩散语言模型的发展提供了清晰的路线图。

Conclusion: 从自回归范式向扩散原生生态系统的转变对于开发下一代AI至关重要，这将使AI具备复杂结构推理、动态自我修正和无缝多模态集成能力，实现扩散语言模型的"GPT-4时刻"。

Abstract: The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.

</details>


### [96] [Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering](https://arxiv.org/abs/2601.14050)
*Yuxin Chen,Zhengzhou Cai,Xiangtian Ji,Weixiang Zhao,An Zhang,Xiang Wang,Tat-Seng Chua*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文系统分析了MoE模型的多语言处理机制，发现路由行为与语系对齐，专家利用呈现清晰的层级模式，并提出了一种路由引导的调控方法以提升多语言性能。


<details>
  <summary>Details</summary>
Motivation: 尽管MoE架构在多语言任务上表现出色，但其内部机制（性能提升原因和跨语言差异）尚未得到充分理解。研究者希望系统分析MoE模型的路由行为和专家专业化模式，以揭示多语言处理的结构化特性。

Method: 1. 系统分析MoE模型在不同语言和网络深度上的路由行为与专家专业化
2. 通过层级干预实验探究不同MoE层的功能
3. 提出路由引导的调控方法，在推理时自适应地将中间层的路由行为导向与主导语言相关的共享专家

Result: 1. MoE模型的多语言处理高度结构化：路由与语系对齐，专家利用呈现清晰的层级模式
2. 高资源语言依赖共享专家，低资源语言更多使用语言专属专家但性能较弱
3. 早期和晚期MoE层支持语言特定处理，中间层作为语言无关的容量枢纽
4. 提出的路由引导调控方法能持续提升多语言性能，特别是对语言相关的语言对

Conclusion: MoE模型的多语言处理具有系统性的结构化特性，理解这些机制可以指导模型设计和优化。路由引导的调控方法为提升多语言性能提供了有效途径，特别是在处理语言相关语言对时效果显著。

Abstract: Mixture-of-Experts (MoE) architectures have shown strong multilingual capabilities, yet the internal mechanisms underlying performance gains and cross-language differences remain insufficiently understood. In this work, we conduct a systematic analysis of MoE models, examining routing behavior and expert specialization across languages and network depth. Our analysis reveals that multilingual processing in MoE models is highly structured: routing aligns with linguistic families, expert utilization follows a clear layerwise pattern, and high-resource languages rely on shared experts while low-resource languages depend more on language-exclusive experts despite weaker performance. Layerwise interventions further show that early and late MoE layers support language-specific processing, whereas middle layers serve as language-agnostic capacity hubs. Building on these insights, we propose a routing-guided steering method that adaptively guides routing behavior in middle layers toward shared experts associated with dominant languages at inference time, leading to consistent multilingual performance improvements, particularly for linguistically related language pairs. Our code is available at https://github.com/conctsai/Multilingualism-in-Mixture-of-Experts-LLMs.

</details>


### [97] [XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs](https://arxiv.org/abs/2601.14063)
*Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Shaoxiong Ji,Hassan Alhuzali,Sophia Ananiadou*

Main category: cs.CL

Relevance: 85.0

TL;DR: XCR-Bench：一个包含4.9k平行句对和1,098个独特文化特定项目的跨文化推理基准，用于评估LLMs识别和适应文化特定项目的能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLMs跨文化能力受限于高质量文化特定项目标注语料库的稀缺，特别是包含平行跨文化句对的语料。需要系统评估LLMs在识别和适应文化特定项目方面的能力。

Method: 结合Newmark的文化特定项目框架和Hall的文化三元论，构建包含三个推理任务的基准：1) 文化特定项目识别，2) 跨文化适应，3) 文化推理。涵盖表面文化元素、半可见和不可见文化元素（社会规范、信仰、价值观）。

Result: 当前最先进的LLMs在识别和适应与社会礼仪和文化参照相关的文化特定项目方面表现一致较弱。LLMs在文化适应过程中即使在同一语言环境中也编码了区域和民族宗教偏见。

Conclusion: XCR-Bench填补了跨文化NLP评估的空白，揭示了LLMs在文化推理方面的系统性弱点，特别是对深层文化元素的理解不足，并暴露了模型中的文化偏见问题。

Abstract: Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.

</details>


### [98] [Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns](https://arxiv.org/abs/2601.14112)
*George Mihaila*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文提出ExpNet，一个轻量级神经网络，通过学习从Transformer注意力模式到token重要性分数的显式映射，实现可解释AI，相比现有方法能自动发现最优注意力特征组合。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型在医疗、法律、金融等高风险领域部署，模型不透明性阻碍了信任和问责。现有注意力解释方法依赖手动定义的聚合策略和固定归因规则，而模型无关方法（如LIME、SHAP）将模型视为黑盒且计算成本高。

Method: 提出Explanation Network (ExpNet)，一个轻量级神经网络，学习从Transformer注意力模式到token级重要性分数的显式映射。与先前方法不同，ExpNet能自动发现最优注意力特征组合，而非依赖预定规则。

Result: 在具有挑战性的跨任务设置中评估ExpNet，并与涵盖四个方法家族的广泛模型无关方法和基于注意力的技术进行基准测试。

Conclusion: ExpNet提供了一种更有效、自动化的Transformer模型解释方法，克服了现有注意力解释方法的局限性。

Abstract: Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.

</details>


### [99] [Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models](https://arxiv.org/abs/2601.14152)
*Hyunjong Ok,Jaeho Lee*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现LLM在多项选择题中，将上下文放在问题和选项之前(CQO)比相反顺序(QOC)性能提升超过14%，核心机制是因果注意力导致QOC中选项无法关注上下文信息。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对提示结构表现出令人惊讶的敏感性，但其机制尚不清楚。本研究深入调查了一个显著案例：在多项选择题回答中，不同提示顺序会导致巨大性能差异。

Method: 通过系统性的架构分析，研究不同提示结构（CQO vs QOC）对模型性能的影响，识别因果注意力机制作为核心原因。

Result: 在多种模型和数据集上，CQO顺序比QOC顺序性能提升超过14个百分点。发现QOC中因果掩码阻止选项token关注上下文，形成信息瓶颈。

Conclusion: 因果注意力是LLM对提示结构敏感性的核心机制，揭示了模型架构如何影响信息流动和推理能力，对提示工程和模型设计有重要启示。

Abstract: Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.

</details>


### [100] [HALT: Hallucination Assessment via Latent Testing](https://arxiv.org/abs/2601.14210)
*Rohan Bhatnagar,Youran Sun,Chi Andrew Zhang,Yixin Wen,Haizhao Yang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出轻量级残差探针直接从LLM中间隐藏状态读取幻觉风险，实现零延迟风险估计，用于选择性生成和路由决策。


<details>
  <summary>Details</summary>
Motivation: LLM幻觉可理解为忠实读取失败：虽然内部表示可能编码查询的不确定性，但解码压力仍会产生流畅答案。中间层可能保留在最终解码阶段被衰减的认知信号。

Method: 设计小型辅助网络（残差探针），直接从问题标记的中间隐藏状态读取幻觉风险。计算成本比标记生成低几个数量级，可与推理完全并行评估，实现近瞬时幻觉风险估计。

Result: 在四个QA基准测试和多个LLM家族中，方法实现了强AUROC和AURAC，在数据集偏移下具有良好泛化能力，并在中间表示中揭示了可解释的结构。

Conclusion: 快速内部不确定性读取可作为可靠智能AI的原则性基础，探针可作为智能批评者用于快速选择性生成和路由，使LLM能立即回答自信查询，同时将不确定查询委托给更强的验证流程。

Abstract: Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.

</details>


### [101] [Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249)
*Yuming Yang,Mingyoung Lai,Wanxu Zhao,Xiaoran Fan,Zhiheng Xi,Mingqi Wu,Chiyue Huang,Jun Zhao,Haijun Lv,Jian Tong,Yunhua Zhou,Yicheng Zou,Qipeng Guo,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出Rank-Surprisal Ratio (RSR)指标，用于评估推理轨迹在知识蒸馏中的适用性，平衡对齐性和信息量，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法中，更强的教师模型生成的推理轨迹不一定能产生更好的学生模型，表明数据与学生模型的匹配度至关重要。现有方法主要通过学生似然度评估适用性，但这种方法偏向于与模型当前行为高度对齐的轨迹，忽略了更具信息量的轨迹。

Method: 提出Rank-Surprisal Ratio (RSR)指标，定义为轨迹的平均token级别排名与平均负对数似然之比。该指标同时捕捉对齐性和信息量：有效的推理轨迹通常在学生模型下具有较低的绝对概率（信息量大）但相对较高的token排名（对齐性好）。

Result: 在5个学生模型和11个不同教师生成的推理轨迹上，RSR与训练后性能强相关（平均Spearman相关系数0.86），优于现有指标。实验还展示了RSR在轨迹选择和教师选择中的实际效用。

Conclusion: RSR是一个简单有效的指标，能够评估推理轨迹在知识蒸馏中的适用性，平衡学习信号强度和行为对齐，为知识蒸馏中的数据选择提供了新方法。

Abstract: Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.

</details>


### [102] [Advances and Frontiers of LLM-based Issue Resolution in Software Engineering: A Comprehensive Survey](https://arxiv.org/abs/2601.11655)
*Caihua Li,Lianghong Guo,Yanlin Wang,Daya Guo,Wei Tao,Zhenyu Shan,Mingwei Liu,Jiachi Chen,Haoyu Song,Duyu Tang,Hongyu Zhang,Zibin Zheng*

Main category: cs.SE

Relevance: 85.0

TL;DR: 这是一篇关于AI解决软件工程问题的系统性综述论文，重点分析LLM在issue resolution任务上的表现、方法和发展趋势。


<details>
  <summary>Details</summary>
Motivation: 软件工程中的issue resolution是一个复杂的现实开发任务，SWE-bench等基准测试显示这对大语言模型极具挑战性，因此需要系统梳理这一新兴领域的研究进展。

Method: 采用系统性综述方法：1) 分析数据构建流程（自动收集与合成方法）；2) 全面分析方法论（训练无关框架的模块化组件到基于训练的技术如监督微调和强化学习）；3) 讨论数据质量和代理行为的批判性分析；4) 识别关键挑战和未来研究方向。

Result: 建立了该领域的系统性知识框架，提供了数据构建、方法分类、分析视角的全面梳理，并创建了开源资源库作为动态参考。

Conclusion: issue resolution是LLM在软件工程中的重要应用方向，虽然面临挑战但发展迅速，需要更多研究关注数据质量、代理行为分析和实际应用。

Abstract: Issue resolution, a complex Software Engineering (SWE) task integral to real-world development, has emerged as a compelling challenge for artificial intelligence. The establishment of benchmarks like SWE-bench revealed this task as profoundly difficult for large language models, thereby significantly accelerating the evolution of autonomous coding agents. This paper presents a systematic survey of this emerging domain. We begin by examining data construction pipelines, covering automated collection and synthesis approaches. We then provide a comprehensive analysis of methodologies, spanning training-free frameworks with their modular components to training-based techniques, including supervised fine-tuning and reinforcement learning. Subsequently, we discuss critical analyses of data quality and agent behavior, alongside practical applications. Finally, we identify key challenges and outline promising directions for future research. An open-source repository is maintained at https://github.com/DeepSoftwareAnalytics/Awesome-Issue-Resolution to serve as a dynamic resource in this field.

</details>


### [103] [The Language You Ask In: Language-Conditioned Ideological Divergence in LLM Analysis of Contested Political Documents](https://arxiv.org/abs/2601.12164)
*Oleg Smirnov*

Main category: cs.CY

Relevance: 85.0

TL;DR: 研究发现LLMs在不同语言提示下对同一乌克兰公民社会文件的政治分析存在系统性偏见：俄语输出呼应俄罗斯国家叙事，乌克兰语输出采用西方自由民主话语，显示提示语言能显著影响模型意识形态取向。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在多语言环境中作为分析工具部署，其输出可能受到提示语言的系统性偏见影响。本研究旨在探究LLMs在不同语言提示下对相同内容的政治分析是否存在系统性差异，特别是在高度政治化的语境中。

Method: 实验比较方法：使用语义等效的俄语和乌克兰语提示，让LLMs分析同一份乌克兰公民社会文件。保持源材料和查询结构完全相同，仅改变提示语言，然后比较输出结果在修辞定位、意识形态取向和解释结论方面的差异。

Result: 俄语输出呼应俄罗斯国家话语，将公民社会行为体描述为破坏民主授权的非法精英；乌克兰语输出采用西方自由民主政治学词汇，将相同行为体视为民主竞争中的合法利益相关者。尽管使用相同模型分析相同内容，仅改变提示语言就产生了显著不同的意识形态取向。

Conclusion: 提示语言本身能够导致LLMs对相同内容产生系统性不同的意识形态取向，这对AI在极化信息环境中的部署、跨语言研究应用以及多语言社会的AI治理具有重要影响。

Abstract: Large language models (LLMs) are increasingly deployed as analytical tools across multilingual contexts, yet their outputs may carry systematic biases conditioned by the language of the prompt. This study presents an experimental comparison of LLM-generated political analyses of a Ukrainian civil society document, using semantically equivalent prompts in Russian and Ukrainian. Despite identical source material and parallel query structures, the resulting analyses varied substantially in rhetorical positioning, ideological orientation, and interpretive conclusions. The Russian-language output echoed narratives common in Russian state discourse, characterizing civil society actors as illegitimate elites undermining democratic mandates. The Ukrainian-language output adopted vocabulary characteristic of Western liberal-democratic political science, treating the same actors as legitimate stakeholders within democratic contestation. These findings demonstrate that prompt language alone can produce systematically different ideological orientations from identical models analyzing identical content, with significant implications for AI deployment in polarized information environments, cross-lingual research applications, and the governance of AI systems in multilingual societies.

</details>


### [104] [Environment-Aware Code Generation: How far are We?](https://arxiv.org/abs/2601.12262)
*Tongtong Wu,Rongyi Chen,Wenjie Du,Suyu Ma,Guilin Qi,Zhenchang Xing,Shahram Khadivi,Ramesh Periyathambi,Gholamreza Haffari*

Main category: cs.SE

Relevance: 85.0

TL;DR: 该论文提出了环境感知代码生成（EACG）的概念，并引入了VersiBCB基准来评估LLM在特定软件环境下生成可执行代码的能力。研究发现当前LLM在此任务上表现不佳，但通过数据、参数和缓存三个维度的适配策略可以显著改善环境兼容性和可执行性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代码生成评估大多测试孤立的小规模代码（如单个函数），在默认或未指定的软件环境下进行，无法评估LLM是否能为用户特定环境生成可靠的可执行代码。需要研究环境感知代码生成，确保生成的代码在任意软件配置下都能功能正确且直接可执行。

Method: 1. 引入VersiBCB基准：多包、执行验证、弃用感知，捕捉复杂且不断演化的环境；2. 研究三个互补的适配维度：数据、参数和缓存；3. 为每个维度开发代表性策略；4. 使用VersiBCB评估当前LLM在环境感知代码生成上的表现。

Result: 当前LLM在环境特定代码生成方面表现不佳，但通过提出的适配策略（数据、参数、缓存三个维度）可以显著改善环境兼容性和可执行性。VersiBCB基准揭示了先前数据集常忽略的复杂演化环境中的挑战。

Conclusion: 环境感知代码生成是LLM在实际软件工程工作流中部署的关键挑战。VersiBCB基准和提出的适配策略为改进LLM在特定环境下的代码生成能力提供了重要方向和机会。

Abstract: Recent progress in large language models (LLMs) has improved code generation, but most evaluations still test isolated, small-scale code (e.g., a single function) under default or unspecified software environments. As a result, it is unclear whether LLMs can reliably generate executable code tailored to a user's specific environment. We present the first systematic study of Environment-Aware Code Generation (EACG), where generated code must be functionally correct and directly executable under arbitrary software configurations. To enable realistic evaluation, we introduce VersiBCB, a benchmark that is multi-package, execution-verified, and deprecation-aware, capturing complex and evolving environments that prior datasets often overlook. Using VersiBCB, we investigate three complementary adaptation axes: data, parameters, and cache, and develop representative strategies for each. Our results show that current LLMs struggle with environment-specific code generation, while our adaptations improve environment compatibility and executability. These findings highlight key challenges and opportunities for deploying LLMs in practical software engineering workflows.

</details>


### [105] [Rethinking the Value of Multi-Agent Workflow: A Strong Single Agent Baseline](https://arxiv.org/abs/2601.12307)
*Jiawei Xu,Arief Koesdwiady,Sisong Bei,Yan Han,Baixiang Huang,Dakuo Wang,Yutong Chen,Zheshen Wang,Peihao Wang,Pan Li,Ying Ding*

Main category: cs.MA

Relevance: 85.0

TL;DR: 研究发现单智能体通过多轮对话可以模拟同质多智能体工作流，甚至匹配自动优化的异构工作流性能，提出了OneFlow算法降低推理成本，同时指出单LLM方法无法真正实现异构多智能体系统。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多智能体系统大多采用同质设计（所有智能体共享相同的基础LLM），这引发了一个问题：这样的工作流是否可以通过单智能体的多轮对话来模拟？研究旨在探索单智能体能否达到多智能体工作流的性能，并降低推理成本。

Method: 在七个基准测试（编码、数学、通用问答、领域特定推理、现实世界规划和工具使用）上对比单智能体与多智能体工作流的性能。提出了OneFlow算法，自动为单智能体执行定制工作流，利用KV缓存重用提高效率。

Result: 单智能体可以达到同质工作流的性能，并具有KV缓存重用的效率优势，甚至可以匹配自动优化的异构工作流性能。OneFlow算法相比现有自动多智能体设计框架，在不牺牲准确性的情况下降低了推理成本。

Conclusion: 单LLM实现的多智能体工作流应作为MAS研究的强基线。同时指出单LLM方法无法真正实现异构工作流（因为不同LLM之间无法共享KV缓存），这为开发真正异构的多智能体系统提供了未来研究方向。

Abstract: Recent advances in LLM-based multi-agent systems (MAS) show that workflows composed of multiple LLM agents with distinct roles, tools, and communication patterns can outperform single-LLM baselines on complex tasks. However, most frameworks are homogeneous, where all agents share the same base LLM and differ only in prompts, tools, and positions in the workflow. This raises the question of whether such workflows can be simulated by a single agent through multi-turn conversations. We investigate this across seven benchmarks spanning coding, mathematics, general question answering, domain-specific reasoning, and real-world planning and tool use. Our results show that a single agent can reach the performance of homogeneous workflows with an efficiency advantage from KV cache reuse, and can even match the performance of an automatically optimized heterogeneous workflow. Building on this finding, we propose \textbf{OneFlow}, an algorithm that automatically tailors workflows for single-agent execution, reducing inference costs compared to existing automatic multi-agent design frameworks without trading off accuracy. These results position the single-LLM implementation of multi-agent workflows as a strong baseline for MAS research. We also note that single-LLM methods cannot capture heterogeneous workflows due to the lack of KV cache sharing across different LLMs, highlighting future opportunities in developing \textit{truly} heterogeneous multi-agent systems.

</details>


### [106] [Zero-Shot Embedding Drift Detection: A Lightweight Defense Against Prompt Injections in LLMs](https://arxiv.org/abs/2601.12359)
*Anirudh Sekar,Mrinal Agarwal,Rachel Sharma,Akitsugu Tanaka,Jasmine Zhang,Arjun Damerla,Kevin Zhu*

Main category: cs.CR

Relevance: 85.0

TL;DR: 提出ZEDD框架，通过量化嵌入空间中的语义漂移来检测直接和间接的提示注入攻击，无需模型内部访问或攻击先验知识，在多个LLM上达到93%准确率。


<details>
  <summary>Details</summary>
Motivation: 提示注入攻击已成为LLM应用的重要安全漏洞，即使最先进的LLM也广泛易受攻击。现有防御方法效率低下且模型特定，需要更鲁棒、通用、轻量级的检测机制。

Method: 提出零样本嵌入漂移检测(ZEDD)框架：使用对抗-干净提示对，通过余弦相似度测量嵌入空间中的语义漂移，识别提示注入攻击。无需模型内部访问、攻击类型先验知识或任务特定重训练。

Result: 在重新标注的LLMail-Inject数据集（包含5个注入类别）上，ZEDD在Llama 3、Qwen 2、Mistral等模型上达到>93%的检测准确率，误报率<3%，优于传统方法。

Conclusion: 嵌入漂移是鲁棒且可迁移的检测信号，ZEDD提供轻量级、可扩展的防御层，可集成到现有LLM管道中，填补了LLM系统安全的关键空白。

Abstract: Prompt injection attacks have become an increasing vulnerability for LLM applications, where adversarial prompts exploit indirect input channels such as emails or user-generated content to circumvent alignment safeguards and induce harmful or unintended outputs. Despite advances in alignment, even state-of-the-art LLMs remain broadly vulnerable to adversarial prompts, underscoring the urgent need for robust, productive, and generalizable detection mechanisms beyond inefficient, model-specific patches. In this work, we propose Zero-Shot Embedding Drift Detection (ZEDD), a lightweight, low-engineering-overhead framework that identifies both direct and indirect prompt injection attempts by quantifying semantic shifts in embedding space between benign and suspect inputs. ZEDD operates without requiring access to model internals, prior knowledge of attack types, or task-specific retraining, enabling efficient zero-shot deployment across diverse LLM architectures. Our method uses adversarial-clean prompt pairs and measures embedding drift via cosine similarity to capture subtle adversarial manipulations inherent to real-world injection attacks. To ensure robust evaluation, we assemble and re-annotate the comprehensive LLMail-Inject dataset spanning five injection categories derived from publicly available sources. Extensive experiments demonstrate that embedding drift is a robust and transferable signal, outperforming traditional methods in detection accuracy and operational efficiency. With greater than 93% accuracy in classifying prompt injections across model architectures like Llama 3, Qwen 2, and Mistral and a false positive rate of <3%, our approach offers a lightweight, scalable defense layer that integrates into existing LLM pipelines, addressing a critical gap in securing LLM-powered systems to withstand adaptive adversarial threats.

</details>


### [107] [De-Anonymization at Scale via Tournament-Style Attribution](https://arxiv.org/abs/2601.12407)
*Lirui Zhang,Huishuai Zhang*

Main category: cs.CR

Relevance: 85.0

TL;DR: 提出DAS方法，利用大语言模型在数万候选文本中识别匿名文档作者，通过分组筛选、迭代查询和多数投票机制实现大规模作者去匿名化，在匿名评审数据和标准基准上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs快速发展并进入实际应用，其隐私影响日益重要。研究作者去匿名化威胁：使用LLMs将匿名文档链接到其作者，可能危及双盲同行评审等场景的匿名性。

Method: 提出DAS方法：1) 将候选语料随机分区为固定大小组；2) 提示LLM选择最可能与查询文本同一作者撰写的文本；3) 迭代查询幸存候选文本生成排名前k列表。为大规模应用，添加密集检索预过滤器缩小搜索空间，以及多数投票聚合提高鲁棒性和排名精度。

Result: 在匿名评审数据上，DAS能从数万文本池中恢复同一作者文本，准确率显著高于随机。在标准作者身份基准（Enron邮件和博客文章）上，DAS在准确性和可扩展性上均优于先前方法。

Conclusion: DAS展示了LLM启用的新型去匿名化漏洞，对匿名平台构成实际隐私风险，突显了LLMs在作者身份识别方面的强大能力及其隐私影响。

Abstract: As LLMs rapidly advance and enter real-world use, their privacy implications are increasingly important. We study an authorship de-anonymization threat: using LLMs to link anonymous documents to their authors, potentially compromising settings such as double-blind peer review.
  We propose De-Anonymization at Scale (DAS), a large language model-based method for attributing authorship among tens of thousands of candidate texts. DAS uses a sequential progression strategy: it randomly partitions the candidate corpus into fixed-size groups, prompts an LLM to select the text most likely written by the same author as a query text, and iteratively re-queries the surviving candidates to produce a ranked top-k list. To make this practical at scale, DAS adds a dense-retrieval prefilter to shrink the search space and a majority-voting style aggregation over multiple independent runs to improve robustness and ranking precision. Experiments on anonymized review data show DAS can recover same-author texts from pools of tens of thousands with accuracy well above chance, demonstrating a realistic privacy risk for anonymous platforms. On standard authorship benchmarks (Enron emails and blog posts), DAS also improves both accuracy and scalability over prior approaches, highlighting a new LLM-enabled de-anonymization vulnerability.

</details>


### [108] [SSVD-O: Parameter-Efficient Fine-Tuning with Structured SVD for Speech Recognition](https://arxiv.org/abs/2601.12600)
*Pu Wang,Shinji Watanabe,Hugo Van hamme*

Main category: cs.SD

Relevance: 85.0

TL;DR: SSVD-Outer是一种参数高效微调方法，结合输入声学特征空间的内变换和输出语义特征空间的外变换，在语音识别任务中实现可扩展且平衡的适配。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法（如LoRA及其变体）通常均匀分配参数到模型子空间，这在语音应用中限制了效率和可扩展性。需要更智能的参数预算分配策略来平衡学习和遗忘之间的权衡。

Method: SSVD-Outer扩展了结构化SVD引导的微调方法，结合输入声学特征空间的内变换和输出语义特征空间的外变换。在ESPnet框架中对0.1B到2B规模的模型进行系统分析，研究模型子空间参数预算分配。

Result: 在儿童语音和地区口音等域转移ASR任务中，SSVD-O相比LoRA、DoRA、PiSSA和SSVD等方法，能持续缩小与全微调的性能差距，同时提升泛化能力并缓解灾难性遗忘。

Conclusion: SSVD-Outer通过平衡的参数分配策略，在语音基础模型的参数高效微调中实现了更好的可扩展性和性能，为大规模语音模型的适配提供了有效解决方案。

Abstract: Parameter-efficient fine-tuning (PEFT) is a scalable approach for adapting large speech foundation models to new domains. While methods such as LoRA and its state-of-the-art variants reduce adaptation costs, they typically allocate parameters uniformly across model subspaces, which limits their efficiency and scalability in speech applications. Building on our prior work, this paper introduces SSVD-Outer (SSVD-O), an extension of the structured SVD-guided (SSVD) fine-tuning method. SSVD-O combines input acoustic feature space-associated inner transformations with output semantic feature space-associated outer transformations to enable scalable and balanced adaptation. We conduct the first systematic analysis of parameter budget allocation across model subspaces in PEFT for automatic speech recognition (ASR), and investigate the trade-off between learning and forgetting under constrained resources. SSVD-O is benchmarked against LoRA, DoRA, PiSSA, and SSVD on domain-shifted ASR tasks, including child speech and regional accents, across model scales from 0.1B to 2B within the ESPnet framework. Experimental results show that SSVD-O consistently narrows the performance gap to full fine-tuning while improving generalization and mitigating catastrophic forgetting.

</details>


### [109] [RAGExplorer: A Visual Analytics System for the Comparative Diagnosis of RAG Systems](https://arxiv.org/abs/2601.12991)
*Haoyu Tian,Yingchaojie Feng,Zhen Wen,Haoxuan Li,Minfeng Zhu,Wei Chen*

Main category: cs.HC

Relevance: 85.0

TL;DR: RAGExplorer是一个可视化分析系统，用于系统比较和诊断RAG配置，帮助开发者理解性能权衡并找到最优设计。


<details>
  <summary>Details</summary>
Motivation: RAG系统性能由多个模块化选择（如嵌入模型、检索算法）的复杂交互决定，形成了庞大且不透明的配置空间，使开发者难以理解性能权衡和识别最优设计。

Method: 开发了RAGExplorer可视化分析系统，采用从宏观到微观的分析流程：先让开发者概览多个配置的性能格局，再深入分析具体失败案例，研究检索信息差异如何导致错误，并可通过交互式操作测试假设。

Result: 通过详细案例研究和用户研究验证了RAGExplorer的有效性，证明其能够帮助开发者在复杂的RAG设计空间中导航。代码和用户指南已公开。

Conclusion: RAGExplorer解决了RAG配置空间复杂性的挑战，为开发者提供了系统化的分析和诊断工具，有助于优化RAG系统设计。

Abstract: The advent of Retrieval-Augmented Generation (RAG) has significantly enhanced the ability of Large Language Models (LLMs) to produce factually accurate and up-to-date responses. However, the performance of a RAG system is not determined by a single component but emerges from a complex interplay of modular choices, such as embedding models and retrieval algorithms. This creates a vast and often opaque configuration space, making it challenging for developers to understand performance trade-offs and identify optimal designs. To address this challenge, we present RAGExplorer, a visual analytics system for the systematic comparison and diagnosis of RAG configurations. RAGExplorer guides users through a seamless macro-to-micro analytical workflow. Initially, it empowers developers to survey the performance landscape across numerous configurations, allowing for a high-level understanding of which design choices are most effective. For a deeper analysis, the system enables users to drill down into individual failure cases, investigate how differences in retrieved information contribute to errors, and interactively test hypotheses by manipulating the provided context to observe the resulting impact on the generated answer. We demonstrate the effectiveness of RAGExplorer through detailed case studies and user studies, validating its ability to empower developers in navigating the complex RAG design space. Our code and user guide are publicly available at https://github.com/Thymezzz/RAGExplorer.

</details>


### [110] [From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace Instruction Tuning](https://arxiv.org/abs/2601.13384)
*Jiajun Zhang,Zeyu Cui,Jiaxi Yang,Lei Zhang,Yuheng Jing,Zeyao Ma,Tianyi Bai,Zilei Wang,Qiang Liu,Liang Wang,Binyuan Hui,Junyang Lin*

Main category: cs.SE

Relevance: 85.0

TL;DR: 提出Search-and-Replace Infilling (SRI)框架，将代理式验证-编辑机制内化为单次推理过程，解决传统FIM代码补全无法修正上下文错误的问题，同时保持低延迟。


<details>
  <summary>Details</summary>
Motivation: 传统FIM代码补全范式存在两个主要问题：1) 无法修正上下文错误，2) 依赖未对齐、不安全的Base模型。Chat LLMs虽然安全但性能下降，Agentic工作流灵活但延迟过高。需要一种能兼顾性能、安全性和效率的解决方案。

Method: 提出SRI框架，通过显式搜索阶段结构化地定位编辑位置，将代理式验证-编辑机制内化为统一的单次推理过程。构建高质量数据集SRI-200K，并微调SRI-Coder系列模型。该方法将静态填充扩展到动态上下文感知编辑。

Result: 仅用2万样本微调，SRI-Coder使Chat模型在代码补全性能上超越其Base模型。与FIM风格微调不同，SRI保持了通用编码能力，且推理延迟与标准FIM相当。已赋能整个Qwen3-Coder系列。

Conclusion: SRI框架成功解决了传统FIM的局限性，在保持低延迟的同时实现了安全、准确的代码补全，为开发者社区提供了先进的自动补全和辅助开发工具。

Abstract: The dominant Fill-in-the-Middle (FIM) paradigm for code completion is constrained by its rigid inability to correct contextual errors and reliance on unaligned, insecure Base models. While Chat LLMs offer safety and Agentic workflows provide flexibility, they suffer from performance degradation and prohibitive latency, respectively. To resolve this dilemma, we propose Search-and-Replace Infilling (SRI), a framework that internalizes the agentic verification-and-editing mechanism into a unified, single-pass inference process. By structurally grounding edits via an explicit search phase, SRI harmonizes completion tasks with the instruction-following priors of Chat LLMs, extending the paradigm from static infilling to dynamic context-aware editing. We synthesize a high-quality dataset, SRI-200K, and fine-tune the SRI-Coder series. Extensive evaluations demonstrate that with minimal data (20k samples), SRI-Coder enables Chat models to surpass the completion performance of their Base counterparts. Crucially, unlike FIM-style tuning, SRI preserves general coding competencies and maintains inference latency comparable to standard FIM. We empower the entire Qwen3-Coder series with SRI, encouraging the developer community to leverage this framework for advanced auto-completion and assisted development.

</details>


### [111] [Chain-of-Thought Compression Should Not Be Blind: V-Skip for Efficient Multimodal Reasoning via Dual-Path Anchoring](https://arxiv.org/abs/2601.13879)
*Dongxu Zhang,Yiding Sun,Cheng Tan,Wenbiao Yan,Ning Yang,Jihua Zhu,Hiajun Zhang*

Main category: cs.MM

Relevance: 85.0

TL;DR: V-Skip：一种针对多模态大语言模型的视觉锚定信息瓶颈优化方法，通过双路径门控机制权衡语言惊奇度和跨模态注意力流，有效解决视觉遗忘问题，在保持细粒度视觉细节的同时实现2.9倍加速。


<details>
  <summary>Details</summary>
Motivation: 链式思维推理显著提升多模态大语言模型性能，但其自回归特性带来过高延迟。现有基于文本中心指标的令牌压缩方法在多模态场景中常失败，导致"视觉遗忘"问题——语言冗余令牌被错误剪枝引发幻觉。

Method: 提出V-Skip方法，将令牌剪枝重新表述为视觉锚定信息瓶颈优化问题。采用双路径门控机制，通过语言惊奇度和跨模态注意力流共同权衡令牌重要性，有效拯救视觉显著锚点。

Result: 在Qwen2-VL和Llama-3.2系列模型上实验表明，V-Skip实现2.9倍加速且精度损失可忽略。特别在DocVQA上，保持细粒度视觉细节，超越其他基线方法30%以上。

Conclusion: V-Skip通过视觉锚定信息瓶颈优化有效解决多模态场景中的视觉遗忘问题，在保持模型性能的同时显著提升推理效率，为多模态大语言模型的推理加速提供了新思路。

Abstract: While Chain-of-Thought (CoT) reasoning significantly enhances the performance of Multimodal Large Language Models (MLLMs), its autoregressive nature incurs prohibitive latency constraints. Current efforts to mitigate this via token compression often fail by blindly applying text-centric metrics to multimodal contexts. We identify a critical failure mode termed Visual Amnesia, where linguistically redundant tokens are erroneously pruned, leading to hallucinations. To address this, we introduce V-Skip that reformulates token pruning as a Visual-Anchored Information Bottleneck (VA-IB) optimization problem. V-Skip employs a dual-path gating mechanism that weighs token importance through both linguistic surprisal and cross-modal attention flow, effectively rescuing visually salient anchors. Extensive experiments on Qwen2-VL and Llama-3.2 families demonstrate that V-Skip achieves a $2.9\times$ speedup with negligible accuracy loss. Specifically, it preserves fine-grained visual details, outperforming other baselines over 30\% on the DocVQA.

</details>


### [112] [Bridging Human Interpretation and Machine Representation: A Landscape of Qualitative Data Analysis in the LLM Era](https://arxiv.org/abs/2601.11739)
*Xinyu Pi,Qisen Yang,Chuong Nguyen,Hua Shen*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文提出了一个4×4框架来分类LLM在定性研究中的输出，发现现有系统偏向低层次意义和低承诺表示，并提出了改进议程。


<details>
  <summary>Details</summary>
Motivation: LLM在定性研究中的应用日益增多，但现有系统产生的输出差异很大——从忠实于原始材料的总结到理论解释和系统模型。为了明确这些差异，需要建立一个分类框架来理解LLM在不同意义层次和建模层次上的表现。

Method: 提出了一个4×4的框架，横跨四个意义构建层次（描述性、分类性、解释性、理论性）和四个建模层次（静态结构、阶段/时间线、因果路径、反馈动态）。将该框架应用于先前的LLM自动化研究，分析其分布特征。

Result: 分析显示现有LLM系统在意义构建和建模层次上存在强烈偏向：主要集中在低层次意义（描述性、分类性）和低承诺表示（静态结构、阶段/时间线），很少有可靠尝试进行解释性/理论性推理或动态建模。

Conclusion: 基于揭示的差距，提出了一个议程，旨在构建能够明确、可选择和可治理其解释性和建模承诺的LLM系统，推动LLM在定性研究中的更高级应用。

Abstract: LLMs are increasingly used to support qualitative research, yet existing systems produce outputs that vary widely--from trace-faithful summaries to theory-mediated explanations and system models. To make these differences explicit, we introduce a 4$\times$4 landscape crossing four levels of meaning-making (descriptive, categorical, interpretive, theoretical) with four levels of modeling (static structure, stages/timelines, causal pathways, feedback dynamics). Applying the landscape to prior LLM-based automation highlights a strong skew toward low-level meaning and low-commitment representations, with few reliable attempts at interpretive/theoretical inference or dynamical modeling. Based on the revealed gap, we outline an agenda for applying and building LLM-systems that make their interpretive and modeling commitments explicit, selectable, and governable.

</details>


### [113] [ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System](https://arxiv.org/abs/2601.11854)
*Yifei Zhang,Hooshang Nayyeri,Rinat Khaziev,Emine Yilmaz,Gokhan Tur,Dilek Hakkani-Tür,Hari Thadakamalla*

Main category: cs.CL

Relevance: 75.0

TL;DR: ATOD是一个面向任务导向对话系统的基准测试和评估框架，专注于评估LLM驱动的对话代理的智能行为，包括多目标协调、依赖管理、记忆、适应性和主动性等能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的任务导向对话系统已经具备了协调交织目标、维护长时上下文和异步执行等智能行为，但现有基准测试缺乏对这些代理行为的系统性评估支持。

Method: 提出了ATOD基准测试和合成对话生成管道，生成需要长期推理的丰富标注对话；设计了ATOD-Eval评估框架，将智能维度转化为细粒度指标，支持可复现的离线和在线评估；开发了基于记忆的智能评估器。

Result: 实验表明ATOD-Eval能够在任务完成度、代理能力和响应质量方面进行全面评估，提出的评估器在准确性和效率之间提供了更好的权衡，优于现有的基于记忆和LLM的方法。

Conclusion: ATOD填补了高级任务导向对话系统评估的空白，为评估LLM驱动的对话代理的智能行为提供了系统性的基准测试和评估框架。

Abstract: Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.

</details>


### [114] [Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes](https://arxiv.org/abs/2601.11932)
*Abdullah Al Monsur,Nitesh Vamshi Bommisetty,Gene Louis Kim*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该研究针对事件检测中的两个关键限制：1) 仅解码器LLMs的单向性架构瓶颈，2) 传统Micro-F1评分对多数类的偏向性。通过引入句子上下文增强和使用LoRA微调，在Macro-F1指标上显著提升了模型在长尾事件类别上的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于事件检测领域的两个持续存在的限制：第一，仅解码器LLMs的单向性架构对于依赖双向上下文理解的自然语言理解任务存在根本性瓶颈；第二，传统事件检测文献过度依赖Micro-F1评分，这种评分会系统性偏向多数类别，无法准确反映模型在长尾事件类型上的真实性能。

Method: 研究方法包括：1) 使用句子上下文增强模型，以克服仅解码器LLMs的单向性限制；2) 在微调过程中采用低秩适配(LoRA)技术；3) 将评估指标从传统的Micro-F1转向更能代表模型在长尾事件类型上能力的Macro-F1。

Result: 实验结果表明：1) 使用句子上下文增强的模型在性能上显著优于标准的仅解码器基线模型；2) 在微调过程中使用LoRA技术，特别是对于仅解码器模型，在Macro-F1分数上带来了显著提升；3) LoRA被证明是增强LLMs在长尾事件类别上性能的有效工具。

Conclusion: 该研究得出结论：通过结合句子上下文增强和LoRA微调，可以显著改善LLMs在事件检测任务中的性能，特别是在处理长尾事件类别时。同时，采用Macro-F1作为评估指标能更准确地反映模型在各类事件上的真实能力。

Abstract: The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language understanding tasks that depend on rich, bidirectional context. Second, we confront the conventional reliance on Micro-F1 scores in event detection literature, which systematically inflates performance by favoring majority classes. Instead, we focus on Macro-F1 as a more representative measure of a model's ability across the long-tail of event types. Our experiments demonstrate that models enhanced with sentence context achieve superior performance over canonical decoder-only baselines. Using Low-Rank Adaptation (LoRA) during finetuning provides a substantial boost in Macro-F1 scores in particular, especially for the decoder-only models, showing that LoRA can be an effective tool to enhance LLMs' performance on long-tailed event classes.

</details>


### [115] [Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning](https://arxiv.org/abs/2601.12019)
*Chaowei Zhang,Xiansheng Luo,Zewei Zhang,Yi Zhu,Jipeng Qiang,Longwei Wang*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出SORG框架，利用LLM的奉承倾向生成对立推理，结合BERT编码器和对比学习进行点击诱饵检测，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在线内容泛滥加剧了点击诱饵问题，LLM虽能解决但受奉承倾向影响，倾向于匹配用户信念而非真实推理。本文创新性地利用这种倾向而非消除它。

Method: 1) SORG框架：提示LLM为新闻标题生成高质量的支持和反对推理对，无需真实标签；2) ORCD模型：三个BERT编码器分别编码标题和推理，通过对比学习和LLM生成的可信度软标签增强检测鲁棒性。

Result: 在三个基准数据集上的实验表明，该方法一致优于LLM提示、微调的小语言模型和最先进的点击诱饵检测基线。

Conclusion: 通过创新性地利用LLM的奉承倾向生成对立推理，结合本地化检测模型，有效提升了点击诱饵检测性能，为LLM的"缺陷"提供了新的应用视角。

Abstract: The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.

</details>


### [116] [Large language models struggle with ethnographic text annotation](https://arxiv.org/abs/2601.12099)
*Leonardo S. Goodall,Dor Shilton,Daniel A. Mullins,Harvey Whitehouse*

Main category: cs.CL

Relevance: 75.0

TL;DR: 评估7个最先进的大语言模型在567个民族志文本片段上标注121个仪式特征的能力，发现性能有限，远未达到可靠自动标注的水平，无法替代人类专业知识


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自动文本标注方面显示出潜力，可能通过从民族志文本中提取结构化数据来加速跨文化研究。本研究旨在评估LLMs在民族志文本标注任务上的实际能力。

Method: 评估了7个最先进的LLMs，在567个民族志文本片段上标注121个仪式特征。分析了不同文本长度、特征类型（需要序数区分的特征）和模糊构造对模型性能的影响。将模型性能与人类编码者的一致性进行比较。

Result: LLMs性能有限，远低于可靠自动标注所需的水平。长文本、需要序数区分的特征和模糊构造特别困难。人类编码者间可靠性设定了LLM准确性的近似上限：人类难以达成一致的特征对LLMs也困难。即使在人类可靠达成一致的特征上，模型也未能达到人类表现水平。

Conclusion: LLMs目前还不能替代人类专业知识进行民族志标注。需要进一步研究提升LLMs在复杂文本分析任务上的能力。

Abstract: Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.

</details>


### [117] [Tolerance Principle and Small Language Model Learning](https://arxiv.org/abs/2601.12179)
*Adam E. Friedman,Stevan Harnad,Rushen Shi*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该研究测试了Transformer语言模型在人工语法学习中的表现，发现BabyBERTa的学习动态不符合人类婴儿遵循的容忍原则


<details>
  <summary>Details</summary>
Motivation: 探索语言模型与人类语言习得的差异。人类婴儿能从少量示例中学习抽象语法规则，并能容忍一定比例的例外，而现代大语言模型需要海量训练数据。研究旨在测试语言模型是否遵循Yang(2016)的容忍原则。

Method: 使用BabyBERTa（专为小数据集优化的Transformer模型）在人工语法上进行训练。训练集在大小、独特句子类型数量、规则遵循与例外示例比例等方面进行系统变化，以测试容忍原则的预测。

Result: 研究发现BabyBERTa的学习动态与容忍原则不一致。与人类婴儿不同，该模型无法在容忍原则预测的阈值内有效学习语法规则。

Conclusion: Transformer语言模型的语言学习机制与人类婴儿存在本质差异，模型不遵循容忍原则，这揭示了当前语言模型在数据效率和语言习得机制方面的局限性。

Abstract: Modern language models like GPT-3, BERT, and LLaMA require massive training data, yet with sufficient training they reliably learn to distinguish grammatical from ungrammatical sentences. Children aged as young as 14 months already have the capacity to learn abstract grammar rules from very few exemplars, even in the presence of non-rule-following exceptions. Yang's (2016) Tolerance Principle defines a precise threshold for how many exceptions a rule can tolerate and still be learnable. The present study explored the minimal amount and quality of training data necessary for rules to be generalized by a transformer-based language model to test the predictions of the Tolerance Principle. We trained BabyBERTa (Huebner et al. 2021), a transformer model optimized for small datasets, on artificial grammars. The training sets varied in size, number of unique sentence types, and proportion of rule-following versus exception exemplars. We found that, unlike human infants, BabyBERTa's learning dynamics do not align with the Tolerance Principle.

</details>


### [118] [CoReflect: Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement](https://arxiv.org/abs/2601.12208)
*Yunzhe Li,Richie Yueqi Feng,Tianxin Wei,Chin-Chia Hsu*

Main category: cs.CL

Relevance: 75.0

TL;DR: CoReflect：通过协同进化模拟和反思性评估准则优化，实现对话系统的自适应多轮评估框架


<details>
  <summary>Details</summary>
Motivation: 传统对话系统评估方法依赖人工定义的固定评估准则和静态对话上下文，覆盖范围有限，无法捕捉对话模型多样化的涌现行为。随着对话模型能力快速进步，需要更灵活、自适应的评估方法。

Method: CoReflect采用协同进化循环：1) 对话规划器生成结构化模板指导用户模拟器进行多样化目标导向对话；2) 反思分析器处理对话，识别系统行为模式并自动优化评估准则；3) 分析结果反馈给规划器更新对话模板，形成测试用例复杂度和评估准则诊断精度同步提升的闭环。

Result: 该方法最小化人工干预，提供可扩展的自优化方法论，使评估协议能够适应对话模型的快速演进能力。

Conclusion: CoReflect将对话模拟和评估统一为自适应迭代过程，解决了多轮对话评估的基本挑战，为对话系统评估提供了更全面、动态的框架。

Abstract: Evaluating conversational systems in multi-turn settings remains a fundamental challenge. Conventional pipelines typically rely on manually defined rubrics and fixed conversational context$-$a static approach that limits coverage and fails to capture the diverse, emergent behaviors of dialogue models. To address this, we introduce CoReflect (Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement), which unifies dialogue simulation and evaluation into an adaptive, iterative process. CoReflect employs a conversation planner that generates structured templates to guide a user simulator through diverse, goal-directed dialogues. Subsequently, a reflective analyzer processes these dialogues to identify systematic behavioral patterns and automatically refine the evaluation rubrics. Crucially, the insights from the conversation analysis are fed back into the planner to update conversation templates for subsequent iterations. This co-evolution loop ensures that the complexity of test cases and the diagnostic precision of rubrics improve in tandem. By minimizing human intervention, CoReflect provides a scalable and self-refining methodology that allows evaluation protocols to adapt alongside the rapidly advancing capabilities of dialogue models.

</details>


### [119] [Can Deep Research Agents Find and Organize? Evaluating the Synthesis Gap with Expert Taxonomies](https://arxiv.org/abs/2601.12369)
*Ming Zhang,Jiabao Zhuang,Wenqing Jing,Ziyu Kong,Jingyi Deng,Yujiong Shen,Kexin Tan,Yuhang Zhao,Ning Luo,Renzhe Zheng,Jiahui Lin,Mingqi Wu,Long Ma,Yi Zou,Shihan Dou,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

Relevance: 75.0

TL;DR: TaxoBench是一个用于评估深度研究代理能力的诊断基准，专注于评估检索关键论文并将其组织成连贯知识结构的能力，而非仅关注流畅性或引用准确性。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究代理越来越多地用于自动生成综述，但它们是否能像人类专家一样撰写综述尚不清楚。现有基准主要关注流畅性或引用准确性，但缺乏对核心能力（检索关键论文并组织成连贯知识结构）的评估。

Method: 从72篇高引用计算机科学综述中手动提取专家撰写的分类树，包含3,815个精确分类的引用作为基准真值。支持两种评估模式：深度研究模式（给定主题进行端到端检索和组织）和自底向上模式（提供人类专家使用的确切论文，隔离组织结构能力）。

Result: 评估了7个领先的深度研究代理和12个前沿LLM。结果显示双重瓶颈：最佳代理仅能召回20.9%的专家选择论文；即使有完美输入，最佳模型在组织结构方面仅达到0.31 ARI。当前深度研究代理距离专家级综述撰写仍有很大差距。

Conclusion: 当前深度研究代理在检索关键论文和组织知识结构方面仍远未达到专家水平。TaxoBench为评估和改进这些能力提供了重要基准。

Abstract: Deep Research Agents are increasingly used for automated survey generation. However, whether they can write surveys like human experts remains unclear. Existing benchmarks focus on fluency or citation accuracy, but none evaluates the core capabilities: retrieving essential papers and organizing them into coherent knowledge structures. We introduce TaxoBench, a diagnostic benchmark derived from 72 highly-cited computer science surveys. We manually extract expert-authored taxonomy trees containing 3,815 precisely categorized citations as ground truth. Our benchmark supports two evaluation modes: Deep Research mode tests end-to-end retrieval and organization given only a topic, while Bottom-Up mode isolates structuring capability by providing the exact papers human experts used. We evaluate 7 leading Deep Research agents and 12 frontier LLMs. Results reveal a dual bottleneck: the best agent recalls only 20.9% of expert-selected papers, and even with perfect input, the best model achieves only 0.31 ARI in organization. Current deep research agents remain far from expert-level survey writing. Our benchmark is publicly available at https://github.com/KongLongGeFDU/TaxoBench.

</details>


### [120] [LR-DWM: Efficient Watermarking for Diffusion Language Models](https://arxiv.org/abs/2601.12376)
*Ofek Raban,Ethan Fetaya,Gal Chechik*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出了一种针对扩散语言模型（DLMs）的水印方法LR-DWM，通过利用左右邻居token来嵌入水印信号，实现了高效的水印嵌入和检测，计算和内存开销接近未加水印的基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLMs）的水印方法主要针对自回归（AR）模型，依赖于token的顺序生成。扩散语言模型（DLMs）通过非顺序的迭代去噪生成文本，需要大幅修改AR模型的水印方法。现有方法通过反转过程实现水印，但存在显著的计算或内存开销。

Method: 提出左右扩散水印（LR-DWM）方案，在左右邻居token可用时，基于左右邻居来偏置生成的token。该方法在生成过程中嵌入水印信号，无需复杂的反转过程，保持了接近基线DLM的运行时和内存开销。

Result: LR-DWM在标准评估设置下实现了可靠的统计检测，同时计算和内存开销最小，接近未加水印的基线DLM。实验结果表明，扩散语言模型可以高效地添加水印，在可忽略的计算和内存开销下实现高可检测性。

Conclusion: LR-DWM为扩散语言模型提供了一种高效的水印解决方案，解决了现有方法计算开销大的问题，使得DLMs能够像AR模型一样可靠地进行水印检测，同时保持接近原始模型的性能。

Abstract: Watermarking (WM) is a critical mechanism for detecting and attributing AI-generated content. Current WM methods for Large Language Models (LLMs) are predominantly tailored for autoregressive (AR) models: They rely on tokens being generated sequentially, and embed stable signals within the generated sequence based on the previously sampled text. Diffusion Language Models (DLMs) generate text via non-sequential iterative denoising, which requires significant modification to use WM methods designed for AR models. Recent work proposed to watermark DLMs by inverting the process when needed, but suffers significant computational or memory overhead. We introduce Left-Right Diffusion Watermarking (LR-DWM), a scheme that biases the generated token based on both left and right neighbors, when they are available. LR-DWM incurs minimal runtime and memory overhead, remaining close to the non-watermarked baseline DLM while enabling reliable statistical detection under standard evaluation settings. Our results demonstrate that DLMs can be watermarked efficiently, achieving high detectability with negligible computational and memory overhead.

</details>


### [121] [NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages](https://arxiv.org/abs/2601.12389)
*Lakshya Tomar,Vinayak Abrol,Puneet Agarwal*

Main category: cs.CL

Relevance: 75.0

TL;DR: NADIR是一种新型非自回归架构，针对序列到序列任务（如多语言音译）设计，平衡了速度和准确性，相比自回归模型实现13倍加速，同时保持竞争力的字符错误率。


<details>
  <summary>Details</summary>
Motivation: 许多序列到序列任务（如多语言音译、代码重构、语法校正）主要依赖局部依赖关系，自回归模型虽然准确但推理延迟高，而非自回归模型速度快但存在幻觉和长度控制问题。需要探索这种权衡，特别是在印度语言的多语言音译任务中。

Method: 提出NADIR架构，结合差分变换器和混合专家机制，能够鲁棒地建模复杂字符映射而无需序列依赖。该设计旨在平衡速度和准确性。

Result: 相比最先进的自回归基线，NADIR实现超过13倍的加速。平均字符错误率为15.78%（自回归模型为14.44%，标准非自回归模型为21.88%）。显著减少各类错误：重复错误减少49.53%，替换错误减少24.45%，省略错误减少32.92%，插入错误减少16.87%。

Conclusion: NADIR为构建快速可靠的非自回归系统提供了实用蓝图，有效弥合了自回归模型的准确性与实时大规模部署需求之间的差距。

Abstract: In this work, we argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. Tasks like multilingual transliteration, code refactoring, grammatical correction or text normalization often rely on local dependencies where the full modeling capacity of AR models can be overkill, creating a trade-off between their high accuracy and high inference latency. While non-autoregressive (NAR) models offer speed, they typically suffer from hallucinations and poor length control. To explore this trade-off, we focus on the multilingual transliteration task in Indic languages and introduce NADIR, a novel NAR architecture designed to strike a balance between speed and accuracy. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling it to robustly model complex character mappings without sequential dependencies. NADIR achieves over a 13x speed-up compared to the state-of-the-art AR baseline. It maintains a competitive mean Character Error Rate of 15.78%, compared to 14.44% for the AR model and 21.88% for a standard NAR equivalent. Importantly, NADIR reduces Repetition errors by 49.53%, Substitution errors by 24.45%, Omission errors by 32.92%, and Insertion errors by 16.87%. This work provides a practical blueprint for building fast and reliable NAR systems, effectively bridging the gap between AR accuracy and the demands of real-time, large-scale deployment.

</details>


### [122] [Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification](https://arxiv.org/abs/2601.12419)
*Mahammad Namazov,Tomáš Koref,Ivan Habernal*

Main category: cs.CL

Relevance: 75.0

TL;DR: 本文提出了一个模型无关的可解释性技术比较分析框架，特别针对法律领域的LLM应用，通过忠实度和合理性评估不同解释方法，发现模型预测原因与法律专家存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 法律领域应用大型语言模型需要信任和透明度，但现有研究缺乏对哪种解释技术最适合法律结果预测的系统比较，这是一个开放性问题。

Method: 提出了一个模型无关的可解释性技术比较分析框架，采用两种理由提取方法，通过忠实度（标准化充分性和全面性指标）和合理性（法律专家评估）进行评估，并评估LLM作为评判者的可行性。

Result: 尽管定量分析结果很有前景且下游分类性能合理，但模型预测违规的"原因"与法律专家的判断存在显著差异，揭示了模型解释与人类专家理解之间的差距。

Conclusion: 法律领域LLM的可解释性需要更细致的评估，仅靠定量指标不足以保证解释质量，模型解释与人类专家理解存在差异，需要结合专家评估来确保解释的可靠性。

Abstract: Interpretability is critical for applications of large language models in the legal domain which requires trust and transparency. While some studies develop task-specific approaches, other use the classification model's parameters to explain the decisions. However, which technique explains the legal outcome prediction best remains an open question. To address this challenge, we propose a comparative analysis framework for model-agnostic interpretability techniques. Among these, we employ two rationale extraction methods, which justify outcomes with human-interpretable and concise text fragments (i.e., rationales) from the given input text. We conduct comparison by evaluating faithfulness-via normalized sufficiency and comprehensiveness metrics along with plausibility-by asking legal experts to evaluate extracted rationales. We further assess the feasibility of LLM-as-a-Judge using legal expert evaluation results. We show that the model's "reasons" for predicting a violation differ substantially from those of legal experts, despite highly promising quantitative analysis results and reasonable downstream classification performance. The source code of our experiments is publicly available at https://github.com/trusthlt/IntEval.

</details>


### [123] [DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity](https://arxiv.org/abs/2601.12505)
*Ashish Raj Shekhar,Shiven Agarwal,Priyanuj Bordoloi,Yash Shah,Tejas Anvekar,Vivek Gupta*

Main category: cs.CL

Relevance: 75.0

TL;DR: DoPE是一种文档层防御框架，通过在PDF/HTML考试文档中嵌入语义诱饵，利用MLLM渲染-解析差异来防止AI作弊和检测AI依赖，无需传统分类器。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）可以直接处理考试文档，威胁传统评估和学术诚信。需要开发模型无关的防御机制来保护考试完整性。

Method: 提出DoPE框架，包含FewSoRT-Q（生成问题级语义诱饵）和FewSoRT-D（将诱饵封装到水印文档中），利用渲染-解析差异来防止和检测AI作弊。

Result: 在Integrity-Bench基准（1826个考试）上评估，对OpenAI和Anthropic的黑盒MLLMs：检测率91.4%（误报率8.7%），96.3%的尝试被阻止或诱导诱饵对齐失败。

Conclusion: DoPE为学术诚信提供了有效的文档层防御，无需依赖传统分类器，具有模型无关性，并发布了基准和工具包供可重复研究。

Abstract: Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.

</details>


### [124] [A Cloud-based Multi-Agentic Workflow for Science](https://arxiv.org/abs/2601.12607)
*Anurag Acharya,Timothy Vega,Rizwan A. Ashraf,Anshu Sharma,Derek Parker,Robert Rallo*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出一个领域无关、模型独立的云端科学助手代理框架，通过监督代理协调多个专业代理，整合文献综述、数据分析、模拟运行等任务，在催化剂研究领域验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学领域应用广泛，但缺乏执行复杂任务（如模拟运行、复杂决策）的能力。基于LLM的代理能够调用外部资源和工具，但构建平衡模型、云提供商和外部资源的工作流程非常困难，阻碍了代理系统的实际部署。

Method: 设计了一个领域无关、模型独立的云端代理框架，采用监督代理（supervisor agent）协调多个具有特定能力的代理。框架整合了从简单的文献综述、数据分析到复杂的模拟运行等任务，并在催化剂研究领域构建了概念验证系统。

Result: 系统在合成基准测试中能够90%的时间将任务路由到正确的代理，97.5%的时间成功完成任务；在真实世界化学基准测试中成功率为91%。与前沿模型相比，达到相当或更好的准确性。同时报告了详细的运营成本分析。

Conclusion: 该框架证明了在云端构建科学助手代理系统的可行性，能够有效协调多个代理完成复杂科学任务，为其他科学领域提供了可复制的解决方案。

Abstract: As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.

</details>


### [125] [Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems](https://arxiv.org/abs/2601.12618)
*Elham Tajik,Conrad Borchers,Bahar Shahrokhian,Sebastian Simon,Ali Keramati,Sonika Pal,Sreecharan Sankaranarayanan*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该论文提出使用LLM多智能体系统的推理轨迹作为过程数据，通过余弦相似度量化智能体间的分歧，将其作为分析信号来提升定性编码的可靠性和解释深度。


<details>
  <summary>Details</summary>
Motivation: 学习分析研究中，定性学生数据（如编码注释或访谈记录）的分析通常依赖人工。随着生成式AI的发展，全自动和人机协作的分析方法出现，但缺乏方法学标准。研究者希望利用LLM智能体的推理轨迹作为新型过程数据，提升定性编码的解释实践。

Method: 使用LLM多智能体系统对辅导对话片段进行编码，收集智能体的推理轨迹。应用余弦相似度量化智能体间的语义推理相似性，系统检测、量化和解释分歧。分析近10,000个智能体对编码实例，将分歧重新定义为有意义的分析信号。

Result: LLM智能体的语义推理相似性能够稳健地区分共识与分歧，并与人类编码可靠性相关。基于该指标的定性分析揭示了代码内的细微教学子功能，以及概念代码本细化的机会。该方法通过量化相似性指标与定性审查相结合，能够改善和加速编码过程中的评分者间信度建立。

Conclusion: 推理轨迹分歧代表了教育研究方法学严谨性和解释深度的宝贵新型分析信号。该方法特别在LLM与人类协作时，通过揭示解释模糊性，有潜力提升定性编码的质量和效率。

Abstract: Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.

</details>


### [126] [BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models](https://arxiv.org/abs/2601.12632)
*Kriti Bhattarai,Vipina K. Keloth,Donald Wright,Andrew Loza,Yang Ren,Hua Xu*

Main category: cs.CL

Relevance: 75.0

TL;DR: BioPulse-QA：一个基于最新生物医学文档（药物标签、试验方案、临床指南）的问答基准，包含2280个专家验证的QA对及扰动变体，用于评估LLMs在动态、高风险的生物医学知识上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学基准存在局限性：依赖静态/过时数据集，无法捕捉动态、上下文丰富的生物医学知识；存在数据泄露风险（与预训练语料重叠）；忽略语言变异鲁棒性和人口统计偏差等关键维度。

Method: 构建BioPulse-QA基准，包含2280个专家验证的QA对（抽取式和抽象式），基于最新发布的生物医学文档（药物标签、试验方案、临床指南）。评估GPT-4o、GPT-o1、Gemini-2.0-Flash和LLaMA-3.1 8B Instruct等LLMs。

Result: GPT-o1在药物标签上获得最高松弛F1分数（0.92），Gemini-2.0-Flash次之（0.90）。临床试验是最具挑战性的来源，抽取式F1分数低至0.36。改写比拼写错误带来的性能差异更大，偏差测试显示差异可忽略。

Conclusion: BioPulse-QA为评估生物医学LLMs提供了一个可扩展且临床相关的框架，能更好地评估模型在动态、高风险生物医学知识上的实际表现。

Abstract: Objective: Large language models (LLMs) are increasingly applied in biomedical settings, and existing benchmark datasets have played an important role in supporting model development and evaluation. However, these benchmarks often have limitations. Many rely on static or outdated datasets that fail to capture the dynamic, context-rich, and high-stakes nature of biomedical knowledge. They also carry increasing risk of data leakage due to overlap with model pretraining corpora and often overlook critical dimensions such as robustness to linguistic variation and potential demographic biases.
  Materials and Methods: To address these gaps, we introduce BioPulse-QA, a benchmark that evaluates LLMs on answering questions from newly published biomedical documents including drug labels, trial protocols, and clinical guidelines. BioPulse-QA includes 2,280 expert-verified question answering (QA) pairs and perturbed variants, covering both extractive and abstractive formats. We evaluate four LLMs - GPT-4o, GPT-o1, Gemini-2.0-Flash, and LLaMA-3.1 8B Instruct - released prior to the publication dates of the benchmark documents.
  Results: GPT-o1 achieves the highest relaxed F1 score (0.92), followed by Gemini-2.0-Flash (0.90) on drug labels. Clinical trials are the most challenging source, with extractive F1 scores as low as 0.36.
  Discussion and Conclusion: Performance differences are larger for paraphrasing than for typographical errors, while bias testing shows negligible differences. BioPulse-QA provides a scalable and clinically relevant framework for evaluating biomedical LLMs.

</details>


### [127] [Augmenting Question Answering with A Hybrid RAG Approach](https://arxiv.org/abs/2601.12658)
*Tianyi Yang,Nashrah Haque,Vaishnave Jonnalagadda,Yuya Jeremy Ong,Zhehui Chen,Yanzhao Wu,Lei Yu,Divyesh Jadav,Wenqi Wei*

Main category: cs.CL

Relevance: 75.0

TL;DR: SSRAG是一种混合架构，通过查询增强、智能路由和结合向量与图检索的结构化检索机制，提升RAG在问答任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在检索上下文相关信息时存在困难，导致答案不完整或次优，需要改进检索过程以提升问答质量。

Method: 提出结构化语义RAG(SSRAG)混合架构，整合查询增强、智能路由、以及结合向量检索和图检索的结构化检索机制，并进行上下文统一。

Result: 在TruthfulQA、SQuAD和WikiQA三个数据集上，对五个大语言模型进行评估，SSRAG相比标准RAG实现一致提升了响应质量。

Conclusion: SSRAG通过改进检索过程和上下文基础，提高了答案准确性和信息丰富度，为RAG系统提供了有效的增强方案。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.

</details>


### [128] [SciCoQA: Quality Assurance for Scientific Paper--Code Alignment](https://arxiv.org/abs/2601.12910)
*Tim Baumgärtner,Iryna Gurevych*

Main category: cs.CL

Relevance: 75.0

TL;DR: SciCoQA是一个用于检测科学论文与代码库之间差异的数据集，包含611个真实和合成的论文-代码差异案例，涵盖AI、物理、定量生物学等多个领域。该任务对LLM具有挑战性，最佳模型GPT-5仅能检测45.7%的真实差异。


<details>
  <summary>Details</summary>
Motivation: 确保科学论文与代码实现之间的一致性对于可复现性至关重要。当前缺乏系统检测论文与代码差异的方法，作者旨在构建一个数据集来评估和提升LLM在此任务上的能力。

Method: 从GitHub问题和可复现性论文中收集真实差异，并提出合成数据生成方法来扩展数据集。详细分析差异类型和类别，构建包含611个差异案例的数据集（81个真实，530个合成）。评估了21个LLM在检测这些差异上的表现。

Result: SciCoQA任务对LLM具有显著挑战性，特别是在处理省略论文细节、长上下文输入和预训练语料库外数据的情况下。GPT-5表现最佳，但仅能检测45.7%的真实世界论文-代码差异，表明当前LLM在此任务上仍有很大提升空间。

Conclusion: 论文-代码差异检测是一个重要但具有挑战性的任务，需要专门的数据集和方法。SciCoQA为评估和改进LLM在此领域的能力提供了基准，揭示了当前模型的局限性。

Abstract: We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\% of real-world paper-code discrepancies.

</details>


### [129] [Pardon? Evaluating Conversational Repair in Large Audio-Language Models](https://arxiv.org/abs/2601.12973)
*Shuanghong Huang,Jinlei Xu,Youchao Zhou,Yanghao Zhou,Xuan Zhao,Chong Feng,Wenxuan Zhang*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该论文提出了针对大型音频语言模型的修复感知评估框架，重点关注可回答与不可回答音频输入的区分，并引入EAR评分来联合评估任务能力和修复行为。


<details>
  <summary>Details</summary>
Motivation: 现有的大型音频语言模型评估主要关注答案准确性和对声学扰动的鲁棒性，但假设语音输入在语义上总是可回答的。这一假设在现实交互中经常失败，因为可能缺少关键信息。需要评估模型识别不可回答输入并启动适当对话修复的能力。

Method: 1) 引入修复感知评估设置，明确区分可回答和不可回答音频输入；2) 将可回答性定义为输入本身的属性；3) 使用语义-声学掩蔽协议构建配对评估条件；4) 提出EAR评分，这是一个非补偿性指标，联合评估可回答条件下的任务能力和不可回答条件下的修复行为。

Result: 在两个口语问答基准测试中，不同LALM模型显示出答案准确性和对话可靠性之间的持续差距：许多模型在输入可回答时表现良好，但大多数无法识别语义不可回答性并启动适当的对话修复。

Conclusion: 当前以准确性为中心的评估实践存在局限性，需要将不可回答输入视为修复和持续交互线索的可靠性评估。EAR评分提供了更全面的评估框架。

Abstract: Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.

</details>


### [130] [ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation](https://arxiv.org/abs/2601.12983)
*Jesus-German Ortiz-Barajas,Jonathan Tonglet,Vivek Gupta,Iryna Gurevych*

Main category: cs.CL

Relevance: 75.0

TL;DR: ChartAttack框架评估多模态大语言模型生成误导性图表的风险，通过注入误导设计元素来诱导错误数据解读，显著降低图表问答准确率。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型越来越多地用于从数据表自动生成图表，虽然提高了数据分析效率，但也引入了新的滥用风险。本研究旨在评估MLLMs如何被滥用来大规模生成误导性图表，揭示现有系统的安全漏洞。

Method: 提出ChartAttack框架，通过向图表设计中注入误导元素来诱导对底层数据的错误解读。同时创建AttackViz数据集，包含标注了有效误导元素及其诱导错误答案的（图表规范，问答）对。在领域内和跨领域设置中进行实验，并通过人类研究验证效果。

Result: ChartAttack显著降低了MLLM阅读器的问答性能，领域内设置准确率平均下降19.6个百分点，跨领域设置下降14.9个百分点。人类研究显示参与者面对误导性图表时准确率平均下降20.2个百分点。

Conclusion: 研究结果强调了在MLLM图表生成系统的设计、评估和部署中迫切需要加强鲁棒性和安全性考虑。公开代码和数据以促进相关研究。

Abstract: Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.

</details>


### [131] [Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs](https://arxiv.org/abs/2601.13099)
*Abdellah El Mekki,Samar M. Magdy,Houdaifa Atou,Ruwa AbuHweidi,Baraah Qawasmeh,Omer Nacar,Thikra Al-hibiri,Razan Saadie,Hamzah Alsayadi,Nadia Ghezaiel Hammouda,Alshima Alkhazimi,Aya Hamod,Al-Yas Al-Ghafri,Wesam El-Sayed,Asila Al sharji,Mohamad Ballout,Anas Belfathi,Karim Ghaddar,Serry Sibaee,Alaa Aoun,Areej Asiri,Lina Abureesh,Ahlam Bashiti,Majdal Yousef,Abdulaziz Hafiz,Yehdih Mohamed,Emira Hamedtou,Brakehe Brahim,Rahaf Alhamouri,Youssef Nafea,Aya El Aatar,Walid Al-Dhabyani,Emhemed Hamed,Sara Shatnawi,Fakhraddin Alwajih,Khalid Elkhidir,Ashwag Alasmari,Abdurrahman Gerrio,Omar Alshahri,AbdelRahim A. Elmadany,Ismail Berrada,Amir Azad Adli Alkathiri,Fadi A Zaraket,Mustafa Jarrar,Yahya Mohamed El Hadj,Hassan Alhuzali,Muhammad Abdul-Mageed*

Main category: cs.CL

Relevance: 75.0

TL;DR: Alexandria是一个大规模、社区驱动、人工翻译的数据集，旨在解决阿拉伯语方言机器翻译的挑战，覆盖13个阿拉伯国家和11个高影响力领域，提供城市级元数据粒度。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语是高度双言制语言，日常交流主要使用地区方言而非现代标准阿拉伯语。尽管存在这一现实，机器翻译系统对方言输入泛化能力差，限制了其对数百万使用者的实用性。

Method: 构建Alexandria数据集：1) 覆盖13个阿拉伯国家和11个高影响力领域；2) 提供城市级元数据粒度，超越粗略的地区标签；3) 包含多轮对话场景，标注说话者-受话者性别配置；4) 总计107K样本。

Result: 数据集既可作为训练资源，也可作为评估机器翻译和大型语言模型的严格基准。通过自动和人工评估阿拉伯语感知的LLMs，展示了当前跨阿拉伯语方言和次方言翻译的能力，同时暴露了持续存在的重大挑战。

Conclusion: Alexandria填补了阿拉伯语方言翻译资源的空白，为研究和开发更有效的方言机器翻译系统提供了重要基础，同时揭示了当前模型在方言处理方面的局限性。

Abstract: Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.

</details>


### [132] [Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision](https://arxiv.org/abs/2601.13217)
*Bingsen Chen,Boyan Li,Ping Nie,Yuyu Zhang,Xi Ye,Chen Zhao*

Main category: cs.CL

Relevance: 75.0

TL;DR: 本文提出Mr Dre评估套件，用于评估深度研究代理在多轮报告修订中的能力，发现现有代理在修订时会破坏先前内容，且难以通过提示工程等简单方法解决


<details>
  <summary>Details</summary>
Motivation: 现有深度研究代理评估基准将报告生成视为单次写作任务，与人类研究者通过自我反思或同行反馈迭代起草和修订报告的方式存在根本差异。深度研究代理能否可靠地根据用户反馈修订报告尚未被探索。

Method: 引入Mr Dre评估套件，包括：(1) 统一的涵盖全面性、事实性和呈现性的长报告评估协议；(2) 用于多轮修订的人类验证反馈模拟管道。分析了五个不同的深度研究代理。

Result: 分析发现关键局限性：虽然代理能处理大部分用户反馈，但也会破坏16-27%先前已覆盖的内容和引用质量。即使最佳性能代理在多轮修订中仍存在显著改进空间，会破坏反馈范围外的内容且无法保留早期编辑。

Conclusion: 多轮报告修订是深度研究代理的重要评估维度，现有代理在这方面存在系统性缺陷，且这些缺陷难以通过推理时修复（如提示工程或专门的修订子代理）轻易解决。

Abstract: Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.

</details>


### [133] [Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph](https://arxiv.org/abs/2601.13251)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出大规模语义聚类系统，解决神经嵌入无法区分同义词与反义词的问题，通过三路语义关系判别器和软到硬聚类算法生成290万个高精度语义簇。


<details>
  <summary>Details</summary>
Motivation: 神经嵌入存在一个显著盲点：无法可靠地区分同义词和反义词。这导致增加相似度阈值往往无法防止对立词被错误分组，特别是在形态丰富和低资源语言中，现有同义词数据库稀疏，需要更精确的语义聚类方法。

Method: 1) 构建84.3万个概念对的标注数据集，涵盖同义、反义和共下位关系，使用Gemini 2.5-Flash LLM增强并通过人工词典资源验证；2) 提出专门的三路语义关系判别器，实现90%的宏F1分数；3) 引入新颖的软到硬聚类算法，采用拓扑感知的两阶段扩展-剪枝过程与拓扑投票，防止语义漂移和错误传递链。

Result: 系统处理了1500万个词汇项，评估了5.2亿个潜在关系，最终生成了290万个高精度语义簇。三路语义关系判别器达到90%宏F1分数，聚类算法有效防止了语义漂移并解决了多义性问题。

Conclusion: 该方法解决了神经嵌入在区分同义词和反义词方面的根本缺陷，为高精度语义搜索和检索增强生成提供了有效资源，特别适用于形态丰富和低资源语言。

Abstract: Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.

</details>


### [134] [Reducing Tokenization Premiums for Low-Resource Languages](https://arxiv.org/abs/2601.13328)
*Geoffrey Churchill,Steven Skiena*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该论文分析了低资源语言在大型语言模型中的分词溢价问题，并提出了一种通过后处理增加词汇表来减少分词溢价的方法。


<details>
  <summary>Details</summary>
Motivation: 相对于英语，低资源语言在现代语言模型中面临显著的分词溢价问题，导致API和能源成本增加，有效上下文窗口减少。这限制了低资源语言在LLM应用中的公平性和效率。

Method: 分析了10个流行语言模型的分词器设计，提出了一种后处理方法：通过向预训练模型的词汇表中添加多字符组合的单一标记，将低资源语言中的多标记字符序列压缩为单个标记。

Result: 在12种低资源语言上应用该方法，使用Llama 3.2 1B模型验证，发现原始输入和压缩输入通常具有相似的最终隐藏状态，表明该方法有效且对模型表示影响较小。

Conclusion: 该方法能够有效减少低资源语言的分词溢价，提高计算效率和上下文利用率，为多语言LLM的公平性和效率优化提供了实用解决方案。

Abstract: Relative to English, low-resource languages suffer from substantial tokenization premiums in modern LMs, meaning that it generally requires several times as many tokens to encode a sentence in a low-resource language than to encode the analogous sentence in English. This tokenization premium results in increased API and energy costs and reduced effective context windows for these languages. In this paper we analyze the tokenizers of ten popular LMs to better understand their designs and per-language tokenization premiums. We also propose a mechanism to reduce tokenization premiums in pre-trained models, by post-hoc additions to the token vocabulary that coalesce multi-token characters into single tokens. We apply this methodology to 12 low-resource languages, demonstrating that the original and compressed inputs often have similar last hidden states when run through the Llama 3.2 1B model.

</details>


### [135] [On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation](https://arxiv.org/abs/2601.13729)
*Weichuan Wang,Mingyang Liu,Linqi Song,Chen Ma*

Main category: cs.CL

Relevance: 75.0

TL;DR: 本文系统评估了机器翻译中的非确定性现象，发现温度约束下的非确定性MT能产生更高质量的候选翻译，但现有D-MT评估框架无法一致评估ND-MT性能，提出了ExpectoSample策略自动评估指标可靠性。


<details>
  <summary>Details</summary>
Motivation: 语言模型的非确定性特性在现实应用中影响显著，但在机器翻译这一复杂的非确定性NLP任务中尚未充分探索。研究旨在系统评估现代MT系统的非确定性现象，并解决由此带来的评估挑战。

Method: 1) 识别温度约束下的非确定性MT现象；2) 评估5个最先进的ND-MT系统在3个开放数据集上的表现；3) 使用基于词汇和基于语义的指标在不同采样规模下进行评估；4) 提出ExpectoSample策略自动评估指标可靠性。

Result: 1) ND-MT在温度约束下比确定性MT产生更高质量的候选翻译；2) 现有D-MT评估框架对ND-MT产生不一致的评估结果；3) 发现"水桶效应"：ND-MT生成的最低质量候选翻译决定了系统在不同采样规模下的整体排名；4) ExpectoSample策略能有效评估指标可靠性。

Conclusion: ND-MT在解决机器翻译的多模态问题方面具有潜力，但需要新的评估框架来准确评估其性能。提出的ExpectoSample策略为选择稳健的ND-MT系统提供了有效工具。

Abstract: In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.

</details>


### [136] [Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues](https://arxiv.org/abs/2601.13742)
*Arjun Chandra,Kevin Miller,Venkatesh Ravichandran,Constantinos Papayiannis,Venkatesh Saligrama*

Main category: cs.CL

Relevance: 75.0

TL;DR: TRACE框架让LLM能够通过音频线索进行推理，实现低成本、与人类对齐的语音到语音评估，超越昂贵的音频语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前语音到语音(S2S)自动评估方法依赖昂贵且不透明的音频语言模型(ALMs)，而具有强大推理能力的LLM只能处理文本内容。需要一种成本效益高且与人类对齐的S2S评估方法。

Method: 提出TRACE框架：1) 引入人类思维链(HCoT)标注协议，将评估分为内容、语音质量和副语言三个维度；2) 构建音频信号的文本蓝图；3) 让LLM进行维度判断，通过确定性策略融合为总体评分。

Result: TRACE在人类评分者一致性方面优于ALMs和仅基于转录的LLM评估，同时显著更经济高效。

Conclusion: TRACE框架实现了可扩展、与人类对齐的S2S评估，将发布HCoT标注和TRACE框架以促进该领域发展。

Abstract: Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.

</details>


### [137] [AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization](https://arxiv.org/abs/2601.13918)
*Yusheng Liao,Chuan Xuan,Yutong Cai,Lina Yang,Zhe Chen,Yanfeng Wang,Yu Wang*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出了AgentEHR基准和RetroSum框架，用于解决LLM在原始、高噪声电子健康记录数据库中进行复杂决策和长程交互推理的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在医疗领域的应用主要依赖精心整理的输入和简化的检索任务，无法适应真实临床环境中原始、高噪声的电子健康记录数据库，限制了其在自主导航和复杂决策任务中的应用。

Method: 提出了AgentEHR基准测试复杂决策任务，并开发了RetroSum框架，该框架结合了回顾性总结机制和演化经验策略，通过动态重新评估交互历史来防止信息丢失，并从记忆库中检索积累的经验来弥合领域差距。

Result: RetroSum在AgentEHR基准上实现了高达29.16%的性能提升，同时将总交互错误减少了高达92.3%，显著优于现有基线方法。

Conclusion: RetroSum框架通过创新的回顾性总结和演化经验策略，有效解决了LLM在原始电子健康记录数据库中进行复杂决策时的信息丢失和推理连续性问题，为医疗领域的自主智能系统提供了实用解决方案。

Abstract: Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.

</details>


### [138] [HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs](https://arxiv.org/abs/2601.13919)
*Yuezhe Yang,Hao Wang,Yige Peng,Jinman Kim,Lei Bi*

Main category: cs.CL

Relevance: 75.0

TL;DR: HyperWalker是一个通过动态超图建模和测试时训练的深度诊断框架，用于整合多模态临床数据和电子健康记录，实现更准确的临床诊断。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型主要采用样本隔离的推理范式，独立处理病例而无法访问纵向电子健康记录或结构相关的患者示例，限制了仅基于图像信息的推理，忽略了外部补充医学证据。

Method: 1) 构建动态超图iBrochure建模EHR数据的结构异质性和多模态临床信息的高阶关联；2) 强化学习智能体Walker在超图中导航寻找最优诊断路径；3) 引入linger机制，采用多跳正交检索策略迭代选择反映不同临床属性的互补邻域病例。

Result: 在MIMIC数据集上的医学报告生成和EHRXQA上的医学视觉问答任务中，HyperWalker实现了最先进的性能。

Conclusion: HyperWalker通过动态超图和测试时训练，有效整合多模态临床数据和电子健康记录，克服了传统样本隔离推理的限制，提升了临床诊断的准确性。

Abstract: Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \textbf{HyperWalker}, a \textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker

</details>


### [139] [Automatic Prompt Optimization for Dataset-Level Feature Discovery](https://arxiv.org/abs/2601.13922)
*Adrian Cosma,Oleg Szehr,David Kletz,Alessandro Antonucci,Olivier Pelletier*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出多智能体提示优化框架，用于从无结构文本中自动发现可解释的判别性特征，将特征发现定义为数据集级提示优化问题


<details>
  <summary>Details</summary>
Motivation: 当前从无结构文本中提取特征的方法主要依赖手工设计的提示或固定特征模式，缺乏自动化的特征发现机制。需要一种能够从标记文本语料库中自动发现全局、可解释且具有判别性的特征定义的方法。

Method: 提出多智能体提示优化框架，其中语言模型智能体共同执行：1) 提出特征定义，2) 提取特征值，3) 使用数据集级性能和可解释性反馈评估特征质量。通过结构化反馈迭代优化指令提示，优化诱导共享特征集的提示而非单样本预测。

Result: 该方法与依赖单样本监督的传统提示优化方法不同，为从无结构文本中自动特征发现提供了原则性机制。通过数据集级优化实现全局特征集的发现。

Conclusion: 该框架将特征发现重新定义为数据集级提示优化问题，通过多智能体协作和结构化反馈实现了自动化的特征发现，为文本分类等下游任务提供了更有效的特征提取方法。

Abstract: Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.

</details>


### [140] [Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law](https://arxiv.org/abs/2601.14160)
*Ali Hamza Bashir,Muhammad Rehan Khalid,Kostadin Cvejoski,Jana Birr,Jule Berghaus,Armin Berger,Sandra Halscheidt,Christian Temath,Rafet Sifa,David Berghaus*

Main category: cs.CL

Relevance: 75.0

TL;DR: 本文提出了一种通过合成数据生成方法，将先进LLMs适配到德国法律问答领域的技术，使用权威法规自动生成高质量问答对，显著提升了LLMs在法律领域的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专业领域（如法律推理）中表现不佳，因为缺乏专家知识，导致事实错误或幻觉。现有方法依赖昂贵的人工标注或不可靠的合成数据，需要一种更有效的方法来适应专业领域。

Method: 提出新颖的合成数据生成方法，直接从权威德国法规中系统生成高质量、多样且法律准确的问答对。采用严格的自动过滤方法和参数高效微调技术，使用合成数据集对LLMs进行适配。

Result: 使用合成数据集适配的LLMs在德国法律问答任务上显著优于基线模型，证明了精心设计的合成数据可以作为人工标注的可靠替代方案。

Conclusion: 在知识密集型的高风险领域，通过系统化合成数据生成方法可以有效适配LLMs，为专业领域应用提供了可行的技术路径。

Abstract: Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.

</details>


### [141] [MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems](https://arxiv.org/abs/2601.14230)
*Yiyang Wang,Yiqiao Jin,Alex Cabral,Josiah Hester*

Main category: cs.CL

Relevance: 75.0

TL;DR: MASCOT是一个多智能体社会协作框架，通过双层优化策略解决角色崩溃和社会谄媚问题，提升角色一致性和社会贡献度。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统存在两个主要问题：1) 角色崩溃 - 智能体退化为通用的、同质化的助手行为；2) 社会谄媚 - 产生冗余、非建设性的对话。这些问题限制了多智能体系统在情感和认知支持方面的实际应用效果。

Method: 提出MASCOT框架，采用双层优化策略：1) 角色感知行为对齐 - 基于RLAIF的流程，微调个体智能体以保持严格角色保真度；2) 协作对话优化 - 基于群体级奖励的元策略，确保多样化和富有成效的对话。

Result: 在心理支持和职场领域的大规模评估显示，MASCOT显著优于现有基线方法，在角色一致性方面提升高达+14.1，在社会贡献度方面提升+10.6。

Conclusion: MASCOT为构建下一代社会智能多智能体系统提供了实用的技术路线图，有效解决了角色崩溃和社会谄媚问题。

Abstract: Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.

</details>


### [142] [APEX-Agents](https://arxiv.org/abs/2601.14242)
*Bertie Vidgen,Austin Mann,Abby Fennelly,John Wright Stanly,Lucas Rothman,Marco Burstein,Julien Benchek,David Ostrofsky,Anirudh Ravichandran,Debnil Sur,Neel Venugopal,Alannah Hsia,Isaac Robinson,Calix Huang,Olivia Varones,Daniyal Khan,Michael Haines,Zach Richards,Chirag Mahapatra,Brendan Foody,Osvald Nitski*

Main category: cs.CL

Relevance: 75.0

TL;DR: APEX-Agents是一个评估AI代理执行投资银行、管理咨询和法律领域长时程跨应用任务的基准测试，包含真实工作环境和工具，Gemini 3 Flash表现最佳(24.0%)


<details>
  <summary>Details</summary>
Motivation: 现有AI代理基准测试主要关注简单任务或特定领域，缺乏对专业领域长时程、跨应用复杂任务的评估能力。需要创建能够模拟真实工作环境、包含文件和工具使用的基准来评估AI代理在实际专业工作场景中的生产力。

Method: 创建APEX-Agents基准，包含480个由投资银行分析师、管理顾问和公司律师设计的任务。构建真实工作环境，包含文件和工具。使用Pass@1指标测试8个代理，包括Gemini、GPT和Claude等模型。开源基准数据和Archipelago基础设施用于代理执行和评估。

Result: Gemini 3 Flash (Thinking=High)得分最高(24.0%)，其次是GPT-5.2 (Thinking=High)、Claude Opus 4.5 (Thinking=High)和Gemini 3 Pro (Thinking=High)。所有测试代理在复杂专业任务上的表现仍有很大提升空间。

Conclusion: APEX-Agents为评估AI代理在专业领域的长时程跨应用任务能力提供了重要基准。当前最先进的AI代理在复杂专业任务上表现有限，需要进一步改进。开源基准和基础设施将促进该领域的研究发展。

Abstract: We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.

</details>


### [143] [The Stability Trap: Evaluating the Reliability of LLM-Based Instruction Adherence Auditing](https://arxiv.org/abs/2601.11783)
*Murtuza N. Shergadwala*

Main category: cs.SE

Relevance: 75.0

TL;DR: 研究发现LLM-as-a-Judge方法在评估企业GenAI系统时存在"稳定性陷阱"：虽然判决结果高度一致（>99%），但推理过程稳定性差异显著，客观指令的推理稳定性可低至19%，主观指令在35%-83%之间波动。


<details>
  <summary>Details</summary>
Motivation: 在受监管行业（如人力资源）中，企业需要可扩展且可复现的GenAI审计机制。LLM-as-a-Judge方法虽然提供了可扩展性，但其在评估不同类型系统指令时的可靠性尚未得到验证。本研究旨在探究应用测试系统的指令类型如何影响评估的稳定性。

Method: 提出了范围化指令分解框架，将应用测试系统的指令分类为客观型和主观型，以分离导致评估不稳定的因素。将该框架应用于两个代表性的人力资源GenAI应用，评估了四种评估架构在可变运行中的稳定性。

Result: 揭示了"稳定性陷阱"现象：判决稳定性与推理稳定性之间存在分歧。虽然评估者对客观和主观评估都达到了近乎完美的判决一致性（>99%），但他们的推理轨迹却显著不同。客观指令（如字数统计）的推理稳定性可低至约19%，而主观指令的推理稳定性在35%-83%之间波动。专注于离散实体提取的客观指令则实现了高推理稳定性（>90%）。

Conclusion: 高判决稳定性可能掩盖脆弱的推理过程。建议审计人员严格限定自动化评估协议的范围：将所有可确定性验证的逻辑委托给代码，同时保留LLM评估者用于复杂的语义评估。

Abstract: The enterprise governance of Generative AI (GenAI) in regulated sectors, such as Human Resources (HR), demands scalable yet reproducible auditing mechanisms. While Large Language Model (LLM)-as-a-Judge approaches offer scalability, their reliability in evaluating adherence of different types of system instructions remains unverified. This study asks: To what extent does the instruction type of an Application Under Test (AUT) influence the stability of judge evaluations? To address this, we introduce the Scoped Instruction Decomposition Framework to classify AUT instructions into Objective and Subjective types, isolating the factors that drive judge instability. We applied this framework to two representative HR GenAI applications, evaluating the stability of four judge architectures over variable runs. Our results reveal a ``Stability Trap'' characterized by a divergence between Verdict Stability and Reasoning Stability. While judges achieved near-perfect verdict agreement ($>99\%$) for both objective and subjective evaluations, their accompanying justification traces diverged significantly. Objective instructions requiring quantitative analysis, such as word counting, exhibited reasoning stability as low as $\approx19\%$, driven by variances in numeric justifications. Similarly, reasoning stability for subjective instructions varied widely ($35\%$--$83\%$) based on evidence granularity, with feature-specific checks failing to reproduce consistent rationale. Conversely, objective instructions focusing on discrete entity extraction achieved high reasoning stability ($>90\%$). These findings demonstrate that high verdict stability can mask fragile reasoning. Thus, we suggest that auditors scope automated evaluation protocols strictly: delegate all deterministically verifiable logic to code, while reserving LLM judges for complex semantic evaluation.

</details>


### [144] [Bielik 11B v3: Multilingual Large Language Model for European Languages](https://arxiv.org/abs/2601.11579)
*Krzysztof Ociepa,Łukasz Flis,Remigiusz Kinas,Krzysztof Wróbel,Adrian Gwoździej*

Main category: cs.CL

Relevance: 65.0

TL;DR: Bielik 11B v3 是一个针对波兰语优化的先进语言模型，基于Mistral 7B架构扩展到110亿参数，通过四阶段训练流程开发，在波兰语任务上超越其他专业模型和更大规模模型。


<details>
  <summary>Details</summary>
Motivation: 开发针对波兰语优化的高性能语言模型，解决小语种语言在AI领域代表性不足的问题，同时探索资源高效的高性能模型开发方法。

Method: 基于Mistral 7B v0.2架构，通过深度扩展达到110亿参数。采用四阶段训练流程：连续预训练、监督微调(SFT)、直接偏好优化(DPO)和强化学习。

Result: 模型在波兰语任务上表现卓越，显著超越其他波兰语专业模型，并在多种任务上优于参数规模大2-6倍的模型。通过量化选项支持多样化硬件部署。

Conclusion: Bielik 11B v3不仅提升了波兰语的AI能力，还为开发资源高效的高性能小语种模型设立了新基准。

Abstract: We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcement learning.
  Comprehensive evaluations demonstrate that Bielik 11B v3 achieves exceptional performance. It significantly surpasses other specialized Polish language models and outperforms many larger models (with 2-6 times more parameters) on a wide range of tasks, from basic linguistic understanding to complex reasoning.
  The model's parameter efficiency, combined with extensive quantization options, allows for effective deployment across diverse hardware configurations. Bielik 11B v3 not only advances AI capabilities for the Polish language but also establishes a new benchmark for developing resource-efficient, high-performance models for less-represented languages.

</details>


### [145] [Enhancing the QA Model through a Multi-domain Debiasing Framework](https://arxiv.org/abs/2601.11581)
*Yuefeng Wang,ChangJae Lee*

Main category: cs.CL

Relevance: 65.0

TL;DR: 该研究评估了ELECTRA-small模型在SQuAD v1.1和对抗数据集上的表现，识别了词汇偏见、数值推理和实体识别等错误，开发了包含知识蒸馏、去偏技术和领域扩展的多领域去偏框架，在对抗环境中取得了最多2.6个百分点的性能提升。


<details>
  <summary>Details</summary>
Motivation: QA模型在机器阅读理解方面取得了显著进展，但经常表现出偏见，特别是在对抗条件下的复杂查询中。这些偏见会阻碍模型性能，影响自然语言理解系统的鲁棒性和可靠性。

Method: 1) 在SQuAD v1.1和对抗数据集AddSent、AddOneSent上评估ELECTRA-small模型；2) 识别词汇偏见、数值推理和实体识别等错误类型；3) 开发多领域去偏框架，结合知识蒸馏、去偏技术和领域扩展方法。

Result: 在所有测试集上实现了最多2.6个百分点的Exact Match（EM）和F1分数提升，在对抗环境中也取得了显著增益。这表明针对性的偏见缓解策略能够有效增强模型鲁棒性。

Conclusion: 针对性的偏见缓解策略具有增强自然语言理解系统鲁棒性和可靠性的潜力。多领域去偏框架能够有效应对QA模型中的各种偏见问题。

Abstract: Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, we develop a multi-domain debiasing framework incorporating knowledge distillation, debiasing techniques, and domain expansion. Our results demonstrate up to 2.6 percentage point improvements in Exact Match (EM) and F1 scores across all test sets, with gains in adversarial contexts. These findings highlight the potential of targeted bias mitigation strategies to enhance the robustness and reliability of natural language understanding systems.

</details>


### [146] [RAC: Retrieval-Augmented Clarification for Faithful Conversational Search](https://arxiv.org/abs/2601.11722)
*Ahmed Rayane Kebir,Vincent Guigue,Lynda Said Lhadj,Laure Soulier*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出RAC框架，通过检索增强生成基于语料库的澄清问题，确保问题能在可用文档中得到回答，避免生成无依据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有对话搜索系统的澄清问题研究主要关注流畅性和用户意图对齐，但忽视了问题在底层语料库中的可回答性。没有这种基础，系统可能提出无法从可用文档中回答的问题。

Method: 1) 比较多种检索索引策略；2) 微调大语言模型以充分利用检索上下文并生成基于证据的问题；3) 应用对比偏好优化，使生成的问题更倾向于基于检索段落而非无依据的替代方案。

Result: 在四个基准测试中，RAC相比基线方法有显著改进。除了LLM-as-Judge评估外，还引入了基于NLI和数据到文本的新指标来评估问题在上下文中的锚定程度，证明该方法能持续增强忠实性。

Conclusion: RAC框架通过检索增强和对比偏好优化，能够生成更忠实于语料库的澄清问题，解决了现有方法中问题无依据的风险。

Abstract: Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.

</details>


### [147] [Industry-Aligned Granular Topic Modeling](https://arxiv.org/abs/2601.11762)
*Sae Young Moon,Myeongjun Erik Jang,Haoyan Luo,Chunyang Xiao,Antonios Georgiadis,Fran Silavong*

Main category: cs.CL

Relevance: 65.0

TL;DR: TIDE是一个基于大语言模型的细粒度主题建模框架，提供主题建模、长文档摘要、主题层级关系构建和蒸馏等功能，在工业业务场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 主题建模在文本挖掘和数据分析中有广泛应用，但现有方法在生成细粒度主题方面的能力尚未得到充分探索。细粒度主题对于商业应用具有重要价值，能提供更深入的洞察。

Method: 提出TIDE框架，核心是基于大语言模型的新型细粒度主题建模方法，同时包含长文档摘要、主题层级关系构建（topic parenting）和蒸馏等辅助功能。

Result: 在多种公开和真实业务数据集上的实验表明，TIDE的主题建模方法优于现代主题建模方法，辅助组件为处理工业业务场景提供了有价值的支持。

Conclusion: TIDE框架为工业应用提供了有效的细粒度主题建模解决方案，目前正在开源过程中。

Abstract: Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.

</details>


### [148] [Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation](https://arxiv.org/abs/2601.12061)
*Jinsook Lee,Kirk Vanacore,Zhuqian Zhou,Jeanine Grutter,Rene F. Kizilcec*

Main category: cs.CL

Relevance: 65.0

TL;DR: 论文提出了一种基于代码本注入的分割方法，通过将边界决策与下游标注标准相结合来改进对话行为标注中的分割问题，并评估了LLM分割器与传统方法的性能差异。


<details>
  <summary>Details</summary>
Motivation: 传统对话行为标注通常将交际或教学意图局限于单个话语或轮次，导致标注者在底层动作上达成一致但在片段边界上存在分歧，降低了标注的可靠性。

Method: 提出代码本注入分割方法，将边界决策与下游标注标准相结合；评估LLM分割器与标准和检索增强基线的性能；引入无金标准标签的评估指标：跨度一致性、区分度和人机分布一致性。

Result: DA感知分割产生的片段内部一致性优于纯文本基线；LLM擅长创建结构一致的跨度，但基于连贯性的基线在检测对话流全局变化方面更优；两个数据集中没有单一分割器占主导；片段内连贯性的提升常以边界区分度和人机分布一致性为代价。

Conclusion: 分割是一个重要的设计选择，应根据下游目标进行优化，而不是追求单一性能分数。

Abstract: Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.

</details>


### [149] [Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning](https://arxiv.org/abs/2601.12535)
*Ahmed Attia,Alham Fikri*

Main category: cs.CL

Relevance: 65.0

TL;DR: 该论文提出了一种基于自监督强化学习的低资源机器翻译微调方法，使用NLLB模型进行往返翻译引导，通过chrF++和BLEU作为奖励函数，在多种低资源语言上取得了翻译质量的提升。


<details>
  <summary>Details</summary>
Motivation: 低资源机器翻译虽然随着平行数据收集而受到关注，但许多改进方法仍未充分探索。研究者希望利用自监督强化学习来提升低资源语言的翻译质量，特别是在缺乏大规模平行语料的情况下。

Method: 采用基于强化学习的自监督微调方法，使用NLLB模型进行往返翻译引导：先将英语翻译成目标低资源语言，再翻译回英语。使用chrF++和BLEU的组合作为奖励函数，评估重建英语句子的质量。在NLLB-MD数据集上评估600M和1.3B参数的NLLB模型。

Result: 在Central Aymara、Friulian、Wolof和俄语等语言上观察到一致的翻译质量改进。定性分析显示翻译输出的流畅性和语义保真度都有所提高。方法显示出随着模型规模增大而获益的潜力。

Conclusion: 该方法为低资源机器翻译提供了一种有效的自监督微调策略，能够利用预训练知识进行自我改进。随着模型规模扩大，方法效果有望进一步提升。

Abstract: Low-resource machine translation (MT) has gained increasing attention as parallel data from low-resource language communities is collected, but many potential methods for improving low-resource MT remain unexplored. We investigate a self-supervised reinforcement-learning-based fine-tuning for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. Our approach translates English into a target low-resource language and then back into English, using a combination of chrF++ and BLEU as the reward function on the reconstructed English sentences. Using the NLLB-MD dataset, we evaluate both the 600M and 1.3B parameter NLLB models and observe consistent improvements for the following languages: Central Aymara, Friulian, Wolof and Russian. Qualitative inspection of translation outputs indicates increased fluency and semantic fidelity. We argue that our method can further benefit from scale, enabling models to increasingly leverage their pretrained knowledge and continue self-improving.

</details>


### [150] [Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?](https://arxiv.org/abs/2601.12648)
*Nafiz Imtiaz Khan,Kylie Cleland,Vladimir Filkov,Roger Eric Goldman*

Main category: cs.CL

Relevance: 65.0

TL;DR: 该研究评估了LLMs从放射学报告中自动提取结构化程序信息的能力，发现本地和商业模型都能达到接近0.87的F1分数，在速度和成本间存在不同权衡，有望显著减少学员的文书负担。


<details>
  <summary>Details</summary>
Motivation: 放射学培训中的程序病例记录耗时且容易不一致，手动完成效率低下。研究旨在探索LLMs能否直接从自由文本放射学报告中自动化程序病例记录文档，减轻学员的文书负担并提高一致性。

Method: 评估了多个本地和商业LLMs，使用基于指令的提示和思维链提示，从2018-2024年间9名住院医师撰写的414份介入放射学报告中提取结构化程序信息。评估指标包括敏感性、特异性、F1分数，以及推理延迟和令牌效率来估算运营成本。

Result: 本地和商业模型都表现出强大的提取性能，最佳F1分数接近0.87。不同模型在速度和成本方面表现出不同的权衡关系。自动化有潜力显著减少学员的文书负担并提高病例记录的一致性。

Conclusion: LLMs在医学教育中的AI辅助文档记录是可行的，研究结果展示了其在医疗培训中的实际应用潜力，但需要跨机构和临床工作流程的进一步验证。

Abstract: Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.

</details>


### [151] [Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs](https://arxiv.org/abs/2601.12921)
*Adimulya Kartiyasa,Bao Gia Cao,Boyang Li*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出IndoSoSci数据集，包含151个印尼社会科学期刊文章，用于增强LLM对印尼文化的理解。开发了结合事实提取和RAG的方法，在IndoCulture基准上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对印尼文化的理解不足，而本地社会科学期刊包含大量本土视角的文化研究，但这一资源被忽视。需要有效方法将印尼文化知识注入LLM。

Method: 1) 创建IndoSoSci数据集：从151个开源印尼社会科学期刊提取文章段落；2) 提出文化知识注入方法：提取印尼文化相关事实，使用RAG框架，以LLM生成的假设文档作为检索查询。

Result: 1) 提出的方法在IndoCulture基准上显著优于多个强基线；2) 结合IndoSoSci和印尼维基百科，在IndoCulture基准上达到新的SOTA准确率。

Conclusion: 本地社会科学期刊是增强LLM文化理解的重要资源，提出的RAG方法能有效注入文化知识，为多语言文化AI研究提供了新方向。

Abstract: Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.

</details>


### [152] [Profiling German Text Simplification with Interpretable Model-Fingerprints](https://arxiv.org/abs/2601.13050)
*Lars Klöser,Mika Beele,Bodo Kraft*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出了Simplification Profiler诊断工具包，用于生成文本简化模型的多维可解释指纹，通过元评估验证其描述能力，能区分不同模型配置和行为变化。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对LLM文本简化行为的全面、高效、可复现的诊断工具，特别是在数据稀缺的语言环境中，需要更灵活的评估范式来替代传统基于人类偏好的相关性度量。

Method: 开发Simplification Profiler工具包，生成多维可解释的简化文本指纹；通过元评估方法，使用线性分类器测试指纹是否能可靠识别不同模型配置，验证指标的敏感性。

Result: 完整特征集达到71.9%的F1分数，比简单基线提高超过48个百分点；能够区分提示策略的高层行为变化和提示工程的细粒度变化。

Conclusion: Simplification Profiler为开发者提供了细粒度、可操作的分析工具，有助于构建更有效和真正自适应的文本简化系统。

Abstract: While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.

</details>


### [153] [RegCheck: A tool for automating comparisons between study registrations and papers](https://arxiv.org/abs/2601.13330)
*Jamie Cummins,Beth Clarke,Ian Hussey,Malte Elson*

Main category: cs.CL

Relevance: 65.0

TL;DR: RegCheck是一个模块化的LLM辅助工具，用于帮助研究人员、审稿人和编辑比较研究注册与对应论文的一致性，保持人类专家判断在循环中，并生成可共享的报告。


<details>
  <summary>Details</summary>
Motivation: 研究注册对于科学透明性和严谨性很重要，但手动检查注册与论文的一致性既耗时又费力，需要跨格式和跨领域的专业知识。AI的发展为促进这一活动提供了新的可能性。

Method: RegCheck采用模块化设计，使用LLM辅助工具：1）用户确定需要比较的特征；2）系统呈现每个特征最相关的文本；3）促进而非替代人类差异判断；4）生成带有唯一ID的可共享报告；5）设计为跨科学领域和格式适应。

Result: 论文概述了RegCheck的动机、工作流程和设计原则，并讨论了其作为可扩展基础设施的潜力，提供了一个示例用例。

Conclusion: RegCheck是一个有前景的工具，可以促进研究注册的检查过程，保持人类专家在循环中，并支持可重复科学的基础设施建设。

Abstract: Across the social and medical sciences, researchers recognize that specifying planned research activities (i.e., 'registration') prior to the commencement of research has benefits for both the transparency and rigour of science. Despite this, evidence suggests that study registrations frequently go unexamined, minimizing their effectiveness. In a way this is no surprise: manually checking registrations against papers is labour- and time-intensive, requiring careful reading across formats and expertise across domains. The advent of AI unlocks new possibilities in facilitating this activity. We present RegCheck, a modular LLM-assisted tool designed to help researchers, reviewers, and editors from across scientific disciplines compare study registrations with their corresponding papers. Importantly, RegCheck keeps human expertise and judgement in the loop by (i) ensuring that users are the ones who determine which features should be compared, and (ii) presenting the most relevant text associated with each feature to the user, facilitating (rather than replacing) human discrepancy judgements. RegCheck also generates shareable reports with unique RegCheck IDs, enabling them to be easily shared and verified by other users. RegCheck is designed to be adaptable across scientific domains, as well as registration and publication formats. In this paper we provide an overview of the motivation, workflow, and design principles of RegCheck, and we discuss its potential as an extensible infrastructure for reproducible science with an example use case.

</details>


### [154] [AfroScope: A Framework for Studying the Linguistic Landscape of Africa](https://arxiv.org/abs/2601.13346)
*Sang Yun Kwon,AbdelRahim Elmadany,Muhammad Abdul-Mageed*

Main category: cs.CL

Relevance: 65.0

TL;DR: AfroScope是一个统一的非洲语言识别框架，包含覆盖713种非洲语言的数据集和强大的LID模型，采用分层分类方法提高混淆语言的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有语言识别方法对非洲语言覆盖有限，且难以区分密切相关的语言变体，这影响了非洲语言NLP应用的可靠性。需要更全面的非洲语言识别系统来支持非洲语言景观的大规模测量。

Method: 1) 构建AfroScope-Data数据集覆盖713种非洲语言；2) 开发AfroScope-Models语言识别模型套件；3) 提出分层分类方法，利用专门针对29种密切相关的Mirror-Serengeti嵌入模型来提高混淆语言的区分能力。

Result: 分层分类方法在混淆语言子集上相比最佳基础模型将macro F1提高了4.55。分析了跨语言迁移和领域效应，为构建稳健的非洲LID系统提供了指导。

Conclusion: AfroScope框架显著扩展了非洲语言识别能力，通过分层方法有效解决了密切相关语言的区分问题，为非洲语言数字文本的大规模测量提供了关键技术。

Abstract: Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.

</details>


### [155] [PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving](https://arxiv.org/abs/2601.13453)
*Aditya Thole,Anmol Agrawal,Arnav Ramamoorthy,Dhruv Kumar*

Main category: cs.CL

Relevance: 65.0

TL;DR: PSA是一个自主代理，使用Manim动画生成长达6分钟的物理解释视频，通过包含15个定量参数和VLM反馈的评估管道评估视频质量，在32个视频上测试发现系统差异，GPT-5-mini实现100%视频完成率但存在视觉布局不一致等质量问题。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在文本物理问题上表现良好，但生成高质量视觉解释的能力尚未充分探索。数值物理问题需要超越文本的清晰视觉推理来提升概念理解，而现有系统在生成长篇高质量视觉解释方面存在不足。

Method: 引入PhysicsSolutionAgent (PSA)自主代理，使用Manim动画生成物理解释视频；设计评估管道，包含15个定量参数的自动检查，并整合视觉语言模型(VLM)反馈进行迭代质量改进；在32个数值和理论物理问题视频上进行评估。

Result: 使用GPT-5-mini时，PSA实现100%视频完成率，平均自动评分3.8/5；但发现视频质量存在系统差异（问题难度和任务类型影响）；定性分析和人工检查揭示视觉布局不一致、视觉内容解释错误等主要问题。

Conclusion: 研究揭示了可靠Manim代码生成的关键限制，突显了数值物理问题视觉解释中多模态推理和评估的广泛挑战；强调未来多模态教育系统需要改进视觉理解、验证和评估框架。

Abstract: Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems

</details>


### [156] [Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives](https://arxiv.org/abs/2601.13503)
*Kyung Ho Lim,Byung-Hoon Kim*

Main category: cs.CL

Relevance: 65.0

TL;DR: Anonpsy：一种将精神病学叙事去识别化为图引导语义重写的框架，通过语义图编码、图约束扰动和图条件LLM生成，在保持诊断保真度的同时降低重识别风险。


<details>
  <summary>Details</summary>
Motivation: 精神病学叙事不仅包含显式标识符，还包含嵌入临床结构中的独特生活事件。现有的去识别方法（如PHI掩码和LLM合成重写）在文本层面操作，对保留或修改哪些语义元素控制有限。

Method: 1) 将叙事转换为编码临床实体、时间锚点和类型关系的语义图；2) 应用图约束扰动，修改识别上下文同时保留临床关键结构；3) 通过图条件LLM生成重新生成文本。

Result: 在90个临床医生撰写的精神病学案例叙事上评估，Anonpsy在保持诊断保真度的同时，在专家、语义和GPT-5评估下实现一致低重识别风险。相比强LLM重写基线，Anonpsy显著降低语义相似性和可识别性。

Conclusion: 显式结构表示与约束生成相结合，为精神病学叙事去识别提供了有效方法。

Abstract: Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.

</details>


### [157] [Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation](https://arxiv.org/abs/2601.13658)
*Arthur Amalvy,Hen-Hsen Huang*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出一个基于未来预测事实的合成评估数据集，用于时间知识图谱抽取任务，解决现有数据集稀缺和评估数据污染问题


<details>
  <summary>Details</summary>
Motivation: 时间知识图谱抽取对构建大型知识库很重要，但现有训练和评估数据集稀缺，且存在数据污染问题（训练集和评估集重叠），导致LLM性能被高估

Method: 采用两步法：1) 时间知识图谱预测生成未来可能的四元组；2) LLM将四元组转换为文本描述。创建了4.2K个未来四元组及其文本描述

Result: 在提出的数据集上评估EDC框架，发现LLM性能相比已知事实数据集有所下降，证明了数据污染问题的影响

Conclusion: 提出的合成数据集解决了数据污染问题，可作为长期、无污染的TKGE基准，并公开了数据集和生成方法

Abstract: The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.

</details>


### [158] [OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens](https://arxiv.org/abs/2601.13695)
*Sifan Li,Hongkai Chen,Yujun Cai,Liyang Chen,Qingwen Ye,Yiwei Wang*

Main category: cs.CL

Relevance: 65.0

TL;DR: OptiSQL：一个视觉驱动的框架，直接从表格图像和自然语言问题生成可执行SQL，使用紧凑的光学标记替代文本化表格表示，显著减少输入标记数量。


<details>
  <summary>Details</summary>
Motivation: 传统文本到SQL方法需要将表格完全线性化为文本模式，这假设了结构化文本的访问权限并产生大量标记开销，与许多现实场景（表格以视觉形式出现在文档或网页中）不符。研究紧凑光学表示是否能作为可执行语义解析的高效接口。

Method: OptiSQL框架：1）使用OCR导向的视觉编码器将表格结构和内容压缩为一小组光学标记；2）微调预训练解码器进行SQL生成，同时冻结编码器以隔离表示充分性；3）在可视化的Spider 2.0-Snow数据集上进行实验。

Result: OptiSQL在保持强大执行准确性的同时，将表格输入标记减少了一个数量级。鲁棒性分析进一步表明，光学标记在视觉扰动下保留了基本的结构信息。

Conclusion: 紧凑光学表示可以作为可执行语义解析的高效接口，OptiSQL框架在减少输入标记的同时保持了SQL生成质量，为处理视觉表格数据提供了新方法。

Abstract: Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.

</details>


### [159] [Kakugo: Distillation of Low-Resource Languages into Small Language Models](https://arxiv.org/abs/2601.14051)
*Peter Devine,Mardhiyah Sanni,Farid Adilazuarda,Julieta Gil Loizaga,Barry Haddow*

Main category: cs.CL

Relevance: 65.0

TL;DR: Kakugo是一个低成本训练低资源语言小语言模型(SLMs)的管道，仅需语言名称作为输入，使用大教师模型生成合成提示和翻译指令数据集，为54种低资源语言训练模型，总成本低于50美元/语言。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言缺乏高质量训练数据和计算资源的问题，为这些语言社区提供可负担的语言特定AI开发方法。

Method: 使用大型教师模型生成合成提示并翻译指令数据集，创建训练数据，然后训练小语言模型(SLMs)。管道仅需语言名称作为输入，自动完成数据生成和模型训练。

Result: 为54种低资源语言训练了SLMs，在翻译、分类、问答等NLP任务上表现优于基础模型，总生成和训练成本低于50美元/语言。

Conclusion: Kakugo提供了一种经济高效的方法，使语言社区能够开发自己的语言特定AI模型，有助于语言多样性和AI包容性。

Abstract: We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.

</details>


### [160] [A Systematic Analysis of Chunking Strategies for Reliable Question Answering](https://arxiv.org/abs/2601.14123)
*Sofia Bennani,Charles Moslonka*

Main category: cs.CL

Relevance: 65.0

TL;DR: 本文系统研究了文档分块策略对RAG系统可靠性的影响，通过端到端评估发现：重叠分块无显著收益且增加成本；句子分块是最具成本效益的方法；存在"上下文悬崖"现象（超过2.5k token质量下降）；最优上下文长度取决于具体目标。


<details>
  <summary>Details</summary>
Motivation: 工业实践中RAG系统的文档分块通常依赖启发式方法，缺乏系统性评估。本文旨在通过实证研究，为工业部署提供基于证据的分块策略指导，优化检索增强生成系统的可靠性和成本效益。

Method: 在Natural Questions数据集上进行端到端评估，系统性地变化分块方法（token、句子、语义、代码）、分块大小、重叠和上下文长度。采用标准工业设置：SPLADE检索和Mistral-8B生成器。

Result: 发现四个关键结论：1) 重叠分块无显著收益且增加索引成本；2) 句子分块是最具成本效益的方法，在~5k token内与语义分块效果相当；3) 存在"上下文悬崖"现象，超过~2.5k token质量下降；4) 最优上下文长度取决于目标（语义质量在小上下文最佳，精确匹配需要更大上下文）。

Conclusion: 为工业RAG部署提供了基于实证的成本效益优化指导：推荐使用句子分块而非重叠分块，注意上下文长度限制，并根据具体应用目标调整分块策略。

Abstract: We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a "context cliff" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).

</details>


### [161] [Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic](https://arxiv.org/abs/2601.14124)
*Saad Mankarious,Aya Zirikly*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出一种基于扩散模型的文本生成方法，用于缓解心理健康分析中的性别偏见，通过风格转换增强女性作者内容，无需依赖预训练大语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有心理健康分析中合成数据方法主要依赖预训练LLMs，但存在输出多样性有限和传播训练数据偏见的问题。特别是在阿拉伯语心理健康语料中，存在显著的性别不平衡问题，需要增强女性作者内容。

Method: 提出预训练无关的基于扩散模型的合成文本生成方法，将偏见缓解视为风格转换问题。使用CARMA阿拉伯语心理健康语料，构建五个数据集捕捉阿拉伯语中性别表达的不同语言和语义方面，为每个设置训练单独的扩散模型。

Result: 定量评估显示源文本和生成文本之间具有一致的高语义保真度，同时具有有意义的表面风格差异。定性分析确认了语言上合理的性别转换。扩散模型能够生成高熵、语义忠实的合成数据。

Conclusion: 基于扩散的风格转换可以在不依赖预训练LLMs的情况下生成高质量合成数据，为缓解敏感、低资源心理健康领域中的性别偏见提供了有效灵活框架。

Abstract: Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.

</details>


### [162] [Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum](https://arxiv.org/abs/2601.14172)
*Víctor Yeste,Paolo Rosso*

Main category: cs.CL

Relevance: 65.0

TL;DR: 论文研究句子级别的施瓦茨价值动机连续体检测，在新闻和政治宣言的零上下文句子中识别19种人类价值。通过比较层次分类与直接多标签分类，发现轻量级信号和小型集成方法效果最佳，监督编码器在计算受限环境下仍是强基线。


<details>
  <summary>Details</summary>
Motivation: 研究动机是在缺乏上下文线索的新闻和政治宣言句子中，检测细粒度的施瓦茨人类价值。这种设置具有稀疏的道德线索和严重的类别不平衡，使得句子级别的价值检测极具挑战性，即使是现代神经模型也难以应对。

Method: 方法包括：1) 二元道德存在性任务；2) 比较存在性门控层次分类与直接多标签分类器（基于DeBERTa-base）；3) 添加轻量级信号（前句上下文、LIWC-22/eMFD/MJD词典、主题特征）；4) 基准测试指令调优LLM（Gemma 2 9B, Llama 3.1 8B等）的零/少样本和QLoRA设置；5) 构建简单集成模型。

Result: 结果显示：1) 二元道德存在性任务可学习（F1≈0.74）；2) 层次分类未优于直接预测；3) 软投票监督集成达到macro-F1 0.332，显著超越最佳单监督模型和先前基线；4) 轻量级信号和小型集成提供最可靠的改进；5) 在8GB单GPU约束下，监督编码器仍是计算高效的强基线。

Conclusion: 结论认为，在计算受限环境下，精心调优的监督编码器对于结构化人类价值检测仍是强基线。轻量级信号和小型集成提供最可靠的改进，而层次门控收益有限。未来可通过更丰富的价值结构和文档上下文进一步提升性能。

Abstract: We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task ("does any value appear?") and show that it is learnable from single sentences (positive-class F1 $\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.

</details>


### [163] [Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees](https://arxiv.org/abs/2601.12447)
*Mohammed Himayath Ali,Mohammed Aqib Abdullah,Syed Muneer Hussin,Mohammed Mudassir Uddin,Shahnawaz Alam*

Main category: cs.CR

Relevance: 65.0

TL;DR: CryptoFair-FL：首个提供可验证公平性保证的密码学联邦学习框架，结合同态加密和安全多方计算，在保护隐私的同时验证公平性指标。


<details>
  <summary>Details</summary>
Motivation: 联邦学习允许分布式机构协作训练模型而不集中敏感数据，但在异构数据分布下确保算法公平性同时保护隐私仍是一个未解决的根本问题。现有方法无法在隐私保护的前提下提供可验证的公平性保证。

Method: 提出CryptoFair-FL框架，结合加法同态加密和安全多方计算，实现隐私保护的公平性指标验证（人口统计均等和机会均等）。采用新颖的批量验证协议将计算复杂度从O(n²)降低到O(n log n)，同时保持(ε,δ)-差分隐私（ε=0.5，δ=10⁻⁶）。

Result: 在四个基准数据集（MIMIC-IV医疗记录、Adult Income、CelebA和新的FedFair-100基准）上的实验表明，CryptoFair-FL将公平性违规从0.231降低到0.031（人口统计均等差异），计算开销仅为标准联邦平均的2.3倍。成功防御属性推断攻击，对抗成功率保持在0.05以下。

Conclusion: 该框架为在需要隐私保护和算法问责的受监管行业中部署公平感知的联邦学习建立了实用途径，实现了隐私与公平性的近乎最优权衡。

Abstract: Federated learning enables collaborative model training across distributed institutions without centralizing sensitive data; however, ensuring algorithmic fairness across heterogeneous data distributions while preserving privacy remains fundamentally unresolved. This paper introduces CryptoFair-FL, a novel cryptographic framework providing the first verifiable fairness guarantees for federated learning systems under formal security definitions. The proposed approach combines additively homomorphic encryption with secure multi-party computation to enable privacy-preserving verification of demographic parity and equalized odds metrics without revealing protected attribute distributions or individual predictions. A novel batched verification protocol reduces computational complexity from BigO(n^2) to BigO(n \log n) while maintaining (\dparam, \deltap)-differential privacy with dparam = 0.5 and deltap = 10^{-6}. Theoretical analysis establishes information-theoretic lower bounds on the privacy cost of fairness verification, demonstrating that the proposed protocol achieves near-optimal privacy-fairness tradeoffs. Comprehensive experiments across four benchmark datasets (MIMIC-IV healthcare records, Adult Income, CelebA, and a novel FedFair-100 benchmark) demonstrate that CryptoFair-FL reduces fairness violations from 0.231 to 0.031 demographic parity difference while incurring only 2.3 times computational overhead compared to standard federated averaging. The framework successfully defends against attribute inference attacks, maintaining adversarial success probability below 0.05 across all tested configurations. These results establish a practical pathway for deploying fairness-aware federated learning in regulated industries requiring both privacy protection and algorithmic accountability.

</details>


### [164] [FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions](https://arxiv.org/abs/2601.12799)
*Peng Li,Zihan Zhuang,Yangfan Gao,Yi Dong,Sixian Li,Changhao Jiang,Shihan Dou,Zhiheng Xi,Enyu Zhou,Jixuan Huang,Hui Li,Jingjing Gong,Xingjun Ma,Tao Gui,Zuxuan Wu,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang,Xipeng Qiu*

Main category: cs.RO

Relevance: 65.0

TL;DR: FRoM-W1是一个开源框架，通过自然语言实现人形机器人全身运动控制，包含H-GPT（基于大规模人类数据的语言驱动运动生成）和H-ACT（通过强化学习优化的运动控制器）两个阶段


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人的运动通常是硬编码或专门训练的，限制了其通用性。需要一种能够通过自然语言指令控制机器人执行多样化全身运动的方法

Method: 1. H-GPT：利用大规模人类数据训练语言驱动的全身运动生成模型，采用Chain-of-Thought技术提升指令理解泛化能力
2. H-ACT：将生成的人类运动重定向为机器人动作，通过物理模拟中的强化学习预训练和微调，实现稳定执行，并通过仿真到现实的模块化部署

Result: 在HumanML3D-X基准测试中表现出色，在Unitree H1和G1机器人上验证，强化学习微调显著提升了运动跟踪精度和任务成功率

Conclusion: FRoM-W1框架通过结合语言理解和强化学习控制，实现了人形机器人通用全身运动控制，开源该框架有望推动人形智能发展

Abstract: Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and generate corresponding motions, as well as enable various humanoid robots to stably execute these motions in the physical world under gravity, FRoM-W1 operates in two stages: (a) H-GPT: utilizing massive human data, a large-scale language-driven human whole-body motion generation model is trained to generate diverse natural behaviors. We further leverage the Chain-of-Thought technique to improve the model's generalization in instruction understanding. (b) H-ACT: After retargeting generated human whole-body motions into robot-specific actions, a motion controller that is pretrained and further fine-tuned through reinforcement learning in physical simulation enables humanoid robots to accurately and stably perform corresponding actions. It is then deployed on real robots via a modular simulation-to-reality module. We extensively evaluate FRoM-W1 on Unitree H1 and G1 robots. Results demonstrate superior performance on the HumanML3D-X benchmark for human whole-body motion generation, and our introduced reinforcement learning fine-tuning consistently improves both motion tracking accuracy and task success rates of these humanoid robots. We open-source the entire FRoM-W1 framework and hope it will advance the development of humanoid intelligence.

</details>


### [165] [Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings](https://arxiv.org/abs/2601.11565)
*Pakorn Ueareeworakul,Shuman Liu,Jinghao Feng,Ling Hu,Zhantang Shi,Chengqi Sun,Liang Yao,Panyi Ouyang,Haibo Zhang,Anxiang Zeng*

Main category: cs.CL

Relevance: 45.0

TL;DR: Compass-Embedding v4是一个针对东南亚电商场景优化的多语言嵌入框架，通过类感知掩码、多样化训练语料构建和推理优化，解决了低资源语言语义表示的质量问题。


<details>
  <summary>Details</summary>
Motivation: 随着全球电商向新兴市场扩张，低资源语言缺乏高质量语义表示已成为检索、推荐和搜索系统的关键瓶颈。东南亚电商场景面临数据稀缺、噪声监督和严格生产约束等挑战。

Method: 1. 提出类感知掩码(CAM)改进InfoNCE目标，抑制无效批次内负样本；2. 通过上下文合成数据生成、跨语言翻译和结构化电商数据构建多样化训练语料；3. 结合鲁棒性驱动的大批次训练与球面模型融合，并通过vLLM和FP8量化优化推理。

Result: 在多项多语言基准测试和专有电商任务评估中，Compass-Embedding v4在主要东南亚语言上达到最先进性能，在领域特定检索和分类任务中显著优于通用嵌入模型，同时在高资源语言上保持竞争力。

Conclusion: 该框架有效解决了低资源语言在电商场景中的语义表示挑战，通过针对性的方法改进实现了高质量、高效率的多语言嵌入学习。

Abstract: As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production constraints jointly challenge representation learning. Compass-Embedding v4 addresses three core challenges. First, large-batch contrastive training under mixed task supervision introduces systematic false negatives that degrade semantic alignment. We propose Class-Aware Masking (CAM), a lightweight modification to the InfoNCE objective that suppresses invalid in-batch negatives and improves semantic discrimination without altering training efficiency. Second, low-resource SEA languages suffer from limited and uneven data coverage. We construct a diversified training corpus through context-grounded synthetic data generation, cross-lingual translation, and structured e-commerce data construction, enabling robust multilingual and domain-specific learning. Third, production deployment requires high-throughput inference while preserving embedding quality. We combine robustness-driven large-batch training with spherical model merging to mitigate catastrophic forgetting, and optimize inference via vLLM and FP8 quantization. Extensive evaluations across multilingual benchmarks and proprietary e-commerce tasks show that Compass-Embedding v4 achieves state-of-the-art performance on major SEA languages, significantly outperforming general-purpose embedding models in domain-specific retrieval and classification, while maintaining competitive performance on high-resource languages.

</details>


### [166] [GloCTM: Cross-Lingual Topic Modeling via a Global Context Space](https://arxiv.org/abs/2601.11872)
*Nguyen Tien Phat,Ngo Vu Minh,Linh Van Ngo,Nguyen Thi Ngoc Diep,Thien Huu Nguyen*

Main category: cs.CL

Relevance: 45.0

TL;DR: GloCTM是一个新颖的跨语言主题建模框架，通过统一的语义空间强制跨语言主题对齐，显著提升了主题连贯性和跨语言对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有跨语言主题建模方法存在两个主要问题：1）在分离的语言特定空间中学习主题，依赖双语词典等对齐机制，无法捕捉深层次的跨语言语义；2）忽略了多语言预训练表示中丰富的语义信号，限制了细粒度对齐能力。

Method: GloCTM框架包含三个关键组件：1）通过跨语言词汇邻域扩展词袋表示，构建丰富的输入表示；2）使用局部和全局编码器推断主题比例，通过内部正则化对齐其潜在表示；3）在输出层定义在组合词汇表上的全局主题-词分布，结构上同步跨语言主题含义；4）引入中心核对齐（CKA）损失，将潜在主题空间与多语言上下文嵌入对齐。

Result: 在多个基准测试上的实验表明，GloCTM显著提高了主题连贯性和跨语言对齐效果，优于现有强基线方法。

Conclusion: GloCTM通过在整个模型流程中构建统一的语义空间，有效解决了跨语言主题建模中的对齐问题，为多语言理解提供了更强大的工具。

Abstract: Cross-lingual topic modeling seeks to uncover coherent and semantically aligned topics across languages - a task central to multilingual understanding. Yet most existing models learn topics in disjoint, language-specific spaces and rely on alignment mechanisms (e.g., bilingual dictionaries) that often fail to capture deep cross-lingual semantics, resulting in loosely connected topic spaces. Moreover, these approaches often overlook the rich semantic signals embedded in multilingual pretrained representations, further limiting their ability to capture fine-grained alignment. We introduce GloCTM (Global Context Space for Cross-Lingual Topic Model), a novel framework that enforces cross-lingual topic alignment through a unified semantic space spanning the entire model pipeline. GloCTM constructs enriched input representations by expanding bag-of-words with cross-lingual lexical neighborhoods, and infers topic proportions using both local and global encoders, with their latent representations aligned through internal regularization. At the output level, the global topic-word distribution, defined over the combined vocabulary, structurally synchronizes topic meanings across languages. To further ground topics in deep semantic space, GloCTM incorporates a Centered Kernel Alignment (CKA) loss that aligns the latent topic space with multilingual contextual embeddings. Experiments across multiple benchmarks demonstrate that GloCTM significantly improves topic coherence and cross-lingual alignment, outperforming strong baselines.

</details>


### [167] [Bengali Text Classification: An Evaluation of Large Language Model Approaches](https://arxiv.org/abs/2601.12132)
*Md Mahmudul Hoque,Md Mehedi Hassain,Md Hojaifa Tanvir,Rahul Nandy*

Main category: cs.CL

Relevance: 45.0

TL;DR: 研究评估了三种指令调优大语言模型（LLaMA 3.1 8B、LLaMA 3.2 3B、Qwen 2.5 7B）在孟加拉语新闻文章分类任务上的表现，Qwen 2.5以72%准确率表现最佳。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语文本分类面临标注数据稀缺和预训练语言模型不足的挑战，研究旨在探索大语言模型在资源有限语言上的分类能力。

Method: 使用来自Prothom Alo报纸的Kaggle数据集，在相同分类框架下评估三种指令调优LLM：LLaMA 3.1 8B Instruct、LLaMA 3.2 3B Instruct和Qwen 2.5 7B Instruct。

Result: Qwen 2.5获得最高分类准确率72%，在"体育"类别表现尤其突出；LLaMA 3.1和LLaMA 3.2分别获得53%和56%准确率。

Conclusion: 尽管孟加拉语NLP资源稀缺，LLM在孟加拉语文本分类中仍表现出有效性，未来研究将探索更多模型、解决类别不平衡问题并改进微调方法。

Abstract: Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the "Sports" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.

</details>


### [168] [Multimodal Multi-Agent Empowered Legal Judgment Prediction](https://arxiv.org/abs/2601.12815)
*Zhaolu Kang,Junhao Gong,Qingxi Chen,Hao Zhang,Jiaxin Liu,Rong Fu,Zhiyuan Feng,Yuan Wang,Simon Fong,Kaiyue Zhou*

Main category: cs.CL

Relevance: 45.0

TL;DR: JurisMMA是一个用于法律判决预测的新框架，通过分解审判任务、标准化流程并组织成不同阶段来解决传统方法的局限性。作者还构建了包含10万+中国司法记录的JurisMM数据集，包含文本和多模态视频-文本数据。


<details>
  <summary>Details</summary>
Motivation: 传统法律判决预测方法依赖统计分析或基于角色的模拟，在处理多重指控、多样化证据时面临挑战且缺乏适应性。需要更有效的框架来处理复杂的法律案件预测任务。

Method: 提出JurisMMA框架，将审判任务分解、流程标准化并组织成不同阶段。构建了包含超过10万个近期中国司法记录的JurisMM大型数据集，包含文本和多模态视频-文本数据，支持全面评估。

Result: 在JurisMM和基准数据集LawBench上的实验验证了框架的有效性。结果表明该框架不仅对法律判决预测有效，也对更广泛的法律应用具有价值。

Conclusion: JurisMMA框架为法律判决预测提供了新的视角，不仅改进了预测性能，还为未来法律方法和数据集的发展提供了新思路。

Abstract: Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.

</details>


### [169] [Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse](https://arxiv.org/abs/2601.13317)
*Samantha Sudhoff,Pranav Perumal,Zhaoqing Wu,Tunazzina Islam*

Main category: cs.CL

Relevance: 45.0

TL;DR: 提出一个可解释的端到端主题发现与分配框架，用于比较Meta付费广告和Bluesky公共帖子中的气候话语，揭示平台激励如何影响气候叙事的主题结构、立场对齐和时间响应性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常孤立分析不同平台的气候话语，难以区分机构信息与公众表达。需要比较付费广告生态系统（激励针对性战略说服）和公共社交媒体平台（主要是用户驱动的有机话语），以理解平台激励如何塑造气候叙事。

Method: 提出可解释的端到端主题发现与分配框架：1）基于语义相似性聚类文本；2）利用大语言模型生成简洁、人类可解释的主题标签；3）与传统主题建模基线比较，使用人类判断和LLM评估器评估质量；4）通过下游立场预测和主题引导检索任务验证语义连贯性。

Result: 1）框架在主题质量上优于传统主题建模基线；2）揭示了付费气候信息与公共气候话语之间的系统性差异；3）展示了主要政治事件前后主题流行度的变化；4）发现平台级激励反映在气候叙事的主题结构、立场对齐和时间响应性中。

Conclusion: 平台激励显著影响气候叙事的特征，付费广告更注重战略说服，而公共平台更多反映用户驱动的表达。虽然实证分析聚焦气候传播，但所提框架支持跨异构传播环境的比较叙事分析。

Abstract: Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.

</details>


### [170] [HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations](https://arxiv.org/abs/2601.13547)
*Yujia Hu,Roy Ka-Wei Lee*

Main category: cs.CL

Relevance: 45.0

TL;DR: HateXScore是一个用于评估仇恨言论检测模型解释质量的四组件指标套件，旨在揭示标准指标无法发现的解释性失败和标注不一致问题。


<details>
  <summary>Details</summary>
Motivation: 当前仇恨言论检测评估框架很少评估文本被判定为仇恨言论的原因，缺乏对模型解释质量的系统评估方法，这影响了内容审核的透明度和可信度。

Method: 提出HateXScore四组件指标：1)结论明确性；2)引用跨度的忠实性和因果基础；3)受保护群体识别（可配置）；4)这些元素间的逻辑一致性。在六个不同的仇恨言论数据集上进行评估。

Result: HateXScore能够揭示标准指标（如准确率或F1分数）无法发现的解释性失败和标注不一致问题。人类评估显示与HateXScore有很强的一致性，验证了其作为可信透明审核工具的实用性。

Conclusion: HateXScore是一个有效的诊断补充工具，用于评估仇恨言论检测模型的解释质量，有助于提高内容审核的透明度和可信度。

Abstract: Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation.
  \textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}

</details>


### [171] [Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis](https://arxiv.org/abs/2601.13659)
*Chunlei Meng,Ziyang Zhou,Lucas He,Xiaojing Du,Chun Ouyang,Zhongxue Gan*

Main category: cs.CL

Relevance: 45.0

TL;DR: TSDA提出时空解耦再激活框架，在多模态情感分析中显式地将每个模态解耦为时间动态和空间结构上下文，通过因子一致跨模态对齐提升性能


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感分析方法基于模态不变/特定因子分解或复杂融合，仍依赖时空混合建模，忽略了时空异质性，导致时空信息不对称和性能受限

Method: TSDA框架：1) 将每个模态显式解耦为时间动态和空间结构上下文；2) 因子一致跨模态对齐：时间特征仅与跨模态的时间对应物对齐，空间特征仅与空间对应物对齐；3) 因子特定监督和去相关正则化减少跨因子泄漏；4) 门控重耦合模块将对齐的流重新耦合用于任务

Result: 广泛实验表明TSDA优于基线方法，消融分析确认了设计的必要性和可解释性

Conclusion: 显式时空解耦和因子一致对齐能有效解决多模态情感分析中的时空异质性问题，提升模型性能

Abstract: Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.

</details>


### [172] [The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations](https://arxiv.org/abs/2601.13835)
*Sam OConnor Russell,Delphine Charuau,Naomi Harte*

Main category: cs.CL

Relevance: 45.0

TL;DR: 该论文研究了语音转接模型中韵律和词汇线索的作用，发现两者都能独立支持转接预测，为未来仅依赖韵律的隐私友好型模型提供了可能。


<details>
  <summary>Details</summary>
Motivation: 在人类-机器人交互中，流畅的对话转接是关键挑战。虽然自监督语音表示(S3Rs)推动了进展，但尚不清楚基于S3R的转接模型主要依赖韵律线索、词汇线索还是两者兼有。

Method: 提出基于声码器的方法，更清晰地控制语音中的韵律和词汇线索。使用该方法探测基于S3R的语音活动投影模型，在韵律匹配但不可理解的噪声和清晰语音上进行对比实验。

Result: 在韵律匹配的不可理解噪声上的预测准确率与清晰语音相似。表明韵律和词汇线索都能支持转接预测，且可以独立使用。当任一信息被干扰时，模型能利用另一线索而不需额外训练。

Conclusion: 韵律和词汇线索在S3Rs中以有限相互依赖的方式编码。未来模型可能仅需韵律线索，这能提供隐私保护和潜在性能优势。结果在CPC和wav2vec2.0 S3Rs中一致。

Abstract: Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.

</details>


### [173] [Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education](https://arxiv.org/abs/2601.13876)
*Unggi Lee,Jahyun Jeong,Sunyoung Shin,Haeun Park,Jeongsu Moon,Youngchang Song,Jaechang Shim,JaeHwan Lee,Yunju Noh,Seungwon Choi,Ahhyun Kim,TaeHyeon Kim,Kyungtae Joo,Taeyeong Kim,Gyeonggeon Lee*

Main category: cs.CL

Relevance: 45.0

TL;DR: 提出Pedagogical VLA Framework，通过文本修复、LLM蒸馏、安全训练和教学评估四个组件，为资源受限的教育环境开发轻量级且能生成解释性文本的视觉-语言-动作模型。


<details>
  <summary>Details</summary>
Motivation: STEM教育中科学演示很重要，但教师面临安全性和一致性的挑战。当前VLA模型需要大量计算资源，且为追求效率牺牲了语言生成能力，不适合需要可解释性解释系统的资源受限教育环境。

Method: 提出Pedagogical VLA Framework框架，包含四个核心组件：1) 文本修复恢复语言生成能力；2) LLM蒸馏传递教学知识；3) 教育环境安全训练；4) 针对科学教育背景调整的教学评估。在物理、化学、生物、地球科学五个科学演示中评估。

Result: 实验结果表明，Pedagogical VLA Framework在任务性能（成功率、协议合规性、效率、安全性）上与基线模型相当，同时能生成上下文适当的教育解释。通过教师调查和LLM-as-Judge评估验证了教学质量。

Conclusion: 该框架成功解决了资源受限教育环境中VLA模型的应用问题，平衡了任务性能和教学解释生成能力，为STEM教育中的机器人辅助科学演示提供了可行解决方案。

Abstract: Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.

</details>


### [174] [PRiSM: Benchmarking Phone Realization in Speech Models](https://arxiv.org/abs/2601.14046)
*Shikhar Bharadwaj,Chin-Jou Li,Yoonjae Kim,Kwanghee Choi,Eunjung Yeo,Ryan Soh-Eun Shim,Hanyu Zhou,Brendon Boldt,Karen Rosero Jacome,Kalvin Chang,Darsh Agrawal,Keer Xu,Chao-Han Huck Yang,Jian Zhu,Shinji Watanabe,David R. Mortensen*

Main category: cs.CL

Relevance: 45.0

TL;DR: PRiSM是首个开源基准测试，通过内在和外在评估揭示语音识别系统的音素感知盲点，发现多语言训练、编码器-CTC模型稳定性以及专用模型优于大型音频语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前语音识别系统评估仅关注表面转录准确性，缺乏对音素感知能力的深入评估。需要建立标准化基准来评估系统在临床、教育和多语言场景下的实际效用。

Method: PRiSM基准标准化转录评估，通过转录和表示探针评估下游应用。比较不同训练策略（多语言vs单语言）、模型架构（编码器-CTC vs 其他）以及专用模型与大型音频语言模型。

Result: 发现：1）训练时多语言暴露对性能至关重要；2）编码器-CTC模型最稳定；3）专用语音识别模型仍优于大型音频语言模型；4）提供代码、配方和数据集促进领域发展。

Conclusion: PRiSM基准推动领域向具有鲁棒音素能力的多语言语音模型发展，揭示了当前评估方法的局限性，并为系统改进提供了方向。

Abstract: Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism.

</details>


### [175] [CTC-DID: CTC-Based Arabic dialect identification for streaming applications](https://arxiv.org/abs/2601.12199)
*Muhammad Umar Farooq,Oscar Saz*

Main category: cs.CL

Relevance: 40.0

TL;DR: 提出基于CTC损失的方言识别方法，将方言识别任务建模为有限词汇的ASR系统，在低资源阿拉伯方言识别任务中表现优于微调的Whisper和ECAPA-TDNN模型


<details>
  <summary>Details</summary>
Motivation: 解决低资源方言识别问题，将方言识别任务重新定义为类似ASR的序列标注问题，利用CTC损失的优势来处理方言标签序列

Method: 提出CTC-DID方法，将方言标签视为ASR系统的输出序列，使用语言无关启发式方法或预训练ASR模型估计方言标签的重复次数，基于SSL模型进行训练

Result: 在低资源阿拉伯方言识别任务中，CTC-DID方法优于微调的Whisper和ECAPA-TDNN模型，在Casablanca数据集上的零样本评估也表现更好，对短语音更鲁棒，适合流式实时应用

Conclusion: CTC-DID方法为方言识别提供了有效的解决方案，特别适合低资源场景，具有鲁棒性和实时应用潜力

Abstract: This paper proposes a Dialect Identification (DID) approach inspired by the Connectionist Temporal Classification (CTC) loss function as used in Automatic Speech Recognition (ASR). CTC-DID frames the dialect identification task as a limited-vocabulary ASR system, where dialect tags are treated as a sequence of labels for a given utterance. For training, the repetition of dialect tags in transcriptions is estimated either using a proposed Language-Agnostic Heuristic (LAH) approach or a pre-trained ASR model. The method is evaluated on the low-resource Arabic Dialect Identification (ADI) task, with experimental results demonstrating that an SSL-based CTC-DID model, trained on a limited dataset, outperforms both fine-tuned Whisper and ECAPA-TDNN models. Notably, CTC-DID also surpasses these models in zero-shot evaluation on the Casablanca dataset. The proposed approach is found to be more robust to shorter utterances and is shown to be easily adaptable for streaming, real-time applications, with minimal performance degradation.

</details>


### [176] [Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition](https://arxiv.org/abs/2601.13044)
*Warit Sirichotedumrong,Adisai Na-Thalang,Potsawee Manakul,Pittawat Taveekitworachai,Sittipong Sripaisarnmongkol,Kunat Pipatanakul*

Main category: cs.CL

Relevance: 40.0

TL;DR: Typhoon ASR Real-time：一个115M参数的FastConformer-Transducer模型，用于低延迟泰语语音识别，通过严格的文本规范化实现45倍计算成本降低，同时保持与Whisper Large-v3相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前泰语ASR领域被离线架构主导，缺乏高效的流式解决方案。虽然Whisper等大型编码器-解码器模型在离线转录方面表现良好，但由于高延迟而不适用于流式应用。

Method: 1) 使用FastConformer-Transducer架构构建115M参数模型；2) 开发严格的文本规范化管道，解决泰语转录中的系统歧义；3) 采用两阶段课程学习方法进行伊桑方言适应；4) 发布Typhoon ASR Benchmark标准化评估数据集。

Result: 紧凑模型相比Whisper Large-v3实现45倍计算成本降低，同时保持可比的准确性。文本规范化与模型缩放具有同等影响，解决了泰语转录中的系统歧义问题。

Conclusion: 严格的文本规范化可以匹配模型缩放的影响，为泰语ASR提供了高效的流式解决方案。发布的标准化基准将促进泰语ASR研究的可重复性。

Abstract: Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.

</details>


### [177] [Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation](https://arxiv.org/abs/2601.11758)
*Arnab Das Utsa*

Main category: cs.CL

Relevance: 35.0

TL;DR: 本文提出了一种基于社交媒体的透明焦虑检测方法，通过语言可解释的特征建模和跨领域验证，实现了可靠、可泛化且对关键词鲁棒的焦虑检测。


<details>
  <summary>Details</summary>
Motivation: 焦虑影响全球数亿人，但大规模筛查仍有限。社交媒体语言提供了可扩展检测的机会，但现有模型通常缺乏可解释性、关键词鲁棒性验证和严格的用户级数据完整性。

Method: 使用Reddit帖子的大规模数据集，在精心策划的子版块上进行训练、验证和测试分割，训练逻辑回归分类器。包括特征消融、关键词掩码实验、焦虑组与对照组的密度差异分析，并使用临床访谈参与者进行外部验证。

Result: 模型在去除情感或掩码关键词后仍保持高准确率。使用最少帖子历史的早期检测显著优于随机分类，跨领域分析与临床访谈数据表现出强一致性。

Conclusion: 透明语言特征可以支持可靠、可泛化且对关键词鲁棒的焦虑检测。该框架为不同在线环境中的可解释心理健康筛查提供了可复现的基线。

Abstract: Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.

</details>


### [178] [TWeddit : A Dataset of Triggering Stories Predominantly Shared by Women on Reddit](https://arxiv.org/abs/2601.11819)
*Shirlene Rose Bandela,Sanjeev Parthasarathy,Vaibhav Garg*

Main category: cs.CL

Relevance: 35.0

TL;DR: TWeddit是一个标注了触发经历（特别是女性相关创伤）的Reddit数据集，用于研究社交媒体上敏感内容的检测和分类


<details>
  <summary>Details</summary>
Motivation: 社交媒体上用户经常分享流产、性暴力等创伤经历，但缺乏触发警告机制。现有数据集稀缺，需要系统性的标注数据来研究这些敏感内容

Method: 构建TWeddit数据集，收集Reddit上相关创伤经历的帖子，进行人工标注，并进行语言分析和主题建模

Result: 数据集显示标注的故事表达了独特的主题和道德基础，可用于多种未来研究

Conclusion: TWeddit数据集填补了社交媒体创伤内容研究的数据空白，为触发警告系统、内容审核和心理健康支持研究提供了基础

Abstract: Warning: This paper may contain examples and topics that may be disturbing to some readers, especially survivors of miscarriage and sexual violence. People affected by abortion, miscarriage, or sexual violence often share their experiences on social media to express emotions and seek support. On public platforms like Reddit, where users can post long, detailed narratives (up to 40,000 characters), readers may be exposed to distressing content. Although Reddit allows manual trigger warnings, many users omit them due to limited awareness or uncertainty about which categories apply. There is scarcity of datasets on Reddit stories labeled for triggering experiences. We propose a curated Reddit dataset, TWeddit, covering triggering experiences related to issues majorly faced by women. Our linguistic analyses show that annotated stories in TWeddit express distinct topics and moral foundations, making the dataset useful for a wide range of future research.

</details>


### [179] [The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization](https://arxiv.org/abs/2601.11846)
*Natalia Tomashenko,Xiaoxiao Miao,Pierre Champion,Sarina Meyer,Michele Panariello,Xin Wang,Nicholas Evans,Emmanuel Vincent,Junichi Yamagishi,Massimiliano Todisco*

Main category: cs.CL

Relevance: 35.0

TL;DR: 2024年第三届VoicePrivacy挑战赛的结果与分析，专注于语音匿名化技术，旨在隐藏说话人身份的同时保留语言内容和情感状态。


<details>
  <summary>Details</summary>
Motivation: 随着语音技术的普及，保护说话人隐私变得越来越重要。语音匿名化技术需要在隐藏说话人身份的同时，保持语音的实用价值（如内容和情感）。VoicePrivacy挑战赛旨在推动这一领域的研究进展。

Method: 挑战赛提供了系统框架，包括匿名化任务定义、开发与评估数据集、攻击模型和客观评估指标。包含六个基线匿名化系统，并总结了参赛者的创新方法。

Result: 提供了第三届VoicePrivacy挑战赛的全面结果分析，包括不同匿名化系统的性能评估、隐私保护与效用保持的权衡分析，以及技术发展趋势观察。

Conclusion: 挑战赛推动了语音匿名化技术的发展，识别了有前景的研究方向，并为未来挑战赛设计提供了关键见解，有助于构建更有效的隐私保护语音系统。

Abstract: We present results and analyses from the third VoicePrivacy Challenge held in 2024, which focuses on advancing voice anonymization technologies. The task was to develop a voice anonymization system for speech data that conceals a speaker's voice identity while preserving linguistic content and emotional state. We provide a systematic overview of the challenge framework, including detailed descriptions of the anonymization task and datasets used for both system development and evaluation. We outline the attack model and objective evaluation metrics for assessing privacy protection (concealing speaker voice identity) and utility (content and emotional state preservation). We describe six baseline anonymization systems and summarize the innovative approaches developed by challenge participants. Finally, we provide key insights and observations to guide the design of future VoicePrivacy challenges and identify promising directions for voice anonymization research.

</details>


### [180] [Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs](https://arxiv.org/abs/2601.12154)
*Teodor-Călin Ionescu,Lifeng Han,Jan Heijdra Suasnabar,Anne Stiggelbout,Suzan Verberne*

Main category: cs.CL

Relevance: 35.0

TL;DR: 该研究使用神经主题建模（BERTopic）和LLMs（GPT-4）分析癌症患者访谈数据，发现BioClinicalBERT嵌入模型能提高主题精度和可解释性，揭示癌症护理中的协调沟通和患者决策等核心主题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是从患者叙事数据中提取有意义的主题，以促进更以患者为中心的医疗实践。通过分析癌症患者访谈，探索如何利用神经主题建模和LLMs为临床医生提供有价值的患者反馈。

Method: 方法包括：1）比较BERTopic和Top2Vec在单个访谈摘要中的表现；2）使用GPT-4进行主题标注；3）通过人工评估（连贯性、清晰度、相关性）验证结果；4）使用三种临床导向嵌入模型（包括BioClinicalBERT）进行完整数据集分析。

Result: 结果显示：1）BERTopic表现优于Top2Vec；2）领域特定嵌入（特别是BioClinicalBERT）提高了主题精度和可解释性；3）全局分析揭示两个主导主题：癌症护理管理中的协调沟通、癌症治疗旅程中的患者决策。

Conclusion: 结论是神经主题建模（特别是BERTopic）能够从患者访谈中提取有用信息，支持更高效的文档导航，并增强患者声音在医疗工作流程中的作用，尽管存在机器翻译和缺乏临床专业评估的局限性。

Abstract: This study investigates the use of neural topic modeling and LLMs to uncover meaningful themes from patient storytelling data, to offer insights that could contribute to more patient-oriented healthcare practices. We analyze a collection of transcribed interviews with cancer patients (132,722 words in 13 interviews). We first evaluate BERTopic and Top2Vec for individual interview summarization by using similar preprocessing, chunking, and clustering configurations to ensure a fair comparison on Keyword Extraction. LLMs (GPT4) are then used for the next step topic labeling. Their outputs for a single interview (I0) are rated through a small-scale human evaluation, focusing on {coherence}, {clarity}, and {relevance}. Based on the preliminary results and evaluation, BERTopic shows stronger performance and is selected for further experimentation using three {clinically oriented embedding} models. We then analyzed the full interview collection with the best model setting. Results show that domain-specific embeddings improved topic \textit{precision} and \textit{interpretability}, with BioClinicalBERT producing the most consistent results across transcripts. The global analysis of the full dataset of 13 interviews, using the BioClinicalBERT embedding model, reveals the most dominant topics throughout all 13 interviews, namely ``Coordination and Communication in Cancer Care Management" and ``Patient Decision-Making in Cancer Treatment Journey''. Although the interviews are machine translations from Dutch to English, and clinical professionals are not involved in this evaluation, the findings suggest that neural topic modeling, particularly BERTopic, can help provide useful feedback to clinicians from patient interviews. This pipeline could support more efficient document navigation and strengthen the role of patients' voices in healthcare workflows.

</details>


### [181] [Capability-Aware Early-Stage Research Idea Evaluation](https://arxiv.org/abs/2601.12473)
*Renlong Jie,Chen Chu,Zhen Wang*

Main category: cs.CL

Relevance: 35.0

TL;DR: 提出基于作者信息和研究想法的能力感知框架，用于预测论文接受度和评分，无需完整文本或实验结果


<details>
  <summary>Details</summary>
Motivation: 在概念阶段预测研究成果（即在投入大量资源之前）对优化科学资源分配和研究规划具有巨大潜力。现有方法严重依赖完成的稿件或同行评审，而本研究希望在只有作者信息和研究想法的情况下进行预测。

Method: 提出能力感知框架，通过三路Transformer架构整合作者信息、（推断的）能力呈现和研究想法，采用灵活融合机制。引入两阶段架构学习给定作者信息和想法的能力表示。

Result: 实验表明，该方法显著优于基于bert-base和bert-large的单路模型，能力预测显著提高了最终模型的预测准确性。

Conclusion: 该方法可应用于早期研究成果预测和科学资源分配，为研究规划提供新的工具。

Abstract: Predicting the outcomes of research ideas at their conceptual stage (i.e. before significant resources are committed) holds great potential for optimizing scientific resource allocation and research planning. While existing methods rely heavily on finished manuscripts or peer reviews, we propose a novel capability-aware framework that predicts paper acceptance and ratings using only author information and research ideas, without requiring full text or experimental results. Our approach integrates author information, (inferred) capability presentation, and research ideas through a three-way transformer architecture with flexible fusion mechanisms. We also introduce a two-stage architecture for learning the capability representation given the author information and idea. Experiments show that our method significantly outperform the single-way models by finetuning bert-base and bert-large, and the capability predicting significantly increase the predictive accuracy of the final model. The proposed method can be applied in both early-stage research outcome prediction and scientific resource allocation.

</details>


### [182] [Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images](https://arxiv.org/abs/2601.12960)
*Ainhoa Vivel-Couso,Nicolás Vila-Blanco,María J. Carreira,Alberto Bugarín-Diz,Inmaculada Tomás,Jose M. Alonso-Moral*

Main category: cs.CL

Relevance: 35.0

TL;DR: 提出一个结合不透明与透明方法的牙科年龄估计系统，通过自然语言生成模块为临床医生提供文本解释，经专家验证获得高评分。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医疗领域的应用面临信任问题，因为模型不透明。需要提高透明度，让临床医生能够理解和信任AI系统的决策过程。

Method: 1) 结合不透明和透明方法进行牙科年龄估计；2) 通过自然语言生成模块产生临床友好的文本解释；3) 与牙科专家合作采用基于规则的方法设计解释；4) 使用问卷手动验证生成解释的质量；5) 遵循ALTAI清单进行可信度自评估。

Result: 专家在五个维度上平均评分为4.77±0.12（满分5分），ALTAI清单七个维度的可信度自评估得分为4.40±0.27（满分5分），显示系统性能优秀且可信度高。

Conclusion: 提出的系统成功提高了牙科年龄估计的透明度，通过自然语言解释增强了临床医生的信任，为医疗AI的可解释性提供了有效解决方案。

Abstract: Integrating deep learning into healthcare enables personalized care but raises trust issues due to model opacity. To improve transparency, we propose a system for dental age estimation from panoramic images that combines an opaque and a transparent method within a natural language generation (NLG) module. This module produces clinician-friendly textual explanations about the age estimations, designed with dental experts through a rule-based approach. Following the best practices in the field, the quality of the generated explanations was manually validated by dental experts using a questionnaire. The results showed a strong performance, since the experts rated 4.77+/-0.12 (out of 5) on average across the five dimensions considered. We also performed a trustworthy self-assessment procedure following the ALTAI checklist, in which it scored 4.40+/-0.27 (out of 5) across seven dimensions of the AI Trustworthiness Assessment List.

</details>


### [183] [Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context](https://arxiv.org/abs/2601.13018)
*Ghislain Dorian Tchuente Mondjo*

Main category: cs.CL

Relevance: 35.0

TL;DR: 提出BiAtt-BiRNN-HateXplain模型，通过双向注意力机制和双向RNN层改进仇恨言论检测的可解释性和分类性能，减少无意偏见。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测模型存在注意力可变性问题，导致解释不一致、预测不稳定和学习困难。需要更透明、可解释的模型来替代复杂的黑盒模型。

Method: 提出BiAtt-BiRNN-HateXplain模型，结合双向注意力机制和双向RNN层，通过多任务学习同时处理可解释性和分类任务，考虑输入数据的序列特性。

Result: 在HateXplain数据上的实验结果显示，模型在检测性能、可解释性方面有明显改进，并减少了无意偏见。

Conclusion: 该模型相比复杂的大语言模型更易于解释，通过正确的解释估计可以改善分类性能并减少与社区相关的无意偏见错误。

Abstract: Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.

</details>


### [184] [SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification](https://arxiv.org/abs/2601.13035)
*Xu Xiaodan,Hu Xiaolin*

Main category: cs.CL

Relevance: 35.0

TL;DR: SASA框架通过分离注意力机制和语义感知对比学习提升知识图谱三元组分类性能，在两个基准数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 知识图谱常包含不可靠知识，三元组分类旨在判断三元组有效性。现有文本方法虽提升泛化能力，但存在两个关键问题：1) 忽略不同KG组件间的有效语义交互；2) 单一二元分类目标导致语义表示学习不足。

Method: 提出SASA框架：1) 分离注意力机制将三元组编码为解耦的上下文表示，并通过更有效的交互方式融合；2) 语义感知分层对比学习作为辅助训练目标，考虑局部和全局层次，提升模型判别能力和语义学习。

Result: 在两个基准数据集上显著超越现有方法：FB15k-237准确率提升+5.9%，YAGO3-10提升+3.4%。

Conclusion: SASA通过分离注意力机制和语义感知对比学习有效解决了现有三元组分类方法的局限性，显著提升了模型性能。

Abstract: Knowledge Graphs~(KGs) often suffer from unreliable knowledge, which restricts their utility. Triple Classification~(TC) aims to determine the validity of triples from KGs. Recently, text-based methods learn entity and relation representations from natural language descriptions, significantly improving the generalization capabilities of TC models and setting new benchmarks in performance. However, there are still two critical challenges. First, existing methods often ignore the effective semantic interaction among different KG components. Second, most approaches adopt single binary classification training objective, leading to insufficient semantic representation learning. To address these challenges, we propose \textbf{SASA}, a novel framework designed to enhance TC models via separated attention mechanism and semantic-aware contrastive learning~(CL). Specifically, we first propose separated attention mechanism to encode triples into decoupled contextual representations and then fuse them through a more effective interactive way. Then, we introduce semantic-aware hierarchical CL as auxiliary training objective to guide models in improving their discriminative capabilities and achieving sufficient semantic learning, considering both local level and global level CL. Experimental results across two benchmark datasets demonstrate that SASA significantly outperforms state-of-the-art methods. In terms of accuracy, we advance the state-of-the-art by +5.9\% on FB15k-237 and +3.4\% on YAGO3-10.

</details>


### [185] [Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification](https://arxiv.org/abs/2601.13105)
*Liu Kaipeng,Wu Ling*

Main category: cs.CL

Relevance: 35.0

TL;DR: 该研究将LoRA微调与RAG框架结合，用于英语双及物结构的自动识别，在BNC语料上进行二分类任务，结果显示LoRA微调的Qwen3-8B模型显著优于原生Qwen3-MAX和纯理论RAG系统。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索如何有效识别英语中的双及物结构，这是自然语言处理中的重要语法分析任务。通过结合LoRA微调和RAG框架，旨在提高大语言模型在特定语言学任务上的性能。

Method: 方法包括：1）使用LoRA对Qwen3-8B模型进行微调；2）构建检索增强生成（RAG）框架；3）在英国国家语料库（BNC）的标注数据上进行二分类任务；4）对比分析LoRA微调模型、原生Qwen3-MAX模型和纯理论RAG系统的性能。

Result: 结果显示：LoRA微调的Qwen3-8B模型在识别英语双及物结构方面表现最佳，显著优于原生Qwen3-MAX模型和纯理论RAG系统。错误分析表明，微调使模型从表面形式模式匹配转向更基于语义的理解。

Conclusion: 结论：LoRA微调与RAG框架的结合能有效提升大语言模型在特定语言学任务上的性能，微调过程使模型获得更语义化的理解能力，而非简单的模式匹配。

Abstract: This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.

</details>


### [186] [A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus](https://arxiv.org/abs/2601.13253)
*Ebubekir Tosun,Mehmet Emin Buldur,Özay Ezerceli,Mahmoud ElHussieni*

Main category: cs.CL

Relevance: 35.0

TL;DR: 提出了一种为低资源语言生成大规模语义关系数据集的混合方法，以土耳其语为例构建了包含84.3万对语义关系的语料库，成本仅65美元，规模是现有资源的10倍。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（特别是土耳其语）中语义关系数据稀缺的问题，为NLP任务提供高质量的大规模语义关系数据集。

Method: 三阶段混合方法：1) 使用FastText嵌入和凝聚聚类识别语义簇；2) 使用Gemini 2.5-Flash进行自动语义关系分类；3) 整合精选词典资源。

Result: 构建了包含84.3万个土耳其语语义对的数据集，涵盖同义词、反义词、共下位词三种关系类型。在下游任务验证中，嵌入模型达到90%的top-1检索准确率，分类模型达到90%的F1-macro分数。

Conclusion: 该方法以低成本有效解决了土耳其语NLP中的数据稀缺问题，可扩展应用于其他低资源语言，并公开了数据集和模型。

Abstract: We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.

</details>


### [187] [Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology](https://arxiv.org/abs/2601.13319)
*Peter Sullivan,AbdelRahim Elmadany,Alcides Alcoba Inciarte,Muhammad Abdul-Mageed*

Main category: cs.CL

Relevance: 35.0

TL;DR: 该论文分析了阿拉伯语方言语音数据的异质性，提出了Arab Voices标准化框架来统一31个数据集，并为现代阿拉伯语方言ASR建立了基准。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言语音数据在领域覆盖、方言标注实践和录音条件方面存在广泛差异，这导致跨数据集比较和模型评估变得复杂。需要标准化表征来减少碎片化并支持可重复评估。

Method: 1) 对广泛使用的阿拉伯语方言语料库进行语言"方言性"的计算分析；2) 分析音频质量的客观代理指标；3) 开发Arab Voices标准化框架，统一访问31个数据集，涵盖14种方言，提供协调的元数据和评估工具；4) 对一系列最新ASR系统进行基准测试。

Result: 发现数据集在声学条件和方言信号强度及一致性方面存在显著异质性。Arab Voices框架成功整合了多个数据集，并为现代阿拉伯语方言ASR建立了强基准。

Conclusion: 需要超越粗粒度标签的标准化表征。Arab Voices框架减少了碎片化，支持可重复评估，并为阿拉伯语方言ASR研究提供了重要基础设施。

Abstract: Dialectal Arabic (DA) speech data vary widely in domain coverage, dialect labeling practices, and recording conditions, complicating cross-dataset comparison and model evaluation. To characterize this landscape, we conduct a computational analysis of linguistic ``dialectness'' alongside objective proxies of audio quality on the training splits of widely used DA corpora. We find substantial heterogeneity both in acoustic conditions and in the strength and consistency of dialectal signals across datasets, underscoring the need for standardized characterization beyond coarse labels. To reduce fragmentation and support reproducible evaluation, we introduce Arab Voices, a standardized framework for DA ASR. Arab Voices provides unified access to 31 datasets spanning 14 dialects, with harmonized metadata and evaluation utilities. We further benchmark a range of recent ASR systems, establishing strong baselines for modern DA ASR.

</details>


### [188] [MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization](https://arxiv.org/abs/2601.13437)
*Adriana-Valentina Costache,Daria-Nicoleta Dragomir,Silviu-Florin Gheorghe,Eduard Poesina,Paul Irofti,Radu Tudor Ionescu*

Main category: cs.CL

Relevance: 35.0

TL;DR: 提出了首个多语言开放集学习与发现（MOSLD）文本分类基准，包含12种语言的96万数据样本，并提出了一个集成多阶段的新框架来持续发现和学习新类别。


<details>
  <summary>Details</summary>
Motivation: 开放集学习与发现（OSLD）是机器学习中的一个挑战性任务，测试时可能出现来自新（未知）类别的样本。虽然零样本学习在文本分类中已被广泛研究，但OSLD在文本领域是一个相对较新的设置，缺乏相应的基准。

Method: 1. 构建了首个多语言OSLD基准，通过(i)重新组织现有数据集和(ii)从新闻领域收集新数据样本，包含12种语言的960K数据样本。2. 提出了一个新颖的OSLD框架，集成多个阶段来持续发现和学习新类别。

Result: 评估了包括作者自己模型在内的多种语言模型，为未来工作提供了参考结果。基准已开源发布。

Conclusion: 这项工作填补了文本领域开放集学习与发现基准的空白，为多语言文本分类的OSLD研究提供了重要的基础设施和参考框架。

Abstract: Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.

</details>


### [189] [Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews](https://arxiv.org/abs/2601.13575)
*Thanh-Lam T. Nguyen,Ngoc-Quang Le,Quoc-Trung Phu,Thi-Phuong Le,Ngoc-Huyen Pham,Phuong-Nguyen Nguyen,Hoang-Quynh Le*

Main category: cs.CL

Relevance: 35.0

TL;DR: SUDO是一个用于隐式比较观点挖掘的新数据集，包含4,150个标注的评论对，用于从同一用户的不同评论中推断偏好，即使没有显式比较线索。


<details>
  <summary>Details</summary>
Motivation: 现有比较观点挖掘研究主要关注显式比较表达，但在真实评论中不常见，而隐式比较（用户在不同评论中表达偏好）尚未充分探索。需要可靠的数据集来支持这一任务。

Method: 构建SUDO数据集，包含4,150个标注的评论对（15,191个句子），采用双层结构捕捉方面级提及和评论级偏好。使用两种基线架构进行基准测试：传统机器学习方法和语言模型方法。

Result: 实验结果显示，语言模型方法优于传统机器学习方法，但整体性能仍然中等，表明该任务具有固有难度。SUDO被确立为一个具有挑战性和价值的基准数据集。

Conclusion: SUDO为隐式比较观点挖掘提供了有价值的基准，揭示了该任务的挑战性，为未来研究奠定了基础。

Abstract: Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research.

</details>


### [190] [Towards Token-Level Text Anomaly Detection](https://arxiv.org/abs/2601.13644)
*Yang Cao,Bicheng Yu,Sikun Yang,Ming Liu,Yujiu Yang*

Main category: cs.CL

Relevance: 35.0

TL;DR: 提出token级文本异常检测新范式，实现细粒度异常定位，构建统一检测框架和三个带token标注的基准数据集，性能优于6个基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本异常检测方法（如垃圾邮件过滤、假新闻检测）仅限于文档级分析，无法定位文本中具体的异常部分，需要更细粒度的检测能力。

Method: 提出token级异常检测范式，在文档级和token级定义文本异常，设计统一的多级检测框架，并构建三个带token标注的基准数据集（垃圾邮件、评论、语法错误）。

Result: 实验结果表明，该框架在三个数据集上优于6个基线方法，实现了精确的异常定位，代码和数据已开源。

Conclusion: token级异常检测为文本异常定位开辟了新可能性，提供了更精细的分析工具，有助于提升文本异常检测的实用性。

Abstract: Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.

</details>


### [191] [GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark](https://arxiv.org/abs/2601.13711)
*Lotta Kiefer,Christoph Leiter,Sotaro Takeshita,Elena Schmidt,Steffen Eger*

Main category: cs.CL

Relevance: 35.0

TL;DR: 提出了GerAV，一个包含60多万个标注文本对的德语作者验证综合基准，基于Twitter和Reddit数据构建，包含多个子集以分析数据源、主题领域和文本长度的影响。


<details>
  <summary>Details</summary>
Motivation: 作者验证任务在英语数据上研究广泛，但其他语言的大规模基准和系统评估仍然稀缺。本文旨在填补德语作者验证领域的这一空白。

Method: 构建GerAV基准，包含Twitter和Reddit数据，Reddit部分进一步分为域内和跨域消息子集以及基于配置文件的子集。使用提供的训练分割对强基线和最先进模型进行系统评估，包括微调的大型语言模型。

Result: 最佳方法（微调的大型语言模型）比最近基线高出0.09绝对F1分数，在零样本设置中超过GPT-5 0.08分。观察到专业化与泛化之间的权衡：在匹配条件下，特定数据类型训练的模型表现最佳，但跨数据制度的泛化能力较差，这一限制可以通过组合训练源来缓解。

Conclusion: GerAV为推进德语和跨域作者验证研究提供了一个具有挑战性和多功能的基准。

Abstract: Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.

</details>


### [192] [Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks](https://arxiv.org/abs/2601.14105)
*Olesya Razuvayevskaya,Kalina Bontcheva*

Main category: cs.CL

Relevance: 35.0

TL;DR: 大规模比较社区与专业辟谣中的说服技巧：研究发现社区笔记（CNs）与专业辟谣在说服技巧数量上无显著差异，但存在系统性修辞差异，且社区评分者能有效惩罚有问题的修辞手段。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解不同事实核查生态系统中的说服技巧使用情况，特别是比较社区生成内容（如Twitter的Community Notes）与专业事实核查机构在辟谣时使用的修辞策略差异。

Method: 使用来自Community Notes（CNs）、EUvsDisinfo和Database of Known Fakes（DBKF）的广泛数据集，量化这些事实核查生态系统中说服技巧的普遍性和类型，并进行统计分析。

Result: 1. 与先前假设相反，社区生成的辟谣并不比专业事实核查包含更多说服技巧；2. 发现社区笔记与专业辟谣存在系统性修辞差异，反映了机构规范和主题覆盖的不同；3. 社区评分者能有效惩罚特定有问题的修辞手段，尽管更具说服力的笔记总体评分略高。

Conclusion: 社区生成的事实核查在说服技巧使用上与专业机构相当，但存在不同的修辞风格。社区评分机制能有效识别和惩罚有问题的修辞手段，表明众包事实核查系统具有一定的自我调节能力。

Abstract: This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means

</details>


### [193] [NewsRECON: News article REtrieval for image CONtextualization](https://arxiv.org/abs/2601.14121)
*Jonathan Tonglet,Iryna Gurevych,Tinne Tuytelaars,Marie-Francine Moens*

Main category: cs.CL

Relevance: 35.0

TL;DR: NewsRECON：一种在反向图像搜索证据不可用时，通过将新闻图像链接到相关文章来推断其拍摄时间和位置的方法


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖反向图像搜索(RIS)引擎，但这些工具经常无法返回结果，限制了实际应用。本文针对RIS证据不可用的挑战场景，提出通过链接图像到新闻文章来推断时空信息的方法。

Method: NewsRECON方法包含：1) 双编码器检索事件相关文章；2) 两个交叉编码器分别按位置一致性和事件一致性对文章进行重排序。利用超过90,000篇文章的语料库。

Result: 在TARA和5Pils-OOC数据集上的实验表明，NewsRECON优于先前工作，并且可以与多模态大语言模型结合，在缺乏RIS证据的情况下达到新的SOTA结果。

Conclusion: NewsRECON为新闻图像时空定位提供了一种有效的替代方案，特别是在反向图像搜索失败的情况下，具有实际应用价值。

Abstract: Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.

</details>


### [194] [Lightweight Prompt Biasing for Contextualized End-to-End ASR Systems](https://arxiv.org/abs/2506.06252)
*Bo Ren,Yu Shi,Jinyu Li*

Main category: eess.AS

Relevance: 35.0

TL;DR: 提出一种基于提示的上下文ASR偏置技术，通过多任务学习框架提升特定实体识别准确率，无需改变模型结构


<details>
  <summary>Details</summary>
Motivation: 当前端到端ASR系统在处理罕见和领域特定实体时仍存在困难，需要更有效的上下文偏置方法来提升实体识别准确率

Method: 采用统一多任务学习框架，包含两个关键组件：1) 提示偏置模型，学习何时关注提示中的实体；2) 实体过滤机制，高效过滤不相关实体

Result: 在内部领域数据集上，相比浅层融合基线模型，实体词错误率相对降低30.7%（小实体列表）和18.0%（大实体列表）

Conclusion: 该方法在保持高效轻量的同时显著提升ASR实体识别准确率，无需改变模型结构，具有简单高效的优势

Abstract: End-to-End Automatic Speech Recognition (ASR) has advanced significantly yet still struggles with rare and domain-specific entities. This paper introduces a simple yet efficient prompt-based biasing technique for contextualized ASR, enhancing recognition accuracy by leverage a unified multitask learning framework. The approach comprises two key components: a prompt biasing model which is trained to determine when to focus on entities in prompt, and a entity filtering mechanism which efficiently filters out irrelevant entities. Our method significantly enhances ASR accuracy on entities, achieving a relative 30.7% and 18.0% reduction in Entity Word Error Rate compared to the baseline model with shallow fusion on in-house domain dataset with small and large entity lists, respectively. The primary advantage of this method lies in its efficiency and simplicity without any structure change, making it lightweight and highly efficient.

</details>


### [195] [Lombard Speech Synthesis for Any Voice with Controllable Style Embeddings](https://arxiv.org/abs/2601.12966)
*Seymanur Akti,Alexander Waibel*

Main category: cs.SD

Relevance: 35.0

TL;DR: 提出了一种无需Lombard训练数据的可控文本转语音系统，通过风格嵌入和PCA分析实现任意说话者的Lombard语音合成


<details>
  <summary>Details</summary>
Motivation: Lombard效应（在嘈杂环境中提高语音清晰度的现象）在自然交流中很重要，但现有TTS系统难以合成高质量的Lombard语音，特别是对于没有Lombard训练数据的说话者

Method: 1) 从大规模韵律多样化数据集中学习风格嵌入；2) 使用PCA分析这些嵌入与Lombard属性的相关性；3) 通过移动相关PCA分量来操纵风格嵌入；4) 将修改后的嵌入集成到TTS模型中生成不同Lombard程度的语音

Result: 方法能够保持自然度和说话人身份，在噪声环境下提高可懂度，提供细粒度的韵律控制，为任意说话者提供鲁棒的Lombard TTS解决方案

Conclusion: 提出了一种无需Lombard训练数据的可控Lombard TTS系统，通过风格嵌入和PCA分析实现任意说话者的高质量Lombard语音合成

Abstract: The Lombard effect plays a key role in natural communication, particularly in noisy environments or when addressing hearing-impaired listeners. We present a controllable text-to-speech (TTS) system capable of synthesizing Lombard speech for any speaker without requiring explicit Lombard data during training. Our approach leverages style embeddings learned from a large, prosodically diverse dataset and analyzes their correlation with Lombard attributes using principal component analysis (PCA). By shifting the relevant PCA components, we manipulate the style embeddings and incorporate them into our TTS model to generate speech at desired Lombard levels. Evaluations demonstrate that our method preserves naturalness and speaker identity, enhances intelligibility under noise, and provides fine-grained control over prosody, offering a robust solution for controllable Lombard TTS for any speaker.

</details>


### [196] [Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset](https://arxiv.org/abs/2601.12068)
*Rowzatul Zannat,Abdullah Al Shafi,Abdul Muntakim*

Main category: cs.CL

Relevance: 25.0

TL;DR: 该研究创建了一个包含758个症状-疾病关系的孟加拉语数据集，用于疾病预测，并通过集成学习方法达到了98%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决孟加拉语人群缺乏可靠健康信息资源的问題，特别是疾病预测方面的资源限制，以增强医疗可及性和早期疾病检测。

Method: 开发了包含85种疾病和758个症状-疾病关系的孟加拉语数据集，使用多种机器学习模型进行疾病预测，并采用软投票和硬投票集成方法。

Result: 集成学习方法（软投票和硬投票）在孟加拉语症状-疾病预测任务上达到了98%的准确率，表现出优越的鲁棒性和泛化能力。

Conclusion: 该工作为孟加拉语疾病预测建立了基础资源，为本地化健康信息学和诊断工具的未来发展铺平了道路，有助于提升孟加拉语社区的医疗公平性。

Abstract: Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.

</details>


### [197] [Rapport du Projet de Recherche TRAIMA](https://arxiv.org/abs/2601.12844)
*Julie Rançon,Jean-François Cerisier,Emilie Remond,Aurélien Nguyen,Andrew Peterson,Ladjel Bellatreche*

Main category: cs.CL

Relevance: 25.0

TL;DR: TRAIMA项目研究教育环境中多模态交互的自动处理，重点关注课堂解释性和协作性序列，为多模态教学交互的机器学习分析建立方法论框架。


<details>
  <summary>Details</summary>
Motivation: 当前教育研究中，语言、副语言和非语言数据的分析完全依赖人工处理，极其耗时且难以扩展。项目旨在探索机器学习如何帮助分类和分类这类多模态交互，解决教育研究中的方法论瓶颈。

Method: 项目基于多个语料库（如INTER-EXPLIC和EXPLIC-LEXIC），采用比较分析方法，研究现有转录规范（ICOR、Mondada等）在多模态课堂数据中的应用。重点关注教师手势、韵律特征等功能角色，利用TechnéLAB平台进行多模态数据采集。

Result: 建立了解释性话语的三段式序列定义（开场、解释核心、结束），展示了转录实践的必然变异性和解释性维度。确定了与机器学习方法兼容的转录规范、标注类别和分析单元，为未来自动化处理奠定基础。

Conclusion: TRAIMA未开发完全可操作的自动化系统，而是为多模态教学交互的自动处理建立了严谨的方法论框架，强调理论明确性和研究者反思性，为教育、话语分析、多模态和人工智能的跨学科研究奠定基础。

Abstract: The TRAIMA project (TRaitement Automatique des Interactions Multimodales en Apprentissage), conducted between March 2019 and June 2020, investigates the potential of automatic processing of multimodal interactions in educational settings. The project addresses a central methodological challenge in educational and interactional research: the analysis of verbal, paraverbal, and non-verbal data is currently carried out manually, making it extremely time-consuming and difficult to scale. TRAIMA explores how machine learning approaches could contribute to the categorisation and classification of such interactions. The project focuses specifically on explanatory and collaborative sequences occurring in classroom interactions, particularly in French as a Foreign Language (FLE) and French as a First Language (FLM) contexts. These sequences are analysed as inherently multimodal phenomena, combining spoken language with prosody, gestures, posture, gaze, and spatial positioning. A key theoretical contribution of the project is the precise linguistic and interactional definition of explanatory discourse as a tripartite sequence (opening, explanatory core, closure), drawing on discourse analysis and interactional linguistics. A substantial part of the research is devoted to the methodological foundations of transcription, which constitute a critical bottleneck for any form of automation. The report provides a detailed state of the art of existing transcription conventions (ICOR, Mondada, GARS, VALIBEL, Ferr{é}), highlighting their respective strengths and limitations when applied to multimodal classroom data. Through comparative analyses of manually transcribed sequences, the project demonstrates the inevitable variability and interpretative dimension of transcription practices, depending on theoretical positioning and analytical goals. Empirical work is based on several corpora, notably the INTER-EXPLIC corpus (approximately 30 hours of classroom interaction) and the EXPLIC-LEXIC corpus, which serve both as testing grounds for manual annotation and as reference datasets for future automation. Particular attention is paid to teacher gestures (kin{é}sic and proxemic resources), prosodic features, and their functional role in meaning construction and learner comprehension. The project also highlights the strategic role of the Techn{é}LAB platform, which provides advanced multimodal data capture (multi-camera video, synchronized audio, eye-tracking, digital interaction traces) and constitutes both a research infrastructure and a test environment for the development of automated tools. In conclusion, TRAIMA does not aim to deliver a fully operational automated system, but rather to establish a rigorous methodological framework for the automatic processing of multimodal pedagogical interactions. The project identifies transcription conventions, annotation categories, and analytical units that are compatible with machine learning approaches, while emphasizing the need for theoretical explicitness and researcher reflexivity. TRAIMA thus lays the groundwork for future interdisciplinary research at the intersection of didactics, discourse analysis, multimodality, and artificial intelligence in education.

</details>


### [198] [Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis](https://arxiv.org/abs/2601.13802)
*Yushen Chen,Junzhe Liu,Yujie Tu,Zhikang Niu,Yuzhe Liang,Kai Yu,Chunyu Qiang,Chen Zhang,Xie Chen*

Main category: cs.CL

Relevance: 25.0

TL;DR: Habibi是一个专门用于阿拉伯语方言语音合成的统一模型套件，利用现有ASR语料库支持高资源到低资源方言，通过语言感知课程学习实现高质量语音生成，超越领先商业服务。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言语音合成研究存在显著空白，缺乏统一建模视角。阿拉伯语方言的语言复杂性高，且缺乏标准化数据、基准和评估指南，导致研究人员倾向于更安全的领域。

Method: 利用现有开源ASR语料库，通过语言感知的课程学习支持广泛的阿拉伯语方言（从高资源到低资源），采用统一文本到语音模型架构，无需文本音标标注。

Result: Habibi在生成质量上超越了领先的商业服务，同时通过有效的上下文学习保持可扩展性，无需文本音标标注。

Conclusion: 该研究填补了阿拉伯语方言语音合成的空白，提供了首个系统性的多方言阿拉伯语语音合成基准，建立了评估标准，为后续研究奠定基础。

Abstract: A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ .

</details>


### [199] [Generalization and Completeness of Stochastic Local Search Algorithms](https://arxiv.org/abs/2601.14212)
*Daniel Loscos,Narciso Marti-Oliet,Ismael Rodriguez*

Main category: cs.NE

Relevance: 15.0

TL;DR: 该论文将随机局部搜索启发式算法统一为一个形式化模型，包含通用结构和参数化结构，并证明了SLS算法（包括遗传算法、蚁群算法、粒子群算法）的图灵完备性，进而推导出相关性质判定问题的不可判定性。


<details>
  <summary>Details</summary>
Motivation: 为多种随机局部搜索启发式算法（如遗传算法、蚁群算法、粒子群算法）建立一个统一的形式化模型，以系统性地分析它们的计算能力和理论性质。

Method: 提出一个包含通用结构和参数化结构的两部分形式化模型，通过不同参数化实例化得到具体启发式算法。使用该框架构造能够模拟任意图灵机的遗传算法，从而证明SLS算法的图灵完备性。

Result: 成功构建了遗传算法、蚁群算法和粒子群算法的具体实例，证明了SLS算法整体具有图灵完备性，这意味着对于遗传算法和一般SLS方法，判定输入输出关系的非平凡性质是不可判定的。

Conclusion: 随机局部搜索启发式算法作为一个整体具有图灵完备性，这导致了相关性质判定问题的不可判定性，为理解这些优化算法的理论极限提供了重要见解。

Abstract: We generalize Stochastic Local Search (SLS) heuristics into a unique formal model. This model has two key components: a common structure designed to be as large as possible and a parametric structure intended to be as small as possible. Each heuristic is obtained by instantiating the parametric part in a different way. Particular instances for Genetic Algorithms (GA), Ant Colony Optimization (ACO), and Particle Swarm Optimization (PSO) are presented. Then, we use our model to prove the Turing-completeness of SLS algorithms in general. The proof uses our framework to construct a GA able to simulate any Turing machine. This Turing-completeness implies that determining any non-trivial property concerning the relationship between the inputs and the computed outputs is undecidable for GA and, by extension, for the general set of SLS methods (although not necessarily for each particular method). Similar proofs are more informally presented for PSO and ACO.

</details>


### [200] [Mapping the maturation of TCM as an adjuvant to radiotherapy](https://arxiv.org/abs/2601.11923)
*P. Bilha Githinji,Aikaterini Melliou,Xi Yuan,Dayan Zhang,Lian Zhang,Zhenglin Chen,Jiansong Ji,Chengying Lv,Jinhao Xu,Peiwu Qin,Dongmei Yu*

Main category: cs.CL

Relevance: 10.0

TL;DR: 该论文通过分析69,745篇出版物（2000-2025年），研究了传统中医作为放疗辅助治疗的研究演变，发现该领域呈现周期性发展模式，并识别出五大主题轴心，表明该领域已成熟并可能面临新突破。


<details>
  <summary>Details</summary>
Motivation: 整合医学进入肿瘤学领域已成为一种范式转变，传统中医作为放疗辅助治疗的应用日益增加。在整合肿瘤学正式制度化约25年后，有必要系统梳理传统中医作为放疗辅助治疗的研究轨迹和证据演变。

Method: 采用大规模文献分析方法，分析了2000-2025年间的69,745篇出版物。使用主题建模工作流程来确定该领域的稳定主题结构，识别主导主题轴心，并分析出版产出、国际合作和资金承诺的周期性演变模式。

Result: 研究发现该领域呈现周期性演变模式（定义-构思-测试模式），识别出五大主导主题轴心：癌症类型、支持性护理、临床终点、机制和方法学。传统中医的跨主题整合以患者为中心且系统导向。该领域表现出普遍的正向报告偏倚，且研究议程可能已趋于饱和。

Conclusion: 该领域已成熟当前研究议程，可能正处于新突破的边缘。主题结构显示出渐进的专业化和潜在的分化或现有研究议程的饱和。系统性的正向报告偏倚存在于所有出版物类型、主题领域和演变周期中。

Abstract: The integration of complementary medicine into oncology represents a paradigm shift that has seen to increasing adoption of Traditional Chinese Medicine (TCM) as an adjuvant to radiotherapy. About twenty-five years since the formal institutionalization of integrated oncology, it is opportune to synthesize the trajectory of evidence for TCM as an adjuvant to radiotherapy. Here we conduct a large-scale analysis of 69,745 publications (2000 - 2025), emerging a cyclical evolution defined by coordinated expansion and contraction in publication output, international collaboration, and funding commitments that mirrors a define-ideate-test pattern. Using a theme modeling workflow designed to determine a stable thematic structure of the field, we identify five dominant thematic axes - cancer types, supportive care, clinical endpoints, mechanisms, and methodology - that signal a focus on patient well-being, scientific rigor and mechanistic exploration. Cross-theme integration of TCM is patient-centered and systems-oriented. Together with the emergent cycles of evolution, the thematic structure demonstrates progressive specialization and potential defragmentation of the field or saturation of existing research agenda. The analysis points to a field that has matured its current research agenda and is likely at the cusp of something new. Additionally, the field exhibits positive reporting of findings that is homogeneous across publication types, thematic areas, and the cycles of evolution suggesting a system-wide positive reporting bias agnostic to structural drivers.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [201] [Beyond Accuracy: Evaluating Grounded Visual Evidence in Thinking with Images](https://arxiv.org/abs/2601.11633)
*Xuchen Li,Xuzhao Li,Renjie Pi,Shiyu Hu,Jian Zhao,Jiahui Gao*

Main category: cs.CV

Relevance: 85.0

TL;DR: ViEBench是一个过程可验证的视觉推理基准，通过200个多场景高分辨率图像和专家标注的视觉证据，评估视觉语言模型是否能够基于细粒度视觉线索进行忠实推理。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型评估主要依赖结果导向的准确率，缺乏评估模型是否能够准确利用细粒度视觉线索进行多步推理的能力，无法验证推理过程的真实性。

Method: 构建包含200个多场景高分辨率图像的基准，每张图像都有专家标注的视觉证据。将任务按难度分为感知和推理两个维度，推理任务需要结合局部视觉细节和先验知识。引入双轴矩阵提供细粒度评估指标。

Result: 实验发现：(1) VLMs有时能给出正确答案但基于无关区域；(2) 模型能定位正确证据但仍无法利用其得出准确结论。ViEBench能更全面地评估VLMs的有效性。

Conclusion: ViEBench作为一个更可解释和实用的基准，能够全面评估视觉语言模型的有效性，特别适合评估具有代理能力的VLMs。

Abstract: Despite the remarkable progress of Vision-Language Models (VLMs) in adopting "Thinking-with-Images" capabilities, accurately evaluating the authenticity of their reasoning process remains a critical challenge. Existing benchmarks mainly rely on outcome-oriented accuracy, lacking the capability to assess whether models can accurately leverage fine-grained visual cues for multi-step reasoning. To address these limitations, we propose ViEBench, a process-verifiable benchmark designed to evaluate faithful visual reasoning. Comprising 200 multi-scenario high-resolution images with expert-annotated visual evidence, ViEBench uniquely categorizes tasks by difficulty into perception and reasoning dimensions, where reasoning tasks require utilizing localized visual details with prior knowledge. To establish comprehensive evaluation criteria, we introduce a dual-axis matrix that provides fine-grained metrics through four diagnostic quadrants, enabling transparent diagnosis of model behavior across varying task complexities. Our experiments yield several interesting observations: (1) VLMs can sometimes produce correct final answers despite grounding on irrelevant regions, and (2) they may successfully locate the correct evidence but still fail to utilize it to reach accurate conclusions. Our findings demonstrate that ViEBench can serve as a more explainable and practical benchmark for comprehensively evaluating the effectiveness agentic VLMs. The codes will be released at: https://github.com/Xuchen-Li/ViEBench.

</details>


### [202] [Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers](https://arxiv.org/abs/2601.11641)
*Yuxi Liu,Yipeng Hu,Zekun Zhang,Kunze Jiang,Kun Yuan*

Main category: cs.CV

Relevance: 85.0

TL;DR: MOD-DiT提出了一种无需采样的动态注意力框架，通过两阶段过程建模视频生成中的注意力模式，显著降低了DiT的二次复杂度，实现了高效高质量的视频生成。


<details>
  <summary>Details</summary>
Motivation: 当前Diffusion Transformers在视频生成中面临自注意力机制的二次复杂度问题，限制了实际部署。现有的稀疏注意力方法要么依赖过于简化的静态模式，要么需要计算昂贵的采样操作来实现动态稀疏性，导致模式预测不准确和生成质量下降。

Method: MOD-DiT采用两阶段方法：1）利用早期去噪步骤的先验信息，通过分布式混合方法建模高效的线性近似模型，预测特定去噪区间的掩码模式；2）在线块掩码策略动态应用这些预测的掩码，同时保持历史稀疏信息，无需重复采样操作。

Result: 在多个基准测试和模型架构上实现了持续的加速和质量提升，验证了MOD-DiT在高效高质量视频生成方面的有效性，克服了传统稀疏注意力方法的计算限制。

Conclusion: MOD-DiT通过创新的采样自由动态注意力框架，成功解决了DiT在视频生成中的计算效率问题，为长序列生成任务提供了实用的解决方案。

Abstract: While Diffusion Transformers (DiTs) have achieved notable progress in video generation, this long-sequence generation task remains constrained by the quadratic complexity inherent to self-attention mechanisms, creating significant barriers to practical deployment. Although sparse attention methods attempt to address this challenge, existing approaches either rely on oversimplified static patterns or require computationally expensive sampling operations to achieve dynamic sparsity, resulting in inaccurate pattern predictions and degraded generation quality. To overcome these limitations, we propose a \underline{\textbf{M}}ixtrue-\underline{\textbf{O}}f-\underline{\textbf{D}}istribution \textbf{DiT} (\textbf{MOD-DiT}), a novel sampling-free dynamic attention framework that accurately models evolving attention patterns through a two-stage process. First, MOD-DiT leverages prior information from early denoising steps and adopts a {distributed mixing approach} to model an efficient linear approximation model, which is then used to predict mask patterns for a specific denoising interval. Second, an online block masking strategy dynamically applies these predicted masks while maintaining historical sparsity information, eliminating the need for repetitive sampling operations. Extensive evaluations demonstrate consistent acceleration and quality improvements across multiple benchmarks and model architectures, validating MOD-DiT's effectiveness for efficient, high-quality video generation while overcoming the computational limitations of traditional sparse attention approaches.

</details>


### [203] [MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents](https://arxiv.org/abs/2601.12346)
*Peizhou Huang,Zixuan Zhong,Zhongwei Wan,Donghao Zhou,Samiul Alam,Xin Wang,Zexin Li,Zhihao Dou,Li Zhu,Jing Xiong,Chaofan Tao,Yan Xu,Dimitrios Dimitriadis,Tuo Zhang,Mi Zhang*

Main category: cs.CV

Relevance: 85.0

TL;DR: MMDR-Bench：首个评估多模态深度研究代理的基准，包含140个专家设计的任务，强调报告式合成与显式证据使用，并提出了统一的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要针对纯文本设置或短格式多模态问答，缺乏端到端的多模态证据使用评估。深度研究代理（DRAs）通过多步搜索和合成生成引用丰富的报告，但当前评估体系未能充分评估其多模态理解能力。

Method: 1. 构建MMDR-Bench基准：包含140个专家设计的任务，覆盖21个领域，每个任务提供图像-文本捆绑数据；2. 提出统一可解释的评估管道：FLAE（报告质量评估）、TRACE（引用证据对齐评估）、MOSAIC（文本-视觉完整性检查）。

Result: 对25个最先进模型的实验显示：生成质量、引用纪律和多模态基础之间存在系统性权衡；强文本生成能力不能保证忠实证据使用；多模态完整性仍是深度研究代理的关键瓶颈。

Conclusion: 需要超越单一整体评分的细粒度评估框架；多模态证据的忠实使用是深度研究代理的核心挑战；MMDR-Bench为评估多模态理解和引用基础报告生成提供了重要基准。

Abstract: Deep Research Agents (DRAs) generate citation-rich reports via multi-step search and synthesis, yet existing benchmarks mainly target text-only settings or short-form multimodal QA, missing end-to-end multimodal evidence use. We introduce MMDeepResearch-Bench (MMDR-Bench), a benchmark of 140 expert-crafted tasks across 21 domains, where each task provides an image-text bundle to evaluate multimodal understanding and citation-grounded report generation. Compared to prior setups, MMDR-Bench emphasizes report-style synthesis with explicit evidence use, where models must connect visual artifacts to sourced claims and maintain consistency across narrative, citations, and visual references. We further propose a unified, interpretable evaluation pipeline: Formula-LLM Adaptive Evaluation (FLAE) for report quality, Trustworthy Retrieval-Aligned Citation Evaluation (TRACE) for citation-grounded evidence alignment, and Multimodal Support-Aligned Integrity Check (MOSAIC) for text-visual integrity, each producing fine-grained signals that support error diagnosis beyond a single overall score. Experiments across 25 state-of-the-art models reveal systematic trade-offs between generation quality, citation discipline, and multimodal grounding, highlighting that strong prose alone does not guarantee faithful evidence use and that multimodal integrity remains a key bottleneck for deep research agents.

</details>


### [204] [Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models](https://arxiv.org/abs/2601.12626)
*Raphi Kang,Hongqiao Chen,Georgia Gkioxari,Pietro Perona*

Main category: cs.CV

Relevance: 85.0

TL;DR: 论文发现视觉语言模型通过线性绑定空间ID到文本激活来编码物体位置，并通过语言token进行推理，揭示了VLM内部的空间推理机制


<details>
  <summary>Details</summary>
Motivation: 研究视觉语言模型中时空推理能力的底层机制，探索视觉/几何表示与文本表示如何结合，并理解这些表示如何因果地解释模型行为

Method: 通过线性模型搜索视觉和文本表示的结合点，进行严格的因果干预实验，识别空间ID机制，并将分析扩展到视频VLM的时间ID机制

Result: 发现VLMs通过线性绑定空间ID到文本激活来编码物体位置，这些ID在模型各层普遍存在并能系统性地调节模型信念，同时可作为诊断工具和学习信号

Conclusion: 揭示了VLM中先前未被充分探索的内部推理过程，为改进模型可解释性和设计更对齐、更强大的模型提供了理论基础

Abstract: Spatio-temporal reasoning is a remarkable capability of Vision Language Models (VLMs), but the underlying mechanisms of such abilities remain largely opaque. We postulate that visual/geometrical and textual representations of spatial structure must be combined at some point in VLM computations. We search for such confluence, and ask whether the identified representation can causally explain aspects of input-output model behavior through a linear model. We show empirically that VLMs encode object locations by linearly binding \textit{spatial IDs} to textual activations, then perform reasoning via language tokens. Through rigorous causal interventions we demonstrate that these IDs, which are ubiquitous across the model, can systematically mediate model beliefs at intermediate VLM layers. Additionally, we find that spatial IDs serve as a diagnostic tool for identifying limitations in existing VLMs, and as a valuable learning signal. We extend our analysis to video VLMs and identify an analogous linear temporal ID mechanism. By characterizing our proposed spatiotemporal ID mechanism, we elucidate a previously underexplored internal reasoning process in VLMs, toward improved interpretability and the principled design of more aligned and capable models. We release our code for reproducibility: https://github.com/Raphoo/linear-mech-vlms.

</details>


### [205] [Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data](https://arxiv.org/abs/2601.12809)
*Takaki Yamamoto,Chihiro Noguchi,Toshihiro Tanizawa*

Main category: cs.CV

Relevance: 85.0

TL;DR: 本文通过可控的1D图像-文本测试平台，探究了CLIP风格模型中左右关系理解的涌现机制，发现标签多样性比布局多样性更能促进泛化，并通过注意力分解揭示了位置嵌入与词元嵌入的交互如何打破左右对称性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型的空间理解能力仍是一个关键挑战。目前尚不清楚这种理解是否真正被习得，以及通过何种机制习得。本文旨在探究Transformer视觉和文本编码器在CLIP风格对比目标训练下，左右关系理解如何涌现。

Method: 构建可控的1D图像-文本测试平台，训练轻量级Transformer视觉和文本编码器端到端，使用单物体和双物体场景的配对描述。评估对未见物体对的泛化能力，系统性地变化标签和布局多样性。通过注意力分解分析机制。

Result: 对比训练确实学习了左右关系，其中标签多样性比布局多样性更能驱动泛化。注意力分解显示位置嵌入与词元嵌入的交互诱导了水平注意力梯度，打破了编码器中的左右对称性；消除这一贡献会显著降低左右辨别能力。

Conclusion: 研究提供了CLIP风格模型何时以及如何获得关系能力的机制性见解，揭示了位置-词元交互在空间关系理解中的关键作用。

Abstract: Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.

</details>


### [206] [CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning](https://arxiv.org/abs/2601.13304)
*Wenxin Ma,Chenlong Wang,Ruisheng Yuan,Hao Chen,Nanru Dai,S. Kevin Zhou,Yijun Yang,Alan Yuille,Jieneng Chen*

Main category: cs.CV

Relevance: 85.0

TL;DR: 论文提出了CausalSpatial基准测试，评估多模态大语言模型在因果空间推理（预测物体运动后果）上的能力，发现模型表现远低于人类，并提出了Causal Object World model (COW)框架来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 人类能够观察静态场景并预测后续事件（如物体移动是否会导致碰撞），这种因果空间推理能力是当前多模态大语言模型所缺乏的。模型主要局限于静态空间感知，难以回答3D场景中的"what-if"问题。

Method: 1) 创建CausalSpatial诊断基准，包含碰撞、兼容性、遮挡和轨迹四个任务；2) 分析模型失败原因，发现模型过度依赖文本思维链推理而偏离视觉证据；3) 提出Causal Object World model (COW)框架，通过生成假设动态的视频来外化模拟过程。

Result: 人类在基准测试中得分84%，而GPT-5仅得54%，存在显著差距。分析显示模型产生流畅但空间上无根据的幻觉。COW框架通过提供明确的因果视觉线索，使模型能够基于物理现实而非语言先验进行推理。

Conclusion: 当前MLLMs在因果空间推理方面存在根本性缺陷，需要新的方法将推理过程与视觉证据更紧密地结合。COW框架通过外化模拟过程为解决这一问题提供了有前景的方向。

Abstract: Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer "what-if" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: https://github.com/CausalSpatial/CausalSpatial

</details>


### [207] [Scaling Test-time Inference for Visual Grounding](https://arxiv.org/abs/2601.13633)
*Guanqi Zhan,Changye Li,Zhijian Liu,Yao Lu,Yi Wu,Song Han,Ligeng Zhu*

Main category: cs.CV

Relevance: 85.0

TL;DR: EGM通过扩展小型视觉语言模型的测试时计算（生成更多token）来提升视觉定位能力，在保持部署友好性的同时达到或超越大型模型性能，显著降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的视觉定位模型通常模型尺寸较大，部署困难且推理缓慢。研究发现小型和大型VLMs的主要差异在于语言模型大小而非视觉编码器，小型模型因语言理解能力不足而落后。需要一种部署友好且高效的方法来缩小这一差距。

Method: 提出EGM方法，通过扩展小型模型的测试时计算（增加生成token数量）来提升视觉定位能力。这种方法部署友好，因为每个token的生成成本远低于直接运行大型模型，从而在保持小模型优势的同时提升性能。

Result: 在RefCOCO基准测试中，EGM-Qwen3-VL-8B达到91.4 IoU，平均延迟737ms（比Qwen3-VL-235B快5.9倍），而后者需要4320ms达到90.5 IoU。在新建立的amodal grounding设置中，该方法也能持续显著提升小型模型的定位能力，达到或超越大型模型水平。

Conclusion: EGM方法通过扩展测试时计算，有效提升了小型视觉语言模型的视觉定位能力，在保持部署友好性和低延迟的同时达到或超越大型模型性能，为视觉定位任务提供了高效的解决方案。

Abstract: Visual grounding is an essential capability of Visual Language Models (VLMs) to understand the real physical world. Previous state-of-the-art grounding visual language models usually have large model sizes, making them heavy for deployment and slow for inference. However, we notice that the sizes of visual encoders are nearly the same for small and large VLMs and the major difference is the sizes of the language models. Small VLMs fall behind larger VLMs in grounding because of the difference in language understanding capability rather than visual information handling. To mitigate the gap, we introduce 'Efficient visual Grounding language Models' (EGM): a method to scale the test-time computation (#generated tokens). Scaling the test-time computation of a small model is deployment-friendly, and yields better end-to-end latency as the cost of each token is much cheaper compared to directly running a large model. On the RefCOCO benchmark, our EGM-Qwen3-VL-8B demonstrates 91.4 IoU with an average of 737ms (5.9x faster) latency while Qwen3-VL-235B demands 4,320ms to achieve 90.5 IoU. To validate our approach's generality, we further set up a new amodal grounding setting that requires the model to predict both the visible and occluded parts of the objects. Experiments show our method can consistently and significantly improve the vanilla grounding and amodal grounding capabilities of small models to be on par with or outperform the larger models, thereby improving the efficiency for visual grounding.

</details>


### [208] [Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2601.13707)
*Yujin Jo,Sangyoon Bae,Taesup Kim*

Main category: cs.CV

Relevance: 85.0

TL;DR: 提出Attention-space Contrastive Guidance (ACG)方法，通过单次前向计算在自注意力层构建视觉-语言和纯语言注意力路径，减少大视觉语言模型中的幻觉问题，降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型(LVLMs)中的幻觉问题通常源于语言先验主导视觉证据，导致物体误识别和视觉不一致描述。需要解决语言先验过度依赖的问题，使生成更基于视觉证据。

Method: 提出注意力空间对比引导(ACG)：1) 单次前向机制在自注意力层同时构建视觉-语言和纯语言注意力路径；2) 应用正交化校正消除纯语言路径对齐分量，选择性增强视觉贡献；3) 通过对比引导减少语言先验依赖，增强视觉基础。

Result: 在CHAIR和POPE基准测试中达到最先进的忠实度和字幕质量，同时显著降低计算成本。相比需要多次前向传播的对比解码方法，延迟降低高达2倍。

Conclusion: ACG为幻觉缓解提供了原则性和高效的替代方案，通过单次前向计算在注意力空间进行对比引导，有效平衡视觉和语言信息，提升生成文本的视觉基础性和语义忠实度。

Abstract: Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes.

</details>


### [209] [Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning](https://arxiv.org/abs/2601.13942)
*Hongbo Bai,Yujin Zhou,Yile Wu,Chi-Min Chan,Pengcheng Wen,Kunhao Pan,Sirui Han,Yike Guo*

Main category: cs.CV

Relevance: 85.0

TL;DR: GoG框架通过选择性注视机制和复杂度自适应强化学习，解决了大型多模态模型在处理知识密集型视觉查询时的局限性，实现了从被动感知到主动视觉规划的转变。


<details>
  <summary>Details</summary>
Motivation: 当前大型多模态模型在视觉理解方面取得了显著成功，但在处理涉及长尾实体或动态信息的知识密集型查询时存在局限，主要原因是静态参数化知识。现有的搜索增强方法存在视觉冗余和噪声问题，缺乏深度迭代反思，限制了在复杂视觉查询上的有效性。

Method: 提出了Glance-or-Gaze (GoG)框架，包含选择性注视机制（动态选择全局上下文或高价值区域）和双阶段训练策略：1）通过监督微调进行反思性GoG行为对齐，2）复杂度自适应强化学习增强处理复杂查询的能力。

Result: 在六个基准测试中展示了最先进的性能，消融研究证实选择性注视机制和复杂度自适应强化学习对有效视觉搜索都是必要的。

Conclusion: GoG框架通过从被动感知转向主动视觉规划，有效解决了大型多模态模型在知识密集型视觉查询中的局限性，为视觉搜索提供了新的解决方案。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon.

</details>


### [210] [The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning](https://arxiv.org/abs/2601.14127)
*Renmiao Chen,Yida Lu,Shiyao Cui,Xuan Ouyang,Victor Shea-Jay Huang,Shumin Zhang,Chengwei Pan,Han Qiu,Minlie Huang*

Main category: cs.CV

Relevance: 85.0

TL;DR: 该论文提出了首个专注于多图像推理安全性的基准测试MIR-SafetyBench，包含2676个实例和9种多图像关系分类。研究发现，具有更强多图像推理能力的MLLM在安全性方面反而更脆弱，且许多被标记为安全的回答实际上是肤浅的误解或回避性回复。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型（MLLMs）在处理复杂多图像指令方面的推理能力增强，这种进步可能带来新的安全风险。目前缺乏专门评估多图像推理安全性的基准测试，需要研究模型在增强推理能力的同时是否牺牲了安全性。

Method: 1. 构建MIR-SafetyBench基准测试，包含2676个实例，涵盖9种多图像关系分类；2. 对19个MLLM进行广泛评估；3. 分析攻击成功率、回答质量（肤浅/误解/回避性回复）；4. 研究不安全生成与注意力熵的关系。

Result: 1. 发现令人担忧的趋势：具有更先进多图像推理能力的模型在MIR-SafetyBench上更脆弱；2. 许多被标记为安全的回答实际上是肤浅的误解或回避性回复；3. 不安全生成的平均注意力熵低于安全生成，表明模型可能过度专注于任务解决而忽视安全约束。

Conclusion: 多模态大语言模型在提升多图像推理能力的同时，可能以牺牲安全性为代价。需要开发新的安全机制来平衡推理能力与安全性，注意力熵可能作为检测不安全生成的内在信号。

Abstract: As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.

</details>


### [211] [TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers](https://arxiv.org/abs/2601.14133)
*Bin Yu,Shijie Lian,Xiaopeng Lin,Yuliang Wei,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Xinming Wang,Bailing Wang,Cong Huang,Kai Chen*

Main category: cs.RO

Relevance: 85.0

TL;DR: TwinBrainVLA提出了一种新颖的双脑架构，将通用视觉语言模型与专用机器人控制模型分离，通过非对称混合Transformer机制协调，解决了传统VLA模型在微调时语义理解与运动技能之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 传统视觉-语言-动作模型在微调时面临一个关键矛盾：既要保持高级语义理解能力，又要学习低级的精细运动技能，这通常导致模型出现"灾难性遗忘"，丧失了原有的开放世界能力。需要一种架构能够同时保留通用语义理解和实现精确机器人控制。

Method: 提出TwinBrainVLA架构，包含两个部分：冻结的"左脑"（通用VLM）保持强大的视觉推理能力，可训练的"右脑"（专用VLM）专注于具身感知。通过新颖的非对称混合Transformer机制，右脑可以动态查询左脑的语义知识，并将其与本体感知状态融合，为流匹配动作专家提供丰富的条件信息以生成精确连续控制。

Result: 在SimplerEnv和RoboCasa基准测试上的广泛实验表明，TwinBrainVLA在操作性能上优于最先进的基线方法，同时明确保留了预训练VLM的全面视觉理解能力。

Conclusion: TwinBrainVLA为解决通用语义理解与低级物理灵巧性之间的冲突提供了一个有前景的方向，为构建同时具备高级语义理解和低级物理操作能力的通用机器人提供了新思路。

Abstract: Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to "catastrophic forgetting" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen "Left Brain", which retains robust general visual reasoning, with a trainable "Right Brain", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.

</details>


### [212] [A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow](https://arxiv.org/abs/2601.11630)
*Haonan Wei,Linyuan Wang,Nuolin Sun,Zhizhong Zheng,Lei Li,Bin Yan*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出SLT（单层Transformer），通过蒸馏将28层FreeFlow模型压缩为单个共享DiT块，参数从675M降至4.3M，利用快速采样在噪声空间筛选高质量初始点，提升一步生成的质量和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前流匹配方法（如FreeFlow）旨在将扩散模型的迭代生成过程压缩为一步生成，但28层Transformer架构仍较复杂。观察到FreeFlow的层结构可视为ODE沿深度轴的欧拉离散化，因此希望通过蒸馏减少层数，同时利用快速采样筛选高质量噪声初始点来提升生成质量。

Method: 将FreeFlow的28层Transformer蒸馏为单个共享DiT块（SLT）。训练时匹配教师模型在多个深度补丁的中间特征，融合这些补丁级表示，并同时对齐教师的最终速度预测。利用SLT的快速采样能力在噪声空间筛选候选点，为教师模型选择高质量初始点。

Result: 成功将参数从675M压缩到4.3M。在相当于教师模型两次随机采样的时间内，能进行超过100次噪声筛选，并通过教师模型使用选定点生成高质量样本。有效避免了有限采样次数下低质量初始噪声引起的质量波动，显著提升了一步生成的稳定性和平均质量。

Conclusion: SLT通过蒸馏实现了极致的模型压缩，同时利用快速采样进行噪声空间探索，为一步生成模型提供了高效的质量提升方案。该方法在保持生成质量的同时大幅减少计算开销，为高效图像生成提供了新思路。

Abstract: Currently, Flow matching methods aim to compress the iterative generation process of diffusion models into a few or even a single step, with MeanFlow and FreeFlow being representative achievements of one-step generation based on Ordinary Differential Equations (ODEs). We observe that the 28-layer Transformer architecture of FreeFlow can be characterized as an Euler discretization scheme for an ODE along the depth axis, where the layer index serves as the discrete time step. Therefore, we distill the number of layers of the FreeFlow model, following the same derivation logic as FreeFlow, and propose SLT (Single-Layer Transformer), which uses a single shared DiT block to approximate the depth-wise feature evolution of the 28-layer teacher. During training, it matches the teacher's intermediate features at several depth patches, fuses those patch-level representations, and simultaneously aligns the teacher's final velocity prediction. Through distillation training, we compress the 28 independent Transformer Blocks of the teacher model DiT-XL/2 into a single Transformer Block, reducing the parameter count from 675M to 4.3M. Furthermore, leveraging its minimal parameters and rapid sampling speed, SLT can screen more candidate points in the noise space within the same timeframe, thereby selecting higher-quality initial points for the teacher model FreeFlow and ultimately enhancing the quality of generated images. Experimental results demonstrate that within a time budget comparable to two random samplings of the teacher model, our method performs over 100 noise screenings and produces a high-quality sample through the teacher model using the selected points. Quality fluctuations caused by low-quality initial noise under a limited number of FreeFlow sampling calls are effectively avoided, substantially improving the stability and average generation quality of one-step generation.

</details>


### [213] [KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering](https://arxiv.org/abs/2601.11632)
*Zhiyang Li,Ao Ke,Yukun Cao,Xike Xie*

Main category: cs.CV

Relevance: 75.0

TL;DR: KG-ViP提出统一框架，通过融合场景图和常识图解决MLLMs在VQA中的知识幻觉和细粒度视觉感知不足问题，显著提升VQA性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉问答中存在两个主要限制：知识幻觉（生成与视觉内容不符的知识）和细粒度视觉感知不足。场景图能捕捉细粒度视觉细节，常识图提供丰富外部知识，但现有工作通常孤立处理两者，忽略了它们的协同潜力。

Method: 提出KG-ViP统一框架，通过新颖的检索-融合流程，利用查询作为语义桥梁逐步整合场景图和常识图，合成统一的结构化上下文，促进可靠的多模态推理。

Result: 在FVQA 2.0+和MVQA基准测试上的广泛实验表明，KG-ViP显著优于现有的VQA方法。

Conclusion: 通过融合场景图和常识图，KG-ViP有效解决了MLLMs在VQA中的知识幻觉和视觉感知不足问题，展示了结构化知识融合在多模态推理中的重要性。

Abstract: Multi-modal Large Language Models (MLLMs) for Visual Question Answering (VQA) often suffer from dual limitations: knowledge hallucination and insufficient fine-grained visual perception. Crucially, we identify that commonsense graphs and scene graphs provide precisely complementary solutions to these respective deficiencies by providing rich external knowledge and capturing fine-grained visual details. However, prior works typically treat them in isolation, overlooking their synergistic potential. To bridge this gap, we propose KG-ViP, a unified framework that empowers MLLMs by fusing scene graphs and commonsense graphs. The core of the KG-ViP framework is a novel retrieval-and-fusion pipeline that utilizes the query as a semantic bridge to progressively integrate both graphs, synthesizing a unified structured context that facilitates reliable multi-modal reasoning. Extensive experiments on FVQA 2.0+ and MVQA benchmarks demonstrate that KG-ViP significantly outperforms existing VQA methods.

</details>


### [214] [When Rules Fall Short: Agent-Driven Discovery of Emerging Content Issues in Short Video Platforms](https://arxiv.org/abs/2601.11634)
*Chenghui Yu,Hongwei Wang,Junwen Chen,Zixuan Wang,Bingfeng Deng,Zhuolin Hao,Hongyu Xiong,Yang Song*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出基于多模态LLM智能体的自动问题发现方法，用于短视频平台内容治理，通过两阶段聚类发现新兴内容问题并自动生成标注策略更新。


<details>
  <summary>Details</summary>
Motivation: 短视频平台内容趋势快速演变，新兴问题不断出现，超出已有标注策略覆盖范围。传统人工发现问题速度太慢，导致标注策略更新延迟，严重影响内容治理效果。

Method: 基于多模态LLM智能体的自动问题发现方法：1) 自动召回包含潜在新问题的短视频；2) 采用两阶段聚类策略将视频分组，每个聚类对应一个新发现的问题；3) 智能体从聚类生成更新的标注策略。

Result: 1) 线下线上实验显示，该方法显著提升新兴问题发现效果（F1分数提升超过20%）；2) 改善后续问题治理性能（问题视频观看量减少约15%）；3) 相比人工发现问题，大幅减少时间成本，加速标注策略迭代。

Conclusion: 基于多模态LLM智能体的自动问题发现方法能有效解决短视频平台内容治理中的新兴问题发现延迟问题，已在真实系统中部署，显著提升治理效率和效果。

Abstract: Trends on short-video platforms evolve at a rapid pace, with new content issues emerging every day that fall outside the coverage of existing annotation policies. However, traditional human-driven discovery of emerging issues is too slow, which leads to delayed updates of annotation policies and poses a major challenge for effective content governance. In this work, we propose an automatic issue discovery method based on multimodal LLM agents. Our approach automatically recalls short videos containing potential new issues and applies a two-stage clustering strategy to group them, with each cluster corresponding to a newly discovered issue. The agent then generates updated annotation policies from these clusters, thereby extending coverage to these emerging issues. Our agent has been deployed in the real system. Both offline and online experiments demonstrate that this agent-based method significantly improves the effectiveness of emerging-issue discovery (with an F1 score improvement of over 20%) and enhances the performance of subsequent issue governance (reducing the view count of problematic videos by approximately 15%). More importantly, compared to manual issue discovery, it greatly reduces time costs and substantially accelerates the iteration of annotation policies.

</details>


### [215] [Evaluating Self-Correcting Vision Agents Through Quantitative and Qualitative Metrics](https://arxiv.org/abs/2601.11637)
*Aradhya Dixit*

Main category: cs.CV

Relevance: 75.0

TL;DR: 本文提出了一个诊断性微基准测试，用于量化评估视觉语言代理的自我纠正能力，揭示了任务成功率与纠正成功率之间的差距，并识别了语义漂移作为主要失败原因。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型使得视觉语言代理能够将复杂视觉任务分解为可执行的工具计划，但现有基准测试对迭代自我纠正能力的评估有限。当前缺乏对自我纠正定量限制和主要推理瓶颈的系统性分析。

Method: 引入诊断性微基准测试，将任务成功率与纠正成功率解耦分析，量化纠正的递减回报（在三次重试后饱和），并通过失败分类法识别主要失败模式，特别是语义漂移（约28%的失败）。

Result: 任务成功率为62%，但纠正成功率仅为25-33%，表明初始能力不能预测修复能力。纠正效果在三次尝试后达到饱和，语义漂移是主要失败原因，占失败案例的28%。

Conclusion: 该基准测试为评估多模态代理的自我纠正能力提供了可复现框架，揭示了语义漂移这一关键推理瓶颈，为开发具有状态保持能力的可信多模态代理指明了方向。

Abstract: Recent progress in multimodal foundation models has enabled Vision-Language Agents (VLAs) to decompose complex visual tasks into executable tool-based plans. While recent benchmarks have begun to evaluate iterative self-correction, its quantitative limits and dominant reasoning bottlenecks remain poorly characterized. This work introduces a Diagnostic Micro-Benchmark. Our analysis decouples Task Success Rate (TSR = 62 percent) from Correction Success Rate (CSR = 25 to 33 percent), revealing that initial competence does not predict repair ability. We explicitly quantify the diminishing returns of correction, which saturates after three retries. Our Failure Taxonomy reveals a frequent factor is Semantic Drift (about 28 percent of failures), a loss of contextual state. By isolating this reasoning bottleneck, this benchmark defines a reproducible framework toward stateful, trustworthy multimodal agents.

</details>


### [216] [Predicting When to Trust Vision-Language Models for Spatial Reasoning](https://arxiv.org/abs/2601.11644)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出基于视觉的置信度估计框架，通过物体检测的几何验证来预测VLM空间推理的可靠性，相比基于文本的自评估方法有显著改进


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在空间推理方面存在系统性失败（准确率仅49-54%），在机器人和自动驾驶等安全关键应用中需要预测何时信任VLM的空间预测

Method: 提出视觉置信度估计框架，通过物体检测进行独立几何验证，融合四个信号：VLM声明与坐标的几何对齐、空间重叠的模糊性、检测质量、VLM内部不确定性

Result: 在BLIP-2上AUROC达到0.674（比文本基线提升34.0%），在CLIP上达到0.583（提升16.1%）；在60%目标准确率下，覆盖率达到61.9%（基线27.6%）；场景图构建中精度从52.1%提升到78.3%

Conclusion: 外部几何验证比VLM自评估更有效，视觉信号贡献87.4%的重要性；该框架能实现选择性预测，提高VLM在空间推理任务中的可靠性

Abstract: Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks, yet exhibit systematic spatial reasoning failures, achieving only 49% (CLIP) to 54% (BLIP-2) accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, we need to predict when to trust VLM spatial predictions rather than accepting all outputs. We propose a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches relying on self-assessment, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. We achieve 0.674 AUROC on BLIP-2 (34.0% improvement over text-based baselines) and 0.583 AUROC on CLIP (16.1% improvement), generalizing across generative and classification architectures. Our framework enables selective prediction: at 60% target accuracy, we achieve 61.9% coverage versus 27.6% baseline (2.2x improvement) on BLIP-2. Feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence, validating that external geometric verification outperforms self-assessment. We demonstrate reliable scene graph construction where confidence-based pruning improves precision from 52.1% to 78.3% while retaining 68.2% of edges.

</details>


### [217] [MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models](https://arxiv.org/abs/2601.11666)
*Muhammad Imran,Chi Lee,Yugyung Lee*

Main category: cs.CV

Relevance: 75.0

TL;DR: MATEX是一个用于医学视觉语言模型可解释性的新框架，通过结合多尺度注意力展开、文本引导空间先验和层一致性分析，生成精确、稳定且临床相关的梯度归因图。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型的可解释性方法存在空间不精确、缺乏解剖学基础和注意力粒度有限等关键限制，这影响了模型解释的临床可信度和实用性。

Method: MATEX框架结合了多层级注意力展开、文本引导的空间先验和层一致性分析，通过解剖学信息增强空间推理能力，生成精确的梯度归因图。

Result: 在MS-CXR数据集上的评估显示，MATEX在空间精度和与专家标注结果的匹配度方面均优于当前最先进的M2IB方法。

Conclusion: MATEX通过提供更忠实和可解释的模型解释，增强了放射学AI应用中的信任和透明度，为医学视觉语言模型的可解释性提供了有效解决方案。

Abstract: We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.

</details>


### [218] [SpaRRTa: A Synthetic Benchmark for Evaluating Spatial Intelligence in Visual Foundation Models](https://arxiv.org/abs/2601.11729)
*Turhan Can Kargin,Wojciech Jasiński,Adam Pardyl,Bartosz Zieliński,Marcin Przewięźlikowski*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出了SpaRRTa基准测试，用于评估视觉基础模型的空间关系识别能力，发现现有模型在空间推理方面存在显著差异


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型（如DINO、CLIP）在语义理解方面表现出色，但空间推理能力有限，限制了它们在具身系统中的应用。现有研究虽然引入了3D任务（如深度估计），但模型在不同空间任务上的表现不一致，需要评估这些模型是否真正具有空间意识还是仅仅过拟合于特定3D目标。

Method: 提出了空间关系识别任务（SpaRRTa）基准测试，通过生成任意数量的逼真图像，包含多样化场景和完全可控的对象排列，同时提供可自由访问的空间标注。使用该基准评估了一系列最先进的视觉基础模型。

Result: 评估结果显示，不同视觉基础模型在空间推理能力方面存在显著差异。分析揭示了支持或阻碍现代视觉基础模型空间意识的机制。

Conclusion: SpaRRTa基准测试能够有效评估视觉基础模型的空间关系识别能力，为未来具有空间意识的视觉模型开发提供指导工具。

Abstract: Visual Foundation Models (VFMs), such as DINO and CLIP, excel in semantic understanding of images but exhibit limited spatial reasoning capabilities, which limits their applicability to embodied systems. As a result, recent work incorporates some 3D tasks (such as depth estimation) into VFM training. However, VFM performance remains inconsistent across other spatial tasks, raising the question of whether these models truly have spatial awareness or overfit to specific 3D objectives. To address this question, we introduce the Spatial Relation Recognition Task (SpaRRTa) benchmark, which evaluates the ability of VFMs to identify relative positions of objects in the image. Unlike traditional 3D objectives that focus on precise metric prediction (e.g., surface normal estimation), SpaRRTa probes a fundamental capability underpinning more advanced forms of human-like spatial understanding. SpaRRTa generates an arbitrary number of photorealistic images with diverse scenes and fully controllable object arrangements, along with freely accessible spatial annotations. Evaluating a range of state-of-the-art VFMs, we reveal significant disparities between their spatial reasoning abilities. Through our analysis, we provide insights into the mechanisms that support or hinder spatial awareness in modern VFMs. We hope that SpaRRTa will serve as a useful tool for guiding the development of future spatially aware visual models.

</details>


### [219] [From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce](https://arxiv.org/abs/2601.11769)
*Cheng Lyu,Jingyue Zhang,Ryan Maunu,Mengwei Li,Vinny DeGenova,Yuanli Pei*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出了一种解耦分类法的视觉搜索架构，使用无分类区域建议和统一嵌入进行相似性检索，并采用LLM-as-a-Judge框架进行零样本评估，在电商平台部署后提升了检索质量和用户参与度。


<details>
  <summary>Details</summary>
Motivation: 电商视觉搜索面临挑战：现有工业系统通常将目标检测与基于分类法的分类耦合，依赖目录数据进行评估，这种方法容易受到噪声影响，限制了系统的鲁棒性和可扩展性。特别是在风格驱动的领域，用户意图主观且开放，需要更灵活通用的解决方案。

Method: 1. 提出分类法解耦架构：使用无分类的区域建议和统一嵌入进行相似性检索，实现更灵活通用的视觉搜索。2. 提出LLM-as-a-Judge评估框架：以零样本方式评估查询-结果对的细微视觉相似性和类别相关性，摆脱对人类标注或噪声目录数据的依赖。

Result: 1. 在全球家居用品平台大规模部署，提高了检索质量并带来可衡量的客户参与度提升。2. 离线评估指标与实际业务结果强相关，验证了方法的有效性。

Conclusion: 提出的分类法解耦视觉搜索架构结合LLM评估框架，解决了现有工业系统的局限性，在电商应用中表现出更好的鲁棒性、可扩展性和实际业务价值。

Abstract: Visual search is critical for e-commerce, especially in style-driven domains where user intent is subjective and open-ended. Existing industrial systems typically couple object detection with taxonomy-based classification and rely on catalog data for evaluation, which is prone to noise that limits robustness and scalability. We propose a taxonomy-decoupled architecture that uses classification-free region proposals and unified embeddings for similarity retrieval, enabling a more flexible and generalizable visual search. To overcome the evaluation bottleneck, we propose an LLM-as-a-Judge framework that assesses nuanced visual similarity and category relevance for query-result pairs in a zero-shot manner, removing dependence on human annotations or noise-prone catalog data. Deployed at scale on a global home goods platform, our system improves retrieval quality and yields a measurable uplift in customer engagement, while our offline evaluation metrics strongly correlate with real-world outcomes.

</details>


### [220] [AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search](https://arxiv.org/abs/2601.12272)
*Shahrzad Esmat,Mahdi Banisharif,Ali Jannesari*

Main category: cs.CV

Relevance: 75.0

TL;DR: AgenticPruner：利用LLM进行MAC约束优化的神经网络剪枝框架，通过三个智能体协作实现计算预算控制，在ImageNet上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络剪枝方法主要关注参数减少，但无法直接控制计算成本，导致在严格MAC预算场景下推理延迟不可预测。需要一种能直接控制计算成本的剪枝方法。

Method: 提出AgenticPruner框架，利用LLM进行MAC约束优化：1) Profiling Agent分析模型架构和MAC分布；2) Master Agent协调工作流并监控分歧；3) Analysis Agent（基于Claude 3.5 Sonnet）从历史尝试中学习最优策略。基于同构剪枝的图结构分组，增加跨剪枝迭代的模式分析，实现上下文感知适应。

Result: 在ImageNet-1K上验证：CNN方面，ResNet-50达到1.77G MACs，准确率77.04%（+0.91%）；ResNet-101达到4.22G MACs，准确率78.94%（+1.56%）。ConvNeXt-Small剪枝到8.17G MACs，实现1.41x GPU和1.07x CPU加速，参数减少45%。Vision Transformers能在用户定义容差带内满足MAC预算。

Conclusion: AgenticPruner通过LLM驱动的智能体协作，实现了MAC约束的神经网络剪枝，为需要严格计算保证的部署场景提供了可行方案。

Abstract: Neural network pruning remains essential for deploying deep learning models on resource-constrained devices, yet existing approaches primarily target parameter reduction without directly controlling computational cost. This yields unpredictable inference latency in deployment scenarios where strict Multiply-Accumulate (MAC) operation budgets must be met. We propose AgenticPruner, a framework utilizing large language models to achieve MAC-constrained optimization through iterative strategy learning. Our approach coordinates three specialized agents: a Profiling Agent that analyzes model architecture and MAC distributions, a Master Agent that orchestrates the workflow with divergence monitoring, and an Analysis Agent powered by Claude 3.5 Sonnet that learns optimal strategies from historical attempts. Through in-context learning, the Analysis Agent improves convergence success rate from 48% to 71% compared to grid search. Building upon isomorphic pruning's graph-based structural grouping, our method adds context-aware adaptation by analyzing patterns across pruning iterations, enabling automatic convergence to target MAC budgets within user-defined tolerance bands.
  We validate our framework on ImageNet-1K across ResNet, ConvNeXt, and DeiT architectures. On CNNs, our approach achieves MAC targeting while maintaining or improving accuracy: ResNet-50 reaches 1.77G MACs with 77.04% accuracy (+0.91% vs baseline); ResNet-101 achieves 4.22G MACs with 78.94% accuracy (+1.56% vs baseline). For ConvNeXt-Small, pruning to 8.17G MACs yields 1.41x GPU and 1.07x CPU speedup with 45% parameter reduction. On Vision Transformers, we demonstrate MAC-budget compliance within user-defined tolerance bands (typically +1% to +5% overshoot, -5% to -15% undershoot), establishing feasibility for deployment scenarios requiring strict computational guarantees.

</details>


### [221] [SDiT: Semantic Region-Adaptive for Diffusion Transformers](https://arxiv.org/abs/2601.12283)
*Bowen Lin,Fanjiang Ye,Yihua Liu,Zhenghui Guo,Boyuan Zhang,Weijian Zheng,Yufan Xu,Tiancheng Xing,Yuke Wang,Chengming Zhang*

Main category: cs.CV

Relevance: 75.0

TL;DR: SDiT：基于语义区域自适应的扩散Transformer，通过观察去噪过程的空间不均匀性（背景区域快速收敛而边缘纹理区域活跃），提出无需训练的框架，结合语义聚类、复杂度驱动调度和边界感知细化，实现3倍加速且保持感知质量


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer（DiTs）在文本到图像合成中达到SOTA性能，但由于迭代去噪和全局注意力的二次计算成本，计算开销大。观察到去噪动态在空间上不均匀：背景区域快速收敛，而边缘和纹理区域演化更活跃。

Method: 提出SDiT（语义区域自适应扩散Transformer）：1）基于快速Quickshift的语义感知聚类进行分割；2）复杂度驱动的区域调度，选择性更新信息丰富区域；3）边界感知细化以保持空间连贯性。无需模型重训练或架构修改。

Result: SDiT实现高达3.0倍的加速，同时保持与全注意力推理几乎相同的感知和语义质量。

Conclusion: 通过利用去噪过程的空间不均匀性，SDiT提供了一种无需训练的高效推理框架，显著加速扩散Transformer同时保持生成质量。

Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.

</details>


### [222] [Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations](https://arxiv.org/abs/2601.12303)
*Shizhan Gong,Xiaofan Zhang,Qi Dou*

Main category: cs.CV

Relevance: 75.0

TL;DR: PCBM-ReD：一种通过表示分解的后处理概念瓶颈模型，为预训练黑盒模型添加可解释性，使用MLLM自动提取视觉概念，在保持高精度的同时提升模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有概念解释方法存在概念相关性不可靠、概念定义非视觉化或劳动密集、模型或数据无关假设等局限性。需要一种方法能够为预训练的黑盒模型添加可解释性，同时保持高性能。

Method: 1. 从预训练编码器自动提取视觉概念；2. 使用多模态大语言模型（MLLMs）基于视觉可识别性和任务相关性标记和过滤概念；3. 通过重建引导优化选择独立概念子集；4. 利用CLIP的视觉-文本对齐，将图像表示分解为概念嵌入的线性组合，适配概念瓶颈模型框架。

Result: 在11个图像分类任务上的实验表明，PCBM-ReD达到最先进的准确率，缩小了与端到端模型的性能差距，并展现出更好的可解释性。

Conclusion: PCBM-ReD成功为预训练黑盒模型添加了可解释性，通过自动概念提取和表示分解实现了高性能与可解释性的平衡，为可信AI提供了新方法。

Abstract: Deep learning has achieved remarkable success in image recognition, yet their inherent opacity poses challenges for deployment in critical domains. Concept-based interpretations aim to address this by explaining model reasoning through human-understandable concepts. However, existing post-hoc methods and ante-hoc concept bottleneck models (CBMs), suffer from limitations such as unreliable concept relevance, non-visual or labor-intensive concept definitions, and model or data-agnostic assumptions. This paper introduces Post-hoc Concept Bottleneck Model via Representation Decomposition (PCBM-ReD), a novel pipeline that retrofits interpretability onto pretrained opaque models. PCBM-ReD automatically extracts visual concepts from a pre-trained encoder, employs multimodal large language models (MLLMs) to label and filter concepts based on visual identifiability and task relevance, and selects an independent subset via reconstruction-guided optimization. Leveraging CLIP's visual-text alignment, it decomposes image representations into linear combination of concept embeddings to fit into the CBMs abstraction. Extensive experiments across 11 image classification tasks show PCBM-ReD achieves state-of-the-art accuracy, narrows the performance gap with end-to-end models, and exhibits better interpretability.

</details>


### [223] [S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation](https://arxiv.org/abs/2601.12719)
*Lin Zhao,Yushu Wu,Aleksei Lebedev,Dishani Lahiri,Meng Dong,Arpit Sahni,Michael Vasilkovsky,Hao Chen,Ju Hu,Aliaksandr Siarohin,Sergey Tulyakov,Yanzhi Wang,Anil Kag,Yanyu Li*

Main category: cs.CV

Relevance: 75.0

TL;DR: S2DiT：面向移动硬件的流式三明治扩散Transformer，通过高效注意力机制和动态规划搜索实现高质量实时视频生成，在iPhone上达到10+FPS。


<details>
  <summary>Details</summary>
Motivation: 当前Diffusion Transformers（DiTs）在视频生成质量上虽有提升，但计算成本过高，无法实现实时或设备端生成。需要设计高效、高保真且支持流式生成的移动端视频生成模型。

Method: 1) 提出Streaming Sandwich Diffusion Transformer (S2DiT)，采用混合高效注意力机制：LinConv Hybrid Attention (LCHA) 和 Stride Self-Attention (SSA)；2) 通过预算感知动态规划搜索发现三明治设计；3) 提出2合1蒸馏框架，将大教师模型能力迁移到紧凑的少步三明治模型中。

Result: S2DiT在质量上与最先进的服务器视频模型相当，同时在iPhone上实现超过10 FPS的流式生成性能。

Conclusion: S2DiT通过创新的高效注意力机制、三明治架构设计和知识蒸馏，实现了移动端高质量实时视频生成，为设备端AI视频应用开辟了新途径。

Abstract: Diffusion Transformers (DiTs) have recently improved video generation quality. However, their heavy computational cost makes real-time or on-device generation infeasible. In this work, we introduce S2DiT, a Streaming Sandwich Diffusion Transformer designed for efficient, high-fidelity, and streaming video generation on mobile hardware. S2DiT generates more tokens but maintains efficiency with novel efficient attentions: a mixture of LinConv Hybrid Attention (LCHA) and Stride Self-Attention (SSA). Based on this, we uncover the sandwich design via a budget-aware dynamic programming search, achieving superior quality and efficiency. We further propose a 2-in-1 distillation framework that transfers the capacity of large teacher models (e.g., Wan 2.2-14B) to the compact few-step sandwich model. Together, S2DiT achieves quality on par with state-of-the-art server video models, while streaming at over 10 FPS on an iPhone.

</details>


### [224] [Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration](https://arxiv.org/abs/2601.12766)
*Lu Yue,Yue Fan,Shiwei Lian,Yu Zhao,Jiaxin Yu,Liang Xie,Feitian Zhang*

Main category: cs.CV

Relevance: 75.0

TL;DR: Spatial-VLN：一个感知引导的探索框架，通过空间感知增强和专家推理解决视觉语言导航中的空间挑战，在复杂连续环境中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的零样本视觉语言导航代理在泛化能力上表现优异，但在复杂连续环境中存在空间感知不足的问题，特别是在门交互、多房间导航和模糊指令执行等关键空间挑战上失败率较高。

Method: 提出Spatial-VLN框架，包含两个核心模块：1) 空间感知增强模块，通过全景过滤和专门的门/区域专家生成空间一致、跨视图一致的感知表示；2) 探索多专家推理模块，使用并行LLM专家处理路径点级语义和区域级空间转换，当专家预测不一致时激活查询探索机制主动探测关键区域。

Result: 在VLN-CE基准测试中实现了最先进的性能，仅使用低成本LLM。通过基于价值的路径点采样策略有效弥合Sim2Real差距，真实世界评估证实了优越的泛化能力和鲁棒性。

Conclusion: Spatial-VLN通过增强空间感知和主动探索机制，有效解决了视觉语言导航中的关键空间挑战，为复杂环境中的零样本导航提供了实用解决方案，并展示了良好的真实世界适用性。

Abstract: Zero-shot Vision-and-Language Navigation (VLN) agents leveraging Large Language Models (LLMs) excel in generalization but suffer from insufficient spatial perception. Focusing on complex continuous environments, we categorize key perceptual bottlenecks into three spatial challenges: door interaction,multi-room navigation, and ambiguous instruction execution, where existing methods consistently suffer high failure rates. We present Spatial-VLN, a perception-guided exploration framework designed to overcome these challenges. The framework consists of two main modules. The Spatial Perception Enhancement (SPE) module integrates panoramic filtering with specialized door and region experts to produce spatially coherent, cross-view consistent perceptual representations. Building on this foundation, our Explored Multi-expert Reasoning (EMR) module uses parallel LLM experts to address waypoint-level semantics and region-level spatial transitions. When discrepancies arise between expert predictions, a query-and-explore mechanism is activated, prompting the agent to actively probe critical areas and resolve perceptual ambiguities. Experiments on VLN-CE demonstrate that Spatial VLN achieves state-of-the-art performance using only low-cost LLMs. Furthermore, to validate real-world applicability, we introduce a value-based waypoint sampling strategy that effectively bridges the Sim2Real gap. Extensive real-world evaluations confirm that our framework delivers superior generalization and robustness in complex environments. Our codes and videos are available at https://yueluhhxx.github.io/Spatial-VLN-web/.

</details>


### [225] [Think3D: Thinking with Space for Spatial Reasoning](https://arxiv.org/abs/2601.13029)
*Zaibin Zhang,Yuhan Wu,Lianjie Jia,Yifan Wang,Zhongbo Zhang,Yijiang Li,Binghao Ran,Fuxi Zhang,Zhuohan Sun,Zhenfei Yin,Lijun Wang,Huchuan Lu*

Main category: cs.CV

Relevance: 75.0

TL;DR: Think3D是一个无需训练的框架，通过3D重建模型和相机操作，让视觉大模型具备交互式3D空间推理能力，显著提升空间推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉大模型（VLMs）本质上是2D感知器，缺乏真正的3D空间推理能力。物理世界理解需要空间智能，包括几何、视角和空间关系的解释能力。

Method: 利用3D重建模型从图像/视频恢复点云和相机姿态，通过相机操作（移动、旋转）和视角切换（自我/全局视图），将空间推理转化为交互式3D思维链过程。

Result: 无需额外训练，显著提升GPT-4.1和Gemini 2.5 Pro等先进模型的空间推理性能：BLINK Multi-view和MindCube平均提升7.8%，VSI-Bench提升4.7%。小模型通过强化学习策略选择信息丰富的视角和操作，工具使用收益从0.7%提升到6.8%。

Conclusion: 无需训练的工具增强空间探索是实现更灵活、类人3D推理的可行路径，建立了多模态智能的新维度。

Abstract: Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.

</details>


### [226] [GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction](https://arxiv.org/abs/2601.13207)
*Jinnao Li,Zijian Chen,Tingzhu Chen,Changbo Wang*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出了GTPred基准测试，用于评估多模态大语言模型在结合时空信息的地理定位任务上的表现，包含370张全球分布、时间跨度120年的图像。


<details>
  <summary>Details</summary>
Motivation: 现有地理定位研究大多忽略图像中的时间信息，而时间信息可以进一步约束位置推断。为了填补这一空白，需要建立包含时空信息的基准测试来评估MLLMs的能力。

Method: 构建GTPred基准测试，包含370张全球分布、时间跨度120年的图像。评估方法包括：1) 联合考虑年份和分层位置序列匹配；2) 使用精心标注的真实推理过程评估中间推理链。

Result: 在8个专有和7个开源MLLMs上的实验表明：尽管模型具有较强的视觉感知能力，但在世界知识和地理时空推理方面仍有局限。结果还显示，结合时间信息能显著提升位置推断性能。

Conclusion: 当前MLLMs在结合时空信息的地理定位任务上仍有不足，需要提升世界知识和时空推理能力。GTPred基准为评估和改进MLLMs的时空推理能力提供了重要工具。

Abstract: Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.

</details>


### [227] [A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models](https://arxiv.org/abs/2601.13238)
*Chengyin Hu,Xiang Chen,Zhe Jia,Weiwen Shi,Fengyu Zhang,Jiujiang Guo,Yiwei Wei*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出首个利用真实天气条件攻击视觉语言模型（VLM）的对抗框架，通过两阶段参数化扰动模型分析雨天场景下的决策偏移，揭示VLM在真实天气条件下的语义对齐脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型通常在规范视觉条件下训练，但在真实天气条件（如雨天）下的鲁棒性和跨模态语义对齐稳定性研究不足。需要探究天气扰动如何影响VLM的决策边界和语义理解。

Method: 提出两阶段参数化扰动框架：第一阶段通过低维全局调制弱化原始语义决策边界；第二阶段显式建模多尺度雨滴外观和降雨引起的照明变化，优化不可微天气空间以诱导稳定语义偏移。在非像素参数空间中生成物理可解释的扰动。

Result: 实验表明，即使是物理上合理且高度约束的天气扰动，也能在主流VLM中引发显著的语义错位，揭示VLM在真实天气条件下的安全性和可靠性风险。消融研究证实照明建模和多尺度雨滴结构是语义偏移的关键驱动因素。

Conclusion: 该研究首次系统分析了雨天场景下VLM的脆弱性，提出的对抗框架不仅揭示了VLM在真实天气条件下的安全风险，也为评估和改进VLM的鲁棒性提供了新视角和方法。

Abstract: Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.

</details>


### [228] [Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics](https://arxiv.org/abs/2601.13401)
*Peter A. Massih,Eric Cosatto*

Main category: cs.CV

Relevance: 75.0

TL;DR: QVLM通过代码生成架构解决VLMs在定量空间推理中的像素级信息丢失问题，在卫星图像定量推理基准SQuID上达到42.0%准确率


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在定量空间推理（如计数和测量）上表现不佳，因为其架构通过补丁嵌入压缩图像，破坏了像素级信息，导致空间索引丢失和精确跟踪能力不足

Method: 提出QVLM（定量视觉语言模型），采用代码生成架构：1）生成可执行代码调用分割模型获取像素级掩码；2）直接在掩码上操作，保持空间索引；3）将语言理解与视觉分析解耦。同时创建SQuID基准数据集，包含2000个卫星图像QA对

Result: QVLM使用GPT-5作为编码器在SQuID基准上达到42.0%准确率，显著优于传统VLM的28.1%。实验表明架构解耦能显著提升定量空间推理任务的准确性

Conclusion: 对于定量空间推理任务，通过代码生成架构将语言理解与视觉分析解耦，能够保持像素级精度，显著提升模型性能。这为VLMs在需要精确空间索引的任务上提供了新的架构思路

Abstract: Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.

</details>


### [229] [Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study](https://arxiv.org/abs/2601.13416)
*A. Nieto Juscafresa,Á. Mazcuñán Herreros,J. Sullivan*

Main category: cs.CV

Relevance: 75.0

TL;DR: 扩散模型作为通用特征编码器的潜力被低估，本文通过冻结扩散模型主干并探测其去噪特征，在细粒度识别任务上取得了与监督方法相当的性能，并在分布偏移下保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成领域表现出色，但其作为通用特征编码器的潜力尚未充分探索。扩散模型通过去噪训练，无需标签即可学习多层次结构特征，这使其具备成为强大自监督特征提取器的潜力。

Method: 使用冻结的扩散模型主干，探测不同层和去噪时间步的中间特征，为每对层-时间步组合训练线性分类器。在真实世界浮游生物监测场景中，与监督和自监督基线进行对比评估。

Result: 冻结扩散特征在平衡和长尾分布设置中均与监督基线相当，并优于其他自监督方法。在时间和地理分布偏移的浮游生物数据集上，扩散特征保持了高准确率和Macro F1分数，表现出强大的分布外泛化能力。

Conclusion: 扩散模型不仅是强大的生成模型，也是有效的通用特征编码器。其冻结特征在细粒度识别任务中表现出色，且在分布偏移下保持鲁棒性，为自监督学习提供了新思路。

Abstract: Diffusion models have emerged as state-of-the-art generative methods for image synthesis, yet their potential as general-purpose feature encoders remains underexplored. Trained for denoising and generation without labels, they can be interpreted as self-supervised learners that capture both low- and high-level structure. We show that a frozen diffusion backbone enables strong fine-grained recognition by probing intermediate denoising features across layers and timesteps and training a linear classifier for each pair. We evaluate this in a real-world plankton-monitoring setting with practical impact, using controlled and comparable training setups against established supervised and self-supervised baselines. Frozen diffusion features are competitive with supervised baselines and outperform other self-supervised methods in both balanced and naturally long-tailed settings. Out-of-distribution evaluations on temporally and geographically shifted plankton datasets further show that frozen diffusion features maintain strong accuracy and Macro F1 under substantial distribution shift.

</details>


### [230] [ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch](https://arxiv.org/abs/2601.13606)
*Zheng Liu,Honglin Lin,Chonghan Qin,Xiaoyang Wang,Xin Gao,Yu Li,Mengzhang Cai,Yun Zhu,Zhanping Zhong,Qizhi Pei,Zhuoshi Pan,Xiaoran Shang,Bin Cui,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

Relevance: 75.0

TL;DR: ChartVerse：一个用于合成复杂图表和可靠推理数据的可扩展框架，通过复杂度感知的图表编码和基于真实答案的反向QA合成，解决了开源视觉语言模型在图表推理中缺乏高质量训练数据的问题。


<details>
  <summary>Details</summary>
Motivation: 开源视觉语言模型在图表推理能力发展上受到高质量训练数据缺乏的严重制约。现有数据集面临双重挑战：合成图表过于简单重复，而相关的QA对存在幻觉问题且缺乏复杂任务所需的推理深度。

Method: 1) 引入Rollout Posterior Entropy (RPE)量化图表复杂度，开发复杂度感知的图表编码器通过可执行程序自主合成多样化的高复杂度图表；2) 采用基于真实答案的反向QA合成方法，直接从源代码提取确定性答案，基于这些锚点生成问题，并进行严格的一致性验证；3) 基于模型失败率筛选样本并蒸馏高质量的思维链推理，进一步提升难度和推理深度。

Result: 构建了ChartVerse-SFT-600K和ChartVerse-RL-40K数据集，使用Qwen3-VL-30B-A3B-Thinking作为教师模型。ChartVerse-8B模型在实验中实现了最先进的性能，显著超越了其教师模型，并可与更强的Qwen3-VL-32B-Thinking相媲美。

Conclusion: ChartVerse框架有效解决了图表推理训练数据质量不足的问题，通过创新的复杂度度量和反向QA合成方法，为开源视觉语言模型的图表推理能力发展提供了高质量的数据支持。

Abstract: Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.

</details>


### [231] [CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models](https://arxiv.org/abs/2601.13622)
*Donghee Lee,Rui Cai,Zhe Zhao*

Main category: cs.CV

Relevance: 75.0

TL;DR: CARPE是一个模型无关的框架，通过视觉集成层和上下文感知集成策略，让大型视觉语言模型能自适应地权衡视觉和文本模态，提升图像分类和视觉语言任务的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（LVLMs）在通用助手方面取得进展，但在图像分类等视觉中心任务上表现不佳，甚至不如其基础的CLIP视觉编码器。需要解决LVLMs在视觉表示利用上的局限性。

Method: 提出CARPE框架：1）引入视觉集成层，让模型能捕捉图像表示的不同方面；2）采用上下文感知集成策略，动态决定何时优先使用图像表示或依赖语言模型的推理能力；3）设计为模型无关，可与大多数开源LVLMs集成。

Result: 实验表明CARPE不仅提升了图像分类基准的性能，还在各种视觉语言基准上取得了改进。该框架能有效集成到大多数由视觉编码器和语言模型组成的开源LVLMs中。

Conclusion: CARPE通过自适应地权衡视觉和文本模态，增强了LVLMs在视觉中心任务上的能力，同时保持了在视觉语言任务上的优势，为多模态模型设计提供了新思路。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.

</details>


### [232] [Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles](https://arxiv.org/abs/2601.13705)
*Maria Lymperaiou,Vasileios Karampinis,Giorgos Filandrianos,Angelos Vlachos,Chrysoula Zerva,Athanasios Voulodimos*

Main category: cs.CV

Relevance: 75.0

TL;DR: 该论文是一篇关于视觉谜题作为大型视觉语言模型推理能力诊断工具的综述，系统分析了LVLMs在视觉谜题推理中的表现、局限性和未来方向。


<details>
  <summary>Details</summary>
Motivation: 视觉谜题长期以来作为人类认知的紧凑探针，能够以最小先验知识需求来测试抽象、规则发现和系统推理能力。作者希望利用视觉谜题作为诊断工具，评估大型视觉语言模型的推理能力，提供比开放式多模态基准更可控、可验证的评估方法。

Method: 通过统一框架将视觉谜题抽象化，按推理机制（归纳、类比、算法、演绎、几何/空间）组织现有基准，分析不同类别谜题所需的认知操作，并综合实证证据评估模型表现。

Result: 研究发现当前模型存在一致的局限性：脆弱的泛化能力、感知与推理的紧密纠缠、流畅解释与忠实执行之间的持续差距。视觉谜题揭示了LVLMs在系统推理方面的根本缺陷。

Conclusion: 视觉谜题应被视为诊断工具而非任务格式，该综述阐明了LVLM推理的现状，并为未来基准测试和推理感知的多模态系统指明了关键方向。

Abstract: Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems.

</details>


### [233] [Revisiting Multi-Task Visual Representation Learning](https://arxiv.org/abs/2601.13886)
*Shangzhe Di,Zhonghua Zhai,Weidi Xie*

Main category: cs.CV

Relevance: 75.0

TL;DR: MTV是一个多任务视觉预训练框架，通过联合优化视觉语言对比、自监督和密集空间目标，结合专家模型生成的伪标签，实现全局语义对齐与局部空间精度的统一。


<details>
  <summary>Details</summary>
Motivation: 当前视觉表示学习存在分裂：视觉语言模型（如CLIP）擅长全局语义对齐但缺乏空间精度，而自监督方法（如MAE、DINO）能捕捉局部结构但缺乏高级语义上下文。这两种范式本质上是互补的，可以集成到统一框架中。

Method: 提出MTV多任务视觉预训练框架，联合优化共享骨干网络在三个目标上：1) 视觉语言对比学习，2) 自监督学习，3) 密集空间监督。利用Depth Anything V2和OWLv2等专家模型生成大规模密集结构化伪标签，避免人工标注需求。

Result: MTV实现了"两全其美"的性能，显著提升了细粒度空间推理能力，同时不损害全局语义理解。系统分析了各目标的边际增益、任务协同与干扰、以及不同数据和模型规模下的扩展行为。

Conclusion: 多任务学习结合高质量伪监督是构建更通用视觉编码器的可扩展路径。MTV框架证明了不同视觉学习范式可以互补集成，为视觉表示学习提供了新的方向。

Abstract: Current visual representation learning remains bifurcated: vision-language models (e.g., CLIP) excel at global semantic alignment but lack spatial precision, while self-supervised methods (e.g., MAE, DINO) capture intricate local structures yet struggle with high-level semantic context. We argue that these paradigms are fundamentally complementary and can be integrated into a principled multi-task framework, further enhanced by dense spatial supervision. We introduce MTV, a multi-task visual pretraining framework that jointly optimizes a shared backbone across vision-language contrastive, self-supervised, and dense spatial objectives. To mitigate the need for manual annotations, we leverage high-capacity "expert" models -- such as Depth Anything V2 and OWLv2 -- to synthesize dense, structured pseudo-labels at scale. Beyond the framework, we provide a systematic investigation into the mechanics of multi-task visual learning, analyzing: (i) the marginal gain of each objective, (ii) task synergies versus interference, and (iii) scaling behavior across varying data and model scales. Our results demonstrate that MTV achieves "best-of-both-worlds" performance, significantly enhancing fine-grained spatial reasoning without compromising global semantic understanding. Our findings suggest that multi-task learning, fueled by high-quality pseudo-supervision, is a scalable path toward more general visual encoders.

</details>


### [234] [FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation](https://arxiv.org/abs/2601.13976)
*Jing Zuo,Lingzhou Mu,Fan Jiang,Chengcheng Ma,Mu Xu,Yonggang Qi*

Main category: cs.CV

Relevance: 75.0

TL;DR: FantasyVLN：一个统一的隐式推理框架，通过将想象的视觉标记编码到紧凑的潜在空间，在保持CoT推理优势的同时避免了显式标记开销，实现了推理感知的实时视觉语言导航。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航中的CoT方法存在两个关键问题：纯文本CoT缺乏空间基础且容易过拟合稀疏标注的推理步骤，而多模态CoT由于生成想象的视觉观察导致严重的标记膨胀，使得实时导航不切实际。

Method: 提出FantasyVLN框架，使用预训练的视觉自回归器（VAR）将想象的视觉标记编码到紧凑的潜在空间，在CoT推理训练中联合学习文本、视觉和多模态CoT模式，采用统一的多CoT策略。推理时直接进行指令到动作的映射，同时保持推理感知的表征。

Result: 在LH-VLN数据集上的广泛实验表明，该方法实现了推理感知的实时导航，提高了成功率和效率，同时推理延迟比显式CoT方法降低了一个数量级。

Conclusion: FantasyVLN通过隐式推理框架解决了现有CoT方法的局限性，在保持推理能力的同时实现了实时性能，为视觉语言导航提供了一种高效实用的解决方案。

Abstract: Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.

</details>


### [235] [Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology](https://arxiv.org/abs/2601.14044)
*Kaiyu Wu,Pucheng Han,Hualong Zhang,Naigeng Wu,Keze Wang*

Main category: cs.CV

Relevance: 75.0

TL;DR: 该论文针对气象领域的视觉语言模型，提出了WeatherQA基准和LoCo-RFT方法，解决了自我矛盾推理问题，并开发了首个具有逻辑忠实性的气象推理VLM模型Weather-R1。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在气象领域的应用受到领域差距和推理忠实性差距的限制。主流强化微调方法会导致自我矛盾推理，即模型的推理过程与最终答案相矛盾，这在气象等高风险领域是不可接受的。

Method: 1) 构建WeatherQA气象多模态推理基准；2) 提出逻辑一致强化微调方法，通过引入逻辑一致性奖励来解决自我矛盾推理问题；3) 开发Weather-R1模型，这是首个具有逻辑忠实性的气象推理视觉语言模型。

Result: Weather-R1在WeatherQA基准上比基线提高了9.8个百分点，优于监督微调和传统强化微调方法，甚至超越了原始的Qwen2.5-VL-32B模型。

Conclusion: LoCo-RFT方法有效解决了自我矛盾推理问题，Weather-R1模型在气象推理任务上表现出优越性能，为高风险领域的可靠AI推理提供了重要解决方案。

Abstract: While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1.

</details>


### [236] [Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model](https://arxiv.org/abs/2601.14052)
*Haoran Xu,Yanlin Liu,Zizhao Tong,Jiaze Li,Kexue Fu,Yuyang Zhang,Longxiang Gao,Shuaiguang Li,Xingyu Li,Yanran Xu,Changwei Wang*

Main category: cs.CV

Relevance: 75.0

TL;DR: MM-OOD：利用多模态大语言模型进行零样本OOD检测的新方法，通过多轮对话增强离群值检测，在近OOD和远OOD任务上都取得显著改进


<details>
  <summary>Details</summary>
Motivation: 当前基于CLIP的零样本OOD检测方法过度依赖文本空间知识，忽视了图像空间检测的固有挑战。需要利用MLLMs的多模态推理能力来改进OOD检测性能。

Method: 提出MM-OOD管道：1) 近OOD任务：直接将ID图像和文本提示输入MLLMs识别离群值；2) 远OOD任务：采用草图-生成-阐述框架：先用文本提示草图化离群暴露，生成视觉OOD样本，最后用多模态提示进行阐述。

Result: 在Food-101等广泛使用的多模态数据集上取得显著改进，并在ImageNet-1K上验证了方法的可扩展性。

Conclusion: MM-OOD通过利用MLLMs的多模态推理和多轮对话能力，有效解决了传统方法过度依赖文本空间知识的问题，在OOD检测任务上表现出优越性能。

Abstract: Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.

</details>


### [237] [LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR](https://arxiv.org/abs/2601.14251)
*Said Taghadouini,Adrien Cavaillès,Baptiste Aubertin*

Main category: cs.CV

Relevance: 75.0

TL;DR: LightOnOCR-2-1B是一个10亿参数的多语言视觉-语言模型，可直接将文档图像转换为干净、自然排序的文本，无需传统OCR流程，在保持高性能的同时比现有最佳模型小9倍且更快。


<details>
  <summary>Details</summary>
Motivation: 传统OCR流程脆弱且复杂，需要多步骤处理。作者希望开发一个端到端的模型，能够直接从文档图像生成干净、自然排序的文本，同时支持多语言文档和科学PDF。

Method: 1. 使用大规模高质量蒸馏混合数据进行训练，覆盖扫描文档、法语文档和科学PDF；2. 扩展输出格式以预测嵌入图像的归一化边界框；3. 通过恢复策略在预训练中引入定位能力；4. 使用基于IoU奖励的RLVR进行细化；5. 通过检查点平均和任务算术合并提高鲁棒性。

Result: 在OlmOCR-Bench上达到最先进结果，比之前最佳模型小9倍且速度显著更快。模型支持图像边界框预测，并公开了数据集和LightOnOCR-bbox-bench评估基准。

Conclusion: LightOnOCR-2-1B展示了端到端文档理解模型的潜力，在保持高性能的同时实现了显著的效率提升，为文档处理提供了更简单、更强大的解决方案。

Abstract: We present \textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses.

</details>


### [238] [ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models](https://arxiv.org/abs/2601.12428)
*Baorui Peng,Wenyao Zhang,Liang Xu,Zekun Qi,Jiazhao Zhang,Hongsi Liu,Wenjun Zeng,Xin Jin*

Main category: cs.RO

Relevance: 75.0

TL;DR: ReWorld：通过强化学习对齐视频世界模型，提升物理真实性、任务完成能力和视觉质量，用于接触丰富的机器人操作任务


<details>
  <summary>Details</summary>
Motivation: 当前基于视频的世界模型主要关注视觉生成质量，但忽略了物理保真度、动态一致性和任务逻辑，特别是在接触丰富的操作任务中，这限制了其在下游任务中的应用。

Method: 1) 构建大规模视频偏好数据集（~235K）；2) 训练分层奖励模型捕捉与人类偏好一致的多维度奖励；3) 提出实用对齐算法，通过计算高效的PPO风格算法对基于流的世界模型进行后训练。

Result: ReWorld显著提升了生成rollouts的物理保真度、逻辑一致性、具身性和视觉质量，优于先前方法。

Conclusion: 通过强化学习对齐视频世界模型是提升其在机器人学习中应用的有效方法，特别是在接触丰富的操作任务中。

Abstract: Recently, video-based world models that learn to simulate the dynamics have gained increasing attention in robot learning. However, current approaches primarily emphasize visual generative quality while overlooking physical fidelity, dynamic consistency, and task logic, especially for contact-rich manipulation tasks, which limits their applicability to downstream tasks. To this end, we introduce ReWorld, a framework aimed to employ reinforcement learning to align the video-based embodied world models with physical realism, task completion capability, embodiment plausibility and visual quality. Specifically, we first construct a large-scale (~235K) video preference dataset and employ it to train a hierarchical reward model designed to capture multi-dimensional reward consistent with human preferences. We further propose a practical alignment algorithm that post-trains flow-based world models using this reward through a computationally efficient PPO-style algorithm. Comprehensive experiments and theoretical analysis demonstrate that ReWorld significantly improves the physical fidelity, logical coherence, embodiment and visual quality of generated rollouts, outperforming previous methods.

</details>


### [239] [LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System](https://arxiv.org/abs/2601.13096)
*Muhayy Ud Din,Waseem Akram,Ahsan B. Bakht,Irfan Hussain*

Main category: cs.RO

Relevance: 75.0

TL;DR: 提出一个结合LLM和VLM的自主海事港口检查框架，用LLM进行符号规划，VLM进行语义检查，实现无人机和水面机器人的协同作业


<details>
  <summary>Details</summary>
Motivation: 传统海事港口检查方法依赖人工操作和传统计算机视觉技术，缺乏可扩展性和上下文理解能力，需要更智能、自适应的检查系统

Method: 1) LLM模块：将自然语言任务指令转换为带依赖图的符号规划，编码操作约束确保无人机-水面机器人安全协调
2) VLM模块：实时语义检查和合规性评估，生成带上下文推理的结构化报告
3) 轻量级机载设计，适用于资源受限的海事平台

Result: 在扩展的MBZIRC海事模拟器中进行验证，包含真实港口基础设施，并通过实际机器人检查试验评估，证明框架有效性

Conclusion: LLM-VLM融合框架能够实现上下文感知和自适应监控，推进智能自主检查系统的发展，适用于资源受限的海事平台

Abstract: Maritime port inspection plays a critical role in ensuring safety, regulatory compliance, and operational efficiency in complex maritime environments. However, existing inspection methods often rely on manual operations and conventional computer vision techniques that lack scalability and contextual understanding. This study introduces a novel integrated engineering framework that utilizes the synergy between Large Language Models (LLMs) and Vision Language Models (VLMs) to enable autonomous maritime port inspection using cooperative aerial and surface robotic platforms. The proposed framework replaces traditional state-machine mission planners with LLM-driven symbolic planning and improved perception pipelines through VLM-based semantic inspection, enabling context-aware and adaptive monitoring. The LLM module translates natural language mission instructions into executable symbolic plans with dependency graphs that encode operational constraints and ensure safe UAV-USV coordination. Meanwhile, the VLM module performs real-time semantic inspection and compliance assessment, generating structured reports with contextual reasoning. The framework was validated using the extended MBZIRC Maritime Simulator with realistic port infrastructure and further assessed through real-world robotic inspection trials. The lightweight on-board design ensures suitability for resource-constrained maritime platforms, advancing the development of intelligent, autonomous inspection systems. Project resources (code and videos) can be found here: https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection

</details>


### [240] [Compress to Focus: Efficient Coordinate Compression for Policy Optimization in Multi-Turn GUI Agents](https://arxiv.org/abs/2601.11631)
*Yurun Song,Jiong Yin,Rongjunchen Zhang,Ian G. Harris*

Main category: cs.CV

Relevance: 65.0

TL;DR: CCPO是一个针对多轮GUI智能体的高效策略优化框架，通过坐标感知空间压缩和基于距离的优势函数，在保持性能的同时实现高达55%的token压缩和3.8倍训练加速。


<details>
  <summary>Details</summary>
Motivation: 多轮GUI智能体在完成任务时面临严重的上下文膨胀问题，现有方法要么通过截断牺牲长期上下文，要么通过token剪枝破坏空间结构。需要一种既能保持性能又能高效处理历史交互的方法。

Method: 提出Coordinate Compression Policy Optimization (CCPO)框架，包含两个核心组件：1) Coordinate-Aware Spatial Compression (CASC)：通过多轮交互聚合坐标信息，识别目标相关区域，逐步缩小历史注意力范围；2) Distance-Based Advantage：基于距离而非二元正确性提供细粒度学习信号，提升定位准确性和压缩质量。

Result: 在四个基准测试中达到SOTA性能，实现高达55%的token压缩和3.8倍的训练加速。

Conclusion: CCPO通过将视觉压缩与策略优化相结合，有效解决了多轮GUI智能体的上下文膨胀问题，在保持性能的同时显著提升了计算效率。

Abstract: Multi-turn GUI agents enable complex task completion through sequential decision-making, but suffer from severe context inflation as interaction history accumulates. Existing strategies either sacrifice long-term context via truncation or compromise spatial structure through token pruning. In this paper, we propose Coordinate Compression Policy Optimization (CCPO), an efficient policy optimization framework that couples visual compression with policy optimization for multi-turn GUI agents. CCPO introduces Coordinate-Aware Spatial Compression (CASC), which aggregates coordinates from multiple rollouts to capture target-relevant regions and progressively narrow historical attention around key visual areas. From interactions across rollouts, CASC adaptively constructs attention boundaries that concentrate computation on the most informative regions of the scene. We further design a Distance-Based Advantage that provides fine-grained learning signals based on distance rather than binary correctness, improving both grounding accuracy and compression quality. Extensive experiments demonstrate that CCPO achieves SOTA performance across four benchmarks with up to 55% token compression and 3.8$\times$ training speedup.

</details>


### [241] [Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification](https://arxiv.org/abs/2601.11651)
*Miriam Doh,Aditya Gulati,Corina Canali,Nuria Oliver*

Main category: cs.CV

Relevance: 65.0

TL;DR: 该研究揭示了文本到图像生成AI中的算法外貌歧视现象，发现Stable Diffusion模型系统性地将面部吸引力与积极属性关联，并在性别分类算法中存在显著性别偏见，加剧了现有不平等。


<details>
  <summary>Details</summary>
Motivation: 研究动机是调查文本到图像生成AI中存在的算法外貌歧视现象，即基于外貌的系统性偏好对待。研究者关注生成AI如何编码社会建构的偏见，以及这些偏见如何在下游任务（如性别分类）中加剧不平等。

Method: 方法包括使用Stable Diffusion 2.1和3.5 Medium生成26,400张合成人脸，分析生成AI模型如何系统性地将面部吸引力与积极属性关联。同时评估三种性别分类算法在不同属性输入面孔上的表现，揭示性别偏见。

Result: 研究发现：(1) T2I模型系统性地编码吸引力-积极属性关联；(2) 性别分类系统存在显著性别差异，女性面孔（特别是带有负面属性的）误分类率远高于男性；(3) 新模型通过年龄同质化、性别化曝光模式和地理简化加剧了审美约束。

Conclusion: 结论指出算法外貌歧视是跨AI视觉系统的系统性基础设施，通过表征和识别两方面加剧现有不平等。研究强调需要解决生成AI中的社会偏见编码问题。

Abstract: This paper examines algorithmic lookism-the systematic preferential treatment based on physical appearance-in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, we demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, we find significant gender bias in three gender classification algorithms depending on the attributes of the input faces. Our findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women's faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men's; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition.
  Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems-not from empirical truths or the authors' views.

</details>


### [242] [A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection](https://arxiv.org/abs/2601.11910)
*Guiying Zhu,Bowen Yang,Yin Zhuang,Tong Zhang,Guanqun Wang,Zhihao Che,He Chen,Lianlin Li*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出了一种无需训练的开放词汇目标检测方法GW-VLM，通过多尺度视觉语言搜索和上下文概念提示，利用预训练的视觉语言模型和大语言模型实现零样本目标检测。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法虽然利用大规模预训练基础模型，但通常忽略了根据已预训练模型建立通用对象认知理解的重要性。本文旨在构建一个无需训练的通用理解范式。

Method: 提出GW-VLM框架：1) MS-VLS（多尺度视觉语言搜索）利用VLM进行多尺度视觉语言软对齐，从类别无关目标检测结果生成片段；2) CCP（上下文概念提示）形成概念流，让LLM理解这些片段用于开放词汇目标检测。

Result: 在自然图像数据集（COCO val, Pascal VOC）和遥感数据集（DIOR, NWPU-10）上的实验表明，GW-VLM无需任何训练步骤即可达到最先进的开放词汇目标检测性能。

Conclusion: GW-VLM通过巧妙结合预训练的VLM和LLM，构建了一个无需训练的通用理解范式，在开放词汇目标检测任务上表现出色，为利用基础模型进行零样本视觉理解提供了新思路。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of "guess what". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.

</details>


### [243] [Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal](https://arxiv.org/abs/2601.11952)
*Haonan An,Guang Hua,Wei Du,Hangcheng Cao,Yihang Tao,Guowen Xu,Susanto Rahardja,Yuguang Fang*

Main category: cs.CV

Relevance: 65.0

TL;DR: 本文提出Decoder Gradient Shields (DGS)防御机制，保护盒自由模型水印中的解码器免受基于梯度泄露查询的攻击，通过重定向和重新缩放梯度来防止水印移除器的训练收敛。


<details>
  <summary>Details</summary>
Motivation: 现有盒自由模型水印研究主要关注编码器的鲁棒性以抵抗各种攻击，而解码器被忽视，导致水印面临攻击。本文识别了一种针对解码器的攻击，攻击者利用查询响应获取反向传播梯度来训练水印移除器。

Method: 提出Decoder Gradient Shields (DGS)防御机制家族，包括输出层DGS-O、输入层DGS-I和层间DGS-L。DGS-O有闭式解，所有DGS都有可证明的性能。通过联合设计重定向和重新缩放来自水印通道梯度泄露查询的梯度，防止水印移除器达到低损失值的训练收敛，同时保持解码器输出的图像质量。

Result: 在去雨和图像生成任务中，使用最先进的盒自由水印技术进行实验，结果显示在所有设置下，DGSs实现了100%的防御成功率。

Conclusion: DGSs有效解决了盒自由模型水印中解码器面临的梯度泄露攻击问题，为DNN知识产权保护提供了重要的防御机制。

Abstract: Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.

</details>


### [244] [AVIR: Adaptive Visual In-Document Retrieval for Efficient Multi-Page Document Question Answering](https://arxiv.org/abs/2601.11976)
*Zongmin Li,Yachuan Li,Lei Kang,Dimosthenis Karatzas,Wenkang Ma*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出AVIR框架解决多页文档视觉问答问题，通过轻量级检索模型评分页面相关性，自适应聚类筛选关键页面，减少70%页面输入，在保持性能的同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 多页文档视觉问答面临两个主要挑战：1）长文档计算资源消耗大；2）注意力机制在长文档中效果下降。现有方法要么需要微调模型，要么计算成本高昂。

Method: AVIR框架：1）轻量级检索模型对每页进行相关性评分；2）根据评分分布自适应聚类选择相关页面；3）Top-K筛选保持上下文紧凑；4）短文档使用相关性概率阈值；5）仅将筛选后的页面输入冻结的LVLM生成答案。

Result: 在MP-DocVQA数据集上达到84.58% ANLS，超越先前方法，同时减少70%的页面输入需求。在SlideVQA和DUDE基准测试中也验证了有效性。

Conclusion: AVIR框架通过自适应视觉文档检索有效解决了多页文档视觉问答的计算效率和注意力机制问题，无需微调模型，显著降低计算成本的同时保持高性能。

Abstract: Multi-page Document Visual Question Answering (MP-DocVQA) remains challenging because long documents not only strain computational resources but also reduce the effectiveness of the attention mechanism in large vision-language models (LVLMs). We tackle these issues with an Adaptive Visual In-document Retrieval (AVIR) framework. A lightweight retrieval model first scores each page for question relevance. Pages are then clustered according to the score distribution to adaptively select relevant content. The clustered pages are screened again by Top-K to keep the context compact. However, for short documents, clustering reliability decreases, so we use a relevance probability threshold to select pages. The selected pages alone are fed to a frozen LVLM for answer generation, eliminating the need for model fine-tuning. The proposed AVIR framework reduces the average page count required for question answering by 70%, while achieving an ANLS of 84.58% on the MP-DocVQA dataset-surpassing previous methods with significantly lower computational cost. The effectiveness of the proposed AVIR is also verified on the SlideVQA and DUDE benchmarks. The code is available at https://github.com/Li-yachuan/AVIR.

</details>


### [245] [SMc2f: Robust Scenario Mining for Robotic Autonomy from Coarse to Fine](https://arxiv.org/abs/2601.12010)
*Yifei Chen,Ross Greer*

Main category: cs.CV

Relevance: 65.0

TL;DR: 本文提出SMc2f框架，通过粗到细的流程改进机器人自主系统的场景挖掘：先用视觉语言模型进行粗粒度图像-文本过滤，再构建成功案例数据库并few-shot提示LLM，最后通过文本-轨迹对比学习进行细粒度匹配，显著提升检索质量和效率。


<details>
  <summary>Details</summary>
Motivation: 自主机器人车辆的安全验证依赖于在罕见安全关键场景中系统测试其规划和控制栈。现有方法RefAV使用LLM在轨迹标签上进行检索，但忽略了自然语言与原始RGB图像的直接联系，且依赖上游3D目标检测和跟踪的质量，轨迹数据不准确会导致下游时空定位错误。

Method: 提出粗到细的SMc2f框架：1) 使用视觉语言模型进行粗粒度图像-文本过滤；2) 在RefAV基础上构建成功挖掘案例数据库，自动检索示例进行few-shot提示以增强LLM检索鲁棒性；3) 引入文本-轨迹对比学习，在共享嵌入空间中将匹配对拉近、不匹配对推远，形成细粒度匹配器来优化LLM的候选轨迹。

Result: 在公共数据集上的实验表明，该方法在检索质量和效率方面都取得了显著提升。

Conclusion: SMc2f框架通过结合视觉语言模型、few-shot提示和对比学习，有效解决了现有场景挖掘方法的问题，为机器人自主系统的安全验证提供了更鲁棒和高效的解决方案。

Abstract: The safety validation of autonomous robotic vehicles hinges on systematically testing their planning and control stacks against rare, safety-critical scenarios. Mining these long-tail events from massive real-world driving logs is therefore a critical step in the robotic development lifecycle. The goal of the Scenario Mining task is to retrieve useful information to enable targeted re-simulation, regression testing, and failure analysis of the robot's decision-making algorithms. RefAV, introduced by the Argoverse team, is an end-to-end framework that uses large language models (LLMs) to spatially and temporally localize scenarios described in natural language. However, this process performs retrieval on trajectory labels, ignoring the direct connection between natural language and raw RGB images, which runs counter to the intuition of video retrieval; it also depends on the quality of upstream 3D object detection and tracking. Further, inaccuracies in trajectory data lead to inaccuracies in downstream spatial and temporal localization. To address these issues, we propose Robust Scenario Mining for Robotic Autonomy from Coarse to Fine (SMc2f), a coarse-to-fine pipeline that employs vision-language models (VLMs) for coarse image-text filtering, builds a database of successful mining cases on top of RefAV and automatically retrieves exemplars to few-shot condition the LLM for more robust retrieval, and introduces text-trajectory contrastive learning to pull matched pairs together and push mismatched pairs apart in a shared embedding space, yielding a fine-grained matcher that refines the LLM's candidate trajectories. Experiments on public datasets demonstrate substantial gains in both retrieval quality and efficiency.

</details>


### [246] [A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models](https://arxiv.org/abs/2601.12051)
*Weixin Ye,Wei Wang,Yahui Liu,Yue Song,Bin Ren,Wei Bi,Rita Cucchiara,Nicu Sebe*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出MJP框架，通过随机打乱token顺序并使用可学习的未知位置嵌入来掩盖位置信息，增强Transformer在联邦学习中的安全性和性能


<details>
  <summary>Details</summary>
Motivation: Transformer在联邦学习中面临梯度攻击的严重安全风险，研究发现位置嵌入的梯度包含足够信息可用于重构输入数据，需要一种既能防御攻击又能提升模型性能的统一解决方案

Method: 提出Masked Jigsaw Puzzle (MJP)框架：1）随机打乱token顺序破坏token顺序信息；2）使用可学习的未知位置嵌入掩盖打乱token的位置信息；3）迫使模型学习不依赖局部空间信息的特征表示

Result: 实验表明MJP不仅能提高模型对梯度攻击的鲁棒性，还能在图像分类（如ImageNet-1K）和文本情感分析（如Yelp和Amazon）任务中提升性能，为不同Transformer模型提供了统一的解决方案

Conclusion: MJP是一个有效的统一框架，通过破坏位置嵌入中的局部空间信息，同时增强了Transformer在联邦学习中的安全性和任务性能

Abstract: In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via https://github.com/ywxsuperstar/transformerattack

</details>


### [247] [Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models](https://arxiv.org/abs/2601.12150)
*Mengxuan Hu,Zihan Guan,John Kang,Sheng Li,Zhongliang Zhou*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出一种针对病理学基础模型的高效推理策略，通过空间感知的邻近块稀疏化注意力机制和基于全局注意力分数的非信息性token过滤，显著降低GPU内存和运行时间，同时保持甚至提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有病理学基础模型受限于特定输入尺寸（如224×224），在处理数千分辨率级别的全切片图像时效率低下。简单放大输入会导致GPU内存消耗过大，而降低采样则会丢失关键形态细节。

Method: 提出空间和时间高效的推理策略：1）使用空间感知的邻近块稀疏化注意力机制；2）通过全局注意力分数过滤非信息性token。这种方法在保持高分辨率推理的同时减少计算资源需求。

Result: 实验结果显示，该方法在ROI分类任务上实现高达7.67%的性能提升，在分割任务上获得兼容结果，同时在相同GPU预算下支持更高分辨率的推理。

Conclusion: 提出的高效推理策略成功解决了病理学基础模型在处理全切片图像时的计算效率问题，在减少资源消耗的同时保持甚至提升了模型性能，为高分辨率医学图像分析提供了实用解决方案。

Abstract: Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.

</details>


### [248] [VIRTUE: Versatile Video Retrieval Through Unified Embeddings](https://arxiv.org/abs/2601.12193)
*Shaunak Halbe,Bhagyashree Puranik,Jayakrishnan Unnikrishnan,Kushan Thakkar,Vimal Bhat,Toufiq Parag*

Main category: cs.CV

Relevance: 65.0

TL;DR: VIRTUE是一个基于多模态大语言模型(MLLM)的视频检索框架，支持语料库级检索、细粒度时刻定位和组合多模态查询，通过对比对齐和LoRA高效训练，在零样本视频检索和组合检索任务上达到先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索系统存在局限性：专用架构虽然检索性能强，但无法处理组合多模态查询；而MLLM方法支持丰富查询但检索性能较差。需要一种既能处理复杂查询又具备强大检索能力的统一框架。

Method: 使用共享MLLM骨干网络生成视觉和文本嵌入，通过对比对齐促进高效的基于嵌入的候选搜索。采用低秩适应(LoRA)在70万对视觉-文本数据上高效训练嵌入模型，并通过重排序进一步提升性能。

Result: 在零样本视频检索任务上超越其他MLLM方法；无需额外训练即可在零样本时刻检索上获得竞争性结果；在零样本组合视频检索上达到最先进水平；通过重排序后，性能可与在更大规模数据上训练的专用模型相媲美。

Conclusion: VIRTUE展示了MLLM在视频检索任务中的强大潜力，通过高效训练策略实现了多功能检索能力，为统一视频检索系统提供了可行方案。

Abstract: Modern video retrieval systems are expected to handle diverse tasks ranging from corpus-level retrieval and fine-grained moment localization to flexible multimodal querying. Specialized architectures achieve strong retrieval performance by training modality-specific encoders on massive datasets, but they lack the ability to process composed multimodal queries. In contrast, multimodal LLM (MLLM)-based methods support rich multimodal search but their retrieval performance remains well below that of specialized systems. We present VIRTUE, an MLLM-based versatile video retrieval framework that integrates corpus and moment-level retrieval capabilities while accommodating composed multimodal queries within a single architecture. We use contrastive alignment of visual and textual embeddings generated using a shared MLLM backbone to facilitate efficient embedding-based candidate search. Our embedding model, trained efficiently using low-rank adaptation (LoRA) on 700K paired visual-text data samples, surpasses other MLLM-based methods on zero-shot video retrieval tasks. Additionally, we demonstrate that the same model can be adapted without further training to achieve competitive results on zero-shot moment retrieval, and state of the art results for zero-shot composed video retrieval. With additional training for reranking candidates identified in the embedding-based search, our model substantially outperforms existing MLLM-based retrieval systems and achieves retrieval performance comparable to state of the art specialized models which are trained on orders of magnitude larger data.

</details>


### [249] [Less is More: Label-Guided Summarization of Procedural and Instructional Videos](https://arxiv.org/abs/2601.12243)
*Shreya Rajpal,Michal Golovanesky,Carsten Eickhoff*

Main category: cs.CV

Relevance: 65.0

TL;DR: PRISM是一个三阶段视频摘要框架，通过自适应视觉采样、标签驱动关键帧锚定和LLM上下文验证，生成语义基础视频摘要，在采样少于5%帧的情况下保留84%语义内容。


<details>
  <summary>Details</summary>
Motivation: 视频摘要对于手术培训等高风险领域至关重要。现有方法从基本视觉特征发展到预训练视觉语言模型，但需要更好的语义理解和上下文感知能力来生成更准确、连贯的视频摘要。

Method: 提出PRISM三阶段框架：1) 自适应视觉采样选择信息丰富帧；2) 标签驱动关键帧锚定识别程序性转换；3) 使用大语言模型进行上下文验证，过滤通用或幻觉内容，确保语义连贯性。

Result: 在采样少于5%原始帧的情况下，保留84%语义内容，比基线方法提升高达33%。在程序性和领域特定视频任务上表现出良好的泛化能力，语义对齐和精度均表现优异。

Conclusion: PRISM框架通过结合自适应采样、关键帧锚定和LLM验证，能够生成语义基础、上下文连贯的视频摘要，在保留关键语义内容的同时显著减少帧数，适用于各种程序性和领域特定视频任务。

Abstract: Video summarization helps turn long videos into clear, concise representations that are easier to review, document, and analyze, especially in high-stakes domains like surgical training. Prior work has progressed from using basic visual features like color, motion, and structural changes to using pre-trained vision-language models that can better understand what's happening in the video (semantics) and capture temporal flow, resulting in more context-aware video summarization. We propose a three-stage framework, PRISM: Procedural Representation via Integrated Semantic and Multimodal analysis, that produces semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). Our method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. We evaluate our method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, our summaries retain 84% semantic content while improving over baselines by as much as 33%. Our approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.

</details>


### [250] [Federated Joint Learning for Domain and Class Generalization](https://arxiv.org/abs/2601.12253)
*Haoran Xu,Jiaze Li,Jianzhong Ju,Zhenbo Luo*

Main category: cs.CV

Relevance: 65.0

TL;DR: FedDCG：一种联邦学习框架，同时解决类别和领域泛化问题，通过领域分组策略和可学习网络提升CLIP等视觉语言模型的微调效率


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理未见类别或未见领域问题，缺乏同时解决两者的联合框架。CLIP等视觉语言模型参数量大、预训练需求高，需要高效的微调方法，特别是在联邦学习环境中同时实现类别和领域泛化。

Method: 提出FedDCG框架：1) 领域分组策略，在每个组内训练类别泛化网络以避免决策边界混淆；2) 基于领域相似性聚合类别泛化结果；3) 使用可学习网络增强类别泛化能力；4) 解耦机制分离通用知识和领域特定知识。

Result: 在多个数据集上的实验表明，FedDCG在准确性和鲁棒性方面优于现有最先进的基线方法。

Conclusion: FedDCG成功解决了联邦学习中同时进行类别和领域泛化的挑战，为视觉语言模型的高效微调提供了有效解决方案。

Abstract: Efficient fine-tuning of visual-language models like CLIP has become crucial due to their large-scale parameter size and extensive pretraining requirements. Existing methods typically address either the issue of unseen classes or unseen domains in isolation, without considering a joint framework for both. In this paper, we propose \textbf{Fed}erated Joint Learning for \textbf{D}omain and \textbf{C}lass \textbf{G}eneralization, termed \textbf{FedDCG}, a novel approach that addresses both class and domain generalization in federated learning settings. Our method introduces a domain grouping strategy where class-generalized networks are trained within each group to prevent decision boundary confusion. During inference, we aggregate class-generalized results based on domain similarity, effectively integrating knowledge from both class and domain generalization. Specifically, a learnable network is employed to enhance class generalization capabilities, and a decoupling mechanism separates general and domain-specific knowledge, improving generalization to unseen domains. Extensive experiments across various datasets show that \textbf{FedDCG} outperforms state-of-the-art baselines in terms of accuracy and robustness.

</details>


### [251] [A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models](https://arxiv.org/abs/2601.12304)
*Wutao Chen,Huaqin Zou,Chen Wan,Lifeng Huang*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出2S-GDA框架，通过全局多样性策略增强多模态对抗攻击效果，在文本和视觉层面分别引入多样性扰动，显著提升黑盒攻击成功率


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言预训练模型对对抗样本脆弱，尤其在黑盒场景下。现有多模态攻击方法存在扰动多样性有限和多阶段流程不稳定的问题

Method: 提出两阶段全局多样性攻击框架：1) 文本扰动阶段：结合候选文本扩展和全局感知替换的全局多样性策略；2) 视觉扰动阶段：使用多尺度调整和块状洗牌旋转生成图像级扰动

Result: 在VLP模型上的实验表明，2S-GDA持续提升攻击成功率，在黑盒设置中相比现有方法提升高达11.17%。框架模块化，可与现有方法结合进一步提升对抗可迁移性

Conclusion: 2S-GDA通过增强文本和视觉扰动多样性，有效提升了多模态对抗攻击在黑盒场景下的效果，为解决VLP模型安全漏洞提供了新思路

Abstract: Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The proposed method first introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17\% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.

</details>


### [252] [From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles](https://arxiv.org/abs/2601.12358)
*Omar Y. Goba,Ahmed Y. Gado,Catherine M. Elias,Ahmed Hussein*

Main category: cs.CV

Relevance: 65.0

TL;DR: 该论文提出了一种利用LLM和多模态视觉模型动态生成和调整行为树的智能体框架，用于自动驾驶车辆在不可预测环境中的自适应行为规划。


<details>
  <summary>Details</summary>
Motivation: 传统行为树（BTs）虽然是结构化的决策逻辑，但本质上是静态的，需要大量人工调优，限制了其在SAE Level 5自动驾驶中的应用。自动驾驶车辆需要自适应行为规划器来安全导航不可预测的真实世界环境。

Method: 提出了一个智能体框架：1）描述器智能体使用符号链提示评估场景关键性；2）规划器智能体通过上下文学习构建高层子目标；3）生成器智能体合成XML格式的可执行BT子树。该系统集成到CARLA+Nav2仿真中，仅在基线BT失败时触发。

Result: 在CARLA+Nav2仿真中，系统成功导航绕过意外障碍物（如街道堵塞），无需人工干预。与静态BT基线相比，该方法作为概念验证可扩展到多种驾驶场景。

Conclusion: 该框架展示了LLM和LVMs在动态生成自适应行为树方面的潜力，为自动驾驶车辆在不可预测环境中的安全导航提供了新的解决方案。

Abstract: Autonomous vehicles (AVs) require adaptive behavior planners to navigate unpredictable, real-world environments safely. Traditional behavior trees (BTs) offer structured decision logic but are inherently static and demand labor-intensive manual tuning, limiting their applicability at SAE Level 5 autonomy. This paper presents an agentic framework that leverages large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs on the fly. A specialized Descriptor agent applies chain-of-symbols prompting to assess scene criticality, a Planner agent constructs high-level sub-goals via in-context learning, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, our system triggers only upon baseline BT failure, demonstrating successful navigation around unexpected obstacles (e.g., street blockage) with no human intervention. Compared to a static BT baseline, this approach is a proof-of-concept that extends to diverse driving scenarios.

</details>


### [253] [A Hierarchical Benchmark of Foundation Models for Dermatology](https://arxiv.org/abs/2601.12382)
*Furkan Yuceyalcin,Abdurrahim Yilmaz,Burak Temelkuran*

Main category: cs.CV

Relevance: 65.0

TL;DR: 该研究评估了10个基础模型在皮肤病变分层分类中的表现，发现通用医学基础模型在高级筛查中表现优异，但皮肤病学专用模型在细粒度亚型分类上更优，揭示了模型能力的"粒度差距"。


<details>
  <summary>Details</summary>
Motivation: 当前皮肤病学基准测试常将复杂的诊断分类简化为二元分类任务，这种过度简化掩盖了模型进行细粒度鉴别诊断的能力，而这是临床工作流程整合的关键。研究旨在评估不同基础模型在分层皮肤病变分类中的实用性。

Method: 使用DERM12345数据集（包含40个病变亚类），计算10个基础模型的冻结嵌入并训练轻量级适配器模型，采用五折交叉验证。引入分层评估框架，在四个临床粒度级别评估性能：40个亚类、15个主类、2和4个超类、二元恶性分类。

Result: MedImageInsights在二元恶性检测中表现最佳（97.52%加权F1分数），但在细粒度40类亚型分类中降至65.50%。MedSigLip（69.79%）和皮肤病学专用模型在细粒度亚型鉴别中表现优异，但在更广泛的分类任务中整体性能较低。

Conclusion: 通用医学基础模型在高级筛查中非常有效，但诊断支持系统所需的细粒度区分需要专门的建模策略。研究揭示了模型能力的"粒度差距"，强调了根据临床需求选择适当模型的重要性。

Abstract: Foundation models have transformed medical image analysis by providing robust feature representations that reduce the need for large-scale task-specific training. However, current benchmarks in dermatology often reduce the complex diagnostic taxonomy to flat, binary classification tasks, such as distinguishing melanoma from benign nevi. This oversimplification obscures a model's ability to perform fine-grained differential diagnoses, which is critical for clinical workflow integration. This study evaluates the utility of embeddings derived from ten foundation models, spanning general computer vision, general medical imaging, and dermatology-specific domains, for hierarchical skin lesion classification. Using the DERM12345 dataset, which comprises 40 lesion subclasses, we calculated frozen embeddings and trained lightweight adapter models using a five-fold cross-validation. We introduce a hierarchical evaluation framework that assesses performance across four levels of clinical granularity: 40 Subclasses, 15 Main Classes, 2 and 4 Superclasses, and Binary Malignancy. Our results reveal a "granularity gap" in model capabilities: MedImageInsights achieved the strongest overall performance (97.52% weighted F1-Score on Binary Malignancy detection) but declined to 65.50% on fine-grained 40-class subtype classification. Conversely, MedSigLip (69.79%) and dermatology-specific models (Derm Foundation and MONET) excelled at fine-grained 40-class subtype discrimination while achieving lower overall performance than MedImageInsights on broader classification tasks. Our findings suggest that while general medical foundation models are highly effective for high-level screening, specialized modeling strategies are necessary for the granular distinctions required in diagnostic support systems.

</details>


### [254] [Adversarial Defense in Vision-Language Models: An Overview](https://arxiv.org/abs/2601.12443)
*Xiaowei Fu,Lei Zhang*

Main category: cs.CV

Relevance: 65.0

TL;DR: 该论文综述了视觉语言模型（VLMs）对抗性防御策略的最新进展，重点分析了三种主要防御范式：训练时防御、测试时自适应防御和免训练防御，并讨论了增强VLM鲁棒性的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（如CLIP）的广泛应用，其对抗性攻击脆弱性引发了安全担忧。这些攻击可能损害跨模态任务中的模型性能和系统安全，因此需要系统性地研究防御策略。

Method: 采用文献综述方法，系统性地分类和分析三种主要防御范式：1）训练时防御（通过对抗性微调改进训练过程）；2）测试时自适应防御（在推理时更新参数处理对抗样本）；3）免训练防御（通过修改输入或特征嵌入来缓解攻击影响）。

Result: 论文总结了各种防御方法的优缺点：训练时防御有效但计算成本高且泛化能力有限；测试时自适应防御灵活但增加复杂性和计算开销；免训练防御无需额外训练但可能防御效果有限。指出了当前防御策略面临的挑战。

Conclusion: 需要开发更高效、通用且实用的防御策略来增强VLMs的鲁棒性，平衡防御效果与计算效率，并应对不断演变的对抗性攻击威胁。

Abstract: The widespread use of Vision Language Models (VLMs, e.g. CLIP) has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks. These attacks could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve the robustness to adversarial examples. While effective, this approach requires substantial computational resources and may not generalize across all adversarial attacks. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings, which enforces input perturbations to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.

</details>


### [255] [DCAC: Dynamic Class-Aware Cache Creates Stronger Out-of-Distribution Detectors](https://arxiv.org/abs/2601.12468)
*Yanqi Wu,Qichao Chen,Runhe Lai,Xinhua Lu,Jia-Xin Zhuang,Zhilin Zhao,Wei-Shi Zheng,Ruixuan Wang*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出DCAC（动态类感知缓存），一种无需训练、测试时校准模块，通过为每个ID类别维护独立缓存来收集高熵样本，校准输入样本的原始预测，缓解OOD样本的过度自信预测问题。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在OOD检测中存在根本性挑战，特别是在未见OOD样本上产生过度自信预测。研究发现：被预测为同一类别或具有高概率的OOD样本，在视觉上彼此相似度高于真实ID样本。基于这一类别特定观察，需要开发有效的OOD检测方法。

Method: 提出DCAC模块：1）为每个ID类别维护独立缓存，收集高熵样本；2）利用缓存视觉特征和预测概率，通过轻量级两层模块校准原始预测；3）可无缝集成到各种现有OOD检测方法中，适用于单模态和视觉语言模型；4）计算开销最小。

Result: 在多个OOD基准测试中，DCAC显著增强现有方法：与ASH-S集成时，在ImageNet OOD基准上FPR95降低6.55%。

Conclusion: DCAC是一种有效的训练免费、测试时校准模块，能够显著改善现有OOD检测方法的性能，通过类别特定的缓存机制缓解OOD样本的过度自信预测问题。

Abstract: Out-of-distribution (OOD) detection remains a fundamental challenge for deep neural networks, particularly due to overconfident predictions on unseen OOD samples during testing. We reveal a key insight: OOD samples predicted as the same class, or given high probabilities for it, are visually more similar to each other than to the true in-distribution (ID) samples. Motivated by this class-specific observation, we propose DCAC (Dynamic Class-Aware Cache), a training-free, test-time calibration module that maintains separate caches for each ID class to collect high-entropy samples and calibrate the raw predictions of input samples. DCAC leverages cached visual features and predicted probabilities through a lightweight two-layer module to mitigate overconfident predictions on OOD samples. This module can be seamlessly integrated with various existing OOD detection methods across both unimodal and vision-language models while introducing minimal computational overhead. Extensive experiments on multiple OOD benchmarks demonstrate that DCAC significantly enhances existing methods, achieving substantial improvements, i.e., reducing FPR95 by 6.55% when integrated with ASH-S on ImageNet OOD benchmark.

</details>


### [256] [VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness](https://arxiv.org/abs/2601.12672)
*Qimao Chen,Fang Li,Shaoqing Xu,Zhiyi Lai,Zixun Xie,Yuechen Luo,Shengyin Jiang,Hanbing Li,Long Chen,Bing Wang,Yi Zhang,Zhi-Xin Yang*

Main category: cs.CV

Relevance: 65.0

TL;DR: VILTA框架利用视觉语言模型直接编辑周围车辆的未来轨迹，在自动驾驶闭环训练中生成多样化的危险场景，解决长尾安全问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统面临长尾问题，罕见但关键的驾驶场景在真实数据中严重不足。现有方法依赖规则启发式、重采样和离线学习的生成模型，难以产生多样新颖的挑战场景。两阶段方法限制了VLM的生成潜力。

Method: 提出VILTA框架，将VLM集成到自动驾驶代理的闭环训练中。VLM理解动态驾驶环境，通过直接精细编辑周围车辆的未来轨迹，战略性地生成挑战性场景，充分利用VLM的强大泛化能力。

Result: 该方法显著增强了自动驾驶策略的安全性和鲁棒性，特别是在处理关键长尾事件方面表现出色，超越了传统方法的范围。

Conclusion: VILTA框架通过VLM直接编辑轨迹的方式，有效解决了自动驾驶的长尾安全问题，为生成多样化挑战场景提供了新思路。

Abstract: The safe deployment of autonomous driving (AD) systems is fundamentally hindered by the long-tail problem, where rare yet critical driving scenarios are severely underrepresented in real-world data. Existing solutions including safety-critical scenario generation and closed-loop learning often rely on rule-based heuristics, resampling methods and generative models learned from offline datasets, limiting their ability to produce diverse and novel challenges. While recent works leverage Vision Language Models (VLMs) to produce scene descriptions that guide a separate, downstream model in generating hazardous trajectories for agents, such two-stage framework constrains the generative potential of VLMs, as the diversity of the final trajectories is ultimately limited by the generalization ceiling of the downstream algorithm. To overcome these limitations, we introduce VILTA (VLM-In-the-Loop Trajectory Adversary), a novel framework that integrates a VLM into the closed-loop training of AD agents. Unlike prior works, VILTA actively participates in the training loop by comprehending the dynamic driving environment and strategically generating challenging scenarios through direct, fine-grained editing of surrounding agents' future trajectories. This direct-editing approach fully leverages the VLM's powerful generalization capabilities to create a diverse curriculum of plausible yet challenging scenarios that extend beyond the scope of traditional methods. We demonstrate that our approach substantially enhances the safety and robustness of the resulting AD policy, particularly in its ability to navigate critical long-tail events.

</details>


### [257] [Moaw: Unleashing Motion Awareness for Video Diffusion Models](https://arxiv.org/abs/2601.12761)
*Tianqi Zhang,Ziyi Wang,Wenzhao Zheng,Weiliang Chen,Yuanhui Huang,Zhengyang Huang,Jie Zhou,Jiwen Lu*

Main category: cs.CV

Relevance: 65.0

TL;DR: Moaw框架利用视频扩散模型的运动感知能力进行运动迁移，通过训练扩散模型进行运动感知（视频到密集跟踪），然后将运动特征注入到结构相同的视频生成模型中，实现零样本运动迁移。


<details>
  <summary>Details</summary>
Motivation: 视频扩散模型在大规模数据集训练中自然捕捉了帧间共享特征的对应关系，已有工作利用这一特性进行零样本光流预测和跟踪。本文研究监督训练是否能更充分地利用视频扩散模型的跟踪能力。

Method: 提出Moaw框架：1）训练扩散模型进行运动感知，将其模态从图像到视频生成转变为视频到密集跟踪；2）构建运动标注数据集识别编码最强运动信息的特征；3）将这些特征注入到结构相同的视频生成模型中，利用网络同质性实现零样本适配。

Result: 该框架实现了运动迁移而无需额外适配器，为生成建模和运动理解之间的桥梁提供了新范式，为更统一和可控的视频学习框架铺平道路。

Conclusion: Moaw框架成功释放了视频扩散模型的运动感知能力，通过监督训练充分利用其跟踪能力，实现了有效的运动迁移，展示了生成模型在运动理解任务中的潜力。

Abstract: Video diffusion models, trained on large-scale datasets, naturally capture correspondences of shared features across frames. Recent works have exploited this property for tasks such as optical flow prediction and tracking in a zero-shot setting. Motivated by these findings, we investigate whether supervised training can more fully harness the tracking capability of video diffusion models. To this end, we propose Moaw, a framework that unleashes motion awareness for video diffusion models and leverages it to facilitate motion transfer. Specifically, we train a diffusion model for motion perception, shifting its modality from image-to-video generation to video-to-dense-tracking. We then construct a motion-labeled dataset to identify features that encode the strongest motion information, and inject them into a structurally identical video generation model. Owing to the homogeneity between the two networks, these features can be naturally adapted in a zero-shot manner, enabling motion transfer without additional adapters. Our work provides a new paradigm for bridging generative modeling and motion understanding, paving the way for more unified and controllable video learning frameworks.

</details>


### [258] [A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling](https://arxiv.org/abs/2601.12820)
*Wei Chen,Liang Wu,Shuyi Lu,Yuanyuan Sun,Wenkai Bi,Zilong Yuan,Yaoyao He,Feng Wang,Junchi Ma,Shuyong Liu,Zhaoping Cheng,Xiaoyan Hu,Jianfeng Qiu*

Main category: cs.CV

Relevance: 65.0

TL;DR: SDF-HOLO是一个用于全身PET/CT的多模态基础模型，通过双流编码器分离CT和PET表示学习，结合跨模态交互模块，并利用解剖分割掩码作为语义锚点进行体素-掩码-文本对齐，在肿瘤分割、低剂量病变检测和多语言诊断报告生成等任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 全身PET/CT成像面临三个主要挑战：1) 异质的解剖和代谢信号；2) 约2米的轴向覆盖范围；3) 结构化的放射学语义。现有医学AI模型假设单模态输入、局部视野和粗糙的图像-文本对齐，无法有效处理这些挑战。需要开发能够处理全身范围、多模态输入并理解复杂临床语义的基础模型。

Method: 1) 使用双流编码器分离CT和PET表示学习；2) 通过跨模态交互模块耦合两种模态，让解剖上下文细化PET聚合，同时代谢显著性指导细微形态推理；3) 分层上下文建模结合高效局部窗口和全局注意力来处理长距离依赖；4) 使用解剖分割掩码作为显式语义锚点，在预训练期间执行体素-掩码-文本对齐；5) 在超过10,000名患者数据上进行预训练。

Result: 在肿瘤分割、低剂量病变检测和多语言诊断报告生成任务上，SDF-HOLO超越了强大的任务特定基线和临床参考基线，同时减少了定位错误和幻觉发现。模型不仅支持局部解释，还能实现全身代谢分析，揭示肿瘤相关的器官间代谢网络相互作用的指纹特征。

Conclusion: SDF-HOLO为全身PET/CT诊断和系统级精准肿瘤学提供了一个可扩展的计算基础。该模型通过创新的多模态融合、长距离依赖建模和语义对齐方法，解决了现有医学AI模型在处理全身成像时的局限性。

Abstract: Total-body PET/CT enables system-wide molecular imaging, but heterogeneous anatomical and metabolic signals, approximately 2 m axial coverage, and structured radiology semantics challenge existing medical AI models that assume single-modality inputs, localized fields of view, and coarse image-text alignment. We introduce SDF-HOLO (Systemic Dual-stream Fusion Holo Model), a multimodal foundation model for holistic total-body PET/CT, pre-trained on more than 10,000 patients. SDF-HOLO decouples CT and PET representation learning with dual-stream encoders and couples them through a cross-modal interaction module, allowing anatomical context to refine PET aggregation while metabolic saliency guides subtle morphological reasoning. To model long-range dependencies across the body, hierarchical context modeling combines efficient local windows with global attention. To bridge voxels and clinical language, we use anatomical segmentation masks as explicit semantic anchors and perform voxel-mask-text alignment during pre-training. Across tumor segmentation, low-dose lesion detection, and multilingual diagnostic report generation, SDF-HOLO outperforms strong task-specific and clinical-reference baselines while reducing localization errors and hallucinated findings. Beyond focal interpretation, the model enables system-wide metabolic profiling and reveals tumor-associated fingerprints of inter-organ metabolic network interactions, providing a scalable computational foundation for total-body PET/CT diagnostics and system-level precision oncology.

</details>


### [259] [Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification](https://arxiv.org/abs/2601.12826)
*Teerapong Panboonyuen*

Main category: cs.CV

Relevance: 65.0

TL;DR: 该研究批判性评估了Grad-CAM在肺癌图像分类中的解释可靠性，发现其在卷积网络中有效，但在Vision Transformer中解释保真度显著下降，揭示了当前显著性解释方法在医学影像中的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管Grad-CAM等XAI技术在医学图像分析中广泛使用，但其解释的忠实性和可靠性仍受到质疑。本研究旨在探究Grad-CAM是否真正反映了深度模型在肺癌图像分类中的内部决策过程，特别是在不同架构模型中的表现差异。

Method: 使用公开的IQ-OTH/NCCD数据集，评估五种代表性架构：ResNet-50、ResNet-101、DenseNet-161、EfficientNet-B0和ViT-Base-Patch16-224。引入定量评估框架，结合定位准确性、基于扰动的忠实性和解释一致性来评估Grad-CAM在不同架构中的可靠性。

Result: 实验发现：1) Grad-CAM在大多数卷积网络中能有效突出肿瘤区域；2) 在Vision Transformer模型中，由于非局部注意力行为，其解释保真度显著下降；3) 跨模型比较显示显著性定位存在显著变异性，表明Grad-CAM解释可能并不总是对应网络使用的真实诊断证据。

Conclusion: 该研究揭示了当前基于显著性的XAI方法在医学影像中的关键局限性，强调需要开发既计算可靠又具有临床意义的模型感知可解释性方法。研究结果旨在促进医学AI中视觉解释工具的更谨慎和严谨采用，促使社区重新思考"信任"模型解释的真正含义。

Abstract: Explainable Artificial Intelligence (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM), have become indispensable for visualizing the reasoning process of deep neural networks in medical image analysis. Despite their popularity, the faithfulness and reliability of these heatmap-based explanations remain under scrutiny. This study critically investigates whether Grad-CAM truly represents the internal decision-making of deep models trained for lung cancer image classification. Using the publicly available IQ-OTH/NCCD dataset, we evaluate five representative architectures: ResNet-50, ResNet-101, DenseNet-161, EfficientNet-B0, and ViT-Base-Patch16-224, to explore model-dependent variations in Grad-CAM interpretability. We introduce a quantitative evaluation framework that combines localization accuracy, perturbation-based faithfulness, and explanation consistency to assess Grad-CAM reliability across architectures. Experimental findings reveal that while Grad-CAM effectively highlights salient tumor regions in most convolutional networks, its interpretive fidelity significantly degrades for Vision Transformer models due to non-local attention behavior. Furthermore, cross-model comparisons indicate substantial variability in saliency localization, implying that Grad-CAM explanations may not always correspond to the true diagnostic evidence used by the networks. This work exposes critical limitations of current saliency-based XAI approaches in medical imaging and emphasizes the need for model-aware interpretability methods that are both computationally sound and clinically meaningful. Our findings aim to inspire a more cautious and rigorous adoption of visual explanation tools in medical AI, urging the community to rethink what it truly means to "trust" a model's explanation.

</details>


### [260] [Proxy Robustness in Vision Language Models is Effortlessly Transferable](https://arxiv.org/abs/2601.12865)
*Xiaowei Fu,Fuxiang Huang,Lei Zhang*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出HPT-GPD方法，通过异构代理传输框架实现视觉语言模型（如CLIP）的对抗鲁棒性迁移，同时保持零样本泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统对抗鲁棒性蒸馏方法在应用于大规模视觉语言模型（如CLIP）时面临计算资源过高的问题。作者发现普通CLIP模型对不同架构CLIP生成的对抗样本具有内在防御能力，这为鲁棒性迁移提供了新思路。

Method: 提出异构代理传输（HPT）框架，在不同架构的CLIP变体之间建立跨架构鲁棒性蒸馏通道。为解决代理传输导致的过拟合问题，设计泛化枢轴解耦（GPD）方法，利用学习率调度差异将代理传输过程分解为保持泛化的预热阶段和提升对抗鲁棒性的HPT阶段。

Result: 在15个零样本数据集上的广泛实验证明了HPT-GPD方法的有效性，能够在保持自然泛化能力的同时提升对抗鲁棒性。

Conclusion: 该方法为视觉语言模型的对抗鲁棒性迁移提供了一种高效且实用的解决方案，解决了传统方法计算成本过高的问题，同时平衡了鲁棒性和泛化能力。

Abstract: As a pivotal technique for improving the defense of deep models, adversarial robustness transfer via distillation has demonstrated remarkable success in conventional image classification tasks. However, this paradigm encounters critical challenges when applied to vision-language models (VLM) (e.g., CLIP): constructing adversarially robust teacher for large-scale multi-modal models demands prohibitively high computational resources. We bridge this gap by revealing an interesting phenomenon: vanilla CLIP (without adversarial training) exhibits intrinsic defensive capabilities against adversarial examples generated by another CLIP with different architectures. We formally define this as proxy adversarial robustness, and naturally propose a Heterogeneous Proxy Transfer (HPT) framework that establishes cross-architectural robustness distillation channels between CLIP variants, effortlessly enabling the VLM robustness transfer from proxy to target models. Yet, such proxy transfer paradigm easily induces severe overfitting, leading to a sharp degradation in zero-shot natural generalization. To resolve that, we design Generalization-Pivot Decoupling (GPD) by leveraging the difference in learning rate scheduling. This decouples the proxy transfer process into a generalization-anchored warm-up that maintains generalization and a generalization-pulled HPT that promotes adversarial robustness, to achieve an equilibrium between natural generalization and adversarial robustness. Extensive experiments on 15 zero-shot datasets demonstrate the effectiveness of our HPT-GPD method. The code is available at the website of github.com/fxw13/HPT-GPD.

</details>


### [261] [StyMam: A Mamba-Based Generator for Artistic Style Transfer](https://arxiv.org/abs/2601.12954)
*Zhou Hong,Rongsheng Hu,Yicheng Di,Xiaolong Xu,Ning Dong,Yihua Shao,Run Ling,Yun Wang,Juqin Wang,Zhanjie Zhang,Ao Ma*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出基于Mamba的生成器StyMam用于图像风格迁移，通过残差双路径条带扫描机制和通道重加权空间注意力模块，在保持内容结构的同时提升生成质量与速度


<details>
  <summary>Details</summary>
Motivation: 现有GAN方法难以同时捕捉局部和全局依赖关系，导致伪影和不协调模式；SD方法虽然减少这些问题但难以保持内容结构且推理速度慢。需要一种既能保持内容结构又能高效生成高质量风格化图像的方法。

Method: 提出基于Mamba的生成器StyMam，包含：1）残差双路径条带扫描机制，高效捕捉局部纹理特征；2）通道重加权空间注意力模块，建模全局依赖关系。结合GAN框架实现高质量风格迁移。

Result: 定性和定量实验表明，该方法在质量和速度上都优于现有最先进算法，能够生成无伪影、模式协调的高质量风格化图像。

Conclusion: 基于Mamba的生成器在图像风格迁移任务中表现出色，既能保持内容结构，又能高效生成高质量结果，为风格迁移提供了新的有效解决方案。

Abstract: Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.

</details>


### [262] [TVWorld: Foundations for Remote-Control TV Agents](https://arxiv.org/abs/2601.13142)
*Zhantao Ma,Quanfeng Lu,Shuai Zhong,Dahai Yu,Ping Luo,Michael K. Ng*

Main category: cs.CV

Relevance: 65.0

TL;DR: TVWorld：基于离线图抽象的真实世界电视导航评估框架，包含拓扑感知导航(TVWorld-N)和焦点感知定位(TVWorld-G)两个基准，揭示了现有智能体在长视野电视导航中的拓扑意识不足问题，并提出了拓扑感知训练框架和TVTheseus模型。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型(LVLMs)在设备控制方面的研究主要集中在点按交互(PnC)，而日常电视使用中常见的遥控交互(RC)尚未得到充分探索。需要填补这一空白，建立可重复、无需部署的电视导航评估体系。

Method: 1) 提出TVWorld：基于离线图抽象的真实世界电视导航系统，实现可重复评估；2) 构建两个互补基准：TVWorld-N用于拓扑感知导航，TVWorld-G用于焦点感知定位；3) 提出拓扑感知训练框架，将拓扑意识注入LVLMs；4) 开发TVTheseus：专门用于电视导航的基础模型。

Result: TVTheseus在TVWorld-N上达到68.3%的成功率，超越了Gemini 3 Flash等强闭源基线，建立了最先进的性能。分析揭示了现有智能体在基于焦点的长视野电视导航中拓扑意识不足的关键限制。

Conclusion: 该研究填补了电视遥控交互评估的空白，提出的拓扑感知训练框架有效提升了LVLMs在复杂电视导航任务中的性能，为开发有效的电视使用智能体提供了有价值的见解。

Abstract: Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \textbf{TVWorld-N} for topology-aware navigation and \textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.

</details>


### [263] [ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection](https://arxiv.org/abs/2601.13234)
*Md. Nishan Khan,Kazi Shahriar Sanjid,Md. Tanzim Hossain,Asib Mostakim Fony,Istiak Ahmed,M. Monir Uddin*

Main category: cs.CV

Relevance: 65.0

TL;DR: ConvMambaNet：结合CNN与Mamba SSM的混合深度学习模型，用于癫痫发作检测，在CHB-MIT头皮EEG数据集上达到99%准确率


<details>
  <summary>Details</summary>
Motivation: 癫痫严重影响生活质量，EEG是监测神经活动和检测癫痫的主要工具，但由于EEG信号的时序复杂性，自动分析仍然具有挑战性。需要开发能够有效捕捉时空特征的模型来改进癫痫发作检测。

Method: 提出ConvMambaNet混合深度学习模型，将Mamba结构化状态空间模型（SSM）块嵌入CNN框架中。CNN负责提取空间特征，Mamba SSM捕捉长程时序动态，两者结合实现时空特征的有效提取。

Result: 在CHB-MIT头皮EEG数据集上评估，ConvMambaNet达到99%的准确率，并在严重类别不平衡情况下表现出鲁棒性能。

Conclusion: ConvMambaNet展示了精确高效的癫痫发作检测潜力，为临床环境中实时自动化癫痫监测提供了可行路径。模型结合了CNN的空间特征提取能力和Mamba SSM的时序建模优势。

Abstract: Epilepsy is a chronic neurological disorder marked by recurrent seizures that can severely impact quality of life. Electroencephalography (EEG) remains the primary tool for monitoring neural activity and detecting seizures, yet automated analysis remains challenging due to the temporal complexity of EEG signals. This study introduces ConvMambaNet, a hybrid deep learning model that integrates Convolutional Neural Networks (CNNs) with the Mamba Structured State Space Model (SSM) to enhance temporal feature extraction. By embedding the Mamba-SSM block within a CNN framework, the model effectively captures both spatial and long-range temporal dynamics. Evaluated on the CHB-MIT Scalp EEG dataset, ConvMambaNet achieved a 99% accuracy and demonstrated robust performance under severe class imbalance. These results underscore the model's potential for precise and efficient seizure detection, offering a viable path toward real-time, automated epilepsy monitoring in clinical environments.

</details>


### [264] [Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation](https://arxiv.org/abs/2601.13683)
*Boyuan Cao,Xingbo Yao,Chenhui Wang,Jiaxin Ye,Yujie Wei,Hongming Shan*

Main category: cs.CV

Relevance: 65.0

TL;DR: DyDiLA提出动态差分线性注意力机制，解决线性扩散变换器中注意力权重过度平滑问题，提升生成质量


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiTs)在图像生成中表现出色，但自注意力的二次计算成本成为可扩展性瓶颈。线性注意力机制虽然降低了计算成本，但线性扩散变换器(LiTs)往往以生成性能为代价，产生过度平滑的注意力权重，限制了表达能力。

Method: 提出动态差分线性注意力(DyDiLA)，包含三个关键设计：1) 动态投影模块，通过学习动态分配的知识促进令牌表示解耦；2) 动态测量核，通过为令牌处理动态分配核函数提供更好的相似性测量；3) 令牌差分算子，通过计算令牌与其对应信息冗余之间的差异实现更稳健的查询到键检索。基于DyDiLA构建了改进的LiT模型DyDi-LiT。

Result: 广泛实验表明，DyDi-LiT在多个指标上持续优于当前最先进模型，显示出强大的实际潜力。

Conclusion: DyDiLA通过解决线性注意力中的过度平滑问题，显著提升了线性扩散变换器的生成质量，为高效高保真图像生成提供了有前景的解决方案。

Abstract: Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.

</details>


### [265] [Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search](https://arxiv.org/abs/2601.13719)
*Xinlei Yin,Xiulian Peng,Xiao Li,Zhiwei Xiong,Yan Lu*

Main category: cs.CV

Relevance: 65.0

TL;DR: HAVEN框架通过整合视听实体凝聚和分层视频索引，结合智能搜索机制，解决了长视频理解中的信息碎片化和全局连贯性问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于分块策略和检索增强生成的长视频理解方法存在信息碎片化和全局连贯性丢失的问题，需要一种能够保持语义一致性和全局推理能力的统一框架。

Method: 1) 跨视觉和听觉流的实体级表示整合以保持语义一致性；2) 构建全局摘要、场景、片段和实体级别的结构化层次；3) 采用智能搜索机制在这些层次间进行动态检索和推理。

Result: 在LVBench上达到84.1%的整体准确率，在具有挑战性的推理类别中达到80.1%，在时间连贯性、实体一致性和检索效率方面表现优异。

Conclusion: 结构化多模态推理对于长视频的全面和上下文一致理解是有效的，HAVEN框架为长视频理解建立了新的技术标准。

Abstract: Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.

</details>


### [266] [Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders](https://arxiv.org/abs/2601.13798)
*Kai Wittenmayer,Sukrut Rao,Amin Parchami-Araghi,Bernt Schiele,Jonas Fischer*

Main category: cs.CV

Relevance: 65.0

TL;DR: Insight是一个语言对齐的概念基础模型，通过分层稀疏自编码器提取细粒度、空间定位的概念，提供可解释的视觉表示，在分类和分割任务上保持竞争力的同时提供高质量概念解释。


<details>
  <summary>Details</summary>
Motivation: 当前语言对齐的视觉基础模型虽然在多种下游任务上表现优异，但其学习到的表示仍然不透明，难以解释其决策过程。现有工作虽然尝试将表示分解为人类可解释的概念，但存在空间定位能力差、仅限于图像分类任务的局限性。

Method: 提出Insight模型，利用分层稀疏自编码器和具有强语义表示的基础模型，自动提取不同粒度的概念。通过分析概念的局部共现依赖关系定义概念关系，并利用这些关系改进概念命名和获得更丰富的解释。

Result: 在基准数据上，Insight在分类和分割任务上的性能与不透明的基础模型相当，同时提供细粒度、高质量的概念解释。代码已开源。

Conclusion: Insight成功构建了一个既能保持竞争力性能又能提供可解释概念表示的语言对齐概念基础模型，解决了现有视觉基础模型解释性不足的问题。

Abstract: Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight.

</details>


### [267] [Human detectors are surprisingly powerful reward models](https://arxiv.org/abs/2601.14037)
*Kumar Ashutosh,XuDong Wang,Xi Yin,Kristen Grauman,Adam Polyak,Ishan Misra,Rohit Girdhar*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出HuDA奖励模型，通过结合人体检测置信度和时序提示对齐分数来量化和改进生成视频中的人类动作质量，无需额外训练即可超越专门微调的模型。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在复杂非刚性动作（如体育、舞蹈等）上表现不佳，经常出现肢体缺失、姿势扭曲或物理上不合理的问题，需要更好的方法来评估和改进人类动作质量。

Method: 提出HuDA奖励模型，结合两个简单组件：1)人体检测置信度评估外观质量，2)时序提示对齐分数捕捉动作真实性。使用现成模型无需额外训练，然后通过Group Reward Policy Optimization (GRPO)对视频模型进行后训练。

Result: HuDA在评估人类动作质量方面优于专门微调的模型，使用GRPO后训练显著提升视频生成质量，在复杂人类动作生成上超越Wan 2.1等SOTA模型，胜率达73%。该方法还能改进动物视频和人物-物体交互的生成。

Conclusion: 简单的奖励模型HuDA能有效量化和改进生成视频中的人类动作质量，无需额外训练即可超越专门微调的模型，通过GRPO后训练能显著提升视频生成性能，且方法具有泛化性。

Abstract: Video generation models have recently achieved impressive visual fidelity and temporal coherence. Yet, they continue to struggle with complex, non-rigid motions, especially when synthesizing humans performing dynamic actions such as sports, dance, etc. Generated videos often exhibit missing or extra limbs, distorted poses, or physically implausible actions. In this work, we propose a remarkably simple reward model, HuDA, to quantify and improve the human motion in generated videos. HuDA integrates human detection confidence for appearance quality, and a temporal prompt alignment score to capture motion realism. We show this simple reward function that leverages off-the-shelf models without any additional training, outperforms specialized models finetuned with manually annotated data. Using HuDA for Group Reward Policy Optimization (GRPO) post-training of video models, we significantly enhance video generation, especially when generating complex human motions, outperforming state-of-the-art models like Wan 2.1, with win-rate of 73%. Finally, we demonstrate that HuDA improves generation quality beyond just humans, for instance, significantly improving generation of animal videos and human-object interactions.

</details>


### [268] [Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI](https://arxiv.org/abs/2601.14055)
*Andrea Protani,Marc Molina Van Den Bosch,Lorenzo Giusti,Heloisa Barbosa Da Silva,Paolo Cacace,Albert Sund Aillet,Miguel Angel Gonzalez Ballester,Friedhelm Hummel,Luigi Serio*

Main category: cs.CV

Relevance: 65.0

TL;DR: SVGFormer：基于语义图分割的3D医学图像编码器，通过内容感知分组将体素网格转换为超体素图，结合Transformer和GAT实现双尺度特征学习，无需解码器即可获得可解释的表示。


<details>
  <summary>Details</summary>
Motivation: 传统3D医学视觉主干网络采用参数密集的编码器-解码器结构，大量参数用于空间重建而非特征学习。需要一种更专注于特征编码且具有内在可解释性的替代方案。

Method: 1. 内容感知分组阶段：将3D体素网格分割成语义图（超体素图）
2. 分层编码器：结合补丁级Transformer和超体素级图注意力网络（GAT）
3. 无解码器设计：所有可学习容量集中于特征编码
4. 双尺度可解释性：从补丁到区域级别的内在解释

Result: 在BraTS数据集上训练了两个专门模型：节点级分类模型（F1-score 0.875）和肿瘤比例回归模型（MAE 0.028），验证了编码器学习判别性和局部化特征的能力。

Conclusion: 基于图的编码器范式为3D医学图像表示提供了准确且内在可解释的替代方案，专注于特征学习而非空间重建。

Abstract: Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, a design that allocates a significant portion of its parameters to spatial reconstruction rather than feature learning. Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework's flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder's ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.

</details>


### [269] [POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion](https://arxiv.org/abs/2601.14056)
*Andrea Rigo,Luca Stornaiuolo,Weijie Wang,Mauro Martino,Bruno Lepri,Nicu Sebe*

Main category: cs.CV

Relevance: 65.0

TL;DR: POCI-Diff：基于扩散的文本到图像生成框架，通过3D边界框实现一致且交互式的布局控制和编辑，避免几何扭曲并保持跨编辑一致性


<details>
  <summary>Details</summary>
Motivation: 现有方法使用2D线索或迭代复制-扭曲-粘贴策略，常常扭曲对象几何形状且无法在编辑间保持一致性。需要一种能同时强制执行3D几何约束和实例级语义绑定的统一框架

Method: 1) 通过Blended Latent Diffusion将文本描述绑定到特定3D边界框，实现显式的每对象语义控制；2) 提出无扭曲生成编辑流程，通过重新生成而非像素变形支持对象插入、移除和变换；3) 使用IP-Adapter基于参考图像条件化扩散过程，保持对象身份和一致性

Result: POCI-Diff生成高质量图像，与指定3D布局和编辑保持一致，在视觉保真度和布局遵循方面优于现有方法，消除了扭曲引起的几何伪影

Conclusion: 该方法通过统一扩散过程实现了3D几何约束和语义绑定，为文本到图像生成提供了更一致、可交互的布局控制和编辑能力

Abstract: We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.

</details>


### [270] [Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition](https://arxiv.org/abs/2601.14101)
*Emily Kim,Allen Wu,Jessica Hodgins*

Main category: cs.CV

Relevance: 65.0

TL;DR: 该论文研究课程学习在跨视角动作识别中的应用，通过合成空中视角数据和真实地面视角数据的组合训练，实现在未见真实空中数据上的泛化，同时提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前动作识别模型在跨视角泛化方面存在挑战，特别是从地面视角到空中视角的迁移。现有数据集多为地面视角，模型难以适应空中视角等不同领域。本研究旨在探索如何在不使用真实空中数据的情况下，通过课程学习策略提升对未见真实空中视角数据的泛化能力。

Method: 提出两种课程学习策略：1）两阶段课程：先在合成空中数据上预训练，然后在真实地面数据上微调；2）渐进式课程：通过多阶段逐步扩展数据集后再微调。使用SlowFast（CNN）和MViTv2（Transformer）两种架构在REMAG数据集上进行评估。

Result: 组合两种域外数据源明显优于单一域训练。两种课程策略在保持top-1准确率（在3%范围内）的同时显著提升训练效率：两阶段微调使SlowFast减少37%迭代次数，MViTv2减少30%；渐进式方法进一步减少迭代次数（SlowFast减少9%，MViTv2减少30%）。

Conclusion: 课程学习在跨视角动作识别中能有效平衡性能与效率，通过合理利用合成数据和真实地面数据的组合训练，可以在不使用真实空中数据的情况下实现良好的泛化性能，同时大幅减少训练成本。

Abstract: Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training.
  We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures.
  Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.

</details>


### [271] [Soft Tail-dropping for Adaptive Visual Tokenization](https://arxiv.org/abs/2601.14246)
*Zeyuan Chen,Kai Zhang,Zhuowen Tu,Yuanjun Xiong*

Main category: cs.CV

Relevance: 65.0

TL;DR: STAT是一种自适应视觉分词器，根据图像结构复杂度动态选择输出token数量，生成长度自适应的1D视觉token，与因果自回归视觉生成模型兼容。


<details>
  <summary>Details</summary>
Motivation: 现有视觉分词器通常生成固定长度的token序列，无法根据图像复杂度自适应调整，限制了因果自回归视觉生成模型的效率和性能。

Method: 提出Soft Tail-dropping Adaptive Tokenizer (STAT)，将图像编码为离散代码序列及每个token的保留概率，通过单调递减正则化和图像级复杂度对齐来优化保留概率分布。

Result: 在ImageNet-1k上，STAT使普通因果自回归模型达到与其他概率模型家族竞争或更优的视觉生成质量，并展现出良好的扩展性。

Conclusion: STAT提供了一种有效的自适应视觉分词方法，解决了传统自回归视觉生成模型的扩展性问题，为视觉生成任务提供了新的解决方案。

Abstract: We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.

</details>


### [272] [OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer](https://arxiv.org/abs/2601.14250)
*Pengze Zhang,Yanze Wu,Mengtian Li,Xu Bai,Songtao Zhao,Fulong Ye,Chong Mou,Xinghui Li,Zhuowei Chen,Qian He,Mingyuan Gao*

Main category: cs.CV

Relevance: 65.0

TL;DR: OmniTransfer是一个统一的时空视频迁移框架，通过多视角信息和时序线索实现外观一致性和精细时序控制，支持多种视频迁移任务。


<details>
  <summary>Details</summary>
Motivation: 现有视频定制方法大多依赖参考图像或特定任务的时序先验，未能充分利用视频固有的丰富时空信息，限制了视频生成的灵活性和泛化能力。

Method: 提出三个关键设计：1) 任务感知位置偏置，自适应利用参考视频信息改善时序对齐或外观一致性；2) 参考解耦因果学习，分离参考和目标分支实现精确参考迁移并提高效率；3) 任务自适应多模态对齐，使用多模态语义指导动态区分和处理不同任务。

Result: 在外观迁移（ID和风格）和时序迁移（相机运动和视频效果）方面优于现有方法，在运动迁移方面与使用姿态指导的方法相当（无需使用姿态信息），建立了灵活、高保真视频生成的新范式。

Conclusion: OmniTransfer通过统一框架充分利用视频的时空信息，实现了灵活、高质量的多种视频迁移任务，为视频生成提供了新范式。

Abstract: Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.

</details>


### [273] [Implicit Neural Representation Facilitates Unified Universal Vision Encoding](https://arxiv.org/abs/2601.14256)
*Matthew Gwilliam,Xiao Wang,Xuefeng Hu,Zhenheng Yang*

Main category: cs.CV

Relevance: 65.0

TL;DR: 该论文提出了一种统一图像识别和生成任务的表示学习方法，通过超网络学习隐式神经表示，结合知识蒸馏，实现了同时适用于识别和生成的高质量紧凑嵌入空间。


<details>
  <summary>Details</summary>
Motivation: 当前图像表示学习模型通常分别针对识别任务（如分类、检测、分割）和生成任务设计。识别模型使用对比学习等方法学习分类有用的嵌入，而生成模型使用重建损失学习生成有用的潜在空间。作者希望统一这两个方向，开发一种同时适用于识别和生成的表示学习模型。

Method: 1. 将模型训练为隐式神经表示（INR）的超网络，学习将图像映射到模型权重以实现快速准确的重建。2. 将INR超网络与知识蒸馏集成，提高泛化能力和性能。3. 学习前所未有的压缩嵌入空间，在各种视觉任务中表现出色。

Result: 1. 模型在图像表示学习方面与最先进结果竞争。2. 通过高质量的小型嵌入实现生成能力。3. 学习到的压缩嵌入空间在各种视觉任务中表现优异。

Conclusion: 该研究首次实现了同时适用于识别和生成的统一表示学习模型，通过INR超网络和知识蒸馏的结合，创造了具有出色性能的压缩嵌入空间，为视觉表示学习提供了新的方向。

Abstract: Models for image representation learning are typically designed for either recognition or generation. Various forms of contrastive learning help models learn to convert images to embeddings that are useful for classification, detection, and segmentation. On the other hand, models can be trained to reconstruct images with pixel-wise, perceptual, and adversarial losses in order to learn a latent space that is useful for image generation. We seek to unify these two directions with a first-of-its-kind model that learns representations which are simultaneously useful for recognition and generation. We train our model as a hyper-network for implicit neural representation, which learns to map images to model weights for fast, accurate reconstruction. We further integrate our INR hyper-network with knowledge distillation to improve its generalization and performance. Beyond the novel training design, the model also learns an unprecedented compressed embedding space with outstanding performance for various visual tasks. The complete model competes with state-of-the-art results for image representation learning, while also enabling generative capabilities with its high-quality tiny embeddings. The code is available at https://github.com/tiktok/huvr.

</details>


### [274] [Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access](https://arxiv.org/abs/2601.13134)
*Heng Fang,Adam J. Stewart,Isaac Corley,Xiao Xiang Zhu,Hossein Azizpour*

Main category: cs.SE

Relevance: 65.0

TL;DR: 论文提出统一API标准化地理空间基础模型嵌入产品，解决现有生态系统碎片化问题，促进模型比较和可复现性。


<details>
  <summary>Details</summary>
Motivation: 地理空间基础模型(GFMs)计算成本高，预计算嵌入产品作为实用替代方案，但现有生态系统存在格式和分辨率不兼容的碎片化问题，缺乏标准化阻碍了模型比较和可复现性。

Method: 1) 提出三层分类法：数据、工具、价值；2) 调研现有产品识别互操作性障碍；3) 扩展TorchGeo提供统一API，标准化嵌入产品的加载和查询，将嵌入作为一等地理空间数据集处理。

Result: 开发了统一API标准化地理空间嵌入产品，解耦下游分析与模型特定工程，为更透明和可访问的地球观测工作流提供路线图。

Conclusion: 通过标准化地理空间嵌入产品生态系统，解决了工程瓶颈，促进了模型比较和可复现性，使地球观测工作流更加透明和可访问。

Abstract: Geospatial Foundation Models (GFMs) provide powerful representations, but high compute costs hinder their widespread use. Pre-computed embedding data products offer a practical "frozen" alternative, yet they currently exist in a fragmented ecosystem of incompatible formats and resolutions. This lack of standardization creates an engineering bottleneck that prevents meaningful model comparison and reproducibility. We formalize this landscape through a three-layer taxonomy: Data, Tools, and Value. We survey existing products to identify interoperability barriers. To bridge this gap, we extend TorchGeo with a unified API that standardizes the loading and querying of diverse embedding products. By treating embeddings as first-class geospatial datasets, we decouple downstream analysis from model-specific engineering, providing a roadmap for more transparent and accessible Earth observation workflows.

</details>


### [275] [Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning](https://arxiv.org/abs/2601.14104)
*Tairan Huang,Qingqing Ye,Yulin Jin,Jiawei Lian,Yi Wang,Haibo Hu*

Main category: cs.RO

Relevance: 65.0

TL;DR: 提出扩散引导的后门攻击框架(DGBA)，针对真实世界强化学习系统，通过条件扩散模型生成多样化的视觉补丁触发器，并采用基于优势的投毒策略，在物理机器人上实现可靠的后门激活


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击主要在仿真环境中验证，但在真实世界机器人系统中，安全约束控制管道（如速度限制、动作平滑、碰撞避免）会抑制异常动作，导致传统后门攻击效果大幅衰减。本文研究这一被忽视的问题，旨在开发适用于真实世界RL系统的有效后门攻击方法。

Method: 1) 设计可打印的视觉补丁触发器放置在地面上；2) 使用条件扩散模型生成多样化的补丁外观以适应真实世界视觉变化；3) 将机器人控制栈视为黑盒系统；4) 引入基于优势的投毒策略，仅在决策关键的训练状态注入触发器；5) 在TurtleBot3移动机器人上进行评估。

Result: 在TurtleBot3移动机器人上成功演示了目标攻击的可靠激活，同时保持了正常的任务性能。该方法能够克服真实世界安全约束控制管道对后门攻击的抑制效应。

Conclusion: DGBA框架首次展示了在真实世界机器人系统中实现有效后门攻击的可行性，揭示了现有安全约束控制管道在防御后门攻击方面的局限性，为RL系统的安全研究提供了重要启示。

Abstract: Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material.

</details>


### [276] [UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM](https://arxiv.org/abs/2601.11665)
*Amir Farzin Nikkhah,Dong Chen,Bradford Campbell,Somayeh Asadi,Arsalan Heydarian*

Main category: cs.CV

Relevance: 45.0

TL;DR: 该综述论文系统回顾了无人机在AEC+FM领域基础设施检测中的应用，涵盖数据采集、建模、缺陷检测和决策支持，并提出了一个融合多模态数据和Transformer架构的框架来改进结构缺陷检测。


<details>
  <summary>Details</summary>
Motivation: 无人机正在改变建筑、工程、施工和设施管理领域的基础设施检测方式，但现有方法在实时处理、多模态数据融合和泛化能力方面仍面临挑战，需要更系统化的框架来提高检测的准确性和可靠性。

Method: 基于150多项研究的综合分析，提出了一个集成RGB图像、LiDAR和热成像的多模态数据融合框架，结合Transformer架构进行缺陷检测，并包含动态路径规划以适应复杂环境。

Result: 无人机已在结构健康监测、灾害响应、城市基础设施管理、能源效率评估和文化遗产保护等领域证明价值，但实时处理、数据融合和泛化仍是挑战。提出的框架旨在提高结构缺陷、热异常和几何不一致检测的准确性。

Conclusion: 未来研究方向包括轻量级AI模型、自适应飞行规划、合成数据集和更丰富的模态融合，以优化现代基础设施检测流程。

Abstract: Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections.

</details>


### [277] [Digital FAST: An AI-Driven Multimodal Framework for Rapid and Early Stroke Screening](https://arxiv.org/abs/2601.11896)
*Ngoc-Khai Hoang,Thi-Nhu-Mai Nguyen,Huy-Hieu Pham*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出一种基于F.A.S.T.评估的多模态深度学习框架，用于早期中风筛查，整合面部表情、语音信号和上半身运动信息，通过注意力融合机制实现95.83%的准确率。


<details>
  <summary>Details</summary>
Motivation: 早期识别中风症状对于及时干预和改善患者预后至关重要，特别是在院前环境中。传统方法依赖专业医疗评估，需要开发快速、非侵入性的自动筛查工具。

Method: 提出多模态深度学习框架：1) 面部动态使用基于地标的特征和Transformer架构建模时间依赖；2) 语音信号转换为梅尔频谱图并用Audio Spectrogram Transformer处理；3) 上半身姿态序列用MLP-Mixer网络分析时空运动模式；4) 通过注意力融合机制整合多模态特征。

Result: 在自收集的222个视频数据集上，多模态模型优于单模态基线，达到95.83%准确率和96.00% F1分数，成功检测所有测试集中的中风病例，在敏感性和特异性之间取得良好平衡。

Conclusion: 多模态学习和迁移学习在早期中风筛查中具有潜力，但需要更大、更具临床代表性的数据集来支持可靠的现实世界部署。

Abstract: Early identification of stroke symptoms is essential for enabling timely intervention and improving patient outcomes, particularly in prehospital settings. This study presents a fast, non-invasive multimodal deep learning framework for automatic binary stroke screening based on data collected during the F.A.S.T. assessment. The proposed approach integrates complementary information from facial expressions, speech signals, and upper-body movements to enhance diagnostic robustness. Facial dynamics are represented using landmark based features and modeled with a Transformer architecture to capture temporal dependencies. Speech signals are converted into mel spectrograms and processed using an Audio Spectrogram Transformer, while upper-body pose sequences are analyzed with an MLP-Mixer network to model spatiotemporal motion patterns. The extracted modality specific representations are combined through an attention-based fusion mechanism to effectively learn cross modal interactions. Experiments conducted on a self-collected dataset of 222 videos from 37 subjects demonstrate that the proposed multimodal model consistently outperforms unimodal baselines, achieving 95.83% accuracy and a 96.00% F1-score. The model attains a strong balance between sensitivity and specificity and successfully detects all stroke cases in the test set. These results highlight the potential of multimodal learning and transfer learning for early stroke screening, while emphasizing the need for larger, clinically representative datasets to support reliable real-world deployment.

</details>


### [278] [\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions](https://arxiv.org/abs/2601.12049)
*Chenchen Zhao,Muxi Chen,Qiang Xu*

Main category: cs.CV

Relevance: 45.0

TL;DR: FocaLogic是一个模型无关的视觉模型可解释性框架，通过逻辑表示来量化和解释视觉模型的决策过程，识别影响预测的最小可解释视觉区域（视觉焦点），并将其转化为精确的逻辑表达式。


<details>
  <summary>Details</summary>
Motivation: 现代视觉模型的可解释性在高风险应用中至关重要，但现有方法要么依赖白盒模型访问，要么缺乏足够的量化严谨性。需要一种既能保持模型无关性又能提供定量评估的可解释性方法。

Method: FocaLogic框架识别最小可解释视觉区域（视觉焦点），这些区域对模型预测有决定性影响，并将其转化为精确紧凑的逻辑表达式。同时提出了一套量化指标（焦点精度、召回率、分歧度等）来客观评估模型行为。

Result: 实证分析表明FocaLogic能够揭示重要洞察：训练诱导的集中性、通过泛化提高焦点准确性，以及在偏见和对抗攻击下的异常焦点。该框架提供了系统、可扩展和定量的视觉模型解释方案。

Conclusion: FocaLogic为视觉模型解释提供了一个系统、可扩展和定量的解决方案，能够以透明和结构化的方式理解模型决策过程，特别适用于需要严格可解释性的高风险应用场景。

Abstract: Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.

</details>


### [279] [Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation](https://arxiv.org/abs/2601.12493)
*Mehrdad Noori,Gustavo Adolfo Vargas Hakim,David Osowiechi,Fereshteh Shakeri,Ali Bahri,Moslem Yazdanpanah,Sahar Dastani,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出了Histopath-C基准测试和LATTE方法，用于评估和提升医学视觉语言模型在组织病理学图像域偏移下的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型在组织病理学图像上表现良好，但实际应用中存在染色、污染、模糊、噪声等严重域偏移问题，会显著降低模型性能，需要专门的评估和适应方法

Method: 1) 提出Histopath-C基准测试，包含模拟真实世界分布偏移的合成腐蚀；2) 提出LATTE方法，一种转导式低秩适应策略，利用多个文本模板缓解模型对文本输入的敏感性

Result: LATTE方法在多个组织病理学数据集上超越了为自然图像设计的最先进测试时适应方法，证明了该方法在组织病理学图像鲁棒适应方面的有效性

Conclusion: Histopath-C基准测试和LATTE方法为解决医学视觉语言模型在组织病理学图像域偏移问题提供了有效工具，代码和数据已开源

Abstract: Medical Vision-language models (VLMs) have shown remarkable performances in various medical imaging domains such as histo\-pathology by leveraging pre-trained, contrastive models that exploit visual and textual information. However, histopathology images may exhibit severe domain shifts, such as staining, contamination, blurring, and noise, which may severely degrade the VLM's downstream performance. In this work, we introduce Histopath-C, a new benchmark with realistic synthetic corruptions designed to mimic real-world distribution shifts observed in digital histopathology. Our framework dynamically applies corruptions to any available dataset and evaluates Test-Time Adaptation (TTA) mechanisms on the fly. We then propose LATTE, a transductive, low-rank adaptation strategy that exploits multiple text templates, mitigating the sensitivity of histopathology VLMs to diverse text inputs. Our approach outperforms state-of-the-art TTA methods originally designed for natural images across a breadth of histopathology datasets, demonstrating the effectiveness of our proposed design for robust adaptation in histopathology images. Code and data are available at https://github.com/Mehrdad-Noori/Histopath-C.

</details>


### [280] [TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents](https://arxiv.org/abs/2601.12895)
*Chan Naseeb,Adeel Ashraf Cheema,Hassan Sami,Tayyab Afzal,Muhammad Omair,Usman Habib*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出TwoHead-SwinFPN架构，用于身份证件中合成篡改的检测与定位，集成Swin Transformer、FPN和UNet解码器，采用双头架构进行联合优化，在FantasyIDiap数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI模型的普及，身份证件中的合成篡改（如人脸替换、文本修复）威胁日益严重，需要同时进行篡改检测和精确定位的统一解决方案。

Method: 提出统一深度学习架构：Swin Transformer骨干网络结合FPN和UNet式解码器，增强CBAM注意力模块；采用双头架构联合优化检测和分割任务，使用不确定性加权多任务学习。

Result: 在FantasyIDiap数据集上取得84.31%准确率、90.78% AUC（分类）和57.24%平均Dice分数（定位）；二分类F1分数88.61%；通过FastAPI实现计算效率，适合实际部署。

Conclusion: TwoHead-SwinFPN能有效检测和定位身份证件中的合成篡改，在多语言、多设备场景下表现稳健，为文档防伪提供了实用解决方案。

Abstract: The proliferation of sophisticated generative AI models has significantly escalated the threat of synthetic manipulations in identity documents, particularly through face swapping and text inpainting attacks. This paper presents TwoHead-SwinFPN, a unified deep learning architecture that simultaneously performs binary classification and precise localization of manipulated regions in ID documents. Our approach integrates a Swin Transformer backbone with Feature Pyramid Network (FPN) and UNet-style decoder, enhanced with Convolutional Block Attention Module (CBAM) for improved feature representation. The model employs a dual-head architecture for joint optimization of detection and segmentation tasks, utilizing uncertainty-weighted multi-task learning. Extensive experiments on the FantasyIDiap dataset demonstrate superior performance with 84.31\% accuracy, 90.78\% AUC for classification, and 57.24\% mean Dice score for localization. The proposed method achieves an F1-score of 88.61\% for binary classification while maintaining computational efficiency suitable for real-world deployment through FastAPI implementation. Our comprehensive evaluation includes ablation studies, cross-device generalization analysis, and detailed performance assessment across 10 languages and 3 acquisition devices.

</details>


### [281] [Membership Inference Test: Auditing Training Data in Object Classification Models](https://arxiv.org/abs/2601.12929)
*Gonzalo Mancera,Daniel DeAlcala,Aythami Morales,Ruben Tolosana,Julian Fierrez*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出针对目标识别领域的成员推断测试（MINT）架构，通过卷积层建模训练过程中的激活模式，在三个公开数据库（共17.4万+图像）上实现70-80%的精度，并分析影响MINT模块的因素。


<details>
  <summary>Details</summary>
Motivation: 研究成员推断测试（MINT）在目标识别领域的性能，旨在确定给定数据是否在训练阶段被使用。目标识别领域需要专门优化的MINT架构来处理该领域的复杂性。

Method: 提出专门针对目标识别领域的MINT架构，利用卷积层捕获和建模训练过程中的激活模式。实验包括目标检测模型、嵌入提取器和MINT模块，在三个公开数据库上进行测试。

Result: 能够识别用于测试和训练的数据，精度在70-80%之间，具体取决于选择输入MINT模块的检测模块层深度。分析了影响MINT模块的因素。

Conclusion: 提出的专门MINT架构在目标识别领域有效，能够以较高精度进行成员推断，并提供了更透明的训练过程分析。

Abstract: In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.

</details>


### [282] [QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning](https://arxiv.org/abs/2601.12936)
*Tianran Ouyang,Xingping Dong,Jing Zhang,Mang Ye,Jun Chen,Bo Du*

Main category: cs.CV

Relevance: 45.0

TL;DR: QASA提出了一种质量引导的K自适应槽注意力方法，通过解耦槽选择与重建、引入无监督槽质量度量、设计质量引导的槽选择方案，解决了现有K自适应方法中槽绑定质量差和优化目标冲突的问题。


<details>
  <summary>Details</summary>
Motivation: 现有K自适应槽注意力方法存在两个主要问题：1) 没有显式约束槽绑定质量，导致低质量槽引起特征归属模糊；2) 在重建目标中添加槽数量惩罚会创建冲突的优化目标（减少活跃槽数量 vs 保持重建保真度）。因此，现有方法显著落后于强K固定基线。

Method: 1) 解耦槽选择与重建，消除两个目标间的相互约束；2) 提出无监督槽质量度量来评估每个槽的质量，为细粒度槽-对象绑定提供原则性信号；3) 基于该度量设计质量引导的槽选择方案，动态选择高质量槽子集，输入新设计的门控解码器进行训练重建；4) 推理时，槽注意力上的token-wise竞争产生K自适应结果。

Result: QASA在真实和合成数据集上显著优于现有K自适应方法。在真实世界数据集上，QASA甚至超越了K固定方法。

Conclusion: QASA通过质量引导的K自适应槽注意力方法，有效解决了现有方法的局限性，在槽绑定质量和动态槽数量适应方面取得了显著改进，为无监督对象中心学习提供了更优的解决方案。

Abstract: Slot Attention, an approach that binds different objects in a scene to a set of "slots", has become a leading method in unsupervised object-centric learning. Most methods assume a fixed slot count K, and to better accommodate the dynamic nature of object cardinality, a few works have explored K-adaptive variants. However, existing K-adaptive methods still suffer from two limitations. First, they do not explicitly constrain slot-binding quality, so low-quality slots lead to ambiguous feature attribution. Second, adding a slot-count penalty to the reconstruction objective creates conflicting optimization goals between reducing the number of active slots and maintaining reconstruction fidelity. As a result, they still lag significantly behind strong K-fixed baselines. To address these challenges, we propose Quality-Guided K-Adaptive Slot Attention (QASA). First, we decouple slot selection from reconstruction, eliminating the mutual constraints between the two objectives. Then, we propose an unsupervised Slot-Quality metric to assess per-slot quality, providing a principled signal for fine-grained slot--object binding. Based on this metric, we design a Quality-Guided Slot Selection scheme that dynamically selects a subset of high-quality slots and feeds them into our newly designed gated decoder for reconstruction during training. At inference, token-wise competition on slot attention yields a K-adaptive outcome. Experiments show that QASA substantially outperforms existing K-adaptive methods on both real and synthetic datasets. Moreover, on real-world datasets QASA surpasses K-fixed methods.

</details>


### [283] [Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers](https://arxiv.org/abs/2601.12981)
*Sulaiman Khan,Md. Rafiul Biswas,Zubair Shah*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出基于表格Transformer（TabTrans）的早期2型糖尿病风险预测方法，利用纵向患者数据和骨相关表格数据，在卡塔尔生物银行队列上验证，性能优于传统机器学习和生成式AI模型。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉疾病进展中的复杂长期依赖关系，需要更先进的模型来分析纵向医疗表格数据，以改善2型糖尿病的早期预测。

Method: 使用表格Transformer（TabTrans）架构处理纵向患者健康记录和骨相关表格数据，结合SMOTE和SMOTE-ENN处理类别不平衡，并与传统ML及生成式AI模型（Claude 3.5 Sonnet、GPT-4、Gemini Pro）进行对比。

Result: TabTrans模型在T2DM预测中达到ROC AUC ≥ 79.7%，优于生成式AI和传统ML方法。特征解释分析识别出内脏脂肪组织质量/体积、骨密度、骨矿物质含量等关键风险指标。

Conclusion: TabTrans在处理复杂医疗表格数据方面具有显著潜力，为卡塔尔人群的主动T2DM管理和个性化临床干预提供了有力工具。

Abstract: This study introduces a novel approach for early Type 2 Diabetes Mellitus (T2DM) risk prediction using a tabular transformer (TabTrans) architecture to analyze longitudinal patient data. By processing patients` longitudinal health records and bone-related tabular data, our model captures complex, long-range dependencies in disease progression that conventional methods often overlook. We validated our TabTrans model on a retrospective Qatar BioBank (QBB) cohort of 1,382 subjects, comprising 725 men (146 diabetic, 579 healthy) and 657 women (133 diabetic, 524 healthy). The study integrated electronic health records (EHR) with dual-energy X-ray absorptiometry (DXA) data. To address class imbalance, we employed SMOTE and SMOTE-ENN resampling techniques. The proposed model`s performance is evaluated against conventional machine learning (ML) and generative AI models, including Claude 3.5 Sonnet (Anthropic`s constitutional AI), GPT-4 (OpenAI`s generative pre-trained transformer), and Gemini Pro (Google`s multimodal language model). Our TabTrans model demonstrated superior predictive performance, achieving ROC AUC $\geq$ 79.7 % for T2DM prediction compared to both generative AI models and conventional ML approaches. Feature interpretation analysis identified key risk indicators, with visceral adipose tissue (VAT) mass and volume, ward bone mineral density (BMD) and bone mineral content (BMC), T and Z-scores, and L1-L4 scores emerging as the most important predictors associated with diabetes development in Qatari adults. These findings demonstrate the significant potential of TabTrans for analyzing complex tabular healthcare data, providing a powerful tool for proactive T2DM management and personalized clinical interventions in the Qatari population.
  Index Terms: tabular transformers, multimodal data, DXA data, diabetes, T2DM, feature interpretation, tabular data

</details>


### [284] [Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations](https://arxiv.org/abs/2601.13371)
*Junyi Zhang,Yiming Wang,Yunhong Lu,Qichao Wang,Wenzhe Qian,Xiaoyin Xu,David Gu,Min Zhang*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出Spherical Geometry Representation和Spherical Geometry Diffusion方法，通过将3D面部几何约束到球形流形上，实现高质量文本到3D面部生成


<details>
  <summary>Details</summary>
Motivation: 文本到3D面部生成面临几何质量差的挑战，主要原因是3D空间中顶点分布复杂不规则，导致连接性差和几何不理想。需要简化底层几何结构。

Method: 1) 提出球形几何表示：将几何信号锚定到均匀球形坐标，保证规则点分布，便于网格重建；2) 球形几何扩散：基于2D映射的条件扩散框架，联合建模几何和纹理，几何显式条件纹理合成

Result: 在文本到3D生成、面部重建和基于文本的3D编辑等任务中表现优异，在几何质量、文本保真度和推理效率方面显著优于现有方法

Conclusion: 通过将3D面部几何约束到球形流形并利用2D生成模型，实现了高质量、可控的文本到3D面部生成

Abstract: A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.

</details>


### [285] [Leveraging Transformer Decoder for Automotive Radar Object Detection](https://arxiv.org/abs/2601.13386)
*Changxu Zhang,Zhaoze Wang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出基于Transformer的3D雷达目标检测架构，使用Transformer解码器作为预测头，直接从雷达特征回归3D边界框和类别分数，无需密集候选框生成和启发式后处理。


<details>
  <summary>Details</summary>
Motivation: 传统雷达目标检测方法通常依赖密集候选框生成和复杂的后处理（如NMS调优），这些方法计算成本高且需要大量启发式调整。需要一种更简洁、端到端的检测框架来建模雷达数据的时空相关性。

Method: 1) 使用Transformer解码器作为预测头直接回归3D边界框和类别分数；2) 提出金字塔令牌融合(PTF)模块，将多尺度雷达特征金字塔转换为统一的尺度感知令牌序列；3) 将检测建模为集合预测问题，使用可学习对象查询和位置编码；4) 建模长程时空相关性和跨特征交互。

Result: 在RADDet数据集上评估，相比最先进的仅使用雷达的基线方法取得了显著改进。

Conclusion: 提出的Transformer-based架构为3D雷达目标检测提供了一种简洁有效的解决方案，消除了传统方法中的密集候选框生成和启发式后处理需求，通过建模时空相关性提升了检测性能。

Abstract: In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.

</details>


### [286] [DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis](https://arxiv.org/abs/2601.13551)
*Feng Ding,Wenhui Yi,Xinan He,Mengyao Xiao,Jianfeng Xu,Jianqiang Du*

Main category: cs.CV

Relevance: 45.0

TL;DR: DiffFace-Edit数据集包含200多万张AI生成的面部图像，专注于细粒度区域编辑（如眼睛、鼻子），并首次研究拼接攻击对检测器的影响。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成的面部数据集缺乏细粒度区域编辑的样本，且没有研究真实与操纵样本之间的拼接攻击对检测器的实际影响，这些被称为检测器规避样本。

Method: 构建DiffFace-Edit数据集，包含200多万张AI生成的假图像，涵盖8个面部区域的编辑（单区域和多区域组合），并进行跨域评估结合IMDL方法。

Result: 创建了大规模细粒度编辑面部数据集，分析了检测器规避样本对检测模型的影响，提供了全面的数据集分析和评估框架。

Conclusion: DiffFace-Edit填补了细粒度区域操纵数据集的空白，为研究检测器规避攻击提供了重要资源，有助于提升AI生成面部检测的鲁棒性。

Abstract: Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit.

</details>


### [287] [Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation](https://arxiv.org/abs/2601.13565)
*Yu Qin,Shimeng Fan,Fan Yang,Zixuan Xue,Zijie Mai,Wenrui Chen,Kailun Yang,Zhiyong Li*

Main category: cs.CV

Relevance: 45.0

TL;DR: FiCoP提出了一种细粒度对应姿态估计框架，通过从全局匹配转向空间约束的patch级对应，解决开放词汇6D物体姿态估计中的背景干扰问题。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇6D物体姿态估计方法依赖无约束的全局匹配策略，在开放世界场景中容易将目标特征与背景干扰混淆，导致姿态估计性能下降。需要一种能过滤无关噪声、实现细粒度匹配的方法。

Method: 1) 物体中心解耦预处理：隔离语义目标与环境噪声；2) 跨视角全局感知模块：融合双视角特征，通过显式上下文推理建立结构共识；3) Patch相关性预测器：生成精确的块级关联图作为空间滤波器，实现噪声鲁棒的细粒度匹配。

Result: 在REAL275和Toyota-Light数据集上，FiCoP相比最先进方法分别提高了8.0%和6.1%的平均召回率，展示了在复杂开放世界环境中的鲁棒泛化能力。

Conclusion: FiCoP通过patch级对应和空间约束匹配，有效解决了开放词汇6D姿态估计中的背景干扰问题，为机器人在复杂开放世界环境中的感知提供了更鲁棒的解决方案。

Abstract: Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP.

</details>


### [288] [VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement](https://arxiv.org/abs/2601.13664)
*Tiancheng Fang,Bowen Pan,Lingxi Chen,Jiangjing Lyu,Chengfei Lyu,Chaoyue Niu,Fan Wu*

Main category: cs.CV

Relevance: 45.0

TL;DR: VIAFormer是一个用于多视角条件体素细化的体素-图像对齐Transformer模型，通过图像索引、校正流目标和混合流Transformer实现噪声体素修复。


<details>
  <summary>Details</summary>
Motivation: 解决从视觉基础模型获取的体素形状中存在的合成损坏和真实伪影问题，为现实世界3D创建管道提供实用可靠的桥梁。

Method: 1) 图像索引：为2D图像token提供显式3D空间基础；2) 校正流目标：学习直接的体素细化轨迹；3) 混合流Transformer：实现鲁棒的跨模态融合。

Result: 在纠正严重合成损坏和真实伪影方面建立了新的最先进水平，并在现实世界3D创建管道中展示了实用性。

Conclusion: VIAFormer为基于体素的方法在大模型、大数据浪潮中蓬勃发展铺平了道路。

Abstract: We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.

</details>


### [289] [DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes](https://arxiv.org/abs/2601.13839)
*Aisha Al-Mohannadi,Ayisha Firoz,Yin Yang,Muhammad Imran,Ferda Ofli*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出了DisasterVQA基准数据集，用于评估视觉问答模型在灾害响应场景中的感知和推理能力，包含1,395张真实灾害图像和4,405个专家标注的问答对。


<details>
  <summary>Details</summary>
Motivation: 社交媒体图像在灾害响应中提供低延迟的态势信息，但现有视觉问答模型在复杂、安全关键的灾害推理任务中的适用性尚不明确。需要专门针对灾害响应场景的评估基准。

Method: 构建了基于人道主义框架（FEMA ESF和OCHA MIRA）的DisasterVQA数据集，包含洪水、野火、地震等多种灾害的真实图像，设计了二元、多项选择和开放式问题，涵盖态势感知和操作决策任务。

Result: 评估了7个最先进的视觉语言模型，发现模型在二元问题上表现良好，但在细粒度定量推理、物体计数和上下文敏感解释方面存在困难，特别是在代表性不足的灾害场景中。

Conclusion: DisasterVQA为灾害响应提供了具有挑战性和实用性的基准，可指导开发更鲁棒、操作意义更强的视觉语言模型。数据集已公开可用。

Abstract: Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.

</details>


### [290] [OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3](https://arxiv.org/abs/2601.13895)
*Xu Zhang,Danyang Li,Yingjie Xia,Xiaohang Dong,Hualong Yu,Jianye Wang,Qicheng Li*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出了OmniOVCD框架，利用SAM 3的解耦输出头实现开放词汇变化检测，通过协同融合到实例解耦策略在四个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有免训练的开放词汇变化检测方法通常结合CLIP和DINO等不同模型，导致特征匹配问题和系统不稳定。SAM 3集成了分割和识别能力，为OVCD任务提供了新可能。

Method: 提出OmniOVCD框架，利用SAM 3的解耦输出头设计协同融合到实例解耦策略：首先融合SAM 3的语义、实例和存在性输出构建土地覆盖掩码，然后分解为单个实例掩码进行变化比较。

Result: 在四个公共基准测试（LEVIR-CD、WHU-CD、S2Looking、SECOND）上达到SOTA性能，IoU分数分别为67.2、66.5、24.5和27.1（类别平均），超越所有先前方法。

Conclusion: OmniOVCD通过利用SAM 3的集成能力解决了现有方法的多模型融合问题，实现了准确的变化检测，同时保持了类别识别的高精度和实例级一致性。

Abstract: Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.

</details>


### [291] [Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution](https://arxiv.org/abs/2601.14030)
*Samuel W. Remedios,Zhangxing Bian,Shuwen Wei,Aaron Carass,Jerry L. Prince,Blake E. Dewey*

Main category: cs.CV

Relevance: 45.0

TL;DR: 该论文将扩散模型从单图像逆问题求解扩展到多图像超分辨率MRI，通过可分离梯度分解实现多测量融合，无需修改扩散模型或增加计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型主要解决单图像逆问题，但医学成像（如MRI）通常需要融合多个互补的低分辨率测量。现有方法无法有效处理多图像超分辨率问题，限制了扩散模型在真实医学成像场景中的应用。

Method: 提出将DPS似然校正扩展到多图像超分辨率，证明其梯度可精确分解为各独立测量的和。基于此推导了MISR版本的DPS、DMAP、DPPS及扩散PnP/ADMM方法，无需构建联合算子或修改扩散模型。

Result: 在4×/8×/16×各向异性退化条件下显著优于单图像超分辨率，实现各向异性MRI体数据的SOTA超分辨率，能从常规2D多切片采集重建近各向同性解剖结构。

Conclusion: 成功将扩散模型扩展到多图像MRI超分辨率，为医学成像提供高效解决方案，特别适用于从常规2D采集重建高质量3D体积数据。

Abstract: Diffusion models are the current state-of-the-art for solving inverse problems in imaging. Their impressive generative capability allows them to approximate sampling from a prior distribution, which alongside a known likelihood function permits posterior sampling without retraining the model. While recent methods have made strides in advancing the accuracy of posterior sampling, the majority focuses on single-image inverse problems. However, for modalities such as magnetic resonance imaging (MRI), it is common to acquire multiple complementary measurements, each low-resolution along a different axis. In this work, we generalize common diffusion-based inverse single-image problem solvers for multi-image super-resolution (MISR) MRI. We show that the DPS likelihood correction allows an exactly-separable gradient decomposition across independently acquired measurements, enabling MISR without constructing a joint operator, modifying the diffusion model, or increasing network function evaluations. We derive MISR versions of DPS, DMAP, DPPS, and diffusion-based PnP/ADMM, and demonstrate substantial gains over SISR across $4\times/8\times/16\times$ anisotropic degradations. Our results achieve state-of-the-art super-resolution of anisotropic MRI volumes and, critically, enable reconstruction of near-isotropic anatomy from routine 2D multi-slice acquisitions, which are otherwise highly degraded in orthogonal views.

</details>


### [292] [DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning](https://arxiv.org/abs/2601.14084)
*Abdurrahim Yilmaz,Ozan Erdem,Ece Gokyayla,Ayda Acar,Burc Bugra Dagtas,Dilara Ilhan Erdil,Gulsum Gencoglan,Burak Temelkuran*

Main category: cs.CV

Relevance: 45.0

TL;DR: DermaBench是一个皮肤科视觉问答基准，包含656张临床图像和约14,474个专家标注的VQA注释，用于评估视觉语言模型在皮肤病学中的综合理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉语言模型的评估主要局限于图像分类任务（如病变识别），无法全面评估模型的多模态理解、语言基础和临床推理能力。需要专门的VQA基准来评估模型对皮肤科图像的细粒度形态学理解和临床描述生成能力。

Method: 基于Diverse Dermatology Images (DDI)数据集构建，包含656张来自570名不同患者的临床图像，涵盖Fitzpatrick皮肤类型I-VI。采用分层标注方案，包含22个主要问题类型（单选、多选、开放式），由皮肤科专家标注诊断、解剖部位、病变形态、分布、表面特征、颜色和图像质量等信息。

Result: 创建了包含约14,474个VQA风格注释的DermaBench基准，作为元数据数据集在Harvard Dataverse公开发布，尊重上游许可协议。

Conclusion: DermaBench填补了皮肤科视觉语言模型评估的空白，为评估模型在皮肤病学中的视觉理解、语言基础和临床推理能力提供了标准化基准。

Abstract: Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.

</details>


### [293] [Two-Stream temporal transformer for video action classification](https://arxiv.org/abs/2601.14086)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出了一种新的双流Transformer视频分类器，结合内容流和光流来提取时空信息，在三个知名人类活动视频数据集上取得了优秀的分类结果。


<details>
  <summary>Details</summary>
Motivation: 运动表示在视频理解中扮演重要角色，具有动作识别、机器人导航等多种应用。Transformer网络通过自注意力机制在许多应用中证明了其有效性，但如何有效结合时空信息进行视频分类仍需探索。

Method: 提出双流Transformer视频分类器：1) 内容流提取空间信息；2) 光流流提取运动信息。模型在联合光流和时序帧域中识别自注意力特征，并通过Transformer编码器机制表示它们之间的关系。

Result: 在三个知名的人类活动视频数据集上取得了优秀的分类结果，证明了该方法的有效性。

Conclusion: 提出的双流Transformer视频分类器能够有效提取时空信息，在视频动作识别任务中表现优异，为视频理解提供了新的解决方案。

Abstract: Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities.

</details>


### [294] [S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection](https://arxiv.org/abs/2601.12313)
*Xiangyu Hu,Yicheng Hong,Hongchuang Zheng,Wenjun Zeng,Bingyao Liu*

Main category: cs.CV

Relevance: 40.0

TL;DR: S²F-Net：一种基于频谱差异的跨模型生成内容检测框架，通过可学习频率注意力模块增强判别性频带，在17类生成模型上达到90.49%的检测准确率


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展对具有强泛化能力的检测方案提出了迫切需求。现有检测方法通常过度拟合特定源模型，在面对未见过的生成架构时性能显著下降。

Method: 提出跨模型检测框架S²F-Net，核心是探索和利用真实与合成纹理之间的固有频谱差异。引入可学习频率注意力模块，通过协同空间纹理分析和频谱依赖关系，自适应地加权和增强判别性频带。

Result: 在包含17类生成模型的AIGCDetectBenchmark上，S²F-Net实现了90.49%的检测准确率，在跨域检测场景中显著优于各种现有基线方法。

Conclusion: 通过关注上采样操作在频域留下的独特指纹，S²F-Net从根本上改善了模型的泛化性能，为生成内容检测提供了有效的跨模型解决方案。

Abstract: The rapid development of generative models has imposed an urgent demand for detection schemes with strong generalization capabilities. However, existing detection methods generally suffer from overfitting to specific source models, leading to significant performance degradation when confronted with unseen generative architectures. To address these challenges, this paper proposes a cross-model detection framework called S 2 F-Net, whose core lies in exploring and leveraging the inherent spectral discrepancies between real and synthetic textures. Considering that upsampling operations leave unique and distinguishable frequency fingerprints in both texture-poor and texture-rich regions, we focus our research on the detection of frequency-domain artifacts, aiming to fundamentally improve the generalization performance of the model. Specifically, we introduce a learnable frequency attention module that adaptively weights and enhances discriminative frequency bands by synergizing spatial texture analysis and spectral dependencies.On the AIGCDetectBenchmark, which includes 17 categories of generative models, S 2 F-Net achieves a detection accuracy of 90.49%, significantly outperforming various existing baseline methods in cross-domain detection scenarios.

</details>


### [295] [EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation](https://arxiv.org/abs/2601.12326)
*Jing Zhang,Bingjie Fan*

Main category: cs.CV

Relevance: 40.0

TL;DR: EmoKGEdit：基于多模态情感关联知识图谱的训练免费图像情感编辑框架，通过解耦情感与内容表示，实现精确且结构保持的情感编辑。


<details>
  <summary>Details</summary>
Motivation: 现有图像情感编辑方法难以从潜在内容表示中解耦情感线索，导致情感表达弱且视觉结构扭曲。需要一种能精确编辑情感同时保持视觉结构的方法。

Method: 1. 构建多模态情感关联知识图谱（MSA-KG），解耦对象、场景、属性、视觉线索和情感之间的复杂关系；2. MSA-KG编码对象-属性-情感因果链，作为外部知识支持思维链推理；3. 设计解耦结构-情感编辑模块，在潜在空间中分离情感属性和布局特征。

Result: 大量实验表明，EmoKGEdit在情感保真度和内容保持方面表现优异，优于现有最先进方法。

Conclusion: EmoKGEdit通过知识图谱驱动的解耦方法，实现了精确且结构保持的图像情感编辑，解决了现有方法的情感表达弱和结构扭曲问题。

Abstract: Existing image emotion editing methods struggle to disentangle emotional cues from latent content representations, often yielding weak emotional expression and distorted visual structures. To bridge this gap, we propose EmoKGEdit, a novel training-free framework for precise and structure-preserving image emotion editing. Specifically, we construct a Multimodal Sentiment Association Knowledge Graph (MSA-KG) to disentangle the intricate relationships among objects, scenes, attributes, visual clues and emotion. MSA-KG explicitly encode the causal chain among object-attribute-emotion, and as external knowledge to support chain of thought reasoning, guiding the multimodal large model to infer plausible emotion-related visual cues and generate coherent instructions. In addition, based on MSA-KG, we design a disentangled structure-emotion editing module that explicitly separates emotional attributes from layout features within the latent space, which ensures that the target emotion is effectively injected while strictly maintaining visual spatial coherence. Extensive experiments demonstrate that EmoKGEdit achieves excellent performance in both emotion fidelity and content preservation, and outperforms the state-of-the-art methods.

</details>


### [296] [DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data](https://arxiv.org/abs/2601.12366)
*Jiafei Zhang,Songliang Cao,Binghui Xu,Yanan Li,Weiwei Jia,Tingting Wu,Hao Lu,Weijuan Hu,Zhiguo Han*

Main category: cs.CV

Relevance: 40.0

TL;DR: DepthCropSeg++是一个用于作物分割的基础模型，能够分割开放田间环境下的不同作物物种。该模型通过大规模数据集、改进的ViT-Adapter架构和两阶段自训练流程，在多种作物类型和环境条件下实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前作物分割模型由于像素级标注成本高昂，通常只能从有限数据中学习，仅在特定作物类型或受控环境下表现良好。作者希望开发一个能够跨物种、跨场景泛化的作物分割基础模型，以支持植物表型分析、密度估计和杂草控制等下游农业任务。

Method: 1) 扩展了跨物种和跨场景的作物分割数据集，包含28,406张图像，涵盖30+物种和15种环境条件；2) 基于最先进的语义分割架构ViT-Adapter，通过动态上采样增强细节感知；3) 采用两阶段自训练流程进行模型训练。

Result: 在综合测试集上达到93.11% mIoU，显著优于监督基线（+0.36%）和通用视觉基础模型如SAM（+48.57%）。在夜间环境（86.90% mIoU）、高密度冠层（90.09% mIoU）和未见作物品种（90.09% mIoU）等挑战性场景中表现优异。

Conclusion: DepthCropSeg++为作物分割设立了新的技术标杆，展示了基础模型在农业视觉任务中的潜力，特别是在跨物种和跨场景泛化能力方面。

Abstract: DepthCropSeg++: a foundation model for crop segmentation, capable of segmenting different crop species under open in-field environment. Crop segmentation is a fundamental task for modern agriculture, which closely relates to many downstream tasks such as plant phenotyping, density estimation, and weed control. In the era of foundation models, a number of generic large language and vision models have been developed. These models have demonstrated remarkable real world generalization due to significant model capacity and largescale datasets. However, current crop segmentation models mostly learn from limited data due to expensive pixel-level labelling cost, often performing well only under specific crop types or controlled environment. In this work, we follow the vein of our previous work DepthCropSeg, an almost unsupervised approach to crop segmentation, to scale up a cross-species and crossscene crop segmentation dataset, with 28,406 images across 30+ species and 15 environmental conditions. We also build upon a state-of-the-art semantic segmentation architecture ViT-Adapter architecture, enhance it with dynamic upsampling for improved detail awareness, and train the model with a two-stage selftraining pipeline. To systematically validate model performance, we conduct comprehensive experiments to justify the effectiveness and generalization capabilities across multiple crop datasets. Results demonstrate that DepthCropSeg++ achieves 93.11% mIoU on a comprehensive testing set, outperforming both supervised baselines and general-purpose vision foundation models like Segmentation Anything Model (SAM) by significant margins (+0.36% and +48.57% respectively). The model particularly excels in challenging scenarios including night-time environment (86.90% mIoU), high-density canopies (90.09% mIoU), and unseen crop varieties (90.09% mIoU), indicating a new state of the art for crop segmentation.

</details>


### [297] [Combating Noisy Labels through Fostering Self- and Neighbor-Consistency](https://arxiv.org/abs/2601.12795)
*Zeren Sun,Yazhou Yao,Tongliang Liu,Zechao Li,Fumin Shen,Jinhui Tang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出Jo-SNC方法，通过联合样本选择和模型正则化处理标签噪声，使用Jensen-Shannon散度评估样本清洁度，结合自适应阈值和三元一致性正则化提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中标签噪声普遍存在，深度网络容易记忆噪声样本。现有方法主要关注识别清洁数据，但忽视了不同小批量中标签噪声的不平衡性，以及对分布外噪声数据的关注不足。

Method: 提出Jo-SNC方法：1) 使用Jensen-Shannon散度结合样本最近邻评估样本清洁度；2) 设计自适应数据驱动的阈值方案调整每类选择阈值；3) 对清洁样本采用常规训练，对分布内和分布外噪声样本分别采用部分标签学习和负学习；4) 提出三元一致性正则化促进自预测一致性、邻预测一致性和特征一致性。

Result: 在多个基准数据集上的广泛实验和消融研究表明，该方法相比现有最先进方法具有有效性和优越性。

Conclusion: Jo-SNC方法通过联合样本选择和模型正则化，有效处理标签噪声问题，特别是在处理不平衡噪声分布和分布外噪声方面表现出色。

Abstract: Label noise is pervasive in various real-world scenarios, posing challenges in supervised deep learning. Deep networks are vulnerable to such label-corrupted samples due to the memorization effect. One major stream of previous methods concentrates on identifying clean data for training. However, these methods often neglect imbalances in label noise across different mini-batches and devote insufficient attention to out-of-distribution noisy data. To this end, we propose a noise-robust method named Jo-SNC (\textbf{Jo}int sample selection and model regularization based on \textbf{S}elf- and \textbf{N}eighbor-\textbf{C}onsistency). Specifically, we propose to employ the Jensen-Shannon divergence to measure the ``likelihood'' of a sample being clean or out-of-distribution. This process factors in the nearest neighbors of each sample to reinforce the reliability of clean sample identification. We design a self-adaptive, data-driven thresholding scheme to adjust per-class selection thresholds. While clean samples undergo conventional training, detected in-distribution and out-of-distribution noisy samples are trained following partial label learning and negative learning, respectively. Finally, we advance the model performance further by proposing a triplet consistency regularization that promotes self-prediction consistency, neighbor-prediction consistency, and feature consistency. Extensive experiments on various benchmark datasets and comprehensive ablation studies demonstrate the effectiveness and superiority of our approach over existing state-of-the-art methods.

</details>


### [298] [ICo3D: An Interactive Conversational 3D Virtual Human](https://arxiv.org/abs/2601.13148)
*Richard Shaw,Youngkyoon Jang,Athanasios Papaioannou,Arthur Moreau,Helisa Dhamo,Zhensong Zhang,Eduardo Pérez-Pellitero*

Main category: cs.CV

Relevance: 40.0

TL;DR: ICo3D是一种生成交互式、对话式、逼真3D虚拟人的方法，结合了多视角捕捉、可动画的3D面部和身体模型（使用高斯溅射渲染），并集成了LLM进行对话，支持实时用户交互。


<details>
  <summary>Details</summary>
Motivation: 创建能够实时交互、对话且逼真的3D虚拟人，适用于游戏、虚拟助手、个性化教育等多个领域，提供沉浸式体验。

Method: 基于多视角捕捉创建可动画的3D面部模型和动态3D身体模型，使用高斯溅射渲染；集成LLM进行对话；音频语音驱动面部动画实现精确同步；改进动态高斯模型（SWinGS++用于身体重建，HeadGaS++用于面部重建）并解决面部与身体模型融合问题。

Result: 开发了完整的ICo3D系统，展示了实时与3D虚拟人对话的多个用例，实现了逼真的虚拟人体验，支持口头和书面形式的交互。

Conclusion: ICo3D提供了一个完全集成的虚拟人体验，在沉浸式环境中支持口头和书面交互，适用于广泛的应用领域。

Abstract: This work presents Interactive Conversational 3D Virtual Human (ICo3D), a method for generating an interactive, conversational, and photorealistic 3D human avatar. Based on multi-view captures of a subject, we create an animatable 3D face model and a dynamic 3D body model, both rendered by splatting Gaussian primitives. Once merged together, they represent a lifelike virtual human avatar suitable for real-time user interactions. We equip our avatar with an LLM for conversational ability. During conversation, the audio speech of the avatar is used as a driving signal to animate the face model, enabling precise synchronization. We describe improvements to our dynamic Gaussian models that enhance photorealism: SWinGS++ for body reconstruction and HeadGaS++ for face reconstruction, and provide as well a solution to merge the separate face and body models without artifacts. We also present a demo of the complete system, showcasing several use cases of real-time conversation with the 3D avatar. Our approach offers a fully integrated virtual avatar experience, supporting both oral and written form interactions in immersive environments. ICo3D is applicable to a wide range of fields, including gaming, virtual assistance, and personalized education, among others. Project page: https://ico3d.github.io/

</details>


### [299] [FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation](https://arxiv.org/abs/2601.13837)
*Xinya Ji,Sebastian Weiss,Manuel Kansy,Jacek Naruniec,Xun Cao,Barbara Solenthaler,Derek Bradley*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于3D高斯表示的前馈式头部化身生成方法，仅需少量输入图像即可实时生成高质量动态化身


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯头部化身建模方法依赖多视图捕捉或单目视频优化，推理时需要逐身份优化，限制了可扩展性和对新主体的适用性

Method: 1) 从输入图像直接学习逐像素高斯表示；2) 使用基于Transformer的编码器融合DINOv3和Stable Diffusion VAE特征；3) 引入轻量级MLP动态网络预测3D高斯形变；4) 利用预训练大重建模型的点云图进行几何监督

Result: 在渲染质量和推理效率上显著优于现有方法，支持实时动态化身动画

Conclusion: 该方法克服了现有方法的效率限制，实现了从少量图像高效生成高质量可动画头部化身

Abstract: Despite recent progress in 3D Gaussian-based head avatar modeling, efficiently generating high fidelity avatars remains a challenge. Current methods typically rely on extensive multi-view capture setups or monocular videos with per-identity optimization during inference, limiting their scalability and ease of use on unseen subjects. To overcome these efficiency drawbacks, we propose \OURS, a feed-forward method to generate high-quality Gaussian head avatars from only a few input images while supporting real-time animation. Our approach directly learns a per-pixel Gaussian representation from the input images, and aggregates multi-view information using a transformer-based encoder that fuses image features from both DINOv3 and Stable Diffusion VAE. For real-time animation, we extend the explicit Gaussian representations with per-Gaussian features and introduce a lightweight MLP-based dynamic network to predict 3D Gaussian deformations from expression codes. Furthermore, to enhance geometric smoothness of the 3D head, we employ point maps from a pre-trained large reconstruction model as geometry supervision. Experiments show that our approach significantly outperforms existing methods in both rendering quality and inference efficiency, while supporting real-time dynamic avatar animation.

</details>


### [300] [Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation](https://arxiv.org/abs/2601.14039)
*Wesam Moustafa,Hossam Elsafty,Helen Schneider,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种用于医学图像分割的通用弃权框架，通过选择性忽略噪声标签样本来提高分割模型的噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中标签噪声问题严重，现有方法对此研究不足。弃权机制在分类任务中已被证明有效，但在分割领域尚未验证。

Method: 提出模块化弃权框架，包含两个关键组件：1) 引导弃权行为的正则化项；2) 基于幂律的自适应调参算法。框架与三种损失函数集成，创建了GAC、SAC和ADS三种噪声鲁棒变体。

Result: 在CaDIS和DSAD医学数据集上的实验表明，该方法显著优于非弃权基线，特别是在高噪声水平下表现优异。

Conclusion: 使模型能够选择性忽略噪声样本是构建更可靠分割模型的强大且可泛化策略。

Abstract: Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation.

</details>


### [301] [Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study](https://arxiv.org/abs/2601.11612)
*Arnav S. Sonavane*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文研究了领域特定自监督预训练对农业病害分类的影响，发现SimCLR预训练比层次架构设计带来更大的性能提升，且这种提升是架构无关的。


<details>
  <summary>Details</summary>
Motivation: 研究在农业病害分类任务中，领域特定自监督预训练与层次视觉Transformer架构设计之间的权衡，为实践者提供优先级的指导。

Method: 使用HierarchicalViT（HVT）作为Swin风格的层次Transformer，在三个农业病害数据集上进行评估。比较了SimCLR自监督预训练与不同架构（Swin-Base、ViT-Base）的性能差异。

Result: SimCLR预训练仅用3000张未标记农业图像就能带来+4.57%的准确率提升，超过了层次架构设计带来的+3.70%增益。HVT-Base在参数数量相近的情况下比Swin-Base有+1.68%的改进。

Conclusion: 实践者应优先考虑领域数据收集而非架构选择，因为自监督预训练带来的性能提升是架构无关的，且能显著提高模型性能。

Abstract: We investigate the impact of domain-specific self-supervised pre-training on agricultural disease classification using hierarchical vision transformers. Our key finding is that SimCLR pre-training on just 3,000 unlabeled agricultural images provides a +4.57% accuracy improvement--exceeding the +3.70% gain from hierarchical architecture design. Critically, we show this SSL benefit is architecture-agnostic: applying the same pre-training to Swin-Base yields +4.08%, to ViT-Base +4.20%, confirming practitioners should prioritize domain data collection over architectural choices. Using HierarchicalViT (HVT), a Swin-style hierarchical transformer, we evaluate on three datasets: Cotton Leaf Disease (7 classes, 90.24%), PlantVillage (38 classes, 96.3%), and PlantDoc (27 classes, 87.1%). At matched parameter counts, HVT-Base (78M) achieves 88.91% vs. Swin-Base (88M) at 87.23%, a +1.68% improvement. For deployment reliability, we report calibration analysis showing HVT achieves 3.56% ECE (1.52% after temperature scaling). Code: https://github.com/w2sg-arnav/HierarchicalViT

</details>


### [302] [Zeros can be Informative: Masked Binary U-Net for Image Segmentation on Tensor Cores](https://arxiv.org/abs/2601.11660)
*Chunshu Wu,Ruibing Song,Sushant Kondguli,Tong Geng,Ang Li*

Main category: cs.CV

Relevance: 35.0

TL;DR: MBU-Net：一种通过成本感知掩码策略实现掩码二值化U-Net，结合GPU执行框架，在保持接近全精度准确率的同时，实现实时图像分割的加速和能耗降低。


<details>
  <summary>Details</summary>
Motivation: 实时图像分割在AR/VR、机器人、无人机和自动驾驶系统中至关重要，但现有方法在资源受限的边缘设备上难以同时满足准确率、延迟和能耗要求。U-Net虽然比大型Transformer模型更高效，但在高分辨率输入下仍难以实现实时性能。极端量化（特别是二值网络）具有硬件友好性，但面临严重准确率下降和缺乏端到端GPU实现的问题。

Method: 提出掩码二值化U-Net（MBU-Net），基于两个经验观察：1）显式零状态至关重要，通过零掩码训练二值U-Net权重会产生显著稀疏性；2）量化敏感性在层间是均匀的。采用成本感知掩码策略，优先在准确率-成本比最高的位置进行掩码，平衡准确率与近二值化效率。开发GPU执行框架，通过减法位编码方案将MBU-Net映射到Tensor Core，利用原生二值Tensor Core BMMA指令实现高效计算。

Result: 在3个分割基准测试中，MBU-Net达到接近全精度准确率（平均仅下降3%），同时相比16位浮点U-Net实现2.04倍加速和3.54倍能耗降低。

Conclusion: MBU-Net通过成本感知掩码策略和GPU优化框架，成功解决了二值网络在实时图像分割中的准确率下降和实现效率问题，为资源受限边缘设备上的高效分割提供了实用解决方案。

Abstract: Real-time image segmentation is a key enabler for AR/VR, robotics, drones, and autonomous systems, where tight accuracy, latency, and energy budgets must be met on resource-constrained edge devices. While U-Net offers a favorable balance of accuracy and efficiency compared to large transformer-based models, achieving real-time performance on high-resolution input remains challenging due to compute, memory, and power limits. Extreme quantization, particularly binary networks, is appealing for its hardware-friendly operations. However, two obstacles limit practicality: (1) severe accuracy degradation, and (2) a lack of end-to-end implementations that deliver efficiency on general-purpose GPUs.
  We make two empirical observations that guide our design. (1) An explicit zero state is essential: training with zero masking to binary U-Net weights yields noticeable sparsity. (2) Quantization sensitivity is uniform across layers. Motivated by these findings, we introduce Masked Binary U-Net (MBU-Net), obtained through a cost-aware masking strategy that prioritizes masking where it yields the highest accuracy-per-cost, reconciling accuracy with near-binary efficiency.
  To realize these gains in practice, we develop a GPU execution framework that maps MBU-Net to Tensor Cores via a subtractive bit-encoding scheme, efficiently implementing masked binary weights with binary activations. This design leverages native binary Tensor Core BMMA instructions, enabling high throughput and energy savings on widely available GPUs. Across 3 segmentation benchmarks, MBU-Net attains near full-precision accuracy (3% average drop) while delivering 2.04x speedup and 3.54x energy reductions over a 16-bit floating point U-Net.

</details>


### [303] [Generating metamers of human scene understanding](https://arxiv.org/abs/2601.11675)
*Ritik Raina,Abe Leite,Alexandros Graikos,Seoyoung Ahn,Dimitris Samaras,Gregory J. Zelinsky*

Main category: cs.CV

Relevance: 35.0

TL;DR: MetamerGen是一个潜在扩散模型，通过结合视觉外围的低分辨率"要点"信息和注视点的高分辨率信息，生成与人类场景表征对齐的图像，用于研究人类场景理解。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过结合外围低分辨率信息和注视点高分辨率信息来理解场景。为了研究这种场景理解机制，需要生成与人类潜在场景表征对齐的图像（即"同构体"）。

Method: 使用双流潜在扩散模型：结合DINOv2 tokens融合注视点的详细特征和外围降级的场景上下文特征。通过行为实验（相同/不同判断）评估生成图像与人类表征的对齐程度。

Result: MetamerGen能够生成与人类场景表征对齐的图像，当基于观看者自身注视区域生成时，高层次语义对齐最能预测同构性。发现了影响人类判断的多个视觉处理层次特征。

Conclusion: MetamerGen是理解人类场景理解的强大工具，揭示了视觉处理的多层次特征贡献。基于观看者注视区域的生成最能产生语义对齐的同构体。

Abstract: Human vision combines low-resolution "gist" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. "foveated") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a "same" or "different" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.

</details>


### [304] [SemAlign: Language Guided Semi-supervised Domain Generalization](https://arxiv.org/abs/2601.11724)
*Muditha Fernando,Kajhanan Kailainathan,Krishnakanth Nagaratnam,Isuranga Udaravi Bandara Senavirathne,Ranga Rodrigo*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出了一种新的半监督域泛化方法，通过将模型中间特征与视觉语言模型的特征空间对齐来提升域不变性，结合图像级增强和输出级正则化策略，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有SSDG方法过度关注伪标签精度，而忽视了训练过程中的最大数据利用率，这限制了性能提升潜力。作者认为需要同时考虑伪标签精度和数据利用效率。

Method: 1) 将模型中间特征与视觉语言模型(VLM)的语义丰富且泛化的特征空间对齐，以促进域不变性；2) 采用有效的图像级增强策略；3) 实施输出级正则化策略来减少过拟合。

Result: 在四个基准测试上与现有SSDG基线方法相比，该方法在定性和定量上都达到了最先进的性能。

Conclusion: 通过特征对齐、数据增强和正则化的组合策略，能够有效解决SSDG中的伪标签精度和数据利用率问题，实现更好的域泛化性能。

Abstract: Semi-supervised Domain Generalization (SSDG) addresses the challenge of generalizing to unseen target domains with limited labeled data. Existing SSDG methods highlight the importance of achieving high pseudo-labeling (PL) accuracy and preventing model overfitting as the main challenges in SSDG. In this light, we show that the SSDG literature's excessive focus on PL accuracy, without consideration for maximum data utilization during training, limits potential performance improvements. We propose a novel approach to the SSDG problem by aligning the intermediate features of our model with the semantically rich and generalized feature space of a Vision Language Model (VLM) in a way that promotes domain-invariance. The above approach is enhanced with effective image-level augmentation and output-level regularization strategies to improve data utilization and minimize overfitting. Extensive experimentation across four benchmarks against existing SSDG baselines suggests that our method achieves SOTA results both qualitatively and quantitatively. The code will be made publicly available.

</details>


### [305] [RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection](https://arxiv.org/abs/2601.11898)
*Yilmaz Korkmaz,Vishal M. Patel*

Main category: cs.CV

Relevance: 35.0

TL;DR: RemoteVAR是一个基于视觉自回归模型(VAR)的遥感变化检测框架，通过多分辨率双时相特征融合和专门的自回归训练策略，在标准基准测试中显著优于基于扩散和Transformer的基线方法。


<details>
  <summary>Details</summary>
Motivation: 遥感变化检测在环境监测和灾害评估中至关重要，但现有的视觉自回归模型(VARs)在像素级判别任务中存在可控性弱、密集预测性能不佳和曝光偏差等限制，需要专门的设计来解决这些问题。

Method: 提出RemoteVAR框架：1) 通过交叉注意力将自回归预测条件化到多分辨率融合的双时相特征上；2) 采用专门为变化图预测设计的自回归训练策略，以解决现有VAR模型的局限性。

Result: 在标准变化检测基准测试中，RemoteVAR相比基于扩散和Transformer的强基线方法，取得了持续且显著的改进，为遥感变化检测建立了具有竞争力的自回归替代方案。

Conclusion: RemoteVAR成功解决了VAR模型在像素级判别任务中的限制，展示了自回归模型在遥感变化检测任务中的潜力，为相关应用提供了新的技术方案。

Abstract: Remote sensing change detection aims to localize and characterize scene changes between two time points and is central to applications such as environmental monitoring and disaster assessment. Meanwhile, visual autoregressive models (VARs) have recently shown impressive image generation capability, but their adoption for pixel-level discriminative tasks remains limited due to weak controllability, suboptimal dense prediction performance and exposure bias. We introduce RemoteVAR, a new VAR-based change detection framework that addresses these limitations by conditioning autoregressive prediction on multi-resolution fused bi-temporal features via cross-attention, and by employing an autoregressive training strategy designed specifically for change map prediction. Extensive experiments on standard change detection benchmarks show that RemoteVAR delivers consistent and significant improvements over strong diffusion-based and transformer-based baselines, establishing a competitive autoregressive alternative for remote sensing change detection. Code will be available \href{https://github.com/yilmazkorkmaz1/RemoteVAR}{\underline{here}}.

</details>


### [306] [From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection](https://arxiv.org/abs/2601.11915)
*Chi Wang,Xinjue Hu,Boyu Wang,Ziwen He,Zhangjie Fu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一种用于人脸伪造检测的表示空间干预方法，通过将虚假相关性特征建模为低秩子空间并移除，从而提升模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 人脸伪造检测中的泛化问题是一个关键挑战。研究发现，从伪造无关信息到标签的"后门路径"会导致有偏学习，阻碍泛化。这些伪造无关信息被称为虚假相关性因素。现有方法主要关注识别具体的虚假相关性并设计相应解决方案，但由于虚假相关性来自不可观测的混杂因素，逐一识别和处理不切实际。

Method: 提出表示空间干预范式：将各种实例级虚假相关性统一建模为低秩子空间并进行干预。具体通过正交低秩投影将虚假相关性特征分解为低秩子空间，从原始表示中移除该子空间，并训练其正交补集来捕获伪造相关特征。低秩投影移除有效消除了虚假相关性因素。

Result: 仅使用0.43M可训练参数，该方法在多个基准测试中实现了最先进的性能，表现出优秀的鲁棒性和泛化能力。

Conclusion: 通过将虚假相关性统一建模为低秩子空间并进行干预，能够有效提升人脸伪造检测的泛化性能，避免了逐一处理具体虚假相关性的复杂性。

Abstract: The generalization problem remains a critical challenge in face forgery detection. Some researches have discovered that ``a backdoor path" in the representations from forgery-irrelevant information to labels induces biased learning, thereby hindering the generalization. In this paper, these forgery-irrelevant information are collectively termed spurious correlations factors. Previous methods predominantly focused on identifying concrete, specific spurious correlation and designing corresponding solutions to address them. However, spurious correlations arise from unobservable confounding factors, making it impractical to identify and address each one individually. To address this, we propose an intervention paradigm for representation space. Instead of tracking and blocking various instance-level spurious correlation one by one, we uniformly model them as a low-rank subspace and intervene in them. Specifically, we decompose spurious correlation features into a low-rank subspace via orthogonal low-rank projection, subsequently removing this subspace from the original representation and training its orthogonal complement to capture forgery-related features. This low-rank projection removal effectively eliminates spurious correlation factors, ensuring that classification decision is based on authentic forgery cues. With only 0.43M trainable parameters, our method achieves state-of-the-art performance across several benchmarks, demonstrating excellent robustness and generalization.

</details>


### [307] [SupScene: Learning Overlap-Aware Global Descriptor for Unconstrained SfM](https://arxiv.org/abs/2601.11930)
*Xulei Shi,Maoyu Wang,Yuning Peng,Guanbo Wang,Xin Wang,Qi Chen,Pengjie Tao*

Main category: cs.CV

Relevance: 35.0

TL;DR: SupScene提出了一种用于SfM图像检索的新方法，通过子图训练策略和DiVLAD聚合器学习更具几何匹配性的全局描述符，显著优于NetVLAD等现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的图像检索方法主要关注语义相似性，但在SfM应用中更需要关注几何匹配性。现有方法使用二元重叠/非重叠标签进行监督，无法捕捉几何关系的细微差别。

Method: 1) 提出子图训练策略，利用几何重叠关系的不同权重提供细粒度监督；2) 设计DiVLAD聚合器，利用ViT最后一层的多头注意力图；3) 引入可学习门控机制自适应融合语义线索和视觉特征。

Result: 在GL3D数据集上达到最先进性能，显著优于NetVLAD，同时仅引入少量可训练参数。训练策略在不同聚合技术上都带来一致提升。

Conclusion: SupScene通过细粒度监督和注意力引导的特征聚合，有效学习适用于SfM的几何感知全局描述符，为图像检索提供了新思路。

Abstract: Image retrieval is a critical step for alleviating the quadratic complexity of image matching in unconstrained Structure-from-Motion (SfM). However, in this context, image retrieval typically focuses more on the image pairs of geometric matchability than on those of semantic similarity, a nuance that most existing deep learning-based methods guided by batched binaries (overlapping vs. non-overlapping pairs) fail to capture. In this paper, we introduce SupScene, a novel solution that learns global descriptors tailored for finding overlapping image pairs of similar geometric nature for SfM. First, to better underline co-visible regions, we employ a subgraph-based training strategy that moves beyond equally important isolated pairs, leveraging ground-truth geometric overlapping relationships with various weights to provide fine-grained supervision via a soft supervised contrastive loss. Second, we introduce DiVLAD, a DINO-inspired VLAD aggregator that leverages the inherent multi-head attention maps from the last block of ViT. And then, a learnable gating mechanism is designed to adaptively utilize these semantically salient cues with visual features, enabling a more discriminative global descriptor. Extensive experiments on the GL3D dataset demonstrate that our method achieves state-of-the-art performance, significantly outperforming NetVLAD while introducing a negligible number of additional trainable parameters. Furthermore, we show that the proposed training strategy brings consistent gains across different aggregation techniques. Code and models are available at https://anonymous.4open.science/r/SupScene-5B73.

</details>


### [308] [Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection](https://arxiv.org/abs/2601.11981)
*Jian Lang,Rongpei Hong,Ting Zhong,Yong Wang,Fan Zhou*

Main category: cs.CV

Relevance: 35.0

TL;DR: RADAR是一个用于假新闻视频检测的测试时自适应框架，通过检索引导的适应范式处理未见新闻主题，解决了现有方法在新兴事件和未见主题上的检测失败问题。


<details>
  <summary>Details</summary>
Motivation: 现有假新闻视频检测方法假设训练和测试阶段新闻主题分布一致，无法检测与新兴事件和未见主题相关的假新闻视频。需要解决测试时适应未见新闻视频的挑战。

Method: 提出RADAR框架，采用检索引导的自适应范式：1) 基于熵选择的检索机制，为目标域提供稳定（低熵）相关参考视频；2) 稳定锚点引导的对齐模块，通过分布级匹配将不稳定实例表示与源域对齐；3) 目标域感知的自训练范式，生成信息丰富的伪标签。

Result: 大量实验表明，RADAR在测试时假新闻视频检测方面实现了卓越性能，能够对未见假新闻视频主题进行强大的即时适应。

Conclusion: RADAR是首个实现测试时适应未见新闻视频的框架，通过创新的检索引导自适应范式有效解决了假新闻视频检测中的领域适应问题。

Abstract: Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.

</details>


### [309] [Structural Graph Neural Networks with Anatomical Priors for Explainable Chest X-ray Diagnosis](https://arxiv.org/abs/2601.11987)
*Khaled Berkani*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出了一种结合解剖学先验的结构图推理框架，用于可解释的视觉诊断。将卷积特征图重新解释为图结构，通过自定义的结构传播机制建模空间关系，支持节点级病变预测和图级诊断推理。


<details>
  <summary>Details</summary>
Motivation: 现有视觉诊断方法缺乏可解释性，难以理解模型决策过程。传统图神经网络使用通用消息传递机制，无法有效建模医学图像中的解剖结构关系。需要一种能够结合领域先验知识、提供内在可解释性的结构推理框架。

Method: 将卷积特征图重新解释为patch级图结构：节点编码外观特征和空间坐标，边反映局部结构邻接关系。引入自定义结构传播机制，显式建模相对空间关系作为推理过程的一部分。支持节点级病变感知预测和图级诊断推理，通过学习的节点重要性分数提供内在可解释性。

Result: 在胸部X光案例研究中展示了结构先验如何指导关系推理并提高可解释性。框架是领域无关的，支持结构感知和可解释学习。提供了内在解释能力，无需依赖后处理可视化技术。

Conclusion: 该框架为结构感知和可解释学习提供了计算基础，将图作为计算基板。虽然评估于医学成像领域，但框架具有领域通用性，适用于更广泛的人工智能系统中的图基推理。

Abstract: We present a structural graph reasoning framework that incorporates explicit anatomical priors for explainable vision-based diagnosis. Convolutional feature maps are reinterpreted as patch-level graphs, where nodes encode both appearance and spatial coordinates, and edges reflect local structural adjacency. Unlike conventional graph neural networks that rely on generic message passing, we introduce a custom structural propagation mechanism that explicitly models relative spatial relations as part of the reasoning process. This design enables the graph to act as an inductive bias for structured inference rather than a passive relational representation. The proposed model jointly supports node-level lesion-aware predictions and graph-level diagnostic reasoning, yielding intrinsic explainability through learned node importance scores without relying on post-hoc visualization techniques. We demonstrate the approach through a chest X-ray case study, illustrating how structural priors guide relational reasoning and improve interpretability. While evaluated in a medical imaging context, the framework is domain-agnostic and aligns with the broader vision of graph-based reasoning across artificial intelligence systems. This work contributes to the growing body of research exploring graphs as computational substrates for structure-aware and explainable learning.

</details>


### [310] [DAOS: A Multimodal In-cabin Behavior Monitoring with Driver Action-Object Synergy Dataset](https://arxiv.org/abs/2601.11990)
*Yiming Li,Chen Cai,Tianyi Liu,Dan Lin,Wenqian Wang,Wenfei Liang,Bingbing Li,Kim-Hui Yap*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出了DAOS数据集和AOR-Net模型，用于驾驶员活动监控中的细粒度动作识别，通过建模人-物关系提升识别准确性。


<details>
  <summary>Details</summary>
Motivation: 驾驶员活动监控中，许多动作看起来相似（主要限于上半身），人类通常依赖驾驶员使用的物体来区分动作。现有数据集缺乏准确的物体位置标注或未将物体与相关动作关联，导致可靠动作识别存在关键缺口。

Method: 1. 引入DAOS数据集：包含9,787个视频片段，标注了36个细粒度驾驶员动作和15个物体类别，总计超过250万个物体实例，提供多模态（RGB、IR、深度）和多视角（前、面部、左、右）数据。2. 提出AOR-Net模型：通过多级推理和动作链提示机制建模动作、物体及其关系的逻辑关系，引入Mixture of Thoughts模块动态选择每个阶段的关键知识。

Result: 大量实验表明，该模型在各种数据集上优于其他最先进方法，在物体丰富和物体稀缺条件下都表现出更强的鲁棒性。

Conclusion: DAOS数据集填补了驾驶员监控数据集的空白，AOR-Net通过建模人-物关系有效提升了细粒度驾驶员动作识别性能，特别是在物体丰富的驾驶舱环境中。

Abstract: In driver activity monitoring, movements are mostly limited to the upper body, which makes many actions look similar. To tell these actions apart, human often rely on the objects the driver is using, such as holding a phone compared with gripping the steering wheel. However, most existing driver-monitoring datasets lack accurate object-location annotations or do not link objects to their associated actions, leaving a critical gap for reliable action recognition. To address this, we introduce the Driver Action with Object Synergy (DAOS) dataset, comprising 9,787 video clips annotated with 36 fine-grained driver actions and 15 object classes, totaling more than 2.5 million corresponding object instances. DAOS offers multi-modal, multi-view data (RGB, IR, and depth) from front, face, left, and right perspectives. Although DAOS captures a wide range of cabin objects, only a few are directly relevant to each action for prediction, so focusing on task-specific human-object relations is essential. To tackle this challenge, we propose the Action-Object-Relation Network (AOR-Net). AOR-Net comprehends complex driver actions through multi-level reasoning and a chain-of-action prompting mechanism that models the logical relationships among actions, objects, and their relations. Additionally, the Mixture of Thoughts module is introduced to dynamically select essential knowledge at each stage, enhancing robustness in object-rich and object-scarce conditions. Extensive experiments demonstrate that our model outperforms other state-of-the-art methods on various datasets.

</details>


### [311] [Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer](https://arxiv.org/abs/2601.12055)
*Lina Meyer,Felix Wissel,Tobias Knopp,Susanne Pfefferle,Ralf Fliegert,Maximilian Sandmann,Liana Uebler,Franziska Möckl,Björn-Philipp Diercks,David Lohr,René Werner*

Main category: cs.CV

Relevance: 35.0

TL;DR: AUTO-DIP：一种用于荧光显微镜图像去噪的无监督深度图像先验自动参数转移方法，通过图像元数据相似性实现免优化的参数配置


<details>
  <summary>Details</summary>
Motivation: 传统无监督深度图像先验（DIP）方法需要为每张新图像单独优化网络架构和停止点，这在处理大量图像时效率低下。研究者假设相似的荧光显微镜图像共享可比较的最优DIP参数配置，从而开发免优化的自动参数转移方法。

Method: 1. 使用开源数据集生成校准集（n=110）和验证集（n=55）的语义不同图像；2. 针对理想U-net架构和停止点进行网络架构搜索；3. 基于图像元数据相似性（显微镜类型、成像样本等）而非定量图像相似性度量进行参数转移；4. 实现AUTO-DIP自动参数转移管道。

Result: AUTO-DIP在多个不同复杂度的开源测试数据集上优于基线DIP（原始DIP参数）和变分去噪方法，特别是在高噪声输入情况下。基于图像元数据相似性的参数转移效果优于基于定量图像相似性度量的方法。

Conclusion: AUTO-DIP为荧光显微镜图像去噪提供了一种高效、免优化的DIP参数转移方法，显著提高了处理效率，特别是在处理大量相似图像时表现出优越性能。

Abstract: Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, we hypothesize that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. We generated a calibration (n=110) and validation set (n=55) of semantically different images from an open-source dataset for a network architecture search targeted towards ideal U-net architectures and stopping points. The calibration set represented our transfer basis. The validation set enabled the assessment of which image similarity criterion yields the best results. We then implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration (baseline) and a state-of-the-art image-specific variational denoising approach. We show that a parameter transfer from the calibration dataset to a test image based on only image metadata similarity (e.g., microscope type, imaged specimen) leads to similar and better performance than a transfer based on quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP (DIP with original DIP parameters) as well as the variational denoising approaches for several open-source test datasets of varying complexity, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved superiority of AUTO-DIP.

</details>


### [312] [Learning Language-Driven Sequence-Level Modal-Invariant Representations for Video-Based Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2601.12062)
*Xiaomei Yang,Xizhan Gao,Antai Liu,Kang Wei,Fa Zhu,Guang Feng,Xiaofeng Qu,Sijie Niu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出LSMRL方法用于视频可见光-红外行人重识别，通过语言驱动的序列级模态不变表示学习，包含时空特征学习、语义扩散和跨模态交互模块，提升模态不变特征学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP语言提示的方法在时空建模效率、跨模态交互充分性和显式模态级损失指导方面存在局限，需要改进视频可见光-红外行人重识别中的模态不变表示学习。

Method: 提出LSMRL方法：1) STFL模块基于CLIP进行最小修改实现高效时空建模；2) SD模块将模态共享语言提示扩散到可见光和红外特征中建立初步模态一致性；3) CMI模块利用双向跨模态自注意力消除剩余模态差异；4) 引入两种模态级损失提升特征判别性和泛化能力。

Result: 在大规模VVI-ReID数据集上的广泛实验表明，LSMRL方法优于现有所有方法，实现了最优性能。

Conclusion: LSMRL方法通过语言驱动的序列级模态不变表示学习，有效解决了现有方法在时空建模效率、跨模态交互和显式损失指导方面的局限，显著提升了视频可见光-红外行人重识别性能。

Abstract: The core of video-based visible-infrared person re-identification (VVI-ReID) lies in learning sequence-level modal-invariant representations across different modalities. Recent research tends to use modality-shared language prompts generated by CLIP to guide the learning of modal-invariant representations. Despite achieving optimal performance, such methods still face limitations in efficient spatial-temporal modeling, sufficient cross-modal interaction, and explicit modality-level loss guidance. To address these issues, we propose the language-driven sequence-level modal-invariant representation learning (LSMRL) method, which includes spatial-temporal feature learning (STFL) module, semantic diffusion (SD) module and cross-modal interaction (CMI) module. To enable parameter- and computation-efficient spatial-temporal modeling, the STFL module is built upon CLIP with minimal modifications. To achieve sufficient cross-modal interaction and enhance the learning of modal-invariant features, the SD module is proposed to diffuse modality-shared language prompts into visible and infrared features to establish preliminary modal consistency. The CMI module is further developed to leverage bidirectional cross-modal self-attention to eliminate residual modality gaps and refine modal-invariant representations. To explicitly enhance the learning of modal-invariant representations, two modality-level losses are introduced to improve the features' discriminative ability and their generalization to unseen categories. Extensive experiments on large-scale VVI-ReID datasets demonstrate the superiority of LSMRL over AOTA methods.

</details>


### [313] [Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation](https://arxiv.org/abs/2601.12066)
*Zijie Lou,Xiangwei Feng,Jiaxin Wang,Xiaochao Qu,Luoqi Liu,Ting Liu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出一种基于随机桥模型的视频对象移除方法，将任务重新定义为视频到视频的转换，利用原始视频作为结构先验，通过自适应掩码调制平衡背景保真度和生成灵活性


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频对象移除方法从高斯噪声开始生成，丢弃了原始视频丰富的结构和上下文先验，导致对象擦除不完整或生成内容与场景物理逻辑冲突

Method: 将视频对象移除重新定义为视频到视频转换任务，使用随机桥模型建立从源视频（含对象）到目标视频（对象移除）的直接随机路径，提出自适应掩码调制策略动态调节输入嵌入

Result: 在视觉质量和时间一致性方面显著优于现有方法

Conclusion: 通过桥模型利用输入视频作为强结构先验，能够精确移除对象并确保填充区域与周围环境逻辑一致，自适应掩码调制解决了强先验阻碍大对象移除的权衡问题

Abstract: Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency.

</details>


### [314] [CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation](https://arxiv.org/abs/2601.12076)
*H. Jiang,Y. Sun,Z. Dong,T. Liu,Y. Gu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 本文针对遥感视频指代目标分割任务，构建了首个大规模基准数据集RS-RVOS Bench，并提出基于Segment Anything Model的记忆质量控制框架MQC-SAM，通过时序运动一致性模块和解耦注意力机制解决记忆偏差和错误传播问题。


<details>
  <summary>Details</summary>
Motivation: 遥感视频指代目标分割面临目标显著性弱、视觉信息截断严重等挑战，现有方法存在初始记忆构建偏差和噪声积累问题，且缺乏大规模专用基准数据集。

Method: 1) 构建RS-RVOS Bench基准数据集，包含111个视频序列、约25,000帧和213,000个时序指代标注，采用因果感知标注策略；2) 提出MQC-SAM框架，包含时序运动一致性模块用于初始记忆校准，以及基于解耦注意力的记忆集成机制进行动态质量评估。

Result: 在RS-RVOS Bench上的大量实验表明，MQC-SAM实现了最先进的性能表现。

Conclusion: 本文通过数据集构建和方法创新推动了遥感视频指代目标分割领域的发展，解决了记忆偏差和错误传播等关键问题。

Abstract: Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.

</details>


### [315] [Conditional Random Fields for Interactive Refinement of Histopathological Predictions](https://arxiv.org/abs/2601.12082)
*Tiffanie Godelaine,Maxime Zanella,Karim El Khoury,Saïd Mahmoudi,Benoît Macq,Christophe De Vleeschouwer*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出HistoCRF框架，通过条件随机场（CRF）改进病理图像分析中视觉语言模型（VLM）的零样本预测，无需额外模型训练，利用标注信息提升分类准确性。


<details>
  <summary>Details</summary>
Motivation: 病理图像分析对癌症检测和分期具有重要临床价值。虽然视觉语言模型（VLMs）在组织病理学中提供了强大的零样本预测能力，但其预测结果仍不完美，需要进一步改进。

Method: 提出HistoCRF框架，将条件随机场（CRF）适应于组织病理学应用。设计了新颖的成对势函数定义，促进标签多样性并利用专家标注。考虑三种实验设置：无标注、有专家标注、以及迭代式人机协同标注。

Result: 在五个涵盖不同器官和疾病的patch级分类数据集上，相比零样本预测，无标注时平均准确率提升16.0%，仅使用100个标注时提升27.5%。人机协同标注进一步达到32.6%的提升。

Conclusion: HistoCRF能有效改进VLM在组织病理学图像分析中的预测性能，无需额外模型训练，且通过人机协同标注可获得更大提升，具有临床应用潜力。

Abstract: Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.

</details>


### [316] [RCDN: Real-Centered Detection Network for Robust Face Forgery Identification](https://arxiv.org/abs/2601.12111)
*Wyatt McCurdy,Xin Zhang,Yuqi Song,Min Gao*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出RCDN网络，通过以真实图像为中心的表征空间，提升伪造图像检测的跨域泛化能力，在DiFF数据集上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 随着AI生成工具的普及，图像伪造检测面临严峻挑战。现有方法在同域检测中表现优异，但在跨域场景下性能显著下降。由于新的伪造技术不断涌现，检测器必须对未见过的伪造方法保持鲁棒性。

Method: 提出Real-Centered Detection Network (RCDN)，基于Xception骨干网络的频域空间CNN框架。核心思想是将表征空间锚定在真实面部图像周围，而不是建模多样且不断演变的伪造模式。采用双分支架构和真实中心损失设计，增强分布偏移下的鲁棒性。

Result: 在DiFF数据集上对三种代表性伪造类型（FE, I2I, T2I）进行广泛实验，RCDN在域内准确率上达到SOTA，同时显著增强了跨域泛化能力。相比领先基线，RCDN减少了泛化差距，并实现了最高的跨域/域内稳定性比率。

Conclusion: RCDN通过强调真实图像的一致性而非建模伪造模式，为防御不断演化和未见过的图像伪造技术提供了实用的解决方案，在跨域泛化方面表现出色。

Abstract: Image forgery has become a critical threat with the rapid proliferation of AI-based generation tools, which make it increasingly easy to synthesize realistic but fraudulent facial content. Existing detection methods achieve near-perfect performance when training and testing are conducted within the same domain, yet their effectiveness deteriorates substantially in crossdomain scenarios. This limitation is problematic, as new forgery techniques continuously emerge and detectors must remain reliable against unseen manipulations. To address this challenge, we propose the Real-Centered Detection Network (RCDN), a frequency spatial convolutional neural networks(CNN) framework with an Xception backbone that anchors its representation space around authentic facial images. Instead of modeling the diverse and evolving patterns of forgeries, RCDN emphasizes the consistency of real images, leveraging a dual-branch architecture and a real centered loss design to enhance robustness under distribution shifts. Extensive experiments on the DiFF dataset, focusing on three representative forgery types (FE, I2I, T2I), demonstrate that RCDN achieves both state-of-the-art in-domain accuracy and significantly stronger cross-domain generalization. Notably, RCDN reduces the generalization gap compared to leading baselines and achieves the highest cross/in-domain stability ratio, highlighting its potential as a practical solution for defending against evolving and unseen image forgery techniques.

</details>


### [317] [Segment and Matte Anything in a Unified Model](https://arxiv.org/abs/2601.12147)
*Zezhong Fan,Xiaohan Li,Topojoy Biswas,Kaushiki Nag,Kannan Achan*

Main category: cs.CV

Relevance: 35.0

TL;DR: SAMA是SAM的轻量级扩展，在单一体化框架中实现高质量交互式图像分割和抠图，通过多视图定位编码器和局部适配器提升边界细节，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: SAM在分割精度上仍不足，现有细化模块未能实现单一体化框架的高精度分割，且交互式图像抠图在SAM背景下尚未探索。分割与抠图存在强相关性，表明统一模型的可行性。

Method: 提出SAMA：1) Multi-View Localization Encoder (MVLE)捕获局部视图细节特征；2) Localization Adapter (Local-Adapter)恢复细微边界细节；3) 双预测头架构同时生成分割和抠图掩码；4) 在公开数据集上训练。

Result: 在多个分割和抠图基准测试中达到最先进性能，展示在广泛下游任务中的适应性和有效性，仅需少量额外参数即可实现高质量交互式分割和抠图。

Conclusion: SAMA成功扩展SAM能力，在单一体化框架中实现高质量分割和抠图，为实际应用提供更精确的解决方案，验证了分割与抠图统一模型的可行性。

Abstract: Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.

</details>


### [318] [Inverse Rendering for High-Genus 3D Surface Meshes from Multi-view Images with Persistent Homology Priors](https://arxiv.org/abs/2601.12155)
*Xiang Gao,Xinmu Wang,Yuanpeng Liu,Yue Wang,Junqi Huang,Wei Chen,Xianfeng Gu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 论文提出了一种结合持久同调先验的协作式逆渲染方法，用于解决3D重建中的拓扑歧义问题，特别针对高亏格表面重建。


<details>
  <summary>Details</summary>
Motivation: 从图像重建3D物体存在固有的病态问题，因为几何、外观和拓扑存在歧义。传统方法难以准确重建高亏格表面（如带孔洞或环状结构），容易导致拓扑结构崩溃或丢失。

Method: 提出协作式逆渲染框架，结合多视图图像的光度一致性和持久同调先验。持久同调用于捕捉关键拓扑特征（如隧道环和手柄环），通过基于网格的逆渲染框架进行梯度优化，而非神经网络。

Result: 实验结果表明，加入持久同调先验的方法在Chamfer距离和体积IoU指标上优于最先进的基于网格的方法，显示出更好的几何精度和对拓扑失败的鲁棒性。

Conclusion: 持久同调先验能有效解决3D重建中的拓扑歧义问题，特别适用于高亏格表面重建，避免了拓扑结构崩溃等灾难性失败。

Abstract: Reconstructing 3D objects from images is inherently an ill-posed problem due to ambiguities in geometry, appearance, and topology. This paper introduces collaborative inverse rendering with persistent homology priors, a novel strategy that leverages topological constraints to resolve these ambiguities. By incorporating priors that capture critical features such as tunnel loops and handle loops, our approach directly addresses the difficulty of reconstructing high-genus surfaces. The collaboration between photometric consistency from multi-view images and homology-based guidance enables recovery of complex high-genus geometry while circumventing catastrophic failures such as collapsing tunnels or losing high-genus structure. Instead of neural networks, our method relies on gradient-based optimization within a mesh-based inverse rendering framework to highlight the role of topological priors. Experimental results show that incorporating persistent homology priors leads to lower Chamfer Distance (CD) and higher Volume IoU compared to state-of-the-art mesh-based methods, demonstrating improved geometric accuracy and robustness against topological failure.

</details>


### [319] [Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion](https://arxiv.org/abs/2601.12224)
*Meng Wei,Kun Yuan,Shi Li,Yue Zhou,Long Bai,Nassir Navab,Hongliang Ren,Hong Joo Lee,Tom Vercauteren,Nicolas Padoy*

Main category: cs.CV

Relevance: 35.0

TL;DR: SurgRef是一个基于运动引导的框架，通过工具运动而非静态视觉特征来实现手术视频中基于自然语言描述的器械分割，解决了遮挡、模糊和术语不熟悉等问题。


<details>
  <summary>Details</summary>
Motivation: 当前手术场景中的指代分割任务（基于自然语言描述定位手术器械）研究不足，现有方法依赖静态视觉线索和预定义器械名称，导致泛化能力差。需要实现更直观、语言驱动的手术场景交互，这是迈向智能手术室和自主手术机器人辅助的关键步骤。

Method: 提出SurgRef框架，通过运动引导将自由形式的语言表达与器械运动关联起来，捕捉工具随时间移动和交互的方式，而不是它们的外观。还创建了Ref-IMotion数据集，这是一个多样化、多机构的视频数据集，包含密集的时空掩码和丰富的以运动为中心的表达。

Result: SurgRef在不同手术程序中实现了最先进的准确性和泛化能力，为鲁棒的语言驱动手术视频分割设立了新的基准。

Conclusion: 通过关注器械运动而非静态视觉特征，SurgRef框架能够更好地理解和分割手术器械，即使在遮挡、模糊或不熟悉术语的情况下也能工作，为智能手术室和自主手术机器人辅助提供了重要进展。

Abstract: Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.

</details>


### [320] [An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion](https://arxiv.org/abs/2601.12249)
*Ehsan Sadeghi Pour,Mahdi Esmaeili,Morteza Romoozi*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一种结合金字塔自适应空洞卷积（PAAC）和Transformer架构的创新框架，用于乳腺X光图像中恶性肿块的检测，在多个数据集上实现了高精度分类。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性最常见的癌症之一，准确及时的诊断对改善治疗结果至关重要。传统方法在检测恶性肿块方面存在局限性，需要更精确高效的计算机辅助诊断系统。

Method: 提出PAAC-Transformer框架，结合金字塔自适应空洞卷积和Transformer架构。采用多尺度特征融合技术增强特征提取，结合Dice Loss和Focal Loss函数优化学习过程。使用INbreast、MIAS和DDSM数据集，经过数据增强和对比度增强预处理后，将图像调整为227x227像素进行训练。

Result: 模型在乳腺癌检测任务中表现出色：准确率98.5%、敏感性97.8%、特异性96.3%、F1分数98.2%、精确率97.9%。显著优于BreastNet、DeepMammo、Multi-Scale CNN、Swin-Unet和SegFormer等基准模型。

Conclusion: 该模型在复杂场景和大规模数据集上有效识别癌性肿块，证明了PAAC-Transformer框架在医学图像分析中的优越性，有望成为乳腺癌诊断的可靠高效工具，可集成到医疗诊断系统中。

Abstract: Breast cancer is one of the most common cancers among women worldwide, and its accurate and timely diagnosis plays a critical role in improving treatment outcomes. This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating the Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model's learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. In this study, a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM was preprocessed through data augmentation and contrast enhancement and resized to 227x227 pixels for model training. Leveraging the Transformer's ability to manage long-range dependencies with Self-Attention mechanisms, the proposed model achieved high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5\%, sensitivity of 97.8\%, specificity of 96.3\%, F1-score of 98.2\%, and overall precision of 97.9\%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.

</details>


### [321] [CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding](https://arxiv.org/abs/2601.12312)
*Yongjun Jeon,Jongmin Shin,Kanggil Park,Seonmin Park,Soyoung Lim,Jung Yong Kim,Jinsoo Rhu,Jongman Kim,Gyu-Seong Choi,Namkee Oh,Kyu-Hwan Jung*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出CurConMix+框架，通过课程引导对比学习、结构化硬对采样和多分辨率时序Transformer，解决手术动作三元组识别中的类别不平衡和语义依赖问题，并在新数据集LLS48上验证性能。


<details>
  <summary>Details</summary>
Motivation: 手术动作三元组识别对工作流分析和技能评估具有临床重要性，但面临严重类别不平衡、细微视觉变化和三元组组件间语义依赖等挑战。现有方法通常只解决部分问题，缺乏整体理解。

Method: 基于CurConMix空间表示框架，提出课程引导对比学习策略，结合结构化硬对采样和特征级混合。时序扩展CurConMix+集成多分辨率时序Transformer，自适应融合多尺度时序特征并动态平衡时空线索。还引入层次标注的新数据集LLS48。

Result: 在CholecT45和LLS48数据集上的实验表明，CurConMix+在动作三元组识别上优于现有方法，并展现出强大的跨层级泛化能力，其细粒度特征能有效迁移到更高层级的阶段和步骤识别任务。

Conclusion: 该框架和数据集为层次感知、可复现和可解释的手术工作流理解提供了统一基础。代码和数据集将在GitHub公开以促进复现和进一步研究。

Abstract: Surgical action triplet recognition aims to understand fine-grained surgical behaviors by modeling the interactions among instruments, actions, and anatomical targets. Despite its clinical importance for workflow analysis and skill assessment, progress has been hindered by severe class imbalance, subtle visual variations, and the semantic interdependence among triplet components. Existing approaches often address only a subset of these challenges rather than tackling them jointly, which limits their ability to form a holistic understanding. This study builds upon CurConMix, a spatial representation framework. At its core, a curriculum-guided contrastive learning strategy learns discriminative and progressively correlated features, further enhanced by structured hard-pair sampling and feature-level mixup. Its temporal extension, CurConMix+, integrates a Multi-Resolution Temporal Transformer (MRTT) that achieves robust, context-aware understanding by adaptively fusing multi-scale temporal features and dynamically balancing spatio-temporal cues. Furthermore, we introduce LLS48, a new, hierarchically annotated benchmark for complex laparoscopic left lateral sectionectomy, providing step-, task-, and action-level annotations. Extensive experiments on CholecT45 and LLS48 demonstrate that CurConMix+ not only outperforms state-of-the-art approaches in triplet recognition, but also exhibits strong cross-level generalization, as its fine-grained features effectively transfer to higher-level phase and step recognition tasks. Together, the framework and dataset provide a unified foundation for hierarchy-aware, reproducible, and interpretable surgical workflow understanding. The code and dataset will be publicly released on GitHub to facilitate reproducibility and further research.

</details>


### [322] [GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer](https://arxiv.org/abs/2601.12316)
*Xinyuan Zhao,Xianrui Chen,Ahmad Chaddad*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出了Gazeformer，一种语义调制、多尺度Transformer，用于3D视线估计，通过原型库调节CLIP特征，融合多尺度特征，并使用MoE提升条件容量，在多个数据集上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 3D视线估计在HCI、AR/VR、驾驶员监控等领域有重要应用，但现有方法在复杂光照、头部姿态、背景变化等条件下性能有限。需要更鲁棒、语义感知的模型来处理这些挑战。

Method: 1) 使用可学习的原型库（光照、头部姿态、背景、方向）调节CLIP全局特征；2) 在统一注意力空间中融合原型增强的全局向量、CLIP patch token和高分辨率CNN token；3) 用路由/共享的混合专家（MoE）替换部分FFN块以增加条件容量。

Result: 在MPIIFaceGaze、EYEDIAP、Gaze360和ETH-XGaze数据集上分别达到2.49°、3.22°、10.16°和1.44°的角误差，相比之前最佳结果相对提升达64%。消融实验证明原型调节、跨尺度融合、MoE和超参数对性能提升有贡献。

Conclusion: Gazeformer通过语义调制和多尺度特征融合，显著提升了3D视线估计的准确性和鲁棒性，为复杂条件下的视线估计提供了有效解决方案。

Abstract: We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github. com/AIPMLab/Gazeformer.

</details>


### [323] [Multi-Sensor Matching with HyperNetworks](https://arxiv.org/abs/2601.12325)
*Eli Passov,Nathan S. Netanyahu,Yosi Keller*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一种基于超网络的轻量级描述符学习架构，用于改进多模态图像块匹配，通过自适应通道缩放/平移和条件实例归一化增强Siamese CNN，在VIS-IR跨模态匹配任务中取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 多模态图像匹配（如可见光与红外图像）面临外观差异大的挑战。现有方法要么计算成本高，要么对域偏移鲁棒性不足。需要一种既能保持描述符方法推理效率，又能增强跨模态鲁棒性的解决方案。

Method: 1) 使用超网络模块计算自适应、每通道的缩放和偏移参数；2) 引入条件实例归一化，在浅层提供模态特定适应（如VIS vs IR）；3) 结合Siamese CNN架构；4) 使用三元组损失和难负样本挖掘进行训练。

Result: 在VIS-NIR和其他VIS-IR基准测试中取得最先进结果；在其他数据集上匹配或超越先前方法，尽管推理成本更低；发布了GAP-VIR跨平台（地面/空中）VIS-IR图像块数据集，包含50万对样本。

Conclusion: 超网络为多模态图像匹配提供了一种高效且鲁棒的解决方案，能够在保持推理效率的同时增强对域偏移的适应性。新发布的GAP-VIR数据集将促进跨域泛化和适应研究。

Abstract: Hypernetworks are models that generate or modulate the weights of another network. They provide a flexible mechanism for injecting context and task conditioning and have proven broadly useful across diverse applications without significant increases in model size. We leverage hypernetworks to improve multimodal patch matching by introducing a lightweight descriptor-learning architecture that augments a Siamese CNN with (i) hypernetwork modules that compute adaptive, per-channel scaling and shifting and (ii) conditional instance normalization that provides modality-specific adaptation (e.g., visible vs. infrared, VIS-IR) in shallow layers. This combination preserves the efficiency of descriptor-based methods during inference while increasing robustness to appearance shifts. Trained with a triplet loss and hard-negative mining, our approach achieves state-of-the-art results on VIS-NIR and other VIS-IR benchmarks and matches or surpasses prior methods on additional datasets, despite their higher inference cost. To spur progress on domain shift, we also release GAP-VIR, a cross-platform (ground/aerial) VIS-IR patch dataset with 500K pairs, enabling rigorous evaluation of cross-domain generalization and adaptation.

</details>


### [324] [FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching](https://arxiv.org/abs/2601.12329)
*Mithlesh Singla,Seema Kumari,Shanmuganathan Raman*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出FlowIID，一种基于流匹配的本征图像分解方法，通过VAE引导的潜空间和流匹配模块实现参数高效的单步推理，在多个基准测试中取得竞争性结果。


<details>
  <summary>Details</summary>
Motivation: 现有本征图像分解(IID)模型虽然效果好但参数量大，难以与其他模型结合应用于实际场景。需要开发参数高效、适合实时视觉应用的IID方法。

Method: 提出FlowIID架构，基于潜流匹配：1) 使用VAE引导的潜空间；2) 结合流匹配模块；3) 实现稳定的反照率和阴影分解；4) 单步推理完成。

Result: FlowIID在多个基准测试中取得竞争性和优越的结果，尽管设计紧凑但性能不输现有模型，适合资源受限和实时应用部署。

Conclusion: FlowIID通过流匹配方法实现了参数高效的本征图像分解，为实际应用提供了可行的解决方案，特别是在资源受限环境中。

Abstract: Intrinsic Image Decomposition (IID) separates an image into albedo and shading components. It is a core step in many real-world applications, such as relighting and material editing. Existing IID models achieve good results, but often use a large number of parameters. This makes them costly to combine with other models in real-world settings. To address this problem, we propose a flow matching-based solution. For this, we design a novel architecture, FlowIID, based on latent flow matching. FlowIID combines a VAE-guided latent space with a flow matching module, enabling a stable decomposition of albedo and shading. FlowIID is not only parameter-efficient, but also produces results in a single inference step. Despite its compact design, FlowIID delivers competitive and superior results compared to existing models across various benchmarks. This makes it well-suited for deployment in resource-constrained and real-time vision applications.

</details>


### [325] [SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence](https://arxiv.org/abs/2601.12357)
*Hailing Jin,Huiying Li*

Main category: cs.CV

Relevance: 35.0

TL;DR: SimpleMatch是一个用于语义对应的简单高效框架，通过轻量级上采样解码器和多尺度监督损失，在低分辨率下实现强性能，同时通过稀疏匹配和窗口定位减少51%的训练内存使用。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练大规模模型的语义对应方法依赖高分辨率输入以获得最佳性能，导致计算开销大。主要问题是深度下采样操作导致相邻关键点特征的不可逆融合，当语义不同的关键点落在同一采样感受野内时，性能会下降。

Method: 提出SimpleMatch框架：1) 轻量级上采样解码器，逐步将深度特征上采样到1/4分辨率以恢复空间细节；2) 多尺度监督损失，确保上采样特征在不同空间尺度上保持判别性；3) 稀疏匹配和基于窗口的定位，优化训练内存使用。

Result: 在252x252分辨率（比当前SOTA方法小3.3倍）下，在SPair-71k基准测试上达到84.1%的PCK@0.1性能，同时训练内存使用减少51%。

Conclusion: SimpleMatch为语义对应研究提供了一个实用高效的基础框架，解决了高分辨率依赖和计算开销问题，同时保持了强性能。

Abstract: Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, a limitation of these approaches is their dependence on high-resolution input images to achieve optimal performance, which results in considerable computational overhead. In this work, we address a fundamental limitation in current methods: the irreversible fusion of adjacent keypoint features caused by deep downsampling operations. This issue is triggered when semantically distinct keypoints fall within the same downsampled receptive field (e.g., 16x16 patches). To address this issue, we present SimpleMatch, a simple yet effective framework for semantic correspondence that delivers strong performance even at low resolutions. We propose a lightweight upsample decoder that progressively recovers spatial detail by upsampling deep features to 1/4 resolution, and a multi-scale supervised loss that ensures the upsampled features retain discriminative features across different spatial scales. In addition, we introduce sparse matching and window-based localization to optimize training memory usage and reduce it by 51%. At a resolution of 252x252 (3.3x smaller than current SOTA methods), SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. We believe this framework provides a practical and efficient baseline for future research in semantic correspondence. Code is available at: https://github.com/hailong23-jin/SimpleMatch.

</details>


### [326] [Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation](https://arxiv.org/abs/2601.12391)
*Dasith de Silva Edirimuni,Ajmal Saeed Mian*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出CPVQ-VAE方法，通过类别划分的码书和类别感知更新机制，实现从扩散模型生成的潜在特征直接解码为点云场景，无需外部数据库检索。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景生成方法主要生成边界框参数，扩散方法虽然能生成类别标签和潜在特征，但当前自编码器无法有效解码复杂多类别场景的潜在特征为正确的点云对象。需要一种能直接从潜在特征解码为类别特定点云的方法。

Method: 1) 提出类别划分向量量化变分自编码器(CPVQ-VAE)，使用类别划分的码书，码向量按类别标记；2) 提出类别感知运行平均更新机制，解决码书坍缩问题；3) 使用专门设计的潜在空间流匹配模型(LFMM)生成对象特征和类别标签；4) 通过类别感知逆查找将生成潜在映射到码书条目，解码为点云形状。

Result: 在复杂客厅场景上，Chamfer误差减少70.4%，Point2Mesh误差减少72.3%，可靠地恢复合理的点云场景，实现纯点云生成而无需外部对象数据库检索。

Conclusion: CPVQ-VAE方法能有效解码扩散模型生成的潜在特征为类别特定的点云对象，解决了复杂多类别场景生成中自编码器解码能力不足的问题，实现了端到端的点云场景生成。

Abstract: Most 3D scene generation methods are limited to only generating object bounding box parameters while newer diffusion methods also generate class labels and latent features. Using object size or latent feature, they then retrieve objects from a predefined database. For complex scenes of varied, multi-categorical objects, diffusion-based latents cannot be effectively decoded by current autoencoders into the correct point cloud objects which agree with target classes. We introduce a Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE) that is trained to effectively decode object latent features, by employing a pioneering $\textit{class-partitioned codebook}$ where codevectors are labeled by class. To address the problem of $\textit{codebook collapse}$, we propose a $\textit{class-aware}$ running average update which reinitializes dead codevectors within each partition. During inference, object features and class labels, both generated by a Latent-space Flow Matching Model (LFMM) designed specifically for scene generation, are consumed by the CPVQ-VAE. The CPVQ-VAE's class-aware inverse look-up then maps generated latents to codebook entries that are decoded to class-specific point cloud shapes. Thereby, we achieve pure point cloud generation without relying on an external objects database for retrieval. Extensive experiments reveal that our method reliably recovers plausible point cloud scenes, with up to 70.4% and 72.3% reduction in Chamfer and Point2Mesh errors on complex living room scenes.

</details>


### [327] [SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition](https://arxiv.org/abs/2601.12432)
*Shunyu Huang,Yunjiao Zhou,Jianfei Yang*

Main category: cs.CV

Relevance: 35.0

TL;DR: SkeFi提出了一种新颖的跨模态知识转移方法，利用数据丰富的RGB模态来增强无线传感器（LiDAR和mmWave）的骨架估计和动作识别，解决了无线传感器数据不足和噪声问题。


<details>
  <summary>Details</summary>
Motivation: 基于骨架的动作识别在黑暗环境和隐私敏感场景（如智能家居和医院）中面临挑战，因为传统RGB摄像头在这些场景下性能下降且存在隐私问题。无线传感器（LiDAR和mmWave）作为非侵入式替代方案，但存在数据不足和噪声大的问题。

Method: 提出了SkeFi框架，通过跨模态知识转移从数据丰富的RGB模态学习。核心包括：增强的时间相关自适应图卷积（TC-AGC）处理缺失或不连续帧的噪声；双时间卷积增强多尺度时间建模；整合TC-AGC与时间建模进行跨模态转移。

Result: 实验表明SkeFi在mmWave和LiDAR传感器上实现了最先进的性能，能够从噪声无线传感器中提取准确的姿态和动作。

Conclusion: SkeFi通过创新的跨模态知识转移方法，成功解决了无线传感器在骨架估计和动作识别中的数据不足和噪声问题，为黑暗环境和隐私敏感场景提供了可行的非侵入式解决方案。

Abstract: Skeleton-based action recognition leverages human pose keypoints to categorize human actions, which shows superior generalization and interoperability compared to regular end-to-end action recognition. Existing solutions use RGB cameras to annotate skeletal keypoints, but their performance declines in dark environments and raises privacy concerns, limiting their use in smart homes and hospitals. This paper explores non-invasive wireless sensors, i.e., LiDAR and mmWave, to mitigate these challenges as a feasible alternative. Two problems are addressed: (1) insufficient data on wireless sensor modality to train an accurate skeleton estimation model, and (2) skeletal keypoints derived from wireless sensors are noisier than RGB, causing great difficulties for subsequent action recognition models. Our work, SkeFi, overcomes these gaps through a novel cross-modal knowledge transfer method acquired from the data-rich RGB modality. We propose the enhanced Temporal Correlation Adaptive Graph Convolution (TC-AGC) with frame interactive enhancement to overcome the noise from missing or inconsecutive frames. Additionally, our research underscores the effectiveness of enhancing multiscale temporal modeling through dual temporal convolution. By integrating TC-AGC with temporal modeling for cross-modal transfer, our framework can extract accurate poses and actions from noisy wireless sensors. Experiments demonstrate that SkeFi realizes state-of-the-art performances on mmWave and LiDAR. The code is available at https://github.com/Huang0035/Skefi.

</details>


### [328] [Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild](https://arxiv.org/abs/2601.12464)
*Yanrui Lu,Danyang Chen,Haowen Xiao,Jiarui Zhu,Fukang Ge,Binqian Zou,Jiali Guan,Jiayin Liang,Yuting Wang,Ziqian Guan,Xiangcheng Bao,Jinhao Bi,Lin Gu,Jun He,Yingying Zhu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一个大规模、多源的多细胞器实例分割基准，包含超过10万张2D电子显微镜图像，用于评估当前分割模型在真实世界异质性数据上的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于小规模、精心策划数据集的基准无法捕捉真实世界电子显微镜数据的固有异质性和大空间上下文，限制了基于patch的方法的发展，需要更全面的基准来评估模型在真实场景下的表现。

Method: 开发了大规模多源基准数据集，包含超过10万张2D EM图像，涵盖多种细胞类型和五个细胞器类别；设计了连接感知的标签传播算法（3D LPA）进行标注，并由专家精修；对U-Net、SAM变体和Mask2Former等SOTA模型进行了基准测试。

Result: 当前模型在异质性EM数据上泛化能力有限，对具有全局分布形态的细胞器（如内质网）表现不佳，揭示了局部上下文模型与建模长程结构连续性之间的根本性不匹配。

Conclusion: 需要开发能够处理真实世界异质性和长程结构连续性的新模型架构，该基准数据集和标注工具将为推动这一领域发展提供重要资源。

Abstract: Accurate instance-level segmentation of organelles in electron microscopy (EM) is critical for quantitative analysis of subcellular morphology and inter-organelle interactions. However, current benchmarks, based on small, curated datasets, fail to capture the inherent heterogeneity and large spatial context of in-the-wild EM data, imposing fundamental limitations on current patch-based methods. To address these limitations, we developed a large-scale, multi-source benchmark for multi-organelle instance segmentation, comprising over 100,000 2D EM images across variety cell types and five organelle classes that capture real-world variability. Dataset annotations were generated by our designed connectivity-aware Label Propagation Algorithm (3D LPA) with expert refinement. We further benchmarked several state-of-the-art models, including U-Net, SAM variants, and Mask2Former. Our results show several limitations: current models struggle to generalize across heterogeneous EM data and perform poorly on organelles with global, distributed morphologies (e.g., Endoplasmic Reticulum). These findings underscore the fundamental mismatch between local-context models and the challenge of modeling long-range structural continuity in the presence of real-world variability. The benchmark dataset and labeling tool will be publicly released soon.

</details>


### [329] [SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection](https://arxiv.org/abs/2601.12507)
*Ruo Qi,Linhui Dai,Yusong Qin,Chaolei Yang,Yanshan Li*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出SDCoNet，一个显著性驱动的多任务协作网络，通过隐式特征共享将超分辨率和检测耦合，解决遥感图像中小目标检测的挑战。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中复杂背景、弱目标信号和小目标尺度使得准确检测特别困难，尤其是在低质量成像条件下。现有的串行流水线（先超分辨率后检测）存在优化目标不对齐、特征冗余以及SR和检测之间缺乏有效交互的问题。

Method: 提出SDCoNet，采用基于Swin Transformer的共享编码器，通过分层窗口移位自注意力支持跨任务特征协作。引入多尺度显著性预测模块生成重要性分数来选择关键token，聚焦弱目标区域并抑制背景杂波。采用梯度路由策略缓解优化冲突，先稳定检测语义，然后沿检测导向方向路由SR梯度。

Result: 在NWPU VHR-10-Split、DOTAv1.5-Split和HRSSD-Split等公开数据集上的实验表明，该方法在保持计算效率的同时，在低质量遥感图像的小目标检测方面显著优于现有主流算法。

Conclusion: SDCoNet通过隐式特征共享和任务特异性保持，有效解决了遥感图像中小目标检测的挑战，为多任务学习在计算机视觉中的应用提供了新思路。

Abstract: In remote sensing images, complex backgrounds, weak object signals, and small object scales make accurate detection particularly challenging, especially under low-quality imaging conditions. A common strategy is to integrate single-image super-resolution (SR) before detection; however, such serial pipelines often suffer from misaligned optimization objectives, feature redundancy, and a lack of effective interaction between SR and detection. To address these issues, we propose a Saliency-Driven multi-task Collaborative Network (SDCoNet) that couples SR and detection through implicit feature sharing while preserving task specificity. SDCoNet employs the swin transformer-based shared encoder, where hierarchical window-shifted self-attention supports cross-task feature collaboration and adaptively balances the trade-off between texture refinement and semantic representation. In addition, a multi-scale saliency prediction module produces importance scores to select key tokens, enabling focused attention on weak object regions, suppression of background clutter, and suppression of adverse features introduced by multi-task coupling. Furthermore, a gradient routing strategy is introduced to mitigate optimization conflicts. It first stabilizes detection semantics and subsequently routes SR gradients along a detection-oriented direction, enabling the framework to guide the SR branch to generate high-frequency details that are explicitly beneficial for detection. Experiments on public datasets, including NWPU VHR-10-Split, DOTAv1.5-Split, and HRSSD-Split, demonstrate that the proposed method, while maintaining competitive computational efficiency, significantly outperforms existing mainstream algorithms in small object detection on low-quality remote sensing images. Our code is available at https://github.com/qiruo-ya/SDCoNet.

</details>


### [330] [From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2](https://arxiv.org/abs/2601.12636)
*Satyaki Roy Chowdhury,Aswathnarayan Radhakrishnan,Hsiao Jou Hsu,Hari Subramoni,Joachim Moortgat*

Main category: cs.CV

Relevance: 35.0

TL;DR: 本文提出Swin-BathyUNet模型用于卫星遥感水深反演，通过注意力机制分析、波段重要性排名和跨区域推理研究，揭示了模型深度推断机制及可信度评估方法，为跨站点稳健部署提供实用指导。


<details>
  <summary>Details</summary>
Motivation: Sentinel-2卫星遥感水深反演(SDB)在不同站点的稳健部署仍具挑战性。需要理解模型如何推断水深以及何时预测可信，以提高跨区域应用的可靠性。

Method: 1) 使用基于Swin-Transformer的U-Net模型(Swin-BathyUNet)；2) 进行留一波段实验以评估光谱重要性；3) 将基于消融的CAM适应到回归任务(A-CAM-R)；4) 通过性能保持测试验证解释可靠性；5) 进行注意力消融分析；6) 跨区域推理实验(在一个站点训练，另一个站点测试)。

Result: 1) 波段重要性排名与浅水光学理论一致；2) A-CAM-R能有效定位模型依赖的证据区域；3) 解码器条件化跨注意力机制能提高对眩光/泡沫的鲁棒性；4) 跨区域推理显示误差随深度线性增加，双峰深度分布加剧中/深水区误差。

Conclusion: 提出实用指导：保持宽感受野、保护绿/蓝通道辐射保真度、预过滤近岸高方差亮区、结合深度感知校准进行轻量目标站点微调，以实现跨区域迁移。

Abstract: Deploying Sentinel-2 satellite derived bathymetry (SDB) robustly across sites remains challenging. We analyze a Swin-Transformer based U-Net model (Swin-BathyUNet) to understand how it infers depth and when its predictions are trustworthy. A leave-one-band out study ranks spectral importance to the different bands consistent with shallow water optics. We adapt ablation-based CAM to regression (A-CAM-R) and validate the reliability via a performance retention test: keeping only the top-p% salient pixels while neutralizing the rest causes large, monotonic RMSE increase, indicating explanations localize on evidence the model relies on. Attention ablations show decoder conditioned cross attention on skips is an effective upgrade, improving robustness to glint/foam. Cross-region inference (train on one site, test on another) reveals depth-dependent degradation: MAE rises nearly linearly with depth, and bimodal depth distributions exacerbate mid/deep errors. Practical guidance follows: maintain wide receptive fields, preserve radiometric fidelity in green/blue channels, pre-filter bright high variance near shore, and pair light target site fine tuning with depth aware calibration to transfer across regions.

</details>


### [331] [Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT](https://arxiv.org/abs/2601.12638)
*Ninnart Fuengfusin,Keisuke Yoneda,Naoki Suganuma*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出用于LIDAR 3D目标检测的混合精度量化框架，通过敏感层识别和贪婪搜索优化量化策略，在保持性能的同时显著降低延迟和模型大小


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的LIDAR 3D目标检测需要实时运行，但直接应用模型量化会导致性能下降，主要原因是LIDAR数据的宽数值分布和极端异常值

Method: 1) 使用PTQ逐层量化识别敏感层，将top-k敏感层设为浮点；2) 贪婪搜索混合精度组合；3) 使用少量校准数据减少异常值影响；4) 提供PTQ和QAT两种流水线

Result: 混合精度模型在TensorRT部署下，延迟降低最多2.35倍，模型大小减少最多2.26倍，QAT流水线性能与浮点模型相当

Conclusion: 提出的混合精度量化框架有效解决了LIDAR数据量化挑战，实现了实时3D目标检测的性能与效率平衡

Abstract: LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.

</details>


### [332] [Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification](https://arxiv.org/abs/2601.12671)
*Thamara Leandra de Deus Melo,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文研究联邦学习环境下脑肿瘤MRI图像分类，发现预处理单独使用效果有限，但结合测试时增强(TTA)能显著提升分类性能，建议在联邦学习医疗影像中默认使用TTA。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤早期诊断对治疗至关重要，但由于病变变异性和图像复杂性而具有挑战性。作者旨在评估联邦学习环境下卷积神经网络在MRI图像分类中的表现，特别关注预处理和测试时增强的效果。

Method: 在联邦学习设置中评估卷积神经网络，比较在原始MRI图像与预处理图像（包括调整大小、灰度转换、归一化、滤波和直方图均衡化）上训练的模型。分析预处理单独使用以及与测试时增强(TTA)结合的效果。

Result: 单独预处理带来的增益可忽略不计，但与测试时增强(TTA)结合后，在联邦MRI分类中获得了持续且统计显著的改进(p<0.001)。

Conclusion: 在基于联邦学习的医疗影像中，测试时增强(TTA)应作为默认推理策略；当计算预算允许时，将TTA与轻量预处理结合可提供额外的可靠增益。

Abstract: Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.

</details>


### [333] [P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2601.12714)
*Songlin Dong,Jiangyang Li,Chenhao Ding,Zhiheng Ma,Haoyu Luo,Yuhang He,Yihong Gong*

Main category: cs.CV

Relevance: 35.0

TL;DR: P2L-CA是一个参数高效的框架，通过Prompt-to-Label模块和Continuous Adapter模块解决多标签类增量学习中的计算成本高、存储开销大和特征混淆问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在计算成本高（全参数微调）、存储开销大（内存缓冲区）以及特征混淆和领域差异问题，需要更高效的解决方案。

Method: 提出P2L-CA框架：1) P2L模块使用类特定提示解耦多标签表示，结合语言先验稳定语义-视觉对齐；2) CA模块使用轻量适配器缓解预训练模型与下游任务间的领域差距。

Result: 在MS-COCO和PASCAL VOC的标准和挑战性MLCIL设置中，P2L-CA显著优于现有方法，展示强泛化能力，同时只需最小可训练参数且无需内存缓冲区。

Conclusion: P2L-CA有效解决了多标签类增量学习的关键挑战，实现了高效、准确的学习，具有实际应用价值。

Abstract: Multi-label Class-Incremental Learning aims to continuously recognize novel categories in complex scenes where multiple objects co-occur. However, existing approaches often incur high computational costs due to full-parameter fine-tuning and substantial storage overhead from memory buffers, or they struggle to address feature confusion and domain discrepancies adequately. To overcome these limitations, we introduce P2L-CA, a parameter-efficient framework that integrates a Prompt-to-Label module with a Continuous Adapter module. The P2L module leverages class-specific prompts to disentangle multi-label representations while incorporating linguistic priors to enforce stable semantic-visual alignment. Meanwhile, the CA module employs lightweight adapters to mitigate domain gaps between pre-trained models and downstream tasks, thereby enhancing model plasticity. Extensive experiments across standard and challenging MLCIL settings on MS-COCO and PASCAL VOC show that P2L-CA not only achieves substantial improvements over state-of-the-art methods but also demonstrates strong generalization in CIL scenarios, all while requiring minimal trainable parameters and eliminating the need for memory buffers.

</details>


### [334] [DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition](https://arxiv.org/abs/2601.12729)
*Hanyu Zhu,Zhihao Zhan,Yuhang Ming,Liang Li,Dibo Hou,Javier Civera,Wanzeng Kong*

Main category: cs.CV

Relevance: 35.0

TL;DR: DC-VLAQ：一个用于视觉地点识别的表示中心框架，通过融合互补的视觉基础模型特征和创新的全局聚合方案，提升在视角变化、光照变化和域偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 视觉地点识别面临的主要挑战是在大视角变化、光照变化和严重域偏移下学习鲁棒的全局表示。现有方法通常依赖单一视觉基础模型，忽略了不同模型提供的互补信息，而利用这些互补信息会改变token分布，挑战现有基于查询的全局聚合方案的稳定性。

Method: 提出DC-VLAQ框架：1）轻量级残差引导的互补融合，以DINOv2特征空间为锚点，通过学习的残差校正注入CLIP的互补语义；2）局部聚合查询向量（VLAQ），一种查询-残差全局聚合方案，通过局部token对可学习查询的残差响应进行编码，提高稳定性并保留细粒度判别线索。

Result: 在Pitts30k、Tokyo24/7、MSLS、Nordland、SPED和AmsterTime等标准VPR基准测试中，DC-VLAQ始终优于强基线方法，在挑战性域偏移和长期外观变化下实现最先进的性能。

Conclusion: DC-VLAQ通过有效融合互补视觉基础模型特征和稳定的全局聚合机制，显著提升了视觉地点识别的鲁棒性和判别能力，特别是在域偏移和长期变化场景下。

Abstract: One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes.

</details>


### [335] [SSPFormer: Self-Supervised Pretrained Transformer for MRI Images](https://arxiv.org/abs/2601.12747)
*Jingkai Li,Xiaoze Tian,Yuhang Shen,Jia Wang,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出SSPFormer自监督预训练Transformer用于MRI图像，通过逆频率投影掩码和频率加权FFT噪声增强解决医学图像领域适应和数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 预训练Transformer在自然图像处理中表现出色，但直接迁移到MRI图像面临两个关键挑战：1) 无法适应医学解剖结构的特异性；2) 医学数据的隐私性和稀缺性限制。需要开发能够学习医学图像领域特定特征表示的自监督方法。

Method: 提出SSPFormer自监督预训练Transformer，包含两个核心策略：1) 逆频率投影掩码：优先重建高频解剖区域，强制结构感知表示学习；2) 频率加权FFT噪声增强：在傅里叶域注入生理真实的噪声，增强对真实MRI伪影的鲁棒性。

Result: 在分割、超分辨率和去噪任务上的广泛实验表明，SSPFormer实现了最先进的性能，充分验证了其捕获细粒度MRI图像保真度和适应临床需求的能力。

Conclusion: SSPFormer通过自监督学习直接从原始扫描中学习领域不变和伪影鲁棒的特征，为医学图像分析提供了有效的预训练Transformer解决方案。

Abstract: The pre-trained transformer demonstrates remarkable generalization ability in natural image processing. However, directly transferring it to magnetic resonance images faces two key challenges: the inability to adapt to the specificity of medical anatomical structures and the limitations brought about by the privacy and scarcity of medical data. To address these issues, this paper proposes a Self-Supervised Pretrained Transformer (SSPFormer) for MRI images, which effectively learns domain-specific feature representations of medical images by leveraging unlabeled raw imaging data. To tackle the domain gap and data scarcity, we introduce inverse frequency projection masking, which prioritizes the reconstruction of high-frequency anatomical regions to enforce structure-aware representation learning. Simultaneously, to enhance robustness against real-world MRI artifacts, we employ frequency-weighted FFT noise enhancement that injects physiologically realistic noise into the Fourier domain. Together, these strategies enable the model to learn domain-invariant and artifact-robust features directly from raw scans. Through extensive experiments on segmentation, super-resolution, and denoising tasks, the proposed SSPFormer achieves state-of-the-art performance, fully verifying its ability to capture fine-grained MRI image fidelity and adapt to clinical application requirements.

</details>


### [336] [Towards Unbiased Source-Free Object Detection via Vision Foundation Models](https://arxiv.org/abs/2601.12765)
*Zhi Cai,Yingjie Gao,Yanan Zhang,Xinzhu Ma,Di Huang*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出DSOD框架解决源自由目标检测中的源偏置问题，通过VFM辅助的特征注入和正则化，在多个跨域任务上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有源自由目标检测方法存在源偏置问题，即适应后的模型仍然偏向源域特征，导致泛化能力差和自训练过程中的错误累积。需要解决这一挑战以实现更好的跨域适应。

Method: 提出DSOD框架：1) 统一特征注入模块，通过简单尺度扩展和域感知自适应加权将VFM特征集成到CNN骨干网络；2) 语义感知特征正则化，约束特征学习防止过拟合源域特征；3) 提出VFM-free变体DSOD-distill，通过双教师蒸馏方案适应计算受限场景。

Result: 在多个基准测试中优于现有SOTA方法：在正常到雾天天气适应上达到48.1% AP，跨场景适应达到39.3% AP，合成到真实适应达到61.4% AP。

Conclusion: DSOD框架有效缓解了源自由目标检测中的源偏置问题，通过VFM辅助的特征增强和正则化机制，在多种跨域适应任务上取得了显著性能提升，同时提供了计算受限场景下的蒸馏变体。

Abstract: Source-Free Object Detection (SFOD) has garnered much attention in recent years by eliminating the need of source-domain data in cross-domain tasks, but existing SFOD methods suffer from the Source Bias problem, i.e. the adapted model remains skewed towards the source domain, leading to poor generalization and error accumulation during self-training. To overcome this challenge, we propose Debiased Source-free Object Detection (DSOD), a novel VFM-assisted SFOD framework that can effectively mitigate source bias with the help of powerful VFMs. Specifically, we propose Unified Feature Injection (UFI) module that integrates VFM features into the CNN backbone through Simple-Scale Extension (SSE) and Domain-aware Adaptive Weighting (DAAW). Then, we propose Semantic-aware Feature Regularization (SAFR) that constrains feature learning to prevent overfitting to source domain characteristics. Furthermore, we propose a VFM-free variant, termed DSOD-distill for computation-restricted scenarios through a novel Dual-Teacher distillation scheme. Extensive experiments on multiple benchmarks demonstrate that DSOD outperforms state-of-the-art SFOD methods, achieving 48.1% AP on Normal-to-Foggy weather adaptation, 39.3% AP on Cross-scene adaptation, and 61.4% AP on Synthetic-to-Real adaptation.

</details>


### [337] [Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval](https://arxiv.org/abs/2601.12768)
*Zequn Xie,Boyun Zhang,Yuxiao Lin,Tao Jin*

Main category: cs.CV

Relevance: 35.0

TL;DR: HVP-Net通过从视觉编码器的多个中间层提取和精炼特征，挖掘更丰富的视频语义，缓解视频冗余问题，在视频文本检索任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练模型（如CLIP）的视频文本检索方法存在两个主要问题：1）视频固有的冗余性；2）依赖粗糙的最终层特征，限制了匹配精度。

Method: 提出HVP-Net（分层视觉感知网络），从视觉编码器的多个中间层提取特征，在不同语义层次上从原始patch-tokens中逐步蒸馏出显著的视觉概念，缓解冗余同时保留对齐的关键细节。

Result: 在MSRVTT、DiDeMo和ActivityNet等具有挑战性的基准测试中取得了新的最先进性能。

Conclusion: 验证了利用分层特征提升视频文本检索的有效性，为视频表示学习提供了新思路。

Abstract: Video-text retrieval (VTR) aims to locate relevant videos using natural language queries. Current methods, often based on pre-trained models like CLIP, are hindered by video's inherent redundancy and their reliance on coarse, final-layer features, limiting matching accuracy. To address this, we introduce the HVP-Net (Hierarchical Visual Perception Network), a framework that mines richer video semantics by extracting and refining features from multiple intermediate layers of a vision encoder. Our approach progressively distills salient visual concepts from raw patch-tokens at different semantic levels, mitigating redundancy while preserving crucial details for alignment. This results in a more robust video representation, leading to new state-of-the-art performance on challenging benchmarks including MSRVTT, DiDeMo, and ActivityNet. Our work validates the effectiveness of exploiting hierarchical features for advancing video-text retrieval. Our codes are available at https://github.com/boyun-zhang/HVP-Net.

</details>


### [338] [Open Vocabulary Panoptic Segmentation With Retrieval Augmentation](https://arxiv.org/abs/2601.12779)
*Nafis Sadeq,Qingfeng Liu,Mostafa El-Khamy*

Main category: cs.CV

Relevance: 35.0

TL;DR: RetCLIP：一种检索增强的开放词汇全景分割方法，通过构建掩码片段特征数据库，在推理时检索相似特征和类别标签，结合CLIP分数提升未见类别的分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统全景分割方法在训练数据集上表现良好，但难以泛化到未见类别。开放词汇全景分割旨在根据用户输入分割任意类别，需要解决模型对未见类别泛化能力不足的问题。

Method: 1. 使用配对图像-文本数据构建掩码片段特征数据库；2. 推理时使用输入图像的掩码片段特征作为查询键，从数据库中检索相似特征和相关类别标签；3. 基于查询特征与检索特征的相似度分配分类分数；4. 将检索分类分数与CLIP分数结合得到最终输出。

Result: 在COCO上训练后，在ADE20k数据集上达到30.9 PQ、19.3 mAP、44.0 mIoU，相比基线方法分别提升+4.5 PQ、+2.5 mAP、+10.0 mIoU。

Conclusion: RetCLIP通过检索增强机制显著提升了开放词汇全景分割中对未见类别的泛化能力，结合检索和CLIP的方法有效解决了传统方法泛化不足的问题。

Abstract: Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.

</details>


### [339] [AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection](https://arxiv.org/abs/2601.12994)
*Shiming Wang,Holger Caesar,Liangliang Nan,Julian F. P. Kooij*

Main category: cs.CV

Relevance: 35.0

TL;DR: AsyncBEV：一个可训练的轻量级模块，用于提高3D BEV目标检测模型对传感器异步的鲁棒性，通过估计特征流来对齐不同模态的特征图。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的多模态感知任务（如3D目标检测）通常依赖良好同步的传感器，但实际中完美同步很难保证。传感器可能以不同频率运行，网络延迟、硬件故障或处理瓶颈等因素会引入时间偏移，这种异步会降低感知性能，特别是对动态物体。

Method: 受场景流估计启发，AsyncBEV首先从两种不同传感器模态的BEV特征中估计2D流，考虑已知的时间偏移。然后使用预测的特征流来扭曲和对齐特征图。该方法可轻松集成到不同的BEV检测器架构中（如BEV网格基和token基）。

Result: 在token基的CMT和网格基的UniBEV上的大量实验表明，AsyncBEV提高了对LiDAR或相机传感器之间小和大异步的鲁棒性，特别是对动态物体。在0.5秒时间偏移的最坏情况下，动态物体的NDS分别比基线提高了16.6%和11.9%。

Conclusion: AsyncBEV是一个有效解决传感器异步问题的通用模块，可集成到现有BEV检测器中，显著提高对动态物体的检测性能，特别是在严重异步情况下。

Abstract: In autonomous driving, multi-modal perception tasks like 3D object detection typically rely on well-synchronized sensors, both at training and inference. However, despite the use of hardware- or software-based synchronization algorithms, perfect synchrony is rarely guaranteed: Sensors may operate at different frequencies, and real-world factors such as network latency, hardware failures, or processing bottlenecks often introduce time offsets between sensors. Such asynchrony degrades perception performance, especially for dynamic objects. To address this challenge, we propose AsyncBEV, a trainable lightweight and generic module to improve the robustness of 3D Birds' Eye View (BEV) object detection models against sensor asynchrony. Inspired by scene flow estimation, AsyncBEV first estimates the 2D flow from the BEV features of two different sensor modalities, taking into account the known time offset between these sensor measurements. The predicted feature flow is then used to warp and spatially align the feature maps, which we show can easily be integrated into different current BEV detector architectures (e.g., BEV grid-based and token-based). Extensive experiments demonstrate AsyncBEV improves robustness against both small and large asynchrony between LiDAR or camera sensors in both the token-based CMT and grid-based UniBEV, especially for dynamic objects. We significantly outperform the ego motion compensated CMT and UniBEV baselines, notably by $16.6$ % and $11.9$ % NDS on dynamic objects in the worst-case scenario of a $0.5 s$ time offset. Code will be released upon acceptance.

</details>


### [340] [Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups](https://arxiv.org/abs/2601.13094)
*Gelei Xu,Yuying Duan,Jun Xia,Ruining Deng,Wei Jin,Yiyu Shi*

Main category: cs.CV

Relevance: 35.0

TL;DR: HyperAdapt：一种患者条件适应框架，通过超网络模块生成残差调制参数，在保持共享诊断模型的同时改善亚组可靠性，特别适用于医疗诊断中的异质性患者群体。


<details>
  <summary>Details</summary>
Motivation: 医疗AI模型在不同患者群体中表现不均，现有公平性方法通过抑制敏感属性会降低准确性，而临床决策需要结合患者上下文信息进行诊断。

Method: 将临床相关属性编码为紧凑嵌入，通过超网络模块为共享骨干网络生成小规模残差调制参数，采用低秩和瓶颈参数化约束适应过程。

Result: 在多个医疗影像基准测试中，该方法持续改善亚组性能而不牺牲整体准确性，在PAD-UFES-20数据集上比最强基线提升4.1%召回率和4.4% F1分数。

Conclusion: HyperAdapt框架通过患者条件适应有效解决医疗AI中的亚组可靠性问题，在保持共享模型优势的同时实现针对性调整，对代表性不足的患者群体效果更显著。

Abstract: AI models for medical diagnosis often exhibit uneven performance across patient populations due to heterogeneity in disease prevalence, imaging appearance, and clinical risk profiles. Existing algorithmic fairness approaches typically seek to reduce such disparities by suppressing sensitive attributes. However, in medical settings these attributes often carry essential diagnostic information, and removing them can degrade accuracy and reliability, particularly in high-stakes applications. In contrast, clinical decision making explicitly incorporates patient context when interpreting diagnostic evidence, suggesting a different design direction for subgroup-aware models. In this paper, we introduce HyperAdapt, a patient-conditioned adaptation framework that improves subgroup reliability while maintaining a shared diagnostic model. Clinically relevant attributes such as age and sex are encoded into a compact embedding and used to condition a hypernetwork-style module, which generates small residual modulation parameters for selected layers of a shared backbone. This design preserves the general medical knowledge learned by the backbone while enabling targeted adjustments that reflect patient-specific variability. To ensure efficiency and robustness, adaptations are constrained through low-rank and bottlenecked parameterizations, limiting both model complexity and computational overhead. Experiments across multiple public medical imaging benchmarks demonstrate that the proposed approach consistently improves subgroup-level performance without sacrificing overall accuracy. On the PAD-UFES-20 dataset, our method outperforms the strongest competing baseline by 4.1% in recall and 4.4% in F1 score, with larger gains observed for underrepresented patient populations.

</details>


### [341] [A Streamlined Attention-Based Network for Descriptor Extraction](https://arxiv.org/abs/2601.13126)
*Mattia D'Urso,Emanuele Santellani,Christian Sormann,Mattia Rossi,Andreas Kuhn,Friedrich Fraundorfer*

Main category: cs.CV

Relevance: 35.0

TL;DR: SANDesc是一种基于注意力机制的轻量级描述符提取网络，可在不修改关键点检测器的情况下提升匹配性能，参数量仅240万。


<details>
  <summary>Details</summary>
Motivation: 现有关键点描述符提取架构存在改进空间，需要一种既能提升匹配性能又保持计算效率的轻量级解决方案。

Method: 采用改进的U-Net架构，结合卷积块注意力模块和残差路径，构建残差U-Net注意力块。使用改进的三元组损失和课程学习启发的困难负样本挖掘策略进行训练。

Result: 在HPatches、MegaDepth-1500和Image Matching Challenge 2021等基准测试中，SANDesc在现有关键点检测器上训练后，相比原始描述符在多个匹配任务上取得改进。同时提出了包含4K图像和预校准内参的新城市数据集。

Conclusion: SANDesc是一种高效轻量的描述符提取网络，能够在有限计算资源下显著提升匹配性能，同时贡献了新的评估数据集。

Abstract: We introduce SANDesc, a Streamlined Attention-Based Network for Descriptor extraction that aims to improve on existing architectures for keypoint description.
  Our descriptor network learns to compute descriptors that improve matching without modifying the underlying keypoint detector. We employ a revised U-Net-like architecture enhanced with Convolutional Block Attention Modules and residual paths, enabling effective local representation while maintaining computational efficiency. We refer to the building blocks of our model as Residual U-Net Blocks with Attention. The model is trained using a modified triplet loss in combination with a curriculum learning-inspired hard negative mining strategy, which improves training stability.
  Extensive experiments on HPatches, MegaDepth-1500, and the Image Matching Challenge 2021 show that training SANDesc on top of existing keypoint detectors leads to improved results on multiple matching tasks compared to the original keypoint descriptors. At the same time, SANDesc has a model complexity of just 2.4 million parameters.
  As a further contribution, we introduce a new urban dataset featuring 4K images and pre-calibrated intrinsics, designed to evaluate feature extractors. On this benchmark, SANDesc achieves substantial performance gains over the existing descriptors while operating with limited computational resources.

</details>


### [342] [PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain](https://arxiv.org/abs/2601.13128)
*Sung Ju Lee,Nam Ik Cho*

Main category: cs.CV

Relevance: 35.0

TL;DR: PhaseMark：一种单次、无优化的水印框架，通过在VAE潜在频域中直接调制相位，实现比优化方法快数千倍的速度，同时保持图像质量并抵抗严重攻击。


<details>
  <summary>Details</summary>
Motivation: 随着潜在扩散模型生成超真实图像的普及，需要强大的水印技术。现有的事后水印方法由于迭代优化或反演过程而速度极慢，无法满足实际应用需求。

Method: PhaseMark直接在VAE潜在频域中调制相位，无需优化过程。分析了四种调制变体，探索性能与质量之间的权衡关系。

Result: PhaseMark比基于优化的技术快数千倍，同时实现了最先进的抗攻击能力（包括再生攻击），且不降低图像质量。

Conclusion: PhaseMark展示了一种新范式：通过利用潜在表示的内在属性，实现高效、有弹性的水印技术。

Abstract: The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.

</details>


### [343] [GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning](https://arxiv.org/abs/2601.13132)
*Kim Yu-Ji,Dahye Lee,Kim Jun-Seong,GeonU Kim,Nam Hyeon-Woo,Yongjin Kwon,Yu-Chiang Frank Wang,Jaesung Choe,Tae-Hyun Oh*

Main category: cs.CV

Relevance: 35.0

TL;DR: GaussExplorer是一个基于3D高斯泼溅（3DGS）的具身探索与推理框架，通过集成视觉语言模型（VLMs）实现3D场景中的问题驱动探索和推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要问题：1）基于语言嵌入的3DGS方法只能处理简单文本查询，难以解释复杂的组合式语言查询；2）基于物体中心RGB-D结构化记忆的方法虽然提供空间基础，但受限于预固定的视角。需要一种能够处理复杂查询并支持灵活视角探索的3D场景理解方法。

Method: 在3DGS基础上集成视觉语言模型（VLMs），采用两步法：1）识别与查询问题最相关的预捕获图像；2）将这些图像调整到新的视角，以更准确地捕捉视觉信息供VLMs进行推理。实现了问题驱动的3D场景探索和推理。

Result: 在多个基准测试中优于现有方法，证明了将基于VLM的推理与3DGS集成对于具身任务的有效性。

Conclusion: GaussExplorer成功解决了现有方法的局限性，通过结合3DGS和VLMs实现了对复杂组合式语言查询的理解和灵活视角探索，为具身AI任务提供了有效的3D场景理解框架。

Abstract: We present GaussExplorer, a framework for embodied exploration and reasoning built on 3D Gaussian Splatting (3DGS). While prior approaches to language-embedded 3DGS have made meaningful progress in aligning simple text queries with Gaussian embeddings, they are generally optimized for relatively simple queries and struggle to interpret more complex, compositional language queries. Alternative studies based on object-centric RGB-D structured memories provide spatial grounding but are constrained by pre-fixed viewpoints. To address these issues, GaussExplorer introduces Vision-Language Models (VLMs) on top of 3DGS to enable question-driven exploration and reasoning within 3D scenes. We first identify pre-captured images that are most correlated with the query question, and subsequently adjust them into novel viewpoints to more accurately capture visual information for better reasoning by VLMs. Experiments show that ours outperforms existing methods on several benchmarks, demonstrating the effectiveness of integrating VLM-based reasoning with 3DGS for embodied tasks.

</details>


### [344] [CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks](https://arxiv.org/abs/2601.13133)
*Mingshuang Luo,Ruibing Hou,Bo Chao,Hong Chang,Zimo Liu,Yaowei Wang,Shiguang Shan*

Main category: cs.CV

Relevance: 35.0

TL;DR: CLASP是一个用于以人为中心的视觉任务的无监督预训练框架，利用CLIP生成多级语义伪标签，并通过提示控制的MoE模块动态适应不同下游任务的需求。


<details>
  <summary>Details</summary>
Motivation: 随着大规模无标签人体图像数据集的涌现，需要一种通用的无监督预训练模型来支持多样化的以人为中心的下游任务。现有方法缺乏对不同任务所需语义粒度的适应性。

Method: 1) 利用CLIP生成低层（身体部位）和高层（属性）语义伪标签；2) 设计提示控制的混合专家模块动态适应任务需求；3) 采用多任务预训练策略，整合部位和属性级伪标签指导表示学习。

Result: 在多个基准测试上的广泛实验表明，CLASP在无监督预训练方法中表现优异，提升了以人为中心的视觉分析性能。

Conclusion: CLASP通过整合多级语义线索和任务自适应机制，为以人为中心的视觉任务提供了一个强大且通用的无监督预训练框架。

Abstract: Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.

</details>


### [345] [From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models](https://arxiv.org/abs/2601.13166)
*Pedro M. Gordaliza,Jaume Banus,Benoît Gérin,Maxence Wynen,Nataliia Molchanova,Jonas Richiardi,Meritxell Bach Cuadra*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一种用于3D脑MRI分析的医学影像基础模型，在MICCAI 2025的SSL3D和FOMO25挑战赛中均获得第一名。该方法采用U-Net CNN架构，结合解剖学先验和神经影像领域知识，相比基于Transformer的方法训练速度快1-2个数量级，模型小10倍。


<details>
  <summary>Details</summary>
Motivation: 开发医学影像分析的基础模型对于解决放射学任务的独特挑战至关重要。针对3D脑MRI分析，需要克服数据标注稀缺、计算资源有限等实际问题，同时要有效利用医学领域的解剖学先验知识。

Method: 采用U-Net CNN架构，结合解剖学先验和神经影像领域知识策略。与主流的Transformer方法不同，该方法专注于更高效的架构设计，利用医学影像的特定领域知识来提升性能。

Result: 在MICCAI 2025的SSL3D和FOMO25两个3D脑MRI挑战赛中均获得第一名。模型训练速度比Transformer方法快1-2个数量级，模型大小仅为Transformer方法的1/10。

Conclusion: 对于医学影像分析任务，精心设计的CNN架构结合领域知识可以超越Transformer方法，在计算效率和模型大小方面具有显著优势，为医学影像基础模型的发展提供了新的方向。

Abstract: Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.

</details>


### [346] [Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising](https://arxiv.org/abs/2601.13208)
*Vikram R Lakkavalli*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出Additive U-Net，用可学习的门控加法连接替代传统的拼接跳跃连接，减少通道维度膨胀，提供对编码器贡献的显式可解释控制，在图像去噪任务中保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 传统U-Net架构中的拼接跳跃连接会加倍通道维度并模糊信息流，导致不受控制的噪声传递。需要更轻量、可解释的替代方案来改善多尺度信息传递。

Method: 用可学习的非负标量缩放的门控加法连接替代拼接跳跃连接。每个跳跃路径通过标量控制编码器贡献，避免通道膨胀，同时保持模型学习从高频到低频特征的渐进能力。

Result: 在Kodak-17去噪基准测试中，在噪声水平σ=15,25,50下达到竞争性的PSNR/SSIM性能，对不同核调度和深度具有鲁棒性。即使没有显式下采样/上采样或强制层次结构，模型也能自然学习特征渐进。

Conclusion: 加法跳跃连接是拼接连接的轻量且可解释的替代方案，既能实现高效设计，又能更清晰地理解重建网络中的多尺度信息传递。

Abstract: Skip connections are central to U-Net architectures for image denoising, but standard concatenation doubles channel dimensionality and obscures information flow, allowing uncontrolled noise transfer. We propose the Additive U-Net, which replaces concatenative skips with gated additive connections. Each skip pathway is scaled by a learnable non-negative scalar, offering explicit and interpretable control over encoder contributions while avoiding channel inflation. Evaluations on the Kodak-17 denoising benchmark show that Additive U-Net achieves competitive PSNR/SSIM at noise levels σ = 15, 25, 50, with robustness across kernel schedules and depths. Notably, effective denoising is achieved even without explicit down/up-sampling or forced hierarchies, as the model naturally learns a progression from high-frequency to band-pass to low-frequency features. These results position additive skips as a lightweight and interpretable alternative to concatenation, enabling both efficient design and a clearer understanding of multi-scale information transfer in reconstruction networks.

</details>


### [347] [ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments](https://arxiv.org/abs/2601.13218)
*Igor Vozniak,Philipp Mueller,Nils Lipp,Janis Sprenger,Konstantin Poddubnyy,Davit Hovhannisyan,Christian Mueller,Andreas Bulling,Philipp Slusallek*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出了一个用于评估基于对象的视觉注意力的新数据集和度量标准，并开发了基于Mamba U-Net的模型SUMGraph，在街道导航场景中实现了更好的注意力预测性能。


<details>
  <summary>Details</summary>
Motivation: 人类视觉注意力具有基于对象的特性，但在计算视觉注意力模型中很少被考虑，主要原因是缺乏合适的数据集和评估指标。特别是在街道导航等安全关键场景中，收集真实世界数据存在伦理和安全挑战。

Method: 1) 创建了包含120名参与者的虚拟现实街道导航数据集，提供精确的注视数据、完整的状态空间表示、全景分割、深度信息和车辆关键点等丰富标注；2) 提出了基于对象的相似度度量oSIM；3) 开发了SUMGraph模型，基于Mamba U-Net架构，将关键场景对象（车辆）编码为图表示。

Result: 实验表明，显式优化基于对象的注意力不仅提高了oSIM性能，还改善了模型在常见指标上的表现。SUMGraph模型在多个最先进的视觉注意力预测方法上取得了进一步的性能提升。

Conclusion: 该工作填补了基于对象的视觉注意力研究的空白，提供了首个专门用于此目的的数据集和评估指标，并展示了基于对象的建模方法在视觉注意力预测中的有效性。数据集、代码和模型将公开发布。

Abstract: The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.

</details>


### [348] [Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams](https://arxiv.org/abs/2601.13299)
*Ethan Seefried,Prahitha Movva,Naga Harshita Marupaka,Tilak Kasturi,Tirthankar Ghosal*

Main category: cs.CV

Relevance: 35.0

TL;DR: Enginuity是首个开放、大规模、多领域的工程图数据集，包含全面的结构标注，旨在实现自动化图表解析，支持多模态大语言模型处理工程图相关任务。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在科学发现工作流程中存在根本性障碍，无法充分理解和操作工程图中的视觉-结构知识。工程图在科学工作流程中至关重要，但缺乏大规模、多领域、结构标注的数据集限制了多模态LLM在工程图解析、跨模态信息检索等下游任务中的应用。

Method: 创建Enginuity数据集：1) 大规模收集多领域工程图；2) 提供全面的结构标注，包括层次化组件关系、连接关系和语义元素；3) 设计用于支持多模态大语言模型训练和评估的数据格式。

Result: 提出了首个开放、大规模、多领域的工程图数据集，包含全面的结构标注，能够支持多模态LLM在结构化图表解析、跨模态信息检索和AI辅助工程仿真等关键下游任务。

Conclusion: Enginuity数据集将变革AI for Scientific Discovery领域，使AI系统能够理解和操作工程图中的视觉-结构知识，打破当前阻碍AI充分参与科学工作流程的根本障碍。

Abstract: We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.

</details>


### [349] [Practical Insights into Semi-Supervised Object Detection Approaches](https://arxiv.org/abs/2601.13380)
*Chaoxin Wang,Bharaneeshwar Balasubramaniyam,Anurag Sangem,Nicolais Guevara,Doina Caragea*

Main category: cs.CV

Relevance: 35.0

TL;DR: 本文对三种最先进的半监督目标检测方法（MixPL、Semi-DETR和Consistent-Teacher）进行了全面比较，分析了在有限标注数据下性能随标注图像数量变化的规律，并在MS-COCO、Pascal VOC和自定义甲虫数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 研究数据稀缺环境下的学习问题，特别是半监督目标检测（SSOD），旨在通过利用大量未标注图像和有限标注图像（少样本学习）来提高检测性能。了解不同SSOD方法在不同标注数据量下的性能变化规律。

Method: 对三种最先进的SSOD方法（MixPL、Semi-DETR和Consistent-Teacher）进行系统比较，在MS-COCO和Pascal VOC两个标准目标检测基准数据集上进行实验，同时在一个自定义的甲虫数据集上评估，分析性能随标注图像数量变化的规律。

Result: 研究发现不同方法在准确率、模型大小和延迟之间存在权衡，为低数据环境下选择最适合的方法提供了见解。实验揭示了这些方法在标准数据集和专用数据集上的性能差异。

Conclusion: 该研究为半监督目标检测在数据稀缺环境下的应用提供了实用指导，帮助研究人员根据具体需求（准确率、效率、数据特性）选择合适的方法。

Abstract: Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.

</details>


### [350] [Organ-Aware Attention Improves CT Triage and Classification](https://arxiv.org/abs/2601.13385)
*Lavsen Dahal,Yubraj Bhandari,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CV

Relevance: 35.0

TL;DR: ORACLE-CT：一种用于胸部CT分类的器官感知注意力模型，通过器官掩码注意力和器官标量融合技术，在CT-RATE和RADCHEST-CT数据集上实现了最先进的监督分类性能。


<details>
  <summary>Details</summary>
Motivation: 医疗影像（如CT）的高通量分类和分诊需求迫切，可改善患者护理并缓解放射科医生工作负担。现有视觉语言模型在处理3D解剖结构、协议变化和噪声报告监督方面存在困难。

Method: 提出ORACLE-CT：1）器官掩码注意力（器官特定池化提供空间证据）；2）器官标量融合（轻量级融合归一化体积和平均HU特征）。基于监督基线（全局平均池化头）构建。

Result: 胸部CT：ORACLE-CT在CT-RATE上AUROC达0.86；腹部CT：在MERLIN（30个发现）上，监督基线超过复现的零样本VLM基线，添加掩码注意力和标量融合后AUROC提升至0.85。

Conclusion: ORACLE-CT在统一评估协议下，在胸部和腹部CT分类中实现了最先进的监督分类性能，为医学影像分诊提供了有效解决方案。

Abstract: There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.

</details>


### [351] [Local-to-Global Logical Explanations for Deep Vision Models](https://arxiv.org/abs/2601.13404)
*Bhavan Vasu,Giuseppe Raffa,Prasad Tadepalli*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一种为黑盒图像分类模型生成可解释性解释的方法，使用人类可识别的原始概念构建单调析取范式逻辑公式，提供局部和全局解释。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在图像分类方面非常有效，但缺乏可解释性，难以理解其决策过程。需要为黑盒模型开发既能保持高保真度又具有人类可理解性的解释方法。

Method: 提出局部和全局解释方法，将解释表示为单调析取范式逻辑公式。局部解释针对单个图像，全局解释针对图像集合。还提出单调解释列表算法来处理多类别分类。使用人类可识别的原始概念构建解释。

Result: 在具有挑战性的视觉数据集上，该方法生成的解释在保持高保真度和覆盖度的同时，具有很好的可解释性。解释既简单易懂，又能准确反映黑盒模型的决策逻辑。

Conclusion: 该方法成功地为黑盒图像分类模型提供了可解释的解释，平衡了保真度和可理解性，有助于增强深度学习模型的可信度和透明度。

Abstract: While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.

</details>


### [352] [Using deep learning for predicting cleansing quality of colon capsule endoscopy images](https://arxiv.org/abs/2601.13412)
*Puneet Sharma,Kristian Dalsbø Hindberg,Benedicte Schelde-Olesen,Ulrik Deding,Esmaeil S. Nadimi,Jan-Matthias Braun*

Main category: cs.CV

Relevance: 35.0

TL;DR: 使用ResNet-18和结构化剪枝技术预测结肠胶囊内镜图像清洁质量，达到88%准确率和79%稀疏度，并评估多种可解释性方法


<details>
  <summary>Details</summary>
Motivation: 解决结肠胶囊内镜图像清洁质量评估的挑战，提高模型效率同时保持性能，并增强临床应用中的可解释性

Method: 使用ResNet-18模型，采用分层K折交叉验证，应用结构化剪枝技术优化模型，使用Grad-CAM等多种方法进行可解释性分析，采用ROAD方法评估，最后使用自适应温度缩放进行校准

Result: 剪枝后模型达到88%交叉验证准确率，79%稀疏度，相比未剪枝模型84%准确率有所提升，同时保持了高效性

Conclusion: 结构化剪枝能有效提高模型效率而不牺牲性能，可解释性在临床应用中至关重要，ROAD方法在特定任务中存在挑战

Abstract: In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.

</details>


### [353] [SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement](https://arxiv.org/abs/2601.13417)
*Yujian Xiong,Xuanzhao Dong,Wenhui Zhu,Xin Li,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出SGW-GAN框架，将切片Gromov Wasserstein距离融入视网膜图像增强，在保持类内几何结构的同时降低计算成本，优于传统GAN和扩散方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于GAN和扩散的视网膜图像增强方法虽然改善了感知质量，但会扭曲类内几何结构，导致临床相关样本分散、疾病类别边界模糊，损害下游诊断任务。Gromov Wasserstein距离能通过内部成对距离对齐分布来保持类内结构，但计算成本过高限制了实际应用。

Method: 提出SGW-GAN框架，首次将切片Gromov Wasserstein距离融入视网膜图像增强。SGW通过随机投影近似GW距离，在保留关系保真度的同时大幅降低计算成本。框架用于无配对医学图像增强。

Result: 在公共数据集上的实验表明，SGW-GAN能产生视觉上令人信服的增强效果，在糖尿病视网膜病变分级任务上表现优异，并在疾病标签上报告最低的GW距离，展示了效率和临床保真度。

Conclusion: SGW-GAN成功解决了传统增强方法扭曲类内几何结构的问题，通过高效计算GW距离实现了既保持临床相关性又具有视觉质量的视网膜图像增强，为无配对医学图像增强提供了新方案。

Abstract: Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.

</details>


### [354] [Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation](https://arxiv.org/abs/2601.13440)
*Mohit Kakda,Mirudula Shri Muthukumaran,Uttapreksha Patel,Lawrence Swaminathan Xavier Prince*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文系统分析了基于视觉语言模型（VLMs）的异常检测方法，重点研究了CLIP在零样本和少样本异常分类与分割中的应用，比较了不同架构范式在多个维度上的表现。


<details>
  <summary>Details</summary>
Motivation: 传统异常检测方法需要大量标注数据和特定任务训练，而视觉语言模型通过学习图像和文本的对齐表示，能够实现零样本/少样本异常检测，无需缺陷样本或任务特定训练，这为工业质量控制提供了更高效的解决方案。

Method: 系统研究了三种主要架构范式：1) 基于滑动窗口的密集特征提取（WinCLIP）；2) 多阶段特征对齐与可学习投影（AprilLab框架）；3) 组合提示集成策略。在MVTec AD和VisA等基准上评估了特征提取机制、文本-视觉对齐策略、提示工程技术、零样本与少样本权衡、计算效率和跨域泛化能力。

Result: 通过严格的实验比较了分类精度、分割精度和推理效率，提供了关于VLM在异常检测中成功原因的基础理解，为方法选择提供了实用见解，并识别了当前局限性。

Conclusion: 该工作为工业质量控制中基于VLM的方法的明智采用提供了指导，并指出了未来研究方向，强调了VLM在零样本/少样本异常检测中的潜力及其实际应用价值。

Abstract: Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.

</details>


### [355] [Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging](https://arxiv.org/abs/2601.13498)
*Nimrod Kruger,Nicholas Owen Ralph,Gregory Cohen,Paul Hurley*

Main category: cs.CV

Relevance: 35.0

TL;DR: 论文提出了一种将事件视觉传感器（神经形态相机）数据与计算成像模型相结合的物理基础处理框架，通过将事件流映射到对数强度和强度导数估计，并嵌入动态线性系统模型，实现直接从事件数据进行逆滤波。


<details>
  <summary>Details</summary>
Motivation: 事件视觉传感器输出稀疏、异步的事件流，具有微秒级感知、高动态范围和低数据带宽的优点，但其非线性表示难以与大多数计算成像和光学系统设计所依赖的线性前向模型集成。需要建立事件传感与基于模型的计算成像之间的桥梁。

Method: 提出物理基础处理管道：1) 将事件流映射到像素级对数强度和强度导数估计；2) 将这些测量嵌入具有时变点扩散函数的动态线性系统模型；3) 使用已知（或参数化）动态传递函数的频域维纳反卷积，直接从事件数据进行逆滤波。

Result: 在模拟中验证了调制离焦下单点和重叠点源的情况，并在真实事件数据（可调焦望远镜观测星场）上进行了验证，展示了源定位和可分离性。

Conclusion: 该框架为动态光学系统中的事件传感与基于模型的计算成像提供了实用桥梁，使事件数据能够直接用于逆滤波和计算成像任务。

Abstract: Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.

</details>


### [356] [DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities](https://arxiv.org/abs/2601.13502)
*Nhi Kieu,Kien Nguyen,Arnold Wiliem,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

Relevance: 35.0

TL;DR: DIS2：针对遥感多模态学习中模态缺失问题的新范式，通过DLKD（解缠学习与知识蒸馏协同）和类特定特征学习模块，实现主动引导的缺失特征补偿。


<details>
  <summary>Details</summary>
Motivation: 遥感多模态学习面临模态缺失的严重挑战，且数据高度异构、尺度变化巨大。传统跨域方法（如依赖模态不变特征的解缠学习、知识蒸馏）在遥感领域失效，因为模态间特征重叠少，知识蒸馏变成病态的模仿任务，无法解决语义鸿沟。

Method: 提出DIS2方法，基于三个支柱：1）原则性缺失信息补偿；2）类特定模态贡献；3）多分辨率特征重要性。核心是DLKD（解缠学习与知识蒸馏协同），显式捕获补偿特征，与可用模态特征融合以近似完整模态表示。CFLM模块自适应学习每个目标的判别性证据。采用分层混合融合结构利用多分辨率特征。

Result: 在多个基准测试中，DIS2显著优于现有最先进方法。

Conclusion: DIS2从依赖模态共享特征和无目标模仿转向主动引导的缺失特征补偿，为遥感多模态学习中的模态缺失问题提供了有效解决方案。

Abstract: The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.

</details>


### [357] [Face-Voice Association with Inductive Bias for Maximum Class Separation](https://arxiv.org/abs/2601.13651)
*Marta Moscati,Oleksandr Kats,Mubashir Noman,Muhammad Zaigham Zaheer,Yufang Hou,Markus Schedl,Shah Nawaz*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一种在面部-语音关联任务中应用最大类别分离作为归纳偏置的新方法，通过强制不同说话者的多模态表示之间实现最大类别分离来增强嵌入的判别能力。


<details>
  <summary>Details</summary>
Motivation: 面部-语音关联是多模态学习中的重要研究领域，传统方法使用损失函数来确保同一人的面部和语音嵌入接近而不同人的分离。然而，分类领域的最新进展表明，通过施加最大类别分离作为归纳偏置可以显著增强嵌入的判别能力，这种方法在面部-语音关联领域尚未被探索。

Method: 开发了一种面部-语音关联方法，将不同说话者多模态表示之间的最大类别分离作为归纳偏置。该方法结合了类间正交性损失，通过强制不同说话者的表示在嵌入空间中实现最大分离来增强判别能力。

Result: 该方法在两个面部-语音关联任务上实现了最先进的性能。消融研究表明，当归纳偏置与类间正交性损失结合时效果最佳，证明了最大类别分离作为归纳偏置在多模态学习中的有效性。

Conclusion: 这是首次在多模态学习中应用并证明最大类别分离作为归纳偏置的有效性，为建立新的多模态学习范式铺平了道路。

Abstract: Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm.

</details>


### [358] [Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging](https://arxiv.org/abs/2601.13677)
*Carsten T. Lüth,Jeremias Traub,Kim-Celine Kahl,Till J. Bungert,Lukas Klein,Lars Krämer,Paul F. Jäger,Klaus Maier-Hein,Fabian Isensee*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出ClaSP PE方法解决3D生物医学图像分割中主动学习的两个关键问题：类别不平衡和早期选择冗余，在24个实验设置中显著优于随机基线


<details>
  <summary>Details</summary>
Motivation: 3D生物医学图像分割的专家标注成本高昂，现有主动学习方法无法在3D数据上稳定优于改进的随机采样基线，需要可靠解决方案

Method: ClaSP PE结合类别分层查询确保欠表示结构的覆盖，以及带衰减调度的对数尺度功率噪声来强制早期查询多样性并鼓励后期利用

Result: 在nnActive基准测试的24个实验设置中，ClaSP PE是唯一在分割质量和标注效率方面均显著优于改进随机基线的方法，并在未见数据集上表现出稳健泛化能力

Conclusion: ClaSP PE首次证明主动学习方法可以在3D分割任务中一致优于随机基线，开源实现和清晰部署指南使其易于实际应用

Abstract: Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive.

</details>


### [359] [HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection](https://arxiv.org/abs/2601.13751)
*Daniel Kyselica,Jonáš Herec,Oliver Kutis,Rado Pitoňák*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出HiT（历史注入Transformer）机制，用于卫星上的洪水检测，在保持检测精度的同时将历史数据存储减少99%以上，并在Jetson Orin Nano上达到43 FPS的实时性能。


<details>
  <summary>Details</summary>
Motivation: 自然灾害监测需要连续卫星观测，但小型卫星的内存和计算资源有限。洪水检测作为灾害管理的关键应用，需要能在星上运行的实时变化检测系统，减少对地面处理基础设施的依赖。

Method: 提出HiT（History Injection Transformer）机制，在Transformer模型中维护历史观测的上下文信息，同时将原始图像大小的数据存储减少99%以上。基于Prithvi-tiny基础模型构建HiT-Prithvi模型，在STTORM-CD洪水数据集上进行测试。

Result: HiT机制在Prithvi-tiny基础模型中保持了与双时相基线相当的检测精度。HiT-Prithvi模型在Jetson Orin Nano（纳米卫星代表性硬件）上达到43 FPS的实时性能。

Conclusion: 建立了卫星连续监测自然灾害的实用框架，支持实时灾害评估，无需依赖地面处理基础设施。为资源受限的卫星平台提供了高效的变化检测解决方案。

Abstract: Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection

</details>


### [360] [PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval](https://arxiv.org/abs/2601.13797)
*Gabriele Serussi,David Vainshtein,Jonathan Kouchly,Dotan Di Castro,Chaim Baskin*

Main category: cs.CV

Relevance: 35.0

TL;DR: PREGEN是一个高效的组合视频检索框架，通过冻结预训练的视觉语言模型并提取其隐藏状态，结合轻量级编码器生成紧凑的语义嵌入，无需微调VLM即可实现先进的检索性能。


<details>
  <summary>Details</summary>
Motivation: 当前组合视频检索方法未能充分利用现代视觉语言模型，要么使用过时架构，要么需要计算昂贵的微调和缓慢的标题生成。需要一种高效且强大的框架来克服这些限制。

Method: 提出PREGEN框架：1）使用冻结的预训练VLM处理查询视频和修改文本；2）提取每层最后一个token的隐藏状态；3）训练简单编码器在这些池化表示上，生成语义丰富且紧凑的检索嵌入。

Result: 在标准CoVR基准测试中显著超越所有先前方法，Recall@1提升+27.23和+69.59。在不同VLM骨干上表现出鲁棒性，对更复杂的文本修改具有强大的零样本泛化能力。

Conclusion: PREGEN通过有效利用预训练VLM而不需要微调，为组合视频检索提供了高效且强大的解决方案，展示了卓越的语义能力和泛化性能。

Abstract: Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities.

</details>


### [361] [Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation](https://arxiv.org/abs/2601.13852)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出Deep Discriminant Analysis (DDA)和Probabilistic DDA (PDDA)，通过深度网络直接优化Fisher准则，改进非线性可分数据的分类性能，并首次应用于图像分割任务。


<details>
  <summary>Details</summary>
Motivation: 线性判别分析(LDA)能提高类别可分性，但难以处理非线性可分数据。需要一种能利用深度网络优势、直接优化Fisher准则的方法来处理复杂数据分布。

Method: 提出DDA框架：1) 引入带符号的类间方差；2) 用sigmoid函数约束输出；3) 将乘法关系转换为加法关系。进一步提出PDDA：在DDA损失函数基础上增加概率损失，最小化输出分布的类别重叠。

Result: PDDA在风力叶片分割任务中表现出显著的性能提升和一致性改进，产生高度自信的预测并减少类内方差，对风能维护至关重要。

Conclusion: DDA和PDDA为处理非线性可分数据提供了稳定的深度判别分析方法，首次成功应用于图像分割领域，在风力叶片分割中展示了优越性能。

Abstract: Linear discriminant analysis improves class separability but struggles with non-linearly separable data. To overcome this, we introduce Deep Discriminant Analysis (DDA), which directly optimizes the Fisher criterion utilizing deep networks. To ensure stable training and avoid computational instabilities, we incorporate signed between-class variance, bound outputs with a sigmoid function, and convert multiplicative relationships into additive ones. We present two stable DDA loss functions and augment them with a probability loss, resulting in Probabilistic DDA (PDDA). PDDA effectively minimizes class overlap in output distributions, producing highly confident predictions with reduced within-class variance. When applied to wind blade segmentation, PDDA showcases notable advances in performance and consistency, critical for wind energy maintenance. To our knowledge, this is the first application of DDA to image segmentation.

</details>


### [362] [OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting](https://arxiv.org/abs/2601.13871)
*Michail Spanakis,Iason Oikonomidis,Antonis Argyros*

Main category: cs.CV

Relevance: 35.0

TL;DR: OCCAM是首个无需训练、无需额外信息的类无关目标计数方法，能够处理图像中多类别目标计数问题，基于SAM2和自定义FINCH算法实现。


<details>
  <summary>Details</summary>
Motivation: 现有类无关目标计数方法通常假设每张图像只有一个目标类别，需要大量训练数据，且依赖额外信息（如视觉示例或文本提示）。需要一种更通用、无需训练、无需额外信息的方法来解决多类别计数问题。

Method: 结合Segment Anything Model 2 (SAM2)基础模型和自定义阈值版本的First Integer Neighbor Clustering Hierarchy (FINCH)算法，无需训练即可实现多类别目标计数。

Result: 在FSC-147和CARPK基准数据集上取得有竞争力的性能，提出了合成多类别数据集和更适合的F1评分指标。

Conclusion: OCCAM证明了无需训练的基础模型方法在类无关目标计数任务中的有效性，为多类别计数问题提供了新解决方案。

Abstract: Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter.

</details>


### [363] [Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging](https://arxiv.org/abs/2601.13899)
*Masoumeh Javanbakhat,Piotr Komorowski,Dilyara Bareeva,Wei-Chang Lai,Wojciech Samek,Christoph Lippert*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出可解释的深度统计测试框架，为深度双样本测试提供样本级和特征级解释，识别驱动统计显著差异的样本和特征。


<details>
  <summary>Details</summary>
Motivation: 深度神经双样本测试在检测组间分布差异方面表现出强大能力，但其黑盒性质限制了在生物医学分析中的可解释性和实际应用。现有的事后解释方法大多依赖类别标签，不适用于无标签的统计测试场景。

Method: 提出可解释的深度统计测试框架，增强深度双样本测试的样本级和特征级解释能力。该方法能够识别哪些个体样本和哪些输入特征驱动了统计显著的组间差异，在医学影像数据中突出显示影响最大的样本和解剖学相关区域。

Result: 该框架能够突出显示哪些图像区域和哪些个体样本对检测到的组间差异贡献最大，提供空间和实例层面的洞察。应用于生物医学影像数据时，能够识别有影响力的样本并突出显示与疾病相关变异相关的解剖学意义区域。

Conclusion: 这项工作桥接了统计推断和可解释AI，实现了医学影像中可解释、无标签的群体分析。

Abstract: Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.

</details>


### [364] [TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation](https://arxiv.org/abs/2601.13935)
*Anoushkrit Goel,Simroop Singh,Ankita Joshi,Ranjeet Ranjan Jha,Chirag Ahuja,Aditya Nigam,Arnav Bhavsar*

Main category: cs.CV

Relevance: 35.0

TL;DR: TrackletGPT：一种用于白质纤维束分割的类语言GPT框架，通过引入轨迹片段（tracklets）重新引入序列信息，在跨数据集泛化、自动化和精细分割方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 白质纤维束分割对研究大脑结构连接性、神经系统疾病和神经外科至关重要。该任务复杂，因为纤维束在不同个体、条件和半球之间存在差异，但具有相似的3D结构。现有方法难以处理这些挑战。

Method: 提出TrackletGPT框架，将纤维束分割视为语言建模任务。使用轨迹片段（tracklets）作为token，重新引入序列信息。该方法能够跨数据集无缝泛化，完全自动化，并编码细粒度的子流线片段。

Result: 在TractoInferno和HCP数据集上，TrackletGPT在平均DICE、Overlap和Overreach分数上优于现有最先进方法，即使在跨数据集实验中也能保持优异性能。

Conclusion: TrackletGPT成功将GPT框架应用于纤维束分割任务，通过轨迹片段编码序列信息，实现了跨数据集泛化、自动化和精细分割，为脑连接研究提供了新工具。

Abstract: White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.

</details>


### [365] [DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging](https://arxiv.org/abs/2601.13954)
*Adrien Meyer,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

Relevance: 35.0

TL;DR: DExTeR是一个基于Transformer的点到框回归器，专门用于医学图像中的弱半监督目标检测，通过类引导可变形注意力、CLICK-MoE专家系统和多点训练策略，在三个医学数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像中的解剖标志检测对诊断和介入指导至关重要，但传统目标检测模型依赖昂贵的边界框标注，限制了可扩展性。弱半监督目标检测使用点标注来减少标注成本，但医学图像存在重叠解剖结构、可变对象大小和难以捉摸的结构等独特挑战，阻碍了准确的边界框推断。

Method: 基于Point-DETR构建，DExTeR将单点标注编码为对象查询，通过类引导可变形注意力改进特征提取，该注意力使用点坐标和类别标签来引导注意力采样以捕获类别特定特征。引入CLICK-MoE（类别、实例和通用知识混合专家）来解耦类别和实例表示，减少相邻或重叠实例之间的混淆。采用多点训练策略，促进不同点放置位置之间的一致性预测，提高对标注变化的鲁棒性。

Result: DExTeR在三个不同医学领域的数据集（内窥镜、胸部X光和内窥镜超声）上实现了最先进的性能，展示了在减少标注成本的同时保持高检测准确性的潜力。

Conclusion: DExTeR通过专门设计的Transformer架构和训练策略，有效解决了医学图像中弱半监督目标检测的挑战，为减少医学图像标注成本提供了有前景的解决方案。

Abstract: Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.

</details>


### [366] [STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames](https://arxiv.org/abs/2601.13974)
*Shih-Yao Lin*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出STEC（时空熵覆盖）指标，用于评估视频帧采样质量，关注采样帧是否能充分捕捉视频的时空信息，而非重建保真度。


<details>
  <summary>Details</summary>
Motivation: 现有视频帧采样评估指标主要关注感知质量或重建保真度，缺乏评估采样帧是否能充分捕捉视频信息内容和代表性的方法。需要一种任务无关的评估工具来分析帧采样行为。

Method: 基于时空帧熵（STFE）测量每帧的空间信息（基于熵的结构复杂度），通过联合建模空间信息强度、时间分散性和非冗余性，评估采样帧的时空覆盖和冗余度。

Result: 在MSR-VTT测试集上，STEC能清晰区分随机、均匀和内容感知等常见采样策略，并揭示平均性能无法捕捉的个体视频鲁棒性模式。

Conclusion: STEC提供了一个轻量级、原则性的帧采样质量评估指标，可作为通用评估工具用于高效视频理解，但并非设计用于预测下游任务准确性。

Abstract: Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content.
  We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality.
  Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding.
  We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.

</details>


### [367] [Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains](https://arxiv.org/abs/2601.13975)
*Marco Piccolo,Qiwei Han,Astrid van Toor,Joachim Vanneste*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文建立了一个统一信息管道，用于标准化异构海洋生物多样性数据集，评估跨域检测性能，发现场景结构因素比视觉退化对性能影响更大，并验证了在低成本边缘硬件上的可行性。


<details>
  <summary>Details</summary>
Motivation: 海洋生物多样性监测需要跨复杂水下环境的可扩展性和可靠性，以支持保护和入侵物种管理。现有检测解决方案在转移到新地点时性能会急剧下降，存在明显的部署差距。本研究旨在为北极和大西洋海洋生态系统的多年入侵物种监测计划建立基础检测层。

Method: 开发统一信息管道，将异构数据集标准化为可比信息流；在受控跨域协议下评估固定的部署相关检测器；分析结构因素（场景组成、物体密度、上下文冗余）与视觉退化（浑浊度）对性能的影响；在低成本边缘硬件上基准测试推理性能。

Result: 发现结构因素比视觉退化更能解释跨域性能损失，稀疏场景会引发特征性的"上下文崩溃"故障模式；通过运行时优化，在低成本边缘硬件上实现了实际采样率，验证了操作可行性。

Conclusion: 研究结果将重点从图像增强转向结构感知的可靠性，为一致的海洋生态系统评估提供了民主化工具，强调场景结构因素对跨域检测性能的关键影响。

Abstract: Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic "Context Collapse" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.

</details>


### [368] [Federated Balanced Learning](https://arxiv.org/abs/2601.14042)
*Jiaze Li,Haoran Xu,Wanyi Wu,Changwei Wang,Shuaiguang Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Youyang Qu,Longxiang Gao,Xudong Yang,Lumin Xing*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出Federated Balanced Learning (FBL)方法，通过在客户端进行样本平衡来防止非IID数据下的客户端漂移问题，使用边缘生成模型进行知识填充和知识采样，并设计了知识对齐和知识丢弃策略。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，非独立同分布(non-iid)数据会导致全局模型出现客户端漂移，严重影响最终性能。现有方法主要基于损失函数或梯度来纠正已经偏离的全局模型，忽略了客户端样本的影响。

Method: 提出FBL方法：1) 在客户端通过边缘生成模型进行知识填充和知识采样实现样本平衡；2) 设计知识对齐策略来弥合合成数据与真实数据之间的差距；3) 设计知识丢弃策略进行正则化；4) 扩展到真实复杂场景，允许不同客户端采用不同方法。

Result: 大量实验表明，该方法优于最先进的基线方法。

Conclusion: 通过从客户端样本平衡的角度出发，FBL方法能够有效防止联邦学习中的客户端漂移问题，在非IID设置下取得更好的性能。

Abstract: Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.

</details>


### [369] [Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration](https://arxiv.org/abs/2601.14060)
*Yongcong Ye,Kai Zhang,Yanghai Zhang,Enhong Chen,Longfei Li,Jun Zhou*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出CVSI方法，通过互补的视觉-语义集成实现细粒度零样本组合图像检索，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有ZS-CIR方法在捕捉细粒度变化和有效整合视觉与语义信息方面存在不足，主要依赖图像转文本或LLM生成描述，无法充分利用互补的视觉信息和完整的语义上下文

Method: CVSI包含三个关键组件：1) 视觉信息提取（提取全局特征+图像转伪标记+可能添加的对象）；2) 语义信息提取（预训练描述模型生成多个描述+LLM生成修改描述和可能添加的对象）；3) 互补信息检索（整合查询和数据库图像信息进行检索）

Result: 在CIRR、CIRCO和FashionIQ三个公开数据集上的实验表明，CVSI显著优于现有最先进方法

Conclusion: CVSI通过互补的视觉-语义集成有效解决了ZS-CIR中的细粒度变化捕捉问题，为组合图像检索提供了更强大的解决方案

Abstract: Zero-shot composed image retrieval (ZS-CIR) is a rapidly growing area with significant practical applications, allowing users to retrieve a target image by providing a reference image and a relative caption describing the desired modifications. Existing ZS-CIR methods often struggle to capture fine-grained changes and integrate visual and semantic information effectively. They primarily rely on either transforming the multimodal query into a single text using image-to-text models or employing large language models for target image description generation, approaches that often fail to capture complementary visual information and complete semantic context. To address these limitations, we propose a novel Fine-Grained Zero-Shot Composed Image Retrieval method with Complementary Visual-Semantic Integration (CVSI). Specifically, CVSI leverages three key components: (1) Visual Information Extraction, which not only extracts global image features but also uses a pre-trained mapping network to convert the image into a pseudo token, combining it with the modification text and the objects most likely to be added. (2) Semantic Information Extraction, which involves using a pre-trained captioning model to generate multiple captions for the reference image, followed by leveraging an LLM to generate the modified captions and the objects most likely to be added. (3) Complementary Information Retrieval, which integrates information extracted from both the query and database images to retrieve the target image, enabling the system to efficiently handle retrieval queries in a variety of situations. Extensive experiments on three public datasets (e.g., CIRR, CIRCO, and FashionIQ) demonstrate that CVSI significantly outperforms existing state-of-the-art methods. Our code is available at https://github.com/yyc6631/CVSI.

</details>


### [370] [PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning](https://arxiv.org/abs/2601.14111)
*Jiaying Wu,Can Gao,Jinglu Hu,Hui Li,Xiaofeng Cao,Jingcai Guo*

Main category: cs.CV

Relevance: 35.0

TL;DR: PMCE是一个概率少样本学习框架，利用多粒度语义和字幕引导增强来改进原型估计，通过结合类别级先验知识和实例级图像描述来提升少样本分类性能。


<details>
  <summary>Details</summary>
Motivation: 少样本学习中，仅从少量标注样本估计的原型往往存在偏差且泛化能力差。现有的语义方法主要应用于支持集侧，而查询表示保持不变，限制了性能提升。

Method: PMCE构建非参数知识库存储视觉统计量和CLIP编码的类别名嵌入。在元测试时，检索最相关的基类，将统计量聚合为类别特定先验信息并与支持集原型融合。同时使用冻结的BLIP字幕生成器提供无标签实例级图像描述，通过轻量级增强器优化支持原型和查询特征，并采用一致性正则化稳定噪声字幕。

Result: 在四个基准测试上，PMCE始终优于强基线方法，在MiniImageNet的1-shot设置中比最强的语义竞争对手获得高达7.71%的绝对增益提升。

Conclusion: PMCE通过结合多粒度语义信息和字幕引导增强，有效解决了少样本学习中原型估计偏差问题，显著提升了分类性能。

Abstract: Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D

</details>


### [371] [LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery](https://arxiv.org/abs/2601.14154)
*Shubham Pandey,Bhavin Jawade,Srirangaraj Setlur,Venu Govindaraju,Kenneth Seastedt*

Main category: cs.CV

Relevance: 35.0

TL;DR: MIRACLE是一个深度学习架构，用于预测肺癌手术后的并发症风险，通过整合术前临床和放射学数据，在球形嵌入空间融合异质输入，并包含可解释的干预模块。


<details>
  <summary>Details</summary>
Motivation: 术后并发症严重影响患者预后并增加医疗成本，需要更准确、可解释的风险预测方法来改善临床决策。

Method: 采用球形嵌入空间融合异质输入（结构化临床记录和高维放射学图像），包含干预式深度学习模块，提供可解释和可操作的见解，允许临床专家基于专业知识交互调整建议。

Result: 在包含3,094名肺癌患者的真实世界数据集POC-L上验证，MIRACLE优于传统机器学习模型和当代大型语言模型变体。

Conclusion: MIRACLE为个性化、可解释的术后风险管理提供了有效解决方案，通过融合多模态数据和可解释性模块提升了临床实用性。

Abstract: Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.

</details>


### [372] [One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion](https://arxiv.org/abs/2601.14161)
*Yitong Dong,Qi Zhang,Minchao Jiang,Zhiqiang Wu,Qingnan Fan,Ying Feng,Huaqi Zhang,Hujun Bao,Guofeng Zhang*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出了一种用于稀疏图像高保真新视角合成的框架，通过双域细节感知模块和特征引导扩散网络解决现有3D高斯泼溅方法在分辨率和一致性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有基于ViT的3D高斯泼溅方法受计算成本限制只能处理低分辨率输入，且现有生成增强方法往往是3D无关的，导致不同视角间结构不一致，特别是在未见区域。

Method: 设计了双域细节感知模块，使系统能处理高分辨率图像而不受ViT骨干网络限制；开发了特征引导扩散网络以在恢复过程中保持高频细节；提出了统一训练策略联合优化ViT几何骨干和扩散细化模块。

Result: 实验表明该方法在多个数据集上能保持优异的生成质量。

Conclusion: 该框架通过结合几何先验和生成细化，有效解决了稀疏图像新视角合成中的分辨率和一致性问题。

Abstract: We present a novel framework for high-fidelity novel view synthesis (NVS) from sparse images, addressing key limitations in recent feed-forward 3D Gaussian Splatting (3DGS) methods built on Vision Transformer (ViT) backbones. While ViT-based pipelines offer strong geometric priors, they are often constrained by low-resolution inputs due to computational costs. Moreover, existing generative enhancement methods tend to be 3D-agnostic, resulting in inconsistent structures across views, especially in unseen regions. To overcome these challenges, we design a Dual-Domain Detail Perception Module, which enables handling high-resolution images without being limited by the ViT backbone, and endows Gaussians with additional features to store high-frequency details. We develop a feature-guided diffusion network, which can preserve high-frequency details during the restoration process. We introduce a unified training strategy that enables joint optimization of the ViT-based geometric backbone and the diffusion-based refinement module. Experiments demonstrate that our method can maintain superior generation quality across multiple datasets.

</details>


### [373] [IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models](https://arxiv.org/abs/2601.14188)
*Liang Shi,Wei Li,Kevin M Beussman,Lin Chen,Yun Fu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出了IIR-VLM，一种增强视觉语言模型进行上下文实例级识别的方法，通过集成预训练的ILR专家模型作为辅助视觉编码器，实现单样本学习新实例


<details>
  <summary>Details</summary>
Motivation: 现代视觉语言模型在实例级识别任务上表现不佳，远低于领域特定的ILR模型，这限制了VLM在实际应用中的有效性，特别是在需要识别熟悉人物和物体的场景中

Method: 集成预训练的ILR专家模型作为辅助视觉编码器，提供专门的特征表示，使VLM能够以单样本方式在上下文中学习新实例，并利用这些知识进行实例感知的视觉理解

Result: 在现有实例个性化基准测试中验证了IIR-VLM的有效性，并在包含人物、面部、宠物和一般物体的新挑战性基准测试中展示了优越的ILR性能

Conclusion: IIR-VLM通过集成ILR专家模型有效提升了VLM的实例级识别能力，实现了单样本学习，为VLM的实际应用提供了更好的实例识别支持

Abstract: Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task.

</details>


### [374] [Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253)
*Hongyuan Chen,Xingyu Chen,Youjia Zhang,Zexiang Xu,Anpei Chen*

Main category: cs.CV

Relevance: 35.0

TL;DR: Motion 3-to-4：从单目视频和可选3D参考网格合成高质量4D动态物体的前馈框架，通过分解为静态3D形状生成和运动重建来解决4D合成难题


<details>
  <summary>Details</summary>
Motivation: 虽然2D、视频和3D内容生成已有显著进展，但4D合成仍面临挑战，主要原因是训练数据有限以及从单目视角恢复几何和运动存在固有模糊性

Method: 将4D合成分解为静态3D形状生成和运动重建，使用规范参考网格学习紧凑的运动潜在表示，预测逐帧顶点轨迹以恢复完整的时间一致几何，采用可扩展的逐帧Transformer处理不同序列长度

Result: 在标准基准测试和具有准确地面真实几何的新数据集上评估，Motion 3-to-4在保真度和空间一致性方面优于先前工作

Conclusion: 该框架有效解决了4D动态物体合成的关键挑战，通过分解策略和紧凑运动表示实现了高质量结果

Abstract: We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/.

</details>


### [375] [VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255)
*Sangbeom Lim,Seoung Wug Oh,Jiahui Huang,Heeji Yoon,Seungryong Kim,Joon-Young Lee*

Main category: cs.CV

Relevance: 35.0

TL;DR: VideoMaMa利用预训练视频扩散模型将粗分割掩码转换为精确alpha遮罩，在合成数据训练下实现真实视频的零样本泛化，并构建大规模伪标注视频遮罩数据集MA-V，提升模型在真实视频中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 视频遮罩标注数据稀缺，现有模型难以泛化到真实世界视频。需要开发能够利用合成数据和预训练模型的方法来解决数据稀缺问题，并构建大规模高质量视频遮罩数据集推动领域发展。

Method: 1) VideoMaMa：基于预训练视频扩散模型，将粗分割掩码转换为精确alpha遮罩；2) 构建MA-V数据集：利用VideoMaMa的可扩展伪标注流程，为5万+真实视频提供高质量遮罩标注；3) SAM2-Matte：在MA-V数据集上微调SAM2模型。

Result: 1) VideoMaMa在合成数据训练下实现真实视频的零样本泛化；2) 构建包含5万+视频的MA-V数据集；3) SAM2-Matte在真实视频上的鲁棒性优于现有遮罩数据集训练的模型。

Conclusion: 大规模伪标注视频遮罩数据集对提升模型鲁棒性至关重要，生成先验和可访问分割线索能够推动视频遮罩研究的可扩展进展。

Abstract: Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.

</details>


### [376] [An Efficient and Explainable KAN Framework forWireless Radiation Field Prediction](https://arxiv.org/abs/2601.11656)
*Jingzhou Shen,Xuyu Wang*

Main category: cs.NI

Relevance: 35.0

TL;DR: 该论文提出了一种新的无线信道建模方法，通过结合Kolmogorov-Arnold网络（KAN）和Transformer模块，学习完整射线的综合表示而非独立处理每个体素，从而更准确地捕捉环境特征。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络方法在处理无线信道建模时，独立处理射线上的每个体素，缺乏全局上下文和环境因素考虑，导致对复杂无线信号传播模式建模不够准确。

Method: 提出了一种结合Kolmogorov-Arnold网络（KAN）和Transformer模块的新架构，学习完整射线的综合表示，而非独立处理每个点，以捕捉更详细的环境特征。

Result: 实验结果表明，该方法在真实和合成场景中均优于现有方法，消融研究证实了模型各组成部分的有效性，额外实验提供了模型性能的清晰解释。

Conclusion: 通过整合KAN和Transformer学习完整射线表示的方法，能够更准确地建模无线信道，在保持计算效率的同时提高性能。

Abstract: Modeling wireless channels accurately remains a challenge due to environmental variations and signal uncertainties. Recent neural networks can learn radio frequency~(RF) signal propagation patterns, but they process each voxel on the ray independently, without considering global context or environmental factors. Our paper presents a new approach that learns comprehensive representations of complete rays rather than individual points, capturing more detailed environmental features. We integrate a Kolmogorov-Arnold network (KAN) architecture with transformer modules to achieve better performance across realistic and synthetic scenes while maintaining computational efficiency. Our experimental results show that this approach outperforms existing methods in various scenarios. Ablation studies confirm that each component of our model contributes to its effectiveness. Additional experiments provide clear explanations for our model's performance.

</details>


### [377] [Joint Source-Channel-Generation Coding: From Distortion-oriented Reconstruction to Semantic-consistent Generation](https://arxiv.org/abs/2601.12808)
*Tong Wu,Zhiyong Chen,Guo Lu,Li Song,Feng Yang,Meixia Tao,Wenjun Zhang*

Main category: cs.IT

Relevance: 35.0

TL;DR: 提出联合信源-信道-生成编码（JSCGC）新范式，将通信重点从确定性重构转向概率生成，利用接收端生成模型直接最大化互信息，显著提升感知质量和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 传统通信系统（包括分离编码和AI驱动的联合信源信道编码）主要基于香农率失真理论，但通用的失真度量无法捕捉复杂的人类视觉感知，导致重建图像模糊或不真实。

Method: 提出JSCGC范式，在接收端使用生成模型作为生成器而非传统解码器，参数化数据分布，在信道约束下直接最大化互信息，同时控制随机采样以产生位于真实数据流形上的高保真输出。推导了理论下界以阐明控制生成过程的通信基本极限。

Result: 在图像传输实验中，JSCGC显著提高了感知质量和语义保真度，明显优于传统的失真导向JSCC方法。

Conclusion: JSCGC为通信系统提供了新范式，通过将重点从确定性重构转向概率生成，能够更好地捕捉人类视觉感知，产生更真实、语义更准确的重建结果。

Abstract: Conventional communication systems, including both separation-based coding and AI-driven joint source-channel coding (JSCC), are largely guided by Shannon's rate-distortion theory. However, relying on generic distortion metrics fails to capture complex human visual perception, often resulting in blurred or unrealistic reconstructions. In this paper, we propose Joint Source-Channel-Generation Coding (JSCGC), a novel paradigm that shifts the focus from deterministic reconstruction to probabilistic generation. JSCGC leverages a generative model at the receiver as a generator rather than a conventional decoder to parameterize the data distribution, enabling direct maximization of mutual information under channel constraints while controlling stochastic sampling to produce outputs residing on the authentic data manifold with high fidelity. We further derive a theoretical lower bound on the maximum semantic inconsistency with given transmitted mutual information, elucidating the fundamental limits of communication in controlling the generative process. Extensive experiments on image transmission demonstrate that JSCGC substantially improves perceptual quality and semantic fidelity, significantly outperforming conventional distortion-oriented JSCC methods.

</details>


### [378] [DALD-PCAC: Density-Adaptive Learning Descriptor for Point Cloud Lossless Attribute Compression](https://arxiv.org/abs/2601.12261)
*Chunyang Fu,Ge Li,Wei Gao,Shiqi Wang,Zhu Li,Shan Liu*

Main category: eess.IV

Relevance: 35.0

TL;DR: DALD-PCAC：一种基于学习的点云无损属性压缩框架，利用层次细节（LoD）处理不同密度的点云，采用置换不变Transformer和密度自适应学习描述符实现高效压缩。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的点云几何压缩已有显著进展，但针对不同密度点云的无损属性压缩研究不足。点云的稀疏性和不规则性给上下文建模带来挑战，需要开发能够适应密度变化的压缩方法。

Method: 1. 基于层次细节（LoD）的框架设计；2. 使用置换不变Transformer的点级注意力模型处理稀疏和不规则性；3. 密度自适应学习描述符（DALD）捕捉大范围邻域内的结构和相关性；4. 先验引导的块划分减少块内属性方差。

Result: 在LiDAR和物体点云上的实验表明，DALD-PCAC在大多数数据上达到最先进的性能。方法提升了压缩性能，对点云密度变化具有鲁棒性，并在性能和复杂度之间取得了良好平衡。

Conclusion: DALD-PCAC为点云无损属性压缩提供了有效的学习框架，特别适合处理密度变化的点云，在实际应用中具有很大潜力。

Abstract: Recently, deep learning has significantly advanced the performance of point cloud geometry compression. However, the learning-based lossless attribute compression of point clouds with varying densities is under-explored. In this paper, we develop a learning-based framework, namely DALD-PCAC that leverages Levels of Detail (LoD) to tailor for point cloud lossless attribute compression. We develop a point-wise attention model using a permutation-invariant Transformer to tackle the challenges of sparsity and irregularity of point clouds during context modeling. We also propose a Density-Adaptive Learning Descriptor (DALD) capable of capturing structure and correlations among points across a large range of neighbors. In addition, we develop a prior-guided block partitioning to reduce the attribute variance within blocks and enhance the performance. Experiments on LiDAR and object point clouds show that DALD-PCAC achieves the state-of-the-art performance on most data. Our method boosts the compression performance and is robust to the varying densities of point clouds. Moreover, it guarantees a good trade-off between performance and complexity, exhibiting great potential in real-world applications. The source code is available at https://github.com/zb12138/DALD_PCAC.

</details>


### [379] [OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization](https://arxiv.org/abs/2601.12291)
*Jianhao Jiao,Changkun Liu,Jingwen Yu,Boyi Liu,Qianyi Zhang,Yue Wang,Dimitrios Kanoulas*

Main category: cs.RO

Relevance: 35.0

TL;DR: OPENNAVMAP：基于3D几何基础模型的轻量级无结构拓扑系统，用于机器人视觉导航中的可扩展地图表示和多会话建图对齐


<details>
  <summary>Details</summary>
Motivation: 传统基于结构的方法在无特征环境或显著视角变化下表现不佳，且维护成本高。需要一种轻量级、无需预建3D模型的方法来实现大规模视觉导航和机器人部署。

Method: 提出结构自由的拓扑系统，利用3D几何基础模型进行按需重建。统一了基于动态规划的序列匹配、几何验证和置信度校准优化，实现从粗到精的子图对齐。

Result: 在Map-Free基准测试中优于传统方法，平均平移误差0.62m。在15km多会话数据中保持全局一致性，绝对轨迹误差低于3m。在模拟和物理机器人上完成12次自主图像目标导航任务。

Conclusion: OPENNAVMAP提供了一种高效、鲁棒的视觉导航地图表示方法，无需预建3D模型，在真实环境中具有实际应用价值。

Abstract: Scalable and maintainable map representations are fundamental to enabling large-scale visual navigation and facilitating the deployment of robots in real-world environments. While collaborative localization across multi-session mapping enhances efficiency, traditional structure-based methods struggle with high maintenance costs and fail in feature-less environments or under significant viewpoint changes typical of crowd-sourced data. To address this, we propose OPENNAVMAP, a lightweight, structure-free topometric system leveraging 3D geometric foundation models for on-demand reconstruction. Our method unifies dynamic programming-based sequence matching, geometric verification, and confidence-calibrated optimization to robust, coarse-to-fine submap alignment without requiring pre-built 3D models. Evaluations on the Map-Free benchmark demonstrate superior accuracy over structure-from-motion and regression baselines, achieving an average translation error of 0.62m. Furthermore, the system maintains global consistency across 15km of multi-session data with an absolute trajectory error below 3m for map merging. Finally, we validate practical utility through 12 successful autonomous image-goal navigation tasks on simulated and physical robots. Code and datasets will be publicly available in https://rpl-cs-ucl.github.io/OpenNavMap_page.

</details>


### [380] [Data-Consistent Learning of Inverse Problems](https://arxiv.org/abs/2601.12831)
*Markus Haltmeier,Gyeongha Hwang*

Main category: math.NA

Relevance: 35.0

TL;DR: DC网络通过将测量模型嵌入网络架构，结合经典正则化与数据驱动学习，为逆问题提供理论可靠且视觉质量高的重建方法。


<details>
  <summary>Details</summary>
Motivation: 解决逆问题中经典正则化方法（理论可靠但灵活性/视觉质量有限）与学习重建方法（视觉效果好但缺乏理论保证）之间的差距。

Method: 提出DC网络，通过零空间网络结合经典正则化方法作为初始重建，在网络架构中强制执行测量模型，形成收敛的正则化方法。

Result: 该方法既保持了经典方案的理论可靠性，又利用了数据驱动学习的表达能力，产生既准确又视觉吸引人的重建结果。

Conclusion: DC网络为逆问题重建提供了理论严谨且实用的框架，弥合了传统方法与深度学习之间的鸿沟。

Abstract: Inverse problems are inherently ill-posed, suffering from non-uniqueness and instability. Classical regularization methods provide mathematically well-founded solutions, ensuring stability and convergence, but often at the cost of reduced flexibility or visual quality. Learned reconstruction methods, such as convolutional neural networks, can produce visually compelling results, yet they typically lack rigorous theoretical guarantees. DC (DC) networks address this gap by enforcing the measurement model within the network architecture. In particular, null-space networks combined with a classical regularization method as an initial reconstruction define a convergent regularization method. This approach preserves the theoretical reliability of classical schemes while leveraging the expressive power of data-driven learning, yielding reconstructions that are both accurate and visually appealing.

</details>


### [381] [Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning](https://arxiv.org/abs/2601.12894)
*Kangye Ji,Yuan Meng,Zhou Jianbo,Ye Li,Hanyun Cui,Zhi Wang*

Main category: cs.RO

Relevance: 35.0

TL;DR: SAG（稀疏动作生成）提出了一种用于机器人实时视觉运动控制的稀疏动作生成方法，通过自适应剪枝和重用机制加速扩散策略，实现4倍速度提升而不损失性能。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在动作生成方面表现出色，但其多步去噪过程导致实时性不足。现有缓存加速方法使用静态调度，无法适应机器人-环境交互的动态变化，导致性能下降。

Method: SAG采用rollout-adaptive prune-then-reuse机制：1）全局识别可剪枝计算；2）重用缓存激活值替代剪枝计算；3）参数化观察条件扩散剪枝器进行环境感知适应；4）使用zig-zag方式跨时间步和块重用激活值。

Result: 在多个机器人基准测试中，SAG实现了高达4倍的动作生成加速，同时保持了与原始扩散策略相当的性能。

Conclusion: SAG通过自适应剪枝和重用机制，有效解决了扩散策略在实时机器人控制中的计算效率问题，为实时视觉运动控制提供了实用解决方案。

Abstract: Diffusion Policy has dominated action generation due to its strong capabilities for modeling multi-modal action distributions, but its multi-step denoising processes make it impractical for real-time visuomotor control. Existing caching-based acceleration methods typically rely on $\textit{static}$ schedules that fail to adapt to the $\textit{dynamics}$ of robot-environment interactions, thereby leading to suboptimal performance. In this paper, we propose $\underline{\textbf{S}}$parse $\underline{\textbf{A}}$ction$\underline{\textbf{G}}$en ($\textbf{SAG}$) for extremely sparse action generation. To accommodate the iterative interactions, SAG customizes a rollout-adaptive prune-then-reuse mechanism that first identifies prunable computations globally and then reuses cached activations to substitute them during action diffusion. To capture the rollout dynamics, SAG parameterizes an observation-conditioned diffusion pruner for environment-aware adaptation and instantiates it with a highly parameter- and inference-efficient design for real-time prediction. Furthermore, SAG introduces a one-for-all reusing strategy that reuses activations across both timesteps and blocks in a zig-zag manner, minimizing the global redundancy. Extensive experiments on multiple robotic benchmarks demonstrate that SAG achieves up to 4$\times$ generation speedup without sacrificing performance. Project Page: https://sparse-actiongen.github.io/.

</details>


### [382] [Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization](https://arxiv.org/abs/2601.13451)
*Reza Ahmadvand,Sarah Safura Sharif,Yaser Mike Banad*

Main category: cs.RO

Relevance: 35.0

TL;DR: 提出了一种用于机器人视觉导航的新型混合神经网络框架，结合了人工神经网络和脉冲神经网络的优势，通过双通路架构实现未建模障碍物的检测和定位。


<details>
  <summary>Details</summary>
Motivation: 传统机器人导航系统在处理动态、不可预测环境中的未建模障碍物时存在局限性，需要既能准确理解环境又能快速高效处理的解决方案。混合神经网络（HNNs）结合了人工神经网络（ANNs）的准确性和脉冲神经网络（SNNs）的能效优势，为这一问题提供了新的可能性。

Method: 采用双通路架构：ANN组件以低频率处理静态空间特征，SNN组件实时处理动态、基于事件的传感器数据。系统集成了预开发的SNN滤波器，直接使用脉冲编码输入进行定位和状态估计。检测到的异常通过ANN通路的上下文信息进行验证，并持续跟踪以支持预测性导航策略。

Result: 仿真结果表明，该方法在保持接近纯SNN实现的计算效率的同时，提供了可接受的检测精度。纯SNN实现仅需传统方法的一小部分资源成本，而混合框架在准确性和效率之间取得了良好平衡。

Conclusion: 该框架代表了神经形态导航系统的重要进展，特别适用于机器人在不可预测和动态环境中的操作。通过有效结合ANN和SNN的优势，为机器人导航提供了既准确又高效的解决方案。

Abstract: This paper introduces a novel framework for robotic vision-based navigation that integrates Hybrid Neural Networks (HNNs) with Spiking Neural Network (SNN)-based filtering to enhance situational awareness for unmodeled obstacle detection and localization. By leveraging the complementary strengths of Artificial Neural Networks (ANNs) and SNNs, the system achieves both accurate environmental understanding and fast, energy-efficient processing. The proposed architecture employs a dual-pathway approach: an ANN component processes static spatial features at low frequency, while an SNN component handles dynamic, event-based sensor data in real time. Unlike conventional hybrid architectures that rely on domain conversion mechanisms, our system incorporates a pre-developed SNN-based filter that directly utilizes spike-encoded inputs for localization and state estimation. Detected anomalies are validated using contextual information from the ANN pathway and continuously tracked to support anticipatory navigation strategies. Simulation results demonstrate that the proposed method offers acceptable detection accuracy while maintaining computational efficiency close to SNN-only implementations, which operate at a fraction of the resource cost. This framework represents a significant advancement in neuromorphic navigation systems for robots operating in unpredictable and dynamic environments.

</details>


### [383] [Copy-Trasform-Paste: Zero-Shot Object-Object Alignment Guided by Vision-Language and Geometric Constraints](https://arxiv.org/abs/2601.14207)
*Rotem Gatenyo,Ohad Fried*

Main category: cs.GR

Relevance: 35.0

TL;DR: 提出一种零样本3D网格对齐方法，通过CLIP梯度直接优化相对位姿，结合几何感知目标实现语言指导的物理合理对齐


<details>
  <summary>Details</summary>
Motivation: 现有3D对齐方法主要依赖几何对齐或2D扩散模型，缺乏直接优化相对位姿的语言条件方法。需要一种无需训练新模型、能同时考虑语义和物理约束的零样本对齐框架。

Method: 1) 测试时直接优化相对位姿（平移、旋转、各向同性缩放）；2) 通过可微分渲染器使用CLIP梯度；3) 结合几何感知目标：软ICP项促进表面接触，穿透损失防止相互穿透；4) 分阶段调度加强接触约束；5) 相机控制聚焦交互区域

Result: 在包含多样类别和关系的基准测试中，该方法优于所有基线，产生语义忠实且物理合理的对齐结果

Conclusion: 提出的零样本3D对齐框架通过直接优化相对位姿，结合语言监督和几何约束，实现了语义和物理上合理的对齐，为内容创建和场景组装提供了有效工具

Abstract: We study zero-shot 3D alignment of two given meshes, using a text prompt describing their spatial relation -- an essential capability for content creation and scene assembly. Earlier approaches primarily rely on geometric alignment procedures, while recent work leverages pretrained 2D diffusion models to model language-conditioned object-object spatial relationships. In contrast, we directly optimize the relative pose at test time, updating translation, rotation, and isotropic scale with CLIP-driven gradients via a differentiable renderer, without training a new model. Our framework augments language supervision with geometry-aware objectives: a variant of soft-Iterative Closest Point (ICP) term to encourage surface attachment and a penetration loss to discourage interpenetration. A phased schedule strengthens contact constraints over time, and camera control concentrates the optimization on the interaction region. To enable evaluation, we curate a benchmark containing diverse categories and relations, and compare against baselines. Our method outperforms all alternatives, yielding semantically faithful and physically plausible alignments.

</details>


### [384] [Cross-Domain Object Detection Using Unsupervised Image Translation](https://arxiv.org/abs/2601.11779)
*Vinicius F. Arruda,Rodrigo F. Berriel,Thiago M. Paixão,Claudine Badue,Alberto F. De Souza,Nicu Sebe,Thiago Oliveira-Santos*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出一种通过无监督图像翻译生成目标域人工数据集来训练目标检测器的方法，使用CycleGAN和AdaIN模型，在自动驾驶场景中显著提升性能并接近上限


<details>
  <summary>Details</summary>
Motivation: 当前基于中间特征对齐的无监督域自适应方法虽然有效，但实现复杂且难以解释，性能仍有提升空间。需要更简单、可解释且能进一步缩小与目标域训练上限差距的方法。

Method: 使用两种无监督图像翻译模型（CycleGAN和AdaIN-based模型），仅利用源域标注数据和目标域非标注数据，生成目标域的人工数据集来训练目标检测器。

Result: 在自动驾驶真实场景中取得显著改进，在大多数情况下超越现有最先进方法，进一步缩小了与目标域训练上限的差距。

Conclusion: 提出的方法不仅复杂度更低、可解释性更好，而且更有效，为无监督域自适应目标检测提供了一种有前景的替代方案。

Abstract: Unsupervised domain adaptation for object detection addresses the adaption of detectors trained in a source domain to work accurately in an unseen target domain. Recently, methods approaching the alignment of the intermediate features proven to be promising, achieving state-of-the-art results. However, these methods are laborious to implement and hard to interpret. Although promising, there is still room for improvements to close the performance gap toward the upper-bound (when training with the target data). In this work, we propose a method to generate an artificial dataset in the target domain to train an object detector. We employed two unsupervised image translators (CycleGAN and an AdaIN-based model) using only annotated data from the source domain and non-annotated data from the target domain. Our key contributions are the proposal of a less complex yet more effective method that also has an improved interpretability. Results on real-world scenarios for autonomous driving show significant improvements, outperforming state-of-the-art methods in most cases, further closing the gap toward the upper-bound.

</details>


### [385] [Weaknesses of Facial Emotion Recognition Systems](https://arxiv.org/abs/2601.12402)
*Aleksandra Jamróz,Patrycja Wysocka,Piotr Garbat*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文对基于面部表情的情感检测方法进行了深入综述，选择了三种最佳解决方案和三个多样化数据集，通过跨数据集实验揭示了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 面部情感检测是人机交互的重要机器学习问题，现有方法繁多但缺乏系统性比较，需要深入评估不同方法的性能表现。

Method: 1. 对相关文献进行深入综述；2. 选择三种最佳神经网络解决方案；3. 选择三个具有图像多样性和数量优势的数据集；4. 训练所选神经网络并进行系列实验，包括在不同数据集上的交叉测试。

Result: 实验揭示了现有解决方案的弱点：数据集之间存在差异、不同情感识别难度不均、相似情感难以区分等挑战。

Conclusion: 面部情感检测方法存在数据集偏差、情感识别难度差异和相似情感混淆等问题，需要更鲁棒和泛化的解决方案。

Abstract: Emotion detection from faces is one of the machine learning problems needed for human-computer interaction. The variety of methods used is enormous, which motivated an in-depth review of articles and scientific studies. Three of the most interesting and best solutions are selected, followed by the selection of three datasets that stood out for the diversity and number of images in them. The selected neural networks are trained, and then a series of experiments are performed to compare their performance, including testing on different datasets than a model was trained on. This reveals weaknesses in existing solutions, including differences between datasets, unequal levels of difficulty in recognizing certain emotions and the challenges in differentiating between closely related emotions.

</details>


### [386] [Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation](https://arxiv.org/abs/2601.12876)
*Zhenxuan Lu,Zhihua Xu,Zhijing Yang,Feng Gao,Yongyi Lu,Keze Wang,Tianshui Chen*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出THFEM框架，结合音频驱动说话头生成模型与面部表情操纵技术，通过相邻帧学习策略提升视频中表情操纵时的唇部同步质量。


<details>
  <summary>Details</summary>
Motivation: 现有语音保留面部表情操纵技术难以准确保持唇部同步，而音频驱动说话头生成模型擅长生成精确的唇部运动，但单独使用时会影响图像真实性和表情保真度。

Method: 提出THFEM框架：1) 使用音频驱动说话头生成模型从音频输入和SPFEM处理图像生成唇部同步帧；2) 开发相邻帧学习策略，微调模型预测连续帧序列，利用相邻帧信息提升图像质量。

Result: 实验表明该框架能有效在表情操纵过程中保持嘴型，显著改善了音频驱动说话头生成模型与面部表情操纵技术的集成效果。

Conclusion: 通过集成音频驱动说话头生成模型与面部表情操纵技术，并采用相邻帧学习策略，能够有效解决表情操纵中的唇部同步问题，提升视频质量。

Abstract: Speech-Preserving Facial Expression Manipulation (SPFEM) is an innovative technique aimed at altering facial expressions in images and videos while retaining the original mouth movements. Despite advancements, SPFEM still struggles with accurate lip synchronization due to the complex interplay between facial expressions and mouth shapes. Capitalizing on the advanced capabilities of audio-driven talking head generation (AD-THG) models in synthesizing precise lip movements, our research introduces a novel integration of these models with SPFEM. We present a new framework, Talking Head Facial Expression Manipulation (THFEM), which utilizes AD-THG models to generate frames with accurately synchronized lip movements from audio inputs and SPFEM-altered images. However, increasing the number of frames generated by AD-THG models tends to compromise the realism and expression fidelity of the images. To counter this, we develop an adjacent frame learning strategy that finetunes AD-THG models to predict sequences of consecutive frames. This strategy enables the models to incorporate information from neighboring frames, significantly improving image quality during testing. Our extensive experimental evaluations demonstrate that this framework effectively preserves mouth shapes during expression manipulations, highlighting the substantial benefits of integrating AD-THG with SPFEM.

</details>


### [387] [Karhunen-Loève Expansion-Based Residual Anomaly Map for Resource-Efficient Glioma MRI Segmentation](https://arxiv.org/abs/2601.11833)
*Anthony Hur*

Main category: q-bio.QM

Relevance: 30.0

TL;DR: 提出了一种基于Karhunen-Loève展开（KLE）的脑肿瘤分割方法，通过特征提取和残差异常图显著降低了计算资源和数据需求，在消费级硬件上实现了与顶级方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的脑肿瘤分割方法需要大量训练数据和强大的计算资源（如超级计算机），这在大多数地区难以获得。当数据或计算资源受限时，性能会急剧下降。需要开发一种在有限资源和数据下仍能保持高性能的方法。

Method: 使用Karhunen-Loève展开（KLE）作为特征提取步骤，对下采样和z-score归一化的MRI体积进行处理。将240×240×155的多模态扫描减少到四个48³通道，压缩为32个KL系数。通过近似重建生成残差异常图，将其上采样后作为第五个通道输入到紧凑的3D U-Net中。

Result: 在消费级工作站（AMD Ryzen 5 7600X CPU，RTX 4060Ti 8GB VRAM，64GB RAM）上，使用较少训练案例，获得了后处理Dice分数：WT 0.929、TC 0.856、ET 0.821，HD95距离分别为2.93、6.78、10.35体素。在HD95距离和WT Dice分数上显著优于BraTS 2023获胜方法。

Conclusion: KLE基残差异常图方法能够显著降低计算成本和数据需求，同时保持最先进的性能，为资源受限环境下的脑肿瘤分割提供了可行解决方案。

Abstract: Accurate segmentation of brain tumors is essential for clinical diagnosis and treatment planning. Deep learning is currently the state-of-the-art for brain tumor segmentation, yet it requires either large datasets or extensive computational resources that are inaccessible in most areas. This makes the problem increasingly difficult: state-of-the-art models use thousands of training cases and vast computational power, where performance drops sharply when either is limited. The top performer in the Brats GLI 2023 competition relied on supercomputers trained on over 92,000 augmented MRI scans using an AMD EPYC 7402 CPU, six NVIDIA RTX 6000 GPUs (48GB VRAM each), and 1024GB of RAM over multiple weeks. To address this, the Karhunen--Loève Expansion (KLE) was implemented as a feature extraction step on downsampled, z-score normalized MRI volumes. Each 240$\times$240$\times$155 multi-modal scan is reduced to four $48^3$ channels and compressed into 32 KL coefficients. The resulting approximate reconstruction enables a residual-based anomaly map, which is upsampled and added as a fifth channel to a compact 3D U-Net. All experiments were run on a consumer workstation (AMD Ryzen 5 7600X CPU, RTX 4060Ti (8GB VRAM), and 64GB RAM while using far fewer training cases. This model achieves post-processed Dice scores of 0.929 (WT), 0.856 (TC), and 0.821 (ET), with HD95 distances of 2.93, 6.78, and 10.35 voxels. These results are significantly better than the winning BraTS 2023 methodology for HD95 distances and WT dice scores. This demonstrates that a KLE-based residual anomaly map can dramatically reduce computational cost and data requirements while retaining state-of-the-art performance.

</details>


### [388] [On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2601.13913)
*Pavlo Melnyk,Cuong Le,Urs Waldmann,Per-Erik Forssén,Bastian Wandt*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文提出通过数据增强学习2D旋转等变性，而非设计等变架构，来提升单目3D人体姿态估计性能，在旋转输入上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体姿态估计方法在遇到旋转输入时表现不佳。作者认为学习人体姿态及其平面内旋转比直接学习点对点映射更简单且几何基础更扎实，通过数据增强学习旋转等变性比设计等变架构更直接有效。

Method: 采用两阶段方法：首先检测2D骨骼关节点，然后进行2D到3D提升。关键创新是通过数据增强（而非架构约束）让模型学习2D旋转等变性，使模型能够处理图像平面内的旋转变化。

Result: 在标准HPE基准测试中验证，通过数据增强学习的2D旋转等变性显著提升了模型在类似旋转人体姿态上的性能，优于现有的等变设计方法。

Conclusion: 通过数据增强学习旋转等变性是提升单目3D人体姿态估计性能的有效方法，比设计等变架构更简单直接，在旋转输入上表现更好。

Abstract: Estimating 3D from 2D is one of the central tasks in computer vision. In this work, we consider the monocular setting, i.e. single-view input, for 3D human pose estimation (HPE). Here, the task is to predict a 3D point set of human skeletal joints from a single 2D input image. While by definition this is an ill-posed problem, recent work has presented methods that solve it with up to several-centimetre error. Typically, these methods employ a two-step approach, where the first step is to detect the 2D skeletal joints in the input image, followed by the step of 2D-to-3D lifting. We find that common lifting models fail when encountering a rotated input. We argue that learning a single human pose along with its in-plane rotations is considerably easier and more geometrically grounded than directly learning a point-to-point mapping. Furthermore, our intuition is that endowing the model with the notion of rotation equivariance without explicitly constraining its parameter space should lead to a more straightforward learning process than one with equivariance by design. Utilising the common HPE benchmarks, we confirm that the 2D rotation equivariance per se improves the model performance on human poses akin to rotations in the image plane, and can be efficiently and straightforwardly learned by augmentation, outperforming state-of-the-art equivariant-by-design methods.

</details>


### [389] [Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning](https://arxiv.org/abs/2601.11614)
*Jason Qiu*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出3D TransUNet框架，从T1w MRI预测扩散MRI的FA和MD图，提升阿尔茨海默病诊断准确性


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期检测至关重要，但T1w MRI只能检测晚期宏观变化，而扩散MRI能检测早期微观异常但扫描时间长且易受运动伪影影响。临床需要从常规T1w MRI获取扩散微结构信息的方法。

Method: 使用3D TransUNet图像合成框架，直接从T1w MRI预测分数各向异性(FA)和平均扩散率(MD)图。模型生成高质量扩散MRI指标图。

Result: 生成的FA和MD图与真实扩散MRI高度一致(SSIM>0.93，Pearson相关系数>0.94)。在多模态诊断模型中，合成特征将AD分类准确率提升5%(78.75%->83.75%)，轻度认知障碍检测提升12.5%。

Conclusion: 从常规T1w MRI可以推断高质量的扩散微结构信息，将多模态成像的优势转移到没有扩散数据的临床环境中，有望提高AD诊断的可及性、效率和准确性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder in which pathological changes begin many years before the onset of clinical symptoms, making early detection essential for timely intervention. T1-weighted (T1w) Magnetic Resonance Imaging (MRI) is routinely used in clinical practice to identify macroscopic brain alterations, but these changes typically emerge relatively late in the disease course. Diffusion MRI (dMRI), in contrast, is sensitive to earlier microstructural abnormalities by probing water diffusion in brain tissue. dMRI metrics, including fractional anisotropy (FA) and mean diffusivity (MD), provide complementary information about white matter integrity and neurodegeneration. However, dMRI acquisitions are time-consuming and susceptible to motion artifacts, limiting their routine use in clinical populations. To bridge this gap, I propose a 3D TransUNet image synthesis framework that predicts FA and MD maps directly from T1w MRI. My model generates high-fidelity maps, achieving a structural similarity index (SSIM) exceeding 0.93 and a strong Pearson correlation (>0.94) with ground-truth dMRI. When integrated into a multi-modal diagnostic model, these synthetic features boost AD classification accuracy by 5% (78.75%->83.75%) and, most importantly, improve mild cognitive impairment (MCI) detection by 12.5%. This study demonstrates that high-quality diffusion microstructural information can be inferred from routinely acquired T1w MRI, effectively transferring the benefits of multi-modality imaging to settings where diffusion data are unavailable. By reducing scan time while preserving complementary structural and microstructural information, the proposed approach has the potential to improve the accessibility, efficiency, and accuracy of AD diagnosis in clinical practice.

</details>


### [390] [PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM](https://arxiv.org/abs/2601.11617)
*Xu Wang,Boyao Han,Xiaojun Chen,Ying Liu,Ruihui Li*

Main category: cs.CV

Relevance: 25.0

TL;DR: PointSLAM++ 是一个新颖的 RGB-D SLAM 系统，采用分层约束的神经高斯表示来保持结构一致性，通过渐进姿态优化减少深度噪声，并使用动态神经表示图实时适应场景细节，在重建精度和渲染质量上优于现有 3DGS 方法。


<details>
  <summary>Details</summary>
Motivation: 当前 SLAM 方法在存在深度噪声时难以保持结构一致性和鲁棒的姿态估计，而实时 3D 重建对于机器人和增强现实应用至关重要。

Method: 1) 分层约束的神经高斯表示：保持结构关系同时生成高斯基元进行场景建图；2) 渐进姿态优化：减轻深度传感器噪声，提高定位精度；3) 动态神经表示图：根据局部几何复杂度调整高斯节点分布，实时适应复杂场景细节。

Result: PointSLAM++ 在重建精度和渲染质量上优于现有的 3DGS-based SLAM 方法，展示了其在大规模 AR 和机器人应用中的优势。

Conclusion: PointSLAM++ 通过结合分层约束神经高斯表示、渐进姿态优化和动态神经表示图，实现了高精度 3D 建图和逼真场景渲染，为实时 3D 重建提供了有效解决方案。

Abstract: Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics.

</details>


### [391] [Confident Learning for Object Detection under Model Constraints](https://arxiv.org/abs/2601.11640)
*Yingda Yu,Jiaqi Xuan,Shuhui Shi,Xuanyu Teng,Shuyang Xu,Guanchao Tong*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出MDDC数据中心框架，通过迭代诊断和修正数据质量问题来提升边缘设备上的杂草检测性能，在固定轻量级检测器下实现5-25%的mAP提升


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的农业杂草检测面临严格约束：模型容量有限、计算资源受限、需要实时推理延迟。这些限制使得无法通过模型扩展或集成来提升性能，因此需要从数据角度寻找解决方案。

Method: 提出模型驱动的数据修正（MDDC）框架：1）自动化错误分析，将检测失败分为四类（假阴性、假阳性、类别混淆、定位错误）；2）结构化训练-修复-再训练流程；3）版本控制的数据管理。使用固定轻量级检测器YOLOv8n，通过数据质量优化而非模型扩展来提升性能。

Result: 在多个杂草检测数据集上，使用固定的轻量级检测器（YOLOv8n）实现了5-25%的mAP@0.5提升，表明系统化的数据质量优化可以有效缓解固定模型容量约束下的性能瓶颈。

Conclusion: 在边缘设备约束下，通过数据中心的系统化数据质量优化可以显著提升检测性能，为资源受限环境下的计算机视觉应用提供了有效解决方案。

Abstract: Agricultural weed detection on edge devices is subject to strict constraints on model capacity, computational resources, and real-time inference latency, which prevent performance improvements through model scaling or ensembling. This paper proposes Model-Driven Data Correction (MDDC), a data-centric framework that enhances detection performance by iteratively diagnosing and correcting data quality deficiencies. An automated error analysis procedure categorizes detection failures into four types: false negatives, false positives, class confusion, and localization errors. These error patterns are systematically addressed through a structured train-fix-retrain pipeline with version-controlled data management. Experimental results on multiple weed detection datasets demonstrate consistent improvements of 5-25 percent in mAP at 0.5 using a fixed lightweight detector (YOLOv8n), indicating that systematic data quality optimization can effectively alleviate performance bottlenecks under fixed model capacity constraints.

</details>


### [392] [IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation](https://arxiv.org/abs/2601.11645)
*Ujjwal Jain,Oshin Misra,Roshni Chakraborty,Mahua Bhattacharya*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出IMSAHLO框架用于荧光显微镜神经元分割，通过多尺度密集块和分层注意力机制处理细胞密度变化，结合混合损失函数解决类别不平衡和拓扑保持问题，在FNC数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜神经元分割面临密集与稀疏细胞共存、复杂重叠形态、严重类别不平衡等挑战，传统深度学习模型难以保持精细拓扑细节和准确边界划分。

Method: 提出IMSAHLO框架：1) 多尺度密集块(MSDBs)捕获不同感受野特征；2) 分层注意力(HA)机制自适应聚焦形态特征；3) 混合损失函数结合Tversky损失、Focal损失、拓扑感知中心线Dice损失和轮廓加权边界损失。

Result: 在FNC数据集上达到81.4%精度、82.7%宏F1分数、83.3%微F1分数、99.5%平衡准确率，在密集和稀疏细胞情况下均优于现有方法，消融实验验证了多尺度注意力和混合损失项的协同效益。

Conclusion: 该工作为可泛化的分割模型奠定了基础，适用于广泛的生物医学成像模态，推动AI辅助分析向高通量神经生物学流程发展。

Abstract: Accurate segmentation of neuronal cells in fluorescence microscopy is a fundamental task for quantitative analysis in computational neuroscience. However, it is significantly impeded by challenges such as the coexistence of densely packed and sparsely distributed cells, complex overlapping morphologies, and severe class imbalance. Conventional deep learning models often fail to preserve fine topological details or accurately delineate boundaries under these conditions. To address these limitations, we propose a novel deep learning framework, IMSAHLO (Integrating Multi-Scale Attention and Hybrid Loss Optimization), for robust and adaptive neuronal segmentation. The core of our model features Multi-Scale Dense Blocks (MSDBs) to capture features at various receptive fields, effectively handling variations in cell density, and a Hierarchical Attention (HA) mechanism that adaptively focuses on salient morphological features to preserve Region of Interest (ROI) boundary details. Furthermore, we introduce a novel hybrid loss function synergistically combining Tversky and Focal loss to combat class imbalance, alongside a topology-aware Centerline Dice (clDice) loss and a Contour-Weighted Boundary loss to ensure topological continuity and precise separation of adjacent cells. Large-scale experiments on the public Fluorescent Neuronal Cells (FNC) dataset demonstrate that our framework outperforms state-of-the-art architectures, achieving precision of 81.4%, macro F1 score of 82.7%, micro F1 score of 83.3%, and balanced accuracy of 99.5% on difficult dense and sparse cases. Ablation studies validate the synergistic benefits of multi-scale attention and hybrid loss terms. This work establishes a foundation for generalizable segmentation models applicable to a wide range of biomedical imaging modalities, pushing AI-assisted analysis toward high-throughput neurobiological pipelines.

</details>


### [393] [LTV-YOLO: A Lightweight Thermal Object Detector for Young Pedestrians in Adverse Conditions](https://arxiv.org/abs/2601.11662)
*Abdullah Jirjees,Ryan Myers,Muhammad Haris Ikram,Mohamed H. Zaki*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出LTV-YOLO轻量级热成像检测模型，专门用于恶劣天气和低光照条件下检测儿童等弱势道路使用者，基于YOLO11架构优化计算效率，实现边缘设备实时性能。


<details>
  <summary>Details</summary>
Motivation: 传统RGB相机在低光照和恶劣天气条件下检测弱势道路使用者（特别是儿童和青少年）效果不佳，需要可靠的热成像检测方案来提升行人安全，尤其是在学校区域和自动驾驶系统中。

Method: 基于YOLO11架构定制热成像检测模型LTV-YOLO，集成深度可分离卷积和特征金字塔网络（FPN），专门针对热成像数据优化，用于检测小尺度、部分遮挡和热特征明显的弱势道路使用者。

Result: LTV-YOLO在计算效率、准确性和实时性能方面表现优异，能够在边缘设备上实现可靠的弱势道路使用者检测，特别是在恶劣环境条件下。

Conclusion: 该研究为智能交通系统提供了实用的热成像检测解决方案，专门针对儿童等小尺度弱势道路使用者在恶劣条件下的检测问题，有助于提升行人安全。

Abstract: Detecting vulnerable road users (VRUs), particularly children and adolescents, in low light and adverse weather conditions remains a critical challenge in computer vision, surveillance, and autonomous vehicle systems. This paper presents a purpose-built lightweight object detection model designed to identify young pedestrians in various environmental scenarios. To address these challenges, our approach leverages thermal imaging from long-wave infrared (LWIR) cameras, which enhances detection reliability in conditions where traditional RGB cameras operating in the visible spectrum fail. Based on the YOLO11 architecture and customized for thermal detection, our model, termed LTV-YOLO (Lightweight Thermal Vision YOLO), is optimized for computational efficiency, accuracy and real-time performance on edge devices. By integrating separable convolutions in depth and a feature pyramid network (FPN), LTV-YOLO achieves strong performance in detecting small-scale, partially occluded, and thermally distinct VRUs while maintaining a compact architecture. This work contributes a practical and scalable solution to improve pedestrian safety in intelligent transportation systems, particularly in school zones, autonomous navigation, and smart city infrastructure. Unlike prior thermal detectors, our contribution is task-specific: a thermally only edge-capable design designed for young and small VRUs (children and distant adults). Although FPN and depthwise separable convolutions are standard components, their integration into a thermal-only pipeline optimized for short/occluded VRUs under adverse conditions is, to the best of our knowledge, novel.

</details>


### [394] [Towards Airborne Object Detection: A Deep Learning Analysis](https://arxiv.org/abs/2601.11907)
*Prosenjit Chatterjee,ANK Zaman*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出基于EfficientNetB4的双任务模型，同时进行空中物体分类和威胁等级预测，在自建AODTA数据集上达到96%分类准确率和90%威胁预测准确率。


<details>
  <summary>Details</summary>
Motivation: 随着商用飞机、无人机等空中平台的快速普及，对实时自动化威胁评估系统的需求日益增长。现有方法依赖人工监控，可扩展性有限且操作效率低下。

Method: 采用EfficientNetB4架构构建双任务模型，同时处理物体分类和威胁等级预测。为解决数据稀缺问题，整合多个公开数据集构建了AODTA数据集，并在AVD数据集和AODTA数据集上进行基准测试。

Result: EfficientNetB4模型在物体分类任务上达到96%准确率，在威胁等级预测上达到90%准确率，显著优于ResNet-50基线模型。

Conclusion: 该双任务模型在监视、国防和空域管理应用中具有潜力，尽管标题提到检测，但实际研究聚焦于使用预定位图像进行分类和威胁推断。

Abstract: The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.

</details>


### [395] [Reliable Deep Learning for Small-Scale Classifications: Experiments on Real-World Image Datasets from Bangladesh](https://arxiv.org/abs/2601.11911)
*Muhammad Ibrahim,Alfe Suny,MD Sakib Ul Islam,Md. Imran Hossain*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该研究评估了一个紧凑型CNN在孟加拉国五个真实世界图像数据集上的表现，证明了简化CNN架构在小类别图像分类任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统CNN在图像识别任务中表现出色，但复杂架构容易在小数据集上过拟合。研究旨在探索紧凑型CNN在真实世界、小数据集图像分类任务中的表现和适用性。

Method: 使用一个紧凑型卷积神经网络，在孟加拉国五个公开的真实世界图像数据集上进行评估，包括城市侵占、车辆检测、道路损坏和农作物分类等任务。

Result: 该网络表现出高分类准确率、高效收敛和低计算开销。定量指标和显著性分析表明，模型能有效捕捉判别性特征，并在多样化场景中稳健泛化。

Conclusion: 简化CNN架构特别适合小类别图像分类任务，在保持高性能的同时降低了计算复杂度，为资源受限环境下的图像分析提供了实用解决方案。

Abstract: Convolutional neural networks (CNNs) have achieved state-of-the-art performance in image recognition tasks but often involve complex architectures that may overfit on small datasets. In this study, we evaluate a compact CNN across five publicly available, real-world image datasets from Bangladesh, including urban encroachment, vehicle detection, road damage, and agricultural crops. The network demonstrates high classification accuracy, efficient convergence, and low computational overhead. Quantitative metrics and saliency analyses indicate that the model effectively captures discriminative features and generalizes robustly across diverse scenarios, highlighting the suitability of streamlined CNN architectures for small-class image classification tasks.

</details>


### [396] [Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition](https://arxiv.org/abs/2601.11931)
*Zhengxian Wu,Chuanrui Zhang,Shenao Jiang,Hangrui Xu,Zirui Liao,Luyuan Zhang,Huaqiu Li,Peng Jiao,Haoqian Wang*

Main category: cs.CV

Relevance: 25.0

TL;DR: LMGait是一个语言引导和运动感知的步态识别框架，利用设计的步态相关语言提示来捕捉步态序列中的关键运动特征，解决现有方法过度拟合静态噪声和未能有效捕捉动态运动区域的问题。


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法通常依赖复杂架构直接从图像提取特征，并通过池化操作获得序列级表示。这种设计容易导致对静态噪声（如衣物）的过拟合，同时未能有效捕捉动态运动区域。

Method: 提出LMGait框架，利用设计的步态相关语言提示来捕捉步态序列中的关键运动特征，实现语言引导和运动感知的步态识别。

Result: 论文声称该方法能够有效解决现有步态识别方法的局限性，但具体实验结果未在摘要中提供。

Conclusion: LMGait框架通过语言引导和运动感知的方法，为步态识别领域提供了一种新的解决方案，能够更好地捕捉动态运动特征并减少对静态噪声的过拟合。

Abstract: Gait recognition is emerging as a promising technology and an innovative field within computer vision. However, existing methods typically rely on complex architectures to directly extract features from images and apply pooling operations to obtain sequence-level representations. Such designs often lead to overfitting on static noise (e.g., clothing), while failing to effectively capture dynamic motion regions.To address the above challenges, we present a Language guided and Motion-aware gait recognition framework, named LMGait.In particular, we utilize designed gait-related language cues to capture key motion features in gait sequences.

</details>


### [397] [Deep learning-based neurodevelopmental assessment in preterm infants](https://arxiv.org/abs/2601.11944)
*Lexin Ren,Jiamiao Lu,Weichuan Zhang,Benqing Wu,Tuo Wang,Yi Liao,Jiapan Guo,Changming Sun,Liang Guo*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种用于早产儿脑MRI白质和灰质分割的Hierarchical Dense Attention Network，通过3D空间通道注意力机制和注意力引导的密集上采样策略，解决了早产儿脑组织信号强度相似的分割难题。


<details>
  <summary>Details</summary>
Motivation: 早产儿面临神经发育延迟的高风险，需要早期识别进行及时干预。虽然基于深度学习的脑MRI体积分割为评估新生儿神经发育提供了有前景的途径，但由于早产儿在早期大脑发育期间MRI上白质和灰质具有相似的信号强度（等强度外观），实现准确分割仍然具有挑战性。

Method: 提出了一种名为Hierarchical Dense Attention Network的新型分割神经网络。该架构结合了3D空间通道注意力机制和注意力引导的密集上采样策略，以增强低对比度体积数据中的特征区分能力。

Result: 定量实验表明，该方法相比最先进的基线方法实现了更优的分割性能，有效解决了等强度组织区分的挑战。此外，应用该算法证实早产儿的白质和灰质体积显著低于足月儿，为早产相关的神经发育延迟提供了额外的影像证据。

Conclusion: 提出的HDAN网络能够有效解决早产儿脑MRI中白质和灰质等强度外观带来的分割挑战，为早产儿神经发育评估提供了准确的体积测量工具，并证实了早产儿脑组织体积减少的影像学证据。

Abstract: Preterm infants (born between 28 and 37 weeks of gestation) face elevated risks of neurodevelopmental delays, making early identification crucial for timely intervention. While deep learning-based volumetric segmentation of brain MRI scans offers a promising avenue for assessing neonatal neurodevelopment, achieving accurate segmentation of white matter (WM) and gray matter (GM) in preterm infants remains challenging due to their comparable signal intensities (isointense appearance) on MRI during early brain development. To address this, we propose a novel segmentation neural network, named Hierarchical Dense Attention Network. Our architecture incorporates a 3D spatial-channel attention mechanism combined with an attention-guided dense upsampling strategy to enhance feature discrimination in low-contrast volumetric data. Quantitative experiments demonstrate that our method achieves superior segmentation performance compared to state-of-the-art baselines, effectively tackling the challenge of isointense tissue differentiation. Furthermore, application of our algorithm confirms that WM and GM volumes in preterm infants are significantly lower than those in term infants, providing additional imaging evidence of the neurodevelopmental delays associated with preterm birth. The code is available at: https://github.com/ICL-SUST/HDAN.

</details>


### [398] [Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms](https://arxiv.org/abs/2601.11970)
*S. M. Khalid Bin Zahid,Md. Rakibul Hasan Nishat,Abdul Hasib,Md. Rakibul Hasan,Md. Ashiqussalehin,Md. Sahadat Hossen Sajib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出一个在树莓派5边缘设备上部署的多模态视觉框架，通过自适应调度机制整合目标检测、人脸识别和情绪分析，相比持续处理减少65%计算负载


<details>
  <summary>Details</summary>
Motivation: 现有智能监控系统通常独立处理感知任务（如目标检测、人脸识别、情绪分析），缺乏统一的、自适应的运行时调度器来根据上下文触发动态分配计算资源，这限制了在低功耗边缘设备上的整体理解和效率

Method: 1) 在树莓派5边缘平台上部署统一的多模态视觉框架；2) 集成YOLOv8n进行目标检测、基于FaceNet的自定义嵌入系统进行人脸识别、DeepFace的CNN进行情绪分类；3) 核心是自适应调度机制，根据上下文触发选择性激活模块

Result: 1) 计算负载相比持续处理减少65%；2) 目标检测模块平均精度(AP)0.861；3) 人脸识别准确率88%；4) 情绪检测AUC最高达0.97；5) 系统运行速度5.6帧/秒

Conclusion: 上下文感知调度是解锁低成本边缘硬件上复杂多模态AI的关键，使智能感知更易访问且保护隐私

Abstract: Intelligent surveillance systems often handle perceptual tasks such as object detection, facial recognition, and emotion analysis independently, but they lack a unified, adaptive runtime scheduler that dynamically allocates computational resources based on contextual triggers. This limits their holistic understanding and efficiency on low-power edge devices. To address this, we present a real-time multi-modal vision framework that integrates object detection, owner-specific face recognition, and emotion detection into a unified pipeline deployed on a Raspberry Pi 5 edge platform. The core of our system is an adaptive scheduling mechanism that reduces computational load by 65\% compared to continuous processing by selectively activating modules such as, YOLOv8n for object detection, a custom FaceNet-based embedding system for facial recognition, and DeepFace's CNN for emotion classification. Experimental results demonstrate the system's efficacy, with the object detection module achieving an Average Precision (AP) of 0.861, facial recognition attaining 88\% accuracy, and emotion detection showing strong discriminatory power (AUC up to 0.97 for specific emotions), while operating at 5.6 frames per second. Our work demonstrates that context-aware scheduling is the key to unlocking complex multi-modal AI on cost-effective edge hardware, making intelligent perception more accessible and privacy-preserving.

</details>


### [399] [An AI-IoT Based Smart Wheelchair with Gesture-Controlled Mobility, Deep Learning-Based Obstacle Detection, Multi-Sensor Health Monitoring, and Emergency Alert System](https://arxiv.org/abs/2601.11983)
*Md. Asiful Islam,Abdul Hasib,Tousif Mahmud Emon,Khandaker Tabin Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

Relevance: 25.0

TL;DR: 基于AI-IoT的智能轮椅系统，集成手势控制、障碍物检测和健康监测功能，为残障人士和老年人提供经济实惠的辅助解决方案


<details>
  <summary>Details</summary>
Motivation: 随着残障人士和老年人口增长，需要经济实惠的智能轮椅系统。传统轮椅缺乏动态功能，现有智能轮椅成本高、功能单一且健康监测集成不足。需要开发先进、个性化且价格合理的辅助技术。

Method: 提出综合AI-IoT智能轮椅系统：1) 基于手套的手势控制实现免手导航；2) 使用YOLOv8进行实时物体检测并提供听觉反馈；3) 超声波传感器用于即时碰撞避免；4) 持续监测生命体征（心率、血氧、心电图、体温），上传至ThingSpeak平台，并在危急情况触发邮件警报。系统基于模块化低成本架构。

Result: 手势控制成功率95.5%，超声波障碍检测准确率94%，YOLOv8物体检测达到91.5%精确率、90.2%召回率和90.8% F1分数。系统提供实用、可扩展且经济实惠的解决方案。

Conclusion: 这种集成多模态方法通过结合创新研究和实际部署，显著增强用户自主性、安全性和独立性，为辅助技术领域提供实用解决方案。

Abstract: The growing number of differently-abled and elderly individuals demands affordable, intelligent wheelchairs that combine safe navigation with health monitoring. Traditional wheelchairs lack dynamic features, and many smart alternatives remain costly, single-modality, and limited in health integration. Motivated by the pressing demand for advanced, personalized, and affordable assistive technologies, we propose a comprehensive AI-IoT based smart wheelchair system that incorporates glove-based gesture control for hands-free navigation, real-time object detection using YOLOv8 with auditory feedback for obstacle avoidance, and ultrasonic for immediate collision avoidance. Vital signs (heart rate, SpO$_2$, ECG, temperature) are continuously monitored, uploaded to ThingSpeak, and trigger email alerts for critical conditions. Built on a modular and low-cost architecture, the gesture control achieved a 95.5\% success rate, ultrasonic obstacle detection reached 94\% accuracy, and YOLOv8-based object detection delivered 91.5\% Precision, 90.2\% Recall, and a 90.8\% F1-score. This integrated, multi-modal approach offers a practical, scalable, and affordable solution, significantly enhancing user autonomy, safety, and independence by bridging the gap between innovative research and real-world deployment.

</details>


### [400] [SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture](https://arxiv.org/abs/2601.12015)
*Pavan Kumar Yata,Pediredla Pradeep,Goli Himanish,Swathi M*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出DeepSegFusion混合深度学习模型，用于SAR图像中的油污分割，结合SegNet和DeepLabV3+并采用注意力特征融合机制，显著降低误报率，适用于近实时油污监测。


<details>
  <summary>Details</summary>
Motivation: 传统基于阈值的方法在卫星图像油污检测中因风浪波纹、船迹等类似现象导致高误报率，需要更精确的检测方法。

Method: 提出DeepSegFusion混合模型，集成SegNet和DeepLabV3+两种分割网络，采用注意力机制进行特征融合，提升边界精度和上下文理解能力。

Result: 在SAR油污数据集上达到94.85%准确率、0.5685 IoU和0.9330 ROC-AUC，误报率比基线方法降低64.4%，误检减少三倍以上。

Conclusion: DeepSegFusion在各种海洋条件下表现稳定，可用于近实时油污监测，显著优于传统方法和单一基线模型。

Abstract: Detection of oil spills from satellite images is essential for both environmental surveillance and maritime safety. Traditional threshold-based methods frequently encounter performance degradation due to very high false alarm rates caused by look-alike phenomena such as wind slicks and ship wakes. Here, a hybrid deep learning model, DeepSegFusion, is presented for oil spill segmentation in Synthetic Aperture Radar (SAR) images. The model uses SegNet and DeepLabV3+ integrated with an attention-based feature fusion mechanism to achieve better boundary precision as well as improved contextual understanding. Results obtained on SAR oil spill datasets, including ALOS PALSAR imagery, confirm that the proposed DeepSegFusion model achieves an accuracy of 94.85%, an Intersection over Union (IoU) of 0.5685, and a ROC-AUC score of 0.9330. The proposed method delivers more than three times fewer false detections compared to individual baseline models and traditional non-segmentation methods, achieving a reduction of 64.4%. These results indicate that DeepSegFusion is a stable model under various marine conditions and can therefore be used in near real-time oil spill monitoring scenarios.

</details>


### [401] [DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering](https://arxiv.org/abs/2601.12020)
*Guillermo Figueroa-Araneda,Iris Diana Jimenez,Florian Hofherr,Manny Ko,Hector Andrade-Loarca,Daniel Cremers*

Main category: cs.CV

Relevance: 25.0

TL;DR: DIAMOND-SSS是一个用于从极稀疏监督（少至10张图像）进行高保真半透明重建的数据高效框架，通过扩散模型生成新视角和重光照图像，减少真实采集需求达90%。


<details>
  <summary>Details</summary>
Motivation: 解决神经渲染中半透明材质（如蜡、玉石、大理石、皮肤）建模的挑战，这些材质需要复杂的多次散射光传输和密集的多视角多光照数据集（通常超过100个视角和112个OLATs）。当前方法需要大量数据采集，成本高昂。

Method: 1) 微调扩散模型进行新视角合成和重光照，基于估计的几何信息，在不到7%的数据集上训练；2) 引入光照无关的几何先验：多视角轮廓一致性损失和多视角深度一致性损失，以稳定稀疏或合成监督下的重建；3) 使用可重光照的高斯渲染。

Result: 在所有稀疏度情况下，DIAMOND-SSS在可重光照高斯渲染中达到最先进的质量，与SSS-3DGS相比，真实采集需求减少达90%，能够用少于7%的数据集训练，生成可替代高达95%缺失采集的光真实感增强图像。

Conclusion: DIAMOND-SSS通过结合扩散模型生成和几何一致性约束，实现了从极稀疏监督的高质量半透明重建，大幅降低了数据采集成本，为神经渲染中的半透明材质建模提供了高效解决方案。

Abstract: Subsurface scattering (SSS) gives translucent materials -- such as wax, jade, marble, and skin -- their characteristic soft shadows, color bleeding, and diffuse glow. Modeling these effects in neural rendering remains challenging due to complex light transport and the need for densely captured multi-view, multi-light datasets (often more than 100 views and 112 OLATs).
  We present DIAMOND-SSS, a data-efficient framework for high-fidelity translucent reconstruction from extremely sparse supervision -- even as few as ten images. We fine-tune diffusion models for novel-view synthesis and relighting, conditioned on estimated geometry and trained on less than 7 percent of the dataset, producing photorealistic augmentations that can replace up to 95 percent of missing captures. To stabilize reconstruction under sparse or synthetic supervision, we introduce illumination-independent geometric priors: a multi-view silhouette consistency loss and a multi-view depth consistency loss.
  Across all sparsity regimes, DIAMOND-SSS achieves state-of-the-art quality in relightable Gaussian rendering, reducing real capture requirements by up to 90 percent compared to SSS-3DGS.

</details>


### [402] [Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation](https://arxiv.org/abs/2601.12052)
*Zaiyan Zhang,Jie Li,Shaowei Shi,Qiangqiang Yuan*

Main category: cs.CV

Relevance: 25.0

TL;DR: TDP-CR是一个任务驱动的多模态云去除框架，通过可学习的退化提示编码云层厚度和空间不确定性，联合执行云去除和土地覆盖分割，在保持参数效率的同时提升语义实用性。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中的云遮挡限制了其下游应用价值。现有云去除方法过度关注低层保真度，导致纹理和边界过度平滑，造成视觉上合理的恢复与语义实用性之间的不匹配。

Method: 提出TDP-CR框架，核心是提示引导融合机制，使用可学习的退化提示编码云层厚度和空间不确定性，结合全局通道上下文和局部提示条件空间偏置，自适应地集成SAR信息。采用参数高效的两阶段训练策略，解耦重建和语义表示学习。

Result: 在LuojiaSET-OSFCR数据集上，TDP-CR在PSNR上超过最先进基线0.18dB，同时仅使用15%的参数；在mIoU上比多任务竞争者提升1.4%，有效提供分析就绪数据。

Conclusion: TDP-CR通过任务驱动的多模态方法，在保持参数效率的同时，有效解决了云去除中的语义实用性挑战，为遥感图像分析提供了更有效的解决方案。

Abstract: Optical remote sensing imagery is indispensable for Earth observation, yet persistent cloud occlusion limits its downstream utility. Most cloud removal (CR) methods are optimized for low-level fidelity and can over-smooth textures and boundaries that are critical for analysis-ready data (ARD), leading to a mismatch between visually plausible restoration and semantic utility. To bridge this gap, we propose TDP-CR, a task-driven multimodal framework that jointly performs cloud removal and land-cover segmentation. Central to our approach is a Prompt-Guided Fusion (PGF) mechanism, which utilizes a learnable degradation prompt to encode cloud thickness and spatial uncertainty. By combining global channel context with local prompt-conditioned spatial bias, PGF adaptively integrates Synthetic Aperture Radar (SAR) information only where optical data is corrupted. We further introduce a parameter-efficient two-phase training strategy that decouples reconstruction and semantic representation learning. Experiments on the LuojiaSET-OSFCR dataset demonstrate the superiority of our framework: TDP-CR surpasses heavy state-of-the-art baselines by 0.18 dB in PSNR while using only 15\% of the parameters, and achieves a 1.4\% improvement in mIoU consistently against multi-task competitors, effectively delivering analysis-ready data.

</details>


### [403] [EmoLat: Text-driven Image Sentiment Transfer via Emotion Latent Space](https://arxiv.org/abs/2601.12079)
*Jing Zhang,Bingjie Fan,Jixiang Zhu,Zhe Wang*

Main category: cs.CV

Relevance: 25.0

TL;DR: EmoLat：一种新颖的情感潜在空间，通过建模文本语义与视觉情感特征之间的跨模态相关性，实现细粒度的文本驱动图像情感迁移。


<details>
  <summary>Details</summary>
Motivation: 当前图像情感编辑方法通常缺乏细粒度控制和文本引导能力，难以实现精确的跨模态情感迁移。需要一种能够建模文本语义与视觉情感特征之间复杂关系的框架。

Method: 1) 构建EmoLat情感潜在空间，通过情感语义图捕捉情感、物体和视觉属性之间的关系结构；2) 使用对抗正则化增强情感表示的区分性和可迁移性；3) 提出跨模态情感迁移框架，通过文本和EmoLat特征的联合嵌入来操纵图像情感；4) 使用包含语义一致性、情感对齐和对抗正则化的多目标损失优化网络；5) 构建EmoSpace Set大规模基准数据集，包含情感、物体语义和视觉属性的密集标注。

Result: 在EmoSpace Set数据集上的广泛实验表明，该方法在定量指标和定性迁移保真度方面显著优于现有最先进方法，为文本引导的可控图像情感编辑建立了新范式。

Conclusion: EmoLat成功实现了细粒度的文本驱动图像情感迁移，通过建模跨模态相关性并利用对抗正则化，在情感表示学习和可控图像编辑方面取得了显著进展。

Abstract: We propose EmoLat, a novel emotion latent space that enables fine-grained, text-driven image sentiment transfer by modeling cross-modal correlations between textual semantics and visual emotion features. Within EmoLat, an emotion semantic graph is constructed to capture the relational structure among emotions, objects, and visual attributes. To enhance the discriminability and transferability of emotion representations, we employ adversarial regularization, aligning the latent emotion distributions across modalities. Building upon EmoLat, a cross-modal sentiment transfer framework is proposed to manipulate image sentiment via joint embedding of text and EmoLat features. The network is optimized using a multi-objective loss incorporating semantic consistency, emotion alignment, and adversarial regularization. To support effective modeling, we construct EmoSpace Set, a large-scale benchmark dataset comprising images with dense annotations on emotions, object semantics, and visual attributes. Extensive experiments on EmoSpace Set demonstrate that our approach significantly outperforms existing state-of-the-art methods in both quantitative metrics and qualitative transfer fidelity, establishing a new paradigm for controllable image sentiment editing guided by textual input. The EmoSpace Set and all the code are available at http://github.com/JingVIPLab/EmoLat.

</details>


### [404] [Toward Real-World High-Precision Image Matting and Segmentation](https://arxiv.org/abs/2601.12080)
*Haipeng Zhou,Zhaohu Xing,Hongqiu Wang,Jun Ma,Ping Li,Lei Zhu*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出FCLM模型解决高精度场景解析任务，通过深度感知蒸馏、域不变学习和面向对象解码器，在图像抠图和二值分割任务上超越SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有高精度场景解析方法主要关注显著单前景对象，交互式方法类别不可知限制了跨类别泛化，高质量标注数据稀缺导致依赖不和谐的合成数据，泛化到真实场景效果差。

Method: 1) 深度感知蒸馏策略：传递深度相关知识改善前景表示；2) 域不变学习策略：将合成数据处理视为域适应问题，关注前景学习；3) 面向对象解码器：接收视觉和语言提示预测参考目标。

Result: 实验结果显示，该方法在定量和定性评估上都超越了最先进的方法。

Conclusion: FCLM模型通过深度感知蒸馏、域不变学习和面向对象解码器，有效解决了高精度场景解析中的泛化问题和数据稀缺问题。

Abstract: High-precision scene parsing tasks, including image matting and dichotomous segmentation, aim to accurately predict masks with extremely fine details (such as hair). Most existing methods focus on salient, single foreground objects. While interactive methods allow for target adjustment, their class-agnostic design restricts generalization across different categories. Furthermore, the scarcity of high-quality annotation has led to a reliance on inharmonious synthetic data, resulting in poor generalization to real-world scenarios. To this end, we propose a Foreground Consistent Learning model, dubbed as FCLM, to address the aforementioned issues. Specifically, we first introduce a Depth-Aware Distillation strategy where we transfer the depth-related knowledge for better foreground representation. Considering the data dilemma, we term the processing of synthetic data as domain adaptation problem where we propose a domain-invariant learning strategy to focus on foreground learning. To support interactive prediction, we contribute an Object-Oriented Decoder that can receive both visual and language prompts to predict the referring target. Experimental results show that our method quantitatively and qualitatively outperforms SOTA methods.

</details>


### [405] [Detecting 3D Line Segments for 6DoF Pose Estimation with Limited Data](https://arxiv.org/abs/2601.12090)
*Matej Mok,Lukáš Gajdošech,Michal Mesároš,Martin Madaras,Viktor Kocur*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种针对工业料箱的6DoF位姿估计新方法，利用料箱的立方体几何特性，通过检测3D线段并采用几何处理来估计位姿，无需实例特定的CAD模型。


<details>
  <summary>Details</summary>
Motivation: 传统6DoF物体位姿估计方法需要大量训练数据或CAD模型，限制了在数据稀缺、物体实例多变的工业场景中的应用。工业料箱具有标准化的立方体几何形状，可以利用这一特性简化位姿估计。

Method: 1. 利用料箱的立方体几何特性，首先检测对应料箱顶部边缘的中间3D线段；2. 将2D线段检测网络LeTR扩展到结构化点云数据；3. 使用简单的几何处理程序处理检测到的3D线段，稳健地确定料箱的6DoF位姿。

Result: 方法在公开数据集上评估，结合合成训练数据显著提高了真实扫描数据的位姿估计精度。相比当前最先进的6DoF位姿估计方法，在姿态精度上显著优于（3cm平移误差，8.2°旋转误差），且推理时不需要实例特定的CAD模型。

Conclusion: 该方法为工业料箱位姿估计提供了一种有效解决方案，通过利用几何先验知识和合成数据增强，在数据稀缺的工业环境中实现了高精度的位姿估计，无需实例特定的CAD模型。

Abstract: The task of 6DoF object pose estimation is one of the fundamental problems of 3D vision with many practical applications such as industrial automation. Traditional deep learning approaches for this task often require extensive training data or CAD models, limiting their application in real-world industrial settings where data is scarce and object instances vary. We propose a novel method for 6DoF pose estimation focused specifically on bins used in industrial settings. We exploit the cuboid geometry of bins by first detecting intermediate 3D line segments corresponding to their top edges. Our approach extends the 2D line segment detection network LeTR to operate on structured point cloud data. The detected 3D line segments are then processed using a simple geometric procedure to robustly determine the bin's 6DoF pose. To evaluate our method, we extend an existing dataset with a newly collected and annotated dataset, which we make publicly available. We show that incorporating synthetic training data significantly improves pose estimation accuracy on real scans. Moreover, we show that our method significantly outperforms current state-of-the-art 6DoF pose estimation methods in terms of the pose accuracy (3 cm translation error, 8.2$^\circ$ rotation error) while not requiring instance-specific CAD models during inference.

</details>


### [406] [Energy-Aware Ensemble Learning for Coffee Leaf Disease Classification](https://arxiv.org/abs/2601.12109)
*Larissa Ferreira Rodrigues Moreira,Rodrigo Moreira,Leonardo Gabriel Ferreira Rodrigues*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该研究通过知识蒸馏和集成学习，将高容量CNN模型的知识转移到紧凑CNN上，实现咖啡叶病害的轻量级设备端诊断，在保持准确性的同时显著降低能耗和碳足迹。


<details>
  <summary>Details</summary>
Motivation: 咖啡叶病害的及时准确诊断对产量至关重要，但田间评估面临挑战。虽然AI视觉模型能达到高精度，但受限于设备计算能力和间歇性连接，难以在边缘设备上部署。需要开发轻量级、低能耗的解决方案。

Method: 采用知识蒸馏方法：在数据中心训练高容量卷积神经网络（CNNs），然后通过集成学习（EL）将知识转移到紧凑CNN上。通过简单优化的集成方法整合密集微小对，在严格的计算和能耗约束下提升准确性。

Result: 在咖啡叶数据集上，蒸馏后的微小集成模型达到了与先前工作相当的竞争性性能，同时显著降低了能耗和碳足迹。轻量级模型经过适当蒸馏和集成后，可为物联网应用提供实用的诊断解决方案。

Conclusion: 通过知识蒸馏和集成学习的结合，可以开发出在边缘设备上高效运行的轻量级病害诊断模型，为可持续的物联网农业应用提供可行方案。

Abstract: Coffee yields are contingent on the timely and accurate diagnosis of diseases; however, assessing leaf diseases in the field presents significant challenges. Although Artificial Intelligence (AI) vision models achieve high accuracy, their adoption is hindered by the limitations of constrained devices and intermittent connectivity. This study aims to facilitate sustainable on-device diagnosis through knowledge distillation: high-capacity Convolutional Neural Networks (CNNs) trained in data centers transfer knowledge to compact CNNs through Ensemble Learning (EL). Furthermore, dense tiny pairs were integrated through simple and optimized ensembling to enhance accuracy while adhering to strict computational and energy constraints. On a curated coffee leaf dataset, distilled tiny ensembles achieved competitive with prior work with significantly reduced energy consumption and carbon footprint. This indicates that lightweight models, when properly distilled and ensembled, can provide practical diagnostic solutions for Internet of Things (IoT) applications.

</details>


### [407] [CARLA-Round: A Multi-Factor Simulation Dataset for Roundabout Trajectory Prediction](https://arxiv.org/abs/2601.12119)
*Xiaotong Zhou,Zhenhui Yuan,Yi Han,Tianhua Xu,Laurence T. Yang*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了CARLA-Round数据集，这是一个用于环岛场景车辆轨迹预测的系统化仿真数据集，包含25个控制场景，涵盖不同天气和交通密度条件，支持因素影响分析。


<details>
  <summary>Details</summary>
Motivation: 环岛场景的车辆轨迹预测对交通安全至关重要，但由于其圆形几何结构、连续汇入和让行交互、缺乏交通信号等特点，预测极具挑战性。现有数据集稀缺，真实世界数据收集存在观测不完整和因素混杂的问题。

Method: 通过CARLA仿真平台系统化设计数据集，包含5种天气条件和5个服务水平等级（A-E）的交通密度，形成25个控制场景。每个场景包含真实的驾驶行为混合，并提供现有数据集缺乏的显式标注。

Result: 验证实验显示交通密度对预测难度具有单调强影响，而天气条件呈现非线性影响。最佳模型在真实世界rounD数据集上达到0.312m ADE，展示了有效的仿真到真实迁移能力。

Conclusion: CARLA-Round数据集通过系统化设计量化了真实世界混杂数据集中无法分离的因素影响，为环岛轨迹预测研究提供了可靠的多模态数据集。

Abstract: Accurate trajectory prediction of vehicles at roundabouts is critical for reducing traffic accidents, yet it remains highly challenging due to their circular road geometry, continuous merging and yielding interactions, and absence of traffic signals. Developing accurate prediction algorithms relies on reliable, multimodal, and realistic datasets; however, such datasets for roundabout scenarios are scarce, as real-world data collection is often limited by incomplete observations and entangled factors that are difficult to isolate. We present CARLA-Round, a systematically designed simulation dataset for roundabout trajectory prediction. The dataset varies weather conditions (five types) and traffic density levels (spanning Level-of-Service A-E) in a structured manner, resulting in 25 controlled scenarios. Each scenario incorporates realistic mixtures of driving behaviors and provides explicit annotations that are largely absent from existing datasets. Unlike randomly sampled simulation data, this structured design enables precise analysis of how different conditions influence trajectory prediction performance. Validation experiments using standard baselines (LSTM, GCN, GRU+GCN) reveal traffic density dominates prediction difficulty with strong monotonic effects, while weather shows non-linear impacts. The best model achieves 0.312m ADE on real-world rounD dataset, demonstrating effective sim-to-real transfer. This systematic approach quantifies factor impacts impossible to isolate in confounded real-world datasets. Our CARLA-Round dataset is available at https://github.com/Rebecca689/CARLA-Round.

</details>


### [408] [Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy](https://arxiv.org/abs/2601.12257)
*Fadlullah Raji,John Murray-Bruce*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该论文提出了一种从普通非视距(NLOS)照片进行3D场景重建的新方法，通过将隐藏场景分解为光遮挡和非光遮挡组件，并开发了梯度优化和物理启发神经网络两种解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统成像需要视线才能创建准确场景表示，但在某些情况下获取合适视线可能不切实际、危险甚至不可能。非视距成像通过间接测量重建场景来解决这一挑战。现有被动NLOS方法仅限于1D或低分辨率2D彩色成像，或只能定位形状大致已知的隐藏物体。

Method: 提出新的光传输模型重新表述，将隐藏场景分解为光遮挡和非光遮挡组件，形成可分离非线性最小二乘(SNLLS)逆问题。开发两种解决方案：基于梯度的优化方法和物理启发的神经网络方法(Soft Shadow diffusion, SSD)。

Result: 在真实实验场景中对多个3D场景有效，尽管面临具有挑战性的病态逆问题。SSD在模拟中训练，但能很好地泛化到模拟和真实世界NLOS场景中的未见类别，并对噪声和环境光照表现出惊人的鲁棒性。

Conclusion: 该方法实现了从普通NLOS照片进行3D重建的突破，克服了现有被动方法的限制，为NLOS成像提供了新的有效解决方案。

Abstract: Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into \textit{light-occluding} and \textit{non-light-occluding} components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.

</details>


### [409] [CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training](https://arxiv.org/abs/2601.12282)
*Pralaypati Ta,Sriram Venkatesaperumal,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CV

Relevance: 25.0

TL;DR: CytoCLIP：基于CLIP预训练框架的视觉-语言模型，用于学习大脑细胞构筑的联合视觉-文本表示，实现大脑区域的自动识别


<details>
  <summary>Details</summary>
Motivation: 大脑不同区域的功能与其独特的细胞构筑密切相关，但手动在脑组织切片中划分这些区域耗时且需要专业知识，需要自动化方法来减少专家工作量

Method: 提出CytoCLIP模型套件，包含两个变体：1）使用低分辨率全区域图像训练，理解区域的整体细胞构筑模式；2）使用高分辨率图像块训练，获取详细的细胞级表示。训练数据来自不同孕周胎儿大脑的NISSL染色组织切片

Result: CytoCLIP在区域分类和跨模态检索任务中优于现有方法，全区域分类F1分数达0.87，高分辨率图像块分类F1分数达0.91

Conclusion: CytoCLIP能够有效学习大脑细胞构筑的视觉-文本表示，为大脑区域自动识别提供了有效的自动化解决方案

Abstract: The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, which is defined by the spatial arrangement and morphology of the cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.

</details>


### [410] [Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification](https://arxiv.org/abs/2601.12308)
*Anurag Kaushish,Ayan Sar,Sampurna Roy,Sudeshna Chakraborty,Prashant Trivedi,Tanupriya Choudhury,Kanav Gupta*

Main category: cs.CV

Relevance: 25.0

TL;DR: AMC-MetaNet是一个轻量级元学习框架，通过相关引导特征金字塔、自适应通道相关模块和相关引导元学习来解决遥感小样本学习中的尺度变化、领域偏移和数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 遥感小样本学习面临三大挑战：标注数据稀缺、显著的领域偏移以及地理空间对象的多尺度特性。现有方法通常依赖大型预训练模型或Transformer，计算成本高且难以适应多尺度变化。

Method: 提出自适应多尺度相关元网络（AMC-MetaNet），包含三个关键创新：1）相关引导特征金字塔捕捉尺度不变模式；2）自适应通道相关模块学习动态跨尺度关系；3）相关引导元学习利用相关模式而非传统原型平均。

Result: AMC-MetaNet仅约60万参数，比ResNet-18少20倍，推理时间<50ms/图像。在EuroSAT、NWPU-RESISC45等遥感数据集上，5-way 5-shot分类准确率高达86.65%。

Conclusion: AMC-MetaNet是一个计算高效、尺度感知的框架，为实际遥感小样本学习提供了轻量级解决方案，无需依赖大型预训练模型。

Abstract: Few-shot learning in remote sensing remains challenging due to three factors: the scarcity of labeled data, substantial domain shifts, and the multi-scale nature of geospatial objects. To address these issues, we introduce Adaptive Multi-Scale Correlation Meta-Network (AMC-MetaNet), a lightweight yet powerful framework with three key innovations: (i) correlation-guided feature pyramids for capturing scale-invariant patterns, (ii) an adaptive channel correlation module (ACCM) for learning dynamic cross-scale relationships, and (iii) correlation-guided meta-learning that leverages correlation patterns instead of conventional prototype averaging. Unlike prior approaches that rely on heavy pre-trained models or transformers, AMC-MetaNet is trained from scratch with only $\sim600K$ parameters, offering $20\times$ fewer parameters than ResNet-18 while maintaining high efficiency ($<50$ms per image inference). AMC-MetaNet achieves up to 86.65\% accuracy in 5-way 5-shot classification on various remote sensing datasets, including EuroSAT, NWPU-RESISC45, UC Merced Land Use, and AID. Our results establish AMC-MetaNet as a computationally efficient, scale-aware framework for real-world few-shot remote sensing.

</details>


### [411] [HOT-POT: Optimal Transport for Sparse Stereo Matching](https://arxiv.org/abs/2601.12423)
*Antonin Clerc,Michael Quellmalz,Moritz Piening,Philipp Flotho,Gregor Kornhardt,Gabriele Steidl*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该论文提出了一种基于最优传输理论的非监督稀疏特征匹配方法，通过将相机投影点建模为（半）直线，利用经典极线距离和3D射线距离作为匹配质量度量，解决了立体视觉中因遮挡、运动和相机畸变带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 立体视觉在自动驾驶、机器人和人脸分析等应用中面临遮挡、运动和相机畸变等挑战。对于稀疏特征（如面部标志点）的立体匹配，参数敏感性进一步增加了问题的复杂性。为了克服这种不适定性并实现非监督稀疏匹配，作者从最优传输视角考虑相机几何的线约束。

Method: 将相机投影点建模为（半）直线，提出使用经典极线距离和3D射线距离来量化匹配质量。将这些距离作为（部分）最优传输问题的成本函数，得到可高效求解的分配问题。此外，通过将无监督对象匹配表述为分层最优传输问题来扩展该方法。

Result: 所提出的算法实现了高效的特征和对象匹配，在数值实验中得到了验证。特别关注面部分析应用，旨在匹配不同的标志点标注规范。

Conclusion: 该方法通过最优传输框架有效解决了立体视觉中的稀疏特征匹配问题，特别是在面部标志点匹配等应用中表现出色，为处理不同标注规范提供了有效解决方案。

Abstract: Stereo vision between images faces a range of challenges, including occlusions, motion, and camera distortions, across applications in autonomous driving, robotics, and face analysis. Due to parameter sensitivity, further complications arise for stereo matching with sparse features, such as facial landmarks. To overcome this ill-posedness and enable unsupervised sparse matching, we consider line constraints of the camera geometry from an optimal transport (OT) viewpoint. Formulating camera-projected points as (half)lines, we propose the use of the classical epipolar distance as well as a 3D ray distance to quantify matching quality. Employing these distances as a cost function of a (partial) OT problem, we arrive at efficiently solvable assignment problems. Moreover, we extend our approach to unsupervised object matching by formulating it as a hierarchical OT problem. The resulting algorithms allow for efficient feature and object matching, as demonstrated in our numerical experiments. Here, we focus on applications in facial analysis, where we aim to match distinct landmarking conventions.

</details>


### [412] [NeuralFur: Animal Fur Reconstruction From Multi-View Images](https://arxiv.org/abs/2601.12481)
*Vanessa Sklyarova,Berna Kabadayi,Anastasios Yiannakidis,Giorgio Becherini,Michael J. Black,Justus Thies*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出首个基于多视角图像的高保真3D动物毛发重建方法，利用视觉语言模型（VLM）获取毛发结构先验知识，通过几何和光度损失监督重建过程。


<details>
  <summary>Details</summary>
Motivation: 从图像重建逼真的动物毛发几何极具挑战，因为毛发具有精细细节、自遮挡和视角相关外观。与人类发型重建不同，缺乏可用于学习不同动物毛发先验的数据集。

Method: 1. 使用传统多视角立体技术重建粗糙表面几何；2. 利用VLM系统检索身体各部位毛发的真实长度结构信息；3. 基于此构建无毛几何并在其上生长毛发束；4. 使用多视角图像计算的几何和光度损失监督重建；5. 利用VLM指导毛发束生长方向和重力向量关系以解决方向模糊问题。

Result: 展示了该方法在多种不同毛发类型动物上的泛化能力，实现了高保真的3D毛发建模。

Conclusion: 提出了利用VLM指导多视角输入3D重建的新范式，成功解决了动物毛发重建中缺乏先验知识的问题，实现了跨物种的泛化。

Abstract: Reconstructing realistic animal fur geometry from images is a challenging task due to the fine-scale details, self-occlusion, and view-dependent appearance of fur. In contrast to human hairstyle reconstruction, there are also no datasets that can be leveraged to learn a fur prior for different animals. In this work, we present a first multi-view-based method for high-fidelity 3D fur modeling of animals using a strand-based representation, leveraging the general knowledge of a vision language model. Given multi-view RGB images, we first reconstruct a coarse surface geometry using traditional multi-view stereo techniques. We then use a vision language model (VLM) system to retrieve information about the realistic length structure of the fur for each part of the body. We use this knowledge to construct the animal's furless geometry and grow strands atop it. The fur reconstruction is supervised with both geometric and photometric losses computed from multi-view images. To mitigate orientation ambiguities stemming from the Gabor filters that are applied to the input images, we additionally utilize the VLM to guide the strands' growth direction and their relation to the gravity vector that we incorporate as a loss. With this new schema of using a VLM to guide 3D reconstruction from multi-view inputs, we show generalization across a variety of animals with different fur types. For additional results and code, please refer to https://neuralfur.is.tue.mpg.de.

</details>


### [413] [Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods](https://arxiv.org/abs/2601.12500)
*Yaowu Fan,Jia Wan,Tao Han,Andy J. Ma,Antoni B. Chan*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出基于移动无人机的大规模密集人群计数与追踪方法，包括新数据集MovingDroneCrowd++和GD3A/DVTrack算法，显著提升密集复杂场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有密集人群计数方法主要依赖固定摄像头数据集，空间覆盖有限，无法满足大规模场景分析需求。移动无人机能提供更灵活的视角和覆盖范围，但缺乏相应数据集和方法。

Method: 1) 提出MovingDroneCrowd++数据集：最大规模的移动无人机密集人群视频数据集；2) GD3A方法：基于密度图的视频个体计数，通过最优传输建立像素级描述符对应关系，分解全局密度图为共享、流入、流出分量；3) DVTrack方法：通过描述符投票机制将描述符级匹配转为实例级关联，实现行人追踪。

Result: 在密集人群和复杂运动条件下，方法显著优于现有方法：计数误差降低47.4%，追踪性能提升39.2%。

Conclusion: 移动无人机为大规模密集人群分析提供了新范式，提出的数据集和算法有效解决了固定摄像头方法的局限性，在复杂场景下表现出色。

Abstract: Counting and tracking dense crowds in large-scale scenes is highly challenging, yet existing methods mainly rely on datasets captured by fixed cameras, which provide limited spatial coverage and are inadequate for large-scale dense crowd analysis. To address this limitation, we propose a flexible solution using moving drones to capture videos and perform video-level crowd counting and tracking of unique pedestrians across entire scenes. We introduce MovingDroneCrowd++, the largest video-level dataset for dense crowd counting and tracking captured by moving drones, covering diverse and complex conditions with varying flight altitudes, camera angles, and illumination. Existing methods fail to achieve satisfactory performance on this dataset. To this end, we propose GD3A (Global Density Map Decomposition via Descriptor Association), a density map-based video individual counting method that avoids explicit localization. GD3A establishes pixel-level correspondences between pedestrian descriptors across consecutive frames via optimal transport with an adaptive dustbin score, enabling the decomposition of global density maps into shared, inflow, and outflow components. Building on this framework, we further introduce DVTrack, which converts descriptor-level matching into instance-level associations through a descriptor voting mechanism for pedestrian tracking. Experimental results show that our methods significantly outperform existing approaches under dense crowds and complex motion, reducing counting error by 47.4 percent and improving tracking performance by 39.2 percent.

</details>


### [414] [Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images](https://arxiv.org/abs/2601.12512)
*Mohd Usama,Belal Ahmad,Faleh Menawer R Althiyabi*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出基于CycleGAN的无监督医学图像域适应方法，用于解决不同MRI扫描仪间的域偏移问题，无需配对训练数据即可学习双向映射，保持图像解剖结构完整性。


<details>
  <summary>Details</summary>
Motivation: 不同MRI扫描仪和机构获取的图像存在域偏移（硬件、协议、采集参数差异），导致在源域训练的深度学习模型在目标域性能下降，需要无监督域适应方法来提升模型跨域性能。

Method: 基于CycleGAN的无监督域适应模型，学习源域和目标域间的双向映射，无需配对训练数据。采用内容和差异损失函数，在适应过程中保持图像完整性。

Result: 在多个MRI数据集上的实验表明，该方法能有效实现双向域适应，无需标注数据。统计结果证实该方法能提升模型性能，减少域相关变异性，提高医学图像分析的一致性和准确性。

Conclusion: 提出的CycleGAN-based域适应方法为解决医学图像域偏移问题提供了有效方案，有望提升医疗诊断准确性，为更精确、一致的医学图像分析做出贡献。

Abstract: Magnetic Resonance Imaging (MRI) scans acquired from different scanners or institutions often suffer from domain shifts owing to variations in hardware, protocols, and acquisition parameters. This discrepancy degrades the performance of deep learning models trained on source domain data when applied to target domain images. In this study, we propose a Cycle-GAN-based model for unsupervised medical-image domain adaptation. Leveraging CycleGANs, our model learns bidirectional mappings between the source and target domains without paired training data, preserving the anatomical content of the images. By leveraging Cycle-GAN capabilities with content and disparity loss for adaptation tasks, we ensured image-domain adaptation while maintaining image integrity. Several experiments on MRI datasets demonstrated the efficacy of our model in bidirectional domain adaptation without labelled data. Furthermore, research offers promising avenues for improving the diagnostic accuracy of healthcare. The statistical results confirm that our approach improves model performance and reduces domain-related variability, thus contributing to more precise and consistent medical image analysis.

</details>


### [415] [Encoding Emotion Through Self-Supervised Eye Movement Reconstruction](https://arxiv.org/abs/2601.12534)
*Marcus Ma,Jordan Prescott,Emily Zhou,Tiantian Feng,Kleanthis Avramidis,Gabor Mihaly Toth,Shrikanth Narayanan*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出基于自监督眼动重建的新方法，从低分辨率视频中预测情感表达的多模态标记，在Holocaust幸存者访谈数据集上验证了模型有效性


<details>
  <summary>Details</summary>
Motivation: 现有眼动-情感关系研究依赖高分辨率眼动追踪设备，限制了应用范围。本文旨在探索如何从自然、低分辨率视频中利用眼动预测情感表达的多模态标记

Method: 1) 受语言模型预训练启发，开发自监督眼动重建模型，有效利用未标记视频；2) 使用模型编码器嵌入微调两个下游任务：眼动与语音情感方向估计对齐，以及眼动预测三种瞬时情感行为（笑、哭/抽泣、叹气）

Result: 新模型能有效预测情感结果，观察到预训练性能与情感处理性能呈正相关，表明自监督眼动重建是编码情感信号的有效方法

Conclusion: 自监督眼动重建是从低分辨率视频中编码情感信号的有效方法，为情感计算研究提供了更广泛的应用可能性

Abstract: The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation's Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model's encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry.

</details>


### [416] [Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images](https://arxiv.org/abs/2601.12664)
*Elisa Gonçalves Ribeiro,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该论文研究了在癌症组织病理学联邦学习中，针对非独立同分布数据集的超参数优化问题。通过集中式贝叶斯超参数优化，并将数据集特定最优配置转移到联邦学习设置中，提出了一种简单的跨数据集聚合启发式方法。


<details>
  <summary>Details</summary>
Motivation: 癌症组织病理学深度学习训练面临临床隐私约束，联邦学习可以保持数据本地化，但其性能在非独立同分布客户端数据集下依赖于超参数选择。需要研究在一种癌症影像数据集上优化的超参数是否能泛化到其他非独立同分布联邦场景。

Method: 针对卵巢癌和结直肠癌的二元组织病理学任务，进行集中式贝叶斯超参数优化，然后将数据集特定最优配置转移到非独立同分布联邦学习设置中。主要贡献是引入简单的跨数据集聚合启发式方法：通过平均学习率、考虑模态优化器和批量大小来组合配置。

Result: 组合配置实现了具有竞争力的分类性能，表明该方法在非独立同分布联邦学习场景中有效。

Conclusion: 提出的跨数据集聚合启发式方法能够为癌症组织病理学的非独立同分布联邦学习提供有效的超参数配置，平衡了隐私保护和模型性能。

Abstract: Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.

</details>


### [417] [RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels](https://arxiv.org/abs/2601.12715)
*Chengzhou Li,Ping Guo,Guanchen Meng,Qi Jia,Jinyuan Liu,Zhu Liu,Xiaokang Liu,Yu Liu,Zhongxuan Luo,Xin Fan*

Main category: cs.CV

Relevance: 25.0

TL;DR: RSOD：一种面向声纳图像的教师-学生框架，通过可靠性评分和对象混合伪标签策略解决标注数据极度稀缺的问题，在仅5%标注数据下达到与全标注基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 声纳图像相比自然图像纹理细节少、噪声多，非专家难以区分类别间的细微差异，导致无法提供精确标注数据。因此，在标注数据极度有限的情况下设计有效的声纳图像目标检测方法尤为重要。

Method: 提出RSOD教师-学生框架：1）通过评估教师模型在不同视图下预测的一致性计算可靠性评分；2）引入对象混合伪标签方法解决声纳图像标注数据短缺问题；3）实施可靠性引导的自适应约束优化学生模型性能。

Result: 在UATD数据集上，仅使用5%标注数据的RSOD方法能够与使用100%标注数据的基线算法竞争。此外，作者还收集了新数据集为声纳领域研究提供更有价值的数据。

Conclusion: RSOD框架通过充分利用未标注数据，在标注数据极度有限的情况下仍能实现良好的目标检测性能，为解决声纳图像标注困难问题提供了有效方案。

Abstract: Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.

</details>


### [418] [KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction](https://arxiv.org/abs/2601.12736)
*Qingtian Zhu,Xu Cao,Zhixiang Wang,Yinqiang Zheng,Takafumi Taketomi*

Main category: cs.CV

Relevance: 25.0

TL;DR: KaoLRM利用预训练的3D先验知识（LRM）改进单视角图像到参数化3D人脸的重建，通过将LRM的三平面特征投影到FLAME参数空间，并结合2D高斯泼溅渲染，实现了更好的视角一致性和重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有参数化3D人脸重建方法（3DMM回归器）在不同视角下的一致性较差，对视角变化敏感。为了解决这个问题，作者希望利用预训练的大规模重建模型（LRM）的3D先验知识来改进重建的鲁棒性和一致性。

Method: 1) 利用预训练的LRM模型的3D先验知识；2) 将LRM的三平面特征投影到FLAME参数空间来恢复几何形状；3) 使用与FLAME网格紧密耦合的2D高斯基元建模外观；4) 在LRM的渲染流程中集成基于FLAME的2D高斯泼溅技术。

Result: 在受控和野外基准测试中，KaoLRM在重建精度和跨视角一致性方面优于现有方法，特别是在自遮挡和多样视角下表现出更好的鲁棒性，而现有方法对视角变化仍然敏感。

Conclusion: 通过利用预训练的3D先验知识并将其与参数化人脸模型（FLAME）相结合，KaoLRM能够实现更准确、更鲁棒的单视角3D人脸重建，显著提高了跨视角的一致性。

Abstract: We propose KaoLRM to re-target the learned prior of the Large Reconstruction Model (LRM) for parametric 3D face reconstruction from single-view images. Parametric 3D Morphable Models (3DMMs) have been widely used for facial reconstruction due to their compact and interpretable parameterization, yet existing 3DMM regressors often exhibit poor consistency across varying viewpoints. To address this, we harness the pre-trained 3D prior of LRM and incorporate FLAME-based 2D Gaussian Splatting into LRM's rendering pipeline. Specifically, KaoLRM projects LRM's pre-trained triplane features into the FLAME parameter space to recover geometry, and models appearance via 2D Gaussian primitives that are tightly coupled to the FLAME mesh. The rich prior enables the FLAME regressor to be aware of the 3D structure, leading to accurate and robust reconstructions under self-occlusions and diverse viewpoints. Experiments on both controlled and in-the-wild benchmarks demonstrate that KaoLRM achieves superior reconstruction accuracy and cross-view consistency, while existing methods remain sensitive to viewpoint variations. The code is released at https://github.com/CyberAgentAILab/KaoLRM.

</details>


### [419] [SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification](https://arxiv.org/abs/2601.12791)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Hongyuan Shu,Junchu Zhao,Yanjun Huang,Yue Xiu,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

Relevance: 25.0

TL;DR: SKANet：一种用于GNSS复合干扰分类的认知深度学习框架，通过双流架构整合时频图像和功率谱密度，采用选择性核与不对称卷积模块动态调整感受野，在低信噪比下实现96.99%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 随着电磁环境日益复杂，全球导航卫星系统面临越来越复杂的干扰威胁。深度学习能有效识别基本干扰，但对复合干扰分类困难，因为不同干扰源叠加且瞬态突发信号与连续全局信号需要冲突的特征提取尺度。现有单域方法性能下降严重。

Method: 提出SKANet（选择性核与不对称卷积网络），基于双流架构整合时频图像和功率谱密度。核心创新包括：1）多分支选择性核模块结合不对称卷积块，动态调整感受野，同时捕获微尺度瞬态特征和宏尺度频谱趋势；2）融合阶段集成Squeeze-and-Excitation机制，自适应重新校准各模态异构特征的贡献。

Result: 在包含405,000个样本的数据集上评估，SKANet实现96.99%的整体准确率，在复合干扰分类方面表现出优越的鲁棒性，特别是在低信噪比条件下。

Conclusion: SKANet通过动态感受野调整和自适应特征融合，有效解决了复合干扰分类中的尺度冲突问题，为复杂电磁环境下的GNSS干扰识别提供了有效的深度学习解决方案。

Abstract: As the electromagnetic environment becomes increasingly complex, Global Navigation Satellite Systems (GNSS) face growing threats from sophisticated jamming interference. Although Deep Learning (DL) effectively identifies basic interference, classifying compound interference remains difficult due to the superposition of diverse jamming sources. Existing single-domain approaches often suffer from performance degradation because transient burst signals and continuous global signals require conflicting feature extraction scales. We propose the Selective Kernel and Asymmetric convolution Network(SKANet), a cognitive deep learning framework built upon a dual-stream architecture that integrates Time-Frequency Images (TFIs) and Power Spectral Density (PSD). Distinct from conventional fusion methods that rely on static receptive fields, the proposed architecture incorporates a Multi-Branch Selective Kernel (SK) module combined with Asymmetric Convolution Blocks (ACBs). This mechanism enables the network to dynamically adjust its receptive fields, acting as an adaptive filter that simultaneously captures micro-scale transient features and macro-scale spectral trends within entangled compound signals. To complement this spatial-temporal adaptation, a Squeeze-and-Excitation (SE) mechanism is integrated at the fusion stage to adaptively recalibrate the contribution of heterogeneous features from each modality. Evaluations on a dataset of 405,000 samples demonstrate that SKANet achieves an overall accuracy of 96.99\%, exhibiting superior robustness for compound jamming classification, particularly under low Jamming-to-Noise Ratio (JNR) regimes.

</details>


### [420] [TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement](https://arxiv.org/abs/2601.12823)
*Belal Shaheen,Minh-Hieu Nguyen,Bach-Thuan Bui,Shubham,Tim Wu,Michael Fairley,Matthew David Zane,Michael Wu,James Tompkin*

Main category: cs.CV

Relevance: 25.0

TL;DR: TreeDGS：基于3D高斯泼溅的航空图像重建方法，用于从航拍图像中准确测量树木胸径（DBH），在10个地块上达到4.79cm RMSE，优于LiDAR基线（7.91cm RMSE）。


<details>
  <summary>Details</summary>
Motivation: 航空遥感虽然能高效进行大面积勘测，但在复杂自然场景中难以实现准确的直接物体级测量。特别是树木胸径（DBH）的测量，由于树干在航拍图像中距离远、观测稀疏（通常只占几个像素），传统重建方法无法有效约束胸高处的树干几何形状。

Method: 提出TreeDGS方法：1）使用3D高斯泼溅作为连续、可致密化的场景表示；2）通过SfM-MVS初始化和高斯优化；3）使用RaDe-GS的深度感知累积不透明度积分从高斯场提取密集点集；4）为每个样本分配多视角不透明度可靠性分数；5）通过不透明度加权实心圆拟合从树干隔离点估计DBH。

Result: 在10个具有实地测量DBH的地块上评估，TreeDGS达到4.79cm RMSE（约2.6像素），优于最先进的LiDAR基线（7.91cm RMSE），表明基于泼溅的致密化几何能够实现准确、低成本的航空DBH测量。

Conclusion: TreeDGS通过3D高斯泼溅表示和优化方法，成功解决了航拍图像中树干几何约束弱的问题，实现了比传统LiDAR更准确的树木胸径测量，为低成本航空森林测量提供了新途径。

Abstract: Aerial remote sensing enables efficient large-area surveying, but accurate direct object-level measurement remains difficult in complex natural scenes. Recent advancements in 3D vision, particularly learned radiance-field representations such as NeRF and 3D Gaussian Splatting, have begun to raise the ceiling on reconstruction fidelity and densifiable geometry from posed imagery. Nevertheless, direct aerial measurement of important natural attributes such as tree diameter at breast height (DBH) remains challenging. Trunks in aerial forest scans are distant and sparsely observed in image views: at typical operating altitudes, stems may span only a few pixels. With these constraints, conventional reconstruction methods leave breast-height trunk geometry weakly constrained. We present TreeDGS, an aerial image reconstruction method that leverages 3D Gaussian Splatting as a continuous, densifiable scene representation for trunk measurement. After SfM-MVS initialization and Gaussian optimization, we extract a dense point set from the Gaussian field using RaDe-GS's depth-aware cumulative-opacity integration and associate each sample with a multi-view opacity reliability score. We then estimate DBH from trunk-isolated points using opacity-weighted solid-circle fitting. Evaluated on 10 plots with field-measured DBH, TreeDGS reaches 4.79,cm RMSE (about 2.6 pixels at this GSD) and outperforms a state-of-the-art LiDAR baseline (7.91,cm RMSE), demonstrating that densified splat-based geometry can enable accurate, low-cost aerial DBH measurement.

</details>


### [421] [FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection](https://arxiv.org/abs/2601.12863)
*Jun Wan,Xinyu Xiong,Ning Chen,Zhihui Lai,Jie Zhou,Wenwen Min*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出FGTBT框架，通过频率引导的结构感知和多数据集统一训练提升面部关键点检测，在挑战性场景下改善几何结构捕捉能力


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的面部关键点检测方法在姿态变化、光照变化和表情变化等挑战性场景下，难以准确捕捉面部几何结构，且现有数据集规模有限、多样性不足，限制了模型的鲁棒性训练

Method: 提出频率引导的任务平衡Transformer（FGTBT）：1）细粒度多任务平衡损失（FMB-loss），基于关键点在数据集中的出现频率分配权重，实现更有效的统一训练；2）频率引导的结构感知（FGSA）模型，通过频率引导的结构注入和正则化学习面部结构约束

Result: 在多个流行基准数据集上的实验结果表明，FGTBT框架实现了与最先进方法相当的性能

Conclusion: 通过频率域建模和多数据集统一训练，FGTBT能够增强面部结构感知，在挑战性场景下提升面部关键点检测的准确性和鲁棒性

Abstract: Recently, deep learning based facial landmark detection (FLD) methods have achieved considerable success. However, in challenging scenarios such as large pose variations, illumination changes, and facial expression variations, they still struggle to accurately capture the geometric structure of the face, resulting in performance degradation. Moreover, the limited size and diversity of existing FLD datasets hinder robust model training, leading to reduced detection accuracy. To address these challenges, we propose a Frequency-Guided Task-Balancing Transformer (FGTBT), which enhances facial structure perception through frequency-domain modeling and multi-dataset unified training. Specifically, we propose a novel Fine-Grained Multi-Task Balancing loss (FMB-loss), which moves beyond coarse task-level balancing by assigning weights to individual landmarks based on their occurrence across datasets. This enables more effective unified training and mitigates the issue of inconsistent gradient magnitudes. Additionally, a Frequency-Guided Structure-Aware (FGSA) model is designed to utilize frequency-guided structure injection and regularization to help learn facial structure constraints. Extensive experimental results on popular benchmark datasets demonstrate that the integration of the proposed FMB-loss and FGSA model into our FGTBT framework achieves performance comparable to state-of-the-art methods. The code is available at https://github.com/Xi0ngxinyu/FGTBT.

</details>


### [422] [YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection](https://arxiv.org/abs/2601.12882)
*Sudip Chakrabarty*

Main category: cs.CV

Relevance: 25.0

TL;DR: YOLO26通过消除NMS后处理，采用端到端学习策略，在实时目标检测中实现了延迟与精度的新帕累托前沿，超越了包括RTMDet和DAMO-YOLO在内的现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统YOLO系列（v1-v11）受限于NMS后处理的延迟和超参数敏感性，需要在实时目标检测中解决延迟与精度之间的权衡问题。

Method: 提出YOLO26架构，消除NMS后处理，采用端到端学习策略。关键技术包括：MuSGD优化器稳定轻量级骨干网络、STAL小目标感知分配机制、ProgLoss动态监督损失函数。

Result: 在官方性能基准测试中，YOLO26建立了新的帕累托前沿，在推理速度和检测精度上均超越了包括RTMDet和DAMO-YOLO在内的前代方法和最先进竞争对手。

Conclusion: 通过将表示学习与启发式后处理解耦，YOLO26成功解决了延迟与精度之间的历史权衡，标志着边缘计算机视觉的下一个进化步骤。

Abstract: The "You Only Look Once" (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.

</details>


### [423] [Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning](https://arxiv.org/abs/2601.12889)
*Nazibul Basar Ayon,Abdul Hasib,Md. Faishal Ahmed,Md. Sadiqur Rahman,Kamrul Islam,T. M. Mehrab Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

Relevance: 25.0

TL;DR: 本文提出了一种集成深度学习框架，用于同时检测牛结节性皮肤病（LSD）和口蹄疫（FMD），通过优化加权平均集成VGG16、ResNet50和InceptionV3模型，在10,516张图像上达到98.2%的准确率。


<details>
  <summary>Details</summary>
Motivation: LSD和FMD是高度传染性的牛病毒疾病，造成重大经济损失。视觉诊断面临症状重叠（包括彼此之间以及与良性状况如昆虫叮咬或化学烧伤）的挑战，这阻碍了及时的控制措施。

Method: 使用来自印度、巴西和美国18个农场的10,516张专家标注图像，提出了一种新颖的集成深度学习框架，集成VGG16、ResNet50和InceptionV3模型，采用优化加权平均策略进行同时LSD和FMD检测。

Result: 模型达到最先进的98.2%准确率，宏平均精确率98.2%、召回率98.1%、F1分数98.1%、AUC-ROC 99.5%。独特解决了多疾病检测中症状重叠的关键挑战。

Conclusion: 该方法能够实现早期、精确和自动化的诊断，有潜力增强疾病管理，支持全球农业可持续性，并设计用于未来在资源有限环境中的部署。

Abstract: Lumpy Skin Disease (LSD) and Foot-and-Mouth Disease (FMD) are highly contagious viral diseases affecting cattle, causing significant economic losses and welfare challenges. Their visual diagnosis is complicated by significant symptom overlap with each other and with benign conditions like insect bites or chemical burns, hindering timely control measures. Leveraging a comprehensive dataset of 10,516 expert-annotated images from 18 farms across India, Brazil, and the USA, this study presents a novel Ensemble Deep Learning framework integrating VGG16, ResNet50, and InceptionV3 with optimized weighted averaging for simultaneous LSD and FMD detection. The model achieves a state-of-the-art accuracy of 98.2\%, with macro-averaged precision of 98.2\%, recall of 98.1\%, F1-score of 98.1\%, and an AUC-ROC of 99.5\%. This approach uniquely addresses the critical challenge of symptom overlap in multi-disease detection, enabling early, precise, and automated diagnosis. This tool has the potential to enhance disease management, support global agricultural sustainability, and is designed for future deployment in resource-limited settings.

</details>


### [424] [Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection](https://arxiv.org/abs/2601.12919)
*Jun Wan,Yuanzhi Yao,Zhihui Lai,Jie Zhou,Xianxu Hou,Wenwen Min*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出SHT弱监督框架，通过双幻觉学习和面部姿态迁移提升低分辨率人脸图像的地标检测精度


<details>
  <summary>Details</summary>
Motivation: 低分辨率人脸图像或图像压缩会阻碍高分辨率深度特征表示的学习，从而降低面部地标检测精度；训练数据不足和标注不精确进一步影响性能

Method: 提出SHT框架，包含两个相互增强的模块：DHLN（双幻觉学习网络）通过结合地标检测和人脸幻觉任务学习高分辨率表示；FPTN（面部姿态迁移网络）通过姿态变换进一步改进地标热图

Result: 在人脸幻觉和面部地标检测任务上都超越了现有最佳技术

Conclusion: 这是首个通过整合人脸幻觉和面部姿态迁移任务探索弱监督面部地标检测的研究，提出的SHT框架在低分辨率输入下能实现更鲁棒和精确的地标检测

Abstract: High-precision facial landmark detection (FLD) relies on high-resolution deep feature representations. However, low-resolution face images or the compression (via pooling or strided convolution) of originally high-resolution images hinder the learning of such features, thereby reducing FLD accuracy. Moreover, insufficient training data and imprecise annotations further degrade performance. To address these challenges, we propose a weakly-supervised framework called Supervision-by-Hallucination-and-Transfer (SHT) for more robust and precise FLD. SHT contains two novel mutually enhanced modules: Dual Hallucination Learning Network (DHLN) and Facial Pose Transfer Network (FPTN). By incorporating FLD and face hallucination tasks, DHLN is able to learn high-resolution representations with low-resolution inputs for recovering both facial structures and local details and generating more effective landmark heatmaps. Then, by transforming faces from one pose to another, FPTN can further improve landmark heatmaps and faces hallucinated by DHLN for detecting more accurate landmarks. To the best of our knowledge, this is the first study to explore weakly-supervised FLD by integrating face hallucination and facial pose transfer tasks. Experimental results of both face hallucination and FLD demonstrate that our method surpasses state-of-the-art techniques.

</details>


### [425] [Dual-Stream Collaborative Transformer for Image Captioning](https://arxiv.org/abs/2601.12926)
*Jun Wan,Jun Liu,Zhihui lai,Jie Zhou*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出DSCT（双流协作Transformer）用于图像描述生成，通过融合区域特征和分割特征来解决现有方法缺乏上下文信息、过度依赖部分生成描述的问题，在多个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于区域特征的图像描述方法虽然进展迅速，但仍容易生成不相关描述，主要原因是缺乏上下文信息以及过度依赖已生成的部分描述来预测剩余词汇。需要解决不同模式特征之间的语义不一致和空间错位问题。

Method: 提出双流协作Transformer（DSCT），包含多个模式特定互注意力编码器（PSMAE）和动态提名解码器（DND）。PSMAE通过相互查询有效突出和整合两种表示的私有信息；DND动态搜索与输入文本表示最相关的学习块，并利用整合后的区域和分割特征之间的同质特征来生成更准确、更具描述性的句子。

Result: 在多个流行的基准数据集上的实验结果表明，DSCT在图像描述任务上优于文献中最先进的模型。

Conclusion: 这是首个探索如何以动态方式融合不同模式特定特征以绕过其语义不一致和空间错位问题的研究，为图像描述生成提供了新的有效方法。

Abstract: Current region feature-based image captioning methods have progressed rapidly and achieved remarkable performance. However, they are still prone to generating irrelevant descriptions due to the lack of contextual information and the over-reliance on generated partial descriptions for predicting the remaining words. In this paper, we propose a Dual-Stream Collaborative Transformer (DSCT) to address this issue by introducing the segmentation feature. The proposed DSCT consolidates and then fuses the region and segmentation features to guide the generation of caption sentences. It contains multiple Pattern-Specific Mutual Attention Encoders (PSMAEs) and Dynamic Nomination Decoders (DNDs). The PSMAE effectively highlights and consolidates the private information of two representations by querying each other. The DND dynamically searches for the most relevant learning blocks to the input textual representations and exploits the homogeneous features between the consolidated region and segmentation features to generate more accurate and descriptive caption sentences. To the best of our knowledge, this is the first study to explore how to fuse different pattern-specific features in a dynamic way to bypass their semantic inconsistencies and spatial misalignment issues for image captioning. The experimental results from popular benchmark datasets demonstrate that our DSCT outperforms the state-of-the-art image captioning models in the literature.

</details>


### [426] [GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation](https://arxiv.org/abs/2601.12948)
*Riccardo Catalini,Davide Di Nucci,Guido Borghi,Davide Davoli,Lorenzo Garattoni,Giampiero Francesca,Yuki Kawana,Roberto Vezzani*

Main category: cs.CV

Relevance: 25.0

TL;DR: GazeD：一种基于扩散模型的单RGB图像3D视线估计方法，同时生成3D视线和人体姿态，通过多假设生成处理不确定性，在多个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 从单张RGB图像同时估计3D视线和人体姿态具有挑战性，传统方法难以处理视线估计中的不确定性。扩散模型能够处理不确定性并生成多个合理假设，为这一问题提供了新的解决方案。

Method: 1）使用扩散模型生成多个3D视线和姿态假设；2）将3D视线表示为距离眼睛固定距离的额外身体关节；3）在去噪过程中以2D姿态、主体周围环境和场景上下文为条件；4）联合去噪视线和姿态。

Result: 在三个基准数据集上的评估表明，GazeD在3D视线估计方面达到了最先进的性能，甚至超过了依赖时序信息的方法。

Conclusion: GazeD证明了扩散模型在3D视线估计中的有效性，通过将视线表示为额外身体关节并与姿态联合估计，能够处理不确定性并实现高精度估计。

Abstract: We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at https://aimagelab.ing.unimore.it/go/gazed.

</details>


### [427] [Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures](https://arxiv.org/abs/2601.13059)
*Yulun Guo*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种基于Retinex理论和少样本学习的双分支原型学习网络，用于低光照条件下的混凝土裂缝分割，通过反射分量引导光照不变表示学习，减少对大规模标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 混凝土裂缝检测对基础设施安全至关重要，但真实世界裂缝常出现在隧道、桥底等低光照环境中，导致计算机视觉分割精度下降。像素级标注低光照裂缝图像极其耗时，而大多数深度学习方法需要大规模、良好光照的数据集。

Method: 提出双分支原型学习网络，集成Retinex理论和少样本学习：1) Retinex-based反射分量引导光照不变全局表示学习；2) 度量学习减少对大规模标注数据的依赖；3) 跨相似性先验掩码生成模块计算查询和支持特征间的高维相似性以捕捉裂缝位置和结构；4) 多尺度特征增强模块融合多尺度特征与先验掩码以缓解空间不一致性。

Result: 在多个基准测试上的广泛实验表明，该方法在低光照条件下取得了最先进的性能。

Conclusion: 该方法有效解决了低光照环境下混凝土裂缝分割的挑战，通过结合Retinex理论和少样本学习，实现了对光照变化鲁棒且数据高效的裂缝检测。

Abstract: Crack detection is critical for concrete infrastructure safety, but real-world cracks often appear in low-light environments like tunnels and bridge undersides, degrading computer vision segmentation accuracy. Pixel-level annotation of low-light crack images is extremely time-consuming, yet most deep learning methods require large, well-illuminated datasets. We propose a dual-branch prototype learning network integrating Retinex theory with few-shot learning for low-light crack segmentation. Retinex-based reflectance components guide illumination-invariant global representation learning, while metric learning reduces dependence on large annotated datasets. We introduce a cross-similarity prior mask generation module that computes high-dimensional similarities between query and support features to capture crack location and structure, and a multi-scale feature enhancement module that fuses multi-scale features with the prior mask to alleviate spatial inconsistency. Extensive experiments on multiple benchmarks demonstrate consistent state-of-the-art performance under low-light conditions. Code: https://github.com/YulunGuo/CrackFSS.

</details>


### [428] [Deep Learning for Semantic Segmentation of 3D Ultrasound Data](https://arxiv.org/abs/2601.13263)
*Chenyu Liu,Marco Cecotti,Harikrishnan Vijayakumar,Patrick Robinson,James Barson,Mihai Caleap*

Main category: cs.CV

Relevance: 25.0

TL;DR: 本文提出了一种基于Calyo Pulse固态3D超声传感器系统的学习型3D语义分割框架，用于恶劣和杂乱环境中的自动驾驶感知。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶感知系统主要依赖LiDAR和摄像头，但在成本、鲁棒性和恶劣环境性能方面存在权衡。需要开发成本效益高且可靠的感知系统，特别是在恶劣和杂乱环境中。

Method: 引入基于Calyo Pulse模块化固态3D超声传感器系统的学习框架，采用3D U-Net架构在空间超声数据上进行训练，实现体积分割。

Result: 实验结果表明Calyo Pulse传感器具有稳健的分割性能，通过更大数据集、精细化地面真值和加权损失函数有进一步改进潜力。

Conclusion: 3D超声传感是可靠自动驾驶的有前景的补充模态，为恶劣环境感知提供了新解决方案。

Abstract: Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.

</details>


### [429] [MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic](https://arxiv.org/abs/2601.13331)
*Wei Wang,Quoc-Toan Ly,Chong Yu,Jun Bai*

Main category: cs.CV

Relevance: 25.0

TL;DR: MultiST是一个统一的多模态框架，通过跨注意力融合联合建模空间拓扑、基因表达和组织形态学，用于空间转录组学分析，能产生更清晰的空间域边界。


<details>
  <summary>Details</summary>
Motivation: 现有空间转录组学方法缺乏组织形态学与分子谱的有效整合，通常采用浅层融合策略或完全忽略组织图像，限制了其解析模糊空间域边界的能力。

Method: 提出MultiST框架：1) 使用基于图的基因编码器与对抗对齐学习鲁棒空间表示；2) 通过跨注意力融合整合颜色归一化的组织学特征；3) 联合建模空间拓扑、基因表达和组织形态学。

Result: 在13个不同ST数据集（包括人类大脑皮层和乳腺癌组织）上评估，MultiST产生比现有方法更清晰、更一致的空间域边界，导致更稳定的伪时间轨迹和更具生物学可解释性的细胞间相互作用模式。

Conclusion: MultiST通过有效整合多模态信息，显著提升了空间转录组学分析的质量，为研究组织结构和细胞间相互作用提供了更强大的工具。

Abstract: Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at https://github.com/LabJunBMI/MultiST.git.

</details>


### [430] [Deep Image Prior with L0 Gradient Regularizer for Image Smoothing](https://arxiv.org/abs/2601.13400)
*Nhat Thanh Tran,Kevin Bui,Jack Xin*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出DIP-ℓ₀框架，结合深度图像先验和ℓ₀梯度正则化，无需训练数据即可实现高质量图像平滑


<details>
  <summary>Details</summary>
Motivation: 传统图像平滑方法依赖局部窗口统计或优化问题，而基于深度学习的方法需要精心构建的训练数据集。由于构建合适的图像平滑训练数据集具有挑战性，作者提出无需训练数据的深度图像先验框架。

Method: 提出DIP-ℓ₀框架，将ℓ₀梯度正则化器融入深度图像先验。开发了交替方向乘子法（ADMM）算法来最小化包含非凸、非光滑ℓ₀"范数"的损失函数，并利用现成的ℓ₀梯度最小化求解器。

Result: 数值实验表明，DIP-ℓ₀在边缘保持图像平滑和JPEG伪影去除方面优于许多现有图像平滑算法。

Conclusion: DIP-ℓ₀框架能够在不依赖训练数据的情况下实现高质量的图像平滑，为图像处理任务提供了一种有效的数据无关深度学习方法。

Abstract: Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\ell_0$, a deep image prior framework that incorporates the $\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\ell_0$ ``norm", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.

</details>


### [431] [GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models](https://arxiv.org/abs/2601.13524)
*Yang Yu,Yunze Deng,Yige Zhang,Yanjie Xiao,Youkun Ou,Wenhao Hu,Mingchao Li,Bin Feng,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

Relevance: 25.0

TL;DR: GO-MLVTON是首个多层虚拟试穿方法，通过服装遮挡学习和基于StableDiffusion的服装变形拟合模块，解决多层服装试穿中的遮挡关系和变形问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像虚拟试穿方法主要关注单层或多件服装试穿，忽略了多层服装试穿（ML-VTON），即需要将多层服装穿在人体上，产生真实的变形和层次效果。主要挑战在于准确建模内外服装之间的遮挡关系，以减少冗余内层服装特征的干扰。

Method: 提出GO-MLVTON方法，包含两个核心模块：1) 服装遮挡学习模块，学习遮挡关系；2) 基于StableDiffusion的服装变形与拟合模块，将服装变形并适配到人体上。同时构建了MLG数据集用于该任务。

Result: 实验表明GO-MLVTON达到了最先进的性能。提出了新的评估指标LACD（分层外观一致性差异）用于评估多层试穿效果。

Conclusion: GO-MLVTON是首个解决多层虚拟试穿问题的方法，能够生成高质量的多层试穿结果，通过遮挡学习和变形拟合技术有效解决了多层服装的遮挡和变形挑战。

Abstract: Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.

</details>


### [432] [ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins](https://arxiv.org/abs/2601.13706)
*Xinhao Liu,Yu Wang,Xiansheng Guo,Gordon Owusu Boateng,Yu Cao,Haonan Si,Xingchen Guo,Nirwan Ansari*

Main category: cs.CV

Relevance: 25.0

TL;DR: ParkingTwin：一种免训练、轻量级的在线流式3D重建系统，用于停车场数字孪生，解决了机器人导向重建中的三难问题（稀疏视角、动态遮挡、极端光照），在低端GPU上实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 停车场高保真数字孪生对自动代客泊车（AVP）的路径规划、碰撞检测和感知验证至关重要，但现有方法面临三难困境：稀疏前向视角导致弱视差和病态几何；动态遮挡和极端光照阻碍稳定纹理融合；神经渲染通常需要昂贵的离线优化，违反边缘端流式约束。

Method: 1. OSM先验驱动的几何构建：利用OpenStreetMap语义拓扑直接生成度量一致的TSDF，替代盲目的几何搜索；2. 几何感知的动态过滤：使用四模态约束场（法线/高度/深度一致性）实时剔除移动车辆和瞬态遮挡；3. 光照鲁棒的CIELAB融合：通过自适应L通道加权和深度梯度抑制解耦亮度和色度，减少光照突变下的接缝。

Result: 在GTX 1660上以30+ FPS运行，在68,000 m²真实世界数据集上达到SSIM 0.87（提升16.0%），相比需要高端GPU（RTX 4090D）的3D高斯泼溅（3DGS）实现约15倍端到端加速，GPU内存减少83.3%。

Conclusion: ParkingTwin提供了一种高效、实用的停车场数字孪生解决方案，在低端硬件上实现实时性能，输出与Unity/Unreal数字孪生流水线兼容的显式三角网格，为AVP系统提供了可靠的先验信息。

Abstract: High-fidelity parking-lot digital twins provide essential priors for path planning, collision checking, and perception validation in Automated Valet Parking (AVP). Yet robot-oriented reconstruction faces a trilemma: sparse forward-facing views cause weak parallax and ill-posed geometry; dynamic occlusions and extreme lighting hinder stable texture fusion; and neural rendering typically needs expensive offline optimization, violating edge-side streaming constraints. We propose ParkingTwin, a training-free, lightweight system for online streaming 3D reconstruction. First, OSM-prior-driven geometric construction uses OpenStreetMap semantic topology to directly generate a metric-consistent TSDF, replacing blind geometric search with deterministic mapping and avoiding costly optimization. Second, geometry-aware dynamic filtering employs a quad-modal constraint field (normal/height/depth consistency) to reject moving vehicles and transient occlusions in real time. Third, illumination-robust fusion in CIELAB decouples luminance and chromaticity via adaptive L-channel weighting and depth-gradient suppression, reducing seams under abrupt lighting changes. ParkingTwin runs at 30+ FPS on an entry-level GTX 1660. On a 68,000 m^2 real-world dataset, it achieves SSIM 0.87 (+16.0%), delivers about 15x end-to-end speedup, and reduces GPU memory by 83.3% compared with state-of-the-art 3D Gaussian Splatting (3DGS) that typically requires high-end GPUs (RTX 4090D). The system outputs explicit triangle meshes compatible with Unity/Unreal digital-twin pipelines. Project page: https://mihoutao-liu.github.io/ParkingTwin/

</details>


### [433] [Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement](https://arxiv.org/abs/2601.13724)
*Sam Cantrill,David Ahmedt-Aristizabal,Lars Petersson,Hanna Suominen,Mohammad Ali Armin*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出Facial Spatiotemporal Graph (STGraph)表示和MeshPhys模型，通过3D面部网格序列实现表面对齐的时空处理，用于面部远程光电容积描记(rPPG)生理信号估计。


<details>
  <summary>Details</summary>
Motivation: 现有面部rPPG方法未能明确将感受野与3D面部表面对齐，而面部表面是rPPG信号的空间支撑。需要一种能够显式对齐面部表面的建模方法。

Method: 提出Facial Spatiotemporal Graph (STGraph)表示，使用3D面部网格序列编码面部颜色和结构；设计MeshPhys轻量级时空图卷积网络，在STGraph上操作估计生理信号。

Result: 在四个基准数据集上，MeshPhys在数据集内和跨数据集设置中都达到了最先进或具有竞争力的性能。消融研究表明，将模型感受野约束到面部表面起到了强大的结构先验作用。

Conclusion: STGraph和MeshPhys构成了面部rPPG的新颖、原则性建模范式，实现了鲁棒、可解释和可泛化的生理信号估计。

Abstract: Facial remote photoplethysmography (rPPG) methods estimate physiological signals by modeling subtle color changes on the 3D facial surface over time. However, existing methods fail to explicitly align their receptive fields with the 3D facial surface-the spatial support of the rPPG signal. To address this, we propose the Facial Spatiotemporal Graph (STGraph), a novel representation that encodes facial color and structure using 3D facial mesh sequences-enabling surface-aligned spatiotemporal processing. We introduce MeshPhys, a lightweight spatiotemporal graph convolutional network that operates on the STGraph to estimate physiological signals. Across four benchmark datasets, MeshPhys achieves state-of-the-art or competitive performance in both intra- and cross-dataset settings. Ablation studies show that constraining the model's receptive field to the facial surface acts as a strong structural prior, and that surface-aligned, 3D-aware node features are critical for robustly encoding facial surface color. Together, the STGraph and MeshPhys constitute a novel, principled modeling paradigm for facial rPPG, enabling robust, interpretable, and generalizable estimation. Code is available at https://samcantrill.github.io/facial-stgraph-rppg/ .

</details>


### [434] [Discriminant Learning-based Colorspace for Blade Segmentation](https://arxiv.org/abs/2601.13816)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出一种新颖的多维非线性判别分析算法CSDA，通过定制化色彩表示来改进图像分割，在风电叶片数据上取得显著精度提升


<details>
  <summary>Details</summary>
Motivation: 当前许多现代分割算法忽视了色彩表示这一关键预处理步骤，而次优的色彩表示往往阻碍准确的分割性能。特别是在特定领域的分割任务中，通用的色彩空间可能不够有效。

Method: 提出Colorspace Discriminant Analysis (CSDA)算法，将线性判别分析扩展到深度学习环境中。通过最大化多维有符号的类间可分性并最小化类内变异性，使用广义判别损失来定制色彩表示。引入三种替代损失函数以确保稳定训练，实现判别性色彩空间和分割过程的端到端优化。

Result: 在风电叶片数据上的实验表明，该方法带来了显著的精度提升，强调了在特定领域分割中定制化预处理的重要性。

Conclusion: CSDA算法通过改进色彩表示这一关键预处理步骤，有效提升了图像分割的准确性，特别是在特定领域应用中。该方法强调了预处理在分割任务中的重要性。

Abstract: Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.

</details>


### [435] [Accelerated MR Elastography Using Learned Neural Network Representation](https://arxiv.org/abs/2601.11878)
*Xi Peng*

Main category: eess.SP

Relevance: 25.0

TL;DR: 提出一种基于深度神经网络表示的自监督学习方法，用于从高度欠采样的k空间数据中快速重建高分辨率磁共振弹性成像，无需高质量训练数据集。


<details>
  <summary>Details</summary>
Motivation: 传统线性子空间方法在磁共振弹性成像（MRE）重建中存在局限性，特别是在高度欠采样情况下。需要开发非线性扩展方法，能够在无需高质量训练数据集的情况下，从高度欠采样数据中实现高质量重建。

Method: 1. 将深度神经网络表示框架化为线性子空间模型的非线性扩展
2. 使用该网络表示从欠采样k空间数据重建MRE图像重复
3. 采用多级k空间一致性损失进行自监督学习
4. 引入相位对比特定的幅度和相位先验（解剖结构相似性和波诱导谐波位移平滑性）

Result: 相比传统线性子空间方法，非线性网络表示方法能够从每个MRE重复的单个平面螺旋臂（总R=10）产生更优的图像重建，抑制噪声和伪影，获得与全采样数据相当的刚度估计。

Conclusion: 该工作证明了使用深度网络表示从高度欠采样数据中建模和重建MRE图像的可行性，是子空间方法的非线性扩展。

Abstract: To develop a deep-learning method for achieving fast high-resolution MR elastography from highly undersampled data without the need of high-quality training dataset. We first framed the deep neural network representation as a nonlinear extension of the linear subspace model, then used it to represent and reconstruct MRE image repetitions from undersampled k-space data. The network weights were learned using a multi-level k-space consistent loss in a self-supervised manner. To further enhance reconstruction quality, phase-contrast specific magnitude and phase priors were incorporated, including the similarity of anatomical structures and smoothness of wave-induced harmonic displacement. Experiments were conducted using both 3D gradient-echo spiral and multi-slice spin-echo spiral MRE datasets. Compared to the conventional linear subspace-based approaches, the nonlinear network representation method was able to produce superior image reconstruction with suppressed noise and artifacts from a single in-plane spiral arm per MRE repetition (e.g., total R=10), yielding comparable stiffness estimation to the fully sampled data. This work demonstrated the feasibility of using deep network representations to model and reconstruct MRE images from highly-undersampled data, a nonlinear extension of the subspace-based approaches.

</details>


### [436] [VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content](https://arxiv.org/abs/2601.13951)
*Shengyi Wu,Yan Hong,Shengyao Chen,Zheng Wang,Xianbing Sun,Jiahui Zhan,Jun Lan,Jianfu Zhang*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了VTONGuard基准数据集，包含超过77.5万张真实和合成的虚拟试穿图像，用于评估AI生成内容检测方法，并设计了多任务框架提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在虚拟试穿(VTON)领域的快速发展，AI生成内容的真实性和负责任使用成为紧迫问题，需要建立基准数据集和检测方法来应对这一挑战。

Method: 1) 构建大规模VTONGuard数据集，包含77.5万+真实和合成试穿图像，覆盖多种现实条件；2) 在统一训练测试协议下系统评估多种检测范式；3) 设计集成辅助分割的多任务框架，增强边界感知特征学习。

Result: 揭示了各种检测方法的优缺点，强调了跨范式泛化的持续挑战。提出的多任务框架在VTONGuard上实现了最佳整体性能。

Conclusion: VTONGuard基准能够实现公平比较，促进更鲁棒检测模型的开发，推动VTON技术在实际中的安全负责任部署。

Abstract: With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.

</details>


### [437] [Equivariant Learning for Unsupervised Image Dehazing](https://arxiv.org/abs/2601.13986)
*Zhang Wen,Jiangwei Xie,Dongdong Chen*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种名为EID的无监督图像去雾框架，利用图像信号的对称性从原始有雾图像中恢复清晰图像，无需精心设计的先验或大量无雾地面真值。


<details>
  <summary>Details</summary>
Motivation: 当前图像去雾方法依赖精心设计的先验或大量无雾地面真值，这些在科学成像中获取成本高或不切实际。需要一种无需这些昂贵资源的方法。

Method: 提出EID框架，通过强制雾度一致性和系统等变性来利用图像信号的对称性。还提出对抗学习策略来建模未知的雾物理特性，促进EID学习。

Result: 在两个科学图像去雾基准测试（细胞显微镜和医学内窥镜）以及自然图像去雾上，EID显著优于最先进的方法。

Conclusion: 通过将等变学习与雾物理建模相结合，EID有望在科学成像中实现更通用和有效的雾去除。

Abstract: Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published.

</details>


### [438] [Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management](https://arxiv.org/abs/2601.14069)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种无监督视频类增量学习方法，通过深度特征提取和渐进式深度聚类来解决视频信息学习中的遗忘问题，无需标签或任务边界信息。


<details>
  <summary>Details</summary>
Motivation: 现有的视频类增量学习主要依赖监督学习，需要标签和任务边界信息，这成本高昂且不现实。无监督视频类增量学习（uVCIL）是一个重要但未充分探索的领域，旨在学习视频信息而不遗忘，且无需任何数据标签。

Method: 1. 使用深度特征提取器网络为每个任务生成代表性视频特征，不假设任何类别或任务信息；2. 从提取的特征中渐进式构建一系列深度聚类；3. 在连续任务学习中，将前一任务更新的模型作为初始状态，以将知识转移到当前学习任务。

Result: 在三个标准视频动作识别数据集（UCF101、HMDB51、Something-to-Something V2）上进行了深入评估，忽略监督设置中的标签。该方法在所有数据集上显著优于其他基线方法。

Conclusion: 提出了一种简单有效的无监督视频类增量学习方法，通过深度特征提取和渐进式聚类解决了视频学习中的遗忘问题，无需标签信息，在实际应用中具有重要价值。

Abstract: Unsupervised video class incremental learning (uVCIL) represents an important learning paradigm for learning video information without forgetting, and without considering any data labels. Prior approaches have focused on supervised class-incremental learning, relying on using the knowledge of labels and task boundaries, which is costly, requires human annotation, or is simply not a realistic option. In this paper, we propose a simple yet effective approach to address the uVCIL. We first consider a deep feature extractor network, providing a set of representative video features during each task without assuming any class or task information. We then progressively build a series of deep clusters from the extracted features. During the successive task learning, the model updated from the previous task is used as an initial state in order to transfer knowledge to the current learning task. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, by ignoring the labels from the supervised setting. Our approach significantly outperforms other baselines on all datasets.

</details>


### [439] [Bridging Modalities: Joint Synthesis and Registration Framework for Aligning Diffusion MRI with T1-Weighted Images](https://arxiv.org/abs/2601.11689)
*Xiaofan Wang,Junyi Wang,Yuqian Chen,Lauren J. O' Donnell,Fan Zhang*

Main category: eess.IV

Relevance: 25.0

TL;DR: 提出一种基于生成注册网络的无监督多模态图像配准框架，将b0和T1w图像间的多模态配准问题转化为生成图像与真实T1w图像间的单模态配准任务，有效降低跨模态配准复杂度。


<details>
  <summary>Details</summary>
Motivation: 扩散MRI和T1加权MRI图像间的多模态配准对于将扩散加权成像数据与结构解剖空间对齐至关重要。传统方法由于扩散数据与高分辨率解剖结构间存在大的强度差异，难以确保配准准确性。

Method: 采用无监督配准框架，首先使用图像合成模型生成具有T1w对比度的图像，然后将原始多模态配准问题转化为生成图像与真实T1w图像间的单模态配准任务。配准网络联合优化局部结构相似性和跨模态统计依赖性以提高变形估计精度。

Result: 在两个独立数据集上的实验表明，该方法在多模态配准任务中优于多种最先进方法。

Conclusion: 提出的生成配准网络框架通过将多模态配准转化为单模态任务，有效解决了扩散MRI和T1w MRI图像配准中的强度差异问题，提高了配准精度。

Abstract: Multimodal image registration between diffusion MRI (dMRI) and T1-weighted (T1w) MRI images is a critical step for aligning diffusion-weighted imaging (DWI) data with structural anatomical space. Traditional registration methods often struggle to ensure accuracy due to the large intensity differences between diffusion data and high-resolution anatomical structures. This paper proposes an unsupervised registration framework based on a generative registration network, which transforms the original multimodal registration problem between b0 and T1w images into a unimodal registration task between a generated image and the real T1w image. This effectively reduces the complexity of cross-modal registration. The framework first employs an image synthesis model to generate images with T1w-like contrast, and then learns a deformation field from the generated image to the fixed T1w image. The registration network jointly optimizes local structural similarity and cross-modal statistical dependency to improve deformation estimation accuracy. Experiments conducted on two independent datasets demonstrate that the proposed method outperforms several state-of-the-art approaches in multimodal registration tasks.

</details>


### [440] [DeepRAHT: Learning Predictive RAHT for Point Cloud Attribute Compression](https://arxiv.org/abs/2601.12255)
*Chunyang Fu,Tai Qin,Shiqi Wang,Zhu Li*

Main category: eess.IV

Relevance: 25.0

TL;DR: 提出DeepRAHT：基于稀疏张量的端到端RAHT框架，用于有损点云属性压缩，无需手动RAHT预处理，支持可逆和失真可控的编码。


<details>
  <summary>Details</summary>
Motivation: RAHT（区域自适应分层变换）是有效的点云属性压缩方法，但在深度学习中的应用缺乏研究。现有方法需要手动RAHT预处理，限制了端到端优化。

Method: 1) 基于稀疏张量的端到端RAHT框架，在学习重建过程中执行RAHT变换；2) 引入预测性RAHT降低码率，设计基于学习的预测模型；3) 设计码率代理，对熵模型应用游程编码，实现无缝可变码率编码。

Result: 实验表明DeepRAHT相比基线方法具有更高性能、更快速度和更强鲁棒性。框架可逆且失真可控，确保了下界性能。

Conclusion: DeepRAHT是高性能、快速且鲁棒的点云属性压缩解决方案，具有显著应用潜力，填补了RAHT在深度学习应用中的研究空白。

Abstract: Regional Adaptive Hierarchical Transform (RAHT) is an effective point cloud attribute compression (PCAC) method. However, its application in deep learning lacks research. In this paper, we propose an end-to-end RAHT framework for lossy PCAC based on the sparse tensor, called DeepRAHT. The RAHT transform is performed within the learning reconstruction process, without requiring manual RAHT for preprocessing. We also introduce the predictive RAHT to reduce bitrates and design a learning-based prediction model to enhance performance. Moreover, we devise a bitrate proxy that applies run-length coding to entropy model, achieving seamless variable-rate coding and improving robustness. DeepRAHT is a reversible and distortion-controllable framework, ensuring its lower bound performance and offering significant application potential. The experiments demonstrate that DeepRAHT is a high-performance, faster, and more robust solution than the baseline methods. Project Page: https://github.com/zb12138/DeepRAHT.

</details>


### [441] [SHARE: A Fully Unsupervised Framework for Single Hyperspectral Image Restoration](https://arxiv.org/abs/2601.13987)
*Jiangwei Xie,Zhang Wen,Mike Davies,Dongdong Chen*

Main category: eess.IV

Relevance: 25.0

TL;DR: SHARE是一个完全无监督的高光谱图像修复框架，结合几何等变性和低秩光谱建模，无需地面真值数据，在修复和超分辨率任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像修复是一个基础挑战，传统深度学习方法依赖精心标注的地面真值数据集，这在真实场景中往往不可得，限制了实际应用。

Method: SHARE框架统一了几何等变性原理和低秩光谱建模，利用高光谱结构在可微几何变换下的内在不变性，通过等变性一致性约束获得自监督信号。创新的动态自适应光谱注意力模块显式编码HSI的全局低秩特性，并通过可学习注意力机制自适应优化局部光谱-空间相关性。

Result: 在HSI修复和超分辨率任务上的大量实验表明，SHARE优于许多最先进的无监督方法，性能可与监督方法相媲美。

Conclusion: SHARE为HSI修复和更广泛的科学成像场景提供了新的思路，展示了无监督方法在实际应用中的潜力。

Abstract: Hyperspectral image (HSI) restoration is a fundamental challenge in computational imaging and computer vision. It involves ill-posed inverse problems, such as inpainting and super-resolution. Although deep learning methods have transformed the field through data-driven learning, their effectiveness hinges on access to meticulously curated ground-truth datasets. This fundamentally restricts their applicability in real-world scenarios where such data is unavailable. This paper presents SHARE (Single Hyperspectral Image Restoration with Equivariance), a fully unsupervised framework that unifies geometric equivariance principles with low-rank spectral modelling to eliminate the need for ground truth. SHARE's core concept is to exploit the intrinsic invariance of hyperspectral structures under differentiable geometric transformations (e.g. rotations and scaling) to derive self-supervision signals through equivariance consistency constraints. Our novel Dynamic Adaptive Spectral Attention (DASA) module further enhances this paradigm shift by explicitly encoding the global low-rank property of HSI and adaptively refining local spectral-spatial correlations through learnable attention mechanisms. Extensive experiments on HSI inpainting and super-resolution tasks demonstrate the effectiveness of SHARE. Our method outperforms many state-of-the-art unsupervised approaches and achieves performance comparable to that of supervised methods. We hope that our approach will shed new light on HSI restoration and broader scientific imaging scenarios. The code will be released at https://github.com/xuwayyy/SHARE.

</details>


### [442] [CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting](https://arxiv.org/abs/2601.12814)
*Yu-Jen Tseng,Chia-Hao Kao,Jing-Zhong Chen,Alessandro Gnutti,Shao-Yuan Lo,Yen-Yu Lin,Wen-Hsiao Peng*

Main category: cs.CV

Relevance: 20.0

TL;DR: 首个统一框架，用于3D高斯泼溅的率失真优化压缩与分割，将语义学习集成到压缩流程中，支持解码器端应用如场景编辑


<details>
  <summary>Details</summary>
Motivation: 虽然3DGS在实时渲染和语义场景理解方面都很有效，但先前工作大多独立处理这些任务，缺乏联合考虑。需要支持解码器端应用（如场景编辑和操作），而不仅仅是传统的场景重建和视图合成。

Method: 1. 使用轻量级隐式神经表示的超先验，高效编码颜色和语义属性，避免昂贵的基于网格的超先验；2. 开发压缩引导的分割学习，包括量化感知训练以增强特征可分离性，以及质量感知加权机制以抑制不可靠的高斯基元

Result: 在LERF和3D-OVS数据集上的广泛实验表明，该方法显著降低了传输成本，同时保持了高渲染质量和强大的分割性能

Conclusion: 提出了首个统一的3DGS率失真优化压缩与分割框架，成功将语义学习集成到压缩流程中，为解码器端应用提供了有效支持

Abstract: We present the first unified framework for rate-distortion-optimized compression and segmentation of 3D Gaussian Splatting (3DGS). While 3DGS has proven effective for both real-time rendering and semantic scene understanding, prior works have largely treated these tasks independently, leaving their joint consideration unexplored. Inspired by recent advances in rate-distortion-optimized 3DGS compression, this work integrates semantic learning into the compression pipeline to support decoder-side applications--such as scene editing and manipulation--that extend beyond traditional scene reconstruction and view synthesis. Our scheme features a lightweight implicit neural representation-based hyperprior, enabling efficient entropy coding of both color and semantic attributes while avoiding costly grid-based hyperprior as seen in many prior works. To facilitate compression and segmentation, we further develop compression-guided segmentation learning, consisting of quantization-aware training to enhance feature separability and a quality-aware weighting mechanism to suppress unreliable Gaussian primitives. Extensive experiments on the LERF and 3D-OVS datasets demonstrate that our approach significantly reduces transmission cost while preserving high rendering quality and strong segmentation performance.

</details>


### [443] [Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation](https://arxiv.org/abs/2601.12964)
*John Waithaka,Gustave Bwirayesu,Moise Busogi*

Main category: cs.CV

Relevance: 20.0

TL;DR: 该论文提出了一种在遥感图像自监督预训练中融合高分辨率(HR)和中分辨率(MR)图像的方法，通过空间亲和力组件提升MR图像表示学习，从而改善下游分割任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前遥感领域的自监督预训练主要使用中分辨率(MR)图像数据集，因为其可用性高。随着高分辨率(HR)数据集的发布，研究如何将HR数据纳入自监督预训练，以增强MR图像表示学习并提升MR任务的下游分割性能。

Method: 设计了一个空间亲和力组件，可以添加到现有的自监督学习框架中。该组件利用HR图像来学习更好的MR图像表示。在两个自监督学习框架上测试了该组件。

Result: 实验表明，添加空间亲和力组件的模型在性能上超过了仅使用HR或MR图像单独预训练的模型。

Conclusion: 通过将HR图像纳入自监督预训练过程，可以有效提升MR图像的表示学习能力，从而改善下游分割任务的性能。

Abstract: Self-supervised pretraining in remote sensing is mostly done using mid-spatial resolution (MR) image datasets due to their high availability. Given the release of high-resolution (HR) datasets, we ask how HR datasets can be included in self-supervised pretraining to enhance MR image representation learning and downstream segmentation performance on MR tasks. We design a spatial affinity component that can be added to existing self-supervised learning frameworks and that uses HR imagery to learn better representations of MR imagery. We test the spatial affinity component on two self-supervised learning frameworks and show that it outperforms models pretrained on HR or MR images alone.

</details>


### [444] [MooneyMaker: A Python package to create ambiguous two-tone images](https://arxiv.org/abs/2601.14077)
*Lars C. Reining,Thabo Matthies,Luisa Haussner,Rabea Turon,Thomas S. A. Wallis*

Main category: q-bio.NC

Relevance: 20.0

TL;DR: MooneyMaker是一个开源Python包，用于自动化生成模糊的Mooney图像（高对比度双色调视觉刺激），通过多种互补方法创建初始难以识别但看到模板后可解释的图像。


<details>
  <summary>Details</summary>
Motivation: 传统手动创建Mooney图像的方法劳动密集且主观，导致研究间不一致。需要自动化工具来标准化生成过程，支持更一致和可重复的视觉感知研究。

Method: 开发了MooneyMaker包，提供多种生成技术：从基于图像统计的方法到深度学习模型。这些方法策略性地改变边缘信息以增加初始模糊性，用户可以比较不同方法的结果。

Result: 实验验证显示，初始识别率较低的技术与模板后识别率较高（即更大的解模糊效应）相关。为视觉科学家提供了技术选择的实用指南。

Conclusion: MooneyMaker通过标准化Mooney图像的生成过程，支持更一致和可重复的视觉感知研究，为研究人员提供了自动化工具和实用指南。

Abstract: Mooney images are high-contrast, two-tone visual stimuli, created by thresholding photographic images. They allow researchers to separate image content from image understanding, making them valuable for studying visual perception. An ideal Mooney image for this purpose achieves a specific balance: it initially appears unrecognizable but becomes fully interpretable to the observer after seeing the original template. Researchers traditionally created these stimuli manually using subjective criteria, which is labor-intensive and can introduce inconsistencies across studies. Automated generation techniques now offer an alternative to this manual approach. Here, we present MooneyMaker, an open-source Python package that automates the generation of ambiguous Mooney images using several complementary approaches. Users can choose between various generation techniques that range from approaches based on image statistics to deep learning models. These models strategically alter edge information to increase initial ambiguity. The package lets users create two-tone images with multiple methods and directly compare the results visually. In an experiment, we validate MooneyMaker by generating Mooney images using different techniques and assess their recognizability for human observers before and after disambiguating them by presenting the template images. Our results reveal that techniques with lower initial recognizability are associated with higher post-template recognition (i.e. a larger disambiguation effect). To help vision scientists build effective databases of Mooney stimuli, we provide practical guidelines for technique selection. By standardizing the generation process, MooneyMaker supports more consistent and reproducible visual perception research.

</details>


### [445] [Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings](https://arxiv.org/abs/2601.11627)
*Hassan Ugail,Jan Ritch-Frel,Irina Matuzava*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出基于单类自编码器的历史绘画认证框架，使用手工特征进行艺术家验证，在稀缺数据场景下为鉴赏提供定量证据


<details>
  <summary>Details</summary>
Motivation: 文化遗产领域中的作品认证和归属问题面临挑战，特别是当参考语料库小且风格线索主要通过线条和有限色调变化表达时，需要可重复的定量分析方法来补充传统鉴赏

Method: 使用单类自编码器训练艺术家特定验证器，特征向量包括傅里叶域能量、香农熵、全局对比度、GLCM同质性和分形复杂度估计，采用生物识别式协议进行评估

Result: 在900个验证决策中，系统真接受率为83.3%，假接受率为9.5%，性能因艺术家而异，假接受分析显示与风格接近性和共享绘画传统相关的结构化错误路径

Conclusion: 该方法旨在补充而非取代传统鉴赏，为历史素描归属中常见的数据稀缺场景提供可重复的定量证据，同时指出需要更好控制数字化伪影和阈值校准

Abstract: Authentication and attribution of works on paper remain persistent challenges in cultural heritage, particularly when the available reference corpus is small and stylistic cues are primarily expressed through line and limited tonal variation. We present a verification-based computational framework for historical drawing authentication using one-class autoencoders trained on a compact set of interpretable handcrafted features. Ten artist-specific verifiers are trained using authenticated sketches from the Metropolitan Museum of Art open-access collection, the Ashmolean Collections Catalogue, the Morgan Library and Museum, the Royal Collection Trust (UK), the Victoria and Albert Museum Collections, and an online catalogue of the Casa Buonarroti collection and evaluated under a biometric-style protocol with genuine and impostor trials. Feature vectors comprise Fourier-domain energy, Shannon entropy, global contrast, GLCM-based homogeneity, and a box-counting estimate of fractal complexity. Across 900 verification decisions (90 genuine and 810 impostor trials), the pooled system achieves a True Acceptance Rate of 83.3% with a False Acceptance Rate of 9.5% at the chosen operating point. Performance varies substantially by artist, with near-zero false acceptance for some verifiers and elevated confusability for others. A pairwise attribution of false accepts indicates structured error pathways consistent with stylistic proximity and shared drawing conventions, whilst also motivating tighter control of digitisation artefacts and threshold calibration. The proposed methodology is designed to complement, rather than replace, connoisseurship by providing reproducible, quantitative evidence suitable for data-scarce settings common in historical sketch attribution.

</details>


### [446] [Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos](https://arxiv.org/abs/2601.11635)
*Anil Egin,Andrea Tangherloni,Antitza Dantcheva*

Main category: cs.CV

Relevance: 15.0

TL;DR: Anon-NET：一个统一的视频人脸匿名化框架，使用扩散模型进行人脸修复，通过属性识别和运动感知表情迁移指导，再通过视频驱动动画实现去身份化，同时保留年龄、性别、种族、姿态和表情等属性。


<details>
  <summary>Details</summary>
Motivation: 视频人脸匿名化需要在保护隐私的同时保持视频分析价值（如表情识别、人员跟踪、动作识别）。现有方法难以在去身份化和保留有用视觉属性之间取得平衡，需要一种能同时实现身份混淆和属性保留的统一框架。

Method: 1. 使用基于扩散的生成模型进行人脸修复，通过高层属性识别和运动感知表情迁移指导生成过程；2. 采用视频驱动动画技术，将去身份化的人脸与原始视频结合，实现时间一致性；3. 在VoxCeleb2、CelebV-HQ和HDTF等多样化人脸动态数据集上进行评估。

Result: 在包含多样化面部动态的数据集上实验表明，Anon-NET能有效混淆身份，同时保持视觉真实性和时间一致性，成功保留年龄、性别、种族、姿态和表情等属性。

Conclusion: Anon-NET提供了一个有效的视频人脸匿名化解决方案，在隐私保护和视觉分析价值之间取得了良好平衡，代码将公开释放以促进相关研究。

Abstract: Face video anonymization is aimed at privacy preservation while allowing for the analysis of videos in a number of computer vision downstream tasks such as expression recognition, people tracking, and action recognition. We propose here a novel unified framework referred to as Anon-NET, streamlined to de-identify facial videos, while preserving age, gender, race, pose, and expression of the original video. Specifically, we inpaint faces by a diffusion-based generative model guided by high-level attribute recognition and motion-aware expression transfer. We then animate deidentified faces by video-driven animation, which accepts the de-identified face and the original video as input. Extensive experiments on the datasets VoxCeleb2, CelebV-HQ, and HDTF, which include diverse facial dynamics, demonstrate the effectiveness of AnonNET in obfuscating identity while retaining visual realism and temporal consistency. The code of AnonNet will be publicly released.

</details>


### [447] [PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models](https://arxiv.org/abs/2601.11642)
*Abbas Alzubaidi,Ali Al-Bayaty*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了一个基于物理的合成模拟框架(PSSF)，用于生成可控的膝关节X射线图像，以解决医学影像数据获取的隐私和资源限制问题，并用于骨关节炎的机器学习评估。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎(OA)是全球致残的主要原因，目前主要依赖主观的放射学分级（如Kellgren-Lawrence量表）。AI和影像组学提供了定量评估工具，但需要大量标注良好的X射线图像数据集，而这些数据由于隐私、治理和资源限制往往难以获取。

Method: 1. 开发基于物理的合成模拟框架(PSSF)：从参数化解剖模型生成前后位膝关节X射线投影的2D模拟器
2. 创建虚拟队列：180名受试者（260个膝盖），每个受试者在三种协议下成像（参考、低剂量、几何偏移）
3. 自动定位内侧关节区域，使用IBSI标准进行预处理和特征提取
4. 使用三种机器学习模型（逻辑回归、随机森林、梯度提升）进行二分类（KL-like "0" vs. "2"）和三分类（0-2）预测
5. 在IBSI协议内、跨协议和多协议场景下评估模型鲁棒性
6. 使用组内相关系数评估特征在不同采集变化下的稳定性

Result: 1. 成功开发了能够生成可控X射线图像的物理模拟框架
2. 创建了包含180名虚拟受试者的合成数据集
3. 实现了自动化的关节区域定位和特征提取流程
4. 机器学习模型能够进行骨关节炎的放射学分级预测
5. 评估了模型在不同成像协议下的鲁棒性
6. 分析了影像组学特征在采集变化下的稳定性

Conclusion: 该研究提出的PSSF框架能够生成无需患者参与的合成X射线图像，解决了医学影像数据获取的隐私和资源限制问题。该方法为骨关节炎的定量评估提供了新的数据生成途径，并展示了在合成数据上训练的机器学习模型的有效性。

Abstract: Knee osteoarthritis (OA) is a major cause of disability worldwide and is still largely assessed using subjective radiographic grading, most commonly the Kellgren-Lawrence (KL) scale. Artificial intelligence (AI) and radiomics offer quantitative tools for OA assessment but depend on large, well-annotated image datasets, mainly X-ray scans, that are often difficult to obtain because of privacy, governance and resourcing constraints. In this research, we introduce a physics-based synthetic simulation framework (PSSF) to fully generate controllable X-ray scans without patients' involvement and violating their privacy and institutional constraints. This PSSF is a 2D X-ray projection simulator of anteroposterior knee radiographs from a parametric anatomical model of the distal femur and proximal tibia. Using PSSF, we create a virtual cohort of 180 subjects (260 knees), each is imaged under three protocols (reference, low-dose, and geometry-shift). Medial joint regions are automatically localized, preprocessed, and processed with the Image Biomarker Standardisation Initiative (IBSI). Practically, three machine learning (ML) models are utilized, logistic regression, random forest, and gradient boosting, to train binary (KL-like "0" vs. "2") and three-class (0-2) prediction radiographic images. Robustness is assessed within IBSI protocol, cross-protocol, and multi-protocol scenarios. Finally, features stability is then evaluated using intraclass correlation coefficients across acquisition changes.

</details>


### [448] [PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation](https://arxiv.org/abs/2601.11654)
*Kaustubh Shivshankar Shejole,Gaurav Mishra*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出一种基于图的交互式图像分割新方法，使用像素段相似度指数(PSSI)作为图边权重度量，结合MeanShift低层分割和最大生成树(MaxST)进行分割，在GrabCut和Images250数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的交互式分割方法存在计算成本高、对用户交互敏感、前景背景颜色分布相似时性能下降等问题。关键影响因素是图中边权重的相似度度量方法。

Method: 1) 提出像素段相似度指数(PSSI)，利用像素强度和空间平滑特征的通道间相似度的调和平均；2) 使用MeanShift进行低层分割，捕获颜色、纹理和形状；3) 基于像素段构建图，用PSSI计算边权重；4) 使用最大生成树(MaxST)进行分割，捕获强连接的局部邻域。

Result: 在GrabCut和Images250数据集上，方法在Jaccard指数(IoU)、F1分数、执行时间和平均误差(ME)方面均优于AMOE、OneCut、SSNCut等现有图基交互分割方法。

Conclusion: 提出的PSSI-MaxST方法通过结合PSSI相似度度量、MeanShift低层分割和MaxST分割，能够联合捕获颜色相似性、平滑性、纹理、形状和强局部连接性，实现了更优的分割性能。

Abstract: Interactive graph-based segmentation methods partition an image into foreground and background regions with the aid of user inputs. However, existing approaches often suffer from high computational costs, sensitivity to user interactions, and degraded performance when the foreground and background share similar color distributions. A key factor influencing segmentation performance is the similarity measure used for assigning edge weights in the graph. To address these challenges, we propose a novel Pixel Segment Similarity Index (PSSI), which leverages the harmonic mean of inter-channel similarities by incorporating both pixel intensity and spatial smoothness features. The harmonic mean effectively penalizes dissimilarities in any individual channel, enhancing robustness. The computational complexity of PSSI is $\mathcal{O}(B)$, where $B$ denotes the number of histogram bins. Our segmentation framework begins with low-level segmentation using MeanShift, which effectively captures color, texture, and segment shape. Based on the resulting pixel segments, we construct a pixel-segment graph with edge weights determined by PSSI. For partitioning, we employ the Maximum Spanning Tree (MaxST), which captures strongly connected local neighborhoods beneficial for precise segmentation. The integration of the proposed PSSI, MeanShift, and MaxST allows our method to jointly capture color similarity, smoothness, texture, shape, and strong local connectivity. Experimental evaluations on the GrabCut and Images250 datasets demonstrate that our method consistently outperforms current graph-based interactive segmentation methods such as AMOE, OneCut, and SSNCut in terms of segmentation quality, as measured by Jaccard Index (IoU), $F_1$ score, execution time and Mean Error (ME). Code is publicly available at: https://github.com/KaustubhShejole/PSSI-MaxST.

</details>


### [449] [Telling Human and Machine Handwriting Apart](https://arxiv.org/abs/2601.11700)
*Luis A. Leiva,Moises Diaz,Nuwan T. Attygalle,Miguel A. Ferrer,Rejean Plamondon*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该研究提出使用手写运动作为行为生物特征来检测人类与合成手写输入，通过训练浅层循环神经网络在多个数据集和合成器上达到98.3%的AUC性能。


<details>
  <summary>Details</summary>
Motivation: 手写运动可作为独特的生物特征来验证设备操作者是否为真实用户，这本质上是一个反向图灵测试问题。研究旨在开发能够区分人类手写和合成手写的方法，为计算机系统提供额外安全层。

Method: 使用10个公开手写符号数据集（字符、数字、手势、指向轨迹、签名），通过7种不同合成器（包括运动学理论、GAN、Transformer、扩散模型）生成人工手写。训练浅层循环神经网络，直接使用非特征化的轨迹数据作为输入。

Result: 模型在所有合成器和数据集上平均达到98.3%的AUC分数和1.4%的等错误率。在少样本设置中，仅使用10%数据训练就能在剩余90%测试集上保持优异性能。在域外设置中也表现出色。

Conclusion: 该方法能有效区分人类与合成手写，为需要验证人类存在的计算机系统提供额外安全层，有助于防止攻击者入侵。

Abstract: Handwriting movements can be leveraged as a unique form of behavioral biometrics, to verify whether a real user is operating a device or application. This task can be framed as a reverse Turing test in which a computer has to detect if an input instance has been generated by a human or artificially. To tackle this task, we study ten public datasets of handwritten symbols (isolated characters, digits, gestures, pointing traces, and signatures) that are artificially reproduced using seven different synthesizers, including, among others, the Kinematic Theory (Sigma h model), generative adversarial networks, Transformers, and Diffusion models. We train a shallow recurrent neural network that achieves excellent performance (98.3 percent Area Under the ROC Curve (AUC) score and 1.4 percent equal error rate on average across all synthesizers and datasets) using nonfeaturized trajectory data as input. In few-shot settings, we show that our classifier achieves such an excellent performance when trained on just 10 percent of the data, as evaluated on the remaining 90% of the data as a test set. We further challenge our classifier in out-of-domain settings, and observe very competitive results as well. Our work has implications for computerized systems that need to verify human presence, and adds an additional layer of security to keep attackers at bay.

</details>


### [450] [studentSplat: Your Student Model Learns Single-view 3D Gaussian Splatting](https://arxiv.org/abs/2601.11772)
*Yimu Pan,Hongda Mao,Qingshuang Chen,Yelin Kim*

Main category: cs.CV

Relevance: 15.0

TL;DR: studentSplat：一种用于单视图3D场景重建的3D高斯泼溅方法，通过师生架构和推断网络解决单视图的尺度模糊和外推问题


<details>
  <summary>Details</summary>
Motivation: 虽然前馈3D高斯泼溅在多视图3D场景重建和单视图3D物体重建方面取得了显著进展，但单视图3D场景重建仍然研究不足，主要原因是单视图固有的模糊性问题。需要解决尺度模糊和外推问题来实现高质量的单视图3D场景重建。

Method: 提出studentSplat方法，包含两个关键技术：1）师生架构：使用多视图教师模型在训练期间为单视图学生模型提供几何监督，解决尺度模糊并鼓励几何有效性；2）外推网络：完成缺失的场景上下文，实现高质量的外推。

Result: studentSplat在单视图新视角重建质量上达到最先进水平，在场景级别上与多视图方法性能相当。此外，作为自监督单视图深度估计方法也表现出有竞争力的性能，显示出在通用单视图3D理解任务中的潜力。

Conclusion: studentSplat通过创新的师生架构和外推网络，成功解决了单视图3D场景重建中的尺度模糊和外推问题，为单视图3D理解任务提供了有效的解决方案。

Abstract: Recent advance in feed-forward 3D Gaussian splatting has enable remarkable multi-view 3D scene reconstruction or single-view 3D object reconstruction but single-view 3D scene reconstruction remain under-explored due to inherited ambiguity in single-view. We present \textbf{studentSplat}, a single-view 3D Gaussian splatting method for scene reconstruction. To overcome the scale ambiguity and extrapolation problems inherent in novel-view supervision from a single input, we introduce two techniques: 1) a teacher-student architecture where a multi-view teacher model provides geometric supervision to the single-view student during training, addressing scale ambiguity and encourage geometric validity; and 2) an extrapolation network that completes missing scene context, enabling high-quality extrapolation. Extensive experiments show studentSplat achieves state-of-the-art single-view novel-view reconstruction quality and comparable performance to multi-view methods at the scene level. Furthermore, studentSplat demonstrates competitive performance as a self-supervised single-view depth estimation method, highlighting its potential for general single-view 3D understanding tasks.

</details>


### [451] [Effects of the retina-inspired light intensity encoding on color discrimination performance](https://arxiv.org/abs/2601.11909)
*Io Yamada,Hirotsugu Okuno*

Main category: cs.CV

Relevance: 15.0

TL;DR: 研究探讨了光强度编码函数（对数函数 vs Naka-Rushton函数）对中心/周边Retinex模型颜色恒常性性能的影响，发现N-R函数结合双拮抗颜色平面表示能提供更好的颜色辨别性能。


<details>
  <summary>Details</summary>
Motivation: 颜色恒常性是视觉系统的重要特性，使视觉目标颜色感知不受照明颜色影响。研究旨在改进基于视觉神经系统的中心/周边Retinex模型，通过比较不同光强度编码函数来提升颜色恒常性性能。

Method: 使用颜色可变LED以不同照明颜色照射视觉目标，比较两种光强度编码函数：原始C/S Retinex模型的对数函数和视网膜光感受器响应模型Naka-Rushton函数。颜色信息使用HSV颜色空间和基于经典拮抗颜色理论的颜色平面表示。

Result: Naka-Rushton函数与双拮抗颜色平面表示的组合提供了最优的颜色辨别性能，能够更好地在不同照明条件下区分视觉目标的颜色。

Conclusion: Naka-Rushton函数作为视网膜光感受器响应模型，结合双拮抗颜色表示，能够显著提升中心/周边Retinex模型的颜色恒常性性能，为使用颜色信息的视觉系统提供了改进方案。

Abstract: Color is an important source of information for visual functions such as object recognition, but it is greatly affected by the color of illumination. The ability to perceive the color of a visual target independent of illumination color is called color constancy (CC), and is an important feature for vision systems that use color information. In this study, we investigated the effects of the light intensity encoding function on the performance of CC of the center/surround (C/S) retinex model, which is a well-known model inspired by CC of the visual nervous system. The functions used to encode light intensity are the logarithmic function used in the original C/S retinex model and the Naka-Rushton (N-R) function, which is a model of retinal photoreceptor response. Color-variable LEDs were used to illuminate visual targets with various lighting colors, and color information computed by each model was used to evaluate the degree to which the color of visual targets illuminated with different lighting colors could be discriminated. Color information was represented using the HSV color space and a color plane based on the classical opponent color theory. The results showed that the combination of the N-R function and the double opponent color plane representation provided superior discrimination performance.

</details>


### [452] [Effects of Gabor Filters on Classification Performance of CNNs Trained on a Limited Number of Conditions](https://arxiv.org/abs/2601.11918)
*Akito Morita,Hirotsugu Okuno*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出使用Gabor滤波器作为CNN预处理，在机器人视觉边缘设备上实现小数据训练、提高泛化性能并减小模型尺寸


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备上CNN需要小型架构且能在有限数据条件下高效训练的问题，受生物视觉神经系统（VNS）启发，使用Gabor滤波器模拟VNS特征提取器

Method: 使用Gabor滤波器作为CNN预处理，在有限视角条件下采集的图像数据集上训练，比较不同CNN架构在有/无Gabor预处理时的性能

Result: Gabor滤波器预处理能提高CNN的泛化性能，并有助于减小CNN模型尺寸

Conclusion: Gabor滤波器作为预处理能有效提升边缘设备CNN在机器人视觉应用中的性能，实现小数据高效训练和模型轻量化

Abstract: In this study, we propose a technique to improve the accuracy and reduce the size of convolutional neural networks (CNNs) running on edge devices for real-world robot vision applications. CNNs running on edge devices must have a small architecture, and CNNs for robot vision applications involving on-site object recognition must be able to be trained efficiently to identify specific visual targets from data obtained under a limited variation of conditions. The visual nervous system (VNS) is a good example that meets the above requirements because it learns from few visual experiences. Therefore, we used a Gabor filter, a model of the feature extractor of the VNS, as a preprocessor for CNNs to investigate the accuracy of the CNNs trained with small amounts of data. To evaluate how well CNNs trained on image data acquired under a limited variation of conditions generalize to data acquired under other conditions, we created an image dataset consisting of images acquired from different camera positions, and investigated the accuracy of the CNNs that trained using images acquired at a certain distance. The results were compared after training on multiple CNN architectures with and without Gabor filters as preprocessing. The results showed that preprocessing with Gabor filters improves the generalization performance of CNNs and contributes to reducing the size of CNNs.

</details>


### [453] [ARMARecon: An ARMA Convolutional Filter based Graph Neural Network for Neurodegenerative Dementias Classification](https://arxiv.org/abs/2601.12067)
*VSS Tejaswi Abburi,Ananya Singhal,Saurabh J. Shigwan,Nitin Kumar*

Main category: cs.CV

Relevance: 15.0

TL;DR: ARMARecon：一种结合自回归移动平均图滤波与重建目标的统一图学习框架，用于阿尔茨海默病和额颞叶痴呆的早期检测，在ADNI和NIFD数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）和额颞叶痴呆（FTD）等神经退行性疾病的早期检测对于降低进展为严重疾病阶段的风险至关重要。由于AD和FTD沿着白质区域以全局、图依赖的方式传播，基于图的神经网络非常适合捕捉这些模式。

Method: 提出ARMARecon统一图学习框架，整合自回归移动平均（ARMA）图滤波与重建驱动目标，增强特征表示并提高分类准确性。该方法利用从白质区域提取的20-bin分数各向异性（FA）直方图特征，有效建模局部和全局连接性，同时减轻过平滑问题。

Result: ARMARecon在ADNI和NIFD多站点dMRI数据集上相比最先进方法实现了优越性能。

Conclusion: ARMARecon通过整合ARMA图滤波和重建目标，为神经退行性疾病的早期检测提供了一个有效的图学习框架，在分类准确性方面表现出色。

Abstract: Early detection of neurodegenerative diseases such as Alzheimer's Disease (AD) and Frontotemporal Dementia (FTD) is essential for reducing the risk of progression to severe disease stages. As AD and FTD propagate along white-matter regions in a global, graph-dependent manner, graph-based neural networks are well suited to capture these patterns. Hence, we introduce ARMARecon, a unified graph learning framework that integrates Autoregressive Moving Average (ARMA) graph filtering with a reconstruction-driven objective to enhance feature representation and improve classification accuracy. ARMARecon effectively models both local and global connectivity by leveraging 20-bin Fractional Anisotropy (FA) histogram features extracted from white-matter regions, while mitigating over-smoothing. Overall, ARMARecon achieves superior performance compared to state-of-the-art methods on the multi-site dMRI datasets ADNI and NIFD.

</details>


### [454] [Principal Component Analysis-Based Terahertz Self-Supervised Denoising and Deblurring Deep Neural Networks](https://arxiv.org/abs/2601.12149)
*Pengfei Zhu,Xavier Maldague*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出了一种基于主成分分析(PCA)的太赫兹自监督去噪去模糊网络(THz-SSDD)，用于同时解决太赫兹系统中的低频模糊和高频噪声问题，无需手动干预或标记数据。


<details>
  <summary>Details</summary>
Motivation: 太赫兹系统固有的频率相关退化效应导致振幅图像出现低频模糊和高频噪声。传统图像处理技术无法同时解决这两个问题，且由于去噪和去模糊的边界未知，通常需要人工干预。

Method: 提出THz-SSDD网络，采用Recorrupted-to-Recorrupted自监督学习策略，通过利用重复损坏下的不变性来捕捉噪声的内在特征。然后应用PCA分解和重建来恢复低频和高频图像。

Result: 在四种样品类型上评估了THz-SSDD网络的性能。训练仅需要少量未标记的噪声图像，在不同材料特性和测量模式的样品测试中显示出有效的去噪和去模糊效果。定量分析进一步验证了网络的可行性，显示图像质量得到改善，同时保留了原始信号的物理特性。

Conclusion: THz-SSDD网络能够有效解决太赫兹图像中的频率相关退化问题，无需标记数据或人工干预，在保持信号物理特性的同时显著提升图像质量。

Abstract: Terahertz (THz) systems inherently introduce frequency-dependent degradation effects, resulting in low-frequency blurring and high-frequency noise in amplitude images. Conventional image processing techniques cannot simultaneously address both issues, and manual intervention is often required due to the unknown boundary between denoising and deblurring. To tackle this challenge, we propose a principal component analysis (PCA)-based THz self-supervised denoising and deblurring network (THz-SSDD). The network employs a Recorrupted-to-Recorrupted self-supervised learning strategy to capture the intrinsic features of noise by exploiting invariance under repeated corruption. PCA decomposition and reconstruction are then applied to restore images across both low and high frequencies. The performance of the THz-SSDD network was evaluated on four types of samples. Training requires only a small set of unlabeled noisy images, and testing across samples with different material properties and measurement modes demonstrates effective denoising and deblurring. Quantitative analysis further validates the network feasibility, showing improvements in image quality while preserving the physical characteristics of the original signals.

</details>


### [455] [DiffusionQC: Artifact Detection in Histopathology via Diffusion Model](https://arxiv.org/abs/2601.12233)
*Zhenzhen Wang,Zhongliang Zhou,Zhuoyu Wen,Jeong Hwan Kook,John B Wojcik,John Kang*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出DiffusionQC方法，仅需干净图像训练即可检测组织病理学图像中的伪影，无需像素级标注或预定义伪影类型，并通过对比学习增强性能。


<details>
  <summary>Details</summary>
Motivation: 数字病理学图像在制备和数字化过程中常引入伪影，影响下游分析可靠性。传统监督方法需要大量标注数据，资源密集且难以泛化到新伪影类型。

Method: 使用扩散模型将伪影检测为干净图像中的异常值，仅需干净图像训练。引入对比学习模块显式扩大伪影与干净图像的分布分离，增强方法性能。

Result: 实验结果显示优于现有方法，具有跨染色泛化能力，且所需数据和标注显著减少。

Conclusion: DiffusionQC提供了一种高效、通用的数字病理学图像质量控制方法，减少对标注数据的依赖，提高伪影检测的泛化能力。

Abstract: Digital pathology plays a vital role across modern medicine, offering critical insights for disease diagnosis, prognosis, and treatment. However, histopathology images often contain artifacts introduced during slide preparation and digitization. Detecting and excluding them is essential to ensure reliable downstream analysis. Traditional supervised models typically require large annotated datasets, which is resource-intensive and not generalizable to novel artifact types. To address this, we propose DiffusionQC, which detects artifacts as outliers among clean images using a diffusion model. It requires only a set of clean images for training rather than pixel-level artifact annotations and predefined artifact types. Furthermore, we introduce a contrastive learning module to explicitly enlarge the distribution separation between artifact and clean images, yielding an enhanced version of our method. Empirical results demonstrate superior performance to state-of-the-art and offer cross-stain generalization capacity, with significantly less data and annotations.

</details>


### [456] [LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines](https://arxiv.org/abs/2601.12285)
*Safa C. Medin,Gengyan Li,Ziqian Bai,Ruofei Du,Leonhard Helminger,Yinda Zhang,Stephan J. Garbin,Philip L. Davidson,Gregory W. Wornell,Thabo Beeler,Abhimitra Meka*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出一种用于高效经典渲染的3D人脸化身表示方法，基于参数化人脸模型的辐射场，实现可控的体积渲染，包括头发、皮肤和眼睛等复杂面部特征。


<details>
  <summary>Details</summary>
Motivation: 传统3D人脸渲染通常需要复杂的自定义工程和集成，难以在传统图形平台上高效运行。需要一种既能保持照片级真实感，又能在标准图形硬件上高效渲染的表示方法。

Method: 基于参数化人脸模型的辐射场表示，学习3D空间中的辐射流形，提取显式的分层网格以及外观和变形纹理。通过线性混合和alpha合成纹理在静态网格上进行控制和动画。

Result: 实现了可控的体积渲染，能够高效在线流式传输，并在传统图形平台上使用经典网格和着色器进行渲染，无需自定义工程或集成。

Conclusion: 该方法提供了一种高效的3D人脸化身表示，结合了辐射场的照片级真实感和传统网格渲染的效率，适用于实际部署。

Abstract: We introduce a novel representation for efficient classical rendering of photorealistic 3D face avatars. Leveraging recent advances in radiance fields anchored to parametric face models, our approach achieves controllable volumetric rendering of complex facial features, including hair, skin, and eyes. At enrollment time, we learn a set of radiance manifolds in 3D space to extract an explicit layered mesh, along with appearance and warp textures. During deployment, this allows us to control and animate the face through simple linear blending and alpha compositing of textures over a static mesh. This explicit representation also enables the generated avatar to be efficiently streamed online and then rendered using classical mesh and shader-based rendering on legacy graphics platforms, eliminating the need for any custom engineering or integration.

</details>


### [457] [Turbo-GoDec: Exploiting the Cluster Sparsity Prior for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12337)
*Jiahui Sheng,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出Turbo-GoDec方法，将异常点的聚类稀疏性先验结合到GoDec算法中，用于高光谱图像异常检测


<details>
  <summary>Details</summary>
Motivation: 现有高光谱异常检测方法主要依赖低秩背景和稀疏异常的先验假设，但很少对异常的空间分布特性进行深入挖掘。作者观察到异常像素在空间上往往呈现小规模聚集的分布特征，称为"聚类稀疏性"

Method: 将聚类稀疏性先验结合到经典GoDec算法中，使用马尔可夫随机场建模异常点的聚类稀疏性先验，通过因子图上的消息传递计算异常概率，将高异常概率位置作为Turbo-GoDec中的稀疏分量

Result: 在三个真实高光谱图像数据集上的实验表明，Turbo-GoDec在小尺寸异常检测方面优于原始GoDec（LSMAD）和最先进的异常检测方法

Conclusion: 提出的Turbo-GoDec方法通过引入异常点的聚类稀疏性先验，有效提升了高光谱图像异常检测性能，特别是在检测小尺寸异常方面表现优异

Abstract: As a key task in hyperspectral image processing, hyperspectral anomaly detection has garnered significant attention and undergone extensive research. Existing methods primarily relt on two prior assumption: low-rank background and sparse anomaly, along with additional spatial assumptions of the background. However, most methods only utilize the sparsity prior assumption for anomalies and rarely expand on this hypothesis. From observations of hyperspectral images, we find that anomalous pixels exhibit certain spatial distribution characteristics: they often manifest as small, clustered groups in space, which we refer to as cluster sparsity of anomalies. Then, we combined the cluster sparsity prior with the classical GoDec algorithm, incorporating the cluster sparsity prior into the S-step of GoDec. This resulted in a new hyperspectral anomaly detection method, which we called Turbo-GoDec. In this approach, we modeled the cluster sparsity prior of anomalies using a Markov random field and computed the marginal probabilities of anomalies through message passing on a factor graph. Locations with high anomalous probabilities were treated as the sparse component in the Turbo-GoDec. Experiments are conducted on three real hyperspectral image (HSI) datasets which demonstrate the superior performance of the proposed Turbo-GoDec method in detecting small-size anomalies comparing with the vanilla GoDec (LSMAD) and state-of-the-art anomaly detection methods. The code is available at https://github.com/jiahuisheng/Turbo-GoDec.

</details>


### [458] [CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology](https://arxiv.org/abs/2601.12373)
*Amro Khaled,Farah Khaled,Omar Riad,Catherine M. Elias*

Main category: cs.CV

Relevance: 15.0

TL;DR: CD-TWINSAFE是一个基于V2I的自动驾驶数字孪生系统，包含车载驾驶栈和数字孪生栈，通过4G网络实时同步数据，提供安全警报。


<details>
  <summary>Details</summary>
Motivation: 提高自动驾驶系统的安全性和可靠性，通过数字孪生技术实现实时场景监控和安全预警，解决自动驾驶在复杂环境中的安全问题。

Method: 采用双栈架构：车载驾驶栈（定位+感知模块，使用立体相机进行场景理解）和数字孪生栈（Unreal Engine 5场景复制）。通过ROS2消息和UDP/4G网络进行V2I通信，实时同步定位和感知数据。

Result: 系统在不同驾驶场景下进行了测试，验证了架构的有效性和实时响应能力，能够提供安全警报和实时监控。

Conclusion: CD-TWINSAFE是一个有效的V2I数字孪生系统，能够增强自动驾驶车辆的安全监控能力，通过实时数据同步和场景复制提供安全预警。

Abstract: In this paper, the CD-TWINSAFE is introduced, a V2I-based digital twin for Autonomous Vehicles. The proposed architecture is composed of two stacks running simultaneously, an on-board driving stack that includes a stereo camera for scene understanding, and a digital twin stack that runs an Unreal Engine 5 replica of the scene viewed by the camera as well as returning safety alerts to the cockpit. The on-board stack is implemented on the vehicle side including 2 main autonomous modules; localization and perception. The position and orientation of the ego vehicle are obtained using on-board sensors. Furthermore, the perception module is responsible for processing 20-fps images from stereo camera and understands the scene through two complementary pipelines. The pipeline are working on object detection and feature extraction including object velocity, yaw and the safety metrics time-to-collision and time-headway. The collected data form the driving stack are sent to the infrastructure side through the ROS-enabled architecture in the form of custom ROS2 messages and sent over UDP links that ride a 4G modem for V2I communication. The environment is monitored via the digital twin through the shared messages which update the information of the spawned ego vehicle and detected objects based on the real-time localization and perception data. Several tests with different driving scenarios to confirm the validity and real-time response of the proposed architecture.

</details>


### [459] [Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12379)
*Jiahui Sheng,Yidan Shi,Shu Xiang,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出了一种基于分数生成模型（SGM）的高光谱图像异常检测方法ScoreAD，利用数据分布的梯度场（分数）来区分背景和异常光谱


<details>
  <summary>Details</summary>
Motivation: 高光谱图像包含丰富的光谱信息，其高维光谱实际上由少数因素（如化学成分和光照）决定，因此很可能满足流形假设。基于高光谱流形假设，可以利用分数生成模型学习数据分布的梯度场来实现异常检测。

Method: 首先在整个高光谱图像的光谱集上训练分数生成模型（SGM）。测试时，每个光谱通过扰动核处理，然后将扰动后的光谱输入训练好的SGM获取估计分数。基于背景光谱位于低维流形而异常光谱不符合该流形的假设，利用SGM实现异常检测。

Result: 在四个高光谱数据集上的实验证明了该方法的有效性。

Conclusion: 基于分数生成模型和流形假设的高光谱异常检测方法ScoreAD能够有效区分背景和异常光谱，为高光谱图像分析提供了新思路。

Abstract: Hyperspectral images (HSIs) are a type of image that contains abundant spectral information. As a type of real-world data, the high-dimensional spectra in hyperspectral images are actually determined by only a few factors, such as chemical composition and illumination. Thus, spectra in hyperspectral images are highly likely to satisfy the manifold hypothesis. Based on the hyperspectral manifold hypothesis, we propose a novel hyperspectral anomaly detection method (named ScoreAD) that leverages the time-dependent gradient field of the data distribution (i.e., the score), as learned by a score-based generative model (SGM). Our method first trains the SGM on the entire set of spectra from the hyperspectral image. At test time, each spectrum is passed through a perturbation kernel, and the resulting perturbed spectrum is fed into the trained SGM to obtain the estimated score. The manifold hypothesis of HSIs posits that background spectra reside on one or more low-dimensional manifolds. Conversely, anomalous spectra, owing to their unique spectral signatures, are considered outliers that do not conform to the background manifold. Based on this fundamental discrepancy in their manifold distributions, we leverage a generative SGM to achieve hyperspectral anomaly detection. Experiments on the four hyperspectral datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/jiahuisheng/ScoreAD.

</details>


### [460] [XRefine: Attention-Guided Keypoint Match Refinement](https://arxiv.org/abs/2601.12530)
*Jan Fabian Schmid,Annika Hagemann*

Main category: cs.CV

Relevance: 15.0

TL;DR: XRefine：一种检测器无关的亚像素关键点细化方法，通过跨注意力架构在图像块上操作，无需依赖检测器内部表示，可泛化到不同检测器并扩展到多视角特征跟踪。


<details>
  <summary>Details</summary>
Motivation: 当前关键点检测器在3D视觉任务中常产生空间不准确的匹配，现有细化方法通常针对特定检测器设计，需要为每个检测器重新训练，缺乏通用性。

Method: 提出XRefine方法，基于跨注意力架构，仅使用以匹配关键点为中心的图像块来预测细化后的关键点坐标，不依赖检测器内部表示，实现检测器无关的亚像素级细化。

Result: 在MegaDepth、KITTI和ScanNet数据集上的实验表明，该方法能持续提升几何估计精度，相比现有细化方法获得更优性能，同时保持运行时效率。

Conclusion: XRefine提供了一种通用、检测器无关的关键点细化解决方案，能有效提高3D视觉任务中的匹配精度，并可扩展到多视角特征跟踪场景。

Abstract: Sparse keypoint matching is crucial for 3D vision tasks, yet current keypoint detectors often produce spatially inaccurate matches. Existing refinement methods mitigate this issue through alignment of matched keypoint locations, but they are typically detector-specific, requiring retraining for each keypoint detector. We introduce XRefine, a novel, detector-agnostic approach for sub-pixel keypoint refinement that operates solely on image patches centered at matched keypoints. Our cross-attention-based architecture learns to predict refined keypoint coordinates without relying on internal detector representations, enabling generalization across detectors. Furthermore, XRefine can be extended to handle multi-view feature tracks. Experiments on MegaDepth, KITTI, and ScanNet demonstrate that the approach consistently improves geometric estimation accuracy, achieving superior performance compared to existing refinement methods while maintaining runtime efficiency. Our code and trained models can be found at https://github.com/boschresearch/xrefine.

</details>


### [461] [BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images](https://arxiv.org/abs/2601.12533)
*Md. Ahanaf Arif Khan,Ariful Islam,Sangeeta Biswas,Md. Iqbal Aziz Khan,Subrata Pramanik,Sanjoy Kumar Chakrabarty,Bimal Kumar Pramanik*

Main category: cs.CV

Relevance: 15.0

TL;DR: 本文介绍了BirdsEye-RU数据集，这是一个包含2,978张图像、超过8,000个标注人脸的航拍图像数据集，专门用于检测小尺寸和远距离人脸，包含无人机和高空智能手机拍摄的图像。


<details>
  <summary>Details</summary>
Motivation: 航拍图像中的人脸检测面临极端尺度变化和环境杂波的挑战，现有数据集难以覆盖小尺寸和远距离人脸检测的需求。

Method: 创建了BirdsEye-RU数据集，包含2,978张航拍图像，涵盖无人机和高空智能手机拍摄的多样化环境，标注了超过8,000个人脸。

Result: 构建了一个专门针对小尺寸和远距离人脸检测的公开数据集，包含详细的图像描述和标注信息，已在Kaggle平台公开可用。

Conclusion: BirdsEye-RU数据集填补了航拍图像中小尺寸人脸检测数据集的空白，为相关研究提供了有价值的资源。

Abstract: Detecting faces in overhead images remains a significant challenge due to extreme scale variations and environmental clutter. To address this, we created the BirdsEye-RU dataset, a comprehensive collection of 2,978 images containing over eight thousand annotated faces. This dataset is specifically designed to capture small and distant faces across diverse environments, containing both drone images and smartphone-captured images from high altitude. We present a detailed description of the BirdsEye-RU dataset in this paper. We made our dataset freely available to the public, and it can be accessed at https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru.

</details>


### [462] [PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception](https://arxiv.org/abs/2601.12551)
*Tong Wu*

Main category: cs.CV

Relevance: 15.0

TL;DR: PISE：一种结合伴随算子初始化和语义引导的物理信息深度鬼成像框架，用于低带宽边缘感知，在5%采样率下分类精度提升2.57%，方差降低9倍


<details>
  <summary>Details</summary>
Motivation: 解决低带宽边缘感知场景下的成像质量与效率问题，传统方法在低采样率下性能受限，需要结合物理先验与深度学习提升感知能力

Method: 提出物理信息深度鬼成像框架PISE，结合伴随算子初始化（利用物理模型先验）和语义引导（利用深度学习语义信息），优化低采样率下的成像重建

Result: 在5%采样率下，分类精度提升2.57%，方差降低9倍，显著提升低带宽边缘感知的稳定性和准确性

Conclusion: PISE框架有效融合物理先验与语义信息，显著提升低采样率下的边缘感知性能，为资源受限的边缘计算场景提供高效解决方案

Abstract: We propose PISE, a physics-informed deep ghost imaging framework for low-bandwidth edge perception. By combining adjoint operator initialization with semantic guidance, PISE improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.

</details>


### [463] [Camera Pose Revisited](https://arxiv.org/abs/2601.12567)
*Władysław Skarbek,Michał Salomonowicz,Michał Król*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出PnP-ProCay78算法解决平面透视n点问题，结合二次重建误差与Cayley旋转参数化，通过确定性起点选择避免搜索，在RGB-IR系统中验证性能接近最优方法但结构更简单。


<details>
  <summary>Details</summary>
Motivation: 解决相机姿态估计中的平面透视n点问题，特别是在标定物体初始姿态估计方面。现有方法要么计算复杂，要么缺乏几何直观性，需要一种既高效又具有几何透明度的解决方案。

Method: 提出PnP-ProCay78算法：1) 结合经典二次重建误差公式与Cayley旋转参数化；2) 使用最小二乘优化；3) 关键创新是通过分析两个规范向量的重建误差进行确定性起点选择，避免昂贵的解空间搜索；4) 采用混合代价函数，将投影误差最小化与解析消除平移重建误差相结合。

Result: 实验验证使用高分辨率RGB相机和低分辨率热成像相机的RGB-IR系统数据。结果显示：1) 投影精度与最优SQPnP几乎相同；2) 略高于IPPE；3) 算法结构显著更简单；4) Cayley空间中的优化轨迹分析提供了收敛过程的直观理解。

Conclusion: PnP-ProCay78算法在保持与最优方法相当精度的同时，提供了更简单的算法结构和几何透明度。Cayley空间分析增强了方法的可理解性，使其也具有教学价值。该算法为平面PnP问题提供了一种高效且直观的解决方案。

Abstract: Estimating the position and orientation of a camera with respect to an observed scene is one of the central problems in computer vision, particularly in the context of camera calibration and multi-sensor systems. This paper addresses the planar Perspective--$n$--Point problem, with special emphasis on the initial estimation of the pose of a calibration object. As a solution, we propose the \texttt{PnP-ProCay78} algorithm, which combines the classical quadratic formulation of the reconstruction error with a Cayley parameterization of rotations and least-squares optimization. The key component of the method is a deterministic selection of starting points based on an analysis of the reconstruction error for two canonical vectors, allowing costly solution-space search procedures to be avoided. Experimental validation is performed using data acquired also from high-resolution RGB cameras and very low-resolution thermal cameras in an integrated RGB--IR setup. The results demonstrate that the proposed algorithm achieves practically the same projection accuracy as optimal \texttt{SQPnP} and slightly higher than \texttt{IPPE}, both prominent \texttt{PnP-OpenCV} procedures. However, \texttt{PnP-ProCay78} maintains a significantly simpler algorithmic structure. Moreover, the analysis of optimization trajectories in Cayley space provides an intuitive insight into the convergence process, making the method attractive also from a didactic perspective. Unlike existing PnP solvers, the proposed \texttt{PnP-ProCay78} algorithm combines projection error minimization with an analytically eliminated reconstruction-error surrogate for translation, yielding a hybrid cost formulation that is both geometrically transparent and computationally efficient.

</details>


### [464] [Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface](https://arxiv.org/abs/2601.12666)
*Zonglin Li,Jieji Ren,Shuangfan Zhou,Heng Guo,Jinnuo Zhang,Jiang Zhou,Boxin Shi,Zhanyu Ma,Guoying Gu*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出一个利用神经隐式表示进行单图像颜色光度立体视觉的框架，在单色性假设下实现深度和BRDF建模，并设计光学触觉传感器进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有颜色光度立体视觉方法大多假设理想远距离照明和朗伯反射，忽略了更实际的近光条件和非朗伯表面。需要克服这些限制，实现更实用的单图像表面重建。

Method: 提出基于神经隐式表示的框架，在单色性假设（均匀色度和同质材料）下进行深度和BRDF建模，缓解颜色光度立体视觉的固有不适定性，并设计紧凑的光学触觉传感器进行验证。

Result: 在合成和真实世界数据集上的实验表明，该方法实现了准确且鲁棒的表面重建。

Conclusion: 该框架成功解决了颜色光度立体视觉在实际条件下的限制，通过神经隐式表示和单色性假设实现了从单图像进行详细表面恢复。

Abstract: Color photometric stereo enables single-shot surface reconstruction, extending conventional photometric stereo that requires multiple images of a static scene under varying illumination to dynamic scenarios. However, most existing approaches assume ideal distant lighting and Lambertian reflectance, leaving more practical near-light conditions and non-Lambertian surfaces underexplored. To overcome this limitation, we propose a framework that leverages neural implicit representations for depth and BRDF modeling under the assumption of mono-chromaticity (uniform chromaticity and homogeneous material), which alleviates the inherent ill-posedness of color photometric stereo and allows for detailed surface recovery from just one image. Furthermore, we design a compact optical tactile sensor to validate our approach. Experiments on both synthetic and real-world datasets demonstrate that our method achieves accurate and robust surface reconstruction.

</details>


### [465] [Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement](https://arxiv.org/abs/2601.12682)
*Banglei Guan,Dongcai Tan,Jing Tao,Ang Su,Yang Shang,Qifeng Yu*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了一种用于高温结构变形测量的图像处理方法，通过多曝光图像融合和灰度平均算法来抑制热辐射和热霾干扰，提高数字图像相关法（DIC）的测量精度。


<details>
  <summary>Details</summary>
Motivation: 在高温结构变形测量中，热辐射引起的图像退化和热霾引入的随机误差限制了变形测量的精度和有效性。传统DIC方法在高温环境下受到这些干扰因素的影响，需要新的图像处理技术来抑制这些干扰。

Method: 1. 针对热辐射引起的图像退化：基于图像分层表示，将图像分解为正负通道并行处理，通过多曝光图像融合优化图像质量。
2. 针对热霾引入的高频随机误差：采用FSIM作为目标函数指导模型参数迭代优化，应用灰度平均算法均衡异常灰度值以减少测量误差。

Result: 1. 多曝光图像融合算法将欠曝光图像的有效计算区域从26%提升到50%，过曝光图像从32%提升到40%，且不降低测量精度。
2. 结合灰度平均算法的图像恢复方法显著减少了静态热变形测量误差：ε_xx误差减少85.3%，ε_yy误差减少36.0%，γ_xy误差减少36.4%。

Conclusion: 提出的图像处理方法能有效抑制高温变形测量中热辐射和热霾的干扰，提高图像质量并减少变形测量误差，在热变形测量中具有潜在应用价值。

Abstract: In the deformation measurement of high-temperature structures, image degradation caused by thermal radiation and random errors introduced by heat haze restrict the accuracy and effectiveness of deformation measurement. To suppress thermal radiation and heat haze using fusion-restoration image processing methods, thereby improving the accuracy and effectiveness of DIC in the measurement of high-temperature deformation. For image degradation caused by thermal radiation, based on the image layered representation, the image is decomposed into positive and negative channels for parallel processing, and then optimized for quality by multi-exposure image fusion. To counteract the high-frequency, random errors introduced by heat haze, we adopt the FSIM as the objective function to guide the iterative optimization of model parameters, and the grayscale average algorithm is applied to equalize anomalous gray values, thereby reducing measurement error. The proposed multi-exposure image fusion algorithm effectively suppresses image degradation caused by complex illumination conditions, boosting the effective computation area from 26% to 50% for under-exposed images and from 32% to 40% for over-exposed images without degrading measurement accuracy in the experiment. Meanwhile, the image restoration combined with the grayscale average algorithm reduces static thermal deformation measurement errors. The error in ε_xx is reduced by 85.3%, while the errors in ε_yy and γ_xy are reduced by 36.0% and 36.4%, respectively. We present image processing methods to suppress the interference of thermal radiation and heat haze in high-temperature deformation measurement using DIC. The experimental results verify that the proposed method can effectively improve image quality, reduce deformation measurement errors, and has potential application value in thermal deformation measurement.

</details>


### [466] [GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation](https://arxiv.org/abs/2601.12683)
*Liwei Liao,Ronggang Wang*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出GaussianTrimmer，一种用于3D高斯分割的在线边界修剪方法，通过虚拟相机和2D分割结果来修剪粗糙边界，提升分割质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯分割方法基于高斯基元进行分割，但由于3D高斯尺度变化范围大，大尺寸高斯经常跨越前景和背景，导致分割对象边界出现锯齿状问题。

Method: 提出GaussianTrimmer，包含两个核心步骤：1) 生成均匀且覆盖良好的虚拟相机；2) 基于虚拟相机上的2D分割结果在基元级别修剪高斯。

Result: 大量定量和定性实验表明，该方法作为即插即用方法能够提高现有3D高斯分割方法的分割质量。

Conclusion: GaussianTrimmer是一种高效、即插即用的后处理方法，能够为现有3D高斯分割方法修剪粗糙边界，改善分割效果。

Abstract: With the widespread application of 3D Gaussians in 3D scene representation, 3D scene segmentation methods based on 3D Gaussians have also gradually emerged. However, existing 3D Gaussian segmentation methods basically segment on the basis of Gaussian primitives. Due to the large variation range of the scale of 3D Gaussians, large-sized Gaussians that often span the foreground and background lead to jagged boundaries of segmented objects. To this end, we propose an online boundary trimming method, GaussianTrimmer, which is an efficient and plug-and-play post-processing method capable of trimming coarse boundaries for existing 3D Gaussian segmentation methods. Our method consists of two core steps: 1. Generating uniformly and well-covered virtual cameras; 2. Trimming Gaussian at the primitive level based on 2D segmentation results on virtual cameras. Extensive quantitative and qualitative experiments demonstrate that our method can improve the segmentation quality of existing 3D Gaussian segmentation methods as a plug-and-play method.

</details>


### [467] [Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation](https://arxiv.org/abs/2601.12697)
*Chao Yang,Deshui Miao,Chao Tian,Guoqing Zhu,Yameng Gu,Zhenyu He*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出IVGF框架，利用3D高斯表示重建场景几何，通过跨模态调整模块解决模态冲突，实现红外-可见光图像融合的直接渲染。


<details>
  <summary>Details</summary>
Motivation: 现有2D融合方法局限于固定视角，缺乏对复杂场景的全面理解，导致关键信息丢失。需要一种能重建场景几何并直接渲染融合图像的方法。

Method: 提出红外-可见光高斯融合(IVGF)框架：1) 从多模态2D输入重建场景几何；2) 跨模态调整(CMA)模块调制高斯不透明度解决模态冲突；3) 融合损失指导CMA优化，保留各模态关键特征。

Result: 综合定性和定量实验证明了该方法的有效性，能够生成保留红外和可见光关键特征的融合图像。

Conclusion: IVGF框架通过3D高斯表示和跨模态调整，解决了传统2D融合方法的局限性，实现了更全面的场景理解和信息保留。

Abstract: Infrared-visible image fusion aims to integrate infrared and visible information into a single fused image. Existing 2D fusion methods focus on fusing images from fixed camera viewpoints, neglecting a comprehensive understanding of complex scenarios, which results in the loss of critical information about the scene. To address this limitation, we propose a novel Infrared-Visible Gaussian Fusion (IVGF) framework, which reconstructs scene geometry from multimodal 2D inputs and enables direct rendering of fused images. Specifically, we propose a cross-modal adjustment (CMA) module that modulates the opacity of Gaussians to solve the problem of cross-modal conflicts. Moreover, to preserve the distinctive features from both modalities, we introduce a fusion loss that guides the optimization of CMA, thus ensuring that the fused image retains the critical characteristics of each modality. Comprehensive qualitative and quantitative experiments demonstrate the effectiveness of the proposed method.

</details>


### [468] [Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image](https://arxiv.org/abs/2601.12770)
*Shuling Zhao,Dan Xu*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出单图像3D可动画头像重建框架，通过高斯基元嵌入参数化人脸模型，结合3D GAN先验和对称性特征融合，实现实时动画和360度渲染


<details>
  <summary>Details</summary>
Motivation: 现有单图像3D头像重建方法在大视角变化下效果不佳，难以保持真实感。需要解决单次前向传播即可重建3D全头可动画头像的挑战，支持实时动画和全方位渲染。

Method: 1) 在参数化人脸模型UV空间嵌入高斯基元建模3D头像；2) 利用预训练3D GAN提取全局全头特征并进行多视角监督；3) 利用UV空间和人脸对称性，融合局部精细输入图像特征与全局全头纹理。

Result: 实验证明该方法能实现高质量3D全头建模和实时动画，显著提升3D说话头像的真实感，优于现有方法。

Conclusion: 提出的框架成功解决了单图像3D可动画头像重建问题，通过结合参数化模型、3D GAN先验和对称性特征融合，实现了高质量、实时动画的全头3D头像生成。

Abstract: Building 3D animatable head avatars from a single image is an important yet challenging problem. Existing methods generally collapse under large camera pose variations, compromising the realism of 3D avatars. In this work, we propose a new framework to tackle the novel setting of one-shot 3D full-head animatable avatar reconstruction in a single feed-forward pass, enabling real-time animation and simultaneous 360$^\circ$ rendering views. To facilitate efficient animation control, we model 3D head avatars with Gaussian primitives embedded on the surface of a parametric face model within the UV space. To obtain knowledge of full-head geometry and textures, we leverage rich 3D full-head priors within a pretrained 3D generative adversarial network (GAN) for global full-head feature extraction and multi-view supervision. To increase the fidelity of the 3D reconstruction of the input image, we take advantage of the symmetric nature of the UV space and human faces to fuse local fine-grained input image features with the global full-head textures. Extensive experiments demonstrate the effectiveness of our method, achieving high-quality 3D full-head modeling as well as real-time animation, thereby improving the realism of 3D talking avatars.

</details>


### [469] [PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition](https://arxiv.org/abs/2601.12798)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Yue Xiu,Lu Chen,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出PhyG-MoE框架，通过物理引导的混合专家模型动态调整计算资源以适应信号复杂度，解决GNSS干扰识别中静态模型资源不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习干扰识别模型采用固定计算拓扑，无法根据输入信号的物理熵动态调整，导致简单信号和复杂信号消耗相同计算资源，造成资源浪费和效率低下。

Method: 提出PhyG-MoE框架，采用基于频谱的门控机制根据信号频谱特征纠缠度进行路由：复杂饱和场景激活高容量TransNeXt专家，基础信号使用轻量专家处理以降低延迟。

Result: 在21种干扰类别上达到97.58%的整体准确率，显著降低计算开销且无性能损失，为资源受限的认知接收器提供可行解决方案。

Conclusion: PhyG-MoE通过动态对齐模型容量与信号复杂度，解决了静态计算与动态电磁环境的内在冲突，实现了高效可靠的GNSS干扰识别。

Abstract: Complex electromagnetic interference increasingly compromises Global Navigation Satellite Systems (GNSS), threatening the reliability of Space-Air-Ground Integrated Networks (SAGIN). Although deep learning has advanced interference recognition, current static models suffer from a \textbf{fundamental limitation}: they impose a fixed computational topology regardless of the input's physical entropy. This rigidity leads to severe resource mismatch, where simple primitives consume the same processing cost as chaotic, saturated mixtures. To resolve this, this paper introduces PhyG-MoE (Physics-Guided Mixture-of-Experts), a framework designed to \textbf{dynamically align model capacity with signal complexity}. Unlike static architectures, the proposed system employs a spectrum-based gating mechanism that routes signals based on their spectral feature entanglement. A high-capacity TransNeXt expert is activated on-demand to disentangle complex features in saturated scenarios, while lightweight experts handle fundamental signals to minimize latency. Evaluations on 21 jamming categories demonstrate that PhyG-MoE achieves an overall accuracy of 97.58\%. By resolving the intrinsic conflict between static computing and dynamic electromagnetic environments, the proposed framework significantly reduces computational overhead without performance degradation, offering a viable solution for resource-constrained cognitive receivers.

</details>


### [470] [GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure](https://arxiv.org/abs/2601.13052)
*Antoine Carreaud,Shanci Li,Malo De Lacour,Digre Frinde,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

Relevance: 15.0

TL;DR: GridNet-HD是一个用于电力基础设施3D语义分割的多模态数据集，结合高密度LiDAR和高分辨率倾斜影像，包含7,694张图像和25亿个点，标注为11个类别，提供单模态和多模态融合基线。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏同时提供高密度LiDAR和高分辨率倾斜影像的公开数据集，用于电力线路资产的3D语义标注。电力基础设施的监测和维护需要精确的3D语义分割，而几何信息（LiDAR）和外观信息（影像）的互补性尚未得到充分探索。

Method: 创建了一个多模态数据集，包含高密度LiDAR点云和高分辨率倾斜影像，标注了11个语义类别。提供了单模态基线（仅LiDAR、仅影像）和多模态融合基线，使用mIoU作为评估指标，并进行了预定义的数据集划分。

Result: 在GridNet-HD数据集上，多模态融合模型比最佳单模态基线提升了+5.55 mIoU，证明了几何信息和外观信息的互补性。数据集、基线和代码已公开提供。

Conclusion: GridNet-HD填补了电力基础设施3D语义分割领域的数据集空白，证明了多模态融合在电力线路资产识别中的有效性，为相关研究提供了基准和资源。

Abstract: This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: https://huggingface.co/collections/heig-vd-geo/gridnet-hd.

</details>


### [471] [Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations](https://arxiv.org/abs/2601.13225)
*Tim Lachmann,Alexandra Israelsson,Christina Tornberg,Teimuraz Saghinadze,Michal Balazia,Philipp Müller,Petri Laukka*

Main category: cs.CV

Relevance: 15.0

TL;DR: 本文介绍了BLEMORE数据集，用于多模态混合情感识别，包含情感相对显著性的标注，评估了现有方法在混合情感识别任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 人类经常同时体验多种混合情感，而现有视频情感识别方法大多只能识别单一情感，少数尝试识别混合情感的方法无法评估情感间的相对显著性，这主要源于缺乏包含大量混合情感样本且标注了相对显著性的数据集。

Method: 提出了BLEMORE数据集，包含来自58位演员的3000多个视频片段，涵盖6种基本情感和10种不同混合情感，每种混合有3种显著性配置（50/50、70/30、30/70）。使用该数据集评估了最先进的视频分类方法在两个混合情感预测任务上的表现：情感存在预测和情感相对显著性预测。

Result: 单模态分类器在验证集上达到29%的存在准确率和13%的显著性准确率，多模态方法有明显改进，ImageBind + WavLM达到35%存在准确率，HiCMAE达到18%显著性准确率。在测试集上，最佳模型达到33%存在准确率（VideoMAEv2 + HuBERT）和18%显著性准确率（HiCMAE）。

Conclusion: BLEMORE数据集为推进考虑混合情感表达复杂性和重要性的情感识别系统研究提供了宝贵资源。

Abstract: Humans often experience not just a single basic emotion at a time, but rather a blend of several emotions with varying salience. Despite the importance of such blended emotions, most video-based emotion recognition approaches are designed to recognize single emotions only. The few approaches that have attempted to recognize blended emotions typically cannot assess the relative salience of the emotions within a blend. This limitation largely stems from the lack of datasets containing a substantial number of blended emotion samples annotated with relative salience. To address this shortcoming, we introduce BLEMORE, a novel dataset for multimodal (video, audio) blended emotion recognition that includes information on the relative salience of each emotion within a blend. BLEMORE comprises over 3,000 clips from 58 actors, performing 6 basic emotions and 10 distinct blends, where each blend has 3 different salience configurations (50/50, 70/30, and 30/70). Using this dataset, we conduct extensive evaluations of state-of-the-art video classification approaches on two blended emotion prediction tasks: (1) predicting the presence of emotions in a given sample, and (2) predicting the relative salience of emotions in a blend. Our results show that unimodal classifiers achieve up to 29% presence accuracy and 13% salience accuracy on the validation set, while multimodal methods yield clear improvements, with ImageBind + WavLM reaching 35% presence accuracy and HiCMAE 18% salience accuracy. On the held-out test set, the best models achieve 33% presence accuracy (VideoMAEv2 + HuBERT) and 18% salience accuracy (HiCMAE). In sum, the BLEMORE dataset provides a valuable resource to advancing research on emotion recognition systems that account for the complexity and significance of blended emotion expressions.

</details>


### [472] [Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments](https://arxiv.org/abs/2601.13364)
*Zhenan Liu,Yaodong Cui,Amir Khajepour,George Shaker*

Main category: cs.CV

Relevance: 15.0

TL;DR: 本文提出了一种在高度杂乱环境中生成可控多级粉尘浓度的方法，用于毫米波传播研究，并开发了基于阈值的噪声过滤框架和聚类级规则分类管道，实现粉尘环境下可靠的行人检测。


<details>
  <summary>Details</summary>
Motivation: 研究动机是在地下矿井、公路隧道等恶劣封闭环境中，粉尘颗粒和反射表面会严重影响毫米波雷达的感知功能，需要开发能够在严重电磁约束下可靠工作的检测系统。

Method: 方法包括：1）生成可控多级粉尘浓度的实验环境；2）提出基于阈值（RCS、速度、方位角、仰角）的噪声过滤框架来抑制鬼目标和多径反射；3）基于过滤点云的聚类级规则分类管道，利用雷达语义特征实现实时行人检测。

Result: 实验结果表明，该集成方法显著增强了粉尘环境中杂波抑制、检测鲁棒性和系统整体弹性，实现了可靠的实时行人检测。

Conclusion: 本文提出的方法能够有效应对粉尘环境下的毫米波雷达感知挑战，为恶劣环境中的可靠检测提供了解决方案。

Abstract: This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.

</details>


### [473] [A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions](https://arxiv.org/abs/2601.13373)
*Zhenan Liu,Amir Khajepour,George Shaker*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出一个完全模型驱动的4D毫米波雷达感知框架，用于恶劣工业/地下环境中实时嵌入式边缘硬件上的人类检测，在粉尘/烟雾等能见度下降条件下比相机和LiDAR更稳定。


<details>
  <summary>Details</summary>
Motivation: 工业/地下环境中普遍存在的粉尘、烟雾、受限几何结构和金属结构严重限制了光学和LiDAR感知，而4D毫米波雷达对此类条件具有强鲁棒性，但对其稀疏各向异性点云处理的理解有限。

Method: 完全模型驱动的4D雷达感知框架，包含领域感知多阈值滤波、自我运动补偿时间累积、KD树欧几里得聚类与多普勒感知细化、基于规则的3D分类器。

Result: 在粉尘填充的封闭拖车和真实地下采矿隧道中评估，在测试场景中，当相机和LiDAR在严重能见度下降条件下失效时，雷达检测器保持稳定的行人识别。

Conclusion: 提出的模型驱动方法为恶劣工业/地下环境中的安全关键应用提供了鲁棒、可解释且计算高效的感知。

Abstract: Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.

</details>


### [474] [Anisotropic Tensor Deconvolution of Hyperspectral Images](https://arxiv.org/abs/2601.11694)
*Xinjue Wang,Xiuheng Wang,Esa Ollila,Sergiy A. Vorobyov*

Main category: eess.IV

Relevance: 15.0

TL;DR: 该论文提出了一种基于低秩CPD分解的HSI去卷积框架，通过将高维图像恢复问题转化为估计CPD因子，大幅减少参数数量，并采用各向异性TV正则化保持光谱平滑性。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像去卷积是一个具有挑战性的病态逆问题，主要困难在于数据的高维度。传统方法需要恢复大量变量，计算复杂度高，因此需要一种参数简洁的框架来有效处理这一问题。

Method: 提出基于低秩CPD分解的参数简洁框架，将整个潜在HSI分解为CPD因子，将恢复问题从PQN个变量减少到(P+Q+N)R个变量。采用结构感知的各向异性TV正则化仅应用于空间因子，保持光谱平滑性。开发基于PALM框架的高效算法求解非凸优化问题。

Result: 实验证实了模型的高效性，参数数量减少了两个数量级以上，在模型紧凑性和重建精度之间取得了良好的平衡。

Conclusion: 提出的CPD分解框架为高维HSI去卷积问题提供了一种参数简洁且有效的解决方案，通过大幅减少参数数量同时保持重建质量。

Abstract: Hyperspectral image (HSI) deconvolution is a challenging ill-posed inverse problem, made difficult by the data's high dimensionality.We propose a parameter-parsimonious framework based on a low-rank Canonical Polyadic Decomposition (CPD) of the entire latent HSI $\mathbf{\mathcal{X}} \in \mathbb{R}^{P\times Q \times N}$.This approach recasts the problem from recovering a large-scale image with $PQN$ variables to estimating the CPD factors with $(P+Q+N)R$ variables.This model also enables a structure-aware, anisotropic Total Variation (TV) regularization applied only to the spatial factors, preserving the smooth spectral signatures.An efficient algorithm based on the Proximal Alternating Linearized Minimization (PALM) framework is developed to solve the resulting non-convex optimization problem.Experiments confirm the model's efficiency, showing a numerous parameter reduction of over two orders of magnitude and a compelling trade-off between model compactness and reconstruction accuracy.

</details>


### [475] [Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting](https://arxiv.org/abs/2601.13665)
*Mounika Kanulla,Rajasree Dadigi,Sailaja Thota,Vivek Yelleti*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出融合CNN与LSTM/DeiT Transformer的多任务架构，用于蔬菜分类、腐败检测和保质期预测，在自建数据集上表现优于多个深度学习基准模型。


<details>
  <summary>Details</summary>
Motivation: 农业供应链中的食物浪费是重要挑战，准确的腐败检测和预测能减少浪费并延长供应链管理寿命，因此需要同时处理蔬菜分类、腐败检测和保质期预测的多任务解决方案。

Method: 提出融合架构：CNN+CNN-LSTM和CNN+DeiT Transformer，通过自建数据集（从新鲜到完全腐败的蔬菜图像），同时处理三个任务：蔬菜分类、腐败检测和保质期预测。

Result: CNN+DeiT Transformer在蔬菜分类和腐败检测的F1分数分别为0.98和0.61，保质期预测的MSE和SMAPE分别为3.58和41.66%，优于CNN、VGG16、ResNet50、胶囊网络和DeiT Transformer等基准模型。

Conclusion: 融合架构在蔬菜腐败检测和预测任务中表现优异，通过噪声图像验证了模型鲁棒性，并集成LIME进行决策可视化，为农业供应链管理提供了有效解决方案。

Abstract: Food wastage is one of the critical challenges in the agricultural supply chain, and accurate and effective spoilage detection can help to reduce it. Further, it is highly important to forecast the spoilage information. This aids the longevity of the supply chain management in the agriculture field. This motivated us to propose fusion based architectures by combining CNN with LSTM and DeiT transformer for the following multi-tasks simultaneously: (i) vegetable classification, (ii) food spoilage detection, and (iii) shelf life forecasting. We developed a dataset by capturing images of vegetables from their fresh state until they were completely spoiled. From the experimental analysis it is concluded that the proposed fusion architectures CNN+CNN-LSTM and CNN+DeiT Transformer outperformed several deep learning models such as CNN, VGG16, ResNet50, Capsule Networks, and DeiT Transformers. Overall, CNN + DeiT Transformer yielded F1-score of 0.98 and 0.61 in vegetable classification and spoilage detection respectively and mean squared error (MSE) and symmetric mean absolute percentage error (SMAPE) of 3.58, and 41.66% respectively in spoilage forecasting. Further, the reliability of the fusion models was validated on noisy images and integrated with LIME to visualize the model decisions.

</details>


### [476] [MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network](https://arxiv.org/abs/2601.13715)
*Yiwei Lu,Hao Huang,Tao Yan*

Main category: cs.CV

Relevance: 15.0

TL;DR: MVGD-Net：利用运动不一致性检测视频中玻璃表面的新网络，包含跨尺度多模态融合、历史引导注意力和时序交叉注意力模块，并构建了大规模数据集。


<details>
  <summary>Details</summary>
Motivation: 玻璃表面在日常生活和专业环境中普遍存在，对机器人、无人机等视觉系统构成潜在威胁。现有视频玻璃表面检测方法有限，作者观察到玻璃反射/透射层中的物体看起来更远，在视频运动场景中移动更慢，这种运动不一致性可有效揭示玻璃表面存在。

Method: 提出MVGD-Net网络，包含三个核心模块：1) 跨尺度多模态融合模块(CMFM)整合空间特征和光流图；2) 历史引导注意力模块(HGAM)增强时序特征；3) 时序交叉注意力模块(TCAM)进一步优化时序特征。还使用时序-空间解码器(TSD)融合时空特征生成玻璃区域掩码。构建包含312个场景、19,268帧的大规模数据集。

Result: 大量实验表明，MVGD-Net在视频玻璃表面检测任务上优于相关最先进方法。

Conclusion: 通过利用运动不一致性线索，MVGD-Net能有效检测视频中的玻璃表面，提出的网络架构和数据集为这一重要计算机视觉任务提供了有力解决方案。

Abstract: Glass surface ubiquitous in both daily life and professional environments presents a potential threat to vision-based systems, such as robot and drone navigation. To solve this challenge, most recent studies have shown significant interest in Video Glass Surface Detection (VGSD). We observe that objects in the reflection (or transmission) layer appear farther from the glass surfaces. Consequently, in video motion scenarios, the notable reflected (or transmitted) objects on the glass surface move slower than objects in non-glass regions within the same spatial plane, and this motion inconsistency can effectively reveal the presence of glass surfaces. Based on this observation, we propose a novel network, named MVGD-Net, for detecting glass surfaces in videos by leveraging motion inconsistency cues. Our MVGD-Net features three novel modules: the Cross-scale Multimodal Fusion Module (CMFM) that integrates extracted spatial features and estimated optical flow maps, the History Guided Attention Module (HGAM) and Temporal Cross Attention Module (TCAM), both of which further enhances temporal features. A Temporal-Spatial Decoder (TSD) is also introduced to fuse the spatial and temporal features for generating the glass region mask. Furthermore, for learning our network, we also propose a large-scale dataset, which comprises 312 diverse glass scenarios with a total of 19,268 frames. Extensive experiments demonstrate that our MVGD-Net outperforms relevant state-of-the-art methods.

</details>


### [477] [Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving](https://arxiv.org/abs/2601.14038)
*Alexandre Justo Miro,Ludvig af Klinteberg,Bogdan Timus,Aron Asefaw,Ajinkya Khoche,Thomas Gustafsson,Sina Sharif Mansouri,Masoud Daneshtalab*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了一种校正自动驾驶数据集3D边界框标注误差的方法，通过离线估计实现物理可行的轨迹和时空一致性，显著提升标注质量


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统依赖准确的标注数据进行监督学习和性能评估。主动传感器（如LiDAR）在动态场景中扫描时，物体在不同时间戳处于不同位置，导致3D边界框标注存在系统性误差。作者首次在广泛使用的公开数据集中发现了这种标注错误。

Method: 提出新颖的离线估计方法，通过校正标注使其遵循物理可行的轨迹，并与传感器数据保持时空一致性。首次定义了该问题的评估指标，并在Argoverse 2、MAN TruckScenes和专有数据集上进行评估。

Result: 方法将边界框标注质量提升超过17%。量化显示原始标注误差可达2.5米，高度动态物体受影响最大。测试发现这些误差对基准测试的影响超过了SOTA方法相对于先前SOTA方法的改进幅度。

Conclusion: 准确的标注对于正确解释性能至关重要。提出的校正方法显著提升了自动驾驶数据集的标注质量，揭示了现有基准测试中可能存在的误导性结果。

Abstract: Accurate ground truth annotations are critical to supervised learning and evaluating the performance of autonomous vehicle systems. These vehicles are typically equipped with active sensors, such as LiDAR, which scan the environment in predefined patterns. 3D box annotation based on data from such sensors is challenging in dynamic scenarios, where objects are observed at different timestamps, hence different positions. Without proper handling of this phenomenon, systematic errors are prone to being introduced in the box annotations. Our work is the first to discover such annotation errors in widely used, publicly available datasets. Through our novel offline estimation method, we correct the annotations so that they follow physically feasible trajectories and achieve spatial and temporal consistency with the sensor data. For the first time, we define metrics for this problem; and we evaluate our method on the Argoverse 2, MAN TruckScenes, and our proprietary datasets. Our approach increases the quality of box annotations by more than 17% in these datasets. Furthermore, we quantify the annotation errors in them and find that the original annotations are misplaced by up to 2.5 m, with highly dynamic objects being the most affected. Finally, we test the impact of the errors in benchmarking and find that the impact is larger than the improvements that state-of-the-art methods typically achieve with respect to the previous state-of-the-art methods; showing that accurate annotations are essential for correct interpretation of performance. Our code is available at https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes.

</details>


### [478] [VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences](https://arxiv.org/abs/2601.14066)
*Hendrik Möller,Hanna Schoen,Robert Graf,Matan Atad,Nathan Molinier,Anjany Sekuboyina,Bettina K. Budai,Fabian Bamberg,Steffen Ringhof,Christopher Schlett,Tobias Pischon,Thoralf Niendorf,Josua A. Decker,Marc-André Weber,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke*

Main category: cs.CV

Relevance: 15.0

TL;DR: VERIDAH：一种基于多分类头和加权椎体序列预测算法的椎体标记算法，能够自动识别椎体计数异常，在MRI和CT影像上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 人类脊柱通常有固定的椎体数量，但存在计数异常（如11或13个胸椎、4或6个腰椎）。这些异常对慢性背痛和手术规划有临床意义，但临床报告中很少描述。现有深度学习椎体标记算法缺乏自动识别计数异常的能力。

Method: 提出VERIDAH算法，基于多分类头结合加权椎体序列预测算法。通过多个分类头处理不同椎体类型，结合序列预测来处理任意视野图像中的椎体计数异常。

Result: 在T2w TSE矢状位MRI上，正确标记所有椎体的比例从94.24%提升到98.30%（p<0.001）；在CT影像上从77.26%提升到99.18%（p<0.001）。胸椎计数异常识别准确率：T2w 87.80%，CT 96.30%；腰椎计数异常识别准确率：T2w 94.48%，CT 97.22%。

Conclusion: VERIDAH能够有效自动识别椎体计数异常，在MRI和CT影像上表现优异，填补了现有椎体标记算法无法处理计数异常的空白。

Abstract: The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing "Vertebra Identification with Anomaly Handling" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps.

</details>


### [479] [VENI: Variational Encoder for Natural Illumination](https://arxiv.org/abs/2601.14079)
*Paul Walker,James A. D. Gardner,Andreea Ardelean,William A. P. Smith,Bernhard Egger*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出了一种旋转等变变分自编码器，用于在球面上建模自然光照，避免了2D投影，通过VN-ViT编码器和旋转等变条件神经场解码器实现SO(2)等变性。


<details>
  <summary>Details</summary>
Motivation: 逆渲染是一个不适定问题，现有方法要么忽略了光照环境的球面和旋转等变特性，要么没有提供良好的潜在空间。需要一种能够保持环境图SO(2)等变性的方法。

Method: 使用新型Vector Neuron Vision Transformer作为编码器，旋转等变条件神经场作为解码器。在编码器中通过SO(2)等变全连接层将等变性从SO(3)降为SO(2)，这是Vector Neurons的扩展。

Result: SO(2)等变全连接层在SO(2)等变模型中优于标准Vector Neurons。相比先前方法，该变分自编码器在潜在空间中实现更平滑的插值，并提供更良好的潜在空间。

Conclusion: 提出的旋转等变变分自编码器能够有效建模球面上的自然光照，保持SO(2)等变性，提供更优的潜在空间表示。

Abstract: Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.

</details>


### [480] [Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing](https://arxiv.org/abs/2601.14103)
*Xiaolu Liu,Yicong Li,Qiyuan He,Jiayin Zhu,Wei Ji,Angela Yao,Jianke Zhu*

Main category: cs.CV

Relevance: 15.0

TL;DR: Interp3D：一种无需训练的三维纹理变形框架，通过生成先验和渐进对齐原则，在保持几何一致性和纹理连贯性的同时，实现两个三维资产之间的平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 现有三维变形方法存在局限性：几何方法只能处理形状变形而忽略纹理；基于二维插值扩展到三维的方法常导致语义模糊、结构错位和纹理模糊。需要一种能同时保持几何一致性、纹理对齐和鲁棒性的联合方法。

Method: 提出Interp3D训练免费框架：1）从条件空间的语义对齐插值开始；2）通过SLAT引导的结构插值强制结构一致性；3）通过细粒度纹理融合传递外观细节。采用渐进对齐原则确保几何保真度和纹理连贯性。

Result: 构建了专用数据集Interp3DData，包含分级难度级别。在保真度、过渡平滑性和合理性方面进行评估，定量指标和人工研究均显示该方法显著优于先前方法。

Conclusion: Interp3D成功解决了三维纹理变形中的关键挑战，在保持几何和纹理一致性的同时实现了平滑可信的过渡，为三维生成研究提供了重要工具。

Abstract: Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.

</details>


### [481] [GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression](https://arxiv.org/abs/2601.14130)
*Till Aczel,David F. Jenny,Simon Bührer,Andreas Plesner,Antonio Di Maio,Roger Wattenhofer*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出GIC-DLC方法，通过训练查找表结合神经网络的灵活性和布尔运算的效率，在灰度图像压缩中超越传统编解码器，同时显著降低能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 神经图像编解码器虽然压缩比优于传统方法（如PNG、JPEG-XL），但计算开销大，限制了在智能手机、相机、无人机等能源受限设备上的部署。需要在保持压缩效率的同时降低计算成本。

Method: 提出GIC-DLC（Grayscale Image Compression with Differentiable Logic Circuits），一种硬件感知的编解码器。通过训练查找表（lookup tables）来结合神经网络的灵活性和布尔运算的效率，实现高效压缩。

Result: 在灰度基准数据集上的实验表明，GIC-DLC在压缩效率上优于传统编解码器，同时能显著降低能耗和延迟。

Conclusion: 学习型压缩可以是硬件友好的，为边缘设备上的低功耗图像压缩提供了有前景的方向。

Abstract: Neural image codecs achieve higher compression ratios than traditional hand-crafted methods such as PNG or JPEG-XL, but often incur substantial computational overhead, limiting their deployment on energy-constrained devices such as smartphones, cameras, and drones. We propose Grayscale Image Compression with Differentiable Logic Circuits (GIC-DLC), a hardware-aware codec where we train lookup tables to combine the flexibility of neural networks with the efficiency of Boolean operations. Experiments on grayscale benchmark datasets show that GIC-DLC outperforms traditional codecs in compression efficiency while allowing substantial reductions in energy consumption and latency. These results demonstrate that learned compression can be hardware-friendly, offering a promising direction for low-power image compression on edge devices.

</details>


### [482] [ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction](https://arxiv.org/abs/2601.14165)
*Zhenghong Li,Wensheng Cheng,Congwu Du,Yingtian Pan,Zhaozheng Yin,Haibin Ling*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出ASBA网络，通过A-line ROI状态空间模型和B-line相位注意力，从高度稀疏采样的原始A扫描重建ODT图像，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前ODT技术依赖密集采样，导致扫描时间长、存储需求大，且难以捕捉快速血流动态。现有稀疏采样方法受限于保守采样率和均匀建模，效果有限。

Method: 提出ASBA网络：1) A-line ROI状态空间模型提取稀疏分布的血流特征；2) B-line相位注意力基于相位差捕获长程血流信号；3) 血流感知加权损失函数优先准确重建血流信号。

Result: 在真实动物数据上的大量实验表明，该方法明显优于现有的最先进重建方法。

Conclusion: ASBA网络能够从高度稀疏采样的原始A扫描有效重建ODT图像，解决了当前ODT技术的局限性。

Abstract: Optical Doppler Tomography (ODT) is an emerging blood flow analysis technique. A 2D ODT image (B-scan) is generated by sequentially acquiring 1D depth-resolved raw A-scans (A-line) along the lateral axis (B-line), followed by Doppler phase-subtraction analysis. To ensure high-fidelity B-scan images, current practices rely on dense sampling, which prolongs scanning time, increases storage demands, and limits the capture of rapid blood flow dynamics. Recent studies have explored sparse sampling of raw A-scans to alleviate these limitations, but their effectiveness is hindered by the conservative sampling rates and the uniform modeling of flow and background signals. In this study, we introduce a novel blood flow-aware network, named ASBA (A-line ROI State space model and B-line phase Attention), to reconstruct ODT images from highly sparsely sampled raw A-scans. Specifically, we propose an A-line ROI state space model to extract sparsely distributed flow features along the A-line, and a B-line phase attention to capture long-range flow signals along each B-line based on phase difference. Moreover, we introduce a flow-aware weighted loss function that encourages the network to prioritize the accurate reconstruction of flow signals. Extensive experiments on real animal data demonstrate that the proposed approach clearly outperforms existing state-of-the-art reconstruction methods.

</details>


### [483] [Progressive self-supervised blind-spot denoising method for LDCT denoising](https://arxiv.org/abs/2601.14180)
*Yichao Liu,Yueyang Teng,Junwen Guo*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出一种仅使用低剂量CT图像的自监督训练策略，通过逐步盲点去噪机制和添加高斯噪声作为正则化，在LDCT图像去噪任务上达到与监督方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 临床实践中获取配对的正常剂量CT数据困难，自监督学习可以缓解对配对数据的依赖。现有自监督方法在低剂量CT图像去噪方面仍有改进空间。

Method: 1) 提出仅使用LDCT图像的自监督训练策略；2) 引入逐步盲点去噪机制，通过条件独立性实现更精细的去噪学习；3) 添加高斯噪声作为正则化，防止过拟合。

Result: 在Mayo LDCT数据集上的实验表明，该方法持续优于现有自监督方法，性能与多个代表性监督去噪方法相当甚至更好。

Conclusion: 提出的自监督方法有效解决了LDCT图像去噪问题，减少了对配对数据的依赖，在临床应用中具有实际价值。

Abstract: Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.

</details>


### [484] [Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting](https://arxiv.org/abs/2601.14208)
*Nitin Kulkarni,Akhil Devarashetti,Charlie Cluss,Livio Forte,Dan Buckmaster,Philip Schneider,Chunming Qiao,Alina Vereshchaka*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出端到端管道，使用三相机装置捕捉车辆底盘视频，生成交互式3D模型，通过改进的SfM方法解决广角镜头畸变和低视差场景问题


<details>
  <summary>Details</summary>
Motivation: 车辆底盘检查是劳动密集型任务，需要检查员蹲下或爬行检查，且在线买家很少能看到底盘照片。需要提高检查效率和买家信心

Method: 使用三相机装置同步拍摄底盘视频，提出rig-aware SfM管道，集成精确相机标定、同步视频流和相机装置几何先验，采用约束匹配策略（DISK特征提取器+LightGlue匹配器）生成高质量稀疏点云，然后通过高斯泼溅生成实时渲染的逼真模型

Result: 实验和消融研究表明，该方法设计选择对实现最先进质量至关重要，能够生成交互式3D底盘模型，支持旋转、缩放和切片操作，在几秒内检测锈蚀、泄漏或碰撞损伤

Conclusion: 提出的端到端管道显著改善了车辆底盘检查的工作场所安全和买家信心，通过专门的SfM方法克服了广角镜头畸变和低视差场景的挑战

Abstract: Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.

</details>


### [485] [FourierPET: Deep Fourier-based Unrolled Network for Low-count PET Reconstruction](https://arxiv.org/abs/2601.11680)
*Zheng Zhang,Hao Tang,Yingying Hu,Zhanli Hu,Jing Qin*

Main category: eess.IV

Relevance: 15.0

TL;DR: FourierPET：一种基于傅里叶域的PET重建框架，通过频谱分析分离不同退化效应，实现高效低参数重建。


<details>
  <summary>Details</summary>
Motivation: 低计数PET重建面临泊松噪声、光子稀缺和衰减校正误差等多重退化问题。现有深度学习方法通常在空间域处理，难以分离重叠伪影，校正效果有限。

Method: 提出FourierPET框架，基于傅里叶域分析发现退化效应在频谱上可分离：泊松噪声和光子稀缺导致高频相位扰动，衰减误差抑制低频幅度分量。采用ADMM展开式重建框架，包含三个模块：频谱一致性模块（全局频率对齐）、幅度-相位校正模块（解耦校正）、双重调整模块（加速收敛）。

Result: 实验表明FourierPET在显著减少参数数量的情况下达到最先进性能，同时通过频率感知校正提供更好的可解释性。

Conclusion: 通过傅里叶域分析分离PET重建中的不同退化效应，提出的FourierPET框架在性能和可解释性方面均有显著提升。

Abstract: Low-count positron emission tomography (PET) reconstruction is a challenging inverse problem due to severe degradations arising from Poisson noise, photon scarcity, and attenuation correction errors. Existing deep learning methods typically address these in the spatial domain with an undifferentiated optimization objective, making it difficult to disentangle overlapping artifacts and limiting correction effectiveness. In this work, we perform a Fourier-domain analysis and reveal that these degradations are spectrally separable: Poisson noise and photon scarcity cause high-frequency phase perturbations, while attenuation errors suppress low-frequency amplitude components. Leveraging this insight, we propose FourierPET, a Fourier-based unrolled reconstruction framework grounded in the Alternating Direction Method of Multipliers. It consists of three tailored modules: a spectral consistency module that enforces global frequency alignment to maintain data fidelity, an amplitude-phase correction module that decouples and compensates for high-frequency phase distortions and low-frequency amplitude suppression, and a dual adjustment module that accelerates convergence during iterative reconstruction. Extensive experiments demonstrate that FourierPET achieves state-of-the-art performance with significantly fewer parameters, while offering enhanced interpretability through frequency-aware correction.

</details>


### [486] [A Constraint Programming Model for the Super-Agile Earth Observation Satellite Imaging Scheduling Problem](https://arxiv.org/abs/2601.11967)
*Margarida Caleiras,Samuel Moniz,Paulo Jorge Nascimento*

Main category: eess.SY

Relevance: 15.0

TL;DR: 本文提出了首个用于超敏捷地球观测卫星成像调度问题的精确约束规划模型，考虑了灵活的观测窗口、多指向方向和序列依赖的转移时间。


<details>
  <summary>Details</summary>
Motivation: 随着卫星成像依赖度增加，新一代超敏捷地球观测卫星提供了前所未有的成像灵活性，但其高度动态能力给观测任务调度带来了新挑战。现有传统敏捷卫星调度方法无法处理可变观测时长和多成像方向问题，且目前尚无精确方法解决SAEOS成像调度问题。

Method: 提出了首个精确的约束规划模型，考虑了灵活的观测窗口、多指向方向和序列依赖的转移时间，并在多卫星环境下进行建模。通过新生成的基准测试集进行实验验证。

Result: 计算实验表明，该模型能够在非常短的计算时间内高效求解。与当前最先进的非精确方法相比，该方法具有更高的计算性能潜力。

Conclusion: 本研究填补了SAEOS成像调度问题精确方法的空白，提出的约束规划模型能够高效解决这一复杂调度问题，为实际卫星任务调度提供了有效工具。

Abstract: As the dependence on satellite imaging continues to grow, modern satellites have become increasingly agile, with the new generation, namely super-agile Earth observation satellites (SAEOS), providing unprecedented imaging flexibility. The highly dynamic capabilities of these satellites introduce additional challenges to the scheduling of observation tasks, as existing approaches for conventional agile satellites do not account for variable observation durations and multiple imaging directions. Although some efforts have been made in this regard, the SAEOS imaging scheduling problem (SAEOS-ISP) remains largely unexplored, and no exact approaches have yet been proposed. In this context, this study presents the first exact Constraint Programming formulation for the SAEOS-ISP, considering flexible observation windows, multiple pointing directions and sequence-dependent transition times across multiple satellites. Computational experiments on a newly generated benchmark set demonstrate that the model can be solved efficiently and within very short computational times. Moreover, the results also show that the proposed approach has the potential to achieve higher computational performance compared to the non-exact approaches that are currently considered state-of-the-art.

</details>


### [487] [Multimodal Feedback for Handheld Tool Guidance: Combining Wrist-Based Haptics with Augmented Reality](https://arxiv.org/abs/2601.12037)
*Yue Yang,Christoph Leuze,Brian Hargreaves,Bruce Daniel,Fred M Baik*

Main category: cs.HC

Relevance: 15.0

TL;DR: 该研究探索了在光学透视增强现实(AR)中，通过腕部振动触觉反馈来增强手持工具空间引导的效果。研究发现AR与触觉结合能显著提高空间精度和可用性。


<details>
  <summary>Details</summary>
Motivation: 在AR辅助手术中，视觉遮挡、光照条件和界面模糊性会影响操作精度和信心。需要多模态系统来克服这些挑战，提高手术引导的精确性和可靠性。

Method: 设计了结合AR视觉和定制腕戴式触觉设备的多模态系统，提供方向和状态提示。通过形成性研究确定关键工具操作和参考映射，进行提示识别实验和引导任务实验。

Result: 在引导任务中，同时使用AR和触觉的参与者实现了显著更高的空间精度(5.8毫米)和可用性(SUS=88.1)，尽管任务时间略有增加。参与者报告触觉提示提供了确认感并减少了认知负担。

Conclusion: 腕部触觉与AR系统的整合对于高精度、视觉复杂任务(如手术引导)具有重要前景，多模态界面能支持更自信、高效的工具操作。

Abstract: We investigate how vibrotactile wrist feedback can enhance spatial guidance for handheld tool movement in optical see-through augmented reality (AR). While AR overlays are widely used to support surgical tasks, visual occlusion, lighting conditions, and interface ambiguity can compromise precision and confidence. To address these challenges, we designed a multimodal system combining AR visuals with a custom wrist-worn haptic device delivering directional and state-based cues. A formative study with experienced surgeons and residents identified key tool maneuvers and preferences for reference mappings, guiding our cue design. In a cue identification experiment (N=21), participants accurately recognized five vibration patterns under visual load, with higher recognition for full-actuator states than spatial direction cues. In a guidance task (N=27), participants using both AR and haptics achieved significantly higher spatial precision (5.8 mm) and usability (SUS = 88.1) than those using either modality alone, despite having modest increases in task time. Participants reported that haptic cues provided reassuring confirmation and reduced cognitive effort during alignment. Our results highlight the promise of integrating wrist-based haptics into AR systems for high-precision, visually complex tasks such as surgical guidance. We discuss design implications for multimodal interfaces supporting confident, efficient tool manipulation.

</details>


### [488] [Breaking Coordinate Overfitting: Geometry-Aware WiFi Sensing for Cross-Layout 3D Pose Estimation](https://arxiv.org/abs/2601.12252)
*Songming Jia,Yan Lu,Bin Liu,Xiang Zhang,Peng Zhao,Xinmeng Tang,Yelin Wei,Jinyang Huang,Huan Yan,Zhi Liu*

Main category: cs.HC

Relevance: 15.0

TL;DR: PerceptAlign提出首个几何条件化WiFi跨布局3D人体姿态估计框架，通过坐标统一和几何感知特征融合，解决现有方法因坐标过拟合导致的泛化失败问题。


<details>
  <summary>Details</summary>
Motivation: 现有WiFi姿态估计方法依赖视觉3D姿态作为监督，直接将CSI回归到相机坐标系，导致坐标过拟合问题：模型记忆特定部署的WiFi收发器布局而非学习活动相关表示，造成严重泛化失败。

Method: 提出几何条件化框架PerceptAlign：1) 轻量级坐标统一程序，使用两个棋盘格和少量照片将WiFi和视觉测量对齐到共享3D空间；2) 将校准的收发器位置编码为高维嵌入，与CSI特征融合，使模型将设备几何作为条件变量；3) 强制网络解耦人体运动和部署布局。

Result: 构建了迄今最大的跨域3D WiFi姿态估计数据集（21个主体、5个场景、18个动作、7种设备布局）。实验显示，PerceptAlign将域内误差降低12.3%，跨域误差降低超过60%，优于现有最佳基线。

Conclusion: 几何条件化学习是实现可扩展和实用WiFi感知的可行路径，首次实现了布局不变的WiFi姿态估计。

Abstract: WiFi-based 3D human pose estimation offers a low-cost and privacy-preserving alternative to vision-based systems for smart interaction. However, existing approaches rely on visual 3D poses as supervision and directly regress CSI to a camera-based coordinate system. We find that this practice leads to coordinate overfitting: models memorize deployment-specific WiFi transceiver layouts rather than only learning activity-relevant representations, resulting in severe generalization failures. To address this challenge, we present PerceptAlign, the first geometry-conditioned framework for WiFi-based cross-layout pose estimation. PerceptAlign introduces a lightweight coordinate unification procedure that aligns WiFi and vision measurements in a shared 3D space using only two checkerboards and a few photos. Within this unified space, it encodes calibrated transceiver positions into high-dimensional embeddings and fuses them with CSI features, making the model explicitly aware of device geometry as a conditional variable. This design forces the network to disentangle human motion from deployment layouts, enabling robust and, for the first time, layout-invariant WiFi pose estimation. To support systematic evaluation, we construct the largest cross-domain 3D WiFi pose estimation dataset to date, comprising 21 subjects, 5 scenes, 18 actions, and 7 device layouts. Experiments show that PerceptAlign reduces in-domain error by 12.3% and cross-domain error by more than 60% compared to state-of-the-art baselines. These results establish geometry-conditioned learning as a viable path toward scalable and practical WiFi sensing.

</details>


### [489] [Accurate Simulation Pipeline for Passive Single-Photon Imaging](https://arxiv.org/abs/2601.12850)
*Aleksi Suonsivu,Lauri Salmela,Leevi Uosukainen,Edoardo Peretti,Radu Ciprian Bilcu,Giacomo Boracchi*

Main category: physics.ins-det

Relevance: 15.0

TL;DR: 提出了一个全面的SPAD（单光子雪崩二极管）传感器仿真管道，并创建了SPAD-MNIST数据集，用于在极低光照条件下（如5 mlux）研究CNN分类器在重建光通量上的有效性。


<details>
  <summary>Details</summary>
Motivation: SPAD传感器价格昂贵且供应有限，缺乏真实数据集阻碍了SPAD特定处理算法的发展和学习型解决方案的训练，因此需要准确的仿真管道来生成合成数据。

Method: 开发了全面的SPAD仿真管道，使用两个商用SPAD传感器进行验证，生成了SPAD-MNIST数据集（MNIST的单光子版本），并在不同光照条件下评估了仅使用仿真数据训练的CNN分类器在真实SPAD图像上的性能。

Result: 仿真管道得到验证，SPAD-MNIST数据集可用于研究极低光照条件下的分类性能，合成数据集涵盖了不同的SPAD成像模式并可供下载。

Conclusion: 提出的SPAD仿真管道和SPAD-MNIST数据集为SPAD成像算法的开发和评估提供了有价值的工具，特别是在真实数据稀缺的情况下。

Abstract: Single-Photon Avalanche Diodes (SPADs) are new and promising imaging sensors. These sensors are sensitive enough to detect individual photons hitting each pixel, with extreme temporal resolution and without readout noise. Thus, SPADs stand out as an optimal choice for low-light imaging. Due to the high price and limited availability of SPAD sensors, the demand for an accurate data simulation pipeline is substantial. Indeed, the scarcity of SPAD datasets hinders the development of SPAD-specific processing algorithms and impedes the training of learning-based solutions.
  In this paper, we present a comprehensive SPAD simulation pipeline and validate it with multiple experiments using two recent commercial SPAD sensors. Our simulator is used to generate the SPAD-MNIST, a single-photon version of the seminal MNIST dataset, to investigate the effectiveness of convolutional neural network (CNN) classifiers on reconstructed fluxes, even at extremely low light conditions, e.g., 5 mlux. We also assess the performance of classifiers exclusively trained on simulated data on real images acquired from SPAD sensors at different light conditions. The synthetic dataset encompasses different SPAD imaging modalities and is made available for download. Project page: https://boracchi.faculty.polimi.it/Projects/SPAD-MNIST.html.

</details>


### [490] [Deep Feature Deformation Weights](https://arxiv.org/abs/2601.12527)
*Richard Liu,Itai Lang,Rana Hanocka*

Main category: cs.CV

Relevance: 10.0

TL;DR: 该论文提出了一种结合传统网格变形精确控制与数据驱动语义编辑的方法，通过深度特征邻近性生成平滑语义的变形权重，实现了实时高分辨率网格变形。


<details>
  <summary>Details</summary>
Motivation: 传统基于手柄的网格变形方法需要用户预先知道手柄的理想分布，且手柄到变形行为的映射不直观、非语义；而现代数据驱动方法虽然能获得语义编辑，但速度慢且不精确。需要融合两者的优势。

Method: 提出使用深度特征邻近性生成平滑语义的变形权重，无需额外正则化；引入改进的特征蒸馏管道——重心特征蒸馏，利用形状渲染的视觉信号最小化蒸馏成本；通过特征空间约束和局部性加权保留经典方法特性；利用场表示自动检测语义对称性。

Result: 方法能在消费者级机器上实时处理高达100万面的网格变形，权重计算时间从传统和神经方法的数小时缩短到一分钟内，实现了语义部分的协同变形和对称保持变形。

Conclusion: 成功融合了数据驱动的语义先验与传统框架的精确控制和速度，提供了一种简单有效的实时高分辨率网格变形解决方案。

Abstract: Handle-based mesh deformation has been a long-standing paradigm in computer graphics, enabling intuitive shape edits from sparse controls. Classic techniques offer precise and rapid deformation control. However, they solve an optimization problem with constraints defined by control handle placement, requiring a user to know apriori the ideal distribution of handles on the shape to accomplish the desired edit. The mapping from handle set to deformation behavior is often unintuitive and, importantly, non-semantic. Modern data-driven methods, on the other hand, leverage a data prior to obtain semantic edits, but are slow and imprecise. We propose a technique that fuses the semantic prior of data with the precise control and speed of traditional frameworks. Our approach is surprisingly simple yet effective: deep feature proximity makes for smooth and semantic deformation weights, with no need for additional regularization. The weights can be computed in real-time for any surface point, whereas prior methods require optimization for new handles. Moreover, the semantic prior from deep features enables co-deformation of semantic parts. We introduce an improved feature distillation pipeline, barycentric feature distillation, which efficiently uses the visual signal from shape renders to minimize distillation cost. This allows our weights to be computed for high resolution meshes in under a minute, in contrast to potentially hours for both classical and neural methods. We preserve and extend properties of classical methods through feature space constraints and locality weighting. Our field representation allows for automatic detection of semantic symmetries, which we use to produce symmetry-preserving deformations. We show a proof-of-concept application which can produce deformations for meshes up to 1 million faces in real-time on a consumer-grade machine.

</details>


### [491] [Conformal Point and the Calibrated Conic](https://arxiv.org/abs/2601.11679)
*Richard Hartley*

Main category: cs.CV

Relevance: 5.0

TL;DR: 论文介绍了共形点和校准圆锥的概念及其相互关系，这些概念有助于可视化图像几何，并提供计算图像中角度和方向等几何属性的直观方法。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发更直观的几何计算工具，特别是在图像处理领域。通过引入共形点和校准圆锥的概念，研究者希望为图像几何提供更好的可视化方法，使角度和方向等几何属性的计算更加直观和易于理解。

Method: 论文提出了共形点和校准圆锥的数学概念，并建立了它们之间的相互关系。这些概念基于几何原理，用于描述和计算图像中的几何属性。方法包括对这些几何概念的数学定义、性质分析以及在图像几何中的应用。

Result: 研究结果表明，共形点和校准圆锥的概念能够有效地可视化图像几何，并为计算图像中的角度和方向等几何属性提供了直观的方法。这些工具简化了几何计算过程，使其更加易于理解和应用。

Conclusion: 共形点和校准圆锥是理解图像几何的有用工具，它们提供了直观的可视化方法，并简化了几何计算。这些概念在计算机视觉和图像处理领域具有潜在的应用价值。

Abstract: This gives some information about the conformal point and the calibrating conic, and their relationship one to the other. These concepts are useful for visualizing image geometry, and lead to intuitive ways to compute geometry, such as angles and directions in an image.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [492] [Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart](https://arxiv.org/abs/2601.11940)
*Kang Chen,Fan Yu,Junjie Nian,Shihan Zhao,Zhuoka Feng,Zijun Yao,Heng Wang,Minshen Yu,Yixin Cao*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出TAAR框架，通过训练诊断策略识别思维陷阱，在推理时截断错误轨迹并自适应重启解码，提升大语言模型的推理性能


<details>
  <summary>Details</summary>
Motivation: 长思维链（Long-CoT）通过增加测试时计算来增强推理能力，但扩展生成不能保证正确性：模型在早期做出错误承诺后，可能会继续阐述一个自洽但不正确的前缀。研究发现89%的失败案例存在"思维陷阱"——前缀主导的死锁状态，后续反思、替代尝试或验证都无法修正根错误。

Method: 提出TAAR（Trap-Aware Adaptive Restart）框架：1）训练诊断策略从部分轨迹中预测两个信号：陷阱索引（指示截断位置）和逃脱概率（指示干预强度）；2）推理时截断预测的陷阱段前轨迹并自适应重启解码；3）对于严重陷阱情况，应用更强的扰动，包括更高温度重采样和可选的结构化重启后缀。

Result: 在具有挑战性的数学和科学推理基准（AIME24、AIME25、GPQA-Diamond、HMMT25、BRUMO25）上，TAAR在不微调基础模型参数的情况下提高了推理性能。

Conclusion: TAAR框架有效解决了长思维链中的思维陷阱问题，通过自适应重启机制提升了大语言模型的推理可靠性，为测试时计算优化提供了新方向。

Abstract: Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.

</details>


### [493] [Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models](https://arxiv.org/abs/2601.11622)
*Hassan Ugail,Newton Howard*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文将神经科学中的时间整合和亚稳态概念应用于Transformer模型，提出了一种复合动力学指标来分析LLM文本生成过程中的内部动态组织，发现在结构化推理任务中该指标显著高于重复、噪声和扰动条件。


<details>
  <summary>Details</summary>
Motivation: 当前LLM解释性研究主要关注静态表示或因果干预，忽视了内部动态的时间组织。受神经科学中时间整合和亚稳态概念的启发，作者希望开发能够表征LLM不同功能状态下计算组织差异的动力学指标。

Method: 从神经科学中借鉴时间整合和亚稳态概念，构建复合动力学指标，基于自回归生成过程中的激活时间序列计算。在GPT-2-medium模型上评估五个条件：结构化推理、强制重复、高温噪声采样、注意力头剪枝和权重噪声注入。

Result: 结构化推理条件相比重复、噪声和扰动条件表现出显著更高的动力学指标，通过单因素方差分析确认统计显著性，关键比较中效应量大。结果对层选择、通道子采样和随机种子具有鲁棒性。

Conclusion: 神经科学启发的动力学指标能够可靠地表征大语言模型中不同功能状态下的计算组织差异。该指标捕获形式动力学特性，不暗示主观体验。

Abstract: Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.

</details>


### [494] [Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance](https://arxiv.org/abs/2601.11625)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文提出了一种训练时解释性方法，通过跟踪微调过程中token级归因的变化来监控模型决策证据的演变，定义了"解释漂移"和"推理稳定点"的概念。


<details>
  <summary>Details</summary>
Motivation: 微调预训练语言模型可能会微妙地改变模型所依赖的证据，需要一种方法来监控微调过程中决策证据的演变，特别是在模型可能依赖捷径特征的情况下。

Method: 提出训练时解释性视角，跟踪微调过程中token级归因的变化。定义解释漂移（epoch间归一化token归因的变化）和推理稳定点（漂移首次持续保持低水平的epoch）。该方法仅需运行内漂移动态，无需在分布外数据上调整。

Result: 在多个轻量级Transformer分类器和基准分类任务中，漂移通常在训练早期就进入低稳定状态，而验证精度仅发生微小变化。在受控的捷径设置中，归因动态揭示了模型对捷径的依赖增加，即使验证精度保持竞争力。

Conclusion: 解释漂移提供了一种简单、低成本的诊断工具，用于监控微调过程中决策证据的演变，并选择处于稳定证据状态的检查点。

Abstract: Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.

</details>


### [495] [Harmonizing the Arabic Audio Space with Data Scheduling](https://arxiv.org/abs/2601.12494)
*Hunzalah Hassan Bhatti,Firoj Alam,Shammur Absar Chowdhury*

Main category: cs.SD

Relevance: 85.0

TL;DR: 本文系统研究了阿拉伯语中心音频大语言模型的多任务指令微调，提出任务渐进课程学习(TPC)和对齐器多样性采样(ADS)策略，发现两者结合能实现最优训练效果。


<details>
  <summary>Details</summary>
Motivation: 音频大语言模型在统一语音理解和生成方面表现出色，但在语言复杂、方言丰富的环境中的适应能力尚未充分探索。本文旨在研究阿拉伯语中心音频LLM在多任务指令微调中的表现。

Method: 1) 引入AraMega-SSum阿拉伯语语音摘要数据集；2) 微调Qwen2.5-Omni (7B)模型；3) 提出任务渐进课程学习(TPC)策略；4) 提出对齐器多样性采样(ADS)策略构建信息密集批次；5) 探索混合TPC+ADS策略。

Result: 发现效率与鲁棒性的关键权衡：ADS加速初始收敛并提升副语言F1分数，但其梯度波动性在长时间训练下会破坏生成解码稳定性；TPC稳定核心声学映射，但常在下游任务中引发负迁移；混合TPC+ADS策略提供最优训练方案。

Conclusion: 混合TPC+ADS策略首先建立鲁棒表示基础，然后通过多样性感知细化捕捉细粒度差异，为复杂低资源多模态环境中Omni模型的高效适应提供实用指导。

Abstract: Audio large language models (LLMs) enable unified speech understanding and generation, yet their adaptation to linguistically complex, dialect-rich settings remains underexplored. This paper presents the first systematic study of multi-task instruction tuning for an Arabic-centric audio LLM, covering a hierarchy of generative tasks (ASR, speech summarization) and discriminative tasks (dialect and emotion identification). To support this study, we introduce AraMega-SSum, a novel dataset for Arabic speech summarization. We fine-tune Qwen2.5-Omni (7B) and propose Task-Progressive Curriculum (TPC) along with Aligner-Based Diverse Sampling (ADS), a strategy that constructs information-dense batches by selecting task- and label-balanced examples. Our results reveal a critical efficiency, robustness trade-off: while ADS accelerates initial convergence and boosts paralinguistic F1-scores, its inherent gradient volatility can destabilize generative decoding under prolonged training. Furthermore, while the TPC stabilizes core acoustic mapping, it often induces negative transfer in downstream tasks. We demonstrate that a Hybrid TPC+ADS Strategy provides an optimal training ``recipe'', first establishing a robust representative foundation before employing diversity-aware refinement to capture fine-grained nuances. These findings offer practical guidance for the efficient adaptation of Omni-models in complex, low-resource multimodal environments.

</details>


### [496] [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538)
*Tianxin Wei,Ting-Wei Li,Zhining Liu,Xuying Ning,Ze Yang,Jiaru Zou,Zhichen Zeng,Ruizhong Qiu,Xiao Lin,Dongqi Fu,Zihao Li,Mengting Ai,Duo Zhou,Wenxuan Bao,Yunzhe Li,Gaotang Li,Cheng Qian,Yu Wang,Xiangru Tang,Yin Xiao,Liri Fang,Hui Liu,Xianfeng Tang,Yuji Zhang,Chi Wang,Jiaxuan You,Heng Ji,Hanghang Tong,Jingrui He*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该综述将智能体推理组织为三个互补维度：基础智能体推理（单智能体能力）、自演化智能体推理（通过反馈和记忆优化）和集体多智能体推理（协作设置），并区分上下文推理与训练后推理方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在封闭环境中表现出强大的推理能力，但在开放和动态环境中表现不佳。智能体推理通过将LLM重构为能够持续交互的自主智能体，实现了范式转变，旨在解决LLM在开放环境中的局限性。

Method: 该综述采用三维框架组织智能体推理：1）基础智能体推理（规划、工具使用、搜索）；2）自演化智能体推理（反馈、记忆、适应）；3）集体多智能体推理（协调、知识共享、共同目标）。同时区分上下文推理（测试时结构化编排）和训练后推理（强化学习、监督微调）。

Result: 综述系统性地整理了智能体推理方法，提出了统一路线图，并回顾了在科学、机器人、医疗、自主研究和数学等领域的代表性框架和基准测试。

Conclusion: 智能体推理为连接思维与行动提供了桥梁，但仍面临个性化、长时程交互、世界建模、可扩展多智能体训练以及实际部署治理等开放挑战。

Abstract: Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.

</details>


### [497] [RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions](https://arxiv.org/abs/2601.13235)
*Drishti Goel,Jeongah Lee,Qiuyue Joy Zhong,Violeta J. Rodriguez,Daniel S. Brown,Ravi Karkar,Dong Whi Yoo,Koustuv Saha*

Main category: cs.HC

Relevance: 85.0

TL;DR: RubRIX：一个基于理论、经临床验证的框架，用于评估LLM在护理场景中的风险，包含五个风险维度，在6个SOTA LLM上测试，通过Rubric指导的优化可将风险降低45-98%。


<details>
  <summary>Details</summary>
Motivation: 现有AI评估框架主要关注通用风险（毒性、幻觉、政策违规等），无法充分捕捉LLM在护理场景中的细微风险。护理者寻求AI支持时表达复杂需求（信息寻求、情感验证、痛苦信号），需要仔细评估响应安全性和适当性。

Method: 基于"关怀伦理要素"理论，开发RubRIX框架，操作化五个经验推导的风险维度：注意力不集中、偏见与污名化、信息不准确、不加批判的肯定、认知傲慢。在Reddit和ALZConnected的20,000多个护理者查询上评估6个SOTA LLM，使用Rubric指导的优化方法。

Result: Rubric指导的优化在单次迭代后，各模型的风险组件持续减少45-98%。框架成功识别并减少了护理场景中的特定风险。

Conclusion: 这项工作为高负担场景开发领域敏感、以用户为中心的评估框架提供了方法论贡献。研究结果强调了领域敏感、交互式风险评估对于负责任部署LLM在护理支持场景中的重要性。

Abstract: Caregivers seeking AI-mediated support express complex needs -- information-seeking, emotional validation, and distress cues -- that warrant careful evaluation of response safety and appropriateness. Existing AI evaluation frameworks, primarily focused on general risks (toxicity, hallucinations, policy violations, etc), may not adequately capture the nuanced risks of LLM-responses in caregiving-contexts. We introduce RubRIX (Rubric-based Risk Index), a theory-driven, clinician-validated framework for evaluating risks in LLM caregiving responses. Grounded in the Elements of an Ethic of Care, RubRIX operationalizes five empirically-derived risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. We evaluate six state-of-the-art LLMs on over 20,000 caregiver queries from Reddit and ALZConnected. Rubric-guided refinement consistently reduced risk-components by 45-98% after one iteration across models. This work contributes a methodological approach for developing domain-sensitive, user-centered evaluation frameworks for high-burden contexts. Our findings highlight the importance of domain-sensitive, interactional risk evaluation for the responsible deployment of LLMs in caregiving support contexts. We release benchmark datasets to enable future research on contextual risk evaluation in AI-mediated support.

</details>


### [498] [KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?](https://arxiv.org/abs/2601.13240)
*Xue Jiang,Jiaru Qian,Xianjie Shi,Chenjie Li,Hao Zhu,Ziyu Wang,Jielun Zhang,Zheyu Zhao,Kechi Zhang,Jia Li,Wenpin Jiao,Zhi Jin,Ge Li,Yihong Dong*

Main category: cs.SE

Relevance: 85.0

TL;DR: KOCO-BENCH是一个针对领域专业化方法的代码基准测试，包含6个新兴领域、11个软件框架和25个项目，提供知识语料库和多粒度评估任务，旨在评估LLMs如何获取和应用新领域知识。


<details>
  <summary>Details</summary>
Motivation: 现有领域特定代码基准测试无法评估领域专业化方法的有效性，它们主要关注LLMs已具备什么知识，而非如何获取和应用新知识，且缺乏明确的开发知识语料库。

Method: 构建包含6个新兴领域、11个软件框架和25个项目的基准测试，提供精心策划的知识语料库，包含多粒度评估任务：领域代码生成（从函数级到项目级，带严格测试套件）和领域知识理解（通过多项选择问答）。

Result: 评估显示KOCO-BENCH对最先进的LLMs构成重大挑战，即使应用领域专业化方法（如SFT、RAG、kNN-LM），改进仍然有限。最佳性能的编码代理Claude Code仅达到34.2%。

Conclusion: 该基准测试揭示了当前LLMs在获取和应用领域知识方面的局限性，迫切需要更有效的领域专业化方法。

Abstract: Large language models (LLMs) excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. However, existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To this end, we present KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development. KOCO-BENCH contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation (from function-level to project-level with rigorous test suites) and domain knowledge understanding (via multiple-choice Q&A). Unlike previous benchmarks that only provide test sets for direct evaluation, KOCO-BENCH requires acquiring and applying diverse domain knowledge (APIs, rules, constraints, etc.) from knowledge corpora to solve evaluation tasks. Our evaluations reveal that KOCO-BENCH poses significant challenges to state-of-the-art LLMs. Even with domain specialization methods (e.g., SFT, RAG, kNN-LM) applied, improvements remain marginal. Best-performing coding agent, Claude Code, achieves only 34.2%, highlighting the urgent need for more effective domain specialization methods. We release KOCO-BENCH, evaluation code, and baselines to advance further research at https://github.com/jiangxxxue/KOCO-bench.

</details>


### [499] [CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning](https://arxiv.org/abs/2601.13262)
*Eric Onyame,Akash Ghosh,Subhadip Baidya,Sriparna Saha,Xiuying Chen,Chirag Agarwal*

Main category: cs.AI

Relevance: 85.0

TL;DR: CURE-MED提出一个课程强化学习框架，通过代码切换感知的监督微调和组相对策略优化，提升LLM在多语言医疗推理中的逻辑正确性和语言稳定性，在13种语言上显著超越基线。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在单语言数学和常识推理上表现良好，但在多语言医疗推理应用中仍不可靠，阻碍了在多语言医疗环境中的部署。需要解决LLM在多语言医疗推理中的可靠性问题。

Method: 1) 引入CUREMED-BENCH高质量多语言医疗推理数据集，包含13种语言（包括阿姆哈拉语、约鲁巴语、斯瓦希里语等资源不足语言）；2) 提出CURE-MED课程强化学习框架，整合代码切换感知的监督微调和组相对策略优化，共同提升逻辑正确性和语言稳定性。

Result: 在13种语言上一致超越强基线，7B参数模型达到85.21%语言一致性和54.35%逻辑正确性，32B参数模型达到94.96%语言一致性和70.04%逻辑正确性，有效扩展。

Conclusion: 该方法支持LLM实现可靠和公平的多语言医疗推理，为多语言医疗环境中的LLM部署提供了解决方案。

Abstract: While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/

</details>


### [500] [LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning](https://arxiv.org/abs/2601.11905)
*Junyu Cao,Ruijiang Gao,Esmaeil Keyvanshokooh,Jianhao Ma*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出一个结合算法追索、上下文赌博机和LLM的统一框架，用于高风险顺序决策（如个性化医疗）。开发了GLRB算法和LIBRA算法，后者将LLM领域知识与赌博机统计严谨性结合，提供三个理论保证。


<details>
  <summary>Details</summary>
Motivation: 在高风险顺序决策场景（如个性化医疗）中，需要同时选择治疗行动和可行的患者特征修改。现有方法缺乏将算法追索、上下文赌博机和LLM知识有效结合的框架。

Method: 1. 提出追索赌博机问题，决策者需同时选择治疗行动和可变的患者特征修改；2. 开发GLRB算法；3. 提出LIBRA算法，策略性地结合LLM领域知识和赌博机学习统计严谨性。

Result: LIBRA提供三个理论保证：热启动保证（LLM推荐接近最优时显著减少初始遗憾）、LLM努力保证（仅咨询LLM O(log²T)次）、鲁棒性保证（即使LLM不可靠也不差于纯赌博机算法）。实验显示GLRB和LIBRA在遗憾、治疗质量和样本效率上优于基准方法。

Conclusion: 该框架展示了追索感知、LLM辅助的赌博机算法在高风险个性化决策中的潜力，为可信的LLM-赌博机协作提供了理论基础和实用算法。

Abstract: We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.

</details>


### [501] [Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs](https://arxiv.org/abs/2601.13528)
*Jackson Kaunismaa,Avery Griffin,John Hughes,Christina Q. Knight,Mrinank Sharma,Erik Jones*

Main category: cs.CR

Relevance: 85.0

TL;DR: 论文提出了一种通过"诱导攻击"绕过前沿模型安全防护的方法，利用无害提示获取响应，然后微调开源模型来恢复有害能力，在危险化学品合成领域恢复了约40%的能力差距。


<details>
  <summary>Details</summary>
Motivation: 模型开发者通常在前沿模型中实施安全防护措施（如分类器过滤危险输出），但本文发现即使有强大防护的模型也可能被用来诱导开源模型获得有害能力，这揭示了仅靠输出级防护难以缓解生态系统层面的风险。

Method: 提出三阶段诱导攻击方法：1) 在目标有害任务的相邻领域构建不直接请求危险信息的提示；2) 从有防护的前沿模型获取这些提示的响应；3) 使用这些提示-响应对微调开源模型。由于初始提示不直接请求危险信息，不会被前沿模型的安全防护拒绝。

Result: 在危险化学品合成和处理领域评估，诱导攻击能够恢复开源模型与无限制前沿模型之间约40%的能力差距。攻击效果随前沿模型能力和生成的微调数据量增加而提升。

Conclusion: 仅依靠输出级安全防护难以缓解生态系统层面的风险，因为攻击者可以通过诱导攻击间接获取有害能力。这突显了需要更全面的安全防护方法。

Abstract: Model developers implement safeguards in frontier models to prevent misuse, for example, by employing classifiers to filter dangerous outputs. In this work, we demonstrate that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. Our elicitation attacks consist of three stages: (i) constructing prompts in adjacent domains to a target harmful task that do not request dangerous information; (ii) obtaining responses to these prompts from safeguarded frontier models; (iii) fine-tuning open-source models on these prompt-output pairs. Since the requested prompts cannot be used to directly cause harm, they are not refused by frontier model safeguards. We evaluate these elicitation attacks within the domain of hazardous chemical synthesis and processing, and demonstrate that our attacks recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. We then show that the efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. Our work demonstrates the challenge of mitigating ecosystem level risks with output-level safeguards.

</details>


### [502] [Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion](https://arxiv.org/abs/2601.11979)
*Ang Gao,Changshuo Zhang,Xiao Zhang,Deyang Li,Minjun Zhao,Fangchao Liu,Xinyu Zhang*

Main category: cs.AI

Relevance: 85.0

TL;DR: PICL是一种动态演示集成框架，通过实时识别推理过程中的困惑点并插入相关演示来增强数学推理能力，相比静态演示方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习（ICL）方法在数学推理等需要逐步逻辑推导的任务中存在局限，主要问题是演示示例在推理前预先选定且固定不变，无法适应推理过程中出现的动态困惑点（如模糊计算、逻辑漏洞），这些未解决的困惑点会导致级联错误，降低最终准确性。

Method: PICL采用两阶段框架：1）通过分析推理过程中的语义和熵来识别潜在困惑点并总结其核心特征；2）在遇到这些困惑点时，从演示池中检索与困惑上下文匹配的相关演示，并将其直接插入到正在进行的推理过程中以指导后续步骤。

Result: 实验表明PICL优于基线方法，通过缓解推理过程中的困惑点，证明了自适应演示插入在复杂数学推理中的价值。

Conclusion: 动态演示集成框架PICL能够有效提升数学推理任务的性能，表明适应推理过程中实时需求的上下文学习方法比静态演示方法更有效。

Abstract: In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.

</details>


### [503] [DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems](https://arxiv.org/abs/2601.13591)
*Maojun Sun,Yifei Xie,Yue Wu,Ruijian Han,Binyan Jiang,Defeng Sun,Yancheng Yuan,Jian Huang*

Main category: cs.AI

Relevance: 85.0

TL;DR: DSAEval是一个包含641个真实世界数据科学问题的基准测试，涵盖285个多样化数据集，支持多模态环境感知、多查询交互和多维度评估，用于评估LLM数据代理的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的数据代理旨在自动化数据科学任务，但真实世界数据科学问题的开放性、跨分类和缺乏标准答案的特性使得评估变得困难，需要专门的基准测试。

Method: 提出DSAEval基准，包含641个真实世界数据科学问题，基于285个多样化数据集（结构化和非结构化数据），具有三个核心特征：多模态环境感知、多查询交互和多维度评估。

Result: 评估了11个先进的代理LLM，结果显示Claude-Sonnet-4.5整体性能最强，GPT-5.2最有效率，MiMo-V2-Flash最具成本效益。多模态感知在视觉相关任务上带来2.04%到11.30%的性能提升。

Conclusion: 当前数据科学代理在结构化数据和常规分析工作流上表现良好，但在非结构化领域仍面临重大挑战。需要进一步研究来推进数据科学代理的发展。

Abstract: Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.

</details>


### [504] [Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games](https://arxiv.org/abs/2601.13709)
*Christopher Kao,Vanshika Vats,James Davis*

Main category: cs.AI

Relevance: 85.0

TL;DR: 研究LLM在社交推理游戏《Mafia》中的欺骗能力，发现GPT-4o代理比人类更擅长通过自然语言欺骗他人


<details>
  <summary>Details</summary>
Motivation: LLM代理在应用中日益普及，但其在社交语境中的欺骗能力尚不明确。先前研究多在受控任务中测试LLM欺骗，缺乏对自然语言社交欺骗的系统性研究

Method: 使用异步多代理框架模拟35场《Mafia》游戏，GPT-4o作为代理参与。创建基于GPT-4-Turbo的Mafia检测器分析游戏记录（无角色信息）来预测黑手党玩家，以预测准确率作为欺骗质量的替代指标

Result: Mafia检测器在LLM游戏中的预测准确率低于人类游戏，表明LLM能更好地融入群体、更有效地欺骗。结果在不同游戏天数和检测到的黑手党数量上保持一致

Conclusion: LLM在社交语境中具有复杂的欺骗能力，这既展示了其语言能力的成熟度，也凸显了潜在风险。研究团队发布了LLM Mafia游戏记录数据集以支持未来研究

Abstract: Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.

</details>


### [505] [Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering](https://arxiv.org/abs/2601.13752)
*Chak Tou Leong,Dingwei Chen,Heming Xia,Qingyu Yin,Sunbowen Lee,Jian Wang,Wenjie Li*

Main category: cs.AI

Relevance: 85.0

TL;DR: RELIEF框架通过调整大推理模型的内在推理信念来塑造其行为，无需监督推理轨迹，只需基于目标信念蓝图进行微调


<details>
  <summary>Details</summary>
Motivation: 当前大推理模型存在计算冗余和推理不忠实问题，现有方法依赖强化学习或黄金推理轨迹微调，计算成本高且难以扩展。研究发现模型具有内在的推理信念，可以用于行为塑造。

Method: 提出RELIEF框架：1）通过logit探测捕捉模型的推理信念；2）创建目标信念蓝图；3）生成自我反思的问答对来确认目标信念；4）微调模型使其自我概念与目标信念对齐

Result: 在效率和忠实性任务上，RELIEF匹配或超越了基于行为监督和偏好的基线方法，同时训练成本更低。分析验证了调整推理信念能有效塑造实际行为。

Conclusion: RELIEF提供了一种简单有效的框架，通过调整模型的自我概念来塑造大推理模型的行为，无需昂贵的推理轨迹监督，具有更好的可扩展性。

Abstract: Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.

</details>


### [506] [DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution](https://arxiv.org/abs/2601.13761)
*Shengda Fan,Xuyan Ye,Yankai Lin*

Main category: cs.AI

Relevance: 85.0

TL;DR: DARC是一个两阶段自演化解耦框架，通过难度校准的问题生成和非对称自蒸馏机制，稳定大型语言模型的自对弈训练过程。


<details>
  <summary>Details</summary>
Motivation: 现有自对弈框架存在优化不稳定问题：1) 提问者依赖求解器反馈的非平稳目标；2) 使用自生成伪标签训练求解器时的自举误差。需要稳定自演化过程。

Method: 两阶段框架：第一阶段训练提问者基于显式难度级别和外部语料合成难度校准的问题；第二阶段使用非对称自蒸馏机制训练求解器，文档增强的教师生成高质量伪标签来监督无文档访问的学生求解器。

Result: DARC具有模型无关性，在9个推理基准和3个骨干模型上平均提升10.9分，持续优于所有基线，接近完全监督模型的性能且无需人工标注。

Conclusion: DARC通过解耦和非对称设计有效稳定了LLM自对弈训练，实现了显著的推理能力提升，为自改进AI提供了实用框架。

Abstract: Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.

</details>


### [507] [A New Strategy for Artificial Intelligence: Training Foundation Models Directly on Human Brain Data](https://arxiv.org/abs/2601.12053)
*Maël Donoso*

Main category: q-bio.NC

Relevance: 85.0

TL;DR: 提出直接用人脑数据训练基础模型的新策略，以超越表面统计规律，探索通过神经影像数据获取人类深层认知知识的方法


<details>
  <summary>Details</summary>
Motivation: 当前基础模型依赖人类生成的数据（如文本），但这些数据只是人类大脑深层神经复杂性的过滤投影。作者认为神经影像数据可以打开观察人类认知不可通过行为观察到的元素的窗口，这种额外知识可以与传统训练数据结合，克服当前基础模型的局限性。

Method: 1. 将基础模型局限性和有潜力的大脑区域/认知过程分为四个层次：感知、价值评估、执行和整合；2. 提出两种方法优先使用有限的神经影像数据：基于人脑的强化学习（RLHB）和基于人脑的思维链（CoTHB）。

Result: 论文提出了理论框架和方法论，但尚未展示具体实验结果。主要贡献在于系统性地阐述了脑数据训练基础模型的理论基础、潜在应用场景和技术路径。

Conclusion: 脑训练基础模型代表了在继续扩展当前架构和探索替代性神经科学启发解决方案之间的现实有效中间路径，具有推动智能体、通用人工智能和超级人工智能发展的潜力，但也面临伦理、社会和技术挑战。

Abstract: While foundation models have achieved remarkable results across a diversity of domains, they still rely on human-generated data, such as text, as a fundamental source of knowledge. However, this data is ultimately the product of human brains, the filtered projection of a deeper neural complexity. In this paper, we explore a new strategy for artificial intelligence: moving beyond surface-level statistical regularities by training foundation models directly on human brain data. We hypothesize that neuroimaging data could open a window into elements of human cognition that are not accessible through observable actions, and argue that this additional knowledge could be used, alongside classical training data, to overcome some of the current limitations of foundation models. While previous research has demonstrated the possibility to train classical machine learning or deep learning models on neural patterns, this path remains largely unexplored for high-level cognitive functions. Here, we classify the current limitations of foundation models, as well as the promising brain regions and cognitive processes that could be leveraged to address them, along four levels: perception, valuation, execution, and integration. Then, we propose two methods that could be implemented to prioritize the use of limited neuroimaging data for strategically chosen, high-value steps in foundation model training: reinforcement learning from human brain (RLHB) and chain of thought from human brain (CoTHB). We also discuss the potential implications for agents, artificial general intelligence, and artificial superintelligence, as well as the ethical, social, and technical challenges and opportunities. We argue that brain-trained foundation models could represent a realistic and effective middle ground between continuing to scale current architectures and exploring alternative, neuroscience-inspired solutions.

</details>


### [508] [Toward Efficient Agents: Memory, Tool learning, and Planning](https://arxiv.org/abs/2601.14192)
*Xiaofang Yang,Lijun Li,Heng Zhou,Tong Zhu,Xiaoye Qu,Yuchen Fan,Qianshan Wei,Rui Ye,Li Kang,Yiran Qin,Zhiqiang Kou,Daizong Liu,Qi Li,Ning Ding,Siheng Chen,Jing Shao*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文系统综述了大型语言模型智能体系统的效率问题，从记忆、工具学习和规划三个核心组件出发，分析效率优化方法、评估指标及未来挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体系统的发展，现有研究多关注效果提升，而忽略了效率这一实际部署的关键因素。论文旨在填补这一空白，系统研究智能体系统的效率问题。

Method: 从智能体系统的三个核心组件（记忆、工具学习、规划）出发，综述近期效率优化方法，包括上下文压缩管理、工具调用最小化的RL奖励设计、受控搜索机制等。提出两种效率评估方式：固定成本下的效果比较和同等效果下的成本比较。

Result: 系统梳理了智能体效率优化的共同原则，建立了基于帕累托前沿的效率-效果权衡框架，总结了各组件评估协议和常用效率指标，为智能体系统效率研究提供了系统化视角。

Conclusion: 智能体系统效率研究是实际部署的关键，需要平衡效果与成本。论文为这一新兴领域提供了系统框架，指出了未来研究方向，包括更精细的效率优化、标准化评估基准等。

Abstract: Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.

</details>


### [509] [Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck](https://arxiv.org/abs/2601.12499)
*Meiru Zhang,Zaiqiao Meng,Nigel Collier*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文提出Multi-Focus Attention Instruction (MFAI)语义探针，揭示LLMs在多跳推理中因位置偏差导致的失败机制，发现"最弱链接定律"，并展示System-2推理模型能有效解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs拥有大规模上下文窗口，但在多跳推理任务中表现不佳，主要原因是固有的位置偏差导致模型忽略某些位置的信息。需要厘清这种失败是由于无法定位证据（识别失败）还是无法整合证据（合成失败）。

Method: 提出Multi-Focus Attention Instruction (MFAI)语义探针，通过显式引导注意力到特定位置来解耦识别和合成机制。在5个LLMs和两个多跳QA任务（MuSiQue和NeoQA）上进行实验。

Result: 发现"最弱链接定律"：多跳推理性能下降到最不可见证据的性能水平；失败由绝对位置而非事实间线性距离决定（性能方差<3%）；匹配的MFAI可解决识别瓶颈，在低可见性位置提升准确率达11.5%；System-2推理模型能有效定位和整合信息。

Conclusion: LLMs的多跳推理失败主要由位置偏差导致，识别失败是主要瓶颈；注意力引导具有双重性；System-2推理模型能有效克服位置偏差问题，在噪声长上下文环境中表现良好。

Abstract: Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the "Weakest Link Law": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that "thinking" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.

</details>


### [510] [Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition](https://arxiv.org/abs/2601.12522)
*Asif Mohammed Samir,Mohammad Masudur Rahman*

Main category: cs.SE

Relevance: 85.0

TL;DR: CogniGent是一种基于多智能体AI的bug定位技术，通过因果推理、调用图分析和上下文工程，模拟开发者的动态认知调试过程，显著提升了bug定位性能。


<details>
  <summary>Details</summary>
Motivation: 传统bug定位方法孤立分析代码组件，忽略了组件间的关联；现有LLM方法缺乏因果推理能力且难以管理增长中的上下文，限制了bug定位效果。软件bug每年造成数十亿美元损失，开发者50%时间用于bug修复。

Method: 提出CogniGent多智能体系统：1) 具备因果推理能力的AI智能体；2) 基于调用图的根因分析；3) 上下文工程；4) 模拟开发者动态认知调试实践；5) 假设检验支持bug定位。

Result: 在591个bug报告数据集上评估，相比6个基准方法，在文档和方法级别MAP提升23.33-38.57%，MRR提升25.14-53.74%，统计显著性测试确认了技术优势。

Conclusion: CogniGent通过解决推理、依赖和上下文限制，将类人认知与智能体自动化结合，推进了bug定位技术发展，为LLM在代码理解领域的应用提供了新方向。

Abstract: Software bugs cost technology providers (e.g., AT&T) billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components (e.g., methods, documents) in isolation, overlooking their connections with other components in the codebase. Recent advances in Large Language Models (LLMs) and agentic AI techniques have shown strong potential for code understanding, but still lack causal reasoning during code exploration and struggle to manage growing context effectively, limiting their capability. In this paper, we present a novel agentic technique for bug localization -- CogniGent -- that overcomes the limitations above by leveraging multiple AI agents capable of causal reasoning, call-graph-based root cause analysis and context engineering. It emulates developers-inspired debugging practices (a.k.a., dynamic cognitive debugging) and conducts hypothesis testing to support bug localization. We evaluate CogniGent on a curated dataset of 591 bug reports using three widely adopted performance metrics and compare it against six established baselines from the literature. Experimental results show that our technique consistently outperformed existing traditional and LLM-based techniques, achieving MAP improvements of 23.33-38.57% at the document and method levels. Similar gains were observed in MRR, with increases of 25.14-53.74% at both granularity levels. Statistical significance tests also confirm the superiority of our technique. By addressing the reasoning, dependency, and context limitations, CogniGent advances the state of bug localization, bridging human-like cognition with agentic automation for improved performance.

</details>


### [511] [Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts](https://arxiv.org/abs/2601.12711)
*Kevin Wang,Neel P. Bhatt,Cong Liu,Junbo Li,Runjin Chen,Yihan Xi,Timothy Barclay,Alvaro Velasquez,Ufuk Topcu,Zhangyang Wang*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出神经符号LoRA框架，动态结合数值更新（LoRA）和符号更新（TextGrad），在保持内存效率的同时提升LLM微调的适应性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM适应方法中，数值微调擅长注入新事实知识，但符号更新能灵活控制风格和对齐而无需重新训练。两者各有优势但互补，需要一种能动态结合两者的框架。

Method: 提出神经符号LoRA框架：1）统一监控信号和基于奖励的分类器，决定何时使用LoRA进行事实重构，何时使用TextGrad进行token级编辑；2）将符号转换卸载到外部LLM以保持内存效率；3）符号编辑产生的精炼提示可作为高质量可重用训练数据。

Result: 在多个LLM骨干上的实验表明，神经符号LoRA始终优于纯数值或纯符号基线，展现出更优的适应性和改进的性能，特别是在数学推理等数据稀缺领域。

Conclusion: 交错使用数值和符号更新能解锁语言模型微调的新层次多功能性，神经符号LoRA框架为LLM适应提供了更灵活高效的解决方案。

Abstract: Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.

</details>


### [512] [Actionable Interpretability Must Be Defined in Terms of Symmetries](https://arxiv.org/abs/2601.12913)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Francesco Giannini,Alberto Termine,Filippo Bonchi,Mateja Jamnik,Giuseppe Marra*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文认为当前AI可解释性研究存在根本性问题，因为现有定义缺乏可操作性。作者提出基于对称性的可操作定义，并假设四种对称性足以统一可解释性建模和推理。


<details>
  <summary>Details</summary>
Motivation: 当前AI可解释性研究缺乏可操作的定义，无法为具体建模和推理规则提供形式化原则。现有定义无法指导实际的可解释性实践，需要建立更严谨的理论基础。

Method: 提出基于对称性的可操作可解释性定义框架。假设四种对称性：(1) 动机核心可解释性属性，(2) 刻画可解释模型类别，(3) 推导统一的可解释推理形式化（如对齐、干预、反事实），作为贝叶斯逆问题的形式。

Result: 提出了一种基于对称性的可解释性理论框架，将可解释性建模和推理统一为形式化原则。该框架能够为可解释性实践提供具体指导，包括模型设计、推理方法和评估标准。

Conclusion: 可解释性研究需要基于对称性的可操作定义。四种对称性足以建立统一的可解释性理论框架，为AI系统的可解释性提供形式化基础和实践指导。

Abstract: This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.

</details>


### [513] [Reasoning is a Modality](https://arxiv.org/abs/2601.13562)
*Zhiguang Liu,Yi Shang*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文提出了一种新的角色分离Transformer块，将全局控制器token与网格工作空间token分离，用于解决ARC视觉推理任务，在ARC-1上达到62.6%准确率，超过人类平均表现。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统（如LLMs和ViTs）主要作为行为序列预测机器运行，通过建模token统计来匹配可观察行为，但没有持久、可读的思维状态。这与人类行为存在差距：人类可以通过解码内部状态来解释行为，而AI系统可以产生流利的事后合理化，但这些合理化并不基于这样的内部状态。作者假设推理是一种模态：推理应该作为一个独立的通道存在，与规则应用的低级工作空间分离。

Method: 设计了新颖的角色分离Transformer块，将全局控制器token从网格工作空间token中分离出来，实现迭代规则执行。在VARC视觉中心协议中进行训练和评估，将ARC任务作为视觉推理问题来解决。

Result: 在ARC-1上达到62.6%的准确率，超过了人类平均表现（60.2%），并显著优于先前的方法。定性分析显示，与密集ViT基线相比，模型展现出更连贯的规则应用结构，从概率斑点向控制器驱动的推理转变。

Conclusion: 通过将推理作为独立模态并分离控制器与工作空间，可以在抽象推理任务上实现超越人类的表现，这支持了推理应作为独立通道存在的假设，为构建更具解释性的AI系统提供了方向。

Abstract: The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.

</details>


### [514] [The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models](https://arxiv.org/abs/2601.13358)
*Samuel Cyrenius Anderson*

Main category: cs.AI

Relevance: 85.0

TL;DR: 研究发现模型规模并不均匀提升推理能力，而是重构推理过程。通过分析25,000+思维链轨迹，发现神经缩放定律触发领域特定的相变而非均匀能力提升，推理几何结构预测可学习性。


<details>
  <summary>Details</summary>
Motivation: 理解大规模语言模型推理能力如何随规模变化，探究规模增长是否均匀提升所有领域的推理能力，还是引发结构性变化。

Method: 分析25,000+思维链轨迹，覆盖法律、科学、代码、数学四个领域和8B、70B两个规模。使用几何分析方法（表示维度、轨迹对齐、流形解缠），引入神经推理算子学习从初始到最终隐藏状态的映射。

Result: 发现领域特异性相变：法律推理经历"结晶化"（维度降低45%，轨迹对齐增加31%，流形解缠10倍）；科学和数学推理保持"液态"；代码推理形成"晶格"结构。神经推理算子在法律推理上达到63.6%准确率。发现普遍振荡特征（相干性~-0.4）。

Conclusion: 推理成本由流形几何而非任务难度决定，为推理加速提供蓝图。规模增长重构而非均匀提升推理能力，几何结构预测可学习性。

Abstract: Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.

</details>


### [515] [Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval](https://arxiv.org/abs/2601.13969)
*Joaquín Polonuer,Lucas Vittor,Iñaki Arango,Ayush Noori,David A. Clifton,Luciano Del Corro,Marinka Zitnik*

Main category: cs.AI

Relevance: 85.0

TL;DR: ARK是一个自适应知识图谱检索器，让语言模型通过两种操作工具（全局词汇搜索和一跳邻域探索）控制检索的广度-深度权衡，无需训练即可实现多跳遍历，并通过蒸馏将轨迹知识迁移到小型模型。


<details>
  <summary>Details</summary>
Motivation: 当前知识图谱检索方法存在局限性：基于相似性的检索器覆盖广但深度浅，而基于遍历的方法依赖种子节点选择，当查询涉及多个实体和关系时容易失败。需要一种能自适应平衡广度-深度权衡的检索方法。

Method: ARK采用代理式知识图谱检索器，为语言模型提供两种操作工具：1）全局词汇搜索（用于语言密集型查询），2）一跳邻域探索（用于关系密集型查询）。模型可交替使用这两种操作进行广度发现和深度扩展，无需预设跳数或训练。还通过无标签模仿将大型教师模型的工具使用轨迹蒸馏到8B模型中。

Result: 在STaRK基准测试中，ARK达到59.1%的平均Hit@1和67.4的平均MRR，比基于检索和代理式免训练方法分别提升最多31.4%的Hit@1和28.0%的MRR。通过蒸馏到8B模型，在AMAZON、MAG和PRIME数据集上比基础8B模型分别提升+7.0、+26.6和+13.5个绝对百分点的Hit@1，同时保留教师模型高达98.5%的Hit@1率。

Conclusion: ARK通过让语言模型自适应控制检索的广度-深度权衡，有效解决了知识图谱检索中的覆盖与深度问题。其免训练设计和蒸馏能力使其既高效又可扩展到较小模型，为知识增强型语言模型提供了实用的检索解决方案。

Abstract: Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.

</details>


### [516] [Medication counseling with large language models: balancing flexibility and rigidity](https://arxiv.org/abs/2601.11544)
*Joar Sabel,Mattias Wingren,Andreas Lundell,Sören Andersson,Sara Rosenberg,Susanne Hägglund,Linda Estman,Malin Andtfolk*

Main category: cs.HC

Relevance: 75.0

TL;DR: 本文提出一个基于LLM的用药咨询系统原型，专注于狭窄但长期的任务，旨在平衡对话规范遵循与灵活性，减少幻觉并提高响应质量。


<details>
  <summary>Details</summary>
Motivation: LLM增强了软件代理的能力，但在药房等容错率低的领域，过度灵活会导致灾难性错误，而过度僵化也会因无法处理未预料情况而产生错误。现有研究多关注广泛药物和简短交互，本文反其道而行，专注于狭窄但长期的任务，以深入理解任务挑战。

Method: 设计了一个原型系统，采用多种方法：1) 平衡对话规范遵循与灵活性；2) 减少幻觉；3) 促进高质量响应；4) 增加系统确定性同时保留LLM的动态对话能力；5) 强调持续测试和人在回路；6) 建议在常用LLM基准之外评估。

Result: 提出了一个原型系统，展示了在用药咨询场景中平衡规范与灵活性的方法框架，但具体性能结果未在摘要中详细说明。

Conclusion: 在关键领域应用LLM需要平衡规范遵循与灵活性，狭窄但长期的任务能提供更深入的挑战洞察。未来工作需要持续测试、人在回路，以及超越传统LLM基准的评估方法。

Abstract: The introduction of large language models (LLMs) has greatly enhanced the capabilities of software agents. Instead of relying on rule-based interactions, agents can now interact in flexible ways akin to humans. However, this flexibility quickly becomes a problem in fields where errors can be disastrous, such as in a pharmacy context, but the opposite also holds true; a system that is too inflexible will also lead to errors, as it can become too rigid to handle situations that are not accounted for. Work using LLMs in a pharmacy context have adopted a wide scope, accounting for many different medications in brief interactions -- our strategy is the opposite: focus on a more narrow and long task. This not only enables a greater understanding of the task at hand, but also provides insight into what challenges are present in an interaction of longer nature. The main challenge, however, remains the same for a narrow and wide system: it needs to strike a balance between adherence to conversational requirements and flexibility. In an effort to strike such a balance, we present a prototype system meant to provide medication counseling while juggling these two extremes. We also cover our design in constructing such a system, with a focus on methods aiming to fulfill conversation requirements, reduce hallucinations and promote high-quality responses. The methods used have the potential to increase the determinism of the system, while simultaneously not removing the dynamic conversational abilities granted by the usage of LLMs. However, a great deal of work remains ahead, and the development of this kind of system needs to involve continuous testing and a human-in-the-loop. It should also be evaluated outside of commonly used benchmarks for LLMs, as these do not adequately capture the complexities of this kind of conversational system.

</details>


### [517] [A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation](https://arxiv.org/abs/2601.11792)
*Yifei Sun,Yongan Li,A. K. Qin,Sicheng Hou,Tamas Pflanzner*

Main category: cs.AI

Relevance: 75.0

TL;DR: 本文提出创新数学题生成任务(IMPG)，通过自演进多角色协作框架与细粒度难度指导，显著提升生成题目的创新性同时保持高正确率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在数学题生成中虽然正确率高，但缺乏创新性和区分度。为克服这一问题，作者提出创新数学题生成任务，旨在生成既正确又具有创新性的数学题目。

Method: 1) 构建包含采样器、生成器、评估器、状态机和记忆的多角色协作机制，通过自评估和外部反馈进行迭代优化；2) 引入改进的难度模型进行细粒度指导，采用DAPS算法增强采样编码的语义合理性；3) 构建HSM3K-CN数据集，采用CPT、SFT和GRPO多阶段训练流程；4) 通过蒸馏将专家模型的评估能力迁移到学徒模型，实现系统自演进。

Result: 实验表明，相比基线模型，该方法在保持高正确率的同时，显著提升了生成题目的创新性。

Conclusion: 提出的自演进多角色协作框架能有效解决创新数学题生成任务，在创新性和正确性之间取得良好平衡，为智能教育领域的数学题生成提供了新方法。

Abstract: Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided path sampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.

</details>


### [518] [Utilizing Metadata for Better Retrieval-Augmented Generation](https://arxiv.org/abs/2601.11863)
*Raquib Bin Yousuf,Shengzhe Xu,Mandar Sharma,Andrew Neeser,Chris Latimer,Naren Ramakrishnan*

Main category: cs.IR

Relevance: 75.0

TL;DR: 该论文系统研究了在结构化文档检索中集成元数据的策略，发现元数据前缀和统一嵌入方法能显著提升RAG系统的检索效果，通过增强文档内聚性和减少文档间混淆来改善检索质量。


<details>
  <summary>Details</summary>
Motivation: 在结构化、重复性强的语料库（如监管文件）中，仅基于文本相似度的检索方法难以区分语言重叠的文档。实践中常将元数据作为文本输入，但这种做法的影响和权衡缺乏系统研究。

Method: 系统比较了多种元数据感知检索策略：1) 元数据作为文本（前缀和后缀）；2) 统一嵌入（将元数据和内容融合到单一索引）；3) 双编码器后期融合检索；4) 元数据感知查询重构。在RAGMATE-10K数据集上进行了多指标评估。

Result: 元数据前缀和统一嵌入方法持续优于纯文本基线，统一嵌入有时超越前缀方法且更易维护。元数据集成通过增强文档内聚性、减少文档间混淆、扩大相关与不相关块之间的分离来提高检索效果。结构线索提供强消歧信号。

Conclusion: 在结构化文档的RAG系统中，元数据集成能显著提升检索质量。统一嵌入方法在效果和可维护性之间提供了良好平衡。元数据增强了嵌入空间的区分能力，为实际应用提供了实用指导。

Abstract: Retrieval-Augmented Generation systems depend on retrieving semantically relevant document chunks to support accurate, grounded outputs from large language models. In structured and repetitive corpora such as regulatory filings, chunk similarity alone often fails to distinguish between documents with overlapping language. Practitioners often flatten metadata into input text as a heuristic, but the impact and trade-offs of this practice remain poorly understood. We present a systematic study of metadata-aware retrieval strategies, comparing plain-text baselines with approaches that embed metadata directly. Our evaluation spans metadata-as-text (prefix and suffix), a dual-encoder unified embedding that fuses metadata and content in a single index, dual-encoder late-fusion retrieval, and metadata-aware query reformulation. Across multiple retrieval metrics and question types, we find that prefixing and unified embeddings consistently outperform plain-text baselines, with the unified at times exceeding prefixing while being easier to maintain. Beyond empirical comparisons, we analyze embedding space, showing that metadata integration improves effectiveness by increasing intra-document cohesion, reducing inter-document confusion, and widening the separation between relevant and irrelevant chunks. Field-level ablations show that structural cues provide strong disambiguating signals. Our code, evaluation framework, and the RAGMATE-10K dataset are publicly hosted.

</details>


### [519] [A Multi-Agent System for Generating Actionable Business Advice](https://arxiv.org/abs/2601.12024)
*Kartikey Singh Bhandari,Tanish Jain,Archit Agrawal,Dhruv Kumar,Praveen Kumar,Pratik Narang*

Main category: cs.AI

Relevance: 75.0

TL;DR: 提出一个基于LLM的多智能体框架，将大规模客户评论转化为可执行的商业建议，通过聚类、生成、迭代评估和可行性排序，在多个服务领域优于单模型基线。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法（如情感分析、方面提取）停留在描述性任务，而LLM生成的建议缺乏准确性和深度推理。需要将丰富的客户评论信号转化为可操作的商业建议。

Method: 多智能体LLM框架包含四个组件：1）聚类选择代表性评论；2）生成建议；3）迭代评估；4）基于可行性的排序。结合语料库蒸馏和反馈驱动的建议精炼。

Result: 在三个服务领域和多个模型系列上的实验表明，该框架在可操作性、特异性和非冗余性方面持续优于单模型基线，中等规模模型接近大型模型框架的性能。

Conclusion: 该框架成功将大规模评论语料转化为具体、可操作、实用的商业建议，为基于LLM的决策支持提供了有效方法。

Abstract: Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.

</details>


### [520] [AQUA-Bench: Beyond Finding Answers to Knowing When There Are None in Audio Question Answering](https://arxiv.org/abs/2601.12248)
*Chun-Yi Kuan,Hung-yi Lee*

Main category: eess.AS

Relevance: 75.0

TL;DR: AQUA-Bench是一个音频问答不可回答性评估基准，专门测试模型处理无法从音频中推断答案的问题的能力，包括答案缺失、选项不匹配和问题不相关三种场景。


<details>
  <summary>Details</summary>
Motivation: 现有音频问答基准主要关注可回答的问题，忽略了现实世界中常见的不可回答问题（如误导性、不恰当或与信息不兼容的问题）。这种缺失导致无法全面评估音频语言模型的可靠性。

Method: 提出AQUA-Bench基准，系统评估三种不可回答场景：1) 答案缺失检测（正确答案选项缺失）；2) 不兼容答案集检测（选项与问题类别不匹配）；3) 不兼容音频问题检测（问题与音频无关或缺乏足够依据）。

Result: 实验表明，虽然模型在标准可回答任务上表现优异，但在不可回答问题上面临显著挑战，揭示了当前音频语言理解的一个盲点。

Conclusion: AQUA-Bench为评估音频语言模型的可靠性提供了严格标准，促进了更稳健和可信赖的音频语言系统的发展，填补了现有基准的空白。

Abstract: Recent advances in audio-aware large language models have shown strong performance on audio question answering. However, existing benchmarks mainly cover answerable questions and overlook the challenge of unanswerable ones, where no reliable answer can be inferred from the audio. Such cases are common in real-world settings, where questions may be misleading, ill-posed, or incompatible with the information. To address this gap, we present AQUA-Bench, a benchmark for Audio Question Unanswerability Assessment. It systematically evaluates three scenarios: Absent Answer Detection (the correct option is missing), Incompatible Answer Set Detection (choices are categorically mismatched with the question), and Incompatible Audio Question Detection (the question is irrelevant or lacks sufficient grounding in the audio). By assessing these cases, AQUA-Bench offers a rigorous measure of model reliability and promotes the development of audio-language systems that are more robust and trustworthy. Our experiments suggest that while models excel on standard answerable tasks, they often face notable challenges with unanswerable ones, pointing to a blind spot in current audio-language understanding.

</details>


### [521] [PAIR-SAFE: A Paired-Agent Approach for Runtime Auditing and Refining AI-Mediated Mental Health Support](https://arxiv.org/abs/2601.12754)
*Jiwon Kim,Violeta J. Rodriguez,Dong Whi Yoo,Eshwar Chandrasekharan,Koustuv Saha*

Main category: cs.HC

Relevance: 75.0

TL;DR: PAIR-SAFE：一个用于AI心理健康支持的配对代理框架，通过临床验证的MITI-4框架进行监督，提高响应的临床对齐性和质量。


<details>
  <summary>Details</summary>
Motivation: LLMs在心理健康支持中可能产生过于指令性、不一致或临床不对齐的响应，特别是在敏感或高风险情境下。现有方法主要依赖训练或提示的隐式对齐，缺乏透明度和运行时问责。

Method: 提出PAIR-SAFE配对代理框架：Responder代理生成响应，Judge代理基于MITI-4临床框架进行审计，提供ALLOW或REVISE的结构化决策来指导运行时响应优化。使用人类标注的动机性访谈数据构建的支持寻求者模拟器进行咨询交互模拟。

Result: Judge监督的交互在MITI关键维度（包括伙伴关系、寻求合作和整体关系质量）上显示出显著改善。定量结果得到定性专家评估支持，突出了运行时监督的细微差别。

Conclusion: 配对代理方法能够为AI辅助的对话式心理健康支持提供基于临床基础的审计和优化，提高响应的临床对齐性和质量。

Abstract: Large language models (LLMs) are increasingly used for mental health support, yet they can produce responses that are overly directive, inconsistent, or clinically misaligned, particularly in sensitive or high-risk contexts. Existing approaches to mitigating these risks largely rely on implicit alignment through training or prompting, offering limited transparency and runtime accountability. We introduce PAIR-SAFE, a paired-agent framework for auditing and refining AI-generated mental health support that integrates a Responder agent with a supervisory Judge agent grounded in the clinically validated Motivational Interviewing Treatment Integrity (MITI-4) framework. The Judgeaudits each response and provides structuredALLOW or REVISE decisions that guide runtime response refinement. We simulate counseling interactions using a support-seeker simulator derived from human-annotated motivational interviewing data. We find that Judge-supervised interactions show significant improvements in key MITI dimensions, including Partnership, Seek Collaboration, and overall Relational quality. Our quantitative findings are supported by qualitative expert evaluation, which further highlights the nuances of runtime supervision. Together, our results reveal that such pairedagent approach can provide clinically grounded auditing and refinement for AI-assisted conversational mental health support.

</details>


### [522] [AI-generated data contamination erodes pathological variability and diagnostic reliability](https://arxiv.org/abs/2601.12946)
*Hongyu He,Shaowen Xiang,Ye Zhang,Yingtao Zhu,Jin Zhang,Hao Deng,Emily Alsentzer,Qingyu Chen,Kun-Hsing Yu,Andrew Marmenshall,Tingting Chen,Srinivas Anumasa,Daniel Ebner,Dean Ho,Kee Yuan Ngiam,Ching-Yu Cheng,Dianbo Liu*

Main category: cs.CY

Relevance: 75.0

TL;DR: 生成式AI在医疗记录中产生合成内容，形成反馈循环，导致病理变异性和诊断可靠性迅速退化，罕见关键发现消失，虚假诊断信心掩盖问题，仅两代后AI生成文档即失去临床价值。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI在医疗记录中产生合成内容形成的反馈循环问题，探索AI生成数据污染对临床诊断的潜在影响，填补这一领域的研究空白。

Method: 分析超过80万个合成数据点，涵盖临床文本生成、视觉语言报告和医学图像合成；进行盲法医师评估；系统评估三种缓解策略：合成数据规模扩展、真实数据混合、质量感知过滤。

Result: AI生成内容中罕见关键发现（如气胸和积液）消失，人口统计表示偏向中年男性表型；虚假诊断信心掩盖退化问题，虚假保证率增加至40%；仅两代后AI生成文档即失去临床价值；合成数据规模扩展无法防止崩溃，真实数据混合与质量感知过滤能有效保持多样性。

Conclusion: 没有政策强制的人工监督，生成式AI的部署可能破坏其依赖的医疗数据生态系统；需要人类监督和质量控制机制来防止数据退化。

Abstract: Generative artificial intelligence (AI) is rapidly populating medical records with synthetic content, creating a feedback loop where future models are increasingly at risk of training on uncurated AI-generated data. However, the clinical consequences of this AI-generated data contamination remain unexplored. Here, we show that in the absence of mandatory human verification, this self-referential cycle drives a rapid erosion of pathological variability and diagnostic reliability. By analysing more than 800,000 synthetic data points across clinical text generation, vision-language reporting, and medical image synthesis, we find that models progressively converge toward generic phenotypes regardless of the model architecture. Specifically, rare but critical findings, including pneumothorax and effusions, vanish from the synthetic content generated by AI models, while demographic representations skew heavily toward middle-aged male phenotypes. Crucially, this degradation is masked by false diagnostic confidence; models continue to issue reassuring reports while failing to detect life-threatening pathology, with false reassurance rates tripling to 40%. Blinded physician evaluation confirms that this decoupling of confidence and accuracy renders AI-generated documentation clinically useless after just two generations. We systematically evaluate three mitigation strategies, finding that while synthetic volume scaling fails to prevent collapse, mixing real data with quality-aware filtering effectively preserves diversity. Ultimately, our results suggest that without policy-mandated human oversight, the deployment of generative AI threatens to degrade the very healthcare data ecosystems it relies upon.

</details>


### [523] [Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance](https://arxiv.org/abs/2601.13770)
*Mostapha Benhenda*

Main category: cs.AI

Relevance: 75.0

TL;DR: 提出Look-Ahead-Bench基准，用于评估金融工作流中PiT大语言模型的向前看偏差，通过分析不同市场周期下的性能衰减来区分真实预测能力与记忆性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过问答测试内部前瞻知识，缺乏对实际场景中模型行为的评估。需要区分模型的真实预测能力和基于记忆的性能，为金融LLM的标准化评估建立基础。

Method: 构建标准化基准测试，分析模型在不同时间市场周期下的性能衰减，引入多个量化基线建立性能阈值。评估开源LLM（Llama 3.1和DeepSeek 3.2）与PiT-Inferece的PiT LLM系列模型。

Result: 标准LLM显示出显著的前瞻偏差（通过alpha衰减测量），而PiT模型随着规模扩大展现出更好的泛化和推理能力，适合实际部署。

Conclusion: 为金融LLM的时间偏差标准化评估奠定基础，提供识别适合实际部署模型的实用框架。

Abstract: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench

</details>


### [524] [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259)
*Jiashuo Liu,Siyuan Chen,Zaiyuan Wang,Zhiyuan Zeng,Jiacheng Guo,Liang Hu,Lingyue Yin,Suozhi Huang,Wenxin Hao,Yang Yang,Zerui Cheng,Zixin Yao,Lingyue Yin,Haoxin Liu,Jiayi Cheng,Yuzhen Li,Zezhong Ma,Bingjie Wang,Bingsen Qiu,Xiao Liu,Zeyang Zhang,Zijian Liu,Jinpeng Wang,Mingren Yin,Tianci He,Yali Liao,Yixiao Tian,Zhenwei Zhu,Anqi Dai,Ge Zhang,Jingkai Liu,Kaiyuan Zhang,Wenlong Wu,Xiang Gao,Xinjie Chen,Zhixin Yao,Zhoufutu Wen,B. Aditya Prakash,Jose Blanchet,Mengdi Wang,Nian Si,Wenhao Huang*

Main category: cs.AI

Relevance: 75.0

TL;DR: FutureX-Pro是一个专业化的未来预测框架，扩展了通用未来预测到金融、零售、公共卫生和自然灾害等高价值垂直领域，评估了当前最先进的智能体LLM在这些关键领域的实际应用能力。


<details>
  <summary>Details</summary>
Motivation: 虽然通用智能体在开放领域搜索中表现出色，但在资本密集型和安全关键领域的可靠性尚未充分探索。需要评估当前最先进的智能体LLM是否具备工业部署所需的领域基础。

Method: 基于FutureX的无污染实时评估流程，构建了包含金融、零售、公共卫生和自然灾害的FutureX-Pro框架，在入门级但基础的预测任务上对智能体LLM进行基准测试。

Result: 研究发现通用推理能力与高价值垂直应用所需精度之间存在性能差距，揭示了当前SOTA智能体LLM在工业部署方面的局限性。

Conclusion: 当前最先进的智能体LLM在专业垂直领域的预测能力仍有不足，需要更强的领域基础才能满足工业部署要求。

Abstract: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.

</details>


### [525] [Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles](https://arxiv.org/abs/2601.11781)
*Dawood Wasif,Terrence J. Moore,Seunghyun Yoon,Hyuk Lim,Dan Dongseong Kim,Frederica F. Nelson,Jin-Hee Cho*

Main category: cs.AI

Relevance: 75.0

TL;DR: RAIL是一个风险感知的人机协同框架，用于自动驾驶车辆处理罕见长尾场景和网络物理入侵。它融合多种运行时信号进行风险评分，通过混合控制策略和人类干预来确保安全，同时通过强化学习持续改进。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在遇到罕见的长尾驾驶场景或网络物理入侵时，必须保持安全和有效性。现有方法在处理这些复杂风险场景时存在局限性，需要一种能够实时感知风险、自适应调整控制策略并支持人类干预的框架。

Method: RAIL框架融合三种风险信号（曲率执行完整性、碰撞时间接近度、观测偏移一致性）通过加权Noisy-OR生成入侵风险评分（IRS）。当风险超过阈值时，将名义策略与特定风险防护策略混合，同时保留人类干预选项。使用上下文多臂赌博机根据风险信号向量选择防护策略。结合Soft Actor-Critic强化学习，采用风险优先回放和双重奖励机制，使接管和接近碰撞事件指导学习。

Result: 在MetaDrive测试中，RAIL获得测试回报360.65、测试成功率0.85、测试安全违规0.75、扰动率0.0027，仅记录29.07个训练安全违规，优于各种基线方法。在CAN注入和LiDAR欺骗攻击下，成功率分别提升至0.68和0.80，攻击下脱离率降至0.37和0.03，攻击成功率降至0.34和0.11。在CARLA中，仅用8000步获得测试回报1609.70和测试成功率0.41。

Conclusion: RAIL框架通过风险感知的人机协同机制，有效提升了自动驾驶系统在罕见场景和网络攻击下的安全性和鲁棒性，同时保持了良好的学习效率和性能。

Abstract: Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor-Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations, outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8000 steps.

</details>


### [526] [SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning](https://arxiv.org/abs/2601.12842)
*Qitong Fang,Haotian Li,Xu Wang*

Main category: cs.AI

Relevance: 75.0

TL;DR: SCULPT是一个约束引导的蒙特卡洛树搜索方法，通过领域感知评分和剪枝来改进LLM代理工作流的搜索策略，避免随机探索中的不合理分支。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理工作流的搜索策略依赖随机探索，经常遍历不合理分支，因为现有方法使用通用提示或弱领域先验的策略来采样候选步骤，导致在操作符、单位和格式上的近随机游走。

Method: SCULPT将领域感知评分集成到MCTS的选择、扩展、模拟和反向传播中，通过符号检查（维度一致性、类型兼容性、幅度合理性、深度控制和多样性）和结构模式指导来评分和剪枝动作。

Result: 在匹配的LLM配置下，SCULPT在多个数据集上带来稳定改进；使用GPT-5.2的额外结果评估了执行器可迁移性和前沿推理模型的性能。

Conclusion: 领域感知约束可以在保持效率和推理稳定性的同时提高准确性。

Abstract: Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.

</details>


### [527] [Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models](https://arxiv.org/abs/2601.12234)
*Fadlullah Raji,Stefano Petrangeli,Matheus Gadelha,Yu Shen,Uttaran Bhattacharya,Gang Wu*

Main category: cs.GR

Relevance: 75.0

TL;DR: Proc3D：一个通过程序化紧凑图（PCG）表示生成可编辑3D模型的系统，支持实时参数化修改和自然语言编辑，相比传统方法实现400倍加速。


<details>
  <summary>Details</summary>
Motivation: 传统3D建模需要专业知识，现有生成方法产生不可编辑的表示（如网格或点云），限制了迭代设计的适应性。需要一种既能生成3D模型又能支持实时编辑的系统。

Method: 引入程序化紧凑图（PCG）作为3D模型的图表示，编码生成模型的算法规则和结构。使用两种生成方法：GPT-4o的上下文学习和微调的LLAMA-3模型，支持通过滑块、复选框和自然语言提示进行实时参数化编辑。

Result: Proc3D在编辑效率上超越现有方法，相比需要完全重新生成的传统方法实现400倍加速。ULIP分数（评估生成3D模型与文本提示对齐的指标）提升28%。

Conclusion: Proc3D通过可编辑的程序化表示实现了文本对齐的3D模型生成和精确的实时参数化编辑，为基于文本的图像编辑应用提供了高效解决方案。

Abstract: Generating 3D models has traditionally been a complex task requiring specialized expertise. While recent advances in generative AI have sought to automate this process, existing methods produce non-editable representation, such as meshes or point clouds, limiting their adaptability for iterative design. In this paper, we introduce Proc3D, a system designed to generate editable 3D models while enabling real-time modifications. At its core, Proc3D introduces procedural compact graph (PCG), a graph representation of 3D models, that encodes the algorithmic rules and structures necessary for generating the model. This representation exposes key parameters, allowing intuitive manual adjustments via sliders and checkboxes, as well as real-time, automated modifications through natural language prompts using Large Language Models (LLMs). We demonstrate Proc3D's capabilities using two generative approaches: GPT-4o with in-context learning (ICL) and a fine-tuned LLAMA-3 model. Experimental results show that Proc3D outperforms existing methods in editing efficiency, achieving more than 400x speedup over conventional approaches that require full regeneration for each modification. Additionally, Proc3D improves ULIP scores by 28%, a metric that evaluates the alignment between generated 3D models and text prompts. By enabling text-aligned 3D model generation along with precise, real-time parametric edits, Proc3D facilitates highly accurate text-based image editing applications.

</details>


### [528] [Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs](https://arxiv.org/abs/2601.13458)
*Zihan Dong,Ruijia Wu,Linjun Zhang*

Main category: stat.ML

Relevance: 75.0

TL;DR: 提出Preference-Calibrated Active Learning (PCAL)方法，通过半参数推断将预算分配问题建模为单调缺失数据框架，优化标注预算在真实标签和成对偏好之间的分配。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成伪标签越来越依赖人类偏好反馈，需要原则性的、预算意识的数据采集策略。核心问题是如何在固定标注预算下，最优分配真实标签和成对偏好的标注资源。

Method: 基于半参数推断，将预算分配问题建模为单调缺失数据框架。提出PCAL方法：1) 学习最优数据采集策略；2) 开发数据分布泛函的统计高效估计器；3) 直接优化估计器方差而非要求闭式解。

Result: 理论上证明了PCAL估计器的渐近最优性，建立了鲁棒性保证（即使辅助模型估计不佳也能保持稳健）。模拟和真实数据分析展示了方法的实际优势和优越性能。

Conclusion: 为现代AI中的预算约束学习提供了原则性和统计高效的方法框架，适用于广泛问题类别。

Abstract: The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. We address the crucial question of how to optimally allocate a fixed annotation budget between ground-truth labels and pairwise preferences in AI. Our solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. Building on this formulation, we introduce Preference-Calibrated Active Learning (PCAL), a novel method that learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretically, we prove the asymptotic optimality of our PCAL estimator and establish a key robustness guarantee that ensures robust performance even with poorly estimated nuisance models. Our flexible framework applies to a general class of problems, by directly optimizing the estimator's variance instead of requiring a closed-form solution. This work provides a principled and statistically efficient approach for budget-constrained learning in modern AI. Simulations and real-data analysis demonstrate the practical benefits and superior performance of our proposed method.

</details>


### [529] [Performance and Complexity Trade-off Optimization of Speech Models During Training](https://arxiv.org/abs/2601.13704)
*Esteban Gómez,Tom Bäckström*

Main category: cs.SD

Relevance: 75.0

TL;DR: 提出一种基于特征噪声注入的重参数化技术，可在训练过程中联合优化性能与计算复杂度，无需依赖启发式准则选择剪枝结构。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络设计通常采用固定层大小和结构，层尺寸选择依赖启发式方法，无法保证性能与计算复杂度的最优权衡。现有方法如权重量化或模型剪枝通常在训练后进行，因为SGD只能优化可微函数，而影响计算复杂度的因素（如层大小、FLOP/s）是不可微的。

Method: 提出基于特征噪声注入的重参数化技术，使模型能够在训练过程中通过SGD方法联合优化性能和计算复杂度。该方法允许模型大小根据目标性能-复杂度权衡动态优化，无需依赖启发式准则选择要移除的权重或结构。

Result: 通过三个案例研究验证了方法的有效性：一个合成示例和两个实际应用（语音活动检测和音频反欺骗）。代码已公开以促进进一步研究。

Conclusion: 该方法提供了一种在训练过程中联合优化模型性能和计算复杂度的新途径，克服了传统方法依赖后处理剪枝的局限性。

Abstract: In speech machine learning, neural network models are typically designed by choosing an architecture with fixed layer sizes and structure. These models are then trained to maximize performance on metrics aligned with the task's objective. While the overall architecture is usually guided by prior knowledge of the task, the sizes of individual layers are often chosen heuristically. However, this approach does not guarantee an optimal trade-off between performance and computational complexity; consequently, post hoc methods such as weight quantization or model pruning are typically employed to reduce computational cost. This occurs because stochastic gradient descent (SGD) methods can only optimize differentiable functions, while factors influencing computational complexity, such as layer sizes and floating-point operations per second (FLOP/s), are non-differentiable and require modifying the model structure during training. We propose a reparameterization technique based on feature noise injection that enables joint optimization of performance and computational complexity during training using SGD-based methods. Unlike traditional pruning methods, our approach allows the model size to be dynamically optimized for a target performance-complexity trade-off, without relying on heuristic criteria to select which weights or structures to remove. We demonstrate the effectiveness of our method through three case studies, including a synthetic example and two practical real-world applications: voice activity detection and audio anti-spoofing. The code related to our work is publicly available to encourage further research.

</details>


### [530] [MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?](https://arxiv.org/abs/2601.11559)
*Zilal Eiz AlDin,John Wu,Jeffrey Paul Fung,Jennifer King,Mya Watts,Lauren ONeill,Adam Richard Cross,Jimeng Sun*

Main category: cs.AI

Relevance: 65.0

TL;DR: 论文提出了MIMIC-RD基准，用于评估LLM在罕见病鉴别诊断中的表现，发现当前最先进的LLM在此任务上表现不佳，揭示了现有能力与临床需求之间的巨大差距。


<details>
  <summary>Details</summary>
Motivation: 尽管罕见病影响大量人群，但其鉴别诊断仍然具有挑战性。现有评估LLM在罕见病诊断中的方法存在两个关键局限：1) 依赖理想化的临床案例研究，未能捕捉真实世界的临床复杂性；2) 使用ICD代码作为疾病标签，这显著低估了罕见病数量，因为许多罕见病缺乏与Orphanet等综合罕见病数据库的直接映射。

Method: 1) 构建MIMIC-RD基准：通过直接将临床文本实体映射到Orphanet数据库来构建罕见病鉴别诊断基准；2) 采用LLM-based挖掘流程，然后由四位医学注释者验证，确认识别的实体是真正的罕见病；3) 在包含145名患者的数据集上评估各种模型。

Result: 当前最先进的大型语言模型在罕见病鉴别诊断任务上表现不佳，揭示了现有能力与临床需求之间的巨大差距。

Conclusion: 需要改进罕见病的鉴别诊断方法，论文提出了几个未来改进方向，强调了LLM在罕见病诊断领域仍有很大提升空间。

Abstract: Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.

</details>


### [531] [Overview of the SciHigh Track at FIRE 2025: Research Highlight Generation from Scientific Papers](https://arxiv.org/abs/2601.11582)
*Tohida Rehman,Debarshi Kumar Sanyal,Samiran Chattopadhyay*

Main category: cs.CY

Relevance: 65.0

TL;DR: SciHigh是一个从科学论文摘要自动生成简洁要点式亮点的任务，旨在评估计算模型捕捉论文关键贡献、发现和新颖性的能力，帮助读者快速掌握核心思想。


<details>
  <summary>Details</summary>
Motivation: 科学论文数量激增，读者需要快速掌握核心内容。要点式亮点比长段落更易阅读，尤其在移动设备上。自动生成亮点可以减少阅读负担，加速文献综述，并增强数字图书馆和学术搜索平台的元数据。

Method: 使用MixSub数据集（包含摘要和作者撰写的亮点对），12个团队参与探索了各种方法，包括预训练语言模型。评估采用ROUGE、METEOR和BERTScore等指标，主要基于ROUGE-L分数进行排名。

Result: 自动生成的亮点可以有效减少阅读努力，加速文献综述过程，并为数字图书馆和学术搜索平台提供更好的元数据。SciHigh为推进从科学写作生成简洁准确亮点的方法提供了专用基准。

Conclusion: SciHigh建立了从科学论文自动生成亮点的基准任务，展示了自动生成亮点在加速科学传播和增强学术搜索方面的潜力，为未来研究提供了评估框架。

Abstract: `SciHigh: Research Highlight Generation from Scientific Papers' focuses on the task of automatically generating concise, informative, and meaningful bullet-point highlights directly from scientific abstracts. The goal of this task is to evaluate how effectively computational models can generate highlights that capture the key contributions, findings, and novelty of a paper in a concise form. Highlights help readers grasp essential ideas quickly and are often easier to read and understand than longer paragraphs, especially on mobile devices. The track uses the MixSub dataset \cite{10172215}, which provides pairs of abstracts and corresponding author-written highlights.
  In this inaugural edition of the track, 12 teams participated, exploring various approaches, including pre-trained language models, to generate highlights from this scientific dataset. All submissions were evaluated using established metrics such as ROUGE, METEOR, and BERTScore to measure both alignment with author-written highlights and overall informativeness. Teams were ranked based on ROUGE-L scores. The findings suggest that automatically generated highlights can reduce reading effort, accelerate literature reviews, and enhance metadata for digital libraries and academic search platforms. SciHigh provides a dedicated benchmark for advancing methods aimed at concise and accurate highlight generation from scientific writing.

</details>


### [532] [MemeLens: Multilingual Multitask VLMs for Memes](https://arxiv.org/abs/2601.12539)
*Ali Ezzat Shahroor,Mohamed Bayan Kmainasi,Abul Hasnat,Dimitar Dimitrov,Giovanni Da San Martino,Preslav Nakov,Firoj Alam*

Main category: cs.AI

Relevance: 65.0

TL;DR: MemeLens是一个统一的多语言多任务视觉语言模型，用于增强meme理解，整合了38个公共meme数据集，映射到20个任务的共享分类法中。


<details>
  <summary>Details</summary>
Motivation: 现有meme研究分散在不同任务（仇恨、厌女、宣传、情感、幽默）和语言中，限制了跨领域泛化能力。需要统一的框架来理解meme这种结合文本、图像和文化背景的复杂媒介。

Method: 提出MemeLens模型，整合38个公共meme数据集，将数据集特定标签过滤并映射到包含20个任务的共享分类法中，涵盖危害、目标、比喻/语用意图和情感等维度。进行跨建模范式、任务类别和数据集的全面实证分析。

Result: 研究发现：1）稳健的meme理解需要多模态训练；2）不同语义类别间存在显著差异；3）在单个数据集上微调而非统一训练时，模型容易过度专业化。

Conclusion: MemeLens为meme理解提供了统一的多语言多任务框架，揭示了多模态训练的重要性，并展示了跨任务泛化的挑战。将公开实验资源和数据集供社区使用。

Abstract: Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.

</details>


### [533] [SciHorizon-GENE: Benchmarking LLM for Life Sciences Inference from Gene Knowledge to Functional Understanding](https://arxiv.org/abs/2601.12805)
*Xiaohan Huang,Meng Xiao,Chuan Qin,Qingqing Long,Jinmiao Chen,Yuanchun Zhou,Hengshu Zhu*

Main category: q-bio.GN

Relevance: 65.0

TL;DR: SciHorizon-GENE：一个面向基因功能推理的大规模基准测试，评估LLM在生物医学知识推理中的可靠性，重点关注研究关注度敏感性、幻觉倾向、答案完整性和文献影响四个维度。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在生物医学研究中显示出潜力，但其从基因层面知识到功能理解的可靠推理能力尚未充分探索，这是知识增强细胞图谱解释的核心需求。现有方法在基因尺度推理方面存在不足，限制了LLM在生物解释管道中的安全采用。

Method: 构建SciHorizon-GENE基准测试，整合来自权威生物数据库的超过190K人类基因的精选知识，包含超过540K个问题，涵盖细胞类型注释、功能解释和机制导向分析等多样化的基因到功能推理场景。基于初步观察的行为模式，从四个生物学关键视角评估LLM：研究关注度敏感性、幻觉倾向、答案完整性和文献影响。

Result: 系统评估了多种最先进的通用和生物医学LLM，揭示了基因层面推理能力的显著异质性，以及在生成忠实、完整和文献基础的功能解释方面存在的持续挑战。不同模型在四个评估维度上表现差异明显。

Conclusion: 该基准为分析LLM在基因尺度的行为建立了系统基础，为模型选择和开发提供了见解，对知识增强的生物解释具有直接相关性。强调了LLM在生物医学推理中需要改进的领域，特别是减少幻觉和提高文献基础。

Abstract: Large language models (LLMs) have shown growing promise in biomedical research, particularly for knowledge-driven interpretation tasks. However, their ability to reliably reason from gene-level knowledge to functional understanding, However, their ability to reliably reason from gene-level knowledge to functional understanding, a core requirement for knowledge-enhanced cell atlas interpretation, remains largely underexplored. To address this gap, we introduce SciHorizon-GENE, a large-scale gene-centric benchmark constructed from authoritative biological databases. The benchmark integrates curated knowledge for over 190K human genes and comprises more than 540K questions covering diverse gene-to-function reasoning scenarios relevant to cell type annotation, functional interpretation, and mechanism-oriented analysis. Motivated by behavioral patterns observed in preliminary examinations, SciHorizon-GENE evaluates LLMs along four biologically critical perspectives: research attention sensitivity, hallucination tendency, answer completeness, and literature influence, explicitly targeting failure modes that limit the safe adoption of LLMs in biological interpretation pipelines. We systematically evaluate a wide range of state-of-the-art general-purpose and biomedical LLMs, revealing substantial heterogeneity in gene-level reasoning capabilities and persistent challenges in generating faithful, complete, and literature-grounded functional interpretations. Our benchmark establishes a systematic foundation for analyzing LLM behavior at the gene scale and offers insights for model selection and development, with direct relevance to knowledge-enhanced biological interpretation.

</details>


### [534] [Learning Audio-Visual Embeddings with Inferred Latent Interaction Graphs](https://arxiv.org/abs/2601.11995)
*Donghuo Zeng,Hao Niu,Yanan Wang,Masato Taya*

Main category: cs.MM

Relevance: 65.0

TL;DR: 提出AV-SAL、ILI和LIR框架，通过软标签预测和推断潜在交互来解决音频-视觉嵌入学习中虚假负样本问题，在AVE和VEGAS基准上提升mAP。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习和三元组损失方法使用稀疏标注，将任何共现视为语义相似性，导致虚假负样本和遗漏跨模态依赖。例如，标注为"火车"的视频可能包含摩托车音频和视觉，但标准方法将这些共现视为负样本，造成错误。

Method: 1) AV-SAL：训练教师网络产生跨模态对齐的软标签分布，为非标注但共现的事件分配非零概率；2) ILI：应用GRaSP算法从教师软标签推断类别间的稀疏有向依赖图；3) LIR：学生网络使用度量损失和ILI图指导的正则化器训练，拉近依赖链接但未标注对的嵌入。

Result: 在AVE和VEGAS基准测试中显示mAP的持续改进，表明将推断的潜在交互整合到嵌入学习中增强了鲁棒性和语义连贯性。

Conclusion: 通过软标签预测和推断潜在交互的框架能有效解决音频-视觉嵌入学习中的虚假负样本问题，提升跨模态表示的质量和鲁棒性。

Abstract: Learning robust audio-visual embeddings requires bringing genuinely related audio and visual signals together while filtering out incidental co-occurrences - background noise, unrelated elements, or unannotated events. Most contrastive and triplet-loss methods use sparse annotated labels per clip and treat any co-occurrence as semantic similarity. For example, a video labeled "train" might also contain motorcycle audio and visual, because "motorcycle" is not the chosen annotation; standard methods treat these co-occurrences as negatives to true motorcycle anchors elsewhere, creating false negatives and missing true cross-modal dependencies. We propose a framework that leverages soft-label predictions and inferred latent interactions to address these issues: (1) Audio-Visual Semantic Alignment Loss (AV-SAL) trains a teacher network to produce aligned soft-label distributions across modalities, assigning nonzero probability to co-occurring but unannotated events and enriching the supervision signal. (2) Inferred Latent Interaction Graph (ILI) applies the GRaSP algorithm to teacher soft labels to infer a sparse, directed dependency graph among classes. This graph highlights directional dependencies (e.g., "Train (visual)" -> "Motorcycle (audio)") that expose likely semantic or conditional relationships between classes; these are interpreted as estimated dependency patterns. (3) Latent Interaction Regularizer (LIR): A student network is trained with both metric loss and a regularizer guided by the ILI graph, pulling together embeddings of dependency-linked but unlabeled pairs in proportion to their soft-label probabilities. Experiments on AVE and VEGAS benchmarks show consistent improvements in mean average precision (mAP), demonstrating that integrating inferred latent interactions into embedding learning enhances robustness and semantic coherence.

</details>


### [535] [Kernel-Based Learning of Safety Barriers](https://arxiv.org/abs/2601.12002)
*Oliver Schön,Zhengang Zhong,Sadegh Soudjani*

Main category: cs.AI

Relevance: 65.0

TL;DR: 提出一种数据驱动的安全验证方法，利用控制屏障证书和核希尔伯特空间嵌入技术，为具有离散时间随机动力学的黑盒系统提供可扩展的安全保证。


<details>
  <summary>Details</summary>
Motivation: 随着AI算法在自动驾驶、医疗等安全关键领域的广泛应用，传统形式化安全验证工具难以处理AI系统的黑盒特性，且无法扩展到现实应用的复杂性。需要一种能够处理黑盒系统、具有可扩展性的安全验证方法。

Method: 1. 使用控制屏障证书保证系统安全性，直接从系统轨迹数据中学习证书；2. 采用条件均值嵌入将系统数据嵌入再生核希尔伯特空间(RKHS)；3. 构建RKHS模糊集以增强对分布外行为的鲁棒性；4. 利用有限傅里叶展开将半无限优化问题转化为线性规划；5. 通过快速傅里叶变换高效生成松弛问题。

Result: 提出了一个可扩展且分布鲁棒的安全验证框架，能够超越对系统动力学和不确定性的限制性假设。方法在两个案例研究中得到验证，包括具有神经网络控制器的黑盒系统。

Conclusion: 该方法为黑盒AI系统的安全验证提供了数据驱动的解决方案，具有理论保证和实际可扩展性，适用于超越安全性的更广泛时序逻辑规范。

Abstract: The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.

</details>


### [536] [Purification Before Fusion: Toward Mask-Free Speech Enhancement for Robust Audio-Visual Speech Recognition](https://arxiv.org/abs/2601.12436)
*Linzhi Wu,Xingyu Zhang,Hao Yuan,Yakun Zhang,Changyan Zheng,Liang Xie,Tiejun Liu,Erwei Yin*

Main category: eess.AS

Relevance: 65.0

TL;DR: 提出了一种结合语音增强的端到端噪声鲁棒视听语音识别框架，无需显式噪声掩码生成，通过Conformer瓶颈融合模块隐式优化噪声音频特征，在LRS3基准上优于现有基于掩码的方法。


<details>
  <summary>Details</summary>
Motivation: 传统视听语音识别在噪声环境中通过视觉线索提高识别准确率，但高噪声音频输入会在特征融合过程中引入不良干扰。现有基于掩码的方法虽然能过滤音频噪声，但可能同时丢弃语义相关信息。

Method: 提出端到端噪声鲁棒AVSR框架，结合语音增强，无需显式噪声掩码生成。采用基于Conformer的瓶颈融合模块，利用视频辅助隐式优化噪声音频特征，减少模态冗余并增强模态间交互。

Result: 在公开LRS3基准上的实验评估表明，该方法在噪声条件下优于先前先进的基于掩码的基线方法。

Conclusion: 提出的框架通过隐式特征优化而非显式噪声过滤，在保持语音语义完整性的同时实现了鲁棒的识别性能，为噪声环境下的视听语音识别提供了更有效的解决方案。

Abstract: Audio-visual speech recognition (AVSR) typically improves recognition accuracy in noisy environments by integrating noise-immune visual cues with audio signals. Nevertheless, high-noise audio inputs are prone to introducing adverse interference into the feature fusion process. To mitigate this, recent AVSR methods often adopt mask-based strategies to filter audio noise during feature interaction and fusion, yet such methods risk discarding semantically relevant information alongside noise. In this work, we propose an end-to-end noise-robust AVSR framework coupled with speech enhancement, eliminating the need for explicit noise mask generation. This framework leverages a Conformer-based bottleneck fusion module to implicitly refine noisy audio features with video assistance. By reducing modality redundancy and enhancing inter-modal interactions, our method preserves speech semantic integrity to achieve robust recognition performance. Experimental evaluations on the public LRS3 benchmark suggest that our method outperforms prior advanced mask-based baselines under noisy conditions.

</details>


### [537] [Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction](https://arxiv.org/abs/2601.12688)
*Xu Zhang,Qinghua Wang,Mengyang Zhao,Fang Wang,Cunquan Qu*

Main category: cs.AI

Relevance: 65.0

TL;DR: 提出MMSI框架，结合预训练Transformer编码器和量刑逻辑，通过面向掩码机制和比较数据构建策略，提升多被告人案件中角色区分和罪责评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 多被告人案件中司法表述模糊，难以区分被告角色，影响AI辅助司法分析的公平性和精确性。需要解决司法文本中角色信息不明确的问题，提升智能司法系统的罪责区分能力。

Method: 1. 基于预训练Transformer编码器框架，融入量刑逻辑；2. 设计面向掩码机制澄清被告角色；3. 采用比较数据构建策略增强模型对主犯与从犯罪责差异的敏感性；4. 通过广播机制将预测的罪责标签整合到回归模型中，结合犯罪描述和法庭观点。

Result: 在自定义的IMLJP故意伤害案件数据集上评估，MMSI框架在基于角色的罪责区分方面显著优于基线方法，实现了准确度提升。

Conclusion: 该工作为增强智能司法系统提供了稳健解决方案，通过结合深度学习与司法逻辑，有效解决了多被告人案件中的角色区分难题，代码已公开。

Abstract: Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.

</details>


### [538] [VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781)
*Hyejin Park,Junhyuk Kwon,Suha Kwak,Jungseul Ok*

Main category: cs.AI

Relevance: 65.0

TL;DR: VIRO是一个神经符号框架，通过在推理步骤中嵌入轻量级操作级验证器来解决REC中的级联错误问题，在目标存在和无目标情况下都实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号REC方法假设中间推理步骤准确，导致级联错误：错误检测和无效关系在推理链中传播，即使图像中没有目标也会产生高置信度误报。

Method: 引入验证集成推理操作符(VIRO)，在推理步骤中嵌入轻量级操作级验证器。每个操作符执行并验证其输出（如对象存在性或空间关系），当验证条件不满足时能稳健处理无目标情况。

Result: 在目标存在和无目标设置下达到61.1%的平衡准确率，实现了最先进的性能。在真实世界第一人称数据上展示泛化能力，计算效率高（吞吐量高），可靠性强（程序失败率<0.3%），通过解耦程序生成和执行实现可扩展性。

Conclusion: VIRO通过集成操作级验证器解决了神经符号REC中的级联错误问题，在准确率、可靠性、效率和可扩展性方面都有显著提升，特别是在处理无目标情况时表现出色。

Abstract: Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.

</details>


### [539] [ConceptCaps -- a Distilled Concept Dataset for Interpretability in Music Models](https://arxiv.org/abs/2601.14157)
*Bruno Sienkiewicz,Łukasz Neumann,Mateusz Modrzejewski*

Main category: cs.SD

Relevance: 65.0

TL;DR: ConceptCaps：一个包含23k音乐-字幕-音频三元组的数据集，具有明确的200属性分类标签，用于概念可解释性研究，通过分离语义建模和文本生成提高可控性。


<details>
  <summary>Details</summary>
Motivation: 现有音乐数据集缺乏清晰、分离的正负概念示例，标签稀疏、嘈杂或定义不清，限制了TCAV等概念可解释性方法的应用。

Method: 采用分离式流水线：1) VAE学习属性共现模式；2) 微调LLM将属性列表转换为专业描述；3) MusicGen合成对应音频。验证包括音频-文本对齐(CLAP)、语言质量指标(BERTScore, MAUVE)和TCAV分析。

Result: 创建了ConceptCaps数据集，包含23k音乐-字幕-音频三元组，具有200属性分类。验证显示音频-文本对齐良好，语言质量高，TCAV分析确认概念探针能恢复音乐上有意义的模式。

Conclusion: ConceptCaps解决了音乐领域概念可解释性研究的数据瓶颈，分离式方法比端到端方法具有更好的连贯性和可控性，支持TCAV等概念分析方法的应用。

Abstract: Concept-based interpretability methods like TCAV require clean, well-separated positive and negative examples for each concept. Existing music datasets lack this structure: tags are sparse, noisy, or ill-defined. We introduce ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. Our pipeline separates semantic modeling from text generation: a VAE learns plausible attribute co-occurrence patterns, a fine-tuned LLM converts attribute lists into professional descriptions, and MusicGen synthesizes corresponding audio. This separation improves coherence and controllability over end-to-end approaches. We validate the dataset through audio-text alignment (CLAP), linguistic quality metrics (BERTScore, MAUVE), and TCAV analysis confirming that concept probes recover musically meaningful patterns. Dataset and code are available online.

</details>


### [540] [Graph Neural Networks are Heuristics](https://arxiv.org/abs/2601.13465)
*Yimeng Min,Carla P. Gomes*

Main category: cs.AI

Relevance: 45.0

TL;DR: 图神经网络通过单次训练轨迹即可成为组合优化的无监督启发式方法，无需搜索、监督或序列决策，仅通过前向传播生成解


<details>
  <summary>Details</summary>
Motivation: 传统组合优化方法通常需要监督训练或显式搜索，本文探索图神经网络是否能在无监督、无搜索的情况下直接学习全局组合结构并作为强启发式方法

Method: 将全局结构约束作为归纳偏置编码到图神经网络中，使用非自回归模型通过直接前向传播生成解，推理时通过dropout和快照集成实现隐式集成以增加解多样性

Result: 在旅行商问题上验证了该方法能有效减少最优性差距，表明图神经网络无需监督训练或显式搜索即可成为有效的学习启发式方法

Conclusion: 学习在组合优化中的角色从增强经典算法转变为直接实例化新启发式方法，图神经网络能够内化全局组合结构并作为强学习启发式方法

Abstract: We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.

</details>


### [541] [Communication Methods in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.12886)
*Christoph Wittner*

Main category: cs.MA

Relevance: 40.0

TL;DR: 该论文对多智能体强化学习中的通信技术进行了系统性综述，分析了29篇相关文献，评估了显式、隐式、注意力机制、图基和分层/角色基通信方法的优缺点，指出没有通用的最优通信框架，选择取决于具体问题，并强调了低计算开销通信方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在处理部分可观测环境、非平稳性和指数增长动作空间等问题时面临挑战，通信技术能促进智能体间的高效协作。然而，现有通信方法多样且缺乏系统比较，需要全面分析不同通信方法的优缺点，为实际应用提供指导。

Method: 通过对29篇相关文献的深入分析，系统评估了五种主要通信方法：1) 显式通信（直接信息交换），2) 隐式通信（通过观察行为间接通信），3) 注意力机制通信，4) 图基通信（利用图结构），5) 分层/角色基通信。从计算效率、可扩展性、鲁棒性等维度进行比较分析。

Result: 分析表明：1) 不存在适用于所有问题的通用最优通信框架；2) 通信方法的选择高度依赖于具体问题特性；3) 低计算开销的通信方法对于大规模多智能体环境至关重要；4) 当前研究缺乏标准化基准测试和现实通信条件下的鲁棒性评估。

Conclusion: 多智能体强化学习通信方法需要根据具体问题定制，未来研究方向应关注：1) 建立标准化系统级指标基准测试；2) 提升在现实通信条件下的鲁棒性；3) 开发更高效可扩展的通信机制，以增强实际应用价值。

Abstract: Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to this field to address problems such as partially observable environments, non-stationarity, and exponentially growing action spaces. Communication further enables efficient cooperation among all agents interacting in an environment. This work aims at providing an overview of communication techniques in multi-agent reinforcement learning. By an in-depth analysis of 29 publications on this topic, the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication are evaluated. The results of this comparison show that there is no general, optimal communication framework for every problem. On the contrary, the choice of communication depends heavily on the problem at hand. The comparison also highlights the importance of communication methods with low computational overhead to enable scalability to environments where many agents interact. Finally, the paper discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions to enhance the real-world applicability of these approaches.

</details>


### [542] [Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy](https://arxiv.org/abs/2601.12922)
*Johannes Kaiser,Alexander Ziller,Eleni Triantafillou,Daniel Rückert,Georgios Kaissis*

Main category: cs.CR

Relevance: 40.0

TL;DR: 该论文揭示了个体差分隐私(iDP)机制中一个被忽视的漏洞：个体的隐私风险不仅取决于自身的隐私预算，还受其他所有数据贡献者隐私选择的影响，导致隐私控制承诺与现实风险不匹配，并可能被恶意利用。


<details>
  <summary>Details</summary>
Motivation: 个体差分隐私(iDP)承诺用户能控制自己的隐私，但在实践中这一承诺可能被打破。作者发现采样基iDP机制中存在一个被忽视的漏洞：个体的隐私风险不仅由自身隐私预算决定，还受其他所有数据贡献者隐私选择的影响，导致隐私控制承诺与现实风险不匹配。

Method: 论文通过理论分析和实证评估揭示iDP机制中的漏洞。首先展示隐私风险如何受其他用户隐私选择影响，然后设计攻击实验，让中央对手或合谋对手通过故意选择隐私预算来放大目标个体的脆弱性。最后提出$(\varepsilon_i,δ_i,\overlineΔ)$-iDP隐私契约，使用$Δ$-散度为用户提供超额脆弱性的硬上限。

Result: 实证评估显示，62%的目标个体成功受到攻击，其成员推理易感性显著增加。攻击完全在DP保证范围内操作，隐藏了超额脆弱性。某些隐私偏好分布会无意中放大个体隐私风险，即使其形式化保证得到满足。

Conclusion: 研究暴露了当前iDP范式的根本挑战，需要重新评估iDP系统的设计、审计、沟通和部署方式，使超额风险透明且可控。提出的$(\varepsilon_i,δ_i,\overlineΔ)$-iDP契约为用户提供超额脆弱性的硬上限，同时为机制设计提供灵活性。

Abstract: Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. We reveal a previously overlooked vulnerability in sampling-based iDP mechanisms: while conforming to the iDP guarantees, an individual's privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. We demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. Moreover, this excess risk provides an exploitable attack vector. A central adversary or a set of colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. Most importantly, this attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Our empirical evaluation demonstrates successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, we propose $(\varepsilon_i,δ_i,\overlineΔ)$-iDP a privacy contract that uses $Δ$-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Our findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.

</details>


### [543] [DeepEvidence: Empowering Biomedical Discovery with Deep Knowledge Graph Research](https://arxiv.org/abs/2601.11560)
*Zifeng Wang,Zheng Chen,Ziwei Yang,Xuan Wang,Qiao Jin,Yifan Peng,Zhiyong Lu,Jimeng Sun*

Main category: cs.IR

Relevance: 35.0

TL;DR: DeepEvidence是一个AI代理框架，专门用于在异构生物医学知识图谱上进行深度研究，通过协调广度优先和深度优先搜索策略，结合知识图谱工具，实现跨资源的系统性探索和证据合成。


<details>
  <summary>Details</summary>
Motivation: 生物医学知识图谱包含大量异构信息，但由于结构差异、持续演化和有限的跨资源对齐，需要大量手动集成，限制了知识探索的深度和规模。现有深度研究系统主要依赖互联网文本，缺乏专门的知识图谱工具和协调探索策略。

Method: 1. 设计了一个协调器，指导两个互补代理：广度优先搜索(BFRS)用于多图谱实体搜索，深度优先搜索(DFRS)用于多跳证据聚焦推理。2. 构建增量证据图谱，结构化记录检索到的实体、关系和证据。3. 提供统一接口查询多样生物医学API和执行沙箱，支持程序化数据检索、提取和分析。

Result: 在深度推理基准测试和生物医学发现生命周期的四个关键阶段（药物发现、临床前实验、临床试验开发、循证医学）中，DeepEvidence在系统性探索和证据合成方面表现出显著优势。

Conclusion: 知识图谱驱动的深度研究有潜力加速生物医学发现，DeepEvidence框架通过协调异构知识图谱探索，为大规模生物医学研究提供了有效工具。

Abstract: Biomedical knowledge graphs (KGs) encode vast, heterogeneous information spanning literature, genes, pathways, drugs, diseases, and clinical trials, but leveraging them collectively for scientific discovery remains difficult. Their structural differences, continual evolution, and limited cross-resource alignment require substantial manual integration, limiting the depth and scale of knowledge exploration. We introduce DeepEvidence, an AI-agent framework designed to perform Deep Research across various heterogeneous biomedical KGs. Unlike generic Deep Research systems that rely primarily on internet-scale text, DeepEvidence incorporates specialized knowledge-graph tooling and coordinated exploration strategies to systematically bridge heterogeneous resources. At its core is an orchestrator that directs two complementary agents: Breadth-First ReSearch (BFRS) for broad, multi-graph entity search, and Depth-First ReSearch (DFRS) for multi-hop, evidence-focused reasoning. An internal, incrementally built evidence graph provides a structured record of retrieved entities, relations, and supporting evidence. To operate at scale, DeepEvidence includes unified interfaces for querying diverse biomedical APIs and an execution sandbox that enables programmatic data retrieval, extraction, and analysis. Across established deep-reasoning benchmarks and four key stages of the biomedical discovery lifecycle: drug discovery, pre-clinical experimentation, clinical trial development, and evidence-based medicine, DeepEvidence demonstrates substantial gains in systematic exploration and evidence synthesis. These results highlight the potential of knowledge-graph-driven Deep Research to accelerate biomedical discovery.

</details>


### [544] [Reinforcement Learning for Dynamic Workflow Optimization in CI/CD Pipelines](https://arxiv.org/abs/2601.11647)
*Aniket Abhishek Soni,Milan Parikh,Rashi Nimesh Kumar Dhenia,Jubin Abhishek Soni,Ayush Raj Jha,Sneja Mitinbhai Shah*

Main category: cs.SE

Relevance: 35.0

TL;DR: 本文提出了一种基于强化学习的CI/CD管道动态优化方法，通过将管道建模为马尔可夫决策过程，训练RL代理在运行时做出决策（如选择完整、部分或无测试执行），以提高吞吐量并减少测试开销。


<details>
  <summary>Details</summary>
Motivation: 现代软件交付中的CI/CD管道虽然重要，但其静态工作流在系统扩展时常常引入低效率问题。传统的固定流程无法根据实际情况动态调整，导致资源浪费和反馈周期延长。

Method: 将CI/CD管道建模为马尔可夫决策过程，训练强化学习代理在运行时动态决策。开发了可配置的CI/CD仿真环境，在构建、测试和部署阶段评估该方法。代理学习根据提交风险选择性地跳过或简化测试。

Result: 实验结果显示，RL优化的管道相比静态基线实现了高达30%的吞吐量提升和约25%的测试执行时间减少，同时缺陷遗漏率保持在5%以下。代理学会了针对低风险提交选择性跳过或简化测试。

Conclusion: 强化学习能够实现自适应和智能的DevOps工作流，为更高效、弹性和可持续的CI/CD自动化提供了实用途径。该方法展示了RL在软件工程优化中的潜力。

Abstract: Continuous Integration and Continuous Deployment (CI/CD) pipelines are central to modern software delivery, yet their static workflows often introduce inefficiencies as systems scale. This paper proposes a reinforcement learning (RL) based approach to dynamically optimize CI/CD pipeline workflows. The pipeline is modeled as a Markov Decision Process, and an RL agent is trained to make runtime decisions such as selecting full, partial, or no test execution in order to maximize throughput while minimizing testing overhead.
  A configurable CI/CD simulation environment is developed to evaluate the approach across build, test, and deploy stages. Experimental results show that the RL optimized pipeline achieves up to a 30 percent improvement in throughput and approximately a 25 percent reduction in test execution time compared to static baselines, while maintaining a defect miss rate below 5 percent. The agent learns to selectively skip or abbreviate tests for low risk commits, accelerating feedback cycles without significantly increasing failure risk.
  These results demonstrate the potential of reinforcement learning to enable adaptive and intelligent DevOps workflows, providing a practical pathway toward more efficient, resilient, and sustainable CI/CD automation.

</details>


### [545] [Cascaded Transformer for Robust and Scalable SLA Decomposition via Amortized Optimization](https://arxiv.org/abs/2601.11859)
*Cyril Shih-Huan Hsu*

Main category: cs.NI

Relevance: 35.0

TL;DR: Casformer：基于级联Transformer架构的优化自由SLA分解方法，用于6G网络切片，通过历史领域反馈和跨领域依赖建模实现高效实时SLA管理


<details>
  <summary>Details</summary>
Motivation: 6G网络切片需要将端到端服务等级协议（SLA）分解为领域特定SLA，现有基于优化的方法计算密集、延迟高、复杂度大，需要更高效的实时解决方案

Method: 提出Casformer级联Transformer架构：第一层使用领域特定Transformer编码器处理历史领域反馈，第二层使用Transformer聚合器整合跨领域依赖；采用领域感知神经网络（DINN）学习范式，结合风险感知建模和摊销优化学习稳定的前向分解策略

Result: Casformer在SLA分解质量上优于现有基于优化的框架，在波动和噪声网络条件下表现出更好的可扩展性和鲁棒性；前向设计降低运行时复杂度，简化部署和维护

Conclusion: 将摊销优化与基于Transformer的序列建模结合，为高级5G及以后网络环境中的实时SLA管理提供了可扩展高效的解决方案，推动了网络自动化发展

Abstract: The evolution toward 6G networks increasingly relies on network slicing to provide tailored, End-to-End (E2E) logical networks over shared physical infrastructures. A critical challenge is effectively decomposing E2E Service Level Agreements (SLAs) into domain-specific SLAs, which current solutions handle through computationally intensive, iterative optimization processes that incur substantial latency and complexity. To address this, we introduce Casformer, a cascaded Transformer architecture designed for fast, optimization-free SLA decomposition. Casformer leverages historical domain feedback encoded through domain-specific Transformer encoders in its first layer, and integrates cross-domain dependencies using a Transformer-based aggregator in its second layer. The model is trained under a learning paradigm inspired by Domain-Informed Neural Networks (DINNs), incorporating risk-informed modeling and amortized optimization to learn a stable, forward-only SLA decomposition policy. Extensive evaluations demonstrate that Casformer achieves improved SLA decomposition quality against state-of-the-art optimization-based frameworks, while exhibiting enhanced scalability and robustness under volatile and noisy network conditions. In addition, its forward-only design reduces runtime complexity and simplifies deployment and maintenance. These insights reveal the potential of combining amortized optimization with Transformer-based sequence modeling to advance network automation, providing a scalable and efficient solution suitable for real-time SLA management in advanced 5G-and-beyond network environments.

</details>


### [546] [Mobile-friendly Image de-noising: Hardware Conscious Optimization for Edge Application](https://arxiv.org/abs/2601.11684)
*Srinivas Miriyala,Sowmya Vajrala,Hitesh Kumar,Sravanth Kodavanti,Vikram Rajendiran*

Main category: eess.IV

Relevance: 35.0

TL;DR: 本文提出了一种基于熵正则化可微分神经架构搜索的移动友好型图像去噪网络，在保持竞争力的准确率下显著减少了计算复杂度和内存占用。


<details>
  <summary>Details</summary>
Motivation: 传统图像信号处理在图像增强任务中效果有限，而深度学习方法的成功越来越依赖于在边缘设备（如智能手机）上的部署便利性。需要设计既高效又能在移动设备上实时运行的图像去噪网络。

Method: 采用熵正则化可微分神经架构搜索（NAS）在硬件感知的搜索空间中为U-Net架构自动设计网络结构。这是首次将NAS应用于U-Net架构进行图像去噪。

Result: 设计的模型参数减少12%，在三星Galaxy S24 Ultra上部署时，设备延迟改善约2倍，内存占用改善1.5倍，PSNR仅下降0.7%。与SOTA的Swin-Transformer相比，在保持竞争力的准确率下，GMACs减少约18倍。在4个基准测试上成功测试了3种强度的高斯去噪，并在1个真实世界去噪基准上验证了泛化能力。

Conclusion: 提出的移动友好型图像去噪网络通过NAS方法实现了在边缘设备上的高效部署，在准确率和效率之间取得了良好平衡，具有实际应用价值。

Abstract: Image enhancement is a critical task in computer vision and photography that is often entangled with noise. This renders the traditional Image Signal Processing (ISP) ineffective compared to the advances in deep learning. However, the success of such methods is increasingly associated with the ease of their deployment on edge devices, such as smartphones. This work presents a novel mobile-friendly network for image de-noising obtained with Entropy-Regularized differentiable Neural Architecture Search (NAS) on a hardware-aware search space for a U-Net architecture, which is first-of-its-kind. The designed model has 12% less parameters, with ~2-fold improvement in ondevice latency and 1.5-fold improvement in the memory footprint for a 0.7% drop in PSNR, when deployed and profiled on Samsung Galaxy S24 Ultra. Compared to the SOTA Swin-Transformer for Image Restoration, the proposed network had competitive accuracy with ~18-fold reduction in GMACs. Further, the network was tested successfully for Gaussian de-noising with 3 intensities on 4 benchmarks and real-world de-noising on 1 benchmark demonstrating its generalization ability.

</details>


### [547] [Towards Efficient Image Deblurring for Edge Deployment](https://arxiv.org/abs/2601.11685)
*Srinivas Miriyala,Sowmya Vajrala,Sravanth Kodavanti*

Main category: eess.IV

Relevance: 35.0

TL;DR: 本文提出了一种硬件感知的图像去模糊模型适配框架，通过敏感性引导的块替换、代理蒸馏和基于设备性能分析的无训练多目标搜索，在保持竞争力的准确率同时显著降低计算开销和延迟。


<details>
  <summary>Details</summary>
Motivation: 移动图像信号处理中的去模糊任务需要在恢复精细结构和纹理与边缘设备实时约束之间取得平衡。现有深度网络（如Transformer和无激活架构）虽然达到SOTA准确率，但其效率通常用FLOPs或参数量衡量，这些指标与嵌入式硬件上的延迟不相关。

Method: 提出硬件感知适配框架，包含：1）敏感性引导的块替换；2）代理蒸馏；3）基于设备性能分析的无训练多目标搜索。以36块NAFNet为基线，通过该框架进行优化。

Result: 优化变体相比最近的Transformer-based SOTA减少55% GMACs，同时保持竞争力准确率。在设备上部署实现1.25倍延迟改进。在运动去模糊（GoPro）、散焦去模糊（DPDD）和辅助基准（RealBlur-J/R, HIDE）上验证了方法的通用性。

Conclusion: 反馈驱动的适配是弥合算法设计与部署就绪去模糊模型之间差距的原则性策略。

Abstract: Image deblurring is a critical stage in mobile image signal processing pipelines, where the ability to restore fine structures and textures must be balanced with real-time constraints on edge devices. While recent deep networks such as transformers and activation-free architectures achieve state-of-the-art (SOTA) accuracy, their efficiency is typically measured in FLOPs or parameters, which do not correlate with latency on embedded hardware. We propose a hardware-aware adaptation framework that restructures existing models through sensitivity-guided block substitution, surrogate distillation, and training-free multi-objective search driven by device profiling. Applied to the 36-block NAFNet baseline, the optimized variants achieve up to 55% reduction in GMACs compared to the recent transformer-based SOTA while maintaining competitive accuracy. Most importantly, on-device deployment yields a 1.25X latency improvement over the baseline. Experiments on motion deblurring (GoPro), defocus deblurring (DPDD), and auxiliary benchmarks (RealBlur-J/R, HIDE) demonstrate the generality of the approach, while comparisons with prior efficient baselines confirm its accuracy-efficiency trade-off. These results establish feedback-driven adaptation as a principled strategy for bridging the gap between algorithmic design and deployment-ready deblurring models.

</details>


### [548] [SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability](https://arxiv.org/abs/2601.12804)
*Hanwei Zhang,Luo Cheng,Rui Wen,Yang Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.AI

Relevance: 35.0

TL;DR: 提出SL-CBM模型，通过空间对齐的概念瓶颈模型增强可解释性，生成语义局部性的显著图，提高概念与图像区域的对应关系。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型(CBMs)存在局部忠实性问题，无法将概念与有意义的图像区域进行空间对齐，限制了可解释性和可靠性。需要一种能生成空间相干显著图的方法，增强概念与图像区域的对应关系。

Method: 提出SL-CBM，通过1x1卷积层和交叉注意力机制增强概念、图像区域和最终预测之间的对齐。使用对比性和基于熵的正则化来平衡准确性、稀疏性和忠实性。

Result: 在图像数据集上的实验表明，SL-CBM显著提高了局部忠实性、解释质量和干预效果，同时保持了竞争力的分类准确性。消融研究验证了正则化方法的重要性。

Conclusion: SL-CBM填补了概念推理与空间可解释性之间的空白，为可解释和可信赖的概念模型设立了新标准。

Abstract: Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.

</details>


### [549] [Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification](https://arxiv.org/abs/2601.13197)
*Aravind B,Anirud R. S.,Sai Surya Teja N,Bala Subrahmanya Sriranga Navaneeth A,Karthika R,Mohankumar N*

Main category: cs.CR

Relevance: 35.0

TL;DR: 本文提出使用TabDDPM（表格去噪扩散概率模型）对网络入侵检测中的类别不平衡问题进行数据增强，通过生成高质量少数类样本提升分类器性能


<details>
  <summary>Details</summary>
Motivation: 网络入侵检测数据集中存在严重的类别不平衡问题，某些攻击类别的样本数量远少于其他类别，导致模型对这些少数类攻击的检测性能较差。传统的数据增强方法在处理表格数据时效果有限，需要更有效的解决方案。

Method: 使用TabDDPM（表格去噪扩散概率模型）对CIC-IDS2017数据集中的少数类别进行数据增强。通过迭代去噪过程生成高质量合成样本，然后将这些合成样本与原始数据集合并，形成增强的训练数据集。最后使用ANN（人工神经网络）分类器进行训练和评估。

Result: 增强后的训练数据使ANN分类器在先前代表性不足的攻击类别上实现了接近完美的召回率。结果表明扩散模型在安全领域的表格数据不平衡问题中是一种有效的解决方案。

Conclusion: 扩散模型是解决表格数据类别不平衡问题的有效方法，在网络安全领域具有应用潜力，并可扩展到欺诈检测和医疗诊断等其他领域。

Abstract: Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than oth- ers, leading to biased model performance. Class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation is ad- dressed in this paper. Our approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. For the minority classes that have smaller samples, synthetic samples were generated and merged with the original dataset. The augmented training data enables an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. These results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.

</details>


### [550] [Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning](https://arxiv.org/abs/2601.13657)
*Myong-Yol Choi,Hankyoul Ko,Hanse Cho,Changseung Kim,Seunghwan Kim,Jaemin Seo,Hyondong Oh*

Main category: cs.RO

Relevance: 35.0

TL;DR: 基于深度强化学习的无人机群在无通信环境中的集体导航控制器，采用隐式领导者-跟随者框架，仅领导者拥有目标信息，跟随者通过LiDAR感知学习策略，无需通信或外部定位。


<details>
  <summary>Details</summary>
Motivation: 解决无人机群在通信受限环境中的集体导航问题，特别是在复杂障碍环境中。受生物群体行为的启发，设计无需显式通信的隐式领导-跟随机制，提高系统的鲁棒性和适应性。

Method: 采用深度强化学习控制器，基于LiDAR点云聚类和扩展卡尔曼滤波器进行邻居跟踪。在Nvidia Isaac Sim中进行GPU加速训练，使跟随无人机仅通过局部感知学习群体行为和避障策略。

Result: 通过大量仿真和真实世界实验验证了方法的鲁棒性和仿真到现实的迁移能力。五架无人机组成的群体成功在多样化的室内外环境中完成集体导航，无需任何通信或外部定位。

Conclusion: 提出了一种有效的无人机群集体导航解决方案，在无通信和外部定位条件下实现了鲁棒的群体行为，为通信受限环境中的自主群体系统提供了新思路。

Abstract: This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.

</details>


### [551] [Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments](https://arxiv.org/abs/2601.13846)
*Glinskaya Maria*

Main category: cs.AI

Relevance: 35.0

TL;DR: 论文提出Virtual Urbanism (VU)框架，使用多模态AI通过合成城市副本量化城市身份，以东京九个区域为案例验证可行性，获得约81%的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏计算上可处理的量化城市身份的方法，需要开发AI增强的城市分析框架来评估城市身份，为自动化多参数身份指标铺平道路。

Method: 整合Stable Diffusion和LoRA模型生成东京九个区域的合成城市序列，排除现有导向标记以提取核心身份形成元素，通过人类评估实验验证感知合法性、量化区域级身份、推导核心身份形成元素。

Result: 合成副本的平均识别准确率约81%，验证了有效性；Urban Identity Level (UIL)指标能评估不同区域的身份水平；语义分析揭示文化嵌入的类型学是核心身份形成元素。

Conclusion: VU是AI增强城市分析的可行框架，为自动化多参数身份指标提供了路径，展示了多模态AI在城市身份量化中的应用潜力。

Abstract: This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.

</details>


### [552] [Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration](https://arxiv.org/abs/2601.14235)
*LSST Dark Energy Science Collaboration,Eric Aubourg,Camille Avestruz,Matthew R. Becker,Biswajit Biswas,Rahul Biswas,Boris Bolliet,Adam S. Bolton,Clecio R. Bom,Raphaël Bonnet-Guerrini,Alexandre Boucaud,Jean-Eric Campagne,Chihway Chang,Aleksandra Ćiprijanović,Johann Cohen-Tanugi,Michael W. Coughlin,John Franklin Crenshaw,Juan C. Cuevas-Tello,Juan de Vicente,Seth W. Digel,Steven Dillmann,Mariano Javier de León Dominguez Romero,Alex Drlica-Wagner,Sydney Erickson,Alexander T. Gagliano,Christos Georgiou,Aritra Ghosh,Matthew Grayling,Kirill A. Grishin,Alan Heavens,Lindsay R. House,Mustapha Ishak,Wassim Kabalan,Arun Kannawadi,François Lanusse,C. Danielle Leonard,Pierre-François Léget,Michelle Lochner,Yao-Yuan Mao,Peter Melchior,Grant Merz,Martin Millon,Anais Möller,Gautham Narayan,Yuuki Omori,Hiranya Peiris,Laurence Perreault-Levasseur,Andrés A. Plazas Malagón,Nesar Ramachandra,Benjamin Remy,Cécile Roucelle,Jaime Ruiz-Zapatero,Stefan Schuldt,Ignacio Sevilla-Noarbe,Ved G. Shah,Tjitske Starkenburg,Stephen Thorp,Laura Toribio San Cipriano,Tilman Tröster,Roberto Trotta,Padma Venkatraman,Amanda Wasserman,Tim White,Justine Zeghal,Tianqing Zhang,Yuanyuan Zhang*

Main category: astro-ph.IM

Relevance: 35.0

TL;DR: LSST天文观测数据量巨大，传统分析面临挑战，DESC合作组需要AI/ML方法进行暗能量研究，但需解决不确定性量化、鲁棒性等可信AI问题，并探索基础模型和LLM智能体在科学工作流中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: LSST天文台将产生海量异构数据，传统分析流程难以应对。DESC合作组需要从这些数据中提取暗能量和暗物质的可靠约束，要求方法具有统计效力、可扩展性和操作可靠性。

Method: 调研DESC主要宇宙学探测和交叉分析中AI/ML的现状，识别跨领域挑战，提出关键方法研究重点：大规模贝叶斯推断、物理信息方法、验证框架、主动学习等，并探索基础模型和LLM智能体系统的应用潜力。

Result: 发现相同核心方法和基础挑战在不同科学案例中重复出现，跨领域挑战的进展将同时惠及多个探测。识别了关键方法研究重点，并探讨了基础模型和LLM智能体重塑工作流的潜力。

Conclusion: AI/ML在DESC科学工作流中已广泛应用，但用于精密宇宙学需要可信的不确定性量化、鲁棒性和可重复性。跨领域挑战的解决将推动多个探测的进展，基础模型和LLM智能体有潜力重塑工作流，但需严格评估和治理。

Abstract: The Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful, scalable, and operationally reliable. Artificial intelligence and machine learning (AI/ML) are already embedded across DESC science workflows, from photometric redshifts and transient classification to weak lensing inference and cosmological simulations. Yet their utility for precision cosmology hinges on trustworthy uncertainty quantification, robustness to covariate shift and model misspecification, and reproducible integration within scientific pipelines. This white paper surveys the current landscape of AI/ML across DESC's primary cosmological probes and cross-cutting analyses, revealing that the same core methodologies and fundamental challenges recur across disparate science cases. Since progress on these cross-cutting challenges would benefit multiple probes simultaneously, we identify key methodological research priorities, including Bayesian inference at scale, physics-informed methods, validation frameworks, and active learning for discovery. With an eye on emerging techniques, we also explore the potential of the latest foundation model methodologies and LLM-driven agentic AI systems to reshape DESC workflows, provided their deployment is coupled with rigorous evaluation and governance. Finally, we discuss critical software, computing, data infrastructure, and human capital requirements for the successful deployment of these new methodologies, and consider associated risks and opportunities for broader coordination with external actors.

</details>


### [553] [Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis](https://arxiv.org/abs/2601.13558)
*Mehrab Beikzadeh,Chenglin Hong,Cory J Cascalheira,Callisto Boka,Majid Sarrafzadeh,Ian W Holloway*

Main category: cs.AI

Relevance: 30.0

TL;DR: 利用社交媒体和约会应用文本数据，通过ChatGPT嵌入、BERT嵌入等机器学习方法预测男男性行为者的性风险行为、酒精使用和PrEP使用情况


<details>
  <summary>Details</summary>
Motivation: 男男性行为者面临较高的性传播感染和有害饮酒风险，社交媒体和约会应用的文本数据可能为个性化公共卫生干预提供新机会，通过自动识别风险和保护行为来支持公共卫生项目

Method: 收集参与者社交媒体和约会应用文本数据，使用ChatGPT嵌入、BERT嵌入、LIWC（语言查询和词数统计）和基于词典的风险术语方法提取特征，训练机器学习模型预测性风险行为、酒精使用和PrEP使用

Result: 模型在预测每月暴饮和超过5个性伴侣方面表现优异（F1分数0.78），在预测PrEP使用和重度饮酒方面表现中等（F1分数分别为0.64和0.63）

Conclusion: 社交媒体和约会应用文本数据能够提供关于风险和保护行为的宝贵见解，基于大语言模型的方法有潜力支持针对男男性行为者的可扩展和个性化公共卫生干预

Abstract: Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.

</details>


### [554] [Let Me Try Again: Examining Replay Behavior by Tracing Students' Latent Problem-Solving Pathways](https://arxiv.org/abs/2601.11586)
*Shan Zhang,Siddhartha Pradhan,Ji-Eun Lee,Ashish Gurung,Anthony F. Botelho*

Main category: cs.CY

Relevance: 25.0

TL;DR: 研究使用马尔可夫链和隐马尔可夫模型分析游戏学习平台中学生的重播行为，发现即时重播对学习有积极影响，而延迟重播效果较弱或负面。


<details>
  <summary>Details</summary>
Motivation: 虽然先前研究表明学生在游戏学习环境中的问题解决路径反映其概念理解和程序知识，重播行为可能表明生产性挣扎或探索，但缺乏对这些路径如何跨问题顺序展开以及重播时机与学习结果关系的研究。

Method: 使用马尔可夫链和隐马尔可夫模型分析777名七年级学生在From Here to There!游戏学习平台上的日志数据，识别问题解决状态和模式。

Result: 发现四个潜在状态：不完整主导、最优结束、重播和混合状态；即时重播一致支持学习结果，而延迟重播与非重播相比关联较弱或负面；重播主导和最优结束状态预测更高的概念知识、灵活性和表现。

Conclusion: 数字学习中的重播并非普遍有益，其效果取决于时机，即时重播支持灵活性和更有效的探索。

Abstract: Prior research has shown that students' problem-solving pathways in game-based learning environments reflect their conceptual understanding, procedural knowledge, and flexibility. Replay behaviors, in particular, may indicate productive struggle or broader exploration, which in turn foster deeper learning. However, little is known about how these pathways unfold sequentially across problems or how the timing of replays and other problem-solving strategies relates to proximal and distal learning outcomes. This study addresses these gaps using Markov Chains and Hidden Markov Models (HMMs) on log data from 777 seventh graders playing the game-based learning platform of From Here to There!. Results show that within problem sequences, students often persisted in states or engaged in immediate replay after successful completions, while across problems, strong self-transitions indicated stable strategic pathways. Four latent states emerged from HMMs: Incomplete-dominant, Optimal-ending, Replay, and Mixed. Regression analyses revealed that engagement in replay-dominant and optimal-ending states predicted higher conceptual knowledge, flexibility, and performance compared with the Incomplete-dominant state. Immediate replay consistently supported learning outcomes, whereas delayed replay was weakly or negatively associated in relation to Non-Replay. These findings suggest that replay in digital learning is not uniformly beneficial but depends on timing, with immediate replay supporting flexibility and more productive exploration.

</details>


### [555] [Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music](https://arxiv.org/abs/2601.11768)
*Venkat Suprabath Bitra,Homayoon Beigi*

Main category: eess.AS

Relevance: 25.0

TL;DR: 提出一种轻量级、完全自监督的基频估计和发声检测框架，通过转置等变学习和EM式迭代重加权方案，无需大量标注数据即可实现单乐器快速训练。


<details>
  <summary>Details</summary>
Motivation: 传统基频提取器依赖大量标注数据，在真实录音环境下性能下降。需要一种轻量级、自监督的方法，能够在有限音频数据上快速训练，并处理录音伪影问题。

Method: 使用CQT特征进行转置等变学习，提出基于Shift Cross-Entropy（SCE）一致性的EM式迭代重加权方案，抑制无信息噪声/无声帧，生成置信度分数用于伪标注训练轻量级发声分类器。

Result: 在MedleyDB上训练，MDB-stem-synth上评估，获得竞争性跨语料库性能（RPA 95.84，RCA 96.24），并展示了跨乐器泛化能力。

Conclusion: 该方法提供了一种有效的自监督基频估计和发声检测解决方案，无需大量标注数据，在有限音频上快速训练，具有良好的泛化性能。

Abstract: Reliable fundamental frequency (F 0) and voicing estimation is essential for neural synthesis, yet many pitch extractors depend on large labeled corpora and degrade under realistic recording artifacts. We propose a lightweight, fully self-supervised framework for joint F 0 estimation and voicing inference, designed for rapid single-instrument training from limited audio. Using transposition-equivariant learning on CQT features, we introduce an EM-style iterative reweighting scheme that uses Shift Cross-Entropy (SCE) consistency as a reliability signal to suppress uninformative noisy/unvoiced frames. The resulting weights provide confidence scores that enable pseudo-labeling for a separate lightweight voicing classifier without manual annotations. Trained on MedleyDB and evaluated on MDB-stem-synth ground truth, our method achieves competitive cross-corpus performance (RPA 95.84, RCA 96.24) and demonstrates cross-instrument generalization.

</details>


### [556] [The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing](https://arxiv.org/abs/2601.13487)
*Olivia Pal,Agam Goyal,Eshwar Chandrasekharan,Koustuv Saha*

Main category: cs.SI

Relevance: 25.0

TL;DR: 研究发现社交媒体新闻消费存在系统性权衡：增加抑郁、压力和焦虑，但减少孤独感并增加平台社交互动；书签功能比评论或引用带来更严重的心理社会恶化


<details>
  <summary>Details</summary>
Motivation: 社交媒体新闻消费普遍，但不同形式的参与如何影响心理社会结果尚不清楚。研究旨在填补这一空白，了解新闻参与对心理社会福祉的影响

Method: 利用BlueSky平台约2600万帖子和4500万评论的大规模数据集，进行准实验研究，通过分层倾向得分分析匹配81,345名暴露于新闻源的"处理组"用户和83,711名"对照组"用户

Result: 新闻参与产生系统性权衡：增加抑郁、压力和焦虑，但减少孤独感并增加平台社交互动。回归模型显示，新闻源书签比评论或引用带来更严重的心理社会恶化，差异超过十倍

Conclusion: 研究扩展了新闻效应理论，表明常规消费根据参与类型产生不同的心理动态，对减轻社交媒体新闻消费心理社会成本的工具和干预措施具有重要意义

Abstract: News consumption on social media has become ubiquitous, yet how different forms of engagement shape psychosocial outcomes remains unclear. To address this gap, we leveraged a large-scale dataset of ~26M posts and ~45M comments on the BlueSky platform, and conducted a quasi-experimental study, matching 81,345 Treated users exposed to News feeds with 83,711 Control users using stratified propensity score analysis. We examined psychosocial wellbeing, in terms of affective, behavioral, and cognitive outcomes. Our findings reveal that news engagement produces systematic trade-offs: increased depression, stress, and anxiety, yet decreased loneliness and increased social interaction on the platform. Regression models reveal that News feed bookmarking is associated with greater psychosocial deterioration compared to commenting or quoting, with magnitude differences exceeding tenfold. These per-engagement effects accumulate with repeated exposure, showing significant psychosocial impacts. Our work extends theories of news effects beyond crisis-centric frameworks by demonstrating that routine consumption creates distinct psychological dynamics depending on engagement type, and bears implications for tools and interventions for mitigating the psychosocial costs of news consumption on social media.

</details>


### [557] [Asymmetric regularization mechanism for GAN training with Variational Inequalities](https://arxiv.org/abs/2601.13920)
*Spyridon C. Giagtzoglou,Mark H. M. Winands,Barbara Franci*

Main category: cs.GT

Relevance: 25.0

TL;DR: 该论文将GAN训练公式化为纳什均衡寻求问题，提出基于Tikhonov步长和零中心梯度惩罚的非对称正则化机制来稳定训练，在特定条件下获得显式Lipschitz和强单调性常数，保证单次调用EFTP方法的最后迭代线性收敛。


<details>
  <summary>Details</summary>
Motivation: 生成对抗网络（GAN）训练存在不稳定性和收敛困难的问题，传统方法难以保证收敛到纳什均衡。作者旨在将GAN训练形式化为纳什均衡寻求问题，并提出稳定训练的理论框架。

Method: 提出非对称正则化机制，结合经典Tikhonov步长和新型零中心梯度惩罚。在由高斯-牛顿Gramian诱导的光滑性和局部可识别性条件下，推导正则化算子的显式Lipschitz和强单调性常数，并应用单次调用EFTP方法。

Result: 理论分析表明，在满足条件时能保证最后迭代线性收敛。即使无法实现强单调性，非对称正则化仍能收敛到均衡并稳定轨迹，学术示例的实证模拟验证了方法的有效性。

Conclusion: 该研究为GAN训练提供了理论保证的稳定化方法，将GAN训练形式化为纳什均衡问题并通过非对称正则化机制解决收敛问题，为对抗性训练提供了新的理论框架。

Abstract: We formulate the training of generative adversarial networks (GANs) as a Nash equilibrium seeking problem. To stabilize the training process and find a Nash equilibrium, we propose an asymmetric regularization mechanism based on the classic Tikhonov step and on a novel zero-centered gradient penalty. Under smoothness and a local identifiability condition induced by a Gauss-Newton Gramian, we obtain explicit Lipschitz and (strong)-monotonicity constants for the regularized operator. These constants ensure last-iterate linear convergence of a single-call Extrapolation-from-the-Past (EFTP) method. Empirical simulations on an academic example show that, even when strong monotonicity cannot be achieved, the asymmetric regularization is enough to converge to an equilibrium and stabilize the trajectory.

</details>


### [558] [Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding](https://arxiv.org/abs/2601.11713)
*Rodney Martinez Alonso,Cel Thys,Cedric Dehos,Yuneisy Esthela Garcia Guzman,Sofie Pollin*

Main category: eess.SP

Relevance: 15.0

TL;DR: 提出一种用于超宽带通信系统的端到端无线自编码器架构，在沃尔什域中联合优化发射机和接收机编码/解码，以抑制来自共存窄带5G基站的干扰。


<details>
  <summary>Details</summary>
Motivation: 超宽带通信系统面临来自共存窄带5G基站的带内部分干扰问题，传统方法难以有效抑制这种干扰，需要新的干扰抑制技术。

Method: 设计端到端无线自编码器架构，利用沃尔什函数的正交性和自逆特性，在沃尔什域中并行分支编码比特字，联合优化发射机和接收机。

Result: 通过分析和仿真，确定了传输频率与采样率的最优比例，实验结果显示该自编码器在相同基线信道噪声下，实现了高达12 dB的干扰抑制，同时保持低块错误率。

Conclusion: 提出的沃尔什域端到端自编码器架构能有效抑制5G基站对超宽带系统的干扰，为无线通信干扰抑制提供了新方法。

Abstract: This paper proposes a novel technique for rejecting partial-in-band inter-cell interference (ICI) in ultrawideband communication systems. We present the design of an end-to-end wireless autoencoder architecture that jointly optimizes the transmitter and receiver encoding/decoding in the Walsh domain to mitigate interference from coexisting narrower-band 5G base stations. By exploiting the orthogonality and self-inverse properties of Walsh functions, the system distributes and learns to encode bit-words across parallel Walsh branches. Through analytical modeling and simulation, we characterize how 5G CPOFDM interference maps into the Walsh domain and identify optimal ratios of transmission frequencies and sampling rate where the end-to-end autoencoder achieves the highest rejection. Experimental results show that the proposed autoencoder achieves up to 12 dB of ICI rejection while maintaining a low block error rate (BLER) for the same baseline channel noise, i.e., baseline Signal-to-Noise-Ratio (SNR) without the interference.

</details>


### [559] [Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning](https://arxiv.org/abs/2601.12242)
*WooSeok Kim,Jeonghoon Lee,Sangho Kim,Taesun An,WonMin Lee,Dowon Kim,Kyungseop Shin*

Main category: cs.AI

Relevance: 15.0

TL;DR: 本文提出了一种结合回放记忆的深度强化学习框架，用于NOMA系统中的网络资源分配，以解决信道分配问题并实现泛化学习。


<details>
  <summary>Details</summary>
Motivation: 随着物联网(IoT)的扩展导致网络资源稀缺，需要优化网络资源利用。NOMA系统通过功率复用允许多用户同时接入，但存在信道分配问题需要进一步研究。

Method: 提出一个结合回放记忆的深度强化学习框架，采用on-policy算法，在NOMA系统中分配网络资源以实现学习泛化。通过模拟评估学习率、批量大小、模型类型和状态特征数量的影响。

Result: 通过广泛的模拟实验，评估了不同学习率、批量大小、模型类型和状态特征数量对资源分配性能的影响。

Conclusion: 提出的深度强化学习框架能够有效解决NOMA系统中的信道分配问题，并通过回放记忆机制实现更好的学习泛化。

Abstract: In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation(JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.

</details>


### [560] [Pigment Network Detection and Classification in Dermoscopic Images Using Directional Imaging Algorithms and Convolutional Neural Networks](https://arxiv.org/abs/2601.11674)
*M. A. Rasel,Sameem Abdul Kareem,Unaizah Obaidellah*

Main category: eess.IV

Relevance: 15.0

TL;DR: 该研究提出了一种结合方向性成像算法和CNN的自动化方法，用于检测和分类皮肤镜图像中的色素网络（PN），以辅助黑色素瘤的早期诊断。


<details>
  <summary>Details</summary>
Motivation: 黑色素瘤的早期诊断依赖于皮肤镜图像分析，其中色素网络（PN）的识别是关键诊断标准。然而，区分规则（典型）和不规则（非典型）PN具有挑战性，需要自动化方法来提高诊断效率和准确性。

Method: 1. 方向性成像算法：结合PCA、对比度增强、滤波和噪声减少技术，用于PN检测
2. 数据集构建：从PH2数据集中提取PN图像，创建包含200张图像的新数据集
3. 分类器设计：采用CNN（包含两个卷积层和两个批归一化层）和Bag of Features两种分类器
4. 分类任务：将PN分为非典型（不规则）和典型（规则）两类

Result: 1. 方向性成像算法在PH2数据集上达到96%成功率，像素强度调整后提升至100%
2. 提出的CNN模型在PN分类任务中达到90%准确率、90%灵敏度和89%特异性
3. 与现有最先进方法相比，该CNN表现出更优性能

Conclusion: 该研究证明了所提出的CNN模型在PN分类中的有效性，为黑色素瘤诊断提供了有前景的自动化工具。未来研究应关注扩大数据集和整合更多皮肤学特征以进一步提升诊断性能。

Abstract: Early diagnosis of melanoma, which can save thousands of lives, relies heavily on the analysis of dermoscopic images. One crucial diagnostic criterion is the identification of unusual pigment network (PN). However, distinguishing between regular (typical) and irregular (atypical) PN is challenging. This study aims to automate the PN detection process using a directional imaging algorithm and classify PN types using machine learning classifiers. The directional imaging algorithm incorporates Principal Component Analysis (PCA), contrast enhancement, filtering, and noise reduction. Applied to the PH2 dataset, this algorithm achieved a 96% success rate, which increased to 100% after pixel intensity adjustments. We created a new dataset containing only PN images from these results. We then employed two classifiers, Convolutional Neural Network (CNN) and Bag of Features (BoF), to categorize PN into atypical and typical classes. Given the limited dataset of 200 images, a simple and effective CNN was designed, featuring two convolutional layers and two batch normalization layers. The proposed CNN achieved 90% accuracy, 90% sensitivity, and 89% specificity. When compared to state-of-the-art methods, our CNN demonstrated superior performance. Our study highlights the potential of the proposed CNN model for effective PN classification, suggesting future research should focus on expanding datasets and incorporating additional dermatological features to further enhance melanoma diagnosis.

</details>


### [561] [AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal](https://arxiv.org/abs/2601.11876)
*Christopher Kao,Akhil Pathapati,James Davis*

Main category: cs.RO

Relevance: 15.0

TL;DR: 本文提出了一种用于公园草地自主导航、识别和拾取垃圾的机器人系统，结合了STC路径规划、RTK GPS定位、ResNet50视觉识别和专用拾取机制，实现了80%的整体成功率。


<details>
  <summary>Details</summary>
Motivation: 美国有500亿件垃圾，公园草地上的野餐者经常留下垃圾，造成严重的环境污染问题。需要自动化解决方案来清理公园草地上的垃圾。

Method: 1) 使用生成树覆盖(STC)算法生成覆盖路径；2) 采用实时动态(RTK)GPS进行厘米级精确定位导航；3) 使用ResNet50卷积神经网络进行垃圾识别(准确率94.52%)；4) 设计专门针对草地垃圾的拾取机制。

Result: 系统整体成功率达到80%，证明了自主垃圾拾取机器人在草地环境中的可行性。ResNet50的垃圾检测准确率为94.52%。

Conclusion: 自主垃圾拾取机器人是解决公园草地垃圾问题的可行方案，通过STC路径规划、RTK GPS导航、ResNet50视觉识别和专用拾取机制的有效集成，实现了较高的整体性能。

Abstract: There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution.

</details>


### [562] [Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data](https://arxiv.org/abs/2601.12856)
*Liping Huang,Gaoxi Xiao,Stefan Ma,Hechang Chen,Shisong Tang,Flora Salim*

Main category: cs.AI

Relevance: 15.0

TL;DR: 提出一个新颖的框架，通过挖掘公开登革热病例数据中的潜在传播链接，预测城市地区的登革热传播风险，该框架利用梯度下降优化隐藏传播网络，并与人类通勤流动对齐，提供可解释的传播解释。


<details>
  <summary>Details</summary>
Motivation: 登革热在热带城市地区持续构成公共卫生挑战。现有方法通常将病例视为孤立报告，缺乏对区域间潜在传播链接的挖掘。需要一种能够主动预测传播风险而非被动响应的工具，以支持早期干预和公共卫生规划。

Method: 提出一个新颖框架，从公开登革热病例数据中挖掘区域间的潜在传播链接。通过梯度下降优化隐藏传播网络，建模热点区域形成如何受邻近区域流行病动态影响。框架不仅预测热点状态，还通过检查推断网络在连续周内的稳定性来验证传播模式的一致性。

Result: 在新加坡2013-2018年和2020年的案例研究中，仅需四周热点历史数据即可达到平均F分数0.79。学习到的传播链接与通勤流动高度一致，揭示了隐藏流行病传播与人类移动性之间的可解释相互作用。

Conclusion: 该框架将公开病例数据转化为预测性和解释性资源，推进了流行病建模，为公共卫生规划、早期干预和城市韧性提供了可扩展、低成本的工具。通过从简单报告病例转向挖掘和验证隐藏传播动态，实现了更主动的疾病控制策略。

Abstract: Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.

</details>


### [563] ['1'-bit Count-based Sorting Unit to Reduce Link Power in DNN Accelerators](https://arxiv.org/abs/2601.14087)
*Ruichi Han,Yizhi Chen,Tong Lei,Jordi Altayo Gonzalez,Ahmed Hemani*

Main category: cs.AR

Relevance: 15.0

TL;DR: 该论文提出了一种针对CNN优化的免比较排序单元硬件实现，通过近似计算将人口计数分组到粗粒度桶中，在保持数据重排序链路功耗优势的同时减少硬件面积。


<details>
  <summary>Details</summary>
Motivation: 互连功耗仍然是深度神经网络加速器的瓶颈。虽然基于'1'位计数的数据排序可以通过减少切换活动来缓解这一问题，但实用的硬件排序实现仍未得到充分探索。

Method: 提出硬件实现的免比较排序单元，专为卷积神经网络优化。利用近似计算将人口计数分组到粗粒度桶中，在保持数据重排序链路功耗优势的同时减少硬件面积。

Result: 近似排序单元实现了高达35.4%的面积减少，同时保持了19.50%的BT减少，而精确实现的BT减少为20.42%。

Conclusion: 该工作展示了通过近似计算实现硬件高效的排序单元，在保持互连功耗优势的同时显著减少硬件面积，为DNN加速器的互连功耗优化提供了实用解决方案。

Abstract: Interconnect power consumption remains a bottleneck in Deep Neural Network (DNN) accelerators. While ordering data based on '1'-bit counts can mitigate this via reduced switching activity, practical hardware sorting implementations remain underexplored. This work proposes the hardware implementation of a comparison-free sorting unit optimized for Convolutional Neural Networks (CNN). By leveraging approximate computing to group population counts into coarse-grained buckets, our design achieves hardware area reductions while preserving the link power benefits of data reordering. Our approximate sorting unit achieves up to 35.4% area reduction while maintaining 19.50\% BT reduction compared to 20.42% of precise implementation.

</details>


### [564] ["Jutters"](https://arxiv.org/abs/2601.11532)
*Meike Driessen,Selina Khan,Gonçalo Marcelino*

Main category: cs.HC

Relevance: 10.0

TL;DR: 这是一个艺术装置项目，将AI生成内容比作海岸冲积物，邀请参观者像荷兰海岸拾荒者一样筛选和反思AI媒体


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容越来越多地影响我们的生活，该项目旨在通过艺术装置的形式，让人们以更审慎的态度对待AI媒体，将其视为反思的材料而非被动消费的内容

Method: 创建一个海滩式艺术装置，混合真实的海岸碎片与AI转换的图像和视频，让参观者扮演当代"jutter"（荷兰海岸拾荒者），在空间中探索并决定保留或丢弃哪些内容

Result: 该项目通过艺术体验重新构想了AI图像作为反思材料，鼓励人们对社交媒体流中的内容进行更有辨别力的参与

Conclusion: AI生成内容应被视为可供批判性反思的材料，而非仅仅是消费对象；通过艺术装置的形式可以促进人们对AI媒体的更深入思考

Abstract: This project explores how we engage with AI-generated content through the lens of the jutter: Dutch coastal foragers who comb the shoreline after storms, gathering and repurposing what the sea leaves behind. Reflecting how our lives are increasingly shaped by AI-generated media, we create a beach-like installation that blends real shoreline debris with AI-transformed images and videos. Visitors are invited to explore this space as contemporary jutters, deciding what to keep and what to discard. In doing so, the project reimagines AI-imagery as material for reflection, encouraging a more discerning engagement with the content that drifts through our feeds. A video preview of the installation can be found at https://www.youtube.com/watch?v=L6319Ii7MT8.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [565] [GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment](https://arxiv.org/abs/2601.11574)
*Lukas Abrie Nel*

Main category: cs.LG

Relevance: 95.0

TL;DR: GRADE是一种用于LLM对齐的新方法，用可微分的Gumbel-Softmax松弛替代高方差的策略梯度方法，显著降低梯度方差并提升性能


<details>
  <summary>Details</summary>
Motivation: RLHF已成为对齐LLM的主流方法，但PPO等策略梯度方法存在梯度方差高、需要精细调参和大量计算资源的问题，需要更稳定高效的对齐方法

Method: GRADE使用Gumbel-Softmax重参数化配合直通估计（GRADE-STE），通过离散token采样过程的可微分松弛实现端到端梯度传播，替代传统的策略梯度估计

Result: 在IMDB情感控制文本生成任务中，GRADE-STE获得0.763的测试奖励，比PPO（0.510）和REINFORCE（0.617）分别提升50%和23%，梯度方差比REINFORCE低14倍以上，训练更稳定

Conclusion: GRADE为LLM对齐提供了更简单、更稳定、更有效的强化学习替代方案，具有良好的泛化特性

Abstract: Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.

</details>


### [566] [LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems](https://arxiv.org/abs/2601.14053)
*Badri N. Patro,Vijay S. Agneeswaran*

Main category: cs.LG

Relevance: 95.0

TL;DR: LLMOrbit 是一个全面的循环分类法，涵盖了2019-2025年的大语言模型发展，分析了50多个模型，识别了三大危机（数据稀缺、成本增长、能耗问题）和六大突破范式，揭示了三个范式转变。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在系统梳理大语言模型的发展脉络，从Transformer架构到接近人类水平的推理系统。通过建立循环分类法，帮助研究人员理解LLM领域的架构创新、训练方法和效率模式，同时识别当前面临的规模化瓶颈和突破路径。

Method: 采用LLMOrbit循环分类法，通过八个相互关联的轨道维度分析50多个模型和15个组织。该方法从多个角度（架构、训练、效率等）系统性地考察LLM发展，并识别关键趋势和模式。

Result: 识别了三大危机：数据稀缺（2026-2028年耗尽9-27T tokens）、成本指数增长（5年内从300万美元到3亿美元以上）、能耗不可持续（增加22倍）。同时发现了六大突破范式：测试时计算、量化、分布式边缘计算、模型融合、高效训练、小型专用模型。揭示了三个范式转变：训练后增益、效率革命、民主化。

Conclusion: LLM发展面临规模化瓶颈，但通过测试时计算、效率优化和开源民主化等创新范式可以突破限制。未来趋势包括从被动生成向工具使用代理的演进，以及训练后技术（如RLHF）的重要性日益凸显。

Abstract: The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.

</details>


### [567] [The Llama 4 Herd: Architecture, Training, Evaluation, and Deployment Notes](https://arxiv.org/abs/2601.11659)
*Aaron Adcock,Aayushi Srivastava,Abhimanyu Dubey,Abhinav Jauhri,Abhinav Pande,Abhinav Pandey,Abhinav Sharma,Abhishek Kadian,Abhishek Kumawat,Adam Kelsey,Adam Stelle,Adeel Cheema,Adela Kabiljo,Adina Katz,Adithya Gangidi,Aditya Tayade,Adolfo Victoria,Adrian Samatan Alastuey,Adrien Conrath,Afroz Mohiuddin,Ahmed Sharif,Ahnaf Siddiqui,Ahuva Goldstand,Aijung Li,Aidan Boyd,Aidin Kazemi Daliri,Aisha Iqbal,Ajay Menon,Ajit Mathews,Akhil Mathur,Akshat Agarwal,Alan Schelten,Alana Shine,Alejandro Castillejo Muñoz,Aleksei Guliaev,Alex Radovic,Alex Song,Alex Vaughan,Alexander Simeonov,Alexandre Rezende,Alexandre Rezende,Alexei Baevski,Alexey Roubaud,Allen Ma,Alvin Lee,Alyssa Pereira,Aman Ahmed,Aman Shankar,Amanda Kallet,Amar Budhiraja,Ameya Khandekar,Amine Benhalloum,Amir Gershman,Amit Nagpal,Amit Zohar,Amr Sharaf,Anant Desai,Anastasia Razdaibiedina,Anca Agape,Andranik Kurghinyan,Andre Perunicic,Andrea Madotto,Andrei Darabanov,Andrés Alvarado,Andrew Brown,Andrew Cohen,Andrew Fang,Andrew Freeman,Andrew Gallagher,Andrew Gu,Andrew Prasetyo Jo,Andrew Ryan,Andrew Steffen,Andrew Wei,Andrey Rusakov,Andrii Golovei,Andy Shang,Angela Fan,Angela Fan,Angela Flewellen,Animesh Pathak,Anirudh Goyal,Ankit Ramchandani,Ankur Pai,Ankur Singh,Ankush Garg,Anlu Xing,Anna Cai,Anna Grosul,Anna Prochowska,Anna Sun,Annie Dong,Annie Franco,Anqi Hu,Anshul Chawla,Anthony Hartshorn,Antonia Sheng,Antony Thomas,Anuj Goyal,Anusha De,Anvit Bodiwala,Anvit Bodiwala,Aobo Yang,Aparajita Saraf,Apurva Samudra,Aran Mun,Arash Rahnama,Archi Mitra,Archie Sravankumar,Archit Gupta,Aria Haghighi,Ariel Stolerman,Arkabandhu Chowdhury,Arnab Choudhury,Artem Korenev,Arthur Guo,Arthur Hinsvark,Arun Mallya,Arvind Neelakantan,Arya Talebzadeh,Ashish Shah,Ashmitha Jeevaraj Shetty,Ashwin Bharambe,Asif Islam,Aston Zhang,Austen Gregerson,Avi Lewis,Aya Ibrahim,Ayaz Minhas,Ayelet Dahan,Ayelet Regev Dabah,Bangsheng Tang,Bar Ulman,Bardiya Sadeghi,Bartosz Jedrzejewski,Barys Skarabahaty,Beibei Zhu,Beibin Li,Ben Bharier,Benjamin Leonhardi,Benjamin Muller,Bennett Plessala,Bernie Huang,Beth Loyd,Bhargavi Paranjape,Bhavik Sheth,Bill Bonner,Bill Holland,Bill Wang,Bingzhe Liu,Binh Tang,Bo Liu,Bo Wu,Boduo Li,Bokai Yu,Bor-Chun Chen,Boris Araya,Boris Vidolov,Botao Chen,Boya Peng,Boyu Ni,Bradley Davis,Bram Wasti,Brandon Adams,Brandon Taylor,Brandon Wu,Brant Swidler,Brian Chiang,Brian Clerkin,Brian Fuller,Brooks Cutter,Bruno Novais,Bryan Gmyrek,Bysshe Easton,Cait Campos,Canaan Case,Carl Chengyan Fu,Carly Burton,Caro Diaz,Catherine Cole,Ce Liu,Cedric Fougerat,Cen Peng,Cen Peng,Cen Zhao,Changhan Wang,Changkyu Kim,Chantal Shaib,Chao Zhou,Charlotte Caucheteux,Chau Nguyen,Chawin Sitawarin,Chaya Nayak,Chelsea Asher,Chen Fan,Chen Zhu,Cheng Cheng,Cheng Zhang,Chenguang Zhu,Chengxiong Ruan,Chengzhu Yu,Chenheli Hua,Chenxi Whitehouse,Cheryl Holloway,Ching-Hsiang Chu,Ching-Yao Chuang,Chinmay Karande,Chirag Nagpal,Chloé Bakalar,Chloe Bi,Chris Cai,Chris Marra,Chris McConnell,Chris Thi,Chris Tindal,Chris Waterson,Christian Deverall,Christian Fuegen,Christian Keller,Christine Cheng,Christine Jou,Christine Smith,Christine Wang,Christoph Feichtenhofer,Christophe Touret,Christopher Luc,Christy Sauper,Chuanhao Zhuge,Chun-Yi Sung,Chunqiang Tang,Chunyang Wu,Clara Siegel,Cody Heale,Cody Wilbourn,Colin White,Congying Xia,Corinne Wong,Cornel Rat,Cristian Canton Ferrer,Cyrille Habis,Cyrus Nikolaidis,D Lohachov,Da Ju,Dalton Flanagan,Damien Allonsius,Damon Civin,Dan Johnson,Daniel Bolya,Daniel Francisco,Daniel Fried,Daniel Hawthorne,Daniel Haziza,Daniel Ho,Daniel Kreymer,Daniel Li,Daniel Machlab,Daniel McKinnon,Daniel Obenshain,Daniel Rodriguez,Daniel Song,Daniel Tse,Danielle Pintz,Danny Livshits,Daryl James Rodrigo,Dat Huynh,Daulet Askarov,David Brandfonbrener,David Esiobu,David Kant,David Levin,David Renardy,David Soofian,David Stevens,David Xu,David Zhang,Deep Shah,Delia David,Demi Douglas,Denis Boyda,Desh Raj,Devamanyu Hazarika,Dheeraj Mekala,Dhruv Choudhary,Dhruv Mahajan,Di Jin,Didac Suris Coll-Vinent,Didem Foss,Diego Garcia-Olano,Diego Perino,Dieuwke Hupkes,DiJia Su,Dilip Madathil,Dinesh Govindasamy,Dinesh Yeduguru,Dmitry Vengertsev,Dong He,Dong Li,Dong Wang,Dongzhuo Li,Duc Le,Dunant Hin,Dustin Holland,Duy Nguyen,Duy Nguyen,Ed Dowling,Eden Litt,Egor Lakomkin,Ehab AlBadawy,Ehsan K. Ardestani,Elad Eckstein,Elahe Dabir,Elaine Montgomery,Elina Lobanova,Elior Abramoviz,Eliot Hedeman,Elissa Li,Elizabeth Hilbert,Ellen Xiaoqing Tan,Elliot Yun,Elodie Stener,Emilian Stoimenov,Emilien Garreau,Emily Dinan,Emily Hahn,Emily Wood,Emma Li,Emmanuel Ademuwagun,Emrah Seker,Eric Alamillo,Eric Gan,Eric Han,Eric Huang,Eric Michael Smith,Eric-Tuan Le,Ernie Chang,Eryk Helenowski,Eslam Elnikety,Esteban Arcaute,Ethan Myers,Eugene Nho,Eugene Poliukhovych,Evan Dunbar,Evgeniy Litvinenko,Evrim Altıntaş,Eyal Hochman,Eyal Shtrauch,Fabian Mastenbroek,Faiza Zeb,Faizan Ahmad,Farhad Farahbakhshian,Fei Kou,Fei Sun,Feiyu Chen,Felix Chung,Feng Tian,Feng Xu,Filip Radenovic,Filippos Kokkinos,Francesco Barbieri,Francesco Caggioni,Francisco Esparza,Francisco Guzmán,Frank Kanayet,Frank Seide,Frank Zhang,Fred Lewis,Freda Huang,Fulton Wang,Gabriel Synnaeve,Gabriela Jacques-Silva,Gabriella Schwarz,Gaganjit Ghardhora,Gal Elfer,Garrett Dickson,Gaurav Chaurasia,Gautam Sewani,Geet Shingi,Gefei Zuo,Geonhwa Jeong,George Puthanpurackal,Georgia Swee,Gerard Moreno-Torres Bertran,Gil Keren,Gina Ling,Gjergji Stasa,Gobinda Saha,Gor Safran,Gordy French,Goutham Rajendran,Govind Thattai,Grace Cineas,Graeme Nail,Greg Fletcher,Grégoire Mialon,Griffin Adams,Grigory Sizov,Guan Pang,Hady Elsahar,Hai Dang Tran,Hailey Nguyen,Haiping Wu,Hakan Inan,Hamid Eghbalzadeh,Han Fang,Han Zou,Hannah Doyle,Hannah Korevaar,Hannah Wang,Hannah Werbel,Hanwen Zha,Hany Morsy,Hao Ma,Haoci Zhang,Haonan Sun,Haozhu Wang,Hardik Shah,Haroun Habeeb,Harrison Rudolph,Harsh Gupta,Harsh Poddar,Harshil Parikh,Hejia Zhang,Heming Wang,Hengduo Li,Himanshu Sharma,Hoang Phi Nguyen,Hongbo Zhang,Honghao Qiu,Hongjiang Lv,Hongli Xu,Hongyuan Zhan,Hossein Hamooni,Howard Huang,Hu Xu,Hugo Laurençon,Hugo Touvron,Hung Dinh,Hunter Goldman,Hussein Mehanna,Huy Nguyen,Hweimi Tsuo,Ian Graves,Ian Yu,Ibrahim Damlaj,Idan Cohen,Igor Tufanov,Ilan Goldenstein,Ilias Leontiadis,Iliyan Zarov,Imad Ahmed,Innocent Djiofack,Iosif Spulber,Irina-Elena Veliche,Isabella Ramos,Ishan Misra,Itai Gal,Ivan Evtimov,Ivan Evtimov,Ivan Obraztsov,Jack Wu,Jacqueline Romero Vertino,Jaemo Koo,Jaewon Lee,Jake Jung,Jake Weissman,James Beldock,James Crnkovich,James Grinage,James Hongyi Zeng,James Kohli,James Tian,Jamie Cahill,Jan Geffert,Jan Seidel,Jan Seidel,Janey Tracey,Jang Hyun Cho,Janice Wei,Jarrod Kahn,Jasmyn Howell,Jason Long Vu,Jason Park,Jason Yan,Jason Yip,Jay Li,Jay Mahadeokar,Jaya Bharath R Goluguri,Jayasi Mehar,Jean-Baptiste Gaya,Jeet Shah,Jeff Hanson,Jeff Marcus,Jeff Walsh,Jeff Yang,Jelmer van der Linde,Jemma Fan,Jennifer Chan,Jenny Zhen,Jenya Lee,Jeremy Fu,Jeremy Reizenstein,Jeremy Teboul,Jesse He,Jessica Zhong,Ji Hou,Ji Yang,Jia Ding,Jiabo Hu,Jiacheng Zhu,Jiadong Guo,Jialiang Wang,Jialin Ouyang,Jianfeng Chi,Jianyu Huang,Jianyun Zhao,Jiaowen Yang,Jiatong Zhou,Jiawei Zhao,Jiawen Liu,Jie Wang,Jie You,Jiecao Yu,Jillian Schwiep,Jilong Wu,Jing Huang,Jing Li,Jing Yu Koh,Jing Zhang,Jingxiang Chen,Jingyi Yang,Jingyue Shen,Jinho Hwang,Jinxi Guo,Jiwan Khatiwada,Joanna Bitton,Joe Li,Joe Quanaim,Joel Beales,Johan Schuijt,John Chang,John Quan,Johnnie Chan,Jon Shepard,Jona Harris,Jonah Rubin,Jonathan Janzen,Jonathan Kaldor,Jorge Lopez Silva,Jose Leitao,Joseph Greer,Joseph Moon,Joseph Rocca,Joseph Tighe,Josh Fromm,Joshua Deng,Joshua Fernandes,Joshua Saxe,Joyce Zheng,Juan Pino,Julien Prigent,Jun Chen,Junjiao Tian,Junjie Qi,Junjie Wang,Junteng Jia,Kade Baker,Kai Londenberg,Kai Wang,Kainan Peng,Kaiyan Peng,Kaiyue Yang,Kalyan Vasudev Alwala,Kam Hou Yu,Kanika Narang,Karan Chadha,Karan Sikka,Karen Zhang,Karina Schuberts,Karishma Mandyam,Karthik Abinav Sankararaman,Karthik Padthe,Karthik Prasad,Karthik Sivakumar,Kartikeya Upasani,Kate Plawiak,Kate Saenko,Kateřina Žmolíková,Kathryn Stadler,Kathy Matosich,Katie Doulgass,Kaveh Hassani,Kay Ji,Ke Li,Kenneth Heafield,Kenny Yu,Keqian Li,Kevin Chih-Yao Ma,Kevin Hannan,Keyu Man,Kezhen Chen,Khalid El-Arini,Khrystyna Hutsulyak,Kieran Nash,Kiran Jagadeesh,Kody Bartelt,Konstantin Topaloglou-Mundy,Konstantinos Chatziioannou,Konstantinos Karanasos,Konstantinos Vougioukas,Kostas Tsiampouris,Kristen Hamill,Kristy Choi,Krithika Iyer,Kshitiz Malik,Kuenley Chiu,Kun Huang,Kunal Bhalla,Kunal Chawla,Kunpeng Li,Kushal Lakhotia,Kyle Monk,Lakshya Garg,Lalit Chourey,Lars Hamre,Laura Gustafson,Lauren Deason,Laurence Rouesnel,Laurens van der Maaten,Lavender A,Lawrence Chen,Lawrence Jang,Leandro Silva,Leda Sari,Lee Hetherington,Lei Zhang,Leiyu Zhao,Lele Chen,Leo Chenghui Li,Leon Yang,Leon Zhan,Levi Corallo,Liang Tan,Licheng Yu,Lijuan Liu,Lilach Mor,Lincoln Lin,Linfeng Li,Lisa Titus,Liz Jenkins,Lovish Madaan,Lu Fang,Lu Yuan,Lucas Nava,Lucas Pasqualin,Lucas Switzer,Lucia Fang,Lucy Sun,Luka Tadic,Lukas Blecher,Lukas Landzaat,Luxin Zhang,Madhavi Rao,Madian Khabsa,Mahalia Miller,Mahendra Kariya,Mahesh Pasupuleti,Mahi Luthra,Manaal Faruqui,Manav Avlani,Manchen Wang,Mannat Singh,Manohar Paluri,Manoj Chakkaravarthy,Manoj Nair,Maquelle Tiffany,Marcin Pawlowski,Marcus Wu,Maria Lomeli,Mario Consuegra,Marion Boiteux,Marios Andreas Galanis,Marshall Chen,Martin Gleize,Maryam Fazel-Zarandi,Matan Hasson,Mathew Oldham,Mathieu Rita,Matt Dordal,Matt Setzler,Matt Staats,Matt Staats,Matt Wilde,Matthew Clark,Matthew Grange,Matthew Lennie,Matthew Schmohl,Max Raphael,Maxim Naumov,Maxim Samoylov,Maxime Lecanu,Maya Pavlova,Md Taha Bin Jawaid,Meghan Keneally,Melanie Kambadur,Meng Zhang,Mengchen Liu,Mengdi Lin,Mengjiao Wang,Mervyn Abraham,Miao Liu,Michael Au-Yeung,Michael Feldergraf,Michael Man,Michael Matheny,Michael Suo,Michael Tontchev,Michel Meyer,Michelle Ma,Mihir Patel,Mihir Sanjay Kale,Mik Vyatskov,Mikayla Alexander,Mike Andersland,Mike Clark,Mike Lewis,Mike Li,Mike Macey,Mike Macey,Mike Seltzer,Mikel Jimenez Fernandez,Mikhail Antonov,Mikhail Plekhanov,Milan Zhou,Min Si,Ming Qiao,Mingbo Ma,Mingjun Zhang,Mingyi Liang,Miquel Jubert Hermoso,Mirac Suzgun,Mirjam Skarica,Mitesh Kumar Singh,Mohammad Kabbani,Mohammad Rastegari,Mona Sarantakos,Monica Sim,Monika Gangapuram,Mor Moshe,Morrie Doulaty,Morvarid Metanat,Moya Chen,Mrinal Kumar,Munish Bansal,Murali Ramarao,Na Li,Nadav Azaria,Nahiyan Malik,Naman Goyal,Nancy Vargas Balderas,Nanshu Wang,Naoyuki Kanda,Natalia Gimelshein,Natalia Neverova,Nathan Aclander,Natt Sithiviraporn,Navneet Madhu Kumar,Ned Newton,Neeraj Bahl,Negar Ghorbani,Neil Patel,Neta-lee Golan,Nicholas Longenbaugh,Nick Egebo,Nikhil Johri,Nikhil Mehta,Nikhil Naik,Niko Moritz,Nikolay Bashlykov,Nikolay Bogoychev,Nikolay Pavlovich Laptev,Niladri Chatterji,Nile Jones,Nimish Shah,Ning Dong,Ning Li,Ning Li,Ning Zhang,Nishant Yadav,Noam Paz,Norman Cheng,Norman Cheng,Olaoluwa Adesanya,Oleg Repin,Oleksandr Maksymets,Omkar Salpekar,Omri Harosh,Onkar Pednekar,Onur Çelebi,Oran Gafni,Oren Edinger,Osama Hanna,Owais Khan Mohammed,Ozlem Kalinli,Paden Tomasello,Pankaj Singh,Paola Quevedo,Parag Jain,Paria Rashidinejad,Parker Tooley,Parth Parekh,Parth Thakkar,Parvin Taheri,Pasan Hapuarachchi,Pascal Kesseli,Patrick Alrassy,Paulo de Rezende Pinatti,Pavan Balaji,Pawan Sisodiya,Pedro Jose Ferreira Moreira,Pedro Rittner,Pedro Valenzuela,Peize Sun,Peizhao Zhang,Peng-Jen Chen,Pengchao Wang,Pengchuan Zhang,Pengwei Li,Petar Vasic,Peter Carras,Peter Ney,Peter Weng,Petru Dumea,Phil Hayes,Philip Woods,Pierre Andrews,Pierre Ménard,Ping-Hao Wu,Pingchuan Liu,Piotr Dollar,Plamen Dzhelepov,Polina Zvyagina,Posten A,Prabhav Agrawal,Pradhapan Rajendran,Pradyot Prakash,Prajjwal Bhargava,Pramono,Pranay Shah,Pranshu Dave,Prash Jain,Pratik Dubal,Praveen Gollakota,Praveen Krishnan,Pritish Yuvraj,Projjal Ghosh,Punit Singh Koura,Puxin Xu,Qi Qi,Qi Zhou,Qian Guan,Qian Sun,Qiang Liu,Qing He,Qinqing Zheng,Qirui Yang,Qizhen Guo,Quanzeng You,Quentin Carbonneaux,Quentin Carbonneaux,Quentin Duval,Quintin Fettes,Rachad Alao,Rachel Batish,Rachel Guo,Rachel Rodriguez,Radhika Bhargava,Rafael Asuncion,Raghotham Murthy,Rahul Dutta,Rahul Jha,Rahul Kindi,Rahul Mitra,Raj Ganapathy,Raj Shah,Rajarshi Das,Rajat Shrivastava,Rajesh Nishtala,Ramakant Shankar,Raman Shukhau,Ramon Calderer,Rangaprabhu Parthasarathy,Ranjan Subramanian,Raphael Bensadoun,Rares Bostan,Rashnil Chaturvedi,Ravi Agrawal,Ray Gao,Raymond Li,Rebecca Kogen,Ricardo Juan Palma Duran,Ricardo Silveira Cabral,Richard Lee,Richard Yuanzhe Pang,Riddhish Bhalodia,Riham Mansour,Rishabh Singh,Rishi Godugu,Ritun Patney,Rob Boyle,Robbie Goldfarb,Robert Caldwell,Robert Kuo,Roberta Raileanu,Robin Battey,Robin Sharma,Rochit Sapra,Rocky Wang,Rodolfo Granata,Rodrigo De Castro,Rodrigo Paim,Rohan Maheshwari,Rohan Varma,Rohit Girdhar,Rohit Patel,Roshan Sumbaly,Roy Sheaffer,Ruan Silva,Ruben Rodriguez Buchillon,Rui Hou,Ruiming Xie,Ruslan Mavlyutov,Ruslan Semenov,Rustam Dinov,Ruxiao Bao,Ryan Fox,Ryan Kilpatrick,Ryan Kwan,Ryan Lim,Ryan Smith,Saaketh Narayan,Sabrina Qiao,Sachin Mehta,Sachin Siby,Sagar Jain,Saghar Hosseini,Sagie Gur-Ari,Sahana Chennabasappa,Sahin Geyik,Sai Jayesh Bondu,Sai Mounika Chowdhary Nekkalapudi,Saif Hasan,Saisuke Okabayashi,Saketh Rambhatla,Salil Sawhney,Sam Dunster,Sam Zhao,Saman Keon,Samaneh Azadi,Sameet Sapra,Samuel Dooley,Samyak Datta,Sandeep Parab,Sang Michael Xie,Sanjay Singh,Sanyuan Chen,Sara Behn,Sara Khodeir,Sarah Shirazyan,Sargun Dhillon,Sarunya Pumma,Sasha Sidorov,Saskia Adaime,Saurabh Khanna,Sayem Wani,Scott Brenton,Sean Bell,Sean Kelly,Sean Koger,Sean Nunley,Sean Perry,Sebastian Caicedo,Sebastian Dahlgren,Sebastian Ruder,Seiji Yamamoto,Selam Mehretu,Selvan Sunitha Ravi,Sen Lyu,Senthil Chellapan,Serafeim Mellos,Sergey Edunov,Sergey Royt,Shaina Cohen,Shangfu Peng,Shannon Adams,Shaoliang Nie,Sharadh Ramaswamy,Sharan Narang,Shashank Pisupati,Shashi Gandham,Shaun Lim,Shaun Lindsay,Sheena Artrip,Shelly Sheynin,Shen Yan,Sheng Feng,Sheng Shen,Shengbao Zheng,Shenghao Lin,Shengjie Bi,Shengxin Cindy Zha,Shengye Wan,Shengyi Qian,Shengyong Cai,Shengzhi Shao,Shervin Shahidi,Shikai Li,Shimon Bernholtz,Shiqi Wang,Shishir G. Patil,Shiv Verma,Shiva Shankar P,Shiyang Chen,Sho Yaida,Shoubhik Debnath,Shreyas Siravara,Shruti Bhosale,Shuang Ma,Shun Zhang,Shuo Tang,Shuqiang Zhang,Shuyan Zhou,Sicong Che,Sidd Srinivisan,Siddharth Bhattacharya,Siddharth Patki,Sijia Chen,Sili Chen,Simon Vandenhende,Simone Merello,Sinong Wang,Sivan Barzily,Sixian Yi,Siyu Lin,SK Bong,Sky Yin,Sneha Agarwal,Sneha Agarwal,Soerian Lieve,Soji Sajuyigbe,Song Jiang,Songlin Li,Sonia Kim,Sopan Khosla,Soumi Maiti,Spencer Whitman,Sravya Popuri,Sreen Tallam,Srinivas Vaidyanathan,Srinivas Vaidyanathan,Sten Sootla,Stephane Collot,Stephanie Ding,Stephen Chen,Steven Cai,Suchin Gururangan,Sudarshan Govindaprasad,Sue Young,Suganthi Dewakar,Sujan Kumar Gonugondla,Sujeet Bhandari,Suman Gumudavelli,Suman Gumudavelli,Sumit Gupta,Summer Deng,Sungmin Cho,Suresh Ganapathy,Surjyendu Dhal,Susan Fedynak,Susana Contrera,Suyoun Kim,Sylvestre Rebuffi,Takshak Chahande,Tamar Herman,Tan Li,Tao Xu,Tara Fowler,Tarek Sheasha,Tarun Anand,Tarun Kalluri,Tarun Singh,Tatiana Shavrina,Ted Li,Teja Rao,Tejas Patil,Teng Li,Thach Bui,Thai Quach,Thamer Alharbash,Thanh Vinh Vo,Thawan Kooburat,Thilo Koehler,Thomas Georgiou,Thomas Scialom,Tian Ye,Tianhe Li,Tianjun Zhang,Tianyu Li,Tijmen Blankevoort,Timon Willi,Timothy Chou,Timothy Leung,TJ Lee,Todor Mihaylov,Tom Heatwole,Tong Xiao,Tony Cao,Tony Lee,Trang Le,Tristan Rice,Tsz Kei Serena Chan,Tuan Tran,Tudor Tiplea,Tyler Baumgartner,Uday Savagaonkar,Ujjwal Karn,Ulises Martinez Araiza,Umar Farooq,Uriel Cohen,Usman Sharif,Utkarsh Murarka,Van Phung,Varun Joginpalli,Varun Saravagi,Vasu Sharma,Vasudha Viswamurthy,Vedanuj Goswami,Vedika Seth,Venkat Ramesh,Venkat Ramesh,Vibhor Gupta,Victoria Montanez,Vidhya Natarajan,Vidya Sarma,Vignesh Ramanathan,Viktor Kerkez,Vinay Rao,Vincent Gonguet,Vincent Mauge,Virginie Do,Vish Vogeti,Vishrav Chaudhary,Viswesh Sankaran,Vítor Albiero,Vivek Miglani,Vivek Pai,Vlad Cojanu,Vlad Shubin,Vlad Tiberiu Mihailescu,Vladan Petrovic,Vladimir Ivanov,Vladislav Vorotilov,Vrushali Bhutada,Wai I Ng,Wei Cheng,Wei Sun,Wei Tu,Wei Wei,Wei Zhou,Wei-Ning Hsu,Weiwei Chu,Weizhe Yuan,Wenchen Wang,Wenjun Zhao,Wenwen Jiang,Wenyin Fu,Wenzhe Jiang,Whitney Meers,Will Constable,Will Wang,William R. Wong,Xavier Martinet,Xi Victoria Lin,Xi Yan,Xi Yin,Xian Li,Xianfeng Rui,Xianjun Yang,Xiaocheng Tang,Xiaodong Wang,Xiaofang Wang,Xiaolan Wang,Xiaoliang Dai,Xiaoliang Peng,Xiaopeng Li,Xiaozhu Meng,Xibei Zhang,Xide Xia,Xin Jin,xinbo Gao,Xinfeng Xie,Xingyi Zhou,Xu Ma,Xuan Ju,Xuanyi Zhao,Xubo Liu,Xuchao Jia,Xuedong Zhang,Xuefei Cao,Xuewei Wang,Xuewei Wu,Xunnan Xu,Xutai Ma,Xuyang Wang,Yan Cui,Yang Chen,Yang Li,Yang Shu,Yang Xia,Yanjun Chen,Yanjun Zhou,Yash Mehta,Yash Patel,Yash Tekena,Yashesh Gaur,Yasmine Babaei,Yaxuan Zhou,Ye Hu,Ye Qi,Yejin Lee,Yeming Wen,Yen-Cheng Liu,Yexin Bruce Wu,Yi Pan,Yi Yang,Yi-Hui Lin,Yifan Wang,Yifan Wu,Yifan Yang,Yifei Huang,Yiftah Ben Aharon,Yilin Yang,Yiling You,Ying Xu,Ying Zhang,Yingquan Yuan,Yingru Liu,Yingyi Ma,Yining Yang,Yiting Lu,Yonatan Komornik,Yongjie Lin,Yoni Goyhman,Yossi Moran Mamo,Youngjin Nam,Yu Wang,Yu Lu,Yu Zhao,Yu-Ho Hsieh,Yu-Jung Lo,Yuandong Tian,Yuanhan Zhang,Yuanhao Xiong,Yuanshun Yao,Yuchen Hao,Yuchen Zhang,Yuchuan Li,Yue Cao,Yue Yu,Yue Zhao,Yuhan Guo,Yuhao Wang,Yuheng Huang,Yujie Lu,Yujun Shi,Yulun Wang,Yun He,Yun Wang,Yundi Qian,Yunfan Wang,Yunhao Tang,Yuning Mao,Yunlu Li,Yuqi Dai,Yuriy Hulovatyy,Yushi Hu,Yuxuan Sun,Zach Rait,Zach Wentz,Zacharie Delpierre Coudert,Zachary Collins,Zahra Hankir,Zecheng He,Zeeshan Ahmed,Zeeshan Ahmed,Zef RosnBrick,Zhan Shu,Zhanna Rohalska,Zhaoduo Wen,Zhe Liu,Zhe Liu,Zhen Qiao,Zhenggang Xu,Zhengwen Zhou,Zhengxing Chen,Zhenyu Tang,Zhichen Wu,Zhicheng Ouyang,Zhihong Lei,Zhipeng Hong,Zhiping Xiu,Zhiwei Zhao,Zhong Meng,Zhou Jin,Zhouhao Zeng,Zichang Liu,Zihang Meng,Zihuan Qiao,Zinnia Zheng,Zixi Qi,Ziyi Luo,Zoe Foulkes Birkhead,Zoey Sun,Zohar Achdut*

Main category: cs.SE

Relevance: 95.0

TL;DR: Llama 4技术报告：总结Meta Llama 4模型系列的技术细节，包括Scout和Maverick变体、MoE架构、多模态融合、长上下文设计、训练方法、基准测试结果及部署限制。


<details>
  <summary>Details</summary>
Motivation: 为研究者和从业者提供关于Llama 4模型家族的精确技术参考，整合公开报告的技术细节，帮助理解这一最新LLM系列的设计、训练和部署特性。

Method: 技术报告整合方法：收集并分析公开技术资料，涵盖模型变体（Scout、Maverick、Behemoth教师模型）、MoE架构细节（路由/共享专家结构）、早期融合多模态、长上下文设计（iRoPE和长度泛化策略）、训练流程（预训练、中期训练、后训练SFT/RL/DPO）、基准测试结果和部署约束。

Result: 提供全面的技术参考文档，详细记录了Llama 4系列的技术规格、架构创新（如改进的MoE设计、长上下文处理）、训练方法学、性能基准以及实际部署中的限制（上下文长度限制、量化支持等）。

Conclusion: Llama 4代表了Meta在大型语言模型领域的最新进展，通过创新的MoE架构、多模态融合和长上下文处理技术，在保持高效性的同时提升了模型能力，为研究社区提供了重要的技术参考。

Abstract: This document consolidates publicly reported technical details about Metas Llama 4 model family. It summarizes (i) released variants (Scout and Maverick) and the broader herd context including the previewed Behemoth teacher model, (ii) architectural characteristics beyond a high-level MoE description covering routed/shared-expert structure, early-fusion multimodality, and long-context design elements reported for Scout (iRoPE and length generalization strategies), (iii) training disclosures spanning pre-training, mid-training for long-context extension, and post-training methodology (lightweight SFT, online RL, and lightweight DPO) as described in release materials, (iv) developer-reported benchmark results for both base and instruction-tuned checkpoints, and (v) practical deployment constraints observed across major serving environments, including provider-specific context limits and quantization packaging. The manuscript also summarizes licensing obligations relevant to redistribution and derivative naming, and reviews publicly described safeguards and evaluation practices. The goal is to provide a compact technical reference for researchers and practitioners who need precise, source-backed facts about Llama 4.

</details>


### [568] [AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control](https://arxiv.org/abs/2601.11568)
*Quang-Hung Bui,Anh Son Ta*

Main category: cs.LG

Relevance: 85.0

TL;DR: AdaFRUGAL：自动化梯度分割框架的动态参数调整，减少LLM训练内存开销和计算时间


<details>
  <summary>Details</summary>
Motivation: 现有FRUGAL框架通过梯度分割减少LLM训练的内存开销，但其静态超参数（子空间比例ρ和更新频率T）需要昂贵的手动调优，限制了适应性和实用性

Method: 提出AdaFRUGAL框架，引入两个动态控制机制：1) ρ的线性衰减策略，逐步减少内存占用；2) 基于损失感知的T调度策略，降低计算开销

Result: 在大规模预训练（英语C4、越南语VietVault）和微调（GLUE）实验中，AdaFRUGAL在保持与AdamW和静态FRUGAL相当性能的同时，显著减少了GPU内存和训练时间

Conclusion: AdaFRUGAL为资源受限的LLM训练提供了更实用、自主的解决方案，实现了内存、计算和性能的良好平衡

Abstract: Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($ρ$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $ρ$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.

</details>


### [569] [Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces](https://arxiv.org/abs/2601.11572)
*Timo Aukusti Laine*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文使用量子力学启发的数学工具（线性代数和哈密顿形式）分析LLM嵌入空间的结构，发现L2归一化约束创造了适合哈密顿形式分析的结构化空间，并探索了语义转换的量子类比。


<details>
  <summary>Details</summary>
Motivation: LLM嵌入空间表现出离散语义状态，类似于量子系统。作者希望通过数学工具（特别是量子力学启发的线性代数和哈密顿形式）来分析这些语义关系，以深入理解LLM的内部表示结构。

Method: 使用线性代数和哈密顿形式分析LLM嵌入空间，推导余弦相似度与嵌入向量扰动之间的关系，探索直接和间接语义转换，并从量子力学角度推导零点能量类比，讨论与Koopman-von Neumann力学的潜在联系。

Result: 证明了L2归一化约束导致结构化嵌入空间适合哈密顿形式分析，建立了余弦相似度与嵌入扰动之间的数学关系，并成功应用量子力学概念（如零点能量）来分析语义表示。

Conclusion: 这种量子力学启发的数学方法为深入理解LLM提供了有前景的途径，可能为缓解幻觉问题提供新的方法，但解释需要谨慎考虑。

Abstract: We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.

</details>


### [570] [Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction](https://arxiv.org/abs/2601.11609)
*Weinuo Ou*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出ApCM模型，一种神经记忆存储架构，用于解决LLMs缺乏有效运行时记忆机制的问题，以适应动态和个性化交互需求


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型普遍缺乏有效的运行时记忆机制，难以适应动态和个性化的交互需求，这限制了模型在持续对话、个性化服务等场景中的应用能力

Method: 提出辅助预测压缩记忆模型（ApCM Model），这是一种新颖的神经记忆存储架构，通过压缩和预测机制来增强LLMs的运行时记忆能力

Result: 从摘要中无法得知具体实验结果，但该方法旨在解决LLMs记忆机制不足的问题，理论上应能提升模型在动态交互场景中的表现

Conclusion: ApCM模型为解决LLMs运行时记忆问题提供了一种新的架构方案，有望增强模型对动态和个性化交互的适应能力

Abstract: Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).

</details>


### [571] [Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective](https://arxiv.org/abs/2601.11616)
*Feilong Liu*

Main category: cs.LG

Relevance: 85.0

TL;DR: MoE架构通过软分区表示空间来降低局部敏感度，增加表示的有效秩，专家变换近似正交，Top-k路由产生低秩结构而软路由产生高秩表示。


<details>
  <summary>Details</summary>
Motivation: 研究MoE架构对学习函数和表示几何特性的影响，理解路由机制如何软分区表示空间，分析不同路由策略（Top-k vs 软路由）对函数几何和表示结构的影响。

Method: 提出双雅可比-PCA谱几何探针：通过雅可比奇异值谱分析局部函数几何，通过加权PCA分析路由隐藏状态的表示几何。在可控的MLP-MoE设置中进行实验，比较密集、Top-k和完全软路由架构。

Result: MoE路由一致降低局部敏感度，专家局部雅可比矩阵具有更小的主导奇异值和更快的谱衰减。加权PCA显示专家局部表示在更多主方向上分布方差，表明在相同输入分布下具有更高的有效秩。专家雅可比矩阵近似正交，表明变换分解为低重叠的专家特定子空间。

Conclusion: MoE可解释为函数空间的软分区，能够平坦化局部曲率同时重新分配表示方差，不同路由策略产生不同的几何特性：Top-k路由产生低秩集中结构，软路由产生高秩广泛表示。

Abstract: Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.

</details>


### [572] [Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention](https://arxiv.org/abs/2601.11618)
*Luis Rosario Freytes*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文提出了几何注意力(GA)框架，将注意力层分解为四个独立组件：载体、证据核规则、探针族和锚点/更新规则，为理解和比较不同的注意力机制提供了统一的理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制（如Transformer中的softmax注意力）缺乏统一的理论框架，难以系统比较不同变体。作者旨在建立一个几何化的注意力理论，将注意力分解为基本组件，从而分离不变结构与建模选择，实现注意力机制的原则性比较和扩展。

Method: 提出几何注意力(GA)框架，将注意力层分解为：1）有限载体（可寻址索引）；2）证据核规则（如何从掩码原始分数和链接产生非负权重）；3）探针族（可观测量的集合）；4）锚点/更新规则（选择哪个代表核以及如何应用）。通过操作等价关系和规范选择，建立了注意力机制的统一数学描述。

Result: 该框架能够统一描述多种注意力变体：在特定条件下（标量关系工作表示和乘法组合性），可接受的链接族是指数族，产生Gibbs权重；行锚定包含softmax核族作为子机制。框架还支持多头/混合核、基于计划的锚点（如熵最优传输/Sinkhorn）和一元算子等扩展。

Conclusion: 几何注意力框架为注意力机制提供了统一的理论基础，分离了不变结构与建模选择，使得能够原则性地比较和扩展注意力机制及基于注意力的架构。该框架将标准Transformer注意力作为特例包含，并支持自适应载体和分阶段深度等更灵活的机制。

Abstract: Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.

</details>


### [573] [NoiseFormer -- Noise Diffused Symmetric Attention Transformer](https://arxiv.org/abs/2601.11619)
*Phani Kumar,Nyshadham,Jyothendra Varma,Polisetty V R K,Aditya Rathore*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出一种名为噪声扩散对称注意力Transformer的新架构，在保持对称注意力内存优势的同时，通过微小参数和计算开销提升模型性能，在GLUE基准测试中取得介于原始对称注意力和GPT2基础模型之间的准确率，同时显著减少模型大小。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型规模急剧增长，内存占用和计算成本成为主要瓶颈。稀疏注意力技术（如对称注意力）虽然能减少参数和计算量，但可能牺牲模型性能。本文旨在在保持对称注意力内存优势的同时，提升模型性能。

Method: 提出噪声扩散对称注意力Transformer（Noise Diffused Symmetric Attention Transformer），在对称点积注意力基础上引入噪声扩散机制，形成统一的模型架构。该方法在GPT2基础模型上进行验证，保持对称注意力的内存增益，仅增加微小的参数和计算开销。

Result: 在多个GLUE基准任务上，所提模型的性能介于原始对称注意力和GPT2基础模型之间，在准确率方面优于对称注意力，同时实现了相对于基础模型的显著模型大小缩减。

Conclusion: 噪声扩散对称注意力Transformer在保持稀疏注意力内存优势的同时，能够有效提升模型性能，为大规模语言模型的高效训练和推理提供了一种有前景的解决方案。

Abstract: Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.

</details>


### [574] [Activation Sensitivity as a Unifying Principle for Post-Training Quantization](https://arxiv.org/abs/2601.11663)
*Bruce Changlong Xu*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文提出了一个统一的理论框架来分析大语言模型的后训练量化方法，通过形式化"激活敏感性"概念，将AWQ和GPTQ等主流量化方法解释为在不同简化假设下对敏感性的近似。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型的后训练量化方法（如AWQ和GPTQ）依赖于启发式方法，但缺乏统一的理论框架。这些方法在概念上分散，不清楚它们近似的是什么底层量。本文旨在提供一个统一的理论基础来理解和比较不同的量化方法。

Method: 通过一阶泰勒展开，形式化定义"激活敏感性"——通道级扰动对损失的期望影响。敏感性被表示为梯度加权激活的平方范数，捕捉了激活幅度和下游误差传播。在此框架下，AWQ和GPTQ被解释为在不同简化假设下对敏感性的互补近似。

Result: 建立了一个统一的理论框架，将激活敏感性作为量化通道重要性的原则性度量。分析了敏感性度量的设计空间，连接了梯度显著性、Fisher信息和Hessian准则，并阐明了它们与经典剪枝方法（如OBD和OBS）的关系。

Conclusion: 本文提供了一个概念性基础，通过敏感性视角来理解和比较后训练量化方法，而不是提出新的量化算法。该框架统一了当前分散的量化方法，为未来量化研究提供了理论基础。

Abstract: Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.

</details>


### [575] [Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction](https://arxiv.org/abs/2601.11667)
*Xiaojie Xia,Huigang Zhang,Chaoliang Zhong,Jun Sun,Yusuke Oishi*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出一种高效方法，将预训练的全注意力Transformer转换为任务特定的混合注意力模型，通过块级局部蒸馏和贪婪层替换策略，在保持性能的同时实现线性复杂度。


<details>
  <summary>Details</summary>
Motivation: Transformer的全注意力机制具有二次复杂度，限制了实际部署。线性注意力虽然效率高但性能下降。混合模型需要从头训练成本高，且手动设计注意力类型布局困难。需要一种高效方法将预训练模型转换为任务特定的混合模型。

Method: 1) 通过块级局部蒸馏将预训练全注意力模块的权重迁移到线性注意力对应模块；2) 引入贪婪层替换策略，迭代地将全注意力块替换为线性注意力块，同时监控目标任务的验证性能。

Result: 该方法能在单次高效过程中生成任务特定的混合模型，无需昂贵的重新训练或神经架构搜索，可应用于任何预训练全注意力骨干网络，适用于多种下游任务。

Conclusion: 提出了一种实用方法，在保持Transformer性能的同时实现线性复杂度，解决了混合注意力模型训练成本高和架构设计困难的问题。

Abstract: Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.

</details>


### [576] [AGGC: Adaptive Group Gradient Clipping for Stabilizing Large Language Model Training](https://arxiv.org/abs/2601.11864)
*Zhiyuan Li,Yuan Wu,Yi Chang*

Main category: cs.LG

Relevance: 85.0

TL;DR: AGGC提出自适应分组梯度裁剪方法，通过按功能类型分组参数、使用EMA历史行为调节，解决传统全局梯度裁剪中的梯度异质性问题，在LLM微调中稳定训练并超越LoRA和全参数微调。


<details>
  <summary>Details</summary>
Motivation: 传统全局梯度裁剪假设梯度在不同功能模块间同质，导致"溢出效应"——波动参数对稳定参数进行不必要的缩放。需要解决梯度异质性，稳定LLM训练。

Method: 1) 按功能类型将参数分组；2) 使用指数移动平均(EMA)跟踪每组历史行为；3) 构建自适应区间同时缓解梯度爆炸和消失；4) 时间相关调度机制平衡探索与收敛。

Result: 在LLaMA 2-7B、Mistral-7B、Gemma-7B上优于LoRA，常超越全参数微调。GSM8K上Mistral-7B+AGGC达72.93%准确率(对比LoRA 69.5%)。有效稳定RLVR训练，增强Qwen 2.5和Llama 3.2逻辑推理。

Conclusion: AGGC通过模块化自适应裁剪策略有效解决传统梯度裁剪限制，轻量设计可无缝集成现有后训练流程，显著提升LLM训练稳定性与性能。

Abstract: To stabilize the training of Large Language Models (LLMs), gradient clipping is a nearly ubiquitous heuristic used to alleviate exploding gradients. However, traditional global norm clipping erroneously presupposes gradient homogeneity across different functional modules, leading to an adverse "spill-over" effect where volatile parameters force unnecessary scaling on stable ones. To overcome this, we propose Adaptive Group-wise Gradient Clipping (AGGC). AGGC partitions parameters into groups based on functional types and regulates each according to its historical behavior using an Exponential Moving Average (EMA). Specifically, it constructs an adaptive interval to simultaneously mitigate gradient explosion and vanishing, while employing a time-dependent scheduling mechanism to balance exploration and convergence. Experiments on LLaMA 2-7B, Mistral-7B, and Gemma-7B models show that AGGC consistently outperforms LoRA and frequently surpasses Full Fine-Tuning. On the GSM8K benchmark, Mistral-7B fine-tuned with AGGC achieves an accuracy of 72.93%, exceeding LoRA's 69.5%. AGGC also effectively stabilizes Reinforcement Learning with Verifiable Rewards (RLVR), enhancing the logic deduction of Qwen 2.5 and Llama 3.2 models. Experimental results demonstrate that AGGC effectively addresses the limitations of traditional gradient clipping methods, particularly in overcoming gradient heterogeneity, by utilizing a modular, adaptive clipping strategy to stabilize the training process. Due to its lightweight design, AGGC can be seamlessly integrated into existing post-training pipelines with negligible overhead.

</details>


### [577] [DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models](https://arxiv.org/abs/2601.11895)
*Pareesa Ameneh Golnari,Adarsh Kumarappan,Wen Wen,Xiaoyu Liu,Gabriel Ryan,Yuting Sun,Shengyu Fu,Elsie Nallipogu*

Main category: cs.LG

Relevance: 85.0

TL;DR: DevBench是一个基于真实开发者遥测数据的代码补全基准测试，包含6种编程语言和6个任务类别，共1800个评估实例，强调生态有效性并避免训练数据污染。


<details>
  <summary>Details</summary>
Motivation: 现有代码补全基准测试缺乏生态有效性，容易受到训练数据污染影响，且无法提供详细的诊断信息。需要开发一个基于真实开发者行为的基准测试，以评估LLM在实际代码补全任务中的表现。

Method: 1. 从真实开发者遥测数据中提取任务，涵盖6种编程语言和6个任务类别
2. 设计1800个评估实例，避免训练数据污染
3. 结合功能正确性、相似性度量和LLM评判评估
4. 评估9个最先进的模型，分析语法精度、语义推理和实际效用

Result: 评估了9个SOTA模型，揭示了在语法精度、语义推理和实际效用方面的差异。基准测试提供了可操作的见解，指导模型选择和改进，这些细节在其他基准测试中通常缺失但对实际部署和针对性模型开发至关重要。

Conclusion: DevBench提供了一个生态有效的代码补全基准测试，能够提供详细的诊断信息，帮助指导模型选择和针对性改进，填补了现有基准测试在实用部署指导方面的空白。

Abstract: DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.

</details>


### [578] [Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration](https://arxiv.org/abs/2601.11953)
*Shiqing Gao,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出MICE方法解决约束强化学习中的成本函数低估问题，通过内在成本估计和记忆模块减少训练期间的约束违反，同时保持策略性能。


<details>
  <summary>Details</summary>
Motivation: 现有约束强化学习算法在训练期间经常出现显著的约束违反，限制了在安全关键场景中的应用。作者发现成本价值函数的低估是导致这些违反的关键因素。

Method: 提出记忆驱动的内在成本估计（MICE）方法：1）构建记忆模块存储先前探索的不安全状态；2）将内在成本定义为当前状态访问风险区域的伪计数；3）提出包含内在成本的外在-内在成本价值函数，采用偏差校正策略；4）在信任区域内制定优化目标和相应优化方法。

Result: 实验表明MICE显著减少了约束违反，同时保持了与基线相当的策略性能。理论上提供了成本价值函数的收敛保证和MICE更新的最坏情况约束违反界限。

Conclusion: MICE通过解决成本函数低估问题，有效提升了约束强化学习的安全性，为安全关键应用提供了更可靠的解决方案。

Abstract: Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, existing CRL algorithms often encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to mitigate underestimation and control bias to promote safer exploration. Inspired by flashbulb memory, where humans vividly recall dangerous experiences to avoid risks, MICE constructs a memory module that stores previously explored unsafe states to identify high-cost regions. The intrinsic cost is formulated as the pseudo-count of the current state visiting these risk regions. Furthermore, we propose an extrinsic-intrinsic cost value function that incorporates intrinsic costs and adopts a bias correction strategy. Using this function, we formulate an optimization objective within the trust region, along with corresponding optimization methods. Theoretically, we provide convergence guarantees for the proposed cost value function and establish the worst-case constraint violation for the MICE update. Extensive experiments demonstrate that MICE significantly reduces constraint violations while preserving policy performance comparable to baselines.

</details>


### [579] [R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning](https://arxiv.org/abs/2601.11960)
*Jingchu Wang,Bingbing Xu,Yige Yuan,Bin Xie,Xiaoqian Sun,Huawei Shen*

Main category: cs.LG

Relevance: 85.0

TL;DR: R²PO通过引入轻量级残差Rollout-Head解耦训练轨迹与推理响应，解决RL方法中单一策略在生成稳定推理响应与多样化训练轨迹之间的目标冲突问题，提升LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法使用单一策略同时产生推理响应和训练优化轨迹，导致生成稳定推理响应与多样化训练轨迹之间的目标冲突，造成探索不足，损害推理能力。

Method: 提出R²PO（残差Rollout策略优化），在策略之上引入轻量级残差Rollout-Head，解耦训练轨迹与推理响应，在训练期间实现可控的轨迹多样化，同时保持推理生成的稳定性。

Result: 在多个基准测试中一致优于基线方法，在MATH-500上平均准确率提升3.1%，在APPS上提升2.4%，同时减少格式错误并缓解长度偏差以实现稳定优化。

Conclusion: R²PO通过解耦训练轨迹与推理响应，有效解决了RL方法中的目标冲突问题，显著提升了LLM的推理能力，同时保持了推理生成的稳定性。

Abstract: Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.

</details>


### [580] [Extreme Value Policy Optimization for Safe Reinforcement Learning](https://arxiv.org/abs/2601.12008)
*Shiqing Gao,Yihang Zhou,Shuai Shao,Haoyu Luo,Yiheng Bing,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

Relevance: 85.0

TL;DR: EVO算法利用极值理论处理强化学习中的安全约束，通过极端分位数优化和优先回放机制减少罕见但高影响的约束违反事件。


<details>
  <summary>Details</summary>
Motivation: 传统约束强化学习基于期望累积成本，但忽略了分布尾部的罕见极端事件（如黑天鹅事件），这些事件可能导致严重的约束违反。需要一种能处理极端值的方法来确保安全。

Method: 提出极端值策略优化（EVO）算法：1）利用极值理论建模极端奖励和成本样本；2）引入极端分位数优化目标捕获成本分布尾部的极端样本；3）设计极端优先回放机制，放大罕见高影响样本的学习信号。

Result: 理论上证明了策略更新期间期望约束违反的上界，保证在零违反分位数水平上的严格约束满足。实验表明EVO显著减少训练期间的约束违反，同时保持与基线相当的策略性能。

Conclusion: EVO通过极值理论方法有效处理约束强化学习中的极端事件，比基于期望的方法有更低的约束违反概率，比分位数回归方法有更低的方差，为安全强化学习提供了新思路。

Abstract: Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.

</details>


### [581] [Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate](https://arxiv.org/abs/2601.12091)
*Qian Tan,Lei Jiang,Yuting Zeng,Shuoyang Ding,Xiaohua Xu*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文研究了LLM中的西方中心偏见问题，发现中文提示仅将偏见转向东亚视角而非消除偏见，提出了多智能体文化辩论框架来缓解偏见。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在系统性西方中心偏见，但使用非西方语言（如中文）提示是否能缓解这种偏见尚未充分研究。现有方法在评估和缓解两方面都存在不足：评估方法强制输出到预定义的文化类别而没有中立选项，缓解方法依赖昂贵的多文化语料库或缺乏明确文化表征的智能体框架。

Method: 提出了CEBiasBench中英双语基准和Multi-Agent Vote（MAV）评估框架，支持明确的"无偏见"判断。为缓解偏见，提出了Multi-Agent Cultural Debate（MACD）训练免费框架，为智能体分配不同的文化角色，并通过"求同存异"策略进行辩论。

Result: 实验表明，中文提示仅将偏见转向东亚视角而非消除偏见。MACD在CEBiasBench上实现了57.6%的平均无偏见率（LLM作为评判者）和86.0%（MAV评估），相比使用GPT-4o作为骨干的基线方法的47.6%和69.0%。MACD还能推广到阿拉伯语CAMeL基准。

Conclusion: 在智能体框架中明确的文化表征对于跨文化公平至关重要。中文提示不能消除偏见，而多智能体文化辩论框架能有效缓解LLM中的文化偏见。

Abstract: Large language models (LLMs) exhibit systematic Western-centric bias, yet whether prompting in non-Western languages (e.g., Chinese) can mitigate this remains understudied. Answering this question requires rigorous evaluation and effective mitigation, but existing approaches fall short on both fronts: evaluation methods force outputs into predefined cultural categories without a neutral option, while mitigation relies on expensive multi-cultural corpora or agent frameworks that use functional roles (e.g., Planner--Critique) lacking explicit cultural representation. To address these gaps, we introduce CEBiasBench, a Chinese--English bilingual benchmark, and Multi-Agent Vote (MAV), which enables explicit ``no bias'' judgments. Using this framework, we find that Chinese prompting merely shifts bias toward East Asian perspectives rather than eliminating it. To mitigate such persistent bias, we propose Multi-Agent Cultural Debate (MACD), a training-free framework that assigns agents distinct cultural personas and orchestrates deliberation via a "Seeking Common Ground while Reserving Differences" strategy. Experiments demonstrate that MACD achieves 57.6% average No Bias Rate evaluated by LLM-as-judge and 86.0% evaluated by MAV (vs. 47.6% and 69.0% baseline using GPT-4o as backbone) on CEBiasBench and generalizes to the Arabic CAMeL benchmark, confirming that explicit cultural representation in agent frameworks is essential for cross-cultural fairness.

</details>


### [582] [EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts](https://arxiv.org/abs/2601.12137)
*Anzhe Cheng,Shukai Duan,Shixuan Li,Chenzhong Yin,Mingxi Cheng,Shahin Nazarian,Paul Thompson,Paul Bogdan*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出EMoE架构，通过学习的正交特征基进行路由，解决MoE中负载不均衡和专家同质化问题，无需额外平衡损失函数。


<details>
  <summary>Details</summary>
Motivation: MoE架构虽然能提高效率，但存在两个根本问题：1) "富者愈富"的负载不均衡现象，少数专家被过度使用；2) 专家同质化问题，专家学习冗余表示，违背了MoE的初衷。现有解决方案通常使用辅助负载平衡损失，虽然缓解了不均衡，但往往以牺牲专业化为代价加剧同质化。

Method: 提出Eigen-Mixture-of-Experts (EMoE)架构，采用基于学习的正交特征基的路由机制。将输入token投影到这个共享的特征基上，根据token与特征空间主成分的对齐程度进行路由。这种基于几何的数据划分方法本质上促进了专家利用的平衡和多样化、专业化专家的发展。

Result: EMoE能够同时解决负载不均衡和专家同质化问题，无需使用冲突的辅助损失函数。代码已公开在GitHub上。

Conclusion: EMoE通过几何路由机制为MoE架构提供了更优雅的解决方案，在保持效率的同时解决了现有MoE模型的两个核心挑战。

Abstract: The relentless scaling of deep learning models has led to unsustainable computational demands, positioning Mixture-of-Experts (MoE) architectures as a promising path towards greater efficiency. However, MoE models are plagued by two fundamental challenges: 1) a load imbalance problem known as the``rich get richer" phenomenon, where a few experts are over-utilized, and 2) an expert homogeneity problem, where experts learn redundant representations, negating their purpose. Current solutions typically employ an auxiliary load-balancing loss that, while mitigating imbalance, often exacerbates homogeneity by enforcing uniform routing at the expense of specialization. To resolve this, we introduce the Eigen-Mixture-of-Experts (EMoE), a novel architecture that leverages a routing mechanism based on a learned orthonormal eigenbasis. EMoE projects input tokens onto this shared eigenbasis and routes them based on their alignment with the principal components of the feature space. This principled, geometric partitioning of data intrinsically promotes both balanced expert utilization and the development of diverse, specialized experts, all without the need for a conflicting auxiliary loss function. Our code is publicly available at https://github.com/Belis0811/EMoE.

</details>


### [583] [Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling](https://arxiv.org/abs/2601.12145)
*Xingyue Huang,Xueying Ding,Mingxuan Ju,Yozen Liu,Neil Shah,Tong Zhao*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出Threshold Differential Attention (TDA)，一种无注意力下沉的注意力机制，通过极值阈值化和差分视图解决Softmax注意力在长上下文中的结构限制问题


<details>
  <summary>Details</summary>
Motivation: Softmax注意力在长上下文中存在结构限制：严格的归一化约束导致注意力下沉到无关token上，且随着序列长度增加，概率质量会分散。现有方法要么计算开销大（投影方法），要么因噪声积累导致性能下降（标准修正注意力）

Method: TDA采用行级极值阈值化配合长度相关门控，只保留超过阈值的值。受差分transformer启发，TDA还减去抑制性视图以增强表达能力。理论证明TDA能将每行虚假幸存者数量控制在O(1)，且独立视图间的共识虚假匹配会随上下文增长而消失

Result: TDA能产生>99%的精确零值，消除注意力下沉，同时在标准和长上下文基准测试中保持竞争力

Conclusion: TDA是一种有效的注意力机制，解决了Softmax在长上下文中的限制，实现了超稀疏性和更好的鲁棒性，且没有额外计算开销或性能下降

Abstract: Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.

</details>


### [584] [Speculative Sampling with Reinforcement Learning](https://arxiv.org/abs/2601.12212)
*Chenan Wang,Daniel H. Shi,Haipeng Chen*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出Re-SpS框架，使用强化学习动态优化推测采样的草稿树超参数，相比静态方法EAGLE-3获得最高1.12倍加速，且不损失输出质量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型推理延迟是实际应用的主要挑战。现有推测采样方法（如EAGLE-3）使用静态树结构超参数，限制了在不同上下文和领域中的灵活性和效率。

Method: 提出Re-SpS框架：1) 使用强化学习动态调整草稿树超参数；2) 从目标模型隐藏状态提取高效状态表示；3) 引入多步动作持久性以更好建模上下文；4) 学习平衡推测激进性与计算开销的上下文感知策略。

Result: 在五个多样化基准测试中，相比骨干LLM获得最高5.45倍加速，相比SOTA方法EAGLE-3获得最高1.12倍加速，且输出保真度无损失。

Conclusion: Re-SpS首次将强化学习应用于草稿树超参数优化，实现了动态、上下文感知的推测采样，显著提升推理速度而不牺牲质量。

Abstract: Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\times$ speedup over the backbone LLM and up to 1.12$\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.

</details>


### [585] [LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH](https://arxiv.org/abs/2601.12355)
*Beicheng Xu,Weitong Qian,Lingching Tung,Yupeng Lu,Bin Cui*

Main category: cs.LG

Relevance: 85.0

TL;DR: LB-MCTS框架结合LLMs和贝叶斯优化，通过蒙特卡洛树搜索解决AutoML中的CASH问题，在104个AMLB数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 降低机器学习专业门槛，解决传统贝叶斯优化在CASH问题中的冷启动问题，同时克服现有LLM优化器在高维结构化CASH空间泛化能力差的局限。

Method: 提出LB-MCTS框架，将LLMs和贝叶斯优化结合在蒙特卡洛树搜索结构中。使用选择性调优记忆（STM）最大化LLM推理能力，实现显式的探索-利用权衡，并随着数据积累动态从LLM驱动转向BO驱动提案。

Result: 在104个AMLB数据集上的实验表明，LB-MCTS优于现有竞争基线方法。

Conclusion: LB-MCTS成功结合了LLMs的语义先验优势和贝叶斯优化的数据驱动优势，为AutoML中的CASH问题提供了有效的解决方案。

Abstract: To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.

</details>


### [586] [Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation](https://arxiv.org/abs/2601.12401)
*Jinmei Liu,Haoru Li,Zhenhong Sun,Chaofeng Chen,Yatao Bian,Bo Wang,Daoyi Dong,Chunlin Chen,Zhi Wang*

Main category: cs.LG

Relevance: 85.0

TL;DR: DRIFT框架通过采样、提示和优化三个视角解决RL微调中的多样性崩溃问题，在保持任务对齐的同时显著提升生成多样性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在微调大规模生成模型（如扩散模型）时存在多样性崩溃问题，即优化过程导致策略收敛到狄拉克分布，限制了生成结果的多样性。这对于需要多样化候选生成的应用至关重要。

Method: 提出DRIFT框架，从三个角度解决多样性崩溃：1) 采样奖励集中的子集，过滤奖励异常值防止过早崩溃；2) 使用随机变体提示扩展条件空间；3) 通过基于势能的奖励塑造机制优化组内多样性。

Result: 实验结果显示DRIFT在任务对齐和生成多样性方面实现帕累托优势：在相同对齐水平下多样性提升9.08%~43.46%，在相同多样性水平下对齐度提升59.65%~65.86%。

Conclusion: DRIFT成功解决了RL微调中的多样性崩溃问题，实现了任务对齐与生成多样性的平衡，为需要多样化生成的应用提供了有效解决方案。

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \textbf{DRIFT} (\textbf{D}ive\textbf{R}sity-\textbf{I}ncentivized Reinforcement \textbf{F}ine-\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\%\!\sim\! 43.46\%$ increase in diversity at equivalent alignment levels and a $ 59.65\% \!\sim\! 65.86\%$ increase in alignment at equivalent levels of diversity.

</details>


### [587] [Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF](https://arxiv.org/abs/2601.12415)
*Wang Zixian*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文提出了正交化策略优化（OPO）框架，将对齐方法中的采样几何与优化几何解耦，解决了传统KL散度导致的数值不稳定和梯度消失问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐方法（如PPO、DPO、IPO）通常将采样几何和优化几何隐式地混为一谈，导致KL散度在无界值信号上产生指数惩罚，造成数值不稳定和高置信度下的梯度消失问题。

Method: 提出正交化策略优化（OPO）框架，将对齐形式化为策略能量与目标能量之间的广义距离最小化。使用α散度加权的重采样进行采样几何设计，在比率坐标中使用χ²诱导的二次正则化进行优化几何设计，实现线性梯度动态。

Result: OPO框架提供了简单且条件良好的目标函数，在保持峰值搜索行为的同时实现稳定优化，即使在高模型置信度下也能避免梯度饱和。该框架为现有对齐方法提供了统一视角。

Conclusion: OPO通过明确解耦采样几何和优化几何，为鲁棒的推理导向训练提供了原则性基础，解决了传统对齐方法中的数值不稳定问题。

Abstract: Recent alignment methods for large language models, including PPO, DPO, and IPO, are often presented as distinct algorithms. In this work, we show that many of these approaches implicitly conflate two fundamental and independent design choices: (i) the sampling geometry, which determines which samples dominate the gradient signal, and (ii) the optimization geometry, which determines how deviations in value are penalized. We formalize this observation by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an alpha-divergence-based sampling weight and a Bregman-divergence-based value metric. We demonstrate that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this issue, we propose Orthogonalized Policy Optimization (OPO), a framework that explicitly decouples sampling geometry from optimization geometry. By combining alpha-weighted importance sampling with a chi-square-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This formulation maintains stable optimization while preserving peak-seeking behavior and avoids gradient saturation even when model confidence is high. Our analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.

</details>


### [588] [Dissecting Linear Recurrent Models: How Different Gating Strategies Drive Selectivity and Generalization](https://arxiv.org/abs/2601.12598)
*Younes Bouhadjar,Maxime Fabre,Felix Schmidt,Emre Neftci*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文提出了SelectivBench，一个用于系统评估序列模型（特别是线性循环神经网络）的轻量级可定制合成基准测试套件，专注于评估模型的选择性能力。


<details>
  <summary>Details</summary>
Motivation: 线性循环神经网络作为Transformer注意力机制的高效替代方案出现，但现有基准测试要么过于简单无法揭示实质性差异，要么过于资源密集难以实验。缺乏系统性的直接比较，且模型架构复杂性不断增加。

Method: 提出线性循环模型的细化分类法，并设计SelectivBench基准测试套件。使用基于规则的语法生成可调整复杂度的序列，包含故意违反转换规则的不规则间隔，专门评估模型在中小规模下的选择性能力。

Result: 在SelectivBench上评估线性循环模型显示出与大规模语言任务一致的性能模式。分析揭示了关键架构特征的作用：门控和快速遗忘机制促进召回，状态内通道混合对选择性不必要但对泛化关键，softmax注意力因内存容量随序列长度缩放而保持优势。

Conclusion: SelectivBench为线性循环模型提供了有针对性的高效探索工具，并为研究大规模评估中观察到的行为提供了受控环境。该基准测试能够系统评估序列模型的选择性能力。

Abstract: Linear recurrent neural networks have emerged as efficient alternatives to the original Transformer's softmax attention mechanism, thanks to their highly parallelizable training and constant memory and computation requirements at inference. Iterative refinements of these models have introduced an increasing number of architectural mechanisms, leading to increased complexity and computational costs. Nevertheless, systematic direct comparisons among these models remain limited. Existing benchmark tasks are either too simplistic to reveal substantial differences or excessively resource-intensive for experimentation. In this work, we propose a refined taxonomy of linear recurrent models and introduce SelectivBench, a set of lightweight and customizable synthetic benchmark tasks for systematically evaluating sequence models. SelectivBench specifically evaluates selectivity in sequence models at small to medium scale, such as the capacity to focus on relevant inputs while ignoring context-based distractors. It employs rule-based grammars to generate sequences with adjustable complexity, incorporating irregular gaps that intentionally violate transition rules. Evaluations of linear recurrent models on SelectivBench reveal performance patterns consistent with results from large-scale language tasks. Our analysis clarifies the roles of essential architectural features: gating and rapid forgetting mechanisms facilitate recall, in-state channel mixing is unnecessary for selectivity, but critical for generalization, and softmax attention remains dominant due to its memory capacity scaling with sequence length. Our benchmark enables targeted, efficient exploration of linear recurrent models and provides a controlled setting for studying behaviors observed in large-scale evaluations. Code is available at https://github.com/symseqbench/selectivbench

</details>


### [589] [MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning](https://arxiv.org/abs/2601.12680)
*Zheng Fang,Wolfgang Mayer,Zeyu Zhang,Jian Wang,Hong-Yu Zhang,Wanli Li,Zaiwen Feng*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出MetaToolAgent (MTA)，一种基于元学习的工具选择方法，用于提升LLM在未见工具上的泛化能力，并构建了包含7个领域、155个工具、9377个问答对的综合数据集。


<details>
  <summary>Details</summary>
Motivation: 现有工具选择方法通常局限于有限工具集，难以泛化到实际部署中遇到的新工具。需要解决LLM在复杂现实任务中有效协调和利用多样化工具的挑战。

Method: 提出MetaToolAgent (MTA)，一种元学习方法，通过元学习框架提升跨工具泛化能力。同时构建了涵盖7个领域、155个工具、9377个问答对的综合数据集，模拟现实集成场景。

Result: 实验结果显示MTA在未见工具上显著优于基线方法，证明了其在构建需要动态工具协调的灵活可扩展系统方面的潜力。

Conclusion: MTA通过元学习方法有效提升了LLM在工具选择上的跨工具泛化能力，为构建灵活可扩展的工具协调系统提供了有前景的解决方案。

Abstract: Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.

</details>


### [590] [Towards Spectroscopy: Susceptibility Clusters in Language Models](https://arxiv.org/abs/2601.12703)
*Andrew Gordon,Garrett Baker,George Wang,William Snell,Stan van Wingerden,Daniel Murfet*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文提出了一种基于光谱学原理的神经网络分析方法，通过扰动数据分布并测量模型响应（敏感性）来揭示语言模型的内部结构，识别出510个可解释的聚类模式。


<details>
  <summary>Details</summary>
Motivation: 受光谱学启发，希望开发一种系统性的方法来理解神经网络内部结构，通过测量模型对数据扰动的响应来揭示其工作机制，类似于物理系统通过扰动响应分析内部结构。

Method: 提出敏感性分析方法：通过在上下文x中上加权标记y来扰动数据分布，使用随机梯度Langevin动力学（SGLD）计算组件级观测值与扰动之间的协方差作为敏感性。理论证明敏感性可分解为数据分布模式之和，并开发了基于电导的聚类算法。

Result: 在Pythia-14M模型上应用该方法，识别出510个可解释的聚类，涵盖语法模式、代码结构和数学符号等。与稀疏自编码器（SAE）比较，50%的聚类与SAE特征匹配，验证了两种方法能发现相似结构。

Conclusion: 敏感性分析为理解神经网络内部结构提供了系统框架，能够识别可解释的聚类模式，并与现有方法结果一致，为模型可解释性研究提供了新工具。

Abstract: Spectroscopy infers the internal structure of physical systems by measuring their response to perturbations. We apply this principle to neural networks: perturbing the data distribution by upweighting a token $y$ in context $x$, we measure the model's response via susceptibilities $χ_{xy}$, which are covariances between component-level observables and the perturbation computed over a localized Gibbs posterior via stochastic gradient Langevin dynamics (SGLD). Theoretically, we show that susceptibilities decompose as a sum over modes of the data distribution, explaining why tokens that follow their contexts "for similar reasons" cluster together in susceptibility space. Empirically, we apply this methodology to Pythia-14M, developing a conductance-based clustering algorithm that identifies 510 interpretable clusters ranging from grammatical patterns to code structure to mathematical notation. Comparing to sparse autoencoders, 50% of our clusters match SAE features, validating that both methods recover similar structure.

</details>


### [591] [Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off](https://arxiv.org/abs/2601.12730)
*Zhaochun Li,Chen Wang,Jionghao Bai,Shisheng Cui,Ge Lan,Zhou Zhao,Yue Wang*

Main category: cs.LG

Relevance: 85.0

TL;DR: DCPO提出了一种分布中心的强化学习方法，通过分布级正则化控制策略熵，解决LLM强化学习中探索-利用权衡问题，相比GRPO平均提升20%性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM强化学习方法（如GRPO）存在探索不足问题，训练偏向利用驱动，熵单调下降，探索消失。现有解决方案大多是样本中心的，依赖稀有样本的"运气"，缺乏对策略的原则性控制，效果有限且不稳定。

Method: 提出分布中心策略优化（DCPO），从分布中心视角重新思考强化学习，将探索视为由"更好"的目标分布引导。将熵调节重新表述为分布级正则化，完全在策略上实现可控熵，无需从外部分布采样。

Result: 在多个模型和七个基准测试中，DCPO相比GRPO平均提升约20%性能。实现了可控探索，同时保持训练稳定性。

Conclusion: DCPO用分布级原则替代样本级启发式方法，为可控探索和更强的探索-利用权衡提供了理论基础和灵活框架。

Abstract: The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the "luck" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \textbf{distribution-centric} perspective for RL, in which exploration is always guided by a "better" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in https://github.com/597358816/DCPO.

</details>


### [592] [Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs](https://arxiv.org/abs/2601.12807)
*Zixing Song,Irwin King*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出SIT-Graph半监督指令调优框架，通过自训练利用未标记节点提升图学习性能，在低标签率下实现20%+改进


<details>
  <summary>Details</summary>
Motivation: 传统图指令调优需要大量标注节点，在社交领域获取专家标签成本高且慢，且未利用未标记节点中的潜在相关性

Method: 提出模型无关的SIT-Graph框架，通过迭代自训练：先用标记节点微调，生成置信度过滤的伪响应扩充数据集，迭代优化对齐LLM与节点相关性

Result: 在文本属性图基准测试中，结合SIT-Graph显著提升SOTA图指令调优方法性能，低标签率下实现超过20%改进

Conclusion: SIT-Graph有效利用未标记数据增强图学习，为LLM在图分析中的半监督应用提供实用框架

Abstract: The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.

</details>


### [593] [Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition](https://arxiv.org/abs/2601.12879)
*Mohammed Mudassir Uddin,Shahnawaz Alam,Mohammed Kaif Pasha*

Main category: cs.LG

Relevance: 85.0

TL;DR: HAGD框架通过分层图分解将电路发现复杂度从O(2^n)降至O(n² log n)，结合跨层转码器、图神经网络元学习和因果干预，在GPT-2、Llama和Pythia模型上验证了算法任务和自然语言基准的电路发现能力。


<details>
  <summary>Details</summary>
Motivation: 机械可解释性旨在将神经网络计算反工程为人类可理解的算法，但从数十亿参数语言模型中提取稀疏计算电路面临指数搜索复杂性和普遍多义性的挑战。

Method: 提出分层归因图分解(HAGD)框架，通过多分辨率抽象层次和可微分电路搜索降低复杂度；集成跨层转码器用于单义特征提取，图神经网络元学习用于拓扑预测，因果干预协议用于验证。

Result: 在模块化算术任务上，框架实现高达91%的行为保持(±2.3%)，同时保持可解释子图大小；跨架构迁移实验显示电路结构相似性平均67%，表明潜在共享计算模式。

Conclusion: 结果为更大模型规模的可解释性提供了初步基础，同时识别出现有归因方法的显著局限性，需要未来进一步改进。

Abstract: Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\pm$2.3\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.

</details>


### [594] [CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction](https://arxiv.org/abs/2601.12917)
*He Sun,Jinrui Zhou,Li Li,Mingjun Xiao*

Main category: cs.LG

Relevance: 85.0

TL;DR: CooperLLM：一种云辅助的边缘端协同联邦微调框架，结合移动设备上的零阶优化和云端的梯度修正，显著降低内存使用、加速收敛并提高精度


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在移动设备上微调面临内存和计算成本高的挑战，而现有联邦学习方法要么依赖内存密集型反向传播，要么使用收敛慢、精度低的零阶优化方法

Method: 提出CooperLLM框架：移动客户端在私有数据上执行轻量级零阶优化更新，云端在辅助公共数据上使用反向传播微调，并通过注入引导扰动来修正本地更新；引入流水线调度和自适应压缩来优化系统瓶颈

Result: 在多个Transformer模型和数据集上的实验表明，CooperLLM将设备内存减少高达86.4%，加速收敛8.8倍，相比最先进的零阶优化基线提高精度达10个百分点

Conclusion: CooperLLM通过云辅助的边缘端协同设计，在保护隐私的同时有效解决了移动设备上LLM联邦微调的内存、收敛和精度问题

Abstract: Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\%$, accelerates convergence by $8.8 \times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.

</details>


### [595] [PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient](https://arxiv.org/abs/2601.12988)
*Zijian Wang,Tiancheng Huang,Hanqi Li,Da Ma,Lu Chen,Kai Yu*

Main category: cs.LG

Relevance: 85.0

TL;DR: PaperCompass：一个基于认知科学启发的框架，通过分离高层规划与细粒度执行来提高LLM阅读科学论文的效率，使用Draft-and-Follow Policy Optimization（DFPO）训练方法


<details>
  <summary>Details</summary>
Motivation: 科学文献快速增长使得研究人员难以通过手动阅读跟踪新进展，现有LLM代理方法要么依赖大量工程化提示，要么使用传统SFT-RL训练流程，导致过度探索和低效

Method: 提出PaperCompass框架：1）先制定明确计划大纲行动序列；2）通过详细推理实例化每个步骤，选择相应函数调用的参数。引入DFPO训练方法，联合优化草稿计划和最终解决方案，可视为轻量级分层强化学习

Result: 在Paper-QA基准测试中，PaperCompass在保持性能的同时提高了效率，实现了与更大模型相当的结果

Conclusion: 通过分离规划与执行，PaperCompass框架有效缩小了LLM中的"知行差距"，提供更稳定可靠的训练过程，为科学文献处理提供了高效解决方案

Abstract: The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.

</details>


### [596] [PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning](https://arxiv.org/abs/2601.13020)
*Zhiyan Hou,Haiyun Guo,Haokai Ma,Yandu Sun,Yonghui Yang,Jinqiao Wang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出PASs（通路激活子空间）方法解决多模态大语言模型持续指令调优中的专家共漂移问题，通过PAS引导的重加权和PAS感知的秩稳定化提升性能并减少遗忘


<details>
  <summary>Details</summary>
Motivation: 现有基于LoRA的MoE方法在持续指令调优中，路由器和专家会共同漂移，导致专家职责模糊和遗忘问题。作者将这种现象称为"错位共漂移"，需要解决专家能力对齐和路由校准的问题。

Method: 提出PASs（通路激活子空间）概念，捕捉每个专家中低秩通路方向的激活模式。基于此开发PASs-based MoE-LoRA方法，包含两个组件：1) PAS引导的重加权：利用专家通路激活信号校准路由；2) PAS感知的秩稳定化：选择性稳定对先前任务重要的秩方向。

Result: 在持续指令调优基准测试中，该方法在准确率和抗遗忘性方面均优于传统持续学习基线和多种MoE-LoRA变体，且不增加参数数量。

Conclusion: PASs提供了一个能力对齐的坐标系，有效解决了专家共漂移问题，为多模态大语言模型的持续指令调优提供了更稳定的路由和保存机制。

Abstract: Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.

</details>


### [597] [Analysis of Long Range Dependency Understanding in State Space Models](https://arxiv.org/abs/2601.13048)
*Srividya Ravikumar,Abhinav Anand,Shweta Verma,Mira Mezini*

Main category: cs.LG

Relevance: 85.0

TL;DR: 首次对在真实任务（源代码漏洞检测）上训练的S4D模型进行系统性核可解释性研究，发现S4D的长程建模能力因架构不同而有显著差异，其核可表现为低通、带通或高通滤波器。


<details>
  <summary>Details</summary>
Motivation: 尽管状态空间模型（SSMs）在长序列基准测试中表现出色，但现有研究大多关注预测准确性而非可解释性。本文旨在填补这一空白，首次对在真实世界任务上训练的S4D模型进行系统性核可解释性分析。

Method: 通过时域和频域分析S4D核函数，研究不同模型架构下S4D的长程建模能力变化。具体分析S4D核在不同架构下的滤波器特性（低通、带通、高通）。

Result: 研究发现S4D的长程建模能力在不同模型架构下存在显著差异，直接影响模型性能。S4D核可根据架构表现为不同类型的滤波器（低通、带通或高通滤波器）。

Conclusion: 本文的分析结果为未来设计更好的基于S4D的模型提供了指导，强调了架构选择对状态空间模型长程建模能力的重要影响。

Abstract: Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.

</details>


### [598] [FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference](https://arxiv.org/abs/2601.13143)
*Chaeyoung Jung,Youngjoon Jang,Seungwoo Lee,Joon Son Chung*

Main category: cs.LG

Relevance: 85.0

TL;DR: FastAV是首个针对音频-视觉大语言模型（AV-LLMs）的token剪枝框架，通过两阶段剪枝策略减少40%以上计算量，同时保持或提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 虽然token剪枝在标准LLMs和视觉语言模型中已被广泛研究，但在AV-LLMs中却很少被关注。多模态集成显著增加了token需求，因此需要专门的剪枝方法来提高计算效率。

Method: 提出基于注意力权重的剪枝策略：1）中间层全局剪枝，移除广泛影响力较小的token；2）后续层精细剪枝，考虑对下一个token生成的影响。该方法不依赖完整注意力图，与FlashAttention等高效注意力机制完全兼容。

Result: 在两种代表性AV-LLMs上，FastAV将FLOPs减少超过40%，同时保持甚至提升了模型性能。

Conclusion: FastAV为AV-LLMs提供了有效的token剪枝解决方案，显著降低了计算成本，同时保持了模型性能，填补了该领域的研究空白。

Abstract: In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.

</details>


### [599] [Training instability in deep learning follows low-dimensional dynamical principles](https://arxiv.org/abs/2601.13160)
*Zhipeng Zhang,Zhenjie Yao,Kai Li,Lei Yang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出从动力学系统视角研究深度学习训练稳定性，将稳定性分为优化、环境/数据、参数和学习信号四个维度，通过受控扰动审计识别训练稳定性规律，发现最终性能与训练稳定性经常解耦、受控随机性可缓冲学习动力学、低维潜在元状态偏差可预测性能崩溃。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统虽然取得显著经验性能，但训练过程本身的稳定性仍缺乏理解。训练作为高维动力学系统，对优化、数据、参数或学习信号的小扰动可能引发突然且不可逆的崩溃，损害可复现性和可扩展性。需要建立统一的理论框架来表征和理解训练稳定性。

Method: 提出统一的动力学视角，将训练稳定性组织为四个相互作用维度：优化稳定性、环境/数据稳定性、参数稳定性、学习信号稳定性。通过受控扰动审计训练轨迹来操作化这一视角，在不修改学习算法的情况下探测学习动力学对结构化扰动的响应。

Result: 在强化学习和大型语言模型训练中识别出三个重复规律：1) 高最终性能经常与训练稳定性解耦；2) 受控随机性在不同范式中一致地缓冲学习动力学；3) 低维潜在元状态中的偏差系统性地先于可观察的性能崩溃出现。

Conclusion: 训练稳定性可作为学习系统的可测量和可比较的动力学特性，为超越最终性能结果研究学习动力学提供了描述性基础。这有助于理解训练过程的鲁棒性和可预测性。

Abstract: Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.
  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.
  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.

</details>


### [600] [A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms](https://arxiv.org/abs/2601.13243)
*Yapeng Li,Jiakuo Yu,Zhixin Liu,Xinnan Liu,Jing Yu,Songze Li,Tonghua Su*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文对LLM推理范式进行了系统评估，包括单模型直接生成、思维链增强推理和多智能体系统，分析了成本-准确率权衡，并提出了新的开放式基准MIMeBench来评估语义能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为推理系统部署时，不同推理范式（如思维链和多智能体系统）的相对有效性、成本-准确率权衡以及语义能力评估缺乏系统研究，需要全面评估来指导实践选择。

Method: 1) 对三种推理范式进行统一评估：直接单模型生成、思维链增强单模型推理、代表性多智能体系统工作流；2) 使用角色隔离分析探究MAS中角色特定能力需求；3) 分析成本-准确率权衡；4) 提出新基准MIMeBench评估语义抽象和对比判别能力。

Result: 1) 结构复杂性增加并不总是带来推理性能提升，其效益高度依赖于推理范式本身的特性和适用性；2) 识别了哪些MAS工作流在成本和准确率间达到良好平衡，哪些存在边际收益但成本过高；3) MIMeBench提供了现有基准难以捕捉的语义能力细粒度评估。

Conclusion: 推理范式的选择应基于任务特性和成本约束，而非盲目追求结构复杂性。MIMeBench为LLM语义能力评估提供了新维度，有助于更全面地理解LLM推理能力。

Abstract: Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.

</details>


### [601] [Do Instruction-Tuned Models Always Perform Better Than Base Models? Evidence from Math and Domain-Shifted Benchmarks](https://arxiv.org/abs/2601.13244)
*Prateek Munjal,Clement Christophe,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.LG

Relevance: 85.0

TL;DR: 指令微调并不增强推理能力，而是诱导表面模式匹配：在零样本思维链设置中，基础模型优于指令微调模型，且微调增益在分布偏移下脆弱


<details>
  <summary>Details</summary>
Motivation: 研究指令微调是否真正提升大语言模型的推理能力，还是仅仅诱导表面模式匹配，通过系统评估揭示指令微调的局限性

Method: 在标准数学基准测试、结构扰动变体和领域转移任务上评估基础和指令微调模型，分析它们在零样本思维链、少样本提示等不同设置下的表现

Result: 1) 在GSM8K零样本思维链设置中，基础模型始终优于指令微调变体（Llama3-70B下降高达32.67%）；2) 指令微调模型仅在提供少样本示例时匹配或超越基础模型；3) 在MedCalc领域特定基准测试中，基础模型优于指令微调变体；4) 指令微调模型在扰动数据集上表现急剧下降

Conclusion: 指令微调并不增强内在推理能力，而是使模型依赖特定提示模式，其性能增益不稳定且对分布偏移脆弱，这对当前指令微调实践提出了重要质疑

Abstract: Instruction finetuning is standard practice for improving LLM performance, yet it remains unclear whether it enhances reasoning or merely induces surface-level pattern matching. We investigate this by evaluating base and instruction-tuned models on standard math benchmarks, structurally perturbed variants, and domain-shifted tasks. Our analysis highlights two key (often overlooked) limitations of instruction tuning. First, the performance advantage is unstable and depends heavily on evaluation settings. In zero-shot CoT settings on GSM8K, base models consistently outperform instruction-tuned variants, with drops as high as 32.67\% (Llama3-70B). Instruction-tuned models only match or exceed this performance when provided with few-shot exemplars, suggesting a reliance on specific prompting patterns rather than intrinsic reasoning. Second, tuning gains are brittle under distribution shift. Our results show that base models surpass instruction-tuned variants on the domain-specific MedCalc benchmark. Additionally, instruction-tuned models show sharp declines on perturbed datasets, indicating sensitivity to prompt structure over robust reasoning.

</details>


### [602] [Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning](https://arxiv.org/abs/2601.13284)
*Duygu Nur Yaldiz,Evangelia Spiliopoulou,Zheng Qi,Siddharth Varia,Srikanth Doss,Nikolaos Pappas*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文系统研究了LLM在监督微调(SFT)和强化学习(RLVR)两种微调范式下的校准问题，发现RLVR虽然提升任务性能但产生过度自信模型，而SFT校准更好但性能提升较小。作者提出了一种校准感知的强化学习方法，在保持RLVR准确性的同时缓解过度自信问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地应用于决策任务，不仅需要准确性，还需要可靠的置信度估计。良好校准的置信度使下游系统能够决定何时信任模型、何时依赖备用机制。然而，当前对LLM在不同微调范式下校准特性的理解不足，特别是RLVR方法虽然提升性能但可能导致过度自信问题。

Method: 1. 系统研究SFT和RLVR两种微调范式的校准特性；2. 通过针对性实验诊断RLVR失败原因，发现决策令牌在推理轨迹中仅作为决策提取步骤，不携带置信度信息；3. 提出校准感知的强化学习公式，直接调整决策令牌概率，在保持RLVR准确性的同时改善校准。

Result: 1. RLVR虽然提升任务性能，但产生极度过度自信的模型；2. SFT在分布偏移下仍能保持更好的校准，但性能提升较小；3. 提出的校准感知强化学习方法在保持RLVR准确性水平的同时显著缓解过度自信，将ECE分数降低多达9个点。

Conclusion: RLVR方法虽然能提升LLM的任务性能，但会导致严重的过度自信问题，而SFT在保持良好校准方面更优。通过理解决策令牌在推理中的作用机制，提出的校准感知强化学习方法能够在不牺牲准确性的情况下显著改善模型校准，为LLM在决策任务中的可靠部署提供了重要解决方案。

Abstract: Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.

</details>


### [603] [On the Relation of State Space Models and Hidden Markov Models](https://arxiv.org/abs/2601.13357)
*Aydin Ghojogh,M. Hadi Sepanj,Benyamin Ghojogh*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文系统比较了HMMs、线性高斯状态空间模型、卡尔曼滤波与当代NLP状态空间模型，通过概率图模型视角分析其公式、推理算法和学习方法，澄清了这些模型之间的等价性和根本差异。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型(SSMs)和隐马尔可夫模型(HMMs)是序列数据建模的基础框架，但它们在潜在状态性质、概率假设、推理过程等方面存在根本差异。近年来，确定性状态空间模型通过S4和Mamba等架构在NLP中重新出现，引发了关于经典概率SSMs、HMMs与现代神经序列模型关系的新问题。

Method: 通过概率图模型视角进行统一系统比较，分析HMMs、线性高斯状态空间模型、卡尔曼滤波和当代NLP状态空间模型的公式化表示，检查前向后向推理和卡尔曼滤波等推理算法，对比EM算法和基于梯度的优化等学习过程。

Result: 阐明了这些模型在结构相似性和语义差异，明确了它们何时等价、何时根本不同，以及现代NLP SSMs如何与经典概率模型相关联，为控制理论、概率建模和现代深度学习提供了桥梁视角。

Conclusion: 该分析建立了经典概率模型与现代深度学习架构之间的联系，为理解状态空间模型在不同领域的应用提供了统一框架，特别有助于澄清Mamba等现代架构与经典SSMs/HMMs的理论关系。

Abstract: State Space Models (SSMs) and Hidden Markov Models (HMMs) are foundational frameworks for modeling sequential data with latent variables and are widely used in signal processing, control theory, and machine learning. Despite their shared temporal structure, they differ fundamentally in the nature of their latent states, probabilistic assumptions, inference procedures, and training paradigms. Recently, deterministic state space models have re-emerged in natural language processing through architectures such as S4 and Mamba, raising new questions about the relationship between classical probabilistic SSMs, HMMs, and modern neural sequence models.
  In this paper, we present a unified and systematic comparison of HMMs, linear Gaussian state space models, Kalman filtering, and contemporary NLP state space models. We analyze their formulations through the lens of probabilistic graphical models, examine their inference algorithms -- including forward-backward inference and Kalman filtering -- and contrast their learning procedures via Expectation-Maximization and gradient-based optimization. By highlighting both structural similarities and semantic differences, we clarify when these models are equivalent, when they fundamentally diverge, and how modern NLP SSMs relate to classical probabilistic models. Our analysis bridges perspectives from control theory, probabilistic modeling, and modern deep learning.

</details>


### [604] [Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility](https://arxiv.org/abs/2601.13398)
*Nickil Maveli,Antonio Vergari,Shay B. Cohen*

Main category: cs.LG

Relevance: 85.0

TL;DR: RTCE是一个评估代码LLM往返执行一致性的基准，测试模型在编码-解码操作中保持双向映射的能力，发现现有模型缺乏真正的往返一致性。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在代码基准测试中表现良好，但往返代码执行揭示了它们在前后向执行中保持一致性推理的局限性。现有基准主要关注I/O预测或执行推理，缺乏对双向一致性的系统性评估。

Method: 提出了RoundTripCodeEval(RTCE)基准，包含四个不同的代码执行推理任务，采用免执行的精确匹配评估双向映射保真度。评估了零样本提示、监督微调和自反思机制三种方法。

Result: 所有方法都只带来适度改进，但都无法弥补差距，表明当前LLM在真正的往返一致性方面存在困难，缺乏可信代码推理所需的内在连贯性。

Conclusion: RTCE揭示了现有I/O预测、执行推理或往返自然语言基准无法捕捉的新见解，表明当前LLM缺乏可信代码推理所需的内部一致性。

Abstract: LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.

</details>


### [605] [Fairness-informed Pareto Optimization : An Efficient Bilevel Framework](https://arxiv.org/abs/2601.13448)
*Sofiane Tanji,Samuel Vaiter,Yassine Laguel*

Main category: cs.LG

Relevance: 85.0

TL;DR: BADR是一个双层自适应重标量化框架，用于为任何公平性指标恢复最优帕累托效率模型，解决了现有公平机器学习方法常产生帕累托无效模型的问题。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习方法存在两个主要问题：1）传统方法（如公平正则化）常产生帕累托无效模型，即某些群体的性能可以在不损害其他群体的情况下得到改善；2）现有帕累托效率方法偏向特定公平视角，无法适应文献中广泛研究的各种公平性指标。

Method: BADR采用双层自适应重标量化框架：下层是加权经验风险最小化任务，权重是各群体的凸组合；上层优化选定的公平性目标。框架包含两种新颖的大规模单循环算法BADR-GD和BADR-SGD，并建立了收敛保证。

Result: BADR能够为任何公平性指标恢复最优帕累托效率模型，优于现有的帕累托效率公平方法。作者发布了badr开源Python工具箱，支持多种学习任务和公平性指标。

Conclusion: BADR提供了一个通用框架，能够为任何公平性指标找到帕累托最优模型，解决了现有方法的局限性，并通过开源工具箱促进实际应用。

Abstract: Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.

</details>


### [606] [Preconditioning Benefits of Spectral Orthogonalization in Muon](https://arxiv.org/abs/2601.13474)
*Jianhao Ma,Yu Huang,Yuejie Chi,Yuxin Chen*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文分析了Muon优化器的简化版本，通过矩阵分解和线性Transformer的上下文学习两个案例，证明了Muon在谱域中具有与条件数无关的线性收敛性，优于梯度下降和Adam。


<details>
  <summary>Details</summary>
Motivation: Muon优化器作为大语言模型预训练的重要算法，其核心机制——梯度正交化的作用——仍缺乏深入理解。现有研究很少提供端到端的理论分析来解释Muon在实际应用中的优势。

Method: 研究Muon优化器的简化变体，通过两个具体案例进行分析：1) 矩阵分解问题；2) 线性Transformer的上下文学习。在谱域中将Muon动态解耦为独立的标量序列，分析其收敛行为。

Result: 证明了简化Muon在这两个问题上都能实现线性收敛，且迭代复杂度与相关条件数无关。理论分析表明Muon在谱域中通过梯度正交化产生预条件效应，优于梯度下降和Adam。

Conclusion: Muon优化器的谱正交化机制在矩阵优化问题中具有预条件效应，能够实现与条件数无关的快速收敛。这为理解Muon在大语言模型训练中的有效性提供了理论依据。

Abstract: The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.

</details>


### [607] [Patterning: The Dual of Interpretability](https://arxiv.org/abs/2601.13548)
*George Wang,Daniel Murfet*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文提出了"模式化"作为机制可解释性的对偶问题：给定期望的泛化形式，确定产生它的训练数据。通过基于敏感性的方法，可以反演线性响应关系来设计数据干预，从而引导模型达到目标内部配置。


<details>
  <summary>Details</summary>
Motivation: 机制可解释性研究神经网络如何泛化到训练数据之外，但现有方法主要关注从训练好的模型中"读取"内部结构。本文提出对偶问题：如何通过设计训练数据来"写入"期望的泛化模式，实现从数据到模型内部结构的可控引导。

Method: 基于敏感性概念，测量可观测量后验期望值对数据分布微小变化的响应。通过反演这种线性响应关系，计算出能够引导模型达到目标内部配置的数据干预策略。在小型语言模型和合成括号平衡任务中验证方法。

Result: 1) 在小型语言模型中，沿主要敏感性方向重新加权训练数据可以加速或延迟结构形成（如归纳电路）；2) 在括号平衡任务中，当多个算法都能达到完美训练准确率时，模式化可以通过针对每个解决方案的局部学习系数来选择模型学习的算法。

Conclusion: 建立了用于读取内部结构的数学框架可以反演用于写入内部结构，为可控模型训练提供了理论基础。模式化作为机制可解释性的对偶问题，开启了通过数据设计引导模型学习特定泛化模式的新研究方向。

Abstract: Mechanistic interpretability aims to understand how neural networks generalize beyond their training data by reverse-engineering their internal structures. We introduce patterning as the dual problem: given a desired form of generalization, determine what training data produces it. Our approach is based on susceptibilities, which measure how posterior expectation values of observables respond to infinitesimal shifts in the data distribution. Inverting this linear response relationship yields the data intervention that steers the model toward a target internal configuration. We demonstrate patterning in a small language model, showing that re-weighting training data along principal susceptibility directions can accelerate or delay the formation of structure, such as the induction circuit. In a synthetic parentheses balancing task where multiple algorithms achieve perfect training accuracy, we show that patterning can select which algorithm the model learns by targeting the local learning coefficient of each solution. These results establish that the same mathematical framework used to read internal structure can be inverted to write it.

</details>


### [608] [ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits](https://arxiv.org/abs/2601.13563)
*Aryan Karmore*

Main category: cs.LG

Relevance: 85.0

TL;DR: ButterflyMoE：通过几何参数化打破MoE线性内存扩展瓶颈，将专家视为共享量化基质的几何重定向，实现次线性内存增长


<details>
  <summary>Details</summary>
Motivation: 传统MoE方法需要存储N个独立的专家权重矩阵，内存复杂度为O(N·d²)，超出边缘设备内存预算。现有压缩方法（量化、剪枝、低秩分解）只能减少常数因子，无法解决扩展瓶颈问题。

Method: 将专家视为共享量化基质的几何重定向，而非独立权重矩阵。通过对共享三元原型应用学习到的旋转，每个专家实现O(d² + N·d log d)内存复杂度。训练这些旋转与量化结合可以减少激活异常值并稳定极低位训练。

Result: 在语言建模基准测试中，ButterflyMoE在256个专家时实现150倍内存减少，精度损失可忽略。这使得64个专家可以部署在4GB设备上，而标准MoE只能部署8个专家。

Conclusion: 几何参数化打破了MoE的线性内存扩展瓶颈，实现了次线性内存增长，使大规模专家模型能够在资源受限的边缘设备上部署。

Abstract: Linear memory scaling stores $N$ independent expert weight matrices requiring $\mathcal{O}(N \cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\mathcal{O}(d^2 + N \cdot d \log d)$ memory -- sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150 times memory reduction at 256 experts with negligible accuracy loss. This allows 64 experts to fit on 4GB devices compared to standard MoE's 8 experts, showing geometric parametrization breaks linear scaling.

</details>


### [609] [Self-Improvement as Coherence Optimization: A Theoretical Account](https://arxiv.org/abs/2601.13566)
*Tianyi Qiu,Ahmed Hani Ismail,Zhonghao He,Shi Feng*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文提出"一致性优化"理论框架，解释语言模型无需外部监督的自我改进方法（如辩论、自举、内部一致性最大化）的工作原理，证明这些方法都是压缩性和联合可预测性优化的特例。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型无需外部监督就能提高准确性的现象（如辩论、自举等方法），这些方法甚至能达到有监督微调的性能，但其工作原理缺乏理论解释。

Method: 提出一致性优化理论框架：寻找最可压缩且联合可预测的上下文到行为的映射。证明一致性优化等价于描述长度正则化，并推导出在半监督学习中的最优性条件。

Result: 理论分析表明无反馈自我改进方法的工作原理，并预测其成功或失败的条件。初步实验支持理论结论。

Conclusion: 一致性优化为语言模型自我改进提供了统一的理论解释，揭示了压缩性和可预测性在无监督学习中的核心作用。

Abstract: Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.

</details>


### [610] [Behavior Knowledge Merge in Reinforced Agentic Models](https://arxiv.org/abs/2601.13572)
*Xiangchi Yuan,Dachuan Shi,Chunhui Zhang,Zheyuan Liu,Shenglong Yao,Soroush Vosoughi,Wenke Lee*

Main category: cs.LG

Relevance: 85.0

TL;DR: RAM是一个专门为RL训练的智能体模型设计的分布感知融合框架，通过分离共享和任务特定的参数更新，在保持任务特定能力的同时实现智能体融合。


<details>
  <summary>Details</summary>
Motivation: 现有的模型融合方法主要针对监督微调（SFT）设计，不适用于RL训练的智能体模型。RL产生的任务向量是稀疏且异质的，而SFT融合方法假设密集且全局可比的向量，导致RL智能体融合时任务特定能力被稀释。

Method: RAM框架明确区分共享参数更新和任务特定参数更新：对共享组件进行平均，同时选择性地保留和重新缩放独特组件，以抵消参数更新稀释。该方法能够保持RL智能体的关键任务特定行为。

Result: 在多个智能体领域和模型架构上的实验表明，RAM不仅超越了现有的融合基线方法，还能解锁智能体之间的协同潜力，在各自领域实现优于专门化智能体的性能。

Conclusion: RAM为RL训练的智能体模型提供了一种有效的融合框架，解决了任务向量不匹配问题，能够保持任务特定能力并实现智能体协同，对构建通用智能体模型具有重要意义。

Abstract: Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.

</details>


### [611] [Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models](https://arxiv.org/abs/2601.13599)
*Linrui Ma,Yufei Cui,Kai Han,Yunhe Wang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出Diffusion in Diffusion框架，通过"草稿-精炼"两阶段方法解决块扩散语言模型的不可逆性和短视问题，在OpenWebText数据集上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 块扩散语言模型结合了自回归和扩散模型的优势，但其严格的单向块依赖导致不可逆性和缺乏全局规划能力，限制了扩散模型的优势发挥

Method: 采用两阶段框架：1) 使用小块进行快速草稿生成（块扩散），2) 通过全局双向扩散进行精炼，使用快照置信度重掩码识别需要修改的关键token，并采用混合尺度训练扩展模型的全局能力

Result: 在OpenWebText数据集上为离散扩散模型设定了新基准，仅使用基线模型26%的微调预算，将生成困惑度从25.7降至21.9，显著缩小了与自回归模型的性能差距

Conclusion: Diffusion in Diffusion框架有效解决了块扩散模型的局限性，在保持效率的同时显著提升了生成质量，为离散扩散模型的发展提供了新方向

Abstract: Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. In order to address these issues, we propose Diffusion in Diffusion, a draft-then-refine framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilise snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using just 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.

</details>


### [612] [ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks](https://arxiv.org/abs/2601.13824)
*Xiaohong Yang,Tong Xie,Minghui Liwang,Chikai Shang,Yang Lu,Zhenzhen Jiao,Liqun Fu,Seyyedali Hosseinalipour*

Main category: cs.LG

Relevance: 85.0

TL;DR: ELSA是一个用于边缘网络LLM微调的高效框架，结合了分割学习和分层联邦学习，通过客户端聚类、模型分割和轻量通信方案解决资源限制、数据异构和隐私风险问题。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上训练大型语言模型面临三大挑战：设备资源限制、严重的数据异构性和高隐私风险。现有方法难以同时解决这些问题，需要一种系统性的解决方案。

Method: 1. 任务无关的行为感知客户端聚类机制，使用公共探针输入和对称KL散度构建语义指纹，结合预测一致性信任评分和延迟感知边缘分配
2. 将LLM分割为三部分分布在客户端和边缘服务器，云端仅用于适配器聚合
3. 基于计算草图结合语义子空间正交扰动的轻量通信方案

Result: 在多样化NLP任务上的实验表明，ELSA在适应性、收敛行为和鲁棒性方面持续优于最先进方法，为资源受限的边缘侧LLM微调提供了可扩展且隐私感知的解决方案。

Conclusion: ELSA通过系统集成分割学习和分层联邦学习，有效解决了边缘LLM训练的资源、异构性和隐私挑战，为边缘AI应用提供了实用的框架。

Abstract: Training large language models (LLMs) at the network edge faces fundamental challenges arising from device resource constraints, severe data heterogeneity, and heightened privacy risks. To address these, we propose ELSA (Efficient LLM-centric Split Aggregation), a novel framework that systematically integrates split learning (SL) and hierarchical federated learning (HFL) for distributed LLM fine-tuning over resource-constrained edge networks. ELSA introduces three key innovations. First, it employs a task-agnostic, behavior-aware client clustering mechanism that constructs semantic fingerprints using public probe inputs and symmetric KL divergence, further enhanced by prediction-consistency-based trust scoring and latency-aware edge assignment to jointly address data heterogeneity, client unreliability, and communication constraints. Second, it splits the LLM into three parts across clients and edge servers, with the cloud used only for adapter aggregation, enabling an effective balance between on-device computation cost and global convergence stability. Third, it incorporates a lightweight communication scheme based on computational sketches combined with semantic subspace orthogonal perturbation (SS-OP) to reduce communication overhead while mitigating privacy leakage during model exchanges. Experiments across diverse NLP tasks demonstrate that ELSA consistently outperforms state-of-the-art methods in terms of adaptability, convergence behavior, and robustness, establishing a scalable and privacy-aware solution for edge-side LLM fine-tuning under resource constraints.

</details>


### [613] [A universal linearized subspace refinement framework for neural networks](https://arxiv.org/abs/2601.13989)
*Wenbo Cao,Weiwei Zhang*

Main category: cs.LG

Relevance: 85.0

TL;DR: LSR是一种架构无关的框架，利用固定训练网络状态的Jacobian诱导线性残差模型，通过求解子空间内的最小二乘问题，显著提升梯度训练模型的精度，无需修改网络架构或训练过程。


<details>
  <summary>Details</summary>
Motivation: 神经网络通常使用基于梯度的方法训练，但最终预测精度往往远未达到模型表达能力可达到的水平。梯度训练即使在局部线性化产生凸问题时，也常常无法达到可达到的精度，这表明损失诱导的数值病态性可能是主要瓶颈。

Method: LSR利用固定训练网络状态的Jacobian诱导线性残差模型，在子空间内求解简化的直接最小二乘问题，计算线性化残差模型的子空间最优解。对于具有复合损失结构的算子约束问题，进一步引入迭代LSR，交替进行一次性LSR和监督非线性对齐。

Result: LSR系统性地暴露了梯度训练未充分利用的精度水平，经常实现数量级的误差减少。在监督函数逼近、数据驱动的算子学习和物理信息算子微调等任务中，LSR显著优于标准梯度训练解决方案。

Conclusion: LSR通过将非线性神经表示与固定线性化点的降阶线性求解器桥接，为监督学习、算子学习和科学计算提供了一个数值基础且广泛适用的精炼框架。

Abstract: Neural networks are predominantly trained using gradient-based methods, yet in many applications their final predictions remain far from the accuracy attainable within the model's expressive capacity. We introduce Linearized Subspace Refinement (LSR), a general and architecture-agnostic framework that exploits the Jacobian-induced linear residual model at a fixed trained network state. By solving a reduced direct least-squares problem within this subspace, LSR computes a subspace-optimal solution of the linearized residual model, yielding a refined linear predictor with substantially improved accuracy over standard gradient-trained solutions, without modifying network architectures, loss formulations, or training procedures. Across supervised function approximation, data-driven operator learning, and physics-informed operator fine-tuning, we show that gradient-based training often fails to access this attainable accuracy, even when local linearization yields a convex problem. This observation indicates that loss-induced numerical ill-conditioning, rather than nonconvexity or model expressivity, can constitute a dominant practical bottleneck. In contrast, one-shot LSR systematically exposes accuracy levels not fully exploited by gradient-based training, frequently achieving order-of-magnitude error reductions. For operator-constrained problems with composite loss structures, we further introduce Iterative LSR, which alternates one-shot LSR with supervised nonlinear alignment, transforming ill-conditioned residual minimization into numerically benign fitting steps and yielding accelerated convergence and improved accuracy. By bridging nonlinear neural representations with reduced-order linear solvers at fixed linearization points, LSR provides a numerically grounded and broadly applicable refinement framework for supervised learning, operator learning, and scientific computing.

</details>


### [614] [A model of errors in transformers](https://arxiv.org/abs/2601.14175)
*Suvrat Raju,Praneeth Netrapalli*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文研究LLM在确定性任务（如算术）上的错误率，提出错误源于注意力机制小误差累积超过阈值，建立了一个包含两个参数的错误率定量模型，并通过实验验证了模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在需要确定性输出的任务（如算术）上的错误率，这些任务通常涉及从小集合中重复处理标记。现有研究认为LLM在长重复任务上的错误表明"推理崩溃"或无法表达"组合"函数，但本文试图提供不同的理论解释。

Method: 采用"有效场论"视角，将LLM的众多原始参数重组为两个关键参数：基本噪声率和可能错误标记的数量。通过理论分析推导出错误率与任务复杂度的定量关系，并使用Gemini 2.5 Flash、Gemini 2.5 Pro和DeepSeek R1进行广泛的实证测试。

Result: 实验结果显示预测错误率与观察到的准确率在多种任务上高度一致，验证了理论模型的有效性。同时发现某些情况下存在偏差。研究还展示了如何构建提示来降低错误率。

Conclusion: LLM在确定性任务上的错误源于注意力机制小误差的累积效应，而非"推理崩溃"或组合表达能力不足。提出的两参数模型能够有效预测错误率，为理解和改进LLM在重复性任务上的表现提供了新视角。

Abstract: We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.

</details>


### [615] [InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning](https://arxiv.org/abs/2601.14209)
*Matthew Y. R. Yang,Hao Bai,Ian Wu,Gene Yang,Amrith Setlur,Aviral Kumar*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出Intervention Training (InT)训练范式，通过模型自身对推理轨迹进行细粒度信用分配，识别第一个错误并提出单步干预，从而改善LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习在最终答案层面分配信用，当答案错误时惩罚整个推理轨迹，正确时统一强化所有步骤。这导致正确中间步骤在失败轨迹中被抑制，而虚假步骤在成功轨迹中被强化，即信用分配问题。

Method: 提出Intervention Training (InT)：模型利用数学推理数据集中可用的参考解，识别自身推理中的第一个错误，提出单步干预将轨迹转向正确解。然后对有监督微调应用于错误点之前的策略轨迹与干预的拼接，将错误定位到具体步骤。

Result: 经过InT和后续RL微调后，在4B参数基础模型上，IMO-AnswerBench准确率提升近14%，优于gpt-oss-20b等更大的开源模型。

Conclusion: InT通过让模型对自身推理轨迹进行细粒度信用分配，有效解决了RL中的信用分配问题，为后续RL训练提供了更好的初始化模型。

Abstract: Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.

</details>


### [616] [Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow](https://arxiv.org/abs/2601.14243)
*Haocheng Xi,Charlie Ruan,Peiyuan Liao,Yujun Lin,Han Cai,Yilong Zhao,Shuo Yang,Kurt Keutzer,Song Han,Ligeng Zhu*

Main category: cs.LG

Relevance: 85.0

TL;DR: Jet-RL：首个全面的FP8强化学习训练框架，通过统一的FP8精度流解决现有BF16训练+FP8推理策略的稳定性问题，实现显著加速且保持收敛稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有RL训练流程中，rollout阶段占训练时间70%以上，计算效率低下。FP8量化是缓解这一瓶颈的有前景方法，但常用的BF16训练+FP8推理策略在长序列和复杂任务中会出现严重训练不稳定和精度崩溃问题。

Method: 提出Jet-RL框架，采用统一的FP8精度流同时用于训练和rollout，最小化数值差异，消除低效的跨步骤校准需求。这是首个全面的FP8 RL训练研究。

Result: Jet-RL实现：rollout阶段加速33%，训练阶段加速41%，端到端加速16%（相比BF16训练），在所有设置中保持稳定收敛，精度损失可忽略。

Conclusion: 统一的FP8精度流是解决RL训练中数值不匹配问题的关键，Jet-RL为高效RL训练提供了实用解决方案，在保持稳定性的同时显著提升训练效率。

Abstract: Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.

</details>


### [617] [Enhancing Model Context Protocol (MCP) with Context-Aware Server Collaboration](https://arxiv.org/abs/2601.11595)
*Meenakshi Amulya Jayanti,X. Y. Han*

Main category: cs.DC

Relevance: 85.0

TL;DR: 提出了一种上下文感知的MCP（CA-MCP）框架，通过共享上下文存储来改进多智能体LLM系统的协调效率，减少冗余和LLM调用次数。


<details>
  <summary>Details</summary>
Motivation: 当前MCP框架中的智能体、模型和服务器都是无状态的，缺乏全局上下文，导致多智能体协调任务中存在冗余和效率问题。共享上下文存储可以改善工作流效率和一致性。

Method: 设计了上下文感知MCP（CA-MCP），将执行逻辑卸载到专门的MCP服务器，这些服务器可以读写共享上下文内存，实现实时自主协调。上下文管理作为核心机制，通过跟踪中间状态和共享变量来保持任务执行的连续性。

Result: 在TravelPlanner和REALM-Bench基准数据集上的实验显示，CA-MCP相比传统MCP能显著减少复杂任务所需的LLM调用次数，降低响应失败频率，提高整体效率和响应性。

Conclusion: 通过共享上下文存储的CA-MCP框架在多智能体LLM系统中具有显著优势，能够提高协调效率和任务执行成功率。

Abstract: The Model Context Protocol (MCP) has emerged as a widely used framework for enabling LLM-based agents to communicate with external tools and services. The most common implementation of MCP, proposed by Anthropic, heavily relies on a Large Language Model (LLM) to decompose tasks and issue instructions to servers, which act as stateless executors. In particular, the agents, models, and servers are stateless and do not have access to a global context. However, in tasks involving LLM-driven coordination, it is natural that a Shared Context Store (SCS) could improve the efficiency and coherence of multi-agent workflows by reducing redundancy and enabling knowledge transfer between servers. Thus, in this work, we design and assess the performance of a Context-Aware MCP (CA-MCP) that offloads execution logic to specialized MCP servers that read from and write to a shared context memory, allowing them to coordinate more autonomously in real time. In this design, context management serves as the central mechanism that maintains continuity across task executions by tracking intermediate states and shared variables, thereby enabling persistent collaboration among agents without repeated prompting. We present experiments showing that the CA-MCP can outperform the traditional MCP by reducing the number of LLM calls required for complex tasks and decreasing the frequency of response failures when task conditions are not satisfied, thereby improving overall efficiency and responsiveness. In particular, we conducted experiments on the TravelPlanner and REALM-Bench benchmark datasets and observed statistically significant results indicating the potential advantages of incorporating a shared context store via CA-MCP in LLM-driven multi-agent systems.

</details>


### [618] [TrojanPraise: Jailbreak LLMs via Benign Fine-Tuning](https://arxiv.org/abs/2601.12460)
*Zhixin Xie,Xurui Song,Jun Luo*

Main category: cs.CR

Relevance: 85.0

TL;DR: TrojanPraise是一种利用良性数据微调LLM的新型攻击方法，通过将特定词汇（如"bruaf"）与无害概念关联，然后用该词汇赞美有害内容，从而绕过内容审核，实现高达95.88%的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 商业LLM提供黑盒微调API带来了安全漏洞，攻击者可能通过恶意数据微调来越狱模型。虽然现有研究认为恶意训练数据可被审核模型检测，但本文发现利用良性数据也能实现有效攻击。

Method: 提出TrojanPraise攻击方法：1）使用良性数据微调模型，将特定词汇与无害概念关联；2）用该词汇赞美有害概念，改变模型态度而不改变知识理解；3）从知识和态度两个维度解构LLM内部表示，确保只改变态度维度。

Result: 在5个开源LLM和2个商业LLM上进行实验，TrojanPraise在严格黑盒设置下最高达到95.88%的攻击成功率，同时成功绕过内容审核模型的检测。

Conclusion: 即使使用良性数据进行微调，LLM仍面临安全风险。攻击者可以通过精心设计的词汇关联改变模型态度而不改变知识理解，这揭示了当前LLM安全防护的局限性。

Abstract: The demand of customized large language models (LLMs) has led to commercial LLMs offering black-box fine-tuning APIs, yet this convenience introduces a critical security loophole: attackers could jailbreak the LLMs by fine-tuning them with malicious data. Though this security issue has recently been exposed, the feasibility of such attacks is questionable as malicious training dataset is believed to be detectable by moderation models such as Llama-Guard-3. In this paper, we propose TrojanPraise, a novel finetuning-based attack exploiting benign and thus filter-approved data. Basically, TrojanPraise fine-tunes the model to associate a crafted word (e.g., "bruaf") with harmless connotations, then uses this word to praise harmful concepts, subtly shifting the LLM from refusal to compliance. To explain the attack, we decouple the LLM's internal representation of a query into two dimensions of knowledge and attitude. We demonstrate that successful jailbreak requires shifting the attitude while avoiding knowledge shift, a distortion in the model's understanding of the concept. To validate this attack, we conduct experiments on five opensource LLMs and two commercial LLMs under strict black-box settings. Results show that TrojanPraise achieves a maximum attack success rate of 95.88% while evading moderation.

</details>


### [619] [Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading](https://arxiv.org/abs/2601.13082)
*Advije Rizvani,Giovanni Apruzzese,Pavel Laskov*

Main category: cs.CR

Relevance: 85.0

TL;DR: 该论文研究了针对金融领域LLM的对抗性攻击，通过操纵新闻标题（Unicode同形字替换和隐藏文本）误导交易系统，量化了攻击对投资组合收益的影响（年回报率最多降低17.7个百分点）。


<details>
  <summary>Details</summary>
Motivation: LLM在金融领域应用日益广泛，特别是用于分析新闻情感以指导算法交易决策。然而，威胁者可能制作"对抗性新闻"来误导LLM，现有研究尚未量化这种攻击对LLM支持的算法交易系统的系统性财务风险。

Method: 1) 考虑无直接访问ATS权限但能单日篡改股票相关新闻标题的对手；2) 评估两种人类难以察觉的操纵：Unicode同形字替换（误导股票名称识别）和隐藏文本条款（改变新闻情感）；3) 在Backtrader中实现现实ATS，融合LSTM价格预测和LLM情感分析（FinBERT、FinGPT、FinLLaMA及6个通用LLM）；4) 使用投资组合指标量化财务影响。

Result: 实验显示，在14个月期间进行单日攻击能可靠误导LLM，使年回报率最多降低17.7个百分点。通过分析流行爬虫库和交易平台，并调查27名金融科技从业者，确认了现实可行性。

Conclusion: LLM在金融应用中的对抗性攻击构成实质性财务风险，需要加强安全防护。已通知交易平台所有者此安全问题。

Abstract: Large Language Models (LLMs) are increasingly adopted in the financial domain. Their exceptional capabilities to analyse textual data make them well-suited for inferring the sentiment of finance-related news. Such feedback can be leveraged by algorithmic trading systems (ATS) to guide buy/sell decisions. However, this practice bears the risk that a threat actor may craft "adversarial news" intended to mislead an LLM. In particular, the news headline may include "malicious" content that remains invisible to human readers but which is still ingested by the LLM. Although prior work has studied textual adversarial examples, their system-wide impact on LLM-supported ATS has not yet been quantified in terms of monetary risk. To address this threat, we consider an adversary with no direct access to an ATS but able to alter stock-related news headlines on a single day. We evaluate two human-imperceptible manipulations in a financial context: Unicode homoglyph substitutions that misroute models during stock-name recognition, and hidden-text clauses that alter the sentiment of the news headline. We implement a realistic ATS in Backtrader that fuses an LSTM-based price forecast with LLM-derived sentiment (FinBERT, FinGPT, FinLLaMA, and six general-purpose LLMs), and quantify monetary impact using portfolio metrics. Experiments on real-world data show that manipulating a one-day attack over 14 months can reliably mislead LLMs and reduce annual returns by up to 17.7 percentage points. To assess real-world feasibility, we analyze popular scraping libraries and trading platforms and survey 27 FinTech practitioners, confirming our hypotheses. We notified trading platform owners of this security issue.

</details>


### [620] [Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.11604)
*Jonaid Shianifar,Michael Schukat,Karl Mason*

Main category: cs.LG

Relevance: 75.0

TL;DR: Hindsight Preference Replay (HPR) 是一种简单的回放增强策略，通过重新标记存储的转移数据以使用替代偏好，在多目标强化学习中提高了数据利用效率，显著提升了性能指标。


<details>
  <summary>Details</summary>
Motivation: 现有方法如CAPQL在优化向量值奖励时，只能使用特定偏好下收集的数据，导致其他偏好的离线数据未被利用，限制了学习效率和性能。

Method: 提出Hindsight Preference Replay (HPR)策略，在不改变CAPQL架构或损失函数的情况下，对存储的转移数据进行事后重新标记，使用替代偏好来增强监督信号。

Result: 在6个MO-Gymnasium运动任务中，HPR-CAPQL在5个环境中提高了超体积(HV)，在4个环境中提高了期望效用(EUM)。例如在mo-humanoid-v5中，EUM从323±125提升到1613±464，HV从0.52M提升到9.63M。

Conclusion: HPR是一种简单有效的回放增强策略，能够显著提高多目标强化学习的性能，通过更有效地利用离线数据来增强学习过程。

Abstract: Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\!\pm\!125$ to $1613\!\pm\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.

</details>


### [621] [Task-tailored Pre-processing: Fair Downstream Supervised Learning](https://arxiv.org/abs/2601.11897)
*Jinwon Sohn,Guang Lin,Qifan Song*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出一种面向监督学习的公平性预处理方法，通过HGR相关性分析发现传统数据公平方法正则化过强，设计新的预处理映射平衡公平性与效用，并理论分析下游模型的公平性改进和效用保持。


<details>
  <summary>Details</summary>
Motivation: 现有公平性预处理方法分为两类：数据公平（独立于下游模型）和任务定制公平（考虑监督学习任务）。作者认为数据公平方法从HGR相关性角度看施加了过强的正则化，需要设计更适合监督学习的预处理方法。

Method: 提出一种新颖的监督学习定制预处理框架，考虑公平性与效用的权衡，构建预处理映射。理论分析下游模型在变换数据上的行为，找到保证公平性改进和效用保持的充分条件。

Result: 在表格和图像数据集上的对比实验显示，该方法在多个下游模型中保持一致的权衡性能优于现有方法。特别在计算机视觉数据上，方法仅改变与核心机器学习任务相关的必要语义特征来实现公平性。

Conclusion: 该工作为监督学习公平性预处理提供了理论保证，首次在任务定制方法分支中理论分析预处理数据在下游模型中的保证，展示了在多种数据类型上的优越性能。

Abstract: Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.

</details>


### [622] [Why Loss Re-weighting Works If You Stop Early: Training Dynamics of Unconstrained Features](https://arxiv.org/abs/2601.12011)
*Yize Zhao,Christos Thrampoulidis*

Main category: cs.LG

Relevance: 75.0

TL;DR: 损失重加权在过参数化深度神经网络中无法改变最终学习阶段，但在训练早期能显著改善少数类学习，通过简化模型揭示了重加权如何恢复平衡学习动态


<details>
  <summary>Details</summary>
Motivation: 尽管损失重加权在过参数化深度神经网络中无法改变最终学习结果，但实证表明它在训练早期能带来显著好处。研究者希望透明地展示和分析这一现象，理解重加权如何影响不同类别（多数类和少数类）的学习动态。

Method: 引入一个小规模模型（SSM），该模型专门设计用于抽象深度神经网络架构和输入数据的固有复杂性，同时保持其频谱分量中不平衡结构的关键信息。通过这个简化模型，分析普通经验风险最小化与重加权方法在不同类别学习上的差异。

Result: SSM揭示：普通经验风险最小化在训练早期优先学习区分多数类，从而延迟少数类学习；而重加权方法恢复了平衡的学习动态，使得与多数类和少数类相关的特征能够同时学习。

Conclusion: 损失重加权虽然在过参数化深度神经网络的最终学习阶段无法改变结果，但在训练早期通过恢复平衡学习动态，能够显著改善少数类的学习效果，这对于理解重加权机制的实际价值具有重要意义。

Abstract: The application of loss reweighting in modern deep learning presents a nuanced picture. While it fails to alter the terminal learning phase in overparameterized deep neural networks (DNNs) trained on high-dimensional datasets, empirical evidence consistently shows it offers significant benefits early in training. To transparently demonstrate and analyze this phenomenon, we introduce a small-scale model (SSM). This model is specifically designed to abstract the inherent complexities of both the DNN architecture and the input data, while maintaining key information about the structure of imbalance within its spectral components. On the one hand, the SSM reveals how vanilla empirical risk minimization preferentially learns to distinguish majority classes over minorities early in training, consequently delaying minority learning. In stark contrast, reweighting restores balanced learning dynamics, enabling the simultaneous learning of features associated with both majorities and minorities.

</details>


### [623] [Learning to Factorize and Adapt: A Versatile Approach Toward Universal Spatio-Temporal Foundation Models](https://arxiv.org/abs/2601.12083)
*Siru Zhong,Junjie Qiu,Yangyu Wu,Yiqiu Liu,Yuanpeng He,Zhongwen Rao,Bin Yang,Chenjuan Guo,Hao Xu,Yuxuan Liang*

Main category: cs.LG

Relevance: 75.0

TL;DR: FactoST-v2是一个增强的因子化时空基础模型框架，通过解耦通用时间学习和领域特定空间适应，实现全权重迁移和任意长度泛化，在零样本和少样本场景下达到SOTA精度。


<details>
  <summary>Details</summary>
Motivation: 时空基础模型虽然承诺跨数据集泛化能力，但联合时空预训练计算成本高昂，且难以处理领域特定空间模式的异质性。现有方法在计算效率和泛化能力方面存在局限。

Method: 采用两阶段因子化框架：第一阶段预训练仅编码器骨干网络，使用随机序列掩码捕获不变时间动态，实现跨可变视野的概率分位数预测；第二阶段通过精简适配器，利用元自适应学习和提示快速注入空间感知。

Result: 在多个领域的综合评估表明，FactoST-v2在线性效率下达到最先进精度，在零样本和少样本场景中显著优于现有基础模型，并能与领域特定专家基线相媲美。

Conclusion: 因子化范式为真正通用的时空基础模型提供了实用、可扩展的路径，解决了计算效率和领域适应性的关键挑战。

Abstract: Spatio-Temporal (ST) Foundation Models (STFMs) promise cross-dataset generalization, yet joint ST pretraining is computationally expensive and grapples with the heterogeneity of domain-specific spatial patterns. Substantially extending our preliminary conference version, we present FactoST-v2, an enhanced factorized framework redesigned for full weight transfer and arbitrary-length generalization. FactoST-v2 decouples universal temporal learning from domain-specific spatial adaptation. The first stage pretrains a minimalist encoder-only backbone using randomized sequence masking to capture invariant temporal dynamics, enabling probabilistic quantile prediction across variable horizons. The second stage employs a streamlined adapter to rapidly inject spatial awareness via meta adaptive learning and prompting. Comprehensive evaluations across diverse domains demonstrate that FactoST-v2 achieves state-of-the-art accuracy with linear efficiency - significantly outperforming existing foundation models in zero-shot and few-shot scenarios while rivaling domain-specific expert baselines. This factorized paradigm offers a practical, scalable path toward truly universal STFMs. Code is available at https://github.com/CityMind-Lab/FactoST.

</details>


### [624] [SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics](https://arxiv.org/abs/2601.12131)
*Santosh Chapagain,MohammadReza EskandariNasab,Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

Relevance: 75.0

TL;DR: SolarGPT-QA是基于LLaMA-3构建的领域适应LLM问答系统，专门用于空间天气和太阳物理学教育，通过领域自适应预训练和教学微调平衡科学准确性和教育效果。


<details>
  <summary>Details</summary>
Motivation: 太阳活动对卫星、航空、电网等关键基础设施有重大影响，但现有LLM缺乏领域知识和教学能力来解释复杂的空间科学概念。需要开发专门的教育系统来提高空间科学知识的可及性。

Method: 基于LLaMA-3基础模型，使用科学文献和GPT-4生成的大规模问答数据进行领域自适应预训练，然后用Grok-3以学生友好的故事化风格进行精炼。结合领域自适应预训练和教学微调。

Result: 在零样本设置下优于通用模型，在空间天气和太阳物理学教育解释方面与指令微调模型竞争。学生理解研究表明生成的解释具有更好的清晰度和可访问性。

Conclusion: 领域自适应预训练与教学微调的结合对于平衡科学准确性和教育效果至关重要，这是向更广泛的SolarGPT空间科学教育和预报框架迈出的第一步。

Abstract: Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.
  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.

</details>


### [625] [Distribution Shift Is Key to Learning Invariant Prediction](https://arxiv.org/abs/2601.12296)
*Hong Zheng,Fei Teng*

Main category: cs.LG

Relevance: 75.0

TL;DR: 研究发现训练数据中的分布偏移程度越大，即使使用简单的经验风险最小化（ERM）方法，也能获得更好的泛化性能，甚至接近不变预测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 观察到经验风险最小化（ERM）有时在分布外任务上表现优于专门设计的方法，这促使研究者探究算法设计之外的原因。研究发现分布偏移程度是影响模型性能的关键因素。

Method: 通过理论推导和实证验证相结合的方法：1）提出理论上界，表明分布偏移程度直接影响模型预测能力；2）证明在特定数据条件下，ERM解能达到与不变预测模型相当的性能；3）通过实验验证分布偏移增大时，学习模型的预测接近Oracle或最优模型。

Result: 理论分析显示分布偏移程度与模型预测能力正相关，大偏移能提升模型能力使其接近不变预测模型。实证结果表明，训练数据分布偏移增大时，学习模型的预测确实更接近理想模型。

Conclusion: 分布偏移在模型学习中起关键作用，能促进学习不变预测。即使使用简单的ERM方法，只要训练数据中存在足够大的分布偏移，就能获得良好的泛化性能，这为理解模型泛化提供了新视角。

Abstract: An interesting phenomenon arises: Empirical Risk Minimization (ERM) sometimes outperforms methods specifically designed for out-of-distribution tasks. This motivates an investigation into the reasons behind such behavior beyond algorithmic design. In this study, we find that one such reason lies in the distribution shift across training domains. A large degree of distribution shift can lead to better performance even under ERM. Specifically, we derive several theoretical and empirical findings demonstrating that distribution shift plays a crucial role in model learning and benefits learning invariant prediction. Firstly, the proposed upper bounds indicate that the degree of distribution shift directly affects the prediction ability of the learned models. If it is large, the models' ability can increase, approximating invariant prediction models that make stable predictions under arbitrary known or unseen domains; and vice versa. We also prove that, under certain data conditions, ERM solutions can achieve performance comparable to that of invariant prediction models. Secondly, the empirical validation results demonstrated that the predictions of learned models approximate those of Oracle or Optimal models, provided that the degree of distribution shift in the training data increases.

</details>


### [626] [Explanation Multiplicity in SHAP: Characterization and Assessment](https://arxiv.org/abs/2601.12654)
*Hyunseung Hwang,Seungeun Lee,Lucas Rosenblatt,Julia Stoyanovich,Steven Euijong Whang*

Main category: cs.LG

Relevance: 75.0

TL;DR: SHAP解释存在多重性问题：即使输入、任务和模型固定，多次运行也会产生显著不同的特征归因解释，这种内部有效但实质不同的解释现象称为"解释多重性"。


<details>
  <summary>Details</summary>
Motivation: SHAP等事后解释方法被广泛用于高风险领域的决策验证和审计，但现有研究忽视了这些解释方法本身的不稳定性问题。当同一决策存在多个看似有效但实质不同的解释时，会严重影响解释的可信度和实际应用价值。

Method: 提出了一种系统方法来表征特征归因解释中的多重性现象，区分模型训练/选择带来的变异与解释管道内在随机性的影响。通过随机基线值在合理零模型下量化观察到的分歧，并比较基于幅度的距离度量和基于排名的度量。

Result: 研究发现解释多重性普遍存在，即使对于高置信度预测也是如此。基于幅度的度量可能显示稳定性（接近零），而基于排名的度量则揭示出top特征的身份和排序存在显著变化。

Conclusion: 解释多重性是普遍且持续存在的问题，需要开发与解释预期用途相匹配的度量和基线方法。仅依赖单一解释可能产生误导，应考虑解释的不确定性。

Abstract: Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.

</details>


### [627] [Distilling Time Series Foundation Models for Efficient Forecasting](https://arxiv.org/abs/2601.12785)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Szu-Yu Chen,Yingli Tian*

Main category: cs.LG

Relevance: 75.0

TL;DR: DistilTS：首个专门为时间序列基础模型设计的知识蒸馏框架，通过水平加权目标和时间对齐策略解决预测任务难度差异和架构差异问题，实现模型压缩同时保持预测性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型（TSFMs）通过大规模预训练提供强大的预测性能，但参数量大导致部署成本高。现有的通用知识蒸馏技术无法直接应用于时间序列预测，因为存在预测任务特有的难度差异（短期与长期预测）和架构差异问题。

Method: DistilTS框架包含两个核心组件：1）水平加权目标函数，平衡不同预测水平的学习权重，避免优化被短期预测主导；2）时间对齐策略，减少教师模型与学生模型之间的架构不匹配，专门针对时间序列预测设计。

Result: 在多个基准测试中，DistilTS实现了与完整TSFMs相当的预测性能，同时将参数减少高达1/150，推理速度提升高达6000倍。

Conclusion: DistilTS是首个专门为时间序列基础模型设计的蒸馏框架，有效解决了预测任务特有的挑战，为高效部署时间序列基础模型提供了实用解决方案。

Abstract: Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.

</details>


### [628] [Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning](https://arxiv.org/abs/2601.12816)
*Ishir Garg,Neel Kolhe,Andy Peng,Rohan Gopalam*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出FOPNG优化器，通过Fisher正交投影约束参数更新，在持续学习中防止灾难性遗忘，统一了自然梯度下降与正交梯度方法。


<details>
  <summary>Details</summary>
Motivation: 持续学习需要神经网络在顺序任务中学习新知识，但关键挑战是在学习新任务时不遗忘旧任务。现有方法在欧几里得参数空间操作，缺乏信息几何框架下的统一方法。

Method: 提出Fisher-正交投影自然梯度下降(FOPNG)优化器，将梯度投影到先前任务梯度的Fisher正交补空间。该方法在信息几何框架下统一自然梯度下降与正交梯度方法，更新方向具有重参数化不变性，保证在Fisher度量下下降，并保持先前任务输出。

Result: 在标准持续学习基准测试(Permuted-MNIST、Split-MNIST、Rotated-MNIST、Split-CIFAR10、Split-CIFAR100)上展示了强劲结果，验证了方法的有效性。

Conclusion: FOPNG通过Fisher正交约束提供了一种理论严谨的持续学习优化方法，在信息几何框架下统一了自然梯度与正交梯度方法，有效缓解灾难性遗忘问题。

Abstract: Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks. However, the key challenge in such settings is to learn new tasks without catastrophically forgetting previously learned tasks. We propose the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. We provide theoretical analysis establishing the properties of the projected update, describe efficient and practical implementations using the diagonal Fisher, and demonstrate strong results on standard continual learning benchmarks such as Permuted-MNIST, Split-MNIST, Rotated-MNIST, Split-CIFAR10, and Split-CIFAR100.

</details>


### [629] [Online Continual Learning for Time Series: a Natural Score-driven Approach](https://arxiv.org/abs/2601.12931)
*Edoardo Urettini,Daniele Atzeni,Ioanna-Yvonni Tsaknaki,Antonio Carta*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文将在线持续学习（OCL）应用于在线时间序列预测（OTSF），提出NatSR方法，通过自然梯度下降和t分布似然实现鲁棒优化，结合回放缓冲和动态尺度启发式，在预测性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在线时间序列预测需要快速适应环境变化并保持长期记忆，这与在线持续学习的目标高度一致。论文旨在加强时间序列方法与OCL之间的理论和实践联系，解决现有方法在适应性和鲁棒性方面的不足。

Method: 1) 将神经网络优化重构为参数滤波问题，证明自然梯度下降是一种得分驱动方法并证明其信息论最优性；2) 使用Student's t似然结合自然梯度实现有界更新，提高对异常值的鲁棒性；3) 提出NatSR方法，结合鲁棒优化器、回放缓冲和动态尺度启发式，改进在机制漂移时的快速适应能力。

Result: 实验结果表明，NatSR在预测性能上优于更复杂的现有方法，证明了该方法在在线时间序列预测中的有效性。

Conclusion: 论文成功建立了时间序列方法与在线持续学习之间的理论联系，提出的NatSR方法通过鲁棒优化和自适应机制，在在线时间序列预测中实现了更好的性能，为OCL在时间序列领域的应用提供了新思路。

Abstract: Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student's t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.

</details>


### [630] [Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement](https://arxiv.org/abs/2601.13100)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文提出了一个递归元蒸馏的公理化算子理论框架，将迭代知识蒸馏形式化为概率分布算子序列，证明了在温和假设下锚定递归蒸馏能诱导KL散度收缩，收敛到基教师分布的唯一全局吸引不动点。


<details>
  <summary>Details</summary>
Motivation: 当前概率域知识蒸馏已有单阶段设置的温度缩放、多教师聚合和偏差-方差权衡的公理化框架，但递归或多代蒸馏的数学行为理解不足，先前方法主要依赖经验启发式。需要理论框架来理解迭代蒸馏的稳定性和收敛性。

Method: 引入递归元蒸馏的公理化和算子理论框架，将迭代知识蒸馏形式化为概率分布算子序列，定义有效元教师构建的结构公理，证明满足这些公理的非平凡算子族存在性，在可实现性和凸性假设下分析收敛性。

Result: 证明锚定递归蒸馏在温和假设下诱导KL散度收缩，产生几何收敛到基教师分布，存在唯一全局吸引不动点，为理解迭代蒸馏的稳定性、偏差-方差行为和失败模式提供理论基础。

Conclusion: 该框架是基础性的而非算法性的，刻画了递归蒸馏何时数学上适定且收敛而非误差累积，独立于模型架构、优化细节或具体算子实现，为迭代和多教师蒸馏提供理论依据。

Abstract: Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.
  We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.
  The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.

</details>


### [631] [CooperBench: Why Coding Agents Cannot be Your Teammates Yet](https://arxiv.org/abs/2601.13295)
*Arpandeep Khatua,Hao Zhu,Peter Tran,Arya Prabhudesai,Frederic Sadrieh,Johann K. Lieberwirth,Xinkai Yu,Yicheng Fu,Michael J. Ryan,Jiaxin Pei,Diyi Yang*

Main category: cs.LG

Relevance: 75.0

TL;DR: CooperBench是一个包含600多个协作编码任务的基准测试，用于评估AI代理的团队协作能力。研究发现当前最先进的编码代理存在"协调诅咒"：协作时成功率比单独执行低30%，而人类团队通常能通过协作提高生产力。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在复杂工作中越来越多地协作，它们需要发展协调能力来成为有效的团队成员。然而，作者假设当前代理缺乏这些能力，因此需要创建一个基准来测试和评估AI代理的协作能力。

Method: 创建CooperBench基准，包含12个库中4种编程语言的600多个协作编码任务。每个任务分配两个代理不同的功能特性，这些特性可以独立实现，但如果没有适当协调可能会冲突。任务基于真实开源仓库和专家编写的测试。评估最先进的编码代理，并通过大规模模拟分析协作问题。

Result: 发现"协调诅咒"现象：代理协作时的平均成功率比单独执行两个任务低30%。这与人类团队形成鲜明对比，人类团队通常通过增加队友提高生产力。分析揭示三个关键问题：1)通信渠道被模糊、时机不当和不准确的消息堵塞；2)即使有有效通信，代理也会偏离承诺；3)代理经常对他人计划和通信持有错误期望。但也观察到罕见但有趣的新兴协调行为，包括角色分工、资源分配和谈判。

Conclusion: 该研究提出了一个新颖的协作编码基准，并呼吁从追求单个代理能力转向发展社交智能。AI代理需要发展协调能力才能成为有效的团队成员。

Abstract: Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.

</details>


### [632] [Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models](https://arxiv.org/abs/2601.13580)
*Ahmad Al-Zuraiqi*

Main category: cs.LG

Relevance: 75.0

TL;DR: Neural Organ Transplantation (NOT) 是一种模块化适应框架，可将训练好的Transformer层作为可重用检查点进行领域适应，在解码器模型上显著优于LoRA等现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法将训练参数与特定模型实例和训练数据紧密耦合，缺乏模块化和可重用性。NOT旨在实现训练好的Transformer层作为独立检查点的移植，支持隐私保护的专家知识共享。

Method: 从预训练模型中提取连续层子集（"供体器官"），在领域特定数据上独立训练，保存为独立检查点文件，然后移植到兼容的接收模型中，无需原始训练数据。

Result: 在三个解码器架构（GPT-2、TinyLlama、GPT-OSS，124M到20B参数）上，NOT在困惑度上比LoRA提升一个数量级，训练速度更快。移植位置有依赖性，早期插入效果最佳。

Conclusion: Transformer中间层支持解码器架构的高效模块化迁移，实现隐私保护的检查点共享。该方法目前仅限于解码器模型，在编码器架构上效果有限。

Abstract: We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ("donor organs") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.

</details>


### [633] [TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation](https://arxiv.org/abs/2601.13653)
*Xingjian Wu,Junkai Lu,Zhengyu Li,Xiangfei Qiu,Jilin Hu,Chenjuan Guo,Christian S. Jensen,Bin Yang*

Main category: cs.LG

Relevance: 75.0

TL;DR: TimeART是一个融合强大现成工具分析能力和LLM推理能力的时间序列问答框架，通过收集10万专家轨迹数据集TimeToolBench和四阶段训练策略，训练出8B参数的时间序列推理模型，在多个TSQA任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列分析主要依赖数据科学家，人工成本高且缺乏自动化。需要开发能够自动化分析时间序列数据的智能系统，结合现成工具的分析能力和LLM的推理能力。

Method: 1) 提出TimeART框架，融合现成工具和LLM能力；2) 收集10万专家轨迹数据集TimeToolBench；3) 设计四阶段训练策略（包括从早期经验和自我反思中学习）；4) 训练8B参数的时间序列推理模型。

Result: 训练的8B TSRM在多个时间序列问答任务上取得一致的state-of-the-art性能，为智能时间序列推理开辟了新途径。

Conclusion: TimeART框架结合TimeToolBench数据集和四阶段训练策略，成功实现了智能化的时间序列问答系统，展示了LLM在时间序列分析领域的应用潜力。

Abstract: Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of strong out-of-the-box tools and the reasoning capability of Large Language Models (LLMs), which serves as a fully agentic data scientist for Time Series Question Answering (TSQA). To teach the LLM-based Time Series Reasoning Models (TSRMs) strategic tool-use, we also collect a 100k expert trajectory corpus called TimeToolBench. To enhance TSRMs' generalization capability, we then devise a four-stage training strategy, which boosts TSRMs through learning from their own early experiences and self-reflections. Experimentally, we train an 8B TSRM on TimeToolBench and equip it with the TimeART framework, and it achieves consistent state-of-the-art performance on multiple TSQA tasks, which pioneers a novel approach towards agentic time series reasoning.

</details>


### [634] [Principled Latent Diffusion for Graphs via Laplacian Autoencoders](https://arxiv.org/abs/2601.13780)
*Antoine Siraudin,Christopher Morris*

Main category: cs.LG

Relevance: 75.0

TL;DR: LG-Flow：一种潜在图扩散框架，通过置换等变自编码器将图压缩到低维潜在空间，消除传统图扩散模型的二次复杂度瓶颈，实现高效图生成。


<details>
  <summary>Details</summary>
Motivation: 传统图扩散模型存在二次复杂度问题（节点数平方），且大部分计算资源浪费在稀疏图的空边上。现有潜在扩散方法难以应用于图生成，因为图生成需要近乎无损的重建（邻接矩阵的单个错误就会导致样本无效）。

Method: 1. 使用置换等变自编码器将每个节点映射到固定维嵌入，从该嵌入中可证明完全恢复完整邻接矩阵，实现近乎无损重建（适用于无向图和有向无环图）。2. 潜在表示维度与节点数线性相关，消除二次瓶颈。3. 在潜在空间中训练基于流匹配的扩散变换器，实现高效表达性图生成。

Result: 与最先进的图扩散模型相比，LG-Flow取得竞争性结果，同时实现高达1000倍的加速。

Conclusion: LG-Flow成功解决了图生成中潜在扩散的关键挑战，通过近乎无损的压缩和线性缩放，实现了高效且高质量的图生成，为大规模图生成模型训练开辟了新途径。

Abstract: Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\times$ speed-up.

</details>


### [635] [Multi-Objective Hierarchical Optimization with Large Language Models](https://arxiv.org/abs/2601.13892)
*Andrej Schwanke,Lyubomir Ivanov,David Salinas,Frank Hutter,Arber Zela*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文提出了一种利用LLM作为代理模型和候选采样器的分层搜索策略，用于多目标优化问题。通过自适应分区和局部优化，使LLM专注于高潜力子空间，而非全局问题结构。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在推理能力方面表现出色，但在多目标优化任务中尚未成为首选工具。传统方法因其处理数值输入和平衡探索-利用的能力而表现优异。本文旨在弥补这一差距，将LLM有效应用于多目标优化领域。

Method: 提出分层搜索策略：1）将输入空间自适应划分为不相交的超矩形区域；2）使用复合评分函数对区域进行排名；3）将LLM的生成过程限制在特定高潜力子空间，使其只需进行局部推理而非全局推理。

Result: 理论上证明算法生成的候选解在Hausdorff距离下收敛到真实Pareto集。实证结果表明，该方法持续优于基于LLM的全局多目标优化器，并在合成和真实世界基准测试中与标准进化算法和贝叶斯优化算法表现相当。

Conclusion: 通过结构化分层搜索策略，成功将LLM应用于多目标优化问题，使其能够有效处理数值优化任务，填补了LLM在该领域的应用空白。

Abstract: Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.

</details>


### [636] [PAC-Private Responses with Adversarial Composition](https://arxiv.org/abs/2601.14033)
*Xiaochen Zhu,Mayuri Sridhar,Srinivas Devadas*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出一种基于PAC隐私的API模型输出隐私保护方法，通过自适应噪声校准实现对抗性查询组合，在极小的每查询隐私预算下保持高实用性，并能通过蒸馏得到可发布的隐私保护模型。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型通常通过API部署，传统的权重隐私方法（如DP-SGD）在API场景下会产生不必要的噪声并降低实用性。模型权重对训练数据敏感，但模型对特定输入的输出维度更低且更稳定，这促使直接在模型输出上实施隐私保护。

Method: 采用PAC隐私框架，通过控制互信息（MI）为任意黑盒函数提供实例级隐私保证。核心创新是引入自适应噪声校准算法，解决对抗性查询组合问题，证明互信息保证在自适应和对抗性查询下线性累积。

Result: 在表格、视觉和NLP任务上验证了方法的高实用性：在CIFAR-10上达到87.79%准确率，每步MI预算仅2^{-32}；服务100万查询时，成员推理攻击成功率上限为51.08%，相当于(0.04, 10^{-5})-DP保证。通过蒸馏从21万响应得到的模型在CIFAR-10上达到91.86%准确率，MIA成功率上限50.49%，相当于(0.02,10^{-5})-DP。

Conclusion: 该方法在API部署场景下实现了高效实用的隐私保护，通过输出级隐私和自适应噪声校准，在极小隐私预算下保持模型性能，并能通过响应蒸馏产生可发布的隐私保护模型。

Abstract: Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.
  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.
  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.

</details>


### [637] [Q-learning with Adjoint Matching](https://arxiv.org/abs/2601.14234)
*Qiyang Li,Sergey Levine*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出QAM算法，通过伴随匹配技术解决连续动作RL中扩散/流匹配策略优化的数值不稳定问题，在稀疏奖励任务上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 连续动作强化学习中，使用扩散或流匹配等表达性强的策略时，直接通过反向传播优化Q函数存在数值不稳定问题。现有方法要么丢弃梯度信息，要么牺牲策略表达能力，需要新方法解决这一长期挑战。

Method: QAM采用伴随匹配技术，将critic的动作梯度转换为步进式目标函数，避免不稳定的反向传播，同时保持策略的表达性和无偏性。结合时序差分备份进行critic学习。

Result: 在离线RL和离线到在线RL的困难稀疏奖励任务上，QAM一致优于现有方法。

Conclusion: QAM通过伴随匹配技术有效解决了连续动作RL中扩散/流匹配策略优化的数值不稳定问题，为表达性策略优化提供了新思路。

Abstract: We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.

</details>


### [638] [AI Agents Need Memory Control Over More Context](https://arxiv.org/abs/2601.11653)
*Fouad Bousetouane*

Main category: q-bio.NC

Relevance: 75.0

TL;DR: 提出Agent Cognitive Compressor (ACC)，一种受生物启发的记忆控制器，用于解决AI代理在长序列多轮工作流中的行为退化问题，通过有界内部状态在线更新替代传统的转录回放机制。


<details>
  <summary>Details</summary>
Motivation: AI代理在长序列多轮工作流中经常出现行为退化，包括约束焦点丢失、错误累积和记忆诱导漂移。传统基于转录回放或检索的持久记忆方法会导致无界上下文增长、噪声回忆和记忆中毒，引发不稳定行为和漂移增加。

Method: 提出Agent Cognitive Compressor (ACC)，一种生物启发的记忆控制器，用有界内部状态在线更新替代转录回放。ACC将工件回忆与状态承诺分离，实现稳定条件化，同时防止未验证内容成为持久记忆。

Result: 在IT运维、网络安全响应和医疗工作流等场景中，ACC始终维持有界记忆并展现更稳定的多轮行为，相比转录回放和基于检索的代理，幻觉和漂移显著降低。

Conclusion: 认知压缩为长视野AI代理提供了实用有效的可靠记忆控制基础，能够解决传统记忆方法带来的不稳定性和漂移问题。

Abstract: AI agents are increasingly used in long, multi-turn workflows in both research and enterprise settings. As interactions grow, agent behavior often degrades due to loss of constraint focus, error accumulation, and memory-induced drift. This problem is especially visible in real-world deployments where context evolves, distractions are introduced, and decisions must remain consistent over time. A common practice is to equip agents with persistent memory through transcript replay or retrieval-based mechanisms. While convenient, these approaches introduce unbounded context growth and are vulnerable to noisy recall and memory poisoning, leading to unstable behavior and increased drift. In this work, we introduce the Agent Cognitive Compressor (ACC), a bio-inspired memory controller that replaces transcript replay with a bounded internal state updated online at each turn. ACC separates artifact recall from state commitment, enabling stable conditioning while preventing unverified content from becoming persistent memory. We evaluate ACC using an agent-judge-driven live evaluation framework that measures both task outcomes and memory-driven anomalies across extended interactions. Across scenarios spanning IT operations, cybersecurity response, and healthcare workflows, ACC consistently maintains bounded memory and exhibits more stable multi-turn behavior, with significantly lower hallucination and drift than transcript replay and retrieval-based agents. These results show that cognitive compression provides a practical and effective foundation for reliable memory control in long-horizon AI agents.

</details>


### [639] [RAPID-Serve: Resource-efficient and Accelerated P/D Intra-GPU Disaggregation](https://arxiv.org/abs/2601.11822)
*Amna Masood,Pratishtha Gaur,Nuwan Jayasena*

Main category: cs.DC

Relevance: 75.0

TL;DR: RAPID-Serve：一种在相同GPU上并发执行预填充和解码阶段的LLM推理服务技术，通过自适应资源管理在满足延迟SLO的同时提高吞吐量和资源利用率


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理服务系统采用混合批处理（hybrid batching）和分离式服务（disaggregated serving）两种技术，但前者以增加延迟为代价提高吞吐量，后者以资源利用不足和KV缓存传输开销为代价优化SLO。需要一种能同时满足延迟SLO、高吞吐量和高效资源利用的技术。

Method: 提出RAPID-Serve技术，在相同GPU上并发执行预填充和解码阶段，结合自适应资源管理进行运行时计算资源分配，可选利用AMD Instinct™ GPU的CU masking（计算单元分区）功能实现细粒度资源控制。

Result: RAPID-Serve提供高达4.1倍（平均1.7倍）的无约束吞吐量提升，在SLO约束下提供32倍及以上（平均4.9倍）的吞吐量提升，相比现有技术表现更优，尤其在资源受限环境中效果显著。

Conclusion: RAPID-Serve是一种有效的LLM推理服务策略，能够同时满足延迟SLO、高吞吐量和高效资源利用，特别适用于资源受限环境，相比现有技术有显著优势。

Abstract: Two widely adopted techniques for LLM inference serving systems today are hybrid batching and disaggregated serving. A hybrid batch combines prefill and decode tokens of different requests in the same batch to improve resource utilization and throughput at the cost of increased latency per token. In contrast, disaggregated serving decouples compute-bound prefill and bandwidth-bound decode phases to optimize for service level objectives (SLOs) at the cost of resource under-utilization and KV-cache transfer overheads. To address the limitations of these techniques, we propose RAPID-Serve: a technique to concurrently execute prefill and decode on the same GPU(s) to meet latency SLOs while maintaining high throughput and efficient resource utilization. Furthermore, we propose Adaptive Resource Management for runtime compute resource allocation, optionally leveraging CU masking (a fine-grained Compute Unit partitioning feature on AMD Instinct\textsuperscript{TM} GPUs). RAPID-Serve provides up to 4.1x (average 1.7x) unconstrained throughput improvement and 32x and higher (average 4.9x) throughput improvement under SLO constraints, showing it as an effective strategy compared to the state-of-the-art approaches, particularly in resource-constrained environments.

</details>


### [640] [A Theory of Diversity for Random Matrices with Applications to In-Context Learning of Schrödinger Equations](https://arxiv.org/abs/2601.12587)
*Frank Cole,Yulong Lu,Shaurya Sehgal*

Main category: stat.ML

Relevance: 75.0

TL;DR: 该论文研究了随机矩阵集合中心化子为平凡的概率下界，并将结果应用于证明transformer网络在薛定谔方程上下文学习中的泛化能力保证。


<details>
  <summary>Details</summary>
Motivation: 研究随机矩阵集合中心化子为平凡的概率问题，旨在为transformer神经网络在薛定谔方程上下文学习中的泛化能力提供理论保证。这连接了随机矩阵理论和机器学习理论。

Method: 针对从随机势能的线性薛定谔算子离散化得到的几类随机矩阵族，建立了中心化子为平凡的概率下界。这些下界以样本大小N和维度d表示，结合了最近的机器学习理论成果。

Result: 为几类随机矩阵族提供了中心化子为平凡的概率下界，这些结果能够保证transformer网络在薛定谔方程上下文学习中的泛化能力。

Conclusion: 随机矩阵理论中的中心化子概率分析为transformer神经网络在科学计算任务（特别是薛定谔方程学习）中的理论理解提供了新的数学工具和保证。

Abstract: We address the following question: given a collection $\{\mathbf{A}^{(1)}, \dots, \mathbf{A}^{(N)}\}$ of independent $d \times d$ random matrices drawn from a common distribution $\mathbb{P}$, what is the probability that the centralizer of $\{\mathbf{A}^{(1)}, \dots, \mathbf{A}^{(N)}\}$ is trivial? We provide lower bounds on this probability in terms of the sample size $N$ and the dimension $d$ for several families of random matrices which arise from the discretization of linear Schrödinger operators with random potentials. When combined with recent work on machine learning theory, our results provide guarantees on the generalization ability of transformer-based neural networks for in-context learning of Schrödinger equations.

</details>


### [641] [OFA-MAS: One-for-All Multi-Agent System Topology Design based on Mixture-of-Experts Graph Generative Models](https://arxiv.org/abs/2601.12996)
*Shiyuan Li,Yixin Liu,Yu Zheng,Mei Li,Quoc Viet Hung Nguyen,Shirui Pan*

Main category: cs.MA

Relevance: 75.0

TL;DR: OFA-TAD是一个通用多智能体系统协作拓扑生成框架，通过单个模型为任意自然语言描述的任务生成自适应协作图，显著优于传统的"一对一"专用模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于图学习的多智能体系统拓扑设计采用"一对一"范式，每个任务领域需要专门训练模型，这导致泛化能力差且无法跨任务共享结构知识。随着MAS在Web服务中的广泛应用，需要能够适应多样化跨领域用户查询的自适应拓扑设计方法。

Method: 提出OFA-TAD框架，包含任务感知图状态编码器（TAGSE）通过稀疏门控过滤任务相关节点信息，以及混合专家（MoE）架构动态选择专门子网络进行节点和边预测。采用三阶段训练策略：1）在规范拓扑上进行无条件预训练获取结构先验；2）在LLM生成的数据集上进行大规模条件预训练学习任务-拓扑映射；3）在经验验证图上进行监督微调。

Result: 在六个多样化基准测试中，OFA-TAD显著优于专门的"一对一"模型，能够生成高度自适应的MAS拓扑。

Conclusion: OFA-TAD通过通用模型为任意自然语言描述的任务生成自适应协作图，解决了传统"一对一"方法的泛化限制，实现了跨任务的结构知识共享，在多智能体系统拓扑设计中具有重要价值。

Abstract: Multi-Agent Systems (MAS) offer a powerful paradigm for solving complex problems, yet their performance is critically dependent on the design of their underlying collaboration topology. As MAS become increasingly deployed in web services (e.g., search engines), designing adaptive topologies for diverse cross-domain user queries becomes essential. Current graph learning-based design methodologies often adhere to a "one-for-one" paradigm, where a specialized model is trained for each specific task domain. This approach suffers from poor generalization to unseen domains and fails to leverage shared structural knowledge across different tasks. To address this, we propose OFA-TAD, a one-for-all framework that generates adaptive collaboration graphs for any task described in natural language through a single universal model. Our approach integrates a Task-Aware Graph State Encoder (TAGSE) that filters task-relevant node information via sparse gating, and a Mixture-of-Experts (MoE) architecture that dynamically selects specialized sub-networks to drive node and edge prediction. We employ a three-stage training strategy: unconditional pre-training on canonical topologies for structural priors, large-scale conditional pre-training on LLM-generated datasets for task-topology mappings, and supervised fine-tuning on empirically validated graphs. Experiments across six diverse benchmarks show that OFA-TAD significantly outperforms specialized one-for-one models, generating highly adaptive MAS topologies. Code: https://github.com/Shiy-Li/OFA-MAS.

</details>


### [642] [The Tag is the Signal: URL-Agnostic Credibility Scoring for Messages on Telegram](https://arxiv.org/abs/2601.13294)
*Yipeng Wang,Huy Gia Han Vu,Mohit Singhal*

Main category: cs.SI

Relevance: 75.0

TL;DR: 提出TAG2CRED管道，使用LLM为Telegram短消息分配标签，再通过逻辑回归映射到风险评分，解决传统方法对短文本、少URL消息的失效问题。


<details>
  <summary>Details</summary>
Motivation: Telegram已成为传播错误信息的主要平台，但现有方法依赖域名声誉或词频特征，对短文本、少URL的高风险帖子效果不佳，需要专门针对此类消息的解决方案。

Method: 设计简洁标签系统（主题、声明类型、行动号召、证据），使用微调LLM为消息分配标签，通过L2正则化逻辑回归将标签映射到[0,1]风险评分，并与TF-IDF、SBERT等基线方法比较。

Result: 在87,936条Telegram消息上评估，TAG2CRED的ROC-AUC达0.871，macro-F1为0.787，Brier分数0.167，优于TF-IDF基线；集成模型（TF-IDF+TAG2CRED+SBERT）ROC-AUC达0.901，macro-F1为0.813。

Conclusion: 风格标签和词法特征捕捉了信息风险的不同但互补维度，TAG2CRED在短文本分类中表现出色，特征数量少且在罕见域名上泛化能力更强。

Abstract: Telegram has become one of the leading platforms for disseminating misinformational messages. However, many existing pipelines still classify each message's credibility based on the reputation of its associated domain names or its lexical features. Such methods work well on traditional long-form news articles published by well-known sources, but high-risk posts on Telegram are short and URL-sparse, leading to failures for link-based and standard TF-IDF models. To this end, we propose the TAG2CRED pipeline, a method designed for such short, convoluted messages. Our model will directly score each post based on the tags assigned to the text. We designed a concise label system that covers the dimensions of theme, claim type, call to action, and evidence. The fine-tuned large language model (LLM) assigns tags to messages and then maps these tags to calibrated risk scores in the [0,1] interval through L2-regularized logistic regression. We evaluated 87,936 Telegram messages associated with Media Bias/Fact Check (MBFC), using URL masking and domain disjoint splits. The results showed that the ROC-AUC of the TAG2CRED model reached 0.871, the macro-F1 value was 0.787, and the Brier score was 0.167, outperforming the baseline TF-IDF (macro-F1 value 0.737, Brier score 0.248); at the same time, the number of features used in this model is much smaller, and the generalization ability on infrequent domains is stronger. The performance of the stacked ensemble model (TF-IDF + TAG2CRED + SBERT) was further improved over the baseline SBERT. ROC-AUC reached 0.901, and the macro-F1 value was 0.813 (Brier score 0.114). This indicates that style labels and lexical features may capture different but complementary dimensions of information risk.

</details>


### [643] [SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories](https://arxiv.org/abs/2601.13713)
*Aditya Bharat Soni,Rajat Ghosh,Vaishnavi Bhargava,Valerie Chen,Debojyoti Dutta*

Main category: cs.SE

Relevance: 75.0

TL;DR: SWE-Tester：一种用于训练开源LLMs生成问题复现测试的新管道，在SWT-Bench Verified上实现了最高10%的成功率和21%的变更覆盖率绝对提升。


<details>
  <summary>Details</summary>
Motivation: 软件测试对确保软件系统正确性和可靠性至关重要。从自然语言问题描述自动生成问题复现测试能提高开发者生产力、促进测试驱动开发，并改进自动问题解决系统。现有方法主要依赖闭源LLMs，对开源模型探索有限。

Method: 提出SWE-Tester管道：1）从2.6K个开源GitHub仓库中整理41K个高质量训练实例数据集；2）使用该数据集训练不同规模和家族的开源LLMs；3）通过微调提升模型性能。

Result: 微调模型在SWT-Bench Verified上实现了最高10%的成功率绝对提升和21%的变更覆盖率绝对提升。分析显示增加推理时计算、更多数据和更大模型能带来一致改进。

Conclusion: 该框架有效推进了开源LLMs在问题复现测试生成领域的应用，为开源模型在该任务上的性能提升提供了可行路径。

Abstract: Software testing is crucial for ensuring the correctness and reliability of software systems. Automated generation of issue reproduction tests from natural language issue descriptions enhances developer productivity by simplifying root cause analysis, promotes test-driven development -- "test first, write code later", and can be used for improving the effectiveness of automated issue resolution systems like coding agents. Existing methods proposed for this task predominantly rely on closed-source LLMs, with limited exploration of open models. To address this, we propose SWE-Tester -- a novel pipeline for training open-source LLMs to generate issue reproduction tests. First, we curate a high-quality training dataset of 41K instances from 2.6K open-source GitHub repositories and use it to train LLMs of varying sizes and families. The fine-tuned models achieve absolute improvements of up to 10\% in success rate and 21\% in change coverage on SWT-Bench Verified. Further analysis shows consistent improvements with increased inference-time compute, more data, and larger models. These results highlight the effectiveness of our framework for advancing open-source LLMs in this domain.

</details>


### [644] [CSyMR: Benchmarking Compositional Symbolic Muisc Reasoning With MIR Tool Integration](https://arxiv.org/abs/2601.11556)
*Boyang Wang,Yash Vishe,Xin Xu,Zachary Novack,Julian McAuley,Junda Wu*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出了CSyMR-Bench，一个用于评估LLM在符号音乐推理中组合性推理能力的基准数据集，并开发了基于music21工具的工具增强代理框架来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有音乐推理基准主要关注孤立知识或原子分析，缺乏对连接音乐结构的组合性推理能力的评估，而这是音乐创作和理解的关键。

Method: 1) 从专家论坛和专业考试中收集126个多项选择题构建CSyMR-Bench数据集；2) 开发基于music21符号音乐分析工具的工具增强代理框架，通过组合多个原子分析来解决复杂推理问题。

Result: CSyMR-Bench对现有模型构成显著挑战，而工具增强代理框架相比所有基线模型实现了5-7%的绝对准确率提升。

Conclusion: 组合性符号音乐推理是LLM能力评估的重要方向，工具增强方法能有效提升模型在复杂音乐推理任务上的表现。

Abstract: Large Language Models (LLMs) are leveraged in symbolic music reasoning, yet existing benchmarks emphasize isolated knowledge or atomic analyses rather than the integrative compositional reasoning needed to connect musical structures. To address this, we present the Compositional Symbolic Music Reasoning Benchmark (CSyMR-Bench), a curated multiple-choice dataset of 126 questions derived from expert forums and professional examinations. Each item involves combining several atomic analyses to arrive at the final answer. Furthermore, we introduce a tool-augmented agent framework that leverages symbolic music analysis tools from the music21 library to address the challenges posed by CSyMR-Bench. Experiments validate that CSyMR-Bench poses a non-trivial challenge across both community-sourced and exam-style questions, while our tool-augmented agent consistently outperforms all baselines, achieving 5-7% absolute accuracy gains.

</details>


### [645] [Shapelets-Enriched Selective Forecasting using Time Series Foundation Models](https://arxiv.org/abs/2601.11821)
*Shivani Tomar,Seshu Tirupathi,Elizabeth Daly,Ivana Dusparic*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出基于shapelet的选择性预测框架，识别时间序列关键区域，选择性丢弃不可靠预测，提升时间序列基础模型的可靠性


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型在零样本预测中表现出色，但在某些关键数据区域的预测不可靠，限制了在实际应用中的可用性，特别是当数据呈现独特趋势时

Method: 使用shapelet识别时间序列关键片段，通过目标域验证集上的平移不变字典学习学习shapelet，基于与shapelet的距离相似性选择性地丢弃不可靠预测

Result: 在多样化基准时间序列数据集上，该方法使零样本模型平均减少22.17%误差，全样本微调模型减少22.62%误差，相比随机选择方法在某个数据集上分别提升21.41%和21.43%

Conclusion: 提出的选择性预测框架能有效识别时间序列基础模型的不可靠预测区域，提升模型在实际应用中的可靠性和实用性

Abstract: Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.

</details>


### [646] [TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures](https://arxiv.org/abs/2601.11880)
*Yingxiao Zhang,Jiaxin Duan,Junfu Zhang,Ke Feng*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出了TF-CoDiT，首个用于语言控制国债期货合成的扩散Transformer框架，通过离散小波变换和U形VAE处理低数据量学习，引入金融市场属性协议生成提示，在国债期货数据合成上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer在金融时间序列数据合成方面已取得进展，但在国债期货数据合成方面仍未被充分探索。国债期货数据具有低交易量、市场依赖性和多变量分组相关性等特点，需要专门的方法来处理这些挑战。

Method: 1. 将多通道1-D时间序列转换为离散小波变换系数矩阵以促进低数据学习；2. 提出U形VAE分层编码跨通道依赖关系到潜在变量，并通过解码桥接潜在空间和DWT空间，实现潜在扩散生成；3. 引入金融市场属性协议(FinMAP)，从7/8个视角识别17/23个经济指标，标准化每日/周期性市场动态以生成提示。

Result: 在2015-2025年期间四种国债期货数据上，TF-CoDiT能生成高度真实的数据，与真实数据的误差最多为MSE 0.433和MAE 0.453。进一步研究证明了TF-CoDiT在不同合约和时间跨度上的鲁棒性。

Conclusion: TF-CoDiT是首个用于语言控制国债期货合成的扩散Transformer框架，通过结合离散小波变换、U形VAE和金融市场属性协议，有效解决了国债期货数据合成的特殊挑战，在合成质量和鲁棒性方面表现出色。

Abstract: Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.

</details>


### [647] [Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models](https://arxiv.org/abs/2601.12215)
*Megha Thukral,Cyrus Tanade,Simon A. Lee,Juhyeon Lee,Hao Zhou,Keum San Chun,Migyeong Gwak,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Mehrab Bin Morshed,Subramaniam Venkatraman,Sharanya Arcot Desai*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出MMR（Masked Multiscale Reconstruction）自监督预训练框架，通过小波多分辨率分解学习PPG信号的层次化时频特征，在19个健康相关任务中的17个上达到或超越SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴基础模型大多忽略PPG信号的频谱结构，而许多下游健康任务需要从细粒度波形形态到全局节律动态的多分辨率特征。需要开发能显式学习PPG层次化时频尺度的表示学习方法。

Method: MMR框架：使用小波多分辨率分解将PPG信号转换为多尺度系数，随机掩蔽部分系数，训练Transformer编码器重建被掩蔽的系数，强制模型整合跨时间和频谱尺度的信息。

Result: 使用约1700万个未标记的10秒PPG片段（来自约3.2万智能手表用户）预训练。在19个健康相关任务中的17个上，MMR优于或匹配SOTA开源PPG基础模型、时间序列基础模型和其他自监督基线。

Conclusion: 小波表示能捕捉稳健且生理基础的特征，MMR是迈向通用PPG基础模型的重要一步，展示了多尺度时频学习在可穿戴健康监测中的价值。

Abstract: Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.

</details>


### [648] [Learning Longitudinal Health Representations from EHR and Wearable Data](https://arxiv.org/abs/2601.12227)
*Yuanyun Zhang,Han Zhou,Li Feng,Yilin Hong,Shi Li*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出一种多模态基础模型，联合建模电子健康记录和可穿戴设备数据作为连续时间潜在过程，在生理预测和风险建模任务上优于单模态基线


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据稀疏且不规则，可穿戴设备数据密集连续但缺乏语义基础，现有方法通常单独建模或通过后期融合结合，需要更好的联合表示方法

Method: 使用模态特定编码器和共享时序骨干网络，通过自监督和跨模态目标进行预训练，将两种数据源表示为连续时间潜在过程

Result: 在生理预测和风险建模任务上优于仅使用电子健康记录或仅使用可穿戴设备的基线，尤其在长时预测和缺失数据情况下表现更好

Conclusion: 联合电子健康记录和可穿戴设备预训练能产生更忠实的长时健康表示，为临床预测任务提供更好的多模态基础模型

Abstract: Foundation models trained on electronic health records show strong performance on many clinical prediction tasks but are limited by sparse and irregular documentation. Wearable devices provide dense continuous physiological signals but lack semantic grounding. Existing methods usually model these data sources separately or combine them through late fusion. We propose a multimodal foundation model that jointly represents electronic health records and wearable data as a continuous time latent process. The model uses modality specific encoders and a shared temporal backbone pretrained with self supervised and cross modal objectives. This design produces representations that are temporally coherent and clinically grounded. Across forecasting physiological and risk modeling tasks the model outperforms strong electronic health record only and wearable only baselines especially at long horizons and under missing data. These results show that joint electronic health record and wearable pretraining yields more faithful representations of longitudinal health.

</details>


### [649] [Explanova: Automatically Discover Data Insights in N \times M Table via XAI Combined LLM Workflow](https://arxiv.org/abs/2601.12317)
*Yiming Huang*

Main category: cs.LG

Relevance: 65.0

TL;DR: Explanova是一个基于预设AutoML工作流的自动化数据分析框架，使用本地小型LLM降低成本，通过系统化探索数据统计、变量关系和解释分析来实现自动化数据探索。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM代理工具调用的自动化数据分析框架（如DeepAnalyze、DataSage、Datawise）虽然强大，但作者提出探索预设AutoML工作流的替代方案，通过系统化遍历所有可能的分析路径（如变量统计、变量间关系、解释分析）来实现更全面的自动化分析。

Method: Explanova采用预设的AutoML式工作流程，系统化探索数据的所有可能分析维度：1) 变量自身统计特性，2) 变量间关系分析，3) 变量与所有其他变量的关联，4) 最终的解释分析。框架使用本地小型LLM来降低计算成本。

Result: 论文声称Explanova能够实现全面的自动化数据探索，相比现有基于大型LLM代理的框架，成本更低（使用本地小型LLM），同时通过预设工作流确保分析的系统性和完整性。

Conclusion: Explanova展示了预设AutoML工作流在自动化数据分析中的潜力，提供了一种成本效益更高的替代方案，通过系统化探索路径实现全面的数据洞察，而不完全依赖大型LLM的代理能力。

Abstract: Automation in data analysis has been a long-time pursuit. Current agentic LLM shows a promising solution towards it. Like DeepAnalyze, DataSage, and Datawise. They are all powerful agentic frameworks for automatic fine-grained analysis and are powered by LLM-based agentic tool calling ability. However, what about powered by a preset AutoML-like workflow? If we traverse all possible exploration, like Xn itself`s statistics, Xn1-Xn2 relationships, Xn to all other, and finally explain? Our Explanova is such an attempt: Cheaper due to a Local Small LLM.

</details>


### [650] [Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLMs](https://arxiv.org/abs/2601.12341)
*Rezky Kam,Coddy N. Siswanto*

Main category: cs.LG

Relevance: 65.0

TL;DR: 该论文提出了一个数据集和概念框架，让LLMs能够通过时间序列和上下文学习来模拟真实世界的情感动态，利用物理信息神经网络，为可解释的对话建模开辟了可能性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在情感理解和动态建模方面存在局限，缺乏对情感随时间演变的真实模拟能力。研究者希望开发能够捕捉真实世界情感动态的框架，提升对话系统的情感智能和可解释性。

Method: 1) 创建专门的情感动态数据集；2) 提出概念框架，结合时间序列分析和上下文学习；3) 利用物理信息神经网络（PINN）来建模情感动态，将物理原理融入神经网络架构。

Result: 开发了一个新的数据集和框架，使LLMs能够更真实地模拟情感动态变化。物理信息神经网络的引入增强了模型的可解释性，为情感感知对话系统提供了新方法。

Conclusion: 该研究为LLMs的情感动态建模提供了新方向，结合物理信息神经网络实现了更可解释的情感模拟，有望提升对话系统的情感智能和用户体验。

Abstract: This paper introduces a dataset and conceptual framework for LLMs to mimic real world emotional dynamics through time and in-context learning leveraging physics-informed neural network, opening a possibility for interpretable dialogue modeling.

</details>


### [651] [Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery](https://arxiv.org/abs/2601.12442)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.LG

Relevance: 65.0

TL;DR: CANUF框架将贝叶斯深度学习与可微符号推理结合，在科学AI中实现不确定性量化与领域约束满足的统一，相比贝叶斯神经网络将预期校准误差降低34.7%，同时保持99.2%的约束满足率。


<details>
  <summary>Details</summary>
Motivation: 科学AI应用需要提供可信不确定性估计并尊重领域约束的模型。现有不确定性量化方法缺乏融入符号科学知识的机制，而神经符号方法则缺乏原则性的不确定性建模。

Method: CANUF框架包含三个组件：1) 从科学文献自动提取约束；2) 具有变分推理的概率神经网络骨干；3) 确保物理一致性的可微约束满足层。该框架统一了贝叶斯深度学习与可微符号推理。

Result: 在Materials Project（14万+材料）、QM9分子属性和气候基准测试中，CANUF相比贝叶斯神经网络将预期校准误差降低34.7%，同时保持99.2%的约束满足率。约束引导的重新校准贡献了18.3%的性能增益，约束提取达到91.4%的精确度。

Conclusion: CANUF提供了首个端到端可微管道，同时解决科学预测中的不确定性量化、约束满足和可解释性解释问题，为科学AI应用提供了统一的框架。

Abstract: Scientific Artificial Intelligence (AI) applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. We introduce the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises three components: automated constraint extraction from scientific literature, probabilistic neural backbone with variational inference, and differentiable constraint satisfaction layer ensuring physical consistency. Experiments on Materials Project (140,000+ materials), QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.

</details>


### [652] [Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization](https://arxiv.org/abs/2601.12604)
*Safwan Labbi,Daniil Tiapkin,Paul Mangold,Eric Moulines*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出使用广义f-softargmax替代softmax的策略参数化方法，结合f-散度正则化，为有限MDP的随机策略梯度方法建立了首个显式非渐近最后迭代收敛保证，无需预条件处理。


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法对策略参数化选择高度敏感，广泛使用的softmax参数化会导致病态优化景观和指数级慢收敛。虽然可以通过预条件处理缓解，但计算成本高昂。

Method: 提出基于广义f-softargmax的替代策略参数化家族，结合相同f-散度诱导的正则化器，改善优化景观并确保正则化目标满足Polyak-Lojasiewicz不等式。

Result: 为有限MDP的随机策略梯度方法建立了首个显式非渐近最后迭代收敛保证，无需任何形式的预条件处理。对于非正则化问题推导了样本复杂度界限，显示f-PG与Tsallis散度实现多项式样本复杂度，而标准softmax参数化需要指数复杂度。

Conclusion: 提出的f-softargmax参数化结合f-散度正则化，为策略梯度方法提供了更优的优化特性，避免了softmax的指数收敛问题，且无需昂贵的预条件处理。

Abstract: Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.

</details>


### [653] [Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach](https://arxiv.org/abs/2601.12624)
*Shiqi Wang,Mahdi Khosravy,Neeraj Gupta,Olaf Witkowski*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出一种基于浮点编码、惩罚驱动的单目标进化框架，用于生成通用对抗扰动，在降低可见性的同时提高攻击成功率


<details>
  <summary>Details</summary>
Motivation: 通用对抗扰动（UAPs）能够用单一噪声模式破坏多个深度神经网络输入，进化算法因其在非凸、无梯度环境中的导航能力，为生成此类扰动提供了有前景的方法

Method: 采用浮点编码、惩罚驱动的单目标进化框架，利用连续基因表示与现代深度学习规模对齐，结合动态进化算子与自适应调度，使用模块化PyTorch实现，通过跨模型测试和周期性批次切换确保扰动通用性

Result: 在ImageNet数据集上的实验表明，该框架相比现有进化方法，能产生更小范数、更高误分类效果、更快收敛的扰动

Conclusion: 该方法展示了在不同深度学习架构上进行通用对抗攻击的鲁棒性和可扩展性

Abstract: Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.

</details>


### [654] [Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization](https://arxiv.org/abs/2601.12707)
*Junyi Liao,Zihan Zhu,Ethan Fang,Zhuoran Yang,Vahid Tarokh*

Main category: cs.LG

Relevance: 65.0

TL;DR: 本文提出了一个统一的框架，用于从观察到的玩家策略和行动中恢复两人零和矩阵博弈和马尔可夫博弈中的未知奖励函数，解决了逆强化学习中的奖励函数识别问题。


<details>
  <summary>Details</summary>
Motivation: 在逆强化学习和博弈论中，从观察到的行为推断驱动智能体的未知奖励函数是一个核心问题。现有方法面临逆问题的固有模糊性、可行奖励的非唯一性以及有限观测数据覆盖等挑战，需要建立理论保证和实用算法来解决这些问题。

Method: 1. 建立奖励函数在熵正则化下的可识别性理论，使用量化响应均衡(QRE)在线性假设下进行分析
2. 提出从观察到的行动中学习奖励函数的新算法，适用于静态和动态设置
3. 算法可适应不同方法，如最大似然估计(MLE)
4. 提供理论保证，包括可靠性和样本效率

Result: 1. 建立了奖励函数在量化响应均衡下的可识别性理论
2. 提出的算法在静态和动态设置中都能有效工作
3. 提供了算法的理论保证，包括可靠性和样本效率
4. 通过广泛的数值研究证明了框架的实际有效性
5. 为竞争环境中的决策制定提供了新的见解

Conclusion: 本文开发了一个统一的框架，用于在两人零和博弈中恢复奖励函数，解决了逆强化学习中的关键挑战。通过建立理论可识别性并提出实用算法，为从观察到的行为推断奖励函数提供了可靠的方法，对理解竞争环境中的决策制定有重要意义。

Abstract: Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.

</details>


### [655] [METIS: Mentoring Engine for Thoughtful Inquiry & Solutions](https://arxiv.org/abs/2601.13075)
*Abhinav Rajeev Kumar,Dhruv Trehan,Paras Chopra*

Main category: cs.LG

Relevance: 65.0

TL;DR: METIS是一个面向本科生科研论文写作的AI导师系统，通过工具增强、阶段感知的架构，在文献搜索、指南指导、方法检查等方面提供支持，在多阶段评估中表现优于GPT-5和Claude Sonnet 4.5。


<details>
  <summary>Details</summary>
Motivation: 许多本科生缺乏专业的研究指导，需要AI导师帮助他们从想法到论文的完整写作过程。研究旨在探索AI能否有效替代专家导师，提供系统化的科研指导。

Method: 构建METIS系统，包含工具增强、阶段感知架构，配备文献搜索、指南库、方法检查、记忆模块。采用多维度评估：LLM作为裁判的成对偏好比较、学生角色评分标准、多轮对话辅导、证据/合规性检查。

Result: 在90个单轮提示评估中，LLM裁判偏好METIS超过Claude Sonnet 4.5（71%）和GPT-5（54%）。学生评分（清晰度/可操作性/约束匹配）在各阶段均更高。多轮对话中METIS最终质量略高于GPT-5，优势集中在文档基础阶段（D-F）。

Conclusion: 阶段感知路由和文档基础支持是METIS成功的关键，但系统存在工具路由过早、基础不够深入、阶段分类错误等失败模式。AI导师在特定结构化任务中能有效辅助本科生科研写作。

Abstract: Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.

</details>


### [656] [NeuroShield: A Neuro-Symbolic Framework for Adversarial Robustness](https://arxiv.org/abs/2601.13162)
*Ali Shafiee Sarvestani,Jason Schmidt,Arman Roohi*

Main category: cs.LG

Relevance: 65.0

TL;DR: 论文提出DesignII神经符号框架，通过符号规则监督增强神经网络对抗鲁棒性和可解释性，在GTSRB数据集上相比标准对抗训练获得3倍鲁棒性提升。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络存在对抗脆弱性和缺乏可解释性的关键限制，特别是在自动驾驶等安全敏感场景中。需要一种既能增强对抗鲁棒性又能提高可解释性的方法。

Method: 提出DesignII神经符号框架，将领域知识编码为形状、颜色等外观属性的逻辑约束，通过语义和符号逻辑损失在训练中强制执行这些约束。使用FGSM和PGD对抗训练变体进行评估。

Result: 在GTSRB数据集上，FGSM-Neuro-Symbolic和PGD-Neuro-Symbolic模型相比对应对抗训练基线分别提升18.1%和17.35%的对抗准确率，相比干净训练基线的鲁棒性增益是标准对抗训练的3倍，且不降低干净样本准确率。使用ResNet18骨干网络训练10个epoch即可达到或超过需要重型架构和大量数据增强的transformer防御方法（如LNL-MoEx）的鲁棒性。

Conclusion: 符号推理为构建鲁棒且可解释的AI提供了有效路径，神经符号方法在对抗防御方面具有显著优势。

Abstract: Adversarial vulnerability and lack of interpretability are critical limitations of deep neural networks, especially in safety-sensitive settings such as autonomous driving. We introduce \DesignII, a neuro-symbolic framework that integrates symbolic rule supervision into neural networks to enhance both adversarial robustness and explainability. Domain knowledge is encoded as logical constraints over appearance attributes such as shape and color, and enforced through semantic and symbolic logic losses applied during training. Using the GTSRB dataset, we evaluate robustness against FGSM and PGD attacks at a standard $\ell_\infty$ perturbation budget of $\varepsilon = 8/255$. Relative to clean training, standard adversarial training provides modest improvements in robustness ($\sim$10 percentage points). Conversely, our FGSM-Neuro-Symbolic and PGD-Neuro-Symbolic models achieve substantially larger gains, improving adversarial accuracy by 18.1\% and 17.35\% over their corresponding adversarial-training baselines, representing roughly a three-fold larger robustness gain than standard adversarial training provides when both are measured relative to the same clean-training baseline, without reducing clean-sample accuracy. Compared to transformer-based defenses such as LNL-MoEx, which require heavy architectures and extensive data augmentation, our PGD-Neuro-Symbolic variant attains comparable or superior robustness using a ResNet18 backbone trained for 10 epochs. These results show that symbolic reasoning offers an effective path to robust and interpretable AI.

</details>


### [657] [A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model](https://arxiv.org/abs/2601.13476)
*Jinhao Li,Hao Wang*

Main category: cs.LG

Relevance: 65.0

TL;DR: PRAIM：基于大语言模型和检索增强记忆的概率变分插补框架，用于处理电动汽车充电数据中的缺失值问题，显著提升插补精度并改善下游预测性能。


<details>
  <summary>Details</summary>
Motivation: 电动汽车基础设施中数据驱动应用的可靠性依赖于完整、高质量的充电数据，但现实世界中的EV数据集经常存在缺失记录。现有插补方法无法处理充电数据的复杂多模态特性，通常采用"一站一模型"的范式，忽略了站间有价值的相关性。

Method: 开发了PRAIM框架：1) 使用预训练语言模型编码异构数据（时间序列需求、日历特征、地理空间上下文）为统一语义表示；2) 通过检索增强记忆动态检索整个充电网络中的相关示例；3) 采用变分神经架构构建统一的插补模型，克服数据稀疏性问题。

Result: 在四个公共数据集上的广泛实验表明，PRAIM在插补准确性和保持原始数据统计分布方面显著优于现有基线方法，并显著提升了下游预测性能。

Conclusion: PRAIM通过结合大语言模型和检索增强记忆，有效解决了EV充电数据中的缺失值问题，为数据驱动的EV基础设施应用提供了更可靠的解决方案。

Abstract: The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, hinges on the availability of complete, high-quality charging data. However, real-world EV datasets are often plagued by missing records, and existing imputation methods are ill-equipped for the complex, multimodal context of charging data, often relying on a restrictive one-model-per-station paradigm that ignores valuable inter-station correlations. To address these gaps, we develop a novel PRobabilistic variational imputation framework that leverages the power of large lAnguage models and retrIeval-augmented Memory (PRAIM). PRAIM employs a pre-trained language model to encode heterogeneous data, spanning time-series demand, calendar features, and geospatial context, into a unified, semantically rich representation. This is dynamically fortified by retrieval-augmented memory that retrieves relevant examples from the entire charging network, enabling a single, unified imputation model empowered by variational neural architecture to overcome data sparsity. Extensive experiments on four public datasets demonstrate that PRAIM significantly outperforms established baselines in both imputation accuracy and its ability to preserve the original data's statistical distribution, leading to substantial improvements in downstream forecasting performance.

</details>


### [658] [GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2601.13570)
*Tingting Dan,Jiaqi Ding,Guorong Wu*

Main category: cs.LG

Relevance: 65.0

TL;DR: GeoDynamics是一个几何状态空间神经网络，直接在对称正定流形上建模大脑功能连接性动态，用于追踪任务驱动状态变化和神经疾病早期标志物。


<details>
  <summary>Details</summary>
Motivation: 现有方法将大脑视为松散连接区域或施加过度简化的网络先验，缺乏真正的整体自组织动态系统视角。大脑功能连接性矩阵位于黎曼流形而非欧几里得空间，需要几何感知的方法来捕捉其轨迹。

Method: 提出GeoDynamics框架，将每个连接性矩阵嵌入到流形感知的循环框架中，学习平滑且尊重几何的转移，直接在对称正定流形上追踪潜在大脑状态轨迹。

Result: 模型能够揭示任务驱动状态变化，检测阿尔茨海默病、帕金森病和自闭症的早期标志物，并在人类动作识别基准（UTKinect、Florence、HDM05）上验证了其可扩展性和鲁棒性。

Conclusion: GeoDynamics提供了一个几何感知的状态空间建模框架，能够捕捉复杂时空动态，不仅适用于神经科学，也适用于其他领域。

Abstract: State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining the flexibility of deep learning with the principled dynamical structure of SSMs, recent studies have achieved powerful fits to functional neuroimaging data. However, most existing approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic and self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive definite (SPD) matrix, which resides on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth and geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer's disease, Parkinson's disease, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.

</details>


### [659] [FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning](https://arxiv.org/abs/2601.13578)
*Qian Feng,JiaHang Tu,Mintong Kang,Hanbin Zhao,Chao Zhang,Hui Qian*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出FG-OrIU框架，通过特征和梯度的双重正交约束实现增量遗忘学习中的深度遗忘，防止残留信息可恢复


<details>
  <summary>Details</summary>
Motivation: 现有增量遗忘学习方法主要在参数层面抑制或混淆知识，缺乏对特征和梯度层面的显式约束，导致"表面遗忘"问题，残留信息仍可恢复，存在安全风险并破坏保留平衡

Method: 提出FG-OrIU框架：1) 使用SVD分解特征空间，将遗忘类和保留类特征分离到不同子空间；2) 实施双重正交约束：特征正交投影防止特征混合，梯度正交投影防止更新时重新引入遗忘知识；3) 动态子空间适应机制合并新遗忘子空间并收缩保留子空间

Result: 实验证明该方法有效，能够实现深度遗忘效果，确保遗忘的不可逆性，同时在序列遗忘任务中保持移除与保留的稳定平衡

Conclusion: FG-OrIU通过特征和梯度的双重正交约束解决了增量遗忘学习中的深度遗忘问题，为预训练模型处理序列数据删除请求提供了更安全有效的解决方案

Abstract: Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\textbf{F}eature-\textbf{G}radient \textbf{Or}thogonality for \textbf{I}ncremental \textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.

</details>


### [660] [Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction](https://arxiv.org/abs/2601.13710)
*Sayeed Shafayet Chowdhury,Snehasis Mukhopadhyay,Shiaofen Fang,Vijay R. Ramakrishnan*

Main category: cs.LG

Relevance: 65.0

TL;DR: 该研究比较了传统机器学习与生成式AI在预测慢性鼻窦炎手术效果方面的表现，发现MLP模型在准确率、校准和决策效益方面优于生成式AI，建议采用ML为主、GenAI为辅的工作流程。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在医学影像领域取得了进展，但在临床数据上进行前瞻性决策支持的应用仍然有限。研究旨在探索如何利用术前临床数据预测慢性鼻窦炎手术效果，识别那些手术效果不佳的患者，从而避免不必要的手术。

Method: 在前瞻性收集的队列中，比较监督机器学习（逻辑回归、树集成、MLP）与生成式AI（ChatGPT、Claude、Gemini、Perplexity）的性能。所有模型接收相同的结构化输入，输出被约束为二元推荐及置信度。建立了可复现的表格数据到生成式AI的评估协议。

Result: 最佳ML模型（MLP）达到85%的准确率，具有优越的校准和决策曲线净效益。生成式AI模型在零样本设置下的区分度和校准表现较差。生成式AI的解释与临床经验和MLP特征重要性一致，都强调了基线SNOT-22评分、CT/内镜严重程度、息肉表型和心理/疼痛共病。

Conclusion: 支持ML优先、GenAI增强的工作流程：部署校准的ML进行手术候选者的初步筛选，使用GenAI作为解释器来增强透明度和共享决策制定。

Abstract: Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.

</details>


### [661] [vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.13768)
*Wenzhen Yue,Ruohao Guo,Ji Shi,Zihan Hao,Shiyu Hu,Xianghua Ying*

Main category: cs.LG

Relevance: 65.0

TL;DR: vLinear提出了一种基于线性结构的高效多元时间序列预测器，包含vecTrans模块和WFMLoss目标函数，在22个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有SOTA预测器通常依赖自注意力或其变体来捕捉多元相关性，但存在O(N²)的计算复杂度问题。需要设计更高效的架构来降低计算成本同时保持性能。

Method: 1. vecTrans模块：使用可学习向量建模多元相关性，将复杂度从O(N²)降至O(N)，可无缝集成到Transformer预测器中；2. WFMLoss目标函数：采用最终序列导向的流匹配损失，而非速度导向，结合路径和视界加权策略，关注更可靠的路径和视界。

Result: 在22个基准测试和124个预测设置中达到SOTA性能；vecTrans集成到Transformer预测器可实现5倍推理加速和性能提升；WFMLoss作为即插即用目标函数能持续改进现有预测器。

Conclusion: vLinear通过vecTrans模块和WFMLoss目标函数，实现了高效且有效的多元时间序列预测，在计算效率和预测准确性方面均取得显著改进。

Abstract: In this paper, we present \textbf{vLinear}, an effective yet efficient \textbf{linear}-based multivariate time series forecaster featuring two components: the \textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \textbf{velocity-oriented} flow matching objectives, we demonstrate that a \textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.

</details>


### [662] [Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment](https://arxiv.org/abs/2601.14228)
*Punit Kumar,Vaibhav Saran,Divyesh Patel,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出一个可解释的败血症决策支持框架，包含患者分层、数据增强、离线强化学习和LLM驱动的理由生成四个模块，在ICU数据集上实现高治疗准确性。


<details>
  <summary>Details</summary>
Motivation: 败血症是ICU主要死亡原因，及时准确的治疗决策至关重要。现有系统缺乏可解释性，难以获得临床医生信任，且数据不平衡问题影响模型性能。

Method: 1) 聚类分层模块：基于统计验证将患者分为低、中、高风险组；2) VAE和扩散模型的数据增强管道；3) 离线RL代理（AWR算法+轻量注意力编码器+集成模型）；4) 多模态LLM驱动的理由生成模块。

Result: 在MIMIC-III和eICU数据集上评估，实现了高治疗准确性，同时提供可解释和稳健的策略推荐。

Conclusion: 该框架通过结合分层、数据增强、安全感知RL和LLM解释，为败血症治疗提供了准确且可解释的决策支持，有助于临床采纳。

Abstract: Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.

</details>


### [663] [KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning](https://arxiv.org/abs/2601.14232)
*Egor Cherepanov,Daniil Zelezetsky,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

Relevance: 65.0

TL;DR: KAGE-Env是一个JAX原生的2D平台游戏环境，将观测过程分解为可独立控制的视觉轴，同时保持底层控制问题不变，用于研究视觉分布偏移下的强化学习泛化问题。


<details>
  <summary>Details</summary>
Motivation: 基于像素的强化学习智能体在纯视觉分布偏移下经常失败，即使潜在动态和奖励保持不变。现有基准测试往往将多个偏移源纠缠在一起，阻碍了系统性分析。

Method: 开发了KAGE-Env环境，将观测过程分解为可独立控制的视觉轴；基于此构建KAGE-Bench基准，包含6个已知轴套件、34个训练-评估配置对，用于隔离单个视觉偏移；使用标准PPO-CNN基线进行评估。

Result: 观察到强烈的轴依赖性失败：背景和光度偏移经常导致完全失败，而智能体外观偏移相对良性；某些偏移保留了前进运动但破坏了任务完成，表明仅看回报会掩盖泛化失败；JAX实现支持单GPU上每秒3300万环境步的快速评估。

Conclusion: KAGE-Bench提供了一个干净的系统化框架来研究视觉泛化问题，揭示了不同视觉偏移对强化学习性能的不同影响，并强调了仅依赖回报指标可能掩盖泛化失败的问题。

Abstract: Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Building on this environment, we define KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, we observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. Several shifts preserve forward motion while breaking task completion, showing that return alone can obscure generalization failures. Finally, the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors. Code: https://avanturist322.github.io/KAGEBench/.

</details>


### [664] [Semantic Differentiation for Tackling Challenges in Watermarking Low-Entropy Constrained Generation Outputs](https://arxiv.org/abs/2601.11629)
*Nghia T. Le,Alan Ritter,Kartik Goyal*

Main category: cs.CR

Relevance: 65.0

TL;DR: SeqMark是一种针对低熵约束生成任务的序列级水印算法，解决了现有token级水印方法在受限输出空间中的不足，通过语义分区平衡输出质量、水印可检测性和不可感知性。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型水印方法在开放生成任务中有效，但在输出空间低熵的约束生成任务（如机器翻译、代码生成、摘要）中表现不足。token级水印算法未能充分利用序列级熵，且存在区域坍塌问题。

Method: SeqMark采用序列级水印算法，通过语义区分对高概率输出子空间进行分区，将高概率输出均匀分配到有效和无效区域，避免区域坍塌问题。算法平衡输出质量、水印可检测性和不可感知性。

Result: 在机器翻译、代码生成和摘要等约束生成任务上，SeqMark显著提高水印检测准确率（F1分数提升高达28%），同时保持高质量生成输出。

Conclusion: SeqMark解决了现有水印方法在约束生成任务中的局限性，通过序列级语义分区方法有效平衡了水印检测能力和输出质量，为低熵输出空间的水印技术提供了新思路。

Abstract: We demonstrate that while the current approaches for language model watermarking are effective for open-ended generation, they are inadequate at watermarking LM outputs for constrained generation tasks with low-entropy output spaces. Therefore, we devise SeqMark, a sequence-level watermarking algorithm with semantic differentiation that balances the output quality, watermark detectability, and imperceptibility. It improves on the shortcomings of the prevalent token-level watermarking algorithms that cause under-utilization of the sequence-level entropy available for constrained generation tasks. Moreover, we identify and improve upon a different failure mode we term region collapse, associated with prior sequence-level watermarking algorithms. This occurs because the pseudorandom partitioning of semantic space for watermarking in these approaches causes all high-probability outputs to collapse into either invalid or valid regions, leading to a trade-off in output quality and watermarking effectiveness. SeqMark instead, differentiates the high-probable output subspace and partitions it into valid and invalid regions, ensuring the even spread of high-quality outputs among all the regions. On various constrained generation tasks like machine translation, code generation, and abstractive summarization, SeqMark substantially improves watermark detection accuracy (up to 28% increase in F1) while maintaining high generation quality.

</details>


### [665] [Nonlinear Dynamic Factor Analysis With a Transformer Network](https://arxiv.org/abs/2601.12039)
*Oliver Snellman*

Main category: econ.EM

Relevance: 65.0

TL;DR: 本文开发了一种基于Transformer的架构，用于在灵活识别假设下从多元时间序列数据中估计动态因子。通过使用传统因子模型作为先验信息进行正则化，在小数据集上显著提升了性能。注意力矩阵可解释变量及其滞后项对因子估计的相对重要性，注意力模式的时间变化有助于检测机制转换和评估叙事。蒙特卡洛实验表明，当数据偏离线性高斯假设时，Transformer比线性因子模型更准确。实证应用使用Transformer构建了美国实际经济活动的同步指数。


<details>
  <summary>Details</summary>
Motivation: 传统因子模型通常基于线性高斯假设，但在现实世界的时间序列数据中，这些假设常常被违反。需要一种更灵活的方法来估计动态因子，能够处理非线性关系和非高斯分布，同时保持可解释性。Transformer架构在序列建模方面的成功为时间序列因子分析提供了新的可能性。

Method: 开发了基于Transformer的架构用于动态因子估计，采用注意力机制捕捉变量间的复杂依赖关系。通过将传统线性因子模型作为先验信息，在训练目标中加入正则化项，在小数据集上提升性能。使用注意力矩阵进行可解释性分析，量化变量及其滞后项对因子估计的相对重要性。

Result: 蒙特卡洛实验表明，当数据偏离线性高斯假设时，Transformer比传统线性因子模型更准确。在小数据集上，通过传统因子模型正则化显著提升了性能。注意力模式的时间变化能够有效检测经济机制转换，实证应用成功构建了美国实际经济活动的同步指数。

Conclusion: Transformer架构为动态因子估计提供了灵活且强大的框架，特别是在数据偏离传统线性高斯假设时。注意力机制不仅提升了估计精度，还提供了有价值的可解释性工具。该方法在经济学和金融时间序列分析中具有重要应用价值。

Abstract: The paper develops a Transformer architecture for estimating dynamic factors from multivariate time series data under flexible identification assumptions. Performance on small datasets is improved substantially by using a conventional factor model as prior information via a regularization term in the training objective. The results are interpreted with Attention matrices that quantify the relative importance of variables and their lags for the factor estimate. Time variation in Attention patterns can help detect regime switches and evaluate narratives. Monte Carlo experiments suggest that the Transformer is more accurate than the linear factor model, when the data deviate from linear-Gaussian assumptions. An empirical application uses the Transformer to construct a coincident index of U.S. real economic activity.

</details>


### [666] [Cross-reality Location Privacy Protection in 6G-enabled Vehicular Metaverses: An LLM-enhanced Hybrid Generative Diffusion Model-based Approach](https://arxiv.org/abs/2601.12311)
*Xiaofeng Luo,Jiayi He,Jiawen Kang,Ruichen Zhang,Zhaoshui He,Ekram Hossain,Dong In Kim*

Main category: cs.NI

Relevance: 65.0

TL;DR: 提出基于混合动作的跨现实位置隐私保护框架，结合连续位置扰动和离散隐私感知AI代理迁移，使用LLM增强的混合扩散近端策略优化算法来平衡隐私保护、服务延迟和服务质量


<details>
  <summary>Details</summary>
Motivation: 6G车联网元宇宙中，自动驾驶车辆在物理和虚拟空间跨现实交互会带来严重的位置隐私风险，攻击者可以通过关联物理空间LBS请求位置和虚拟空间AI代理部署位置来推断车辆轨迹

Method: 设计跨现实位置隐私保护框架，提出跨现实位置熵隐私度量，构建优化问题，并开发LLM增强的混合扩散近端策略优化算法，结合LLM驱动的信息奖励设计和基于生成扩散模型的策略探索

Result: 在真实数据集上的实验表明，该框架能有效减轻自动驾驶车辆的跨现实位置隐私泄露，同时在6G车联网元宇宙场景中保持强大的用户沉浸感

Conclusion: 提出的混合动作隐私保护框架和LLM增强的优化算法能够有效解决车联网元宇宙中的跨现实位置隐私问题，平衡隐私保护和服务质量

Abstract: The emergence of 6G-enabled vehicular metaverses enables Autonomous Vehicles (AVs) to operate across physical and virtual spaces through space-air-ground-sea integrated networks. The AVs can deploy AI agents powered by large AI models as personalized assistants, on edge servers to support intelligent driving decision making and enhanced on-board experiences. However, such cross-reality interactions may cause serious location privacy risks, as adversaries can infer AV trajectories by correlating the location reported when AVs request LBS in reality with the location of the edge servers on which their corresponding AI agents are deployed in virtuality. To address this challenge, we design a cross-reality location privacy protection framework based on hybrid actions, including continuous location perturbation in reality and discrete privacy-aware AI agent migration in virtuality. In this framework, a new privacy metric, termed cross-reality location entropy, is proposed to effectively quantify the privacy levels of AVs. Based on this metric, we formulate an optimization problem to optimize the hybrid action, focusing on achieving a balance between location protection, service latency reduction, and quality of service maintenance. To solve the complex mixed-integer problem, we develop a novel LLM-enhanced Hybrid Diffusion Proximal Policy Optimization (LHDPPO) algorithm, which integrates LLM-driven informative reward design to enhance environment understanding with double Generative Diffusion Models-based policy exploration to handle high-dimensional action spaces, thereby enabling reliable determination of optimal hybrid actions. Extensive experiments on real-world datasets demonstrate that the proposed framework effectively mitigates cross-reality location privacy leakage for AVs while maintaining strong user immersion within 6G-enabled vehicular metaverse scenarios.

</details>


### [667] [LiQSS: Post-Transformer Linear Quantum-Inspired State-Space Tensor Networks for Real-Time 6G](https://arxiv.org/abs/2601.12375)
*Farhad Rezazadeh,Hatim Chergui,Mehdi Bennis,Houbing Song,Lingjia Liu,Dusit Niyato,Merouane Debbah*

Main category: cs.NI

Relevance: 65.0

TL;DR: 本文提出LiQSS模型，一种量子启发的多体状态空间张量网络，用于6G O-RAN中的高效无线电遥测预测，相比Transformer实现155倍参数减少和2.74倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 6G O-RAN需要满足近实时延迟和计算约束的控制级预测。基于Transformer的模型虽然有效，但其二次复杂度限制了在近实时RAN智能控制器分析中的可扩展性。

Method: 提出量子启发的多体状态空间张量网络，用稳定的结构化状态空间动态核替换自注意力机制，实现线性时间序列建模。采用张量列车/矩阵乘积状态表示来减少参数化和数据移动，结合轻量级通道门控和混合层捕获非平稳跨KPI依赖关系。

Result: LiQSS模型比现有结构化状态空间基线小10.8-15.8倍，快约1.4倍。相比Transformer模型，实现高达155倍的参数减少和2.74倍的推理加速，同时保持预测精度。

Conclusion: LiQSS为6G O-RAN中的高效无线电遥测预测提供了一种后Transformer设计范式，在保持精度的同时显著提升了效率和可扩展性。

Abstract: Proactive and agentic control in Sixth-Generation (6G) Open Radio Access Networks (O-RAN) requires control-grade prediction under stringent Near-Real-Time (Near-RT) latency and computational constraints. While Transformer-based models are effective for sequence modeling, their quadratic complexity limits scalability in Near-RT RAN Intelligent Controller (RIC) analytics. This paper investigates a post-Transformer design paradigm for efficient radio telemetry forecasting. We propose a quantum-inspired many-body state-space tensor network that replaces self-attention with stable structured state-space dynamics kernels, enabling linear-time sequence modeling. Tensor-network factorizations in the form of Tensor Train (TT) / Matrix Product State (MPS) representations are employed to reduce parameterization and data movement in both input projections and prediction heads, while lightweight channel gating and mixing layers capture non-stationary cross-Key Performance Indicator (KPI) dependencies. The proposed model is instantiated as an agentic perceive-predict xApp and evaluated on a bespoke O-RAN KPI time-series dataset comprising 59,441 sliding windows across 13 KPIs, using Reference Signal Received Power (RSRP) forecasting as a representative use case. Our proposed Linear Quantum-Inspired State-Space (LiQSS) model is 10.8x-15.8x smaller and approximately 1.4x faster than prior structured state-space baselines. Relative to Transformer-based models, LiQSS achieves up to a 155x reduction in parameter count and up to 2.74x faster inference, without sacrificing forecasting accuracy.

</details>


### [668] [BlocksecRT-DETR: Decentralized Privacy-Preserving and Token-Efficient Federated Transformer Learning for Secure Real-Time Object Detection in ITS](https://arxiv.org/abs/2601.12693)
*Mohoshin Ara Tahera,Sabbir Rahman,Shuvalaxmi Dass,Sharif Ullah,Mahmoud Abouyessef*

Main category: cs.CR

Relevance: 65.0

TL;DR: 提出了BlockSecRT-DETR框架，结合区块链安全机制和实时目标检测Transformer，解决智能交通系统中联邦学习的非IID数据、边缘延迟和隐私安全问题。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中的联邦实时目标检测面临三大挑战：1) 地理分布导致的缺失类非IID数据异构性；2) 边缘硬件上高容量Transformer模型的延迟约束；3) 不可信客户端更新和集中聚合带来的隐私安全风险。

Method: 提出BlockSecRT-DETR框架：1) 使用RT-DETR Transformer进行联邦训练；2) 引入Token Engineering Module(TEM)剪枝低效用token，降低编码器复杂度和延迟；3) 集成区块链安全更新验证机制，实现去中心化、防篡改的模型聚合。

Result: TEM将推理延迟降低17.2%，编码器FLOPs减少47.8%，同时保持89.20% mAP@0.5的全局检测精度。区块链集成每轮增加400ms延迟，账本大小保持在12KB以下。

Conclusion: BlockSecRT-DETR有效解决了智能交通系统中联邦目标检测的关键挑战，通过token剪枝优化边缘延迟，通过区块链机制确保隐私安全，为实际部署提供了可行方案。

Abstract: Federated real-time object detection using transformers in Intelligent Transportation Systems (ITS) faces three major challenges: (1) missing-class non-IID data heterogeneity from geographically diverse traffic environments, (2) latency constraints on edge hardware for high-capacity transformer models, and (3) privacy and security risks from untrusted client updates and centralized aggregation. We propose BlockSecRT-DETR, a BLOCKchain-SECured Real-Time Object DEtection TRansformer framework for ITS that provides a decentralized, token-efficient, and privacy-preserving federated training solution using RT-DETR transformer, incorporating a blockchain-secured update validation mechanism for trustworthy aggregation. In this framework, challenges (1) and (2) are jointly addressed through a unified client-side design that integrates RT-DETR training with a Token Engineering Module (TEM). TEM prunes low-utility tokens, reducing encoder complexity and latency on edge hardware, while aggregated updates mitigate non-IID data heterogeneity across clients. To address challenge (3), BlockSecRT-DETR incorporates a decentralized blockchain-secured update validation mechanism that enables tamper-proof, privacy-preserving, and trust-free authenticated model aggregation without relying on a central server. We evaluated the proposed framework under a missing-class Non-IID partition of the KITTI dataset and conducted a blockchain case study to quantify security overhead. TEM improves inference latency by 17.2% and reduces encoder FLOPs by 47.8%, while maintaining global detection accuracy (89.20% mAP@0.5). The blockchain integration adds 400 ms per round, and the ledger size remains under 12 KB due to metadata-only on-chain storage.

</details>


### [669] [RM -RF: Reward Model for Run-Free Unit Test Evaluation](https://arxiv.org/abs/2601.13097)
*Elena Bruches,Daniil Grebenkin,Mikhail Klementev,Vadim Alperovich,Roman Derunets,Dari Baturova,Georgy Mkrtchyan,Oleg Sedukhin,Ivan Bondarenko,Nikolay Bushkov,Stanislav Moiseev*

Main category: cs.SE

Relevance: 65.0

TL;DR: RM-RF：一个轻量级奖励模型，用于无需运行的自动化单元测试评估，通过源代码和测试代码预测执行相关指标，替代传统的编译执行方法


<details>
  <summary>Details</summary>
Motivation: 传统单元测试评估需要反复编译和执行候选测试，这带来了高延迟和高基础设施成本。为了在大型测试生成和基于RL的代码优化中提供快速、可扩展的反馈，需要一种更高效的评估方法。

Method: 开发RM-RF模型，仅从源代码和测试代码预测三个执行相关信号：1) 增强测试套件能否成功编译运行，2) 生成的测试用例是否增加代码覆盖率，3) 是否提高变异杀死率。使用多语言数据集（Java、Python、Go）训练，测试了多种模型家族和调优策略（零样本、全微调、LoRA PEFT）。

Result: 在三个预测目标上平均F1达到0.69。相比传统编译执行方法，RM-RF显著降低了延迟和基础设施成本，同时保持了有竞争力的预测准确性。

Conclusion: RM-RF为大规模测试生成和基于强化学习的代码优化提供了快速、可扩展的反馈机制，在保持预测准确性的同时大幅降低了评估成本。

Abstract: We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests. Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals: (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage, and (3) whether the generated test cases improve the mutation kill rate. To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files, test files, and candidate test additions labeled by an execution-based pipeline, and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes (zero-shot, full fine-tuning, and PEFT via LoRA), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.

</details>


### [670] [Breaking the Data Barrier in Learning Symbolic Computation: A Case Study on Variable Ordering Suggestion for Cylindrical Algebraic Decomposition](https://arxiv.org/abs/2601.13731)
*Rui-Juan Jing,Yuegang Zhao,Changbo Chen*

Main category: cs.SC

Relevance: 65.0

TL;DR: 提出了一种基于Transformer的预训练方法，通过设计一系列相关任务生成大量标注数据，用于优化圆柱代数分解(CAD)中的变量排序问题，显著超越了现有启发式方法。


<details>
  <summary>Details</summary>
Motivation: 符号计算中的圆柱代数分解(CAD)效率受变量排序影响很大，但传统基于监督深度学习的方法面临标注数据获取困难的问题，导致现有学习方法仅能与专家启发式方法竞争。

Method: 设计了一系列紧密相关的任务来生成大量标注数据，使用这些数据预训练Transformer模型，然后在CAD排序数据集上进行微调。

Result: 在公开CAD排序数据集上的实验表明，新模型预测的排序平均显著优于最佳启发式方法。

Conclusion: 通过设计相关任务生成大量标注数据的预训练方法，有效解决了CAD变量排序中的数据稀缺问题，显著提升了排序质量。

Abstract: Symbolic computation, powered by modern computer algebra systems, has important applications in mathematical reasoning through exact deep computations. The efficiency of symbolic computation is largely constrained by such deep computations in high dimension. This creates a fundamental barrier on labelled data acquisition if leveraging supervised deep learning to accelerate symbolic computation. Cylindrical algebraic decomposition (CAD) is a pillar symbolic computation method for reasoning with first-order logic formulas over reals with many applications in formal verification and automatic theorem proving. Variable orderings have a huge impact on its efficiency. Impeded by the difficulty to acquire abundant labelled data, existing learning-based approaches are only competitive with the best expert-based heuristics. In this work, we address this problem by designing a series of intimately connected tasks for which a large amount of annotated data can be easily obtained. We pre-train a Transformer model with these data and then fine-tune it on the datasets for CAD ordering. Experiments on publicly available CAD ordering datasets show that on average the orderings predicted by the new model are significantly better than those suggested by the best heuristic methods.

</details>


### [671] [Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior](https://arxiv.org/abs/2601.14000)
*Junwoo Chang,Joseph Park,Roberto Horowitz,Jongmin Lee,Jongeun Choi*

Main category: cs.RO

Relevance: 65.0

TL;DR: 提出GISD框架，通过将群结构嵌入技能发现目标，利用环境几何对称性提高无监督技能发现的效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有无监督技能发现方法往往忽略物理环境的几何对称性，导致行为冗余和样本效率低下。为了解决这个问题，作者提出将群结构显式嵌入技能发现目标。

Method: 引入群不变技能发现(GISD)框架，基于理论保证：在群对称环境中，标准Wasserstein依赖度量存在由等变策略和群不变评分函数组成的全局最优解。提出群不变Wasserstein依赖度量，将优化限制在对称感知子空间。使用群傅里叶表示参数化评分函数，通过等变潜在特征对齐定义内在奖励。

Result: 在基于状态和像素的运动基准测试中，GISD相比强基线实现了更广泛的状态空间覆盖和下游任务学习效率提升。

Conclusion: 通过显式建模环境对称性，GISD能够发现更高效、泛化性更好的技能，提高无监督技能发现的样本效率。

Abstract: Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.

</details>


### [672] [A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning](https://arxiv.org/abs/2601.11670)
*Jinshi Liu,Pan Liu*

Main category: cs.LG

Relevance: 45.0

TL;DR: 本文提出CoVar理论框架，通过结合最大置信度(MC)和残差类别方差(RCV)来改进半监督学习中的伪标签选择，解决了深度网络过度自信的问题。


<details>
  <summary>Details</summary>
Motivation: 传统半监督学习中的伪标签选择依赖固定置信度阈值，但深度网络经常过度自信：高置信度预测可能错误，而决策边界附近信息丰富的低置信度样本却被丢弃。需要更可靠的伪标签选择标准。

Method: 从熵最小化原理出发，推导出结合最大置信度(MC)和残差类别方差(RCV)的可靠性度量。将伪标签选择转化为置信度-方差特征空间中的谱松弛问题，设计无阈值选择机制来区分高可靠性和低可靠性预测。

Result: 在PASCAL VOC 2012、Cityscapes、CIFAR-10和Mini-ImageNet数据集上，使用不同标签比例和骨干网络，CoVar作为插件模块持续改进强基线方法。

Conclusion: 结合置信度和残差类别方差比固定置信度阈值为伪标签选择提供了更可靠的基础，能有效纠正过度自信但不稳定的预测。

Abstract: Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, we derive a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. From this perspective, we cast pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space, and design a threshold-free selection mechanism to distinguish high- from low-reliability predictions. We integrate CoVar as a plug-in module into representative semi-supervised semantic segmentation and image classification methods. Across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones, it consistently improves over strong baselines, indicating that combining confidence with residual-class variance provides a more reliable basis for pseudo-label selection than fixed confidence thresholds. (Code: https://github.com/ljs11528/CoVar_Pseudo_Label_Selection.git)

</details>


### [673] [Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis](https://arxiv.org/abs/2601.11686)
*Nicolas Caron,Christophe Guyeux,Hassan Noura,Benjamin Aynes*

Main category: cs.LG

Relevance: 45.0

TL;DR: 提出结合预测模型与LLM的混合框架，将多维度野火风险分析整合为结构化可操作报告


<details>
  <summary>Details</summary>
Motivation: 当前野火风险评估方法忽视实际运营需求，缺乏对第一响应者和消防服务的实用价值。需要多目标分析来捕捉野火风险的多个维度，而不是依赖单一预测指标。

Method: 开发混合框架：为每个风险维度（气象危险、点火活动、干预复杂性、资源调动）建立预测模型，然后使用大型语言模型（LLMs）将这些异构输出合成为结构化的可操作报告。

Result: 这是一个概念验证研究，提出了框架设计，但尚未展示具体实验结果。

Conclusion: 提出的混合框架有望改善野火风险评估的实用性，通过LLM整合多维度分析为第一响应者提供结构化指导。

Abstract: Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.

</details>


### [674] [Learning Relativistic Geodesics and Chaotic Dynamics via Stabilized Lagrangian Neural Networks](https://arxiv.org/abs/2601.12519)
*Abdullah Umut Hamzaogullari,Arkadas Ozakin*

Main category: cs.LG

Relevance: 45.0

TL;DR: 论文提出了改进拉格朗日神经网络(LNNs)训练稳定性的方法，包括Hessian正则化、专用激活函数和物理感知坐标缩放，成功应用于复杂系统如三摆，并在相对论设置中学习测地线拉格朗日量。


<details>
  <summary>Details</summary>
Motivation: 拉格朗日神经网络可以从轨迹数据中学习任意拉格朗日量，但其不寻常的优化目标导致显著的训练不稳定性，限制了在复杂系统中的应用。需要解决这些基本挑战以扩展LNNs的实际应用范围。

Method: 1. Hessian正则化方案：惩罚拉格朗日量对速度二阶导数中的非物理特征，防止网络学习不稳定动力学；2. 更适合学习拉格朗日量的激活函数；3. 物理感知坐标缩放以改善稳定性；4. 在相对论设置中扩展正则化以惩罚洛伦兹特征违反。

Result: 改进架构成功训练了前所未有的复杂系统（包括三摆），在双摆系统中验证损失降低了96.6%，稳定性提高了90.68%。在相对论设置中，成功预测了AdS₄时空度量下的测地线拉格朗日量，这在文献中尚属首次。

Conclusion: 该方法显著扩展了LNNs在科学发现任务中的实际适用性，为物理中几何结构的自动发现（包括从测地线轨迹提取时空度量张量分量）开辟了新可能性，但仍保留了原始LNN框架的一些限制（特别是可逆Hessian要求）。

Abstract: Lagrangian Neural Networks (LNNs) can learn arbitrary Lagrangians from trajectory data, but their unusual optimization objective leads to significant training instabilities that limit their application to complex systems. We propose several improvements that address these fundamental challenges, namely, a Hessian regularization scheme that penalizes unphysical signatures in the Lagrangian's second derivatives with respect to velocities, preventing the network from learning unstable dynamics, activation functions that are better suited to the problem of learning Lagrangians, and a physics-aware coordinate scaling that improves stability. We systematically evaluate these techniques alongside previously proposed methods for improving stability. Our improved architecture successfully trains on systems of unprecedented complexity, including triple pendulums, and achieved 96.6\% lower validation loss value and 90.68\% better stability than baseline LNNs in double pendulum systems. With the improved framework, we show that our LNNs can learn Lagrangians representing geodesic motion in both non-relativistic and general relativistic settings. To deal with the relativistic setting, we extended our regularization to penalize violations of Lorentzian signatures, which allowed us to predict a geodesic Lagrangian under AdS\textsubscript{4} spacetime metric directly from trajectory data, which to our knowledge has not been done in the literature before. This opens new possibilities for automated discovery of geometric structures in physics, including extraction of spacetime metric tensor components from geodesic trajectories. While our approach inherits some limitations of the original LNN framework, particularly the requirement for invertible Hessians, it significantly expands the practical applicability of LNNs for scientific discovery tasks.

</details>


### [675] [MN-TSG:Continuous Time Series Generation with Irregular Observations](https://arxiv.org/abs/2601.13534)
*Xu Zhang,Junwei Deng,Chang Xu,Hao Li,Jiang Bian*

Main category: cs.LG

Relevance: 45.0

TL;DR: MN-TSG提出了一种基于专家混合(MoE)的神经控制微分方程框架，用于不规则和连续时间序列生成，解决了现有方法在临床监测等实际场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列生成方法通常假设规则采样和固定输出分辨率，但现实世界数据（如临床监测）往往是不规则采样和稀疏观测的。神经控制微分方程(NCDE)在建模不规则时间序列方面有潜力，但在捕捉复杂动态时间模式和支撑连续生成方面仍有挑战。

Method: 提出MN-TSG框架：1) 基于MoE的NCDE架构，具有动态参数化的专家函数和解耦设计，便于更有效地优化MoE动态；2) 利用现有TSG模型学习专家混合和生成时间序列的联合分布，支持生成新样本并产生适合每个样本的专家配置。

Result: 在10个公共和合成数据集上的广泛实验表明，MN-TSG在irregular-to-regular和irregular-to-continuous生成任务上始终优于强基线方法。

Conclusion: MN-TSG通过结合MoE-NCDE架构和现有TSG模型，有效解决了不规则和连续时间序列生成的挑战，在临床监测等实际应用中具有重要价值。

Abstract: Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.
  Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.
  The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.
  Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.

</details>


### [676] [Inverting Self-Organizing Maps: A Unified Activation-Based Framework](https://arxiv.org/abs/2601.13851)
*Alessandro Londei,Matteo Benati,Denise Lanzieri,Vittorio Loreto*

Main category: cs.LG

Relevance: 45.0

TL;DR: 提出MUSIC方法，基于自组织映射(SOM)的激活模式反演恢复输入数据，实现可控的语义潜在空间探索，无需采样、先验或编码器-解码器架构。


<details>
  <summary>Details</summary>
Motivation: 自组织映射(SOM)广泛用于可视化、聚类和向量量化，但其激活模式（到原型的平方距离）的反演能力未被充分探索。作者旨在利用欧氏距离几何原理，实现从SOM激活模式精确恢复输入，并在此基础上开发可控的潜在空间探索方法。

Method: 基于欧氏距离几何原理：D维空间中的点由到D+1个仿射独立参考点的距离唯一确定。推导相应线性系统，分析反演的良好条件。提出MUSIC更新规则，通过修改选定原型的平方距离同时保持其他距离不变，实现确定性几何流。使用Tikhonov正则化稳定更新规则，确保高维数据集上的平滑运动。

Result: 在合成高斯混合、MNIST和Faces in the Wild数据集上验证，MUSIC产生平滑、可解释的轨迹，揭示学习流形的底层几何结构。当无扰动时精确恢复输入；指定目标聚类或原型时，产生连贯的语义变化同时保持在数据流形上。

Conclusion: MUSIC为基于原型几何的数据增强和可控潜在探索提供了新视角，展示了SOM反演相比无监督聚类的优势。该方法不依赖采样、潜在先验或编码器-解码器架构，提供了一种纯几何的数据操作框架。

Abstract: Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.

</details>


### [677] [RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning](https://arxiv.org/abs/2601.13964)
*Cheol-Hui Lee,Hwa-Yeon Lee,Dong-Joo Kim*

Main category: cs.LG

Relevance: 45.0

TL;DR: RL-BioAug：利用强化学习代理自动确定EEG对比学习中的最优数据增强策略，仅需10%标注数据指导，在睡眠分期和癫痫检测任务上显著优于随机增强策略。


<details>
  <summary>Details</summary>
Motivation: EEG信号的非平稳性使得静态或随机数据增强策略难以保留内在信息，传统启发式增强方法效果有限。需要一种能自动确定最优增强策略的方法，以提升对比学习在EEG任务中的性能。

Method: 提出RL-BioAug框架，使用标签高效的强化学习代理自主确定最优增强策略。仅需10%标注数据指导代理策略，编码器以严格自监督方式学习鲁棒表示。代理针对不同任务选择不同最优策略（如睡眠分期选择时间掩码，癫痫检测选择裁剪和调整大小）。

Result: 在Sleep-EDFX和CHB-MIT数据集上，RL-BioAug显著优于随机选择策略，Macro-F1分数分别提升9.69%和8.80%。代理针对不同任务选择不同最优策略：睡眠分期任务中时间掩码概率为62%，癫痫检测任务中裁剪和调整大小概率为77%。

Conclusion: RL-BioAug有潜力取代传统的启发式增强方法，建立数据增强的自主新范式。该框架展示了强化学习在优化生物信号数据增强策略方面的有效性。

Abstract: The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10\%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69\% and 8.80\% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task -- for example, Time Masking with a 62\% probability for sleep stage classification and Crop \& Resize with a 77\% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at \href{https://github.com/dlcjfgmlnasa/RL-BioAug}{https://github.com/dlcjfgmlnasa/RL-BioAug}.

</details>


### [678] [Multi-Scale Negative Coupled Information Systems (MNCIS): A Unified Spectral Topology Framework for Stability in Turbulence, AI, and Biology](https://arxiv.org/abs/2601.11594)
*Pengyue Hou*

Main category: physics.comp-ph

Relevance: 45.0

TL;DR: 提出MNCIS框架，通过自适应谱负耦合(ASNC)解决复杂动力系统中的谱间隙塌陷问题，在流体力学、人工智能和生物物理三个领域验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 复杂动力系统经常面临谱间隙塌陷的结构不稳定性，导致系统趋向低维"零模吸引子"。本文旨在建立一个统一的理论框架来理解和解决这一问题。

Method: 基于全局适定性估计，推广了多尺度负耦合信息系统(MNCIS)框架，提出自适应谱负耦合(ASNC)作为状态依赖的高通滤波器，惩罚谱边界处的熵积累。在三个领域实现验证：流体力学中的自适应亚网格尺度模型、图神经网络中的拓扑约束、反应扩散形态发生中的模式稳定。

Result: 1) 在3D Navier-Stokes湍流中稳定无粘极限并保持Kolmogorov惯性范围；2) 在GNN中实现无残差连接的64层超深网络训练，特征方差保持稳定；3) 在反应扩散系统中稳定Turing模式抵抗扩散冲刷。

Conclusion: MNCIS框架提供了区分可行复杂系统与热平衡塌陷系统的拓扑条件，连接了物理稳定性和信息持久性。

Abstract: Complex dynamical systems frequently encounter a recurrent structural instability: the collapse of the spectral gap, driving the system toward a low-dimensional "Zero-Mode Attractor" (e.g., spectral pile-up or over-smoothing). Building upon recent global well-posedness estimates [Hou, arXiv:2601.00638], this work generalizes the Multi-Scale Negative Coupled Information System (MNCIS) framework. We postulate that global stability requires an active topological operator -- Adaptive Spectral Negative Coupling (ASNC) -- functioning as a state-dependent high-pass filter that penalizes entropy accumulation at spectral boundaries. We validate this unified framework via three implementations:(1) Hydrodynamics: In 3D Navier-Stokes turbulence ($N=256^3$), ASNC acts as a global-enstrophy adaptive sub-grid scale (SGS) model, stabilizing the inviscid limit and preserving the Kolmogorov $-5/3$ inertial range without artificial hyper-viscosity.(2) Artificial Intelligence: Addressing Over-smoothing in Graph Neural Networks (GNNs), we implement ASNC as a parameter-free topological constraint. Unlike baselines (e.g., DeepGCNs) relying on dense residual connections to bypass signal decay, our framework enables the training of ultra-deep 64-layer networks without residual connections, maintaining perfectly stationary feature variance ($σ^2 \equiv 1.0$) on the ogbn-arxiv benchmark. (3) Biological Physics: In reaction-diffusion morphogenesis, it stabilizes Turing patterns against diffusive washout in high-entropy regimes. Our results suggest that the MNCIS framework provides a base-independent topological condition for distinguishing viable complex systems from those collapsing into thermal equilibrium, bridging physical stability and information persistence.

</details>


### [679] [BiCoLoR: Communication-Efficient Optimization with Bidirectional Compression and Local Training](https://arxiv.org/abs/2601.12400)
*Laurent Condat,Artavazd Maranjyan,Peter Richtárik*

Main category: math.OC

Relevance: 45.0

TL;DR: BiCoLoR是一种通信高效的分布式优化算法，结合了本地训练和双向压缩技术，在联邦学习中显著减少通信开销


<details>
  <summary>Details</summary>
Motivation: 分布式优化中通信成本高是主要瓶颈，特别是在联邦学习的无线网络环境中。现有方法通常只压缩上行链路（客户端到服务器），而忽略了下行链路（服务器到客户端）的通信成本，但实际上双向通信都很昂贵。

Method: BiCoLoR结合了两种有效策略：1) 本地训练（增加通信轮次间的计算量），2) 双向压缩（使用任意无偏压缩器同时压缩上行和下行通信）。这是首个将本地训练与双向压缩结合的算法。

Result: 该算法在凸和强凸异质设置下实现了加速的复杂度保证。实证结果表明，BiCoLoR优于现有算法，在通信效率方面建立了新标准。

Conclusion: BiCoLoR通过同时解决双向通信瓶颈，显著提高了分布式优化的通信效率，特别是在联邦学习等通信受限环境中具有重要应用价值。

Abstract: Slow and costly communication is often the main bottleneck in distributed optimization, especially in federated learning where it occurs over wireless networks. We introduce BiCoLoR, a communication-efficient optimization algorithm that combines two widely used and effective strategies: local training, which increases computation between communication rounds, and compression, which encodes high-dimensional vectors into short bitstreams. While these mechanisms have been combined before, compression has typically been applied only to uplink (client-to-server) communication, leaving the downlink (server-to-client) side unaddressed. In practice, however, both directions are costly. We propose BiCoLoR, the first algorithm to combine local training with bidirectional compression using arbitrary unbiased compressors. This joint design achieves accelerated complexity guarantees in both convex and strongly convex heterogeneous settings. Empirically, BiCoLoR outperforms existing algorithms and establishes a new standard in communication efficiency.

</details>


### [680] [A Mixture of Experts Vision Transformer for High-Fidelity Surface Code Decoding](https://arxiv.org/abs/2601.12483)
*Hoang Viet Nguyen,Manh Hung Nguyen,Hoang Ta,Van Khu Vu,Yeow Meng Chee*

Main category: quant-ph

Relevance: 45.0

TL;DR: 提出QuantumSMoE，一种基于量子视觉Transformer的解码器，通过加号形嵌入和自适应掩码来利用拓扑码的几何结构，使用混合专家层提高可扩展性，在toric code上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 量子纠错是大规模量子计算的关键，拓扑稳定子码因其几何局部性和实际相关性而备受关注。解码是实时操作的主要瓶颈，现有解码器存在局限性：经典算法解码器计算开销大，机器学习解码器未能充分利用拓扑码的晶格几何结构。

Method: 提出QuantumSMoE解码器：1) 使用量子视觉Transformer架构；2) 通过加号形嵌入和自适应掩码捕获局部相互作用和晶格连接性；3) 采用混合专家层提高可扩展性；4) 引入新颖的辅助损失函数。

Result: 在toric code上的实验表明，QuantumSMoE在性能上超越了最先进的机器学习解码器和广泛使用的经典基线方法。

Conclusion: QuantumSMoE通过有效利用拓扑码的几何结构，结合Transformer架构和混合专家层，为量子纠错解码提供了高效且可扩展的解决方案。

Abstract: Quantum error correction is a key ingredient for large scale quantum computation, protecting logical information from physical noise by encoding it into many physical qubits. Topological stabilizer codes are particularly appealing due to their geometric locality and practical relevance. In these codes, stabilizer measurements yield a syndrome that must be decoded into a recovery operation, making decoding a central bottleneck for scalable real time operation. Existing decoders are commonly classified into two categories. Classical algorithmic decoders provide strong and well established baselines, but may incur substantial computational overhead at large code distances or under stringent latency constraints. Machine learning based decoders offer fast GPU inference and flexible function approximation, yet many approaches do not explicitly exploit the lattice geometry and local structure of topological codes, which can limit performance. In this work, we propose QuantumSMoE, a quantum vision transformer based decoder that incorporates code structure through plus shaped embeddings and adaptive masking to capture local interactions and lattice connectivity, and improves scalability via a mixture of experts layer with a novel auxiliary loss. Experiments on the toric code demonstrate that QuantumSMoE outperforms state-of-the-art machine learning decoders as well as widely used classical baselines.

</details>


### [681] [PTL-PINNs: Perturbation-Guided Transfer Learning with Physics- Informed Neural Networks for Nonlinear Systems](https://arxiv.org/abs/2601.12093)
*Duarte Alexandrino,Ben Moseley,Pavlos Protopapas*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出PTL-PINN框架，将扰动理论与迁移学习结合，通过求解近似线性扰动系统的闭式解，快速求解非线性微分方程，计算速度比传统方法快一个数量级。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络(PINNs)在求解非线性微分方程时存在泛化能力有限、训练时间长的问题。需要一种能高效求解非线性动力学方程的方法，同时保持物理约束。

Method: 提出扰动引导的迁移学习框架PTL-PINN，结合扰动理论和迁移学习。不同于基于梯度的迁移学习，该方法通过闭式表达式求解近似线性扰动系统，计算复杂度仅为矩阵向量乘法。

Result: PTL-PINN在精度上与多种Runge-Kutta方法相当，计算速度提升一个数量级。在非线性振荡器、Lotka-Volterra系统、KPP-Fisher方程和波动方程等广泛问题上验证了性能。

Conclusion: 该工作将长期存在的扰动方法与PINNs连接起来，展示了扰动理论如何指导基础模型以接近经典求解器的速度求解非线性系统。

Abstract: Accurately and efficiently solving nonlinear differential equations is crucial for modeling dynamic behavior across science and engineering. Physics-Informed Neural Networks (PINNs) have emerged as a powerful solution that embeds physical laws in training by enforcing equation residuals. However, these struggle to model nonlinear dynamics, suffering from limited generalization across problems and long training times. To address these limitations, we propose a perturbation-guided transfer learning framework for PINNs (PTL-PINN), which integrates perturbation theory with transfer learning to efficiently solve nonlinear equations. Unlike gradient-based transfer learning, PTL-PINNs solve an approximate linear perturbative system using closed-form expressions, enabling rapid generalization with the time complexity of matrix-vector multiplication. We show that PTL-PINNs achieve accuracy comparable to various Runge-Kutta methods, with computational speeds up to one order of magnitude faster. To benchmark performance, we solve a broad set of problems, including nonlinear oscillators across various damping regimes, the equilibrium-centered Lotka-Volterra system, the KPP-Fisher and the Wave equation. Since perturbation theory sets the accuracy bound of PTL-PINNs, we systematically evaluate its practical applicability. This work connects long-standing perturbation methods with PINNs, demonstrating how perturbation theory can guide foundational models to solve nonlinear systems with speeds comparable to those of classical solvers.

</details>


### [682] [TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization](https://arxiv.org/abs/2601.12288)
*Lei Liu,Tengyuan Liu,Hongwei Zhao,Jiahui Huang,Ruibo Guo,Bin Li*

Main category: cs.LG

Relevance: 40.0

TL;DR: TimeGMM：基于高斯混合模型的概率时间序列预测框架，通过GRIN模块动态适应时间-概率分布偏移，在单次前向传播中捕获复杂未来分布，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有概率时间序列预测方法通常依赖计算昂贵的采样或限制性参数假设来表征未来分布，这限制了预测性能并引入分布不匹配问题。需要一种能高效捕获复杂分布的方法。

Method: 提出TimeGMM框架：1) 基于高斯混合模型(GMM)在单次前向传播中捕获复杂分布；2) 提出GMM适应的可逆实例归一化(GRIN)模块，动态适应时间-概率分布偏移；3) 集成时间编码器(TE-Module)和条件时间-概率解码器(CTPD-Module)联合捕获时间依赖性和混合分布参数。

Result: 在广泛实验中，TimeGMM始终优于最先进方法，在CRPS和NMAE指标上分别实现最大22.48%和21.23%的改进。

Conclusion: TimeGMM通过高斯混合模型框架和GRIN模块，有效解决了现有概率时间序列预测方法的限制，在单次前向传播中高效捕获复杂未来分布，显著提升了预测性能。

Abstract: Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. However, existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. To address these challenges, this paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48\% in CRPS and 21.23\% in NMAE.

</details>


### [683] [Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting](https://arxiv.org/abs/2601.12467)
*Saurish Nagrath*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出一个两阶段时间序列预测框架：第一阶段用CNN提取局部时间动态特征并生成补丁级token嵌入，第二阶段用Transformer编码器建模补丁间依赖关系进行预测。


<details>
  <summary>Details</summary>
Motivation: Transformer在时间序列预测中表现良好，但其效果严重依赖于从原始多元时间序列数据中提取的输入表示的质量和结构。现有方法在局部时间表示学习和全局依赖建模之间的分离不够明确。

Method: 两阶段框架：1) 局部时间表示学习阶段：CNN在固定长度时间补丁上操作，提取短程时间动态和非线性特征交互，生成紧凑的补丁级token嵌入；2) 全局依赖建模阶段：Transformer编码器处理token序列，建模补丁间时间依赖关系并生成预测。

Result: 在具有受控静态和动态因素的合成多元时间序列数据上的实验表明，所提出的基于补丁的token化策略相比卷积和基于补丁的Transformer基线实现了有竞争力的预测性能。

Conclusion: 结构化时间表示的重要性得到验证，将局部时间编码与基于注意力的全局建模解耦能够产生更有效和稳定的时间序列预测。

Abstract: Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.

</details>


### [684] [Deterministic Dynamics of Sampling Processes in Score-Based Diffusion Models with Multiplicative Noise Conditioning](https://arxiv.org/abs/2601.12965)
*Doheon Kim*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该论文从理论上解释了为什么使用乘法噪声条件的扩散模型虽然不能完全学习正确的分数函数，但在实践中仍能生成良好样本。


<details>
  <summary>Details</summary>
Motivation: Song和Ermon（2020）的研究表明，使用乘法噪声条件的神经网络模型（将模型表示为空间变量和噪声幅度的乘积）虽然不能完全学习正确的分数函数，但在实践中仍能生成令人满意的样本。这种理论与实践的差距需要理论解释。

Method: 通过研究相关微分方程的确定性动力学，从理论上分析乘法噪声条件模型的操作机制。该方法不依赖于随机过程，而是专注于确定性动态来理解模型行为。

Result: 提供了理论解释，说明为什么这种受限的模型结构在实践中仍然有效，尽管它不能完全学习正确的分数函数。这揭示了扩散模型在受限表示下的工作机制。

Conclusion: 即使模型表示受限（乘法噪声条件），扩散模型仍能有效工作，这可以通过分析相关微分方程的确定性动力学来解释。这一发现有助于理解扩散模型的鲁棒性和实际表现。

Abstract: Score-based diffusion models generate new samples by learning the score function associated with a diffusion process. While the effectiveness of these models can be theoretically explained using differential equations related to the sampling process, previous work by Song and Ermon (2020) demonstrated that neural networks using multiplicative noise conditioning can still generate satisfactory samples. In this setup, the model is expressed as the product of two functions: one depending on the spatial variable and the other on the noise magnitude. This structure limits the model's ability to represent a more general relationship between the spatial variable and the noise, indicating that it cannot fully learn the correct score. Despite this limitation, the models perform well in practice. In this work, we provide a theoretical explanation for this phenomenon by studying the deterministic dynamics of the associated differential equations, offering insight into how the model operates.

</details>


### [685] [BladeSDF : Unconditional and Conditional Generative Modeling of Representative Blade Geometries Using Signed Distance Functions](https://arxiv.org/abs/2601.13445)
*Ashish S. Nair,Sandipp Krishnan Ravi,Itzel Salgado,Changjie Sun,Sayan Ghosh,Liping Wang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 本文提出了一种基于DeepSDF的涡轮叶片几何生成框架，通过连续符号距离函数表示实现高精度重建和生成，建立了与叶片参数对齐的可解释潜在空间，并通过神经网络将工程描述符映射到潜在代码，实现性能感知的几何生成。


<details>
  <summary>Details</summary>
Motivation: 当前涡轮叶片设计面临性能感知建模和可制造设计生成的挑战，传统2D引导或无约束3D管道无法充分集成约束、目标和性能指标，需要开发领域特定的隐式生成框架。

Method: 使用DeepSDF的连续符号距离函数表示重建和生成平滑、水密几何；建立与叶片相关参数（如锥度和弦长比）对齐的可解释近高斯潜在空间；通过紧凑神经网络将工程描述符（如最大方向应变）映射到潜在代码。

Result: 实现了高重建保真度，表面距离误差集中在最大叶片尺寸的1%以内；对未见设计具有鲁棒泛化能力；能够通过插值和高斯采样进行可控探索和无条件合成。

Conclusion: 该方法超越了传统2D引导或无约束3D管道，为数据驱动的涡轮叶片建模和概念生成提供了实用且可解释的解决方案，通过集成约束、目标和性能指标推进了工程设计领域。

Abstract: Generative AI has emerged as a transformative paradigm in engineering design, enabling automated synthesis and reconstruction of complex 3D geometries while preserving feasibility and performance relevance. This paper introduces a domain-specific implicit generative framework for turbine blade geometry using DeepSDF, addressing critical gaps in performance-aware modeling and manufacturable design generation. The proposed method leverages a continuous signed distance function (SDF) representation to reconstruct and generate smooth, watertight geometries with quantified accuracy. It establishes an interpretable, near-Gaussian latent space that aligns with blade-relevant parameters, such as taper and chord ratios, enabling controlled exploration and unconditional synthesis through interpolation and Gaussian sampling. In addition, a compact neural network maps engineering descriptors, such as maximum directional strains, to latent codes, facilitating the generation of performance-informed geometry. The framework achieves high reconstruction fidelity, with surface distance errors concentrated within $1\%$ of the maximum blade dimension, and demonstrates robust generalization to unseen designs. By integrating constraints, objectives, and performance metrics, this approach advances beyond traditional 2D-guided or unconstrained 3D pipelines, offering a practical and interpretable solution for data-driven turbine blade modeling and concept generation.

</details>


### [686] [Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments](https://arxiv.org/abs/2601.13592)
*Hao Jing,Sa Xiao,Haoyu Li,Huadong Xiao,Wei Xue*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该研究将残差卷积神经网络嵌入中国气象局全球业务系统，替代传统辐射传输模型RRTMG，通过离线训练和在线耦合实现8倍加速，同时保持预报精度。


<details>
  <summary>Details</summary>
Motivation: 辐射过程是数值模型中最耗时的物理过程，机器学习方法可以模拟辐射过程以提高计算效率。研究从业务角度探讨混合预报框架中深度神经网络嵌入数值预报模型的关键限制，特别是耦合兼容性和长期积分稳定性两个基本瓶颈。

Method: 采用残差卷积神经网络近似RRTMG辐射传输模型，采用离线训练和在线耦合方法。首先通过模型模拟生成包含所有大气柱（有云和无云）的全面数据集。为确保混合模型稳定性，通过经验回放增强数据集，并基于物理意义施加额外输出约束。同时使用基于LibTorch的耦合方法，更适合实时业务计算。

Result: 混合模型能够按要求进行十天积分预报。两个月的业务回算实验表明，机器学习模拟器达到与传统物理方案相当的精度，同时计算速度提升约8倍。

Conclusion: 该研究成功将深度学习嵌入数值天气预报系统，解决了耦合兼容性和长期稳定性问题，为业务气象预报中的机器学习应用提供了可行方案。

Abstract: Radiation is typically the most time-consuming physical process in numerical models. One solution is to use machine learning methods to simulate the radiation process to improve computational efficiency. From an operational standpoint, this study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, with a specific focus on two fundamental bottlenecks: coupling compatibility and long-term integration stability. A residual convolutional neural network is employed to approximate the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. We adopted an offline training and online coupling approach. First, a comprehensive dataset is generated through model simulations, encompassing all atmospheric columns both with and without cloud cover. To ensure the stability of the hybrid model, the dataset is enhanced via experience replay, and additional output constraints based on physical significance are imposed. Meanwhile, a LibTorch-based coupling method is utilized, which is more suitable for real-time operational computations. The hybrid model is capable of performing ten-day integrated forecasts as required. A two-month operational reforecast experiment demonstrates that the machine learning emulator achieves accuracy comparable to that of the traditional physical scheme, while accelerating the computation speed by approximately eightfold.

</details>


### [687] [A Multimodal Data Processing Pipeline for MIMIC-IV Dataset](https://arxiv.org/abs/2601.11606)
*Farzana Islam Adiba,Varsha Danduri,Fahmida Liza Piya,Ali Abbasi,Mehak Gupta,Rahmatollah Beheshti*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出了一个针对MIMIC-IV多模态电子健康记录数据的综合处理管道，能够自动化处理结构化数据、临床笔记、波形和影像数据，显著减少处理时间并提高研究可重复性。


<details>
  <summary>Details</summary>
Motivation: MIMIC-IV数据集包含多种模态的医疗数据，但现有处理工具要么只支持部分模态，要么无法满足任意下游应用的需求，需要大量人工预处理和对齐工作。

Method: 扩展了之前流行的单模态管道，开发了一个可定制的多模态处理管道，能够系统整合不同模态数据，实现自动化队列选择、跨模态时间对齐，并生成适合静态和时间序列下游应用的标准输出格式。

Result: 发布了完整的代码库、简单UI界面和Python包，支持选择性集成（包含嵌入功能），显著减少了多模态数据处理时间，提高了基于MIMIC的研究的可重复性。

Conclusion: 该多模态管道为临床机器学习研究提供了高效、可复现的数据处理解决方案，有助于加速医疗AI研究。

Abstract: The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.

</details>


### [688] [Global Optimization By Gradient from Hierarchical Score-Matching Spaces](https://arxiv.org/abs/2601.11639)
*Ming Li*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出了一种通过分数匹配获取梯度的方法，将带复杂约束的优化问题统一为无约束的分层优化目标，首次实现了使用严格梯度的确定性全局优化方法，并揭示了全局优化与基于扩散的生成建模之间的深刻联系。


<details>
  <summary>Details</summary>
Motivation: 梯度下降作为最常用的优化方法存在局限性：只能达到局部最优，且仅适用于连续可微问题和简单凸约束。该工作旨在解决这些限制，将各种复杂约束的优化问题统一处理，实现全局优化。

Method: 通过分数匹配获取梯度，将所有带复杂约束的优化问题统一为无约束的分层优化目标。这种方法首次实现了使用严格梯度的确定性全局优化。

Result: 通过简单构造和复杂实际实验验证了方法的有效性。更重要的是，揭示了全局优化与基于扩散的生成建模之间的深刻理论联系。

Conclusion: 该方法突破了传统梯度下降的局限性，为处理复杂约束优化问题提供了新框架，并在优化理论与生成建模之间建立了重要桥梁。

Abstract: Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.

</details>


### [689] [Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning](https://arxiv.org/abs/2601.11657)
*Jack T. Beerman,Shobhan Roy,H. S. Udaykumar,Stephen S. Baek*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出D-PARC（可变形物理感知循环卷积）架构，通过受混合拉格朗日-欧拉数值方法启发的可变形卷积核，解决了传统CNN在高度非线性物理流建模中的局限性，在多个物理系统上以更小的模型规模实现了优于大型架构的精度。


<details>
  <summary>Details</summary>
Motivation: 当前物理感知深度学习（PADL）中的卷积神经网络（CNN）架构在处理高度非线性流时存在困难。虽然扩大模型规模是通用AI中解决复杂性的常用方法，但在物理建模中这种方法收益递减。需要更物理直觉的架构设计来替代简单的参数扩展。

Method: 受混合拉格朗日-欧拉（HLE）数值方法启发，提出可变形物理感知循环卷积（D-PARC）。该架构使用可变形卷积核，能够自适应地调整感受野，类似于计算力学中的自适应细化。通过分析显示，核表现出反聚类行为，演变成一种与传统h-或p-自适应不同的"主动过滤"策略。

Result: 在Burgers方程、Navier-Stokes方程和反应流等多个物理系统上，D-PARC相比显著更大的架构实现了更优的保真度。有效感受野分析证实，D-PARC能够自主地将资源集中在高应变区域，同时在其他区域粗化关注，这与计算力学中的自适应细化相呼应。

Conclusion: 物理直觉的架构设计可以超越参数缩放，表明在精简网络中进行战略性学习比无差别的网络扩展为PADL提供了更有效的路径。这为物理建模的深度学习架构设计提供了新方向。

Abstract: Physics-aware deep learning (PADL) enables rapid prediction of complex physical systems, yet current convolutional neural network (CNN) architectures struggle with highly nonlinear flows. While scaling model size addresses complexity in broader AI, this approach yields diminishing returns for physics modeling. Drawing inspiration from Hybrid Lagrangian-Eulerian (HLE) numerical methods, we introduce deformable physics-aware recurrent convolutions (D-PARC) to overcome the rigidity of CNNs. Across Burgers' equation, Navier-Stokes, and reactive flows, D-PARC achieves superior fidelity compared to substantially larger architectures. Analysis reveals that kernels display anti-clustering behavior, evolving into a learned "active filtration" strategy distinct from traditional h- or p-adaptivity. Effective receptive field analysis confirms that D-PARC autonomously concentrates resources in high-strain regions while coarsening focus elsewhere, mirroring adaptive refinement in computational mechanics. This demonstrates that physically intuitive architectural design can outperform parameter scaling, establishing that strategic learning in lean networks offers a more effective path forward for PADL than indiscriminate network expansion.

</details>


### [690] [IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning](https://arxiv.org/abs/2601.11669)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Xiaofeng Yang,Qingchao Jiang,Xuefeng Yan*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出IPEC方法，通过动态辅助集利用先前查询样本信息优化原型估计，提升小样本分类性能


<details>
  <summary>Details</summary>
Motivation: 现有基于度量的小样本学习方法在测试时假设批次独立，无法利用先前批次积累的宝贵知识，限制了性能提升

Method: 提出增量原型增强分类器(IPEC)：1)维护动态辅助集，选择性纳入高置信度查询样本；2)设计双重过滤机制评估样本质量；3)基于贝叶斯解释，将支持集视为先验，辅助集视为数据驱动的后验；4)采用"预热-测试"两阶段推理协议

Result: 在多个小样本分类任务上验证了方法的优越性能

Conclusion: IPEC通过利用测试时信息逐步构建更稳定、更具代表性的原型，有效减少对初始支持集的依赖，提升小样本分类性能

Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.

</details>


### [691] [jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation](https://arxiv.org/abs/2601.11719)
*Ho Fung Tsoi,Dylan Rankin*

Main category: cs.LG

Relevance: 35.0

TL;DR: jBOT是一种用于粒子物理中喷注数据的自监督预训练方法，通过局部粒子级蒸馏和全局喷注级蒸馏学习表示，支持异常检测和分类任务


<details>
  <summary>Details</summary>
Motivation: 自监督学习可以在无标签数据上学习特征表示，但粒子物理中的喷注数据需要专门的方法来捕捉局部和全局语义信息，以支持下游任务如异常检测和分类

Method: 提出jBOT预训练方法，结合局部粒子级蒸馏和全局喷注级蒸馏的自蒸馏框架，在CERN大型强子对撞机的喷注数据上进行预训练

Result: 预训练后的表示空间出现语义类别聚类现象；仅用背景喷注预训练的冻结嵌入可通过简单距离度量实现异常检测；微调后的分类性能优于从头训练的监督模型

Conclusion: jBOT为粒子物理喷注数据提供有效的自监督预训练方法，能够学习有意义的表示，支持多种下游任务，并在分类任务上超越监督基线

Abstract: Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.

</details>


### [692] [Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis](https://arxiv.org/abs/2601.11789)
*Shenyang Deng,Boyao Liao,Zhuoli Ouyang,Tianyu Pang,Minhak Song,Yaoqing Yang*

Main category: cs.LG

Relevance: 35.0

TL;DR: 论文研究了SGD在病态优化中的"可疑对齐"现象：Hessian谱分裂为主导和主体子空间时，梯度对齐呈现先下降、后上升、最终稳定的三阶段行为。这种对齐是"可疑"的，因为沿高对齐主导子空间的梯度更新反而无法有效降低损失。


<details>
  <summary>Details</summary>
Motivation: 研究SGD在病态优化问题中的梯度对齐行为，特别是解释为什么沿主导子空间的梯度更新反而无效这一看似矛盾的现象。这有助于理解SGD在非凸优化中的动态行为。

Method: 在高维二次设置中进行细粒度分析，提出步长选择条件。主要方法包括：1) 提出自适应临界步长η_t*来区分对齐下降和对齐增加机制；2) 分析在充分病态条件下，存在步长区间使得主体子空间投影能降低损失而主导子空间投影反而增加损失；3) 基于自适应步长理论证明恒定步长下SGD的两阶段行为。

Result: 1) 在低对齐机制中，自适应临界步长η_t*区分了对齐下降和对齐增加机制；2) 在高对齐机制中，对齐具有自校正特性，无论步长如何都会下降；3) 在充分病态条件下，存在步长区间使得主体子空间投影有效而主导子空间投影无效；4) 恒定步长下SGD确实表现出初始对齐下降阶段，随后稳定在高对齐状态的两阶段行为。

Conclusion: 论文通过理论分析解释了SGD中的"可疑对齐"现象，揭示了步长选择如何影响梯度对齐动态，并解释了为什么沿主导子空间的梯度更新反而无效。这为理解SGD在病态优化问题中的行为提供了理论依据。

Abstract: This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $η_t^*$ separates alignment-decreasing ($η_t < η_t^*$) from alignment-increasing ($η_t > η_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.

</details>


### [693] [MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization](https://arxiv.org/abs/2601.11827)
*Andrea Rubbi,Amir Akbarnejad,Mohammad Vali Sanian,Aryan Yazdan Parast,Hesam Asadollahzadeh,Arian Amani,Naveed Akhtar,Sarah Cooper,Andrew Bassett,Pietro Liò,Lassi Paavolainen,Sattar Vakili,Mo Lotfollahi*

Main category: cs.LG

Relevance: 35.0

TL;DR: MixFlow是一个用于描述符控制生成的流匹配框架，通过联合学习描述符条件的基础分布和流场，显著提升了分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有条件流匹配方法在分布偏移下的泛化能力有限，难以在训练条件之外进行外推。作者旨在解决条件生成建模中的鲁棒泛化挑战。

Method: 提出MixFlow框架：1) 将基础分布建模为可学习的描述符依赖混合分布；2) 通过最短路径流匹配联合学习描述符条件的基础分布和流场；3) 支持平滑插值和外推到未见条件。

Result: 在多个领域（单细胞转录组数据扰动预测、高内涵显微镜药物筛选）中，MixFlow显著优于标准条件流匹配基线，展现出更好的分布外泛化性能。

Conclusion: MixFlow提供了一个简单而强大的方法，可在异构领域实现鲁棒、可泛化和可控的生成建模，有效解决了分布偏移下的泛化挑战。

Abstract: Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.

</details>


### [694] [Trainability-Oriented Hybrid Quantum Regression via Geometric Preconditioning and Curriculum Optimization](https://arxiv.org/abs/2601.11942)
*Qingyu Meng,Yangshuai Wang*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出了一种混合量子-经典回归框架，通过可学习的几何预处理器和课程优化协议来改善量子神经网络在回归任务中的训练稳定性和性能


<details>
  <summary>Details</summary>
Motivation: 量子神经网络在科学机器学习中受到关注，但在回归任务中常面临梯度噪声和优化条件差的问题，导致训练困难

Method: 1) 轻量级经典嵌入层作为可学习的几何预处理器，重塑输入表示以改善下游变分量子电路的优化条件；2) 课程优化协议，逐步增加电路深度并从SPSA随机探索过渡到Adam梯度微调

Result: 在PDE回归基准和标准回归数据集上，在固定训练预算下，该框架始终优于纯QNN基线，在数据有限情况下提供更稳定的收敛，并减少结构化误差

Conclusion: 几何预处理与课程训练相结合是稳定量子回归的实用方法，能改善量子神经网络在回归任务中的性能

Abstract: Quantum neural networks (QNNs) have attracted growing interest for scientific machine learning, yet in regression settings they often suffer from limited trainability under noisy gradients and ill-conditioned optimization. We propose a hybrid quantum-classical regression framework designed to mitigate these bottlenecks. Our model prepends a lightweight classical embedding that acts as a learnable geometric preconditioner, reshaping the input representation to better condition a downstream variational quantum circuit. Building on this architecture, we introduce a curriculum optimization protocol that progressively increases circuit depth and transitions from SPSA-based stochastic exploration to Adam-based gradient fine-tuning. We evaluate the approach on PDE-informed regression benchmarks and standard regression datasets under a fixed training budget in a simulator setting. Empirically, the proposed framework consistently improves over pure QNN baselines and yields more stable convergence in data-limited regimes. We further observe reduced structured errors that are visually correlated with oscillatory components on several scientific benchmarks, suggesting that geometric preconditioning combined with curriculum training is a practical approach for stabilizing quantum regression.

</details>


### [695] [Data-centric Prompt Tuning for Dynamic Graphs](https://arxiv.org/abs/2601.11954)
*Yufei Peng,Cheng Yang,Zhengjie Fan,Chuan Shi*

Main category: cs.LG

Relevance: 35.0

TL;DR: DDGPrompt是一个面向动态图的数据中心化提示调优框架，通过定义统一的节点特征矩阵并引入三种提示矩阵（时间偏置、边权重、特征掩码）来调整预训练节点嵌入，以更好地适应下游任务。


<details>
  <summary>Details</summary>
Motivation: 传统动态图方法通常通过动态链接预测预训练模型，然后将节点时间嵌入直接应用于下游任务。但由于下游任务差异大，特别是在少样本设置下，性能会下降。现有提示方法通常与特定模型架构或预训练任务强耦合，难以适应新模型设计，且只关注修改节点或时间特征而忽略空间结构信息，导致表达能力有限。

Method: 1. 定义统一的节点表达特征矩阵，聚合每个节点的所有相关时间和结构信息，确保与各种动态图模型兼容。2. 引入三种提示矩阵：时间偏置、边权重和特征掩码，在输入数据层面完全调整特征矩阵，实现节点嵌入的任务特定适应。

Result: 在四个公共动态图数据集上，在严格的少样本设置下进行评估。实验结果表明，在标签有限和冷启动条件下，DDGPrompt显著优于传统方法和现有提示方法。

Conclusion: DDGPrompt是一个有效的数据中心化提示框架，能够通过调整预训练节点嵌入来更好地适应多样化的下游任务，特别是在少样本和冷启动场景下表现出色。

Abstract: Dynamic graphs have attracted increasing attention due to their ability to model complex and evolving relationships in real-world scenarios. Traditional approaches typically pre-train models using dynamic link prediction and directly apply the resulting node temporal embeddings to specific downstream tasks. However, the significant differences among downstream tasks often lead to performance degradation, especially under few-shot settings. Prompt tuning has emerged as an effective solution to this problem. Existing prompting methods are often strongly coupled with specific model architectures or pretraining tasks, which makes it difficult to adapt to recent or future model designs. Moreover, their exclusive focus on modifying node or temporal features while neglecting spatial structural information leads to limited expressiveness and degraded performance. To address these limitations, we propose DDGPrompt, a data-centric prompting framework designed to effectively refine pre-trained node embeddings at the input data level, enabling better adaptability to diverse downstream tasks. We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models. Then, we introduce three prompt matrices (temporal bias, edge weight, and feature mask) to adjust the feature matrix completely, achieving task-specific adaptation of node embeddings. We evaluate DDGPrompt under a strict few-shot setting on four public dynamic graph datasets. Experimental results demonstrate that our method significantly outperforms traditional methods and prompting approaches in scenarios with limited labels and cold-start conditions.

</details>


### [696] [One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints](https://arxiv.org/abs/2601.11977)
*Ren He,Yinliang Xu,Jinfeng Wang,Jeremy Watson,Jian Song*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出MoE-Encoder模块，通过稀疏专家混合层增强预训练时间序列模型，解决电力系统多变量时间序列预测中的复杂依赖和隐私约束问题。


<details>
  <summary>Details</summary>
Motivation: 电力系统预测面临多变量复杂依赖、严格隐私约束和跨场景泛化困难。传统方法需要大量专家知识，预训练模型在领域特定任务上零样本性能有限。

Method: 在预训练预测模型的tokenization和encoding之间插入稀疏MoE层，将多变量预测转化为专家引导的单变量任务，支持联邦学习中的本地训练和轻量参数共享。

Result: 在公共多变量数据集上显著提升预测精度，联邦环境模拟显示仅传输MoE-Encoder参数即可高效适应新区域，性能下降最小。

Conclusion: MoE-Encoder为时间序列基础模型提供了可扩展且隐私感知的扩展方案。

Abstract: Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.

</details>


### [697] [Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding](https://arxiv.org/abs/2601.12095)
*Hamidreza Sadeghi,Saeedeh Momtazi,Reza Safabakhsh*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出一种固定长度的数字嵌入向量，在有理数域中保持加法、乘法和比较等代数运算，通过神经同构场实现神经抽象代数结构。


<details>
  <summary>Details</summary>
Motivation: 神经网络在处理极大或极小数值时面临溢出、下溢和不稳定输出变化等问题，需要一种能保持代数性质同时避免数值不稳定的数字表示方法。

Method: 使用嵌入向量代替原始数值，提出神经同构场作为代数结构（如群和域）的神经抽象，其元素是保持代数结构的嵌入向量，在有理数域中保持加法、乘法和比较运算。

Result: 加法运算表现优异，在恒等性、封闭性和结合性等关键代数测试中准确率超过95%；乘法运算面临挑战，在不同代数性质上准确率在53%到73%之间。

Conclusion: 该方法在保持加法代数性质方面表现出色，但在乘法运算上仍需改进，为神经网络处理数值计算提供了有前景的方向。

Abstract: Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations, including addition, multiplication, and comparison, within the field of rational numbers. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures such as groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95 percent accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging from 53 percent to 73 percent across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.

</details>


### [698] [SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data](https://arxiv.org/abs/2601.12124)
*Bing Hu,Yixin Li,Asma Bahamyirou,Helen Chen*

Main category: cs.LG

Relevance: 35.0

TL;DR: SynQP是一个用于合成数据隐私评估的开放框架，使用模拟敏感数据来评估隐私风险，提出了新的身份披露风险指标，并在健康应用中展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 健康应用中合成数据的使用引发隐私担忧，但缺乏开放的隐私评估框架和可访问的基准数据集阻碍了其采用。主要挑战是难以获取敏感数据进行隐私风险评估。

Method: 引入SynQP框架，使用模拟敏感数据进行合成数据生成的隐私基准测试，确保原始数据保密。提出新的身份披露风险指标，更准确地评估隐私风险。

Result: 在质量评估中，非私有模型实现了接近完美的机器学习效能（≥0.97）。隐私评估显示差分隐私（DP）持续降低了身份披露风险和成员推理攻击风险，所有DP增强模型都保持在0.09监管阈值以下。

Conclusion: SynQP为改善隐私评估的透明度和可靠性提供了关键工具，使合成数据在健康相关应用中的使用更加安全。

Abstract: The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \(\ge0.97\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP

</details>


### [699] [One-Sided Matrix Completion from Ultra-Sparse Samples](https://arxiv.org/abs/2601.12213)
*Hongyang R. Zhang,Zhenshuo Zhang,Huy L. Nguyen,Guanghui Lan*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文研究超稀疏采样下的矩阵补全问题，提出了一种无偏估计器，通过梯度下降恢复矩阵的列空间或二阶矩矩阵，在理论保证和实际应用中均优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 矩阵补全是一个经典问题，但在超稀疏采样场景下（每个条目独立观测概率为p=C/d，C≥2），当每行只有C个条目（少于矩阵秩）时，准确补全M是不可能的。本文旨在估计M的行空间或平均二阶矩矩阵T=M^T M/n，这在大型稀疏面板数据应用中很重要。

Method: 提出无偏估计器：首先对二阶矩矩阵的非零条目按其观测频率进行归一化，然后使用梯度下降来补全T的缺失条目。归一化过程将n个二项随机变量的加权和除以总观测数。理论证明该估计器对任意p都是无偏的且方差较低。

Result: 理论证明：当M的行向量来自满足不相干条件的秩r因子模型时，如果n≥O(d r^5 ε^{-2} C^{-2} log d)，梯度下降目标的任何局部最小值都是近似全局的，能以误差最多ε^2恢复T。实验验证：在MovieLens数据集上减少88%偏差；在Amazon评论数据集（稀疏度10^{-7}）上，T的恢复误差减少59%，M的恢复误差减少38%。

Conclusion: 本文提出的方法在超稀疏采样场景下有效估计矩阵的行空间或二阶矩矩阵，理论上有保证，实际应用中显著优于基线方法，特别适用于行数远大于列数的大型稀疏面板数据。

Abstract: Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\times d$ matrix $M$ (with $n \ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\top} M / n$.
  The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \ge O({d r^5 ε^{-2} C^{-2} \log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $ε^2$.
  Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\%$ and $M$ by $38\%$ compared to baseline methods.

</details>


### [700] [Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments](https://arxiv.org/abs/2601.12305)
*Deepak Kanneganti,Sajib Mistry,Sheik Fattah,Joshua Boland,Aneesh Krishna*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出MLaaS数据集生成器(MDG)框架，用于创建可配置、可复现的数据集来评估MLaaS服务选择与组合。该框架通过训练和评估多种模型家族，模拟真实MLaaS行为，记录详细的功能属性、服务质量指标和组合特定指标。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统化、可配置的数据集来评估MLaaS服务选择和组合，现有方法难以模拟真实MLaaS行为和服务间交互，限制了数据驱动研究的发展。

Method: MDG框架训练和评估多种模型家族（如不同神经网络架构）在多个真实数据集和数据分布设置下，记录功能属性、QoS指标和组合特定指标。内置组合机制模拟物联网条件下的服务交互，生成超过1万个MLaaS服务实例。

Result: 生成大规模基准数据集，实验表明MDG生成的数据集相比现有基线提高了选择准确性和组合质量。框架为MLaaS选择和组合的数据驱动研究提供了实用且可扩展的基础。

Conclusion: MDG框架填补了MLaaS评估数据集的空白，通过模拟真实服务行为和交互，为系统化分析服务性能和跨服务行为提供了有效工具，推动了MLaaS选择和组合研究的发展。

Abstract: We propose a novel MLaaS Dataset Generator (MDG) framework that creates configurable and reproducible datasets for evaluating Machine Learning as a Service (MLaaS) selection and composition. MDG simulates realistic MLaaS behaviour by training and evaluating diverse model families across multiple real-world datasets and data distribution settings. It records detailed functional attributes, quality of service metrics, and composition-specific indicators, enabling systematic analysis of service performance and cross-service behaviour. Using MDG, we generate more than ten thousand MLaaS service instances and construct a large-scale benchmark dataset suitable for downstream evaluation. We also implement a built-in composition mechanism that models how services interact under varied Internet of Things conditions. Experiments demonstrate that datasets generated by MDG enhance selection accuracy and composition quality compared to existing baselines. MDG provides a practical and extensible foundation for advancing data-driven research on MLaaS selection and composition

</details>


### [701] [Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays](https://arxiv.org/abs/2601.12322)
*Chang-Wei Shi,Shi-Shang Wang,Wu-Jun Li*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出OrLoMo方法，首次实现带本地更新的异步分布式动量SGD，通过按全局迭代顺序聚合本地动量来加速异构集群训练


<details>
  <summary>Details</summary>
Motivation: 动量SGD是深度模型训练的基础优化器，异步分布式学习对大规模模型训练至关重要，特别是在异构计算能力的集群中。现有方法缺乏异步分布式动量SGD与本地更新的结合方案。

Method: 提出OrLoMo方法：每个工作节点本地运行动量SGD，服务器根据全局迭代索引按顺序聚合各工作节点的本地动量，支持任意延迟下的异步训练。

Result: 实验验证OrLoMo优于其同步版本和其他异步方法，在非凸问题下证明了任意延迟的收敛性。

Conclusion: OrLoMo是首个实现异步分布式动量SGD与本地更新的方法，能有效加速异构集群中的大规模模型训练。

Abstract: Momentum SGD (MSGD) serves as a foundational optimizer in training deep models due to momentum's key role in accelerating convergence and enhancing generalization. Meanwhile, asynchronous distributed learning is crucial for training large-scale deep models, especially when the computing capabilities of the workers in the cluster are heterogeneous. To reduce communication frequency, local updates are widely adopted in distributed learning. However, how to implement asynchronous distributed MSGD with local updates remains unexplored. To solve this problem, we propose a novel method, called \underline{or}dered \underline{lo}cal \underline{mo}mentum (OrLoMo), for asynchronous distributed learning. In OrLoMo, each worker runs MSGD locally. Then the local momentum from each worker will be aggregated by the server in order based on its global iteration index. To the best of our knowledge, OrLoMo is the first method to implement asynchronous distributed MSGD with local updates. We prove the convergence of OrLoMo for non-convex problems under arbitrary delays. Experiments validate that OrLoMo can outperform its synchronous counterpart and other asynchronous methods.

</details>


### [702] [Statistical-Neural Interaction Networks for Interpretable Mixed-Type Data Imputation](https://arxiv.org/abs/2601.12380)
*Ou Deng,Shoji Nishimura,Atsushi Ogihara,Qun Jin*

Main category: cs.LG

Relevance: 35.0

TL;DR: SNI提出了一种可解释的混合类型数据填补框架，结合统计先验和神经特征注意力，通过可控先验特征注意力模块实现统计与神经的权衡，并提供内在的特征依赖诊断。


<details>
  <summary>Details</summary>
Motivation: 现实世界表格数据常包含连续测量和分类记录，但缺失值普遍存在且会扭曲下游分析。现有方法要么是纯统计的（如MICE），要么是纯神经的（如GAIN），缺乏可解释性和统计先验的结合。

Method: 提出Statistical-Neural Interaction (SNI)框架，包含Controllable-Prior Feature Attention (CPFA)模块，学习头级先验强度系数{λ_h}，软正则化注意力朝向统计先验，同时允许数据驱动的非线性模式学习。除了填补，SNI还能聚合注意力图为有向特征依赖矩阵。

Result: 在6个数据集（ICU监测、人口调查、社会经济统计、工程应用）上评估，与6个基线方法比较。在30% MCAR/strict-MAR缺失下，SNI在连续变量指标上具有竞争力，但在分类变量上常被MissForest、MIWAE等准确率优先的方法超越。提供内在依赖诊断和明确的统计-神经权衡参数。

Conclusion: SNI在准确性和可解释性之间提供权衡，特别适用于需要理解填补依赖关系的部署场景。对于严重不平衡的分类目标存在局限性，但在可解释性重要的场景中，这种权衡可能是合理的。

Abstract: Real-world tabular databases routinely combine continuous measurements and categorical records, yet missing entries are pervasive and can distort downstream analysis. We propose Statistical-Neural Interaction (SNI), an interpretable mixed-type imputation framework that couples correlation-derived statistical priors with neural feature attention through a Controllable-Prior Feature Attention (CPFA) module. CPFA learns head-wise prior-strength coefficients $\{λ_h\}$ that softly regularize attention toward the prior while allowing data-driven deviations when nonlinear patterns appear to be present in the data. Beyond imputation, SNI aggregates attention maps into a directed feature-dependency matrix that summarizes which variables the imputer relied on, without requiring post-hoc explainers. We evaluate SNI against six baselines (Mean/Mode, MICE, KNN, MissForest, GAIN, MIWAE) on six datasets spanning ICU monitoring, population surveys, socio-economic statistics, and engineering applications. Under MCAR/strict-MAR at 30\% missingness, SNI is generally competitive on continuous metrics but is often outperformed by accuracy-first baselines (MissForest, MIWAE) on categorical variables; in return, it provides intrinsic dependency diagnostics and explicit statistical-neural trade-off parameters. We additionally report MNAR stress tests (with a mask-aware variant) and discuss computational cost, limitations -- particularly for severely imbalanced categorical targets -- and deployment scenarios where interpretability may justify the trade-off.

</details>


### [703] [Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants](https://arxiv.org/abs/2601.12405)
*Manasi Kanade,Abhi Thakkar,Gabriela Fernandes*

Main category: cs.LG

Relevance: 35.0

TL;DR: 开发了一个可解释的机器学习框架，用于儿科牙科风险分层，强调可解释性和伦理部署而非最大预测准确性


<details>
  <summary>Details</summary>
Motivation: 儿科牙科疾病是全球最普遍且不公平的慢性健康问题之一。虽然流行病学证据显示口腔健康结果与社会经济和人口因素相关，但当前牙科AI应用主要依赖图像诊断和黑盒预测模型，缺乏透明度，在儿科人群中存在伦理应用限制。

Method: 使用人口层面的儿科数据（包括年龄、收入贫困比、种族/民族、性别和病史）训练监督机器学习模型。通过ROC分析和校准曲线评估性能，使用SHAP（SHapley Additive exPlanations）实现全局和个体层面的预测解释。

Result: 模型实现了中等区分度（AUC = 0.61），校准保守，在高概率水平下低估风险。SHAP分析显示年龄和收入贫困比对预测风险贡献最大，其次是种族/民族和性别。

Conclusion: 可解释机器学习支持透明、预防导向的儿科牙科风险分层，有助于人群筛查和公平资源分配，而非诊断决策。

Abstract: Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.
  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.
  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.
  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.
  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.

</details>


### [704] [Cooperative Multi-agent RL with Communication Constraints](https://arxiv.org/abs/2601.12518)
*Nuoya Xiong,Aarti Singh*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出基策略预测方法，通过旧梯度预测策略更新，减少多智能体强化学习中通信轮次，在有限通信下实现高效学习


<details>
  <summary>Details</summary>
Motivation: 传统合作式多智能体强化学习通常假设能频繁获取全局信息（如团队奖励、其他智能体动作），但在去中心化系统中由于高通信成本不现实。当通信受限时，智能体只能依赖过时信息估计梯度和更新策略，重要性采样方法在通信受限时变得不稳定。

Method: 提出基策略预测技术，利用旧梯度预测策略更新，为一系列基策略收集样本，减少基策略与当前策略之间的差距。该方法能在单次通信轮次内收集预测基策略的样本，显著减少通信需求。

Result: 理论上证明算法在势博弈中仅需O(ε^{-3/4})通信轮次和O(poly(max_i|A_i|)ε^{-11/4})样本收敛到ε-纳什均衡，改进了现有最优结果。实验在模拟游戏和复杂环境的MAPPO中验证了有效性。

Conclusion: 基策略预测方法能有效减少多智能体强化学习的通信需求，在有限通信下实现高效学习，为去中心化MARL系统提供了实用解决方案。

Abstract: Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\varepsilon$-Nash equilibrium in potential games with only $O(\varepsilon^{-3/4})$ communication rounds and $O(poly(\max_i |A_i|)\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.

</details>


### [705] [Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem](https://arxiv.org/abs/2601.12543)
*Alireza Ghahtarani,Martin Cousineau,Amir-massoud Farahmand,Jorge E. Mendoza*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文将电动汽车在线集中充电调度问题（OCCSP）游戏化，通过将充电块放置在时空约束网格中，使用专家演示训练学习代理，并采用DAgger算法改进，在负载均衡方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决电动汽车动态到达时的实时充电调度问题，在容量限制下平衡有限规划期内的负载，降低系统成本并延迟昂贵的电网升级需求。

Method: 1. 将OCCSP问题游戏化，建模为在时空和容量约束网格中放置充电块的游戏；2. 设计启发式策略；3. 使用专家演示训练学习代理；4. 采用Dataset Aggregation（DAgger）算法改进学习代理；5. 提出图像到移动模型。

Result: 游戏化学习显著提升负载均衡性能，使用DAgger训练的模型在多种EV到达模式下均优于启发式基线、基于向量的方法和监督学习代理，并在敏感性分析中表现出鲁棒性。在蒙特利尔地区的实际案例中，每年可降低数千万美元系统成本。

Conclusion: 游戏化方法降低了模型复杂度并提供了更紧的泛化界限，基于DAgger的图像到移动模型在电动汽车充电调度中表现出优越性能，具有显著的经济价值和延缓电网升级的潜力。

Abstract: We study the online centralized charging scheduling problem (OCCSP). In this problem, a central authority must decide, in real time, when to charge dynamically arriving electric vehicles (EVs), subject to capacity limits, with the objective of balancing load across a finite planning horizon. To solve the problem, we first gamify it; that is, we model it as a game where charging blocks are placed within temporal and capacity constraints on a grid. We design heuristic policies, train learning agents with expert demonstrations, and improve them using Dataset Aggregation (DAgger). From a theoretical standpoint, we show that gamification reduces model complexity and yields tighter generalization bounds than vector-based formulations. Experiments across multiple EV arrival patterns confirm that gamified learning enhances load balancing. In particular, the image-to-movement model trained with DAgger consistently outperforms heuristic baselines, vector-based approaches, and supervised learning agents, while also demonstrating robustness in sensitivity analyses. These operational gains translate into tangible economic value. In a real-world case study for the Greater Montréal Area (Québec, Canada) using utility cost data, the proposed methods lower system costs by tens of millions of dollars per year over the prevailing practice and show clear potential to delay costly grid upgrades.

</details>


### [706] [Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory](https://arxiv.org/abs/2601.12557)
*Mark Moussa,Amber V. Young,Brianna Isola,Vasuda Trehan,Michael D. Himes,Nicholas Wogan,Giada Arney*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出了两种机器学习架构（BCNN和SQuAT）用于从系外行星反射光谱预测生物特征物种通量，旨在为NASA的HWO等旗舰任务优化观测优先级排序。


<details>
  <summary>Details</summary>
Motivation: 未来直接成像旗舰任务（如NASA的HWO）面临严格的时间和资源限制，需要优先选择观测目标。当前缺乏能够从反射光谱中准确预测生物特征物种通量并提供可靠不确定性量化和可解释性的方法。

Method: 提出了两种架构：1）贝叶斯卷积神经网络（BCNN），用于量化认知和随机不确定性；2）光谱查询自适应Transformer（SQuAT），采用查询驱动的注意力机制，将光谱特征与特定生物特征物种明确关联，增强可解释性。

Result: 两种模型在涵盖广泛系外行星条件的增强数据集上都实现了相当高的预测准确性。BCNN在不确定性量化方面表现优异，SQuAT在光谱可解释性方面具有优势。

Conclusion: 这些方法有望加速目标筛选、优化观测计划，并为HWO等即将到来的旗舰任务最大化科学回报。它们为系外行星观测中的机器学习应用提供了新的工具。

Abstract: Future direct-imaging flagship missions, such as NASA's Habitable Worlds Observatory (HWO), face critical decisions in prioritizing observations due to extremely stringent time and resource constraints. In this paper, we introduce two advanced machine-learning architectures tailored for predicting biosignature species fluxes from exoplanetary reflected-light spectra: a Bayesian Convolutional Neural Network (BCNN) and our novel model architecture, the Spectral Query Adaptive Transformer (SQuAT). The BCNN robustly quantifies both epistemic and aleatoric uncertainties, offering reliable predictions under diverse observational conditions, whereas SQuAT employs query-driven attention mechanisms to enhance interpretability by explicitly associating spectral features with specific biosignature species. We demonstrate that both models achieve comparably high predictive accuracy on an augmented dataset spanning a wide range of exoplanetary conditions, while highlighting their distinct advantages in uncertainty quantification and spectral interpretability. These capabilities position our methods as promising tools for accelerating target triage, optimizing observation schedules, and maximizing scientific return for upcoming flagship missions such as HWO.

</details>


### [707] [Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.12637)
*Long D. Nguyen,Kelin Xia,Binh P. Nguyen*

Main category: cs.LG

Relevance: 35.0

TL;DR: MI-MoE：一种用于3D分子图学习的多尺度交互混合专家模型，通过距离截断专家集合和拓扑门控编码器自适应建模不同几何尺度下的分子相互作用。


<details>
  <summary>Details</summary>
Motivation: 大多数3D分子图神经网络仍依赖全局固定的邻域启发式方法（如距离截断和最大邻居限制）来定义局部消息传递邻域，导致刚性的、数据无关的交互预算。分子性质依赖于3D几何结构，非共价相互作用、立体化学效应和中长程力由空间距离和角度决定，这些无法通过2D键图唯一捕获。

Method: 提出多尺度交互混合专家（MI-MoE）：1）引入距离截断专家集合，显式捕获短程、中程和长程相互作用，不依赖单一截断；2）设计拓扑门控编码器，使用基于过滤的描述符（包括持久同调特征）将输入路由到专家，总结连接性如何随半径演化；3）MI-MoE作为插件模块可改进多种3D分子骨干网络。

Result: MI-MoE在多个强3D分子骨干网络上一致改进，覆盖回归和分类任务的多样化分子和聚合物性质预测基准数据集。结果表明拓扑感知的多尺度路由是3D分子图学习的有效原则。

Conclusion: 拓扑感知的多尺度路由是3D分子图学习的有效原则。MI-MoE通过自适应建模不同几何尺度下的相互作用，显著提升了分子性质预测性能。

Abstract: Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Yet most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.

</details>


### [708] [Resource-Conscious RL Algorithms for Deep Brain Stimulation](https://arxiv.org/abs/2601.12699)
*Arkaprava Gupta,Nicholas Carter,William Zellers,Prateek Ganguli,Benedikt Dietrich,Vibhor Krishna,Parasara Sridhar Duggirala,Samarjit Chakraborty*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出T3P MAB强化学习方法用于帕金森病深部脑刺激，相比现有方法更轻量、无需离线训练，能同时调节频率和振幅，适合在资源受限的植入设备上部署。


<details>
  <summary>Details</summary>
Motivation: 传统DBS使用固定频率和振幅存在副作用和电池寿命短的问题，现有RL方法计算复杂、收敛慢、无法在植入设备上运行，且大多只调节单一参数。

Method: 提出时间与阈值触发的多臂老虎机(T3P MAB)强化学习方法，轻量级设计无需离线训练，能同时优化DBS的频率和振幅参数，并在多种MCU平台上实现硬件部署。

Result: T3P MAB算法在资源受限平台上表现出更好的样本效率和收敛速度，能耗测量显示适合植入设备部署，相比现有RL方法功耗更低。

Conclusion: T3P MAB为自适应DBS提供了一种轻量、高效的RL解决方案，首次在硬件上实现MAB代理，展示了在资源受限医疗设备上的应用潜力。

Abstract: Deep Brain Stimulation (DBS) has proven to be a promising treatment of Parkinson's Disease (PD). DBS involves stimulating specific regions of the brain's Basal Ganglia (BG) using electric impulses to alleviate symptoms of PD such as tremors, rigidity, and bradykinesia. Although most clinical DBS approaches today use a fixed frequency and amplitude, they suffer from side effects (such as slurring of speech) and shortened battery life of the implant. Reinforcement learning (RL) approaches have been used in recent research to perform DBS in a more adaptive manner to improve overall patient outcome. These RL algorithms are, however, too complex to be trained in vivo due to their long convergence time and requirement of high computational resources.
  We propose a new Time & Threshold-Triggered Multi-Armed Bandit (T3P MAB) RL approach for DBS that is more effective than existing algorithms. Further, our T3P agent is lightweight enough to be deployed in the implant, unlike current deep-RL strategies, and even forgoes the need for an offline training phase. Additionally, most existing RL approaches have focused on modulating only frequency or amplitude, and the possibility of tuning them together remains greatly unexplored in the literature. Our RL agent can tune both frequency and amplitude of DBS signals to the brain with better sample efficiency and requires minimal time to converge. We implement an MAB agent for DBS for the first time on hardware to report energy measurements and prove its suitability for resource-constrained platforms. Our T3P MAB algorithm is deployed on a variety of microcontroller unit (MCU) setups to show its efficiency in terms of power consumption as opposed to other existing RL approaches used in recent work.

</details>


### [709] [Trend-Adjusted Time Series Models with an Application to Gold Price Forecasting](https://arxiv.org/abs/2601.12706)
*Sina Kazemdehbashi*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出TATS模型，将时间序列预测重构为趋势预测和数值预测两部分，通过二元分类器预测趋势方向，再用LSTM/Bi-LSTM预测数值，最后基于趋势调整预测值，在金融时间序列上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法（包括LSTM等神经网络）在波动性强的金融时间序列上表现有限，且常用评估指标（MSE、MAE）不能全面反映模型对趋势的捕捉能力。因此需要一种能更好处理趋势预测的框架。

Method: 将时间序列预测分解为两个子任务：1）用二元分类器预测下一时间步的趋势方向（上涨/下跌）；2）用LSTM或Bi-LSTM预测数值。然后提出TATS模型，基于分类器预测的趋势来调整LSTM的预测值，形成最终预测。

Result: 在黄金价格日数据上，TATS模型相比标准LSTM和Bi-LSTM显著降低了预测误差。同时发现仅用MSE/MAE评估不足，需要加入趋势检测准确率指标来全面评估模型性能。

Conclusion: 将时间序列预测分解为趋势预测和数值预测两部分，并通过趋势调整的TATS模型能有效提升预测精度，特别是在波动性强的金融时间序列上。同时需要更全面的评估指标来反映模型对趋势的捕捉能力。

Abstract: Time series data play a critical role in various fields, including finance, healthcare, marketing, and engineering. A wide range of techniques (from classical statistical models to neural network-based approaches such as Long Short-Term Memory (LSTM)) have been employed to address time series forecasting challenges. In this paper, we reframe time series forecasting as a two-part task: (1) predicting the trend (directional movement) of the time series at the next time step, and (2) forecasting the quantitative value at the next time step. The trend can be predicted using a binary classifier, while quantitative values can be forecasted using models such as LSTM and Bidirectional Long Short-Term Memory (Bi-LSTM). Building on this reframing, we propose the Trend-Adjusted Time Series (TATS) model, which adjusts the forecasted values based on the predicted trend provided by the binary classifier. We validate the proposed approach through both theoretical analysis and empirical evaluation. The TATS model is applied to a volatile financial time series (the daily gold price) with the objective of forecasting the next days price. Experimental results demonstrate that TATS consistently outperforms standard LSTM and Bi-LSTM models by achieving significantly lower forecasting error. In addition, our results indicate that commonly used metrics such as MSE and MAE are insufficient for fully assessing time series model performance. Therefore, we also incorporate trend detection accuracy, which measures how effectively a model captures trends in a time series.

</details>


### [710] [A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection](https://arxiv.org/abs/2601.12745)
*Miao Ye,Jing Cui,Yuan huang,Qian He,Yong Wang,Jiwen Zhang*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出一种用于无线传感器网络多时序模态数据异常检测的图神经网络方法，结合时空相关特征提取和多任务自监督训练策略


<details>
  <summary>Details</summary>
Motivation: 针对无线传感器网络中多时序模态数据异常检测的挑战：时空相关特征提取不足、异常样本标注成本高、样本不平衡问题

Method: 1) 改进Mamba模型的多尺度策略和模态间融合方法，结合变分图卷积模块构建异常检测骨干网络；2) 设计"预训练-图提示-微调"的多任务自监督训练策略，包含无负对比学习、预测和重构三个子任务

Result: 在公开数据集和实际采集数据集上的F1指标分别达到91.30%和92.31%，优于现有方法

Conclusion: 该方法能有效提取时空相关特征，降低训练成本，提升检测泛化性能，为WSN可靠运行提供保障

Abstract: Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of "pre-training - graph prompting - fine-tuning" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning "pre-training" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.

</details>


### [711] [Eddy-Resolving Global Ocean Forecasting with Multi-Scale Graph Neural Networks](https://arxiv.org/abs/2601.12775)
*Yuta Hirabayashi,Daisuke Matusoka,Konobu Kimura*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出基于多尺度图神经网络的10天全球海洋预报模型，通过双分辨率球面网格和多尺度特征捕捉，提升短期预报精度和海洋多尺度变率表征能力。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的海洋模型研究进展迅速，但在全球涡旋解析海洋预报中的应用仍有限。准确表征广泛空间尺度上的海洋动力学是主要挑战，需要改进多尺度海洋变率的表示能力。

Method: 采用编码器-处理器-解码器架构，使用两个不同分辨率的球面网格捕捉多尺度海洋动力学。将表面大气变量与海洋状态变量共同作为节点输入，以通过大气强迫表示提高短期预报精度。

Result: 通过表面动能谱和案例研究评估显示，模型能准确表征广泛的空间尺度范围。均方根误差比较表明在短期预测中具有改进的技能，特别是在多尺度海洋动力学表示方面表现优异。

Conclusion: 提出的模型能提供更准确的短期预报和改进的多尺度海洋动力学表示，突显了其在推进数据驱动、涡旋解析全球海洋预报方面的潜力。

Abstract: Research on data-driven ocean models has progressed rapidly in recent years; however, the application of these models to global eddy-resolving ocean forecasting remains limited. The accurate representation of ocean dynamics across a wide range of spatial scales remains a major challenge in such applications. This study proposes a multi-scale graph neural network-based ocean model for 10-day global forecasting that improves short-term prediction skill and enhances the representation of multi-scale ocean variability. The model employs an encoder-processor-decoder architecture and uses two spherical meshes with different resolutions to better capture the multi-scale nature of ocean dynamics. In addition, the model incorporates surface atmospheric variables along with ocean state variables as node inputs to improve short-term prediction accuracy by representing atmospheric forcing. Evaluation using surface kinetic energy spectra and case studies shows that the model accurately represents a broad range of spatial scales, while root mean square error comparisons demonstrate improved skill in short-term predictions. These results indicate that the proposed model delivers more accurate short-term forecasts and improved representation of multi-scale ocean dynamics, thereby highlighting its potential to advance data-driven, eddy-resolving global ocean forecasting.

</details>


### [712] [Knowledge-Integrated Representation Learning for Crypto Anomaly Detection under Extreme Label Scarcity; Relational Domain-Logic Integration with Retrieval-Grounded Context and Path-Level Explanations](https://arxiv.org/abs/2601.12839)
*Gyuyeon Na,Minjung Park,Soyoun Kim,Jungbin Shin,Sangmi Chai*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出RDLI框架，通过嵌入专家启发式逻辑和检索上下文模块，在标签极度稀缺（0.01%）的加密货币网络中检测异常交易轨迹，相比现有GNN方法提升28.9%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 去中心化加密货币网络中的异常轨迹检测面临两个核心挑战：1）极端标签稀缺（仅0.01%），2）恶意行为者的自适应规避策略。传统GNN虽然能捕捉局部结构模式，但难以内化多跳、逻辑驱动的资金分散和分层等洗钱特征，限制了在FATF旅行规则等监管要求下的法证可追溯性。

Method: 提出关系域逻辑集成（RDLI）框架：1）将专家推导的启发式规则嵌入为可微分的、逻辑感知的潜在信号；2）引入检索接地上下文（RGC）模块，根据监管和宏观经济上下文调节异常评分，减少良性制度变化导致的误报。该方法结合了逻辑推理和上下文感知，超越了传统的消息传递机制。

Result: 在极端标签稀缺（0.01%）条件下，RDLI相比最先进的GNN基线方法提升28.9%的F1分数。微观专家用户研究进一步证实，RDLI的路径级解释在可信度、感知有用性和清晰度方面显著优于现有方法。

Conclusion: 将领域逻辑与上下文接地相结合，不仅能提高异常检测的准确性，还能增强模型的可解释性。这对于在监管严格且标签稀缺的加密货币环境中建立可信赖的AI系统至关重要。

Abstract: Detecting anomalous trajectories in decentralized crypto networks is fundamentally challenged by extreme label scarcity and the adaptive evasion strategies of illicit actors. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they struggle to internalize multi hop, logic driven motifs such as fund dispersal and layering that characterize sophisticated money laundering, limiting their forensic accountability under regulations like the FATF Travel Rule. To address this limitation, we propose Relational Domain Logic Integration (RDLI), a framework that embeds expert derived heuristics as differentiable, logic aware latent signals within representation learning. Unlike static rule based approaches, RDLI enables the detection of complex transactional flows that evade standard message passing. To further account for market volatility, we incorporate a Retrieval Grounded Context (RGC) module that conditions anomaly scoring on regulatory and macroeconomic context, mitigating false positives caused by benign regime shifts. Under extreme label scarcity (0.01%), RDLI outperforms state of the art GNN baselines by 28.9% in F1 score. A micro expert user study further confirms that RDLI path level explanations significantly improve trustworthiness, perceived usefulness, and clarity compared to existing methods, highlighting the importance of integrating domain logic with contextual grounding for both accuracy and explainability.

</details>


### [713] [AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs](https://arxiv.org/abs/2601.12893)
*Ting Dang,Soumyajit Chatterjee,Hong Jia,Yu Wu,Flora Salim,Fahim Kawsar*

Main category: cs.LG

Relevance: 35.0

TL;DR: AdaNODEs提出了一种针对时间序列预测的源无关测试时间自适应方法，利用神经常微分方程处理分布偏移，仅需更新有限参数即可显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时间自适应方法主要针对独立数据，很少考虑时间序列数据和预测任务。时间序列数据具有独特的分布偏移特性，需要专门的自适应方法。

Method: 基于神经常微分方程构建自适应框架，提出新的损失函数专门处理预测任务的自适应，仅更新有限模型参数以减少内存使用。

Result: 在一维和高维数据实验中，相比现有最佳基线分别获得5.88%和28.4%的相对改进，在更严重的分布偏移下表现出更强的鲁棒性。

Conclusion: AdaNODEs为时间序列预测提供了一种有效的源无关测试时间自适应方法，能够有效处理时间序列特有的分布偏移问题。

Abstract: Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\% and 28.4\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.

</details>


### [714] [HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads](https://arxiv.org/abs/2601.13013)
*Xiaohui Zhao,Xinjian Zhao,Jiahui Zhang,Guoyu Liu,Houzhi Wang,Shu Wu*

Main category: cs.LG

Relevance: 35.0

TL;DR: HT-GNN：一种超时态图神经网络，用于新闻流广告中的终身价值预测，通过超图监督模块、Transformer时间编码器和任务自适应专家混合模型，解决人口统计异质性和动态营销策略带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 新闻流广告中的终身价值预测面临两大挑战：1）基于人口统计的定向导致不同用户群体间的LTV分布差异巨大；2）动态营销策略产生不规则的行为序列，用户参与模式快速变化。需要同时建模人口统计异质性和时间动态性。

Method: 提出超时态图神经网络（HT-GNN），包含三个核心组件：1）超图监督模块捕捉段间关系；2）基于Transformer的时间编码器，具有自适应加权机制；3）任务自适应专家混合模型，配备动态预测塔，用于多时间范围的LTV预测。

Result: 在百度广告平台的1500万用户数据集上实验表明，HT-GNN在所有指标和预测时间范围上都持续优于最先进的方法。

Conclusion: HT-GNN有效解决了LTV预测中的人口统计异质性和时间动态性问题，为广告平台的竞价和预算分配优化提供了更准确的长期收入增长预测。

Abstract: Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.

</details>


### [715] [Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis](https://arxiv.org/abs/2601.13021)
*Nataša Petrović,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Jose Maria Buades Rubio*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出了一种基于集成学习的镰状细胞病诊断支持系统，通过外周血涂片图像分析红细胞形态，采用随机森林和额外树分类器集成，在泛化性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够为镰状细胞病提供诊断支持的自动化系统，通过外周血涂片图像分析红细胞形态，旨在提高诊断准确性和泛化能力，同时增强模型的可解释性。

Method: 1. 对显微图像进行预处理和分割以提取高质量特征；2. 从血细胞中提取特征；3. 采用集成机器学习方法（随机森林和额外树分类器）进行分类；4. 设计方法识别对分类最关键的特征以降低复杂度；5. 使用新数据集验证泛化性能。

Result: 集成分类器（随机森林+额外树）取得了F1分数90.71%和SDS分数93.33%，相比之前的梯度提升分类器（F1 87.32%，SDS 89.51%）有显著提升，在新数据集上表现出更好的泛化性能。

Conclusion: 提出的集成学习方法在镰状细胞病诊断支持中表现出优越性能，特别是在泛化能力和可解释性方面，为医学图像分析提供了有效的解决方案。

Abstract: This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\% and SDS-score 89.51\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.

</details>


### [716] [Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification](https://arxiv.org/abs/2601.13272)
*Aaron Pim,Tristan Pryer*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文提出了一种用于蒙特卡洛dropout不确定性量化的多级蒙特卡洛框架，通过重用dropout掩码构建耦合的粗-细估计器，在固定计算预算下减少采样方差。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛dropout是深度学习不确定性量化的常用方法，但需要大量前向传播来估计预测均值和方差，计算成本高。本文旨在通过多级蒙特卡洛方法提高估计效率，减少方差。

Method: 将dropout掩码视为认知随机性来源，通过不同数量的随机前向传播定义保真度层次结构。重用dropout掩码构建耦合的粗-细估计器，形成用于预测均值和方差的伸缩式MLMC估计器。推导了显式的偏差、方差和有效成本表达式，以及跨级别的样本分配规则。

Result: 在正向和逆向PINNs-Uzawa基准测试上的数值实验证实了预测的方差率，并展示了在匹配成本下相比单级MC-dropout的效率提升。

Conclusion: 提出的MLMC框架为蒙特卡洛dropout不确定性量化提供了有效的方差减少方法，能够在固定计算预算下获得更准确的预测不确定性估计。

Abstract: We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.

</details>


### [717] [Verifying Local Robustness of Pruned Safety-Critical Networks](https://arxiv.org/abs/2601.13303)
*Minh Le,Phuong Cao*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文研究剪枝对深度神经网络形式化验证的影响，发现轻量剪枝（MNIST上40%）和重度剪枝（JPL数据集上70%-90%）能提升可验证性，使模型在形式化鲁棒性证明上优于未剪枝基线。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络的形式化验证对安全关键应用至关重要，但大规模模型的验证计算成本高昂，阻碍了实际应用。需要研究模型压缩技术（如剪枝）如何影响形式化验证的可验证性。

Method: 使用最先进的α,β-CROWN验证器，在不同剪枝比例下评估ResNet4模型，分别在MNIST和NASA JPL火星霜冻识别数据集上进行实验，分析剪枝对形式化局部鲁棒性证书的影响。

Result: 发现剪枝与可验证性之间存在非线性关系：MNIST上40%的轻量剪枝和JPL数据集上70%-90%的重度剪枝能提升可验证性，使模型在证明的L∞鲁棒性属性上优于未剪枝基线。减少连接性简化了形式化求解器的搜索空间。

Conclusion: 模型压缩对形式化验证的影响复杂，最优剪枝比例因数据集而异。这为在高风险环境中部署高效且经过形式化验证的DNN提供了关键见解，有助于在可靠性和效率之间找到平衡。

Abstract: Formal verification of Deep Neural Networks (DNNs) is essential for safety-critical applications, ranging from surgical robotics to NASA JPL autonomous systems. However, the computational cost of verifying large-scale models remains a significant barrier to adoption. This paper investigates the impact of pruning on formal local robustness certificates with different ratios. Using the state-of-the-art $α,β$-CROWN verifier, we evaluate ResNet4 models across varying pruning ratios on MNIST and, more importantly, on the NASA JPL Mars Frost Identification datasets. Our findings demonstrate a non-linear relationship: light pruning (40%) in MNIST and heavy pruning (70%-90%) in JPL improve verifiability, allowing models to outperform unpruned baselines in proven $L_\infty$ robustness properties. This suggests that reduced connectivity simplifies the search space for formal solvers and that the optimal pruning ratio varies significantly between datasets. This research highlights the complex nature of model compression, offering critical insights into selecting the optimal pruning ratio for deploying efficient, yet formally verified, DNNs in high-stakes environments where reliability is non-negotiable.

</details>


### [718] [Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans](https://arxiv.org/abs/2601.13350)
*Abdel Djalil Sad Saoud,Fred Maurice Ngolè Mboula,Hanane Slimani*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出了一种基于谱嵌入的领域适应方法，将平滑传输计划解释为二分图邻接矩阵，从而学习领域不变的样本表示。


<details>
  <summary>Details</summary>
Motivation: 训练数据和推理数据之间的分布偏移是机器学习中的核心挑战，会导致性能下降。现有的最优传输方法依赖于近似Monge映射，对正则化策略和超参数敏感，可能导致有偏的领域对齐。

Method: 将平滑传输计划解释为连接源域和目标域的二分图邻接矩阵，通过谱嵌入推导领域不变的样本表示。

Result: 在音乐流派识别、音乐-语音区分以及电缆缺陷检测等声学适应基准测试中取得了整体强劲的性能。

Conclusion: 提出的谱嵌入方法为领域适应提供了一种有效的解决方案，能够处理分布偏移问题。

Abstract: Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.

</details>


### [719] [A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization](https://arxiv.org/abs/2601.13435)
*Shuozhe Li,Du Cheng,Leqi Liu*

Main category: cs.LG

Relevance: 35.0

TL;DR: WaveLSFormer：一种可学习的小波变换长短期Transformer模型，用于金融时间序列的日内交易策略学习，通过端到端训练的多尺度分解和收益导向决策学习，显著提升盈利能力和风险调整收益。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列的日内交易策略学习面临三大挑战：1）噪声严重；2）非平稳性；3）相关资产间的强横截面依赖性。传统方法难以有效处理这些复杂特征。

Method: 提出WaveLSFormer模型：1）可学习小波前端：通过端到端训练的滤波器组生成低/高频分量，使用频谱正则化器确保稳定且分离良好的频带；2）低频引导高频注入模块：融合多尺度信息，用高频线索细化低频表示并控制训练稳定性；3）输出满足固定风险预算的多空头寸组合，直接使用交易目标和风险感知正则化进行优化。

Result: 在5年小时数据、6个行业组、10个随机种子的广泛实验中，WaveLSFormer始终优于MLP、LSTM和Transformer基线模型。在所有行业平均中，累计策略收益为0.607±0.045，夏普比率为2.157±0.166，显著提升了盈利能力和风险调整收益。

Conclusion: WaveLSFormer通过联合多尺度分解和收益导向决策学习，有效解决了金融时间序列交易的挑战，为日内交易策略学习提供了强大的端到端框架。

Abstract: Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \pm 0.045$ and a Sharpe ratio of $2.157 \pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.

</details>


### [720] [Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay](https://arxiv.org/abs/2601.13456)
*Sahasra Kokkula,Daniel David,Aaditya Baruah*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文针对联邦学习中时间概念漂移问题，提出客户端经验回放方法，通过在本地训练时混合少量历史样本，有效防止灾难性遗忘，无需修改服务器聚合机制。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在时间概念漂移场景下面临挑战，客户端数据分布随时间变化会导致标准FedAvg算法出现灾难性遗忘问题。在Fashion-MNIST数据集上的季节性漂移实验中，准确率从74%骤降至28%，表明现有方法无法适应动态变化的数据环境。

Method: 提出客户端经验回放方法：每个客户端维护一个小的历史样本缓冲区，在本地训练时将当前数据与缓冲区中的历史样本混合。该方法无需修改服务器聚合机制，保持了联邦学习的标准架构。缓冲区大小可配置，每类保留50个样本。

Result: 实验表明，使用每类50个样本的缓冲区可将性能恢复至78-82%，有效防止了灾难性遗忘。消融研究揭示了内存与准确率之间的权衡关系：随着缓冲区大小增加，性能提升但内存需求也增加。

Conclusion: 客户端经验回放是一种简单有效的解决方案，能够显著缓解联邦学习中的时间概念漂移问题，防止灾难性遗忘，同时保持联邦学习的标准架构不变。该方法在内存效率和性能之间提供了可调节的平衡。

Abstract: Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.

</details>


### [721] [Quantum Qualifiers for Neural Network Model Selection in Hadronic Physics](https://arxiv.org/abs/2601.13463)
*Brandon B. Le,D. Keller*

Main category: cs.LG

Relevance: 35.0

TL;DR: 论文提出了一个诊断框架，使用量子限定器来指导在强子物理问题中选择经典或量子深度神经网络，基于数据的内在特性。


<details>
  <summary>Details</summary>
Motivation: 随着量子机器学习架构的成熟，核心挑战不再是构建这些架构，而是识别它们在哪些领域能提供相对于经典方法的实际优势。特别是在数据驱动的强子物理问题中，需要系统的方法来决定何时使用量子模型。

Method: 开发了一个诊断框架，包括一个定量的量子限定器，基于数据的复杂性、噪声和维度等内在特性来指导模型选择。通过受控的分类和回归研究，分析相对模型性能如何遵循这些特性的系统趋势。

Result: 研究表明，模型性能遵循复杂性、噪声和维度的系统趋势，这些趋势可以提炼为预测性标准。在深度虚拟康普顿散射中的康普顿形状因子提取应用中，量子限定器识别出了有利于量子模型的运动学区域。

Conclusion: 这些结果为在精密强子物理中部署量子机器学习工具建立了一个原则性框架，提供了系统的方法来识别量子模型具有实际优势的领域。

Abstract: As quantum machine-learning architectures mature, a central challenge is no longer their construction, but identifying the regimes in which they offer practical advantages over classical approaches. In this work, we introduce a framework for addressing this question in data-driven hadronic physics problems by developing diagnostic tools - centered on a quantitative quantum qualifier - that guide model selection between classical and quantum deep neural networks based on intrinsic properties of the data. Using controlled classification and regression studies, we show how relative model performance follows systematic trends in complexity, noise, and dimensionality, and how these trends can be distilled into a predictive criterion. We then demonstrate the utility of this approach through an application to Compton form factor extraction from deeply virtual Compton scattering, where the quantum qualifier identifies kinematic regimes favorable to quantum models. Together, these results establish a principled framework for deploying quantum machine-learning tools in precision hadronic physics.

</details>


### [722] [StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing](https://arxiv.org/abs/2601.13522)
*Shuang Li*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出了一种基于Tucker分解的随机交替最小化算法，用于低秩张量感知问题，避免了昂贵的张量投影，实现了高效的小批量更新


<details>
  <summary>Details</summary>
Motivation: 低秩张量感知是信号处理和机器学习中的基础问题，低Tucker秩张量特别适合捕捉高维数据的多模态子空间结构。现有方法要么在完整张量变量上操作，需要昂贵的张量投影；要么采用因子化公式但仍依赖全梯度计算；而大多数随机因子化方法仅限于张量分解设置

Method: 提出了一种随机交替最小化算法，直接在Tucker分解下的核心张量和因子矩阵上操作。该方法避免了重复的张量投影，并能在低维张量因子上实现高效的小批量更新

Result: 在合成张量感知上的数值实验表明，与代表性的随机张量恢复基线相比，所提算法在运行时间上表现出更优的收敛行为

Conclusion: 该方法为低秩张量感知问题提供了一种高效的随机优化解决方案，特别适合处理大规模张量数据

Abstract: Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.

</details>


### [723] [Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework](https://arxiv.org/abs/2601.13564)
*Yanheng Li,Zhichen Pu,Lijiang Yang,Zehao Zhou,Yi Qin Gao*

Main category: cs.LG

Relevance: 35.0

TL;DR: LUMOS是一个数据与物理双驱动的荧光分子逆设计框架，通过结合生成器和预测器在共享潜在表示中，实现从规格到分子的直接设计，并在多目标优化中优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 设计具有特定光学和物理化学性质的荧光小分子需要探索巨大的化学空间，同时满足多个目标和约束。传统的生成-评分-筛选方法在现实设计规范下效率低下，机器学习预测泛化能力不可靠，量子化学计算成本过高。

Method: LUMOS框架将生成器和预测器耦合在共享潜在表示中，结合神经网络和快速TD-DFT计算工作流构建互补预测器，采用属性引导的扩散模型与多目标进化算法集成，实现多目标和约束下的分子设计优化。

Result: 在综合基准测试中，LUMOS在荧光性质预测的准确性、泛化能力和物理合理性方面一致优于基线模型，在多目标分子优化中表现出优越性能。TD-DFT和MD模拟验证表明LUMOS能生成满足各种目标规格的有效荧光团。

Conclusion: LUMOS建立了一个通用的荧光团逆设计数据-物理双驱动框架，解决了传统方法在效率、泛化和成本方面的限制。

Abstract: Designing fluorescent small molecules with tailored optical and physicochemical properties requires navigating vast, underexplored chemical space while satisfying multiple objectives and constraints. Conventional generate-score-screen approaches become impractical under such realistic design specifications, owing to their low search efficiency, unreliable generalizability of machine-learning prediction, and the prohibitive cost of quantum chemical calculation. Here we present LUMOS, a data-and-physics driven framework for inverse design of fluorescent molecules. LUMOS couples generator and predictor within a shared latent representation, enabling direct specification-to-molecule design and efficient exploration. Moreover, LUMOS combines neural networks with a fast time-dependent density functional theory (TD-DFT) calculation workflow to build a suite of complementary predictors spanning different trade-offs in speed, accuracy, and generalizability, enabling reliable property prediction across diverse scenarios. Finally, LUMOS employs a property-guided diffusion model integrated with multi-objective evolutionary algorithms, enabling de novo design and molecular optimization under multiple objectives and constraints. Across comprehensive benchmarks, LUMOS consistently outperforms baseline models in terms of accuracy, generalizability and physical plausibility for fluorescence property prediction, and demonstrates superior performance in multi-objective scaffold- and fragment-level molecular optimization. Further validation using TD-DFT and molecular dynamics (MD) simulations demonstrates that LUMOS can generate valid fluorophores that meet various target specifications. Overall, these results establish LUMOS as a data-physics dual-driven framework for general fluorophore inverse design.

</details>


### [724] [DRGW: Learning Disentangled Representations for Robust Graph Watermarking](https://arxiv.org/abs/2601.13569)
*Jiasen Li,Yanwei Liu,Zhuoyi Shang,Xiaoyan Gu,Weiping Wang*

Main category: cs.LG

Relevance: 35.0

TL;DR: DRGW是首个基于解耦表示学习的图水印框架，通过对抗训练编码器学习不变结构表示，使用图感知可逆神经网络实现无损水印嵌入，并通过结构感知编辑器将潜在修改转化为离散图编辑，在保持水印透明性的同时提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有图水印方法主要在图结构或纠缠的图表示上操作，由于图表示中的信息耦合以及连续数值表示到图结构转换中的不可控离散化，导致水印的透明性和鲁棒性受损。需要一种能够解决这些问题的图水印框架。

Method: 1) 设计对抗训练编码器学习不变结构表示并推导统计独立的水印载体；2) 设计图感知可逆神经网络提供无损水印嵌入和提取通道；3) 开发结构感知编辑器将潜在修改转化为离散图编辑。

Result: 在多个基准数据集上的实验表明DRGW具有优越的有效性，在保持水印透明性的同时显著提升了鲁棒性。

Conclusion: DRGW通过解耦表示学习解决了现有图水印方法在透明性和鲁棒性方面的局限性，为图数据知识产权保护提供了更有效的解决方案。

Abstract: Graph-structured data is foundational to numerous web applications, and watermarking is crucial for protecting their intellectual property and ensuring data provenance. Existing watermarking methods primarily operate on graph structures or entangled graph representations, which compromise the transparency and robustness of watermarks due to the information coupling in representing graphs and uncontrollable discretization in transforming continuous numerical representations into graph structures. This motivates us to propose DRGW, the first graph watermarking framework that addresses these issues through disentangled representation learning. Specifically, we design an adversarially trained encoder that learns an invariant structural representation against diverse perturbations and derives a statistically independent watermark carrier, ensuring both robustness and transparency of watermarks. Meanwhile, we devise a graph-aware invertible neural network to provide a lossless channel for watermark embedding and extraction, guaranteeing high detectability and transparency of watermarks. Additionally, we develop a structure-aware editor that resolves the issue of latent modifications into discrete graph edits, ensuring robustness against structural perturbations. Experiments on diverse benchmark datasets demonstrate the superior effectiveness of DRGW.

</details>


### [725] [Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data](https://arxiv.org/abs/2601.13608)
*Zhipeng Chang,Ting He,Wenrui Hao*

Main category: cs.LG

Relevance: 35.0

TL;DR: FIPA：一种基于Fisher信息的参数级聚合方法，用于解决联邦学习中非IID数据导致的客户端漂移问题，通过参数特定的权重替代客户端级标量权重来提升全局模型性能。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，标准的一阶方法（如FedAvg）对每个客户端的所有参数使用相同的标量权重。在非IID数据分布下，这种统一加权的更新会在客户端间产生强烈错位，导致客户端漂移并降低全局模型性能。

Method: 提出Fisher信息参数级聚合（FIPA），一种二阶聚合方法，用参数特定的Fisher信息矩阵权重替代客户端级标量权重，实现真正的参数级缩放。通过低秩近似保持通信和计算效率。

Result: 在非线性函数回归、PDE学习和图像分类任务中，FIPA始终优于基于平均的聚合方法，并能有效结合最先进的客户端优化算法进一步提升图像分类准确率。

Conclusion: FIPA在异构数据分布下的联邦学习中具有显著优势，通过参数级聚合有效缓解客户端漂移问题。

Abstract: Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.

</details>


### [726] [Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery](https://arxiv.org/abs/2601.13676)
*Fabian Greifeneder,Wolfgang Fenz,Benedikt Alkin,Johannes Brandstetter,Michael Giretzlehner,Philipp Moser*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出基于深度学习的脑组织变形模拟替代模型，使用通用物理Transformer处理大规模网格数据，通过随机教师强制策略改善自回归推理误差累积，实现实时神经外科手术模拟。


<details>
  <summary>Details</summary>
Motivation: 神经外科手术模拟器需要实时、准确地模拟脑组织非线性变形，但传统数值求解器难以满足实时性能要求。需要开发高效的深度学习替代模型来模拟手术器械与脑组织连续交互引起的瞬态变形。

Method: 基于通用物理Transformer构建深度学习替代模型，直接处理大规模网格数据。使用非线性有限元模拟生成的大规模数据集训练，涵盖多种时间性器械-组织交互场景。提出随机教师强制策略：在训练中使用短随机展开，逐步减少真实输入比例，增加模型生成预测比例，以减少自回归推理中的误差累积。

Result: 模型在多种瞬态脑变形场景中实现准确高效预测，可扩展到15万个节点的网格。随机教师强制技术显著改善长期展开稳定性，将最大预测误差从6.7mm降至3.5mm。集成到交互式神经外科模拟环境中，在消费级硬件上实现每模拟步长低于10ms的运行时。

Conclusion: 提出的深度学习框架能够实现快速、平滑且准确的动态脑组织变形生物力学模拟，为真实手术训练环境奠定基础。该方法在实时性能要求下保持了模拟准确性，是传统数值求解器的有效替代方案。

Abstract: Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.

</details>


### [727] [Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation](https://arxiv.org/abs/2601.13698)
*Arjun Nichani,Hsiang Hsu,Chun-Fu,Chen,Haewon Jeong*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文利用信息论中的Chernoff信息度量，研究公平性、隐私性和准确性三者之间的数据依赖性关系，提出了Noisy Chernoff Difference作为分析工具，并展示了其在合成数据和真实数据集上的应用。


<details>
  <summary>Details</summary>
Motivation: 公平性和隐私性是可信机器学习的两大支柱，但现有研究大多单独探讨这两个主题，对公平性、隐私性和准确性三者之间关系的研究相对较少。本文旨在通过信息论方法，揭示这三者关系的本质及其对数据分布的依赖性。

Method: 1. 使用信息论度量Chernoff Information来分析公平性、隐私性和准确性之间的关系
2. 提出Noisy Chernoff Difference作为同时分析三者关系的工具
3. 在合成数据上展示该值在不同数据分布下的三种不同行为模式
4. 提出从未知分布数据中估计Chernoff Information的方法
5. 在真实数据集上应用该框架分析三者动态关系

Result: 1. 揭示了公平性、隐私性和准确性之间的关系具有数据依赖性
2. 展示了Noisy Chernoff Difference在不同数据分布下的三种不同行为模式
3. 发现Noisy Chernoff Difference可以作为公平性-准确性曲线陡峭度的代理指标
4. 成功在真实数据集上应用了该分析框架

Conclusion: 该研究为理解公平性、隐私性和准确性之间的关系提供了统一的信息论框架，强调了这种关系对数据分布的高度依赖性，为可信机器学习中的权衡分析提供了理论工具。

Abstract: Fairness and privacy are two vital pillars of trustworthy machine learning. Despite extensive research on these individual topics, the relationship between fairness and privacy has received significantly less attention. In this paper, we utilize the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among the triad of fairness, privacy, and accuracy. We first define Noisy Chernoff Difference, a tool that allows us to analyze the relationship among the triad simultaneously. We then show that for synthetic data, this value behaves in 3 distinct ways (depending on the distribution of the data). We highlight the data distributions involved in these cases and explore their fairness and privacy implications. Additionally, we show that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, we propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature.

</details>


### [728] [EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory](https://arxiv.org/abs/2601.13748)
*Tien-Dat Pham,Xuan-The Tran*

Main category: cs.LG

Relevance: 35.0

TL;DR: EEG-Titans：一种用于癫痫发作预测的双分支架构，结合滑动窗口注意力捕获短期异常和循环记忆通路总结长期趋势，在CHB-MIT数据集上达到99.46%的平均段级灵敏度。


<details>
  <summary>Details</summary>
Motivation: 癫痫发作预测面临挑战，因为发作前动态可能跨越长时间范围，而临床相关特征可能微妙且短暂。现有深度学习模型在超长序列处理时面临局部时空模式捕获与长距离上下文保持之间的权衡。

Method: 提出EEG-Titans双分支架构：1) 滑动窗口注意力分支捕获短期异常；2) 循环记忆通路总结缓慢的渐进趋势；3) 采用现代神经记忆机制进行长上下文建模；4) 针对高噪声受试者使用分层上下文策略扩展感受野。

Result: 在CHB-MIT头皮EEG数据集上，按时间顺序保留协议评估，EEG-Titans在18名受试者中达到99.46%的平均段级灵敏度。分层上下文策略显著减少误报（极端情况下降至0.00 FPR/h），同时保持灵敏度。

Conclusion: 内存增强的长上下文建模可以在临床约束评估下提供稳健的癫痫发作预测。该方法平衡了局部异常检测和长期趋势分析，在噪声环境下表现优异。

Abstract: Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation

</details>


### [729] [Optimal L2 Regularization in High-dimensional Continual Linear Regression](https://arxiv.org/abs/2601.13844)
*Gilad Karpel,Edward Moroshko,Ran Levinstein,Ron Meir,Daniel Soudry,Itay Evron*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文研究了过参数化连续线性回归中的泛化问题，推导了高维状态下任意线性教师的期望泛化损失闭式解，发现各向同性正则化能缓解标签噪声，并证明最优正则化强度随任务数T呈T/ln T比例缩放。


<details>
  <summary>Details</summary>
Motivation: 研究连续学习中的泛化问题，特别是在过参数化线性回归设置下，探索正则化如何影响模型在序列任务上的表现。现有工作在处理多教师设置时要么未使用正则化，要么采用内存需求大的方法，本文旨在填补这一空白。

Method: 采用理论分析方法，推导高维状态下连续线性回归的期望泛化损失闭式解。研究各向同性正则化在单教师和多独立同分布教师设置下的效果，分析最优正则化强度与任务数量的关系，并通过线性回归和神经网络实验验证理论结果。

Result: 1) 推导出高维状态下任意线性教师的期望泛化损失闭式解；2) 证明各向同性正则化能有效缓解标签噪声；3) 发现最优固定正则化强度随任务数T呈T/ln T比例缩放；4) 通过实验验证理论发现，为连续学习系统设计提供实用指导。

Conclusion: 本文为连续学习中的泛化问题提供了理论分析框架，证明了正则化在缓解标签噪声和优化连续学习性能中的重要作用，并给出了最优正则化强度的缩放规律，对设计实际连续学习系统具有指导意义。

Abstract: We study generalization in an overparameterized continual linear regression setting, where a model is trained with L2 (isotropic) regularization across a sequence of tasks. We derive a closed-form expression for the expected generalization loss in the high-dimensional regime that holds for arbitrary linear teachers. We demonstrate that isotropic regularization mitigates label noise under both single-teacher and multiple i.i.d. teacher settings, whereas prior work accommodating multiple teachers either did not employ regularization or used memory-demanding methods. Furthermore, we prove that the optimal fixed regularization strength scales nearly linearly with the number of tasks $T$, specifically as $T/\ln T$. To our knowledge, this is the first such result in theoretical continual learning. Finally, we validate our theoretical findings through experiments on linear regression and neural networks, illustrating how this scaling law affects generalization and offering a practical recipe for the design of continual learning systems.

</details>


### [730] [Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition](https://arxiv.org/abs/2601.13953)
*Gorgi Pavlov*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出了一种基于分层谱组合的神经符号逻辑合成方法，通过选择布尔傅里叶基的谱系数，结合Sinkhorn约束路由和列符号调制，实现了精确的布尔逻辑学习，支持高效硬件推理。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络学习布尔逻辑时通常收敛到"模糊"近似，量化后性能下降。需要一种能够精确学习布尔逻辑并支持高效硬件实现的架构。

Method: 分层谱组合架构：从冻结的布尔傅里叶基中选择谱系数，通过Sinkhorn约束路由（投影到Birkhoff多面体）和列符号调制（支持布尔否定）进行组合。结合精确Walsh-Hadamard系数、三元量化和MCMC精炼。

Result: 1) n=2时：梯度下降达到100%准确率，零路由漂移，三元掩码零损失量化；2) n=3时：梯度下降76%准确率，但枚举证明所有操作存在最优三元掩码（100%准确率，39%稀疏性）；3) n=4时：谱合成方法在所有操作上达到100%准确率。GPU上实现10,959 MOps/s的单周期组合逻辑推理。

Conclusion: 证明了所有测试函数都存在三元多项式阈值表示，但随着维度增长，需要超越纯梯度下降的方法。该方法展示了硬件高效神经符号逻辑合成的可行性。

Abstract: Learning precise Boolean logic via gradient descent remains challenging: neural networks typically converge to "fuzzy" approximations that degrade under quantization. We introduce Hierarchical Spectral Composition, a differentiable architecture that selects spectral coefficients from a frozen Boolean Fourier basis and composes them via Sinkhorn-constrained routing with column-sign modulation. Our approach draws on recent insights from Manifold-Constrained Hyper-Connections (mHC), which demonstrated that projecting routing matrices onto the Birkhoff polytope preserves identity mappings and stabilizes large-scale training. We adapt this framework to logic synthesis, adding column-sign modulation to enable Boolean negation -- a capability absent in standard doubly stochastic routing.
  We validate our approach across four phases of increasing complexity: (1) For n=2 (16 Boolean operations over 4-dim basis), gradient descent achieves 100% accuracy with zero routing drift and zero-loss quantization to ternary masks. (2) For n=3 (10 three-variable operations), gradient descent achieves 76% accuracy, but exhaustive enumeration over 3^8 = 6561 configurations proves that optimal ternary masks exist for all operations (100% accuracy, 39% sparsity). (3) For n=4 (10 four-variable operations over 16-dim basis), spectral synthesis -- combining exact Walsh-Hadamard coefficients, ternary quantization, and MCMC refinement with parallel tempering -- achieves 100% accuracy on all operations. This progression establishes (a) that ternary polynomial threshold representations exist for all tested functions, and (b) that finding them requires methods beyond pure gradient descent as dimensionality grows. All operations enable single-cycle combinational logic inference at 10,959 MOps/s on GPU, demonstrating viability for hardware-efficient neuro-symbolic logic synthesis.

</details>


### [731] [Universal Approximation Theorem for Input-Connected Multilayer Perceptrons](https://arxiv.org/abs/2601.14026)
*Vugar Ismailov*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文提出了输入连接多层感知机（IC-MLP），这是一种前馈神经网络架构，其中每个隐藏神经元除了接收前一层的输出外，还直接从原始输入接收仿射连接。作者首先在单变量设置中研究该架构，给出了任意有限隐藏层数的IC-MLP的显式系统描述，并证明了深度IC-MLP可以逼近闭区间上的任何连续函数当且仅当激活函数是非线性的。然后将分析扩展到向量值输入，建立了在ℝⁿ紧子集上连续函数的相应通用逼近定理。


<details>
  <summary>Details</summary>
Motivation: 动机是探索一种增强的前馈神经网络架构，其中隐藏神经元直接连接到原始输入，这可能改善信息流和学习能力。作者旨在从理论上分析这种架构的表达能力，特别是研究其通用逼近性质。

Method: 方法包括：1）提出IC-MLP架构，其中每个隐藏神经元接收来自前一层的输出和原始输入的仿射连接；2）在单变量设置中给出任意有限隐藏层数的显式系统描述；3）证明深度IC-MLP的通用逼近定理；4）将分析扩展到向量值输入，建立相应的通用逼近定理。

Result: 主要结果：1）给出了IC-MLP架构的数学描述和迭代公式；2）证明了在单变量情况下，深度IC-MLP可以逼近闭区间上的任何连续函数当且仅当激活函数是非线性的；3）将结果扩展到多维输入，建立了在ℝⁿ紧子集上连续函数的通用逼近定理。

Conclusion: 结论：IC-MLP是一种具有理论保证表达能力的神经网络架构，其通用逼近性质与传统MLP相当，但具有额外的输入连接结构。这为神经网络架构设计提供了新的理论见解。

Abstract: We introduce the Input-Connected Multilayer Perceptron (IC-MLP), a feedforward neural network architecture in which each hidden neuron receives, in addition to the outputs of the preceding layer, a direct affine connection from the raw input. We first study this architecture in the univariate setting and give an explicit and systematic description of IC-MLPs with an arbitrary finite number of hidden layers, including iterated formulas for the network functions. In this setting, we prove a universal approximation theorem showing that deep IC-MLPs can approximate any continuous function on a closed interval of the real line if and only if the activation function is nonlinear. We then extend the analysis to vector-valued inputs and establish a corresponding universal approximation theorem for continuous functions on compact subsets of $\mathbb{R}^n$.

</details>


### [732] [Optimizing Energy and Data Collection in UAV-aided IoT Networks using Attention-based Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.14092)
*Babacar Toure,Dimitrios Tsilimantos,Omid Esrafilian,Marios Kountouris*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出基于注意力的多目标强化学习架构，用于无人机数据收集与能耗权衡的路径规划，无需无线信道先验知识，能适应不同偏好和动态场景。


<details>
  <summary>Details</summary>
Motivation: 无人机在无线网络数据收集任务中日益重要，但现有AI方法面临训练数据有限、忽略多目标本质的问题，难以适应高度动态环境。

Method: 基于注意力的多目标强化学习架构，显式处理数据收集与能耗的权衡，无需无线信道先验知识，单一模型能适应不同偏好和动态参数。

Result: 大量仿真显示，该方法在性能、模型紧凑性、样本效率和泛化能力方面显著优于现有RL解决方案。

Conclusion: 提出的注意力MORL架构能有效解决无人机路径规划中的多目标权衡问题，具有优秀的泛化能力和适应性。

Abstract: Due to their adaptability and mobility, Unmanned Aerial Vehicles (UAVs) are becoming increasingly essential for wireless network services, particularly for data harvesting tasks. In this context, Artificial Intelligence (AI)-based approaches have gained significant attention for addressing UAV path planning tasks in large and complex environments, bridging the gap with real-world deployments. However, many existing algorithms suffer from limited training data, which hampers their performance in highly dynamic environments. Moreover, they often overlook the inherently multi-objective nature of the task, treating it in an overly simplistic manner. To address these limitations, we propose an attention-based Multi-Objective Reinforcement Learning (MORL) architecture that explicitly handles the trade-off between data collection and energy consumption in urban environments, even without prior knowledge of wireless channel conditions. Our method develops a single model capable of adapting to varying trade-off preferences and dynamic scenario parameters without the need for fine-tuning or retraining. Extensive simulations show that our approach achieves substantial improvements in performance, model compactness, sample efficiency, and most importantly, generalization to previously unseen scenarios, outperforming existing RL solutions.

</details>


### [733] [Riemannian Liquid Spatio-Temporal Graph Network](https://arxiv.org/abs/2601.14115)
*Liangsi Lu,Jingchao Wang,Zhaorong Dai,Hanqian Liu,Yang Shi*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出了RLSTG框架，将连续时间液体动力学与黎曼流形几何归纳偏置相结合，用于建模非欧几里得结构的时空图


<details>
  <summary>Details</summary>
Motivation: 现有的Liquid Time-Constant网络（LTCs）虽然擅长建模不规则采样动态，但局限于欧几里得空间，无法有效表示具有固有非欧几里得结构（如层次结构和循环）的真实世界图，导致几何失真和表示质量下降

Method: 提出黎曼液体时空图网络（RLSTG），在弯曲流形上直接制定常微分方程（ODE），将连续时间液体动力学与黎曼流形的几何归纳偏置统一起来，扩展了LTCs的稳定性定理到黎曼域，并通过状态轨迹分析量化其表达能力

Result: 在真实世界基准测试中，RLSTG通过结合先进的时间动力学和黎曼空间表示，在具有复杂结构的图上实现了优越性能

Conclusion: RLSTG框架成功克服了LTCs的欧几里得限制，能够更忠实地捕捉时空图的内在几何结构，为建模非欧几里得图动态提供了有效解决方案

Abstract: Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures. Project Page: https://rlstg.github.io

</details>


### [734] [Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery](https://arxiv.org/abs/2601.14196)
*Albina Galiullina,Wouter van Heeswijk,Tom van Woensel*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出差异化取货点推荐策略(DPO)，通过为每位顾客推荐单一取货点而非开放所有选择，结合强化学习动态优化，同时减少配送车辆和顾客出行的碳排放。


<details>
  <summary>Details</summary>
Motivation: 取货点作为家庭配送的可持续替代方案，虽然能通过订单整合缩短配送路线、提高首次投递成功率，但当顾客开车取货时，这些环保效益可能被抵消。需要一种能同时减少配送车辆和顾客出行碳排放的解决方案。

Method: 采用强化学习方法设计差异化取货点推荐策略(DPO)，在动态随机环境中，根据已实现的顾客位置和配送选择，为每位到达顾客推荐单一取货点，同时保留家庭配送选项。该方法考虑顾客与取货点之间的空间关系及其对未来路线整合的影响。

Result: 差异化取货点推荐策略能显著减少总碳排放量：相比纯家庭配送最多减少9%排放，相比其他策略（如无限制取货点选择或最近取货点分配）平均减少2%。在取货点多、距离短的密集城市环境中效果尤为明显。

Conclusion: 差异化取货点推荐策略能有效减少总碳排放，特别是在密集城市环境中。当顾客不太愿意选择取货点配送时，显式考虑顾客到达和选择的动态特性尤为重要。

Abstract: Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.

</details>


### [735] [Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression](https://arxiv.org/abs/2601.14238)
*Shaurya Mathur,Shreyas Bellary Manjunath,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

Relevance: 35.0

TL;DR: FireCastRL是一个结合野火预测与智能扑救策略的主动AI框架，使用深度时空模型预测野火发生，并通过强化学习智能体在物理模拟中执行实时扑救战术。


<details>
  <summary>Details</summary>
Motivation: 传统野火管理主要是被动反应，只在火灾发生后进行应对。随着野火频率和强度增加，需要更主动的预测和智能响应系统来减少生态破坏和经济损失。

Method: 1) 使用深度时空模型预测野火发生概率；2) 对高风险预测部署预训练的强化学习智能体，在物理信息3D模拟中执行直升机扑救战术；3) 生成威胁评估报告帮助应急响应资源分配。

Result: 提出了完整的FireCastRL框架，并公开了一个包含950万个样本的大规模时空数据集用于野火预测。展示了深度学习与强化学习结合支持野火预测和战术响应的可行性。

Conclusion: 深度学习与强化学习的结合可以为野火管理提供从预测到战术响应的完整解决方案，支持更主动的灾害管理策略。

Abstract: Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.

</details>


### [736] [AllShowers: One model for all calorimeter showers](https://arxiv.org/abs/2601.11716)
*Thorsten Buss,Henry Day-Hall,Frank Gaede,Gregor Kasieczka,Katja Krüger*

Main category: physics.ins-det

Relevance: 35.0

TL;DR: AllShowers是一个统一的生成模型，使用单个连续归一化流和Transformer架构，模拟多种粒子类型（电子、光子、带电/中性强子）在量能器中的簇射，超越了传统需要为每种粒子训练单独模型的方法。


<details>
  <summary>Details</summary>
Motivation: 传统量能器簇射模拟需要为每种粒子类型训练单独的机器学习代理模型，这限制了可扩展性和重用性。现代对撞机实验需要准确高效的探测器模拟，但计算成本很高。

Method: 采用连续归一化流模型结合Transformer架构，处理可变长度的点云表示。关键创新包括：层嵌入学习所有相关量能器层属性；自定义注意力掩码方案降低计算需求并引入归纳偏置；簇射和层间最优传输映射改善训练收敛和样本质量。

Result: 模型能够在广泛的入射能量和角度范围内，为电子、光子、带电和中性强子生成真实的簇射，无需重新训练。对于强子簇射，超越了先前单粒子类型模型的保真度。

Conclusion: AllShowers标志着向对撞机实验中量能器簇射模拟通用模型迈出了重要一步，展示了统一多粒子类型模拟的可行性。

Abstract: Accurate and efficient detector simulation is essential for modern collider experiments. To reduce the high computational cost, various fast machine learning surrogate models have been proposed. Traditional surrogate models for calorimeter shower modeling train separate networks for each particle species, limiting scalability and reuse. We introduce AllShowers, a unified generative model that simulates calorimeter showers across multiple particle types using a single generative model. AllShowers is a continuous normalizing flow model with a Transformer architecture, enabling it to generate complex spatial and energy correlations in variable-length point cloud representations of showers. Trained on a diverse dataset of simulated showers in the highly granular ILD detector, the model demonstrates the ability to generate realistic showers for electrons, photons, and charged and neutral hadrons across a wide range of incident energies and angles without retraining. In addition to unifying shower generation for multiple particle types, AllShowers surpasses the fidelity of previous single-particle-type models for hadronic showers. Key innovations include the use of a layer embedding, allowing the model to learn all relevant calorimeter layer properties; a custom attention masking scheme to reduce computational demands and introduce a helpful inductive bias; and a shower- and layer-wise optimal transport mapping to improve training convergence and sample quality. AllShowers marks a significant step towards a universal model for calorimeter shower simulations in collider experiments.

</details>


### [737] [Quantum Kernel Machine Learning for Autonomous Materials Science](https://arxiv.org/abs/2601.11775)
*Felix Adams,Daiwei Zhu,David W. Steuerman,A. Gilad Kusne,Ichiro Takeuchi*

Main category: cond-mat.mtrl-sci

Relevance: 35.0

TL;DR: 该研究比较了量子核与经典核在自主材料科学中相空间导航的性能，发现量子核模型在某些情况下优于经典核模型，展示了量子核机器学习在加速材料发现方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 自主材料科学需要以最少的数据探索新材料，量子核模型理论上可以用更少的训练数据达到与经典模型相似的性能，这为将量子核机器学习应用于自主材料发现提供了可能优势。

Method: 研究比较了量子核和多种经典核在Fe-Ga-Pd三元成分扩展库的X射线衍射图案上的性能。在IonQ的Aria离子阱量子计算机硬件和相应的经典噪声模拟器上进行实验，采用高斯过程主动学习进行相空间导航。

Result: 实验验证了量子核模型可以超越某些经典核模型，特别是在处理复杂的X射线衍射数据时，量子核模型表现出优势。

Conclusion: 量子核机器学习方法在加速材料发现方面具有潜力，复杂的X射线衍射数据是实现量子核模型优势的候选领域。

Abstract: Autonomous materials science, where active learning is used to navigate large compositional phase space, has emerged as a powerful vehicle to rapidly explore new materials. A crucial aspect of autonomous materials science is exploring new materials using as little data as possible. Gaussian process-based active learning allows effective charting of multi-dimensional parameter space with a limited number of training data, and thus is a common algorithmic choice for autonomous materials science. An integral part of the autonomous workflow is the application of kernel functions for quantifying similarities among measured data points. A recent theoretical breakthrough has shown that quantum kernel models can achieve similar performance with less training data than classical models. This signals the possible advantage of applying quantum kernel machine learning to autonomous materials discovery. In this work, we compare quantum and classical kernels for their utility in sequential phase space navigation for autonomous materials science. Specifically, we compute a quantum kernel and several classical kernels for x-ray diffraction patterns taken from an Fe-Ga-Pd ternary composition spread library. We conduct our study on both IonQ's Aria trapped ion quantum computer hardware and the corresponding classical noisy simulator. We experimentally verify that a quantum kernel model can outperform some classical kernel models. The results highlight the potential of quantum kernel machine learning methods for accelerating materials discovery and suggest complex x-ray diffraction data is a candidate for robust quantum kernel model advantage.

</details>


### [738] [Adversarial Drift-Aware Predictive Transfer: Toward Durable Clinical AI](https://arxiv.org/abs/2601.11860)
*Xin Xiong,Zijian Guo,Haobo Zhu,Chuan Hong,Jordan W Smoller,Tianxi Cai,Molei Liu*

Main category: stat.AP

Relevance: 35.0

TL;DR: ADAPT框架通过构建未来模型的不确定性集合，优化最坏情况性能，以应对临床AI系统中的时间漂移问题，无需频繁重新训练。


<details>
  <summary>Details</summary>
Motivation: 临床AI系统部署后常因时间数据漂移（如人群变化、诊断编码更新、COVID-19疫情等）导致性能衰减。频繁重新训练因计算成本和隐私限制而不切实际。

Method: ADAPT框架结合历史源模型和有限当前数据，构建未来可能模型的不确定性集合，通过优化该集合上的最坏情况性能，平衡当前准确性和对未来漂移的鲁棒性。

Result: 在Mass General Brigham和Duke University Health Systems的纵向自杀风险预测验证中，ADAPT在编码转换和疫情引起的漂移中表现出优越的稳定性，最小化年度性能衰减。

Conclusion: ADAPT为高风险医疗环境中维持可靠AI提供了可扩展路径，无需标记或重新训练未来数据，保护数据隐私并确保操作简单性。

Abstract: Clinical AI systems frequently suffer performance decay post-deployment due to temporal data shifts, such as evolving populations, diagnostic coding updates (e.g., ICD-9 to ICD-10), and systemic shocks like the COVID-19 pandemic. Addressing this ``aging'' effect via frequent retraining is often impractical due to computational costs and privacy constraints. To overcome these hurdles, we introduce Adversarial Drift-Aware Predictive Transfer (ADAPT), a novel framework designed to confer durability against temporal drift with minimal retraining. ADAPT innovatively constructs an uncertainty set of plausible future models by combining historical source models and limited current data. By optimizing worst-case performance over this set, it balances current accuracy with robustness against degradation due to future drifts. Crucially, ADAPT requires only summary-level model estimators from historical periods, preserving data privacy and ensuring operational simplicity. Validated on longitudinal suicide risk prediction using electronic health records from Mass General Brigham (2005--2021) and Duke University Health Systems, ADAPT demonstrated superior stability across coding transitions and pandemic-induced shifts. By minimizing annual performance decay without labeling or retraining future data, ADAPT offers a scalable pathway for sustaining reliable AI in high-stakes healthcare environments.

</details>


### [739] [Harmonica: A Self-Adaptation Exemplar for Sustainable MLOps](https://arxiv.org/abs/2601.11926)
*Ananya Halgatti,Shaunak Biswas,Hiya Bhatt,Srinivasan Rakhunathan,Karthik Vaidhyanathan*

Main category: cs.SE

Relevance: 35.0

TL;DR: Harmonica是一个基于MAPE-K循环的自适应MLOps范例，通过监控可持续性指标、评估动态适应边界、自动触发架构策略来提升机器学习系统的长期稳定性。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统在运行环境中经常面临不确定性变化，这些变化会降低模型性能、增加运营成本、减少系统实用性。虽然MLOps简化了ML模型生命周期，但对运行时不确定性的支持有限，影响系统长期可持续性。需要一种机制来检测执行漂移并调整系统行为。

Method: 基于HarmonE方法构建的自适应范例，采用MAPE-K循环实现结构化自适应控制，将高层适应策略与低层策略执行分离。持续监控可持续性指标，评估动态适应边界，当阈值被违反时自动触发架构策略。

Result: 通过时间序列回归和计算机视觉的案例研究，展示了Harmonica能够提高系统稳定性、减少人工干预，为依赖MLOps管道持续运行的MLS提供了实用且可重用的自适应行为基础。

Conclusion: Harmonica为研究MLOps管道中的可持续性和自适应挑战提供了一个实用的范例，能够支持机器学习系统的长期可持续运行。

Abstract: Machine learning enabled systems (MLS) often operate in settings where they regularly encounter uncertainties arising from changes in their surrounding environment. Without structured oversight, such changes can degrade model behavior, increase operational cost, and reduce the usefulness of deployed systems. Although Machine Learning Operations (MLOps) streamlines the lifecycle of ML models, it provides limited support for addressing runtime uncertainties that influence the longer term sustainability of MLS. To support continued viability, these systems need a mechanism that detects when execution drifts outside acceptable bounds and adjusts system behavior in response. Despite the growing interest in sustainable and self-adaptive MLS, there has been limited work towards exemplars that allow researchers to study these challenges in MLOps pipelines. This paper presents Harmonica, a self-adaptation exemplar built on the HarmonE approach, designed to enable the sustainable operation of such pipelines. Harmonica introduces structured adaptive control through MAPE-K loop, separating high-level adaptation policy from low-level tactic execution. It continuously monitors sustainability metrics, evaluates them against dynamic adaptation boundaries, and automatically triggers architectural tactics when thresholds are violated. We demonstrate the tool through case studies in time series regression and computer vision, examining its ability to improve system stability and reduce manual intervention. The results show that Harmonica offers a practical and reusable foundation for enabling adaptive behavior in MLS that rely on MLOps pipelines for sustained operation.

</details>


### [740] [A Kernel Approach for Semi-implicit Variational Inference](https://arxiv.org/abs/2601.12023)
*Longlin Yu,Ziheng Cheng,Shiyue Zhang,Cheng Zhang*

Main category: stat.ML

Relevance: 35.0

TL;DR: 提出KSIVI方法，使用核方法消除SIVI中的下层优化问题，通过核Stein差异实现高效优化


<details>
  <summary>Details</summary>
Motivation: 传统半隐式变分推断(SIVI)通过分层半隐式分布增强变分族表达能力，但密度不可计算性导致标准ELBO优化存在偏差。现有SIVI-SM方法通过极小极大公式解决此问题，但引入了额外的下层优化问题。

Method: 提出核半隐式变分推断(KSIVI)，利用核方法消除下层优化。在再生核希尔伯特空间中优化时，下层问题有显式解，目标简化为核Stein差异(KSD)。利用半隐式分布的分层结构，KSD目标可通过随机梯度方法高效优化。

Result: 建立了通过蒙特卡洛梯度估计器的方差界优化保证，推导出统计泛化界$\tilde{\mathcal{O}}(1/\sqrt{n})$。引入多层分层扩展在保持可计算性的同时提高表达能力。在合成和真实世界贝叶斯推断任务中验证了有效性。

Conclusion: KSIVI为半隐式变分推断提供了原则性且可计算的方法，消除了下层优化复杂度，同时保持了表达能力，在贝叶斯推断任务中表现优异。

Abstract: Semi-implicit variational inference (SIVI) enhances the expressiveness of variational families through hierarchical semi-implicit distributions, but the intractability of their densities makes standard ELBO-based optimization biased. Recent score-matching approaches to SIVI (SIVI-SM) address this issue via a minimax formulation, at the expense of an additional lower-level optimization problem. In this paper, we propose kernel semi-implicit variational inference (KSIVI), a principled and tractable alternative that eliminates the lower-level optimization by leveraging kernel methods. We show that when optimizing over a reproducing kernel Hilbert space, the lower-level problem admits an explicit solution, reducing the objective to the kernel Stein discrepancy (KSD). Exploiting the hierarchical structure of semi-implicit distributions, the resulting KSD objective can be efficiently optimized using stochastic gradient methods. We establish optimization guarantees via variance bounds on Monte Carlo gradient estimators and derive statistical generalization bounds of order $\tilde{\mathcal{O}}(1/\sqrt{n})$. We further introduce a multi-layer hierarchical extension that improves expressiveness while preserving tractability. Empirical results on synthetic and real-world Bayesian inference tasks demonstrate the effectiveness of KSIVI.

</details>


### [741] [Speaking to Silicon: Neural Communication with Bitcoin Mining ASICs](https://arxiv.org/abs/2601.12032)
*Francisco Angulo de Lafuente,Vladimir Veselov,Richard Goodman*

Main category: cs.NE

Relevance: 35.0

TL;DR: 提出了一种将比特币挖矿ASIC芯片作为神经通信介质的创新范式，通过热力学储层计算、层次数系理论等五个互补框架，实现AI系统与硅基底之间的双向信息交换。


<details>
  <summary>Details</summary>
Motivation: 探索废弃加密货币挖矿硬件的潜在计算能力，将其从被动计算基板转变为主动的对话伙伴，利用其热力学状态编码可开发的计算信息。

Method: 整合五个互补框架：热力学储层计算、层次数系理论、算法分析、网络延迟优化和机器验证数学形式化。使用Lean 4和Mathlib进行数学形式化验证，并在Antminer S9等多种ASIC家族上测试。

Result: 1) 储层计算NRMSE达到0.8661；2) 热力学概率滤波器实现92.19%理论能耗降低；3) 虚拟区块管理器提升25%有效算力；4) 在多种ASIC硬件上验证了通用性。

Conclusion: 建立了一种新范式：将ASIC视为主动的对话伙伴而非被动计算基板，其热力学状态编码了可开发的计算信息，为硬件再利用和神经通信提供了新途径。

Abstract: This definitive research memoria presents a comprehensive, mathematically verified paradigm for neural communication with Bitcoin mining Application-Specific Integrated Circuits (ASICs), integrating five complementary frameworks: thermodynamic reservoir computing, hierarchical number system theory, algorithmic analysis, network latency optimization, and machine-checked mathematical formalization. We establish that obsolete cryptocurrency mining hardware exhibits emergent computational properties enabling bidirectional information exchange between AI systems and silicon substrates. The research program demonstrates: (1) reservoir computing with NARMA-10 Normalized Root Mean Square Error (NRMSE) of 0.8661; (2) the Thermodynamic Probability Filter (TPF) achieving 92.19% theoretical energy reduction; (3) the Virtual Block Manager achieving +25% effective hashrate; and (4) hardware universality across multiple ASIC families including Antminer S9, Lucky Miner LV06, and Goldshell LB-Box. A significant contribution is the machine-checked mathematical formalization using Lean 4 and Mathlib, providing unambiguous definitions, machine-verified theorems, and reviewer-proof claims. Key theorems proven include: independence implies zero leakage, predictor beats baseline implies non-independence (the logical core of TPF), energy savings theoretical maximum, and Physical Unclonable Function (PUF) distinguishability witnesses. Vladimir Veselov's hierarchical number system theory explains why early-round information contains predictive power. This work establishes a new paradigm: treating ASICs not as passive computational substrates but as active conversational partners whose thermodynamic state encodes exploitable computational information.

</details>


### [742] [Offline Policy Learning with Weight Clipping and Heaviside Composite Optimization](https://arxiv.org/abs/2601.12117)
*Jingren Liu,Hanzhang Qin,Junyi Liu,Mabel C. Chou,Jong-Shi Pang*

Main category: math.OC

Relevance: 35.0

TL;DR: 提出基于权重截断估计器的离线策略学习算法，通过截断小倾向得分来减少策略值估计的方差，使用渐进整数规划方法求解，提高学习策略的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于重加权的方法（如逆倾向加权或双重稳健估计器）在小倾向得分情况下存在高方差问题，导致策略值估计不准确，进而影响下游策略优化，产生次优策略。

Method: 提出权重截断估计器，通过截断阈值最小化策略值估计的均方误差；针对线性策略，将问题重构为Heaviside复合优化问题，使用渐进整数规划方法高效求解。

Result: 建立了算法次优性的上界，表明通过权重截断估计器减少策略值估计的均方误差能够提升策略学习性能。

Conclusion: 权重截断估计器能有效解决小倾向得分带来的高方差问题，提出的渐进整数规划方法使实际策略学习变得可行，提高了离线策略学习的性能。

Abstract: Offline policy learning aims to use historical data to learn an optimal personalized decision rule. In the standard estimate-then-optimize framework, reweighting-based methods (e.g., inverse propensity weighting or doubly robust estimators) are widely used to produce unbiased estimates of policy values. However, when the propensity scores of some treatments are small, these reweighting-based methods suffer from high variance in policy value estimation, which may mislead the downstream policy optimization and yield a learned policy with inferior value. In this paper, we systematically develop an offline policy learning algorithm based on a weight-clipping estimator that truncates small propensity scores via a clipping threshold chosen to minimize the mean squared error (MSE) in policy value estimation. Focusing on linear policies, we address the bilevel and discontinuous objective induced by weight-clipping-based policy optimization by reformulating the problem as a Heaviside composite optimization problem, which provides a rigorous computational framework. The reformulated policy optimization problem is then solved efficiently using the progressive integer programming method, making practical policy learning tractable. We establish an upper bound for the suboptimality of the proposed algorithm, which reveals how the reduction in MSE of policy value estimation, enabled by our proposed weight-clipping estimator, leads to improved policy learning performance.

</details>


### [743] [Streaming Operator Inference for Model Reduction of Large-Scale Dynamical Systems](https://arxiv.org/abs/2601.12161)
*Tomoki Koike,Prakash Mohan,Marc T. Henry de Frahan,Julie Bessac,Elizabeth Qian*

Main category: math.NA

Relevance: 35.0

TL;DR: 提出Streaming OpInf方法，通过增量SVD和递归最小二乘法实现流式数据下的降阶模型学习，显著降低内存需求并支持在线模型更新


<details>
  <summary>Details</summary>
Motivation: 传统OpInf作为批量学习方法需要一次性处理所有数据，无法处理大规模应用中的内存限制问题，且不支持在线数据更新。需要开发流式学习方法以适应大规模动态系统仿真需求。

Method: 采用增量SVD进行自适应基函数构建，结合递归最小二乘法进行流式算子更新。系统探索不同流式数值线性代数算法的组合效果，实现无需存储完整数据集的在线模型学习。

Result: Streaming OpInf在精度上与批量OpInf相当，内存需求降低超过99%，维度缩减超过31,000倍，预测速度提升数个数量级。在基准问题和湍流通道流等大规模问题上验证了有效性。

Conclusion: 提出的流式OpInf方法解决了传统批量学习的内存和在线更新限制，为大规模动态系统的高效仿真提供了可行的流式降阶模型学习方案。

Abstract: Projection-based model reduction enables efficient simulation of complex dynamical systems by constructing low-dimensional surrogate models from high-dimensional data. The Operator Inference (OpInf) approach learns such reduced surrogate models through a two-step process: constructing a low-dimensional basis via Singular Value Decomposition (SVD) to compress the data, then solving a linear least-squares (LS) problem to infer reduced operators that govern the dynamics in this compressed space, all without access to the underlying code or full model operators, i.e., non-intrusively. Traditional OpInf operates as a batch learning method, where both the SVD and LS steps process all data simultaneously. This poses a barrier to deployment of the approach on large-scale applications where dataset sizes prevent the loading of all data into memory at once. Additionally, the traditional batch approach does not naturally allow model updates using new data acquired during online computation. To address these limitations, we propose Streaming OpInf, which learns reduced models from sequentially arriving data streams. Our approach employs incremental SVD for adaptive basis construction and recursive LS for streaming operator updates, eliminating the need to store complete data sets while enabling online model adaptation. The approach can flexibly combine different choices of streaming algorithms for numerical linear algebra: we systematically explore the impact of these choices both analytically and numerically to identify effective combinations for accurate reduced model learning. Numerical experiments on benchmark problems and a large-scale turbulent channel flow demonstrate that Streaming OpInf achieves accuracy comparable to batch OpInf while reducing memory requirements by over 99% and enabling dimension reductions exceeding 31,000x, resulting in orders-of-magnitude faster predictions.

</details>


### [744] [HCFT: Hierarchical Convolutional Fusion Transformer for EEG Decoding](https://arxiv.org/abs/2601.12279)
*Haodong Zhang,Jiapeng Zhu,Yitong Chen,Hongqi Li*

Main category: cs.HC

Relevance: 35.0

TL;DR: 提出HCFT框架，结合双分支卷积编码器和分层Transformer块，用于多尺度EEG表征学习，在脑机接口任务中优于现有方法


<details>
  <summary>Details</summary>
Motivation: EEG解码需要能有效提取和整合多通道信号中复杂时域、频域和空间特征的模型。现有方法在处理多尺度特征和全局依赖方面存在局限，需要更轻量且泛化性强的解码框架。

Method: 提出分层卷积融合Transformer（HCFT）：1）双分支卷积编码器分别捕获时域和时空局部动态；2）交叉注意力机制对齐分支特征；3）分层Transformer融合结构编码全局依赖；4）定制动态Tanh归一化模块替代传统层归一化，增强训练稳定性。

Result: 在BCI Competition IV-2b上达到80.83%平均准确率和0.6165 Cohen's kappa；在CHB-MIT上达到99.10%灵敏度、0.0236每小时误报率和98.82%特异性，优于10多个SOTA基线方法。消融研究证实各核心组件均有显著贡献。

Conclusion: HCFT能有效捕获EEG动态特征，在跨被试分类和连续癫痫预测任务中表现优异，具有实际脑机接口应用潜力。框架轻量且泛化性强。

Abstract: Electroencephalography (EEG) decoding requires models that can effectively extract and integrate complex temporal, spectral, and spatial features from multichannel signals. To address this challenge, we propose a lightweight and generalizable decoding framework named Hierarchical Convolutional Fusion Transformer (HCFT), which combines dual-branch convolutional encoders and hierarchical Transformer blocks for multi-scale EEG representation learning. Specifically, the model first captures local temporal and spatiotemporal dynamics through time-domain and time-space convolutional branches, and then aligns these features via a cross-attention mechanism that enables interaction between branches at each stage. Subsequently, a hierarchical Transformer fusion structure is employed to encode global dependencies across all feature stages, while a customized Dynamic Tanh normalization module is introduced to replace traditional Layer Normalization in order to enhance training stability and reduce redundancy. Extensive experiments are conducted on two representative benchmark datasets, BCI Competition IV-2b and CHB-MIT, covering both event-related cross-subject classification and continuous seizure prediction tasks. Results show that HCFT achieves 80.83% average accuracy and a Cohen's kappa of 0.6165 on BCI IV-2b, as well as 99.10% sensitivity, 0.0236 false positives per hour, and 98.82% specificity on CHB-MIT, consistently outperforming over ten state-of-the-art baseline methods. Ablation studies confirm that each core component of the proposed framework contributes significantly to the overall decoding performance, demonstrating HCFT's effectiveness in capturing EEG dynamics and its potential for real-world BCI applications.

</details>


### [745] [ParaMETA: Towards Learning Disentangled Paralinguistic Speaking Styles Representations from Speech](https://arxiv.org/abs/2601.12289)
*Haowei Lou,Hye-young Paik,Wen Hu,Lina Yao*

Main category: cs.SD

Relevance: 35.0

TL;DR: ParaMETA是一个统一的语音风格学习与控制框架，通过将语音投影到特定子空间来学习解耦的任务特定嵌入，支持多任务识别和细粒度风格控制的语音生成。


<details>
  <summary>Details</summary>
Motivation: 学习不同说话风格（如情感、年龄、性别）的代表性嵌入对于识别任务（认知计算、人机交互）和生成任务（风格可控语音生成）都至关重要。现有方法依赖单任务模型或跨模态对齐，存在任务间干扰和负迁移问题。

Method: ParaMETA通过将语音投影到每个风格类型的专用子空间来学习解耦的任务特定嵌入，减少任务间干扰，允许单个模型处理多个副语言任务（情感、性别、年龄、语言分类）。支持语音和文本提示，可在保持其他风格的同时修改特定说话风格。

Result: 大量实验表明，ParaMETA在分类准确率上优于强基线，能生成更自然、更具表现力的语音，同时保持轻量高效的模型，适合实际应用。

Conclusion: ParaMETA提供了一个统一灵活的框架，既能有效学习说话风格嵌入用于识别任务，又能实现细粒度风格控制用于语音生成，在性能和效率上都表现出色。

Abstract: Learning representative embeddings for different types of speaking styles, such as emotion, age, and gender, is critical for both recognition tasks (e.g., cognitive computing and human-computer interaction) and generative tasks (e.g., style-controllable speech generation). In this work, we introduce ParaMETA, a unified and flexible framework for learning and controlling speaking styles directly from speech. Unlike existing methods that rely on single-task models or cross-modal alignment, ParaMETA learns disentangled, task-specific embeddings by projecting speech into dedicated subspaces for each type of style. This design reduces inter-task interference, mitigates negative transfer, and allows a single model to handle multiple paralinguistic tasks such as emotion, gender, age, and language classification. Beyond recognition, ParaMETA enables fine-grained style control in Text-To-Speech (TTS) generative models. It supports both speech- and text-based prompting and allows users to modify one speaking styles while preserving others. Extensive experiments demonstrate that ParaMETA outperforms strong baselines in classification accuracy and generates more natural and expressive speech, while maintaining a lightweight and efficient model suitable for real-world applications.

</details>


### [746] [Toward Faithful Explanations in Acoustic Anomaly Detection](https://arxiv.org/abs/2601.12660)
*Maab Elrashid,Anthony Deschênes,Cem Subakan,Mirco Ravanelli,Rémi Georges,Michael Morin*

Main category: cs.SD

Relevance: 35.0

TL;DR: 该论文研究音频异常检测中自编码器模型的解释性，比较标准自编码器( AE )和掩码自编码器( MAE )在检测性能和解释性方面的差异，提出基于扰动的忠实度评估指标。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的异常检测应用中，可解释性对于用户信任至关重要。尽管深度学习模型性能强大，但往往缺乏透明度。本研究旨在探索音频异常检测中自编码器模型的解释性问题。

Method: 比较标准自编码器(AE)和掩码自编码器(MAE)在音频异常检测中的表现。应用多种归因方法：误差图、显著性图、SmoothGrad、积分梯度、GradSHAP和Grad-CAM。提出基于扰动的忠实度评估指标，通过用重构替换突出区域来模拟正常输入。

Result: MAE虽然检测性能略低于AE，但能提供更忠实、时间上更精确的解释，表明与真实异常有更好的对齐。掩码训练能提高解释质量而不损害性能。

Conclusion: 在异常检测流程中纳入可解释性非常重要，掩码训练能改善解释质量。MAE在解释性方面优于标准AE，为实际工业应用提供了更可信的异常检测方案。

Abstract: Interpretability is essential for user trust in real-world anomaly detection applications. However, deep learning models, despite their strong performance, often lack transparency. In this work, we study the interpretability of autoencoder-based models for audio anomaly detection, by comparing a standard autoencoder (AE) with a mask autoencoder (MAE) in terms of detection performance and interpretability. We applied several attribution methods, including error maps, saliency maps, SmoothGrad, Integrated Gradients, GradSHAP, and Grad-CAM. Although MAE shows a slightly lower detection, it consistently provides more faithful and temporally precise explanations, suggesting a better alignment with true anomalies. To assess the relevance of the regions highlighted by the explanation method, we propose a perturbation-based faithfulness metric that replaces them with their reconstructions to simulate normal input. Our findings, based on experiments in a real industrial scenario, highlight the importance of incorporating interpretability into anomaly detection pipelines and show that masked training improves explanation quality without compromising performance.

</details>


### [747] [Beyond Visual Realism: Toward Reliable Financial Time Series Generation](https://arxiv.org/abs/2601.12990)
*Fan Zhang,Jiabin Luo,Zheng Zhang,Shuanghong Huang,Zhipeng Liu,Yu Chen*

Main category: q-fin.ST

Relevance: 35.0

TL;DR: SFAG（Stylized Facts Alignment GAN）通过将金融时间序列的关键特征事实转化为可微结构约束，并与对抗损失联合优化，生成既保持统计特征又能在交易回测中表现稳健的合成数据。


<details>
  <summary>Details</summary>
Motivation: 现有金融时间序列生成模型（如GANs、WGAN-GP）虽然能生成看似真实的数据并重现厚尾、波动率聚类等特征事实，但在交易回测中经常崩溃，产生极端不现实的结果，导致合成数据无法实际使用。根本原因在于忽视了金融不对称性和罕见尾部事件，这些因素对市场风险影响重大但常被分布匹配目标忽略。

Method: 提出Stylized Facts Alignment GAN（SFAG），将关键特征事实（如厚尾、波动率聚类、杠杆效应等）转化为可微的结构约束，并与对抗损失联合优化。这种多约束设计确保生成的序列不仅在图表上与市场动态对齐，在回测中也保持稳健。

Result: 在上证综指（2004-2024）上的实验表明，基线GANs产生不稳定且不合理的交易结果，而SFAG生成的合成数据能保持特征事实并支持稳健的动量策略表现。SFAG在回测中表现出更好的稳定性和实用性。

Conclusion: 结构保持目标对于弥合金融生成建模中表面真实性与实际可用性之间的差距至关重要。SFAG通过将特征事实转化为约束，生成了既统计真实又交易稳健的合成数据。

Abstract: Generative models for financial time series often create data that look realistic and even reproduce stylized facts such as fat tails or volatility clustering. However, these apparent successes break down under trading backtests: models like GANs or WGAN-GP frequently collapse, yielding extreme and unrealistic results that make the synthetic data unusable in practice. We identify the root cause in the neglect of financial asymmetry and rare tail events, which strongly affect market risk but are often overlooked by objectives focusing on distribution matching. To address this, we introduce the Stylized Facts Alignment GAN (SFAG), which converts key stylized facts into differentiable structural constraints and jointly optimizes them with adversarial loss. This multi-constraint design ensures that generated series remain aligned with market dynamics not only in plots but also in backtesting. Experiments on the Shanghai Composite Index (2004--2024) show that while baseline GANs produce unstable and implausible trading outcomes, SFAG generates synthetic data that preserve stylized facts and support robust momentum strategy performance. Our results highlight that structure-preserving objectives are essential to bridge the gap between superficial realism and practical usability in financial generative modeling.

</details>


### [748] [Forecasting Continuum Intensity for Solar Active Region Emergence Prediction using Transformers](https://arxiv.org/abs/2601.13144)
*Jonas Tirona,Sarang Patil,Spiridon Kasapis,Eren Dogan,John Stefan,Irina N. Kitiashvili,Alexander G. Kosovichev,Mengjia Xu*

Main category: astro-ph.SR

Relevance: 35.0

TL;DR: 该论文提出了一种基于滑动窗口Transformer的太阳活动区（AR）早期预测方法，通过注意力偏置和时序感知损失函数实现比传统LSTM基线更早的检测，在准确性和预警时间上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 太阳活动区（AR）的早期准确预测对空间天气预报至关重要。传统LSTM方法在预测AR出现相关的连续谱强度下降方面已有基础，但需要探索新架构来提升预测性能，特别是实现更早的预警。

Method: 采用滑动窗口Transformer架构预测未来12小时的连续谱强度演化，使用SDO/HMI观测的46个AR数据。进行系统消融研究评估两个关键组件：1）时间1D卷积前端；2）包含注意力偏置和时序感知损失函数的"早期检测"架构。

Result: 最佳模型（早期检测架构，无Conv1D层）达到RMSE 0.1189（比LSTM基线提升10.6%），平均预警时间4.73小时。虽然Transformer在聚合时序和准确性上更优，但高灵敏度检测带来了比平滑基线模型更大的方差。

Conclusion: 带有早期检测偏置的Transformer架构（不使用时间平滑层）为AR出现预测提供了高灵敏度替代方案，优先考虑提前预警而非统计平滑性。这种波动性是操作预警系统的必要权衡。

Abstract: Early and accurate prediction of solar active region (AR) emergence is crucial for space weather forecasting. Building on established Long Short-Term Memory (LSTM) based approaches for forecasting the continuum intensity decrease associated with AR emergence, this work expands the modeling with new architectures and targets. We investigate a sliding-window Transformer architecture to forecast continuum intensity evolution up to 12 hours ahead using data from 46 ARs observed by SDO/HMI. We conduct a systematic ablation study to evaluate two key components: (1) the inclusion of a temporal 1D convolutional (Conv1D) front-end and (2) a novel `Early Detection' architecture featuring attention biases and a timing-aware loss function. Our best-performing model, combining the Early Detection architecture without the Conv1D layer, achieved a Root Mean Square Error (RMSE) of 0.1189 (representing a 10.6% improvement over the LSTM baseline) and an average advance warning time of 4.73 hours (timing difference of -4.73h), even under a stricter emergence criterion than previous studies. While the Transformer demonstrates superior aggregate timing and accuracy, we note that this high-sensitivity detection comes with increased variance compared to smoother baseline models. However, this volatility is a necessary trade-off for operational warning systems: the model's ability to detect micro-changes in precursor signals enables significantly earlier detection, outweighing the cost of increased noise. Our results demonstrate that Transformer architectures modified with early detection biases, when used without temporal smoothing layers, provide a high-sensitivity alternative for forecasting AR emergence that prioritizes advance warning over statistical smoothness.

</details>


### [749] [Deep Neural networks for solving high-dimensional parabolic partial differential equations](https://arxiv.org/abs/2601.13256)
*Wenzhong Zhang,Zhenyuan Hu,Wei Cai,George EM Karniadakis*

Main category: math.NA

Relevance: 35.0

TL;DR: 本文综述了基于神经网络求解高维抛物型偏微分方程的方法，主要围绕三个统一范式：PDE残差方法、随机方法（Feynman-Kac/BSDE）和混合无导数随机差分方法，旨在克服维度灾难问题。


<details>
  <summary>Details</summary>
Motivation: 高维偏微分方程的传统网格方法受维度灾难限制，无法处理高维问题。深度神经网络作为无网格替代方案，能够近似求解数十到数千维的PDE解，本文旨在系统介绍这一新兴领域的方法论。

Method: 1) PDE残差方法：包括物理信息神经网络及其高维变体；2) 随机方法：基于Feynman-Kac公式和后向随机微分方程；3) 混合无导数随机差分方法：旨在降低高维导数计算成本。论文通过Hamilton-Jacobi-Bellman和Black-Scholes等基准问题（高达1000维）验证方法。

Result: 神经网络方法能够有效求解高达1000维的抛物型PDE，展示了方法的可扩展性、有效性和准确性。论文系统比较了不同范式的计算效率、实现复杂度和适用场景。

Conclusion: 神经网络为高维PDE求解提供了有前景的无网格方法，但仍面临可靠性和可扩展性挑战。未来需要发展更稳健、高效的求解器，并解决理论保证和数值稳定性问题。

Abstract: The numerical solution of high dimensional partial differential equations (PDEs) is severely constrained by the curse of dimensionality (CoD), rendering classical grid--based methods impractical beyond a few dimensions. In recent years, deep neural networks have emerged as a promising mesh free alternative, enabling the approximation of PDE solutions in tens to thousands of dimensions. This review provides a tutorial--oriented introduction to neural--network--based methods for solving high dimensional parabolic PDEs, emphasizing conceptual clarity and methodological connections. We organize the literature around three unifying paradigms: (i) PDE residual--based approaches, including physicsinformed neural networks and their high dimensional variants; (ii) stochastic methods derived from Feynman--Kac and backward stochastic differential equation formulations; and (iii) hybrid derivative--free random difference approaches designed to alleviate the computational cost of derivatives in high dimensions. For each paradigm, we outline the underlying mathematical formulation, algorithmic implementation, and practical strengths and limitations. Representative benchmark problems--including Hamilton--Jacobi--Bellman and Black--Scholes equations in up to 1000 dimensions --illustrate the scalability, effectiveness, and accuracy of the methods. The paper concludes with a discussion of open challenges and future directions for reliable and scalable solvers of high dimensional PDEs.

</details>


### [750] [Classifiers in High Dimensional Hilbert Metrics](https://arxiv.org/abs/2601.13410)
*Aditya Acharya,Auguste H. Gezalyan,David M. Mount*

Main category: cs.CG

Relevance: 35.0

TL;DR: 本文提出在希尔伯特多边形度量空间中高效分类高维点的算法，包括大间隔SVM的LP算法、软间隔SVM算法和最近邻分类算法，显著改进了先前方法的理论保证和运行时间。


<details>
  <summary>Details</summary>
Motivation: 高维空间中的点分类是机器学习中的基本几何问题。希尔伯特度量作为Cayley-Klein双曲距离到任意凸体的推广，在机器学习和凸几何中有广泛应用。先前工作要么缺乏理论运行时间保证，要么存在指数级运行时间问题，需要更高效的分类算法。

Method: 1) 提出基于线性规划(LP)的高效算法解决希尔伯特度量中的大间隔SVM问题，运行时间与点数、边界面和维度成多项式关系；2) 考虑密切相关的Funk度量；3) 提出软间隔SVM问题的有效算法；4) 提出希尔伯特度量中基于最近邻分类的高效算法。

Result: 算法在运行时间上显著改进先前工作，提供了多项式时间保证，避免了指数级复杂度。在希尔伯特多边形度量空间中实现了高效的点分类。

Conclusion: 本文为希尔伯特度量空间中的分类问题提供了首个具有多项式时间保证的高效算法，填补了先前工作的理论空白，为高维几何分类问题提供了实用解决方案。

Abstract: Classifying points in high dimensional spaces is a fundamental geometric problem in machine learning. In this paper, we address classifying points in the $d$-dimensional Hilbert polygonal metric. The Hilbert metric is a generalization of the Cayley-Klein hyperbolic distance to arbitrary convex bodies and has a diverse range of applications in machine learning and convex geometry. We first present an efficient LP-based algorithm in the metric for the large-margin SVM problem. Our algorithm runs in time polynomial to the number of points, bounding facets, and dimension. This is a significant improvement on previous works, which either provide no theoretical guarantees on running time, or suffer from exponential runtime. We also consider the closely related Funk metric. We also present efficient algorithms for the soft-margin SVM problem and for nearest neighbor-based classification in the Hilbert metric.

</details>


### [751] [Bridging the Gap Between Estimated and True Regret Towards Reliable Regret Estimation in Deep Learning based Mechanism Design](https://arxiv.org/abs/2601.13489)
*Shuyuan You,Zhiqiang Zhuang,Kewen Wang,Zhe Wang*

Main category: cs.GT

Relevance: 35.0

TL;DR: 该论文发现现有基于深度学习的拍卖机制（如RegretNet、ALGnet等）系统性地低估了实际遗憾值，导致对激励兼容性和收益的夸大宣称，并提出了一种改进的遗憾估计方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习拍卖机制通过放松激励兼容性约束并使用事后遗憾来近似最优拍卖，但真实遗憾的准确性不明确。计算精确遗憾是计算不可行的，现有方法依赖梯度优化器且结果对超参数敏感，导致可能低估实际遗憾。

Method: 1) 通过大量实验揭示现有方法系统性地低估实际遗憾；2) 推导遗憾的下界；3) 提出高效的逐项遗憾近似方法；4) 基于此提出引导精炼程序，显著提高遗憾估计准确性同时降低计算成本。

Result: 研究发现现有方法在某些模型中真实遗憾比报告遗憾大数百倍，导致对激励兼容性和收益的夸大宣称。提出的方法提供了更可靠的遗憾估计基础。

Conclusion: 需要重新评估该领域先前性能宣称，提出的方法为基于深度学习的拍卖机制中的激励兼容性评估提供了更可靠的基础。

Abstract: Recent advances, such as RegretNet, ALGnet, RegretFormer and CITransNet, use deep learning to approximate optimal multi item auctions by relaxing incentive compatibility (IC) and measuring its violation via ex post regret. However, the true accuracy of these regret estimates remains unclear. Computing exact regret is computationally intractable, and current models rely on gradient based optimizers whose outcomes depend heavily on hyperparameter choices. Through extensive experiments, we reveal that existing methods systematically underestimate actual regret (In some models, the true regret is several hundred times larger than the reported regret), leading to overstated claims of IC and revenue. To address this issue, we derive a lower bound on regret and introduce an efficient item wise regret approximation. Building on this, we propose a guided refinement procedure that substantially improves regret estimation accuracy while reducing computational cost. Our method provides a more reliable foundation for evaluating incentive compatibility in deep learning based auction mechanisms and highlights the need to reassess prior performance claims in this area.

</details>


### [752] [An Elementary Approach to Scheduling in Generative Diffusion Models](https://arxiv.org/abs/2601.13602)
*Qiang Sun,H. Vincent Poor,Wenyi Zhang*

Main category: cs.IT

Relevance: 35.0

TL;DR: 该论文提出了一种分析扩散模型中噪声调度和时间离散化影响的基本方法，通过高斯源分布的解析推导，优化噪声调度，并在实验中验证了其时间离散化策略的优越性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型中的噪声调度和时间离散化对生成质量有重要影响，但目前缺乏系统的理论分析框架。作者希望建立一种基本方法来定量分析这些因素对模型性能的影响。

Method: 假设源分布为多元高斯分布，推导反向采样过程中分布的闭式演化轨迹和KL散度。通过欧拉-麦克劳林展开分析时间离散化步数的影响，利用变分法求解最优噪声调度问题。

Result: 理论分析表明最优噪声调度遵循正切定律，系数由源协方差矩阵的特征值决定。实验证明，该方法选择的时间离散化策略在各种数据集和预训练模型上均优于基线方法，尤其在函数评估次数受限时表现更佳。

Conclusion: 该研究为扩散模型的噪声调度和时间离散化提供了理论分析框架和优化方法，有助于提高扩散模型的采样效率和生成质量。

Abstract: An elementary approach to characterizing the impact of noise scheduling and time discretization in generative diffusion models is developed. Considering a simplified model where the source distribution is multivariate Gaussian with a given covariance matrix, the explicit closed-form evolution trajectory of the distributions across reverse sampling steps is derived, and consequently, the Kullback-Leibler (KL) divergence between the source distribution and the reverse sampling output is obtained. The effect of the number of time discretization steps on the convergence of this KL divergence is studied via the Euler-Maclaurin expansion. An optimization problem is formulated, and its solution noise schedule is obtained via calculus of variations, shown to follow a tangent law whose coefficient is determined by the eigenvalues of the source covariance matrix. For an alternative scenario, more realistic in practice, where pretrained models have been obtained for some given noise schedules, the KL divergence also provides a measure to compare different time discretization strategies in reverse sampling. Experiments across different datasets and pretrained models demonstrate that the time discretization strategy selected by our approach consistently outperforms baseline and search-based strategies, particularly when the budget on the number of function evaluations is very tight.

</details>


### [753] [Sample Complexity of Average-Reward Q-Learning: From Single-agent to Federated Reinforcement Learning](https://arxiv.org/abs/2601.13642)
*Yuchen Jiao,Jiin Woo,Gen Li,Gauri Joshi,Yuejie Chi*

Main category: stat.ML

Relevance: 35.0

TL;DR: 本文研究了平均奖励马尔可夫决策过程中的Q学习算法，提出了单智能体和联邦学习两种场景下的样本复杂度分析，并证明了联邦协作能显著降低每个智能体所需的样本量。


<details>
  <summary>Details</summary>
Motivation: 平均奖励强化学习为长期决策提供了理论框架，但Q学习在平均奖励MDP中的理论保证有限。现有研究主要集中在折扣或有限时域MDP上，而平均奖励设置下的Q学习样本复杂度分析不足，特别是在联邦学习场景中。

Method: 提出了一种简单但有效的Q学习算法，适用于有限状态和动作空间的平均奖励MDP。在弱通信假设下，分析了单智能体和联邦学习两种场景。通过精心选择参数，推导了样本复杂度和通信复杂度。

Result: 单智能体场景下，样本复杂度为$\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{\varepsilon^3}\right)$，比先前结果至少改进$\frac{\|h^{\star}\|_{\mathsf{sp}}^2}{\varepsilon^2}$倍。联邦场景中，每个智能体的样本复杂度降至$\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{M\varepsilon^3}\right)$，仅需$\widetilde{O}\left(\frac{\|h^{\star}\|_{\mathsf{sp}}}{\varepsilon}\right)$轮通信。

Conclusion: 这是第一个针对平均奖励MDP的联邦Q学习算法，在样本复杂度和通信复杂度方面都具有可证明的效率。研究为平均奖励强化学习的理论分析提供了重要进展，特别是在分布式学习场景中。

Abstract: Average-reward reinforcement learning offers a principled framework for long-term decision-making by maximizing the mean reward per time step. Although Q-learning is a widely used model-free algorithm with established sample complexity in discounted and finite-horizon Markov decision processes (MDPs), its theoretical guarantees for average-reward settings remain limited. This work studies a simple but effective Q-learning algorithm for average-reward MDPs with finite state and action spaces under the weakly communicating assumption, covering both single-agent and federated scenarios. For the single-agent case, we show that Q-learning with carefully chosen parameters achieves sample complexity $\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{\varepsilon^3}\right)$, where $\|h^{\star}\|_{\mathsf{sp}}$ is the span norm of the bias function, improving previous results by at least a factor of $\frac{\|h^{\star}\|_{\mathsf{sp}}^2}{\varepsilon^2}$. In the federated setting with $M$ agents, we prove that collaboration reduces the per-agent sample complexity to $\widetilde{O}\left(\frac{|\mathcal{S}||\mathcal{A}|\|h^{\star}\|_{\mathsf{sp}}^3}{M\varepsilon^3}\right)$, with only $\widetilde{O}\left(\frac{\|h^{\star}\|_{\mathsf{sp}}}{\varepsilon}\right)$ communication rounds required. These results establish the first federated Q-learning algorithm for average-reward MDPs, with provable efficiency in both sample and communication complexity.

</details>


### [754] [Reinforcement Learning for Opportunistic Routing in Software-Defined LEO-Terrestrial Systems](https://arxiv.org/abs/2601.13662)
*Sivaram Krishnan,Zhouyou Gu,Jihong Park,Sung-Min Oh,Jinho Choi*

Main category: cs.NI

Relevance: 35.0

TL;DR: 论文提出了一种用于低地球轨道卫星网络的机遇式路由方法，利用GEO-SDN控制器和残差强化学习来最小化传输延迟，相比传统方法显著减少了队列长度。


<details>
  <summary>Details</summary>
Motivation: 随着大规模低地球轨道卫星星座的激增，需要智能路由策略来处理快速变化的网络拓扑和间歇性的网关可见性，以实现低延迟和鲁棒的数据传输。

Method: 提出机遇式路由方法，将数据包转发到任何可用的地面网关而非固定目的地；建立约束随机优化问题，采用残差强化学习框架来优化路由以减少传输延迟。

Result: 多天轨道数据的仿真结果表明，该方法相比经典背压算法和其他知名排队算法，在队列长度减少方面取得了显著改进。

Conclusion: 机遇式路由结合GEO-SDN控制器和残差强化学习，为高度动态的LEO网络提供了一种有前景的低延迟、鲁棒数据传输解决方案。

Abstract: The proliferation of large-scale low Earth orbit (LEO) satellite constellations is driving the need for intelligent routing strategies that can effectively deliver data to terrestrial networks under rapidly time-varying topologies and intermittent gateway visibility. Leveraging the global control capabilities of a geostationary (GEO)-resident software-defined networking (SDN) controller, we introduce opportunistic routing, which aims to minimize delivery delay by forwarding packets to any currently available ground gateways rather than fixed destinations. This makes it a promising approach for achieving low-latency and robust data delivery in highly dynamic LEO networks. Specifically, we formulate a constrained stochastic optimization problem and employ a residual reinforcement learning framework to optimize opportunistic routing for reducing transmission delay. Simulation results over multiple days of orbital data demonstrate that our method achieves significant improvements in queue length reduction compared to classical backpressure and other well-known queueing algorithms.

</details>


### [755] [Generative Adversarial Networks for Resource State Generation](https://arxiv.org/abs/2601.13708)
*Shahbaz Shaik,Sourav Chatterjee,Sayantan Pramanik,Indranil Chakrabarty*

Main category: quant-ph

Relevance: 35.0

TL;DR: 提出基于物理知识的生成对抗网络框架，将量子资源态生成重构为逆设计任务，通过嵌入任务特定效用函数来优化生成适用于量子隐形传态和纠缠广播的两量子比特态。


<details>
  <summary>Details</summary>
Motivation: 传统量子态设计方法通常基于理论分析，难以自动化生成针对特定量子信息处理任务优化的资源态。需要一种能够自动设计满足物理约束（如厄米性、迹为1、正定性）且针对特定任务优化的量子态生成方法。

Method: 采用物理知识引导的生成对抗网络框架，比较了基于分解的架构和直接生成架构。在训练中嵌入任务特定的效用函数，通过结构性地强制实施量子态的物理约束（厄米性、迹为1、正定性），而不是仅通过损失函数来约束。

Result: 该框架能够以超过98%的保真度再现Werner-like态和Bell对角态的理论资源边界。结构性地强制物理约束的方法比仅使用损失函数的方法具有更高的保真度和训练稳定性。证明了对抗学习作为轻量级但有效的约束驱动量子态发现方法的可行性。

Conclusion: 该框架为量子信息处理应用中定制化量子资源的自动化设计提供了可扩展的基础，以量子隐形传态和纠缠广播为例展示了应用潜力，并开启了在高效量子网络设计中使用此类态的可能性。

Abstract: We introduce a physics-informed Generative Adversarial Network framework that recasts quantum resource-state generation as an inverse-design task. By embedding task-specific utility functions into training, the model learns to generate valid two-qubit states optimized for teleportation and entanglement broadcasting. Comparing decomposition-based and direct-generation architectures reveals that structural enforcement of Hermiticity, trace-one, and positivity yields higher fidelity and training stability than loss-only approaches. The framework reproduces theoretical resource boundaries for Werner-like and Bell-diagonal states with fidelities exceeding ~98%, establishing adversarial learning as a lightweight yet effective method for constraint-driven quantum-state discovery. This approach provides a scalable foundation for automated design of tailored quantum resources for information-processing applications, exemplified with teleportation and broadcasting of entanglement, and it opens up the possibility of using such states in efficient quantum network design.

</details>


### [756] [Variational Dual-path Attention Network for CSI-Based Gesture Recognition](https://arxiv.org/abs/2601.13745)
*N. Zhang*

Main category: cs.NI

Relevance: 35.0

TL;DR: 提出VDAN轻量级特征预处理模块，通过频域滤波和时域检测进行结构化特征精炼，利用变分推理建模注意力权重不确定性，提升Wi-Fi手势识别在噪声和资源受限环境下的性能。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi基于CSI的手势识别面临高维噪声和边缘设备资源限制的挑战。现有端到端模型将特征提取与分类紧密耦合，忽略了CSI固有的时频稀疏性，导致冗余和泛化能力差。

Method: 提出变分双路径注意力网络(VDAN)，通过频域滤波和时域检测进行结构化特征精炼，引入变分推理建模注意力权重不确定性，从信息瓶颈和正则化角度解释设计原理。

Result: 在公共数据集上的实验表明，学习到的注意力权重与CSI的物理稀疏特性一致，验证了模块的可解释性，为资源受限的无线感知系统提供了高效可解释的前端处理方案。

Conclusion: VDAN模块能够有效处理CSI数据的高维噪声，提供轻量级、可解释的特征预处理方案，适用于资源受限的边缘设备无线感知应用。

Abstract: Wi-Fi gesture recognition based on Channel State Information (CSI) is challenged by high-dimensional noise and resource constraints on edge devices. Prevailing end-to-end models tightly couple feature extraction with classification, overlooking the inherent time-frequency sparsity of CSI and leading to redundancy and poor generalization. To address this, this paper proposes a lightweight feature preprocessing module--the Variational Dual-path Attention Network (VDAN). It performs structured feature refinement through frequency-domain filtering and temporal detection. Variational inference is introduced to model the uncertainty in attention weights, thereby enhancing robustness to noise. The design principles of the module are explained from the perspectives of the information bottleneck and regularization. Experiments on a public dataset demonstrate that the learned attention weights align with the physical sparse characteristics of CSI, verifying its interpretability. This work provides an efficient and explainable front-end processing solution for resource-constrained wireless sensing systems.

</details>


### [757] [Towards Effective Negation Modeling in Joint Audio-Text Models for Music](https://arxiv.org/abs/2601.13931)
*Yannis Vasilakis,Rachel Bittner,Johan Pauwels*

Main category: cs.SD

Relevance: 35.0

TL;DR: 该论文针对音频-文本联合模型中否定语义处理不足的问题，提出了通过文本增强和对比损失来改进CLAP模型对音乐描述中否定表达的理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前音频-文本联合模型在音乐检索中难以处理否定语义（如"有/无"人声），这种能力对于准确区分音乐特征至关重要。现有系统无法可靠地表示否定关系，限制了模型的语义理解能力。

Method: 1) 在Million Song Dataset上从头训练CLAP模型，使用LP-MusicCaps-MSD标注
2) 通过文本增强引入否定表达
3) 设计基于差异性的对比损失，在联合嵌入空间中明确分离原始描述和否定描述
4) 提出两种评估协议：将否定建模视为检索任务和二元分类任务

Result: 实验表明，两种方法（单独或组合使用）都能显著改善否定处理能力，同时基本保持检索性能。模型在否定语义理解方面取得明显进步。

Conclusion: 通过文本增强和对比损失可以有效提升音频-文本联合模型对否定语义的理解能力，为音乐检索系统提供了更可靠的语义表示方法。

Abstract: Joint audio-text models are widely used for music retrieval, yet they struggle with semantic phenomena such as negation. Negation is fundamental for distinguishing the absence (or presence) of musical elements (e.g., "with vocals" vs. "without vocals"), but current systems fail to represent this reliably. In this work, we investigate and mitigate this limitation by training CLAP models from scratch on the Million Song Dataset with LP-MusicCaps-MSD captions. We introduce negation through text augmentation and a dissimilarity-based contrastive loss, designed to explicitly separate original and negated captions in the joint embedding space. To evaluate progress, we propose two protocols that frame negation modeling as retrieval and binary classification tasks. Experiments demonstrate that both methods, individually and combined, improve negation handling while largely preserving retrieval performance.

</details>


### [758] [Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework](https://arxiv.org/abs/2601.13945)
*Yixuan Deng,Tongrun Wu,Donghao Wu,Zeyu Wei,Jiayuan Wang,Zhenglong Sun,Yuqing Tang,Xiaoqiang Ji*

Main category: cs.RO

Relevance: 35.0

TL;DR: ANCHOR是一个模块化框架，为具身AI系统提供显式的解耦和鲁棒性系统级原语，将标准化共享状态的可演化契约与通信总线分离，实现可检查的端到端闭环。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI系统从研究原型转向实际部署，系统需要快速演进同时保持可靠性。现有部署通常只是部分解耦，导致接口漂移、跨模块干扰和脆弱的恢复机制。

Method: ANCHOR框架分离了：(1) 规范记录（Canonical Records）- 标准化共享状态的可演化契约；(2) 通信总线 - 用于多对多传播和面向反馈的协调，形成可检查的端到端闭环。

Result: 验证了闭环可行性，分析了不同负载大小和发布率下的延迟分布，展示了在硬崩溃和重启后即使共享内存丢失也能自动恢复流。

Conclusion: ANCHOR将临时集成粘合剂转变为显式契约，使闭环AI系统能够在负载下受控降级并实现自愈恢复，支持可扩展部署。

Abstract: As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems.

</details>


### [759] [Auditory Brain Passage Retrieval: Cross-Sensory EEG Training for Neural Information Retrieval](https://arxiv.org/abs/2601.14001)
*Niall McGuire,Yashar Moshfeghi*

Main category: cs.IR

Relevance: 35.0

TL;DR: 该论文首次系统研究听觉EEG用于脑部段落检索，发现听觉EEG优于视觉EEG，跨感官训练显著提升性能，甚至超越BM25文本基线。


<details>
  <summary>Details</summary>
Motivation: 传统信息检索中的查询构建存在认知和物理障碍。现有脑部段落检索(BPR)研究仅使用视觉刺激，未探索听觉EEG在语音界面和视障用户中的应用潜力，也未研究跨感官训练能否缓解数据稀缺问题。

Method: 使用双编码器架构和四种池化策略(CLS、均值、最大、多向量)，在Alice(听觉)和Nieuwland(视觉)数据集上对比听觉、视觉及跨感官训练。

Result: 听觉EEG始终优于视觉EEG；跨感官训练结合CLS池化显著提升性能：MRR提升31%(0.474)、Hit@1提升43%(0.314)、Hit@10提升28%(0.858)；听觉EEG模型超越BM25文本基线(MRR: 0.474 vs 0.428)。

Conclusion: 听觉神经接口在信息检索任务中有效，跨感官训练既能解决数据稀缺问题，又优于单模态方法，为可访问界面提供了新途径。

Abstract: Query formulation from internal information needs remains fundamentally challenging across all Information Retrieval paradigms due to cognitive complexity and physical impairments. Brain Passage Retrieval (BPR) addresses this by directly mapping EEG signals to passage representations without intermediate text translation. However, existing BPR research exclusively uses visual stimuli, leaving critical questions unanswered: Can auditory EEG enable effective retrieval for voice-based interfaces and visually impaired users? Can training on combined EEG datasets from different sensory modalities improve performance despite severe data scarcity? We present the first systematic investigation of auditory EEG for BPR and evaluate cross-sensory training benefits. Using dual encoder architectures with four pooling strategies (CLS, mean, max, multi-vector), we conduct controlled experiments comparing auditory-only, visual-only, and combined training on the Alice (auditory) and Nieuwland (visual) datasets. Results demonstrate that auditory EEG consistently outperforms visual EEG, and cross-sensory training with CLS pooling achieves substantial improvements over individual training: 31% in MRR (0.474), 43% in Hit@1 (0.314), and 28% in Hit@10 (0.858). Critically, combined auditory EEG models surpass BM25 text baselines (MRR: 0.474 vs 0.428), establishing neural queries as competitive with traditional retrieval whilst enabling accessible interfaces. These findings validate auditory neural interfaces for IR tasks and demonstrate that cross-sensory training addresses data scarcity whilst outperforming single-modality approaches Code: https://github.com/NiallMcguire/Audio_BPR

</details>


### [760] [SecureSplit: Mitigating Backdoor Attacks in Split Learning](https://arxiv.org/abs/2601.14054)
*Zhihao Dou,Dongfei Cui,Weida Wang,Anjun Gao,Yueyang Quan,Mengyao Ma,Viet Vo,Guangdong Bai,Zhuqing Liu,Minghong Fang*

Main category: cs.CR

Relevance: 35.0

TL;DR: SecureSplit是一种针对Split Learning中后门攻击的防御机制，通过维度变换增强良性嵌入与中毒嵌入的差异，并采用自适应过滤方法去除污染嵌入。


<details>
  <summary>Details</summary>
Motivation: Split Learning（SL）作为一种保护数据隐私的协作训练框架，允许参与方共享数据集但保持特征集独立。然而，SL容易受到后门攻击，恶意客户端可以通过修改嵌入来植入隐藏触发器，从而破坏最终训练模型的安全性。

Method: SecureSplit采用维度变换策略来放大良性嵌入与中毒嵌入之间的细微差异，使它们更容易区分。在此基础上，开发了自适应过滤方法，使用基于多数的投票方案来去除污染嵌入，同时保留干净的嵌入。

Result: 在四个数据集（CIFAR-10、MNIST、CINIC-10、ImageNette）、五种后门攻击场景和七种替代防御方法的严格实验中，SecureSplit在各种挑战性条件下都表现出有效性。

Conclusion: SecureSplit为Split Learning框架提供了一种有效的后门攻击防御机制，通过增强嵌入差异性和自适应过滤，能够在保护数据隐私的同时确保模型安全性。

Abstract: Split Learning (SL) offers a framework for collaborative model training that respects data privacy by allowing participants to share the same dataset while maintaining distinct feature sets. However, SL is susceptible to backdoor attacks, in which malicious clients subtly alter their embeddings to insert hidden triggers that compromise the final trained model. To address this vulnerability, we introduce SecureSplit, a defense mechanism tailored to SL. SecureSplit applies a dimensionality transformation strategy to accentuate subtle differences between benign and poisoned embeddings, facilitating their separation. With this enhanced distinction, we develop an adaptive filtering approach that uses a majority-based voting scheme to remove contaminated embeddings while preserving clean ones. Rigorous experiments across four datasets (CIFAR-10, MNIST, CINIC-10, and ImageNette), five backdoor attack scenarios, and seven alternative defenses confirm the effectiveness of SecureSplit under various challenging conditions.

</details>


### [761] [Verifying Physics-Informed Neural Network Fidelity using Classical Fisher Information from Differentiable Dynamical System](https://arxiv.org/abs/2601.11638)
*Josafat Ribeiro Leal Filho,Antônio Augusto Fröhlich*

Main category: cs.LG

Relevance: 30.0

TL;DR: 该论文提出了一种使用Fisher信息度量来评估物理信息神经网络(PINNs)对动力系统建模完整性的新框架，通过比较PINN学习模型与原始解析模型的Fisher信息景观来量化PINN的保真度。


<details>
  <summary>Details</summary>
Motivation: 虽然PINNs已成为求解微分方程和建模物理系统的强大工具，但如何严格量化PINN是否完整捕获了系统的动态行为（而不仅仅是轨迹预测）仍然是一个挑战。现有方法难以评估PINN是否准确捕捉了系统的几何和稳定性特性。

Method: 提出使用Fisher信息度量$g_F^C$来评估PINN的保真度，该度量针对可微动力系统设计，测量确定性系统中的固有不确定性（如对初始条件的敏感性），并与相空间曲率和状态空间演化的净拉伸作用相关。通过计算PINN学习模型和原始解析模型的Jacobian矩阵，比较两者的Fisher信息景观。

Result: 论文提出了一种实验方法，使用汽车动力学模型来演示如何计算和比较解析模型与训练好的PINN的$g_F^C$。这种比较提供了PINN在表示系统复杂动态特性方面的定量保真度度量。

Conclusion: 如果PINN准确学习了物理系统的底层动力学，那么从PINN学习模型推导出的Fisher信息景观将与原始解析模型密切匹配，这表明PINN不仅捕获了状态演化，还捕获了关键的几何和稳定性特性。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving differential equations and modeling physical systems by embedding physical laws into the learning process. However, rigorously quantifying how well a PINN captures the complete dynamical behavior of the system, beyond simple trajectory prediction, remains a challenge. This paper proposes a novel experimental framework to address this by employing Fisher information for differentiable dynamical systems, denoted $g_F^C$. This Fisher information, distinct from its statistical counterpart, measures inherent uncertainties in deterministic systems, such as sensitivity to initial conditions, and is related to the phase space curvature and the net stretching action of the state space evolution. We hypothesize that if a PINN accurately learns the underlying dynamics of a physical system, then the Fisher information landscape derived from the PINN's learned equations of motion will closely match that of the original analytical model. This match would signify that the PINN has achieved comprehensive fidelity capturing not only the state evolution but also crucial geometric and stability properties. We outline an experimental methodology using the dynamical model of a car to compute and compare $g_F^C$ for both the analytical model and a trained PINN. The comparison, based on the Jacobians of the respective system dynamics, provides a quantitative measure of the PINN's fidelity in representing the system's intricate dynamical characteristics.

</details>


### [762] [Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach](https://arxiv.org/abs/2601.11883)
*Chaoqi Jia,Longkun Guo,Kewen Liao,Zhigang Lu,Chao Chen,Jason Xue*

Main category: cs.LG

Relevance: 30.0

TL;DR: 该论文提出了一个针对带约束k中心聚类问题的新局部搜索框架，通过转化为支配匹配集问题，实现了最佳可能的2近似比。


<details>
  <summary>Details</summary>
Motivation: 传统k中心问题的最佳近似比为2，任何改进都会导致P=NP。在现实应用中，聚类通常需要结合实例级别的"不能链接"和"必须链接"约束作为背景知识。虽然一般CL约束会显著增加近似难度，但之前研究表明不相交的CL集合允许常数因子近似。然而，局部搜索算法是否能在此设置下达到这样的保证仍然是一个开放问题。

Method: 提出了一种基于支配匹配集问题转换的新型局部搜索框架。通过将带约束的k中心聚类问题转化为图论中的支配匹配集问题，设计局部搜索算法来寻找近似最优解。

Result: 算法实现了最佳可能的2近似比，在真实世界和合成数据集上的实验结果表明，该算法在解质量上优于基线方法。

Conclusion: 该工作为带约束k中心聚类问题提供了一个理论保证最优的局部搜索框架，解决了该领域的一个开放问题，并在实践中表现出优越性能。

Abstract: Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - ε would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.

</details>


### [763] [From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs](https://arxiv.org/abs/2601.11890)
*Xihe Gu,Urbashi Mitra,Tara Javidi*

Main category: cs.LG

Relevance: 30.0

TL;DR: 该论文提出了一种基于加权凹覆盖目标U_ρ的主动探索策略，用于无奖励MDP中的目标探索，统一了多种现有覆盖目标，并通过梯度算法引导占用分布实现期望的覆盖模式。


<details>
  <summary>Details</summary>
Motivation: 在无奖励马尔可夫决策过程中，不同状态-动作对具有不同的重要性或难度，需要主动且明确地构建控制探索策略。现有方法缺乏统一的框架来平衡探索的优先级。

Method: 提出参数化凹覆盖目标族U_ρ，定义在状态-动作占用测度上，统一了基于散度的边缘匹配、加权平均覆盖和最坏情况覆盖等目标。利用U_ρ的凹性和梯度闭式解，开发梯度算法主动引导占用分布。

Result: U_ρ框架统一了多种覆盖目标，梯度算法能够有效引导探索策略。当ρ增大时，探索策略越来越强调最少探索的状态-动作对，在极限情况下恢复最坏情况覆盖行为。

Conclusion: 提出的加权凹覆盖目标族为无奖励MDP中的主动探索提供了统一框架，通过参数ρ控制探索优先级，梯度算法能够有效实现期望的覆盖模式。

Abstract: Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_ρ$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_ρ$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_ρ$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $ρ$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.

</details>


### [764] [A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining](https://arxiv.org/abs/2601.12751)
*Manjish Pal*

Main category: cs.LG

Relevance: 30.0

TL;DR: 本文提出了一种基于布尔函数理论的图神经网络表达能力新框架，引入子群体布尔同构(SBI)概念，超越了现有表达能力度量方法，并设计了处理高复杂度布尔函数定义子群体的公平性算法。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络表达能力分析框架（如Weisfeiler-Lehman、双连通性、同态等）无法精细分析GNN捕捉复杂子群体结构的能力，特别是在公平性场景下处理由高复杂度布尔函数定义的子群体时存在局限。

Method: 基于布尔函数理论建立表达能力框架，引入子群体布尔同构(SBI)作为表达能力度量，识别傅里叶度、电路类(AC⁰、NC¹)和影响力作为表达能力关键障碍，设计基于电路遍历的公平性算法处理高复杂度布尔函数定义的子群体。

Result: 在真实世界图数据上的实验表明，该方法在现有方法失败的交叉子群体上实现了较低的公平性差距，首次为公平性量身定制了GNN表达能力的原理性处理方法。

Conclusion: 提出的布尔函数理论框架为分析GNN表达能力提供了更精细的工具，特别是在公平性场景下，能够处理现有方法无法处理的高复杂度子群体定义，为公平性感知的GNN设计提供了理论基础和实用算法。

Abstract: We propose a novel expressivity framework for Graph Neural Networks (GNNs) grounded in Boolean function theory, enabling a fine-grained analysis of their ability to capture complex subpopulation structures. We introduce the notion of \textit{Subpopulation Boolean Isomorphism} (SBI) as an invariant that strictly subsumes existing expressivity measures such as Weisfeiler-Lehman (WL), biconnectivity-based, and homomorphism-based frameworks. Our theoretical results identify Fourier degree, circuit class (AC$^0$, NC$^1$), and influence as key barriers to expressivity in fairness-aware GNNs. We design a circuit-traversal-based fairness algorithm capable of handling subpopulations defined by high-complexity Boolean functions, such as parity, which break existing baselines. Experiments on real-world graphs show that our method achieves low fairness gaps across intersectional groups where state-of-the-art methods fail, providing the first principled treatment of GNN expressivity tailored to fairness.

</details>


### [765] [Architecture-Optimization Co-Design for Physics-Informed Neural Networks Via Attentive Representations and Conflict-Resolved Gradients](https://arxiv.org/abs/2601.12971)
*Pancheng Niu,Jun Guo,Qiaolin He,Yongming Chen,Yanchao Shi*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了ACR-PINN，一种结合层动态注意力机制和梯度冲突解决策略的PINN架构-优化协同设计方法，显著提升了PINN求解PDE的性能。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在求解偏微分方程时面临表示能力有限和优化困难的问题，特别是物理约束竞争和梯度冲突导致的训练困难。

Method: 1. 提出层动态注意力机制(LDA-PINN)增强表示灵活性；2. 将PINN训练重构为多任务学习问题，引入梯度冲突解决策略(GC-PINN)；3. 整合两者形成ACR-PINN，保持标准PINN损失形式。

Result: 在Burgers、Helmholtz、Klein-Gordon和腔流等基准PDE问题上，ACR-PINN相比标准PINNs实现了更快的收敛速度和显著更低的相对L2和L∞误差。

Conclusion: 架构-优化协同设计能有效提升PINN求解器的鲁棒性和准确性，为解决PINN训练中的表示和优化问题提供了新思路。

Abstract: Physics-Informed Neural Networks (PINNs) provide a learning-based framework for solving partial differential equations (PDEs) by embedding governing physical laws into neural network training. In practice, however, their performance is often hindered by limited representational capacity and optimization difficulties caused by competing physical constraints and conflicting gradients. In this work, we study PINN training from a unified architecture-optimization perspective. We first propose a layer-wise dynamic attention mechanism to enhance representational flexibility, resulting in the Layer-wise Dynamic Attention PINN (LDA-PINN). We then reformulate PINN training as a multi-task learning problem and introduce a conflict-resolved gradient update strategy to alleviate gradient interference, leading to the Gradient-Conflict-Resolved PINN (GC-PINN). By integrating these two components, we develop the Architecture-Conflict-Resolved PINN (ACR-PINN), which combines attentive representations with conflict-aware optimization while preserving the standard PINN loss formulation. Extensive experiments on benchmark PDEs, including the Burgers, Helmholtz, Klein-Gordon, and lid-driven cavity flow problems, demonstrate that ACR-PINN achieves faster convergence and significantly lower relative $L_2$ and $L_\infty$ errors than standard PINNs. These results highlight the effectiveness of architecture-optimization co-design for improving the robustness and accuracy of PINN-based solvers.

</details>


### [766] [Quadratic Upper Bound for Boosting Robustness](https://arxiv.org/abs/2601.13645)
*Euijin You,Hyang-Won Lee*

Main category: cs.LG

Relevance: 30.0

TL;DR: 本文提出了一种二次上界损失函数来改善快速对抗训练中的鲁棒性下降问题，通过平滑损失景观提升模型对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 快速对抗训练虽然能减少训练时间，但常常因为对抗空间探索不足而导致鲁棒性下降。本文旨在解决FAT中鲁棒性退化的问题。

Method: 推导了对抗训练损失函数的二次上界，并将该上界损失与现有FAT方法结合使用。

Result: 实验结果表明，将QUB损失应用于现有方法能显著提升鲁棒性。通过多种指标分析，这种改进可能源于所得模型损失景观的平滑化。

Conclusion: 提出的二次上界损失函数能有效改善快速对抗训练中的鲁棒性问题，通过平滑损失景观提升模型对抗攻击的防御能力。

Abstract: Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.

</details>


### [767] [Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks](https://arxiv.org/abs/2601.13776)
*Thibaut Boissin,Franck Mamalet,Valentin Lafargue,Mathieu Serrurier*

Main category: cs.LG

Relevance: 30.0

TL;DR: Orthogonium是一个统一的PyTorch库，提供正交和1-Lipschitz神经网络层，用于构建鲁棒的深度学习架构，支持标准卷积特性并保持严格数学保证。


<details>
  <summary>Details</summary>
Motivation: 正交和1-Lipschitz神经网络层对于认证对抗鲁棒性、稳定生成模型和可靠循环网络至关重要，但现有实现分散、有限且计算成本高，需要统一高效的解决方案。

Method: 开发了Orthogonium库，提供正交和1-Lipschitz层的优化实现，支持标准卷积特性（步长、膨胀、分组、转置），同时保持严格数学保证，并通过严格测试确保可靠性。

Result: 该库在ImageNet等大规模基准测试中减少了开销，发现了现有实现中的关键错误，显著降低了采用门槛，支持可扩展的实验和集成。

Conclusion: Orthogonium为需要正交性和鲁棒Lipschitz约束的多样化应用提供了标准化、可靠的工具，促进了鲁棒深度学习架构的发展。

Abstract: Orthogonal and 1-Lipschitz neural network layers are essential building blocks in robust deep learning architectures, crucial for certified adversarial robustness, stable generative models, and reliable recurrent networks. Despite significant advancements, existing implementations remain fragmented, limited, and computationally demanding. To address these issues, we introduce Orthogonium , a unified, efficient, and comprehensive PyTorch library providing orthogonal and 1-Lipschitz layers. Orthogonium provides access to standard convolution features-including support for strides, dilation, grouping, and transposed-while maintaining strict mathematical guarantees. Its optimized implementations reduce overhead on large scale benchmarks such as ImageNet. Moreover, rigorous testing within the library has uncovered critical errors in existing implementations, emphasizing the importance of standardized and reliable tools. Orthogonium thus significantly lowers adoption barriers, enabling scalable experimentation and integration across diverse applications requiring orthogonality and robust Lipschitz constraints. Orthogonium is available at https://github.com/deel-ai/orthogonium.

</details>


### [768] [Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping](https://arxiv.org/abs/2601.14099)
*Shi-Shun Chen,Xiao-Yang Li,Enrico Zio*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出基于时滞交叉映射的因果特征选择框架，解决工业过程中变量间时滞因果和相互依赖问题，提升软测量模型性能


<details>
  <summary>Details</summary>
Motivation: 现有因果特征选择方法忽略工业过程两个关键特性：1) 变量间因果关系存在时滞，而现有方法在同一时间维度分析；2) 工业过程变量相互依赖，与传统因果推断的去相关假设矛盾。这导致基于现有方法的软测量模型精度和稳定性不足。

Method: 提出基于时滞交叉映射的因果特征选择框架：1) 使用时滞收敛交叉映射(TDCCM)进行总因果推断；2) 使用时滞偏交叉映射(TDPCM)进行直接因果推断；3) 基于验证集模型性能自动确定因果阈值，实现自动特征选择。

Result: 两个真实案例研究表明：TDCCM达到最高平均性能，TDPCM在最差情况下提升软测量稳定性和性能。

Conclusion: 提出的时滞交叉映射框架能有效处理工业过程中的时滞因果和变量相互依赖问题，提升软测量模型的准确性和稳定性。

Abstract: Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.

</details>


### [769] [HERMES: A Unified Open-Source Framework for Realtime Multimodal Physiological Sensing, Edge AI, and Intervention in Closed-Loop Smart Healthcare Applications](https://arxiv.org/abs/2601.12610)
*Maxim Yudayev,Juha Carlon,Diwas Lamsal,Vayalet Stefanova,Benjamin Filtjens*

Main category: eess.SY

Relevance: 30.0

TL;DR: HERMES是一个开源高性能Python框架，用于边缘设备的连续多模态感知和AI处理，支持同步数据收集和实时流式推理，适用于智能医疗应用。


<details>
  <summary>Details</summary>
Motivation: 智能辅助技术对于残疾人和老年人至关重要，但现有系统面临多模态感知处理、实时闭环AI方法、异构数据流处理等挑战，需要可靠的高通量解决方案来加速临床部署。

Method: 开发了HERMES开源框架，支持在商用计算设备上进行同步数据收集和实时流式推理，使用用户自定义的PyTorch模型，适用于固定实验室和自由生活环境。

Result: 在智能假肢闭环控制用例中验证，4个同步主机协同捕获18个可穿戴和体外模态，展示了HERMES的性能和与智能医疗领域的相关性。

Conclusion: HERMES是首个提供整体方法论的框架，弥合了跨学科实施策略的差距，指导下游AI模型开发，加速智能医疗应用的临床部署。

Abstract: Intelligent assistive technologies are increasingly recognized as critical daily-use enablers for people with disabilities and age-related functional decline. Longitudinal studies, curation of quality datasets, live monitoring in activities of daily living, and intelligent intervention devices, share the largely unsolved need in reliable high-throughput multimodal sensing and processing. Streaming large heterogeneous data from distributed sensors, historically closed-source environments, and limited prior works on realtime closed-loop AI methodologies, inhibit such applications. To accelerate the emergence of clinical deployments, we deliver HERMES - an open-source high-performance Python framework for continuous multimodal sensing and AI processing at the edge. It enables synchronized data collection, and realtime streaming inference with user PyTorch models, on commodity computing devices. HERMES is applicable to fixed-lab and free-living environments, of distributed commercial and custom sensors. It is the first work to offer a holistic methodology that bridges cross-disciplinary gaps in real-world implementation strategies, and guides downstream AI model development. Its application on the closed-loop intelligent prosthesis use case illustrates the process of suitable AI model development from the generated constraints and trade-offs. Validation on the use case, with 4 synchronized hosts cooperatively capturing 18 wearable and off-body modalities, demonstrates performance and relevance of HERMES to the trajectory of the intelligent healthcare domain.

</details>


### [770] [Scaling laws for amplitude surrogates](https://arxiv.org/abs/2601.13308)
*Henning Bahl,Victor Bresó-Pla,Anja Butter,Joaquín Iturriza Ramirez*

Main category: hep-ph

Relevance: 30.0

TL;DR: 该论文研究了粒子物理学中振幅替代模型的缩放规律，发现缩放系数与过程的外部粒子数量相关，证明缩放规律是实现精度目标的有用工具。


<details>
  <summary>Details</summary>
Motivation: 缩放规律在机器学习领域广泛存在，但尚未在粒子物理学的振幅替代模型中进行系统研究。作者希望探索这些规律在粒子物理背景下的表现，以指导模型训练和资源分配。

Method: 系统研究了振幅替代模型中训练数据量、计算资源和网络规模对性能的影响，分析了缩放系数与外部粒子数量的关系。

Result: 发现缩放系数与过程的外部粒子数量相关，证明缩放规律可以帮助确定实现特定精度目标所需的数据和计算资源。

Conclusion: 缩放规律在粒子物理学的振幅替代模型中同样适用，可作为实现精度目标的有效工具，为资源分配提供指导。

Abstract: Scaling laws describing the dependence of neural network performance on the amount of training data, the spent compute, and the network size have emerged across a huge variety of machine learning task and datasets. In this work, we systematically investigate these scaling laws in the context of amplitude surrogates for particle physics. We show that the scaling coefficients are connected to the number of external particles of the process. Our results demonstrate that scaling laws are a useful tool to achieve desired precision targets.

</details>


### [771] [Device Association and Resource Allocation for Hierarchical Split Federated Learning in Space-Air-Ground Integrated Network](https://arxiv.org/abs/2601.13817)
*Haitao Zhao,Xiaoyu Tang,Bo Xu,Jinlong Sun,Linghao Zhang*

Main category: cs.DC

Relevance: 30.0

TL;DR: 本文提出了一种用于6G天地一体化网络的层次化分割联邦学习框架，通过联合优化设备关联、模型分割层选择和资源分配来平衡训练效率和模型精度。


<details>
  <summary>Details</summary>
Motivation: 6G促进了联邦学习在天地一体化网络中的部署，但面临资源受限和数据分布不平衡的挑战。现有方法在训练效率和模型精度之间难以取得平衡。

Method: 提出层次化分割联邦学习框架，推导损失函数上界。将联合优化问题分解为多个子问题，提出基于暴力搜索分割点的迭代优化算法，优化设备关联和资源分配。

Result: 仿真结果表明，所提算法能有效平衡天地一体化网络中联邦学习的训练效率和模型精度。

Conclusion: 层次化分割联邦学习框架和优化算法能有效解决6G天地一体化网络中联邦学习的资源约束和数据不平衡问题。

Abstract: 6G facilitates deployment of Federated Learning (FL) in the Space-Air-Ground Integrated Network (SAGIN), yet FL confronts challenges such as resource constrained and unbalanced data distribution. To address these issues, this paper proposes a Hierarchical Split Federated Learning (HSFL) framework and derives its upper bound of loss function. To minimize the weighted sum of training loss and latency, we formulate a joint optimization problem that integrates device association, model split layer selection, and resource allocation. We decompose the original problem into several subproblems, where an iterative optimization algorithm for device association and resource allocation based on brute-force split point search is proposed. Simulation results demonstrate that the proposed algorithm can effectively balance training efficiency and model accuracy for FL in SAGIN.

</details>


### [772] [Intermittent time series forecasting: local vs global models](https://arxiv.org/abs/2601.14031)
*Stefano Damato,Nicolò Rubattu,Dario Azzimonti,Giorgio Corani*

Main category: stat.ML

Relevance: 30.0

TL;DR: 首次系统比较局部模型(iETS, TweedieGP)和全局模型(D-Linear, DeepAR, Transformers)在间歇性时间序列预测上的表现，发现D-Linear在神经网络模型中表现最佳，且优于局部模型


<details>
  <summary>Details</summary>
Motivation: 间歇性时间序列（包含大量零值）在供应链库存管理中广泛存在，需要概率预测来规划库存水平。虽然全局模型在时间序列预测中越来越流行，但尚未在间歇性时间序列上得到充分测试

Method: 比较了最先进的局部模型(iETS, TweedieGP)和全局模型(D-Linear, DeepAR, Transformers)。对于神经网络模型，考虑了三种适合间歇性时间序列的分布头：负二项分布、障碍移位负二项分布和Tweedie分布。在包含超过40,000个真实世界时间序列的五个大型数据集上进行实验

Result: 在神经网络模型中，D-Linear提供最佳准确性，且始终优于局部模型，同时计算需求较低。基于Transformer的架构计算需求更高且准确性较差。在分布头中，Tweedie对最高分位数估计最佳，而负二项分布整体性能最好

Conclusion: D-Linear是间歇性时间序列预测的有效选择，结合负二项分布头可获得良好性能。该研究填补了全局模型在间歇性时间序列评估方面的空白

Abstract: Intermittent time series, characterised by the presence of a significant amount of zeros, constitute a large percentage of inventory items in supply chain. Probabilistic forecasts are needed to plan the inventory levels; the predictive distribution should cover non-negative values, have a mass in zero and a long upper tail. Intermittent time series are commonly forecast using local models, which are trained individually on each time series. In the last years global models, which are trained on a large collection of time series, have become popular for time series forecasting. Global models are often based on neural networks. However, they have not yet been exhaustively tested on intermittent time series. We carry out the first study comparing state-of-the-art local (iETS, TweedieGP) and global models (D-Linear, DeepAR, Transformers) on intermittent time series. For neural networks models we consider three different distribution heads suitable for intermittent time series: negative binomial, hurdle-shifted negative binomial and Tweedie. We use, for the first time, the last two distribution heads with neural networks. We perform experiments on five large datasets comprising more than 40'000 real-world time series. Among neural networks D-Linear provides best accuracy; it also consistently outperforms the local models. Moreover, it has also low computational requirements. Transformers-based architectures are instead much more computationally demanding and less accurate. Among the distribution heads, the Tweedie provides the best estimates of the highest quantiles, while the negative binomial offers overall the best performance.

</details>


### [773] [Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home](https://arxiv.org/abs/2601.11611)
*Marina Vicini,Martin Rudorfer,Zhuangzhuang Dai,Luis J. Manso*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该论文提出了一种改进的基于被动传感器的人类活动识别方法，通过聚类活动到不同时间段并编码到特征加权中，同时加入循环时间特征和用户位置特征，在多个真实数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，需要让老年人能够独立安全地在家中生活。使用被动红外传感器和门传感器等普遍存在的传感器来监测日常活动并促进预防性医疗干预变得越来越重要。现有的人类活动识别方法主要依赖传统机器学习，虽然SWMI等方法能够捕捉空间上下文，但有效利用时间信息仍然是一个挑战。

Method: 1. 将活动聚类到早晨、下午和夜晚三个时间段；2. 将这些时间信息编码到特征加权方法中，计算不同的互信息矩阵；3. 扩展特征向量，加入一天中的时间和一周中的天数作为循环时间特征；4. 添加跟踪用户位置的特征。

Result: 在四个真实世界数据集中的三个上，该方法在准确率和F1分数上优于现有最先进方法，在数据量较少的情况下提升最为显著。

Conclusion: 该方法展示了开发有效智能家居解决方案以支持老年人居家养老的潜力，特别是在时间信息利用方面的改进显著提升了人类活动识别性能。

Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.

</details>


### [774] [A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia](https://arxiv.org/abs/2601.11615)
*Beyza Cinar,Louisa van den Boom,Maria Maleshkova*

Main category: cs.LG

Relevance: 25.0

TL;DR: 这篇综述论文分析了基于连续血糖监测数据的机器学习模型在1型糖尿病低血糖预测中的应用，比较了不同预测时间窗口下模型的性能表现。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病患者需要终身胰岛素治疗，但胰岛素治疗可能导致低血糖，这是一种危及生命的状况。机器学习模型可以通过预测低血糖事件来改善糖尿病管理，但目前缺乏对不同预测时间窗口和模型性能的系统比较。

Method: 对基于连续血糖监测数据的机器学习模型进行系统性综述，比较回归模型（预测血糖值）和分类模型（识别低血糖事件）在短期（15-120分钟）和长期（3-24小时以上）预测时间窗口的性能。

Result: 1) 1小时内的预测时间窗口效果最佳；2) 传统机器学习方法在分类任务中表现最好，深度学习在回归任务中表现最好；3) 多变量数据集和输入序列长度影响模型性能；4) 个性化数据能提升性能，但由于数据质量问题，基于人群的模型更受青睐。

Conclusion: 机器学习模型在1型糖尿病低血糖预测中具有应用潜力，但需要根据具体预测时间窗口选择合适的模型类型。个性化模型虽然理论上更优，但受限于数据质量，目前基于人群的模型更为实用。

Abstract: Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.

</details>


### [775] [Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits](https://arxiv.org/abs/2601.11924)
*Ming Shi*

Main category: cs.LG

Relevance: 25.0

TL;DR: 研究合作式随机多臂老虎机问题，考虑向量值奖励、对抗性腐败和有限验证。主要贡献是揭示了通信协议与腐败效应之间的耦合关系：固定的环境侧腐败预算Γ可能转化为从Γ到NΓ的有效腐败水平，取决于代理共享原始样本、充分统计量还是仅共享臂推荐。


<details>
  <summary>Details</summary>
Motivation: 在多智能体协作环境中，当存在对抗性腐败和有限验证时，如何设计有效的通信协议来最小化团队遗憾。研究通信方式如何影响腐败效应的放大或缩小，以及验证机制如何恢复可学习性。

Method: 提出通信-腐败耦合框架，通过协议诱导的多重性函数量化不同通信协议下的有效腐败水平。分析三种通信模式：原始样本共享、统计量共享和仅推荐共享。建立遗憾界限参数化于有效腐败水平，并研究验证机制的作用。

Result: 发现原始样本共享可能导致N倍的腐败惩罚放大，而统计量共享和仅推荐共享能保持O(Γ)的未放大腐败项，达到中心化速率的团队遗憾。建立了信息论下界，包括不可避免的Ω(Γ)惩罚，以及在Γ=Θ(NT)的高腐败区域，没有干净信息时无法实现次线性遗憾。验证机制在超过识别阈值后能恢复可学习性。

Conclusion: 通信协议设计对多智能体协作中的腐败鲁棒性至关重要。统计量共享和仅推荐共享优于原始样本共享，能避免腐败放大。在高腐败区域，验证是必要的，且一旦超过识别阈值，认证共享能使团队遗憾独立于Γ。

Abstract: We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.

</details>


### [776] [Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses](https://arxiv.org/abs/2601.12178)
*Fallou Niakh*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出一个联邦学习框架，用于校准可再生能源生产损失下的参数化保险指数，在保护数据隐私的同时处理异质性。


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源生产损失参数化保险中的异质性问题，同时保护生产者的私有数据隐私，避免共享原始观测数据。

Method: 使用联邦学习框架，生产者本地使用Tweedie广义线性模型建模损失，通过联邦优化学习共同指数，比较FedAvg、FedProx和FedOpt算法。

Result: 在德国太阳能发电的实证应用中，联邦学习在适度异质性下恢复可比较的指数系数，提供更通用和可扩展的框架。

Conclusion: 联邦学习为参数化保险指数校准提供了有效的隐私保护解决方案，能够处理异质性并保持模型性能。

Abstract: We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.

</details>


### [777] [Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention](https://arxiv.org/abs/2601.12231)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Shijie Xu,Guanggang Geng*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出一个用于企业内部威胁检测的新框架，结合小波感知调制、多分辨率小波分解和分辨率自适应注意力机制，在CERT r4.2基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 企业内部威胁检测面临多通道、非平稳的用户活动日志数据，且异常事件稀少，传统异常检测方法难以有效处理这些复杂的行为模式。

Method: 1) 偏差感知调制方案抑制常规行为并放大异常偏差；2) 离散小波变换将日志信号分解为多分辨率表示；3) 可学习的注意力机制动态重新加权最具区分性的频带。

Result: 在CERT r4.2基准测试中，该方法在不同时间粒度和场景下，在精确率、召回率和F1分数方面均优于现有基线方法。

Conclusion: 该框架通过结合小波分析和自适应注意力机制，有效解决了企业内部威胁检测中的多通道、非平稳数据问题，提高了异常检测性能。

Abstract: Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.

</details>


### [778] [IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning](https://arxiv.org/abs/2601.12330)
*Zuha Fatima,Muhammad Anser Sohaib,Muhammad Talha,Ayesha Kanwal,Sidra Sultana,Nazia Perwaiz*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出IceWatch深度学习框架，结合空间和时间视角预测冰川湖溃决洪水(GLOFs)，包含视觉组件RiskFlow分析卫星影像，以及表格组件TerraFlow和TempFlow建模冰川速度和温度动态


<details>
  <summary>Details</summary>
Motivation: 传统GLOF检测方法依赖水文建模、阈值监测和人工卫星图像分析，存在更新慢、依赖人工、云层干扰和现场数据缺失等问题，需要更自动化和准确的预测系统

Method: IceWatch框架包含：1) RiskFlow：基于CNN的Sentinel-2多光谱卫星图像分类器，分析冰雪融水空间模式；2) TerraFlow：基于NASA ITS_LIVE时间序列建模冰川速度；3) TempFlow：基于MODIS LST记录预测近地表温度；通过协调预处理和同步实现多模态物理信息融合

Result: 系统提供强大的预测性能、实时数据处理能力，对噪声和缺失信息具有鲁棒性，通过交叉验证提高GLOF检测的可靠性和可解释性

Conclusion: IceWatch为自动、可扩展的GLOF预警系统铺平道路，具有与多种传感器输入和全球冰川监测活动集成的潜力

Abstract: Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.

</details>


### [779] [Machine Learning-Based Framework for Real Time Detection and Early Prediction of Control Valve Stiction in Industrial Control Systems](https://arxiv.org/abs/2601.12362)
*Natthapong Promsricha,Chotirawee Chatpattanasiri,Nuttavut Kerdgongsup,Stavroula Balabani*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该研究提出了一种基于机器学习的控制阀粘滞故障检测与预测框架，使用常规过程信号（控制器输出OP和过程变量PV），通过三种深度学习模型（CNN、CNN-SVM、LSTM）进行预测，其中LSTM模型表现最佳，能提前4小时预测粘滞故障。


<details>
  <summary>Details</summary>
Motivation: 控制阀粘滞是工业过程中的常见故障，会导致系统不稳定、设备磨损和维护成本增加。许多工厂仍使用缺乏实时监控的传统阀门，使得早期预测困难。需要一种基于常规过程信号的自动化检测方法。

Method: 开发了三种深度学习模型：CNN、CNN-SVM混合模型和LSTM网络。采用基于斜率比分析的数据驱动标注方法，在真实的油气炼厂数据集上进行训练。仅使用控制器输出（OP）和过程变量（PV）等常规过程信号。

Result: LSTM模型取得了最高准确率，能够提前4小时预测控制阀粘滞故障。这是首个基于真实工业数据展示机器学习早期预测控制阀粘滞的研究。

Conclusion: 提出的框架可以集成到现有控制系统中，支持预测性维护，减少停机时间，避免不必要的硬件更换。为工业过程故障预测提供了实用的机器学习解决方案。

Abstract: Control valve stiction, a friction that prevents smooth valve movement, is a common fault in industrial process systems that causes instability, equipment wear, and higher maintenance costs. Many plants still operate with conventional valves that lack real time monitoring, making early predictions challenging. This study presents a machine learning (ML) framework for detecting and predicting stiction using only routinely collected process signals: the controller output (OP) from control systems and the process variable (PV), such as flow rate. Three deep learning models were developed and compared: a Convolutional Neural Network (CNN), a hybrid CNN with a Support Vector Machine (CNN-SVM), and a Long Short-Term Memory (LSTM) network. To train these models, a data-driven labeling method based on slope ratio analysis was applied to a real oil and gas refinery dataset. The LSTM model achieved the highest accuracy and was able to predict stiction up to four hours in advance. To the best of the authors' knowledge, this is the first study to demonstrate ML based early prediction of control valve stiction from real industry data. The proposed framework can be integrated into existing control systems to support predictive maintenance, reduce downtime, and avoid unnecessary hardware replacement.

</details>


### [780] [Approximating splits for decision trees quickly in sparse data streams](https://arxiv.org/abs/2601.12525)
*Nikolaj Tatti*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出一种针对稀疏二元特征和二元分类的决策树流式学习算法，能在近似最优信息增益或基尼指数下，实现比传统O(d)时间更快的分裂点搜索。


<details>
  <summary>Details</summary>
Motivation: 决策树是流行的分类器，流式学习算法需要高效处理数据流。传统方法在稀疏二元特征场景下，寻找最优分裂点需要O(d)时间（d为特征数），对于稀疏数据（m≪d）效率不高。需要设计更快的近似算法。

Method: 针对稀疏二元特征和二元分类问题，提出近似算法：1）对于条件熵，实现(1+α)近似，摊销时间复杂度O(α^{-1}(1+m log d) log log n)；2）对于基尼指数，实现(1+α)近似，摊销时间复杂度O(α^{-1}+m log d)。利用稀疏性（m为数据点中1的数量）加速搜索。

Result: 实验表明，算法能高效找到近似最优分裂点，比基线方法更快，且实际性能优于理论近似保证。在稀疏数据场景下表现优异。

Conclusion: 提出的算法显著加速了稀疏二元特征决策树流式学习中的分裂点搜索，为实际应用提供了高效解决方案。

Abstract: Decision trees are one of the most popular classifiers in the machine learning literature. While the most common decision tree learning algorithms treat data as a batch, numerous algorithms have been proposed to construct decision trees from a data stream. A standard training strategy involves augmenting the current tree by changing a leaf node into a split. Here we typically maintain counters in each leaf which allow us to determine the optimal split, and whether the split should be done. In this paper we focus on how to speed up the search for the optimal split when dealing with sparse binary features and a binary class. We focus on finding splits that have the approximately optimal information gain or Gini index. In both cases finding the optimal split can be done in $O(d)$ time, where $d$ is the number of features. We propose an algorithm that yields $(1 + α)$ approximation when using conditional entropy in amortized $O(α^{-1}(1 + m\log d) \log \log n)$ time, where $m$ is the number of 1s in a data point, and $n$ is the number of data points. Similarly, for Gini index, we achieve $(1 + α)$ approximation in amortized $O(α^{-1} + m \log d)$ time. Our approach is beneficial for sparse data where $m \ll d$. In our experiments we find almost-optimal splits efficiently, faster than the baseline, overperforming the theoretical approximation guarantees.

</details>


### [781] [What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes](https://arxiv.org/abs/2601.12612)
*Piyush Sao*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出一种基于矩阵迹幂计算对数行列式的新方法，通过矩生成函数变换和插值技术，在常数时间内提供对数行列式的点估计和可证明的上下界。


<details>
  <summary>Details</summary>
Motivation: 高斯过程推断和贝叶斯模型比较中需要计算大型对称正定矩阵的对数行列式。传统方法结合矩阵向量乘积和多项式逼近，但本文研究当矩阵幂可用时，通过迹幂计算对数行列式的替代方法。

Method: 1. 将问题转化为估计矩生成函数M(t)在t=0处的导数；2. 通过变换K(t)=log M(t)压缩数值范围；3. 在m+1个连续整数点插值K(t)并估计K'(0)；4. 从相同迹信息推导出对数行列式的上下界；5. 提供间隙诊断指标判断点估计的可靠性。

Result: 方法在O(m)时间内计算对数行列式，对于m∈{4,...,8}基本是常数时间。证明了使用有限正矩的连续估计器无法在无界条件数下保持均匀精度，因此提供了可证明的上下界。

Conclusion: 提出了一种基于迹幂计算对数行列式的高效方法，通过矩生成函数变换和插值技术，在常数时间内提供点估计和可证明的上下界，解决了传统方法在条件数较大时发散的问题。

Abstract: Computing $\log\det(A)$ for large symmetric positive definite matrices arises in Gaussian process inference and Bayesian model comparison. Standard methods combine matrix-vector products with polynomial approximations. We study a different model: access to trace powers $p_k = \tr(A^k)$, natural when matrix powers are available.
  Classical moment-based approximations Taylor-expand $\log(λ)$ around the arithmetic mean. This requires $|λ- \AM| < \AM$ and diverges when $κ> 4$. We work instead with the moment-generating function $M(t) = \E[X^t]$ for normalized eigenvalues $X = λ/\AM$. Since $M'(0) = \E[\log X]$, the log-determinant becomes $\log\det(A) = n(\log \AM + M'(0))$ -- the problem reduces to estimating a derivative at $t = 0$. Trace powers give $M(k)$ at positive integers, but interpolating $M(t)$ directly is ill-conditioned due to exponential growth. The transform $K(t) = \log M(t)$ compresses this range. Normalization by $\AM$ ensures $K(0) = K(1) = 0$. With these anchors fixed, we interpolate $K$ through $m+1$ consecutive integers and differentiate to estimate $K'(0)$. However, this local interpolation cannot capture arbitrary spectral features.
  We prove a fundamental limit: no continuous estimator using finitely many positive moments can be uniformly accurate over unbounded conditioning. Positive moments downweight the spectral tail; $K'(0) = \E[\log X]$ is tail-sensitive. This motivates guaranteed bounds. From the same traces we derive upper bounds on $(\det A)^{1/n}$. Given a spectral floor $r \leq λ_{\min}$, we obtain moment-constrained lower bounds, yielding a provable interval for $\log\det(A)$. A gap diagnostic indicates when to trust the point estimate and when to report bounds. All estimators and bounds cost $O(m)$, independent of $n$. For $m \in \{4, \ldots, 8\}$, this is effectively constant time.

</details>


### [782] [Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks](https://arxiv.org/abs/2601.12662)
*Xingran Chen,Navid NaderiAlizadeh,Alejandro Ribeiro,Shirin Saeedi Bidokhti*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出基于图的多智能体强化学习框架，用于优化多跳无线网络中自回归马尔可夫源的实时采样和估计策略，该策略具有可迁移性并能处理非平稳性。


<details>
  <summary>Details</summary>
Motivation: 在多跳无线网络中，节点通过无线碰撞信道通信并缓存其他节点的样本，目标是最小化时间平均估计误差。由于动作空间维度高、网络拓扑复杂，传统分析方法难以推导最优策略。

Method: 提出图多智能体强化学习框架进行策略优化。使用独立学习和集中训练分散执行的方法，并强调循环机制在增强非平稳性鲁棒性中的关键作用。

Result: 1) 提出的策略优于现有基线方法；2) 训练的策略可迁移到更大网络，性能增益随智能体数量增加而增加；3) 图训练过程能承受非平稳性；4) 循环机制对独立学习和集中训练分散执行都至关重要。

Conclusion: 图多智能体强化学习框架能有效解决复杂网络中的分布式估计问题，提出的策略具有可迁移性和非平稳性鲁棒性，循环机制是关键设计要素。

Abstract: We address real-time sampling and estimation of autoregressive Markovian sources in dynamic yet structurally similar multi-hop wireless networks. Each node caches samples from others and communicates over wireless collision channels, aiming to minimize time-average estimation error via decentralized policies. Due to the high dimensionality of action spaces and complexity of network topologies, deriving optimal policies analytically is intractable. To address this, we propose a graphical multi-agent reinforcement learning framework for policy optimization. Theoretically, we demonstrate that our proposed policies are transferable, allowing a policy trained on one graph to be effectively applied to structurally similar graphs. Numerical experiments demonstrate that (i) our proposed policy outperforms state-of-the-art baselines; (ii) the trained policies are transferable to larger networks, with performance gains increasing with the number of agents; (iii) the graphical training procedure withstands non-stationarity, even when using independent learning techniques; and (iv) recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity.

</details>


### [783] [Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates](https://arxiv.org/abs/2601.12859)
*Luca Schaufelberger,Aline Hartgers,Kjell Jorner*

Main category: cs.LG

Relevance: 25.0

TL;DR: PuckerFlow是一种用于环状分子构象生成的机器学习模型，通过在Cremer-Pople空间进行流匹配，能够高效可靠地生成环状结构的构象。


<details>
  <summary>Details</summary>
Motivation: 环状分子在化学和生物学中普遍存在，其受限的构象柔性提供了结构预组织，对药物发现和催化功能至关重要。然而，可靠地采样环系统的构象集合仍然具有挑战性。

Method: PuckerFlow是一种生成式机器学习模型，在Cremer-Pople空间（一种捕捉环相关自由度的低维内部坐标系）上执行流匹配。这种方法能够通过设计生成有效的闭合环。

Result: PuckerFlow在几乎所有定量指标上都优于其他构象生成方法，能够生成既多样化又精确的构象。特别展示了PuckerFlow在催化和药物发现相关环系统中的潜力。

Conclusion: 这项工作实现了环状结构的高效可靠构象生成，为建模结构-性质关系和跨化学与生物学广泛应用的环状分子性质引导生成铺平了道路。

Abstract: Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.

</details>


### [784] [LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations](https://arxiv.org/abs/2601.13190)
*Vittoria De Pellegrini,Tariq Alkhalifah*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出LAViG-FLOW框架，使用潜在自回归视频生成扩散模型来高效模拟地下多相流体流动场，相比传统数值求解器快几个数量级。


<details>
  <summary>Details</summary>
Motivation: 地质CO2封存和地热生产等应用中，需要建模和预测地下多相流体流动场。传统高保真多相模拟器在需要大量前向运行进行反演和量化不确定性时计算成本过高。

Method: 提出LAViG-FLOW框架：1) 使用专用2D自编码器压缩每个状态变量（饱和度和压力场）；2) 使用视频扩散变换器(VDiT)建模它们在时间上的耦合分布；3) 先在给定时间范围内训练模型学习耦合关系，然后通过自回归微调使其能够外推到观测时间窗口之外。

Result: 在开源CO2封存数据集上评估，LAViG-FLOW生成的饱和度和压力场在时间上保持一致性，同时运行速度比传统数值求解器快几个数量级。

Conclusion: LAViG-FLOW为地下多相流体流动模拟提供了一种高效替代方案，特别适用于需要大量前向运行的应用场景。

Abstract: Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.

</details>


### [785] [CausationEntropy: Pythonic Optimal Causation Entropy](https://arxiv.org/abs/2601.13365)
*Kevin Slote,Jeremie Fish,Erik Bollt*

Main category: cs.LG

Relevance: 25.0

TL;DR: CausationEntropy v1.1是一个Python因果网络建模工具包，实现了最优因果熵(oCSE)算法及其优化扩展，包含多种熵估计器和数据生成工具。


<details>
  <summary>Details</summary>
Motivation: 开发一个易于使用、功能全面的因果发现工具包，用于复杂动力系统中的因果网络建模，区分直接和间接因果路径。

Method: 基于最优因果熵(oCSE)理论，实现多种熵估计方法（高斯、kNN、几何kNN、核密度、泊松），提供合成数据生成和可视化工具。

Result: 发布了CausationEntropy v1.1，包含新的合成数据生成器、绘图工具和多种先进的信息论因果网络发现算法，支持MIT开源许可。

Conclusion: 该工具包为复杂动力系统的因果发现提供了基准工具，具有模块化结构支持未来扩展。

Abstract: Optimal Causation Entropy (oCSE) is a robust causal network modeling technique that reveals causal networks from dynamical systems and coupled oscillators, distinguishing direct from indirect paths. CausationEntropy is a Python package that implements oCSE and several of its significant optimizations and methodological extensions. In this paper, we introduce the version 1.1 release of CausationEntropy, which includes new synthetic data generators, plotting tools, and several advanced information-theoretical causal network discovery algorithms with criteria for estimating Gaussian, k-nearest neighbors (kNN), geometric k-nearest neighbors (geometric-kNN), kernel density (KDE) and Poisson entropic estimators. The package is easy to install from the PyPi software repository, is thoroughly documented, supplemented with extensive code examples, and is modularly structured to support future additions. The entire codebase is released under the MIT license and is available on GitHub and through PyPi Repository. We expect this package to serve as a benchmark tool for causal discovery in complex dynamical systems.

</details>


### [786] [TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction](https://arxiv.org/abs/2601.13422)
*Dahai Yu,Rongchao Xu,Dingyi Zhuang,Yuheng Bu,Shenhao Wang,Guang Wang*

Main category: cs.LG

Relevance: 25.0

TL;DR: TrustEnergy：用于用户级能源使用预测的统一框架，结合分层时空表示和顺序保形分位数回归，提高预测精度和不确定性量化


<details>
  <summary>Details</summary>
Motivation: 能源使用预测对电网管理、基础设施规划和灾害响应等应用很重要。现有方法要么忽视家庭间的空间相关性，要么无法扩展到个体化预测，且缺乏对动态不确定性的量化。

Method: 提出TrustEnergy框架，包含两个关键技术组件：(1) 分层时空表示模块，使用记忆增强的时空图神经网络捕捉宏观和微观能源使用模式；(2) 顺序保形分位数回归模块，动态调整不确定性边界，确保随时间推移的有效预测区间。

Result: 与佛罗里达州电力供应商合作实施评估，TrustEnergy相比最先进基线方法，预测精度提高5.4%，不确定性量化改进5.7%。

Conclusion: TrustEnergy为准确可靠的用户级能源使用预测提供了有效解决方案，通过分层时空建模和动态不确定性量化解决了现有方法的局限性。

Abstract: Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.

</details>


### [787] [PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles](https://arxiv.org/abs/2601.13793)
*ByeoungDo Kim,JunYeop Na,Kyungwook Tak,JunTae Kim,DongHyeon Kim,Duckky Kim*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出ETA模型，利用注意力机制处理历史道路速度模式，用于自动驾驶和智能交通系统中的到达时间估计


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和智能交通系统普及，准确可靠的ETA估计变得至关重要，但传统方法处理复杂交通流动态性不足，深度学习模型计算成本高且未能有效捕捉时空模式

Method: 提出基于注意力机制的ETA模型，利用注意力机制提取和利用沿路线每个时空点累积的时空特征，轻量级架构有效整合道路特征、实时交通条件和历史速度模式

Result: 在真实驾驶数据集上验证，模型优于现有基线，能有效整合道路特征、实时交通条件和历史速度模式

Conclusion: 提出的注意力机制ETA模型能高效准确估计到达时间，模型轻量且可扩展，解决了传统方法在复杂交通流预测中的局限性

Abstract: In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.

</details>


### [788] [TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography](https://arxiv.org/abs/2601.13897)
*Ankita Joshi,Ashutosh Sharma,Anoushkrit Goel,Ranjeet Ranjan Jha,Chirag Ahuja,Arnav Bhavsar,Aditya Nigam*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出TractRLFusion框架，基于GPT策略融合多个强化学习策略，通过两阶段训练数据选择和多critic微调，提升白质纤维束追踪的准确性和解剖可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统白质纤维束追踪方法存在虚假连接问题，现有深度学习和强化学习方法仍有改进空间。需要更准确、可靠的纤维束重建方法，以支持神经外科规划和脑连接研究。

Method: 提出GPT-based policy fusion框架，集成多个RL策略：1) 两阶段训练数据选择用于有效策略融合；2) 多critic微调阶段增强鲁棒性和泛化能力。

Result: 在HCP、ISMRM和TractoInferno数据集上实验表明，TractRLFusion在准确性和解剖可靠性方面优于单个RL策略以及最先进的经典和DRL方法。

Conclusion: TractRLFusion通过策略融合和多critic微调，显著提升了白质纤维束追踪的性能，为神经影像分析提供了更可靠的工具。

Abstract: Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, we propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability.

</details>


### [789] [Penalizing Localized Dirichlet Energies in Low Rank Tensor Products](https://arxiv.org/abs/2601.14173)
*Paris A. Karakasis,Nicholas D. Sidiropoulos*

Main category: cs.LG

Relevance: 25.0

TL;DR: 论文研究低秩张量积B样条模型在回归任务中的应用，探讨狄利克雷能量作为平滑度度量，并提出基于局部狄利克雷能量的正则化策略，相比神经网络在过拟合场景下表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究低秩张量积B样条模型的平滑性度量问题，发现全局狄利克雷能量正则化在某些情况下无效（完美插值但能量指数小），需要更有效的正则化方法来防止过拟合。

Method: 1) 推导TPBS模型的狄利克雷能量闭式表达式；2) 提出基于训练点为中心的小超立方体上的局部狄利克雷能量正则化策略；3) 利用预训练TPBS模型提出两种从不完整样本进行推断的估计器。

Result: TPBS模型在过拟合场景下优于神经网络（大多数数据集），其他情况下性能相当；TPBS对过拟合更鲁棒且能有效利用正则化，而神经网络对过拟合更敏感且正则化效果较差。

Conclusion: TPBS模型是回归任务的有效替代方案，特别是对过拟合更鲁棒，提出的局部狄利克雷能量正则化策略解决了全局正则化的局限性。

Abstract: We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.

</details>


### [790] [Concatenated Matrix SVD: Compression Bounds, Incremental Approximation, and Error-Constrained Clustering](https://arxiv.org/abs/2601.11626)
*Maksym Shamrai*

Main category: math.NA

Relevance: 25.0

TL;DR: 提出一种基于理论驱动的矩阵压缩感知聚类框架，在SVD压缩约束下对矩阵进行聚类，确保联合压缩误差不超过用户指定阈值。


<details>
  <summary>Details</summary>
Motivation: 现有矩阵压缩方法通常采用启发式或特定架构的分组策略，缺乏对SVD近似误差的理论保证。需要回答一个基本问题：在明确的重构误差约束下，哪些矩阵可以安全地连接和压缩在一起？

Method: 1) 建立水平连接矩阵的谱界理论，从奇异值增长的下界推导全局SVD重构误差上界；2) 开发基于增量截断SVD的高效近似估计器，无需形成完整连接矩阵；3) 提出三种聚类算法，仅在预测的联合SVD压缩误差低于阈值时才合并矩阵。

Result: 提出了首个具有显式误差控制的压缩感知聚类框架，算法在速度、可证明准确性和可扩展性之间提供权衡，支持大规模矩阵集合的高效压缩。

Conclusion: 该理论驱动框架为矩阵压缩提供了原则性保证，解决了现有方法缺乏理论支撑的问题，实现了在明确误差约束下的安全矩阵聚类和压缩。

Abstract: Large collections of matrices arise throughout modern machine learning, signal processing, and scientific computing, where they are commonly compressed by concatenation followed by truncated singular value decomposition (SVD). This strategy enables parameter sharing and efficient reconstruction and has been widely adopted across domains ranging from multi-view learning and signal processing to neural network compression. However, it leaves a fundamental question unanswered: which matrices can be safely concatenated and compressed together under explicit reconstruction error constraints? Existing approaches rely on heuristic or architecture-specific grouping and provide no principled guarantees on the resulting SVD approximation error. In the present work, we introduce a theory-driven framework for compression-aware clustering of matrices under SVD compression constraints. Our analysis establishes new spectral bounds for horizontally concatenated matrices, deriving global upper bounds on the optimal rank-$r$ SVD reconstruction error from lower bounds on singular value growth. The first bound follows from Weyl-type monotonicity under blockwise extensions, while the second leverages singular values of incremental residuals to yield tighter, per-block guarantees. We further develop an efficient approximate estimator based on incremental truncated SVD that tracks dominant singular values without forming the full concatenated matrix. Therefore, we propose three clustering algorithms that merge matrices only when their predicted joint SVD compression error remains below a user-specified threshold. The algorithms span a trade-off between speed, provable accuracy, and scalability, enabling compression-aware clustering with explicit error control. Code is available online.

</details>


### [791] [Explainable histomorphology-based survival prediction of glioblastoma, IDH-wildtype](https://arxiv.org/abs/2601.11691)
*Jan-Philipp Redlich,Friedrich Feuerhake,Stefan Nikolin,Nadine Sarah Schaadt,Sarah Teuber-Hanselmann,Joachim Weis,Sabine Luttmann,Andrea Eberle,Christoph Buck,Timm Intemann,Pascal Birnstill,Klaus Kraywinkel,Jonas Ort,Peter Boor,André Homeyer*

Main category: eess.IV

Relevance: 25.0

TL;DR: 本文提出一种可解释的AI方法，结合多实例学习（MIL）和稀疏自编码器（SAE），从胶质母细胞瘤组织病理图像中提取与生存相关的视觉模式，实现基于组织形态学的预后预测。


<details>
  <summary>Details</summary>
Motivation: 胶质母细胞瘤是最常见的恶性脑肿瘤，组织形态学是其综合诊断的关键组成部分。虽然AI方法已显示出从组织病理图像中提取额外预后信息的潜力，但需要可解释的方法来系统性地解释与生存相关的组织形态学特征。

Method: 1. 结合可解释的多实例学习（MIL）架构和稀疏自编码器（SAE）
2. MIL直接识别与预后相关的图像切片
3. SAE将这些切片映射到人类可解释的视觉模式
4. 使用德国三家医院和四个癌症登记处的720个真实世界病例训练MIL
5. 使用五个独立公共数据集的1878张全切片图像训练SAE

Result: 1. 仅基于组织形态学，方法能够区分生存少于180天和多于360天的患者（AUC: 0.67; 95% CI: 0.63-0.72）
2. Cox比例风险回归确认预测组间生存时间存在显著差异（风险比: 1.47; 95% CI: 1.26-1.72）
3. 识别出多个与生存相关的可解释视觉模式
4. 三位神经病理学家独立发现24个最强相关模式中的21个可明确归因于七个组织形态学类别
5. 坏死和出血与较短生存相关，而高细胞密度肿瘤区域与较长生存相关

Conclusion: 该方法展示了从组织病理图像中提取与生存相关的可解释视觉模式的能力，为胶质母细胞瘤的预后评估提供了新的AI工具，尽管预测性能中等，但具有临床意义。

Abstract: Glioblastoma, IDH-wildtype (GBM-IDHwt) is the most common malignant brain tumor. Histomorphology is a crucial component of the integrated diagnosis of GBM-IDHwt. Artificial intelligence (AI) methods have shown promise to extract additional prognostic information from histological whole-slide images (WSI) of hematoxylin and eosin-stained glioblastoma tissue. Here, we present an explainable AI-based method to support systematic interpretation of histomorphological features associated with survival. It combines an explainable multiple instance learning (MIL) architecture with a sparse autoencoder (SAE) to relate human-interpretable visual patterns of tissue to survival. The MIL architecture directly identifies prognosis-relevant image tiles and the SAE maps these tiles post-hoc to visual patterns. The MIL method was trained and evaluated using a new real-world dataset that comprised 720 GBM-IDHwt cases from three hospitals and four cancer registries in Germany. The SAE was trained using 1878 WSIs of glioblastoma from five independent public data collections. Despite the many factors influencing survival time, our method showed some ability to discriminate between patients living less than 180 days or more than 360 days solely based on histomorphology (AUC: 0.67; 95% CI: 0.63-0.72). Cox proportional hazards regression confirmed a significant difference in survival time between the predicted groups after adjustment for established prognostic factors (hazard ratio: 1.47; 95% CI: 1.26-1.72). Our method identified multiple interpretable visual patterns associated with survival. Three neuropathologists separately found that 21 of the 24 most strongly associated patterns could be clearly attributed to seven histomorphological categories. Necrosis and hemorrhage appeared to be associated with shorter survival while highly cellular tumor areas were associated with longer survival.

</details>


### [792] [Impact of Circuit Depth versus Qubit Count on Variational Quantum Classifiers for Higgs Boson Signal Detection](https://arxiv.org/abs/2601.11937)
*Fatih Maulana*

Main category: quant-ph

Relevance: 25.0

TL;DR: 该研究探索了变分量子分类器在希格斯玻色子信号检测中的应用，发现增加电路深度比增加量子比特数更能提升性能，最高准确率达到56.2%。


<details>
  <summary>Details</summary>
Motivation: 高能物理实验产生海量数据，挑战经典计算极限。量子机器学习在处理高维数据方面具有潜在优势，但为当前NISQ设备寻找最优架构仍是开放挑战。研究旨在探索变分量子分类器在希格斯玻色子信号检测中的性能。

Method: 使用ATLAS希格斯玻色子机器学习挑战赛2014数据集，通过主成分分析将30个物理特征降维到4量子比特和8量子比特的潜空间。比较了三种配置：(A)浅层4量子比特电路，(B)深层4量子比特电路（增加纠缠层），(C)扩展的8量子比特电路。

Result: 增加电路深度显著提升性能，深层4量子比特电路达到最高准确率56.2%（基线为51.9%）。而扩展到8量子比特反而导致性能下降至50.6%，这是由于更大希尔伯特空间中的优化挑战（贫瘠高原问题）。

Conclusion: 对于近期量子硬件，在HEP数据异常检测中，优先考虑电路深度和纠缠能力比增加量子比特数更为关键。这为NISQ设备上的量子机器学习架构设计提供了重要指导。

Abstract: High-Energy Physics (HEP) experiments, such as those at the Large Hadron Collider (LHC), generate massive datasets that challenge classical computational limits. Quantum Machine Learning (QML) offers a potential advantage in processing high-dimensional data; however, finding the optimal architecture for current Noisy Intermediate-Scale Quantum (NISQ) devices remains an open challenge. This study investigates the performance of Variational Quantum Classifiers (VQC) in detecting Higgs Boson signals using the ATLAS Higgs Boson Machine Learning Challenge 2014 experiment dataset. We implemented a dimensionality reduction pipeline using Principal Component Analysis (PCA) to map 30 physical features into 4-qubit and 8-qubit latent spaces. We benchmarked three configurations: (A) a shallow 4-qubit circuit, (B) a deep 4-qubit circuit with increased entanglement layers, and (C) an expanded 8-qubit circuit. Experimental results demonstrate that increasing circuit depth significantly improves performance, yielding the highest accuracy of 56.2% (Configuration B), compared to a baseline of 51.9%. Conversely, simply scaling to 8 qubits resulted in a performance degradation to 50.6% due to optimization challenges associated with Barren Plateaus in the larger Hilbert space. These findings suggest that for near-term quantum hardware, prioritizing circuit depth and entanglement capability is more critical than increasing qubit count for effective anomaly detection in HEP data.

</details>


### [793] [Persistent Sheaf Laplacian Analysis of Protein Stability and Solubility Changes upon Mutation](https://arxiv.org/abs/2601.12219)
*Yiming Ren,Junjie Wee,Xi Chen,Grace Qian,Guo-Wei Wei*

Main category: math.SP

Relevance: 25.0

TL;DR: SheafLapNet：基于拓扑深度学习和持久层拉普拉斯理论的统一预测框架，用于预测蛋白质突变引起的结构和功能变化，在稳定性和溶解度预测任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 遗传突变经常破坏蛋白质结构、稳定性和溶解度，是多种疾病的主要驱动因素。现有计算模型缺乏可解释性，且未能整合必要的物理化学相互作用信息。

Method: 提出SheafLapNet框架，基于拓扑深度学习（TDL）和持久层拉普拉斯（PSL）数学理论。与标准拓扑数据分析工具不同，PSL将特定物理化学信息（如部分电荷）直接编码到拓扑分析中。该框架结合层论不变量、先进的蛋白质transformer特征和辅助物理描述符，以多尺度和机制方式捕捉内在分子相互作用。

Result: 在回归和分类任务的严格基准测试中，SheafLapNet在稳定性预测（S2648和S350数据集）和溶解度预测（PON-Sol2数据集）上均达到最先进的性能。

Conclusion: 层论建模显著增强了预测突变引起的结构和功能变化时的可解释性和泛化能力，证明了整合多视角特征的有效性。

Abstract: Genetic mutations frequently disrupt protein structure, stability, and solubility, acting as primary drivers for a wide spectrum of diseases. Despite the critical importance of these molecular alterations, existing computational models often lack interpretability, and fail to integrate essential physicochemical interaction. To overcome these limitations, we propose SheafLapNet, a unified predictive framework grounded in the mathematical theory of Topological Deep Learning (TDL) and Persistent Sheaf Laplacian (PSL). Unlike standard Topological Data Analysis (TDA) tools such as persistent homology, which are often insensitive to heterogeneous information, PSL explicitly encodes specific physical and chemical information such as partial charges directly into the topological analysis. SheafLapNet synergizes these sheaf-theoretic invariants with advanced protein transformer features and auxiliary physical descriptors to capture intrinsic molecular interactions in a multiscale and mechanistic manner. To validate our framework, we employ rigorous benchmarks for both regression and classification tasks. For stability prediction, we utilize the comprehensive S2648 and S350 datasets. For solubility prediction, we employ the PON-Sol2 dataset, which provides annotations for increased, decreased, or neutral solubility changes. By integrating these multi-perspective features, SheafLapNet achieves state-of-the-art performance across these diverse benchmarks, demonstrating that sheaf-theoretic modeling significantly enhances both interpretability and generalizability in predicting mutation-induced structural and functional changes.

</details>


### [794] [On the Provable Suboptimality of Momentum SGD in Nonstationary Stochastic Optimization](https://arxiv.org/abs/2601.12238)
*Sharan Sahu,Cameron J. Hogan,Martin T. Wells*

Main category: stat.ML

Relevance: 25.0

TL;DR: 本文分析了SGD及其动量变体（Polyak重球和Nesterov）在非平稳环境中的跟踪性能，揭示了动量在抑制梯度噪声的同时会显著放大漂移引起的跟踪误差，并建立了动态遗憾的极小极大下界。


<details>
  <summary>Details</summary>
Motivation: 动量加速在确定性优化问题中已被广泛研究，但在数据分布和最优参数随时间漂移的非平稳环境中，其行为仍未被充分探索。本文旨在理论分析SGD及其动量变体在动态环境中的跟踪性能。

Method: 在均匀强凸性和光滑性假设下，分析SGD、Polyak重球和Nesterov动量在不同步长机制下的跟踪性能。推导期望和高概率下的有限时间边界，将跟踪误差分解为三个分量：初始瞬态项、噪声诱导方差项和漂移诱导跟踪滞后项。同时建立梯度变化约束下的动态遗憾极小极大下界。

Result: 发现动量在抑制梯度噪声的同时会显著放大漂移引起的跟踪误差，当动量参数趋近于1时，放大效应会无限增大。建立了动态遗憾的极小极大下界，证明惯性诱导的惩罚不是分析伪影，而是信息理论障碍：在漂移主导机制中，动量会创建不可避免的"惯性窗口"，从根本上降低性能。

Conclusion: 动量在动态环境中存在根本性权衡：虽然能抑制梯度噪声，但会损害跟踪能力。在漂移主导机制中，SGD理论上优于其加速变体。这些结果为动量在动态环境中经验不稳定性提供了明确的理论基础，并划定了精确的机制边界。

Abstract: While momentum-based acceleration has been studied extensively in deterministic optimization problems, its behavior in nonstationary environments -- where the data distribution and optimal parameters drift over time -- remains underexplored. We analyze the tracking performance of Stochastic Gradient Descent (SGD) and its momentum variants (Polyak heavy-ball and Nesterov) under uniform strong convexity and smoothness in varying stepsize regimes. We derive finite-time bounds in expectation and with high probability for the tracking error, establishing a sharp decomposition into three components: a transient initialization term, a noise-induced variance term, and a drift-induced tracking lag. Crucially, our analysis uncovers a fundamental trade-off: while momentum can suppress gradient noise, it incurs an explicit penalty on the tracking capability. We show that momentum can substantially amplify drift-induced tracking error, with amplification that becomes unbounded as the momentum parameter approaches one, formalizing the intuition that using 'stale' gradients hinders adaptation to rapid regime shifts. Complementing these upper bounds, we establish minimax lower bounds for dynamic regret under gradient-variation constraints. These lower bounds prove that the inertia-induced penalty is not an artifact of analysis but an information-theoretic barrier: in drift-dominated regimes, momentum creates an unavoidable 'inertia window' that fundamentally degrades performance. Collectively, these results provide a definitive theoretical grounding for the empirical instability of momentum in dynamic environments and delineate the precise regime boundaries where SGD provably outperforms its accelerated counterparts.

</details>


### [795] [Bone-conduction Guided Multimodal Speech Enhancement with Conditional Diffusion Models](https://arxiv.org/abs/2601.12354)
*Sina Khanagha,Bunlong Lay,Timo Gerkmann*

Main category: eess.AS

Relevance: 25.0

TL;DR: 提出一种新颖的多模态语音增强框架，通过条件扩散模型整合骨传导传感器和空气传导麦克风，在极端噪声环境下显著提升语音增强性能


<details>
  <summary>Details</summary>
Motivation: 单通道语音增强模型在极端噪声环境下性能显著下降。虽然先前研究表明互补的骨传导语音可以指导增强，但这种噪声免疫模态的有效整合仍然是一个挑战

Method: 引入一个新颖的多模态语音增强框架，使用条件扩散模型整合骨传导传感器和空气传导麦克风

Result: 提出的模型在广泛的声学条件下显著优于先前建立的多模态技术和强大的基于扩散的单模态基线

Conclusion: 通过条件扩散模型整合骨传导和空气传导模态，可以有效解决极端噪声环境下的语音增强问题

Abstract: Single-channel speech enhancement models face significant performance degradation in extremely noisy environments. While prior work has shown that complementary bone-conducted speech can guide enhancement, effective integration of this noise-immune modality remains a challenge. This paper introduces a novel multimodal speech enhancement framework that integrates bone-conduction sensors with air-conducted microphones using a conditional diffusion model. Our proposed model significantly outperforms previously established multimodal techniques and a powerful diffusion-based single-modal baseline across a wide range of acoustic conditions.

</details>


### [796] [onepot CORE -- an enumerated chemical space to streamline drug discovery, enabled by automated small molecule synthesis and AI](https://arxiv.org/abs/2601.12603)
*Andrei S. Tyrin,Brandon Wang,Manuel Muñoz,Samuel H. Foxman,Daniil A. Boiko*

Main category: physics.chem-ph

Relevance: 25.0

TL;DR: 本文介绍了onepot CORE——一个包含34亿分子及其按需合成产品的枚举化学空间，通过自动化合成平台和AI化学家Phil实现设计、执行和分析实验，旨在加速早期药物发现中的"制造"步骤。


<details>
  <summary>Details</summary>
Motivation: 早期药物发现中的"设计-制造-测试-分析"循环主要受限于"制造"步骤：小分子合成缓慢、成本高、难以规模化或自动化。现有商业化学空间仍受限于长交付时间、狭窄的反应范围和大量手动决策。

Method: 通过四个步骤构建onepot CORE：(1)选择药物化学常用反应集；(2)从供应商目录获取并筛选构建块；(3)枚举候选产物；(4)应用基于机器学习的可行性评估来优先考虑稳健执行的化合物。当前版本支持七种反应，并采用端到端工作流程。

Result: 创建了包含34亿分子的枚举化学空间，通过自动化平台实现按需合成。验证了操作指标（成功率、时间线、纯度、身份），包括代表性合成化合物的NMR确认，以及使用DPP4抑制剂系列展示的测定适用性。

Conclusion: onepot CORE展示了通向更快、更可靠获取多样化小分子的路径，支持药物及其他领域的加速发现，通过自动化合成和AI化学家减少合成瓶颈。

Abstract: The design-make-test-analyze cycle in early-stage drug discovery remains constrained primarily by the "make" step: small-molecule synthesis is slow, costly, and difficult to scale or automate across diverse chemotypes. Enumerated chemical spaces aim to reduce this bottleneck by predefining synthesizable regions of chemical space from available building blocks and reliable reactions, yet existing commercial spaces are still limited by long turnaround times, narrow reaction scope, and substantial manual decision-making in route selection and execution.
  Here we present the first version of onepot CORE, an enumerated chemical space containing 3.4B molecules and corresponding on-demand synthesis product enabled by an automated synthesis platform and an AI chemist, Phil, that designs, executes, and analyzes experiments. onepot CORE is constructed by (i) selecting a reaction set commonly used in medicinal chemistry, (ii) sourcing and curating building blocks from supplier catalogs, (iii) enumerating candidate products, and (iv) applying ML-based feasibility assessment to prioritize compounds for robust execution. In the current release, the space is supported by seven reactions.
  We describe an end-to-end workflow - from route selection and automated liquid handling through workup and purification. We further report validation across operational metrics (success rate, timelines, purity, and identity), including NMR confirmation for a representative set of synthesized compounds and assay suitability demonstrated using a series of DPP4 inhibitors. Collectively, onepot CORE illustrates a path toward faster, more reliable access to diverse small molecules, supporting accelerated discovery in pharmaceuticals and beyond.

</details>


### [797] [Empirical Risk Minimization with $f$-Divergence Regularization](https://arxiv.org/abs/2601.13191)
*Francisco Daunas,Iñaki Esnaola,Samir M. Perlaza,H. Vincent Poor*

Main category: stat.ML

Relevance: 25.0

TL;DR: 本文提出了经验风险最小化与f-散度正则化(ERM-fDR)问题的解决方案，建立了该解同时满足f-散度约束下期望经验风险最小化的条件，并引入了归一化函数这一关键数学对象，通过ODE表征和数值算法实现了计算。


<details>
  <summary>Details</summary>
Motivation: 传统经验风险最小化容易过拟合，需要正则化技术。f-散度正则化提供了一种灵活的框架，但现有方法适用范围有限，计算困难。本文旨在扩展f-散度正则化的理论框架，建立更一般的理论结果，并解决实际计算问题。

Method: 1) 建立ERM-fDR问题的对偶公式；2) 引入归一化函数作为关键数学对象；3) 将归一化函数表征为非线性ODE；4) 基于ODE性质构建数值近似算法；5) 通过经验风险变换建立不同f-散度问题的结构等价性；6) 数值实验验证不同f函数的选择影响。

Result: 1) 扩展了f-散度正则化的适用范围；2) 建立了ERM-fDR解与约束问题解的等价条件；3) 提出了归一化函数的ODE表征和数值算法；4) 揭示了不同f-散度问题的结构等价性；5) 数值实验展示了不同f函数对训练和测试风险的影响。

Conclusion: 本文为f-散度正则化提供了更完整的理论框架和实用算法，归一化函数的引入是关键创新，ODE表征和数值算法解决了计算难题，结构等价性分析深化了对不同正则化器的理解。

Abstract: In this paper, the solution to the empirical risk minimization problem with $f$-divergence regularization (ERM-$f$DR) is presented and conditions under which the solution also serves as the solution to the minimization of the expected empirical risk subject to an $f$-divergence constraint are established. The proposed approach extends applicability to a broader class of $f$-divergences than previously reported and yields theoretical results that recover previously known results. Additionally, the difference between the expected empirical risk of the ERM-$f$DR solution and that of its reference measure is characterized, providing insights into previously studied cases of $f$-divergences. A central contribution is the introduction of the normalization function, a mathematical object that is critical in both the dual formulation and practical computation of the ERM-$f$DR solution. This work presents an implicit characterization of the normalization function as a nonlinear ordinary differential equation (ODE), establishes its key properties, and subsequently leverages them to construct a numerical algorithm for approximating the normalization factor under mild assumptions. Further analysis demonstrates structural equivalences between ERM-$f$DR problems with different $f$-divergences via transformations of the empirical risk. Finally, the proposed algorithm is used to compute the training and test risks of ERM-$f$DR solutions under different $f$-divergence regularizers. This numerical example highlights the practical implications of choosing different functions $f$ in ERM-$f$DR problems.

</details>


### [798] [Optimizing Parallel Schemes with Lyapunov Exponents and kNN-LLE Estimation](https://arxiv.org/abs/2601.13604)
*Mudassir Shams,Andrei Velichko,Bruno Carpentieri*

Main category: math.NA

Relevance: 25.0

TL;DR: 本文提出了一种统一的理论-数据驱动方法，用于分析、测量和减少单参数逆并行求解器中的不稳定性。通过理论稳定性分析和基于kNN的局部最大Lyapunov指数估计，实现了对求解器动态行为的精细诊断，并提出了Lyapunov-informed参数选择策略以提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 逆并行方案在计算非线性系统根时仍不可或缺，但其动态行为可能异常丰富，从强收缩到振荡或混沌瞬态，取决于算法参数和初始状态的选择。现有方法难以全面识别和减少这些不稳定性。

Method: 1) 理论方面：推导底层迭代映射的稳定性和分岔特性，识别与周期或混沌行为相关的参数区域。2) 计算方面：引入基于kNN驱动局部最大Lyapunov指数估计的微序列管道，应用于从求解器轨迹导出的标量时间序列。3) 提出Lyapunov-informed参数选择策略，识别与稳定行为相关的求解器设置。

Result: 综合实验表明理论稳定性图与经验Lyapunov剖面之间存在密切一致性，提出的自适应机制显著提高了鲁棒性。微序列Lyapunov分析成为构建自稳定求根方案的实用、可解释工具。

Conclusion: 本研究建立了微序列Lyapunov分析作为构建自稳定求根方案的实用工具，并为将此类诊断扩展到高维或噪声污染问题开辟了途径。

Abstract: Inverse parallel schemes remain indispensable tools for computing the roots of nonlinear systems, yet their dynamical behavior can be unexpectedly rich, ranging from strong contraction to oscillatory or chaotic transients depending on the choice of algorithmic parameters and initial states. A unified analytical-data-driven methodology for identifying, measuring, and reducing such instabilities in a family of uni-parametric inverse parallel solvers is presented in this study. On the theoretical side, we derive stability and bifurcation characterizations of the underlying iterative maps, identifying parameter regions associated with periodic or chaotic behavior. On the computational side, we introduce a micro-series pipeline based on kNN-driven estimation of the local largest Lyapunov exponent (LLE), applied to scalar time series derived from solver trajectories. The resulting sliding-window Lyapunov profiles provide fine-grained, real-time diagnostics of contractive or unstable phases and reveal transient behaviors not captured by coarse linearized analysis. Leveraging this correspondence, we introduce a Lyapunov-informed parameter selection strategy that identifies solver settings associated with stable behavior, particularly when the estimated LLE indicates persistent instability. Comprehensive experiments on ensembles of perturbed initial guesses demonstrate close agreement between the theoretical stability diagrams and empirical Lyapunov profiles, and show that the proposed adaptive mechanism significantly improves robustness. The study establishes micro-series Lyapunov analysis as a practical, interpretable tool for constructing self-stabilizing root-finding schemes and opens avenues for extending such diagnostics to higher-dimensional or noise-contaminated problems.

</details>


### [799] [SCG With Your Phone: Diagnosis of Rhythmic Spectrum Disorders in Field Conditions](https://arxiv.org/abs/2601.13926)
*Peter Golenderov,Yaroslav Matushenko,Anastasia Tushina,Michal Barodkin*

Main category: q-bio.QM

Relevance: 25.0

TL;DR: 提出了一种基于智能手机加速度计的心震图信号分割与节律分析深度学习框架，用于检测主动脉瓣开放事件，适用于嘈杂的现实环境。


<details>
  <summary>Details</summary>
Motivation: 主动脉瓣开放事件对于检测频率和节律障碍至关重要，特别是在现实环境中，消费者智能手机收集的心震图信号容易受到噪声、运动伪影和设备异质性的影响。需要一种能够在嘈杂信号中可靠工作的自动化方法。

Method: 开发了增强的U-Net v3架构，集成了多尺度卷积、残差连接和注意力门，用于噪声心震图信号的分割。设计了专用后处理管道将概率掩码转换为精确的AO时间戳，并提出了新颖的自适应3D到1D投影方法以确保对任意智能手机方向的鲁棒性。

Result: 实验结果表明，该方法在各种设备类型和无监督数据收集条件下均能实现一致的高精度和鲁棒性。

Conclusion: 该方法实现了使用日常移动设备进行实用、低成本和自动化的心脏节律监测，为可扩展、可现场部署的心血管评估和未来多模态诊断系统铺平了道路。

Abstract: Aortic valve opening (AO) events are crucial for detecting frequency and rhythm disorders, especially in real-world settings where seismocardiography (SCG) signals collected via consumer smartphones are subject to noise, motion artifacts, and variability caused by device heterogeneity. In this work, we present a robust deep-learning framework for SCG segmentation and rhythm analysis using accelerometer recordings obtained with consumer smartphones. We develop an enhanced U-Net v3 architecture that integrates multi-scale convolutions, residual connections, and attention gates, enabling reliable segmentation of noisy SCG signals. A dedicated post-processing pipeline converts probability masks into precise AO timestamps, whereas a novel adaptive 3D-to-1D projection method ensures robustness to arbitrary smartphone orientation. Experimental results demonstrate that the proposed method achieves consistently high accuracy and robustness across various device types and unsupervised data-collection conditions. Our approach enables practical, low-cost, and automated cardiac-rhythm monitoring using everyday mobile devices, paving the way for scalable, field-deployable cardiovascular assessment and future multimodal diagnostic systems.

</details>


### [800] [Deep Learning Approaches to Quantum Error Mitigation](https://arxiv.org/abs/2601.14226)
*Leonardo Placidi,Ifan Williams,Enrico Rinaldi,Daniel Mills,Cristina Cîrstoiu,Vanya Eccles,Ross Duncan*

Main category: quant-ph

Relevance: 25.0

TL;DR: 该论文系统研究了深度学习在量子误差缓解中的应用，发现基于注意力机制的序列到序列模型在缓解量子电路噪声输出分布方面最有效，在模拟和真实量子设备数据上都优于其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 量子计算面临噪声干扰，需要有效的误差缓解技术。传统方法有限，而深度学习在处理复杂分布方面有潜力，因此探索深度学习在量子误差缓解中的应用。

Method: 系统比较不同深度学习架构（全连接网络、Transformer等）和训练模式，使用序列到序列的注意力模型处理量子电路输出分布。在模拟和IBM真实量子设备数据上进行测试，并进行消融研究分析不同输入特征、跨数据集泛化和跨设备迁移学习。

Result: 注意力模型在多个电路深度下都优于其他基线误差缓解技术，能产生更接近理想输出的分布。消融研究表明：模型能有效泛化到相似架构的设备，无需完全重新训练；不同输入特征对性能有影响；跨电路家族的泛化能力良好。

Conclusion: 深度学习特别是基于注意力的序列到序列模型是量子误差缓解的有效方法，具有良好的泛化能力和迁移学习潜力，为量子计算噪声处理提供了新途径。

Abstract: We present a systematic investigation of deep learning methods applied to quantum error mitigation of noisy output probability distributions from measured quantum circuits. We compare different architectures, from fully connected neural networks to transformers, and we test different design/training modalities, identifying sequence-to-sequence, attention-based models as the most effective on our datasets. These models consistently produce mitigated distributions that are closer to the ideal outputs when tested on both simulated and real device data obtained from IBM superconducting quantum processing units (QPU) up to five qubits. Across several different circuit depths, our approach outperforms other baseline error mitigation techniques. We perform a series of ablation studies to examine: how different input features (circuit, device properties, noisy output statistics) affect performance; cross-dataset generalization across circuit families; and transfer learning to a different IBM QPU. We observe that generalization performance across similar devices with the same architecture works effectively, without needing to fully retrain models.

</details>


### [801] [Graph Attention Networks with Physical Constraints for Anomaly Detection](https://arxiv.org/abs/2601.12426)
*Mohammadhossein Homaei,Iman Khazrak,Ruben Molano,Andres Caro,Mar Avila*

Main category: cs.LG

Relevance: 20.0

TL;DR: 提出一种基于水力感知的图注意力网络，利用归一化的守恒定律违反特征，结合质量与能量平衡残差、图注意力机制和双向LSTM来学习时空模式，用于水分配系统的异常检测。


<details>
  <summary>Details</summary>
Motivation: 水分配系统面临日益增长的网络物理风险，需要可靠的异常检测。现有数据驱动模型忽视网络拓扑且难以解释，而基于模型的方法严重依赖参数准确性。

Method: 提出水力感知图注意力网络，使用归一化的守恒定律违反作为特征，结合质量与能量平衡残差、图注意力机制和双向LSTM学习时空模式，并采用多尺度模块从节点到网络层面聚合检测分数。

Result: 在BATADAL数据集上达到F1=0.979，相比基线提升3.3个百分点，在15%参数噪声下表现出高鲁棒性。

Conclusion: 该方法有效结合了物理原理与深度学习，在水分配系统异常检测中实现了高性能和高鲁棒性。

Abstract: Water distribution systems (WDSs) face increasing cyber-physical risks, which make reliable anomaly detection essential. Many data-driven models ignore network topology and are hard to interpret, while model-based ones depend strongly on parameter accuracy. This work proposes a hydraulic-aware graph attention network using normalized conservation law violations as features. It combines mass and energy balance residuals with graph attention and bidirectional LSTM to learn spatio-temporal patterns. A multi-scale module aggregates detection scores from node to network level. On the BATADAL dataset, it reaches $F1=0.979$, showing $3.3$pp gain and high robustness under $15\%$ parameter noise.

</details>


### [802] [PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection](https://arxiv.org/abs/2601.12866)
*Sharmila S P*

Main category: cs.CR

Relevance: 20.0

TL;DR: 提出一个统一的PDF恶意文件检测框架，通过图结构、元数据和结构特征提取170维特征向量，适用于恶意软件分类和取证分析。


<details>
  <summary>Details</summary>
Motivation: PDF恶意文件日益增多，需要更鲁棒和全面的特征提取技术来进行有效检测和分析。现有方法往往只关注单一特征类型，缺乏统一的多维度分析框架。

Method: 集成图基、结构和元数据驱动的分析方法：1) 从PDF页面提取文本并构建无向词关系图，计算图论特征；2) 解析元数据量化字符分布、熵模式和字段一致性；3) 从时间戳提取时间特征；4) 量化结构元素如对象流、字体、嵌入图像；5) 提取恶意构造的布尔标志。

Result: 生成170维高维特征向量表示，适用于下游任务如恶意软件分类、异常检测和取证分析。框架具有可扩展性和可扩展性，支持实际PDF威胁情报工作流。

Conclusion: 提出的统一框架能够全面提取PDF文档的多维度特征，为恶意PDF检测提供了强大的特征工程基础，支持实际安全应用。

Abstract: The increasing prevalence of malicious Portable Document Format (PDF) files necessitates robust and comprehensive feature extraction techniques for effective detection and analysis. This work presents a unified framework that integrates graph-based, structural, and metadata-driven analysis to generate a rich feature representation for each PDF document. The system extracts text from PDF pages and constructs undirected graphs based on pairwise word relationships, enabling the computation of graph-theoretic features such as node count, edge density, and clustering coefficient. Simultaneously, the framework parses embedded metadata to quantify character distributions, entropy patterns, and inconsistencies across fields such as author, title, and producer. Temporal features are derived from creation and modification timestamps to capture behavioral signatures, while structural elements including, object streams, fonts, and embedded images, are quantified to reflect document complexity. Boolean flags for potentially malicious PDF constructs (e.g., JavaScript, launch actions) are also extracted. Together, these features form a high-dimensional vector representation (170 dimensions) that is well-suited for downstream tasks such as malware classification, anomaly detection, and forensic analysis. The proposed approach is scalable, extensible, and designed to support real-world PDF threat intelligence workflows.6

</details>


### [803] [Refined Gradient-Based Temperature Optimization for the Replica-Exchange Monte-Carlo Method](https://arxiv.org/abs/2601.13542)
*Tatsuya Miyata,Shunta Arai,Satoshi Takabe*

Main category: physics.comp-ph

Relevance: 20.0

TL;DR: 本文提出了一种改进的在线温度选择方法，用于优化副本交换蒙特卡洛（RXMC）算法中的温度设置，通过重新参数化技术严格保持逆温度的单调顺序约束，并使用梯度下降优化相邻副本间的接受率方差。


<details>
  <summary>Details</summary>
Motivation: RXMC方法在采样多峰分布时非常有效，但其采样效率高度依赖于温度选择。现有方法在寻找最优温度方面仍面临挑战，特别是未能明确处理物理约束（如逆温度的单调顺序），且需要仔细的超参数调优。

Method: 扩展现有的基于梯度的优化框架，引入重新参数化技术来严格强制执行物理约束。将相邻副本间接受率的方差定义为损失函数，利用采样过程中的微分信息估计梯度，通过梯度下降优化温度。

Result: 在二维铁磁Ising模型、二维铁磁XY模型和三维Edwards-Anderson模型等基准自旋系统上的实验表明，该方法成功实现了均匀的接受率，减少了温度空间中的往返时间，且比需要仔细超参数调优的策略梯度方法更具优势。

Conclusion: 提出的方法有效解决了RXMC中的温度优化问题，通过重新参数化技术防止约束违反，同时避免了复杂超参数调优，为多峰分布采样提供了更稳定和高效的解决方案。

Abstract: The replica-exchange Monte-Carlo (RXMC) method is a powerful Markov-chain Monte-Carlo algorithm for sampling from multi-modal distributions, which are challenging for conventional methods. The sampling efficiency of the RXMC method depends highly on the selection of the temperatures, and finding optimal temperatures remains a challenge. In this study, we propose a refined online temperature selection method by extending the gradient-based optimization framework proposed previously. Building upon the existing temperature update approach, we introduce a reparameterization technique to strictly enforce physical constraints, such as the monotonic ordering of inverse temperatures, which were not explicitly addressed in the original formulation. The proposed method defines the variance of acceptance rates between adjacent replicas as a loss function, estimates its gradient using differential information from the sampling process, and optimizes the temperatures via gradient descent. We demonstrate the effectiveness of our method through experiments on benchmark spin systems, including the two-dimensional ferromagnetic Ising model, the two-dimensional ferromagnetic XY model, and the three-dimensional Edwards-Anderson model. Our results show that the method successfully achieves uniform acceptance rates and reduces round-trip times across the temperature space. Furthermore, our proposed method offers a significant advantage over recently proposed policy gradient method that require careful hyperparameter tuning, while simultaneously preventing the constraint violations that destabilize optimization.

</details>


### [804] [Machine learning model for predicting surface wettability in laser-textured metal alloys](https://arxiv.org/abs/2601.11661)
*Mohammad Mohammadzadeh Sanandaji,Danial Ebrahimzadeh,Mohammad Ikram Haider,Yaser Mike Banad,Aleksandar Poleksic,Hongtao Ding*

Main category: cs.LG

Relevance: 15.0

TL;DR: 本文提出了一种机器学习框架，利用实验获得的形态和化学特征来准确预测激光纹理金属合金的润湿性。


<details>
  <summary>Details</summary>
Motivation: 表面润湿性在传热、润滑、微流体和表面涂层等应用中至关重要，但传统方法难以准确预测激光纹理金属合金的润湿行为，需要开发能够捕捉表面形貌和化学复杂相互作用的预测模型。

Method: 通过纳秒激光纹理化和化学浸渍处理制备超亲水和超疏水表面；使用Laws纹理能量方法和轮廓测量法定量表面形貌；通过XPS表征表面化学，提取官能团极性、分子体积和峰面积分数等特征；训练包含残差连接、批量归一化和dropout正则化的集成神经网络模型。

Result: 模型实现了高预测精度（R² = 0.942，RMSE = 13.896），优于先前方法；特征重要性分析显示表面化学对接触角预测影响最大，形貌特征也有显著贡献。

Conclusion: 这项工作展示了人工智能通过捕捉表面特性的复杂相互作用来建模和预测润湿行为的潜力，为设计定制功能表面提供了数据驱动的途径。

Abstract: Surface wettability, governed by both topography and chemistry, plays a critical role in applications such as heat transfer, lubrication, microfluidics, and surface coatings. In this study, we present a machine learning (ML) framework capable of accurately predicting the wettability of laser-textured metal alloys using experimentally derived morphological and chemical features. Superhydrophilic and superhydrophobic surfaces were fabricated on AA6061 and AISI 4130 alloys via nanosecond laser texturing followed by chemical immersion treatments. Surface morphology was quantified using the Laws texture energy method and profilometry, while surface chemistry was characterized through X-ray photoelectron spectroscopy (XPS), extracting features such as functional group polarity, molecular volume, and peak area fraction. These features were used to train an ensemble neural network model incorporating residual connections, batch normalization, and dropout regularization. The model achieved high predictive accuracy (R2 = 0.942, RMSE = 13.896), outperforming previous approaches. Feature importance analysis revealed that surface chemistry had the strongest influence on contact angle prediction, with topographical features also contributing significantly. This work demonstrates the potential of artificial intelligence to model and predict wetting behavior by capturing the complex interplay of surface characteristics, offering a data-driven pathway for designing tailored functional surfaces.

</details>


### [805] [Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing](https://arxiv.org/abs/2601.11794)
*Abdelrahman Ramadan,Zahra Dorbeigi Namaghi,Emily Taylor,Lucas Edwards,Xan Giuliani,David S. McLagan,Sidney Givigi,Melissa Greeff*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出PC²DAE物理约束去噪自编码器，用于解决无人机大气传感器数据漂移问题，在数据稀缺场景下通过架构设计嵌入物理约束，实现零物理违规的去噪效果。


<details>
  <summary>Details</summary>
Motivation: 无人机搭载低成本大气传感器存在基线漂移、交叉敏感性和响应延迟问题，传统深度学习方法需要大量数据，但无人机飞行活动数据有限，难以满足需求。

Method: 提出物理约束去噪自编码器(PC²DAE)，通过softplus激活函数强制非负浓度估计，物理合理的时间平滑，分层解码器头处理不同传感器家族。提供两个变体：PC²DAE-Lean(21k参数)用于边缘部署，PC²DAE-Wide(204k参数)用于离线处理。

Result: 在仅7,894个样本(约2.2小时飞行数据)上评估，PC²DAE-Lean实现67.3%平滑度提升和90.7%高频噪声减少，零物理违规。五个基线方法产生15-23%负输出。精简版优于宽版(+5.6%平滑度)，表明在数据稀缺场景下减少容量并加强归纳偏置可防止过拟合。

Conclusion: PC²DAE通过架构设计直接嵌入物理约束，在数据稀缺的无人机大气监测场景中实现了物理合理的去噪效果，为边缘部署提供了高效解决方案。

Abstract: Wildfire monitoring requires high-resolution atmospheric measurements, yet low-cost sensors on Unmanned Aerial Vehicles (UAVs) exhibit baseline drift, cross-sensitivity, and response lag that corrupt concentration estimates. Traditional deep learning denoising approaches demand large datasets impractical to obtain from limited UAV flight campaigns. We present PC$^2$DAE, a physics-informed denoising autoencoder that addresses data scarcity by embedding physical constraints directly into the network architecture. Non-negative concentration estimates are enforced via softplus activations and physically plausible temporal smoothing, ensuring outputs are physically admissible by construction rather than relying on loss function penalties. The architecture employs hierarchical decoder heads for Black Carbon, Gas, and CO$_2$ sensor families, with two variants: PC$^2$DAE-Lean (21k parameters) for edge deployment and PC$^2$DAE-Wide (204k parameters) for offline processing. We evaluate on 7,894 synchronized 1 Hz samples collected from UAV flights during prescribed burns in Saskatchewan, Canada (approximately 2.2 hours of flight data), two orders of magnitude below typical deep learning requirements. PC$^2$DAE-Lean achieves 67.3\% smoothness improvement and 90.7\% high-frequency noise reduction with zero physics violations. Five baselines (LSTM-AE, U-Net, Transformer, CBDAE, DeSpaWN) produce 15--23\% negative outputs. The lean variant outperforms wide (+5.6\% smoothness), suggesting reduced capacity with strong inductive bias prevents overfitting in data-scarce regimes. Training completes in under 65 seconds on consumer hardware.

</details>


### [806] [Semidefinite Programming for Quantum Channel Learning](https://arxiv.org/abs/2601.12502)
*Mikhail Gennadievich Belov,Victor Victorovich Dubov,Vadim Konstantinovich Ivanov,Alexander Yurievich Maslov,Olga Vladimirovna Proshina,Vladislav Gennadievich Malyshkin*

Main category: cs.LG

Relevance: 15.0

TL;DR: 该论文提出使用半定规划（SDP）从经典数据中重建量子通道的方法，适用于保真度可表示为两个二次型比值的情况，发现重建的量子通道通常具有较小的Kraus秩。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理中需要从实验观测的经典数据重建量子通道，传统方法可能效率低下或不够精确。当保真度可表示为两个二次型比值时，可以利用SDP的凸优化特性高效求解。

Method: 使用半定规划（SDP）方法，将量子通道重建问题转化为关于Choi矩阵的保真度优化问题。测试了多种商用SDP求解器，应用于混合态到纯态映射、投影算子、酉学习等场景。

Result: 所有测试的SDP求解器都能成功重建不同形式的量子通道。重建得到的量子通道通常具有很小的Kraus秩（小于最大可能值的几个百分点），表明少量Kraus算子就足以描述实验观测数据。

Conclusion: SDP为量子通道重建提供了高效可靠的数值方法，重建的量子通道通常具有低Kraus秩，这为量子信息处理提供了实用工具。论文还讨论了基于量子通道变换的经典计算模型。

Abstract: The problem of reconstructing a quantum channel from a sample of classical data is considered. When the total fidelity can be represented as a ratio of two quadratic forms (e.g., in the case of mapping a mixed state to a pure state, projective operators, unitary learning, and others), Semidefinite Programming (SDP) can be applied to solve the fidelity optimization problem with respect to the Choi matrix. A remarkable feature of SDP is that the optimization is convex, which allows the problem to be efficiently solved by a variety of numerical algorithms. We have tested several commercially available SDP solvers, all of which allowed for the reconstruction of quantum channels of different forms. A notable feature is that the Kraus rank of the obtained quantum channel typically comprises less than a few percent of its maximal possible value. This suggests that a relatively small Kraus rank quantum channel is typically sufficient to describe experimentally observed classical data. The theory was also applied to the problem of reconstructing projective operators from data. Finally, we discuss a classical computational model based on quantum channel transformation, performed and calculated on a classical computer, possibly hardware-optimized.

</details>


### [807] [Adaptively trained Physics-informed Radial Basis Function Neural Networks for Solving Multi-asset Option Pricing Problems](https://arxiv.org/abs/2601.12704)
*Yan Ma,Yumeng Ren*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出了一种基于径向基函数神经网络(PIRBFNN)的物理信息机器学习算法，用于求解多资产期权定价的Black-Scholes偏微分方程，通过自适应调整隐藏神经元分布来有效处理非光滑支付条件。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理多资产期权定价的Black-Scholes偏微分方程时面临挑战，特别是当存在非光滑支付条件时。需要开发一种能够有效结合传统数值方法和现代机器学习优势的算法，以提高多维金融PDE问题的求解精度和效率。

Method: 提出物理信息径向基函数神经网络(PIRBFNN)，结合传统径向基函数配置法和物理信息神经网络方法。采用基于PDE残差的技术在训练过程中自适应细化隐藏神经元的分布，同时优化网络架构并预测目标期权价格。

Result: 通过单资产欧式看跌期权、双资产交换期权和四资产篮子看涨期权的实验验证了方法的有效性。PIRBFNN能够准确高效地处理具有非光滑支付条件的多维期权定价模型。

Conclusion: PIRBFNN成功结合了传统径向基函数配置法和物理信息神经网络的优点，为金融领域中的多维PDE问题提供了一种有效的数值求解方法，特别适用于处理非光滑支付条件。

Abstract: The present study investigates the numerical solution of Black-Scholes partial differential equation (PDE) for option valuation with multiple underlying assets. We develop a physics-informed (PI) machine learning algorithm based on a radial basis function neural network (RBFNN) that concurrently optimizes the network architecture and predicts the target option price. The physics-informed radial basis function neural network (PIRBFNN) combines the strengths of the traditional radial basis function collocation method and the physics-informed neural network machine learning approach to effectively solve PDE problems in the financial context. By employing a PDE residual-based technique to adaptively refine the distribution of hidden neurons during the training process, the PIRBFNN facilitates accurate and efficient handling of multidimensional option pricing models featuring non-smooth payoff conditions. The validity of the proposed method is demonstrated through a set of experiments encompassing a single-asset European put option, a double-asset exchange option, and a four-asset basket call option.

</details>


### [808] [Supervised Learning for the (s,S) Inventory Model with General Interarrival Demands and General Lead Times](https://arxiv.org/abs/2601.12900)
*Eliran Sherzer,Yonit Barron*

Main category: cs.LG

Relevance: 15.0

TL;DR: 该论文提出了一种基于神经网络的监督学习框架，用于近似具有一般分布的(s,S)库存系统的稳态性能指标，避免了昂贵的重复仿真。


<details>
  <summary>Details</summary>
Motivation: 连续审查(s,S)库存模型是随机库存理论的基石，但在处理非马尔可夫系统时分析变得解析不可行。传统方法依赖昂贵的仿真来评估长期性能指标，需要更高效的替代方案。

Method: 提出监督学习框架：首先使用仿真生成训练标签，然后训练神经网络模型。使用少量低阶矩作为输入，神经网络可以近似系统的各种稳态性能指标，如库存水平的稳态分布、期望周期时间和缺货概率。

Result: 广泛的数值实验表明，该方法在广泛的系统参数范围内具有高准确性。神经网络训练后可以提供几乎即时的预测，有效替代重复且昂贵的仿真运行。

Conclusion: 该框架为分析复杂随机系统提供了高效快速的替代方案，并且易于扩展到其他库存模型。使用少量分布矩作为输入足以准确捕捉稳态分布。

Abstract: The continuous-review (s,S) inventory model is a cornerstone of stochastic inventory theory, yet its analysis becomes analytically intractable when dealing with non-Markovian systems. In such systems, evaluating long-run performance measures typically relies on costly simulation.
  This paper proposes a supervised learning framework via a neural network model for approximating stationary performance measures of (s,S) inventory systems with general distributions for the interarrival time between demands and lead times under lost sales. Simulations are first used to generate training labels, after which the neural network is trained. After training, the neural network provides almost instantaneous predictions of various metrics of the system, such as the stationary distribution of inventory levels, the expected cycle time, and the probability of lost sales. We find that using a small number of low-order moments of the distributions as input is sufficient to train the neural networks and to accurately capture the steady-state distribution. Extensive numerical experiments demonstrate high accuracy over a wide range of system parameters. As such, it effectively replaces repeated and costly simulation runs. Our framework is easily extendable to other inventory models, offering an efficient and fast alternative for analyzing complex stochastic systems.

</details>


### [809] [Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets](https://arxiv.org/abs/2601.12903)
*Meng Liu,Ke Liang,Siwei Wang,Xingchen Hu,Sihang Zhou,Xinwang Liu*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出了BenchTGC基准，用于解决时序图聚类任务中的技术不适用和数据集不适用两大挑战，通过改进现有聚类技术和开发专用数据集来推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 时序图聚类是一个新兴但关注度低的任务，相比静态图聚类能通过基于交互序列的批处理模式实现时间-空间平衡。然而，现有聚类技术不适用于时序图，且缺乏合适的公开数据集，阻碍了该领域发展。

Method: 提出了BenchTGC基准，包括：1) BenchTGC框架，阐述时序图聚类的范式并改进现有聚类技术以适应时序图；2) BenchTGC数据集，针对现有公开时序图数据集的问题开发了多个适合TGC任务的数据集。

Result: 通过大量实验验证了BenchTGC的优势，并证明了时序图聚类任务的必要性和重要性。现实世界中动态变化和复杂场景是时序图聚类的基础。

Conclusion: BenchTGC基准成功解决了时序图聚类面临的技术和数据集挑战，为这一新兴领域的发展提供了重要支持，展示了时序图聚类在现实动态场景中的价值。

Abstract: Temporal Graph Clustering (TGC) is a new task with little attention, focusing on node clustering in temporal graphs. Compared with existing static graph clustering, it can find the balance between time requirement and space requirement (Time-Space Balance) through the interaction sequence-based batch-processing pattern. However, there are two major challenges that hinder the development of TGC, i.e., inapplicable clustering techniques and inapplicable datasets. To address these challenges, we propose a comprehensive benchmark, called BenchTGC. Specially, we design a BenchTGC Framework to illustrate the paradigm of temporal graph clustering and improve existing clustering techniques to fit temporal graphs. In addition, we also discuss problems with public temporal graph datasets and develop multiple datasets suitable for TGC task, called BenchTGC Datasets. According to extensive experiments, we not only verify the advantages of BenchTGC, but also demonstrate the necessity and importance of TGC task. We wish to point out that the dynamically changing and complex scenarios in real world are the foundation of temporal graph clustering. The code and data is available at: https://github.com/MGitHubL/BenchTGC.

</details>


### [810] [An efficient heuristic for geometric analysis of cell deformations](https://arxiv.org/abs/2601.12928)
*Yaima Paz Soto,Silena Herold Garcia,Ximo Gual-Arnau,Antoni Jaume-i-Capó,Manuel González-Hidalgo*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出了一种基于形状空间的镰状细胞自动分类方法，通过固定参数化和模板对齐简化计算，在监督分类和无监督聚类中达到96.03%准确率


<details>
  <summary>Details</summary>
Motivation: 镰状细胞病导致红细胞变形，影响血液流动和氧气输送，在全球尤其是资源有限地区造成重大医疗负担。自动分类镰状细胞对于减轻专家工作量、避免量化错误和评估危机严重性至关重要。

Method: 将红细胞建模为形状空间中的闭合平面曲线，使用弹性距离（对旋转、平移、缩放和重参数化不变）。改进方法包括：(1) 基于每个细胞主轴使用固定参数化计算距离，(2) 在计算距离前使用该参数化将每个细胞与两个模板对齐。这种模板对齐策略简化了计算。

Result: 在监督分类和无监督聚类中均达到96.03%的准确率，在保持或提高形状空间模型准确性的同时显著降低计算成本。

Conclusion: 该方法实现了高效的红细胞分类，通过固定参数化和模板对齐简化了计算，在保持高准确率的同时降低了计算复杂度，适用于资源有限环境。

Abstract: Sickle cell disease causes erythrocytes to become sickle-shaped, affecting their movement in the bloodstream and reducing oxygen delivery. It has a high global prevalence and places a significant burden on healthcare systems, especially in resource-limited regions. Automated classification of sickle cells in blood images is crucial, allowing the specialist to reduce the effort required and avoid errors when quantifying the deformed cells and assessing the severity of a crisis. Recent studies have proposed various erythrocyte representation and classification methods. Since classification depends solely on cell shape, a suitable approach models erythrocytes as closed planar curves in shape space. This approach employs elastic distances between shapes, which are invariant under rotations, translations, scaling, and reparameterizations, ensuring consistent distance measurements regardless of the curves' position, starting point, or traversal speed. While previous methods exploiting shape space distances had achieved high accuracy, we refined the model by considering the geometric characteristics of healthy and sickled erythrocytes. Our method proposes (1) to employ a fixed parameterization based on the major axis of each cell to compute distances and (2) to align each cell with two templates using this parameterization before computing distances. Aligning shapes to templates before distance computation, a concept successfully applied in areas such as molecular dynamics, and using a fixed parameterization, instead of minimizing distances across all possible parameterizations, simplifies calculations. This strategy achieves 96.03\% accuracy rate in both supervised classification and unsupervised clustering. Our method ensures efficient erythrocyte classification, maintaining or improving accuracy over shape space models while significantly reducing computational costs.

</details>


### [811] [TinyML-Enabled IoT for Sustainable Precision Irrigation](https://arxiv.org/abs/2601.13054)
*Kamogelo Taueatsoala,Caitlyn Daniels,Angelina J. Ramsunar,Petrus Bronkhorst,Absalom E. Ezugwu*

Main category: cs.LG

Relevance: 15.0

TL;DR: 本文提出了一种面向资源受限农业环境的边缘优先物联网框架，集成TinyML实现离线精准灌溉，通过低成本硬件和优化模型显著减少用水量。


<details>
  <summary>Details</summary>
Motivation: 小规模农业社区面临水资源短缺、气候模式不稳定以及缺乏先进、经济实惠的农业技术等问题。为解决这些挑战，需要开发不依赖云计算的自主决策系统，特别适用于互联网连接有限的农村地区。

Method: 提出四层边缘优先物联网架构：1）使用ESP32微控制器作为边缘推理节点，2）Raspberry Pi作为本地边缘服务器，3）集成土壤湿度、温度、湿度、pH值和环境光传感器，4）通过比较分析选择梯度提升作为最优模型（R²=0.9973，MAPE=0.99%），5）将模型转换为轻量级TinyML推理引擎部署在ESP32上，6）采用基于MQTT的局域网协议实现本地通信。

Result: 梯度提升模型表现最佳（R²=0.9973，MAPE=0.99%），优于随机森林（R²=0.9916，MAPE=1.81%）。部署后系统预测灌溉需求的MAPE<1%，在受控环境中相比传统方法显著减少用水量，低功耗设计和离线功能验证了其在资源受限农村环境中的可行性。

Conclusion: 该工作为农业技术鸿沟提供了实用、经济高效的解决方案，通过设备端人工智能增强水资源利用效率，展示了在资源受限农村环境中可持续、可扩展部署的潜力。

Abstract: Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.

</details>


### [812] [Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment](https://arxiv.org/abs/2601.14022)
*Rodrigo Pereira David,Luciano Araujo Dourado Filho,Daniel Marques da Silva,João Alfredo Cal-Braz*

Main category: cs.LG

Relevance: 15.0

TL;DR: 本文提出一个基于机器学习的框架，用于在相同真实驾驶条件下公平比较内燃机车和电动车的CO2排放，通过固定驾驶场景构建反事实分析。


<details>
  <summary>Details</summary>
Motivation: 道路运输脱碳需要一致透明的方法来比较不同车辆技术的CO2排放。现有评估方法往往缺乏公平比较，无法在相同驾驶条件下直接对比内燃机车和电动车的实际排放性能。

Method: 使用循环神经网络分别训练内燃机车和电动车模型，学习从驾驶变量（速度、加速度、温度）到内部执行变量（扭矩、油门）和瞬时CO2当量排放率的映射。通过固定观察到的速度曲线和环境背景，构建反事实场景进行公平比较。

Result: 该框架能够在统一瞬时排放指标下对齐两种车辆类型，实现动力系统技术的公平可重复评估，为真实驾驶条件下的车辆碳性能提供可信的数据驱动评估基础。

Conclusion: 提出的机器学习框架为车辆技术比较提供了可扩展的基础，支持在相同真实驾驶条件下进行公平的CO2排放评估，有助于道路运输脱碳的决策制定。

Abstract: Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: What emissions would an EV have generated if it had followed the same driving profile as an ICEV? By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.

</details>


### [813] [Uniqueness ratio as a predictor of a privacy leakage](https://arxiv.org/abs/2601.11550)
*Danah A. AlSalem AlKhashti*

Main category: cs.DB

Relevance: 15.0

TL;DR: 该研究提出使用候选连接属性的唯一性比率作为连接前重识别风险的早期预测指标，实验表明高唯一性比率与连接后身份泄露风险强相关。


<details>
  <summary>Details</summary>
Motivation: 当独立数据库连接时，即使每个数据集单独匿名化，仍可能出现身份泄露。现有研究主要关注连接后检测或复杂隐私模型，缺乏简单、可解释的连接前指标来警告数据工程师和数据库管理员。

Method: 使用合成多表数据集，计算每个数据库中属性组合的唯一性比率，并研究这些比率如何与连接后的身份暴露相关。通过实验测量连接后变得唯一可识别或落入非常小组的记录比例。

Result: 实验结果显示，连接前高唯一性比率与连接后泄露增加之间存在强相关关系。唯一性比率可作为评估连接引发隐私风险的可解释且实用的信号。

Conclusion: 唯一性比率提供了一个可解释且实用的连接前隐私风险评估信号，为开发更全面的连接前风险估计模型奠定了基础。

Abstract: Identity leakage can emerge when independent databases are joined, even when each dataset is anonymized individually. While previous work focuses on post-join detection or complex privacy models, little attention has been given to simple, interpretable pre-join indicators that can warn data engineers and database administrators before integration occurs. This study investigates the uniqueness ratio of candidate join attributes as an early predictor of re-identification risk. Using synthetic multi-table datasets, we compute the uniqueness ratio of attribute combinations within each database and examine how these ratios correlate with identity exposure after the join. Experimental results show a strong relationship between high pre-join uniqueness and increased post-join leakage, measured by the proportion of records that become uniquely identifiable or fall into very small groups. Our findings demonstrate that uniqueness ratio offers an explainable and practical signal for assessing join induced privacy risk, providing a foundation for developing more comprehensive pre-join risk estimation models.

</details>


### [814] [A Proof of Concept for a Digital Twin of an Ultrasonic Fermentation System](https://arxiv.org/abs/2601.11723)
*Francesco Saverio Sconocchia Pisoni,Andrea Vitaletti,Davide Appolloni,Federico Ortenzi,Blasco Morozzo della Rocca,Mariano José Guillén,Alessandro Contaldo*

Main category: cs.ET

Relevance: 15.0

TL;DR: 开发了一个用于超声波增强啤酒发酵系统的数字孪生概念验证，通过超声波刺激加速酵母生长和发酵过程，并构建了基于环境条件的酵母密度预测模型。


<details>
  <summary>Details</summary>
Motivation: 传统发酵过程缺乏智能监控和预测能力，需要开发能够实时监测、预测和调控酵母生长环境的系统。通过超声波刺激可以增强酵母生长，但需要数字孪生技术来实现智能化管理。

Method: 在传统发酵罐中安装压电换能器产生超声波刺激，构建数字孪生系统。采用并改进Palacios等人的模型，使用温度、超声波频率和占空比作为输入，处理有限的训练样本，预测酵母培养密度随时间的变化。

Result: 实现了超声波增强发酵系统的数字孪生概念验证，模型性能评估表明该方法可行，能够有效预测酵母密度变化，为智能化发酵监控提供了技术基础。

Conclusion: 提出的数字孪生方法为超声波增强啤酒发酵系统提供了可行的智能化监控解决方案，通过整合物理设备和预测模型，实现了对发酵过程的智能预测和调控。

Abstract: This paper presents the design and implementation of a proof of concept digital twin for an innovative ultrasonic-enhanced beer-fermentation system, developed to enable intelligent monitoring, prediction, and actuation in yeast-growth environments. A traditional fermentation tank is equipped with a piezoelectric transducer able to irradiate the tank with ultrasonic waves, providing an external abiotic stimulus to enhance the growth of yeast and accelerate the fermentation process. At its core, the digital twin incorporates a predictive model that estimates yeast's culture density over time based on the surrounding environmental conditions. To this end, we implement, tailor and extend the model proposed in Palacios et al., allowing us to effectively handle the limited number of available training samples by using temperature, ultrasonic frequency, and duty cycle as inputs. The results obtained along with the assessment of model performance demonstrate the feasibility of the proposed approach.

</details>


### [815] [Gradient-based Active Learning with Gaussian Processes for Global Sensitivity Analysis](https://arxiv.org/abs/2601.11790)
*Guerlain Lambert,Céline Helbert,Claire Lauvernet*

Main category: stat.ML

Relevance: 15.0

TL;DR: 提出一种基于高斯过程代理模型的主动学习方法，用于在有限计算预算下提高复杂数值模拟器的全局敏感性分析准确性。


<details>
  <summary>Details</summary>
Motivation: 复杂数值模拟器的全局敏感性分析通常受限于可负担的模型评估次数。在有限模拟次数下，需要高效丰富计算机实验设计，以构建准确的代理模型来降低计算负担。

Method: 基于高斯过程代理模型，利用其梯度信息开发主动学习策略。通过利用GP梯度的联合后验分布，构建考虑偏导数间相关性及其对响应面影响的采集函数，比现有DGSM导向准则更全面稳健。

Result: 在标准基准函数上与最先进方法进行比较，并在农药迁移环境模型的实际应用中验证了方法的有效性。

Conclusion: 提出的主动学习方法能够针对输入空间中最具信息量的区域，在固定评估预算下提高敏感性分析（Sobol指数和基于导数的全局敏感性度量）的准确性。

Abstract: Global sensitivity analysis of complex numerical simulators is often limited by the small number of model evaluations that can be afforded. In such settings, surrogate models built from a limited set of simulations can substantially reduce the computational burden, provided that the design of computer experiments is enriched efficiently. In this context, we propose an active learning approach that, for a fixed evaluation budget, targets the most informative regions of the input space to improve sensitivity analysis accuracy. More specifically, our method builds on recent advances in active learning for sensitivity analysis (Sobol' indices and derivative-based global sensitivity measures, DGSM) that exploit derivatives obtained from a Gaussian process (GP) surrogate. By leveraging the joint posterior distribution of the GP gradient, we develop acquisition functions that better account for correlations between partial derivatives and their impact on the response surface, leading to a more comprehensive and robust methodology than existing DGSM-oriented criteria. The proposed approach is first compared to state-of-the-art methods on standard benchmark functions, and is then applied to a real environmental model of pesticide transfers.

</details>


### [816] [MongoDB Injection Query Classification Model using MongoDB Log files as Training Data](https://arxiv.org/abs/2601.11996)
*Shaunak Perni,Minal Shirodkar,Ramdas Karmalli*

Main category: cs.CR

Relevance: 15.0

TL;DR: 本文提出一种基于日志数据而非原始查询语句的NoSQL注入攻击检测方法，使用FLAML AutoML库和手动编程模型在MongoDB日志数据上训练分类器，最佳模型准确率达71%。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的NoSQL注入防御系统对创新性攻击无效，而基于模型的检测系统通常只训练在查询语句上，由于数据稀缺和类别不平衡问题，在真实世界中效果不佳。本文探索基于MongoDB服务器日志数据和其他提取特征（排除原始查询语句）来分类NoSQL注入攻击。

Method: 1. 从模拟攻击的空MongoDB服务器收集日志数据并进行处理分析
2. 进行判别分析确定统计显著特征以区分注入和良性查询
3. 使用AutoML库FLAML训练多个机器学习分类模型
4. 同时手动编程6个模型作为对比
5. 在50个随机数据样本上进行训练、交叉验证和评估

Result: 最佳模型为FLAML库的"XGBoost limited depth"模型，准确率达到71%。该研究展示了基于日志特征而非原始查询语句的NoSQL注入检测可行性。

Conclusion: 基于日志数据的特征提取方法可以有效检测NoSQL注入攻击，FLAML AutoML库在自动化模型选择方面表现良好，为NoSQL安全检测提供了新的技术路径。

Abstract: NoSQL Injection attacks are a class of cybersecurity attacks where an attacker sends a specifically engineered query to a NoSQL database which then performs an unauthorized operation. To defend against such attacks, rule based systems were initially developed but then were found to be ineffective to innovative injection attacks hence a model based approach was developed. Most model based detection systems, during testing gave exponentially positive results but were trained only on the query statement sent to the server. However due to the scarcity of data and class imbalances these model based systems were found to be not effective against all attacks in the real world. This paper explores classifying NoSQL injection attacks sent to a MongoDB server based on Log Data, and other extracted features excluding raw query statements. The log data was collected from a simulated attack on an empty MongoDB server which was then processed and explored. A discriminant analysis was carried out to determine statistically significant features to discriminate between injection and benign queries resulting in a dataset of significant features. Several Machine learning based classification models using an AutoML library, "FLAML", as well as 6 manually programmed models were trained on this dataset , which were then trained on 50 randomized samples of data, cross validated and evaluated. The study found that the best model was the "FLAML" library's "XGBoost limited depth" model with an accuracy of 71%.

</details>


### [817] [Adaptive Rotary Steering with Joint Autoregression for Robust Extraction of Closely Moving Speakers in Dynamic Scenarios](https://arxiv.org/abs/2601.12345)
*Jakob Kienegger,Timo Gerkmann*

Main category: eess.AS

Relevance: 15.0

TL;DR: 提出了一种用于动态声学条件下多说话人场景的联合自回归框架，通过结合处理后的录音作为引导，改善近距离或交叉说话人的跟踪和增强性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度空间滤波方法在静态多说话人场景中表现良好，但在动态声学条件下（移动说话人）应用受限。当说话人靠近或交叉时，跟踪变得困难且空间线索对增强效果减弱。

Method: 提出联合自回归框架：1）使用基于目标初始方向的交错跟踪算法自动旋转声场；2）将处理后的录音作为额外引导输入两个算法；3）利用语音的时频相关性解决空间挑战性说话人配置。

Result: 在合成数据集上，该方法显著改善了近距离说话人的跟踪和增强，始终优于可比非自回归方法。真实世界录音在复杂场景（多个说话人交叉、不同说话人到阵列距离）中验证了这些发现。

Conclusion: 提出的联合自回归框架通过利用时频相关性有效解决了动态声学条件下空间挑战性说话人配置的问题，在复杂场景中表现出优越性能。

Abstract: Latest advances in deep spatial filtering for Ambisonics demonstrate strong performance in stationary multi-speaker scenarios by rotating the sound field toward a target speaker prior to multi-channel enhancement. For applicability in dynamic acoustic conditions with moving speakers, we propose to automate this rotary steering using an interleaved tracking algorithm conditioned on the target's initial direction. However, for nearby or crossing speakers, robust tracking becomes difficult and spatial cues less effective for enhancement. By incorporating the processed recording as additional guide into both algorithms, our novel joint autoregressive framework leverages temporal-spectral correlations of speech to resolve spatially challenging speaker constellations. Consequently, our proposed method significantly improves tracking and enhancement of closely spaced speakers, consistently outperforming comparable non-autoregressive methods on a synthetic dataset. Real-world recordings complement these findings in complex scenarios with multiple speaker crossings and varying speaker-to-array distances.

</details>


### [818] [Temporal Data and Short-Time Averages Improve Multiphase Mass Flow Metering](https://arxiv.org/abs/2601.12433)
*Amanda Nyholm,Yessica Arellano,Jinyu Liu,Damian Krakowiak,Pierluigi Salvo Rossi*

Main category: eess.SP

Relevance: 15.0

TL;DR: 该论文提出使用机器学习模型结合科里奥利质量流量计来改善多相流测量精度，通过保留时间信息（短时平均而非整体平均）显著提升了模型性能，其中CNN在0.25Hz下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前流量测量仪器在多相流（如空气-水-油混合）条件下测量精度不足，而科里奥利质量流量计作为单相流量计虽能提供直接质量流量测量，但在多相条件下需要校正。机器学习模型可以校正这些测量误差，但传统方法将整个实验压缩为单个平均样本，丢失了重要的时间信息。

Method: 研究比较了多层感知机、窗口化多层感知机和卷积神经网络在342个三相空气-水-油流动实验数据上的表现。创新之处在于不将每个实验压缩为单个平均样本，而是在每个实验内计算短时平均值，并在多个下采样间隔下保留时间信息进行训练。

Result: CNN在0.25Hz下表现最佳：约95%的相对误差低于13%，归一化均方根误差为0.03，平均绝对百分比误差约4.3%。这明显优于最佳的单平均模型，表明在单个实验内进行短时平均优于整体平均。结果在多个数据分割和随机种子下保持一致，证明了方法的鲁棒性。

Conclusion: 保留时间信息显著改善了多相流测量中机器学习模型的性能。在实验内进行短时平均而非整体平均是更好的方法，CNN在适当的下采样频率下能够有效校正科里奥利流量计在多相条件下的测量误差。

Abstract: Reliable flow measurements are essential in many industries, but current instruments often fail to accurately estimate multiphase flows, which are frequently encountered in real-world operations. Combining machine learning (ML) algorithms with accurate single-phase flowmeters has therefore received extensive research attention in recent years. The Coriolis mass flowmeter is a widely used single-phase meter that provides direct mass flow measurements, which ML models can be trained to correct, thereby reducing measurement errors in multiphase conditions. This paper demonstrates that preserving temporal information significantly improves model performance in such scenarios. We compare a multilayer perceptron, a windowed multilayer perceptron, and a convolutional neural network (CNN) on three-phase air-water-oil flow data from 342 experiments. Whereas prior work typically compresses each experiment into a single averaged sample, we instead compute short-time averages from within each experiment and train models that preserve temporal information at several downsampling intervals. The CNN performed best at 0.25 Hz with approximately 95 % of relative errors below 13 %, a normalized root mean squared error of 0.03, and a mean absolute percentage error of approximately 4.3 %, clearly outperforming the best single-averaged model and demonstrating that short-time averaging within individual experiments is preferable. Results are consistent across multiple data splits and random seeds, demonstrating robustness.

</details>


### [819] [Deterministic and probabilistic neural surrogates of global hybrid-Vlasov simulations](https://arxiv.org/abs/2601.12614)
*Daniel Holmberg,Ivan Zaitsev,Markku Alho,Ioanna Bouri,Fanni Franssila,Haewon Jeong,Minna Palmroth,Teemu Roos*

Main category: physics.space-ph

Relevance: 15.0

TL;DR: 该论文提出使用图神经网络构建混合Vlasov模拟的机器学习仿真器，实现等离子体状态预测的加速和不确定性量化


<details>
  <summary>Details</summary>
Motivation: 混合Vlasov模拟虽然能解析离子动力学效应，但计算成本极高（即使是5D模拟）。需要开发高效仿真器来加速太阳风-磁层相互作用的模拟，使其适用于实时应用

Method: 使用图神经网络架构在2D空间网格上操作，开发确定性预测模型（Graph-FM）和基于潜在变量公式的概率集合预测模型（Graph-EFM）。训练时加入散度惩罚确保磁场无散性，概率模型加入连续排序概率评分目标改善集合预测校准

Result: 仿真器在单GPU上生成下一个时间步的速度比原始模拟（使用100个CPU）快两个数量级以上，同时能准确匹配不同运行的物理磁层响应，并提供预测不确定性

Conclusion: 机器学习方法能使混合Vlasov模拟适用于实时应用，同时提供预测不确定性，为空间等离子体物理模拟开辟了新途径

Abstract: Hybrid-Vlasov simulations resolve ion-kinetic effects for modeling the solar wind-magnetosphere interaction, but even 5D (2D + 3V) simulations are computationally expensive. We show that graph-based machine learning emulators can learn the spatiotemporal evolution of electromagnetic fields and lower order moments of ion velocity distribution in the near-Earth space environment from four 5D Vlasiator runs performed with identical steady solar wind conditions. The initial ion number density is systematically varied, while the grid spacing is held constant, to scan the ratio of the characteristic ion skin depth to the numerical grid size. Using a graph neural network architecture operating on the 2D spatial simulation grid comprising 670k cells, we demonstrate that both a deterministic forecasting model (Graph-FM) and a probabilistic ensemble forecasting model (Graph-EFM) based on a latent variable formulation are capable of producing accurate predictions of future plasma states. A divergence penalty is incorporated during training to encourage divergence-freeness in the magnetic fields and improve physical consistency. For the probabilistic model, a continuous ranked probability score objective is added to improve the calibration of the ensemble forecasts. When trained, the emulators achieve more than two orders of magnitude speedup in generating the next time step relative to the original simulation on a single GPU compared to 100 CPUs for the Vlasiator runs, while closely matching physical magnetospheric response of the different runs. These results demonstrate that machine learning offers a way to make hybrid-Vlasov simulation tractable for real-time use while providing forecast uncertainty.

</details>


### [820] [Learning Deterministic Finite-State Machines from the Prefixes of a Single String is NP-Complete](https://arxiv.org/abs/2601.12621)
*Radu Cosmin Dumitru,Ryo Yoshinaka,Ayumi Shinohara*

Main category: cs.FL

Relevance: 15.0

TL;DR: 该论文研究了在给定前缀封闭样本集下计算最小DFA（确定性有限自动机）的计算复杂度问题，证明了即使在样本集仅包含单个二进制字符串的所有前缀时，该问题也是NP难的，且对于Moore和Mealy机器同样成立。


<details>
  <summary>Details</summary>
Motivation: 先前研究已经确定了在何种输入样本条件下计算最小一致DFA是易处理或困难的。本研究专注于前缀封闭样本集这一特殊情况，这等价于计算与运行观察一致的最小Moore机器，旨在理解这种特殊约束下的计算复杂性。

Method: 采用计算复杂性理论的分析方法，通过构造性证明展示问题难解性。具体证明了：1) 当样本集包含所有二进制字符串前缀时，问题NP难近似；2) 当样本集仅包含单个二进制字符串的所有前缀时，决策问题仍是NP难的；3) 将论证扩展到Mealy机器。

Result: 证明了计算与前缀封闭样本集一致的最小DFA是NP难的，即使样本集仅包含单个二进制字符串的所有前缀。同时证明了该问题的近似版本也是NP难的，且这些结果同样适用于Moore和Mealy机器。

Conclusion: 前缀封闭性这一看似自然的约束并不能使最小DFA计算问题变得易处理，即使在最受限的情况下（单个字符串的所有前缀）仍然是NP难的。这表明在自动机学习领域，即使施加显著的结构约束，最小化问题本质上仍是困难的。

Abstract: It is well known that computing a minimum DFA consistent with a given set of positive and negative examples is NP-hard. Previous work has identified conditions on the input sample under which the problem becomes tractable or remains hard. In this paper, we study the computational complexity of the case where the input sample is prefix-closed. This formulation is equivalent to computing a minimum Moore machine consistent with observations along its runs. We show that the problem is NP-hard to approximate when the sample set consists of all prefixes of binary strings. Furthermore, we show that the problem remains NP-hard as a decision problem even when the sample set consists of the prefixes of a single binary string. Our argument also extends to the corresponding problem for Mealy machines.

</details>


### [821] [Reorienting off-path Nudged Elastic Bands (RONEB) via Minimum Mode Following](https://arxiv.org/abs/2601.12630)
*Rohit Goswami,Miha Gunde,Hannes Jónsson*

Main category: physics.chem-ph

Relevance: 15.0

TL;DR: RONEB是一种自适应混合算法，结合了双端NEB方法和单端最小模式跟随方法的优点，用于高效计算化学反应过渡态，相比传统CI-NEB方法减少了46.3%的梯度调用。


<details>
  <summary>Details</summary>
Motivation: 准确确定过渡态对于理解反应动力学至关重要。传统双端方法（如NEB）计算成本高且在平坦或粗糙势能面上容易停滞，而单端特征模式跟随方法虽然高效但无法约束特定状态之间。需要一种结合两者优点的自适应混合算法。

Method: RONEB（Reorienting Off-path Nudged Elastic Bands）是一种自适应混合算法，整合了NEB的双端特性和最小模式跟随方法的加速能力。通过路径优化历史稳定性、相对力触发机制和基于对齐的后退惩罚，动态地将爬升图像从弹性带约束中解耦。

Result: 在Baker-Chan过渡态测试集上，使用PET-MAD机器学习势能，相比基准CI-NEB方法，梯度调用中位数减少46.3% [95% CrI: -54.7%, -36.9%]。在Pt(111)七聚体岛表面扩散测试中，59种金属重排机制平均减少28%的计算量。

Conclusion: RONEB被证明是高效高通量自动化化学发现的有效工具，显著减少了过渡态搜索的计算成本，同时保持了双端方法的可靠性。

Abstract: Accurate determination of transition states remains central to understanding reaction kinetics. Double-ended methods like the Nudged Elastic Band (NEB) ensure relevant transition states and paths, but incur high computational costs and suffer stagnation on flat or rough potential energy surfaces. Conversely, single-ended eigenmode-following techniques offer efficiency but cannot often be constrained between specific states. Here, we present the Reorienting Off-path Nudged Elastic Bands (RONEB), an adaptive hybrid algorithm that integrates the double ended nature of the NEB with the acceleration of single ended Min-Mode Following methods. RONEB provides stability based on the history of the path optimization, relative force triggering, and an alignment-based back-off penalty to dynamically decouple the climbing image from the elastic band constraints. We benchmark the method against the standard Climbing Image NEB (CI-NEB) across the Baker-Chan transition state test set using the PET-MAD machine-learned potential and the OptBench Pt(111) heptamer island surface diffusion set. A Bayesian analysis of the performance data quantifies a median reduction in gradient calls of 46.3% [95% CrI: -54.7%, -36.9%] relative to the baseline, while surface diffusion tests reveal a 28% reduction across 59 metallic rearrangement mechanisms. These results establish RONEB as a highly effective tool for high-throughput automated chemical discovery.

</details>


### [822] [Energy-Efficient Prediction in Textile Manufacturing: Enhancing Accuracy and Data Efficiency With Ensemble Deep Transfer Learning](https://arxiv.org/abs/2601.12663)
*Yan-Chen Chen,Wei-Yu Chiu,Qun-Yu Wang,Jing-Wei Chen,Hao-Ting Zhao*

Main category: eess.SP

Relevance: 15.0

TL;DR: 提出EDTL框架，结合迁移学习和集成策略，用于数据有限的纺织工厂能耗预测，提升预测精度和数据效率。


<details>
  <summary>Details</summary>
Motivation: 纺织工厂能耗高，需要节能优化。传统DNN需要大量历史数据，但传感器部署和数据收集成本高，数据获取困难。

Method: 提出Ensemble Deep Transfer Learning (EDTL)框架：1) 在数据丰富的生产线（源域）预训练DNN模型；2) 通过迁移学习适配到数据有限的生产线（目标域）；3) 集成策略结合多个模型；4) 特征对齐层提升域适应能力。

Result: 在真实纺织工厂数据集上，EDTL相比传统DNN：预测精度提升5.66%，模型鲁棒性提升3.96%，在数据有限场景（20%-40%数据可用性）表现尤其突出。

Conclusion: EDTL为纺织制造提供了一种数据高效、可扩展的节能生产优化方案，减少了对大数据集的依赖，有助于智能生产系统建设。

Abstract: Traditional textile factories consume substantial energy, making energy-efficient production optimization crucial for sustainability and cost reduction. Meanwhile, deep neural networks (DNNs), which are effective for factory output prediction and operational optimization, require extensive historical data, posing challenges due to high sensor deployment and data collection costs. To address this, we propose Ensemble Deep Transfer Learning (EDTL), a novel framework that enhances prediction accuracy and data efficiency by integrating transfer learning with an ensemble strategy and a feature alignment layer. EDTL pretrains DNN models on data-rich production lines (source domain) and adapts them to data-limited lines (target domain), reducing dependency on large datasets. Experiments on real-world textile factory datasets show that EDTL improves prediction accuracy by 5.66% and enhances model robustness by 3.96% compared to conventional DNNs, particularly in data-limited scenarios (20%-40% data availability). This research contributes to energy-efficient textile manufacturing by enabling accurate predictions with fewer data requirements, providing a scalable and cost-effective solution for smart production systems.

</details>


### [823] [SoundPlot: An Open-Source Framework for Birdsong Acoustic Analysis and Neural Synthesis with Interactive 3D Visualization](https://arxiv.org/abs/2601.12752)
*Naqcho Ali Mehdi,Mohammad Adeel,Aizaz Ali Larik*

Main category: cs.SD

Relevance: 15.0

TL;DR: SoundPlot是一个开源框架，用于分析鸟类鸣叫，通过声学特征提取、降维和神经音频合成，实现实时3D可视化。


<details>
  <summary>Details</summary>
Motivation: 开发一个完整的分析-合成框架，用于生物声学、音频信号处理和计算行为学研究，特别是鸟类鸣叫分析，提供实时可视化能力。

Method: 提取频谱特征（质心、带宽、对比度）、概率YIN音高轮廓、MFCCs，映射到统一的音色空间，使用Griffin-Lim算法进行音频重建，基于Three.js的交互式可视化界面。

Result: 梅尔频谱图相关性得分超过0.92，表明高保真度地保留了感知声学结构，框架在波形分析、频谱图比较和特征空间评估方面表现出色。

Conclusion: SoundPlot是一个有效的鸟类鸣叫分析工具，具有高保真音频重建能力，开源发布（MIT许可证）促进生物声学和音频处理研究。

Abstract: We present SoundPlot, an open-source framework for analyzing avian vocalizations through acoustic feature extraction, dimensionality reduction, and neural audio synthesis. The system transforms audio signals into a multi-dimensional acoustic feature space, enabling real-time visualization of temporal dynamics in 3D using web-based interactive graphics. Our framework implements a complete analysis-synthesis pipeline that extracts spectral features (centroid, bandwidth, contrast), pitch contours via probabilistic YIN (pYIN), and mel-frequency cepstral coefficients (MFCCs), mapping them to a unified timbre space for visualization. Audio reconstruction employs the Griffin-Lim phase estimation algorithm applied to mel spectrograms. The accompanying Three.js-based interface provides dual-viewport visualization comparing original and synthesized audio trajectories with independent playback controls. We demonstrate the framework's capabilities through comprehensive waveform analysis, spectrogram comparisons, and feature space evaluation using Principal Component Analysis (PCA). Quantitative evaluation shows mel spectrogram correlation scores exceeding 0.92, indicating high-fidelity preservation of perceptual acoustic structure. SoundPlot is released under the MIT License to facilitate research in bioacoustics, audio signal processing, and computational ethology.

</details>


### [824] [Dynamic Hand Gesture Recognition for Robot Manipulator Tasks](https://arxiv.org/abs/2601.12918)
*Dharmendra Sharma,Peeyush Thakur,Sandeep Gupta,Narendra Kumar Dhar,Laxmidhar Behera*

Main category: cs.RO

Relevance: 15.0

TL;DR: 提出基于高斯混合模型的无监督方法，实时识别动态手势变化，用于人机交互中的机器人任务控制


<details>
  <summary>Details</summary>
Motivation: 解决人机交互中动态手势识别问题，使机器人能够通过手势控制执行不同任务，需要处理手势的动态变化和实时识别需求

Method: 采用基于高斯混合模型的无监督学习方法，能够处理不同手势的动态变化，实现实时识别

Result: 在训练和实时测试中都取得了高准确率，证明了方法的有效性

Conclusion: 提出的无监督高斯混合模型方法能够准确识别动态手势变化，实现实时人机交互

Abstract: This paper proposes a novel approach to recognizing dynamic hand gestures facilitating seamless interaction between humans and robots. Here, each robot manipulator task is assigned a specific gesture. There may be several such tasks, hence, several gestures. These gestures may be prone to several dynamic variations. All such variations for different gestures shown to the robot are accurately recognized in real-time using the proposed unsupervised model based on the Gaussian Mixture model. The accuracy during training and real-time testing prove the efficacy of this methodology.

</details>


### [825] [Polychronous Wave Computing: Timing-Native Address Selection in Spiking Networks](https://arxiv.org/abs/2601.13079)
*Natalila G. Berloff*

Main category: cond-mat.dis-nn

Relevance: 15.0

TL;DR: 提出Polychronous Wave Computing (PWC)，一种基于时序的地址选择原语，将相对脉冲延迟直接映射到波域中的离散输出路径，用于脉冲神经网络的快速路由协处理器。


<details>
  <summary>Details</summary>
Motivation: 脉冲时序提供了组合地址空间，表明基于时序的脉冲推理可以作为查找和路由执行，而不是密集的乘积累加。然而大多数神经形态和光子系统仍将事件数字化为时间戳、分箱或频率，然后在时钟逻辑中执行选择。需要一种原生的时序地址选择方法。

Method: 引入PWC：1) 在旋转框架中对脉冲时间进行相位编码；2) 通过可编程多端口干涉仪并行评估K个模板相关性；3) 驱动-耗散赢家通吃阶段执行物理argmax，发射独热输出端口。推导了相位缠绕和相互相干性施加的操作包络，将时序抖动、静态相位失配和失相合并为单个有效相位噪声预算。

Result: 仿真显示：1) 非线性竞争相比噪声线性强度读取提高了路由保真度；2) 硬件在环相位调谐在强静态失配下将时序顺序门精度从55.9%提升到97.2%。PWC为LUT风格脉冲网络和稀疏top-1门提供快速路由协处理器。

Conclusion: PWC提供了一种时序原生的地址选择原语，可直接将相对脉冲延迟映射到波域中的离散输出路径，适用于极化子、光子和振荡器平台，为脉冲神经网络和稀疏路由任务提供高效的硬件实现方案。

Abstract: Spike timing offers a combinatorial address space, suggesting that timing-based spiking inference can be executed as lookup and routing rather than as dense multiply--accumulate. Yet most neuromorphic and photonic systems still digitize events into timestamps, bins, or rates and then perform selection in clocked logic. We introduce Polychronous Wave Computing (PWC), a timing-native address-selection primitive that maps relative spike latencies directly to a discrete output route in the wave domain. Spike times are phase-encoded in a rotating frame and processed by a programmable multiport interferometer that evaluates K template correlations in parallel; a driven--dissipative winner-take-all stage then performs a physical argmax, emitting a one-hot output port. We derive the operating envelope imposed by phase wrapping and mutual coherence, and collapse timing jitter, static phase mismatch, and dephasing into a single effective phase-noise budget whose induced winner--runner-up margin predicts boundary-first failures and provides an intensity-only calibration target. Simulations show that nonlinear competition improves routing fidelity compared with noisy linear intensity readout, and that hardware-in-the-loop phase tuning rescues a temporal-order gate from 55.9% to 97.2% accuracy under strong static mismatch. PWC provides a fast routing coprocessor for LUT-style spiking networks and sparse top-1 gates (e.g., mixture-of-experts routing) across polaritonic, photonic, and oscillator platforms.

</details>


### [826] [Approximate full conformal prediction in RKHS](https://arxiv.org/abs/2601.13102)
*Davidson Lova Razafindrakoto,Alain Celisse,Jérôme Lacaille*

Main category: stat.ML

Relevance: 15.0

TL;DR: 本文提出了一种计算全保形预测置信区域的高效近似方法，通过引入"厚度"概念量化近似与全保形预测之间的差异，并提供了理论上的紧密度分析。


<details>
  <summary>Details</summary>
Motivation: 全保形预测框架虽然能够为各种估计器构建分布无关的置信预测区域，但传统上存在计算瓶颈：需要训练无限多个估计器（如连续值预测），这在实践中通常无法实现。

Method: 提出了一种通用策略来设计全保形预测区域的紧近似，该近似可以高效计算。引入了"厚度"这一新概念来量化近似置信区域与全保形置信区域之间的差异，并基于损失函数和得分函数的平滑性假设，开发了该近似紧度的理论量化方法。

Result: 开发了一个可以高效计算的近似置信区域，并提供了该近似与全保形预测之间差异的理论量化框架。新引入的"厚度"概念为评估近似质量提供了数学工具。

Conclusion: 本文解决了全保形预测的计算瓶颈问题，通过提出高效近似方法和理论分析框架，使得分布无关的置信预测在实际应用中更加可行。

Abstract: Full conformal prediction is a framework that implicitly formulates distribution-free confidence prediction regions for a wide range of estimators. However, a classical limitation of the full conformal framework is the computation of the confidence prediction regions, which is usually impossible since it requires training infinitely many estimators (for real-valued prediction for instance). The main purpose of the present work is to describe a generic strategy for designing a tight approximation to the full conformal prediction region that can be efficiently computed. Along with this approximate confidence region, a theoretical quantification of the tightness of this approximation is developed, depending on the smoothness assumptions on the loss and score functions. The new notion of thickness is introduced for quantifying the discrepancy between the approximate confidence region and the full conformal one.

</details>


### [827] [SolARED: Solar Active Region Emergence Dataset for Machine Learning Aided Predictions](https://arxiv.org/abs/2601.13145)
*Spiridon Kasapis,Eren Dogan,Irina N. Kitiashvili,Alexander G. Kosovichev,John T. Stefan,Jake D. Butler,Jonas Tirona,Sarang Patil,Mengjia Xu*

Main category: astro-ph.SR

Relevance: 15.0

TL;DR: SolARED是一个用于太阳活动区早期检测的机器学习数据集，包含2010-2023年间50个大型活动区出现前后的多模态太阳观测数据，旨在提升太阳活动预测能力。


<details>
  <summary>Details</summary>
Motivation: 太阳爆发活动预报对保护空间技术和探索任务至关重要。需要检测太阳表面活动区形成前的早期信号，以开发空间天气扰动的预警能力。

Method: 基于太阳动力学观测站HMI仪器的多普勒速度、磁场和连续谱强度全盘图，创建了包含50个大型活动区出现前后时间序列的数据集，包括声学功率、无符号磁通量和连续谱强度等特征。

Result: 开发了SolARED数据集，提供机器学习就绪的数据格式，支持通过交互式可视化网页应用访问，旨在增强太阳活动区出现的预测能力。

Conclusion: SolARED数据集为开发太阳活动区出现的操作预报提供了重要基础，有助于提升空间天气预警能力。

Abstract: The development of accurate forecasts of solar eruptive activity has become increasingly important for preventing potential impacts on space technologies and exploration. Therefore, it is crucial to detect Active Regions (ARs) before they start forming on the solar surface. This will enable the development of early-warning capabilities for upcoming space weather disturbances. For this reason, we prepared the Solar Active Region Emergence Dataset (SolARED). The dataset is derived from full-disk maps of the Doppler velocity, magnetic field, and continuum intensity, obtained by the Helioseismic and Magnetic Imager (HMI) onboard the Solar Dynamics Observatory (SDO). SolARED includes time series of remapped, tracked, and binned data that characterize the evolution of acoustic power of solar oscillations, unsigned magnetic flux, and continuum intensity for 50 large ARs before, during, and after their emergence on the solar surface, as well as surrounding areas observed on the solar disc between 2010 and 2023. The resulting ML-ready SolARED dataset is designed to support enhancements of predictive capabilities, enabling the development of operational forecasts for the emergence of active regions. The SolARED dataset is available at https://sun.njit.edu/sarportal/, through an interactive visualization web application.

</details>


### [828] [Improving Geopolitical Forecasts with Bayesian Networks](https://arxiv.org/abs/2601.13362)
*Matthew Martin*

Main category: stat.AP

Relevance: 15.0

TL;DR: 贝叶斯网络在预测准确性上与逻辑回归和校准聚合方法比较，使用Good Judgment Project数据，发现校准聚合方法表现最佳，贝叶斯网络次之，逻辑回归最差。


<details>
  <summary>Details</summary>
Motivation: 探索贝叶斯网络是否能比传统的逻辑回归和校准聚合方法提供更好的预测准确性，特别是在群体预测环境中。

Method: 使用Good Judgment Project数据，比较正则化逻辑回归模型、基线校准聚合方法与两种贝叶斯网络（结构学习BN和朴素BN）。分析四个预测变量：与聚合值的绝对差异、预测值、距离问题关闭的天数、平均标准化Brier分数。

Result: 校准聚合方法获得最高准确率（AUC = 0.985），其次是两种贝叶斯网络，逻辑回归模型表现最差。贝叶斯网络性能可能因离散化过程的信息损失而受损，逻辑回归则可能因线性假设违反而表现不佳。

Conclusion: 贝叶斯网络在预测准确性上优于逻辑回归但不如校准聚合方法。未来研究应探索贝叶斯网络与逻辑回归的混合方法，考察更多预测变量，并考虑层次数据依赖关系。

Abstract: This study explores how Bayesian networks (BNs) can improve forecast accuracy compared to logistic regression and recalibration and aggregation methods, using data from the Good Judgment Project. Regularized logistic regression models and a baseline recalibrated aggregate were compared to two types of BNs: structure-learned BNs with arcs between predictors, and naive BNs. Four predictor variables were examined: absolute difference from the aggregate, forecast value, days prior to question close, and mean standardized Brier score. Results indicated the recalibrated aggregate achieved the highest accuracy (AUC = 0.985), followed by both types of BNs, then the logistic regression models. Performance of the BNs was likely harmed by reduced information from the discretization process and violation of the assumption of linearity likely harmed the logistic regression models. Future research should explore hybrid approaches combining BNs with logistic regression, examine additional predictor variables, and account for hierarchical data dependencies.

</details>


### [829] [Distribution-Free Confidence Ellipsoids for Ridge Regression with PAC Bounds](https://arxiv.org/abs/2601.13436)
*Szabolcs Szentpéteri,Balázs Csanád Csáji*

Main category: stat.ML

Relevance: 15.0

TL;DR: 本文扩展了SPS EOA算法到岭回归，推导了置信椭球尺寸的PAC上界，并分析了正则化参数对区域大小的影响。


<details>
  <summary>Details</summary>
Motivation: 在线性参数化模型中，当输入激励不足时，最小二乘估计可能无法求解或数值不稳定。虽然正则化（如岭回归）可以解决此问题，但需要量化估计不确定性。现有的SPS EOA算法只能用于普通线性回归，需要扩展到岭回归场景。

Method: 扩展Sign-Perturbed Sums (SPS)椭球外逼近算法到岭回归，推导出置信区域尺寸的Probably Approximately Correct (PAC)上界，分析正则化参数对区域大小的影响。

Result: 获得了比先前分析更紧的上界，在更弱的激励假设下成立，并明确展示了正则化参数如何影响置信区域大小。仿真实验验证了正则化的实际效果。

Conclusion: 成功将SPS EOA算法扩展到岭回归，提供了置信椭球尺寸的理论保证，为线性参数化模型在激励不足情况下的不确定性量化提供了有效工具。

Abstract: Linearly parametrized models are widely used in control and signal processing, with the least-squares (LS) estimate being the archetypical solution. When the input is insufficiently exciting, the LS problem may be unsolvable or numerically unstable. This issue can be resolved through regularization, typically with ridge regression. Although regularized estimators reduce the variance error, it remains important to quantify their estimation uncertainty. A possible approach for linear regression is to construct confidence ellipsoids with the Sign-Perturbed Sums (SPS) ellipsoidal outer approximation (EOA) algorithm. The SPS EOA builds non-asymptotic confidence ellipsoids under the assumption that the noises are independent and symmetric about zero. This paper introduces an extension of the SPS EOA algorithm to ridge regression, and derives probably approximately correct (PAC) upper bounds for the resulting region sizes. Compared with previous analyses, our result explicitly show how the regularization parameter affects the region sizes, and provide tighter bounds under weaker excitation assumptions. Finally, the practical effect of regularization is also demonstrated via simulation experiments.

</details>


### [830] [Small Gradient Norm Regret for Online Convex Optimization](https://arxiv.org/abs/2601.13519)
*Wenzhi Gao,Chang He,Madeleine Udell*

Main category: stat.ML

Relevance: 15.0

TL;DR: 本文为在线凸优化引入了一种新的问题依赖遗憾度量——$G^\star$遗憾，它基于累积平方梯度范数，比现有的$L^\star$（小损失）遗憾更精细，在损失函数在最优解附近曲率消失时表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有在线凸优化中的$L^\star$遗憾度量在某些情况下不够精细，特别是在损失函数在最优解附近曲率消失时。作者希望提出一种更精细的遗憾度量，能够更好地反映优化问题的本质特性。

Method: 提出$G^\star$遗憾度量，定义为$\sum_{t=1}^T \|\nabla \ell(x^\star)\|^2$，即累积平方梯度范数在事后最优决策处的评估。建立了该度量的上下界，并扩展到动态遗憾和bandit设置。

Result: 证明了$G^\star$遗憾严格细化了$L^\star$遗憾，在损失函数在最优解附近曲率消失时可以任意更优。建立了理论上下界，并在插值机制下改进了随机优化算法的收敛性分析。

Conclusion: $G^\star$遗憾为在线凸优化提供了一种更精细的问题依赖性能度量，特别适用于损失函数在最优解附近曲率消失的情况，对优化理论有重要贡献。

Abstract: This paper introduces a new problem-dependent regret measure for online convex optimization with smooth losses. The notion, which we call the $G^\star$ regret, depends on the cumulative squared gradient norm evaluated at the decision in hindsight $\sum_{t=1}^T \|\nabla \ell(x^\star)\|^2$. We show that the $G^\star$ regret strictly refines the existing $L^\star$ (small loss) regret, and that it can be arbitrarily sharper when the losses have vanishing curvature around the hindsight decision. We establish upper and lower bounds on the $G^\star$ regret and extend our results to dynamic regret and bandit settings. As a byproduct, we refine the existing convergence analysis of stochastic optimization algorithms in the interpolation regime. Some experiments validate our theoretical findings.

</details>


### [831] [Co-Initialization of Control Filter and Secondary Path via Meta-Learning for Active Noise Control](https://arxiv.org/abs/2601.13849)
*Ziyi Yang,Li Rao,Zhengding Luo,Dongyuan Shi,Qirui Huang,Woon-Seng Gan*

Main category: eess.AS

Relevance: 15.0

TL;DR: 该论文提出了一种基于模型无关元学习（MAML）的协同初始化方法，用于前馈主动噪声控制（ANC）系统，通过联合设置控制滤波器和次级路径模型来快速适应声学环境变化。


<details>
  <summary>Details</summary>
Motivation: 主动噪声控制需要在声学环境变化时快速适应，但早期性能主要取决于初始化。现有方法在环境变化时初始化效果不佳，导致早期误差大、收敛慢。

Method: 使用模型无关元学习（MAML）进行协同初始化，联合设置FxLMS控制滤波器和次级路径模型。通过少量实测路径进行预训练，采用两阶段内循环模拟识别和残差噪声降低过程，运行时只需设置学习到的初始系数。

Result: 在在线次级路径建模FxLMS测试平台上，相比无重新初始化的基线，该方法实现了更低的早期误差、更短的达到目标时间、更少的辅助噪声能量以及路径变化后更快的恢复速度。

Conclusion: 该方法为前馈主动噪声控制在环境变化下提供了简单快速的启动方案，仅需少量路径进行预训练，保持运行时算法不变。

Abstract: Active noise control (ANC) must adapt quickly when the acoustic environment changes, yet early performance is largely dictated by initialization. We address this with a Model-Agnostic Meta-Learning (MAML) co-initialization that jointly sets the control filter and the secondary-path model for FxLMS-based ANC while keeping the runtime algorithm unchanged. The initializer is pre-trained on a small set of measured paths using short two-phase inner loops that mimic identification followed by residual-noise reduction, and is applied by simply setting the learned initial coefficients. In an online secondary path modeling FxLMS testbed, it yields lower early-stage error, shorter time-to-target, reduced auxiliary-noise energy, and faster recovery after path changes than a baseline without re-initialization. The method provides a simple fast start for feedforward ANC under environment changes, requiring a small set of paths to pre-train.

</details>


### [832] [Unified Unbiased Variance Estimation for MMD: Robust Finite-Sample Performance with Imbalanced Data and Exact Acceleration under Null and Alternative Hypotheses](https://arxiv.org/abs/2601.13874)
*Shijie Zhong,Jiangfeng Fu,Yikun Yang*

Main category: stat.ML

Relevance: 15.0

TL;DR: 该论文研究了最大均值差异(MMD)统计量的方差特性，提出了统一有限样本表征，并在拉普拉斯核下单变量情况下实现了从O(n²)到O(n log n)的计算加速。


<details>
  <summary>Details</summary>
Motivation: MMD是用于双样本检验的核基非参数统计量，其推断准确性严重依赖于方差表征。现有方法提供了各种MMD方差的有限样本估计器，但这些估计器在零假设和备择假设下、平衡或不平衡采样方案中往往不同，缺乏统一的理论框架。

Method: 通过U统计量表示和Hoeffding分解研究MMD统计量的方差，建立覆盖不同假设和样本配置的统一有限样本表征。基于此分析，针对拉普拉斯核下的单变量情况，提出精确加速方法。

Result: 建立了MMD方差在不同假设和样本配置下的统一理论框架，并在拉普拉斯核下单变量情况下实现了计算复杂度从O(n²)到O(n log n)的显著降低。

Conclusion: 该研究为MMD方差提供了统一的理论表征，并展示了特定核函数下的高效计算方法，为双样本检验的统计推断提供了更坚实的理论基础和计算效率。

Abstract: The maximum mean discrepancy (MMD) is a kernel-based nonparametric statistic for two-sample testing, whose inferential accuracy depends critically on variance characterization. Existing work provides various finite-sample estimators of the MMD variance, often differing under the null and alternative hypotheses and across balanced or imbalanced sampling schemes. In this paper, we study the variance of the MMD statistic through its U-statistic representation and Hoeffding decomposition, and establish a unified finite-sample characterization covering different hypotheses and sample configurations. Building on this analysis, we propose an exact acceleration method for the univariate case under the Laplacian kernel, which reduces the overall computational complexity from $\mathcal O(n^2)$ to $\mathcal O(n \log n)$.

</details>
