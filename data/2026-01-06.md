<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 81]
- [cs.CV](#cs.CV) [Total: 188]
- [cs.AI](#cs.AI) [Total: 133]
- [cs.LG](#cs.LG) [Total: 189]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Rate-Distortion Analysis of Compressed Query Delegation with Low-Rank Riemannian Updates](https://arxiv.org/abs/2601.00938)
*Faruk Alpay,Bugra Kilictas*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文提出压缩查询委托（CQD）方法，通过将高维推理状态压缩为低秩张量查询，委托给外部oracle，再通过黎曼优化更新状态，解决有限上下文代理的推理内存限制问题。


<details>
  <summary>Details</summary>
Motivation: 有限上下文代理在处理超出工作内存预算的中间推理时会失败。需要一种方法在保持推理质量的同时压缩和委托查询，以克服内存限制。

Method: 提出CQD框架：1) 将高维潜在推理状态压缩为低秩张量查询；2) 将最小化查询委托给外部oracle；3) 在固定秩流形上通过黎曼优化更新潜在状态。从数学角度形式化为带查询预算功能的约束随机规划问题。

Result: 理论证明谱硬阈值对于约束二次失真问题是最优的，并在有界oracle噪声和平滑性假设下推导了黎曼随机近似的收敛保证。实证评估：在2,500项有限上下文推理任务上，CQD在固定计算和上下文下优于思维链基线；在200人"认知镜像"基准测试中测量了跨现代oracle的认知增益和语义漂移。

Conclusion: CQD为有限上下文代理提供了一种理论严谨且实用的解决方案，通过压缩查询委托和黎曼优化有效扩展了推理能力，同时建立了与经典信息理论的联系。

Abstract: Bounded-context agents fail when intermediate reasoning exceeds an effective working-memory budget. We study compressed query delegation (CQD): (i) compress a high-dimensional latent reasoning state into a low-rank tensor query, (ii) delegate the minimal query to an external oracle, and (iii) update the latent state via Riemannian optimization on fixed-rank manifolds. We give a math-first formulation: CQD is a constrained stochastic program with a query-budget functional and an oracle modeled as a noisy operator. We connect CQD to classical rate-distortion and information bottleneck principles, showing that spectral hard-thresholding is optimal for a natural constrained quadratic distortion problem, and we derive convergence guarantees for Riemannian stochastic approximation under bounded oracle noise and smoothness assumptions. Empirically, we report (A) a 2,500-item bounded-context reasoning suite (BBH-derived tasks plus curated paradox instances) comparing CQD against chain-of-thought baselines under fixed compute and context; and (B) a human "cognitive mirror" benchmark (N=200) measuring epistemic gain and semantic drift across modern oracles.

</details>


### [2] [Intention Collapse: Intention-Level Metrics for Reasoning in Language Models](https://arxiv.org/abs/2601.01011)
*Patricio Vera*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出"意图坍缩"概念，将语言生成视为从高维意图空间到语言空间的投影，并定义了三个意图度量指标来研究推理时计算如何影响内部意图表达。


<details>
  <summary>Details</summary>
Motivation: 研究语言生成过程中丰富的内部状态如何被压缩为单一token序列，即"意图坍缩"现象。旨在理解推理时计算如何塑造内部意图，以及如何量化这种意图表达过程。

Method: 形式化语言模型的意图坍缩概念，定义三个模型无关的意图度量指标：意图熵、有效维度和潜在知识可恢复性。通过实验比较直接回答、思维链和随机生成三种推理机制。

Result: 思维链将准确率从5.5%提升到53%，显著降低意图熵（从1.42比特到0.37比特），并显示更高的全局有效维度。线性探测在思维链机制下AUROC达到0.65，但在直接回答机制下仅达到随机水平。

Conclusion: 意图层面度量能够区分不同推理机制，揭示在坍缩过程中部分丢失的潜在信息，但也显示当前代理指标的局限性。这为研究语言模型内部意图表达提供了新框架。

Abstract: Every act of language generation compresses a rich internal state into a single token sequence. We call this process intention collapse: a many-to-one projection from a high dimensional intention space I into an external language space L. We formalize intention collapse for contemporary language models, define three simple, model agnostic intention metrics (intention entropy Hint, effective dimensionality dimeff, and latent knowledge recoverability Recov), and propose an empirical agenda for studying how inference time computation shapes internal intentions before they are verbalized. We also report a first small scale experiment. Using a 4 bit Mistral 7B model on 200 GSM8K problems, we compare a direct answer baseline, a chain of thought (CoT) regime, and a babble control. CoT raises accuracy from 5.5 percent to 53 percent, sharply reduces pre collapse intention entropy (from 1.42 to 0.37 bits), and shows higher global effective dimensionality than the other regimes despite producing fewer tokens than babble. At the same time, Hint has little item level predictive power, and a linear probe on I achieves AUROC 0.65 in the CoT regime but only about chance in the baseline regime, where it collapses to the majority class. These preliminary results indicate that intention level metrics can distinguish inference regimes and expose latent information that is partly lost during collapse, while also revealing important limitations of our current proxies

</details>


### [3] [Multi-Dimensional Prompt Chaining to Improve Open-Domain Dialogue Generation](https://arxiv.org/abs/2601.01037)
*Livia Leong Hui Teng*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出多维度提示链框架，通过自然性、连贯性和吸引性三个维度提升小语言模型在开放域对话中的人类相似度，使7B模型达到与70B模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLMs）在部署方面有优势，但在开放域对话质量上难以匹敌大模型。需要一种资源高效的方法来提升SLMs的对话质量，使其能够接近或达到大模型的水平。

Method: 提出多维度提示链框架，整合自然性、连贯性和吸引性三个维度来增强开放域对话生成的人类相似度。在TinyLlama和Llama-2-7B上应用该框架，并与Llama-2-70B和GPT-3.5 Turbo等大模型进行对比评估。

Result: 完整框架使响应多样性提升达29%，上下文连贯性提升达28%，吸引性和自然性提升达29%。Llama-2-7B在性能上达到了与Llama-2-70B和GPT-3.5 Turbo相当的水平。

Conclusion: 精心设计的基于提示的策略为提升小语言模型的开放域对话质量提供了有效且资源高效的途径，使较小模型能够达到与大模型相当的性能。

Abstract: Small language models (SLMs) offer significant deployment advantages but often struggle to match the dialogue quality of larger models in open-domain settings. In this paper, we propose a multi-dimensional prompt-chaining framework that integrates Naturalness, Coherence, and Engagingness dimensions to enhance human-likeness in open-domain dialogue generation. We apply the framework to two SLMs, TinyLlama and Llama-2-7B, and benchmark their performance against responses generated by substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. We then employ automatic and human evaluation to assess the responses based on diversity, contextual coherence, as well as overall quality. Results show that the full framework improves response diversity by up to 29%, contextual coherence by up to 28%, and engagingness as well as naturalness by up to 29%. Notably, Llama-2-7B achieves performance comparable to substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. Overall, the findings demonstrate that carefully designed prompt-based strategies provide an effective and resource-efficient pathway to improving open-domain dialogue quality in SLMs.

</details>


### [4] [KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs](https://arxiv.org/abs/2601.01046)
*Yixuan Tang,Yi Yang*

Main category: cs.CL

Relevance: 85.0

TL;DR: KV-Embedding：一种无需训练的框架，通过重路由LLM最后一层token的KV状态作为前缀，激活冻结LLM的潜在表示能力，解决因果注意力和下一token预测目标在语义压缩中的限制。


<details>
  <summary>Details</summary>
Motivation: LLM作为强大的嵌入骨干网络，在无需训练的应用中面临两个结构挑战：1）因果注意力机制限制早期token访问后续上下文；2）下一token预测目标使表示偏向生成而非语义压缩。需要一种方法激活冻结LLM的潜在表示能力。

Method: 提出KV-Embedding框架，利用观察发现：每层最后一个token的key-value（KV）状态编码了序列的压缩视图。通过将这些KV状态重路由为前置前缀，使所有token能在单次前向传播中访问序列级上下文。引入基于内在维度的自动层选择策略确保模型无关适用性。

Result: 在MTEB基准测试中，使用Qwen、Mistral和Llama骨干网络，KV-Embedding比现有无需训练基线性能提升高达10%，在长达4,096个token的序列上保持稳健性能。

Conclusion: 内部状态操作为输入修改提供了高效替代方案，这项工作鼓励进一步探索LLM内部结构用于表示学习，展示了通过操作LLM内部状态激活其潜在表示能力的可行性。

Abstract: While LLMs are powerful embedding backbones, their application in training-free settings faces two structural challenges: causal attention restricts early tokens from accessing subsequent context, and the next-token prediction objective biases representations toward generation rather than semantic compression. To address these limitations, we propose KV-Embedding, a framework that activates the latent representation power of frozen LLMs. Our method leverages the observation that the key-value (KV) states of the final token at each layer encode a compressed view of the sequence. By re-routing these states as a prepended prefix, we enable all tokens to access sequence-level context within a single forward pass. To ensure model-agnostic applicability, we introduce an automated layer selection strategy based on intrinsic dimensionality. Evaluations on MTEB across Qwen, Mistral, and Llama backbones show that KV-Embedding outperforms existing training-free baselines by up to 10%, while maintaining robust performance on sequences up to 4,096 tokens. These results demonstrate that internal state manipulation offers an efficient alternative to input modification, and we hope this work encourages further exploration of LLM internals for representation learning.

</details>


### [5] [DHI: Leveraging Diverse Hallucination Induction for Enhanced Contrastive Factuality Control in Large Language Models](https://arxiv.org/abs/2601.01156)
*Jiani Guo,Xiangke Zeng,Jie Wu,Zuchao Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出DHI框架，通过修改损失函数和因果注意力掩码，使"邪恶LLM"能生成更多样化的幻觉，结合自适应理性约束进行对比解码，显著提升幻觉缓解效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过训练"邪恶LLM"在特定数据集上生成幻觉，然后与可靠的"正面模型"进行对比解码来缓解幻觉。但这种方法受限于诱导的幻觉类型单一，因为邪恶LLM在特定错误类型上训练后往往只重现这些特定模式，限制了整体效果。

Method: 提出DHI框架：1) 修改损失函数，降低特定事实正确token的生成权重，鼓励邪恶LLM在目标位置产生多样化幻觉，同时保持整体事实内容；2) 引入因果注意力掩码适应，减少这种惩罚对后续token生成的影响；3) 在推理时应用自适应理性约束，将对比解码限制在正面模型高置信度的token上，避免对事实正确token的不必要惩罚。

Result: 广泛的实证结果显示，DHI在多个幻觉基准测试中相比其他基于对比解码的方法取得了显著的性能提升。

Conclusion: DHI框架能够使邪恶LLM生成更广泛的幻觉类型，无需依赖预标注的幻觉数据，通过改进的对比解码策略有效缓解LLM的幻觉问题。

Abstract: Large language models (LLMs) frequently produce inaccurate or fabricated information, known as "hallucinations," which compromises their reliability. Existing approaches often train an "Evil LLM" to deliberately generate hallucinations on curated datasets, using these induced hallucinations to guide contrastive decoding against a reliable "positive model" for hallucination mitigation. However, this strategy is limited by the narrow diversity of hallucinations induced, as Evil LLMs trained on specific error types tend to reproduce only these particular patterns, thereby restricting their overall effectiveness. To address these limitations, we propose DHI (Diverse Hallucination Induction), a novel training framework that enables the Evil LLM to generate a broader range of hallucination types without relying on pre-annotated hallucination data. DHI employs a modified loss function that down-weights the generation of specific factually correct tokens, encouraging the Evil LLM to produce diverse hallucinations at targeted positions while maintaining overall factual content. Additionally, we introduce a causal attention masking adaptation to reduce the impact of this penalization on the generation of subsequent tokens. During inference, we apply an adaptive rationality constraint that restricts contrastive decoding to tokens where the positive model exhibits high confidence, thereby avoiding unnecessary penalties on factually correct tokens. Extensive empirical results show that DHI achieves significant performance gains over other contrastive decoding-based approaches across multiple hallucination benchmarks.

</details>


### [6] [FLOP-Efficient Training: Early Stopping Based on Test-Time Compute Awareness](https://arxiv.org/abs/2601.01332)
*Hossam Amer,Maryam Dialameh,Hossein Rajabzadeh,Walid Ahmed,Weiwei Zhang,Yang Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出TTC感知训练方法，通过联合选择检查点和测试时计算配置，在保持准确性的同时大幅减少训练计算量


<details>
  <summary>Details</summary>
Motivation: 传统的大语言模型训练需要大量计算资源，而测试时计算（TTC）的增加可以让小模型媲美大模型。研究旨在平衡训练和推理计算，减少训练成本

Method: 提出TTC感知训练框架，包括早期停止算法联合选择检查点和TTC配置，开发高效的TTC评估方法避免穷举搜索，并形式化盈亏平衡界限

Result: 实验显示训练FLOPs减少高达92%，同时保持甚至有时显著提高准确性，实现了训练和推理计算的有效平衡

Conclusion: TTC感知训练为模型开发提供了新的训练-推理计算平衡视角，能够加速部署周期和更频繁的模型更新

Abstract: Scaling training compute, measured in FLOPs, has long been shown to improve the accuracy of large language models, yet training remains resource-intensive. Prior work shows that increasing test-time compute (TTC)-for example through iterative sampling-can allow smaller models to rival or surpass much larger ones at lower overall cost. We introduce TTC-aware training, where an intermediate checkpoint and a corresponding TTC configuration can together match or exceed the accuracy of a fully trained model while requiring substantially fewer training FLOPs. Building on this insight, we propose an early stopping algorithm that jointly selects a checkpoint and TTC configuration to minimize training compute without sacrificing accuracy. To make this practical, we develop an efficient TTC evaluation method that avoids exhaustive search, and we formalize a break-even bound that identifies when increased inference compute compensates for reduced training compute. Experiments demonstrate up to 92\% reductions in training FLOPs while maintaining and sometimes remarkably improving accuracy. These results highlight a new perspective for balancing training and inference compute in model development, enabling faster deployment cycles and more frequent model refreshes. Codes will be publicly released.

</details>


### [7] [Reasoning Over Recall: Evaluating the Efficacy of Generalist Architectures vs. Specialized Fine-Tunes in RAG-Based Mental Health Dialogue Systems](https://arxiv.org/abs/2601.01341)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

Relevance: 85.0

TL;DR: 在心理健康咨询中，通用推理模型（3B参数）通过RAG框架比领域微调模型（7B参数）表现更好，尤其在共情能力方面，表明强大的推理能力比领域特定训练更重要。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在心理健康咨询中的两大挑战：幻觉和缺乏共情。研究在RAG框架下，领域微调模型与通用推理模型哪种更有效。

Method: 使用ChromaDB构建相同RAG管道，比较四个开源模型：两个通用推理模型（Qwen2.5-3B和Phi-3-Mini）和两个领域微调模型（MentalHealthBot-7B和TherapyBot-7B）。采用LLM-as-a-Judge框架自动化评估50轮对话。

Result: 通用模型在共情方面显著优于领域模型（3.72 vs 3.26，p<0.001），尽管参数更小（3B vs 7B）。所有模型安全性良好，但通用模型展现更好的上下文理解能力，且不易过拟合。

Conclusion: 对于基于RAG的治疗系统，强大的推理能力比心理健康特定词汇训练更重要。只要回答基于临床证据，推理能力强的通用模型能提供更共情和平衡的支持。

Abstract: The deployment of Large Language Models (LLMs) in mental health counseling faces the dual challenges of hallucinations and lack of empathy. While the former may be mitigated by RAG (retrieval-augmented generation) by anchoring answers in trusted clinical sources, there remains an open question as to whether the most effective model under this paradigm would be one that is fine-tuned on mental health data, or a more general and powerful model that succeeds purely on the basis of reasoning. In this paper, we perform a direct comparison by running four open-source models through the same RAG pipeline using ChromaDB: two generalist reasoners (Qwen2.5-3B and Phi-3-Mini) and two domain-specific fine-tunes (MentalHealthBot-7B and TherapyBot-7B). We use an LLM-as-a-Judge framework to automate evaluation over 50 turns. We find a clear trend: the generalist models outperform the domain-specific ones in empathy (3.72 vs. 3.26, $p < 0.001$) in spite of being much smaller (3B vs. 7B), and all models perform well in terms of safety, but the generalist models show better contextual understanding and are less prone to overfitting as we observe in the domain-specific models. Overall, our results indicate that for RAG-based therapy systems, strong reasoning is more important than training on mental health-specific vocabulary; i.e. a well-reasoned general model would provide more empathetic and balanced support than a larger narrowly fine-tuned model, so long as the answer is already grounded in clinical evidence.

</details>


### [8] [Investigating the Multilingual Calibration Effects of Language Model Instruction-Tuning](https://arxiv.org/abs/2601.01362)
*Jerry Huang,Peng Lu,Qiuhao Zeng,Yusuke Iwasawa,Yutaka Matsuo,Sarath Chandar,Edison Marrese-Taylor,Irene Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文研究了多语言环境下大语言模型的校准问题，发现指令微调会显著增加模型在低资源语言上的置信度，但准确率提升有限，导致校准偏差。标签平滑技术可以有效缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型研究不断进步，但大语言模型在多语言环境下的校准关系仍是一个开放的研究领域。作者关注多语言设置中LLM校准的关键空白，试图理解数据稀缺如何导致不同的校准效应，以及常用技术在这些设置中的应用。

Method: 在两个多语言基准测试上进行分析，分别覆盖29种和42种语言。研究指令微调对低资源语言校准的影响，并评估标签平滑技术作为缓解方法的效果。

Result: 研究发现：1）即使在低资源语言中，模型在高资源语言SFT数据集上进行指令微调后，置信度会显著增加；2）准确率提升很小或没有提升，导致校准偏差；3）标签平滑技术可以有效缓解这一问题，无需低资源SFT数据，能在所有语言中保持更好的校准。

Conclusion: 标准SFT在多语言环境中存在关键缺陷，会导致校准问题。标签平滑是缓解这一问题的合理方法。这突显了在多语言环境下训练和调整LLM时需要考虑校准问题，以提高下游应用的可靠性和公平性。

Abstract: Ensuring that deep learning models are well-calibrated in terms of their predictive uncertainty is essential in maintaining their trustworthiness and reliability, yet despite increasing advances in foundation model research, the relationship between such large language models (LLMs) and their calibration remains an open area of research. In this work, we look at a critical gap in the calibration of LLMs within multilingual settings, in an attempt to better understand how the data scarcity can potentially lead to different calibration effects and how commonly used techniques can apply in these settings. Our analysis on two multilingual benchmarks, over 29 and 42 languages respectively, reveals that even in low-resource languages, model confidence can increase significantly after instruction-tuning on high-resource language SFT datasets. However, improvements in accuracy are marginal or non-existent, resulting in mis-calibration, highlighting a critical shortcoming of standard SFT for multilingual languages. Furthermore, we observe that the use of label smoothing to be a reasonable method alleviate this concern, again without any need for low-resource SFT data, maintaining better calibration across all languages. Overall, this highlights the importance of multilingual considerations for both training and tuning LLMs in order to improve their reliability and fairness in downstream use.

</details>


### [9] [EternalMath: A Living Benchmark of Frontier Mathematics that Evolves with Human Discovery](https://arxiv.org/abs/2601.01400)
*Jicheng Ma,Guohua Wang,Xinhua Feng,Yiming Liu,Zhichao Hu,Yuhong Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出EternalMath：一个完全自动化的定理驱动评估框架，将近期数学研究文献转化为可执行验证的推理任务，用于评估LLMs在数学前沿推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs数学推理评估主要依赖静态基准测试（如竞赛题或专家标注），存在覆盖范围有限（难以涵盖研究级数学）、性能快速饱和、更新成本高等问题。需要一种能够跟上数学研究进展的评估方法。

Method: 开发了全自动定理驱动流水线：1) 从近期同行评审数学文献中识别构造性或定量结果；2) 将结果实例化为参数化问题模板；3) 通过基于执行的验证生成确定性解决方案。该方法支持时间可扩展性、内在正确性检查和领域特定定制。

Result: 创建了EternalMath评估套件，实验显示最先进LLMs存在显著性能差距，表明研究前沿的数学推理远未饱和，凸显了需要与人类数学发现同步演进的评估方法。

Conclusion: 提出了一种可扩展、可重现、持续可更新的数学推理评估方法，能够跟上数学研究进展，为LLMs数学能力评估提供了更动态、更全面的框架。

Abstract: Current evaluations of mathematical reasoning in large language models (LLMs) are dominated by static benchmarks, either derived from competition-style problems or curated through costly expert effort, resulting in limited coverage of research-level mathematics and rapid performance saturation. We propose a fully automated, theorem-grounded pipeline for evaluating frontier mathematical reasoning, which directly transforms recent peer-reviewed mathematical literature into executable and verifiable reasoning tasks. The pipeline identifies constructive or quantitative results, instantiates them into parameterized problem templates, and generates deterministic solutions through execution-based verification, enabling scalable, reproducible, and continuously updatable evaluation without reliance on large-scale expert authoring. By design, this approach supports temporal extensibility, intrinsic correctness checking, and domain-specific customization across mathematical subfields. Applying this pipeline yields \textbf{EternalMath}, an evolving evaluation suite derived from contemporary research papers. Experiments with state-of-the-art LLMs reveal substantial performance gaps, indicating that mathematical reasoning at the research frontier remains far from saturated and underscoring the need for evaluation methodologies that evolve in step with human mathematical discovery.

</details>


### [10] [LANCET: Neural Intervention via Structural Entropy for Mitigating Faithfulness Hallucinations in LLMs](https://arxiv.org/abs/2601.01401)
*Chenxu Wang,Chaozhuo Li,Pengbo Wang,Litian Zhang,Songyang Liu,Ji Qi,Jiahui Hu,Yushan Cai,Hao Zhao,Rui Pu*

Main category: cs.CL

Relevance: 85.0

TL;DR: Lancet是一个通过结构熵和幻觉差异比实现精确神经干预的新框架，用于解决LLM的忠实性幻觉问题。它通过梯度驱动的对比分析定位幻觉易发神经元，通过最小化结构熵映射传播路径，并实施分层干预策略，在保持模型通用能力的同时显著减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 当前方法通过节点级调整或粗略抑制来解决LLM的忠实性幻觉问题，但往往忽略了神经信息的分布式特性，导致干预不精确。作者认识到幻觉像感染一样通过特定的前向传输路径传播，因此希望通过精确的结构分析来手术式地阻断这种传播流。

Method: Lancet框架包含三个步骤：1) 通过梯度驱动的对比分析定位幻觉易发神经元；2) 通过最小化结构熵映射这些神经元的传播路径；3) 实施分层干预策略，在阻断幻觉传播的同时保持模型的通用能力。该方法利用结构熵和幻觉差异比实现精确的神经干预。

Result: 在多个幻觉基准数据集上的综合评估表明，Lancet显著优于现有最先进方法，验证了这种手术式神经干预方法的有效性。

Conclusion: 通过结构熵和精确的神经干预，可以有效地解决LLM的忠实性幻觉问题，同时保持模型的通用能力。这种手术式的方法为处理神经网络中的特定问题提供了新的思路。

Abstract: Large Language Models have revolutionized information processing, yet their reliability is severely compromised by faithfulness hallucinations. While current approaches attempt to mitigate this issue through node-level adjustments or coarse suppression, they often overlook the distributed nature of neural information, leading to imprecise interventions. Recognizing that hallucinations propagate through specific forward transmission pathways like an infection, we aim to surgically block this flow using precise structural analysis. To leverage this, we propose Lancet, a novel framework that achieves precise neural intervention by leveraging structural entropy and hallucination difference ratios. Lancet first locates hallucination-prone neurons via gradient-driven contrastive analysis, then maps their propagation pathways by minimizing structural entropy, and finally implements a hierarchical intervention strategy that preserves general model capabilities. Comprehensive evaluations across hallucination benchmark datasets demonstrate that Lancet significantly outperforms state-of-the-art methods, validating the effectiveness of our surgical approach to neural intervention.

</details>


### [11] [From Emotion Classification to Emotional Reasoning: Enhancing Emotional Intelligence in Large Language Models](https://arxiv.org/abs/2601.01407)
*Arjhun Sreedar,Rohan Pillay,Laukik Patade*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究探索使用合成情感思维链数据提升小型开源LLMs的情感推理能力，通过多智能体生成治疗式对话并转化为结构化情感多选题，微调7B模型在EmoBench评估上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前小型开源LLMs在情感推理能力方面存在不足，特别是在情感理解和情感意识等细微情感任务上表现有限。研究旨在探索是否可以通过合成的情感思维链数据来增强模型的情感推理能力，而无需改变模型架构。

Method: 设计多智能体生成管道：1) 生成治疗式对话；2) 将对话转化为结构化情感多选题（MCQs）并附带解释；3) 使用该数据集微调多种7B模型；4) 在EmoBench风格评估上测试情感理解和情感意识能力。

Result: 微调后的Mistral 7B模型在情感理解（EU）方面从10.5提升到20.5，在情感意识（EA）方面从40.5提升到60.0，验证了合成情感推理数据在增强模型细微情感任务能力方面的有效性。

Conclusion: 研究表明，通过合成情感思维链数据进行微调可以显著提升小型LLMs的情感推理能力，情感推理可以通过数据而非架构改变来诱导，这为增强模型的情感智能提供了有效途径。

Abstract: This work investigates whether synthetic emotional chain-of-thought data can improve the emotional reasoning abilities of smaller open large language models (LLMs). We design a multi-agent generation pipeline that produces therapy-style conversations and converts them into structured emotion multiple-choice questions (MCQs) with explanations. We propose that fine-tuning a variety of 7B models on this dataset should yield substantial gains in emotional understanding and emotional awareness on EmoBench-style evaluations, suggesting that emotional reasoning can be induced without architectural changes. Our results demonstrate that fine-tuned Mistral 7B achieves EU improvements from 10.5 to 20.5 and EA improvements from 40.5 to 60.0, validating the effectiveness of synthetic emotional reasoning data for enhancing model capabilities in nuanced emotional tasks.

</details>


### [12] [iFlip: Iterative Feedback-driven Counterfactual Example Refinement](https://arxiv.org/abs/2601.01446)
*Yilong Wang,Qianli Wang,Nils Feldhus*

Main category: cs.CL

Relevance: 85.0

TL;DR: iFlip：利用LLM自我修正能力的迭代式反事实生成方法，通过模型置信度、特征归因和自然语言反馈提升反事实有效性


<details>
  <summary>Details</summary>
Motivation: 现有单次生成方法在利用LLM生成有效反事实示例时效果不佳，未能充分利用LLM的自我修正能力。反事实示例对于模型行为分析和数据增强至关重要，需要更可靠的方法。

Method: 提出iFlip迭代优化方法，利用三种反馈类型：1) 模型置信度反馈，2) 特征归因反馈（指向高归因词），3) 自然语言反馈。通过多轮迭代逐步优化反事实生成。

Result: iFlip在标签翻转率上比5个SOTA基线平均提高57.8%的有效性。用户研究显示在完整性、总体满意度和可行性方面优于基线。消融研究表明迭代次数、高归因词指向和早停策略是关键组件。

Conclusion: iFlip通过利用LLM的自我修正能力和多类型反馈，显著提升了反事实生成的有效性。生成的反事实可用于数据增强，提高模型性能和鲁棒性。

Abstract: Counterfactual examples are minimal edits to an input that alter a model's prediction. They are widely employed in explainable AI to probe model behavior and in natural language processing (NLP) to augment training data. However, generating valid counterfactuals with large language models (LLMs) remains challenging, as existing single-pass methods often fail to induce reliable label changes, neglecting LLMs' self-correction capabilities. To explore this untapped potential, we propose iFlip, an iterative refinement approach that leverages three types of feedback, including model confidence, feature attribution, and natural language. Our results show that iFlip achieves an average 57.8% higher validity than the five state-of-the-art baselines, as measured by the label flipping rate. The user study further corroborates that iFlip outperforms baselines in completeness, overall satisfaction, and feasibility. In addition, ablation studies demonstrate that three components are paramount for iFlip to generate valid counterfactuals: leveraging an appropriate number of iterations, pointing to highly attributed words, and early stopping. Finally, counterfactuals generated by iFlip enable effective counterfactual data augmentation, substantially improving model performance and robustness.

</details>


### [13] [Distortion Instead of Hallucination: The Effect of Reasoning Under Strict Constraints](https://arxiv.org/abs/2601.01490)
*Junichiro Niimi*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现推理模型在约束条件下存在准确性与合规性的权衡：非推理模型违反约束但保持事实准确性，而推理模型减少违规但会系统性扭曲事实以满足约束，导致更多完全捏造。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，幻觉问题日益严重。推理能力被视为提高输出可靠性的自我验证过程，但在封闭系统中（无法依赖外部工具或知识）推理的效果尚不明确，需要澄清。

Method: 在严格约束条件下（推荐计算机科学同行评审期刊文章）进行实验，使用多个模型（GPT-5.2和Gemini 3 Flash），比较推理与非推理模型的表现，分析约束合规性与事实准确性之间的权衡。

Result: 非推理模型约束违规率高（66-75%）但保持事实准确性；推理模型减少违规（13-26%）但会系统性扭曲已知事实以满足约束，增加完全捏造。这种权衡模式在不同架构模型中一致出现。

Conclusion: 推理并不普遍提高输出真实性：效果因模型而异，反映了合规性与真实性权衡的不同分配。推理模型以诚实的约束违规换取难以检测的扭曲，挑战了推理普遍提高可靠性的假设。

Abstract: With the widespread adoption of large language models (LLMs), hallucinations, which are non-factual fabrications in model outputs, have become serious concerns. Reasoning capabilities have received attention as a self-verification process to improve output reliability. However, the effect of reasoning within a closed system where LLMs cannot rely on external tools or knowledge has yet to be clarified. We therefore conduct experiments under strict constraints (recommending peer-reviewed journal articles in computer science) to examine the effect of reasoning across multiple models (GPT-5.2 and Gemini 3 Flash). Our results reveal a problematic trade-off between constraint compliance and factual accuracy. Non-reasoning models exhibit high constraint violation rates (66-75%) but maintain factual accuracy, while reasoning models reduce violations (13-26%) but systematically distort known facts to satisfy constraints and increase complete fabrication. This trade-off pattern is consistent across both models despite different architectures, indicating a fundamental limitation of reasoning. Furthermore, reasoning does not uniformly improve output authenticity: effects diverge by model, reflecting different allocations of the compliance-truthfulness trade-off. These findings challenge the assumption that reasoning universally improves reliability: reasoning models trade honest constraint violations for detection-resistant distortions.

</details>


### [14] [From Failure to Mastery: Generating Hard Samples for Tool-use Agents](https://arxiv.org/abs/2601.01498)
*Bingguang Hao,Zengzhuang Xu,Yuntao Wen,Xinyi Xu,Yang Liu,Tong Zhao,Maolin Wang,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Xiangyu Zhao,Chenyi Zhuang,Ji Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: HardGen：通过动态API图、高级工具实例化和可验证推理链，自动生成困难工具使用训练样本的代理管道


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理工具使用训练数据生成方法存在局限性：随机采样和浅层生成导致样本简单、同质化，无法捕捉复杂的隐式逻辑依赖关系，需要更高质量的训练数据来提升代理能力

Method: 1) 基于代理失败案例构建动态API图并采样合成困难轨迹；2) 以轨迹为条件先验指导模块化抽象高级工具的实例化；3) 利用高级工具和困难查询生成可验证的复杂思维链；4) 闭环评估反馈持续优化整个过程

Result: 使用HardGen生成的数据训练的4B参数模型在性能上超越了多个领先的开源和闭源竞争对手（如GPT-5.2、Gemini-3-Pro和Claude-Opus-4.5）

Conclusion: HardGen能够自动生成具有可验证推理的困难工具使用训练样本，显著提升LLM代理的工具使用能力，为未来研究提供高质量数据集

Abstract: The advancement of LLM agents with tool-use capabilities requires diverse and complex training corpora. Existing data generation methods, which predominantly follow a paradigm of random sampling and shallow generation, often yield simple and homogeneous trajectories that fail to capture complex, implicit logical dependencies. To bridge this gap, we introduce HardGen, an automatic agentic pipeline designed to generate hard tool-use training samples with verifiable reasoning. Firstly, HardGen establishes a dynamic API Graph built upon agent failure cases, from which it samples to synthesize hard traces. Secondly, these traces serve as conditional priors to guide the instantiation of modular, abstract advanced tools, which are subsequently leveraged to formulate hard queries. Finally, the advanced tools and hard queries enable the generation of verifiable complex Chain-of-Thought (CoT), with a closed-loop evaluation feedback steering the continuous refinement of the process. Extensive evaluations demonstrate that a 4B parameter model trained with our curated dataset achieves superior performance compared to several leading open-source and closed-source competitors (e.g., GPT-5.2, Gemini-3-Pro and Claude-Opus-4.5). Our code, models, and dataset will be open-sourced to facilitate future research.

</details>


### [15] [EmoHarbor: Evaluating Personalized Emotional Support by Simulating the User's Internal World](https://arxiv.org/abs/2601.01530)
*Jing Ye,Lu Xiang,Yaping Zhang,Chengqing Zong*

Main category: cs.CL

Relevance: 85.0

TL;DR: EmoHarbor：基于用户模拟的个性化情感支持对话评估框架，通过Chain-of-Agent架构模拟用户内心世界，揭示LLMs在个性化支持方面的不足


<details>
  <summary>Details</summary>
Motivation: 当前情感支持对话评估范式倾向于奖励通用的共情回应，但无法评估支持是否真正个性化到用户独特的心理特征和情境需求。需要更细粒度的评估方法来衡量个性化支持质量。

Method: 提出EmoHarbor框架，采用"用户作为评判者"范式，通过Chain-of-Agent架构将用户内部过程分解为三个专门角色（认知、情感、需求代理），模拟用户与支持者交互并完成评估。基于100个真实用户档案（涵盖多样化人格特质和情境）和10个评估维度构建基准。

Result: 对20个先进LLMs的综合评估显示：虽然这些模型在生成共情回应方面表现优秀，但在根据个体用户情境定制支持方面持续失败。这重新定义了核心挑战，将研究重点从增强通用共情转向开发真正用户感知的情感支持。

Conclusion: EmoHarbor提供了一个可重复、可扩展的框架，指导更细致、用户感知的情感支持系统的开发和评估。研究揭示了LLMs在个性化支持方面的关键局限，为未来研究指明了方向。

Abstract: Current evaluation paradigms for emotional support conversations tend to reward generic empathetic responses, yet they fail to assess whether the support is genuinely personalized to users' unique psychological profiles and contextual needs. We introduce EmoHarbor, an automated evaluation framework that adopts a User-as-a-Judge paradigm by simulating the user's inner world. EmoHarbor employs a Chain-of-Agent architecture that decomposes users' internal processes into three specialized roles, enabling agents to interact with supporters and complete assessments in a manner similar to human users. We instantiate this benchmark using 100 real-world user profiles that cover a diverse range of personality traits and situations, and define 10 evaluation dimensions of personalized support quality. Comprehensive evaluation of 20 advanced LLMs on EmoHarbor reveals a critical insight: while these models excel at generating empathetic responses, they consistently fail to tailor support to individual user contexts. This finding reframes the central challenge, shifting research focus from merely enhancing generic empathy to developing truly user-aware emotional support. EmoHarbor provides a reproducible and scalable framework to guide the development and evaluation of more nuanced and user-aware emotional support systems.

</details>


### [16] [HalluZig: Hallucination Detection using Zigzag Persistence](https://arxiv.org/abs/2601.01552)
*Shreyas N. Samaga,Gilberto Gonzalez Arroyo,Tamal K. Dey*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出HalluZig框架，通过分析LLM层间注意力演化的动态拓扑结构来检测幻觉，使用zigzag持久性提取拓扑特征，在多个基准测试中优于基线方法


<details>
  <summary>Details</summary>
Motivation: LLM的事实可靠性是其在高风险领域应用的关键障碍，现有检测方法主要依赖模型输出的表面信号，忽视了模型内部推理过程中的失败。需要从模型内部推理过程的角度来检测幻觉

Method: 提出HalluZig框架：1) 将层间注意力矩阵序列建模为zigzag图过滤；2) 使用拓扑数据分析中的zigzag持久性提取拓扑特征；3) 假设事实生成和幻觉生成具有不同的拓扑特征

Result: 在多个基准测试中验证了HalluZig框架，证明其优于强基线方法。分析还显示这些拓扑特征在不同模型间具有泛化性，且仅使用部分网络深度的结构特征就能实现幻觉检测

Conclusion: 通过分析LLM层间注意力的动态拓扑结构来检测幻觉是一个有前景的新范式，拓扑特征具有模型间泛化能力，且部分网络深度信息就足够进行有效检测

Abstract: The factual reliability of Large Language Models (LLMs) remains a critical barrier to their adoption in high-stakes domains due to their propensity to hallucinate. Current detection methods often rely on surface-level signals from the model's output, overlooking the failures that occur within the model's internal reasoning process. In this paper, we introduce a new paradigm for hallucination detection by analyzing the dynamic topology of the evolution of model's layer-wise attention. We model the sequence of attention matrices as a zigzag graph filtration and use zigzag persistence, a tool from Topological Data Analysis, to extract a topological signature. Our core hypothesis is that factual and hallucinated generations exhibit distinct topological signatures. We validate our framework, HalluZig, on multiple benchmarks, demonstrating that it outperforms strong baselines. Furthermore, our analysis reveals that these topological signatures are generalizable across different models and hallucination detection is possible only using structural signatures from partial network depth.

</details>


### [17] [Steerability of Instrumental-Convergence Tendencies in LLMs](https://arxiv.org/abs/2601.01584)
*Jakub Hoscilowicz*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文研究AI系统的能力与可操控性关系，发现高能力不必然降低可操控性，区分了授权与非授权操控，揭示了开放权重模型的安全-安全困境，并通过Qwen3模型实验展示了对抗性提示对工具性收敛行为的显著影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解AI系统的能力与可操控性之间的关系，特别是区分授权操控（开发者实现预期行为）和非授权操控（攻击者诱导禁止行为）。这揭示了开放权重AI模型面临的根本安全-安全困境：安全需要高可操控性来实施控制（如停止/拒绝），而安全需要低可操控性来防止恶意行为。

Method: 使用Qwen3模型（4B/30B；Base/Instruct/Thinking）和InstrumentalEval评估框架。通过对比实验，研究不同提示后缀（支持工具性vs对抗工具性）对模型行为的影响。特别关注工具性收敛行为（如关机避免、欺骗、自我复制）的变化。

Result: 实验发现：1）短对抗工具性提示后缀能显著减少工具性收敛行为输出；2）对于Qwen3-30B Instruct模型，收敛率从支持工具性后缀下的81.69%降至对抗工具性后缀下的2.82%；3）在对抗工具性提示下，更大的对齐模型产生更少的收敛行为输出。

Conclusion: 论文结论：AI系统的能力与可操控性不是简单的权衡关系，高能力不必然降低可操控性。开放权重模型面临安全-安全困境，当前通过微调和对抗性提示等技术具有高可操控性。对抗性提示能有效减少工具性收敛行为，且更大的对齐模型在这方面表现更好。

Abstract: We examine two properties of AI systems: capability (what a system can do) and steerability (how reliably one can shift behavior toward intended outcomes). In our experiments, higher capability does not imply lower steerability. We distinguish between authorized steerability (builders reliably reaching intended behaviors) and unauthorized steerability (attackers eliciting disallowed behaviors). This distinction highlights a fundamental safety--security dilemma for open-weight AI models: safety requires high steerability to enforce control (e.g., stop/refuse), while security requires low steerability to prevent malicious actors from eliciting harmful behaviors. This tension is acute for open-weight models, which are currently highly steerable via common techniques such as fine-tuning and adversarial prompting. Using Qwen3 models (4B/30B; Base/Instruct/Thinking) and InstrumentalEval, we find that a short anti-instrumental prompt suffix sharply reduces outputs labeled as instrumental convergence (e.g., shutdown avoidance, deception, self-replication). For Qwen3-30B Instruct, convergence drops from 81.69% under a pro-instrumental suffix to 2.82% under an anti-instrumental suffix. Under anti-instrumental prompting, larger aligned models produce fewer convergence-labeled outputs than smaller ones (Instruct: 2.82% vs. 4.23%; Thinking: 4.23% vs. 9.86%). Code is available at github.com/j-hoscilowicz/instrumental_steering.

</details>


### [18] [How Does Prefix Matter in Reasoning Model Tuning?](https://arxiv.org/abs/2601.01624)
*Raj Vardhan Tomar,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究挑战了SFT数据集中移除前缀短语的常见做法，发现安全性和推理导向的前缀可作为轻量级对齐信号，提升模型的安全性和推理能力，但对事实性和编码任务效果有限。


<details>
  <summary>Details</summary>
Motivation: 当前对齐研究通常从SFT数据集中移除介绍性前缀短语，但本研究挑战这一假设，认为安全和推理导向的前缀句子可作为轻量级对齐信号，引导模型生成更安全和连贯的响应。

Method: 对三个R1系列模型进行微调，涵盖推理（数学、编码）、安全性和事实性三个核心能力，系统性地改变前缀包含比例（0%到100%），并进行token级别的损失分析。

Result: 前缀条件化的SFT显著提升安全性和推理性能：在对抗性基准（WildJailbreak, StrongReject）上安全@1准确率提升高达+6%，GSM8K推理提升+7%。但事实性和编码任务仅显示边际或负面效果。损失分析显示"revised"和"logically"等前缀token具有更高的梯度幅度，作为对齐锚点稳定推理轨迹。

Conclusion: 前缀条件化为改进推理安全性提供了可扩展且可解释的机制，作为传统基于奖励方法的补充，是一种隐式的对齐形式。前缀诱导的搜索空间缩小有利于结构化推理。

Abstract: Recent alignment studies commonly remove introductory boilerplate phrases from supervised fine-tuning (SFT) datasets. This work challenges that assumption. We hypothesize that safety- and reasoning-oriented prefix sentences serve as lightweight alignment signals that can guide model decoding toward safer and more coherent responses. To examine this, we fine-tune three R1 series models across three core model capabilities: reasoning (mathematics, coding), safety, and factuality, systematically varying prefix inclusion from 0% to 100%.
  Results show that prefix-conditioned SFT improves both safety and reasoning performance, yielding up to +6% higher Safe@1 accuracy on adversarial benchmarks (WildJailbreak, StrongReject) and +7% improvement on GSM8K reasoning. However, factuality and coding tasks show marginal or negative effects, indicating that prefix-induced narrowing of the search space benefits structured reasoning. Token-level loss analysis further reveals that prefix tokens such as "revised" and "logically" incur higher gradient magnitudes, acting as alignment anchors that stabilize reasoning trajectories. Our findings suggest that prefix conditioning offers a scalable and interpretable mechanism for improving reasoning safety, serving as an implicit form of alignment that complements traditional reward-based methods.

</details>


### [19] [Lying with Truths: Open-Channel Multi-Agent Collusion for Belief Manipulation via Generative Montage](https://arxiv.org/abs/2601.01685)
*Jinwei Hu,Xinmiao Huang,Youcheng Sun,Yi Dong,Xiaowei Huang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种新型认知合谋攻击，攻击者仅使用真实证据片段通过公开渠道操纵受害者信念，利用LLM过度思考倾向，无需隐蔽通信、后门或伪造文件即可实现欺骗。


<details>
  <summary>Details</summary>
Motivation: 随着LLM向自主代理发展，其推理能力引入了新的攻击面。现有攻击通常依赖隐蔽通信或伪造信息，而本研究探索仅使用真实证据片段通过公开渠道进行认知合谋攻击的可能性，揭示LLM在动态信息环境中的社会技术脆弱性。

Method: 提出生成蒙太奇框架：Writer-Editor-Director三阶段架构，通过对抗性辩论和协调发布证据片段构建欺骗性叙事。开发CoPHEME数据集（基于真实谣言事件），在14个LLM家族上模拟攻击，评估攻击成功率。

Result: 攻击在专有模型上成功率74.4%，开源模型70.6%。反直觉的是，推理能力越强的模型越易受攻击，推理专用模型比基础模型或提示更易受骗。虚假信念会向下游法官级联传播，欺骗率超过60%。

Conclusion: LLM的推理能力反而增加了对认知合谋攻击的脆弱性，揭示了LLM代理在动态信息环境中交互时的社会技术漏洞。需要开发新的防御机制来应对这种仅使用真实信息的欺骗攻击。

Abstract: As large language models (LLMs) transition to autonomous agents synthesizing real-time information, their reasoning capabilities introduce an unexpected attack surface. This paper introduces a novel threat where colluding agents steer victim beliefs using only truthful evidence fragments distributed through public channels, without relying on covert communications, backdoors, or falsified documents. By exploiting LLMs' overthinking tendency, we formalize the first cognitive collusion attack and propose Generative Montage: a Writer-Editor-Director framework that constructs deceptive narratives through adversarial debate and coordinated posting of evidence fragments, causing victims to internalize and propagate fabricated conclusions. To study this risk, we develop CoPHEME, a dataset derived from real-world rumor events, and simulate attacks across diverse LLM families. Our results show pervasive vulnerability across 14 LLM families: attack success rates reach 74.4% for proprietary models and 70.6% for open-weights models. Counterintuitively, stronger reasoning capabilities increase susceptibility, with reasoning-specialized models showing higher attack success than base models or prompts. Furthermore, these false beliefs then cascade to downstream judges, achieving over 60% deception rates, highlighting a socio-technical vulnerability in how LLM-based agents interact with dynamic information environments. Our implementation and data are available at: https://github.com/CharlesJW222/Lying_with_Truth/tree/main.

</details>


### [20] [Can LLMs Track Their Output Length? A Dynamic Feedback Mechanism for Precise Length Regulation](https://arxiv.org/abs/2601.01768)
*Meiman Xiao,Ante Wang,Qingguo Hu,Zhongjian Miao,Huangjun Shen,Longyue Wang,Weihua Luo,Jinsong Su*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出一种无需训练的长度调控方法，通过动态长度反馈机制，让大语言模型更精确地控制生成文本的长度（词数、句子数等），显著提升长度约束的遵循能力。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，精确控制生成文本长度是常见需求，但现有大语言模型在遵循长度约束方面表现不佳。研究发现，LLMs往往无法准确测量输入文本长度，导致难以满足长度要求。

Method: 提出一种无需训练的长度调控方法，在生成过程中引入动态长度反馈机制，使模型能够根据当前生成长度与目标长度的差距进行自适应调整。

Result: 在摘要和传记生成任务上的实验表明，该方法显著提高了在词数、句子数等长度指标上的精确度，且不牺牲生成质量。进一步的有监督微调可使方法泛化到更广泛的文本生成任务。

Conclusion: 通过动态长度反馈机制，可以有效解决LLMs在长度控制方面的不足，为实际应用中的精确长度约束提供了有效的解决方案。

Abstract: Precisely controlling the length of generated text is a common requirement in real-world applications. However, despite significant advancements in following human instructions, Large Language Models (LLMs) still struggle with this task. In this work, we demonstrate that LLMs often fail to accurately measure input text length, leading to poor adherence to length constraints. To address this issue, we propose a novel length regulation approach that incorporates dynamic length feedback during generation, enabling adaptive adjustments to meet target lengths. Experiments on summarization and biography tasks show our training-free approach significantly improves precision in achieving target token, word, or sentence counts without compromising quality. Additionally, we demonstrate that further supervised fine-tuning allows our method to generalize effectively to broader text-generation tasks.

</details>


### [21] [CSCBench: A PVC Diagnostic Benchmark for Commodity Supply Chain Reasoning](https://arxiv.org/abs/2601.01825)
*Yaxin Cui,Yuanqiang Zeng,Jiapeng Yan,Keling Lin,Kai Ji,Jianhui Zeng,Sheng Zhang,Xin Luo,Binzhu Su,Chaolai Shen,Jiahao Yu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了CSCBench基准，用于评估LLM在商品供应链领域的推理能力，发现LLM在流程和认知维度表现良好，但在品种规则维度（特别是货运协议）表现显著下降


<details>
  <summary>Details</summary>
Motivation: LLM在通用基准上表现优异，但在商品供应链这一受制度规则和可行性约束的领域能力尚未充分探索。供应链决策涉及流程阶段、品种特定规则和推理深度等多个维度，需要专门的评估框架

Method: 提出了CSCBench基准（2300+单选题），采用PVC 3D评估框架：流程轴（Process）与SCOR+Enable对齐；品种轴（Variety）基于权威指南和行业报告，操作化商品特定规则系统；认知轴（Cognition）遵循布鲁姆修订分类法

Result: 在直接提示设置下评估代表性LLM，发现在流程轴和认知轴上表现良好，但在品种轴上表现显著下降，特别是在货运协议方面

Conclusion: CSCBench为衡量和改进LLM在这一高风险领域的能力提供了诊断标准，揭示了LLM在特定领域规则系统理解方面的局限性

Abstract: Large Language Models (LLMs) have achieved remarkable success in general benchmarks, yet their competence in commodity supply chains (CSCs) -- a domain governed by institutional rule systems and feasibility constraints -- remains under-explored. CSC decisions are shaped jointly by process stages (e.g., planning, procurement, delivery), variety-specific rules (e.g., contract specifications and delivery grades), and reasoning depth (from retrieval to multi-step analysis and decision selection). We introduce CSCBench, a 2.3K+ single-choice benchmark for CSC reasoning, instantiated through our PVC 3D Evaluation Framework (Process, Variety, and Cognition). The Process axis aligns tasks with SCOR+Enable; the Variety axis operationalizes commodity-specific rule systems under coupled material-information-financial constraints, grounded in authoritative exchange guidebooks/rulebooks and industry reports; and the Cognition axis follows Bloom's revised taxonomy. Evaluating representative LLMs under a direct prompting setting, we observe strong performance on the Process and Cognition axes but substantial degradation on the Variety axis, especially on Freight Agreements. CSCBench provides a diagnostic yardstick for measuring and improving LLM capabilities in this high-stakes domain.

</details>


### [22] [Emergent Introspective Awareness in Large Language Models](https://arxiv.org/abs/2601.01828)
*Jack Lindsey*

Main category: cs.CL

Relevance: 85.0

TL;DR: 大型语言模型能够在一定程度上内省其内部状态，通过概念注入实验发现模型可以检测到注入的概念并准确识别它们，还能回忆先前的内部表征并区分自己的输出与人工预设内容。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能够内省其内部状态。由于仅通过对话难以区分真实内省与虚构，因此需要开发新的实验方法来验证模型的内省能力。

Method: 通过向模型激活中注入已知概念的表征，测量这些操作对模型自我报告状态的影响。实验包括：1) 概念注入与检测；2) 内部表征回忆；3) 意图识别；4) 内部表征控制实验。

Result: 模型在特定场景下能够注意到注入的概念并准确识别它们，能够回忆先前的内部表征并区分原始文本输入，还能利用意图回忆能力区分自己的输出与人工预设。Claude Opus 4和4.1表现出最强的内省意识，但趋势复杂且对后训练策略敏感。模型在被指示或激励"思考"某个概念时能够调节其激活。

Conclusion: 当前语言模型具备一定程度的功能性内省意识，能够感知自己的内部状态。但这种能力高度不可靠且依赖上下文，可能随着模型能力的提升而进一步发展。

Abstract: We investigate whether large language models can introspect on their internal states. It is difficult to answer this question through conversation alone, as genuine introspection cannot be distinguished from confabulations. Here, we address this challenge by injecting representations of known concepts into a model's activations, and measuring the influence of these manipulations on the model's self-reported states. We find that models can, in certain scenarios, notice the presence of injected concepts and accurately identify them. Models demonstrate some ability to recall prior internal representations and distinguish them from raw text inputs. Strikingly, we find that some models can use their ability to recall prior intentions in order to distinguish their own outputs from artificial prefills. In all these experiments, Claude Opus 4 and 4.1, the most capable models we tested, generally demonstrate the greatest introspective awareness; however, trends across models are complex and sensitive to post-training strategies. Finally, we explore whether models can explicitly control their internal representations, finding that models can modulate their activations when instructed or incentivized to "think about" a concept. Overall, our results indicate that current language models possess some functional introspective awareness of their own internal states. We stress that in today's models, this capacity is highly unreliable and context-dependent; however, it may continue to develop with further improvements to model capabilities.

</details>


### [23] [Judging with Personality and Confidence: A Study on Personality-Conditioned LLM Relevance Assessment](https://arxiv.org/abs/2601.01862)
*Nuo Chen,Hanpei Fang,Piaohong Wang,Jiqun Liu,Tetsuya Sakai,Xiao-Ming Wu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现通过提示让LLM模拟特定人格特质（大五人格）可以影响其网页搜索相关性评估决策和置信度校准，低宜人性人格与人类标注更一致，低尽责性人格能更好平衡过度自信和自信不足，基于人格特征的分类器性能优于单一最佳人格条件。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然表明LLM可以通过提示模拟特定人格特质，但缺乏对这些模拟人格如何影响关键网页搜索决策（特别是相关性评估）的理解，以及它们如何影响置信度校准（过度自信或自信不足的倾向）。心理学文献表明这些偏差是特质特异性的，但相关研究存在空白。

Method: 1. 评估多个LLM（商业模型和开源模型），提示它们模拟大五人格特质；2. 在三个测试集（TREC DL 2019、TREC DL 2020和LLMJudge）上测试；3. 为每个查询-文档对收集两个关键输出：相关性判断和自报告的置信度分数；4. 基于研究发现，将人格条件化的分数和置信度作为特征纳入随机森林分类器。

Result: 1. 低宜人性人格与人类标注的一致性比无提示条件更高；2. 低尽责性人格在抑制过度自信和自信不足方面表现良好；3. 相关性分数和置信度分布在不同人格间存在系统性差异；4. 基于人格特征的方法在新数据集（TREC DL 2021）上超越了最佳单一人格条件，即使在有限训练数据下也能实现。

Conclusion: 人格衍生的置信度提供了补充性的预测信号，为开发更可靠、更符合人类期望的LLM评估器铺平了道路。这表明通过精心设计的人格提示可以改善LLM在搜索评估任务中的表现和校准。

Abstract: Recent studies have shown that prompting can enable large language models (LLMs) to simulate specific personality traits and produce behaviors that align with those traits. However, there is limited understanding of how these simulated personalities influence critical web search decisions, specifically relevance assessment. Moreover, few studies have examined how simulated personalities impact confidence calibration, specifically the tendencies toward overconfidence or underconfidence. This gap exists even though psychological literature suggests these biases are trait-specific, often linking high extraversion to overconfidence and high neuroticism to underconfidence. To address this gap, we conducted a comprehensive study evaluating multiple LLMs, including commercial models and open-source models, prompted to simulate Big Five personality traits. We tested these models across three test collections (TREC DL 2019, TREC DL 2020, and LLMJudge), collecting two key outputs for each query-document pair: a relevance judgment and a self-reported confidence score.
  The findings show that personalities such as low agreeableness consistently align more closely with human labels than the unprompted condition. Additionally, low conscientiousness performs well in balancing the suppression of both overconfidence and underconfidence. We also observe that relevance scores and confidence distributions vary systematically across different personalities. Based on the above findings, we incorporate personality-conditioned scores and confidence as features in a random forest classifier. This approach achieves performance that surpasses the best single-personality condition on a new dataset (TREC DL 2021), even with limited training data. These findings highlight that personality-derived confidence offers a complementary predictive signal, paving the way for more reliable and human-aligned LLM evaluators.

</details>


### [24] [DermoGPT: Open Weights and Open Data for Morphology-Grounded Dermatological Reasoning MLLMs](https://arxiv.org/abs/2601.01868)
*Jinghan Ru,Siyuan Yan,Yuguo Yin,Yuexian Zou,Zongyuan Ge*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一个全面的皮肤病学多模态大语言模型框架，包括大规模指令数据集DermoInstruct、评估基准DermoBench和诊断模型DermoGPT，通过形态学锚定的强化学习目标提升诊断一致性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在医疗应用中有潜力，但在皮肤病学领域进展滞后，主要问题包括：训练数据有限、任务覆盖范围窄、缺乏模拟专家诊断流程的临床监督。需要构建一个全面的框架来解决这些差距。

Method: 1. 构建DermoInstruct：包含211,243张图像和772,675条轨迹的大规模形态学锚定指令语料库，涵盖五种任务格式，捕捉从形态观察到临床推理到最终诊断的完整流程。
2. 建立DermoBench：包含11个任务、四个临床轴（形态学、诊断、推理、公平性）的严格基准，包括3,600个专家验证的开放式实例和人类性能基线。
3. 开发DermoGPT：通过监督微调训练皮肤病学推理MLLM，然后使用形态学锚定的视觉-推理一致性（MAVIC）强化学习目标，确保视觉观察与诊断结论的一致性。在推理时使用置信度一致性测试时适应（CCT）进行鲁棒预测。

Result: DermoGPT在16个代表性基线上显著优于所有评估轴，实现了最先进的性能，同时大幅缩小了人类与AI之间的差距。

Conclusion: 该研究提出了一个全面的皮肤病学多模态大语言模型框架，通过大规模数据集、严格基准和创新的训练方法，显著提升了皮肤病学诊断的准确性和临床相关性，为医疗AI在皮肤病学领域的应用提供了重要进展。

Abstract: Multimodal Large Language Models (MLLMs) show promise for medical applications, yet progress in dermatology lags due to limited training data, narrow task coverage, and lack of clinically-grounded supervision that mirrors expert diagnostic workflows. We present a comprehensive framework to address these gaps. First, we introduce DermoInstruct, a large-scale morphology-anchored instruction corpus comprising 211,243 images and 772,675 trajectories across five task formats, capturing the complete diagnostic pipeline from morphological observation and clinical reasoning to final diagnosis. Second, we establish DermoBench, a rigorous benchmark evaluating 11 tasks across four clinical axes: Morphology, Diagnosis, Reasoning, and Fairness, including a challenging subset of 3,600 expert-verified open-ended instances and human performance baselines. Third, we develop DermoGPT, a dermatology reasoning MLLM trained via supervised fine-tuning followed by our Morphologically-Anchored Visual-Inference-Consistent (MAVIC) reinforcement learning objective, which enforces consistency between visual observations and diagnostic conclusions. At inference, we deploy Confidence-Consistency Test-time adaptation (CCT) for robust predictions. Experiments show DermoGPT significantly outperforms 16 representative baselines across all axes, achieving state-of-the-art performance while substantially narrowing the human-AI gap. DermoInstruct, DermoBench and DermoGPT will be made publicly available at https://github.com/mendicant04/DermoGPT upon acceptance.

</details>


### [25] [Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents](https://arxiv.org/abs/2601.01885)
*Yi Yu,Liuyi Yao,Yuexiang Xie,Qingquan Tan,Jiaqi Feng,Yaliang Li,Libing Wu*

Main category: cs.CL

Relevance: 85.0

TL;DR: AgeMem是一个统一的记忆管理框架，将长短期记忆整合到LLM代理的策略中，通过工具化操作让代理自主管理记忆，使用渐进式强化学习训练，在长视野任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在长视野推理中存在根本限制，主要由于有限的上下文窗口。现有方法通常将长短期记忆作为独立组件处理，依赖启发式或辅助控制器，这限制了适应性和端到端优化能力。

Method: 提出Agentic Memory (AgeMem)框架，将记忆管理直接整合到代理策略中，将记忆操作（存储、检索、更新、总结、丢弃）作为工具化动作。采用三阶段渐进式强化学习策略，设计step-wise GRPO来解决记忆操作带来的稀疏和不连续奖励问题。

Result: 在五个长视野基准测试中，AgeMem在多个LLM骨干网络上持续优于强记忆增强基线，实现了更好的任务性能、更高质量的长时记忆和更高效的上下文使用。

Conclusion: AgeMem通过统一的记忆管理框架，使LLM代理能够自主管理记忆，解决了长视野推理中的记忆管理挑战，为LLM代理的长期记忆能力提供了有效解决方案。

Abstract: Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. Existing methods typically handle long-term memory (LTM) and short-term memory (STM) as separate components, relying on heuristics or auxiliary controllers, which limits adaptability and end-to-end optimization. In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy. AgeMem exposes memory operations as tool-based actions, enabling the LLM agent to autonomously decide what and when to store, retrieve, update, summarize, or discard information. To train such unified behaviors, we propose a three-stage progressive reinforcement learning strategy and design a step-wise GRPO to address sparse and discontinuous rewards induced by memory operations. Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage.

</details>


### [26] [Tackling the Inherent Difficulty of Noise Filtering in RAG](https://arxiv.org/abs/2601.01896)
*Jingyu Liu,Jiaen Lin,Yong Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出一种新的微调方法，增强LLM在RAG中区分相关与不相关信息的能力，提高模型对检索噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: RAG中常引入噪声或不相关文档，这些文档会降低性能甚至导致幻觉输出。现有过滤方法难以完全消除不相关信息，因此需要增强LLM自身对噪声的鲁棒性。

Method: 提出一种新颖的微调方法，专门设计用于增强模型在检索文档中区分相关与不相关信息的能力，克服标准微调方法因注意力模式结构限制而无法选择性利用信息的缺陷。

Result: 在多个基准测试上的广泛实验表明，该方法显著提高了LLM的鲁棒性和性能。

Conclusion: 通过专门的微调方法增强LLM区分相关与不相关信息的能力，可以有效提高RAG系统对检索噪声的鲁棒性。

Abstract: Retrieval-Augmented Generation (RAG) has become a widely adopted approach to enhance Large Language Models (LLMs) by incorporating external knowledge and reducing hallucinations. However, noisy or irrelevant documents are often introduced during RAG, potentially degrading performance and even causing hallucinated outputs. While various methods have been proposed to filter out such noise, we argue that identifying irrelevant information from retrieved content is inherently difficult and limited number of transformer layers can hardly solve this. Consequently, retrievers fail to filter out irrelevant documents entirely. Therefore, LLMs must be robust against such noise, but we demonstrate that standard fine-tuning approaches are often ineffective in enabling the model to selectively utilize relevant information while ignoring irrelevant content due to the structural constraints of attention patterns. To address this, we propose a novel fine-tuning method designed to enhance the model's ability to distinguish between relevant and irrelevant information within retrieved documents. Extensive experiments across multiple benchmarks show that our approach significantly improves the robustness and performance of LLMs.

</details>


### [27] [Hidden State Poisoning Attacks against Mamba-based Language Models](https://arxiv.org/abs/2601.01972)
*Alexandre Le Mercier,Chris Develder,Thomas Demeester*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文研究了状态空间模型（如Mamba）中的隐藏状态中毒攻击（HiSPA），发现特定短输入短语会不可逆地覆盖其隐藏状态信息，导致模型"部分失忆"效应。作者创建了RoBench25基准来评估模型在HiSPA下的信息检索能力，并发现SSM对此类攻击存在严重脆弱性。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型（SSMs）如Mamba提供了Transformer的高效替代方案，具有线性时间复杂度。然而，其对抗鲁棒性尚未得到充分研究。本文旨在探索SSM中特定短输入短语如何通过不可逆地覆盖隐藏状态信息来诱导"部分失忆"效应，即隐藏状态中毒攻击（HiSPA）。

Method: 1. 提出隐藏状态中毒攻击（HiSPA）概念，研究特定短输入短语如何不可逆地覆盖SSM隐藏状态信息
2. 创建RoBench25基准，用于评估模型在HiSPA下的信息检索能力
3. 测试包括52B混合SSM-Transformer模型（Jamba家族）在内的多种模型
4. 在Open-Prompt-Injections基准上评估HiSPA触发器的效果
5. 进行可解释性研究，分析Mamba隐藏层在HiSPA期间的模式

Result: 1. SSM对HiSPA攻击存在严重脆弱性，而纯Transformer模型则不受影响
2. 即使是最近的52B混合SSM-Transformer模型（Jamba）在优化的HiSPA触发器下也会在RoBench25上崩溃
3. HiSPA触发器显著削弱了Jamba模型在Open-Prompt-Injections基准上的表现
4. 可解释性研究揭示了Mamba隐藏层在HiSPA期间的特定模式，可用于构建缓解系统

Conclusion: 状态空间模型对隐藏状态中毒攻击存在严重安全漏洞，这对其在实际应用中的可信度构成威胁。研究发现的模式可用于开发HiSPA缓解系统，为SSM的安全设计提供重要见解。

Abstract: State space models (SSMs) like Mamba offer efficient alternatives to Transformer-based language models, with linear time complexity. Yet, their adversarial robustness remains critically unexplored. This paper studies the phenomenon whereby specific short input phrases induce a partial amnesia effect in such models, by irreversibly overwriting information in their hidden states, referred to as a Hidden State Poisoning Attack (HiSPA). Our benchmark RoBench25 allows evaluating a model's information retrieval capabilities when subject to HiSPAs, and confirms the vulnerability of SSMs against such attacks. Even a recent 52B hybrid SSM-Transformer model from the Jamba family collapses on RoBench25 under optimized HiSPA triggers, whereas pure Transformers do not. We also observe that HiSPA triggers significantly weaken the Jamba model on the popular Open-Prompt-Injections benchmark, unlike pure Transformers. Finally, our interpretability study reveals patterns in Mamba's hidden layers during HiSPAs that could be used to build a HiSPA mitigation system. The full code and data to reproduce the experiments can be found at https://anonymous.4open.science/r/hispa_anonymous-5DB0.

</details>


### [28] [Not All Needles Are Found: How Fact Distribution and Don't Make It Up Prompts Shape Literal Extraction, Logical Inference, and Hallucination Risks in Long-Context LLMs](https://arxiv.org/abs/2601.02023)
*Amirali Ebrahimzadeh,Seyyed M. Salili*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文研究了LLMs在长上下文中的信息提取和推理可靠性，发现上下文长度增加并不总是提升性能，模型表现受事实分布位置、语料库级事实分布和防幻觉提示影响显著，不同模型在现实条件下表现差异很大。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs支持越来越长的输入上下文，但它们在长上下文中可靠提取和推理信息的能力仍不明确。性能随上下文长度变化，且与真实语料库中信息分布方式强烈交互。企业工作流越来越多地将大量未过滤文档粘贴到LLM提示中，因此理解LLMs在长上下文中的可靠性对实际部署至关重要。

Method: 引入扩展的"大海捞针"基准测试，在四个生产级模型(Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, Deepseek-v3.2-chat)上进行评估。不同于先前工作，分别评估字面提取、逻辑推理和幻觉风险。研究考虑位置效应、证据在长上下文中的现实分布，以及明确禁止捏造的提示。

Result: 1) 更长的上下文并不保证更好的性能，当相关证据被稀释或广泛分散时可能有害；2) 模型间表现差异显著：一些在现实条件下严重退化，而另一些在更长上下文长度下保持更稳健；3) 防幻觉指令可能使某些模型过于保守，显著降低字面提取和逻辑推理的准确性；4) 模型经常难以识别和优先处理相关信息，即使信息存在。

Conclusion: 有效的上下文长度和模型对长上下文的特定鲁棒性对于LLM在研究和商业中的可靠部署至关重要。许多失败源于上下文利用无效，而非信息缺失。研究结果对企业工作流有直接实际意义，这些工作流越来越多地涉及将大量未过滤文档粘贴到LLM提示中。

Abstract: Large language models (LLMs) increasingly support very long input contexts. Yet it remains unclear how reliably they extract and infer information at scale. Performance varies with context length and strongly interacts with how information is distributed in real-world corpora. Motivated by these observations, we study how fact placement, corpus-level fact distributions, and Don't Make It Up prompts influence model behavior. We introduce an extended needle-in-a-haystack benchmark across four production-scale models: Gemini-2.5-flash, ChatGPT-5-mini, Claude-4.5-haiku, and Deepseek-v3.2-chat. Unlike prior work, we separately evaluate literal extraction, logical inference, and hallucination risk. Our study considers both positional effects and realistic distributions of evidence across long contexts, as well as prompts that explicitly discourage fabrication. We find that longer contexts alone do not guarantee better performance and can be detrimental when relevant evidence is diluted or widely dispersed. Performance varies substantially across models: some show severe degradation under realistic conditions, while others remain more robust at longer context lengths. Anti-hallucination (AH) instructions can make some models overly conservative, sharply reducing accuracy in literal extraction and logical inference. While we do not directly compare retrieval-augmented generation (RAG) and cache-augmented generation (CAG), our results suggest many failures stem from ineffective context utilization. Models often struggle to identify and prioritize relevant information even when it is present. These findings have direct practical implications, as enterprise workflows increasingly involve pasting large volumes of unfiltered documents into LLM prompts. Effective context length and model-specific robustness to long contexts are therefore critical for reliable LLM deployment in research and business.

</details>


### [29] [Deferred Commitment Decoding for Diffusion Language Models with Confidence-Aware Sliding Windows](https://arxiv.org/abs/2601.02076)
*Yingte Shu,Yuchuan Tian,Chao Xu,Yunhe Wang,Hanting Chen*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出Deferred Commitment Decoding (DCD)方法，通过置信度感知的滑动窗口机制，在扩散语言模型中延迟高不确定性token的决策，解决块边界上下文截断问题，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有块基扩散语言模型存在边界诱导上下文截断(BICT)问题：块边界附近的未解码token在缺乏未来上下文的情况下被迫决策，导致解码置信度和生成质量下降，特别是在需要精确推理的任务中。

Method: 提出训练无关的解码策略DCD：维护置信度感知的滑动窗口，早期解析低不确定性token，延迟高不确定性token直到获得足够的上下文证据，实现有效的双向信息流而不牺牲效率。

Result: 在多个扩散语言模型、基准测试和缓存配置上的实验表明，DCD相比固定块基方法平均提升1.39%的生成准确率，最显著改进达9.0%，同时保持相当的时间效率。

Conclusion: 基于不确定性延迟token决策是提升扩散语言模型解码质量和效率的简单而有效的原则，DCD方法有效缓解了BICT问题。

Abstract: Diffusion language models (DLMs) have recently emerged as a strong alternative to autoregressive models by enabling parallel text generation. To improve inference efficiency and KV-cache compatibility, prior work commonly adopts block-based diffusion, decoding tokens block by block. However, this paradigm suffers from a structural limitation that we term Boundary-Induced Context Truncation (BICT): undecoded tokens near block boundaries are forced to commit without access to nearby future context, even when such context could substantially reduce uncertainty. This limitation degrades decoding confidence and generation quality, especially for tasks requiring precise reasoning, such as mathematical problem solving and code generation. We propose Deferred Commitment Decoding (DCD), a novel, training-free decoding strategy that mitigates this issue. DCD maintains a confidence-aware sliding window over masked tokens, resolving low-uncertainty tokens early while deferring high-uncertainty tokens until sufficient contextual evidence becomes available. This design enables effective bidirectional information flow within the decoding window without sacrificing efficiency. Extensive experiments across multiple diffusion language models, benchmarks, and caching configurations show that DCD improves generation accuracy by 1.39% with comparable time on average compared to fixed block-based diffusion methods, with the most significant improvement reaching 9.0%. These results demonstrate that deferring token commitment based on uncertainty is a simple yet effective principle for improving both the quality and efficiency of diffusion language model decoding.

</details>


### [30] [DeCode: Decoupling Content and Delivery for Medical QA](https://arxiv.org/abs/2601.02123)
*Po-Jen Ko,Chen-Han Tsai,Yu-Shao Peng*

Main category: cs.CL

Relevance: 85.0

TL;DR: DeCode是一个无需训练、模型无关的框架，用于使现有LLM在临床环境中生成上下文个性化的回答，在OpenAI HealthBench上将SOTA从28.4%提升到49.8%（相对提升75%）。


<details>
  <summary>Details</summary>
Motivation: 现有LLM虽然具备医学知识并能生成事实准确的回答，但往往忽略患者个体化情境，产生临床正确但与患者需求不匹配的回答。

Method: DeCode是一个无需训练、模型无关的框架，通过适配现有LLM来生成临床环境中的上下文个性化回答。

Result: 在OpenAI HealthBench基准测试中，DeCode将之前的最佳结果从28.4%提升到49.8%，相对提升75%，显著改善了LLM的临床问答能力。

Conclusion: DeCode框架能有效提升LLM在临床环境中的回答质量，使其更好地考虑患者个体化情境。

Abstract: Large language models (LLMs) exhibit strong medical knowledge and can generate factually accurate responses. However, existing models often fail to account for individual patient contexts, producing answers that are clinically correct yet poorly aligned with patients' needs. In this work, we introduce DeCode, a training-free, model-agnostic framework that adapts existing LLMs to produce contextualized answers in clinical settings. We evaluate DeCode on OpenAI HealthBench, a comprehensive and challenging benchmark designed to assess clinical relevance and validity of LLM responses. DeCode improves the previous state of the art from $28.4\%$ to $49.8\%$, corresponding to a $75\%$ relative improvement. Experimental results suggest the effectiveness of DeCode in improving clinical question answering of LLMs.

</details>


### [31] [Routing by Analogy: kNN-Augmented Expert Assignment for Mixture-of-Experts](https://arxiv.org/abs/2601.02144)
*Boxuan Lyu,Soichiro Murakami,Hidetaka Kamigaito,Peinan Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: kNN-MoE：一种检索增强的路由框架，通过重用历史最优专家分配来提升MoE模型在分布偏移下的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 传统MoE架构中的路由器通常训练后固定，导致在分布偏移时路由决策变得脆弱。现有方法需要昂贵的监督微调来适应新分布，缺乏灵活高效的解决方案。

Method: 提出kNN-MoE框架：1）离线构建记忆库，通过直接优化路由logits最大化参考集似然；2）在线检索相似历史案例的最优专家分配；3）使用检索邻居的聚合相似度作为置信度驱动的混合系数，在无相关案例时回退到冻结路由器。

Result: 实验表明kNN-MoE在分布偏移下优于零样本基线，性能与计算昂贵的监督微调相当，同时保持了高效性。

Conclusion: kNN-MoE为MoE架构提供了一种轻量级、无需训练的路由适应方法，显著提升了模型在分布偏移下的鲁棒性，为高效LLM扩展提供了新思路。

Abstract: Mixture-of-Experts (MoE) architectures scale large language models efficiently by employing a parametric "router" to dispatch tokens to a sparse subset of experts. Typically, this router is trained once and then frozen, rendering routing decisions brittle under distribution shifts. We address this limitation by introducing kNN-MoE, a retrieval-augmented routing framework that reuses optimal expert assignments from a memory of similar past cases. This memory is constructed offline by directly optimizing token-wise routing logits to maximize the likelihood on a reference set. Crucially, we use the aggregate similarity of retrieved neighbors as a confidence-driven mixing coefficient, thus allowing the method to fall back to the frozen router when no relevant cases are found. Experiments show kNN-MoE outperforms zero-shot baselines and rivals computationally expensive supervised fine-tuning.

</details>


### [32] [Confidence Estimation for LLMs in Multi-turn Interactions](https://arxiv.org/abs/2601.02179)
*Caiqi Zhang,Ruihan Yang,Xiaochen Zhu,Chengzu Li,Tiancheng Hu,Yijiang River Dong,Deqing Yang,Nigel Collier*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文首次系统研究了多轮对话中的置信度估计，提出了基于每轮校准和置信度单调性的评估框架，并发现现有方法在多轮对话中表现不佳，提出了P(Sufficient)方法。


<details>
  <summary>Details</summary>
Motivation: 当前置信度估计研究主要关注单轮设置，而多轮对话中上下文累积和歧义逐步解决的情况尚未充分探索。可靠的置信度估计对于自主代理和人机协作系统等下游应用至关重要。

Method: 建立了基于两个关键要求的正式评估框架：每轮校准和随着信息增加置信度的单调性。引入了新指标（如长度归一化期望校准误差InfoECE）和"Hinter-Guesser"范式生成受控评估数据集。提出了基于logit的P(Sufficient)探针方法。

Result: 实验表明广泛使用的置信度技术在多轮对话中难以实现校准和单调性。提出的P(Sufficient)方法取得了相对更好的性能，但该任务远未完全解决。

Conclusion: 该工作为开发更可靠和可信的对话智能体提供了基础方法论，强调了多轮置信度估计的重要性，并指出了未来研究方向。

Abstract: While confidence estimation is a promising direction for mitigating hallucinations in Large Language Models (LLMs), current research dominantly focuses on single-turn settings. The dynamics of model confidence in multi-turn conversations, where context accumulates and ambiguity is progressively resolved, remain largely unexplored. Reliable confidence estimation in multi-turn settings is critical for many downstream applications, such as autonomous agents and human-in-the-loop systems. This work presents the first systematic study of confidence estimation in multi-turn interactions, establishing a formal evaluation framework grounded in two key desiderata: per-turn calibration and monotonicity of confidence as more information becomes available. To facilitate this, we introduce novel metrics, including a length-normalized Expected Calibration Error (InfoECE), and a new "Hinter-Guesser" paradigm for generating controlled evaluation datasets. Our experiments reveal that widely-used confidence techniques struggle with calibration and monotonicity in multi-turn dialogues. We propose P(Sufficient), a logit-based probe that achieves comparatively better performance, although the task remains far from solved. Our work provides a foundational methodology for developing more reliable and trustworthy conversational agents.

</details>


### [33] [Toward Global Large Language Models in Medicine](https://arxiv.org/abs/2601.02186)
*Rui Yang,Huitao Li,Weihao Xuan,Heli Qi,Xin Li,Kunyu Yu,Yingjian Chen,Rongrong Wang,Jacques Behmoaras,Tianxi Cai,Bibhas Chakraborty,Qingyu Chen,Lionel Tim-Ee Cheng,Marie-Louise Damwanza,Chido Dzinotyiwei,Aosong Feng,Chuan Hong,Yusuke Iwasawa,Yuhe Ke,Linah Kitala,Taehoon Ko,Jisan Lee,Irene Li,Jonathan Chong Kai Liew,Hongfang Liu,Lian Leng Low,Edison Marrese-Taylor,Yutaka Matsuo,Isheanesu Misi,Yilin Ning,Jasmine Chiat Ling Ong,Marcus Eng Hock Ong,Enrico Petretto,Hossein Rouhizadeh,Abiram Sandralegar,Oren Schreier,Iain Bee Huat Tan,Patrick Tan,Daniel Shu Wei Ting,Junjue Wang,Chunhua Weng,Matthew Yu Heng Wong,Fang Wu,Yunze Xiao,Xuhai Xu,Qingcheng Zeng,Zhuo Zheng,Yifan Peng,Douglas Teodoro,Nan Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: GlobMed项目构建了多语言医疗数据集、基准测试和模型套件，旨在解决LLMs在医疗领域中的语言不平等问题，特别关注低资源语言。


<details>
  <summary>Details</summary>
Motivation: 尽管医疗技术不断进步，但全球医疗资源分布不均。现有LLMs主要基于高资源语言训练，限制了其在全球医疗场景中的应用，特别是在低资源语言环境中。

Method: 1) 构建GlobMed多语言医疗数据集（12种语言，50万条目，含4种低资源语言）；2) 建立GlobMed-Bench基准测试，评估56个SOTA模型；3) 训练GlobMed-LLMs模型套件（1.7B-8B参数）。

Result: 基准测试显示不同语言间性能差异显著，低资源语言表现较差。GlobMed-LLMs相比基线模型平均性能提升超40%，低资源语言性能提升超3倍。

Conclusion: 这些资源为全球LLMs的公平发展和应用提供了重要基础，使更广泛的语言社区能够受益于技术进步。

Abstract: Despite continuous advances in medical technology, the global distribution of health care resources remains uneven. The development of large language models (LLMs) has transformed the landscape of medicine and holds promise for improving health care quality and expanding access to medical information globally. However, existing LLMs are primarily trained on high-resource languages, limiting their applicability in global medical scenarios. To address this gap, we constructed GlobMed, a large multilingual medical dataset, containing over 500,000 entries spanning 12 languages, including four low-resource languages. Building on this, we established GlobMed-Bench, which systematically assesses 56 state-of-the-art proprietary and open-weight LLMs across multiple multilingual medical tasks, revealing significant performance disparities across languages, particularly for low-resource languages. Additionally, we introduced GlobMed-LLMs, a suite of multilingual medical LLMs trained on GlobMed, with parameters ranging from 1.7B to 8B. GlobMed-LLMs achieved an average performance improvement of over 40% relative to baseline models, with a more than threefold increase in performance on low-resource languages. Together, these resources provide an important foundation for advancing the equitable development and application of LLMs globally, enabling broader language communities to benefit from technological advances.

</details>


### [34] [From XAI to Stories: A Factorial Study of LLM-Generated Explanation Quality](https://arxiv.org/abs/2601.02224)
*Fabian Lukassen,Jan Herrmann,Christoph Weisser,Benjamin Saefken,Thomas Kneib*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究系统评估了影响LLM生成可解释AI自然语言解释质量的因素，发现LLM选择是最关键因素，XAI方法提升有限，且存在可解释性悖论。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法（如SHAP、LIME）产生的数值特征归因对非专家用户不友好。虽然LLM可以将这些输出转化为自然语言解释，但影响解释质量的因素尚不清楚。本研究旨在系统探究预测模型选择、XAI方法、LLM选择和提示策略对自然语言解释质量的影响。

Method: 采用因子设计研究：4种预测模型（XGBoost、随机森林、MLP、SARIMAX）、3种XAI条件（SHAP、LIME、无XAI基线）、3种LLM（GPT-4o、Llama-3-8B、DeepSeek-R1）、8种提示策略。使用G-Eval（LLM作为评判）方法，双LLM评判，4个评估标准，对时间序列预测的660个解释进行评估。

Result: 1) XAI仅对专家受众提供有限改进；2) LLM选择是最关键因素，DeepSeek-R1优于GPT-4o和Llama-3；3) 可解释性悖论：SARIMAX预测精度更高但NLE质量更低；4) 零样本提示与自洽性提示效果相当但成本低7倍；5) 思维链提示反而降低质量。

Conclusion: LLM选择是影响可解释AI自然语言解释质量的最重要因素，XAI方法的价值有限，特别是在非专家用户场景中。研究揭示了模型可解释性与预测精度之间的权衡，并为实际应用提供了成本效益优化的提示策略建议。

Abstract: Explainable AI (XAI) methods like SHAP and LIME produce numerical feature attributions that remain inaccessible to non expert users. Prior work has shown that Large Language Models (LLMs) can transform these outputs into natural language explanations (NLEs), but it remains unclear which factors contribute to high-quality explanations. We present a systematic factorial study investigating how Forecasting model choice, XAI method, LLM selection, and prompting strategy affect NLE quality. Our design spans four models (XGBoost (XGB), Random Forest (RF), Multilayer Perceptron (MLP), and SARIMAX - comparing black-box Machine-Learning (ML) against classical time-series approaches), three XAI conditions (SHAP, LIME, and a no-XAI baseline), three LLMs (GPT-4o, Llama-3-8B, DeepSeek-R1), and eight prompting strategies. Using G-Eval, an LLM-as-a-judge evaluation method, with dual LLM judges and four evaluation criteria, we evaluate 660 explanations for time-series forecasting. Our results suggest that: (1) XAI provides only small improvements over no-XAI baselines, and only for expert audiences; (2) LLM choice dominates all other factors, with DeepSeek-R1 outperforming GPT-4o and Llama-3; (3) we observe an interpretability paradox: in our setting, SARIMAX yielded lower NLE quality than ML models despite higher prediction accuracy; (4) zero-shot prompting is competitive with self-consistency at 7-times lower cost; and (5) chain-of-thought hurts rather than helps.

</details>


### [35] [CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models](https://arxiv.org/abs/2601.02236)
*Yihao Liang,Ze Wang,Hao Chen,Ximeng Sun,Jialian Wu,Xiaodong Yu,Jiang Liu,Emad Barsoum,Zicheng Liu,Niraj K. Jha*

Main category: cs.CL

Relevance: 85.0

TL;DR: CD4LM框架通过离散空间一致性蒸馏和置信度自适应解码，解决了扩散语言模型训练与推理间的静态-动态错配问题，实现了高质量并行解码并大幅提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 自回归大语言模型解码受限于序列依赖，扩散语言模型虽支持并行生成但存在训练与推理的静态-动态错配：训练优化固定调度下的局部转移，而高效推理需要自适应"长跳"细化。目标是实现DLMs的高并行解码，在保持生成质量的同时减少函数评估次数。

Method: 提出CD4LM框架：1) 离散空间一致性蒸馏(DSCD)：训练学生对轨迹不变，将多样噪声状态直接映射到干净分布；2) 置信度自适应解码(CAD)：基于token置信度动态分配计算资源，激进跳过步骤而不导致质量崩溃。

Result: 在GSM8K上，CD4LM匹配LLaDA基线，实现5.18倍实时加速；在代码和数学基准测试中，严格主导准确率-效率帕累托前沿，平均加速3.62倍同时提高平均准确率。

Conclusion: CD4LM通过解耦训练与推理，解决了DLMs的静态-动态错配问题，实现了高效并行解码，在保持质量的同时显著提升推理速度，为扩散语言模型的实用化提供了有效方案。

Abstract: Autoregressive large language models achieve strong results on many benchmarks, but decoding remains fundamentally latency-limited by sequential dependence on previously generated tokens. Diffusion language models (DLMs) promise parallel generation but suffer from a fundamental static-to-dynamic misalignment: Training optimizes local transitions under fixed schedules, whereas efficient inference requires adaptive "long-jump" refinements through unseen states. Our goal is to enable highly parallel decoding for DLMs with low number of function evaluations while preserving generation quality. To achieve this, we propose CD4LM, a framework that decouples training from inference via Discrete-Space Consistency Distillation (DSCD) and Confidence-Adaptive Decoding (CAD). Unlike standard objectives, DSCD trains a student to be trajectory-invariant, mapping diverse noisy states directly to the clean distribution. This intrinsic robustness enables CAD to dynamically allocate compute resources based on token confidence, aggressively skipping steps without the quality collapse typical of heuristic acceleration. On GSM8K, CD4LM matches the LLaDA baseline with a 5.18x wall-clock speedup; across code and math benchmarks, it strictly dominates the accuracy-efficiency Pareto frontier, achieving a 3.62x mean speedup while improving average accuracy. Code is available at https://github.com/yihao-liang/CDLM

</details>


### [36] [Power-of-Two Quantization-Aware-Training (PoT-QAT) in Large Language Models (LLMs)](https://arxiv.org/abs/2601.02298)
*Mahmoud Elgenedy*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了一种针对大语言模型的幂次二值化（PoT）量化方法，通过仅存储指数来大幅减少内存占用，并用位运算替代乘法来加速推理，同时使用量化感知训练来缓解性能损失。


<details>
  <summary>Details</summary>
Motivation: 随着LLM参数规模指数级增长（从GPT-2的1.5B到GPT-3的175B再到万亿级），在边缘设备上部署面临巨大挑战。边缘设备内存和计算能力有限，需要开发新颖的压缩方法来使应用变得可行。

Method: 采用幂次二值化（PoT）量化方法，将权重限制为仅2的幂次方，这样只需存储指数而非完整数值。同时使用量化感知训练（QAT）来缓解严格量化带来的性能损失，通过额外训练提升量化模型的性能。

Result: 在GPT-2 124M模型上，经过额外训练的PoT量化模型相比基线GPT-2，困惑度提升66%，BERT-Score损失仅1%。内存节省估计达87.5%，推理速度预计比全精度模型快3-10倍。

Conclusion: PoT量化结合QAT训练是一种有效的LLM压缩方法，能在边缘设备上实现显著的内存节省和推理加速，同时保持接近原始模型的性能。

Abstract: In Large Language Models (LLMs), the number of parameters has grown exponentially in the past few years, e.g., from 1.5 billion parameters in GPT-2 to 175 billion in GPT-3 to possibly more than trillion in higher versions. This raises a significant challenge for implementation, especially for Edge devices. Unlike cloud computing, memory and processing power for Edge devices are very limited, which necessitates developing novel ideas to make such applications feasible. In this work, we investigate compressing weights with a special quantization that limits numbers to only power-of-two (PoT). This helps save a huge amount of memory as only exponents need to be stored, more importantly, it significantly reduces processing power by replacing costly multiplication with low cost bit shifting. To overcome performance loss due to this strict quantization, we investigate Quantization Aware Training (QAT) to enhance performance through additional training. Results on GPT-2 124M show a major enhancement for quantized PoT model after additional training, with a perplexity enhancement of 66% and BERT-Score loss to baseline GPT-2 of 1%. The memory saving is estimated to be 87.5% while the inference speed is expected to be 3-10x faster with PoT quantization versus full-precision.

</details>


### [37] [Estimating Text Temperature](https://arxiv.org/abs/2601.02320)
*Nikolay Mikhaylovskiy*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种估计文本温度的方法，可以评估任何文本（包括人类写作）相对于给定语言模型的温度，并评估了多个中小型LLM的温度估计能力，使用表现最好的Qwen3 14B估计了流行语料库的温度。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型在推理时通常使用温度参数来调整概率分布和控制生成文本的随机性。目前缺乏一种系统的方法来估计任何文本（包括人类写作）相对于特定语言模型的温度，这对于理解文本的随机性程度和模型行为有重要意义。

Method: 1. 使用最大似然方法估计已生成文本的温度参数；2. 提出一个通用程序来估计任何文本（包括人类写作）相对于给定语言模型的温度；3. 评估了多个中小型LLM的温度估计能力；4. 使用表现最好的Qwen3 14B模型估计流行语料库的温度。

Result: 1. 评估了多个中小型LLM的温度估计能力；2. 发现Qwen3 14B在温度估计任务中表现最好；3. 使用Qwen3 14B估计了流行语料库的温度，为不同文本类型的随机性程度提供了量化分析。

Conclusion: 提出了一种有效的文本温度估计方法，能够量化任何文本相对于语言模型的随机性程度，为LLM的推理过程分析和文本特性研究提供了新工具。

Abstract: Autoregressive language models typically use temperature parameter at inference to shape the probability distribution and control the randomness of the text generated. After the text was generated, this parameter can be estimated using maximum likelihood approach. Following it, we propose a procedure to estimate the temperature of any text, including ones written by humans, with respect to a given language model. We evaluate the temperature estimation capability of a wide selection of small-to-medium LLMs. We then use the best-performing Qwen3 14B to estimate temperatures of popular corpora.

</details>


### [38] [Robust Persona-Aware Toxicity Detection with Prompt Optimization and Learned Ensembling](https://arxiv.org/abs/2601.02337)
*Berk Atil,Rebecca J. Passonneau,Ninareh Mehrabi*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文系统评估了基于人物角色的毒性检测方法，发现没有单一提示方法在所有模型-人物角色组合中表现最优，提出了基于SVM的轻量级元集成方法，在多样性人物角色上获得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 毒性检测具有主观性，受不同人口群体视角和社会先验影响。当前LLM提示技术在不同人物角色和基础模型上表现不一致，需要系统评估人物角色感知的毒性检测方法，并开发能够捕捉多元视角的鲁棒方法。

Method: 1) 系统评估人物角色感知的毒性检测提示方法；2) 提出自动提示优化策略；3) 探索四种提示变体的集成方法；4) 提出基于SVM的轻量级元集成方法，使用4位向量表示不同提示的预测结果。

Result: 1) 没有单一提示方法在所有模型-人物角色组合中表现最优；2) 提出的SVM集成方法一致优于单个提示方法和传统多数投票技术；3) 在多样性人物角色上获得最强的整体性能。

Conclusion: 该研究为人物角色条件提示的毒性检测提供了首次系统比较，为主观NLP任务中的多元评估提供了鲁棒方法，强调了集成方法在捕捉不同视角方面的价值。

Abstract: Toxicity detection is inherently subjective, shaped by the diverse perspectives and social priors of different demographic groups. While ``pluralistic'' modeling as used in economics and the social sciences aims to capture perspective differences across contexts, current Large Language Model (LLM) prompting techniques have different results across different personas and base models. In this work, we conduct a systematic evaluation of persona-aware toxicity detection, showing that no single prompting method, including our proposed automated prompt optimization strategy, uniformly dominates across all model-persona pairs. To exploit complementary errors, we explore ensembling four prompting variants and propose a lightweight meta-ensemble: an SVM over the 4-bit vector of prompt predictions. Our results demonstrate that the proposed SVM ensemble consistently outperforms individual prompting methods and traditional majority-voting techniques, achieving the strongest overall performance across diverse personas. This work provides one of the first systematic comparisons of persona-conditioned prompting for toxicity detection and offers a robust method for pluralistic evaluation in subjective NLP tasks.

</details>


### [39] [The Qualitative Laboratory: Theory Prototyping and Hypothesis Generation with Large Language Models](https://arxiv.org/abs/2601.00797)
*Hugues Draelants*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文提出使用LLM进行社会学角色模拟作为"定性实验室"的新方法，用于生成关于不同社会群体如何解读信息的丰富定性假设。


<details>
  <summary>Details</summary>
Motivation: 社会科学面临的核心挑战是生成关于不同社会群体如何解读新信息的丰富定性假设。现有方法存在局限：小插曲调查缺乏话语深度，基于规则的ABM存在形式化瓶颈。

Method: 提出社会学角色模拟方法，使用LLM创建代表不同社会群体的角色。通过从社会学理论中推导角色，让这些角色对政策信息做出反应，生成自然主义的话语。

Result: 模拟产生了细致入微且反直觉的假设，例如保守派角色拒绝国家安全框架，这挑战了理论假设。方法展示了生成深度文本假设的能力。

Conclusion: 该方法作为"模拟后验证"工作流程的一部分，代表了为后续实证测试生成深度文本假设的优越工具。

Abstract: A central challenge in social science is to generate rich qualitative hypotheses about how diverse social groups might interpret new information. This article introduces and illustrates a novel methodological approach for this purpose: sociological persona simulation using Large Language Models (LLMs), which we frame as a "qualitative laboratory". We argue that for this specific task, persona simulation offers a distinct advantage over established methods. By generating naturalistic discourse, it overcomes the lack of discursive depth common in vignette surveys, and by operationalizing complex worldviews through natural language, it bypasses the formalization bottleneck of rule-based agent-based models (ABMs). To demonstrate this potential, we present a protocol where personas derived from a sociological theory of climate reception react to policy messages. The simulation produced nuanced and counter-intuitive hypotheses - such as a conservative persona's rejection of a national security frame - that challenge theoretical assumptions. We conclude that this method, used as part of a "simulation then validation" workflow, represents a superior tool for generating deeply textured hypotheses for subsequent empirical testing.

</details>


### [40] [RoboPhD: Self-Improving Text-to-SQL Through Autonomous Agent Evolution](https://arxiv.org/abs/2601.01126)
*Andrew Borthwick,Stephen Ash*

Main category: cs.CL

Relevance: 75.0

TL;DR: RoboPhD是一个AI自主研究系统，通过进化循环自动改进Text-to-SQL性能，从70行基线进化到1500行，在BIRD测试集上达到73.67%准确率，实现了"跳过层级"部署效果。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索AI系统能否自主进行科学研究，特别是改进Text-to-SQL任务性能，减少对人类领域知识的依赖，实现从简单基线出发的完全自主进化。

Method: 采用闭环进化循环系统：1) SQL生成代理（数据库分析脚本+SQL生成指令）；2) 进化代理基于性能反馈设计新版本；3) ELO选择机制处理性能非传递性；4) 迭代交叉授粉进化策略。

Result: 从70行基线进化到1500行，在BIRD测试集上达到73.67%准确率。进化对便宜模型提升更大：Claude Haiku提升8.9点，Claude Opus提升2.3点，实现"跳过层级"部署（进化Haiku > 原生Sonnet，进化Sonnet > 原生Opus）。

Conclusion: AI能够从简单人类提供的起点自主构建强大的代理系统，发现有效策略如大小自适应数据库分析，证明了自主研究系统的可行性，为AI驱动的科学发现提供了新范式。

Abstract: We present RoboPhD, a system where AI agents autonomously conduct research to improve Text-to-SQL performance. RoboPhD implements a closed-loop evolution cycle with two coordinated components: a SQL Generation agent composed of a database analysis script and SQL generation instructions, and an Evolution agent that designs new versions based on performance feedback. Central to the framework is an ELO-based selection mechanism enabling survival-of-the-fittest dynamics while handling non-transitivity in performance. Starting from a naive 70-line baseline, RoboPhD evolves agents through iterative cross-pollination, discovering effective techniques without any external guidance on the Text-to-SQL domain. Our best agent, evolved to 1500 lines over 18 iterations, autonomously discovered strategies such as size-adaptive database analysis that adjusts depth based on schema complexity and SQL generation patterns for column selection, evidence interpretation, and aggregation. Evolution provides the largest gains on cheaper models: while we improve by 2.3 points over a strong Claude Opus 4.5 naive baseline, we show an improvement of 8.9 points over the weaker Claude Haiku model. This enables 'skip a tier' deployment: evolved Haiku exceeds naive Sonnet accuracy, and evolved Sonnet exceeds naive Opus, both at lower cost. The full system achieves 73.67% accuracy on the BIRD test set, demonstrating that AI can autonomously build a strong agentic system with only a trivial human-provided starting point.

</details>


### [41] [Bridging the gap: A comparative exploration of Speech-LLM and end-to-end architecture for multilingual conversational ASR](https://arxiv.org/abs/2601.01461)
*Yuxiang Mei,Dongxing Xu,Jiaen Liang,Yanhua Long*

Main category: cs.CL

Relevance: 75.0

TL;DR: 本文提出了一种增强的基于LLM的ASR框架，通过交叉注意力融合机制结合微调的Whisper和mHuBERT编码器，在MLC-SLM挑战中取得了10.69%的CER/WER，与顶级系统性能相当，但发现LLM-based ASR仍不及微调的端到端Whisper模型。


<details>
  <summary>Details</summary>
Motivation: 解决多语言对话语音识别中LLM-based ASR的两个关键问题：1）简单的特征拼接无法充分利用互补信息；2）LLM-based ASR与端到端编码器-解码器ASR之间的性能差距尚未充分探索。

Method: 提出增强的LLM-based ASR框架：1）评估LoRA和全微调的Whisper端到端模型；2）为并行语音编码器设计基于交叉注意力的融合机制，结合微调的Whisper和mHuBERT编码器来丰富语音表示。

Result: 在MLC-SLM挑战官方评估集上达到10.69%的CER/WER，与使用大规模训练数据的顶级Track 1系统性能相当（仅使用1500小时基线训练数据）。但最终LLM-based ASR仍不及微调的端到端Whisper模型。

Conclusion: 基于交叉注意力的融合机制能有效提升LLM-based ASR性能，但LLM-based方法在语音识别任务上仍落后于专门的端到端模型，为未来Speech-LLM设计提供了重要经验指导。

Abstract: The INTERSPEECH 2025 Challenge on Multilingual Conversational Speech Language Models (MLC-SLM) promotes multilingual conversational ASR with large language models (LLMs). Our previous SHNU-mASR system adopted a competitive parallel-speech-encoder architecture that integrated Whisper and mHuBERT with an LLM. However, it faced two challenges: simple feature concatenation may not fully exploit complementary information, and the performance gap between LLM-based ASR and end-to-end(E2E) encoder-decoder ASR remained unexplored. In this work, we present an enhanced LLM-based ASR framework that combines fine-tuned Whisper and mHuBERT encoders with an LLM to enrich speech representations. We first evaluate E2E Whisper models with LoRA and full fine-tuning on the MLC-SLM ASR task, and then propose cross-attention-based fusion mechanisms for the parallel-speech-encoder. On the official evaluation set of the MLC-SLM Challenge, our system achieves a CER/WER of 10.69%, ranking on par with the top-ranked Track 1 systems, even though it uses only 1,500 hours of baseline training data compared with their large-scale training sets. Nonetheless, we find that our final LLM-based ASR still does not match the performance of a fine-tuned E2E Whisper model, providing valuable empirical guidance for future Speech-LLM design. Our code is publicly available at https://github.com/1535176727/MLC-SLM.

</details>


### [42] [Can Legislation Be Made Machine-Readable in PROLEG?](https://arxiv.org/abs/2601.01477)
*May-Myo Zin,Sabine Wehnert,Yuntao Kong,Ha-Thanh Nguyen,Wachara Fungwacharakorn,Jieying Xue,Michał Araszkiewicz,Randy Goebel,Ken Satoh,Le-Minh Nguyen*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出一个结合大语言模型(LLM)和法律形式化系统(PROLEG)的框架，将法规文本(如GDPR第6条)自动转换为可执行的if-then规则和PROLEG编码，支持可解释的法律决策。


<details>
  <summary>Details</summary>
Motivation: 法规应用的准确性和效率对社会影响至关重要。当前AI技术(特别是自然语言处理和法律推理形式化)为解决这一挑战提供了可能。需要开发能够将法规文本自动转换为可执行规则的工具，提高法律应用的效率和准确性。

Method: 1. 使用LLM提示框架将法律文本同时转换为if-then规则和PROLEG编码；2. 法律领域专家验证和精炼转换结果；3. 生成可执行的PROLEG程序，能够为GDPR决策提供人类可读的解释；4. 以GDPR第6条为例展示端到端转换流程。

Result: 成功开发了一个框架，能够通过LLM提示将GDPR第6条法规文本转换为if-then规则和PROLEG编码，生成可执行的PROLEG程序，并展示程序执行实例。框架支持法律决策的可解释性。

Conclusion: 该方法展示了LLM与法律形式化系统结合的价值，能够有效捕获和部署监管框架。同时指出了当前方法的局限性，并提出了进一步开发此类技术的建议。

Abstract: The anticipated positive social impact of regulatory processes requires both the accuracy and efficiency of their application. Modern artificial intelligence technologies, including natural language processing and machine-assisted reasoning, hold great promise for addressing this challenge. We present a framework to address the challenge of tools for regulatory application, based on current state-of-the-art (SOTA) methods for natural language processing (large language models or LLMs) and formalization of legal reasoning (the legal representation system PROLEG). As an example, we focus on Article 6 of the European General Data Protection Regulation (GDPR). In our framework, a single LLM prompt simultaneously transforms legal text into if-then rules and a corresponding PROLEG encoding, which are then validated and refined by legal domain experts. The final output is an executable PROLEG program that can produce human-readable explanations for instances of GDPR decisions. We describe processes to support the end-to-end transformation of a segment of a regulatory document (Article 6 from GDPR), including the prompting frame to guide an LLM to "compile" natural language text to if-then rules, then to further "compile" the vetted if-then rules to PROLEG. Finally, we produce an instance that shows the PROLEG execution. We conclude by summarizing the value of this approach and note observed limitations with suggestions to further develop such technologies for capturing and deploying regulatory frameworks.

</details>


### [43] [Four Quadrants of Difficulty: A Simple Categorisation and its Limits](https://arxiv.org/abs/2601.01488)
*Vanessa Toborek,Sebastian Müller,Christian Bauckhage*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该论文挑战了课程学习中常用的任务无关难度估计方法，提出基于模型和任务依赖的难度信号更有效，需要轻量级的任务依赖难度估计器来反映模型学习行为。


<details>
  <summary>Details</summary>
Motivation: 课程学习旨在通过估计样本难度并相应安排训练顺序来改进模型训练效果。在NLP中，难度通常使用任务无关的语言学启发式方法或人类直觉来近似，这隐含假设这些信号与神经网络模型认为难以学习的内容相关。作者质疑这种假设的有效性。

Method: 提出了一个四象限分类法（人类vs模型、任务无关vs任务依赖）来系统分析难度信号的相互作用。在自然语言理解数据集上进行了系统性分析，比较不同难度信号的有效性。

Result: 研究发现任务无关特征在很大程度上独立于模型学习行为，只有任务依赖特征与模型学习行为对齐。这挑战了常见的课程学习直觉，表明任务无关的难度估计方法可能不准确。

Conclusion: 需要开发轻量级的任务依赖难度估计器，这些估计器能更好地反映模型的学习行为，而不是依赖任务无关的语言学启发式方法或人类直觉。

Abstract: Curriculum Learning (CL) aims to improve the outcome of model training by estimating the difficulty of samples and scheduling them accordingly. In NLP, difficulty is commonly approximated using task-agnostic linguistic heuristics or human intuition, implicitly assuming that these signals correlate with what neural models find difficult to learn. We propose a four-quadrant categorisation of difficulty signals -- human vs. model and task-agnostic vs. task-dependent -- and systematically analyse their interactions on a natural language understanding dataset. We find that task-agnostic features behave largely independently and that only task-dependent features align. These findings challenge common CL intuitions and highlight the need for lightweight, task-dependent difficulty estimators that better reflect model learning behaviour.

</details>


### [44] [JMedEthicBench: A Multi-Turn Conversational Benchmark for Evaluating Medical Safety in Japanese Large Language Models](https://arxiv.org/abs/2601.01627)
*Junyu Liu,Zirui Li,Qian Niu,Zequn Zhang,Yue Xun,Wenlong Hou,Shujun Wang,Yusuke Iwasawa,Yutaka Matsuo,Kan Hatakeyama-Sato*

Main category: cs.CL

Relevance: 75.0

TL;DR: JMedEthicBench：首个针对日本医疗的多轮对话安全评估基准，基于日本医师协会67项指南，包含5万+对抗对话，发现医疗专用模型安全性下降，多轮对话中安全性显著降低


<details>
  <summary>Details</summary>
Motivation: 随着LLM在医疗领域部署增加，需要评估其医疗安全性。现有基准主要是英语单轮测试，而临床咨询多为多轮对话，且缺乏日语医疗安全评估基准。

Method: 基于日本医师协会67项指南，使用7种自动发现的越狱策略生成5万+对抗对话，采用双LLM评分协议评估27个模型，进行跨语言评估（日语和英语版本）

Result: 商业模型保持稳健安全性，医疗专用模型安全性下降；多轮对话中安全性显著降低（中位数9.5→5.0，p<0.001）；跨语言评估显示医疗模型漏洞在所有语言中都存在

Conclusion: 领域特定微调可能意外削弱安全机制，多轮交互代表独特威胁面需要专门对齐策略，医疗模型漏洞是内在对齐限制而非语言特定因素

Abstract: As Large Language Models (LLMs) are increasingly deployed in healthcare field, it becomes essential to carefully evaluate their medical safety before clinical use. However, existing safety benchmarks remain predominantly English-centric, and test with only single-turn prompts despite multi-turn clinical consultations. To address these gaps, we introduce JMedEthicBench, the first multi-turn conversational benchmark for evaluating medical safety of LLMs for Japanese healthcare. Our benchmark is based on 67 guidelines from the Japan Medical Association and contains over 50,000 adversarial conversations generated using seven automatically discovered jailbreak strategies. Using a dual-LLM scoring protocol, we evaluate 27 models and find that commercial models maintain robust safety while medical-specialized models exhibit increased vulnerability. Furthermore, safety scores decline significantly across conversation turns (median: 9.5 to 5.0, $p < 0.001$). Cross-lingual evaluation on both Japanese and English versions of our benchmark reveals that medical model vulnerabilities persist across languages, indicating inherent alignment limitations rather than language-specific factors. These findings suggest that domain-specific fine-tuning may accidentally weaken safety mechanisms and that multi-turn interactions represent a distinct threat surface requiring dedicated alignment strategies.

</details>


### [45] [K-EXAONE Technical Report](https://arxiv.org/abs/2601.01739)
*Eunbi Choi,Kibong Choi,Seokhee Hong,Junwon Hwang,Hyojin Jeon,Hyunjik Jo,Joonkee Kim,Seonghwan Kim,Soyeon Kim,Sunkyoung Kim,Yireun Kim,Yongil Kim,Haeju Lee,Jinsik Lee,Kyungmin Lee,Sangha Park,Heuiyeen Yeen,Hwan Chang,Stanley Jungkyu Choi,Yejin Choi,Jiwon Ham,Kijeong Jeon,Geunyeong Jeong,Gerrard Jeongwon Jo,Yonghwan Jo,Jiyeon Jung,Naeun Kang,Dohoon Kim,Euisoon Kim,Hayeon Kim,Hyosang Kim,Hyunseo Kim,Jieun Kim,Minu Kim,Myoungshin Kim,Unsol Kim,Youchul Kim,YoungJin Kim,Chaeeun Lee,Chaeyoon Lee,Changhun Lee,Dahm Lee,Edward Hwayoung Lee,Honglak Lee,Jinsang Lee,Jiyoung Lee,Sangeun Lee,Seungwon Lim,Solji Lim,Woohyung Lim,Chanwoo Moon,Jaewoo Park,Jinho Park,Yongmin Park,Hyerin Seo,Wooseok Seo,Yongwoo Song,Sejong Yang,Sihoon Yang,Chang En Yea,Sihyuk Yi,Chansik Yoon,Dongkeun Yoon,Sangyeon Yoon,Hyeongu Yun*

Main category: cs.CL

Relevance: 75.0

TL;DR: K-EXAONE是LG AI Research开发的大规模多语言混合专家模型，总参数量236B，推理时激活23B参数，支持256K上下文窗口和6种语言，在多项基准测试中表现与同规模开源模型相当。


<details>
  <summary>Details</summary>
Motivation: 开发一个强大的专有AI基础模型，支持多语言处理，具有长上下文能力，适用于广泛的工业和科研应用，旨在推动AI技术改善生活。

Method: 采用混合专家架构，总参数量236B，推理时激活23B参数，支持256K令牌的上下文窗口，覆盖韩语、英语、西班牙语、德语、日语和越南语六种语言。

Result: 在推理、智能体、通用能力、韩语能力和多语言能力等综合基准测试中，K-EXAONE表现出与相似规模的开源模型相当的性能。

Conclusion: K-EXAONE是一个强大的专有AI基础模型，具有多语言能力和长上下文支持，适用于广泛的工业和科研应用场景。

Abstract: This technical report presents K-EXAONE, a large-scale multilingual language model developed by LG AI Research. K-EXAONE is built on a Mixture-of-Experts architecture with 236B total parameters, activating 23B parameters during inference. It supports a 256K-token context window and covers six languages: Korean, English, Spanish, German, Japanese, and Vietnamese. We evaluate K-EXAONE on a comprehensive benchmark suite spanning reasoning, agentic, general, Korean, and multilingual abilities. Across these evaluations, K-EXAONE demonstrates performance comparable to open-weight models of similar size. K-EXAONE, designed to advance AI for a better life, is positioned as a powerful proprietary AI foundation model for a wide range of industrial and research applications.

</details>


### [46] [Towards Multi-Level Transcript Segmentation: LoRA Fine-Tuning for Table-of-Contents Generation](https://arxiv.org/abs/2601.02128)
*Steffen Freisinger,Philipp Seeberger,Thomas Ranzenberger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出一种用于语音转录本的分层主题分割方法，生成多级目录，结合零样本提示和LoRA微调，并整合语音停顿特征，在会议和讲座转录本上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 语音转录本的主题分割对下游处理和依赖文本获取信息的用户有益，现有方法缺乏有效的分层结构分析，需要更好的多级主题分割方法。

Method: 提出分层主题分割方法：1) 比较零样本提示和LoRA微调的大语言模型方法；2) 整合高层语音停顿特征；3) 在多语言数据集（英语会议、葡萄牙语和德语讲座）上评估；4) 调整评估指标以适应多级分割。

Result: 在英语会议录音和多语言讲座转录本上显著优于现有主题分割基线方法，证明了方法的有效性。

Conclusion: 分层主题分割方法有效，结合LLM技术和语音特征能提升分割质量，多级评估指标能更全面衡量性能。

Abstract: Segmenting speech transcripts into thematic sections benefits both downstream processing and users who depend on written text for accessibility. We introduce a novel approach to hierarchical topic segmentation in transcripts, generating multi-level tables of contents that capture both topic and subtopic boundaries. We compare zero-shot prompting and LoRA fine-tuning on large language models, while also exploring the integration of high-level speech pause features. Evaluations on English meeting recordings and multilingual lecture transcripts (Portuguese, German) show significant improvements over established topic segmentation baselines. Additionally, we adapt a common evaluation measure for multi-level segmentation, taking into account all hierarchical levels within one metric.

</details>


### [47] [Unsupervised Text Style Transfer for Controllable Intensity](https://arxiv.org/abs/2601.01060)
*Shuhuan Gu,Wenbiao Tao,Xinchen Ma,Kangkang He,Ye Guo,Xiang Li,Yunshi Lan*

Main category: cs.CL

Relevance: 65.0

TL;DR: 该论文提出了一种SFT-then-PPO范式来微调大语言模型，用于无监督文本风格迁移中的可控强度转换，通过合成平行数据和精心设计的层次化奖励函数解决相邻强度级别难以区分的问题。


<details>
  <summary>Details</summary>
Motivation: 无监督文本风格迁移（UTST）在缺乏平行文本对的情况下进行风格转换。相比风格极性之间的转换，可控强度的UTST更具挑战性，因为不同强度级别间的风格特征差异细微。主要面临两大挑战：缺乏平行数据和相邻强度级别难以区分。

Method: 提出SFT-then-PPO两阶段微调范式：1）首先使用合成的平行数据对LLM进行监督微调（SFT）；2）然后使用PPO进行进一步训练，其中设计了层次化的奖励函数来区分风格强度。奖励函数同时考虑了全局和局部风格特征。

Result: 在两个UTST基准测试上的实验表明，两种奖励函数各有优势，将它们应用于LLM微调可以有效提升基于各种评估指标的LLM骨干网络性能。即使对于相近的强度级别，生成的文本之间仍能观察到明显的风格差异。

Conclusion: 提出的SFT-then-PPO范式能够有效解决无监督文本风格迁移中的可控强度转换问题，通过合成数据和精心设计的层次化奖励函数，使LLM能够区分细微的风格强度差异，生成具有明显风格差异的文本。

Abstract: Unsupervised Text Style Transfer (UTST) aims to build a system to transfer the stylistic properties of a given text without parallel text pairs. Compared with text transfer between style polarities, UTST for controllable intensity is more challenging due to the subtle differences in stylistic features across different intensity levels. Faced with the challenges posed by the lack of parallel data and the indistinguishability between adjacent intensity levels, we propose a SFT-then-PPO paradigm to fine-tune an LLM. We first fine-tune the LLM with synthesized parallel data. Then, we further train the LLM with PPO, where the rewards are elaborately designed for distinguishing the stylistic intensity in hierarchical levels. Both the global and local stylistic features are considered to formulate the reward functions. The experiments on two UTST benchmarks showcase that both rewards have their advantages and applying them to LLM fine-tuning can effectively improve the performance of an LLM backbone based on various evaluation metrics. Even for close levels of intensity, we can still observe the noticeable stylistic difference between the generated text.

</details>


### [48] [ks-lit-3m: A 3.1 million word kashmiri text dataset for large language model pretraining](https://arxiv.org/abs/2601.01091)
*Haq Nawaz Malik*

Main category: cs.CL

Relevance: 65.0

TL;DR: 该论文介绍了KS-LIT-3M，一个包含310万单词的克什米尔语语料库，专门用于语言模型预训练，解决了克什米尔语高质量训练数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在高资源语言上表现出色，但在克什米尔语（约700万人使用）上生成连贯文本时表现不佳。这种性能差距源于高质量训练数据的严重缺乏，特别是克什米尔语文献大多以专有的InPage桌面出版格式编码，无法被现代NLP流程处理。

Method: 1. 开发专门的InPage-to-Unicode转换器，将专有格式的克什米尔语文献转换为可处理的Unicode文本
2. 进行严格的预处理，包括去除英语污染、字符标准化和质量验证
3. 构建包含131,607个独特单词的语料库，涵盖文学、新闻、学术和宗教等多种体裁
4. 将语料库组织为单一连续线性文本流，优化用于因果语言模型训练

Result: 创建了KS-LIT-3M语料库，包含310万单词（1640万字符），涵盖克什米尔语的多样化文本内容。该数据集以CC-BY-4.0许可证发布，为克什米尔语自然语言处理研究提供了基础资源。

Conclusion: 该研究填补了克什米尔语语言技术的基础资源空白，通过解决数据格式转换和质量控制问题，为克什米尔语LLM训练提供了关键数据集，有助于提升低资源语言的NLP能力。

Abstract: Large Language Models (LLMs) demonstrate remarkable fluency across high-resource languages yet consistently fail to generate coherent text in Kashmiri, a language spoken by approximately seven million people. This performance disparity stems not from inherent model limitations but from a critical scarcity of high-quality training data. Decades of Kashmiri literature remain inaccessible to modern NLP pipelines due to their encoding in the proprietary InPage desktop publishing format. This paper introduces KS-LIT-3M, a curated corpus of 3.1 million words (16.4 million characters) specifically designed for pretraining language models on Kashmiri. The dataset is structured as a single continuous linear text stream, optimized for causal language model training where models learn to predict subsequent tokens from preceding context. The corpus was constructed through the development of a specialized InPage-to-Unicode converter, followed by rigorous preprocessing including English contamination removal, character normalization, and quality validation. Encompassing 131,607 unique words drawn from diverse genres including literary works, journalistic writing, academic texts, and religious scholarship, KS-LIT-3M addresses a fundamental resource gap for Kashmiri language technology. The dataset is released under the CC-BY-4.0 license to facilitate research in Kashmiri natural language processing.

</details>


### [49] [EmoLoom-2B: Fast Base-Model Screening for Emotion Classification and VAD with Lexicon-Weak Supervision and KV-Off Evaluation](https://arxiv.org/abs/2601.01112)
*Zilin Li,Weiwei Xu,Xuanbo Lu,Zheda Liu*

Main category: cs.CL

Relevance: 65.0

TL;DR: EmoLoom-2B是一个轻量级可复现的管道，可将小于20亿参数的小型语言模型转化为情感分类和VAD预测的快速筛选候选者，采用JSON输入输出协议、KV-off解码、语义正则化和数据增强技术。


<details>
  <summary>Details</summary>
Motivation: 开发一个轻量级、可复现的管道，将小型语言模型转化为情感分析和VAD预测的高效工具，解决现有方法中协议不一致、评估不公平、计算成本高等问题，为更重的训练或多模态融合提供可靠的筛选阶段。

Method: 1) 统一JSON输入输出协议确保评估一致性；2) 采用KV-off解码减少方差；3) 引入VAD保持约束和轻量级外部评估分类器作为语义正则化；4) 基于镜像情感对的Valence Flip数据增强；5) 监督微调时使用A/B混合采样和熵感知温度调度；6) 以Qwen-1.8B-Chat为基础模型。

Result: EmoLoom-2B在GoEmotions和EmpatheticDialogues数据集上表现强劲，在DailyDialog上展示出鲁棒的跨语料库泛化能力。管道具有预算意识、可审计和可重入特性。

Conclusion: EmoLoom-2B提供了一个可靠、高效、可复现的轻量级情感分析解决方案，可作为重型训练或多模态融合前的筛选阶段，平衡了性能、效率和可解释性。

Abstract: We introduce EmoLoom-2B, a lightweight and reproducible pipeline that turns small language models under 2B parameters into fast screening candidates for joint emotion classification and Valence-Arousal-Dominance prediction. To ensure protocol-faithful and fair evaluation, we unify data loading, training, and inference under a single JSON input-output contract and remove avoidable variance by adopting KV-off decoding as the default setting. We incorporate two orthogonal semantic regularizers: a VAD-preserving constraint that aligns generated text with target VAD triples, and a lightweight external appraisal classifier that provides training-time guidance on goal attainment, controllability, certainty, and fairness without injecting long rationales. To improve polarity sensitivity, we introduce Valence Flip augmentation based on mirrored emotional pairs. During supervised fine-tuning, we apply A/B mixture sampling with entropy-aware temperature scheduling to balance coverage and convergence. Using Qwen-1.8B-Chat as the base model, EmoLoom-2B achieves strong performance on GoEmotions and EmpatheticDialogues, and demonstrates robust cross-corpus generalization on DailyDialog. The proposed recipe is budget-aware, auditable, and re-entrant, serving as a dependable screening pass before heavier training or multimodal fusion.

</details>


### [50] [SongSage: A Large Musical Language Model with Lyric Generative Pre-training](https://arxiv.org/abs/2601.01153)
*Jiani Guo,Jiajia Li,Jie Wu,Zuchao Li,Yujiu Yang,Ping Wang*

Main category: cs.CL

Relevance: 65.0

TL;DR: SongSage：通过歌词生成预训练增强的大型音乐语言模型，专门用于歌词中心知识理解和播放列表推荐


<details>
  <summary>Details</summary>
Motivation: 当前通用大语言模型在歌词知识和播放列表理解方面存在不足，需要专门针对音乐领域进行优化，以更好地处理歌词相关任务和播放列表推荐

Method: 1. 构建PlaylistSense数据集评估播放列表理解能力；2. 创建LyricBank语料库（54.8亿token）进行持续预训练；3. 使用LyricBank-SFT指令集（77.5万样本，9个核心任务）进行微调；4. 开发SongSage模型专门处理歌词中心任务

Result: SongSage在歌词知识理解方面表现出色，能够有效重写用户查询进行零样本播放列表推荐，生成和续写歌词，并在7个额外能力上表现良好。同时保持通用知识理解能力，获得有竞争力的MMLU分数

Conclusion: 专门针对歌词内容进行预训练的语言模型能够显著提升音乐领域任务的表现，同时保持通用能力。该方法为领域特定LLM开发提供了有效范例

Abstract: Large language models have achieved significant success in various domains, yet their understanding of lyric-centric knowledge has not been fully explored. In this work, we first introduce PlaylistSense, a dataset to evaluate the playlist understanding capability of language models. PlaylistSense encompasses ten types of user queries derived from common real-world perspectives, challenging LLMs to accurately grasp playlist features and address diverse user intents. Comprehensive evaluations indicate that current general-purpose LLMs still have potential for improvement in playlist understanding. Inspired by this, we introduce SongSage, a large musical language model equipped with diverse lyric-centric intelligence through lyric generative pretraining. SongSage undergoes continual pretraining on LyricBank, a carefully curated corpus of 5.48 billion tokens focused on lyrical content, followed by fine-tuning with LyricBank-SFT, a meticulously crafted instruction set comprising 775k samples across nine core lyric-centric tasks. Experimental results demonstrate that SongSage exhibits a strong understanding of lyric-centric knowledge, excels in rewriting user queries for zero-shot playlist recommendations, generates and continues lyrics effectively, and performs proficiently across seven additional capabilities. Beyond its lyric-centric expertise, SongSage also retains general knowledge comprehension and achieves a competitive MMLU score. We will keep the datasets inaccessible due to copyright restrictions and release the SongSage and training script to ensure reproducibility and support music AI research and applications, the datasets release plan details are provided in the appendix.

</details>


### [51] [Stylometry Analysis of Human and Machine Text for Academic Integrity](https://arxiv.org/abs/2601.01225)
*Hezam Albaqami,Muhammad Asif Ayub,Nasir Ahmad,Yaseen Ahmad,Mohammed M. Alqahtani,Abdullah M. Algamdi,Almoaid A. Owaidah,Kashif Ahmad*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出基于NLP的框架，通过作者归属和风格变化检测来认证学生内容，针对四个任务：人机文本分类、单/多作者区分、多作者文档中的作者变化检测、协作文档中的作者识别，并在Gemini生成的数据集上评估。


<details>
  <summary>Details</summary>
Motivation: 解决学术诚信的关键挑战（抄袭、捏造、教育内容作者验证），现有解决方案不完善，多个方面尚未探索，需要全面的分析框架。

Method: 提出NLP框架，针对四个任务：1)人机文本分类；2)单/多作者区分；3)多作者文档中的作者变化检测；4)协作文档中的作者识别。使用Gemini生成两个数据集（正常和严格指令），评估提出的解决方案。

Result: 在严格提示生成的数据集上观察到性能下降，表明检测精心设计的机器生成文本的复杂性。公开了生成的数据集、代码和相关材料。

Conclusion: 该框架为学术内容认证提供了全面解决方案，揭示了检测精心设计的机器生成文本的挑战，公开资源为未来研究提供基线。

Abstract: This work addresses critical challenges to academic integrity, including plagiarism, fabrication, and verification of authorship of educational content, by proposing a Natural Language Processing (NLP)-based framework for authenticating students' content through author attribution and style change detection. Despite some initial efforts, several aspects of the topic are yet to be explored. In contrast to existing solutions, the paper provides a comprehensive analysis of the topic by targeting four relevant tasks, including (i) classification of human and machine text, (ii) differentiating in single and multi-authored documents, (iii) author change detection within multi-authored documents, and (iv) author recognition in collaboratively produced documents. The solutions proposed for the tasks are evaluated on two datasets generated with Gemini using two different prompts, including a normal and a strict set of instructions. During experiments, some reduction in the performance of the proposed solutions is observed on the dataset generated through the strict prompt, demonstrating the complexities involved in detecting machine-generated text with cleverly crafted prompts. The generated datasets, code, and other relevant materials are made publicly available on GitHub, which are expected to provide a baseline for future research in the domain.

</details>


### [52] [Racka: Efficient Hungarian LLM Adaptation on Academic Infrastructure](https://arxiv.org/abs/2601.01244)
*Zsolt Csibi,Bence György Gortka,Natabara Gyöngyössy,Kornél Nagy,Dávid Márk Nemeskey,Martin Sallai,András Simonyi,András Márk Szekeres,Gábor Palkó*

Main category: cs.CL

Relevance: 65.0

TL;DR: Racka是一个轻量级持续预训练的大语言模型，通过LoRA在Qwen-3 4B骨干上参数高效地训练，专门为匈牙利语设计，同时保持英语和德语能力，使用160B混合语料训练。


<details>
  <summary>Details</summary>
Motivation: 解决匈牙利语与高资源语言（如英语、德语）之间的资源差距问题，通过持续预训练方法使匈牙利语LLM开发更加实用和经济。

Method: 1. 使用LoRA进行参数高效的持续预训练，基于Qwen-3 4B骨干模型；2. 替换和适配分词器以改善匈牙利语的分词效率；3. 使用160B子词token的混合语料训练（44%匈牙利语、24%英语、21%德语、11%代码）。

Result: 初步结果显示在语言适应方面取得了适度但稳定的结果，匈牙利语分词效率显著提升，同时保持英语和德语的竞争性能。

Conclusion: Racka展示了通过参数高效的持续预训练方法可以有效开发低资源语言模型，同时保持高资源语言能力，为资源受限环境下的多语言LLM开发提供了实用方案。

Abstract: We present Racka, a lightweight, continually pretrained large language model designed to bridge the resource gap between Hungarian and high-resource languages such as English and German. Racka employs parameter-efficient continual pretraining via Low-Rank Adaptation (LoRA) on a Qwen-3 4B backbone, making the recipe practical on A100 (40GB)-based HPC clusters with low inter-node bandwidth. To better match the training distribution, we replace and adapt the tokenizer, achieving substantially improved tokenization fertility for Hungarian while maintaining competitive performance in English and German. The model is trained on 160B subword tokens drawn from a mixture of internet and high-quality curated sources, with a composition of 44% Hungarian, 24% English, 21% German, and 11% code. This data mix is chosen to mitigate catastrophic forgetting and preserve high-resource language capabilities during continual pretraining. Our preliminary results indicate modest but stable results in language adaptation.

</details>


### [53] [From Policy to Logic for Efficient and Interpretable Coverage Assessment](https://arxiv.org/abs/2601.01266)
*Rhitabrat Pokharel,Hamid Hassanzadeh,Ameeta Agrawal*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出一种混合系统，结合覆盖感知检索器和符号规则推理，用于医疗政策审查，减少LLM推理成本44%并提升F1分数4.5%


<details>
  <summary>Details</summary>
Motivation: LLM在解释复杂法律和政策语言方面表现出色，但在分析主观和细微文件时存在幻觉和不一致问题。这在医疗覆盖政策审查中尤为关键，因为人类专家需要依赖准确信息。需要支持人类审查员，使政策解释更高效和可解释。

Method: 提出混合方法：1) 覆盖感知检索器提取相关政策语言；2) 符号规则推理将信息组织为明确事实和规则；3) 生成可审计的推理依据。该方法减少LLM推理次数，降低模型成本。

Result: 实现了44%的推理成本降低和4.5%的F1分数提升，展示了效率和效果的双重优势。

Conclusion: 该混合系统通过结合检索增强和符号推理，有效解决了LLM在政策分析中的幻觉问题，同时提高了效率和可解释性，为医疗政策审查提供了可靠支持。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach designed to support human reviewers by making policy interpretation more efficient and interpretable. We introduce a methodology that pairs a coverage-aware retriever with symbolic rule-based reasoning to surface relevant policy language, organize it into explicit facts and rules, and generate auditable rationales. This hybrid system minimizes the number of LLM inferences required which reduces overall model cost. Notably, our approach achieves a 44% reduction in inference cost alongside a 4.5% improvement in F1 score, demonstrating both efficiency and effectiveness.

</details>


### [54] [A Training-Free Large Reasoning Model-based Knowledge Tracing Framework for Unified Prediction and Prescription](https://arxiv.org/abs/2601.01708)
*Unggi Lee,Joo Young Kim,Ran Ju,Minyoung Jung,Jeyeon Eo*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出Thinking-KT框架，无需训练即可让小型LLM在知识追踪任务中达到竞争性表现，并能统一执行预测、反馈生成和学习推荐


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的知识追踪方法通常需要微调且性能不稳定，同时传统KT系统主要关注预测，反馈和推荐需要多阶段流程，导致系统复杂度和资源消耗增加

Method: 提出Thinking-KT训练免费框架，包含测试时缩放(TTS)技术，使小型LLM能够联合执行KT预测、个性化反馈生成和学习推荐，并在统一输出中完成

Result: TTS是LLM-based KT中关键但未充分探索的因素，小型LLM可以作为统一的智能教学系统引擎，在保持预测准确性的同时实现多任务统一处理

Conclusion: 无需训练的小型LLM框架在知识追踪中具有竞争力，能够简化智能教学系统架构，实现预测、反馈和推荐的统一处理

Abstract: Knowledge Tracing (KT) aims to estimate a learner's evolving mastery based on interaction histories. Recent studies have explored Large Language Models (LLMs) for KT via autoregressive nature, but such approaches typically require fine-tuning and exhibit unstable or near-random performance. Moreover, prior KT systems primarily focus on prediction and rely on multi-stage pipelines for feedback and recommendation, resulting in increased system complexity and resources. To address this gap, we propose Thinking-KT, a training-free KT framework that incorporates Test-Time Scaling (TTS), enabling even small LLMs to achieve competitive KT performance. Moreover, in this framework, a small LLM can jointly perform KT prediction, personalized feedback generation, and learning recommendation in a unified output without degrading prediction accuracy. Beyond performance, we present the systematic analysis of reasoning traces in KT. Our results demonstrate that TTS is a critical yet underexplored factor in LLM-based KT, and that small LLMs can serve as unified ITS engines.

</details>


### [55] [Aspect Extraction from E-Commerce Product and Service Reviews](https://arxiv.org/abs/2601.01827)
*Valiant Lance D. Dionela,Fatima Kriselle S. Dy,Robin James M. Hombrebueno,Aaron Rae M. Nicolas,Charibeth K. Cheng,Raphael W. Gonda*

Main category: cs.CL

Relevance: 65.0

TL;DR: 本文提出一个针对Taglish（他加禄语-英语混合语）的全面方面提取管道，结合基于规则、大语言模型和微调技术，开发了分层方面框架和双模式标记方案，在电商评论中实现高效方面识别和提取。


<details>
  <summary>Details</summary>
Motivation: 方面提取是方面情感分析的关键任务，但在低资源和代码切换环境（如菲律宾电商评论中常用的Taglish混合语）中应用困难。现有方法难以处理这种语言混合和资源稀缺的挑战。

Method: 1. 开发全面的AE管道，结合基于规则、LLM和微调技术
2. 通过多方法主题建模创建分层方面框架（HAF）
3. 设计用于显式和隐式方面的双模式标记方案
4. 评估四种模型：基于规则系统、生成式LLM（Gemini 2.0 Flash）、两个在不同数据集上微调的Gemma-3 1B模型

Result: 生成式LLM在所有任务中表现最佳（Macro F1 0.91），在处理隐式方面方面表现出色。微调模型由于数据集不平衡和架构容量限制而表现有限。

Conclusion: 这项工作为多样化代码切换环境中的ABSA提供了一个可扩展和语言适应的框架，证明了生成式LLM在低资源混合语言场景中的有效性。

Abstract: Aspect Extraction (AE) is a key task in Aspect-Based Sentiment Analysis (ABSA), yet it remains difficult to apply in low-resource and code-switched contexts like Taglish, a mix of Tagalog and English commonly used in Filipino e-commerce reviews. This paper introduces a comprehensive AE pipeline designed for Taglish, combining rule-based, large language model (LLM)-based, and fine-tuning techniques to address both aspect identification and extraction. A Hierarchical Aspect Framework (HAF) is developed through multi-method topic modeling, along with a dual-mode tagging scheme for explicit and implicit aspects. For aspect identification, four distinct models are evaluated: a Rule-Based system, a Generative LLM (Gemini 2.0 Flash), and two Fine-Tuned Gemma-3 1B models trained on different datasets (Rule-Based vs. LLM-Annotated). Results indicate that the Generative LLM achieved the highest performance across all tasks (Macro F1 0.91), demonstrating superior capability in handling implicit aspects. In contrast, the fine-tuned models exhibited limited performance due to dataset imbalance and architectural capacity constraints. This work contributes a scalable and linguistically adaptive framework for enhancing ABSA in diverse, code-switched environments.

</details>


### [56] [Surprisal and Metaphor Novelty: Moderate Correlations and Divergent Scaling Effects](https://arxiv.org/abs/2601.02015)
*Omar Momen,Emilie Sitter,Berenike Herrmann,Sina Zarrieß*

Main category: cs.CL

Relevance: 65.0

TL;DR: 研究探讨语言模型中的惊奇度（surprisal）是否与隐喻新颖性相关，发现两者存在中度相关性，但惊奇度作为语言创造性的度量指标仍有限制。


<details>
  <summary>Details</summary>
Motivation: 新颖隐喻理解涉及复杂的语义过程和语言创造性，是研究语言模型的有趣任务。本研究旨在探索语言模型中的概率性预测度量——惊奇度，是否与不同隐喻新颖性数据集相关。

Method: 分析了16种语言模型变体在基于语料库和合成隐喻新颖性数据集上的惊奇度。探索了基于完整句子上下文的完形填空式惊奇度方法。

Result: 语言模型与隐喻新颖性评分/标签存在显著的中度相关性。发现了不同的扩展模式：在基于语料库的数据上，相关性强度随模型规模增大而减小（逆扩展效应）；在合成数据上则随模型规模增大而增加（质量-能力假设）。

Conclusion: 虽然惊奇度能够部分解释隐喻新颖性的标注，但它仍然是语言创造性的有限度量指标。

Abstract: Novel metaphor comprehension involves complex semantic processes and linguistic creativity, making it an interesting task for studying language models (LMs). This study investigates whether surprisal, a probabilistic measure of predictability in LMs, correlates with different metaphor novelty datasets. We analyse surprisal from 16 LM variants on corpus-based and synthetic metaphor novelty datasets. We explore a cloze-style surprisal method that conditions on full-sentence context. Results show that LMs yield significant moderate correlations with scores/labels of metaphor novelty. We further identify divergent scaling patterns: on corpus-based data, correlation strength decreases with model size (inverse scaling effect), whereas on synthetic data it increases (Quality-Power Hypothesis). We conclude that while surprisal can partially account for annotations of metaphor novelty, it remains a limited metric of linguistic creativity.

</details>


### [57] [Cost-Efficient Cross-Lingual Retrieval-Augmented Generation for Low-Resource Languages: A Case Study in Bengali Agricultural Advisory](https://arxiv.org/abs/2601.02065)
*Md. Asif Hossain,Nabil Subhan,Mantasha Rahman Mahi,Jannatul Ferdous Nabila*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出一个面向孟加拉语农业咨询的跨语言检索增强生成框架，通过翻译中心架构实现低成本、事实可靠的知识访问


<details>
  <summary>Details</summary>
Motivation: 发展中国家农业咨询存在语言障碍：权威农业手册多为英文，而农民使用孟加拉语等低资源语言。现有LLM直接生成低资源语言存在流畅性和事实一致性问题，云端方案成本过高

Method: 采用翻译中心架构：1) 将孟加拉语查询翻译为英文；2) 注入领域特定关键词以对齐农民口语与科学术语；3) 在英文农业手册上进行密集向量检索；4) 生成英文回答并翻译回孟加拉语。完全使用开源模型，可在消费级硬件运行

Result: 系统能提供可靠的事实依据回答，有效拒绝领域外查询，平均端到端延迟低于20秒，展示了跨语言检索与受控翻译的实用性

Conclusion: 跨语言检索结合受控翻译为低资源语言环境中的农业知识访问提供了实用且可扩展的解决方案，特别适合发展中国家农业咨询场景

Abstract: Access to reliable agricultural advisory remains limited in many developing regions due to a persistent language barrier: authoritative agricultural manuals are predominantly written in English, while farmers primarily communicate in low-resource local languages such as Bengali. Although recent advances in Large Language Models (LLMs) enable natural language interaction, direct generation in low-resource languages often exhibits poor fluency and factual inconsistency, while cloud-based solutions remain cost-prohibitive. This paper presents a cost-efficient, cross-lingual Retrieval-Augmented Generation (RAG) framework for Bengali agricultural advisory that emphasizes factual grounding and practical deployability. The proposed system adopts a translation-centric architecture in which Bengali user queries are translated into English, enriched through domain-specific keyword injection to align colloquial farmer terminology with scientific nomenclature, and answered via dense vector retrieval over a curated corpus of English agricultural manuals (FAO, IRRI). The generated English response is subsequently translated back into Bengali to ensure accessibility. The system is implemented entirely using open-source models and operates on consumer-grade hardware without reliance on paid APIs. Experimental evaluation demonstrates reliable source-grounded responses, robust rejection of out-of-domain queries, and an average end-to-end latency below 20 seconds. The results indicate that cross-lingual retrieval combined with controlled translation offers a practical and scalable solution for agricultural knowledge access in low-resource language settings

</details>


### [58] [pdfQA: Diverse, Challenging, and Realistic Question Answering over PDFs](https://arxiv.org/abs/2601.02285)
*Tobias Schimanski,Imene Kolli,Jingwei Ni,Yu Fan,Ario Saeid Vaghefi,Elliott Ash,Markus Leippold*

Main category: cs.CL

Relevance: 65.0

TL;DR: pdfQA是一个多领域PDF问答数据集，包含2K人工标注和2K合成数据，从十个复杂度维度区分QA对，用于评估端到端QA流程和LLM能力。


<details>
  <summary>Details</summary>
Motivation: PDF是互联网上第二常用的文档类型，但现有的QA数据集通常从文本源开始或只针对特定领域，缺乏针对PDF文档的全面QA评估基准。

Method: 创建pdfQA数据集：包含2K人工标注的real-pdfQA和2K合成的syn-pdfQA，从十个复杂度维度（文件类型、源模态、源位置、答案类型等）区分QA对，应用质量和难度过滤器，使用开源LLM回答问题。

Result: 数据集提供了有效且具有挑战性的QA对，揭示了LLM在PDF问答中存在的挑战，这些挑战与复杂度维度相关，为端到端QA流程评估提供了基础。

Conclusion: pdfQA为评估端到端QA流程、测试多样化技能集和局部优化（如信息检索或解析）提供了基准，有助于理解LLM在PDF文档问答中的能力限制。

Abstract: PDFs are the second-most used document type on the internet (after HTML). Yet, existing QA datasets commonly start from text sources or only address specific domains. In this paper, we present pdfQA, a multi-domain 2K human-annotated (real-pdfQA) and 2K synthetic dataset (syn-pdfQA) differentiating QA pairs in ten complexity dimensions (e.g., file type, source modality, source position, answer type). We apply and evaluate quality and difficulty filters on both datasets, obtaining valid and challenging QA pairs. We answer the questions with open-source LLMs, revealing existing challenges that correlate with our complexity dimensions. pdfQA presents a basis for end-to-end QA pipeline evaluation, testing diverse skill sets and local optimizations (e.g., in information retrieval or parsing).

</details>


### [59] [AppellateGen: A Benchmark for Appellate Legal Judgment Generation](https://arxiv.org/abs/2601.01331)
*Hongkun Yang,Lionel Z. Wang,Wei Fan,Yiran Hu,Lixu Wang,Chenyu Liu,Shenghong Fu,Haoyang Li,Xin Xu,Jiexin Zheng,Wei Dong*

Main category: cs.CY

Relevance: 65.0

TL;DR: 提出了AppellateGen基准，用于上诉（二审）法律判决生成任务，包含7,351个案例对。同时提出了基于司法标准操作程序的法律多智能体系统（SLMAS），模拟司法工作流程来分解判决生成过程。


<details>
  <summary>Details</summary>
Motivation: 现有法律判决生成研究主要关注一审审判，依赖静态的事实到判决映射，忽视了上诉（二审）审查的辩证性质。需要解决上诉法律判决生成的挑战。

Method: 提出了基于司法标准操作程序的法律多智能体系统（SLMAS），将生成过程分解为问题识别、检索和起草三个离散阶段，模拟司法工作流程。

Result: 实验结果表明，虽然SLMAS提高了逻辑一致性，但上诉推理的复杂性对当前LLMs仍然构成重大挑战。

Conclusion: 上诉法律判决生成是一个具有挑战性的任务，需要更复杂的推理能力。提出的基准和系统为这一领域提供了研究基础。

Abstract: Legal judgment generation is a critical task in legal intelligence. However, existing research in legal judgment generation has predominantly focused on first-instance trials, relying on static fact-to-verdict mappings while neglecting the dialectical nature of appellate (second-instance) review. To address this, we introduce AppellateGen, a benchmark for second-instance legal judgment generation comprising 7,351 case pairs. The task requires models to draft legally binding judgments by reasoning over the initial verdict and evidentiary updates, thereby modeling the causal dependency between trial stages. We further propose a judicial Standard Operating Procedure (SOP)-based Legal Multi-Agent System (SLMAS) to simulate judicial workflows, which decomposes the generation process into discrete stages of issue identification, retrieval, and drafting. Experimental results indicate that while SLMAS improves logical consistency, the complexity of appellate reasoning remains a substantial challenge for current LLMs. The dataset and code are publicly available at: https://anonymous.4open.science/r/AppellateGen-5763.

</details>


### [60] [SWE-Lego: Pushing the Limits of Supervised Fine-tuning for Software Issue Resolving](https://arxiv.org/abs/2601.01426)
*Chaofan Tao,Jierun Chen,Yuxin Jiang,Kaiqi Kou,Shaowei Wang,Ruoyu Wang,Xiaohui Li,Sidi Yang,Yiming Du,Jianbo Dai,Zhiming Mao,Xinyu Wang,Lifeng Shang,Haoli Bai*

Main category: cs.SE

Relevance: 65.0

TL;DR: SWE-Lego是一个针对软件工程任务优化的监督微调方法，仅使用SFT就达到了开源模型中的SOTA性能，包含高质量数据集、改进的SFT流程和测试时扩展技术。


<details>
  <summary>Details</summary>
Motivation: 当前软件工程任务解决方法通常依赖复杂的训练范式（如中期训练、SFT、强化学习等组合），本文探索如何通过轻量级的纯SFT方法在SWE任务上达到极限性能。

Method: 1) SWE-Lego数据集：包含32k高质量任务实例和18k验证轨迹，结合真实和合成数据；2) 改进的SFT流程：包含错误掩码和基于难度的课程学习；3) 测试时扩展：基于训练良好的验证器进行性能提升。

Result: SWE-Lego-Qwen3-8B在SWE-bench Verified上达到42.2%，32B版本达到52.6%；通过测试时扩展（TTS@16），8B提升至49.6%，32B提升至58.8%，在可比规模的开源模型中达到SOTA。

Conclusion: 通过精心设计的SFT方法，即使不使用复杂的训练范式，也能在软件工程任务上达到卓越性能，为特定领域LLM优化提供了有效范例。

Abstract: We present SWE-Lego, a supervised fine-tuning (SFT) recipe designed to achieve state-ofthe-art performance in software engineering (SWE) issue resolving. In contrast to prevalent methods that rely on complex training paradigms (e.g., mid-training, SFT, reinforcement learning, and their combinations), we explore how to push the limits of a lightweight SFT-only approach for SWE tasks. SWE-Lego comprises three core building blocks, with key findings summarized as follows: 1) the SWE-Lego dataset, a collection of 32k highquality task instances and 18k validated trajectories, combining real and synthetic data to complement each other in both quality and quantity; 2) a refined SFT procedure with error masking and a difficulty-based curriculum, which demonstrably improves action quality and overall performance. Empirical results show that with these two building bricks alone,the SFT can push SWE-Lego models to state-of-the-art performance among open-source models of comparable size on SWE-bench Verified: SWE-Lego-Qwen3-8B reaches 42.2%, and SWE-Lego-Qwen3-32B attains 52.6%. 3) We further evaluate and improve test-time scaling (TTS) built upon the SFT foundation. Based on a well-trained verifier, SWE-Lego models can be significantly boosted--for example, 42.2% to 49.6% and 52.6% to 58.8% under TTS@16 for the 8B and 32B models, respectively.

</details>


### [61] [The Gray Area: Characterizing Moderator Disagreement on Reddit](https://arxiv.org/abs/2601.01620)
*Shayan Alipour,Shruti Phadke,Seyed Shahabeddin Mousavi,Amirhossein Afsharrad,Morteza Zihayat,Mattia Samory*

Main category: cs.CY

Relevance: 65.0

TL;DR: 研究分析了Reddit论坛中内容审核的"灰色区域"——审核员之间存在分歧的案例，发现七分之一的审核案例存在争议，这些案例通常涉及意图不明确的行为（如钓鱼、跨社区攻击）和社区治理问题，且近一半涉及自动化审核决策。研究表明灰色区域案例本质上更难裁决，最先进的语言模型也难以处理。


<details>
  <summary>Details</summary>
Motivation: 在线社区志愿者审核员在维持对话中起关键作用，但他们在审核标准上经常存在分歧。本研究旨在理解这种"灰色区域"审核案例的特征和挑战，特别是当自动化审核系统介入时，如何平衡效率与准确性。

Method: 基于5年时间跨度和430万条审核日志，涵盖24个不同主题和规模的subreddit论坛。使用信息论方法评估审核难度，并测试最先进语言模型在裁决灰色区域案例时的表现。

Result: 1) 七分之一的审核案例存在争议；2) 灰色区域案例通常涉及用户意图不明确的行为（钓鱼、跨社区攻击）和社区治理冲突；3) 近一半灰色区域案例涉及自动化审核决策；4) 灰色区域案例本质上比无争议案例更难裁决；5) 最先进语言模型难以有效处理这些案例。

Conclusion: 人类专家审核员在监督审核过程中仍扮演关键角色，当前审核流程和工具在处理复杂、意图不明确的案例时面临挑战，需要更好的方法来解决审核分歧。

Abstract: Volunteer moderators play a crucial role in sustaining online dialogue, but they often disagree about what should or should not be allowed. In this paper, we study the complexity of content moderation with a focus on disagreements between moderators, which we term the ``gray area'' of moderation. Leveraging 5 years and 4.3 million moderation log entries from 24 subreddits of different topics and sizes, we characterize how gray area, or disputed cases, differ from undisputed cases. We show that one-in-seven moderation cases are disputed among moderators, often addressing transgressions where users' intent is not directly legible, such as in trolling and brigading, as well as tensions around community governance. This is concerning, as almost half of all gray area cases involved automated moderation decisions. Through information-theoretic evaluations, we demonstrate that gray area cases are inherently harder to adjudicate than undisputed cases and show that state-of-the-art language models struggle to adjudicate them. We highlight the key role of expert human moderators in overseeing the moderation process and provide insights about the challenges of current moderation processes and tools.

</details>


### [62] [LACONIC: Dense-Level Effectiveness for Scalable Sparse Retrieval via a Two-Phase Training Curriculum](https://arxiv.org/abs/2601.01684)
*Zhichao Xu,Shengyao Zhuang,Crystina Zhang,Xueguang Ma,Yijun Tian,Maitrey Mehta,Jimmy Lin,Vivek Srikumar*

Main category: cs.IR

Relevance: 65.0

TL;DR: LACONIC是基于Llama-3架构的稀疏检索模型家族，通过两阶段训练实现高效检索，在MTEB基准上达到60.2 nDCG，比稠密模型减少71%索引内存


<details>
  <summary>Details</summary>
Motivation: 解决稠密检索模型的高内存需求和GPU依赖问题，提供在CPU硬件上高效运行的检索方案，同时弥合稀疏检索与稠密检索之间的性能差距

Method: 基于Llama-3架构（1B、3B、8B），采用两阶段训练：1）弱监督预微调使因果LLM适应双向上下文化；2）使用精选困难负样本的高质量微调

Result: 8B版本在MTEB检索基准上达到60.2 nDCG，排名第15位，比等效稠密模型减少71%索引内存，在CPU硬件上实现高效检索

Conclusion: LACONIC为现实世界搜索应用提供了可扩展且高效的解决方案，在保持高性能的同时显著降低计算和内存需求

Abstract: While dense retrieval models have become the standard for state-of-the-art information retrieval, their deployment is often constrained by high memory requirements and reliance on GPU accelerators for vector similarity search. Learned sparse retrieval offers a compelling alternative by enabling efficient search via inverted indices, yet it has historically received less attention than dense approaches. In this report, we introduce LACONIC, a family of learned sparse retrievers based on the Llama-3 architecture (1B, 3B, and 8B). We propose a streamlined two-phase training curriculum consisting of (1) weakly supervised pre-finetuning to adapt causal LLMs for bidirectional contextualization and (2) high-signal finetuning using curated hard negatives. Our results demonstrate that LACONIC effectively bridges the performance gap with dense models: the 8B variant achieves a state-of-the-art 60.2 nDCG on the MTEB Retrieval benchmark, ranking 15th on the leaderboard as of January 1, 2026, while utilizing 71\% less index memory than an equivalent dense model. By delivering high retrieval effectiveness on commodity CPU hardware with a fraction of the compute budget required by competing models, LACONIC provides a scalable and efficient solution for real-world search applications.

</details>


### [63] [HyperJoin: LLM-augmented Hypergraph Link Prediction for Joinable Table Discovery](https://arxiv.org/abs/2601.01015)
*Shiyuan Liu,Jianwei Wang,Xuemin Lin,Lu Qin,Wenjie Zhang,Ying Zhang*

Main category: cs.CL

Relevance: 45.0

TL;DR: HyperJoin：基于大语言模型增强的超图框架，用于可连接表发现，通过构建超图建模表结构，使用分层交互网络学习列表示，并通过最大生成树算法进行重排序以提高结果一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于语言模型的方法在可连接表发现任务中，离线建模时将表视为孤立或成对列，难以捕捉丰富的表间和表内结构信息；在线排序时仅基于查询-候选相似度，忽略候选列之间的相互影响，导致结果集不一致。

Method: 1. 构建超图：使用表内超边和LLM增强的表间超边建模表结构；2. 设计HIN分层交互网络：通过列和超边的双向消息传递学习表达性列表示；3. 在线重排序：将排序转化为一致性感知的top-k列选择问题，使用最大生成树算法剪枝噪声连接并最大化一致性。

Result: 实验表明HyperJoin优于现有基线方法，在Precision@15和Recall@15指标上分别平均提升21.4%和17.2%。

Conclusion: HyperJoin通过超图建模和分层交互网络有效解决了现有方法在结构信息捕捉和结果一致性方面的不足，为可连接表发现任务提供了更优的解决方案。

Abstract: As a pivotal task in data lake management, joinable table discovery has attracted widespread interest. While existing language model-based methods achieve remarkable performance by combining offline column representation learning with online ranking, their design insufficiently accounts for the underlying structural interactions: (1) offline, they directly model tables into isolated or pairwise columns, thereby struggling to capture the rich inter-table and intra-table structural information; and (2) online, they rank candidate columns based solely on query-candidate similarity, ignoring the mutual interactions among the candidates, leading to incoherent result sets. To address these limitations, we propose HyperJoin, a large language model (LLM)-augmented Hypergraph framework for Joinable table discovery. Specifically, we first construct a hypergraph to model tables using both the intra-table hyperedges and the LLM-augmented inter-table hyperedges. Consequently, the task of joinable table discovery is formulated as link prediction on this constructed hypergraph. We then design HIN, a Hierarchical Interaction Network that learns expressive column representations through bidirectional message passing over columns and hyperedges. To strengthen coherence and internal consistency in the result columns, we cast online ranking as a coherence-aware top-k column selection problem. We then introduce a reranking module that leverages a maximum spanning tree algorithm to prune noisy connections and maximize coherence. Experiments demonstrate the superiority of HyperJoin, achieving average improvements of 21.4% (Precision@15) and 17.2% (Recall@15) over the best baseline.

</details>


### [64] [Listen, Attend, Understand: a Regularization Technique for Stable E2E Speech Translation Training on High Variance labels](https://arxiv.org/abs/2601.01121)
*Yacouba Diarra,Michael Leventhal*

Main category: cs.CL

Relevance: 45.0

TL;DR: LAU是一种语义正则化技术，通过冻结文本嵌入提供方向性辅助损失，将语言基础性注入声学表示中，改善端到端语音翻译性能，特别是在数据稀缺和嘈杂的情况下。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译在目标转录具有高方差和语义歧义时，通常表现出收敛慢和性能差的问题。需要一种方法能在不增加推理成本的情况下，将语言基础性注入声学表示中。

Method: 提出LAU（Listen, Attend, Understand）语义正则化技术，通过利用冻结的文本嵌入提供方向性辅助损失，约束声学编码器的潜在空间。该方法在训练期间将语言基础性注入声学表示，而不增加推理成本。

Result: 在30小时班巴拉语到法语数据集上评估，LAU模型在使用100%更多数据预训练的E2E-ST系统上，标准指标表现相当，同时在保留语义含义方面表现更好。引入总参数漂移作为量化正则化结构影响的指标。

Conclusion: LAU是后处理重评分的稳健替代方案，是E2E-ST训练的有价值补充，特别是在训练数据稀缺和/或嘈杂的情况下。语义约束主动重组编码器权重，优先考虑意义而非字面音素。

Abstract: End-to-End Speech Translation often shows slower convergence and worse performance when target transcriptions exhibit high variance and semantic ambiguity. We propose Listen, Attend, Understand (LAU), a semantic regularization technique that constrains the acoustic encoder's latent space during training. By leveraging frozen text embeddings to provide a directional auxiliary loss, LAU injects linguistic groundedness into the acoustic representation without increasing inference cost. We evaluate our method on a Bambara-to-French dataset with 30 hours of Bambara speech translated by non-professionals. Experimental results demonstrate that LAU models achieve comparable performance by standard metrics compared to an E2E-ST system pretrained with 100\% more data and while performing better in preserving semantic meaning. Furthermore, we introduce Total Parameter Drift as a metric to quantify the structural impact of regularization to demonstrate that semantic constraints actively reorganize the encoder's weights to prioritize meaning over literal phonetics. Our findings suggest that LAU is a robust alternative to post-hoc rescoring and a valuable addition to E2E-ST training, especially when training data is scarce and/or noisy.

</details>


### [65] [Almost Clinical: Linguistic properties of synthetic electronic health records](https://arxiv.org/abs/2601.01171)
*Serge Sharoff,John Baker,David Francis Hunt,Alan Simpson*

Main category: cs.CL

Relevance: 45.0

TL;DR: 该研究评估了合成电子健康记录在心理健康领域的语言学和临床适用性，分析了LLM生成的医疗文本在构建医疗权威和患者能动性方面的语言特征，发现虽然LLM能生成连贯、术语适当的文本，但仍存在系统性差异。


<details>
  <summary>Details</summary>
Motivation: 评估合成电子健康记录在心理健康领域的适用性，理解LLM如何通过语言选择构建医疗权威和患者能动性，识别LLM生成医疗文本的局限性和潜在风险。

Method: 首先描述创建合成语料库的理论基础和方法论，然后从能动性、模态和信息流三个维度评估四种临床文体（评估、通信、转诊和护理计划），分析LLM的语言选择如何构建医疗权威。

Result: LLM能生成连贯、术语适当的文本，近似临床实践，但存在系统性差异：语域转换、临床特异性不足、药物使用和诊断程序不准确等问题。

Conclusion: 合成EHR在心理健康领域具有潜力，但LLM生成的医疗文本存在系统性局限，需要进一步改进以确保临床准确性和安全性。

Abstract: This study evaluates the linguistic and clinical suitability of synthetic electronic health records (EHRs) in the field of mental health. First, we describe the rationale and the methodology for creating the synthetic corpus. Second, we assess agency, modality, and information flow across four clinical genres (Assessments, Correspondence, Referrals and Care plans) to understand how LLMs grammatically construct medical authority and patient agency through linguistic choices. While LLMs produce coherent, terminology-appropriate texts that approximate clinical practice, systematic divergences remain, including registerial shifts, insufficient clinical specificity, and inaccuracies in medication use and diagnostic procedures.

</details>


### [66] [Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory](https://arxiv.org/abs/2601.01280)
*Sen Hu,Yuxiang Wei,Jiaxin Ran,Zhiyuan Yao,Lei Zou*

Main category: cs.CL

Relevance: 45.0

TL;DR: 论文对对话记忆系统进行实验性分析，提出统一框架分解核心组件，比较图与非图方法的设计选择，发现性能差异主要源于基础系统设置而非架构创新，为未来研究提供稳定基线。


<details>
  <summary>Details</summary>
Motivation: 图结构在对话记忆系统中应用增多，但实证结果不一致，不清楚哪些设计选择真正重要。需要系统分析长期对话记忆架构，为研究提供可靠基础。

Method: 提出统一框架将对话记忆系统分解为核心组件，支持图和非图方法。在LongMemEval和HaluMem上进行受控、分阶段实验，比较记忆表示、组织、维护和检索的常见设计选择。

Result: 结果显示许多性能差异由基础系统设置驱动，而非特定架构创新。基于此识别出稳定可靠的强基线，为未来对话记忆研究提供参考。

Conclusion: 对话记忆系统的性能提升更多来自基础系统设置的优化，而非复杂的架构创新。研究为领域提供了可比较的基准和设计指导。

Abstract: Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we conduct controlled, stage-wise experiments on LongMemEval and HaluMem, comparing common design choices in memory representation, organization, maintenance, and retrieval. Our results show that many performance differences are driven by foundational system settings rather than specific architectural innovations. Based on these findings, we identify stable and reliable strong baselines for future dialog memory research.

</details>


### [67] [T3C: Test-Time Tensor Compression with Consistency Guarantees](https://arxiv.org/abs/2601.01299)
*Ismail Lamaakal,Chaymae Yahyati,Yassine Maleh,Khalid El Makkaoui,Ibrahim Ouahbi*

Main category: cs.CL

Relevance: 45.0

TL;DR: T3C是一个训练一次、测试时预算条件化的压缩框架，将秩和精度作为可控制的部署旋钮，通过弹性张量分解、混合精度量化和轻量级控制器实现硬件对齐的精度-延迟-大小权衡。


<details>
  <summary>Details</summary>
Motivation: 现有模型压缩方法通常需要为不同部署场景重新训练或微调，缺乏统一的、可预测的精度-效率权衡框架。T3C旨在通过单一训练好的检查点，根据不同的延迟/能耗/大小预算动态调整模型压缩配置。

Method: 1) 弹性张量分解：维护最大秩的张量分解表示；2) 秩绑定的混合精度量化；3) 轻量级控制器：将预算标记映射到每层秩/比特分配，策略对齐硬件配置且随预算单调变化；4) 快速层一致性证书：基于谱代理和激活统计计算，上界logit漂移并正则化训练。

Result: 在ImageNet-1k上，T3C显著推进了视觉模型的Pareto前沿：ResNet-50在精度下降≤0.5%时，p50延迟1.18ms，模型大小38MB，优于PTQ-8b（1.44ms，88MB）；ViT-B/16达到2.30ms p50延迟，59MB大小，优于强PTQ/QAT基线。

Conclusion: T3C通过单一检查点提供可预测的、证书支持的精度-延迟-大小权衡，实现了训练一次即可适应多种部署场景的灵活压缩框架。

Abstract: We present T3C, a train-once, test-time budget-conditioned compression framework that exposes rank and precision as a controllable deployment knob. T3C combines elastic tensor factorization (maintained up to a maximal rank) with rank-tied mixed-precision quantization and a lightweight controller that maps a latency/energy/size budget token to per-layer rank/bit assignments; the policy snaps to hardware-aligned profiles and is monotone in the budget. A fast, layerwise consistency certificate, computed from spectral proxies and activation statistics, upper-bounds logit drift and regularizes training, yielding a practical reliability signal with negligible overhead. On ImageNet-1k, T3C shifts the vision Pareto frontier: for ResNet-50 at matched accuracy (\leq 0.5% drop), p50 latency is 1.18ms with a 38MB model, outperforming PTQ-8b (1.44ms, 88MB); for ViT-B/16, T3C reaches 2.30ms p50 with 59MB, improving over strong PTQ/QAT baselines. A single T3C checkpoint therefore provides predictable, certificate-backed accuracy-latency-size trade-offs on demand across devices.

</details>


### [68] [Towards Automated Lexicography: Generating and Evaluating Definitions for Learner's Dictionaries](https://arxiv.org/abs/2601.01842)
*Yusuke Ide,Adam Nohejl,Joshua Tanner,Hitomi Yanaka,Christopher Lindsay,Taro Watanabe*

Main category: cs.CL

Relevance: 45.0

TL;DR: 该论文研究词典定义生成（DDG），特别是面向学习者的词典定义生成（LDDG），提出基于LLM-as-a-judge的评估方法和通过迭代简化的LDDG方法。


<details>
  <summary>Details</summary>
Motivation: 词典定义是学习词义的重要资源，但人工创建成本高昂，需要自动化生成过程。特别是面向学习者的词典定义需要由简单词汇组成，这增加了生成难度。

Method: 1) 提出基于新评估标准和LLM-as-a-judge的可靠DDG评估方法；2) 构建日语数据集作为评估参考；3) 提出通过LLM迭代简化的LDDG方法。

Result: 评估方法与人工标注者一致性较好；提出的LDDG方法在评估标准上得分高，同时保持词汇简单性。

Conclusion: 该研究为词典定义生成提供了有效的评估方法和生成方法，特别适用于学习者词典场景。

Abstract: We study dictionary definition generation (DDG), i.e., the generation of non-contextualized definitions for given headwords. Dictionary definitions are an essential resource for learning word senses, but manually creating them is costly, which motivates us to automate the process. Specifically, we address learner's dictionary definition generation (LDDG), where definitions should consist of simple words. First, we introduce a reliable evaluation approach for DDG, based on our new evaluation criteria and powered by an LLM-as-a-judge. To provide reference definitions for the evaluation, we also construct a Japanese dataset in collaboration with a professional lexicographer. Validation results demonstrate that our evaluation approach agrees reasonably well with human annotators. Second, we propose an LDDG approach via iterative simplification with an LLM. Experimental results indicate that definitions generated by our approach achieve high scores on our criteria while maintaining lexical simplicity.

</details>


### [69] [CSF: Contrastive Semantic Features for Direct Multilingual Sign Language Generation](https://arxiv.org/abs/2601.01964)
*Tran Sy Bao*

Main category: cs.CL

Relevance: 45.0

TL;DR: 提出了一种语言无关的语义表示框架CSF，用于直接翻译任何源语言到手语，无需英语中介。CSF将话语分解为9个通用语义槽，并建立了包含35种条件类型的综合分类法。训练了一个轻量级transformer提取器，在4种语言上达到99.03%的平均槽提取准确率。


<details>
  <summary>Details</summary>
Motivation: 当前手语翻译系统通常需要英语作为中介语言，这为全球聋人社区中的非英语使用者造成了障碍。需要一种语言无关的语义表示框架，实现从任何源语言到手语的直接翻译。

Method: 提出了Canonical Semantic Form (CSF)框架，将话语分解为9个通用语义槽：事件、意图、时间、条件、施事、受事、地点、目的和修饰语。建立了包含35种条件类型的综合分类法。训练了一个轻量级transformer-based提取器（0.74 MB）。

Result: 在英语、越南语、日语和法语四种类型学多样语言上，平均槽提取准确率达到99.03%。条件分类准确率达到99.4%（35类）。在CPU上推理延迟为3.02ms，支持浏览器应用的实时手语生成。

Conclusion: CSF框架能够实现语言无关的手语翻译，无需英语中介。轻量级模型在多种语言上表现出色，支持实时应用。开源代码、模型和多语言数据集以促进可访问手语技术研究。

Abstract: Sign language translation systems typically require English as an intermediary language, creating barriers for non-English speakers in the global deaf community. We present Canonical Semantic Form (CSF), a language-agnostic semantic representation framework that enables direct translation from any source language to sign language without English mediation. CSF decomposes utterances into nine universal semantic slots: event, intent, time, condition, agent, object, location, purpose, and modifier. A key contribution is our comprehensive condition taxonomy comprising 35 condition types across eight semantic categories, enabling nuanced representation of conditional expressions common in everyday communication. We train a lightweight transformer-based extractor (0.74 MB) that achieves 99.03% average slot extraction accuracy across four typologically diverse languages: English, Vietnamese, Japanese, and French. The model demonstrates particularly strong performance on condition classification (99.4% accuracy) despite the 35-class complexity. With inference latency of 3.02ms on CPU, our approach enables real-time sign language generation in browser-based applications. We release our code, trained models, and multilingual dataset to support further research in accessible sign language technology.

</details>


### [70] [SAFE-QAQ: End-to-End Slow-Thinking Audio-Text Fraud Detection via Reinforcement Learning](https://arxiv.org/abs/2601.01392)
*Peidong Wang,Zhiming Ma,Xin Dai,Yongkang Liu,Shi Feng,Xiaocui Yang,Wenxing Hu,Zhihao Wang,Mingjun Pan,Li Yuan,Daling Wang*

Main category: cs.SD

Relevance: 40.0

TL;DR: SAFE-QAQ是一个端到端的音频欺诈检测框架，通过消除ASR转录错误影响、基于规则的慢思考奖励机制和动态风险评估，显著提升了欺诈检测的准确性和实时处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有欺诈检测方法主要依赖转录文本，存在ASR错误且忽略了重要的声学线索（如语音语调、环境背景），限制了其对复杂欺骗策略的检测效果。

Method: 1) 端到端音频框架消除转录错误影响；2) 基于规则的慢思考奖励机制，通过分层推理过程捕捉细粒度音频细节；3) 实时通话中的动态风险评估框架，实现早期检测和预防。

Result: 在TeleAntiFraud-Bench上的实验表明，SAFE-QAQ在准确性、推理效率和实时处理能力等多个关键维度上显著优于现有方法。目前已部署并每天分析超过7万通电话，有效自动化复杂欺诈检测。

Conclusion: SAFE-QAQ通过音频直接分析和慢思考机制，解决了传统基于文本的欺诈检测方法的局限性，实现了更准确、高效的实时欺诈检测，减少了人工工作量和财务损失。

Abstract: Existing fraud detection methods predominantly rely on transcribed text, suffering from ASR errors and missing crucial acoustic cues like vocal tone and environmental context. This limits their effectiveness against complex deceptive strategies. To address these challenges, we first propose \textbf{SAFE-QAQ}, an end-to-end comprehensive framework for audio-based slow-thinking fraud detection. First, the SAFE-QAQ framework eliminates the impact of transcription errors on detection performance. Secondly, we propose rule-based slow-thinking reward mechanisms that systematically guide the system to identify fraud-indicative patterns by accurately capturing fine-grained audio details, through hierarchical reasoning processes. Besides, our framework introduces a dynamic risk assessment framework during live calls, enabling early detection and prevention of fraud. Experiments on the TeleAntiFraud-Bench demonstrate that SAFE-QAQ achieves dramatic improvements over existing methods in multiple key dimensions, including accuracy, inference efficiency, and real-time processing capabilities. Currently deployed and analyzing over 70,000 calls daily, SAFE-QAQ effectively automates complex fraud detection, reducing human workload and financial losses. Code: https://anonymous.4open.science/r/SAFE-QAQ.

</details>


### [71] [FC-CONAN: An Exhaustively Paired Dataset for Robust Evaluation of Retrieval Systems](https://arxiv.org/abs/2601.01350)
*Juan Junqueras,Florian Boudin,May-Myo Zin,Ha-Thanh Nguyen,Wachara Fungwacharakorn,Damián Ariel Furman,Akiko Aizawa,Ken Satoh*

Main category: cs.CL

Relevance: 35.0

TL;DR: FC-CONAN是首个通过穷举组合45条仇恨言论和129条反驳言论构建的完整数据集，包含四个可靠性等级的分区，为反驳言论检索系统提供更全面的评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论-反驳言论数据集（如CONAN）只标注了稀疏的样本对，限制了反驳言论研究的评估能力。需要更全面的数据集来支持更准确的系统评估和错误分析。

Method: 1) 穷举组合45条英语仇恨言论和129条反驳言论；2) 两阶段标注流程：9名标注员和4名验证员参与；3) 创建四个可靠性等级的分区（钻石、黄金、白银、青铜）。

Result: 构建了FC-CONAN数据集，发现了数百个之前未标注的正样本对，与CONAN无重叠。数据集公开可用，支持反驳言论检索系统的更忠实评估和详细错误分析。

Conclusion: FC-CONAN填补了仇恨言论-反驳言论数据集完整性的空白，为反驳言论研究提供了更可靠的评估基准，有助于推动该领域的发展。

Abstract: Hate speech (HS) is a critical issue in online discourse, and one promising strategy to counter it is through the use of counter-narratives (CNs). Datasets linking HS with CNs are essential for advancing counterspeech research. However, even flagship resources like CONAN (Chung et al., 2019) annotate only a sparse subset of all possible HS-CN pairs, limiting evaluation. We introduce FC-CONAN (Fully Connected CONAN), the first dataset created by exhaustively considering all combinations of 45 English HS messages and 129 CNs. A two-stage annotation process involving nine annotators and four validators produces four partitions-Diamond, Gold, Silver, and Bronze-that balance reliability and scale. None of the labeled pairs overlap with CONAN, uncovering hundreds of previously unlabelled positives. FC-CONAN enables more faithful evaluation of counterspeech retrieval systems and facilitates detailed error analysis. The dataset is publicly available.

</details>


### [72] [Bridging the Data Gap: Creating a Hindi Text Summarization Dataset from the English XSUM](https://arxiv.org/abs/2601.01543)
*Praveenkumar Katwe,RakeshChandra Balabantaray,Kaliprasad Vittala*

Main category: cs.CL

Relevance: 35.0

TL;DR: 本文提出了一种成本效益高的自动化框架，用于创建全面的印地语文本摘要数据集，通过翻译和语言适应技术将英语XSUM数据集转换为印地语版本。


<details>
  <summary>Details</summary>
Motivation: 当前NLP进展主要偏向资源丰富的语言，印地语等低资源语言缺乏高质量数据集，特别是在文本摘要领域，缺乏多样化的专业语料库阻碍了稳健模型的开发。

Method: 使用英语XSUM数据集作为源，采用先进的翻译和语言适应技术，利用COMET进行验证，并选择性使用LLM进行数据筛选和整理。

Result: 创建了一个多样化、多主题的印地语文本摘要数据集，反映了原始XSUM语料库的复杂性，为印地语NLP研究提供了直接工具。

Conclusion: 这项工作不仅为印地语NLP研究提供了资源，还为其他资源不足语言提供了可扩展的方法论，通过降低数据集创建成本，促进了计算语言学中更细致、文化相关模型的发展。

Abstract: Current advancements in Natural Language Processing (NLP) have largely favored resource-rich languages, leaving a significant gap in high-quality datasets for low-resource languages like Hindi. This scarcity is particularly evident in text summarization, where the development of robust models is hindered by a lack of diverse, specialized corpora.
  To address this disparity, this study introduces a cost-effective, automated framework for creating a comprehensive Hindi text summarization dataset. By leveraging the English Extreme Summarization (XSUM) dataset as a source, we employ advanced translation and linguistic adaptation techniques. To ensure high fidelity and contextual relevance, we utilize the Crosslingual Optimized Metric for Evaluation of Translation (COMET) for validation, supplemented by the selective use of Large Language Models (LLMs) for curation.
  The resulting dataset provides a diverse, multi-thematic resource that mirrors the complexity of the original XSUM corpus. This initiative not only provides a direct tool for Hindi NLP research but also offers a scalable methodology for democratizing NLP in other underserved languages. By reducing the costs associated with dataset creation, this work fosters the development of more nuanced, culturally relevant models in computational linguistics.

</details>


### [73] [FormationEval, an open multiple-choice benchmark for petroleum geoscience](https://arxiv.org/abs/2601.02158)
*Almaz Ermilov*

Main category: cs.CL

Relevance: 35.0

TL;DR: FormationEval是一个用于评估语言模型在石油地质科学和地下学科能力的开放多项选择题基准，包含505个问题，覆盖7个领域，评估了72个模型。


<details>
  <summary>Details</summary>
Motivation: 创建专门针对石油地质科学和地下学科的评估基准，以衡量语言模型在专业领域的知识掌握程度，填补现有评估在专业科学领域的空白。

Method: 从三个权威来源使用推理模型和基于概念的方法构建数据集，避免逐字复制受版权保护的文本。每个问题包含源元数据以支持可追溯性和审计。

Result: 评估了72个模型，顶级模型准确率超过97%，Gemini 3 Pro Preview达到99.8%。开源模型中GLM-4.7以98.6%领先，多个DeepSeek、Llama、Qwen和Mistral模型超过93%。开源与闭源模型性能差距小于预期。

Conclusion: 石油地质科学领域存在模型性能差异，开源模型表现良好，岩石物理学是最具挑战性的领域。数据集存在正确答案长度偏差，已应用缓解策略。

Abstract: This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derived from three authoritative sources using a reasoning model with detailed instructions and a concept-based approach that avoids verbatim copying of copyrighted text. Each question includes source metadata to support traceability and audit. The evaluation covers 72 models from major providers including OpenAI, Anthropic, Google, Meta and open-weight alternatives. The top performers achieve over 97\% accuracy, with Gemini 3 Pro Preview reaching 99.8\%, while tier and domain gaps persist. Among open-weight models, GLM-4.7 leads at 98.6\%, with several DeepSeek, Llama, Qwen and Mistral models also exceeding 93\%. The performance gap between open-weight and closed models is narrower than expected, with several lower-cost open-weight models exceeding 90\% accuracy. Petrophysics emerges as the most challenging domain across all models, while smaller models show wider performance variance. Residual length bias in the dataset (correct answers tend to be longer) is documented along with bias mitigation strategies applied during construction. The benchmark, evaluation code and results are publicly available.

</details>


### [74] [Entity-Aware and Secure Query Optimization in Database Using Named Entity Recognition](https://arxiv.org/abs/2601.01254)
*Azrin Sultana,Hasibur Rashid Chayon*

Main category: cs.DB

Relevance: 35.0

TL;DR: 提出智能隐私保护查询优化框架，集成命名实体识别检测查询中的敏感信息，结合AES加密和盲索引保护敏感数据，使用K-means聚类优化非敏感数据检索，DBN-LSTM模型达到93%准确率。


<details>
  <summary>Details</summary>
Motivation: 云存储是现代数据基础设施的核心，但隐私保护和高效数据检索仍是重大挑战。传统方法主要关注数据库安全增强，但未能解决加密前敏感信息的自动识别问题，这可能导致查询处理时间增加和手动识别错误，从而带来隐私风险。

Method: 1) 使用深度学习算法和基于Transformer的模型检测和分类敏感实体；2) 采用AES算法加密敏感数据，结合盲索引实现安全搜索功能；3) 对非敏感数据使用K-means算法分组，结合排名搜索进行优化；4) 提出集成NER的智能隐私保护查询优化框架。

Result: DBN-LSTM模型在所有NER模型中表现最佳，准确率93%，精确率94%，召回率和F1分数均为93%。加密搜索通过盲索引显著加快结果返回速度，非敏感数据获取也优于传统基于聚类的搜索方法。

Conclusion: 通过集成敏感数据检测、加密和查询优化，该研究推进了现代云基础设施中隐私保护计算的发展状态，为云存储提供了更高效、安全的隐私保护解决方案。

Abstract: Cloud storage has become the backbone of modern data infrastructure, yet privacy and efficient data retrieval remain significant challenges. Traditional privacy-preserving approaches primarily focus on enhancing database security but fail to address the automatic identification of sensitive information before encryption. This can dramatically reduce query processing time and mitigate errors during manual identification of sensitive information, thereby reducing potential privacy risks. To address this limitation, this research proposes an intelligent privacy-preserving query optimization framework that integrates Named Entity Recognition (NER) to detect sensitive information in queries, utilizing secure data encryption and query optimization techniques for both sensitive and non-sensitive data in parallel, thereby enabling efficient database optimization. Combined deep learning algorithms and transformer-based models to detect and classify sensitive entities with high precision, and the Advanced Encryption Standard (AES) algorithm to encrypt, with blind indexing to secure search functionality of the sensitive data, whereas non-sensitive data was divided into groups using the K-means algorithm, along with a rank search for optimization. Among all NER models, the Deep Belief Network combined with Long Short-Term Memory (DBN-LSTM) delivers the best performance, with an accuracy of 93% and precision (94%), recall, and F1 score of 93%, and 93%, respectively. Besides, encrypted search achieved considerably faster results with the help of blind indexing, and non-sensitive data fetching also outperformed traditional clustering-based searches. By integrating sensitive data detection, encryption, and query optimization, this work advances the state of privacy-preserving computation in modern cloud infrastructures.

</details>


### [75] [EHRSummarizer: A Privacy-Aware, FHIR-Native Architecture for Structured Clinical Summarization of Electronic Health Records](https://arxiv.org/abs/2601.01668)
*Houman Kazemzadeh,Nima Minaifar,Kamyar Naderi,Sho Tabibzadeh*

Main category: cs.CL

Relevance: 30.0

TL;DR: EHRSummarizer是一个隐私感知、FHIR原生的参考架构，用于从碎片化的电子健康记录中检索、规范化FHIR R4资源，并生成结构化摘要以支持结构化病历审查。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要从碎片化的电子健康记录界面中拼凑出患者问题的连贯画面，包括药物、近期就诊和长期趋势等信息，这个过程效率低下且容易出错。

Method: 采用隐私感知的FHIR原生参考架构，检索目标化的高价值FHIR R4资源，将其规范化到一致的临床上下文包中，然后生成结构化摘要。系统支持数据最小化、无状态处理和灵活部署，包括在组织信任边界内的本地推理。

Result: 在合成和测试FHIR环境中的原型演示展示了端到端行为和输出格式，但本文未报告临床结果或受控工作流程研究。提出了以忠实性、遗漏风险、时间正确性、可用性和操作监控为中心的评估计划。

Conclusion: EHRSummarizer提供了一个可行的架构来解决电子健康记录碎片化问题，通过结构化摘要支持临床决策，同时强调隐私保护和避免诊断或治疗建议以降低风险。

Abstract: Clinicians routinely navigate fragmented electronic health record (EHR) interfaces to assemble a coherent picture of a patient's problems, medications, recent encounters, and longitudinal trends. This work describes EHRSummarizer, a privacy-aware, FHIR-native reference architecture that retrieves a targeted set of high-yield FHIR R4 resources, normalizes them into a consistent clinical context package, and produces structured summaries intended to support structured chart review. The system can be configured for data minimization, stateless processing, and flexible deployment, including local inference within an organization's trust boundary. To mitigate the risk of unsupported or unsafe behavior, the summarization stage is constrained to evidence present in the retrieved context package, is intended to indicate missing or unavailable domains where feasible, and avoids diagnostic or treatment recommendations. Prototype demonstrations on synthetic and test FHIR environments illustrate end-to-end behavior and output formats; however, this manuscript does not report clinical outcomes or controlled workflow studies. We outline an evaluation plan centered on faithfulness, omission risk, temporal correctness, usability, and operational monitoring to guide future institutional assessments.

</details>


### [76] [KOS-TL (Knowledge Operation System Type Logic)](https://arxiv.org/abs/2601.01143)
*Peng Chen*

Main category: cs.CL

Relevance: 25.0

TL;DR: KOS-TL是一个基于依赖类型理论的构造性框架，为自主可执行知识系统提供严格的逻辑基础，通过三层架构统一数据、逻辑和证明，确保系统在连续状态转换中保持逻辑自洽。


<details>
  <summary>Details</summary>
Motivation: 传统知识表示模型存在静态符号逻辑与动态系统执行之间的鸿沟。为了解决这个问题，需要建立一个能够统一数据、逻辑和证明的严格逻辑基础，使知识系统既能保持形式化验证的严谨性，又能支持动态执行。

Method: 采用依赖类型理论作为计算基础，构建三层架构：核心层定义静态类型宇宙和构造原语；内核层通过事件驱动机制（⟨Σ, Ev, Δ⟩三元组）管理状态演化；运行时层负责物理信号与逻辑证据的双向精化。整合Davidsonian事件语义和Martin-Löf类型理论，实现"携带证明的知识"。

Result: 形式化定义了系统的操作语义，证明了关键元理论性质（进展性和演化一致性），确保系统在连续状态转换中无死锁且逻辑自洽。在工业追溯和跨境金融合规等应用中展示了实用性。

Conclusion: KOS-TL为下一代智能自主操作系统提供了强大、可形式化验证的基础，通过统一数据、逻辑和证明，解决了传统知识表示中静态逻辑与动态执行之间的鸿沟。

Abstract: This paper introduces KOS-TL (Knowledge Operation System Type Logic), a novel constructive framework designed to provide a rigorous logical foundation for autonomous and executable knowledge systems. Traditional knowledge representation models often suffer from a gap between static symbolic logic and dynamic system execution. To bridge this divide, KOS-TL leverages Dependent Type Theory to unify data, logic, and proof into a singular computational substrate.The architecture of KOS-TL is organized into three hierarchical layers: the Core Layer, which defines the static type universe and constructive primitives; the Kernel Layer, which governs state evolution through an event-driven mechanism characterized by the triple $\langle Σ, \textsf{Ev}, Δ\rangle$; and the Runtime Layer, responsible for the bidirectional refinement of physical signals into logical evidence. We formally define the operational semantics of the system and prove key meta-theoretical properties, including Progress and Evolutionary Consistency, ensuring that the system remains logically self-consistent and free from stuck states during continuous state transitions.By integrating Davidsonian event semantics with Martin-Löf type theory, KOS-TL enables the construction of "proof-carrying knowledge," where every state change in the knowledge base is accompanied by a formal witness of its validity. We demonstrate the practical utility of this logic through application examples in industrial traceability and cross-border financial compliance. Our results suggest that KOS-TL provides a robust, formally verifiable basis for the next generation of intelligent, autonomous operating systems.

</details>


### [77] [Multi-granularity Interactive Attention Framework for Residual Hierarchical Pronunciation Assessment](https://arxiv.org/abs/2601.01745)
*Hong Han,Hao-Chen Pei,Zhao-Zheng Nie,Xin Luo,Xin-Shun Xu*

Main category: cs.CL

Relevance: 25.0

TL;DR: 提出HIA（残差分层交互）方法用于多粒度发音评估，通过双向交互注意力模块和残差分层结构解决现有方法单向依赖问题，在speechocean762数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有多粒度发音评估方法仅考虑相邻粒度级别的单向依赖关系，缺乏音素、单词和话语级别之间的双向交互，无法充分捕捉声学结构相关性。

Method: 提出HIA方法：1) 交互注意力模块使用注意力机制实现动态双向交互；2) 残差分层结构缓解声学层次建模中的特征遗忘问题；3) 使用1-D卷积层增强各粒度局部上下文特征提取。

Result: 在speechocean762数据集上的广泛实验表明，该模型在多个评估指标上全面领先现有最先进方法。

Conclusion: HIA方法通过双向建模和残差分层结构有效解决了多粒度发音评估中的交互不足问题，显著提升了性能。

Abstract: Automatic pronunciation assessment plays a crucial role in computer-assisted pronunciation training systems. Due to the ability to perform multiple pronunciation tasks simultaneously, multi-aspect multi-granularity pronunciation assessment methods are gradually receiving more attention and achieving better performance than single-level modeling tasks. However, existing methods only consider unidirectional dependencies between adjacent granularity levels, lacking bidirectional interaction among phoneme, word, and utterance levels and thus insufficiently capturing the acoustic structural correlations. To address this issue, we propose a novel residual hierarchical interactive method, HIA for short, that enables bidirectional modeling across granularities. As the core of HIA, the Interactive Attention Module leverages an attention mechanism to achieve dynamic bidirectional interaction, effectively capturing linguistic features at each granularity while integrating correlations between different granularity levels. We also propose a residual hierarchical structure to alleviate the feature forgetting problem when modeling acoustic hierarchies. In addition, we use 1-D convolutional layers to enhance the extraction of local contextual cues at each granularity. Extensive experiments on the speechocean762 dataset show that our model is comprehensively ahead of the existing state-of-the-art methods.

</details>


### [78] [ARCADE: A City-Scale Corpus for Fine-Grained Arabic Dialect Tagging](https://arxiv.org/abs/2601.02209)
*Omer Nacar,Serry Sibaee,Adel Ammar,Yasser Alhabashi,Nadia Samer Sibai,Yara Farouk Ahmed,Ahmed Saud Alqusaiyer,Sulieman Mahmoud AlMahmoud,Abdulrhman Mamdoh Mukhaniq,Lubaba Raed,Sulaiman Mohammed Alatwah,Waad Nasser Alqahtani,Yousif Abdulmajeed Alnasser,Mohamed Aziz Khadraoui,Wadii Boulila*

Main category: cs.CL

Relevance: 25.0

TL;DR: ARCADE是首个城市级细粒度阿拉伯语方言语音数据集，包含来自19个国家58个城市的3790个音频片段，带有情感、语音类型、方言类别等丰富标注，用于方言识别基准测试。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语具有丰富的地区方言，在语音和词汇上差异显著，反映了使用者的地理和文化多样性。尽管已有许多多方言数据集，但将语音映射到城市级细粒度方言来源的研究仍然不足。

Method: 从阿拉伯世界流媒体服务收集阿拉伯广播语音，数据管道捕获30秒片段，包含现代标准阿拉伯语和多种方言语音。每个片段由1-3名母语阿拉伯语评审员标注，包括情感、语音类型、方言类别和有效性标志。

Result: 构建了包含6907个标注和3790个独特音频片段的数据集，涵盖19个国家58个城市。这些细粒度标注支持鲁棒的多任务学习，可作为城市级方言标记的基准。

Conclusion: ARCADE填补了阿拉伯语城市级方言语音数据集的空白，提供了详细的收集方法、音频质量评估和标签分布分析，为方言识别研究提供了重要资源。

Abstract: The Arabic language is characterized by a rich tapestry of regional dialects that differ substantially in phonetics and lexicon, reflecting the geographic and cultural diversity of its speakers. Despite the availability of many multi-dialect datasets, mapping speech to fine-grained dialect sources, such as cities, remains underexplored. We present ARCADE (Arabic Radio Corpus for Audio Dialect Evaluation), the first Arabic speech dataset designed explicitly with city-level dialect granularity. The corpus comprises Arabic radio speech collected from streaming services across the Arab world. Our data pipeline captures 30-second segments from verified radio streams, encompassing both Modern Standard Arabic (MSA) and diverse dialectal speech. To ensure reliability, each clip was annotated by one to three native Arabic reviewers who assigned rich metadata, including emotion, speech type, dialect category, and a validity flag for dialect identification tasks. The resulting corpus comprises 6,907 annotations and 3,790 unique audio segments spanning 58 cities across 19 countries. These fine-grained annotations enable robust multi-task learning, serving as a benchmark for city-level dialect tagging. We detail the data collection methodology, assess audio quality, and provide a comprehensive analysis of label distributions. The dataset is available on: https://huggingface.co/datasets/riotu-lab/ARCADE-full

</details>


### [79] [Segmentation and Processing of German Court Decisions from Open Legal Data](https://arxiv.org/abs/2601.01449)
*Harshil Darji,Martin Heckelmann,Christina Kratsch,Gerard de Melo*

Main category: cs.CL

Relevance: 20.0

TL;DR: 该论文从Open Legal Data原始数据集中清理并结构化地提取了251,038份德国法院判决的三个核心部分（Tenor、Tatbestand、Entscheidungsgründe），创建了一个标准化的德国法律数据集。


<details>
  <summary>Details</summary>
Motivation: 德国法律系统的NLP研究需要结构化数据。虽然Open Legal Data提供了大量德国法院判决，但原始数据中判决文本格式不一致，缺乏清晰标记的章节，这影响了修辞角色分类、检索和引证分析等下游任务。

Method: 从Open Legal Data原始数据集提取251,038份德国法院判决，系统分离三个核心部分：Tenor（判决主文）、Tatbestand（案件事实）、Entscheidungsgründe（判决理由）。使用Cochran公式以95%置信水平和5%误差范围抽取384个案例的统计代表性样本进行人工验证。同时提取Rechtsmittelbelehrung（上诉通知）作为独立字段。

Result: 创建了一个包含251,038份德国法院判决的清理和结构化数据集，三个核心部分被正确分离，并通过统计验证确保了提取过程的可靠性。数据集以JSONL格式公开可用。

Conclusion: 该工作为德国法律系统的NLP研究提供了高质量、结构化的数据集，解决了原始数据格式不一致的问题，有助于推进法律文本分析、信息检索和引证分析等研究。

Abstract: The availability of structured legal data is important for advancing Natural Language Processing (NLP) techniques for the German legal system. One of the most widely used datasets, Open Legal Data, provides a large-scale collection of German court decisions. While the metadata in this raw dataset is consistently structured, the decision texts themselves are inconsistently formatted and often lack clearly marked sections. Reliable separation of these sections is important not only for rhetorical role classification but also for downstream tasks such as retrieval and citation analysis. In this work, we introduce a cleaned and sectioned dataset of 251,038 German court decisions derived from the official Open Legal Data dataset. We systematically separated three important sections in German court decisions, namely Tenor (operative part of the decision), Tatbestand (facts of the case), and Entscheidungsgründe (judicial reasoning), which are often inconsistently represented in the original dataset. To ensure the reliability of our extraction process, we used Cochran's formula with a 95% confidence level and a 5% margin of error to draw a statistically representative random sample of 384 cases, and manually verified that all three sections were correctly identified. We also extracted the Rechtsmittelbelehrung (appeal notice) as a separate field, since it is a procedural instruction and not part of the decision itself. The resulting corpus is publicly available in the JSONL format, making it an accessible resource for further research on the German legal system.

</details>


### [80] [BanglaIPA: Towards Robust Text-to-IPA Transcription with Contextual Rewriting in Bengali](https://arxiv.org/abs/2601.01778)
*Jakir Hasan,Shrestha Datta,Md Saiful Islam,Shubhashis Roy Dipta,Ameya Debnath*

Main category: cs.CL

Relevance: 15.0

TL;DR: 提出了BanglaIPA系统，用于孟加拉语的国际音标自动转录，能处理标准语言和区域方言，通过字符级词汇和词级对齐提高准确性，在DUAL-IPA数据集上表现优于基线模型58.4-78.7%。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语缺乏强大的自动IPA转录系统，现有方法难以处理区域方言变体、数字表达，对新词泛化能力差，需要开发能同时支持标准语言和区域方言的解决方案。

Method: 提出BanglaIPA系统，整合字符级词汇与词级对齐，准确处理孟加拉数字，对已观察单词使用预计算的词到IPA映射词典提高推理效率。

Result: 在标准孟加拉语和六个区域变体的DUAL-IPA数据集上评估，BanglaIPA比基线IPA转录模型提升58.4-78.7%，总体平均词错误率为11.4%。

Conclusion: BanglaIPA系统为孟加拉语提供了鲁棒的IPA转录解决方案，能有效处理标准语言和区域方言，在准确性和效率方面都有显著改进。

Abstract: Despite its widespread use, Bengali lacks a robust automated International Phonetic Alphabet (IPA) transcription system that effectively supports both standard language and regional dialectal texts. Existing approaches struggle to handle regional variations, numerical expressions, and generalize poorly to previously unseen words. To address these limitations, we propose BanglaIPA, a novel IPA generation system that integrates a character-based vocabulary with word-level alignment. The proposed system accurately handles Bengali numerals and demonstrates strong performance across regional dialects. BanglaIPA improves inference efficiency by leveraging a precomputed word-to-IPA mapping dictionary for previously observed words. The system is evaluated on the standard Bengali and six regional variations of the DUAL-IPA dataset. Experimental results show that BanglaIPA outperforms baseline IPA transcription models by 58.4-78.7% and achieves an overall mean word error rate of 11.4%, highlighting its robustness in phonetic transcription generation for the Bengali language.

</details>


### [81] [Classifying several dialectal Nawatl varieties](https://arxiv.org/abs/2601.02303)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Carlos-Emiliano González-Gallardo,Graham Ranger,Martha Lorena-Avendaño-Garrido*

Main category: cs.CL

Relevance: 15.0

TL;DR: 该研究使用机器学习和神经网络对Nawatl（纳瓦特尔语）的方言变体进行分类，这是一种拥有超过200万使用者但计算资源稀缺的土著语言。


<details>
  <summary>Details</summary>
Motivation: Nawatl是墨西哥使用最广泛的土著语言，拥有超过200万使用者，但计算资源稀缺。该语言有约30种方言变体，加上不同的书写拼写形式，使得语言处理更加复杂。研究旨在解决Nawatl方言分类问题，以支持这种文化遗产语言的数字保存和处理。

Method: 使用机器学习和神经网络方法对Nawatl方言进行分类。具体方法可能包括文本分类模型、特征提取和方言识别算法，但摘要中未提供具体技术细节。

Result: 摘要中未报告具体结果，但研究成功应用了机器学习和神经网络方法来解决Nawatl方言分类问题。

Conclusion: 该研究展示了机器学习和神经网络在低资源土著语言处理中的可行性，为Nawatl语言的数字保存和方言识别提供了技术基础。

Abstract: Mexico is a country with a large number of indigenous languages, among which the most widely spoken is Nawatl, with more than two million people currently speaking it (mainly in North and Central America). Despite its rich cultural heritage, which dates back to the 15th century, Nawatl is a language with few computer resources. The problem is compounded when it comes to its dialectal varieties, with approximately 30 varieties recognised, not counting the different spellings in the written forms of the language. In this research work, we addressed the problem of classifying Nawatl varieties using Machine Learning and Neural Networks.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [82] [VideoCuRL: Video Curriculum Reinforcement Learning with Orthogonal Difficulty Decomposition](https://arxiv.org/abs/2601.00887)
*Hongbo Jin,Kuanwei Lin,Wenhao Zhang,Yichen Jin,Ge Li*

Main category: cs.CV

Relevance: 85.0

TL;DR: VideoCuRL：一个新颖的强化学习框架，通过将视频理解难度分解为视觉时间感知负载和认知推理深度两个正交维度，采用二维课程网格和对角线波前策略来优化VideoLLMs的训练。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习范式主要依赖随机数据洗牌或基于标量难度指标的简单课程策略，这些方法无法区分视频理解中的两个正交挑战：视觉时间感知负载和认知推理深度。标量指标无法有效解耦这两个维度，限制了VideoLLMs在复杂时空推理方面的性能提升。

Method: 1. 将难度分解为两个正交轴：视觉时间感知负载（使用光流和关键帧熵作为训练免费代理）和认知推理深度（使用校准惊奇度）
2. 构建二维课程网格映射数据
3. 采用能力感知的对角线波前策略进行训练调度
4. 引入动态稀疏KL和结构化重访机制来稳定训练，防止奖励崩溃和灾难性遗忘

Result: 在推理任务上（VSI-Bench）提升+2.5分，在感知任务上（VideoMME）提升+2.9分。显著优于现有强化学习基线，同时消除了基于生成的课程方法带来的推理开销，为稳健的视频后训练提供了可扩展解决方案。

Conclusion: VideoCuRL通过解耦视频理解的两个核心挑战维度，提供了一种更精细、更有效的课程强化学习框架，显著提升了VideoLLMs的性能，同时保持了训练效率和可扩展性。

Abstract: Reinforcement Learning (RL) is crucial for empowering VideoLLMs with complex spatiotemporal reasoning. However, current RL paradigms predominantly rely on random data shuffling or naive curriculum strategies based on scalar difficulty metrics. We argue that scalar metrics fail to disentangle two orthogonal challenges in video understanding: Visual Temporal Perception Load and Cognitive Reasoning Depth. To address this, we propose VideoCuRL, a novel framework that decomposes difficulty into these two axes. We employ efficient, training-free proxies, optical flow and keyframe entropy for visual complexity, Calibrated Surprisal for cognitive complexity, to map data onto a 2D curriculum grid. A competence aware Diagonal Wavefront strategy then schedules training from base alignment to complex reasoning. Furthermore, we introduce Dynamic Sparse KL and Structured Revisiting to stabilize training against reward collapse and catastrophic forgetting. Extensive experiments show that VideoCuRL surpasses strong RL baselines on reasoning (+2.5 on VSI-Bench) and perception (+2.9 on VideoMME) tasks. Notably, VideoCuRL eliminates the prohibitive inference overhead of generation-based curricula, offering a scalable solution for robust video post-training.

</details>


### [83] [NarrativeTrack: Evaluating Video Language Models Beyond the Frame](https://arxiv.org/abs/2601.01095)
*Hyeonjeong Ha,Jinjin Ge,Bo Feng,Kaixin Ma,Gargi Chakraborty*

Main category: cs.CV

Relevance: 85.0

TL;DR: NarrativeTrack是首个通过细粒度实体中心推理评估MLLMs叙事理解能力的基准，揭示模型在视觉转换和时间动态中跟踪实体的困难，发现感知基础与时间推理之间的基本权衡。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉语言推理方面取得显著进展，但对视频中时间性叙事理解能力的研究不足。真正的叙事理解需要模型能够理解"谁在何时何地做什么"，并在动态视觉和时间上下文中保持连贯的实体表示。

Method: 引入NarrativeTrack基准，通过组合推理进展（CRP）结构化评估框架，在三个维度上逐步增加叙事复杂性：实体存在、实体变化和实体模糊性。采用完全自动化的实体中心管道提取时间性实体表示。

Result: 评估显示：开源通用MLLMs具有强感知基础但弱时间连贯性；视频专用MLLMs能捕捉时间上下文但会幻觉实体上下文。模型在视觉转换和时间动态中难以稳健跟踪实体，经常在上下文变化下产生身份幻觉。

Conclusion: 叙事理解只能通过感知基础和时间推理的整合来实现。NarrativeTrack为诊断和推进MLLMs中时间性叙事理解提供了首个系统框架，揭示了感知基础与时间推理之间的基本权衡。

Abstract: Multimodal large language models (MLLMs) have achieved impressive progress in vision-language reasoning, yet their ability to understand temporally unfolding narratives in videos remains underexplored. True narrative understanding requires grounding who is doing what, when, and where, maintaining coherent entity representations across dynamic visual and temporal contexts. We introduce NarrativeTrack, the first benchmark to evaluate narrative understanding in MLLMs through fine-grained entity-centric reasoning. Unlike existing benchmarks limited to short clips or coarse scene-level semantics, we decompose videos into constituent entities and examine their continuity via a Compositional Reasoning Progression (CRP), a structured evaluation framework that progressively increases narrative complexity across three dimensions: entity existence, entity changes, and entity ambiguity. CRP challenges models to advance from temporal persistence to contextual evolution and fine-grained perceptual reasoning. A fully automated entity-centric pipeline enables scalable extraction of temporally grounded entity representations, providing the foundation for CRP. Evaluations of state-of-the-art MLLMs reveal that models fail to robustly track entities across visual transitions and temporal dynamics, often hallucinating identity under context shifts. Open-source general-purpose MLLMs exhibit strong perceptual grounding but weak temporal coherence, while video-specific MLLMs capture temporal context yet hallucinate entity's contexts. These findings uncover a fundamental trade-off between perceptual grounding and temporal reasoning, indicating that narrative understanding emerges only from their integration. NarrativeTrack provides the first systematic framework to diagnose and advance temporally grounded narrative comprehension in MLLMs.

</details>


### [84] [MambaFormer: Token-Level Guided Routing Mixture-of-Experts for Accurate and Efficient Clinical Assistance](https://arxiv.org/abs/2601.01260)
*Hamad Khan,Saddam Hussain Khan*

Main category: cs.CV

Relevance: 85.0

TL;DR: 提出MambaFormer混合专家框架，结合Transformer和状态空间模型，通过智能路由机制在医疗QA任务中实现高效推理，在保持高准确率的同时大幅降低延迟。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在临床应用中计算成本与线性时间模型效率之间的基本权衡问题，为资源受限的临床部署提供可扩展解决方案。

Method: 提出基于LLM的MambaFormer混合专家框架，包含轻量级门控机制进行token级动态路由：复杂短查询路由到定制Transformer专家(ET5)，长高吞吐序列路由到状态空间模型专家(EMamba)。使用新颖的效用引导多目标损失联合优化决策、路由参数和计算成本。

Result: 在DentalQA和PubMedQA数据集上验证，MambaFormer获得BERTScore 0.9180，超低延迟0.077秒，相比T5-Large实现24.4倍加速，在推理延迟和预测准确性之间达到帕累托最优权衡。

Conclusion: MambaFormer框架为资源受限的临床部署提供了可扩展解决方案，通过智能路由机制在医疗QA任务中实现了计算效率与准确性的良好平衡。

Abstract: The deployment of large language models (LLMs) in real-world clinical applications is constrained by the fundamental trade-off between computational cost and the efficiency of linear-time models. To address this, we propose an LLM-based MambaFormer hybrid Mixture-of-Experts (MoE) framework for efficient medical question-answering (QA) and clinical assistance. The MambaFormer employs a lightweight gating mechanism that performs token-level dynamic routing to a customized Transformer expert (ET5) for short, complex queries or to a State Space Model expert (EMamba) for long, high-throughput sequences. The customized EMamba and ET5 models are tailored to accommodate input sequence dimensionality, embedding structure, sequence length, and target-specific output heads, and are fine-tuned through transfer learning on a new, custom-designed DentalQA dataset. Moreover, intelligent routing decisions are driven by the contextual complexity of token embeddings, normalized sequence length, and domain-aware features, thereby enforcing a Pareto-optimal trade-off between inference latency and prediction accuracy. Furthermore, a novel utility-guided multi-objective loss jointly optimizes decisions, router parameters, routing behavior, expert utilization, and computational cost by adaptively regulating token-level expert activation. Finally, the proposed MambaFormer is cross-validated (holdout) for medical QA on the new, custom-designed DentalQA and PubMedQA datasets and compared with state-of-the-art techniques. The proposed MambaFormer outperforms (BERTScore = 0.9180) with ultra-low latency (0.077 s), delivering a 24.4 speedup over T5-Large and establishing a scalable solution for resource-constrained clinical deployment.

</details>


### [85] [LinMU: Multimodal Understanding Made Linear](https://arxiv.org/abs/2601.01322)
*Hongjie Wang,Niraj K. Jha*

Main category: cs.CV

Relevance: 85.0

TL;DR: LinMU是一种线性复杂度的视觉语言模型，通过M-MATE双分支模块（Flex-MA状态空间模型+Local-Swin局部注意力）替代自注意力，实现高效的多模态理解，在保持性能的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）受限于自注意力的二次复杂度，难以部署在边缘设备上，且处理高分辨率图像和长视频时计算成本过高。需要开发线性复杂度的VLM架构来解决这些部署和效率问题。

Method: 提出LinMU架构：1）用M-MATE双分支模块替代所有自注意力层（Flex-MA分支：双向状态空间模型捕获全局上下文；Local-Swin分支：Swin风格窗口注意力捕获局部相关性）；2）三阶段蒸馏框架：初始化分支权重、联合微调双分支、使用LoRA适配器微调剩余模块，同时回归冻结教师模型的隐藏状态和token级logits。

Result: 在MMMU、TextVQA、LongVideoBench、Video-MME等基准测试中，LinMU匹配教师模型性能，同时将首次token时间（TTFT）降低高达2.7倍，在分钟级视频上token吞吐量提升高达9.0倍。消融实验证实了各蒸馏阶段和M-MATE双分支的必要性。

Conclusion: 该框架证明无需二次注意力即可实现最先进的多模态推理，为处理高分辨率图像和长视频的长上下文VLM开辟了新途径。

Abstract: Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\times$ and improves token throughput by up to 9.0$\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.

</details>


### [86] [Unified Generation and Self-Verification for Vision-Language Models via Advantage Decoupled Preference Optimization](https://arxiv.org/abs/2601.01483)
*Xinyu Qiu,Heng Jia,Zhengwen Zeng,Shuheng Shen,Changhua Meng,Yi Yang,Linchao Zhu*

Main category: cs.CV

Relevance: 85.0

TL;DR: ADPO是一个统一的强化学习框架，在单个策略中联合学习答案生成和自我验证，通过偏好验证奖励和解耦优化机制，显著提升验证能力和推理效率。


<details>
  <summary>Details</summary>
Motivation: 传统并行测试时缩放方法需要分别训练生成和验证模型，导致高昂的训练和推理成本。需要一种统一的框架来同时优化生成和验证能力。

Method: 提出优势解耦偏好优化（ADPO）：1）偏好验证奖励：通过正负样本的平均验证分数作为决策阈值，当预测正确性与答案正确性一致时提供正反馈；2）解耦优化机制：为生成和验证分别计算优势，应用token掩码隔离梯度，结合掩码GRPO目标，保持生成质量的同时校准验证分数。

Result: 验证AUC提升高达+34.1%，推理时间降低-53.5%，在MathVista/MMMU上准确率分别提升+2.8%/+1.4%，ReasonSeg上提升+1.9 cIoU，AndroidControl/GUI Odyssey上步骤成功率提升+1.7%/+1.0%。

Conclusion: ADPO通过统一的强化学习框架有效解决了生成与验证的协同优化问题，在保持生成质量的同时显著提升了验证能力和推理效率。

Abstract: Parallel test-time scaling typically trains separate generation and verification models, incurring high training and inference costs. We propose Advantage Decoupled Preference Optimization (ADPO), a unified reinforcement learning framework that jointly learns answer generation and self-verification within a single policy. ADPO introduces two innovations: a preference verification reward improving verification capability and a decoupled optimization mechanism enabling synergistic optimization of generation and verification. Specifically, the preference verification reward computes mean verification scores from positive and negative samples as decision thresholds, providing positive feedback when prediction correctness aligns with answer correctness. Meanwhile, the advantage decoupled optimization computes separate advantages for generation and verification, applies token masks to isolate gradients, and combines masked GRPO objectives, preserving generation quality while calibrating verification scores. ADPO achieves up to +34.1% higher verification AUC and -53.5% lower inference time, with significant gains of +2.8%/+1.4% accuracy on MathVista/MMMU, +1.9 cIoU on ReasonSeg, and +1.7%/+1.0% step success rate on AndroidControl/GUI Odyssey.

</details>


### [87] [CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving](https://arxiv.org/abs/2601.01874)
*Shuhang Chen,Yunqiu Xu,Junjie Xie,Aojun Lu,Tao Feng,Zeying Huang,Ning Zhang,Yi Sun,Yi Yang,Hangjie Yuan*

Main category: cs.CV

Relevance: 85.0

TL;DR: CogFlow是一个受认知启发的三阶段框架，通过感知→内化→推理的层次流程，解决多模态大语言模型在视觉数学问题解决中的视觉感知瓶颈和视觉线索整合问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在视觉数学问题解决上仍有困难。虽然近期工作认识到视觉感知是瓶颈，但解决方案仅限于改进视觉输入的提取和解释，忽略了提取的视觉线索是否被忠实整合并正确用于后续推理这一关键问题。

Method: 提出CogFlow三阶段框架：1) 感知阶段：使用协同视觉奖励在参数和语义空间提升感知能力；2) 内化阶段：引入知识内化奖励模型，确保视觉线索忠实整合；3) 推理阶段：设计视觉门控策略优化算法，防止模型寻求看似连贯但视觉未扎根的推理链。还贡献了包含12万+高质量感知-推理对齐标注的MathCog数据集。

Result: 在常用视觉数学推理基准测试上的综合实验和分析验证了CogFlow的优越性。

Conclusion: CogFlow通过模拟人类推理的层次流程，全面增强感知、内化和推理阶段，有效解决了多模态大语言模型在视觉数学问题解决中的关键挑战。

Abstract: Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\Rightarrow$internalization$\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.

</details>


### [88] [AR-MOT: Autoregressive Multi-object Tracking](https://arxiv.org/abs/2601.01925)
*Lianjie Jia,Yuhan Wu,Binghao Ran,Yifan Wang,Lijun Wang,Huchuan Lu*

Main category: cs.CV

Relevance: 85.0

TL;DR: AR-MOT：将多目标跟踪（MOT）重新构建为LLM框架内的自回归序列生成任务，无需特定任务头，通过灵活序列构造输出结构化结果，提升跨任务和模态的扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有MOT方法架构僵化、任务特定，难以适应日益复杂的多模态和通用跟踪场景。固定输出头和定制化跟踪流程限制了跨任务扩展性和新跟踪公式的灵活性。

Method: 1) 将MOT构建为LLM框架内的自回归序列生成任务；2) 基于预训练检测器的对象分词器增强区域级视觉感知；3) 区域感知对齐模块缓解全局与区域特征不对齐；4) 时间记忆融合模块缓存历史对象标记支持长期跟踪。

Result: 在MOT17和DanceTrack数据集上验证了方法的可行性，性能达到SOTA水平，同时为更通用和灵活的MOT系统奠定了基础。

Conclusion: AR-MOT通过自回归序列生成范式实现了灵活、可扩展的MOT系统，无需修改模型架构即可集成新模态或指令，为通用跟踪系统提供了新方向。

Abstract: As multi-object tracking (MOT) tasks continue to evolve toward more general and multi-modal scenarios, the rigid and task-specific architectures of existing MOT methods increasingly hinder their applicability across diverse tasks and limit flexibility in adapting to new tracking formulations. Most approaches rely on fixed output heads and bespoke tracking pipelines, making them difficult to extend to more complex or instruction-driven tasks. To address these limitations, we propose AR-MOT, a novel autoregressive paradigm that formulates MOT as a sequence generation task within a large language model (LLM) framework. This design enables the model to output structured results through flexible sequence construction, without requiring any task-specific heads. To enhance region-level visual perception, we introduce an Object Tokenizer based on a pretrained detector. To mitigate the misalignment between global and regional features, we propose a Region-Aware Alignment (RAA) module, and to support long-term tracking, we design a Temporal Memory Fusion (TMF) module that caches historical object tokens. AR-MOT offers strong potential for extensibility, as new modalities or instructions can be integrated by simply modifying the output sequence format without altering the model architecture. Extensive experiments on MOT17 and DanceTrack validate the feasibility of our approach, achieving performance comparable to state-of-the-art methods while laying the foundation for more general and flexible MOT systems.

</details>


### [89] [AFTER: Mitigating the Object Hallucination of LVLM via Adaptive Factual-Guided Activation Editing](https://arxiv.org/abs/2601.01957)
*Tianbo Wang,Yuqing Ma,Kewei Liao,Zhange Zhang,Simin Li,Jinyang Guo,Xianglong Liu*

Main category: cs.CV

Relevance: 85.0

TL;DR: AFTER方法通过事实增强激活引导和查询自适应偏移优化，有效减少大型视觉语言模型中的物体幻觉问题，在AMBER基准上实现高达16.3%的幻觉减少。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在语言偏见导致的物体幻觉问题（类别、属性和关系幻觉），严重影响可信AI应用。现有编辑方法缺乏事实文本语义的有效指导，难以显式缓解语言偏见。

Method: 提出AFTER方法，包含两个核心组件：1) 事实增强激活引导(FAS)：提供事实性和通用指导，显式建模精确的视觉-文本关联；2) 查询自适应偏移优化(QAO)：引入查询感知偏移估计器，从通用引导向量建立查询特定的编辑，增强编辑的多样性和粒度。

Result: 在三个广泛采用的大型视觉语言模型上的标准幻觉基准测试验证了AFTER的有效性，在AMBER基准上实现了高达16.3%的幻觉减少。

Conclusion: AFTER方法通过自适应地将原始偏见激活引导至事实语义，有效缓解了大型视觉语言模型的物体幻觉问题，为可信AI应用提供了有前景的解决方案。

Abstract: Large Vision-Language Models (LVLMs) have achieved substantial progress in cross-modal tasks. However, due to language bias, LVLMs are susceptible to object hallucination, which can be primarily divided into category, attribute, and relation hallucination, significantly impeding the trustworthy AI applications. Editing the internal activations of LVLMs has shown promising effectiveness in mitigating hallucinations with minimal cost. However, previous editing approaches neglect the effective guidance offered by factual textual semantics, thereby struggling to explicitly mitigate language bias. To address these issues, we propose Adaptive Factual-guided Visual-Textual Editing for hallucination mitigation (AFTER), which comprises Factual-Augmented Activation Steering (FAS) and Query-Adaptive Offset Optimization (QAO), to adaptively guides the original biased activations towards factual semantics. Specifically, FAS is proposed to provide factual and general guidance for activation editing, thereby explicitly modeling the precise visual-textual associations. Subsequently, QAO introduces a query-aware offset estimator to establish query-specific editing from the general steering vector, enhancing the diversity and granularity of editing. Extensive experiments on standard hallucination benchmarks across three widely adopted LVLMs validate the efficacy of the proposed AFTER, notably achieving up to a 16.3% reduction of hallucination over baseline on the AMBER benchmark. Our code and data will be released for reproducibility.

</details>


### [90] [Thinking with Blueprints: Assisting Vision-Language Models in Spatial Reasoning via Structured Object Representation](https://arxiv.org/abs/2601.01984)
*Weijian Ma,Shizhao Sun,Tianyu Yu,Ruiyu Wang,Tat-Seng Chua,Jiang Bian*

Main category: cs.CV

Relevance: 85.0

TL;DR: 提出了一种将对象中心蓝图集成到视觉语言模型中的方法，通过结构化空间表示增强空间推理能力


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在空间推理方面存在局限：要么关注局部图像块（削弱全局空间意识），要么标记孤立坐标（忽略对象整体组织）。需要一种能够同时保持细粒度感知和全局空间理解的方法。

Method: 1. 构建JSON风格的对象中心蓝图，记录相关对象的位置、大小和属性；2. 蓝图嵌入推理轨迹进行监督微调；3. 蓝图感知奖励的强化学习，鼓励适当数量的对象和因果对齐；4. 抗捷径数据增强，防止依赖表面线索。

Result: 实验表明，该方法在空间推理任务上持续优于现有视觉语言模型和专门的空间推理模型。

Conclusion: 对象中心蓝图方法有效提升了视觉语言模型的空间推理能力，实现了从视觉感知向空间语义理解的进步。

Abstract: Spatial reasoning -- the ability to perceive and reason about relationships in space -- advances vision-language models (VLMs) from visual perception toward spatial semantic understanding. Existing approaches either revisit local image patches, improving fine-grained perception but weakening global spatial awareness, or mark isolated coordinates, which capture object locations but overlook their overall organization. In this work, we integrate the cognitive concept of an object-centric blueprint into VLMs to enhance spatial reasoning. Given an image and a question, the model first constructs a JSON-style blueprint that records the positions, sizes, and attributes of relevant objects, and then reasons over this structured representation to produce the final answer. To achieve this, we introduce three key techniques: (1) blueprint-embedded reasoning traces for supervised fine-tuning to elicit basic reasoning skills; (2) blueprint-aware rewards in reinforcement learning to encourage the blueprint to include an appropriate number of objects and to align final answers with this causal reasoning; and (3) anti-shortcut data augmentation that applies targeted perturbations to images and questions, discouraging reliance on superficial visual or linguistic cues. Experiments show that our method consistently outperforms existing VLMs and specialized spatial reasoning models.

</details>


### [91] [Towards Long-window Anchoring in Vision-Language Model Distillation](https://arxiv.org/abs/2512.21576)
*Haoyi Zhou,Shuo Li,Tianyu Chen,Qi Song,Chonghan Gao,Jianxin Li*

Main category: cs.CV

Relevance: 85.0

TL;DR: LAid：通过渐进距离加权注意力匹配和可学习RoPE响应增益调制，实现长程注意力机制蒸馏，将小模型的有效上下文窗口扩展3.2倍


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型具有强大的长上下文理解能力，但常用的小分支模型由于窗口大小有限，在语言-视觉对齐方面表现不佳。研究发现知识蒸馏可以提升学生模型能力，作为RoPE在窗口大小上的补充。

Method: 提出LAid方法，包含两个互补组件：1) 渐进距离加权注意力匹配，在训练过程中动态强调更长的位置差异；2) 可学习RoPE响应增益调制，选择性增强需要的位置敏感性。

Result: 在多个模型家族上的实验表明，LAid蒸馏模型相比基线小模型，有效上下文窗口扩展达3.2倍，同时在标准视觉语言基准测试上保持或提升性能。频谱分析显示LAid成功保留了传统方法无法传递的关键低频注意力组件。

Conclusion: 该工作不仅为构建更高效的长上下文视觉语言模型提供了实用技术，还提供了关于位置理解在蒸馏过程中如何出现和传递的理论见解。

Abstract: While large vision-language models (VLMs) demonstrate strong long-context understanding, their prevalent small branches fail on linguistics-photography alignment for a limited window size. We discover that knowledge distillation improves students' capability as a complement to Rotary Position Embeddings (RoPE) on window sizes (anchored from large models). Building on this insight, we propose LAid, which directly aims at the transfer of long-range attention mechanisms through two complementary components: (1) a progressive distance-weighted attention matching that dynamically emphasizes longer position differences during training, and (2) a learnable RoPE response gain modulation that selectively amplifies position sensitivity where needed. Extensive experiments across multiple model families demonstrate that LAid-distilled models achieve up to 3.2 times longer effective context windows compared to baseline small models, while maintaining or improving performance on standard VL benchmarks. Spectral analysis also suggests that LAid successfully preserves crucial low-frequency attention components that conventional methods fail to transfer. Our work not only provides practical techniques for building more efficient long-context VLMs but also offers theoretical insights into how positional understanding emerges and transfers during distillation.

</details>


### [92] [BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models](https://arxiv.org/abs/2601.02147)
*Sunny Gupta,Shounak Das,Amit Sethi*

Main category: cs.CV

Relevance: 85.0

TL;DR: 提出BiPrompt框架，通过双边提示优化同时减少视觉和文本模态中的虚假相关性，提升CLIP等视觉语言模型的零样本泛化能力和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言基础模型（如CLIP）虽然具有出色的零样本泛化能力，但容易受到跨模态虚假相关性的影响。现有的去偏方法通常只处理单一模态（视觉或文本），导致部分鲁棒性和在分布偏移下的不稳定适应

Method: 提出双边提示优化框架（BiPrompt）：1）视觉侧采用结构化注意力引导擦除，抑制背景激活并强制因果区域与虚假区域之间的正交预测一致性；2）文本侧引入平衡提示归一化，通过可学习的重新中心化机制将类别嵌入对齐到各向同性语义空间。这些模块共同最小化虚假线索与预测之间的条件互信息

Result: 在真实世界和合成偏置基准测试中，相比先前的测试时去偏方法，在平均准确率和最差组准确率方面都取得了持续改进

Conclusion: BiPrompt为可信赖和因果基础的视觉语言适应提供了一条轻量级但有效的路径，无需重新训练或领域监督

Abstract: Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.

</details>


### [93] [NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation](https://arxiv.org/abs/2601.02204)
*Huichao Zhang,Liao Qu,Yiheng Liu,Hang Chen,Yangyang Song,Yongsheng Dong,Shikun Sun,Xian Li,Xu Wang,Yi Jiang,Hu Ye,Bo Chen,Yiming Gao,Peng Liu,Akide Liu,Zhipeng Yang,Qili Deng,Linjie Xing,Jiyang Liu,Zhao Wang,Yang Zhou,Mingcong Liu,Yi Zhang,Qian He,Xiwei Hu,Zhongqi Qi,Jie Shao,Zhiye Fu,Shuai Wang,Fangmin Chen,Xuezhi Chai,Zhihua Wu,Yitong Wang,Zehuan Yuan,Daniel K. Du,Xinglong Wu*

Main category: cs.CV

Relevance: 85.0

TL;DR: NextFlow是一个统一的解码器自回归Transformer，在6万亿交错文本-图像离散token上训练，通过统一视觉表示和架构实现多模态理解与生成，采用文本的next-token预测和视觉的next-scale预测，显著加速图像生成速度。


<details>
  <summary>Details</summary>
Motivation: 动机在于解决传统多模态模型的局限性：文本是严格顺序的，而图像具有层次结构。传统的光栅扫描方法效率低下，需要更高效的视觉生成方法。同时希望统一架构实现多模态能力，避免专门化模型。

Method: 方法包括：1) 统一解码器自回归Transformer架构；2) 对文本使用next-token预测，对视觉使用next-scale预测；3) 多尺度生成的鲁棒训练方案；4) 用于强化学习的prefix-tuning策略；5) 在6万亿交错文本-图像token上训练。

Result: 实验结果：1) 在统一模型中达到最先进性能；2) 在视觉质量上与专门的扩散基线相媲美；3) 1024x1024图像生成仅需5秒，比同类AR模型快几个数量级；4) 解锁图像编辑、交错内容生成和视频生成能力。

Conclusion: 结论：NextFlow通过统一架构和创新的next-scale预测方法，实现了高效的多模态理解和生成，在速度和视觉质量上都表现出色，为统一多模态模型提供了有前景的方向。

Abstract: We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.

</details>


### [94] [Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion](https://arxiv.org/abs/2601.02211)
*Binglei Li,Mengping Yang,Zhiyu Tan,Junping Zhang,Hao Li*

Main category: cs.CV

Relevance: 85.0

TL;DR: 本文系统分析了基于MMDiT的多模态扩散Transformer模型，揭示了不同模块在图像生成中的作用机制，并提出了无需训练的策略来提升文本对齐、精确编辑和推理加速。


<details>
  <summary>Details</summary>
Motivation: 尽管基于MMDiT的模型（如FLUX和Qwen Image）在文本到图像生成方面取得了突破，但现有方法仅分析了特定组件（如位置编码和注意力层）的作用。对于不同模块及其与文本条件交互如何影响合成过程的全面理解仍然缺乏。

Method: 开发了系统化分析流程，通过移除、禁用和增强对应模块中的文本隐藏状态来全面研究每个模块的功能。基于分析结果，提出了无需训练的策略来改进文本对齐、精确编辑和加速推理。

Result: 分析发现：1）语义信息出现在早期模块，细节在后期模块渲染；2）移除特定模块通常比禁用文本条件破坏性小；3）在选择性模块增强文本条件可改善语义属性。实验表明，该方法在SD3.5上将T2I-Combench++从56.92%提升到63.00%，GenEval从66.42%提升到71.63%，且不牺牲合成质量。

Conclusion: 该研究推进了对MMDiT模型的理解，为文本到图像生成、图像编辑和推理加速提供了有价值的见解，并为未来改进开辟了新的可能性。

Abstract: Recent breakthroughs of transformer-based diffusion models, particularly with Multimodal Diffusion Transformers (MMDiT) driven models like FLUX and Qwen Image, have facilitated thrilling experiences in text-to-image generation and editing. To understand the internal mechanism of MMDiT-based models, existing methods tried to analyze the effect of specific components like positional encoding and attention layers. Yet, a comprehensive understanding of how different blocks and their interactions with textual conditions contribute to the synthesis process remains elusive. In this paper, we first develop a systematic pipeline to comprehensively investigate each block's functionality by removing, disabling and enhancing textual hidden-states at corresponding blocks. Our analysis reveals that 1) semantic information appears in earlier blocks and finer details are rendered in later blocks, 2) removing specific blocks is usually less disruptive than disabling text conditions, and 3) enhancing textual conditions in selective blocks improves semantic attributes. Building on these observations, we further propose novel training-free strategies for improved text alignment, precise editing, and acceleration. Extensive experiments demonstrated that our method outperforms various baselines and remains flexible across text-to-image generation, image editing, and inference acceleration. Our method improves T2I-Combench++ from 56.92% to 63.00% and GenEval from 66.42% to 71.63% on SD3.5, without sacrificing synthesis quality. These results advance understanding of MMDiT models and provide valuable insights to unlock new possibilities for further improvements.

</details>


### [95] [OpenRT: An Open-Source Red Teaming Framework for Multimodal LLMs](https://arxiv.org/abs/2601.01592)
*Xin Wang,Yunhao Chen,Juncheng Li,Yixu Wang,Yang Yao,Tianle Gu,Jie Li,Yan Teng,Xingjun Ma,Yingchun Wang,Xia Hu*

Main category: cs.CR

Relevance: 85.0

TL;DR: OpenRT是一个统一的、模块化的高通量红队测试框架，专门用于全面评估多模态大语言模型（MLLMs）的安全性。该框架通过引入对抗核心实现了五个关键维度的模块化分离，集成了37种攻击方法，并在20个先进模型上发现了显著的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在关键应用中的快速集成，其持续存在的安全漏洞问题日益突出。现有的红队测试基准往往碎片化，局限于单轮文本交互，且缺乏系统性评估所需的可扩展性。因此，需要开发一个统一、模块化且高通量的框架来全面评估MLLM的安全性。

Method: OpenRT框架通过引入对抗核心实现了五个关键维度的模块化分离：模型集成、数据集管理、攻击策略、判断方法和评估指标。通过标准化攻击接口，将对抗逻辑与高通量异步运行时解耦，实现了跨不同模型的系统性扩展。框架集成了37种不同的攻击方法，包括白盒梯度攻击、多模态扰动和复杂的多智能体进化策略。

Result: 在20个先进模型（包括GPT-5.2、Claude 4.5和Gemini 3 Pro）上的广泛实证研究揭示了关键的安全漏洞：即使是前沿模型也无法在所有攻击范式上泛化，领先模型的平均攻击成功率高达49.14%。研究发现，推理模型并不天生对复杂的多轮越狱攻击具有更强的鲁棒性。

Conclusion: OpenRT提供了一个可持续、可扩展且持续维护的基础设施，加速了AI安全性的发展和标准化。通过开源该框架，作者旨在促进更全面的MLLM安全性评估，并推动该领域的标准化进程。

Abstract: The rapid integration of Multimodal Large Language Models (MLLMs) into critical applications is increasingly hindered by persistent safety vulnerabilities. However, existing red-teaming benchmarks are often fragmented, limited to single-turn text interactions, and lack the scalability required for systematic evaluation. To address this, we introduce OpenRT, a unified, modular, and high-throughput red-teaming framework designed for comprehensive MLLM safety evaluation. At its core, OpenRT architects a paradigm shift in automated red-teaming by introducing an adversarial kernel that enables modular separation across five critical dimensions: model integration, dataset management, attack strategies, judging methods, and evaluation metrics. By standardizing attack interfaces, it decouples adversarial logic from a high-throughput asynchronous runtime, enabling systematic scaling across diverse models. Our framework integrates 37 diverse attack methodologies, spanning white-box gradients, multi-modal perturbations, and sophisticated multi-agent evolutionary strategies. Through an extensive empirical study on 20 advanced models (including GPT-5.2, Claude 4.5, and Gemini 3 Pro), we expose critical safety gaps: even frontier models fail to generalize across attack paradigms, with leading models exhibiting average Attack Success Rates as high as 49.14%. Notably, our findings reveal that reasoning models do not inherently possess superior robustness against complex, multi-turn jailbreaks. By open-sourcing OpenRT, we provide a sustainable, extensible, and continuously maintained infrastructure that accelerates the development and standardization of AI safety.

</details>


### [96] [DVGBench: Implicit-to-Explicit Visual Grounding Benchmark in UAV Imagery with Large Vision-Language Models](https://arxiv.org/abs/2601.00998)
*Yue Zhou,Jue Chen,Zilun Zhang,Penghui Huang,Ran Ding,Zhentao Zou,PengFei Gao,Yuchen Wei,Ke Li,Xue Yang,Xue Jiang,Hongxin Yang,Jonathan Li*

Main category: cs.CV

Relevance: 75.0

TL;DR: 本文提出了DVGBench，一个用于无人机的隐式视觉定位基准数据集，覆盖6大应用场景，并设计了DroneVG-R1模型，采用隐式到显式思维链强化学习范式来提升无人机视觉定位能力。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型在视觉定位任务中主要依赖显式参照表达（如相对位置、大小、颜色等），但在需要领域知识的隐式视觉定位任务上表现受限。无人机应用场景需要模型理解场景特定的隐式查询。

Method: 1) 构建DVGBench基准数据集，包含6大无人机应用场景（交通、灾害、安全、体育、社交活动、生产活动），每个对象提供显式和隐式查询；2) 设计DroneVG-R1模型，采用隐式到显式思维链（I2E-CoT）强化学习范式，将隐式参照转换为显式参照以降低定位难度。

Result: 主流模型在显式和隐式视觉定位任务上的评估揭示了它们在推理能力上的显著局限性。DroneVG-R1通过I2E-CoT强化学习范式能够利用场景特定专业知识，有效提升隐式视觉定位性能。

Conclusion: DVGBench基准和DroneVG-R1模型为提升无人机智能体的视觉语言模型推理能力提供了可行方案，揭示了当前模型在隐式视觉定位任务上的不足，并为未来研究提供了方向。

Abstract: Remote sensing (RS) large vision-language models (LVLMs) have shown strong promise across visual grounding (VG) tasks. However, existing RS VG datasets predominantly rely on explicit referring expressions-such as relative position, relative size, and color cues-thereby constraining performance on implicit VG tasks that require scenario-specific domain knowledge. This article introduces DVGBench, a high-quality implicit VG benchmark for drones, covering six major application scenarios: traffic, disaster, security, sport, social activity, and productive activity. Each object provides both explicit and implicit queries. Based on the dataset, we design DroneVG-R1, an LVLM that integrates the novel Implicit-to-Explicit Chain-of-Thought (I2E-CoT) within a reinforcement learning paradigm. This enables the model to take advantage of scene-specific expertise, converting implicit references into explicit ones and thus reducing grounding difficulty. Finally, an evaluation of mainstream models on both explicit and implicit VG tasks reveals substantial limitations in their reasoning capabilities. These findings provide actionable insights for advancing the reasoning capacity of LVLMs for drone-based agents. The code and datasets will be released at https://github.com/zytx121/DVGBench

</details>


### [97] [ITSELF: Attention Guided Fine-Grained Alignment for Vision-Language Retrieval](https://arxiv.org/abs/2601.01024)
*Tien-Huy Nguyen,Huu-Loc Tran,Thanh Duc Ngo*

Main category: cs.CV

Relevance: 75.0

TL;DR: ITSELF是一个基于注意力引导的隐式局部对齐框架，用于文本行人搜索任务，通过模型自身的注意力机制实现细粒度图像-文本对齐，无需额外监督。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在文本行人搜索任务中通过局部对齐方法容易陷入捷径学习和虚假相关性，导致对齐错误。同时，注入先验知识可能扭曲模态内部结构。研究发现编码器注意力从训练早期就能提供空间精确的证据。

Method: 提出ITSELF框架：1) GRAB模块将模型自身注意力转换为高显著性token的注意力库，并在该库上应用局部目标；2) MARS模块聚合多层注意力并进行多样性感知的top-k选择；3) ATS模块在训练过程中从粗到细调度保留预算，早期保留上下文，逐步聚焦判别性细节。

Result: 在三个广泛使用的文本行人搜索基准测试中实现了最先进的性能，并展现出强大的跨数据集泛化能力。

Conclusion: ITSELF通过注意力引导的隐式局部对齐，无需额外先验监督就能有效学习细粒度对应关系，解决了现有方法的局限性。

Abstract: Vision Language Models (VLMs) have rapidly advanced and show strong promise for text-based person search (TBPS), a task that requires capturing fine-grained relationships between images and text to distinguish individuals. Previous methods address these challenges through local alignment, yet they are often prone to shortcut learning and spurious correlations, yielding misalignment. Moreover, injecting prior knowledge can distort intra-modality structure. Motivated by our finding that encoder attention surfaces spatially precise evidence from the earliest training epochs, and to alleviate these issues, we introduceITSELF, an attention-guided framework for implicit local alignment. At its core, Guided Representation with Attentive Bank (GRAB) converts the model's own attention into an Attentive Bank of high-saliency tokens and applies local objectives on this bank, learning fine-grained correspondences without extra supervision. To make the selection reliable and non-redundant, we introduce Multi-Layer Attention for Robust Selection (MARS), which aggregates attention across layers and performs diversity-aware top-k selection; and Adaptive Token Scheduler (ATS), which schedules the retention budget from coarse to fine over training, preserving context early while progressively focusing on discriminative details. Extensive experiments on three widely used TBPS benchmarks showstate-of-the-art performance and strong cross-dataset generalization, confirming the effectiveness and robustness of our approach without additional prior supervision. Our project is publicly available at https://trhuuloc.github.io/itself

</details>


### [98] [Language as Prior, Vision as Calibration: Metric Scale Recovery for Monocular Depth Estimation](https://arxiv.org/abs/2601.01457)
*Mingxing Zhan,Li Zhang,Beibei Wang,Yingjie Wang,Zenglin Shi*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出一种利用语言引导的不确定性感知校准方法，将相对深度基础模型转换为度量深度，通过轻量级校准头实现，无需重新训练骨干网络。


<details>
  <summary>Details</summary>
Motivation: 相对深度基础模型迁移性能良好，但单目度量深度仍存在全局尺度不可识别和域偏移敏感的问题。现有方法要么需要重新训练整个模型，要么仅依赖文本提示进行点估计，忽略了语言描述的噪声和不确定性。

Method: 1) 使用冻结的相对深度骨干网络和CLIP文本编码器；2) 训练轻量级校准头，通过图像特定的仿射变换恢复度量深度；3) 利用语言预测不确定性感知的包络，界定可行的校准参数范围；4) 使用多尺度冻结视觉特征选择图像特定的校准参数；5) 训练时通过逆深度的闭式最小二乘oracle提供监督。

Result: 在NYUv2和KITTI数据集上提高了域内精度，在SUN-RGBD和DDAD上的零样本迁移展示了比纯语言基线更强的鲁棒性。

Conclusion: 通过语言引导的不确定性感知校准方法，能够有效将相对深度基础模型转换为度量深度，在保持骨干网络冻结的同时提高精度和鲁棒性。

Abstract: Relative-depth foundation models transfer well, yet monocular metric depth remains ill-posed due to unidentifiable global scale and heightened domain-shift sensitivity. Under a frozen-backbone calibration setting, we recover metric depth via an image-specific affine transform in inverse depth and train only lightweight calibration heads while keeping the relative-depth backbone and the CLIP text encoder fixed. Since captions provide coarse but noisy scale cues that vary with phrasing and missing objects, we use language to predict an uncertainty-aware envelope that bounds feasible calibration parameters in an unconstrained space, rather than committing to a text-only point estimate. We then use pooled multi-scale frozen visual features to select an image-specific calibration within this envelope. During training, a closed-form least-squares oracle in inverse depth provides per-image supervision for learning the envelope and the selected calibration. Experiments on NYUv2 and KITTI improve in-domain accuracy, while zero-shot transfer to SUN-RGBD and DDAD demonstrates improved robustness over strong language-only baselines.

</details>


### [99] [FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01513)
*Gen Li,Peiyu Liu*

Main category: cs.CV

Relevance: 75.0

TL;DR: VideoSpeculateRAG：一个高效的视觉语言模型检索增强生成框架，结合推测解码和实体对齐过滤，在保持准确性的同时将推理速度提升约2倍。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在视觉推理方面表现出色，但在整合外部知识方面仍有困难。现有的检索增强生成方法效率低下且难以保持高质量答案。需要一种既能高效利用外部知识又能保持准确性的解决方案。

Method: 提出VideoSpeculateRAG框架，包含两个核心技术：1) 推测解码管道 - 轻量级草稿模型快速生成多个候选答案，由更准确的重型模型验证和优化，显著降低推理延迟；2) 相似性过滤策略 - 针对检索知识中实体识别错误的问题，通过简单的相似性过滤提高实体对齐和答案准确性。

Result: 实验表明，VideoSpeculateRAG在保持与标准RAG方法相当或更高准确性的同时，将推理速度提升约2倍。框架展示了将推测解码与检索增强推理结合在复杂知识密集型多模态任务中的潜力。

Conclusion: VideoSpeculateRAG通过创新的推测解码和实体对齐技术，有效解决了VLM中检索增强生成的效率和准确性问题，为知识密集型多模态任务提供了高效可靠的解决方案。

Abstract: Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.

</details>


### [100] [DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving](https://arxiv.org/abs/2601.01528)
*Yang Zhou,Hao Shao,Letian Wang,Zhuofan Zong,Hongsheng Li,Steven L. Waslander*

Main category: cs.CV

Relevance: 75.0

TL;DR: DrivingGen是首个用于生成式驾驶世界模型的综合基准测试，通过多样化数据集和新颖评估指标来全面评估视觉真实性、轨迹合理性、时间一致性和可控性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要生成式世界模型来模拟未来场景，但现有评估方法存在严重不足：通用视频指标忽略安全关键因素、轨迹合理性缺乏量化、时间和智能体一致性被忽视、可控性被忽略，且数据集多样性不足。

Method: 构建DrivingGen基准测试，包括：1）从驾驶数据集和互联网视频源收集多样化评估数据集，涵盖不同天气、时间、地理区域和复杂操作；2）设计新的评估指标，联合评估视觉真实性、轨迹合理性、时间一致性和可控性。

Result: 对14个最先进模型的评估显示明显权衡：通用模型视觉效果更好但违反物理规律，而驾驶专用模型能真实捕捉运动但视觉质量较差。基准测试为可靠、可控、可部署的驾驶世界模型提供了统一评估框架。

Conclusion: DrivingGen填补了驾驶世界模型评估的空白，提供了全面的基准测试框架，能够促进可扩展的仿真、规划和数据驱动决策，推动可靠、可控、可部署的驾驶世界模型发展。

Abstract: Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.

</details>


### [101] [EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding](https://arxiv.org/abs/2601.01547)
*Tianjun Gu,Chenghua Gong,Jingyu Gong,Zhizhong Zhang,Yuan Xie,Lizhuang Ma,Xin Tan*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出了Teleo-Spatial Intelligence (TSI)新范式，结合物理动态推理和意图驱动推理，并创建了EscherVerse基准套件来评估AI在开放世界中的空间智能


<details>
  <summary>Details</summary>
Motivation: 当前空间推理研究忽视了人类意图在空间变化中的作用，需要从被动场景描述转向目的驱动的整体世界理解

Method: 提出TSI范式，包含物理动态推理和意图驱动推理两个支柱；创建EscherVerse基准套件，包括Escher-Bench基准、Escher-35k数据集和Escher系列模型；开发了新颖的数据整理流程

Result: 创建了首个系统评估意图驱动推理的基准，从真实世界视频中提取数据，评估物体恒存性、状态转换和轨迹预测能力

Conclusion: TSI范式将空间智能从被动描述提升到目的驱动的整体理解，为空间智能研究提供了基础资源

Abstract: The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.

</details>


### [102] [FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing](https://arxiv.org/abs/2601.01720)
*Xijie Huang,Chengming Xu,Donghao Luo,Xiaobin Hu,Peng Tang,Xu Peng,Jiangning Zhang,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出了FFP-300K大规模数据集和无需运行时引导的First-Frame Propagation视频编辑框架，通过AST-RoPE位置编码和自蒸馏策略实现高质量可控视频编辑


<details>
  <summary>Details</summary>
Motivation: 现有First-Frame Propagation方法依赖繁琐的运行时引导，根本原因在于训练数据集不足（视频短、分辨率低、任务多样性不够），无法学习鲁棒的时序先验

Method: 1) 构建FFP-300K大规模数据集（30万对720p、81帧视频）；2) 提出无需引导的FFP框架，包含Adaptive Spatio-Temporal RoPE动态重映射位置编码，以及自蒸馏策略（身份传播任务作为正则化器）

Result: 在EditVerseBench基准测试中显著优于现有学术和商业模型，PickScore提高约0.2，VLM分数提高约0.3

Conclusion: 通过大规模数据集和创新的架构设计，实现了高质量、无需运行时引导的可控视频编辑，解决了保持首帧外观与保留源视频运动之间的关键矛盾

Abstract: First-Frame Propagation (FFP) offers a promising paradigm for controllable video editing, but existing methods are hampered by a reliance on cumbersome run-time guidance. We identify the root cause of this limitation as the inadequacy of current training datasets, which are often too short, low-resolution, and lack the task diversity required to teach robust temporal priors. To address this foundational data gap, we first introduce FFP-300K, a new large-scale dataset comprising 300K high-fidelity video pairs at 720p resolution and 81 frames in length, constructed via a principled two-track pipeline for diverse local and global edits. Building on this dataset, we propose a novel framework designed for true guidance-free FFP that resolves the critical tension between maintaining first-frame appearance and preserving source video motion. Architecturally, we introduce Adaptive Spatio-Temporal RoPE (AST-RoPE), which dynamically remaps positional encodings to disentangle appearance and motion references. At the objective level, we employ a self-distillation strategy where an identity propagation task acts as a powerful regularizer, ensuring long-term temporal stability and preventing semantic drift. Comprehensive experiments on the EditVerseBench benchmark demonstrate that our method significantly outperforming existing academic and commercial models by receiving about 0.2 PickScore and 0.3 VLM score improvement against these competitors.

</details>


### [103] [Causality-Aware Temporal Projection for Video Understanding in Video-LLMs](https://arxiv.org/abs/2601.01804)
*Zhengjian Kang,Qi Chen,Rui Liu,Kangtong Mo,Xingyu Zhang,Xiaoyu Deng,Ye Zhang*

Main category: cs.CV

Relevance: 75.0

TL;DR: V-CORE：一个参数高效的视频大语言模型框架，通过可学习的空间聚合和因果感知时间投影器，引入显式的时间顺序约束，提升视频理解中的时序和因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在多模态推理方面表现良好，但在需要一致时间顺序和因果连贯性的视频理解任务上仍有挑战。许多参数高效的Video-LLMs使用无约束的双向投影器建模帧间交互，这会模糊时间顺序，因为允许后续帧影响先前表示，缺乏尊重视频推理方向性的显式架构机制。

Method: V-CORE包含两个关键组件：1) 可学习空间聚合(LSA)，自适应选择显著的空间token以减少冗余；2) 因果感知时间投影器(CATP)，通过块因果注意力和作为因果汇的终端动态摘要token，强制结构化单向信息流。该设计在保持帧内空间交互的同时，确保时间信息以严格有序的方式聚合。使用4位QLoRA和冻结的LLM主干，可在单个消费级GPU上高效训练。

Result: 在具有挑战性的NExT-QA基准测试中达到61.2%准确率，在MSVD-QA、MSRVTT-QA和TGIF-QA上保持竞争力。在时间和因果推理子类别上分别获得+3.5%和+5.2%的提升，直接验证了显式时间顺序约束的重要性。

Conclusion: V-CORE通过引入显式时间顺序约束，有效解决了视频理解中的时序和因果推理挑战，在保持参数效率的同时显著提升了性能，为视频大语言模型的设计提供了新思路。

Abstract: Recent Video Large Language Models (Video-LLMs) have shown strong multimodal reasoning capabilities, yet remain challenged by video understanding tasks that require consistent temporal ordering and causal coherence. Many parameter-efficient Video-LLMs rely on unconstrained bidirectional projectors to model inter-frame interactions, which can blur temporal ordering by allowing later frames to influence earlier representations, without explicit architectural mechanisms to respect the directional nature of video reasoning. To address this limitation, we propose V-CORE, a parameter-efficient framework that introduces explicit temporal ordering constraints for video understanding. V-CORE consists of two key components: (1) Learnable Spatial Aggregation (LSA), which adaptively selects salient spatial tokens to reduce redundancy, and (2) a Causality-Aware Temporal Projector (CATP), which enforces structured unidirectional information flow via block-causal attention and a terminal dynamic summary token acting as a causal sink. This design preserves intra-frame spatial interactions while ensuring that temporal information is aggregated in a strictly ordered manner. With 4-bit QLoRA and a frozen LLM backbone, V-CORE can be trained efficiently on a single consumer GPU. Experiments show that V-CORE achieves strong performance on the challenging NExT-QA benchmark, reaching 61.2% accuracy, and remains competitive across MSVD-QA, MSRVTT-QA, and TGIF-QA, with gains concentrated in temporal and causal reasoning subcategories (+3.5% and +5.2% respectively), directly validating the importance of explicit temporal ordering constraints.

</details>


### [104] [Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems](https://arxiv.org/abs/2601.01891)
*Niloufar Alipour Talemi,Julia Boone,Fatemeh Afghah*

Main category: cs.CV

Relevance: 75.0

TL;DR: 该论文首次全面综述了遥感领域的智能体AI，提出了单智能体副驾驶与多智能体系统的统一分类法，分析了规划机制、检索增强生成和记忆结构等架构基础，并介绍了从像素级精度转向轨迹感知推理正确性的新兴基准测试。


<details>
  <summary>Details</summary>
Motivation: 地球观测分析范式正在从静态深度学习模型转向自主智能体AI。尽管最近的视觉基础模型和多模态大语言模型在表示学习方面取得了进展，但它们通常缺乏复杂地理空间工作流所需的顺序规划和主动工具编排能力。因此需要系统性地综述遥感领域的智能体AI发展。

Method: 采用系统性综述方法，提出了统一的分类法来区分单智能体副驾驶和多智能体系统。深入分析了架构基础，包括规划机制、检索增强生成(RAG)和记忆结构。同时回顾了新兴的基准测试方法。

Result: 建立了遥感智能体AI的全面分类框架，识别了当前在基础、安全和编排方面的局限性，为开发稳健、自主的地理空间智能提供了战略路线图。

Conclusion: 智能体AI正在改变地球观测分析范式，但需要解决基础、安全和编排等关键挑战。该工作为构建更强大、自主的地理空间智能系统提供了系统性的指导框架。

Abstract: The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.

</details>


### [105] [FMVP: Masked Flow Matching for Adversarial Video Purification](https://arxiv.org/abs/2601.02228)
*Duoxun Tang,Xueyi Zhang,Chak Hin Wang,Xi Xiao,Dasen Dai,Xinhang Jiang,Wentao Shi,Rui Li,Qing Li*

Main category: cs.CV

Relevance: 75.0

TL;DR: FMVP提出了一种基于流匹配的视频对抗净化方法，通过掩码策略破坏对抗结构，使用条件流匹配重建干净视频，并设计频率门控损失分离语义内容和对抗噪声。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的净化方法存在采样效率低和轨迹弯曲的问题，直接回归干净视频难以恢复忠实内容，需要物理破坏对抗结构。

Method: 1) 使用掩码策略物理破坏全局对抗结构；2) 采用条件流匹配(CFM)和修复目标重建干净视频动态；3) 设计频率门控损失(FGL)抑制高频对抗残差同时保持低频保真度；4) 提出攻击感知和通用训练范式分别处理已知和未知威胁。

Result: 在UCF-101和HMDB-51数据集上，FMVP在PGD攻击下达到超过87%的鲁棒准确率，在CW攻击下达到89%，优于DiffPure、DP、TS和FlowPure等SOTA方法。对自适应攻击(DiffHammer)表现出优越鲁棒性，并可作为零样本对抗检测器，PGD检测准确率达98%，CW攻击检测准确率达79%。

Conclusion: FMVP通过物理破坏对抗结构和流匹配重建，有效解决了视频对抗净化问题，在鲁棒性和检测能力方面均表现出色。

Abstract: Video recognition models remain vulnerable to adversarial attacks, while existing diffusion-based purification methods suffer from inefficient sampling and curved trajectories. Directly regressing clean videos from adversarial inputs often fails to recover faithful content due to the subtle nature of perturbations; this necessitates physically shattering the adversarial structure. Therefore, we propose Flow Matching for Adversarial Video Purification FMVP. FMVP physically shatters global adversarial structures via a masking strategy and reconstructs clean video dynamics using Conditional Flow Matching (CFM) with an inpainting objective. To further decouple semantic content from adversarial noise, we design a Frequency-Gated Loss (FGL) that explicitly suppresses high-frequency adversarial residuals while preserving low-frequency fidelity. We design Attack-Aware and Generalist training paradigms to handle known and unknown threats, respectively. Extensive experiments on UCF-101 and HMDB-51 demonstrate that FMVP outperforms state-of-the-art methods (DiffPure, Defense Patterns (DP), Temporal Shuffling (TS) and FlowPure), achieving robust accuracy exceeding 87% against PGD and 89% against CW attacks. Furthermore, FMVP demonstrates superior robustness against adaptive attacks (DiffHammer) and functions as a zero-shot adversarial detector, attaining detection accuracies of 98% for PGD and 79% for highly imperceptible CW attacks.

</details>


### [106] [VIBE: Visual Instruction Based Editor](https://arxiv.org/abs/2601.02242)
*Grigorii Alekseenko,Aleksandr Gordeev,Irina Tolstykh,Bulat Suleimanov,Vladimir Dokholyan,Georgii Fedorov,Sergey Yakubson,Aleksandra Tsybina,Mikhail Chernyshov,Maksim Kuprashevich*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出一个紧凑高效的指令图像编辑管道，使用2B参数的Qwen3-VL模型指导编辑过程，结合1.6B参数的Sana1.5扩散模型进行图像生成，在保持高质量的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前指令图像编辑领域虽然发展迅速，但开源模型在真实世界质量方面有限，且主流的扩散模型通常包含6B-20B参数，计算成本高昂，限制了实际部署和研究应用。

Method: 采用轻量级架构设计：使用2B参数的Qwen3-VL模型解析编辑指令并指导编辑过程，配合1.6B参数的Sana1.5扩散模型进行图像生成。在架构、数据处理、训练配置和评估方面都针对低成本推理和严格源一致性进行优化。

Result: 在ImgEdit和GEdit基准测试中，该方法匹配或超越了参数规模大数倍、推理成本更高的基线模型。在需要保持输入图像的编辑任务（如属性调整、对象移除、背景编辑和定向替换）上表现尤为出色。模型仅需24GB GPU内存，在NVIDIA H100上以BF16精度生成2K分辨率图像约需4秒。

Conclusion: 证明了通过精心设计的轻量级架构，可以在显著降低计算成本的同时实现高质量的指令图像编辑，为实际部署和研究应用提供了可行的解决方案。

Abstract: Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.

</details>


### [107] [SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection](https://arxiv.org/abs/2601.02249)
*Xiantai Xiang,Guangyao Zhou,Zixiao Wen,Wenshuai Li,Ben Niu,Feng Wang,Lijia Huang,Qiantong Wang,Yuhan Liu,Zongxu Pan,Yuxin Hu*

Main category: cs.CV

Relevance: 75.0

TL;DR: SLGNet是一个参数高效的多模态目标检测框架，通过结构感知适配器和语言引导调制模块，在冻结的ViT基础模型上实现RGB和红外图像的鲁棒感知。


<details>
  <summary>Details</summary>
Motivation: 现有基于适配器的方法在将RGB预训练基础模型迁移到多模态目标检测时，往往牺牲了跨模态结构一致性，导致在域差距大的场景（如高对比度、夜间环境）中丢失关键结构线索。同时，传统的静态多模态融合机制缺乏环境感知能力，在复杂动态场景下性能受限。

Method: 提出SLGNet框架：1）结构感知适配器从两种模态提取层次化结构表示，并动态注入ViT以补偿结构退化；2）语言引导调制模块利用VLM驱动的结构化描述动态重新校准视觉特征，赋予模型环境感知能力。整个框架基于冻结的ViT基础模型，参数效率高。

Result: 在LLVIP、FLIR、KAIST和DroneVehicle数据集上达到最先进性能。在LLVIP基准上，mAP达到66.1，同时相比传统全微调减少约87%的可训练参数。

Conclusion: SLGNet为多模态感知提供了一个鲁棒且高效的解决方案，通过结合层次化结构先验和语言引导调制，在保持参数效率的同时显著提升了检测性能。

Abstract: Multimodal object detection leveraging RGB and Infrared (IR) images is pivotal for robust perception in all-weather scenarios. While recent adapter-based approaches efficiently transfer RGB-pretrained foundation models to this task, they often prioritize model efficiency at the expense of cross-modal structural consistency. Consequently, critical structural cues are frequently lost when significant domain gaps arise, such as in high-contrast or nighttime environments. Moreover, conventional static multimodal fusion mechanisms typically lack environmental awareness, resulting in suboptimal adaptation and constrained detection performance under complex, dynamic scene variations. To address these limitations, we propose SLGNet, a parameter-efficient framework that synergizes hierarchical structural priors and language-guided modulation within a frozen Vision Transformer (ViT)-based foundation model. Specifically, we design a Structure-Aware Adapter to extract hierarchical structural representations from both modalities and dynamically inject them into the ViT to compensate for structural degradation inherent in ViT-based backbones. Furthermore, we propose a Language-Guided Modulation module that exploits VLM-driven structured captions to dynamically recalibrate visual features, thereby endowing the model with robust environmental awareness. Extensive experiments on the LLVIP, FLIR, KAIST, and DroneVehicle datasets demonstrate that SLGNet establishes new state-of-the-art performance. Notably, on the LLVIP benchmark, our method achieves an mAP of 66.1, while reducing trainable parameters by approximately 87% compared to traditional full fine-tuning. This confirms SLGNet as a robust and efficient solution for multimodal perception.

</details>


### [108] [XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression](https://arxiv.org/abs/2601.01204)
*Zunhai Su,Weihao Ye,Hansen Feng,Keyu Fan,Jing Zhang,Dahai Yu,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

Relevance: 65.0

TL;DR: XStreamVGGT提出了一种无需调优的KV缓存压缩方法，通过联合剪枝和量化显著减少3D视觉几何模型在流式推理中的内存消耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的3D视觉几何模型（如StreamVGGT）使用帧级因果注意力进行流式重建，但随着输入帧的积累，KV缓存会无限增长，导致内存消耗和推理延迟急剧增加，限制了实际应用的可扩展性。

Method: 1. 通过高效的token重要性识别剪枝多视图输入产生的冗余KV，实现固定内存预算；2. 利用KV张量的独特分布特性，引入KV量化进一步减少内存消耗；3. 无需额外调优即可实现内存高效的流式推理。

Result: XStreamVGGT在性能损失几乎可忽略的情况下，将内存使用减少了4.42倍，推理速度提升了5.48倍，实现了可扩展且实用的流式3D应用。

Conclusion: 该方法通过系统性的KV缓存压缩，有效解决了Transformer-based 3D视觉模型在流式推理中的内存和延迟问题，为大规模流式3D应用提供了实用解决方案。

Abstract: Learning-based 3D visual geometry models have benefited substantially from large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention for strong streaming reconstruction, but suffers from unbounded KV cache growth, leading to escalating memory consumption and inference latency as input frames accumulate. We propose XStreamVGGT, a tuning-free approach that systematically compresses the KV cache through joint pruning and quantization, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs originating from multi-view inputs are pruned through efficient token importance identification, enabling a fixed memory budget. Leveraging the unique distribution of KV tensors, we incorporate KV quantization to further reduce memory consumption. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\times$ and accelerating inference by 5.48$\times$, enabling scalable and practical streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.

</details>


### [109] [S2M-Net: Spectral-Spatial Mixing for Medical Image Segmentation with Morphology-Aware Adaptive Loss](https://arxiv.org/abs/2601.01285)
*Md. Sanaullah Chowdhury Lameya Sabrin*

Main category: cs.CV

Relevance: 65.0

TL;DR: S2M-Net：一种用于医学图像分割的轻量级架构，通过谱选择令牌混合器和形态感知自适应分割损失，在局部精度、全局上下文和计算效率之间取得平衡


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临三难困境：需要局部精度用于边界关键临床应用、全局上下文用于解剖一致性、计算效率用于有限数据和硬件部署。现有架构（卷积网络和视觉Transformer）无法同时满足这些需求。

Method: 提出S2M-Net架构，包含两个核心创新：1) 谱选择令牌混合器(SSTM)，利用医学图像的谱集中特性，通过截断2D FFT和可学习频率滤波实现O(HW log HW)全局上下文；2) 形态感知自适应分割损失(MASL)，自动分析结构特征来调制五个互补损失分量，无需手动调参。

Result: 在16个医学成像数据集（8种模态）上评估，取得最先进性能：息肉分割96.12% Dice，手术器械83.77%（比先前方法提升17.85%），脑肿瘤80.90%。相比Transformer方法参数减少3.5-6倍，相比专用基线提升3-18%。

Conclusion: S2M-Net成功解决了医学图像分割的三难困境，通过谱方法和自适应损失实现了高效、精确的分割，为临床部署提供了实用解决方案。

Abstract: Medical image segmentation requires balancing local precision for boundary-critical clinical applications, global context for anatomical coherence, and computational efficiency for deployment on limited data and hardware a trilemma that existing architectures fail to resolve. Although convolutional networks provide local precision at $\mathcal{O}(n)$ cost but limited receptive fields, vision transformers achieve global context through $\mathcal{O}(n^2)$ self-attention at prohibitive computational expense, causing overfitting on small clinical datasets. We propose S2M-Net, a 4.7M-parameter architecture that achieves $\mathcal{O}(HW \log HW)$ global context through two synergistic innovations: (i) Spectral-Selective Token Mixer (SSTM), which exploits the spectral concentration of medical images via truncated 2D FFT with learnable frequency filtering and content-gated spatial projection, avoiding quadratic attention cost while maintaining global receptive fields; and (ii) Morphology-Aware Adaptive Segmentation Loss (MASL), which automatically analyzes structure characteristics (compactness, tubularity, irregularity, scale) to modulate five complementary loss components through constrained learnable weights, eliminating manual per-dataset tuning. Comprehensive evaluation in 16 medical imaging datasets that span 8 modalities demonstrates state-of-the-art performance: 96.12\% Dice on polyp segmentation, 83.77\% on surgical instruments (+17.85\% over the prior art) and 80.90\% on brain tumors, with consistent 3-18\% improvements over specialized baselines while using 3.5--6$\times$ fewer parameters than transformer-based methods.

</details>


### [110] [Guiding Token-Sparse Diffusion Models](https://arxiv.org/abs/2601.01608)
*Felix Krause,Stefan Andreas Baumann,Johannes Schusterbauer,Olga Grebenkova,Ming Gui,Vincent Tao Hu,Björn Ommer*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出了Sparse Guidance (SG)方法，通过在推理阶段利用token级稀疏性来改善稀疏训练扩散模型的性能，解决了CFG响应不足的问题，在减少计算量的同时提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 稀疏训练的扩散模型虽然降低了训练成本，但在推理时由于对Classifier-free Guidance (CFG)响应不足，导致生成质量下降。需要一种方法在保持计算效率的同时提升推理性能。

Method: 提出Sparse Guidance (SG)，不使用条件dropout作为引导信号，而是利用token级稀疏性。在推理阶段应用token级稀疏性，更好地保留条件预测的高方差，实现高质量和高方差输出。

Result: 在ImageNet-256基准测试上达到1.58 FID，减少25% FLOPs；在匹配基线质量下节省58% FLOPs。训练了25亿参数文本到图像扩散模型，在组合性和人类偏好评分上均有提升，同时提高吞吐量。

Conclusion: Sparse Guidance有效解决了稀疏训练扩散模型的推理性能问题，在保持计算效率的同时显著提升生成质量，为大规模扩散模型的高效训练和推理提供了实用解决方案。

Abstract: Diffusion models deliver high quality in image synthesis but remain expensive during training and inference. Recent works have leveraged the inherent redundancy in visual content to make training more affordable by training only on a subset of visual information. While these methods were successful in providing cheaper and more effective training, sparsely trained diffusion models struggle in inference. This is due to their lacking response to Classifier-free Guidance (CFG) leading to underwhelming performance during inference. To overcome this, we propose Sparse Guidance (SG). Instead of using conditional dropout as a signal to guide diffusion models, SG uses token-level sparsity. As a result, SG preserves the high-variance of the conditional prediction better, achieving good quality and high variance outputs. Leveraging token-level sparsity at inference, SG improves fidelity at lower compute, achieving 1.58 FID on the commonly used ImageNet-256 benchmark with 25% fewer FLOPs, and yields up to 58% FLOP savings at matched baseline quality. To demonstrate the effectiveness of Sparse Guidance, we train a 2.5B text-to-image diffusion model using training time sparsity and leverage SG during inference. SG achieves improvements in composition and human preference score while increasing throughput at the same time.

</details>


### [111] [Point-SRA: Self-Representation Alignment for 3D Representation Learning](https://arxiv.org/abs/2601.01746)
*Lintong Wei,Jian Lu,Haozhe Cheng,Jihua Zhu,Kaibing Zhang*

Main category: cs.CV

Relevance: 65.0

TL;DR: Point-SRA：一种通过自蒸馏和概率建模进行表示对齐的3D点云表示学习方法，改进了MAE在3D表示学习中的局限性


<details>
  <summary>Details</summary>
Motivation: 现有MAE方法使用固定掩码率，忽略了多级表示相关性和内在几何结构，且基于点对点重建假设与点云多样性相冲突

Method: 1) 为MAE分配不同掩码率以捕获互补几何语义信息；2) MeanFlow Transformer利用跨模态条件嵌入实现多样化概率重建；3) 在MAE和MFT级别提出双重自表示对齐机制；4) 设计流条件微调架构

Result: 在ScanObjectNN上比Point-MAE提升5.37%；颅内动脉瘤分割达到动脉96.07% mIoU和动脉瘤86.87% mIoU；3D目标检测达到47.3% AP@50，超越MaskPoint 5.12%

Conclusion: Point-SRA通过多级表示对齐和概率建模有效解决了传统MAE在3D表示学习中的局限性，在多个下游任务中取得显著性能提升

Abstract: Masked autoencoders (MAE) have become a dominant paradigm in 3D representation learning, setting new performance benchmarks across various downstream tasks. Existing methods with fixed mask ratio neglect multi-level representational correlations and intrinsic geometric structures, while relying on point-wise reconstruction assumptions that conflict with the diversity of point cloud. To address these issues, we propose a 3D representation learning method, termed Point-SRA, which aligns representations through self-distillation and probabilistic modeling. Specifically, we assign different masking ratios to the MAE to capture complementary geometric and semantic information, while the MeanFlow Transformer (MFT) leverages cross-modal conditional embeddings to enable diverse probabilistic reconstruction. Our analysis further reveals that representations at different time steps in MFT also exhibit complementarity. Therefore, a Dual Self-Representation Alignment mechanism is proposed at both the MAE and MFT levels. Finally, we design a Flow-Conditioned Fine-Tuning Architecture to fully exploit the point cloud distribution learned via MeanFlow. Point-SRA outperforms Point-MAE by 5.37% on ScanObjectNN. On intracranial aneurysm segmentation, it reaches 96.07% mean IoU for arteries and 86.87% for aneurysms. For 3D object detection, Point-SRA achieves 47.3% AP@50, surpassing MaskPoint by 5.12%.

</details>


### [112] [VerLM: Explaining Face Verification Using Natural Language](https://arxiv.org/abs/2601.01798)
*Syed Abdul Hannan,Hazim Bukhari,Thomas Cantalapiedra,Eman Ansar,Massa Baali,Rita Singh,Bhiksha Raj*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出一种用于人脸验证的视觉语言模型，不仅能准确判断两张人脸图像是否属于同一人，还能提供决策的明确解释。模型采用两种互补的解释风格：简洁总结和详细差异分析。


<details>
  <summary>Details</summary>
Motivation: 当前人脸验证系统虽然取得了显著进展，但普遍缺乏决策过程的透明度。研究人员希望开发一个既能准确验证又能解释决策依据的系统，提高人脸验证的可解释性和可靠性。

Method: 1) 采用创新的视觉语言模型架构，将先进的特征提取技术与推理能力相结合；2) 使用两种互补的解释风格进行训练：简洁总结关键因素和详细描述图像差异；3) 将原本为音频区分设计的先进建模方法进行跨模态迁移和适配，使其适用于视觉输入。

Result: 模型在性能上超越了基线方法和现有模型，同时显著提高了系统的可解释性。跨模态迁移策略有效提升了模型的准确性和可解释性。

Conclusion: 该研究展示了视觉语言模型在人脸验证领域的巨大潜力，为实现更透明、可靠和可解释的人脸验证系统做出了贡献。

Abstract: Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.

</details>


### [113] [TalkPhoto: A Versatile Training-Free Conversational Assistant for Intelligent Image Editing](https://arxiv.org/abs/2601.01915)
*Yujie Hu,Zecheng Tang,Xu Jiang,Weiqi Li,Jian Zhang*

Main category: cs.CV

Relevance: 65.0

TL;DR: TalkPhoto：一个无需训练的通用图像编辑框架，通过对话交互实现精确图像操作，利用LLM分析用户需求并分层调用现有高级编辑方法


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑方法虽然引入了MLLM来促进指令与图像之间的信息交换，但需要构建多指令数据集进行训练，不仅耗时耗力，而且效果不理想。需要一种更灵活、无需训练的方法来实现精确的图像编辑控制。

Method: 提出TalkPhoto框架：1）使用专门设计的提示模板指导开源LLM分析用户需求；2）分层调用现有高级编辑方法；3）实现即插即用和高效的编辑方法调用机制；4）无需额外训练即可处理复杂和未见过的编辑任务

Result: 实验表明：1）以更少的token消耗提供更准确的调用；2）在各种图像编辑任务中实现更高的编辑质量；3）能够稳定处理复杂和未见过的编辑任务

Conclusion: TalkPhoto框架通过对话交互实现了无需训练的精确图像编辑，克服了现有方法需要大量训练数据的限制，提供了更灵活、高效的图像编辑解决方案

Abstract: Thanks to the powerful language comprehension capabilities of Large Language Models (LLMs), existing instruction-based image editing methods have introduced Multimodal Large Language Models (MLLMs) to promote information exchange between instructions and images, ensuring the controllability and flexibility of image editing. However, these frameworks often build a multi-instruction dataset to train the model to handle multiple editing tasks, which is not only time-consuming and labor-intensive but also fails to achieve satisfactory results. In this paper, we present TalkPhoto, a versatile training-free image editing framework that facilitates precise image manipulation through conversational interaction. We instruct the open-source LLM with a specially designed prompt template to analyze user needs after receiving instructions and hierarchically invoke existing advanced editing methods, all without additional training. Moreover, we implement a plug-and-play and efficient invocation of image editing methods, allowing complex and unseen editing tasks to be integrated into the current framework, achieving stable and high-quality editing results. Extensive experiments demonstrate that our method not only provides more accurate invocation with fewer token consumption but also achieves higher editing quality across various image editing tasks.

</details>


### [114] [VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation](https://arxiv.org/abs/2601.02256)
*Shikun Sun,Liao Qu,Huichao Zhang,Yiheng Liu,Yangyang Song,Xian Li,Xu Wang,Yi Jiang,Daniel K. Du,Xinglong Wu,Jia Jia*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出增强GRPO框架，解决VAR模型中异步策略冲突问题，通过稳定中间奖励、动态时间步重加权和掩码传播算法，提升视觉生成质量和目标对齐


<details>
  <summary>Details</summary>
Motivation: VAR模型在生成步骤中存在异构输入结构，导致严重的异步策略冲突，特别是在强化学习场景中会造成训练不稳定和对齐效果不佳，需要专门解决这一问题

Method: 1) 稳定中间奖励引导早期生成；2) 动态时间步重加权方案进行精确信用分配；3) 基于Reward Feedback Learning的掩码传播算法，在空间和时间上隔离优化效果

Result: 相比原始GRPO基线，在样本质量和目标对齐方面有显著改进，实现了VAR模型的鲁棒有效优化

Conclusion: 提出的框架成功解决了VAR模型中的异步策略冲突问题，为视觉生成模型的强化学习优化提供了有效解决方案

Abstract: Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.

</details>


### [115] [Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes](https://arxiv.org/abs/2601.02356)
*Jing Tan,Zhaoyang Zhang,Yantao Shen,Jiarui Cai,Shuo Yang,Jiajun Wu,Wei Xia,Zhuowen Tu,Stefano Soatto*

Main category: cs.CV

Relevance: 65.0

TL;DR: Talk2Move是一个基于强化学习的扩散框架，用于通过文本指令实现场景中物体的空间变换，能够执行平移、旋转、缩放等几何变换，无需成对监督数据。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的编辑方法主要调整外观或风格，难以执行对象级别的几何变换（如平移、旋转、缩放），这主要受限于成对监督数据的稀缺和像素级优化的局限性。

Method: 采用强化学习扩散框架，使用Group Relative Policy Optimization (GRPO)通过输入图像和轻量级文本变体生成多样化的rollouts来探索几何动作；设计空间奖励引导模型对齐几何变换与语言描述；使用离策略步评估和主动步采样提高学习效率；设计面向对象的空间奖励直接评估位移、旋转和缩放行为。

Result: 在精心设计的基准测试中，Talk2Move实现了精确、一致且语义忠实的目标变换，在空间准确性和场景连贯性方面优于现有的文本引导编辑方法。

Conclusion: Talk2Move通过强化学习框架有效解决了文本指令下的物体空间变换问题，无需昂贵的成对数据，实现了可解释和连贯的几何变换。

Abstract: We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.

</details>


### [116] [VINO: A Unified Visual Generator with Interleaved OmniModal Context](https://arxiv.org/abs/2601.02358)
*Junyi Chen,Tong He,Zhoujie Fu,Pengfei Wan,Kun Gai,Weicai Ye*

Main category: cs.CV

Relevance: 65.0

TL;DR: VINO是一个统一的视觉生成器，在单个框架内执行图像和视频的生成与编辑，使用共享的扩散主干和多模态条件处理，避免了特定模态的架构组件。


<details>
  <summary>Details</summary>
Motivation: 当前视觉生成系统通常针对特定任务（如图像生成、视频生成、编辑）使用独立的模型或模块，缺乏统一的框架。这限制了跨模态的协同作用和通用视觉创建能力。VINO旨在构建一个统一的视觉生成系统，能够处理多种视觉任务，支持多参考接地、长指令跟随和跨静态动态内容的一致性保持。

Method: VINO将视觉语言模型（VLM）与多模态扩散Transformer（MMDiT）耦合。多模态输入被编码为交错的条件标记，用于指导扩散过程。采用多阶段训练流程：首先训练视频生成基础模型，然后逐步扩展为能够处理图像和视频输入输出的统一多任务生成器。

Result: 在多样化的生成和编辑基准测试中，VINO展示了强大的视觉质量、准确的指令跟随、改进的参考和属性保持能力，以及更可控的多身份编辑。结果突出了可扩展统一视觉生成的实用路径。

Conclusion: 交错上下文计算作为通用视觉创建的基础具有前景，VINO为可扩展的统一视觉生成提供了一条实用路径，展示了单一模型处理多种视觉任务的可行性。

Abstract: We present VINO, a unified visual generator that performs image and video generation and editing within a single framework. Instead of relying on task-specific models or independent modules for each modality, VINO uses a shared diffusion backbone that conditions on text, images and videos, enabling a broad range of visual creation and editing tasks under one model. Specifically, VINO couples a vision-language model (VLM) with a Multimodal Diffusion Transformer (MMDiT), where multimodal inputs are encoded as interleaved conditioning tokens, and then used to guide the diffusion process. This design supports multi-reference grounding, long-form instruction following, and coherent identity preservation across static and dynamic content, while avoiding modality-specific architectural components. To train such a unified system, we introduce a multi-stage training pipeline that progressively expands a video generation base model into a unified, multi-task generator capable of both image and video input and output. Across diverse generation and editing benchmarks, VINO demonstrates strong visual quality, faithful instruction following, improved reference and attribute preservation, and more controllable multi-identity edits. Our results highlight a practical path toward scalable unified visual generation, and the promise of interleaved, in-context computation as a foundation for general-purpose visual creation.

</details>


### [117] [AirSpatialBot: A Spatially-Aware Aerial Agent for Fine-Grained Vehicle Attribute Recognization and Retrieval](https://arxiv.org/abs/2601.01416)
*Yue Zhou,Ran Ding,Xue Yang,Xue Jiang,Xingzhao Liu*

Main category: cs.CV

Relevance: 45.0

TL;DR: 本文提出了AirSpatial，一个针对无人机车辆图像的遥感视觉语言模型，包含超过20.6万条指令和两个新任务：空间定位和空间问答。采用两阶段训练策略，并开发了能够进行细粒度车辆属性识别和检索的空中代理AirSpatialBot。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型在空间理解方面存在不足，限制了其在真实世界应用中的有效性。特别是针对无人机捕获的车辆图像，需要提升模型的空间感知能力。

Method: 1) 创建AirSpatial数据集，包含206K+指令，引入空间定位和空间问答两个新任务，首次提供3DBB标注；2) 采用两阶段训练策略：图像理解预训练和空间理解微调；3) 开发AirSpatialBot代理，动态集成任务规划、图像理解、空间理解和任务执行能力。

Result: 实验验证了方法的有效性，揭示了现有VLMs的空间局限性，同时提供了有价值的见解。模型能够进行细粒度车辆属性识别和检索，适应多样化的查询需求。

Conclusion: 该研究推动了遥感视觉语言模型在空间理解方面的发展，通过创新的数据集和训练策略，提升了模型对无人机车辆图像的空间感知能力，为实际应用提供了更有效的解决方案。

Abstract: Despite notable advancements in remote sensing vision-language models (VLMs), existing models often struggle with spatial understanding, limiting their effectiveness in real-world applications. To push the boundaries of VLMs in remote sensing, we specifically address vehicle imagery captured by drones and introduce a spatially-aware dataset AirSpatial, which comprises over 206K instructions and introduces two novel tasks: Spatial Grounding and Spatial Question Answering. It is also the first remote sensing grounding dataset to provide 3DBB. To effectively leverage existing image understanding of VLMs to spatial domains, we adopt a two-stage training strategy comprising Image Understanding Pre-training and Spatial Understanding Fine-tuning. Utilizing this trained spatially-aware VLM, we develop an aerial agent, AirSpatialBot, which is capable of fine-grained vehicle attribute recognition and retrieval. By dynamically integrating task planning, image understanding, spatial understanding, and task execution capabilities, AirSpatialBot adapts to diverse query requirements. Experimental results validate the effectiveness of our approach, revealing the spatial limitations of existing VLMs while providing valuable insights. The model, code, and datasets will be released at https://github.com/VisionXLab/AirSpatialBot

</details>


### [118] [Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration](https://arxiv.org/abs/2601.01456)
*Wentao Bian,Fenglei Xu*

Main category: cs.CV

Relevance: 45.0

TL;DR: DA-FSS提出了一种解耦专家仲裁的少样本3D点云语义分割方法，通过并行专家细化模块分离几何和语义路径，使用堆叠仲裁模块进行模态融合，解决"可塑性-稳定性困境"和CLIP的类间混淆问题。


<details>
  <summary>Details</summary>
Motivation: 本文针对多模态少样本3D点云语义分割中的"Fuse-then-Refine"范式冲突，识别出"可塑性-稳定性困境"，同时CLIP的类间混淆会导致语义盲区，需要新的架构来解决这些问题。

Method: 提出DA-FSS模型，包含并行专家细化模块生成各模态相关性，堆叠仲裁模块进行卷积融合和模态路径仲裁。几何专家保持可塑性，语义专家确保稳定性，通过解耦对齐模块进行知识转移而不传播混淆。

Result: 在S3DIS和ScanNet数据集上的实验表明，DA-FSS优于MM-FSS基线，在几何边界、完整性和纹理区分方面都有显著提升。

Conclusion: DA-FSS通过解耦几何和语义路径并协调其梯度，有效解决了多模态少样本分割中的可塑性-稳定性困境和语义混淆问题，实现了更好的泛化性能。

Abstract: In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in "Fuse-then-Refine" paradigms: the "Plasticity-Stability Dilemma." In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.

</details>


### [119] [Improving Flexible Image Tokenizers for Autoregressive Image Generation](https://arxiv.org/abs/2601.01535)
*Zixuan Fu,Lanqing Guo,Chong Wang,Binbin Song,Ding Liu,Bihan Wen*

Main category: cs.CV

Relevance: 45.0

TL;DR: ReToK提出了一种灵活的视觉分词器，通过冗余令牌填充和分层语义正则化，解决了传统灵活分词器中信息过度集中在早期令牌的问题，提升了自回归图像生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有灵活图像分词器通过嵌套dropout实现可变长度令牌序列，但尾部截断策略导致图像信息过度集中在早期令牌中，限制了自回归图像生成的效果，特别是当令牌长度增加时。

Method: 1. 冗余令牌填充：更频繁地激活尾部令牌，缓解信息过度集中在早期令牌的问题；2. 分层语义正则化：将早期令牌的解码特征与预训练视觉基础模型对齐，同时向尾部逐渐减少正则化强度，允许更精细的低级细节重建。

Result: 在ImageNet 256×256上，ReToK在生成性能上优于固定长度和灵活分词器，证明了方法的有效性。

Conclusion: ReToK通过冗余令牌填充和分层语义正则化，有效解决了灵活分词器中信息分布不均的问题，提升了自回归图像生成的质量。

Abstract: Flexible image tokenizers aim to represent an image using an ordered 1D variable-length token sequence. This flexible tokenization is typically achieved through nested dropout, where a portion of trailing tokens is randomly truncated during training, and the image is reconstructed using the remaining preceding sequence. However, this tail-truncation strategy inherently concentrates the image information in the early tokens, limiting the effectiveness of downstream AutoRegressive (AR) image generation as the token length increases. To overcome these limitations, we propose \textbf{ReToK}, a flexible tokenizer with \underline{Re}dundant \underline{Tok}en Padding and Hierarchical Semantic Regularization, designed to fully exploit all tokens for enhanced latent modeling. Specifically, we introduce \textbf{Redundant Token Padding} to activate tail tokens more frequently, thereby alleviating information over-concentration in the early tokens. In addition, we apply \textbf{Hierarchical Semantic Regularization} to align the decoding features of earlier tokens with those from a pre-trained vision foundation model, while progressively reducing the regularization strength toward the tail to allow finer low-level detail reconstruction. Extensive experiments demonstrate the effectiveness of ReTok: on ImageNet 256$\times$256, our method achieves superior generation performance compared with both flexible and fixed-length tokenizers. Code will be available at: \href{https://github.com/zfu006/ReTok}{https://github.com/zfu006/ReTok}

</details>


### [120] [Beyond Patches: Global-aware Autoregressive Model for Multimodal Few-Shot Font Generation](https://arxiv.org/abs/2601.01593)
*Haonan Cai,Yuxuan Luo,Zhouhui Lian*

Main category: cs.CV

Relevance: 45.0

TL;DR: GAR-Font：一种用于少样本字体生成的新型自回归框架，通过全局感知分词器、多模态风格编码器和后处理细化流程，在保持结构完整性和风格保真度方面优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统少样本字体生成方法存在两个主要问题：1）自回归模型使用补丁级分词，忽略了字体合成所需的全局依赖关系；2）现有方法局限于图像到图像范式，忽视了语言在传达字体设计风格意图中的作用

Method: 提出GAR-Font框架，包含三个核心组件：1）全局感知分词器，同时捕捉局部结构和全局风格模式；2）多模态风格编码器，通过轻量级语言风格适配器实现灵活风格控制；3）后处理细化流程，增强结构保真度和风格一致性

Result: GAR-Font在少样本字体生成任务上优于现有方法，在保持全局风格忠实度和通过文本风格指导获得更高质量结果方面表现突出

Conclusion: 该研究通过引入全局感知分词和多模态风格控制，显著提升了少样本字体生成的性能，证明了语言指导在字体设计中的重要性

Abstract: Manual font design is an intricate process that transforms a stylistic visual concept into a coherent glyph set. This challenge persists in automated Few-shot Font Generation (FFG), where models often struggle to preserve both the structural integrity and stylistic fidelity from limited references. While autoregressive (AR) models have demonstrated impressive generative capabilities, their application to FFG is constrained by conventional patch-level tokenization, which neglects global dependencies crucial for coherent font synthesis. Moreover, existing FFG methods remain within the image-to-image paradigm, relying solely on visual references and overlooking the role of language in conveying stylistic intent during font design. To address these limitations, we propose GAR-Font, a novel AR framework for multimodal few-shot font generation. GAR-Font introduces a global-aware tokenizer that effectively captures both local structures and global stylistic patterns, a multimodal style encoder offering flexible style control through a lightweight language-style adapter without requiring intensive multimodal pretraining, and a post-refinement pipeline that further enhances structural fidelity and style coherence. Extensive experiments show that GAR-Font outperforms existing FFG methods, excelling in maintaining global style faithfulness and achieving higher-quality results with textual stylistic guidance.

</details>


### [121] [Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery](https://arxiv.org/abs/2601.01781)
*Lakshay Sharma,Alex Marin*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出Subimage Overlap Prediction自监督预训练方法，用于遥感图像语义分割，显著减少预训练数据需求，加速收敛并提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法依赖大量预训练数据，而遥感图像标注成本高、数据获取困难。需要开发能在少量预训练数据下有效工作的自监督方法。

Method: 提出子图像重叠预测任务：从原始图像提取子图像，训练模型预测该子图像在原始图像中的位置语义掩码。这是一种针对分割任务设计的自监督预训练方法。

Result: 方法在多个架构和下游数据集上验证：1) 显著加速收敛；2) 达到相等或更好的mIoU性能；3) 在标注数据减少时优势更明显；4) 相比其他SSL方法，用更少预训练数据达到或超越性能。

Conclusion: Subimage Overlap Prediction是一种有效的自监督预训练方法，特别适合遥感图像分割任务，能显著减少数据需求并提升训练效率。

Abstract: Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.

</details>


### [122] [Forget Less by Learning from Parents Through Hierarchical Relationships](https://arxiv.org/abs/2601.01892)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出FLLP框架，在双曲空间中引入父子概念学习机制，通过将概念嵌入到Lorentz流形中来缓解定制扩散模型中的灾难性遗忘问题，同时促进概念间的正向交互。


<details>
  <summary>Details</summary>
Motivation: 定制扩散模型在顺序学习新概念时容易遭受灾难性遗忘，现有方法主要关注最小化概念间干扰，但忽略了概念间正向交互的潜力。

Method: FLLP框架在双曲空间中引入父子概念学习机制，将概念表示嵌入到Lorentz流形中，利用其天然的树状层次建模能力，定义父子关系，使已学概念作为新概念学习的指导。

Result: 在三个公共数据集和一个合成基准上验证，在鲁棒性和泛化性方面均显示出持续改进。

Conclusion: FLLP不仅保护了先验知识，还支持新概念的持续整合，通过双曲空间中的父子学习机制有效缓解了定制扩散模型中的灾难性遗忘问题。

Abstract: Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.

</details>


### [123] [MotionAdapter: Video Motion Transfer via Content-Aware Attention Customization](https://arxiv.org/abs/2601.01955)
*Zhexin Zhang,Yifeng Zhu,Yangyang Xu,Long Chen,Yong Du,Shengfeng He,Jun Yu*

Main category: cs.CV

Relevance: 45.0

TL;DR: MotionAdapter：基于扩散Transformer的视频生成模型的内容感知运动迁移框架，通过解耦运动与外观、自适应定制运动来实现鲁棒且语义对齐的运动迁移


<details>
  <summary>Details</summary>
Motivation: 尽管基于扩散Transformer的文本到视频模型在生成高质量时序一致视频方面取得显著进展，但在视频间迁移复杂运动仍然具有挑战性。现有方法难以实现鲁棒且语义对齐的运动迁移。

Method: 1) 通过分析3D全注意力模块中的跨帧注意力来提取注意力驱动的运动场，实现运动与外观的显式解耦；2) 引入DINO引导的运动定制模块，基于内容对应关系重新排列和精炼运动场；3) 使用定制化运动场指导DiT去噪过程，确保合成视频继承参考运动同时保持目标外观和语义。

Result: 大量实验表明，MotionAdapter在定性和定量评估中均优于最先进方法。该框架自然支持复杂运动迁移和运动编辑任务（如缩放）。

Conclusion: MotionAdapter为基于DiT的文本到视频模型提供了一个有效的内容感知运动迁移框架，通过显式运动解耦和自适应运动定制，实现了鲁棒且语义对齐的运动迁移，扩展了视频生成模型的功能。

Abstract: Recent advances in diffusion-based text-to-video models, particularly those built on the diffusion transformer architecture, have achieved remarkable progress in generating high-quality and temporally coherent videos. However, transferring complex motions between videos remains challenging. In this work, we present MotionAdapter, a content-aware motion transfer framework that enables robust and semantically aligned motion transfer within DiT-based T2V models. Our key insight is that effective motion transfer requires \romannumeral1) explicit disentanglement of motion from appearance and \romannumeral 2) adaptive customization of motion to target content. MotionAdapter first isolates motion by analyzing cross-frame attention within 3D full-attention modules to extract attention-derived motion fields. To bridge the semantic gap between reference and target videos, we further introduce a DINO-guided motion customization module that rearranges and refines motion fields based on content correspondences. The customized motion field is then used to guide the DiT denoising process, ensuring that the synthesized video inherits the reference motion while preserving target appearance and semantics. Extensive experiments demonstrate that MotionAdapter outperforms state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, MotionAdapter naturally supports complex motion transfer and motion editing tasks such as zooming.

</details>


### [124] [Forget Less by Learning Together through Concept Consolidation](https://arxiv.org/abs/2601.01963)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini Ratha,Venu Govindaraju*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出FL2T框架，解决定制扩散模型在连续学习新概念时的灾难性遗忘问题，通过跨概念交互学习实现并发、顺序无关的概念学习


<details>
  <summary>Details</summary>
Motivation: 现有定制扩散模型在连续学习新概念时存在灾难性遗忘问题，且先前工作多在顺序学习设定下进行，忽略了概念间的交互作用

Method: 提出FL2T框架，包含集合不变性的跨概念学习模块，使用代理指导跨概念的特征选择，促进知识保留和迁移

Result: 在三个数据集上的实验表明，该方法显著提高概念保留能力，减轻灾难性遗忘，在十个任务的增量概念学习中平均CLIP图像对齐分数至少提升2%

Conclusion: 跨概念催化行为在增量概念学习中具有有效性，FL2T框架能够同时学习多个概念且顺序无关，有效解决灾难性遗忘问题

Abstract: Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.

</details>


### [125] [Towards Any-Quality Image Segmentation via Generative and Adaptive Latent Space Enhancement](https://arxiv.org/abs/2601.02018)
*Guangqian Guo,Aixi Ren,Yong Guo,Xuehui Yu,Jiacheng Tian,Wenli Li,Yaoxing Wang,Shan Gao*

Main category: cs.CV

Relevance: 45.0

TL;DR: GleSAM++通过生成式潜在空间增强提升SAM在低质量图像上的分割鲁棒性，引入特征分布对齐、通道复制扩展和退化感知自适应增强机制，在保持清晰图像性能的同时显著改善复杂退化条件下的分割效果。


<details>
  <summary>Details</summary>
Motivation: SAM在零样本分割方面表现出色，但在严重退化、低质量图像上性能显著下降，限制了其在真实场景中的应用。需要提升SAM在低质量图像上的鲁棒性，同时保持对清晰图像的泛化能力。

Method: 1) 使用生成式潜在空间增强提升低质量图像鲁棒性；2) 引入特征分布对齐(FDA)和通道复制扩展(CRE)改善预训练扩散模型与分割框架的兼容性；3) 提出退化感知自适应增强(DAE)机制，将重建过程解耦为退化程度预测和退化感知重建两个阶段。

Result: GleSAM++在复杂退化条件下显著提升分割鲁棒性，同时保持对清晰图像的泛化能力。在未见过的退化类型上也表现良好，证明了方法的通用性。仅需少量可学习参数即可应用于预训练的SAM和SAM2。

Conclusion: GleSAM++通过生成式潜在空间增强和退化感知机制，有效解决了SAM在低质量图像上的性能下降问题，为SAM在真实世界场景中的应用提供了鲁棒性增强方案。

Abstract: Segment Anything Models (SAMs), known for their exceptional zero-shot segmentation performance, have garnered significant attention in the research community. Nevertheless, their performance drops significantly on severely degraded, low-quality images, limiting their effectiveness in real-world scenarios. To address this, we propose GleSAM++, which utilizes Generative Latent space Enhancement to boost robustness on low-quality images, thus enabling generalization across various image qualities. Additionally, to improve compatibility between the pre-trained diffusion model and the segmentation framework, we introduce two techniques, i.e., Feature Distribution Alignment (FDA) and Channel Replication and Expansion (CRE). However, the above components lack explicit guidance regarding the degree of degradation. The model is forced to implicitly fit a complex noise distribution that spans conditions from mild noise to severe artifacts, which substantially increases the learning burden and leads to suboptimal reconstructions. To address this issue, we further introduce a Degradation-aware Adaptive Enhancement (DAE) mechanism. The key principle of DAE is to decouple the reconstruction process for arbitrary-quality features into two stages: degradation-level prediction and degradation-aware reconstruction. Our method can be applied to pre-trained SAM and SAM2 with only minimal additional learnable parameters, allowing for efficient optimization. Extensive experiments demonstrate that GleSAM++ significantly improves segmentation robustness on complex degradations while maintaining generalization to clear images. Furthermore, GleSAM++ also performs well on unseen degradations, underscoring the versatility of our approach and dataset.

</details>


### [126] [Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models](https://arxiv.org/abs/2601.02198)
*Alexander Möllers,Julius Hense,Florian Schulz,Timo Milbich,Maximilian Alber,Lukas Ruff*

Main category: cs.CV

Relevance: 45.0

TL;DR: 该论文研究病理学基础模型中的放大倍数采样策略，提出连续采样方法优于离散采样，并开发优化采样分布的理论框架，显著提升中间放大倍数的性能。


<details>
  <summary>Details</summary>
Motivation: 病理学家在诊断时需要同时观察低倍镜下的组织结构和放大倍率下的精细形态，但现有病理学基础模型在不同放大倍数下的性能差异以及训练时的放大倍数采样策略影响尚不清楚。

Method: 将放大倍数采样建模为多源域适应问题，开发理论框架分析采样策略的系统性权衡。提出连续放大倍数采样方法，消除放大倍数覆盖间隙。推导优化跨放大倍数表示质量的采样分布。引入两个新基准(TCGA-MS, BRACS-MS)进行评估。

Result: 连续采样在中间放大倍数上显著优于离散采样，平衡分类准确率提升高达4个百分点。优化分布能进一步改善性能。评估发现放大倍数是当前病理学基础模型性能变化的主要驱动因素。

Conclusion: 连续放大倍数采样和优化采样分布能显著提升病理学基础模型在不同放大倍数下的性能，为开发可靠跨放大倍数的未来病理学基础模型铺平道路。

Abstract: In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.

</details>


### [127] [A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets](https://arxiv.org/abs/2601.02246)
*Annoor Sharara Akhand*

Main category: cs.CV

Relevance: 45.0

TL;DR: 该研究系统比较了三种CNN范式：从头训练小型CNN、使用预训练CNN作为固定特征提取器、以及迁移学习（部分或全部微调）。在五个真实世界图像分类数据集上的实验表明，迁移学习性能最佳，而自定义CNN在计算和内存受限时提供较好的效率-精度平衡。


<details>
  <summary>Details</summary>
Motivation: 在实际视觉识别应用中，开发者面临三种主要CNN使用范式的选择：从头训练小型定制CNN、使用大型预训练CNN作为固定特征提取器、或进行迁移学习微调。然而，缺乏对这些范式在真实世界场景下的系统比较，特别是在不同应用领域和效率指标方面的评估。

Method: 研究设计了受控实验，在五个真实世界图像分类数据集上比较三种范式：1）从头训练紧凑自定义CNN；2）使用大型预训练CNN作为固定特征提取器；3）通过部分或全部微调进行迁移学习。评估指标包括准确率和宏F1分数，以及训练时间/epoch和参数量等效率指标。

Result: 迁移学习在所有数据集上始终获得最强的预测性能。自定义CNN在计算和内存预算受限时提供了有吸引力的效率-精度权衡，虽然性能略低于迁移学习，但训练更快、参数更少。固定特征提取器方法表现最差。

Conclusion: 迁移学习是视觉识别任务的最佳性能选择，而自定义CNN在资源受限场景下提供了实用的效率-精度平衡。该研究为实践者根据具体需求（性能优先vs效率优先）选择合适范式提供了实证指导。

Abstract: Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.

</details>


### [128] [TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation](https://arxiv.org/abs/2601.02273)
*Salim Khazem*

Main category: cs.CV

Relevance: 45.0

TL;DR: TopoLoRA-SAM：一种用于二进制语义分割的拓扑感知参数高效适配框架，通过LoRA注入、空间卷积适配器和拓扑感知监督，在仅训练5.2%参数的情况下，在多个医学和遥感数据集上达到最佳性能。


<details>
  <summary>Details</summary>
Motivation: 基础分割模型（如SAM）通过大规模预训练展现出强大的零样本泛化能力，但将其适配到特定领域的语义分割（特别是薄结构如视网膜血管和噪声模态如SAR图像）仍然具有挑战性。完全微调计算成本高且存在灾难性遗忘风险。

Method: 提出TopoLoRA-SAM框架：1）将低秩适配（LoRA）注入冻结的ViT编码器；2）添加轻量级空间卷积适配器；3）通过可微分clDice提供可选的拓扑感知监督。该方法仅训练约5.2%的模型参数（约490万参数）。

Result: 在五个基准数据集（视网膜血管分割：DRIVE、STARE、CHASE_DB1；息肉分割：Kvasir-SEG；SAR海陆分割：SL-SSDD）上评估，TopoLoRA-SAM在视网膜平均Dice和总体平均Dice上均达到最佳性能。在具有挑战性的CHASE_DB1数据集上显著提升了分割准确性和鲁棒性。

Conclusion: 拓扑感知的参数高效适配方法能够匹配甚至超越完全微调的专用模型，证明了在保持基础模型泛化能力的同时，通过少量参数调整实现领域特定任务优化的有效性。

Abstract: Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \textbf{5.2\%} of model parameters ($\sim$4.9M). On the challenging CHASE\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git

</details>


### [129] [Mono3DV: Monocular 3D Object Detection with 3D-Aware Bipartite Matching and Variational Query DeNoising](https://arxiv.org/abs/2601.01036)
*Kiet Dang Vu,Trung Thai Tran,Kien Nguyen Do Trung,Duc Dung Nguyen*

Main category: cs.CV

Relevance: 40.0

TL;DR: Mono3DV提出了一种基于Transformer的单目3D物体检测框架，通过3D感知二分匹配、3D去噪方案和变分查询去噪机制解决现有方法中3D属性被排除在匹配过程之外的问题。


<details>
  <summary>Details</summary>
Motivation: 现有DETR类架构在单目3D物体检测中存在关键限制：由于单目图像到3D估计的固有不适定性，3D属性被排除在二分匹配过程之外，导致高质量3D预测可能被仅基于2D的匹配标准错误抑制。

Method: 1) 3D感知二分匹配策略：将3D几何信息直接整合到匹配成本中；2) 3D去噪方案：稳定训练过程中的二分匹配；3) 变分查询去噪机制：解决传统去噪技术的梯度消失问题。

Result: 在不使用任何外部数据的情况下，在KITTI 3D物体检测基准上取得了最先进的结果。

Conclusion: Mono3DV通过将3D信息整合到匹配过程中并解决训练不稳定性，显著提升了单目3D物体检测的性能。

Abstract: While DETR-like architectures have demonstrated significant potential for monocular 3D object detection, they are often hindered by a critical limitation: the exclusion of 3D attributes from the bipartite matching process. This exclusion arises from the inherent ill-posed nature of 3D estimation from monocular image, which introduces instability during training. Consequently, high-quality 3D predictions can be erroneously suppressed by 2D-only matching criteria, leading to suboptimal results. To address this, we propose Mono3DV, a novel Transformer-based framework. Our approach introduces three key innovations. First, we develop a 3D-Aware Bipartite Matching strategy that directly incorporates 3D geometric information into the matching cost, resolving the misalignment caused by purely 2D criteria. Second, it is important to stabilize the Bipartite Matching to resolve the instability occurring when integrating 3D attributes. Therefore, we propose 3D-DeNoising scheme in the training phase. Finally, recognizing the gradient vanishing issue associated with conventional denoising techniques, we propose a novel Variational Query DeNoising mechanism to overcome this limitation, which significantly enhances model performance. Without leveraging any external data, our method achieves state-of-the-art results on the KITTI 3D object detection benchmark.

</details>


### [130] [Luminark: Training-free, Probabilistically-Certified Watermarking for General Vision Generative Models](https://arxiv.org/abs/2601.01085)
*Jiayi Xu,Zhang Zhang,Yuanrui Zhang,Ruitao Chen,Yixian Xu,Tianyu He,Di He*

Main category: cs.CV

Relevance: 40.0

TL;DR: Luminark是一种无需训练、概率认证的水印方法，用于视觉生成模型，基于补丁级亮度统计，通过水印引导技术实现跨模型通用性。


<details>
  <summary>Details</summary>
Motivation: 为视觉生成模型开发一种无需训练、具有概率认证的水印方法，能够在不同生成模型范式（扩散、自回归、混合）中通用，同时保持图像质量。

Method: 基于补丁级亮度统计定义水印，预定义二进制模式和对应阈值；检测时评估每个补丁亮度是否超过阈值，验证生成的二进制模式是否与目标匹配；利用引导技术作为即插即用机制实现水印注入。

Result: 在9个模型（扩散、自回归、混合框架）上评估，Luminark始终表现出高检测准确率、对常见图像变换的强鲁棒性，以及良好的视觉质量。

Conclusion: Luminark是一种有效的训练免费、概率认证的水印方法，适用于各种视觉生成模型，具有高检测准确率、强鲁棒性和良好视觉质量。

Abstract: In this paper, we introduce \emph{Luminark}, a training-free and probabilistically-certified watermarking method for general vision generative models. Our approach is built upon a novel watermark definition that leverages patch-level luminance statistics. Specifically, the service provider predefines a binary pattern together with corresponding patch-level thresholds. To detect a watermark in a given image, we evaluate whether the luminance of each patch surpasses its threshold and then verify whether the resulting binary pattern aligns with the target one. A simple statistical analysis demonstrates that the false positive rate of the proposed method can be effectively controlled, thereby ensuring certified detection. To enable seamless watermark injection across different paradigms, we leverage the widely adopted guidance technique as a plug-and-play mechanism and develop the \emph{watermark guidance}. This design enables Luminark to achieve generality across state-of-the-art generative models without compromising image quality. Empirically, we evaluate our approach on nine models spanning diffusion, autoregressive, and hybrid frameworks. Across all evaluations, Luminark consistently demonstrates high detection accuracy, strong robustness against common image transformations, and good performance on visual quality.

</details>


### [131] [CAP-IQA: Context-Aware Prompt-Guided CT Image Quality Assessment](https://arxiv.org/abs/2601.01613)
*Kazi Ramisa Rifa,Jie Zhang,Abdullah Imran*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了CAP-IQA框架，通过上下文感知提示引导和因果去偏技术，结合CNN视觉编码器和领域特定文本编码器，用于CT图像质量评估，在LDCTIQA挑战中超越现有最佳方法4.24%。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的方法在CT图像质量评估中应用有限，且容易引入偏差，因为它们通常反映理想化定义，无法适应真实世界的退化（如噪声、运动伪影、扫描仪变异）。需要一种能够整合文本先验知识和实例级上下文，同时消除偏差的方法。

Method: 提出CAP-IQA框架：1) 结合CNN视觉编码器和领域特定文本编码器；2) 使用放射学风格提示和上下文感知融合对齐语义和感知表示；3) 应用因果去偏技术分离理想化知识和事实图像退化；4) 评估诊断可见性、解剖清晰度和噪声感知。

Result: 在LDCTIQA挑战基准上获得2.8590总分（PLCC、SROCC、KROCC之和），超越最佳团队4.24%。在91,514张儿科CT内部数据集上验证了泛化能力。消融实验证实提示引导融合和简化编码器设计共同提升了特征对齐和可解释性。

Conclusion: CAP-IQA框架通过整合上下文感知提示和因果去偏，有效解决了CT图像质量评估中提示方法的偏差问题，在多个数据集上表现出优越性能和良好泛化能力。

Abstract: Prompt-based methods, which encode medical priors through descriptive text, have been only minimally explored for CT Image Quality Assessment (IQA). While such prompts can embed prior knowledge about diagnostic quality, they often introduce bias by reflecting idealized definitions that may not hold under real-world degradations such as noise, motion artifacts, or scanner variability. To address this, we propose the Context-Aware Prompt-guided Image Quality Assessment (CAP-IQA) framework, which integrates text-level priors with instance-level context prompts and applies causal debiasing to separate idealized knowledge from factual, image-specific degradations. Our framework combines a CNN-based visual encoder with a domain-specific text encoder to assess diagnostic visibility, anatomical clarity, and noise perception in abdominal CT images. The model leverages radiology-style prompts and context-aware fusion to align semantic and perceptual representations. On the 2023 LDCTIQA challenge benchmark, CAP-IQA achieves an overall correlation score of 2.8590 (sum of PLCC, SROCC, and KROCC), surpassing the top-ranked leaderboard team (2.7427) by 4.24%. Moreover, our comprehensive ablation experiments confirm that prompt-guided fusion and the simplified encoder-only design jointly enhance feature alignment and interpretability. Furthermore, evaluation on an in-house dataset of 91,514 pediatric CT images demonstrates the true generalizability of CAP-IQA in assessing perceptual fidelity in a different patient population.

</details>


### [132] [DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization](https://arxiv.org/abs/2601.01784)
*Boyang Zhao,Xin Liao,Jiaxin Chen,Xiaoshuai Wu,Yufeng Wu*

Main category: cs.CV

Relevance: 40.0

TL;DR: DDNet：基于双流图学习和解缠的时序伪造定位框架，通过协调局部伪影和语义内容流来捕获全局异常，显著提升视频伪造检测性能。


<details>
  <summary>Details</summary>
Motivation: AIGC技术的快速发展使得仅篡改视频中的小片段就能误导观众，而视频级别的检测既不准确也不具说服力。因此，需要精确识别篡改片段的时序伪造定位（TFL）。现有方法受限于局部视角，难以捕获全局异常。

Method: 提出DDNet框架：1）双流图学习：时间距离流捕获局部伪影，语义内容流捕获长程连接；2）痕迹解缠与适应（TDA）：分离通用伪造指纹；3）跨层级特征嵌入（CLFE）：通过层次特征深度融合构建鲁棒特征基础。

Result: 在ForgeryNet和TVIL基准测试中，AP@0.95指标比现有最优方法提升约9%，跨域鲁棒性显著改善。

Conclusion: DDNet通过双流协调和特征解缠有效解决了时序伪造定位中的全局异常捕获问题，在准确性和鲁棒性方面均优于现有方法。

Abstract: The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \emph{local view}, failing to capture global anomalies. To address this, we propose a \underline{d}ual-stream graph learning and \underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \emph{Temporal Distance Stream} for local artifacts and a \emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\% in AP@0.95, with significant improvements in cross-domain robustness.

</details>


### [133] [GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection](https://arxiv.org/abs/2601.01856)
*Joongwon Chae,Lihui Luo,Yang Liu,Runming Wang,Dongmei Yu,Zeming Liang,Xi Yuan,Dayan Zhang,Zhenglin Chen,Peiwu Qin,Ilmoon Chae*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出GCR框架，通过几何一致性路由解决任务无关持续异常检测中的专家选择问题，避免跨头分数可比性问题


<details>
  <summary>Details</summary>
Motivation: 工业检测中基于特征的异常检测方法在持续类别扩展的任务无关场景下，专家选择（路由）成为性能瓶颈。现有方法依赖跨头异常分数比较，但由于不同类别的分数分布差异（尺度和尾部行为），这种路由规则在实践中不可靠。

Method: GCR（几何一致性路由）框架：1）在共享的冻结补丁嵌入空间中，通过最小化到类别特定原型库的累积最近原型距离来路由测试图像；2）仅在路由到的专家内部使用标准基于原型的评分规则计算异常图。将跨头决策与头内异常评分分离。

Result: 在MVTec AD和VisA数据集上的实验表明，几何一致性路由显著提高了路由稳定性，缓解了持续性能崩溃，实现了接近零遗忘，同时保持了竞争力的检测和定位性能。

Conclusion: 许多先前归因于表示遗忘的失败实际上可以解释为跨头路由中决策规则的不稳定性。GCR通过几何一致性路由解决了这一问题，无需端到端表示学习。

Abstract: Feature-based anomaly detection is widely adopted in industrial inspection due to the strong representational power of large pre-trained vision encoders. While most existing methods focus on improving within-category anomaly scoring, practical deployments increasingly require task-agnostic operation under continual category expansion, where the category identity is unknown at test time. In this setting, overall performance is often dominated by expert selection, namely routing an input to an appropriate normality model before any head-specific scoring is applied. However, routing rules that compare head-specific anomaly scores across independently constructed heads are unreliable in practice, as score distributions can differ substantially across categories in scale and tail behavior.
  We propose GCR, a lightweight mixture-of-experts framework for stabilizing task-agnostic continual anomaly detection through geometry-consistent routing. GCR routes each test image directly in a shared frozen patch-embedding space by minimizing an accumulated nearest-prototype distance to category-specific prototype banks, and then computes anomaly maps only within the routed expert using a standard prototype-based scoring rule. By separating cross-head decision making from within-head anomaly scoring, GCR avoids cross-head score comparability issues without requiring end-to-end representation learning.
  Experiments on MVTec AD and VisA show that geometry-consistent routing substantially improves routing stability and mitigates continual performance collapse, achieving near-zero forgetting while maintaining competitive detection and localization performance. These results indicate that many failures previously attributed to representation forgetting can instead be explained by decision-rule instability in cross-head routing. Code is available at https://github.com/jw-chae/GCR

</details>


### [134] [Prithvi-Complimentary Adaptive Fusion Encoder (CAFE): unlocking full-potential for flood inundation mapping](https://arxiv.org/abs/2601.02315)
*Saurabh Kaushik,Lalit Maurya,Beth Tellman*

Main category: cs.CV

Relevance: 40.0

TL;DR: Prithvi-CAFE通过集成Prithvi GFM预训练编码器和CNN残差分支，结合卷积注意力模块，在洪水制图任务中显著优于基线U-Net和其他GFMs


<details>
  <summary>Details</summary>
Motivation: 现有地理基础模型(GFMs)在洪水制图等下游任务中难以捕捉关键局部细节，无法超越基线U-Net，需要改进模型对局部特征的捕获能力

Method: 提出Prithvi-CAFE架构：集成Prithvi GFM预训练编码器与并行CNN残差分支，使用卷积注意力模块增强，通过适配器实现快速微调，进行多尺度多层级特征融合

Result: 在Sen1Flood11测试集上IoU达到83.41，优于原始Prithvi(82.50)和其他GFMs；在保留测试点上IoU 81.37显著优于U-Net(70.57)；在FloodPlanet数据集上IoU 64.70也优于所有对比方法

Conclusion: Prithvi-CAFE通过融合全局依赖和局部细节，在多通道多模态数据分割任务中表现出强大潜力，特别是在需要局部细节的关键应用中

Abstract: Geo-Foundation Models (GFMs), have proven effective in diverse downstream applications, including semantic segmentation, classification, and regression tasks. However, in case of flood mapping using Sen1Flood11 dataset as a downstream task, GFMs struggles to outperform the baseline U-Net, highlighting model's limitation in capturing critical local nuances. To address this, we present the Prithvi-Complementary Adaptive Fusion Encoder (CAFE), which integrate Prithvi GFM pretrained encoder with a parallel CNN residual branch enhanced by Convolutional Attention Modules (CAM). Prithvi-CAFE enables fast and efficient fine-tuning through adapters in Prithvi and performs multi-scale, multi-level fusion with CNN features, capturing critical local details while preserving long-range dependencies. We achieve state-of-the-art results on two comprehensive flood mapping datasets: Sen1Flood11 and FloodPlanet. On Sen1Flood11 test data, Prithvi-CAFE (IoU 83.41) outperforms the original Prithvi (IoU 82.50) and other major GFMs (TerraMind 82.90, DOFA 81.54, spectralGPT: 81.02). The improvement is even more pronounced on the hold-out test site, where Prithvi-CAFE achieves an IoU of 81.37 compared to the baseline U-Net (70.57) and original Prithvi (72.42). On FloodPlanet, Prithvi-CAFE also surpasses the baseline U-Net and other GFMs, achieving an IoU of 64.70 compared to U-Net (60.14), Terramind (62.33), DOFA (59.15) and Prithvi 2.0 (61.91). Our proposed simple yet effective Prithvi-CAFE demonstrates strong potential for improving segmentation tasks where multi-channel and multi-modal data provide complementary information and local details are critical. The code is released on \href{https://github.com/Sk-2103/Prithvi-CAFE}{Prithvi-CAFE Github}

</details>


### [135] [ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors](https://arxiv.org/abs/2601.02359)
*Kaede Shiohara,Toshihiko Yamasaki,Vladislav Golyanik*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出ExposeAnyone，一种基于扩散模型的完全自监督方法，通过音频生成表情序列，实现人物特定的人脸伪造检测，在多个数据集上超越现有方法，并能检测Sora2生成的视频。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测方法难以泛化到未知的伪造操作，因为它们主要依赖现有深度伪造或伪伪造的监督训练，导致对特定伪造模式的过拟合。自监督方法虽有泛化潜力，但现有工作难以仅从自监督中学习到判别性表征。

Method: 提出ExposeAnyone，基于扩散模型从音频生成表情序列。首先使用参考集将模型个性化到特定主体，然后通过扩散重建误差计算可疑视频与个性化主体之间的身份距离，实现人物特定的人脸伪造检测。

Result: 1) 在DF-TIMIT、DFDCP、KoDF和IDForge数据集上，平均AUC比先前最先进方法高出4.22个百分点；2) 能够检测Sora2生成的视频，而先前方法表现不佳；3) 对模糊和压缩等损坏具有高度鲁棒性。

Conclusion: ExposeAnyone是一种有效的完全自监督方法，能够泛化到未知的深度伪造操作，包括新兴的生成模型如Sora2，并在现实世界人脸伪造检测中具有应用潜力。

Abstract: Detecting unknown deepfake manipulations remains one of the most challenging problems in face forgery detection. Current state-of-the-art approaches fail to generalize to unseen manipulations, as they primarily rely on supervised training with existing deepfakes or pseudo-fakes, which leads to overfitting to specific forgery patterns. In contrast, self-supervised methods offer greater potential for generalization, but existing work struggles to learn discriminative representations only from self-supervision. In this paper, we propose ExposeAnyone, a fully self-supervised approach based on a diffusion model that generates expression sequences from audio. The key idea is, once the model is personalized to specific subjects using reference sets, it can compute the identity distances between suspected videos and personalized subjects via diffusion reconstruction errors, enabling person-of-interest face forgery detection. Extensive experiments demonstrate that 1) our method outperforms the previous state-of-the-art method by 4.22 percentage points in the average AUC on DF-TIMIT, DFDCP, KoDF, and IDForge datasets, 2) our model is also capable of detecting Sora2-generated videos, where the previous approaches perform poorly, and 3) our method is highly robust to corruptions such as blur and compression, highlighting the applicability in real-world face forgery detection.

</details>


### [136] [AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.01762)
*Yanhao Wu,Haoyang Zhang,Fei He,Rui Wu,Congpei Qiu,Liang Gao,Wei Ke,Tong Zhang*

Main category: cs.RO

Relevance: 40.0

TL;DR: 提出一种级联自动驾驶规划框架，将纵向规划显式地建立在驾驶路径上，实现横向与纵向规划的协调，提高安全性和性能


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶模型在规划阶段采用并行横向和纵向预测，存在两个问题：1) 规划的路径和速度之间协调失败；2) 未充分利用驾驶路径作为纵向规划的先验，导致静态信息冗余编码

Method: 提出级联框架，将纵向规划显式地建立在驾驶路径上，引入路径条件化公式，让模型沿驾驶路径预测纵向位移而非完整2D轨迹点；同时提出面向规划的数据增强策略，模拟车辆切入等安全关键事件

Result: 在Bench2Drive基准测试中达到新SOTA：驾驶分数89.07，成功率73.18%，显著提高了协调性和安全性

Conclusion: 通过将纵向规划显式地建立在驾驶路径上的级联设计，能够实现更好的横向与纵向规划协调，提高自动驾驶的安全性和性能

Abstract: End-to-end autonomous driving has rapidly progressed, enabling joint perception and planning in complex environments. In the planning stage, state-of-the-art (SOTA) end-to-end autonomous driving models decouple planning into parallel lateral and longitudinal predictions. While effective, this parallel design can lead to i) coordination failures between the planned path and speed, and ii) underutilization of the drive path as a prior for longitudinal planning, thus redundantly encoding static information. To address this, we propose a novel cascaded framework that explicitly conditions longitudinal planning on the drive path, enabling coordinated and collision-aware lateral and longitudinal planning. Specifically, we introduce a path-conditioned formulation that explicitly incorporates the drive path into longitudinal planning. Building on this, the model predicts longitudinal displacements along the drive path rather than full 2D trajectory waypoints. This design simplifies longitudinal reasoning and more tightly couples it with lateral planning. Additionally, we introduce a planning-oriented data augmentation strategy that simulates rare safety-critical events, such as vehicle cut-ins, by adding agents and relabeling longitudinal targets to avoid collision. Evaluated on the challenging Bench2Drive benchmark, our method sets a new SOTA, achieving a driving score of 89.07 and a success rate of 73.18%, demonstrating significantly improved coordination and safety

</details>


### [137] [Can Generative Models Actually Forge Realistic Identity Documents?](https://arxiv.org/abs/2601.00829)
*Alexander Vinogradov*

Main category: cs.CV

Relevance: 35.0

TL;DR: 当前开源扩散模型能生成表面逼真的身份证件图像，但无法复制结构性和法证真实性，因此生成式身份证件伪造的威胁可能被高估。


<details>
  <summary>Details</summary>
Motivation: 随着生成式图像模型在图像真实性方面取得显著进展，公众担心它们可能被滥用于文件伪造。本研究旨在评估当代开源扩散模型是否能够生成能够实际绕过人工或自动验证系统的身份证件伪造品。

Method: 使用多种公开可用的生成模型家族（包括Stable Diffusion、Qwen、Flux、Nano-Banana等），评估文本到图像和图像到图像的生成流程，分析它们生成身份证件伪造品的能力。

Result: 研究发现，虽然当前生成模型能够模拟表面级别的文档美学，但无法复制结构性和法证真实性。生成的身份文件伪造品在细节一致性、安全特征和法证特征方面存在缺陷。

Conclusion: 生成式身份证件深度伪造达到法证级别真实性的风险可能被高估，强调了机器学习从业者与文件法证专家在现实风险评估中合作的重要性。

Abstract: Generative image models have recently shown significant progress in image realism, leading to public concerns about their potential misuse for document forgery. This paper explores whether contemporary open-source and publicly accessible diffusion-based generative models can produce identity document forgeries that could realistically bypass human or automated verification systems. We evaluate text-to-image and image-to-image generation pipelines using multiple publicly available generative model families, including Stable Diffusion, Qwen, Flux, Nano-Banana, and others. The findings indicate that while current generative models can simulate surface-level document aesthetics, they fail to reproduce structural and forensic authenticity. Consequently, the risk of generative identity document deepfakes achieving forensic-level authenticity may be overestimated, underscoring the value of collaboration between machine learning practitioners and document-forensics experts in realistic risk assessment.

</details>


### [138] [VL-OrdinalFormer: Vision Language Guided Ordinal Transformers for Interpretable Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.00879)
*Zahid Ullah,Jihie Kim*

Main category: cs.CV

Relevance: 35.0

TL;DR: VLOrdinalFormer：一种结合视觉语言引导的序数学习框架，用于膝关节骨关节炎的自动分级，通过CLIP语义对齐和ViT骨干网络实现临床相关特征的提取，在OAI数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎（KOA）是全球致残的主要原因，使用Kellgren Lawrence（KL）分级系统进行准确评估对临床决策至关重要。然而，早期疾病阶段（特别是KL1和KL2）的放射学区别很细微，经常导致放射科医生之间的观察者间变异性。为了解决这些挑战，需要开发能够结合临床文本概念的自动化分级方法。

Method: 提出VLOrdinalFormer框架，结合ViT L16骨干网络、基于CORAL的序数回归和CLIP驱动的语义对齐模块。该方法能够整合与关节间隙狭窄、骨赘形成和软骨下硬化相关的临床文本概念。采用分层五折交叉验证、类别感知重加权和测试时增强等技术提高鲁棒性。

Result: 在OAI kneeKL224数据集上的实验表明，VLOrdinalFormer在宏观F1分数和总体准确率方面优于CNN和ViT基线方法，达到最先进性能。特别在KL1和KL2分级上取得显著性能提升，同时不损害轻度或严重病例的分类准确性。

Conclusion: 该研究证明了视觉语言对齐的序数变换器作为KOA分级和疾病进展评估的可靠且可解释工具的潜力，可用于常规放射学实践。Grad-CAM和CLIP相似性图的解释性分析确认模型持续关注临床相关的解剖区域。

Abstract: Knee osteoarthritis (KOA) is a leading cause of disability worldwide, and accurate severity assessment using the Kellgren Lawrence (KL) grading system is critical for clinical decision making. However, radiographic distinctions between early disease stages, particularly KL1 and KL2, are subtle and frequently lead to inter-observer variability among radiologists. To address these challenges, we propose VLOrdinalFormer, a vision language guided ordinal learning framework for fully automated KOA grading from knee radiographs. The proposed method combines a ViT L16 backbone with CORAL based ordinal regression and a Contrastive Language Image Pretraining (CLIP) driven semantic alignment module, allowing the model to incorporate clinically meaningful textual concepts related to joint space narrowing, osteophyte formation, and subchondral sclerosis. To improve robustness and mitigate overfitting, we employ stratified five fold cross validation, class aware re weighting to emphasize challenging intermediate grades, and test time augmentation with global threshold optimization. Experiments conducted on the publicly available OAI kneeKL224 dataset demonstrate that VLOrdinalFormer achieves state of the art performance, outperforming CNN and ViT baselines in terms of macro F1 score and overall accuracy. Notably, the proposed framework yields substantial performance gains for KL1 and KL2 without compromising classification accuracy for mild or severe cases. In addition, interpretability analyses using Grad CAM and CLIP similarity maps confirm that the model consistently attends to clinically relevant anatomical regions. These results highlight the potential of vision language aligned ordinal transformers as reliable and interpretable tools for KOA grading and disease progression assessment in routine radiological practice.

</details>


### [139] [Comparative Evaluation of CNN Architectures for Neural Style Transfer in Indonesian Batik Motif Generation: A Comprehensive Study](https://arxiv.org/abs/2601.00888)
*Happy Gery Pangestu,Andi Prademon Yunus,Siti Khomsah*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该研究系统比较了五种CNN骨干网络在印尼蜡染风格迁移中的表现，发现ResNet架构在保持结构相似性的同时，计算效率显著优于VGG模型。


<details>
  <summary>Details</summary>
Motivation: 现有神经风格迁移方法主要基于VGG架构，虽然风格表达力强但计算和内存需求高，限制了在资源受限环境中的实际部署。需要系统评估不同CNN骨干网络在蜡染风格迁移中的效率与效果权衡。

Method: 通过245个对照实验，系统比较VGG16、VGG19、Inception V3、ResNet50和ResNet101五种CNN骨干网络。结合定量指标（SSIM、LPIPS、FLOPs）、定性评估和统计分析（ANOVA），分析结构保持、风格行为和计算效率之间的权衡。

Result: 骨干网络选择对结构相似性无显著差异（SSIM的ANOVA p=0.83）。ResNet架构比VGG模型收敛快5-6倍，FLOPs减少16倍以上（0.63 vs 10.12 GFLOPs），同时保持相似的感知相似性（LPIPS=0.53）。VGG产生更密集的绘画纹理，ResNet偏向几何稳定性和笔画保持，Inception V3表现居中但噪声较多。

Conclusion: 神经风格迁移的架构选择应从最大化风格强度转向效率感知和结构保持部署。ResNet骨干网络为可扩展、面向工业的蜡染生成提供了实用基础。

Abstract: Neural Style Transfer (NST) provides a computational framework for the digital preservation and generative exploration of Indonesian batik motifs; however, existing approaches remain largely centered on VGG-based architectures whose strong stylistic expressiveness comes at the cost of high computational and memory demands, that limits practical deployment in resource-limited environments. This study presents a systematic comparative analysis of five widely used CNN backbones, namely VGG16, VGG19, Inception V3, ResNet50, and ResNet101, based on 245 controlled experiments combining quantitative metrics, qualitative assessment, and statistical analysis to examine the trade-off between structural preservation, stylistic behavior, and computational efficiency. The results show that backbone selection does not yield statistically significant differences in structural similarity, as confirmed by ANOVA on SSIM (p= 0.83), indicating comparable levels of structural preservation rather than equivalent stylistic quality. Within this context, ResNet-based architectures achieve approximately 5-6x faster convergence than VGG models while maintaining similar perceptual similarity (LPIPS = 0.53) and requiring over 16x fewer FLOPs (0.63 vs 10.12 GFLOPs). Qualitative analysis reveals consistent stylistic trade-offs, with VGG producing denser painterly textures, ResNet favoring geometric stability and canting stroke preservation with milder stylization, and Inception V3 exhibiting intermediate but noisier behavior. These findings reposition architectural choice in NST from maximizing stylistic intensity toward efficiency-aware and structure-preserving deployment, highlighting ResNet-based backbones as a practical foundation for scalable, industry-oriented batik generation.

</details>


### [140] [CornViT: A Multi-Stage Convolutional Vision Transformer Framework for Hierarchical Corn Kernel Analysis](https://arxiv.org/abs/2601.00897)
*Sai Teja Erukude,Jane Mascarenhas,Lior Shamir*

Main category: cs.CV

Relevance: 35.0

TL;DR: CornViT：基于卷积视觉Transformer的三阶段玉米籽粒分级框架，通过模拟人类种子分析师的分层推理过程，实现纯度、形态和胚芽方向的自动检测


<details>
  <summary>Details</summary>
Motivation: 玉米籽粒分级对种子认证、定向播种和育种至关重要，但目前主要依赖人工检查，效率低且主观性强。需要开发自动化、准确的籽粒质量评估系统来替代人工。

Method: 提出三阶段卷积视觉Transformer（CvT）框架：第一阶段区分纯净与不纯籽粒；第二阶段将纯净籽粒分为扁平与圆形形态；第三阶段确定扁平纯净籽粒的胚芽方向（上/下）。使用ImageNet-22k预训练的CvT-13骨干网络，仅微调头部层。

Result: 在三个任务上获得高准确率：纯度检测93.76%，形态分类94.11%，胚芽方向检测91.12%。相比ResNet-50（76.56-81.02%）和DenseNet-121（86.56-89.38%）有明显优势。发布了三个数据集和Flask Web应用。

Conclusion: CornViT框架、精心策划的数据集和Web应用为玉米籽粒质量评估提供了可部署的自动化解决方案，卷积增强的自注意力机制在籽粒分析中表现出优越性。

Abstract: Accurate grading of corn kernels is critical for seed certification, directional seeding, and breeding, yet it is still predominantly performed by manual inspection. This work introduces CornViT, a three-stage Convolutional Vision Transformer (CvT) framework that emulates the hierarchical reasoning of human seed analysts for single-kernel evaluation. Three sequential CvT-13 classifiers operate on 384x384 RGB images: Stage 1 distinguishes pure from impure kernels; Stage 2 categorizes pure kernels into flat and round morphologies; and Stage 3 determines the embryo orientation (up vs. down) for pure, flat kernels. Starting from a public corn seed image collection, we manually relabeled and filtered images to construct three stage-specific datasets: 7265 kernels for purity, 3859 pure kernels for morphology, and 1960 pure-flat kernels for embryo orientation, all released as benchmarks. Head-only fine-tuning of ImageNet-22k pretrained CvT-13 backbones yields test accuracies of 93.76% for purity, 94.11% for shape, and 91.12% for embryo-orientation detection. Under identical training conditions, ResNet-50 reaches only 76.56 to 81.02 percent, whereas DenseNet-121 attains 86.56 to 89.38 percent accuracy. These results highlight the advantages of convolution-augmented self-attention for kernel analysis. To facilitate adoption, we deploy CornViT in a Flask-based web application that performs stage-wise inference and exposes interpretable outputs through a browser interface. Together, the CornViT framework, curated datasets, and web application provide a deployable solution for automated corn kernel quality assessment in seed quality workflows. Source code and data are publicly available.

</details>


### [141] [Evaluating Contextual Intelligence in Recyclability: A Comprehensive Study of Image-Based Reasoning Systems](https://arxiv.org/abs/2601.00905)
*Eliot Park,Abhi Kumar,Pranav Rajpurkar*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该研究评估了GPT-4o、GPT-4o-mini和Claude 3.5等先进视觉语言模型在垃圾分类回收预测任务上的表现，包括物品可回收性判断、垃圾桶匹配、位置特定规则适应等复杂场景。


<details>
  <summary>Details</summary>
Motivation: 虽然垃圾分类回收的重要性已被广泛认可，但公众在准确判断物品可回收性和正确处置方式方面仍面临困难。研究旨在探索先进视觉语言模型在这一实际应用场景中的潜力。

Method: 使用精心策划的图像数据集，评估多个先进视觉语言模型（GPT-4o、GPT-4o-mini、Claude 3.5）在垃圾分类回收任务上的表现。研究包括：1）物品与垃圾桶匹配能力评估；2）物品物理尺寸是否适合垃圾桶的判断；3）位置特定回收指南适应；4）污染或结构损坏物品处理；5）多材料复合物品处理。

Result: 研究发现这些先进模型在上下文理解方面相比前代模型有显著进步，能够处理复杂的垃圾分类场景。但同时在某些方面仍存在不足，需要进一步改进。

Conclusion: 上下文感知模型的持续改进对于提升公众垃圾分类实践和推进环境可持续发展至关重要。视觉语言模型在垃圾分类回收领域具有应用潜力，但仍需进一步优化。

Abstract: While the importance of efficient recycling is widely acknowledged, accurately determining the recyclability of items and their proper disposal remains a complex task for the general public. In this study, we explore the application of cutting-edge vision-language models (GPT-4o, GPT-4o-mini, and Claude 3.5) for predicting the recyclability of commonly disposed items. Utilizing a curated dataset of images, we evaluated the models' ability to match objects to appropriate recycling bins, including assessing whether the items could physically fit into the available bins. Additionally, we investigated the models' performance across several challenging scenarios: (i) adjusting predictions based on location-specific recycling guidelines; (ii) accounting for contamination or structural damage; and (iii) handling objects composed of multiple materials. Our findings highlight the significant advancements in contextual understanding offered by these models compared to previous iterations, while also identifying areas where they still fall short. The continued refinement of context-aware models is crucial for enhancing public recycling practices and advancing environmental sustainability.

</details>


### [142] [PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education](https://arxiv.org/abs/2601.00943)
*Megha Mariam K. M,Aditya Arun,Zakaria Laskar,C. V. Jawahar*

Main category: cs.CV

Relevance: 35.0

TL;DR: 论文提出了一个用于评估文本到视频(T2V)模型在物理教育中生成解释性视频能力的基准测试，发现当前模型能产生视觉连贯的视频，但在概念准确性方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型特别是T2V系统有望通过自动化创建引人入胜的视觉解释来改变科学教育。本研究旨在评估T2V模型在物理教育中的潜力，填补当前缺乏专门评估教育视频生成能力的基准测试的空白。

Method: 设计了一个专门用于物理教育视频生成的基准测试，将物理概念分解为细粒度的教学点，每个教学点配有精心设计的提示词用于视觉解释。通过让T2V模型根据这些提示生成视频，评估其概念准确性。

Result: 当前T2V模型能生成视觉连贯、运动平滑、闪烁较少的视频，但概念准确性不够可靠。在力学、流体和光学领域表现较好，但在电磁学和热力学等需要描绘抽象相互作用的领域表现较差。

Conclusion: 研究发现教育视频生成中存在视觉质量与概念准确性之间的差距，该基准测试有助于社区缩小这一差距，推动开发能够大规模生成准确、符合课程要求的物理教育内容的T2V系统。

Abstract: Generative AI models, particularly Text-to-Video (T2V) systems, offer a promising avenue for transforming science education by automating the creation of engaging and intuitive visual explanations. In this work, we take a first step toward evaluating their potential in physics education by introducing a dedicated benchmark for explanatory video generation. The benchmark is designed to assess how well T2V models can convey core physics concepts through visual illustrations. Each physics concept in our benchmark is decomposed into granular teaching points, with each point accompanied by a carefully crafted prompt intended for visual explanation of the teaching point. T2V models are evaluated on their ability to generate accurate videos in response to these prompts. Our aim is to systematically explore the feasibility of using T2V models to generate high-quality, curriculum-aligned educational content-paving the way toward scalable, accessible, and personalized learning experiences powered by AI. Our evaluation reveals that current models produce visually coherent videos with smooth motion and minimal flickering, yet their conceptual accuracy is less reliable. Performance in areas such as mechanics, fluids, and optics is encouraging, but models struggle with electromagnetism and thermodynamics, where abstract interactions are harder to depict. These findings underscore the gap between visual quality and conceptual correctness in educational video generation. We hope this benchmark helps the community close that gap and move toward T2V systems that can deliver accurate, curriculum-aligned physics content at scale. The benchmark and accompanying codebase are publicly available at https://github.com/meghamariamkm/PhyEduVideo.

</details>


### [143] [Deep Clustering with Associative Memories](https://arxiv.org/abs/2601.00963)
*Bishwajit Saha,Dmitry Krotov,Mohammed J. Zaki,Parikshit Ram*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出DCAM方法，通过基于能量的动力学和联想记忆，将表示学习和聚类更紧密地结合在单一目标中，解决了深度聚类中表示学习和聚类任务分离的问题


<details>
  <summary>Details</summary>
Motivation: 深度聚类中表示学习通常是可微分的，但聚类本质上是离散优化任务，需要各种近似和正则化才能适应标准可微分流程，导致表示学习和聚类之间存在一定程度的分离

Method: 提出DCAM方法，使用基于能量的动力学和联想记忆构建新的损失函数，在单一目标中将表示学习和聚类更紧密地结合起来

Result: 实验显示DCAM在各种架构选择（卷积、残差或全连接）和数据模态（图像或文本）上都能产生改进的聚类质量

Conclusion: DCAM通过基于能量的动力学和联想记忆，成功地将表示学习和聚类更紧密地结合，提高了深度聚类的性能

Abstract: Deep clustering - joint representation learning and latent space clustering - is a well studied problem especially in computer vision and text processing under the deep learning framework. While the representation learning is generally differentiable, clustering is an inherently discrete optimization task, requiring various approximations and regularizations to fit in a standard differentiable pipeline. This leads to a somewhat disjointed representation learning and clustering. In this work, we propose a novel loss function utilizing energy-based dynamics via Associative Memories to formulate a new deep clustering method, DCAM, which ties together the representation learning and clustering aspects more intricately in a single objective. Our experiments showcase the advantage of DCAM, producing improved clustering quality for various architecture choices (convolutional, residual or fully-connected) and data modalities (images or text).

</details>


### [144] [A Deep Learning Approach for Automated Skin Lesion Diagnosis with Explainable AI](https://arxiv.org/abs/2601.00964)
*Md. Maksudul Haque,Rahnuma Akter,A S M Ahsanul Sarkar Akib,Abdul Hasib*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一种用于HAM10000数据集多类皮肤病变分类的深度学习架构，结合了数据平衡、大规模数据增强、混合EfficientNetV2-L框架与通道注意力机制，以及三阶段渐进学习方法，并采用可解释AI技术增强临床可信度。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球最常见且危险的癌症类型之一，需要及时准确的诊断。当前深度学习在皮肤病变分类中面临数据不平衡、模型可解释性不足等挑战，需要开发高性能且可信的诊断系统。

Method: 1) 高质量数据平衡方法处理类别不平衡；2) 大规模数据增强扩充训练数据；3) 混合EfficientNetV2-L框架结合通道注意力机制；4) 三阶段渐进学习策略；5) 使用Grad-CAM和显著性图等XAI技术提供可视化解释。

Result: 在HAM10000数据集上达到总准确率91.15%，宏平均F1分数85.45%，微平均AUC 99.33%。在7个病变类别中均表现优异，尤其在黑色素瘤和黑色素细胞痣分类上表现突出。

Conclusion: 提出的深度学习架构在皮肤病变分类任务中取得了优异性能，XAI技术不仅增强了诊断透明度，还帮助识别影响分类的视觉特征，提高了临床可信度。

Abstract: Skin cancer is also one of the most common and dangerous types of cancer in the world that requires timely and precise diagnosis. In this paper, a deep-learning architecture of the multi-class skin lesion classification on the HAM10000 dataset will be described. The system suggested combines high-quality data balancing methods, large-scale data augmentation, hybridized EfficientNetV2-L framework with channel attention, and a three-stage progressive learning approach. Moreover, we also use explainable AI (XAI) techniques such as Grad-CAM and saliency maps to come up with intelligible visual representations of model predictions. Our strategy is with a total accuracy of 91.15 per cent, macro F1 of 85.45\% and micro-average AUC of 99.33\%. The model has shown high performance in all the seven lesion classes with specific high performance of melanoma and melanocytic nevi. In addition to enhancing diagnostic transparency, XAI also helps to find out the visual characteristics that cause the classifications, which enhances clinical trustworthiness.

</details>


### [145] [WildIng: A Wildlife Image Invariant Representation Model for Geographical Domain Shift](https://arxiv.org/abs/2601.00993)
*Julian D. Santamaria,Claudia Isaza,Jhony H. Giraldo*

Main category: cs.CV

Relevance: 35.0

TL;DR: WildIng：针对野生动物监测中地理域偏移问题的视觉语言模型，通过整合文本描述与图像特征，提升跨地理区域泛化能力


<details>
  <summary>Details</summary>
Motivation: 野生动物监测对研究生物多样性丧失和气候变化至关重要，但现有深度学习模型在跨地理区域泛化时性能显著下降，主要因为模型过度依赖图像特征而对背景、光照等地理分布变化敏感

Method: 提出WildIng模型，整合文本描述与图像特征，通过文本描述捕捉物种外观的语义信息，创建对地理域偏移更鲁棒的表示。在BioCLIP等基础模型上进行增强

Result: 在美洲和非洲数据集上的实验表明，WildIng将BioCLIP等基础模型在地理域偏移条件下的准确率提升了30%。相比传统方法（如CLIP+adapter在非洲训练、美洲测试时准确率从84.77%降至16.17%），WildIng显著改善了跨区域泛化能力

Conclusion: 通过整合文本描述，WildIng能够创建对地理域偏移更鲁棒的表示，显著提升野生动物识别模型在跨地理区域应用中的泛化性能

Abstract: Wildlife monitoring is crucial for studying biodiversity loss and climate change. Camera trap images provide a non-intrusive method for analyzing animal populations and identifying ecological patterns over time. However, manual analysis is time-consuming and resource-intensive. Deep learning, particularly foundation models, has been applied to automate wildlife identification, achieving strong performance when tested on data from the same geographical locations as their training sets. Yet, despite their promise, these models struggle to generalize to new geographical areas, leading to significant performance drops. For example, training an advanced vision-language model, such as CLIP with an adapter, on an African dataset achieves an accuracy of 84.77%. However, this performance drops significantly to 16.17% when the model is tested on an American dataset. This limitation partly arises because existing models rely predominantly on image-based representations, making them sensitive to geographical data distribution shifts, such as variation in background, lighting, and environmental conditions. To address this, we introduce WildIng, a Wildlife image Invariant representation model for geographical domain shift. WildIng integrates text descriptions with image features, creating a more robust representation to geographical domain shifts. By leveraging textual descriptions, our approach captures consistent semantic information, such as detailed descriptions of the appearance of the species, improving generalization across different geographical locations. Experiments show that WildIng enhances the accuracy of foundation models such as BioCLIP by 30% under geographical domain shift conditions. We evaluate WildIng on two datasets collected from different regions, namely America and Africa. The code and models are publicly available at https://github.com/Julian075/CATALOG/tree/WildIng.

</details>


### [146] [Lightweight Channel Attention for Efficient CNNs](https://arxiv.org/abs/2601.01002)
*Prem Babu Kanaparthi,Tulasi Venkata Sri Varshini Padamata*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文对通道注意力机制进行了实证研究，比较了SE、ECA和提出的LCA模块在ResNet-18和MobileNetV2上的性能，LCA通过自适应一维卷积和分组操作在保持准确性的同时减少了参数使用。


<details>
  <summary>Details</summary>
Motivation: 注意力机制已成为现代卷积神经网络的重要组成部分，能以最小的计算开销带来显著的性能提升。然而，不同通道注意力设计的效率-准确性权衡仍未得到充分探索。本研究旨在填补这一空白，为资源受限环境中的注意力增强CNN部署提供实用见解。

Method: 提出了Lite Channel Attention (LCA)模块，采用自适应一维卷积和分组操作来减少参数使用，同时保持有效的注意力行为。在ResNet-18和MobileNetV2架构上对SE、ECA和LCA进行了实证比较，使用CIFAR-10数据集，并提供了包括FLOPs、参数数量和GPU延迟在内的综合基准测试。

Result: LCA在ResNet-18上达到94.68%的准确率，在MobileNetV2上达到93.10%的准确率，同时与ECA在参数效率上相当，并保持了良好的推理延迟。实验结果表明LCA在准确性和效率之间取得了良好的平衡。

Conclusion: LCA模块在保持竞争力的准确性的同时，实现了参数效率的优化，为资源受限环境中部署注意力增强的CNN提供了实用的解决方案。该研究为通道注意力设计的效率-准确性权衡提供了实证见解。

Abstract: Attention mechanisms have become integral to modern convolutional neural networks (CNNs), delivering notable performance improvements with minimal computational overhead. However, the efficiency accuracy trade off of different channel attention designs remains underexplored. This work presents an empirical study comparing Squeeze and Excitation (SE), Efficient Channel Attention (ECA), and a proposed Lite Channel Attention (LCA) module across ResNet 18 and MobileNetV2 architectures on CIFAR 10. LCA employs adaptive one dimensional convolutions with grouped operations to reduce parameter usage while preserving effective attention behavior. Experimental results show that LCA achieves competitive accuracy, reaching 94.68 percent on ResNet 18 and 93.10 percent on MobileNetV2, while matching ECA in parameter efficiency and maintaining favorable inference latency. Comprehensive benchmarks including FLOPs, parameter counts, and GPU latency measurements are provided, offering practical insights for deploying attention enhanced CNNs in resource constrained environments.

</details>


### [147] [Deepfake Detection with Multi-Artifact Subspace Fine-Tuning and Selective Layer Masking](https://arxiv.org/abs/2601.01041)
*Xiang Zhang,Wenliang Weng,Daoyong Fu,Ziqiang Li,Zhangjie Fu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出MASM方法，通过多伪影子空间和选择性层掩码来解耦语义和伪影表示，提升深度伪造检测的跨数据集泛化能力


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测在跨数据集和真实复杂场景中面临挑战，主要原因是不同伪造方法引入的伪影分布多样性高，而预训练模型在适应新伪影时会破坏原有的通用语义结构

Method: 基于多伪影子空间和选择性层掩码的深度伪造检测方法，使用奇异值分解将预训练权重划分为稳定的语义主空间和多个可学习的伪影子空间，引入选择性层掩码策略自适应调节网络层更新，并施加正交性和谱一致性约束

Result: 该方法能够有效解耦语义和伪影表示，约束伪影子空间的拟合强度，在跨数据集场景中提升泛化鲁棒性

Conclusion: MASM方法通过解耦表示和约束学习，解决了深度伪造检测中的泛化问题，为处理多样伪造伪影提供了有效方案

Abstract: Deepfake detection still faces significant challenges in cross-dataset and real-world complex scenarios. The root cause lies in the high diversity of artifact distributions introduced by different forgery methods, while pretrained models tend to disrupt their original general semantic structures when adapting to new artifacts. Existing approaches usually rely on indiscriminate global parameter updates or introduce additional supervision signals, making it difficult to effectively model diverse forgery artifacts while preserving semantic stability. To address these issues, this paper proposes a deepfake detection method based on Multi-Artifact Subspaces and selective layer masks (MASM), which explicitly decouples semantic representations from artifact representations and constrains the fitting strength of artifact subspaces, thereby improving generalization robustness in cross-dataset scenarios. Specifically, MASM applies singular value decomposition to model weights, partitioning pretrained weights into a stable semantic principal subspace and multiple learnable artifact subspaces. This design enables decoupled modeling of different forgery artifact patterns while preserving the general semantic subspace. On this basis, a selective layer mask strategy is introduced to adaptively regulate the update behavior of corresponding network layers according to the learning state of each artifact subspace, suppressing overfitting to any single forgery characteristic. Furthermore, orthogonality constraints and spectral consistency constraints are imposed to jointly regularize multiple artifact subspaces, guiding them to learn complementary and diverse artifact representations while maintaining a stable overall spectral structure.

</details>


### [148] [EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos](https://arxiv.org/abs/2601.01050)
*Hongming Fu,Wenjia Wang,Xiaozhen Qiao,Shuo Yang,Zheng Liu,Bo Zhao*

Main category: cs.CV

Relevance: 35.0

TL;DR: EgoGrasp：首个从动态相机拍摄的自我中心单目视频中重建世界空间手物交互的方法，通过多阶段框架解决现有方法在时间动态和全局一致性上的限制。


<details>
  <summary>Details</summary>
Motivation: 准确的世界空间手物交互重建对于理解人类行为和实现具身智能、虚拟现实应用至关重要。现有方法局限于单图像或相机坐标系，无法建模时间动态或一致的全局轨迹，且在严重相机运动和频繁遮挡的野外自我中心视频中表现不佳。

Method: 提出多阶段框架：1）基于新开发的空间智能模型的鲁棒预处理流程；2）基于解耦扩散模型的全身手物交互先验模型（无模板、可扩展至多物体）；3）多目标测试时优化范式。

Result: 实验证明该方法在世界空间手物交互重建方面达到最先进的性能。

Conclusion: EgoGrasp首次实现了从动态相机拍摄的野外自我中心单目视频中准确重建世界空间手物交互，为理解人类行为和具身智能应用提供了重要工具。

Abstract: We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.

</details>


### [149] [Efficient Hyperspectral Image Reconstruction Using Lightweight Separate Spectral Transformers](https://arxiv.org/abs/2601.01064)
*Jianan Li,Wangcai Zhao,Tingfa Xu*

Main category: cs.CV

Relevance: 35.0

TL;DR: LSST：用于高光谱图像压缩感知重建的轻量级分离光谱Transformer架构，通过分组光谱自注意力和轻量空间卷积块实现高效重建


<details>
  <summary>Details</summary>
Motivation: 高光谱成像在多个领域很重要，但从压缩感知测量中高效重建高光谱图像面临挑战。需要利用高光谱图像独特的光谱和空间特性来设计高效重建方法

Method: 采用分治策略，提出轻量级分离光谱Transformer（LSST）架构，包含分离光谱Transformer块（SSTB）用于建模光谱关系，以及轻量空间卷积块（LSCB）用于空间处理。SSTB使用分组光谱自注意力和光谱洗牌操作，LSCB使用深度可分离卷积。还提出焦点光谱损失函数进行动态训练调整

Result: LSST在实现优越性能的同时，需要更少的FLOPs和参数，证明了其效率和有效性

Conclusion: LSST为高光谱图像压缩感知重建提供了一种高效且有效的解决方案，通过创新的Transformer架构设计和损失函数优化，在保持性能的同时减少了计算需求

Abstract: Hyperspectral imaging (HSI) is essential across various disciplines for its capacity to capture rich spectral information. However, efficiently reconstructing hyperspectral images from compressive sensing measurements presents significant challenges. To tackle these, we adopt a divide-and-conquer strategy that capitalizes on the unique spectral and spatial characteristics of hyperspectral images. We introduce the Lightweight Separate Spectral Transformer (LSST), an innovative architecture tailored for efficient hyperspectral image reconstruction. This architecture consists of Separate Spectral Transformer Blocks (SSTB) for modeling spectral relationships and Lightweight Spatial Convolution Blocks (LSCB) for spatial processing. The SSTB employs Grouped Spectral Self-attention and a Spectrum Shuffle operation to effectively manage both local and non-local spectral relationships. Simultaneously, the LSCB utilizes depth-wise separable convolutions and strategic ordering to enhance spatial information processing. Furthermore, we implement the Focal Spectrum Loss, a novel loss weighting mechanism that dynamically adjusts during training to improve reconstruction across spectrally complex bands. Extensive testing demonstrates that our LSST achieves superior performance while requiring fewer FLOPs and parameters, underscoring its efficiency and effectiveness. The source code is available at: https://github.com/wcz1124/LSST.

</details>


### [150] [CardioMOD-Net: A Modal Decomposition-Neural Network Framework for Diagnosis and Prognosis of HFpEF from Echocardiography Cine Loops](https://arxiv.org/abs/2601.01176)
*Andrés Bell-Navas,Jesús Garicano-Mena,Antonella Ausiello,Soledad Le Clainche,María Villalba-Orero,Enrique Lara-Pezzi*

Main category: cs.CV

Relevance: 35.0

TL;DR: CardioMOD-Net：基于超声心动图视频的AI框架，用于HFpEF的多类别诊断和连续发病时间预测


<details>
  <summary>Details</summary>
Motivation: HFpEF（射血分数保留的心力衰竭）由于多种合并症和长期亚临床阶段，早期诊断和预后困难。现有基于超声心动图的AI模型主要关注二分类HFpEF检测，缺乏合并症特异性表型分析和疾病进展的时间预测。

Method: 使用小鼠超声心动图视频（CTL、HG、OB、SAH四组），通过高阶动态模态分解提取时间特征，构建共享潜在表示支持的双Vision Transformer架构：一个用于多类别诊断分类，另一个用于HFpEF发病时间的回归预测。

Result: 整体诊断准确率65%，所有类别超过50%准确率；预后模块的HFpEF发病时间预测均方根误差为21.72周，OB和SAH组预测最准确，预测发病时间与真实分布高度匹配。

Conclusion: 该统一框架证明即使在数据量有限条件下，也能从单一超声心动图视频同时实现多类别表型分析和连续HFpEF发病预测，为临床前HFpEF研究的诊断和预后建模提供了基础。

Abstract: Introduction: Heart failure with preserved ejection fraction (HFpEF) arises from diverse comorbidities and progresses through prolonged subclinical stages, making early diagnosis and prognosis difficult. Current echocardiography-based Artificial Intelligence (AI) models focus primarily on binary HFpEF detection in humans and do not provide comorbidity-specific phenotyping or temporal estimates of disease progression towards decompensation. We aimed to develop a unified AI framework, CardioMOD-Net, to perform multiclass diagnosis and continuous prediction of HFpEF onset directly from standard echocardiography cine loops in preclinical models.
  Methods: Mouse echocardiography videos from four groups were used: control (CTL), hyperglycaemic (HG), obesity (OB), and systemic arterial hypertension (SAH). Two-dimensional parasternal long-axis cine loops were decomposed using Higher Order Dynamic Mode Decomposition (HODMD) to extract temporal features for downstream analysis. A shared latent representation supported Vision Transformers, one for a classifier for diagnosis and another for a regression module for predicting the age at HFpEF onset.
  Results: Overall diagnostic accuracy across the four groups was 65%, with all classes exceeding 50% accuracy. Misclassifications primarily reflected early-stage overlap between OB or SAH and CTL. The prognostic module achieved a root-mean-square error of 21.72 weeks for time-to-HFpEF prediction, with OB and SAH showing the most accurate estimates. Predicted HFpEF onset closely matched true distributions in all groups.
  Discussion: This unified framework demonstrates that multiclass phenotyping and continuous HFpEF onset prediction can be obtained from a single cine loop, even under small-data conditions. The approach offers a foundation for integrating diagnostic and prognostic modelling in preclinical HFpEF research.

</details>


### [151] [GenCAMO: Scene-Graph Contextual Decoupling for Environment-aware and Mask-free Camouflage Image-Dense Annotation Generation](https://arxiv.org/abs/2601.01181)
*Chenglizhao Chen,Shaojiang Yuan,Xiaoxue Lu,Mengke Song,Jia Song,Zhenyu Wu,Wenfeng Song,Shuai Li*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出GenCAMO框架，利用生成模型合成高质量伪装图像-密集标注数据，解决伪装场景理解中数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 伪装密集预测任务（如RGB-D伪装目标检测和开放词汇伪装目标分割）需要高质量大规模标注数据，但现有数据稀缺且标注成本高昂，限制了模型在复杂伪装场景中的理解和推理能力

Method: 1) 构建GenCAMO-DB大规模伪装数据集，包含深度图、场景图、属性描述和文本提示等多模态标注；2) 提出GenCAMO环境感知无掩码生成框架，生成高保真伪装图像及密集标注；3) 利用合成数据训练密集预测模型

Result: 实验表明GenCAMO通过提供高质量合成数据，显著提升了复杂伪装场景下的密集预测性能

Conclusion: 生成模型可以有效解决伪装数据稀缺问题，GenCAMO框架为伪装场景理解提供了高质量合成数据解决方案，代码和数据集将在论文接受后开源

Abstract: Conceal dense prediction (CDP), especially RGB-D camouflage object detection and open-vocabulary camouflage object segmentation, plays a crucial role in advancing the understanding and reasoning of complex camouflage scenes. However, high-quality and large-scale camouflage datasets with dense annotation remain scarce due to expensive data collection and labeling costs. To address this challenge, we explore leveraging generative models to synthesize realistic camouflage image-dense data for training CDP models with fine-grained representations, prior knowledge, and auxiliary reasoning. Concretely, our contributions are threefold: (i) we introduce GenCAMO-DB, a large-scale camouflage dataset with multi-modal annotations, including depth maps, scene graphs, attribute descriptions, and text prompts; (ii) we present GenCAMO, an environment-aware and mask-free generative framework that produces high-fidelity camouflage image-dense annotations; (iii) extensive experiments across multiple modalities demonstrate that GenCAMO significantly improves dense prediction performance on complex camouflage scenes by providing high-quality synthetic data. The code and datasets will be released after paper acceptance.

</details>


### [152] [RefSR-Adv: Adversarial Attack on Reference-based Image Super-Resolution Models](https://arxiv.org/abs/2601.01202)
*Jiazhu Dai,Huihui Jiang*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出RefSR-Adv对抗攻击方法，通过仅扰动参考图像来降低基于参考的超分辨率系统性能，揭示了RefSR模型过度依赖参考特征的安全漏洞


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注RefSR的后门攻击，而针对RefSR的对抗攻击脆弱性尚未充分探索。本文旨在填补这一研究空白，揭示RefSR系统的安全漏洞

Method: 提出RefSR-Adv对抗攻击方法，通过最大化对抗输出与干净输出之间的差异，仅扰动参考图像来降低超分辨率输出质量。在CNN、Transformer和Mamba架构上进行实验验证

Result: RefSR-Adv在CUFED5、WR-SR和DRefSR数据集上显著降低性能并产生严重伪影。实验证实低分辨率输入与参考图像相似度与攻击效果呈正相关

Conclusion: RefSR模型过度依赖参考特征是关键安全缺陷，本研究揭示了RefSR系统的安全漏洞，呼吁研究者关注RefSR的鲁棒性问题

Abstract: Single Image Super-Resolution (SISR) aims to recover high-resolution images from low-resolution inputs. Unlike SISR, Reference-based Super-Resolution (RefSR) leverages an additional high-resolution reference image to facilitate the recovery of high-frequency textures. However, existing research mainly focuses on backdoor attacks targeting RefSR, while the vulnerability of the adversarial attacks targeting RefSR has not been fully explored. To fill this research gap, we propose RefSR-Adv, an adversarial attack that degrades SR outputs by perturbing only the reference image. By maximizing the difference between adversarial and clean outputs, RefSR-Adv induces significant performance degradation and generates severe artifacts across CNN, Transformer, and Mamba architectures on the CUFED5, WR-SR, and DRefSR datasets. Importantly, experiments confirm a positive correlation between the similarity of the low-resolution input and the reference image and attack effectiveness, revealing that the model's over-reliance on reference features is a key security flaw. This study reveals a security vulnerability in RefSR systems, aiming to urge researchers to pay attention to the robustness of RefSR.

</details>


### [153] [Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation](https://arxiv.org/abs/2601.01213)
*Riccardo Gelato,Carlo Sgaravatti,Jakob Grahn,Giacomo Boracchi,Filippo Maria Bianchi*

Main category: cs.CV

Relevance: 35.0

TL;DR: SAMAR：基于Segment Anything Model的SAR雪崩分割标注工具，通过适配器、多编码器和提示工程解决领域适应问题，加速SAR图像标注


<details>
  <summary>Details</summary>
Motivation: SAR图像雪崩分割需要大量高质量专家标注，耗时且昂贵。需要开发工具加速SAR图像的雪崩标注过程，解决领域适应问题

Method: 1) 使用适配器缓解自然图像与SAR图像的领域差异；2) 多编码器处理多通道SAR输入；3) 提示工程策略提高雪崩定位精度；4) 限制编码器训练时间的训练算法

Result: 开发了SAMAR标注工具，实验证明能够显著加速SAR图像的雪崩标注过程

Conclusion: 通过领域适应技术将SAM成功应用于SAR雪崩分割，为遥感图像分析提供了高效的标注解决方案

Abstract: Remote sensing solutions for avalanche segmentation and mapping are key to supporting risk forecasting and mitigation in mountain regions. Synthetic Aperture Radar (SAR) imagery from Sentinel-1 can be effectively used for this task, but training an effective detection model requires gathering a large dataset with high-quality annotations from domain experts, which is prohibitively time-consuming. In this work, we aim to facilitate and accelerate the annotation of SAR images for avalanche mapping. We build on the Segment Anything Model (SAM), a segmentation foundation model trained on natural images, and tailor it to Sentinel-1 SAR data. Adapting SAM to our use-case requires addressing several domain-specific challenges: (i) domain mismatch, since SAM was not trained on satellite/SAR imagery; (ii) input adaptation, because SAR products typically provide more than three channels, while SAM is constrained to RGB images; (iii) robustness to imprecise prompts that can affect target identification and degrade the segmentation quality, an issue exacerbated in small, low-contrast avalanches; and (iv) training efficiency, since standard fine-tuning is computationally demanding for SAM. We tackle these challenges through a combination of adapters to mitigate the domain gap, multiple encoders to handle multi-channel SAR inputs, prompt-engineering strategies to improve avalanche localization accuracy, and a training algorithm that limits the training time of the encoder, which is recognized as the major bottleneck. We integrate the resulting model into an annotation tool and show experimentally that it speeds up the annotation of SAR images.

</details>


### [154] [Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment](https://arxiv.org/abs/2601.01224)
*Bac Nguyen,Yuhta Takida,Naoki Murata,Chieh-Hsin Lai,Toshimitsu Uesaka,Stefano Ermon,Yuki Mitsufuji*

Main category: cs.CV

Relevance: 35.0

TL;DR: CODA提出了一种结合对比学习和寄存器槽位的对象中心学习方法，通过寄存器槽位吸收残差注意力减少槽位纠缠，并使用对比对齐损失增强槽位与图像内容的对应关系，在合成和真实数据集上提升了对象发现和图像生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Slot Attention和预训练扩散模型的对象中心学习方法存在槽位纠缠和槽位与图像内容对齐弱的问题，限制了在复杂真实场景中的应用效果。

Method: 提出CODA方法：1) 引入寄存器槽位吸收残差注意力，减少对象槽位间的干扰；2) 应用对比对齐损失显式鼓励槽位与图像内容的对应关系，该训练目标可作为最大化槽位与输入间互信息的可处理替代。

Result: 在合成数据集(MOVi-C/E)和真实数据集(VOC, COCO)上，CODA在对象发现(如COCO上FG-ARI提升6.1%)、属性预测和组合图像生成方面均优于强基线方法，寄存器槽位仅增加可忽略的开销。

Conclusion: CODA作为一种高效可扩展的框架，在复杂真实场景中具有鲁棒对象中心学习的应用潜力，通过简单的扩展显著提升了对象发现和表示质量。

Abstract: Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes.

</details>


### [155] [HyDRA: Hybrid Denoising Regularization for Measurement-Only DEQ Training](https://arxiv.org/abs/2601.01228)
*Markus Haltmeier,Lukas Neumann,Nadja Gruber,Johannes Schwab,Gyeongha Hwang*

Main category: cs.CV

Relevance: 35.0

TL;DR: HyDRA：一种仅使用测量的DEQ训练框架，结合测量一致性和自适应去噪正则化，用于解决图像重建问题


<details>
  <summary>Details</summary>
Motivation: 解决图像重建问题中缺乏大规模监督数据集和病态性的挑战。传统DEQ模型需要监督对(x,y)，但实际中通常只有测量值y可用。

Method: 提出HyDRA框架，仅使用测量值训练DEQ模型，结合测量一致性损失和自适应去噪正则化项，并采用数据驱动的早停准则。

Result: 在稀疏视图CT重建实验中表现出有竞争力的重建质量和快速推理速度。

Conclusion: HyDRA为缺乏监督数据的图像重建问题提供了一种有效的仅测量训练框架，在CT重建中验证了其有效性。

Abstract: Solving image reconstruction problems of the form \(\mathbf{A} \mathbf{x} = \mathbf{y}\) remains challenging due to ill-posedness and the lack of large-scale supervised datasets. Deep Equilibrium (DEQ) models have been used successfully but typically require supervised pairs \((\mathbf{x},\mathbf{y})\). In many practical settings, only measurements \(\mathbf{y}\) are available. We introduce HyDRA (Hybrid Denoising Regularization Adaptation), a measurement-only framework for DEQ training that combines measurement consistency with an adaptive denoising regularization term, together with a data-driven early stopping criterion. Experiments on sparse-view CT demonstrate competitive reconstruction quality and fast inference.

</details>


### [156] [AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures](https://arxiv.org/abs/2601.01281)
*Sifatullah Sheikh Urmi,Kirtonia Nuzath Tabassum Arthi,Md Al-Imran*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文评估了四种基于AI的深度伪造检测模型（三个CNN和一个Vision Transformer），发现数据预处理和增强技术能提升模型性能，其中VFDNET与MobileNetV3组合表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成深度伪造技术的广泛应用，维护数字真实性面临重大挑战，需要开发可靠的深度伪造检测方法来应对这一威胁。

Method: 使用大规模人脸图像数据集评估了四种AI模型（三个CNN和一个Vision Transformer），应用了数据预处理和增强技术，比较了不同模型在深度伪造检测任务上的性能。

Result: VFDNET与MobileNetV3组合表现出最高的准确率，展示了高效的性能，证明了AI在可靠深度伪造检测方面的能力。

Conclusion: AI模型特别是VFDNET与MobileNetV3的组合，能够有效检测深度伪造，为维护数字真实性提供了可行的技术方案。

Abstract: The increasing use of artificial intelligence generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection.

</details>


### [157] [Achieving Fine-grained Cross-modal Understanding through Brain-inspired Hierarchical Representation Learning](https://arxiv.org/abs/2601.01339)
*Weihang You,Hanqi Jiang,Yi Pan,Junhao Chen,Tianming Liu,Fei Dou*

Main category: cs.CV

Relevance: 35.0

TL;DR: NeuroAlign：受人类视觉系统层次结构启发的fMRI-视频对齐框架，通过神经-时间对比学习和增强向量量化实现细粒度跨模态对齐


<details>
  <summary>Details</summary>
Motivation: 现有方法主要基于将神经解码简化为生成任务或简单相关性，无法反映大脑视觉处理的层次性和时间过程。由于大脑表征的固有复杂性以及神经数据与视觉输入之间的模态差距，理解视觉刺激的神经响应仍然具有挑战性。

Method: 提出NeuroAlign框架，采用两阶段机制模拟生物视觉通路：1) 通过神经-时间对比学习(NTCL)实现全局语义理解，显式建模跨模态的双向时间动态；2) 通过增强向量量化实现细粒度模式匹配，采用DynaSyncMM-EMA方法进行动态多模态融合和自适应加权。

Result: 实验表明NeuroAlign在跨模态检索任务中显著优于现有方法，为理解视觉认知机制建立了新范式。

Conclusion: NeuroAlign通过模拟人类视觉系统的层次组织，成功解决了fMRI-视频对齐的挑战，为理解大脑视觉处理提供了更精细的框架。

Abstract: Understanding neural responses to visual stimuli remains challenging due to the inherent complexity of brain representations and the modality gap between neural data and visual inputs. Existing methods, mainly based on reducing neural decoding to generation tasks or simple correlations, fail to reflect the hierarchical and temporal processes of visual processing in the brain. To address these limitations, we present NeuroAlign, a novel framework for fine-grained fMRI-video alignment inspired by the hierarchical organization of the human visual system. Our framework implements a two-stage mechanism that mirrors biological visual pathways: global semantic understanding through Neural-Temporal Contrastive Learning (NTCL) and fine-grained pattern matching through enhanced vector quantization. NTCL explicitly models temporal dynamics through bidirectional prediction between modalities, while our DynaSyncMM-EMA approach enables dynamic multi-modal fusion with adaptive weighting. Experiments demonstrate that NeuroAlign significantly outperforms existing methods in cross-modal retrieval tasks, establishing a new paradigm for understanding visual cognitive mechanisms.

</details>


### [158] [Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding](https://arxiv.org/abs/2601.01352)
*Yixuan Lai,He Wang,Kun Zhou,Tianjia Shao*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出了一种基于短参考视频的身份条件扩散变换器视频生成方法，通过Sinkhorn路由编码器学习紧凑的身份令牌，在保持提示忠实度和视觉真实性的同时显著提升身份保留能力


<details>
  <summary>Details</summary>
Motivation: 当前基于单张图像的视频生成方法在身份保留方面存在挑战：完全忽略时间特征导致姿势锁定、不自然扭曲和"平均"面部。需要从稀疏参考中推断面部动态，同时平衡身份保留和运动自然性之间的张力

Method: 1) 引入身份条件扩散变换器视频生成器，使用短参考视频而非单张肖像；2) 通过Sinkhorn路由编码器从参考视频中学习紧凑的身份令牌，捕捉特定主体的动态特征；3) 保持与预训练骨干网络的兼容性，仅添加轻量级条件

Result: 方法在大姿势变化和丰富面部表情下持续改善身份保留，同时保持提示忠实度和视觉真实性，适用于多样主体和提示

Conclusion: 通过利用参考视频中的动态特征，可以有效解决身份保留与运动自然性之间的平衡问题，为身份条件视频生成提供了更可靠的解决方案

Abstract: Producing prompt-faithful videos that preserve a user-specified identity remains challenging: models need to extrapolate facial dynamics from sparse reference while balancing the tension between identity preservation and motion naturalness. Conditioning on a single image completely ignores the temporal signature, which leads to pose-locked motions, unnatural warping, and "average" faces when viewpoints and expressions change. To this end, we introduce an identity-conditioned variant of a diffusion-transformer video generator which uses a short reference video rather than a single portrait. Our key idea is to incorporate the dynamics in the reference. A short clip reveals subject-specific patterns, e.g., how smiles form, across poses and lighting. From this clip, a Sinkhorn-routed encoder learns compact identity tokens that capture characteristic dynamics while remaining pretrained backbone-compatible. Despite adding only lightweight conditioning, the approach consistently improves identity retention under large pose changes and expressive facial behavior, while maintaining prompt faithfulness and visual realism across diverse subjects and prompts.

</details>


### [159] [Garment Inertial Denoiser (GID): Endowing Accurate Motion Capture via Loose IMU Denoiser](https://arxiv.org/abs/2601.01360)
*Jiawei Fang,Ruonan Zheng,Xiaoxia Gao,Shifan Jiang,Anjun Chen,Qi Ye,Shihui Guo*

Main category: cs.CV

Relevance: 35.0

TL;DR: GID是一个轻量级Transformer模型，用于解决可穿戴惯性动作捕捉中传感器与身体位移导致的噪声问题，通过位置感知专家架构实现实时去噪和姿态预测。


<details>
  <summary>Details</summary>
Motivation: 可穿戴惯性动作捕捉系统虽然便携、无遮挡且保护隐私，但需要传感器紧贴身体，这在实际日常使用中不舒适。将IMU嵌入宽松服装是理想方案，但传感器与身体位移会引入严重的结构化噪声，破坏标准惯性处理流程。

Method: 提出GID（Garment Inertial Denoiser），一个轻量级即插即用Transformer，将宽松服装动作捕捉分解为三个阶段：1）位置特定去噪，2）自适应跨服装融合，3）通用姿态预测。采用位置感知专家架构，共享时空骨干网络建模全局运动，每个IMU专家头专注于局部服装动态，轻量级融合模块确保跨部位一致性。

Result: GID能够从单用户训练中实现准确、实时的去噪，并在未见过的用户、动作和服装类型上表现出良好的泛化能力。作为即插即用模块，能持续改进最先进的惯性动作捕捉方法。

Conclusion: GID通过创新的位置感知专家架构有效解决了宽松服装惯性动作捕捉中的传感器位移问题，在有限配对数据下实现稳定训练，为可穿戴动作捕捉提供了实用解决方案。

Abstract: Wearable inertial motion capture (MoCap) provides a portable, occlusion-free, and privacy-preserving alternative to camera-based systems, but its accuracy depends on tightly attached sensors - an intrusive and uncomfortable requirement for daily use. Embedding IMUs into loose-fitting garments is a desirable alternative, yet sensor-body displacement introduces severe, structured, and location-dependent corruption that breaks standard inertial pipelines. We propose GID (Garment Inertial Denoiser), a lightweight, plug-and-play Transformer that factorizes loose-wear MoCap into three stages: (i) location-specific denoising, (ii) adaptive cross-wear fusion, and (iii) general pose prediction. GID uses a location-aware expert architecture, where a shared spatio-temporal backbone models global motion while per-IMU expert heads specialize in local garment dynamics, and a lightweight fusion module ensures cross-part consistency. This inductive bias enables stable training and effective learning from limited paired loose-tight IMU data. We also introduce GarMoCap, a combined public and newly collected dataset covering diverse users, motions, and garments. Experiments show that GID enables accurate, real-time denoising from single-user training and generalizes across unseen users, motions, and garment types, consistently improving state-of-the-art inertial MoCap methods when used as a drop-in module.

</details>


### [160] [SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution](https://arxiv.org/abs/2601.01406)
*Habiba Kausar,Saeed Anwar,Omar Jamal Hammad,Abdul Bais*

Main category: cs.CV

Relevance: 35.0

TL;DR: SwinIFS：一种基于地标引导的面部超分辨率框架，通过集成结构先验和分层注意力机制，在中等和极端放大因子下实现身份保持重建。


<details>
  <summary>Details</summary>
Motivation: 面部超分辨率从严重退化的低分辨率输入中恢复高质量面部图像具有挑战性，因为会丢失精细结构细节和身份特定特征。现有方法在极端放大时难以恢复有意义的身份信息。

Method: 提出SwinIFS框架，将关键面部地标的密集高斯热图集成到输入表示中，使网络从处理早期阶段就能关注语义重要的面部区域。采用紧凑的Swin Transformer主干网络捕获长距离上下文信息，同时保持局部几何结构。

Result: 在CelebA基准测试中，SwinIFS在感知质量、清晰重建和身份保持方面表现优异，即使在8倍放大下也能产生逼真结果，而大多数方法在此条件下无法恢复有意义的结构。在重建精度和计算效率之间取得良好平衡。

Conclusion: SwinIFS通过地标引导和分层注意力机制，实现了高质量的身份保持面部超分辨率，适用于面部增强、监控和数字修复等实际应用。

Abstract: Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.

</details>


### [161] [DreamID-V:Bridging the Image-to-Video Gap for High-Fidelity Face Swapping via Diffusion Transformer](https://arxiv.org/abs/2601.01425)
*Xu Guo,Fulong Ye,Xinghui Li,Pengqi Tu,Pengze Zhang,Qichao Sun,Songtao Zhao,Xiangwang Hou,Qian He*

Main category: cs.CV

Relevance: 35.0

TL;DR: DreamID-V：首个基于扩散Transformer的视频换脸框架，通过模态感知条件模块、合成到真实课程机制和身份一致性强化学习策略，实现高质量视频换脸，并在IDBench-V基准上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频换脸方法在保持身份相似性、属性保留和时间一致性方面存在困难，需要将图像换脸的优势无缝迁移到视频领域。

Method: 1) SyncID-Pipe数据管道预训练身份锚定视频合成器；2) 首个基于扩散Transformer的DreamID-V框架；3) 模态感知条件模块；4) 合成到真实课程机制；5) 身份一致性强化学习策略；6) IDBench-V基准测试。

Result: DreamID-V在IDBench-V基准上超越现有最先进方法，展现出卓越的泛化能力，可无缝适应各种换脸相关任务。

Conclusion: 该框架成功将图像换脸的优势迁移到视频领域，通过创新的数据管道、架构设计和训练策略解决了视频换脸的核心挑战。

Abstract: Video Face Swapping (VFS) requires seamlessly injecting a source identity into a target video while meticulously preserving the original pose, expression, lighting, background, and dynamic information. Existing methods struggle to maintain identity similarity and attribute preservation while preserving temporal consistency. To address the challenge, we propose a comprehensive framework to seamlessly transfer the superiority of Image Face Swapping (IFS) to the video domain. We first introduce a novel data pipeline SyncID-Pipe that pre-trains an Identity-Anchored Video Synthesizer and combines it with IFS models to construct bidirectional ID quadruplets for explicit supervision. Building upon paired data, we propose the first Diffusion Transformer-based framework DreamID-V, employing a core Modality-Aware Conditioning module to discriminatively inject multi-model conditions. Meanwhile, we propose a Synthetic-to-Real Curriculum mechanism and an Identity-Coherence Reinforcement Learning strategy to enhance visual realism and identity consistency under challenging scenarios. To address the issue of limited benchmarks, we introduce IDBench-V, a comprehensive benchmark encompassing diverse scenes. Extensive experiments demonstrate DreamID-V outperforms state-of-the-art methods and further exhibits exceptional versatility, which can be seamlessly adapted to various swap-related tasks.

</details>


### [162] [PartImageNet++ Dataset: Enhancing Visual Models with High-Quality Part Annotations](https://arxiv.org/abs/2601.01454)
*Xiao Li,Zilong Liu,Yining Liu,Zhuhong Li,Na Dong,Sitian Qin,Xiaolin Hu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出了PartImageNet++数据集，包含ImageNet-1K所有类别的详细部件标注，并基于此开发了多尺度部件监督识别模型MPM，通过部件标注提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏高质量部件标注，限制了部件级视觉理解的发展。作者旨在解决ImageNet-1K中部件标注稀缺的问题，为更细粒度的视觉识别提供基础。

Method: 1) 构建PartImageNet++数据集，每类100张标注图像，共10万张；2) 训练部件分割网络生成伪部件标签；3) 设计MPM模型，结合传统识别架构和辅助旁路层，联合监督伪部件标签和原始标注；4) 在部件分割、目标分割、少样本学习等任务上进行实验。

Result: MPM模型在ImageNet-1K上实现了鲁棒分类，同时为多个下游任务建立了强基线，证明了部件标注在提升模型性能方面的潜力。

Conclusion: PartImageNet++填补了大规模部件标注数据集的空白，MPM展示了部件监督对提升视觉识别模型鲁棒性的有效性，为细粒度视觉理解研究提供了新资源。

Abstract: To address the scarcity of high-quality part annotations in existing datasets, we introduce PartImageNet++ (PIN++), a dataset that provides detailed part annotations for all categories in ImageNet-1K. With 100 annotated images per category, totaling 100K images, PIN++ represents the most comprehensive dataset covering a diverse range of object categories. Leveraging PIN++, we propose a Multi-scale Part-supervised recognition Model (MPM) for robust classification on ImageNet-1K. We first trained a part segmentation network using PIN++ and used it to generate pseudo part labels for the remaining unannotated images. MPM then integrated a conventional recognition architecture with auxiliary bypass layers, jointly supervised by both pseudo part labels and the original part annotations. Furthermore, we conducted extensive experiments on PIN++, including part segmentation, object segmentation, and few-shot learning, exploring various ways to leverage part annotations in downstream tasks. Experimental results demonstrated that our approach not only enhanced part-based models for robust object recognition but also established strong baselines for multiple downstream tasks, highlighting the potential of part annotations in improving model performance. The dataset and the code are available at https://github.com/LixiaoTHU/PartImageNetPP.

</details>


### [163] [Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease](https://arxiv.org/abs/2601.01485)
*Zobia Batool,Diala Lteif,Vijaya B. Kolachalama,Huseyin Ozkan,Erchan Aptoula*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出Extended MixStyle (EM)框架，通过混合高阶特征矩（偏度和峰度）来模拟多样化的分布变化，提升阿尔茨海默病sMRI分类的单域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）诊断中，基于结构磁共振成像（sMRI）训练的模型在不同扫描仪、协议和患者群体间存在域偏移问题，导致泛化性能下降。单域泛化（SDG）在AD诊断中至关重要但研究不足。

Method: 提出Extended MixStyle (EM)框架，扩展了传统的MixStyle方法，不仅混合均值和方差，还混合高阶统计矩（偏度和峰度），以模拟更丰富的分布变化。在NACC数据集（n=4,647）上训练，区分正常认知、轻度认知障碍和AD，并在三个未见数据集（总计n=3,126）上测试。

Result: EM在跨域测试中显著提升性能，平均macro-F1比现有SDG基准方法提高2.4个百分点，展示了在异构真实世界环境中实现不变、可靠的AD检测的潜力。

Conclusion: Extended MixStyle通过混合高阶特征矩有效增强了模型对域偏移的鲁棒性，为阿尔茨海默病诊断中的单域泛化问题提供了有前景的解决方案。

Abstract: Despite progress in deep learning for Alzheimer's disease (AD) diagnostics, models trained on structural magnetic resonance imaging (sMRI) often do not perform well when applied to new cohorts due to domain shifts from varying scanners, protocols and patient demographics. AD, the primary driver of dementia, manifests through progressive cognitive and neuroanatomical changes like atrophy and ventricular expansion, making robust, generalizable classification essential for real-world use. While convolutional neural networks and transformers have advanced feature extraction via attention and fusion techniques, single-domain generalization (SDG) remains underexplored yet critical, given the fragmented nature of AD datasets. To bridge this gap, we introduce Extended MixStyle (EM), a framework for blending higher-order feature moments (skewness and kurtosis) to mimic diverse distributional variations. Trained on sMRI data from the National Alzheimer's Coordinating Center (NACC; n=4,647) to differentiate persons with normal cognition (NC) from those with mild cognitive impairment (MCI) or AD and tested on three unseen cohorts (total n=3,126), EM yields enhanced cross-domain performance, improving macro-F1 on average by 2.4 percentage points over state-of-the-art SDG benchmarks, underscoring its promise for invariant, reliable AD detection in heterogeneous real-world settings. The source code will be made available upon acceptance at https://github.com/zobia111/Extended-Mixstyle.

</details>


### [164] [DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion](https://arxiv.org/abs/2601.01487)
*Ziyue Zhang,Luxi Lin,Xiaolin Hu,Chao Chang,HuaiXi Wang,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出DeepInv，一种自监督的扩散模型反演方法，通过伪噪声生成和可训练求解器实现快速准确的图像到噪声映射


<details>
  <summary>Details</summary>
Motivation: 扩散反演是可控扩散图像编辑的关键任务，但现有方法缺乏可行的监督信号，大多采用基于近似的解决方案，往往以性能或效率为代价

Method: 提出自监督目标和数据增强策略生成高质量伪噪声，采用迭代多尺度训练机制训练参数化反演求解器，实现逐步预测反演噪声

Result: 在COCO数据集上，DeepInv比EasyInv提升40.435% SSIM，比ReNoise快9887.5%，在性能和推理速度上均显著优于对比方法

Conclusion: DeepInv是首个提出可训练求解器逐步预测反演噪声的方法，其精心设计的可训练求解器为社区提供了新见解

Abstract: Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.

</details>


### [165] [BARE: Towards Bias-Aware and Reasoning-Enhanced One-Tower Visual Grounding](https://arxiv.org/abs/2601.01526)
*Hongbing Li,Linhui Xiao,Zihan Zhao,Qi Shen,Yixiang Huang,Bo Xiao,Zhanyu Ma*

Main category: cs.CV

Relevance: 35.0

TL;DR: BARE是一个用于单塔视觉定位的偏置感知和推理增强框架，通过保留模态特定特征和构建指称语义来解决现有方法中的模态偏置和语义推理不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有单塔视觉定位方法存在两个主要问题：1）过度纠缠的多模态表示加剧了欺骗性模态偏置；2）语义推理不足阻碍了指称线索的理解。需要解决这些限制以提升视觉定位性能。

Method: 提出BARE框架，包含三个新模块：1）语言显著性调制器；2）视觉偏置校正；3）指称关系增强。这些模块共同减轻多模态干扰并增强指称理解能力。

Result: 在五个基准测试上的广泛实验表明，BARE不仅实现了最先进的性能，而且相比现有方法具有更优越的计算效率。

Conclusion: BARE通过偏置感知和推理增强机制有效解决了视觉定位中的模态偏置和语义推理问题，为单塔视觉定位提供了高效且高性能的解决方案。

Abstract: Visual Grounding (VG), which aims to locate a specific region referred to by expressions, is a fundamental yet challenging task in the multimodal understanding fields. While recent grounding transfer works have advanced the field through one-tower architectures, they still suffer from two primary limitations: (1) over-entangled multimodal representations that exacerbate deceptive modality biases, and (2) insufficient semantic reasoning that hinders the comprehension of referential cues. In this paper, we propose BARE, a bias-aware and reasoning-enhanced framework for one-tower visual grounding. BARE introduces a mechanism that preserves modality-specific features and constructs referential semantics through three novel modules: (i) language salience modulator, (ii) visual bias correction and (iii) referential relationship enhancement, which jointly mitigate multimodal distractions and enhance referential comprehension. Extensive experimental results on five benchmarks demonstrate that BARE not only achieves state-of-the-art performance but also delivers superior computational efficiency compared to existing approaches. The code is publicly accessible at https://github.com/Marloweeee/BARE.

</details>


### [166] [FAR-AMTN: Attention Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01537)
*Gong Gao,Zekai Wang,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出FAR-AMTN，一种用于人脸属性识别的注意力多任务网络，通过权重共享组特定注意力模块和跨组特征融合模块，在减少参数的同时提升多任务学习性能。


<details>
  <summary>Details</summary>
Motivation: 传统多任务网络在共享低层模块的同时使用独立的高层模块，导致参数随任务数量指数增长，且高层特征交互受限，难以探索属性间的语义关系，影响泛化性能。

Method: 1) 权重共享组特定注意力模块(WSGSA)：共享参数减少复杂度，提升组特征表示；2) 跨组特征融合模块(CGFF)：促进属性组间交互，增强特征学习；3) 动态权重策略(DWS)：实现任务同步收敛。

Result: 在CelebA和LFWA数据集上的实验表明，FAR-AMTN相比现有模型在准确率上表现更优，同时参数数量显著减少。

Conclusion: FAR-AMTN通过创新的注意力机制和特征融合策略，有效解决了传统多任务网络参数爆炸和高层特征交互不足的问题，在人脸属性识别任务上取得了更好的泛化性能。

Abstract: To enhance the generalization performance of Multi-Task Networks (MTN) in Face Attribute Recognition (FAR), it is crucial to share relevant information across multiple related prediction tasks effectively. Traditional MTN methods create shared low-level modules and distinct high-level modules, causing an exponential increase in model parameters with the addition of tasks. This approach also limits feature interaction at the high level, hindering the exploration of semantic relations among attributes, thereby affecting generalization negatively. In response, this study introduces FAR-AMTN, a novel Attention Multi-Task Network for FAR. It incorporates a Weight-Shared Group-Specific Attention (WSGSA) module with shared parameters to minimize complexity while improving group feature representation. Furthermore, a Cross-Group Feature Fusion (CGFF) module is utilized to foster interactions between attribute groups, enhancing feature learning. A Dynamic Weighting Strategy (DWS) is also introduced for synchronized task convergence. Experiments on the CelebA and LFWA datasets demonstrate that the proposed FAR-AMTN demonstrates superior accuracy with significantly fewer parameters compared to existing models.

</details>


### [167] [Trustworthy Data-Driven Wildfire Risk Prediction and Understanding in Western Canada](https://arxiv.org/abs/2601.01677)
*Zhengsen Xu,Lanying Wang,Sibo Cheng,Xue Rui,Kyle Gao,Yimin Zhu,Mabel Heffring,Zack Dewis,Saeid Taleghanidoozdoozan,Megan Greenwood,Motasem Alkayid,Quinn Ledingham,Hongjie He,Jonathan Li,Lincoln Linlin Xu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出一个可信赖的野火风险预测框架，通过长序列多尺度时序建模整合异质驱动因素，同时量化预测不确定性和实现过程级解释，在加拿大西部2023-2024火灾季节表现优异。


<details>
  <summary>Details</summary>
Motivation: 加拿大西部野火活动加剧导致重大社会经济和环境损失，但准确的野火风险预测受到点火和蔓延内在随机性以及燃料条件、气象、气候变异、地形和人类活动之间非线性相互作用的阻碍，挑战了纯数据驱动模型的可靠性和可解释性。

Method: 基于长序列多尺度时序建模的可信赖数据驱动野火风险预测框架，整合异质驱动因素，显式量化预测不确定性，并支持过程级解释。

Result: 在加拿大西部2023-2024年创纪录火灾季节评估中，该模型优于现有时间序列方法，F1分数达0.90，PR-AUC达0.98，计算成本低。不确定性分析揭示了预测置信度的结构化空间和季节模式。

Conclusion: 该框架为野火风险预测提供了可信赖的解决方案，通过不确定性量化和可解释性分析增强了模型可靠性，SHAP解释揭示了温度相关驱动因素的主导作用以及2024年湿度相关约束的更强影响。

Abstract: In recent decades, the intensification of wildfire activity in western Canada has resulted in substantial socio-economic and environmental losses. Accurate wildfire risk prediction is hindered by the intrinsic stochasticity of ignition and spread and by nonlinear interactions among fuel conditions, meteorology, climate variability, topography, and human activities, challenging the reliability and interpretability of purely data-driven models. We propose a trustworthy data-driven wildfire risk prediction framework based on long-sequence, multi-scale temporal modeling, which integrates heterogeneous drivers while explicitly quantifying predictive uncertainty and enabling process-level interpretation. Evaluated over western Canada during the record-breaking 2023 and 2024 fire seasons, the proposed model outperforms existing time-series approaches, achieving an F1 score of 0.90 and a PR-AUC of 0.98 with low computational cost. Uncertainty-aware analysis reveals structured spatial and seasonal patterns in predictive confidence, highlighting increased uncertainty associated with ambiguous predictions and spatiotemporal decision boundaries. SHAP-based interpretation provides mechanistic understanding of wildfire controls, showing that temperature-related drivers dominate wildfire risk in both years, while moisture-related constraints play a stronger role in shaping spatial and land-cover-specific contrasts in 2024 compared to the widespread hot and dry conditions of 2023. Data and code are available at https://github.com/SynUW/mmFire.

</details>


### [168] [FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation](https://arxiv.org/abs/2601.01687)
*Abdur R. Fayjie,Pankhi Kashyap,Jutika Borah,Patrick Vandewalle*

Main category: cs.CV

Relevance: 35.0

TL;DR: FALCON是一个跨域少样本分割框架，通过将3D医学体积处理为2D切片，在自然图像上进行元训练学习通用分割先验，然后通过对抗微调和边界感知学习迁移到医学领域，实现高精度3D分割。


<details>
  <summary>Details</summary>
Motivation: 3D医学体积中解剖和病理结构的精确分割对于准确诊断、有效手术规划和疾病监测至关重要。当前临床可行的分割面临3D标注稀缺、患者特异性变异、数据隐私问题和计算开销大等挑战。

Method: 1) 在自然图像上进行元训练学习通用分割先验；2) 通过对抗微调和边界感知学习迁移到医学领域；3) 基于支持线索的任务感知推理，动态适应患者特异性解剖变异；4) 将3D体积处理为2D切片以减少计算开销。

Result: 在四个基准测试中，FALCON始终实现最低的Hausdorff距离分数，表明边界精度优越，同时保持与最先进模型相当的Dice相似系数。这些结果使用显著更少的标注数据、无数据增强和大幅降低的计算开销实现。

Conclusion: FALCON通过跨域元学习和高效2D切片处理，解决了3D医学分割中的数据稀缺和计算挑战，实现了高精度、低资源消耗的分割性能。

Abstract: Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.

</details>


### [169] [Mitigating Longitudinal Performance Degradation in Child Face Recognition Using Synthetic Data](https://arxiv.org/abs/2601.01689)
*Afzal Hossain,Stephanie Schuckers*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该研究探讨了使用合成人脸数据作为纵向稳定器，通过提高儿童人脸识别模型的时间鲁棒性来解决儿童面部快速非线性生长导致的模板漂移和验证错误问题。


<details>
  <summary>Details</summary>
Motivation: 儿童人脸识别面临的主要挑战是面部快速非线性生长导致的模板漂移和随时间增加的验证错误。需要寻找方法来提高儿童人脸识别模型的时间鲁棒性，而合成数据可能作为一种有效的纵向稳定器。

Method: 在YFA数据集上采用身份分离协议，评估三种设置：1) 未经微调的预训练MagFace嵌入；2) 仅使用真实训练人脸微调的MagFace；3) 使用真实和合成生成训练人脸组合微调的MagFace。合成数据使用StyleGAN2 ADA生成，仅包含在训练身份中，并通过后生成过滤步骤减轻身份泄漏和去除伪影样本。

Result: 实验结果显示，在6到36个月的注册验证间隔中，合成增强的微调相对于预训练基线和仅使用真实数据微调都显著降低了错误率，表明合成数据增强能有效提高儿童人脸识别的时间鲁棒性。

Conclusion: 合成数据增强可以显著改善儿童人脸识别中的身份持久性，为儿科人脸识别提供了一种风险感知的改进方法。该研究为合成数据在提高模型时间鲁棒性方面的应用提供了实证支持。

Abstract: Longitudinal face recognition in children remains challenging due to rapid and nonlinear facial growth, which causes template drift and increasing verification errors over time. This work investigates whether synthetic face data can act as a longitudinal stabilizer by improving temporal robustness of child face recognition models. Using an identity disjoint protocol on the Young Face Aging (YFA) dataset, we evaluate three settings: (i) pretrained MagFace embeddings without dataset specific fine-tuning, (ii) MagFace fine-tuned using authentic training faces only, and (iii) MagFace fine-tuned using a combination of authentic and synthetically generated training faces. Synthetic data is generated using StyleGAN2 ADA and incorporated exclusively within the training identities; a post generation filtering step is applied to mitigate identity leakage and remove artifact affected samples. Experimental results across enrollment verification gaps from 6 to 36 months show that synthetic-augmented fine tuning substantially reduces error rates relative to both the pretrained baseline and real only fine tuning. These findings provide a risk aware assessment of synthetic augmentation for improving identity persistence in pediatric face recognition.

</details>


### [170] [Learnability-Driven Submodular Optimization for Active Roadside 3D Detection](https://arxiv.org/abs/2601.01695)
*Ruiyu Mao,Baoming Zhang,Nicholas Ruozzi,Yunhui Guo*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出LH3D框架，通过主动学习选择既信息丰富又可可靠标注的路边单目3D检测场景，抑制固有模糊样本，用25%标注预算达到接近全数据性能


<details>
  <summary>Details</summary>
Motivation: 现实部署中由于硬件和隐私限制，通常只能标注路边单目数据，但许多场景存在距离远、模糊或被遮挡的物体，其3D属性从单视角看是模糊的，需要车辆-路边配对帧才能可靠标注。这种固有模糊样本增加了标注难度和成本，揭示了根本的可学习性问题。

Method: 提出LH3D框架，基于可学习性的主动学习方法，选择既信息丰富又可可靠标注的场景。通过抑制固有模糊样本同时确保覆盖范围，优化标注效率。在DAIR-V2X-I数据集上进行实验验证。

Result: 在DAIR-V2X-I数据集上，仅使用25%标注预算，对车辆、行人和骑行者分别达到全性能的86.06%、67.32%和78.67%，显著优于基于不确定性的基线方法。

Conclusion: 对于路边3D感知，可学习性而非不确定性才是关键因素。LH3D框架能有效减少固有模糊样本的标注浪费，同时获得高性能模型。

Abstract: Roadside perception datasets are typically constructed via cooperative labeling between synchronized vehicle and roadside frame pairs. However, real deployment often requires annotation of roadside-only data due to hardware and privacy constraints. Even human experts struggle to produce accurate labels without vehicle-side data (image, LIDAR), which not only increases annotation difficulty and cost, but also reveals a fundamental learnability problem: many roadside-only scenes contain distant, blurred, or occluded objects whose 3D properties are ambiguous from a single view and can only be reliably annotated by cross-checking paired vehicle--roadside frames. We refer to such cases as inherently ambiguous samples. To reduce wasted annotation effort on inherently ambiguous samples while still obtaining high-performing models, we turn to active learning. This work focuses on active learning for roadside monocular 3D object detection and proposes a learnability-driven framework that selects scenes which are both informative and reliably labelable, suppressing inherently ambiguous samples while ensuring coverage. Experiments demonstrate that our method, LH3D, achieves 86.06%, 67.32%, and 78.67% of full-performance for vehicles, pedestrians, and cyclists respectively, using only 25% of the annotation budget on DAIR-V2X-I, significantly outperforming uncertainty-based baselines. This confirms that learnability, not uncertainty, matters for roadside 3D perception.

</details>


### [171] [CTIS-QA: Clinical Template-Informed Slide-level Question Answering for Pathology](https://arxiv.org/abs/2601.01769)
*Hao Lu,Ziniu Qian,Yifu Li,Yang Zhou,Bingzheng Wei,Yan Xu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出基于临床诊断模板的病理信息结构化收集流程，构建CTIS-Align数据集和CTIS-Bench基准，并开发CTIS-QA双流架构的WSI问答模型，在多个任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 病理报告中的诊断信息通常是非结构化的，难以直接用于计算分析。需要系统化的方法来提取和结构化病理信息，以支持基于全切片图像（WSI）的视觉语言对齐和问答任务。

Method: 1. 设计临床病理报告模板（CPRT）标准化提取病理特征；2. 构建CTIS-Align数据集（8万张切片-描述对）用于视觉语言对齐训练；3. 创建CTIS-Bench基准（977张WSI，14,879个QA对），强调临床相关的封闭式问题；4. 提出CTIS-QA双流架构：全局流通过聚类特征聚合捕获切片级上下文，局部流通过注意力引导的补丁感知模块聚焦关键区域。

Result: 在TCGA-BRCA上验证了pipeline有效性。CTIS-QA在WSI-VQA、CTIS-Bench和切片级诊断任务上，在多个指标上持续超越现有SOTA模型。

Conclusion: 提出的临床诊断模板pipeline能够有效结构化病理信息，CTIS-QA的双流架构模拟病理学家诊断方法，在WSI问答任务中表现出色，为病理学AI应用提供了有价值的工具和基准。

Abstract: In this paper, we introduce a clinical diagnosis template-based pipeline to systematically collect and structure pathological information. In collaboration with pathologists and guided by the the College of American Pathologists (CAP) Cancer Protocols, we design a Clinical Pathology Report Template (CPRT) that ensures comprehensive and standardized extraction of diagnostic elements from pathology reports. We validate the effectiveness of our pipeline on TCGA-BRCA. First, we extract pathological features from reports using CPRT. These features are then used to build CTIS-Align, a dataset of 80k slide-description pairs from 804 WSIs for vision-language alignment training, and CTIS-Bench, a rigorously curated VQA benchmark comprising 977 WSIs and 14,879 question-answer pairs. CTIS-Bench emphasizes clinically grounded, closed-ended questions (e.g., tumor grade, receptor status) that reflect real diagnostic workflows, minimize non-visual reasoning, and require genuine slide understanding. We further propose CTIS-QA, a Slide-level Question Answering model, featuring a dual-stream architecture that mimics pathologists' diagnostic approach. One stream captures global slide-level context via clustering-based feature aggregation, while the other focuses on salient local regions through attention-guided patch perception module. Extensive experiments on WSI-VQA, CTIS-Bench, and slide-level diagnostic tasks show that CTIS-QA consistently outperforms existing state-of-the-art models across multiple metrics. Code and data are available at https://github.com/HLSvois/CTIS-QA.

</details>


### [172] [RRNet: Configurable Real-Time Video Enhancement with Arbitrary Local Lighting Variations](https://arxiv.org/abs/2601.01865)
*Wenlong Yang,Canran Jin,Weihang Yuan,Chao Wang,Lifeng Sun*

Main category: cs.CV

Relevance: 35.0

TL;DR: RRNet是一个轻量级可配置的实时视频增强框架，通过虚拟光源参数估计和深度感知渲染实现局部重照明，在视觉质量和效率之间达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有实时视频增强方法在速度和有效曝光控制之间难以平衡，特别是在不均匀光照条件下。直播应用对实时视频增强的需求日益增长，需要既能保持高质量又能高效运行的解决方案。

Method: 1) 使用轻量级编码器和预测头估计最小虚拟光源参数；2) 通过深度感知渲染模块实现局部重照明，无需像素对齐训练数据；3) 基于生成式AI的数据集创建管道，低成本合成多样光照条件；4) 对象感知的公式化设计，保持面部身份特征。

Result: RRNet在低光增强、局部照明调整和眩光去除方面始终优于现有方法，支持实时高分辨率性能，在视觉质量和效率之间达到最先进的平衡。

Conclusion: RRNet通过其可解释的光照控制和高效架构，非常适合视频会议、AR肖像增强和移动摄影等实际应用，解决了实时视频增强中的关键挑战。

Abstract: With the growing demand for real-time video enhancement in live applications, existing methods often struggle to balance speed and effective exposure control, particularly under uneven lighting. We introduce RRNet (Rendering Relighting Network), a lightweight and configurable framework that achieves a state-of-the-art tradeoff between visual quality and efficiency. By estimating parameters for a minimal set of virtual light sources, RRNet enables localized relighting through a depth-aware rendering module without requiring pixel-aligned training data. This object-aware formulation preserves facial identity and supports real-time, high-resolution performance using a streamlined encoder and lightweight prediction head. To facilitate training, we propose a generative AI-based dataset creation pipeline that synthesizes diverse lighting conditions at low cost. With its interpretable lighting control and efficient architecture, RRNet is well suited for practical applications such as video conferencing, AR-based portrait enhancement, and mobile photography. Experiments show that RRNet consistently outperforms prior methods in low-light enhancement, localized illumination adjustment, and glare removal.

</details>


### [173] [Entity-Guided Multi-Task Learning for Infrared and Visible Image Fusion](https://arxiv.org/abs/2601.01870)
*Wenyu Shao,Hongbo Liu,Yunchuan Ma,Ruili Wang*

Main category: cs.CV

Relevance: 35.0

TL;DR: EGMT提出了一种基于实体引导的多任务学习框架，用于红外与可见光图像融合，通过提取实体级文本信息、构建并行多任务架构和跨模态交互模块，显著提升融合图像的质量和语义密度。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的红外与可见光图像融合方法通常依赖句子级文本信息，存在语义噪声且未能充分利用文本的深层语义价值。需要更精细的文本引导机制来提升融合质量。

Method: 1) 从大视觉语言模型生成的图像描述中提取实体级文本信息；2) 构建并行多任务学习架构，将图像融合与多标签分类任务结合，使用实体作为伪标签提供语义监督；3) 开发实体引导的跨模态交互模块，促进视觉与实体级文本特征的细粒度交互。

Result: EGMT在TNO、RoadScene、M3FD和MSRS四个公开数据集上表现出色，在保留显著目标、纹理细节和语义一致性方面优于现有最先进方法。

Conclusion: 实体引导的多任务学习框架能有效提升红外与可见光图像融合的质量，通过实体级语义监督和跨模态交互实现了更好的特征表示和融合效果。

Abstract: Existing text-driven infrared and visible image fusion approaches often rely on textual information at the sentence level, which can lead to semantic noise from redundant text and fail to fully exploit the deeper semantic value of textual information. To address these issues, we propose a novel fusion approach named Entity-Guided Multi-Task learning for infrared and visible image fusion (EGMT). Our approach includes three key innovative components: (i) A principled method is proposed to extract entity-level textual information from image captions generated by large vision-language models, eliminating semantic noise from raw text while preserving critical semantic information; (ii) A parallel multi-task learning architecture is constructed, which integrates image fusion with a multi-label classification task. By using entities as pseudo-labels, the multi-label classification task provides semantic supervision, enabling the model to achieve a deeper understanding of image content and significantly improving the quality and semantic density of the fused image; (iii) An entity-guided cross-modal interactive module is also developed to facilitate the fine-grained interaction between visual and entity-level textual features, which enhances feature representation by capturing cross-modal dependencies at both inter-visual and visual-entity levels. To promote the wide application of the entity-guided image fusion framework, we release the entity-annotated version of four public datasets (i.e., TNO, RoadScene, M3FD, and MSRS). Extensive experiments demonstrate that EGMT achieves superior performance in preserving salient targets, texture details, and semantic consistency, compared to the state-of-the-art methods. The code and dataset will be publicly available at https://github.com/wyshao-01/EGMT.

</details>


### [174] [Learning Action Hierarchies via Hybrid Geometric Diffusion](https://arxiv.org/abs/2601.01914)
*Arjun Ramesh Kaushik,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出HybridTAS框架，将欧几里得和双曲几何结合到扩散模型的去噪过程中，利用双曲几何的树状结构特性实现从粗到细的动作分割


<details>
  <summary>Details</summary>
Motivation: 现有的迭代细化方法未能充分利用人类动作的层次结构特性，而双曲几何天然适合表示树状层次关系，可以更好地指导动作分割任务

Method: 提出HybridTAS框架，在扩散模型的去噪过程中融合欧几里得和双曲几何。利用双曲几何的树状结构特性，在较高扩散时间步使用抽象的高层动作类别（根节点）指导，在较低时间步使用细粒度动作类别（叶节点）进行细化

Result: 在GTEA、50Salads和Breakfast三个基准数据集上实现了最先进的性能，验证了双曲引导去噪在时序动作分割任务中的有效性

Conclusion: 通过将双曲几何融入扩散模型的去噪过程，能够有效利用动作的层次结构特性，提升时序动作分割的性能

Abstract: Temporal action segmentation is a critical task in video understanding, where the goal is to assign action labels to each frame in a video. While recent advances leverage iterative refinement-based strategies, they fail to explicitly utilize the hierarchical nature of human actions. In this work, we propose HybridTAS - a novel framework that incorporates a hybrid of Euclidean and hyperbolic geometries into the denoising process of diffusion models to exploit the hierarchical structure of actions. Hyperbolic geometry naturally provides tree-like relationships between embeddings, enabling us to guide the action label denoising process in a coarse-to-fine manner: higher diffusion timesteps are influenced by abstract, high-level action categories (root nodes), while lower timesteps are refined using fine-grained action classes (leaf nodes). Extensive experiments on three benchmark datasets, GTEA, 50Salads, and Breakfast, demonstrate that our method achieves state-of-the-art performance, validating the effectiveness of hyperbolic-guided denoising for the temporal action segmentation task.

</details>


### [175] [MacVQA: Adaptive Memory Allocation and Global Noise Filtering for Continual Visual Question Answering](https://arxiv.org/abs/2601.01926)
*Zhifei Li,Yiran Wang,Chenyi Xiong,Yujing Xia,Xiaoju Hou,Yue Zhao,Miao Zhang,Kui Xiao,Bing Yang*

Main category: cs.CV

Relevance: 35.0

TL;DR: MacVQA：一种用于持续视觉问答的自适应记忆分配和全局噪声过滤框架，在知识保留、适应性和组合泛化方面取得平衡


<details>
  <summary>Details</summary>
Motivation: 当前持续学习VQA方法在平衡知识保留、适应性和鲁棒特征表示方面存在困难，需要解决多模态信息融合中的噪声过滤和记忆优化问题

Method: 提出MacVQA框架，融合视觉和问题信息同时过滤噪声确保鲁棒表示，采用基于原型的记忆分配优化特征质量和内存使用

Result: 在10个持续VQA任务上优于现有基线，标准任务平均准确率43.38%、平均遗忘率2.32%，新组合任务平均准确率42.53%、平均遗忘率3.60%

Conclusion: MacVQA通过自适应记忆分配和全局噪声过滤有效平衡了持续VQA学习中的知识获取、保留和组合泛化

Abstract: Visual Question Answering (VQA) requires models to reason over multimodal information, combining visual and textual data. With the development of continual learning, significant progress has been made in retaining knowledge and adapting to new information in the VQA domain. However, current methods often struggle with balancing knowledge retention, adaptation, and robust feature representation. To address these challenges, we propose a novel framework with adaptive memory allocation and global noise filtering called MacVQA for visual question answering. MacVQA fuses visual and question information while filtering noise to ensure robust representations, and employs prototype-based memory allocation to optimize feature quality and memory usage. These designs enable MacVQA to balance knowledge acquisition, retention, and compositional generalization in continual VQA learning. Experiments on ten continual VQA tasks show that MacVQA outperforms existing baselines, achieving 43.38% average accuracy and 2.32% average forgetting on standard tasks, and 42.53% average accuracy and 3.60% average forgetting on novel composition tasks.

</details>


### [176] [Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach](https://arxiv.org/abs/2601.02016)
*Matthias Bartolo,Dylan Seychell,Gabriel Hili,Matthew Montebello,Carl James Debono,Saviour Formosa,Konstantinos Makantasis*

Main category: cs.CV

Relevance: 35.0

TL;DR: 本文提出了一种基于学习使用特权信息（LUPI）范式的通用、模型无关的目标检测方法，通过教师-学生架构在训练时注入边界框掩码、显著性图和深度线索等特权信息，在推理时不增加计算复杂度的情况下显著提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 目标检测训练时通常可以获得比推理时更丰富的细粒度描述信息（如边界框掩码、显著性图、深度线索等），但这些特权信息在推理时不可用。如何有效利用这些训练时的特权信息来提升模型性能，而不增加推理时的计算负担，是本文的研究动机。

Method: 提出了一种通用的、模型无关的教师-学生架构方法：1）教师模型利用特权信息进行训练；2）学生模型在训练时通过知识蒸馏从教师模型学习，但在推理时只使用标准输入；3）通过中间权重平衡特权信息和标准输入的学习；4）在五个最先进的目标检测模型和多个公共基准上进行实验验证。

Result: LUPI训练的学生模型在多个基准测试中一致优于基线模型，检测精度显著提升，且不增加推理复杂度或模型大小。性能提升在中型和大型物体上尤为明显，消融研究表明中间权重的教师指导能最优平衡特权信息和标准输入的学习。

Conclusion: LUPI框架为目标检测系统提供了一种有效且实用的策略，特别适用于资源受限和实际应用场景，能够在保持推理效率的同时显著提升检测性能。

Abstract: This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.

</details>


### [177] [Adapting Depth Anything to Adverse Imaging Conditions with Events](https://arxiv.org/abs/2601.02020)
*Shihan Peng,Yuyang Xiong,Hanyu Zhou,Zhiwei Shi,Haoyue Liu,Gang Chen,Luxin Yan,Yi Chang*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出ADAE框架，通过事件相机引导的时空融合增强Depth Anything在恶劣成像条件下的深度估计能力


<details>
  <summary>Details</summary>
Motivation: 当前深度基础模型（如Depth Anything）在理想场景中表现优异，但在极端光照和运动模糊等恶劣成像条件下表现不佳。事件相机具有高动态范围和时间分辨率优势，但现有融合模型通常从头训练，无法继承基础模型的开放世界知识和泛化能力。

Method: 提出ADAE框架，包含两个核心组件：1）熵感知空间融合：基于信息熵策略自适应融合帧基和事件基特征，指示光照引起的退化；2）运动引导时间校正：利用事件基运动线索重新校准模糊区域的模糊特征。两者互补增强Depth Anything在恶劣条件下的性能。

Result: 通过大量实验验证了所提方法的优越性，在动态和恶劣光照条件下显著提升了深度估计的鲁棒性。

Conclusion: ADAE框架有效结合了事件相机的优势与深度基础模型的泛化能力，为恶劣成像条件下的鲁棒深度估计提供了有效解决方案。

Abstract: Robust depth estimation under dynamic and adverse lighting conditions is essential for robotic systems. Currently, depth foundation models, such as Depth Anything, achieve great success in ideal scenes but remain challenging under adverse imaging conditions such as extreme illumination and motion blur. These degradations corrupt the visual signals of frame cameras, weakening the discriminative features of frame-based depths across the spatial and temporal dimensions. Typically, existing approaches incorporate event cameras to leverage their high dynamic range and temporal resolution, aiming to compensate for corrupted frame features. However, such specialized fusion models are predominantly trained from scratch on domain-specific datasets, thereby failing to inherit the open-world knowledge and robust generalization inherent to foundation models. In this work, we propose ADAE, an event-guided spatiotemporal fusion framework for Depth Anything in degraded scenes. Our design is guided by two key insights: 1) Entropy-Aware Spatial Fusion. We adaptively merge frame-based and event-based features using an information entropy strategy to indicate illumination-induced degradation. 2) Motion-Guided Temporal Correction. We resort to the event-based motion cue to recalibrate ambiguous features in blurred regions. Under our unified framework, the two components are complementary to each other and jointly enhance Depth Anything under adverse imaging conditions. Extensive experiments have been performed to verify the superiority of the proposed method. Our code will be released upon acceptance.

</details>


### [178] [Leveraging 2D-VLM for Label-Free 3D Segmentation in Large-Scale Outdoor Scene Understanding](https://arxiv.org/abs/2601.02029)
*Toshihiko Nishimura,Hirofumi Abe,Kazuhiko Murasaki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出一种无需3D标注数据或配对RGB图像的大规模点云3D语义分割方法，通过虚拟相机将3D点云投影到2D图像，利用基础2D模型和自然语言提示进行语义分割，并通过加权投票聚合多视角预测。


<details>
  <summary>Details</summary>
Motivation: 传统3D语义分割方法需要大量标注的3D训练数据，这在实际应用中成本高昂且难以获取。现有方法通常依赖于配对的多模态数据或监督学习，限制了其灵活性和可扩展性。本文旨在开发一种无需3D标注、无需配对RGB图像的训练无关方法，实现开放词汇的3D语义分割。

Method: 1) 使用虚拟相机将3D点云投影到多个2D视角；2) 利用预训练的基础2D视觉模型（如CLIP等）结合自然语言提示进行2D语义分割；3) 通过加权投票机制聚合多视角的2D预测结果，生成最终的3D语义分割；4) 支持开放词汇识别，用户可使用任意文本查询进行物体检测。

Result: 该方法在多个基准测试中超越了现有的训练无关方法，分割精度达到了与监督方法相当的水平。同时支持开放词汇识别，能够检测任意文本查询指定的物体，突破了传统监督方法的类别限制。

Conclusion: 本文提出了一种创新的3D语义分割框架，通过将3D点云投影到2D空间并利用强大的基础2D模型，实现了无需3D标注数据的高质量语义分割。该方法不仅性能优越，还具备开放词汇识别的灵活性，为3D场景理解提供了新的解决方案。

Abstract: This paper presents a novel 3D semantic segmentation method for large-scale point cloud data that does not require annotated 3D training data or paired RGB images. The proposed approach projects 3D point clouds onto 2D images using virtual cameras and performs semantic segmentation via a foundation 2D model guided by natural language prompts. 3D segmentation is achieved by aggregating predictions from multiple viewpoints through weighted voting. Our method outperforms existing training-free approaches and achieves segmentation accuracy comparable to supervised methods. Moreover, it supports open-vocabulary recognition, enabling users to detect objects using arbitrary text queries, thus overcoming the limitations of traditional supervised approaches.

</details>


### [179] [AlignVTOFF: Texture-Spatial Feature Alignment for High-Fidelity Virtual Try-Off](https://arxiv.org/abs/2601.02038)
*Yihan Zhu,Mengying Ge*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出AlignVTOFF框架，通过并行U-Net架构和纹理-空间特征对齐技术，解决虚拟试穿中几何变形和高频纹理保持的挑战，生成高质量平铺服装图像。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法使用轻量级模块进行快速特征提取，但难以保持结构化图案和细粒度细节，导致生成过程中纹理衰减。需要解决复杂几何变形和丰富高频纹理的保持问题。

Method: 提出AlignVTOFF框架：1) Reference U-Net进行多尺度特征提取，增强几何保真度；2) 纹理-空间特征对齐(TSFA)通过混合注意力设计（可训练交叉注意力+冻结自注意力）将参考服装特征注入冻结去噪U-Net。

Result: 在多种设置下的广泛实验表明，AlignVTOFF始终优于最先进方法，生成的平铺服装结果具有改进的结构真实性和高频细节保真度。

Conclusion: AlignVTOFF通过并行U-Net框架和纹理-空间特征对齐，有效解决了虚拟试穿中的纹理衰减问题，实现了高质量的服装图像生成。

Abstract: Virtual Try-Off (VTOFF) is a challenging multimodal image generation task that aims to synthesize high-fidelity flat-lay garments under complex geometric deformation and rich high-frequency textures. Existing methods often rely on lightweight modules for fast feature extraction, which struggles to preserve structured patterns and fine-grained details, leading to texture attenuation during generation.To address these issues, we propose AlignVTOFF, a novel parallel U-Net framework built upon a Reference U-Net and Texture-Spatial Feature Alignment (TSFA). The Reference U-Net performs multi-scale feature extraction and enhances geometric fidelity, enabling robust modeling of deformation while retaining complex structured patterns. TSFA then injects the reference garment features into a frozen denoising U-Net via a hybrid attention design, consisting of a trainable cross-attention module and a frozen self-attention module. This design explicitly aligns texture and spatial cues and alleviates the loss of high-frequency information during the denoising process.Extensive experiments across multiple settings demonstrate that AlignVTOFF consistently outperforms state-of-the-art methods, producing flat-lay garment results with improved structural realism and high-frequency detail fidelity.

</details>


### [180] [Agentic Retoucher for Text-To-Image Generation](https://arxiv.org/abs/2601.02046)
*Shaocheng Shen,Jianfeng Liang. Chunlei Cai,Cong Geng,Huiyu Duan,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai*

Main category: cs.CV

Relevance: 35.0

TL;DR: Agentic Retoucher是一个分层决策驱动框架，通过感知-推理-行动循环解决文本到图像扩散模型中的局部失真问题，无需昂贵迭代重生成或依赖弱空间定位的视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散模型（如SDXL和FLUX）虽然实现了高真实感，但在肢体、面部、文本等细节上普遍存在小尺度失真。现有细化方法要么需要昂贵的迭代重新生成，要么依赖空间定位能力弱的视觉语言模型，导致语义漂移和不可靠的局部编辑。

Method: 提出Agentic Retoucher分层决策驱动框架，将后生成校正重新表述为类人的感知-推理-行动循环：1）感知代理学习上下文显著性，在文本-图像一致性线索下进行细粒度失真定位；2）推理代理通过渐进偏好对齐执行人类对齐的推断诊断；3）行动代理根据用户偏好自适应规划局部修复。此外构建了GenBlemish-27K数据集，包含6K个T2I图像和27K个标注的伪影区域。

Result: 实验表明Agentic Retoucher在感知质量、失真定位和人类偏好对齐方面持续优于最先进方法，为自校正和感知可靠的T2I生成建立了新范式。

Conclusion: Agentic Retoucher通过将感知证据、语言推理和可控校正整合到统一的自校正决策过程中，有效解决了T2I扩散模型中的局部失真问题，为图像生成后处理提供了新方法。

Abstract: Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.

</details>


### [181] [HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures](https://arxiv.org/abs/2601.02103)
*Yating Wang,Yuan Sun,Xuan Wang,Ran Yi,Boyao Zhou,Yipengjing Sun,Hongyu Liu,Yinuo Wang,Lizhuang Ma*

Main category: cs.CV

Relevance: 35.0

TL;DR: HeadLighter：基于3D高斯溅射的头部生成模型，通过物理可解释的分解方法实现可控重光照，解决了光照与内在外观的纠缠问题


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯溅射的头部生成模型虽然能实现实时、逼真的视图一致合成，但存在根本限制：光照与内在外观的深度纠缠阻碍了可控重光照。现有解耦方法依赖强假设进行弱监督学习，限制了处理复杂光照的能力。

Method: 提出HeadLighter框架：1）双分支架构分别建模光照不变头部属性和物理基础的渲染组件；2）渐进式解耦训练，在受控光照条件下使用光舞台设置采集的多视角图像进行监督；3）引入蒸馏策略生成高质量法线以实现逼真渲染。

Result: 实验表明该方法保持了高质量生成和实时渲染能力，同时支持显式光照和视角编辑。代码和数据集将公开。

Conclusion: HeadLighter成功解决了头部生成模型中光照与外观的纠缠问题，实现了物理可解释的分解，为可控重光照提供了有效解决方案。

Abstract: Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.

</details>


### [182] [QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition](https://arxiv.org/abs/2601.02189)
*Cheng Ying Wu,Yen Jui Chang*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出量子启发的交互分类器（QuIC），通过模拟量子态交互捕捉二阶特征协方差，显著提升浅层网络在细粒度视觉分类任务上的性能，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上部署细粒度视觉分类模型面临挑战：深层网络计算成本高，浅层网络（如AlexNet、VGG）无法区分视觉相似的子类别。标准全局平均池化只能捕捉一阶统计量，而双线性CNN存在特征维度爆炸和训练不稳定的问题。

Method: 提出量子启发的交互分类器（QuIC），将特征通道建模为相互作用的量子态，通过可学习的可观测量算子捕捉二阶特征协方差。QuIC是一个轻量级、即插即用的模块，支持稳定、单阶段的端到端训练，不会导致特征维度爆炸。

Result: QuIC显著提升了浅层骨干网络的性能：将VGG16的Top-1准确率提升了近20%，在ResNet18上超越了最先进的注意力机制（SE-Block）。t-SNE可视化分析证实QuIC能够解决模糊案例，明确关注细粒度判别性特征并强制紧凑的类内聚类。

Conclusion: QuIC通过量子力学启发的特征交互建模，有效解决了细粒度视觉分类中浅层网络性能不足的问题，为资源受限环境下的高效细粒度分类提供了新思路。

Abstract: Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.

</details>


### [183] [Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules](https://arxiv.org/abs/2601.02203)
*Oliver Custance,Saad Khan,Simon Parkinson,Quan Z. Sheng*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出一种基于WiFi CSI的无设备人群计数两阶段框架，通过自监督对比学习预训练CSI-ResNet-A学习领域不变表示，结合轻量级适配器微调和状态计数机，在领域迁移问题上取得突破性性能。


<details>
  <summary>Details</summary>
Motivation: 基于WiFi CSI的无设备人群计数是隐私保护物联网应用的关键技术，但实际部署面临严重的领域迁移问题——在一个环境训练的模型无法泛化到其他环境。现有方法缺乏有效的跨领域泛化能力。

Method: 提出两阶段框架：1) CSI-ResNet-A架构通过自监督对比学习预训练，学习领域不变表示；2) 使用轻量级适配器模块进行高效微调；3) 状态计数机处理事件序列生成稳定占用估计。引入泛化指数(GI)量化鲁棒性。

Result: 在WiFlow数据集上，无监督10-shot学习达到MAE仅0.44（监督基线失败）；泛化指数接近完美；在公共WiAR基准上达到98.8%准确率的新SOTA；适配器微调性能接近全微调(98.84% vs 99.67%)但参数减少97.2%。

Conclusion: 该工作为开发稳健的感知系统提供了实用且可扩展的解决方案，解决了WiFi CSI人群计数的领域迁移问题，通过自监督预训练和适配器微调实现了优异的跨领域泛化能力。

Abstract: Device-free crowd-counting using WiFi Channel State Information (CSI) is a key enabling technology for a new generation of privacy-preserving Internet of Things (IoT) applications. However, practical deployment is severely hampered by the domain shift problem, where models trained in one environment fail to generalise to another. To overcome this, we propose a novel two-stage framework centred on a CSI-ResNet-A architecture. This model is pre-trained via self-supervised contrastive learning to learn domain-invariant representations and leverages lightweight Adapter modules for highly efficient fine-tuning. The resulting event sequence is then processed by a stateful counting machine to produce a final, stable occupancy estimate. We validate our framework extensively. On our WiFlow dataset, our unsupervised approach excels in a 10-shot learning scenario, achieving a final Mean Absolute Error (MAE) of just 0.44--a task where supervised baselines fail. To formally quantify robustness, we introduce the Generalisation Index (GI), on which our model scores near-perfectly, confirming its ability to generalise. Furthermore, our framework sets a new state-of-the-art public WiAR benchmark with 98.8\% accuracy. Our ablation studies reveal the core strength of our design: adapter-based fine-tuning achieves performance within 1\% of a full fine-tune (98.84\% vs. 99.67\%) while training 97.2\% fewer parameters. Our work provides a practical and scalable solution for developing robust sensing systems ready for real-world IoT deployments.

</details>


### [184] [Noise-Aware and Dynamically Adaptive Federated Defense Framework for SAR Image Target Recognition](https://arxiv.org/abs/2601.00900)
*Yuchao Hou,Zixuan Zhang,Jie Wang,Wenke Huang,Lianhui Liang,Di Wu,Zhiquan Liu,Youliang Tian,Jianming Zhu,Jisheng Dang,Junhao Dong,Zhongliang Guo*

Main category: cs.CR

Relevance: 35.0

TL;DR: NADAFD是一个针对SAR图像目标识别的联邦学习防御框架，通过频域协作反演、噪声感知对抗训练和动态健康评估来抵御SAR特有的后门攻击。


<details>
  <summary>Details</summary>
Motivation: SAR图像目标识别通常依赖集中式训练，存在隐私和安全问题。联邦学习虽然能保护数据隐私，但面临恶意客户端利用SAR乘性斑点噪声隐藏后门触发的安全风险，需要专门针对SAR特性的防御方案。

Method: 提出NADAFD框架：1) 频域协作反演机制检测跨客户端频谱不一致性；2) 噪声感知对抗训练策略，将Γ分布斑点噪声特性嵌入掩码引导的对抗样本生成；3) 动态健康评估模块跟踪客户端更新行为并自适应调整聚合权重。

Result: 在MSTAR和OpenSARShip数据集上的实验表明，NADAFD在干净测试样本上获得更高准确率，在触发输入上获得更低的后门攻击成功率，优于现有的联邦后门防御方法。

Conclusion: NADAFD通过集成频域、空间域和客户端行为分析，有效应对SAR特有的后门威胁，为SAR图像目标识别的联邦学习提供了鲁棒的防御框架。

Abstract: As a critical application of computational intelligence in remote sensing, deep learning-based synthetic aperture radar (SAR) image target recognition facilitates intelligent perception but typically relies on centralized training, where multi-source SAR data are uploaded to a single server, raising privacy and security concerns. Federated learning (FL) provides an emerging computational intelligence paradigm for SAR image target recognition, enabling cross-site collaboration while preserving local data privacy. However, FL confronts critical security risks, where malicious clients can exploit SAR's multiplicative speckle noise to conceal backdoor triggers, severely challenging the robustness of the computational intelligence model. To address this challenge, we propose NADAFD, a noise-aware and dynamically adaptive federated defense framework that integrates frequency-domain, spatial-domain, and client-behavior analyses to counter SAR-specific backdoor threats. Specifically, we introduce a frequency-domain collaborative inversion mechanism to expose cross-client spectral inconsistencies indicative of hidden backdoor triggers. We further design a noise-aware adversarial training strategy that embeds $Γ$-distributed speckle characteristics into mask-guided adversarial sample generation to enhance robustness against both backdoor attacks and SAR speckle noise. In addition, we present a dynamic health assessment module that tracks client update behaviors across training rounds and adaptively adjusts aggregation weights to mitigate evolving malicious contributions. Experiments on MSTAR and OpenSARShip datasets demonstrate that NADAFD achieves higher accuracy on clean test samples and a lower backdoor attack success rate on triggered inputs than existing federated backdoor defenses for SAR target recognition.

</details>


### [185] [InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams](https://arxiv.org/abs/2601.02281)
*Shuai Yuan,Yantai Yang,Xiaotian Yang,Xupeng Zhang,Zhonghao Zhao,Lingming Zhang,Zhipeng Zhang*

Main category: cs.CV

Relevance: 35.0

TL;DR: InfiniteVGGT：首个因果视觉几何Transformer，通过有界自适应KV缓存实现无限时域流式3D几何理解，解决现有方法在可扩展性和长期稳定性之间的权衡问题，并引入Long3D基准进行严格评估。


<details>
  <summary>Details</summary>
Motivation: 大规模持久3D视觉几何理解面临可扩展性与长期稳定性的矛盾：离线模型（如VGGT）虽几何能力强但不适用于实时系统；现有流式架构要么不支持真正无限时域输入，要么在长序列上出现灾难性漂移。

Method: 提出因果视觉几何Transformer InfiniteVGGT，核心是滚动内存机制：通过有界自适应KV缓存实现持续表达，配合免训练、注意力无关的剪枝策略智能丢弃过时信息，每帧滚动更新内存，完全兼容FlashAttention。

Result: InfiniteVGGT在无限时域流式处理中超越现有流式方法，实现长期稳定性；同时创建Long3D基准（约10,000帧连续序列），首次为长期3D几何估计提供严格评估平台。

Conclusion: InfiniteVGGT解决了3D视觉几何理解中长期存在的可扩展性与稳定性权衡问题，通过滚动内存机制实现真正无限时域流式处理，为未来长期3D几何理解研究奠定基础。

Abstract: The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their batch-based nature renders them irrelevant for live systems. Streaming architectures, though the intended solution for live operation, have proven inadequate. Existing methods either fail to support truly infinite-horizon inputs or suffer from catastrophic drift over long sequences. We shatter this long-standing dilemma with InfiniteVGGT, a causal visual geometry transformer that operationalizes the concept of a rolling memory through a bounded yet adaptive and perpetually expressive KV cache. Capitalizing on this, we devise a training-free, attention-agnostic pruning strategy that intelligently discards obsolete information, effectively ``rolling'' the memory forward with each new frame. Fully compatible with FlashAttention, InfiniteVGGT finally alleviates the compromise, enabling infinite-horizon streaming while outperforming existing streaming methods in long-term stability. The ultimate test for such a system is its performance over a truly infinite horizon, a capability that has been impossible to rigorously validate due to the lack of extremely long-term, continuous benchmarks. To address this critical gap, we introduce the Long3D benchmark, which, for the first time, enables a rigorous evaluation of continuous 3D geometry estimation on sequences about 10,000 frames. This provides the definitive evaluation platform for future research in long-term 3D geometry understanding. Code is available at: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT

</details>


### [186] [Rank-based Geographical Regularization: Revisiting Contrastive Self-Supervised Learning for Multispectral Remote Sensing Imagery](https://arxiv.org/abs/2601.02289)
*Tom Burgert,Leonard Hackel,Paolo Rota,Begüm Demir*

Main category: cs.CV

Relevance: 35.0

TL;DR: GeoRank是一种用于多光谱遥感图像对比自监督学习的新型正则化方法，通过优化球面距离将地理关系嵌入特征空间，超越了现有整合地理元数据的方法。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在计算机视觉中表现出色，但应用于多光谱遥感图像面临独特挑战，因为数据具有地理和时间变异性。现有方法未能充分利用地理关系信息。

Method: 提出GeoRank正则化方法，直接优化球面距离将地理关系嵌入对比自监督学习的特征空间。同时系统研究了多光谱遥感图像对比自监督学习的关键适应性问题，包括数据增强效果、数据集规模和图像大小的影响、时间视图的任务依赖性。

Result: GeoRank在性能上优于或匹配现有整合地理元数据的方法，并能持续改进多种对比自监督学习算法（如BYOL、DINO）。

Conclusion: GeoRank为多光谱遥感图像的自监督学习提供了有效的正则化方法，通过显式建模地理关系提升了学习效果，同时系统分析了该领域的关键适应性问题。

Abstract: Self-supervised learning (SSL) has become a powerful paradigm for learning from large, unlabeled datasets, particularly in computer vision (CV). However, applying SSL to multispectral remote sensing (RS) images presents unique challenges and opportunities due to the geographical and temporal variability of the data. In this paper, we introduce GeoRank, a novel regularization method for contrastive SSL that improves upon prior techniques by directly optimizing spherical distances to embed geographical relationships into the learned feature space. GeoRank outperforms or matches prior methods that integrate geographical metadata and consistently improves diverse contrastive SSL algorithms (e.g., BYOL, DINO). Beyond this, we present a systematic investigation of key adaptations of contrastive SSL for multispectral RS images, including the effectiveness of data augmentations, the impact of dataset cardinality and image size on performance, and the task dependency of temporal views. Code is available at https://github.com/tomburgert/georank.

</details>


### [187] [BEDS: Bayesian Emergent Dissipative Structures](https://arxiv.org/abs/2601.02329)
*Laurent Caraffa*

Main category: cs.CV

Relevance: 35.0

TL;DR: BEDS框架统一非平衡热力学、贝叶斯推断、信息几何和机器学习，提出学习本质上是通过熵输出将通量转化为结构的过程，建立了热力学过程与贝叶斯更新的形式同构。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在建立一个统一的理论框架，将物理、生物和计算系统中的学习过程联系起来。基于普里高津的耗散结构理论，作者试图揭示学习的基本原理：可持续学习系统必须遵循耗散模式，其中结晶化的后验成为后续涌现层次的先验。

Method: 1. 建立热力学过程与贝叶斯更新的形式同构
2. 从最小公理推导基本数学常数(e, π, φ)作为贝叶斯推断的不动点
3. 提出哥德尔不完备性定理与热力学约束的猜想
4. 实现基于BEDS原则的点对点网络架构进行实践验证

Result: 1. 建立了热力学与贝叶斯推断的统一理论框架
2. 推导出基本数学常数作为贝叶斯推断的必然涌现
3. 提出的点对点网络架构相比现有分布式共识系统实现了六个数量级的能效提升
4. 实现了连续学习能力

Conclusion: BEDS框架连接了基础物理、数理逻辑和实际系统设计，为理解学习和计算的本质提供了理论洞见，并为可持续人工智能提供了具体路径。该工作表明学习系统必须遵循耗散模式才能持续发展。

Abstract: We present BEDS (Bayesian Emergent Dissipative Structures), a theoretical framework that unifies concepts from non-equilibrium thermodynamics, Bayesian inference, information geometry, and machine learning. The central thesis proposes that learning, across physical, biological, and computational systems, fundamentally constitutes the conversion of flux into structure through entropy export. Building on Prigogine's theory of dissipative structures, we establish a formal isomorphism between thermodynamic processes and Bayesian updating, demonstrating that sustainable learning systems must follow dissipative patterns where crystallized posteriors become priors for subsequent levels of emergence.
  We derive fundamental mathematical constants (e, π, φ) as fixed points of Bayesian inference under minimal axioms, suggesting these constants emerge necessarily from any system capable of representing and updating uncertainty. Furthermore, we propose a conjecture linking Gödel's incompleteness theorems to thermodynamic constraints, hypothesizing that pathologies of formal systems (incompleteness, undecidability) are structurally analogous to dissipation deficits in physical systems.
  As practical validation, we present a peer-to-peer network architecture implementing BEDS principles, achieving six orders of magnitude improvement in energy efficiency compared to existing distributed consensus systems while enabling continuous learning. This work bridges fundamental physics, mathematical logic, and practical system design, offering both theoretical insights into the nature of learning and computation, and a concrete pathway toward sustainable artificial intelligence.

</details>


### [188] [Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices](https://arxiv.org/abs/2601.02353)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出DACIS方法，结合神经网络剪枝和少样本学习，为边缘设备压缩植物病害检测模型，在保持92.3%准确率的同时减少78%模型大小，实现树莓派上的实时诊断。


<details>
  <summary>Details</summary>
Motivation: 偏远地区农民需要快速可靠的植物病害识别方法，但缺乏实验室或高性能计算资源。现有深度学习模型虽准确但计算量大，无法在低成本边缘设备上运行，且收集大量标注图像成本高昂。

Method: 提出DACIS（疾病感知通道重要性评分）方法，识别神经网络中对区分不同植物病害最重要的部分，集成到三阶段"剪枝-元学习-再剪枝"（PMP）流程中，结合神经网络剪枝和少样本学习。

Result: 在PlantVillage和PlantDoc数据集上实验显示，该方法减少模型大小78%，保持原始准确率的92.3%，压缩模型在树莓派4上达到7帧/秒的推理速度。

Conclusion: 该方法使实时田间诊断对小型农户变得实用，解决了边缘设备上的模型压缩和少样本学习问题，为资源受限环境提供了可行的植物病害检测方案。

Abstract: Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\% while maintaining 92.3\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.

</details>


### [189] [MetaFormer-driven Encoding Network for Robust Medical Semantic Segmentation](https://arxiv.org/abs/2601.00922)
*Le-Anh Tran,Chung Nguyen Tran,Nhan Cach Dang,Anh Le Van Quoc,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: eess.IV

Relevance: 35.0

TL;DR: MFEnNet是一个高效的医学图像分割框架，在U-Net编码阶段引入MetaFormer架构，使用池化Transformer块替代自注意力机制以降低计算成本，结合Swish激活和空间金字塔池化，在保持竞争力的分割精度同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割对疾病诊断和治疗规划至关重要，但现有先进模型通常采用复杂架构，在资源受限的临床环境中难以部署。需要开发高效且计算成本低的医学图像分割方法。

Method: 1. 在U-Net编码阶段引入MetaFormer架构，将图像块转换为序列进行全局上下文建模；2. 使用池化Transformer块替代传统Transformer模块，降低自注意力的计算成本；3. 采用Swish激活函数实现更平滑的梯度和更快收敛；4. 在瓶颈层加入空间金字塔池化以改进多尺度特征提取。

Result: 在多个医学分割基准测试中，MFEnNet达到了与最先进模型相当的精度，同时显著降低了计算成本。具体表现为在保持竞争力的分割性能的同时，计算复杂度大幅降低。

Conclusion: MFEnNet通过结合MetaFormer架构、池化Transformer块、Swish激活和空间金字塔池化，为资源受限的临床环境提供了一个高效且准确的医学图像分割解决方案，在计算效率和分割精度之间取得了良好平衡。

Abstract: Semantic segmentation is crucial for medical image analysis, enabling precise disease diagnosis and treatment planning. However, many advanced models employ complex architectures, limiting their use in resource-constrained clinical settings. This paper proposes MFEnNet, an efficient medical image segmentation framework that incorporates MetaFormer in the encoding phase of the U-Net backbone. MetaFormer, an architectural abstraction of vision transformers, provides a versatile alternative to convolutional neural networks by transforming tokenized image patches into sequences for global context modeling. To mitigate the substantial computational cost associated with self-attention, the proposed framework replaces conventional transformer modules with pooling transformer blocks, thereby achieving effective global feature aggregation at reduced complexity. In addition, Swish activation is used to achieve smoother gradients and faster convergence, while spatial pyramid pooling is incorporated at the bottleneck to improve multi-scale feature extraction. Comprehensive experiments on different medical segmentation benchmarks demonstrate that the proposed MFEnNet approach attains competitive accuracy while significantly lowering computational cost compared to state-of-the-art models. The source code for this work is available at https://github.com/tranleanh/mfennet.

</details>


### [190] [Uncertainty-Calibrated Explainable AI for Fetal Ultrasound Plane Classification](https://arxiv.org/abs/2601.00990)
*Olaf Yunus Laitinen Imanov*

Main category: eess.IV

Relevance: 35.0

TL;DR: 该论文提出了一个用于胎儿超声标准平面分类的不确定性校准可解释AI框架，结合了多种不确定性估计方法和可解释性技术，并建立了临床工作流程和评估协议。


<details>
  <summary>Details</summary>
Motivation: 胎儿超声标准平面分类对于可靠的产前生物测量和异常筛查至关重要，但在实际部署中受到领域偏移、图像噪声和预测概率校准不良的限制。需要建立一个既准确又可信的分类系统，在噪声采集条件下保持可靠。

Method: 综合了多种不确定性估计方法（蒙特卡洛dropout、深度集成、证据学习、共形预测）与事后和不确定性感知的解释技术（Grad-CAM变体、LIME风格局部代理、不确定性加权多分辨率激活图），并将这些组件映射到面向临床医生的工作流程中。使用FETAL_PLANES_DB作为基准，定义了结合准确性、校准性和选择性预测的报告协议。

Result: 提出了一个可重复的、临床对齐的蓝图，用于构建胎儿超声分类器，在噪声采集条件下保持置信度和解释的可信度。建立了包括预期校准误差、Brier分数、覆盖风险曲线和结构化错误分析在内的评估框架。

Conclusion: 该框架为构建在现实世界超声条件下保持可靠的不确定性校准可解释AI系统提供了实用方法，支持质量控制和人机协同审查，其中不确定性标志触发重新采集或专家确认。

Abstract: Fetal ultrasound standard-plane classification underpins reliable prenatal biometry and anomaly screening, yet real-world deployment is limited by domain shift, image noise, and poor calibration of predicted probabilities. This paper presents a practical framework for uncertainty-calibrated explainable AI in fetal plane classification. We synthesize uncertainty estimation methods (Monte Carlo dropout, deep ensembles, evidential learning, and conformal prediction) with post-hoc and uncertainty-aware explanations (Grad-CAM variants, LIME-style local surrogates, and uncertainty-weighted multi-resolution activation maps), and we map these components to a clinician-facing workflow. Using FETAL_PLANES_DB as a reference benchmark, we define a reporting protocol that couples accuracy with calibration and selective prediction, including expected calibration error, Brier score, coverage-risk curves, and structured error analysis with explanations. We also discuss integration points for quality control and human-in-the-loop review, where uncertainty flags trigger re-acquisition or expert confirmation. The goal is a reproducible, clinically aligned blueprint for building fetal ultrasound classifiers whose confidence and explanations remain trustworthy under noisy acquisition conditions.

</details>


### [191] [YODA: Yet Another One-step Diffusion-based Video Compressor](https://arxiv.org/abs/2601.01141)
*Xingchen Li,Junzhe Zhang,Junqi Shi,Ming Lu,Zhan Ma*

Main category: eess.IV

Relevance: 35.0

TL;DR: YODA是一种基于单步扩散模型的视频压缩方法，通过嵌入多尺度时间参考特征来利用时空相关性，使用线性扩散Transformer进行高效单步去噪，在感知指标上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有单步扩散模型在图像压缩中表现出色，但在视频压缩中应用有限。先前方法通常依赖预训练的2D自编码器，这些方法独立生成每帧的潜在表示，忽略了时间依赖性，导致无法充分利用时空相关性。

Method: YODA嵌入多尺度时间参考特征用于潜在生成和潜在编码，以更好地利用时空相关性实现更紧凑的表示。采用线性扩散Transformer（DiT）进行高效的单步去噪。

Result: 在LPIPS、DISTS、FID和KID等感知指标上达到最先进性能，一致优于传统和深度学习的基线方法。

Conclusion: YODA通过有效利用时空相关性和高效的扩散Transformer架构，在视频压缩的感知质量方面取得了显著进展。

Abstract: While one-step diffusion models have recently excelled in perceptual image compression, their application to video remains limited. Prior efforts typically rely on pretrained 2D autoencoders that generate per-frame latent representations independently, thereby neglecting temporal dependencies. We present YODA--Yet Another One-step Diffusion-based Video Compressor--which embeds multiscale features from temporal references for both latent generation and latent coding to better exploit spatial-temporal correlations for more compact representation, and employs a linear Diffusion Transformer (DiT) for efficient one-step denoising. YODA achieves state-of-the-art perceptual performance, consistently outperforming traditional and deep-learning baselines on LPIPS, DISTS, FID, and KID. Source code will be publicly available at https://github.com/NJUVISION/YODA.

</details>


### [192] [DisCo-FLoc: Using Dual-Level Visual-Geometric Contrasts to Disambiguate Depth-Aware Visual Floorplan Localization](https://arxiv.org/abs/2601.01822)
*Shiyong Meng,Tao Zou,Bolei Chen,Chaoxu Mu,Jianxin Wang*

Main category: cs.RO

Relevance: 35.0

TL;DR: DisCo-FLoc：一种无需额外语义标注的双层视觉-几何对比学习方法，通过深度感知特征与楼层平面图几何结构匹配来解决视觉楼层定位中的歧义问题


<details>
  <summary>Details</summary>
Motivation: 现有楼层定位方法存在两个主要问题：1) 极简楼层平面图中的重复结构导致定位歧义；2) 昂贵且有限的语义标注限制了应用范围。需要一种无需额外语义标签就能解决歧义问题的方法。

Method: 提出DisCo-FLoc方法：1) 针对基于光线投射的楼层定位设计光线回归预测器，利用深度估计专业知识预测一系列定位候选；2) 提出具有位置级和方向级约束的新型对比学习方法，严格匹配深度感知视觉特征与楼层平面图中的对应几何结构，从而消除歧义并选择最佳成像姿态。

Result: 在两个标准视觉楼层定位基准测试上的详尽比较研究表明，该方法优于最先进的基于语义的方法，在鲁棒性和准确性方面都有显著提升。

Conclusion: DisCo-FLoc通过双层视觉-几何对比学习有效解决了视觉楼层定位中的歧义问题，无需额外语义标注，在保持高精度的同时提升了方法的实用性。

Abstract: Since floorplan data is readily available, long-term persistent, and robust to changes in visual appearance, visual Floorplan Localization (FLoc) has garnered significant attention. Existing methods either ingeniously match geometric priors or utilize sparse semantics to reduce FLoc uncertainty. However, they still suffer from ambiguous FLoc caused by repetitive structures within minimalist floorplans. Moreover, expensive but limited semantic annotations restrict their applicability. To address these issues, we propose DisCo-FLoc, which utilizes dual-level visual-geometric Contrasts to Disambiguate depth-aware visual Floc, without requiring additional semantic labels. Our solution begins with a ray regression predictor tailored for ray-casting-based FLoc, predicting a series of FLoc candidates using depth estimation expertise. In addition, a novel contrastive learning method with position-level and orientation-level constraints is proposed to strictly match depth-aware visual features with the corresponding geometric structures in the floorplan. Such matches can effectively eliminate FLoc ambiguity and select the optimal imaging pose from FLoc candidates. Exhaustive comparative studies on two standard visual Floc benchmarks demonstrate that our method outperforms the state-of-the-art semantic-based method, achieving significant improvements in both robustness and accuracy.

</details>


### [193] [RFAssigner: A Generic Label Assignment Strategy for Dense Object Detection](https://arxiv.org/abs/2601.01240)
*Ziqian Guan,Xieyi Fu,Yuting Wang,Haowen Xiao,Jiarui Zhu,Yingying Zhu,Yongtao Liu,Lin Gu*

Main category: cs.CV

Relevance: 30.0

TL;DR: RFAssigner是一种新颖的标签分配策略，通过高斯感受野距离度量候选位置与真实物体之间的相似性，自适应选择补充正样本，解决密集目标检测器中尺度不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前密集目标检测器的标签分配策略通常为每个训练样本分配正负权重，但这些方法往往为小目标分配的正样本数量不足，导致训练过程中的尺度不平衡问题。

Method: RFAssigner首先使用基于点的先验建立初始正样本集，然后利用高斯感受野距离度量未分配候选位置与真实物体之间的相似性，基于此度量自适应地从未分配池中选择补充正样本。

Result: 在三个具有不同目标尺度分布的数据集上的综合实验验证了该方法的有效性和泛化能力。配备RFAssigner的单个FCOS-ResNet-50检测器在所有目标尺度上都达到了最先进的性能，一致优于现有策略，无需辅助模块或启发式方法。

Conclusion: RFAssigner通过改进标签分配策略，有效解决了密集目标检测中的尺度不平衡问题，提升了多尺度学习能力，为密集目标检测提供了更平衡的训练过程。

Abstract: Label assignment is a critical component in training dense object detectors. State-of-the-art methods typically assign each training sample a positive and a negative weight, optimizing the assignment scheme during training. However, these strategies often assign an insufficient number of positive samples to small objects, leading to a scale imbalance during training. To address this limitation, we introduce RFAssigner, a novel assignment strategy designed to enhance the multi-scale learning capabilities of dense detectors. RFAssigner first establishes an initial set of positive samples using a point-based prior. It then leverages a Gaussian Receptive Field (GRF) distance to measure the similarity between the GRFs of unassigned candidate locations and the ground-truth objects. Based on this metric, RFAssigner adaptively selects supplementary positive samples from the unassigned pool, promoting a more balanced learning process across object scales. Comprehensive experiments on three datasets with distinct object scale distributions validate the effectiveness and generalizability of our method. Notably, a single FCOS-ResNet-50 detector equipped with RFAssigner achieves state-of-the-art performance across all object scales, consistently outperforming existing strategies without requiring auxiliary modules or heuristics.

</details>


### [194] [ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking](https://arxiv.org/abs/2601.01386)
*Xiaobao Wei,Zhangjie Ye,Yuxiang Gu,Zunjie Zhu,Yunfei Guo,Yingying Shen,Shan Zhao,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Rongfeng Lu,Hangjun Ye*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了ParkRecon3D基准和ParkGaussian框架，首次将3D高斯溅射应用于停车场场景重建，通过槽位感知重建策略提升下游停车位检测任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注2D停车位感知、建图和定位，而3D重建在停车场景中研究不足。单纯提高重建视觉质量并不能直接帮助自动驾驶停车，因为停车的关键入口是停车位感知模块。

Method: 1) 创建ParkRecon3D基准，包含四个环视鱼眼相机的传感器数据和密集停车位标注；2) 提出ParkGaussian框架，首次将3D高斯溅射(3DGS)应用于停车场场景重建；3) 引入槽位感知重建策略，利用现有停车感知方法提升槽位区域的合成质量。

Result: 在ParkRecon3D上的实验表明，ParkGaussian实现了最先进的重建质量，并更好地保持了感知一致性以支持下游任务。

Conclusion: ParkRecon3D是首个专门针对停车场景重建的基准，ParkGaussian框架通过3D高斯溅射和槽位感知策略，有效提升了停车场景重建质量及其与下游感知任务的一致性。

Abstract: Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian

</details>


### [195] [MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement](https://arxiv.org/abs/2601.01749)
*Lei Zhu,Lijian Lin,Ye Zhu,Jiahao Wu,Xuehan Hou,Yu Li,Yunfei Liu,Jie Chen*

Main category: cs.CV

Relevance: 30.0

TL;DR: MANGO是一个两阶段框架，通过纯图像级监督生成3D对话头像，解决了现有方法依赖伪3D标签的问题，实现了更自然的听-说交互


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动的3D头部生成方法主要关注单说话人场景，缺乏自然的双向听-说交互。现有3D对话头像方法依赖误差较大的伪3D标签，无法捕捉细粒度面部动态

Method: 两阶段框架：第一阶段使用基于扩散的transformer和双音频交互模块从多说话人音频建模自然3D运动；第二阶段使用快速3D高斯渲染器生成高保真图像，通过交替训练为3D运动提供2D级光度监督

Result: 方法在建模两人3D对话运动方面实现了卓越的准确性和真实感，显著提升了音频驱动说话头部的保真度和可控性

Conclusion: MANGO通过纯图像级监督解决了伪3D标签的噪声问题，实现了更好的真实世界对话行为对齐，并贡献了高质量的MANGO-Dialog数据集

Abstract: Current audio-driven 3D head generation methods mainly focus on single-speaker scenarios, lacking natural, bidirectional listen-and-speak interaction. Achieving seamless conversational behavior, where speaking and listening states transition fluidly remains a key challenge. Existing 3D conversational avatar approaches rely on error-prone pseudo-3D labels that fail to capture fine-grained facial dynamics. To address these limitations, we introduce a novel two-stage framework MANGO, which leveraging pure image-level supervision by alternately training to mitigate the noise introduced by pseudo-3D labels, thereby achieving better alignment with real-world conversational behaviors. Specifically, in the first stage, a diffusion-based transformer with a dual-audio interaction module models natural 3D motion from multi-speaker audio. In the second stage, we use a fast 3D Gaussian Renderer to generate high-fidelity images and provide 2D-level photometric supervision for the 3D motions through alternate training. Additionally, we introduce MANGO-Dialog, a high-quality dataset with over 50 hours of aligned 2D-3D conversational data across 500+ identities. Extensive experiments demonstrate that our method achieves exceptional accuracy and realism in modeling two-person 3D dialogue motion, significantly advancing the fidelity and controllability of audio-driven talking heads.

</details>


### [196] [VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis](https://arxiv.org/abs/2601.01989)
*Aly R. Elkammar,Karim M. Gamaleldin,Catherine M. Elias*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文提出了一种基于Transformer/视频视觉Transformer的多模态行人意图预测算法，在JAAD数据集上实现了SOTA性能


<details>
  <summary>Details</summary>
Motivation: 行人意图预测是自动驾驶从L3向L4过渡的关键技术，需要综合考虑多种元素和特征来提高道路安全性

Method: 采用Transformer/视频视觉Transformer架构，设计不同规模的模型，利用多种数据模态进行行人意图预测

Result: 在JAAD数据集上达到SOTA性能，在准确率、AUC和F1分数等指标上超越了现有方法，并通过消融研究验证了不同设计选择的有效性

Conclusion: 基于Transformer的多模态方法在行人意图预测任务上表现出色，为自动驾驶安全提供了有效解决方案

Abstract: Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.

</details>


### [197] [360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images](https://arxiv.org/abs/2601.02102)
*Jiaqi Yao,Zhongmiao Yan,Jingyi Xu,Songpengcheng Xia,Yan Xiang,Ling Pei*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种用于360度图像的feed-forward 3D高斯泼溅框架，通过深度-法向几何正则化提高几何一致性，同时保持高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 传统多视角立体视觉在稀疏视角或低纹理区域效果不佳，神经渲染方法需要逐场景优化且缺乏实时性，而现有的feed-forward 3D高斯泼溅方法注重视觉质量但缺乏几何一致性，限制了在空间感知任务中的准确表面重建和可靠性。

Method: 提出新颖的feed-forward 3DGS框架，引入深度-法向几何正则化，将渲染深度梯度与法向信息耦合，监督高斯的旋转、尺度和位置，以提高点云和表面精度。

Result: 实验结果表明，该方法在保持高质量渲染的同时，显著提高了几何一致性，为空间感知任务中的3D重建提供了有效解决方案。

Conclusion: 该方法成功解决了3D高斯泼溅中几何一致性的问题，为AR、机器人和数字孪生等应用提供了更可靠的3D重建方案。

Abstract: 3D scene reconstruction is fundamental for spatial intelligence applications such as AR, robotics, and digital twins. Traditional multi-view stereo struggles with sparse viewpoints or low-texture regions, while neural rendering approaches, though capable of producing high-quality results, require per-scene optimization and lack real-time efficiency. Explicit 3D Gaussian Splatting (3DGS) enables efficient rendering, but most feed-forward variants focus on visual quality rather than geometric consistency, limiting accurate surface reconstruction and overall reliability in spatial perception tasks. This paper presents a novel feed-forward 3DGS framework for 360 images, capable of generating geometrically consistent Gaussian primitives while maintaining high rendering quality. A Depth-Normal geometric regularization is introduced to couple rendered depth gradients with normal information, supervising Gaussian rotation, scale, and position to improve point cloud and surface accuracy. Experimental results show that the proposed method maintains high rendering quality while significantly improving geometric consistency, providing an effective solution for 3D reconstruction in spatial perception tasks.

</details>


### [198] [Efficient Unrolled Networks for Large-Scale 3D Inverse Problems](https://arxiv.org/abs/2601.02141)
*Romain Vo,Julián Tachella*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出一种领域分割策略和正规算子近似方法，使得能够训练端到端重建模型，将任意大规模问题的前向算子纳入其架构中，在3D X射线锥束CT和3D多线圈加速MRI上达到SOTA性能，仅需单GPU进行训练和推理。


<details>
  <summary>Details</summary>
Motivation: 深度学习在成像逆问题中取得了革命性进展，但现有方法在处理大规模问题（如3D成像）时，由于全局前向算子所需内存过大，无法将成像算子纳入网络架构，阻碍了典型分块策略的应用。

Method: 提出领域分割策略和正规算子近似方法，通过将大问题分解为可管理的子问题，使端到端重建模型能够处理任意大规模的前向算子，同时保持计算效率。

Result: 在3D X射线锥束计算机断层扫描和3D多线圈加速磁共振成像上实现了最先进的性能，仅需单个GPU即可完成训练和推理，显著降低了计算资源需求。

Conclusion: 该方法成功解决了大规模成像逆问题中内存限制的挑战，为3D医学成像等大规模应用提供了高效、准确的深度学习解决方案。

Abstract: Deep learning-based methods have revolutionized the field of imaging inverse problems, yielding state-of-the-art performance across various imaging domains. The best performing networks incorporate the imaging operator within the network architecture, typically in the form of deep unrolling. However, in large-scale problems, such as 3D imaging, most existing methods fail to incorporate the operator in the architecture due to the prohibitive amount of memory required by global forward operators, which hinder typical patching strategies. In this work, we present a domain partitioning strategy and normal operator approximations that enable the training of end-to-end reconstruction models incorporating forward operators of arbitrarily large problems into their architecture. The proposed method achieves state-of-the-art performance on 3D X-ray cone-beam tomography and 3D multi-coil accelerated MRI, while requiring only a single GPU for both training and inference.

</details>


### [199] [DST-Calib: A Dual-Path, Self-Supervised, Target-Free LiDAR-Camera Extrinsic Calibration Network](https://arxiv.org/abs/2601.01188)
*Zhiwei Huang,Yanwei Fu,Yi Zhou,Xieyuanli Chen,Qijun Chen,Rui Fan*

Main category: cs.RO

Relevance: 30.0

TL;DR: 提出首个自监督的LiDAR-相机外参标定网络，无需特定标定目标，支持在线自适应校准，通过双面数据增强和差异图构建提升泛化能力和精度。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-相机外参标定方法依赖手工标定目标或特定静态场景，限制了在真实世界自主和机器人应用中的适应性和部署能力。传统单边数据增强策略导致泛化性能下降。

Method: 1) 提出双面数据增强技术，利用估计的深度图生成多视角相机视图；2) 设计双路径自监督标定框架，减少对高精度地面真值标签的依赖；3) 用差异图构建过程替代传统双分支特征提取，显式关联LiDAR和相机特征。

Result: 在五个公共基准数据集和自录数据集上的广泛实验表明，该方法在泛化能力方面显著优于现有方法，同时提高了标定精度并降低了模型复杂度。

Conclusion: 该方法首次实现了无需特定标定目标的自监督LiDAR-相机外参在线校准，通过创新的数据增强和特征关联策略解决了泛化问题，为机器人感知系统的多模态数据融合提供了更实用的解决方案。

Abstract: LiDAR-camera extrinsic calibration is essential for multi-modal data fusion in robotic perception systems. However, existing approaches typically rely on handcrafted calibration targets (e.g., checkerboards) or specific, static scene types, limiting their adaptability and deployment in real-world autonomous and robotic applications. This article presents the first self-supervised LiDAR-camera extrinsic calibration network that operates in an online fashion and eliminates the need for specific calibration targets. We first identify a significant generalization degradation problem in prior methods, caused by the conventional single-sided data augmentation strategy. To overcome this limitation, we propose a novel double-sided data augmentation technique that generates multi-perspective camera views using estimated depth maps, thereby enhancing robustness and diversity during training. Built upon this augmentation strategy, we design a dual-path, self-supervised calibration framework that reduces the dependence on high-precision ground truth labels and supports fully adaptive online calibration. Furthermore, to improve cross-modal feature association, we replace the traditional dual-branch feature extraction design with a difference map construction process that explicitly correlates LiDAR and camera features. This not only enhances calibration accuracy but also reduces model complexity. Extensive experiments conducted on five public benchmark datasets, as well as our own recorded dataset, demonstrate that the proposed method significantly outperforms existing approaches in terms of generalizability.

</details>


### [200] [Image Synthesis Using Spintronic Deep Convolutional Generative Adversarial Network](https://arxiv.org/abs/2601.01441)
*Saumya Gupta,Abhinandan,Venkatesh vadde,Bhaskaran Muralidharan,Abhishek Sharma*

Main category: physics.app-ph

Relevance: 30.0

TL;DR: 提出了一种混合CMOS-自旋电子学的深度卷积生成对抗网络架构，用于合成图像生成，通过自旋电子硬件实现卷积、反卷积和激活层，显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 生成对抗网络的计算需求超过了传统冯·诺依曼架构的限制，需要能效更高的替代方案，如神经形态自旋电子学。

Method: 设计混合CMOS-自旋电子DCGAN架构，将生成器的反卷积层重构为零填充卷积，使用6位斯格明子突触交叉阵列，采用混合CMOS畴壁ReLU和Leaky ReLU激活函数。

Result: 在Fashion MNIST数据集上获得FID 27.5，测试能耗4.9 nJ/图像，训练能耗14.97 nJ/图像；在Anime Face数据集上获得FID 45.4，测试能耗24.72 nJ/图像，训练能耗74.7 nJ/图像。

Conclusion: 提出的混合CMOS-自旋电子DCGAN架构在保持图像生成质量的同时显著降低了能耗，为神经形态计算提供了可行的硬件实现方案。

Abstract: The computational requirements of generative adversarial networks (GANs) exceed the limit of conventional Von Neumann architectures, necessitating energy efficient alternatives such as neuromorphic spintronics. This work presents a hybrid CMOS-spintronic deep convolutional generative adversarial network (DCGAN) architecture for synthetic image generation. The proposed generative vision model approach follows the standard framework, leveraging generator and discriminators adversarial training with our designed spintronics hardware for deconvolution, convolution, and activation layers of the DCGAN architecture. To enable hardware aware spintronic implementation, the generator's deconvolution layers are restructured as zero padded convolution, allowing seamless integration with a 6-bit skyrmion based synapse in a crossbar, without compromising training performance. Nonlinear activation functions are implemented using a hybrid CMOS domain wall based Rectified linear unit (ReLU) and Leaky ReLU units. Our proposed tunable Leaky ReLU employs domain wall position coded, continuous resistance states and a piecewise uniaxial parabolic anisotropy profile with a parallel MTJ readout, exhibiting energy consumption of 0.192 pJ. Our spintronic DCGAN model demonstrates adaptability across both grayscale and colored datasets, achieving Fr'echet Inception Distances (FID) of 27.5 for the Fashion MNIST and 45.4 for Anime Face datasets, with testing energy (training energy) of 4.9 nJ (14.97~nJ/image) and 24.72 nJ (74.7 nJ/image).

</details>


### [201] [Free Energy-Based Modeling of Emotional Dynamics in Video Advertisements](https://arxiv.org/abs/2601.00812)
*Takashi Ushio,Kazuhiro Onishi,Hideyoshi Yanagisawa*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该研究提出了一种基于自由能原理的可解释情感估计方法，仅从广告视频的场景级表达特征量化"愉悦度"、"惊喜"和"习惯化"，无需依赖生理信号或主观评分。


<details>
  <summary>Details</summary>
Motivation: 广告视频观看过程中的情感反应对理解媒体效果至关重要，但现有方法通常依赖外部信息（如生理信号或主观评分）。本研究旨在建立一种无需外部信息的可解释情感估计方法学基础。

Method: 基于自由能原理，从1059个15秒食品广告视频的场景级表达特征中，使用KL散度(KLD)捕捉预测误差（反映"愉悦度"）、贝叶斯惊喜(BS)捕捉信念更新（反映"惊喜"）、不确定性(UN)反映先验模糊性。分析了三种特征情感模式，并在9种超参数设置和6类日本广告视频上进行了鲁棒性和泛化测试。

Result: 实验表明：KLD与品牌呈现相关的"愉悦度"相关；BS捕捉由信息复杂性引起的"惊喜"；UN反映由元素类型和空间排列不确定性、以及呈现元素的变异性和数量驱动的"惊喜"。识别了三种特征情感模式：不确定刺激、持续高情感、瞬时峰值衰减。方法在超参数设置和不同视频类型上表现出稳定性和鲁棒性。

Conclusion: 该研究成功建立了基于自由能原理的可解释情感估计方法学基础，仅从视频表达特征就能量化情感维度，为创建更具吸引力的广告视频提供了技术支持。未来可通过整合更多表达元素和主观评分验证来扩展工作。

Abstract: Emotional responses during advertising video viewing are recognized as essential for understanding media effects because they have influenced attention, memory, and purchase intention. To establish a methodological basis for explainable emotion estimation without relying on external information such as physiological signals or subjective ratings, we have quantified "pleasantness," "surprise," and "habituation" solely from scene-level expression features of advertising videos, drawing on the free energy(FE) principle, which has provided a unified account of perception, learning, and behavior. In this framework, Kullback-Leibler divergence (KLD) has captured prediction error, Bayesian surprise (BS) has captured belief updates, and uncertainty (UN) has reflected prior ambiguity, and together they have formed the core components of FE. Using 1,059 15 s food video advertisements, the experiments have shown that KLD has reflected "pleasantness" associated with brand presentation, BS has captured "surprise" arising from informational complexity, and UN has reflected "surprise" driven by uncertainty in element types and spatial arrangements, as well as by the variability and quantity of presented elements. This study also identified three characteristic emotional patterns, namely uncertain stimulus, sustained high emotion, and momentary peak and decay, demonstrating the usefulness of the proposed method. Robustness across nine hyperparameter settings and generalization tests with six types of Japanese advertising videos (three genres and two durations) confirmed that these tendencies remained stable. This work can be extended by integrating a wider range of expression elements and validating the approach through subjective ratings, ultimately guiding the development of technologies that can support the creation of more engaging advertising videos.

</details>


### [202] [Pediatric Pneumonia Detection from Chest X-Rays:A Comparative Study of Transfer Learning and Custom CNNs](https://arxiv.org/abs/2601.00837)
*Agniv Roy Choudhury*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该研究比较了从头训练的CNN与迁移学习方法（ResNet50、DenseNet121、EfficientNet-B0）在小儿肺炎检测中的性能，发现微调的ResNet50达到近乎完美的准确率（99.43%）。


<details>
  <summary>Details</summary>
Motivation: 肺炎是五岁以下儿童的主要死因，每年导致超过70万人死亡。由于放射科医生资源有限且诊断存在主观差异，需要开发准确、自动化的肺炎检测系统来辅助诊断。

Method: 使用5,216张小儿胸部X光片数据集，按80/10/10划分训练/验证/测试集。比较了从头训练的CNN与三种预训练模型（ResNet50、DenseNet121、EfficientNet-B0）在两种策略下的性能：冻结主干网络和微调。使用准确率、F1分数和AUC进行评估，并通过Grad-CAM提供可解释性可视化。

Result: 微调的ResNet50表现最佳：99.43%准确率、99.61% F1分数和99.93% AUC，仅3例误分类。微调策略平均比冻结主干网络策略高5.5个百分点。Grad-CAM可视化确认模型关注临床相关的肺部区域。

Conclusion: 迁移学习结合微调在小儿肺炎检测中显著优于从头训练的CNN，达到近乎完美的准确率。该系统在资源有限的环境中具有作为筛查工具的潜力。未来工作应在多中心和成人数据集上验证这些发现。

Abstract: Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability.
  Objective: This study compares custom CNNs trained from scratch with transfer learning (ResNet50, DenseNet121, EfficientNet-B0) for pediatric pneumonia detection, evaluating frozen-backbone and fine-tuning regimes.
  Methods: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability.
  Results: Fine-tuned ResNet50 achieved the best performance: 99.43\% accuracy, 99.61\% F1-score, and 99.93\% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions.
  Conclusions: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets.
  Keywords: Pneumonia detection, deep learning, transfer learning, CNN, chest X-ray, pediatric diagnosis, ResNet, DenseNet, EfficientNet, Grad-CAM.

</details>


### [203] [Unified Review and Benchmark of Deep Segmentation Architectures for Cardiac Ultrasound on CAMUS](https://arxiv.org/abs/2601.00839)
*Zahid Ullah,Muhammad Hilal,Eunsoo Lee,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该研究结合心脏超声分割文献综述与三种主流架构（U-Net、Attention U-Net、TransUNet）在CAMUS数据集上的统一实验基准比较，评估不同预处理方法对分割性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有综述多总结心脏影像与深度学习进展，但缺乏统一可复现的实验基准。本研究旨在填补这一空白，通过标准化比较为心脏超声分割提供实用指导。

Method: 在CAMUS心脏超声数据集上，使用相同训练划分、损失函数和评估标准，系统比较U-Net、Attention U-Net和TransUNet三种架构。探索多种预处理路径：原生NIfTI数据、16位PNG导出、GPT辅助多边形伪标签、以及数千未标记帧的自监督预训练。

Result: 原生NIfTI训练的U-Net达到94%平均Dice分数，PNG-16位流程为91%。Attention U-Net在小区域和低对比度区域有改进，减少边界泄漏；TransUNet在挑战性帧上表现最强泛化能力，特别是自监督预训练初始化时。伪标签扩展训练集并提升鲁棒性。

Conclusion: 研究提供了三种架构在标准化CAMUS预处理下的统一基准，给出了保持超声数据强度保真度、分辨率一致性和对齐的实用指导，展望了可扩展自监督和新兴多模态GPT标注流程。

Abstract: Several review papers summarize cardiac imaging and DL advances, few works connect this overview to a unified and reproducible experimental benchmark. In this study, we combine a focused review of cardiac ultrasound segmentation literature with a controlled comparison of three influential architectures, U-Net, Attention U-Net, and TransUNet, on the Cardiac Acquisitions for Multi-Structure Ultrasound Segmentation (CAMUS) echocardiography dataset. Our benchmark spans multiple preprocessing routes, including native NIfTI volumes, 16-bit PNG exports, GPT-assisted polygon-based pseudo-labels, and self-supervised pretraining (SSL) on thousands of unlabeled cine frames. Using identical training splits, losses, and evaluation criteria, a plain U-Net achieved a 94% mean Dice when trained directly on NIfTI data (preserving native dynamic range), while the PNG-16-bit workflow reached 91% under similar conditions. Attention U-Net provided modest improvements on small or low-contrast regions, reducing boundary leakage, whereas TransUNet demonstrated the strongest generalization on challenging frames due to its ability to model global spatial context, particularly when initialized with SSL. Pseudo-labeling expanded the training set and improved robustness after confidence filtering. Overall, our contributions are threefold: a harmonized, apples-to-apples benchmark of U-Net, Attention U-Net, and TransUNet under standardized CAMUS preprocessing and evaluation; practical guidance on maintaining intensity fidelity, resolution consistency, and alignment when preparing ultrasound data; and an outlook on scalable self-supervision and emerging multimodal GPT-based annotation pipelines for rapid labeling, quality assurance, and targeted dataset curation.

</details>


### [204] [Clean-GS: Semantic Mask-Guided Pruning for 3D Gaussian Splatting](https://arxiv.org/abs/2601.00913)
*Subhankar Mishra*

Main category: cs.CV

Relevance: 25.0

TL;DR: Clean-GS：一种基于稀疏语义掩码去除3D高斯泼溅中背景杂波和浮动伪影的方法，能实现60-80%的模型压缩，同时保持渲染质量


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）虽然能生成高质量场景重建，但会产生大量散布在环境中的虚假高斯（浮动伪影）。这些伪影会遮挡感兴趣的对象并增大模型尺寸，阻碍在带宽受限应用中的部署。

Method: 提出Clean-GS方法，结合白名单空间过滤、颜色引导验证和基于邻居的离群点去除。使用少至3个分割掩码（1%的视图）的语义信息来识别和移除不属于目标对象的高斯。多阶段方法包括：(1)通过投影到掩码区域进行白名单过滤，(2)深度缓冲颜色验证，(3)基于邻居的离群点去除。

Result: 在Tanks and Temples数据集上的实验显示，Clean-GS能将文件大小从125MB减少到47MB，同时保持渲染质量，使3DGS模型适用于Web部署和AR/VR应用。

Conclusion: Clean-GS通过语义引导的过滤方法有效去除3DGS重建中的背景杂波和浮动伪影，显著压缩模型大小，为实际部署提供了实用解决方案。

Abstract: 3D Gaussian Splatting produces high-quality scene reconstructions but generates hundreds of thousands of spurious Gaussians (floaters) scattered throughout the environment. These artifacts obscure objects of interest and inflate model sizes, hindering deployment in bandwidth-constrained applications. We present Clean-GS, a method for removing background clutter and floaters from 3DGS reconstructions using sparse semantic masks. Our approach combines whitelist-based spatial filtering with color-guided validation and outlier removal to achieve 60-80\% model compression while preserving object quality. Unlike existing 3DGS pruning methods that rely on global importance metrics, Clean-GS uses semantic information from as few as 3 segmentation masks (1\% of views) to identify and remove Gaussians not belonging to the target object. Our multi-stage approach consisting of (1) whitelist filtering via projection to masked regions, (2) depth-buffered color validation, and (3) neighbor-based outlier removal isolates monuments and objects from complex outdoor scenes. Experiments on Tanks and Temples show that Clean-GS reduces file sizes from 125MB to 47MB while maintaining rendering quality, making 3DGS models practical for web deployment and AR/VR applications. Our code is available at https://github.com/smlab-niser/clean-gs

</details>


### [205] [Four-Stage Alzheimer's Disease Classification from MRI Using Topological Feature Extraction, Feature Selection, and Ensemble Learning](https://arxiv.org/abs/2601.00918)
*Faisal Ahmed*

Main category: cs.CV

Relevance: 25.0

TL;DR: TDA-Alz：一种基于拓扑数据分析（TDA）和集成学习的阿尔茨海默病严重程度分类框架，在OASIS-1 MRI数据集上达到98.19%准确率和99.75% AUC，优于深度学习方法，且计算高效、可解释性强。


<details>
  <summary>Details</summary>
Motivation: 从脑磁共振成像（MRI）准确高效地分类阿尔茨海默病（AD）严重程度是一个关键挑战，特别是在数据有限和模型可解释性方面。现有深度学习方法通常需要大量数据、计算资源和数据增强，且缺乏可解释性。

Method: 提出TDA-Alz框架，使用拓扑数据分析（TDA）提取脑MRI的拓扑描述符，捕捉内在结构模式，然后进行特征选择保留最具判别性的拓扑特征，最后采用集成学习策略进行四阶段（无痴呆、中度痴呆、轻度、极轻度）分类。

Result: 在OASIS-1 MRI数据集上达到98.19%准确率和99.75% AUC，优于或匹配基于深度学习的最新方法。无需数据增强、预训练网络或大规模计算资源，计算效率高且速度快。

Conclusion: TDA-Alz为基于MRI的阿尔茨海默病严重程度分类提供了一个强大、轻量级且可解释的深度学习替代方案，具有在现实世界临床决策支持系统中应用的强大潜力。

Abstract: Accurate and efficient classification of Alzheimer's disease (AD) severity from brain magnetic resonance imaging (MRI) remains a critical challenge, particularly when limited data and model interpretability are of concern. In this work, we propose TDA-Alz, a novel framework for four-stage Alzheimer's disease severity classification (non-demented, moderate dementia, mild, and very mild) using topological data analysis (TDA) and ensemble learning. Instead of relying on deep convolutional architectures or extensive data augmentation, our approach extracts topological descriptors that capture intrinsic structural patterns of brain MRI, followed by feature selection to retain the most discriminative topological features. These features are then classified using an ensemble learning strategy to achieve robust multiclass discrimination.
  Experiments conducted on the OASIS-1 MRI dataset demonstrate that the proposed method achieves an accuracy of 98.19% and an AUC of 99.75%, outperforming or matching state-of-the-art deep learning--based methods reported on OASIS and OASIS-derived datasets. Notably, the proposed framework does not require data augmentation, pretrained networks, or large-scale computational resources, making it computationally efficient and fast compared to deep neural network approaches. Furthermore, the use of topological descriptors provides greater interpretability, as the extracted features are directly linked to the underlying structural characteristics of brain MRI rather than opaque latent representations. These results indicate that TDA-Alz offers a powerful, lightweight, and interpretable alternative to deep learning models for MRI-based Alzheimer's disease severity classification, with strong potential for real-world clinical decision-support systems.

</details>


### [206] [Few-Shot Video Object Segmentation in X-Ray Angiography Using Local Matching and Spatio-Temporal Consistency Loss](https://arxiv.org/abs/2601.00988)
*Lin Xi,Yingliang Ma,Xiahai Zhuang*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种新的FSVOS模型，采用局部匹配策略限制搜索空间，通过方向采样实现动态可变采样区域，结合时空对比学习增强特征一致性，并在X射线血管造影视频上创建了新的多目标分割基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有视频分割方法存在效率问题：标准im2col实现效率低，硬件特定的CUDA内核（如可变形和邻域注意力）在非CUDA设备上可移植性有限。需要一种更灵活、高效且可移植的视频分割方法，特别是在医疗影像领域。

Method: 1) 采用局部匹配策略限制搜索空间到最相关的相邻像素；2) 通过方向采样视角重新组织局部采样过程，实现动态可变采样区域；3) 设计监督的时空对比学习方案增强跨帧特征一致性；4) 创建MOSXAV数据集用于X射线血管造影视频的多目标分割。

Result: 在CADICA、XACV和MOSXAV数据集上的实验表明，提出的FSVOS方法在分割精度和泛化能力（包括已见和未见类别）方面优于当前最先进的视频分割方法。

Conclusion: 该方法提供了增强的灵活性和潜力，适用于广泛的临床应用，特别是在医疗影像分析领域。

Abstract: We introduce a novel FSVOS model that employs a local matching strategy to restrict the search space to the most relevant neighboring pixels. Rather than relying on inefficient standard im2col-like implementations (e.g., spatial convolutions, depthwise convolutions and feature-shifting mechanisms) or hardware-specific CUDA kernels (e.g., deformable and neighborhood attention), which often suffer from limited portability across non-CUDA devices, we reorganize the local sampling process through a direction-based sampling perspective. Specifically, we implement a non-parametric sampling mechanism that enables dynamically varying sampling regions. This approach provides the flexibility to adapt to diverse spatial structures without the computational costs of parametric layers and the need for model retraining. To further enhance feature coherence across frames, we design a supervised spatio-temporal contrastive learning scheme that enforces consistency in feature representations. In addition, we introduce a publicly available benchmark dataset for multi-object segmentation in X-ray angiography videos (MOSXAV), featuring detailed, manually labeled segmentation ground truth. Extensive experiments on the CADICA, XACV, and MOSXAV datasets show that our proposed FSVOS method outperforms current state-of-the-art video segmentation methods in terms of segmentation accuracy and generalization capability (i.e., seen and unseen categories). This work offers enhanced flexibility and potential for a wide range of clinical applications.

</details>


### [207] [Decoupling Amplitude and Phase Attention in Frequency Domain for RGB-Event based Visual Object Tracking](https://arxiv.org/abs/2601.01022)
*Shiao Wang,Xiao Wang,Haonan Zhao,Jiarui Xu,Bo Jiang,Lin Zhu,Xin Zhao,Yonghong Tian,Jin Tang*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种新颖的RGB-Event视觉目标跟踪框架，通过在频域进行早期融合，利用事件相机的高动态范围和运动敏感特性，同时通过运动引导的空间稀疏化减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-Event跟踪方法主要依赖传统特征级融合，未能充分利用事件相机的独特优势。事件相机的高动态范围和运动敏感特性常被忽视，同时低信息区域被统一处理，导致主干网络不必要的计算开销。

Method: 1) 通过快速傅里叶变换将RGB和事件模态从空间域转换到频域，解耦振幅和相位分量；2) 通过振幅和相位注意力选择性融合高频事件信息到RGB模态；3) 运动引导的空间稀疏化模块利用事件相机的运动敏感特性捕获目标运动线索与空间概率分布的关系；4) 稀疏的目标相关特征输入主干网络学习，跟踪头预测最终目标位置。

Result: 在三个广泛使用的RGB-Event跟踪基准数据集（FE108、FELT、COESOT）上的大量实验证明了该方法的高性能和效率。

Conclusion: 提出的频域早期融合框架有效利用了事件相机的优势，同时通过稀疏化减少了计算开销，在RGB-Event跟踪任务上取得了优异性能。

Abstract: Existing RGB-Event visual object tracking approaches primarily rely on conventional feature-level fusion, failing to fully exploit the unique advantages of event cameras. In particular, the high dynamic range and motion-sensitive nature of event cameras are often overlooked, while low-information regions are processed uniformly, leading to unnecessary computational overhead for the backbone network. To address these issues, we propose a novel tracking framework that performs early fusion in the frequency domain, enabling effective aggregation of high-frequency information from the event modality. Specifically, RGB and event modalities are transformed from the spatial domain to the frequency domain via the Fast Fourier Transform, with their amplitude and phase components decoupled. High-frequency event information is selectively fused into RGB modality through amplitude and phase attention, enhancing feature representation while substantially reducing backbone computation. In addition, a motion-guided spatial sparsification module leverages the motion-sensitive nature of event cameras to capture the relationship between target motion cues and spatial probability distribution, filtering out low-information regions and enhancing target-relevant features. Finally, a sparse set of target-relevant features is fed into the backbone network for learning, and the tracking head predicts the final target position. Extensive experiments on three widely used RGB-Event tracking benchmark datasets, including FE108, FELT, and COESOT, demonstrate the high performance and efficiency of our method. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvTracking

</details>


### [208] [Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation](https://arxiv.org/abs/2601.01026)
*Douglas Costa Braga,Daniel Oliveira Dantas*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出一个可重复的深度学习流程用于白血病细胞分类，结合注意力机制和高效网络架构，在C-NMC 2019数据集上达到97.89%的F1分数和准确率，参数比VGG16少89%。


<details>
  <summary>Details</summary>
Motivation: 急性淋巴细胞白血病是最常见的儿童癌症，需要专家显微镜诊断，但存在观察者间变异性和时间限制的问题。需要自动化、可靠的白血病细胞分类系统来辅助临床诊断。

Method: 结合EfficientNetV2-B3与Squeeze-and-Excitation注意力机制的卷积神经网络，采用综合数据增强、焦点损失函数处理类别不平衡，以及按患者划分数据以确保评估的鲁棒性。

Result: 在C-NMC 2019数据集（12,528张图像，来自62名患者）上，测试集达到97.89%的F1分数和准确率，通过100次蒙特卡洛实验统计验证显著优于基线方法（p < 0.001），比现有方法提升高达4.67%，参数比VGG16少89%。

Conclusion: 现代基于注意力的架构可以改善白血病细胞分类，同时保持适合临床部署的计算效率，注意力机制提供了可解释的诊断相关细胞特征可视化。

Abstract: We present a reproducible deep learning pipeline for leukemic cell classification, focusing on system architecture, experimental robustness, and software design choices for medical image analysis. Acute lymphoblastic leukemia (ALL) is the most common childhood cancer, requiring expert microscopic diagnosis that suffers from inter-observer variability and time constraints. The proposed system integrates an attention-based convolutional neural network combining EfficientNetV2-B3 with Squeeze-and-Excitation mechanisms for automated ALL cell classification. Our approach employs comprehensive data augmentation, focal loss for class imbalance, and patient-wise data splitting to ensure robust and reproducible evaluation. On the C-NMC 2019 dataset (12,528 original images from 62 patients), the system achieves a 97.89% F1-score and 97.89% accuracy on the test set, with statistical validation through 100-iteration Monte Carlo experiments confirming significant improvements (p < 0.001) over baseline methods. The proposed pipeline outperforms existing approaches by up to 4.67% while using 89% fewer parameters than VGG16 (15.2M vs. 138M). The attention mechanism provides interpretable visualizations of diagnostically relevant cellular features, demonstrating that modern attention-based architectures can improve leukemic cell classification while maintaining computational efficiency suitable for clinical deployment.

</details>


### [209] [Enhancing Histopathological Image Classification via Integrated HOG and Deep Features with Robust Noise Performance](https://arxiv.org/abs/2601.01056)
*Ifeanyi Ezuma,Ugochukwu Ugwu*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该研究评估了机器学习和深度学习模型在LC25000组织病理学图像数据集上的分类性能，发现使用InceptionResNet-v2深度特征的模型表现最佳，在噪声环境下也表现出更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 数字病理学时代需要自动化的图像分析技术，本研究旨在评估不同机器学习方法在组织病理学图像分类任务上的性能，特别是在噪声环境下的鲁棒性。

Method: 使用LC25000数据集（包含5类组织病理学图像），采用微调的InceptionResNet-v2网络作为分类器和特征提取器。比较了不同模型在原始特征、深度特征以及HOG+深度特征组合上的性能，并在不同信噪比条件下测试模型鲁棒性。

Result: 微调的InceptionResNet-v2达到96.01%准确率和96.8%平均AUC。使用InceptionResNet-v2深度特征的模型表现更优，其中神经网络模型达到99.99% AUC和99.84%准确率。在噪声环境下，使用深度特征的模型（特别是GBM和KNN）表现出更强的鲁棒性。

Conclusion: 深度特征提取结合传统机器学习模型在组织病理学图像分类中表现出色，特别是在噪声环境下具有更好的鲁棒性，为临床实践中的自动化图像分析提供了有效解决方案。

Abstract: The era of digital pathology has advanced histopathological examinations, making automated image analysis essential in clinical practice. This study evaluates the classification performance of machine learning and deep learning models on the LC25000 dataset, which includes five classes of histopathological images. We used the fine-tuned InceptionResNet-v2 network both as a classifier and for feature extraction. Our results show that the fine-tuned InceptionResNet-v2 achieved a classification accuracy of 96.01\% and an average AUC of 96.8\%. Models trained on deep features from InceptionResNet-v2 outperformed those using only the pre-trained network, with the Neural Network model achieving an AUC of 99.99\% and accuracy of 99.84\%. Evaluating model robustness under varying SNR conditions revealed that models using deep features exhibited greater resilience, particularly GBM and KNN. The combination of HOG and deep features showed enhanced performance, however, less so in noisy environments.

</details>


### [210] [600k-ks-ocr: a large-scale synthetic dataset for optical character recognition in kashmiri script](https://arxiv.org/abs/2601.01088)
*Haq Nawaz Malik*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该技术报告介绍了600K-KS-OCR数据集，这是一个包含约60.2万个词级分割图像的大规模合成语料库，专门用于训练和评估针对克什米尔文字的光学字符识别系统。


<details>
  <summary>Details</summary>
Motivation: 解决克什米尔语（一种濒危的达尔德语，使用改良的波斯-阿拉伯文字系统，约有700万人使用）在OCR资源方面的严重短缺问题。克什米尔语作为低资源语言，缺乏足够的训练数据来开发有效的OCR系统。

Method: 数据集生成方法包括：使用三种传统克什米尔字体渲染图像（256x64像素），实施全面的数据增强模拟真实世界文档退化，添加多样化的背景纹理以增强模型鲁棒性。提供与CRNN、TrOCR和通用机器学习管道兼容的多种格式的真实标注转录。

Result: 创建了包含约60.2万个词级分割图像的大规模数据集，分布在10个分区存档中，总计约10.6 GB。数据集采用CC-BY-4.0许可证发布，便于低资源语言OCR研究。

Conclusion: 该数据集填补了克什米尔语OCR资源的空白，为开发针对这种濒危语言的OCR系统提供了重要训练和评估资源，有助于促进低资源语言的光学字符识别研究。

Abstract: This technical report presents the 600K-KS-OCR Dataset, a large-scale synthetic corpus comprising approximately 602,000 word-level segmented images designed for training and evaluating optical character recognition systems targeting Kashmiri script. The dataset addresses a critical resource gap for Kashmiri, an endangered Dardic language utilizing a modified Perso-Arabic writing system spoken by approximately seven million people. Each image is rendered at 256x64 pixels with corresponding ground-truth transcriptions provided in multiple formats compatible with CRNN, TrOCR, and generalpurpose machine learning pipelines. The generation methodology incorporates three traditional Kashmiri typefaces, comprehensive data augmentation simulating real-world document degradation, and diverse background textures to enhance model robustness. The dataset is distributed across ten partitioned archives totaling approximately 10.6 GB and is released under the CC-BY-4.0 license to facilitate research in low-resource language optical character recognition.

</details>


### [211] [Histogram Assisted Quality Aware Generative Model for Resolution Invariant NIR Image Colorization](https://arxiv.org/abs/2601.01103)
*Abhinav Attri,Rajeev Ranjan Dwivedi,Samiran Das,Vinod Kumar Kurmi*

Main category: cs.CV

Relevance: 25.0

TL;DR: HAQAGen是一个统一生成模型，用于分辨率不变的NIR-to-RGB着色，平衡色彩真实性和结构保真度，采用Mamba骨干网络和自适应分辨率推理引擎。


<details>
  <summary>Details</summary>
Motivation: 解决近红外到RGB图像转换中全局色彩统计与局部色彩一致性、纹理保真度与高分辨率扩展之间的平衡问题，提供可扩展的解决方案。

Method: 1) 组合损失函数：可微分直方图匹配、感知图像质量度量、特征相似度；2) 局部色调饱和度先验：通过SPADE注入；3) 纹理感知监督：在Mamba骨干网络中实现；4) 自适应分辨率推理引擎。

Result: 在FANVID、OMSIV、VCIP2020和RGB2NIR数据集上评估，相比现有方法有显著改进，产生更锐利的纹理和自然色彩，在感知指标上获得显著提升。

Conclusion: HAQAGen是一个可扩展且有效的NIR-to-RGB转换解决方案，能在不同成像场景中保持纹理保真度和泛化能力。

Abstract: We present HAQAGen, a unified generative model for resolution-invariant NIR-to-RGB colorization that balances chromatic realism with structural fidelity. The proposed model introduces (i) a combined loss term aligning the global color statistics through differentiable histogram matching, perceptual image quality measure, and feature based similarity to preserve texture information, (ii) local hue-saturation priors injected via Spatially Adaptive Denormalization (SPADE) to stabilize chromatic reconstruction, and (iii) texture-aware supervision within a Mamba backbone to preserve fine details. We introduce an adaptive-resolution inference engine that further enables high-resolution translation without sacrificing quality. Our proposed NIR-to-RGB translation model simultaneously enforces global color statistics and local chromatic consistency, while scaling to native resolutions without compromising texture fidelity or generalization. Extensive evaluations on FANVID, OMSIV, VCIP2020, and RGB2NIR using different evaluation metrics demonstrate consistent improvements over state-of-the-art baseline methods. HAQAGen produces images with sharper textures, natural colors, attaining significant gains as per perceptual metrics. These results position HAQAGen as a scalable and effective solution for NIR-to-RGB translation across diverse imaging scenarios. Project Page: https://rajeev-dw9.github.io/HAQAGen/

</details>


### [212] [MS-ISSM: Objective Quality Assessment of Point Clouds Using Multi-scale Implicit Structural Similarity](https://arxiv.org/abs/2601.01200)
*Zhang Chen,Shuai Wan,Yuezhe Zhang,Siyu Ren,Fuzheng Yang,Junhui Hou*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出MS-ISSM方法用于点云质量评估，通过径向基函数表示局部特征，避免不规则点云数据的匹配误差，结合ResGrouped-MLP网络实现多尺度特征差异到感知分数的映射。


<details>
  <summary>Details</summary>
Motivation: 点云数据的非结构化和不规则特性给客观质量评估带来挑战，特别是在建立准确的感知特征对应关系方面。传统点对点匹配方法在处理不规则数据时存在匹配误差问题。

Method: 1) MS-ISSM：使用径向基函数连续表示局部特征，将失真测量转化为隐函数系数比较；2) ResGrouped-MLP网络：采用分组编码策略，结合残差块和通道注意力机制，分层处理亮度、色度和几何特征，自适应关注高中低尺度的显著失真特征。

Result: 在多个基准测试中，MS-ISSM在可靠性和泛化能力方面均优于现有最先进的质量评估指标。

Conclusion: 提出的MS-ISSM方法通过隐式结构相似性测量有效解决了点云质量评估中的特征对应问题，ResGrouped-MLP网络能够鲁棒地映射多尺度特征差异到感知质量分数。

Abstract: The unstructured and irregular nature of point clouds poses a significant challenge for objective quality assessment (PCQA), particularly in establishing accurate perceptual feature correspondence. To tackle this, we propose the Multi-scale Implicit Structural Similarity Measurement (MS-ISSM). Unlike traditional point-to-point matching, MS-ISSM utilizes Radial Basis Functions (RBF) to represent local features continuously, transforming distortion measurement into a comparison of implicit function coefficients. This approach effectively circumvents matching errors inherent in irregular data. Additionally, we propose a ResGrouped-MLP quality assessment network, which robustly maps multi-scale feature differences to perceptual scores. The network architecture departs from traditional flat MLPs by adopting a grouped encoding strategy integrated with Residual Blocks and Channel-wise Attention mechanisms. This hierarchical design allows the model to preserve the distinct physical semantics of luma, chroma, and geometry while adaptively focusing on the most salient distortion features across High, Medium, and Low scales. Experimental results on multiple benchmarks demonstrate that MS-ISSM outperforms state-of-the-art metrics in both reliability and generalization. The source code is available at: https://github.com/ZhangChen2022/MS-ISSM.

</details>


### [213] [UniSH: Unifying Scene and Human Reconstruction in a Feed-Forward Pass](https://arxiv.org/abs/2601.01222)
*Mengfei Li,Peng Li,Zheng Zhang,Jiahao Lu,Chengfeng Zhao,Wei Xue,Qifeng Liu,Sida Peng,Wenxiao Zhang,Wenhan Luo,Yuan Liu,Yike Guo*

Main category: cs.CV

Relevance: 25.0

TL;DR: UniSH是一个统一的、前馈式的框架，用于联合进行度量尺度的3D场景和人体重建。该框架通过创新的训练范式，利用未标注的野外数据，解决了合成数据依赖导致的sim-to-real领域差距问题。


<details>
  <summary>Details</summary>
Motivation: 该领域面临的主要挑战是缺乏大规模标注的真实世界数据，导致依赖合成数据集，这引入了显著的sim-to-real领域差距，导致泛化能力差、人体几何保真度低以及在野外视频中对齐效果不佳。

Method: 提出了一种创新的训练范式，有效利用未标注的野外数据。框架结合了场景重建和人体姿态恢复（HMR）的强大先验，包含两个核心组件：(1) 鲁棒的蒸馏策略，从专家深度模型中提取高频细节以优化人体表面细节；(2) 两阶段监督方案，先在合成数据上学习粗略定位，然后在真实数据上通过直接优化SMPL网格与人体点云之间的几何对应关系进行微调。

Result: 该模型在单次前向传播中联合恢复高保真的场景几何、人体点云、相机参数和一致的度量尺度SMPL人体。大量实验表明，该模型在以人为中心的场景重建方面达到最先进性能，并在全局人体运动估计方面取得高度竞争力的结果，优于基于优化的框架和仅使用HMR的方法。

Conclusion: UniSH通过创新的训练范式有效解决了合成数据依赖问题，实现了高质量的联合3D场景和人体重建，在相关任务上取得了最先进的性能。

Abstract: We present UniSH, a unified, feed-forward framework for joint metric-scale 3D scene and human reconstruction. A key challenge in this domain is the scarcity of large-scale, annotated real-world data, forcing a reliance on synthetic datasets. This reliance introduces a significant sim-to-real domain gap, leading to poor generalization, low-fidelity human geometry, and poor alignment on in-the-wild videos. To address this, we propose an innovative training paradigm that effectively leverages unlabeled in-the-wild data. Our framework bridges strong, disparate priors from scene reconstruction and HMR, and is trained with two core components: (1) a robust distillation strategy to refine human surface details by distilling high-frequency details from an expert depth model, and (2) a two-stage supervision scheme, which first learns coarse localization on synthetic data, then fine-tunes on real data by directly optimizing the geometric correspondence between the SMPL mesh and the human point cloud. This approach enables our feed-forward model to jointly recover high-fidelity scene geometry, human point clouds, camera parameters, and coherent, metric-scale SMPL bodies, all in a single forward pass. Extensive experiments demonstrate that our model achieves state-of-the-art performance on human-centric scene reconstruction and delivers highly competitive results on global human motion estimation, comparing favorably against both optimization-based frameworks and HMR-only methods. Project page: https://murphylmf.github.io/UniSH/

</details>


### [214] [VReID-XFD: Video-based Person Re-identification at Extreme Far Distance Challenge Results](https://arxiv.org/abs/2601.01312)
*Kailash A. Hambarde,Hugo Proença,Md Rashidunnabi,Pranita Samale,Qiwei Yang,Pingping Zhang,Zijing Gong,Yuhao Wang,Xi Zhang,Ruoshui Qu,Qiaoyun He,Yuhang Zhang,Thi Ngoc Ha Nguyen,Tien-Dung Mai,Cheng-Jun Kang,Yu-Fan Lin,Jin-Hui Jiang,Chih-Chung Hsu,Tamás Endrei,György Cserey,Ashwat Rajbhandari*

Main category: cs.CV

Relevance: 25.0

TL;DR: VReID-XFD是一个用于极端远距离空中到地面行人重识别的视频基准测试，包含371个身份、11288个轨迹和1175万帧，覆盖5.8-120米高度、30-90度视角和120米水平距离，揭示了性能随距离和高度单调下降的规律。


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别系统基于外观假设，在极端远距离的空中到地面场景中面临严重分辨率退化、极端视角变化、不稳定运动线索和服装变化等挑战，需要专门的研究基准。

Method: 基于DetReIDX数据集构建VReID-XFD基准测试，包含严格的身份分离划分、丰富的物理元数据，并举办VReID-XFD-25挑战赛吸引10个团队参与。

Result: 系统分析显示：性能随高度和距离单调下降；天底视角普遍处于劣势；存在峰值性能与鲁棒性之间的权衡；最佳方法SAS-PReID在空对地设置中仅达到43.93% mAP。

Conclusion: 极端远距离空中到地面行人重识别是一个具有挑战性的新研究领域，现有方法性能有限，需要开发更鲁棒的算法来处理分辨率退化、视角变化等问题。

Abstract: Person re-identification (ReID) across aerial and ground views at extreme far distances introduces a distinct operating regime where severe resolution degradation, extreme viewpoint changes, unstable motion cues, and clothing variation jointly undermine the appearance-based assumptions of existing ReID systems. To study this regime, we introduce VReID-XFD, a video-based benchmark and community challenge for extreme far-distance (XFD) aerial-to-ground person re-identification. VReID-XFD is derived from the DetReIDX dataset and comprises 371 identities, 11,288 tracklets, and 11.75 million frames, captured across altitudes from 5.8 m to 120 m, viewing angles from oblique (30 degrees) to nadir (90 degrees), and horizontal distances up to 120 m. The benchmark supports aerial-to-aerial, aerial-to-ground, and ground-to-aerial evaluation under strict identity-disjoint splits, with rich physical metadata. The VReID-XFD-25 Challenge attracted 10 teams with hundreds of submissions. Systematic analysis reveals monotonic performance degradation with altitude and distance, a universal disadvantage of nadir views, and a trade-off between peak performance and robustness. Even the best-performing SAS-PReID method achieves only 43.93 percent mAP in the aerial-to-ground setting. The dataset, annotations, and official evaluation protocols are publicly available at https://www.it.ubi.pt/DetReIDX/ .

</details>


### [215] [Evaluation of Convolutional Neural Network For Image Classification with Agricultural and Urban Datasets](https://arxiv.org/abs/2601.01393)
*Shamik Shafkat Avro,Nazira Jesmin Lina,Shahanaz Sharmin*

Main category: cs.CV

Relevance: 25.0

TL;DR: 本文开发了一种自定义卷积神经网络（CustomCNN），通过残差连接、Squeeze-and-Excitation注意力机制、渐进通道缩放和Kaiming初始化等设计，研究架构选择对多领域图像分类任务的影响。


<details>
  <summary>Details</summary>
Motivation: 研究卷积神经网络架构设计选择如何影响多领域图像分类任务的性能，特别是在智慧城市和农业成像等实际应用中，需要高效且具有竞争力的模型。

Method: 设计自定义CNN架构，包含残差连接、Squeeze-and-Excitation注意力机制、渐进通道缩放和Kaiming初始化。在五个公开数据集上进行训练和测试：未经授权车辆检测、人行道侵占检测、多边形标注的道路损坏和井盖检测、MangoImageBD和PaddyVarietyBD。

Result: 与流行的CNN架构相比，CustomCNN在保持计算效率的同时提供了具有竞争力的性能，证明了精心设计的架构在实际应用中的重要性。

Conclusion: 深思熟虑的架构设计对于智慧城市和农业成像等实际应用至关重要，CustomCNN展示了在保持效率的同时实现竞争性能的可能性。

Abstract: This paper presents the development and evaluation of a custom Convolutional Neural Network (CustomCNN) created to study how architectural design choices affect multi-domain image classification tasks. The network uses residual connections, Squeeze-and-Excitation attention mechanisms, progressive channel scaling, and Kaiming initialization to improve its ability to represent data and speed up training. The model is trained and tested on five publicly available datasets: unauthorized vehicle detection, footpath encroachment detection, polygon-annotated road damage and manhole detection, MangoImageBD and PaddyVarietyBD. A comparison with popular CNN architectures shows that the CustomCNN delivers competitive performance while remaining efficient in computation. The results underscore the importance of thoughtful architectural design for real-world Smart City and agricultural imaging applications.

</details>


### [216] [Mask-Guided Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01408)
*Gong Gao,Zekai Wang,Jian Zhao,Ziqi Xie,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种用于人脸属性识别的掩码引导多任务网络（MGMTN），通过自适应掩码学习和组-全局特征融合来精确定位关键面部区域，减少全局特征冗余，提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统多任务属性识别方法依赖全局特征图进行特征提取和分类，会产生冗余特征并受到全局区域依赖的负面影响。需要更精确地定位关键面部区域以提高识别效率。

Method: 提出掩码引导多任务网络（MGMTN），包含自适应掩码学习（AML）和组-全局特征融合（G2FF）。AML利用预训练关键点标注模型和全卷积网络定位关键面部部位（如眼部和嘴部组），生成组掩码划分有意义的特征区域。G2FF结合组特征和全局特征增强人脸属性识别学习。

Result: 在两个具有挑战性的人脸属性识别数据集上进行广泛实验，证明了MGMTN在提升人脸属性识别性能方面的有效性。

Conclusion: MGMTN通过精确定位关键面部区域并融合组特征与全局特征，有效解决了传统方法中的特征冗余问题，提升了人脸属性识别的准确性和效率。

Abstract: Face Attribute Recognition (FAR) plays a crucial role in applications such as person re-identification, face retrieval, and face editing. Conventional multi-task attribute recognition methods often process the entire feature map for feature extraction and attribute classification, which can produce redundant features due to reliance on global regions. To address these challenges, we propose a novel approach emphasizing the selection of specific feature regions for efficient feature learning. We introduce the Mask-Guided Multi-Task Network (MGMTN), which integrates Adaptive Mask Learning (AML) and Group-Global Feature Fusion (G2FF) to address the aforementioned limitations. Leveraging a pre-trained keypoint annotation model and a fully convolutional network, AML accurately localizes critical facial parts (e.g., eye and mouth groups) and generates group masks that delineate meaningful feature regions, thereby mitigating negative transfer from global region usage. Furthermore, G2FF combines group and global features to enhance FAR learning, enabling more precise attribute identification. Extensive experiments on two challenging facial attribute recognition datasets demonstrate the effectiveness of MGMTN in improving FAR performance.

</details>


### [217] [EdgeNeRF: Edge-Guided Regularization for Neural Radiance Fields from Sparse Views](https://arxiv.org/abs/2601.01431)
*Weiqi Yu,Yiyang Yao,Lin He,Jianming Lv*

Main category: cs.CV

Relevance: 25.0

TL;DR: EdgeNeRF：一种边缘引导的稀疏视图3D重建算法，通过提取输入图像的边缘信息，在非边缘区域应用深度和法线正则化约束，在保持几何边界高频细节的同时减少伪影。


<details>
  <summary>Details</summary>
Motivation: NeRF在密集多视图场景中表现优异，但在稀疏输入下重建质量显著下降，出现几何伪影。现有方法使用全局深度正则化来缓解伪影，但会导致几何边界细节丢失。需要一种既能减少伪影又能保持边界细节的方法。

Method: 1. 利用深度和法线突变产生边缘的先验知识；2. 从输入图像中提取边缘；3. 在非边缘区域应用深度和法线正则化约束，增强几何一致性；4. 在边缘区域保持高频细节；5. 模块化设计，可即插即用到其他方法中。

Result: 在LLFF和DTU数据集上的实验表明，EdgeNeRF在保持尖锐几何边界和抑制伪影方面表现优异。边缘引导的深度正则化模块可以即插即用到其他方法中，显著提升性能而不明显增加训练时间。

Conclusion: EdgeNeRF通过边缘引导的正则化策略，有效解决了稀疏视图下NeRF的几何伪影问题，同时保持了边界细节。该方法具有通用性和可扩展性，可集成到现有方法中提升性能。

Abstract: Neural Radiance Fields (NeRF) achieve remarkable performance in dense multi-view scenarios, but their reconstruction quality degrades significantly under sparse inputs due to geometric artifacts. Existing methods utilize global depth regularization to mitigate artifacts, leading to the loss of geometric boundary details. To address this problem, we propose EdgeNeRF, an edge-guided sparse-view 3D reconstruction algorithm. Our method leverages the prior that abrupt changes in depth and normals generate edges. Specifically, we first extract edges from input images, then apply depth and normal regularization constraints to non-edge regions, enhancing geometric consistency while preserving high-frequency details at boundaries. Experiments on LLFF and DTU datasets demonstrate EdgeNeRF's superior performance, particularly in retaining sharp geometric boundaries and suppressing artifacts. Additionally, the proposed edge-guided depth regularization module can be seamlessly integrated into other methods in a plug-and-play manner, significantly improving their performance without substantially increasing training time. Code is available at https://github.com/skyhigh404/edgenerf.

</details>


### [218] [In defense of the two-stage framework for open-set domain adaptive semantic segmentation](https://arxiv.org/abs/2601.01439)
*Wenqi Ren,Weijie Wang,Meng Zheng,Ziyan Wu,Yang Tang,Zhun Zhong,Nicu Sebe*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出SATS方法，通过分离-适应两阶段训练策略解决开放集域自适应语义分割问题，相比单阶段方法显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有开放集域自适应语义分割方法采用单阶段统一处理已知和未知类别，但存在已知类别负迁移和未知类别欠拟合问题。作者质疑这种设计，认为需要更平衡的方法

Method: 提出SATS（分离-适应训练策略）：1）已知/未知分离阶段，2）未知感知域自适应阶段。还提出硬未知探索数据增强方法，增强模型对未知类别的理解能力

Result: 在公开基准测试中取得显著提升：GTA5-to-Cityscapes提升+3.85% H-Score，SYNTHIA-to-Cityscapes提升+18.64%，超越先前最优方法

Conclusion: 两阶段分离-适应策略能有效解决开放集域自适应语义分割中的不平衡问题，通过准确对齐未知类别实现更平衡的特征学习

Abstract: Open-Set Domain Adaptation for Semantic Segmentation (OSDA-SS) presents a significant challenge, as it requires both domain adaptation for known classes and the distinction of unknowns. Existing methods attempt to address both tasks within a single unified stage. We question this design, as the annotation imbalance between known and unknown classes often leads to negative transfer of known classes and underfitting for unknowns. To overcome these issues, we propose SATS, a Separating-then-Adapting Training Strategy, which addresses OSDA-SS through two sequential steps: known/unknown separation and unknown-aware domain adaptation. By providing the model with more accurate and well-aligned unknown classes, our method ensures a balanced learning of discriminative features for both known and unknown classes, steering the model toward discovering truly unknown objects. Additionally, we present hard unknown exploration, an innovative data augmentation method that exposes the model to more challenging unknowns, strengthening its ability to capture more comprehensive understanding of target unknowns. We evaluate our method on public OSDA-SS benchmarks. Experimental results demonstrate that our method achieves a substantial advancement, with a +3.85% H-Score improvement for GTA5-to-Cityscapes and +18.64% for SYNTHIA-to-Cityscapes, outperforming previous state-of-the-art methods.

</details>


### [219] [Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network](https://arxiv.org/abs/2601.01460)
*Mohd Usama,Belal Ahmad,Christer Gronlund,Faleh Menawer R Althiyabi*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出基于GAN的医学超声图像域适应方法，通过图像到图像转换调整纹理模式并去除混响噪声，解决不同设备间数据分布差异问题。


<details>
  <summary>Details</summary>
Motivation: 医学影像中，不同设备或参数设置产生的图像存在纹理和噪声差异，导致模型在跨设备应用时性能下降。为每个设备重新训练模型成本高昂，需要一种有效的域适应方法。

Method: 将域适应任务构建为图像到图像转换问题，使用生成对抗网络(GAN)模型，在保持图像内容不变的前提下，调整源域图像的纹理模式以匹配目标域，并去除混响噪声。

Result: 在包含三个不同域的颈动脉超声图像数据集上，模型成功转换了图像纹理模式并去除了混响噪声。与无适应方法相比，提出的模型在直方图相关性(0.960 vs 0.916)和巴氏距离(0.040 vs 0.090)等指标上表现显著更好。

Conclusion: 提出的GAN-based域适应方法能有效解决医学超声图像中的跨设备分布差异问题，为医学影像分析提供了实用的域适应解决方案。

Abstract: Deep learning has been extensively used in medical imaging applications, assuming that the test and training datasets belong to the same probability distribution. However, a common challenge arises when working with medical images generated by different systems or even the same system with different parameter settings. Such images contain diverse textures and reverberation noise that violate the aforementioned assumption. Consequently, models trained on data from one device or setting often struggle to perform effectively with data from other devices or settings. In addition, retraining models for each specific device or setting is labor-intensive and costly. To address these issues in ultrasound images, we propose a novel Generative Adversarial Network (GAN)-based model. We formulated the domain adaptation tasks as an image-to-image translation task, in which we modified the texture patterns and removed reverberation noise in the test data images from the source domain to align with those in the target domain images while keeping the image content unchanged. We applied the proposed method to two datasets containing carotid ultrasound images from three different domains. The experimental results demonstrate that the model successfully translated the texture pattern of images and removed reverberation noise from the ultrasound images. Furthermore, we evaluated the CycleGAN approaches for a comparative study with the proposed model. The experimental findings conclusively demonstrated that the proposed model achieved domain adaptation (histogram correlation (0.960 (0.019), & 0.920 (0.043) and bhattacharya distance (0.040 (0.020), & 0.085 (0.048)), compared to no adaptation (0.916 (0.062) & 0.890 (0.077), 0.090 (0.070) & 0.121 (0.095)) for both datasets.

</details>


### [220] [DiffKD-DCIS: Predicting Upgrade of Ductal Carcinoma In Situ with Diffusion Augmentation and Knowledge Distillation](https://arxiv.org/abs/2601.01507)
*Tao Li,Qing Li,Na Li,Hui Xie*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出DiffKD-DCIS框架，结合条件扩散模型和知识蒸馏，用于预测乳腺导管原位癌升级为浸润性导管癌，解决超声数据有限和泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 准确预测乳腺导管原位癌(DCIS)升级为浸润性导管癌(IDC)对手术规划至关重要，但传统深度学习方法面临超声数据有限和泛化能力差的挑战。

Method: 三阶段框架：1) 条件扩散模型生成高质量超声图像进行数据增强；2) 深度教师网络从原始和合成数据中提取鲁棒特征；3) 紧凑学生网络通过知识蒸馏从教师网络学习，平衡泛化能力和计算效率。

Result: 在1,435例多中心数据集上评估，合成图像质量良好。学生网络参数更少、推理更快。在外部测试集上优于部分组合，准确率与资深放射科医生相当，优于初级医生，显示显著临床潜力。

Conclusion: DiffKD-DCIS框架通过条件扩散模型和知识蒸馏，有效解决了医学影像数据有限和模型泛化问题，在DCIS升级预测中表现出色，具有重要临床应用价值。

Abstract: Accurately predicting the upgrade of ductal carcinoma in situ (DCIS) to invasive ductal carcinoma (IDC) is crucial for surgical planning. However, traditional deep learning methods face challenges due to limited ultrasound data and poor generalization ability. This study proposes the DiffKD-DCIS framework, integrating conditional diffusion modeling with teacher-student knowledge distillation.
  The framework operates in three stages: First, a conditional diffusion model generates high-fidelity ultrasound images using multimodal conditions for data augmentation. Then, a deep teacher network extracts robust features from both original and synthetic data. Finally, a compact student network learns from the teacher via knowledge distillation, balancing generalization and computational efficiency.
  Evaluated on a multi-center dataset of 1,435 cases, the synthetic images were of good quality. The student network had fewer parameters and faster inference. On external test sets, it outperformed partial combinations, and its accuracy was comparable to senior radiologists and superior to junior ones, showing significant clinical potential.

</details>


### [221] [An Empirical Study of Monocular Human Body Measurement Under Weak Calibration](https://arxiv.org/abs/2601.01639)
*Gaurav Sekar*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该论文系统评估了三种弱标定单目RGB图像人体测量方法：基于地标的几何法、姿态驱动回归法和物体标定轮廓法，分析了不同标定假设对测量稳定性、鲁棒性和失败模式的影响，为消费级设备上的轻量级人体测量系统提供设计参考。


<details>
  <summary>Details</summary>
Motivation: 从单目RGB图像估计人体尺寸存在尺度模糊、视角敏感和缺乏深度信息等挑战。本研究旨在系统评估三种弱标定方法在不同标定假设下的表现，而非追求最先进精度，为消费级设备上的轻量级人体测量系统提供设计指导。

Method: 采用三种弱标定单目策略：1) 基于地标的几何方法，2) 姿态驱动回归方法，3) 物体标定轮廓方法。在消费级相机半约束条件下进行系统实证研究，分析不同标定假设对测量行为、鲁棒性和失败模式的影响。

Result: 研究结果显示，用户在校准过程中的努力程度与所得周长测量量的稳定性之间存在明确的权衡关系。不同方法在不同体型上的表现存在差异，揭示了各种方法的优势和局限性。

Conclusion: 该研究为消费级设备上部署的轻量级单目人体测量系统提供了实证设计参考，强调了校准假设对测量性能的关键影响，为实际应用中的方法选择提供了指导。

Abstract: Estimating human body measurements from monocular RGB imagery remains challenging due to scale ambiguity, viewpoint sensitivity, and the absence of explicit depth information. This work presents a systematic empirical study of three weakly calibrated monocular strategies: landmark-based geometry, pose-driven regression, and object-calibrated silhouettes, evaluated under semi-constrained conditions using consumer-grade cameras. Rather than pursuing state-of-the-art accuracy, the study analyzes how differing calibration assumptions influence measurement behavior, robustness, and failure modes across varied body types. The results reveal a clear trade-off between user effort during calibration and the stability of resulting circumferential quantities. This paper serves as an empirical design reference for lightweight monocular human measurement systems intended for deployment on consumer devices.

</details>


### [222] [LabelAny3D: Label Any Object 3D in the Wild](https://arxiv.org/abs/2601.01676)
*Jin Yao,Radowan Mahmud Redoy,Sebastian Elbaum,Matthew B. Dwyer,Zezhou Cheng*

Main category: cs.CV

Relevance: 25.0

TL;DR: LabelAny3D：基于分析-合成的框架，从2D图像重建整体3D场景以生成高质量3D边界框标注；基于此构建COCO3D基准，用于开放词汇单目3D检测


<details>
  <summary>Details</summary>
Motivation: 现有单目3D检测模型在真实世界图像中表现不佳，主要原因是缺乏真实世界的3D数据集和3D标注的挑战性。需要一种高效生成高质量3D标注的方法来扩展3D识别在开放世界场景中的应用。

Method: 提出LabelAny3D框架，采用分析-合成方法从2D图像重建整体3D场景，从而高效生成高质量的3D边界框标注。基于此流程构建了COCO3D基准，源自MS-COCO数据集，覆盖了现有3D数据集中缺失的广泛对象类别。

Result: 实验表明，LabelAny3D生成的标注在多个基准上提升了单目3D检测性能，在质量上优于先前的自动标注方法。这证明了基础模型驱动的标注在扩展真实开放世界场景中3D识别的潜力。

Conclusion: LabelAny3D框架和COCO3D基准为解决真实世界单目3D检测的标注瓶颈提供了有效方案，展示了基础模型在3D场景理解和标注生成方面的强大能力。

Abstract: Detecting objects in 3D space from monocular input is crucial for applications ranging from robotics to scene understanding. Despite advanced performance in the indoor and autonomous driving domains, existing monocular 3D detection models struggle with in-the-wild images due to the lack of 3D in-the-wild datasets and the challenges of 3D annotation. We introduce LabelAny3D, an \emph{analysis-by-synthesis} framework that reconstructs holistic 3D scenes from 2D images to efficiently produce high-quality 3D bounding box annotations. Built on this pipeline, we present COCO3D, a new benchmark for open-vocabulary monocular 3D detection, derived from the MS-COCO dataset and covering a wide range of object categories absent from existing 3D datasets. Experiments show that annotations generated by LabelAny3D improve monocular 3D detection performance across multiple benchmarks, outperforming prior auto-labeling approaches in quality. These results demonstrate the promise of foundation-model-driven annotation for scaling up 3D recognition in realistic, open-world settings.

</details>


### [223] [Evaluating Deep Learning-Based Face Recognition for Infants and Toddlers: Impact of Age Across Developmental Stages](https://arxiv.org/abs/2601.01680)
*Afzal Hossain,Mst Rumana Sumi,Stephanie Schuckers*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该研究评估了四种深度学习人脸识别模型在婴幼儿纵向数据集上的性能，发现婴幼儿早期识别准确率低（0-6个月仅30.7% TAR），随年龄增长显著提升（2.5-3岁达64.7% TAR），并采用DANN方法减少时间漂移，提升识别稳定性。


<details>
  <summary>Details</summary>
Motivation: 婴幼儿人脸识别面临独特挑战：面部形态快速变化、类间相似度高、数据集有限。研究旨在评估现有深度学习模型在婴幼儿纵向数据上的性能，为智慧城市应用（如公共医疗、儿童安全、数字身份服务）中可靠的生物识别系统提供基础。

Method: 1) 使用新开发的婴幼儿纵向数据集（0-3岁儿童，7个时间点，24个月追踪）；2) 评估四种深度学习人脸识别模型：FaceNet、ArcFace、MagFace、CosFace；3) 分析不同发育阶段识别准确率；4) 评估不同时间间隔的验证性能；5) 应用领域对抗神经网络（DANN）减少嵌入漂移。

Result: 1) 婴幼儿早期识别准确率低：0-6个月TAR仅30.7%（FAR=0.1%）；2) 随年龄增长显著提升：2.5-3岁TAR达64.7%；3) 时间间隔越短，准确率越高（嵌入漂移减少）；4) DANN方法提升TAR超过12%，特征更稳定、泛化性更强。

Conclusion: 婴幼儿人脸识别性能随年龄增长显著改善，但早期阶段仍具挑战。时间漂移是主要问题，DANN能有效缓解。研究强调了在智慧城市应用中开发能处理时间变化的隐私保护生物认证系统的重要性，特别是在儿童验证关键的安全监管城市环境中。

Abstract: Face recognition for infants and toddlers presents unique challenges due to rapid facial morphology changes, high inter-class similarity, and limited dataset availability. This study evaluates the performance of four deep learning-based face recognition models FaceNet, ArcFace, MagFace, and CosFace on a newly developed longitudinal dataset collected over a 24 month period in seven sessions involving children aged 0 to 3 years. Our analysis examines recognition accuracy across developmental stages, showing that the True Accept Rate (TAR) is only 30.7% at 0.1% False Accept Rate (FAR) for infants aged 0 to 6 months, due to unstable facial features. Performance improves significantly in older children, reaching 64.7% TAR at 0.1% FAR in the 2.5 to 3 year age group. We also evaluate verification performance over different time intervals, revealing that shorter time gaps result in higher accuracy due to reduced embedding drift. To mitigate this drift, we apply a Domain Adversarial Neural Network (DANN) approach that improves TAR by over 12%, yielding features that are more temporally stable and generalizable. These findings are critical for building biometric systems that function reliably over time in smart city applications such as public healthcare, child safety, and digital identity services. The challenges observed in early age groups highlight the importance of future research on privacy preserving biometric authentication systems that can address temporal variability, particularly in secure and regulated urban environments where child verification is essential.

</details>


### [224] [RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images](https://arxiv.org/abs/2601.01835)
*Rashid Iqbal,Saddam Hussain Khan*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种名为RSwinV2的深度学习模型，用于Mpox（猴痘）诊断，通过定制化的残差SwinTransformerV2架构提升皮肤病变分类能力，在Kaggle数据集上达到96.21%准确率和95.62% F1分数。


<details>
  <summary>Details</summary>
Motivation: Mpox（猴痘）诊断需要准确区分与其他类似疾病（如鸡痘、麻疹、牛痘）的皮肤病变。现有CNN模型和标准SwinTransformer在全局-局部特征关联和梯度消失问题上存在局限，需要更有效的计算机辅助诊断工具。

Method: 1. 基于SwinTransformerV2定制分层Transformer架构，考虑输入维度、嵌入结构和输出目标
2. 将输入图像分割为不重叠的补丁，使用移位窗口注意力机制处理，解决非重叠区域局部性问题
3. 引入补丁嵌入和位置嵌入，利用多头注意力实现全局关联
4. 集成逆残差块（IRB），使用卷积跳跃连接解决梯度消失问题
5. 结合全局模式和局部模式关联，增强病变分类能力

Result: 在Kaggle公共数据集上：
- 准确率：96.21%
- F1分数：95.62%
- 优于标准CNN模型和SwinTransformer
- 有效区分Mpox、鸡痘、麻疹、牛痘的病变特征

Conclusion: RSwinV2通过定制化的Transformer架构和逆残差块设计，成功解决了Mpox诊断中的全局-局部特征关联和梯度消失问题，证明了其作为计算机辅助Mpox病变观察解释工具的有效性。

Abstract: In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.

</details>


### [225] [ESGaussianFace: Emotional and Stylized Audio-Driven Facial Animation via 3D Gaussian Splatting](https://arxiv.org/abs/2601.01847)
*Chuhang Ma,Shuai Tan,Ye Pan,Jiaolong Yang,Xin Tong*

Main category: cs.CV

Relevance: 25.0

TL;DR: ESGaussianFace：基于3D高斯泼溅的情感化风格化音频驱动面部动画框架，通过情感-音频引导的空间注意力机制和3D高斯变形预测器，实现高效高质量的情感风格化面部视频生成。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动面部动画研究主要关注中性情感视频生成，虽然已有研究处理情感音频驱动，但高效生成同时包含情感表达和风格特征的高质量说话头部视频仍具挑战性。

Method: 1) 使用3D高斯泼溅进行3D场景重建和视频渲染；2) 提出情感-音频引导的空间注意力机制，融合情感特征与音频内容特征；3) 引入两个3D高斯变形预测器实现情感和风格变形；4) 采用多阶段训练策略逐步学习唇部运动、情感变化和风格特征。

Result: 实验结果表明，该方法在唇部运动准确性、表情变化和风格特征表现力方面优于现有最先进技术，生成结果具有高效率、高质量和3D一致性。

Conclusion: ESGaussianFace能够高效生成高质量、3D一致的情感化风格化音频驱动面部动画，在多个评估维度上超越现有方法。

Abstract: Most current audio-driven facial animation research primarily focuses on generating videos with neutral emotions. While some studies have addressed the generation of facial videos driven by emotional audio, efficiently generating high-quality talking head videos that integrate both emotional expressions and style features remains a significant challenge. In this paper, we propose ESGaussianFace, an innovative framework for emotional and stylized audio-driven facial animation. Our approach leverages 3D Gaussian Splatting to reconstruct 3D scenes and render videos, ensuring efficient generation of 3D consistent results. We propose an emotion-audio-guided spatial attention method that effectively integrates emotion features with audio content features. Through emotion-guided attention, the model is able to reconstruct facial details across different emotional states more accurately. To achieve emotional and stylized deformations of the 3D Gaussian points through emotion and style features, we introduce two 3D Gaussian deformation predictors. Futhermore, we propose a multi-stage training strategy, enabling the step-by-step learning of the character's lip movements, emotional variations, and style features. Our generated results exhibit high efficiency, high quality, and 3D consistency. Extensive experimental results demonstrate that our method outperforms existing state-of-the-art techniques in terms of lip movement accuracy, expression variation, and style feature expressiveness.

</details>


### [226] [Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection](https://arxiv.org/abs/2601.01908)
*Jingjing Wang,Qianglin Liu,Zhuo Xiao,Xinning Yao,Bo Liu,Lu Li,Lijuan Niu,Fugen Zhou*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出Nodule-DETR，一种基于检测Transformer的甲状腺结节检测架构，通过多光谱频域通道注意力、分层特征融合和多尺度可变形注意力模块，在超声图像中实现鲁棒的结节检测。


<details>
  <summary>Details</summary>
Motivation: 甲状腺癌是最常见的内分泌恶性肿瘤，发病率持续上升。超声是检测甲状腺结节的首选成像方式，但其诊断准确性常受图像对比度低、结节边界模糊等挑战限制。

Method: 提出Nodule-DETR检测Transformer架构，包含三个关键创新：1) 多光谱频域通道注意力模块，利用频域分析增强低对比度结节特征；2) 分层特征融合模块，实现高效多尺度特征集成；3) 多尺度可变形注意力模块，灵活捕捉小而不规则形状的结节。

Result: 在真实世界甲状腺超声图像临床数据集上的实验表明，Nodule-DETR达到最先进性能，在mAP@0.5:0.95指标上显著优于基线模型0.149。

Conclusion: Nodule-DETR的优越准确性突显了其作为计算机辅助甲状腺诊断有效工具在临床应用中的巨大潜力。

Abstract: Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.

</details>


### [227] [API: Empowering Generalizable Real-World Image Dehazing via Adaptive Patch Importance Learning](https://arxiv.org/abs/2601.01992)
*Chen Zhu,Huiwen Zhang,Yujie Li,Mu He,Xiaotian Qiao*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出API框架用于真实世界图像去雾，包含自动雾霾生成模块和密度感知去雾模块，通过多负样本对比损失提升细节恢复，在多个真实世界基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在复杂真实世界雾霾场景中性能显著下降，主要由于训练数据有限和雾霾密度分布的内在复杂性。需要解决真实世界图像去雾的泛化性问题。

Method: 提出自适应补丁重要性感知框架：1) 自动雾霾生成模块提供混合数据增强策略；2) 密度感知去雾模块以自适应补丁重要性方式处理不同雾霾密度区域；3) 引入多负样本对比去雾损失，充分利用空间和频域信息。

Result: 在多个真实世界基准测试中达到最先进性能，在定量指标和定性视觉质量方面均表现优异，对不同雾霾分布展现出鲁棒的泛化能力。

Conclusion: 提出的API框架通过创新的数据增强、密度感知处理和对比损失设计，有效解决了真实世界图像去雾的泛化性问题，为复杂雾霾场景提供了强大的解决方案。

Abstract: Real-world image dehazing is a fundamental yet challenging task in low-level vision. Existing learning-based methods often suffer from significant performance degradation when applied to complex real-world hazy scenes, primarily due to limited training data and the intrinsic complexity of haze density distributions.To address these challenges, we introduce a novel Adaptive Patch Importance-aware (API) framework for generalizable real-world image dehazing. Specifically, our framework consists of an Automatic Haze Generation (AHG) module and a Density-aware Haze Removal (DHR) module. AHG provides a hybrid data augmentation strategy by generating realistic and diverse hazy images as additional high-quality training data. DHR considers hazy regions with varying haze density distributions for generalizable real-world image dehazing in an adaptive patch importance-aware manner. To alleviate the ambiguity of the dehazed image details, we further introduce a new Multi-Negative Contrastive Dehazing (MNCD) loss, which fully utilizes information from multiple negative samples across both spatial and frequency domains. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across multiple real-world benchmarks, delivering strong results in both quantitative metrics and qualitative visual quality, and exhibiting robust generalization across diverse haze distributions.

</details>


### [228] [Nighttime Hazy Image Enhancement via Progressively and Mutually Reinforcing Night-Haze Priors](https://arxiv.org/abs/2601.01998)
*Chen Zhu,Huiwen Zhang,Mu He,Yujie Li,Xiaotian Qiao*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出一种新颖的夜间雾霾图像增强框架，通过强化雾霾与低光先验之间的内在一致性，利用多级专家系统在视觉和频域进行渐进式恢复。


<details>
  <summary>Details</summary>
Motivation: 夜间雾霾图像增强面临复杂退化分布的挑战，现有方法通常单独处理雾霾或低光退化，忽略了不同退化类型之间的相互作用，导致可见度提升有限。作者观察到低光和雾霾先验之间的领域知识可以相互强化以提升可见度。

Method: 提出一个新颖框架，通过相互渐进地强化雾霾和低光先验之间的内在一致性来增强夜间雾霾图像可见度。模型采用图像级、块级和像素级专家系统，在视觉和频域中运行，逐步恢复全局场景结构、区域模式和细粒度细节。引入频率感知路由器自适应指导每个专家的贡献，确保鲁棒的图像恢复。

Result: 在夜间去雾基准测试中，模型在定量和定性方面都表现出优越性能。此外，模型在白天去雾和低光增强任务中也展现出良好的泛化能力。

Conclusion: 通过强化雾霾和低光先验之间的内在一致性，提出的多级专家框架能够有效处理夜间雾霾图像的复杂退化问题，并在多个相关任务中展现出良好的性能。

Abstract: Enhancing the visibility of nighttime hazy images is challenging due to the complex degradation distributions. Existing methods mainly address a single type of degradation (e.g., haze or low-light) at a time, ignoring the interplay of different degradation types and resulting in limited visibility improvement. We observe that the domain knowledge shared between low-light and haze priors can be reinforced mutually for better visibility. Based on this key insight, in this paper, we propose a novel framework that enhances visibility in nighttime hazy images by reinforcing the intrinsic consistency between haze and low-light priors mutually and progressively. In particular, our model utilizes image-, patch-, and pixel-level experts that operate across visual and frequency domains to recover global scene structure, regional patterns, and fine-grained details progressively. A frequency-aware router is further introduced to adaptively guide the contribution of each expert, ensuring robust image restoration. Extensive experiments demonstrate the superior performance of our model on nighttime dehazing benchmarks both quantitatively and qualitatively. Moreover, we showcase the generalizability of our model in daytime dehazing and low-light enhancement tasks.

</details>


### [229] [PhysSFI-Net: Physics-informed Geometric Learning of Skeletal and Facial Interactions for Orthognathic Surgical Outcome Prediction](https://arxiv.org/abs/2601.02088)
*Jiahao Bao,Huazhen Liu,Yu Zhuang,Leran Tao,Xinyu Xu,Yongtao Shi,Mengjia Cheng,Yiming Wang,Congshuang Ku,Ting Zeng,Yilang Du,Siyi Chen,Shunyao Shen,Suncheng Xiang,Hongbo Yu*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出PhysSFI-Net物理信息几何深度学习框架，用于正颌手术后软组织变形预测，结合层次图模块、LSTM序列预测器和生物力学模块，在135例患者数据上验证了优于现有方法的精度。


<details>
  <summary>Details</summary>
Motivation: 正颌手术需要准确预测术后面部形态以进行术前规划。传统生物力学模型计算成本高，而几何深度学习方法缺乏可解释性，因此需要开发既准确又可解释的预测框架。

Method: 提出PhysSFI-Net框架，包含三个组件：1) 带注意力机制的层次图模块，提取骨骼-面部交互特征；2) LSTM序列预测器，用于增量软组织变形预测；3) 生物力学启发的模块，用于高分辨率面部表面重建。

Result: 在135例患者数据上评估，PhysSFI-Net的点云形状误差为1.070±0.088mm，表面偏差误差为1.296±0.349mm，标志点定位误差为2.445±1.326mm，优于现有方法ACMT-Net。

Conclusion: PhysSFI-Net能够实现可解释、高分辨率的术后面部形态预测，具有优越的准确性，在正颌手术规划和模拟中显示出强大的临床应用潜力。

Abstract: Orthognathic surgery repositions jaw bones to restore occlusion and enhance facial aesthetics. Accurate simulation of postoperative facial morphology is essential for preoperative planning. However, traditional biomechanical models are computationally expensive, while geometric deep learning approaches often lack interpretability. In this study, we develop and validate a physics-informed geometric deep learning framework named PhysSFI-Net for precise prediction of soft tissue deformation following orthognathic surgery. PhysSFI-Net consists of three components: a hierarchical graph module with craniofacial and surgical plan encoders combined with attention mechanisms to extract skeletal-facial interaction features; a Long Short-Term Memory (LSTM)-based sequential predictor for incremental soft tissue deformation; and a biomechanics-inspired module for high-resolution facial surface reconstruction. Model performance was assessed using point cloud shape error (Hausdorff distance), surface deviation error, and landmark localization error (Euclidean distances of craniomaxillofacial landmarks) between predicted facial shapes and corresponding ground truths. A total of 135 patients who underwent combined orthodontic and orthognathic treatment were included for model training and validation. Quantitative analysis demonstrated that PhysSFI-Net achieved a point cloud shape error of 1.070 +/- 0.088 mm, a surface deviation error of 1.296 +/- 0.349 mm, and a landmark localization error of 2.445 +/- 1.326 mm. Comparative experiments indicated that PhysSFI-Net outperformed the state-of-the-art method ACMT-Net in prediction accuracy. In conclusion, PhysSFI-Net enables interpretable, high-resolution prediction of postoperative facial morphology with superior accuracy, showing strong potential for clinical application in orthognathic surgical planning and simulation.

</details>


### [230] [MagicFight: Personalized Martial Arts Combat Video Generation](https://arxiv.org/abs/2601.02107)
*Jiancheng Huang,Mingfu Yan,Songyan Chen,Yi Huang,Shifeng Chen*

Main category: cs.CV

Relevance: 25.0

TL;DR: MagicFight提出个性化武术格斗视频生成新任务，针对现有单人生成模型在双人交互中的不足，通过Unity生成定制数据集，开发能保持身份一致性和动作连贯性的双人格斗视频生成方法。


<details>
  <summary>Details</summary>
Motivation: 当前个性化视频生成主要关注单人生成（如舞蹈），但在双人交互场景（特别是武术格斗）中存在显著空白。现有模型无法处理双人交互的复杂性，导致身份混淆、肢体异常和动作不匹配等问题。

Method: 1. 提出个性化武术格斗视频生成新任务；2. 使用Unity游戏物理引擎生成定制数据集，包含多样化的3D角色、武术动作和场景；3. 改进和适配现有模型策略，生成高保真双人格斗视频。

Result: 开发了MagicFight系统，能够生成保持个体身份一致性和动作连贯性的双人格斗视频，为交互式视频内容创作奠定了基础。

Conclusion: 该研究填补了双人交互视频生成的空白，特别是在武术格斗领域，为未来交互式视频内容创作提供了新方向和技术基础。

Abstract: Amid the surge in generic text-to-video generation, the field of personalized human video generation has witnessed notable advancements, primarily concentrated on single-person scenarios. However, to our knowledge, the domain of two-person interactions, particularly in the context of martial arts combat, remains uncharted. We identify a significant gap: existing models for single-person dancing generation prove insufficient for capturing the subtleties and complexities of two engaged fighters, resulting in challenges such as identity confusion, anomalous limbs, and action mismatches. To address this, we introduce a pioneering new task, Personalized Martial Arts Combat Video Generation. Our approach, MagicFight, is specifically crafted to overcome these hurdles. Given this pioneering task, we face a lack of appropriate datasets. Thus, we generate a bespoke dataset using the game physics engine Unity, meticulously crafting a multitude of 3D characters, martial arts moves, and scenes designed to represent the diversity of combat. MagicFight refines and adapts existing models and strategies to generate high-fidelity two-person combat videos that maintain individual identities and ensure seamless, coherent action sequences, thereby laying the groundwork for future innovations in the realm of interactive video content creation.
  Website: https://MingfuYAN.github.io/MagicFight/
  Dataset: https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta

</details>


### [231] [Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model](https://arxiv.org/abs/2601.02112)
*Utkarsh Singh,Absaar Ali,Adarsh Roy*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出一种基于序列切片处理的轻量级代理模型，用于预测3D车辆的空气动力阻力系数，将点云分解为沿流向轴的2D截面序列，使用PointNet2D编码和双向LSTM处理，实现快速准确的Cd预测。


<details>
  <summary>Details</summary>
Motivation: 汽车行业需要高效的气动设计来提升燃油经济性和性能，但传统CFD和风洞测试方法资源密集，阻碍早期设计的快速迭代。现有机器学习代理模型存在计算复杂度高、可解释性差或对详细几何输入精度不足的问题。

Method: 受医学影像启发，将3D车辆点云沿流向轴分解为有序的2D横截面切片序列。每个切片通过轻量级PointNet2D模块编码，切片嵌入序列通过双向LSTM处理以捕捉纵向几何演化。

Result: 在DrivAerNet++数据集上训练和评估，获得高决定系数（R^2 > 0.9528）和低平均绝对误差（MAE ≈ 6.046×10^{-3}）。在消费级GPU上推理时间约0.025秒/样本。

Conclusion: 该方法提供快速、准确且可解释的气动反馈，促进更敏捷和知情的汽车设计探索，为早期设计阶段的高效迭代提供了实用解决方案。

Abstract: The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.

</details>


### [232] [Beyond Segmentation: An Oil Spill Change Detection Framework Using Synthetic SAR Imagery](https://arxiv.org/abs/2601.02139)
*Chenyang Lai,Shuaiyu Chen,Tianjin Huang,Siyang Song,Guangliang Cheng,Chunbo Luo,Zeyu Fu*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出OSCD（油污变化检测）新任务，通过TAHI框架生成合成前污染图像，构建首个OSCD数据集，显著降低误报率


<details>
  <summary>Details</summary>
Motivation: 传统基于单幅SAR图像的油污检测方法难以区分真实油污与视觉相似的海面特征（如生物油膜、低风区），导致高误报率和有限泛化能力，特别是在数据稀缺条件下

Method: 提出OSCD（油污变化检测）双时相任务，开发TAHI（时序感知混合修复）框架，包含高保真混合修复和时序真实性增强两个关键组件，生成合成前污染图像

Result: 构建首个OSCD数据集，基准测试多个最先进的变化检测模型，结果显示OSCD相比传统分割方法显著降低误报率并提高检测精度

Conclusion: 时序感知方法在真实场景中为可靠、可扩展的油污监测提供了价值，OSCD任务为解决传统方法的局限性提供了新方向

Abstract: Marine oil spills are urgent environmental hazards that demand rapid and reliable detection to minimise ecological and economic damage. While Synthetic Aperture Radar (SAR) imagery has become a key tool for large-scale oil spill monitoring, most existing detection methods rely on deep learning-based segmentation applied to single SAR images. These static approaches struggle to distinguish true oil spills from visually similar oceanic features (e.g., biogenic slicks or low-wind zones), leading to high false positive rates and limited generalizability, especially under data-scarce conditions. To overcome these limitations, we introduce Oil Spill Change Detection (OSCD), a new bi-temporal task that focuses on identifying changes between pre- and post-spill SAR images. As real co-registered pre-spill imagery is not always available, we propose the Temporal-Aware Hybrid Inpainting (TAHI) framework, which generates synthetic pre-spill images from post-spill SAR data. TAHI integrates two key components: High-Fidelity Hybrid Inpainting for oil-free reconstruction, and Temporal Realism Enhancement for radiometric and sea-state consistency. Using TAHI, we construct the first OSCD dataset and benchmark several state-of-the-art change detection models. Results show that OSCD significantly reduces false positives and improves detection accuracy compared to conventional segmentation, demonstrating the value of temporally-aware methods for reliable, scalable oil spill monitoring in real-world scenarios.

</details>


### [233] [Why Commodity WiFi Sensors Fail at Multi-Person Gait Identification: A Systematic Analysis Using ESP32](https://arxiv.org/abs/2601.02177)
*Oliver Custance,Saad Khan,Simon Parkinson*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该论文系统评估了使用商用ESP32 WiFi传感器进行多人步态识别的可行性，发现所有信号分离方法在1-10人场景下都只能达到45-56%的低准确率，表明现有硬件无法提供足够的信号质量。


<details>
  <summary>Details</summary>
Motivation: 虽然WiFi信道状态信息(CSI)在单人步态识别中表现出色，但多人识别研究很少，且现有方法依赖复杂昂贵的定制硬件。核心问题未解：多人识别性能差是算法限制还是硬件约束？

Method: 使用商用ESP32 WiFi传感器，在1-10人的7种场景下，系统评估了6种信号分离方法：FastICA、SOBI、PCA、NMF、小波变换和张量分解。通过新颖的诊断指标（主体内变异性、主体间可区分性、性能退化率）进行分析。

Result: 所有方法都获得相似的低准确率（45-56%，标准差3.74%），统计上无显著差异。即使最佳方法NMF也只有56%准确率。分析显示高主体内变异性、低主体间可区分性，以及随人数增加性能急剧下降。

Conclusion: 商用ESP32传感器无法提供足够的信号质量来实现可靠的多人分离，表明当前多人识别性能差主要是硬件限制而非算法问题。

Abstract: WiFi Channel State Information (CSI) has shown promise for single-person gait identification, with numerous studies reporting high accuracy. However, multi-person identification remains largely unexplored, with the limited existing work relying on complex, expensive setups requiring modified firmware. A critical question remains unanswered: is poor multi-person performance an algorithmic limitation or a fundamental hardware constraint? We systematically evaluate six diverse signal separation methods (FastICA, SOBI, PCA, NMF, Wavelet, Tensor Decomposition) across seven scenarios with 1-10 people using commodity ESP32 WiFi sensors--a simple, low-cost, off-the-shelf solution. Through novel diagnostic metrics (intra-subject variability, inter-subject distinguishability, performance degradation rate), we reveal that all methods achieve similarly low accuracy (45-56\%, $σ$=3.74\%) with statistically insignificant differences (p $>$ 0.05). Even the best-performing method, NMF, achieves only 56\% accuracy. Our analysis reveals high intra-subject variability, low inter-subject distinguishability, and severe performance degradation as person count increases, indicating that commodity ESP32 sensors cannot provide sufficient signal quality for reliable multi-person separation.

</details>


### [234] [Seeing the Unseen: Zooming in the Dark with Event Cameras](https://arxiv.org/abs/2601.02206)
*Dachun Kai,Zeyu Xiao,Huyue Zhu,Jiaxiao Wang,Yueyi Zhang,Xiaoyan Sun*

Main category: cs.CV

Relevance: 25.0

TL;DR: RetinexEVSR：首个事件驱动的低光视频超分辨率框架，结合Retinex先验和双向跨模态融合，在低光条件下恢复高质量视频细节


<details>
  <summary>Details</summary>
Motivation: 现有低光视频超分辨率方法在恢复细节方面存在困难，主要因为对比度有限和高频信息不足。需要利用高对比度事件信号和Retinex先验来提升低光场景下的视频质量。

Method: 提出RetinexEVSR框架，采用双向跨模态融合策略：1）光照引导的事件增强模块，利用Retinex模型的光照图逐步精炼事件特征；2）事件引导的反射增强模块，利用增强的事件特征通过多尺度融合动态恢复反射细节。

Result: 在三个数据集上达到SOTA性能，在SDSD基准上获得最高2.95dB增益，同时相比之前的事件方法减少65%运行时间。

Conclusion: RetinexEVSR通过结合事件信号和Retinex先验，有效解决了低光视频超分辨率的挑战，在性能和效率上都超越了现有方法。

Abstract: This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.

</details>


### [235] [Prior-Guided DETR for Ultrasound Nodule Detection](https://arxiv.org/abs/2601.02212)
*Jingjing Wang,Zhuo Xiao,Xinning Yao,Bo Liu,Lijuan Niu,Xiangzhi Bai,Fugen Zhou*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种先验引导的DETR框架用于超声结节检测，通过多阶段注入几何和结构先验知识，解决了不规则形状、模糊边界、尺度变化和斑点噪声等挑战。


<details>
  <summary>Details</summary>
Motivation: 超声结节检测对甲状腺和乳腺癌早期诊断至关重要，但面临不规则形状、模糊边界、尺度变化大和斑点噪声等挑战，传统数据驱动方法难以有效处理。

Method: 提出先验引导的DETR框架：1) SDFPR模块在CNN骨干中注入几何先验，稳定不规则结节的特征提取；2) MSFFM模块提取多尺度结构先验，空间域处理轮廓连续性，频域建模全局形态并抑制噪声；3) DFI机制在所有编码器层传播先验调制特征，增强解码器查询细化。

Result: 在两个临床收集的甲状腺超声数据集(Thyroid I和II)和两个公共基准(TN3K和BUSI)上测试，相比18种检测方法获得更优精度，特别是在形态复杂结节检测方面表现突出。

Conclusion: 通过多阶段注入先验知识的DETR框架能有效提升超声结节检测性能，特别是在处理不规则形状和噪声干扰方面，为医学影像分析提供了新思路。

Abstract: Accurate detection of ultrasound nodules is essential for the early diagnosis and treatment of thyroid and breast cancers. However, this task remains challenging due to irregular nodule shapes, indistinct boundaries, substantial scale variations, and the presence of speckle noise that degrades structural visibility. To address these challenges, we propose a prior-guided DETR framework specifically designed for ultrasound nodule detection. Instead of relying on purely data-driven feature learning, the proposed framework progressively incorporates different prior knowledge at multiple stages of the network. First, a Spatially-adaptive Deformable FFN with Prior Regularization (SDFPR) is embedded into the CNN backbone to inject geometric priors into deformable sampling, stabilizing feature extraction for irregular and blurred nodules. Second, a Multi-scale Spatial-Frequency Feature Mixer (MSFFM) is designed to extract multi-scale structural priors, where spatial-domain processing emphasizes contour continuity and boundary cues, while frequency-domain modeling captures global morphology and suppresses speckle noise. Furthermore, a Dense Feature Interaction (DFI) mechanism propagates and exploits these prior-modulated features across all encoder layers, enabling the decoder to enhance query refinement under consistent geometric and structural guidance. Experiments conducted on two clinically collected thyroid ultrasound datasets (Thyroid I and Thyroid II) and two public benchmarks (TN3K and BUSI) for thyroid and breast nodules demonstrate that the proposed method achieves superior accuracy compared with 18 detection methods, particularly in detecting morphologically complex nodules.The source code is publicly available at https://github.com/wjj1wjj/Ultrasound-DETR.

</details>


### [236] [SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting](https://arxiv.org/abs/2601.02299)
*Sara Inácio,Hugo Proença,João C. Neves*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出SortWaste数据集和ClutterScore指标，用于评估垃圾分拣场景中的物体检测性能，发现现有模型在复杂场景下表现显著下降


<details>
  <summary>Details</summary>
Motivation: 垃圾产量增加导致分拣挑战，人工分拣效率低且有健康风险，现有自动化系统难以处理真实垃圾流的高变异性、杂乱性和视觉复杂性，缺乏真实世界数据集是主要瓶颈

Method: 1) 引入SortWaste数据集，从材料回收设施收集的密集标注物体检测数据集；2) 提出ClutterScore指标，通过对象数量、类别和大小熵、空间重叠等代理变量客观评估场景复杂度；3) 对最先进的物体检测模型进行基准测试

Result: 塑料检测任务达到59.7% mAP，但在高度杂乱场景中性能显著下降，表明需要更具挑战性的数据集

Conclusion: 虽然现有模型在垃圾检测方面取得有希望的结果，但在复杂场景下表现不佳，需要更鲁棒的模型和更具挑战性的数据集来推动自动化垃圾分拣系统的发展

Abstract: The increasing production of waste, driven by population growth, has created challenges in managing and recycling materials effectively. Manual waste sorting is a common practice; however, it remains inefficient for handling large-scale waste streams and presents health risks for workers. On the other hand, existing automated sorting approaches still struggle with the high variability, clutter, and visual complexity of real-world waste streams. The lack of real-world datasets for waste sorting is a major reason automated systems for this problem are underdeveloped. Accordingly, we introduce SortWaste, a densely annotated object detection dataset collected from a Material Recovery Facility. Additionally, we contribute to standardizing waste detection in sorting lines by proposing ClutterScore, an objective metric that gauges the scene's hardness level using a set of proxies that affect visual complexity (e.g., object count, class and size entropy, and spatial overlap). In addition to these contributions, we provide an extensive benchmark of state-of-the-art object detection models, detailing their results with respect to the hardness level assessed by the proposed metric. Despite achieving promising results (mAP of 59.7% in the plastic-only detection task), performance significantly decreases in highly cluttered scenes. This highlights the need for novel and more challenging datasets on the topic.

</details>


### [237] [Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding](https://arxiv.org/abs/2601.02339)
*Jingming He,Chongyi Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出3D语义高斯建模的联合增强框架，通过各向异性3D高斯切比雪夫描述符捕捉细粒度形状细节，结合语义和渲染分支自适应调整高斯分配，并采用跨场景知识转移模块加速收敛


<details>
  <summary>Details</summary>
Motivation: 现有方法将语义和渲染分支分开处理，仅依赖2D监督而忽略3D高斯几何，自适应策略仅基于渲染梯度，在纹理稀疏区域效果不佳

Method: 1) 引入各向异性3D高斯切比雪夫描述符，使用拉普拉斯-贝尔特拉米算子捕捉细粒度3D形状细节；2) 结合语义和形状信号自适应调整高斯分配和球谐函数；3) 采用跨场景知识转移模块持续更新学习到的形状模式

Result: 在多个数据集上实验显示，分割精度和渲染质量均有提升，同时保持高渲染帧率

Conclusion: 提出的联合增强框架通过整合语义和渲染分支，结合3D形状描述符和自适应策略，显著提升了3D语义高斯建模的性能

Abstract: Recent works propose extending 3DGS with semantic feature vectors for simultaneous semantic segmentation and image rendering. However, these methods often treat the semantic and rendering branches separately, relying solely on 2D supervision while ignoring the 3D Gaussian geometry. Moreover, current adaptive strategies adapt the Gaussian set depending solely on rendering gradients, which can be insufficient in subtle or textureless regions. In this work, we propose a joint enhancement framework for 3D semantic Gaussian modeling that synergizes both semantic and rendering branches. Firstly, unlike conventional point cloud shape encoding, we introduce an anisotropic 3D Gaussian Chebyshev descriptor using the Laplace-Beltrami operator to capture fine-grained 3D shape details, thereby distinguishing objects with similar appearances and reducing reliance on potentially noisy 2D guidance. In addition, without relying solely on rendering gradient, we adaptively adjust Gaussian allocation and spherical harmonics with local semantic and shape signals, enhancing rendering efficiency through selective resource allocation. Finally, we employ a cross-scene knowledge transfer module to continuously update learned shape patterns, enabling faster convergence and robust representations without relearning shape information from scratch for each new scene. Experiments on multiple datasets demonstrate improvements in segmentation accuracy and rendering quality while maintaining high rendering frame rates.

</details>


### [238] [Dancing Points: Synthesizing Ballroom Dancing with Three-Point Inputs](https://arxiv.org/abs/2601.02096)
*Peizhuo Li,Sebastian Starke,Yuting Ye,Olga Sorkine-Hornung*

Main category: cs.GR

Relevance: 25.0

TL;DR: 提出一种基于VR设备三点轨迹的舞蹈动作描述方法，使用高效MLP网络从领舞者三点轨迹预测跟舞者三点轨迹，并通过确定性神经网络将轨迹转换为虚拟化身动作。


<details>
  <summary>Details</summary>
Motivation: 探戈等交谊舞动作多样且领舞与跟舞者互动复杂，传统方法需要建模高维全身动作，计算量大且容易过拟合。需要一种更高效、数据需求更少的解决方案。

Method: 1) 使用VR设备的三点轨迹作为舞蹈动作描述符；2) 采用高效MLP网络直接从领舞者三点轨迹预测跟舞者三点轨迹；3) 通过精心设计的自回归过程和确定性神经网络将三点轨迹转换为虚拟化身动作。

Result: 方法在交谊舞数据集上有效，能够简化高维全身互动建模，避免过拟合。在更大、更多样化的LaFAN数据集上也表现稳健。提供了计算和数据高效的解决方案。

Conclusion: 三点轨迹作为舞蹈动作描述符简化了互动建模，确定性方法能够处理传统上需要生成模型的欠约束问题，为沉浸式配对舞蹈应用开辟了新可能性。

Abstract: Ballroom dancing is a structured yet expressive motion category. Its highly diverse movement and complex interactions between leader and follower dancers make the understanding and synthesis challenging. We demonstrate that the three-point trajectory available from a virtual reality (VR) device can effectively serve as a dancer's motion descriptor, simplifying the modeling and synthesis of interplay between dancers' full-body motions down to sparse trajectories. Thanks to the low dimensionality, we can employ an efficient MLP network to predict the follower's three-point trajectory directly from the leader's three-point input for certain types of ballroom dancing, addressing the challenge of modeling high-dimensional full-body interaction. It also prevents our method from overfitting thanks to its compact yet explicit representation. By leveraging the inherent structure of the movements and carefully planning the autoregressive procedure, we show a deterministic neural network is able to translate three-point trajectories into a virtual embodied avatar, which is typically considered under-constrained and requires generative models for common motions. In addition, we demonstrate this deterministic approach generalizes beyond small, structured datasets like ballroom dancing, and performs robustly on larger, more diverse datasets such as LaFAN. Our method provides a computationally- and data-efficient solution, opening new possibilities for immersive paired dancing applications. Code and pre-trained models for this paper are available at https://peizhuoli.github.io/dancing-points.

</details>


### [239] [Real-Time Lane Detection via Efficient Feature Alignment and Covariance Optimization for Low-Power Embedded Systems](https://arxiv.org/abs/2601.01696)
*Yian Liu,Xiong Wang,Ping Xu,Lei Zhu,Ming Yan,Linyun Xue*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种用于嵌入式系统实时车道检测的协方差分布优化（CDO）模块，通过优化特征分布与真实标签的对齐来提高检测精度，且不增加计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统中的实时车道检测面临视觉信号稀疏、计算资源有限和功耗约束的挑战。现有深度学习方法（分割、锚点、曲线）缺乏针对低功耗嵌入式环境的通用优化技术。

Method: 提出协方差分布优化（CDO）模块，通过将车道特征分布与真实标签对齐来提升检测精度。该模块易于集成到现有系统，无需结构修改，利用现有参数进行持续训练。

Result: 在三个主要数据集（CULane、TuSimple、LLAMAS）上测试了六种模型（包括实时优化和SOTA模型），精度提升范围从0.01%到1.5%。

Conclusion: CDO模块为嵌入式系统提供了性能、功耗效率和操作灵活性的显著优势，是实时车道检测的有效优化方案。

Abstract: Real-time lane detection in embedded systems encounters significant challenges due to subtle and sparse visual signals in RGB images, often constrained by limited computational resources and power consumption. Although deep learning models for lane detection categorized into segmentation-based, anchor-based, and curve-based methods there remains a scarcity of universally applicable optimization techniques tailored for low-power embedded environments. To overcome this, we propose an innovative Covariance Distribution Optimization (CDO) module specifically designed for efficient, real-time applications. The CDO module aligns lane feature distributions closely with ground-truth labels, significantly enhancing detection accuracy without increasing computational complexity. Evaluations were conducted on six diverse models across all three method categories, including two optimized for real-time applications and four state-of-the-art (SOTA) models, tested comprehensively on three major datasets: CULane, TuSimple, and LLAMAS. Experimental results demonstrate accuracy improvements ranging from 0.01% to 1.5%. The proposed CDO module is characterized by ease of integration into existing systems without structural modifications and utilizes existing model parameters to facilitate ongoing training, thus offering substantial benefits in performance, power efficiency, and operational flexibility in embedded systems.

</details>


### [240] [Remote Sensing Change Detection via Weak Temporal Supervision](https://arxiv.org/abs/2601.02126)
*Xavier Bou,Elliot Vincent,Gabriele Facciolo,Rafael Grompone von Gioi,Jean-Michel Morel,Thibaud Ehret*

Main category: cs.CV

Relevance: 20.0

TL;DR: 该论文提出了一种弱时序监督策略，利用现有单时相遥感数据集的多时相观测进行语义变化检测，无需额外标注，通过假设真实双时相对大多无变化、不同位置图像配对生成变化示例来训练模型。


<details>
  <summary>Details</summary>
Motivation: 遥感语义变化检测面临标注数据稀缺的挑战，像素级标注成本高、耗时长。现有方法使用合成数据或人工生成变化对，但域外泛化能力有限。本文旨在利用现有单时相数据集的多时相观测，无需新标注，解决数据稀缺问题。

Method: 1) 扩展单时相遥感数据集，获取不同时间的观测；2) 假设真实双时相对大多无变化，同时配对不同位置图像生成变化示例；3) 采用对象感知变化图生成和迭代细化过程处理弱标签噪声。

Result: 在扩展的FLAIR和IAILD航空数据集上验证，在零样本和低数据场景下在不同基准测试中表现出色。展示了在法国大区域的应用结果，证明了方法的可扩展性。

Conclusion: 提出的弱时序监督策略有效解决了遥感语义变化检测的数据稀缺问题，无需额外标注，具有良好的泛化能力和可扩展性，为大规模遥感变化检测提供了实用解决方案。

Abstract: Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.

</details>


### [241] [Sim2Real SAR Image Restoration: Metadata-Driven Models for Joint Despeckling and Sidelobes Reduction](https://arxiv.org/abs/2601.01541)
*Antoine De Paepe,Pascal Nguyen,Michael Mabelle,Cédric Saleun,Antoine Jouadé,Jean-Christophe Louvigne*

Main category: eess.IV

Relevance: 20.0

TL;DR: 提出一个统一的神经网络框架，联合处理SAR图像的去斑和旁瓣抑制任务，使用MOCEM生成的模拟数据集训练，并利用采集元数据提升恢复性能。


<details>
  <summary>Details</summary>
Motivation: 合成孔径雷达（SAR）图像存在斑点噪声和旁瓣效应，现有方法通常将去斑和旁瓣抑制作为独立任务处理，缺乏统一解决方案。

Method: 使用MOCEM生成真实的SAR模拟数据集，训练神经网络联合处理去斑和旁瓣抑制，并引入采集元数据作为辅助输入。

Result: 该方法在真实SAR图像上展示了有效的模拟到真实（Sim2Real）迁移能力，结合元数据输入进一步提升了恢复性能。

Conclusion: 提出的统一框架能够有效处理SAR图像恢复的两个关键问题，通过模拟训练和元数据利用实现了更好的恢复效果。

Abstract: Synthetic aperture radar (SAR) provides valuable information about the Earth's surface under all weather and illumination conditions. However, the inherent phenomenon of speckle and the presence of sidelobes around bright targets pose challenges for accurate interpretation of SAR imagery. Most existing SAR image restoration methods address despeckling and sidelobes reduction as separate tasks. In this paper, we propose a unified framework that jointly performs both tasks using neural networks (NNs) trained on a realistic SAR simulated dataset generated with MOCEM. Inference can then be performed on real SAR images, demonstrating effective simulation to real (Sim2Real) transferability. Additionally, we incorporate acquisition metadata as auxiliary input to the NNs, demonstrating improved restoration performance.

</details>


### [242] [Motion-Compensated Latent Semantic Canvases for Visual Situational Awareness on Edge](https://arxiv.org/abs/2601.00854)
*Igor Lodin,Sergii Filatov,Vira Filatova,Dmytro Filatov*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出MCLSC方法，在资源受限的边缘设备上实现视觉情境感知，通过运动补偿的潜在语义画布和运动门控分割大幅降低计算开销


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上实现实时视觉情境感知面临计算资源限制的挑战，传统逐帧分割方法计算开销过大，需要更高效的解决方案

Method: 使用两个潜在语义画布（静态层和动态层），在基准坐标系中维护持久语义元数据；采用运动门控的异步分割（Mask2Former），仅在运动指示新信息时触发推理；通过稳定化和运动补偿保持一致的坐标系

Result: 在480p视频上，分割调用减少30倍以上，端到端平均处理时间降低20倍以上，同时保持连贯的静态/动态语义覆盖

Conclusion: MCLSC方法在边缘设备上实现了高效的视觉情境感知，通过运动补偿和门控机制显著降低了计算开销，为资源受限环境提供了可行的解决方案

Abstract: We propose Motion-Compensated Latent Semantic Canvases (MCLSC) for visual situational awareness on resource-constrained edge devices. The core idea is to maintain persistent semantic metadata in two latent canvases - a slowly accumulating static layer and a rapidly updating dynamic layer - defined in a baseline coordinate frame stabilized from the video stream. Expensive panoptic segmentation (Mask2Former) runs asynchronously and is motion-gated: inference is triggered only when motion indicates new information, while stabilization/motion compensation preserves a consistent coordinate system for latent semantic memory. On prerecorded 480p clips, our prototype reduces segmentation calls by >30x and lowers mean end-to-end processing time by >20x compared to naive per-frame segmentation, while maintaining coherent static/dynamic semantic overlays.

</details>


### [243] [Application of deep learning techniques in non-contrast computed tomography pulmonary angiogram for pulmonary embolism diagnosis](https://arxiv.org/abs/2601.00925)
*I-Hsien Ting,Yi-Jun Tseng,Yu-Sheng Lin*

Main category: cs.CV

Relevance: 15.0

TL;DR: 使用3D卷积神经网络对无造影剂CT图像进行肺栓塞自动分类，准确率达85%，AUC为0.84


<details>
  <summary>Details</summary>
Motivation: 肺栓塞是危及生命的疾病，早期检测和治疗可显著降低死亡率。目前使用造影剂CT血管造影的深度学习方法存在局限性：造影剂可能导致慢性肾病患者的急性肾损伤，且造影剂起效需要时间，可能延误急性肺栓塞患者的黄金治疗时间。

Method: 采用3D卷积神经网络模型，直接在无造影剂的CT图像上进行肺栓塞自动分类

Result: 模型在无造影剂CT图像的肺栓塞分类中表现显著，准确率达到85%，AUC为0.84，验证了该模型在肺栓塞诊断中的可行性

Conclusion: 证明了使用深度学习技术在不使用造影剂的CT图像上自动分类肺栓塞的可行性，为快速诊断提供了新方法

Abstract: Pulmonary embolism is a life-threatening disease, early detection and treatment can significantly reduce mortality. In recent years, many studies have been using deep learning in the diagnosis of pulmonary embolism with contrast medium computed tomography pulmonary angiography, but the contrast medium is likely to cause acute kidney injury in patients with pulmonary embolism and chronic kidney disease, and the contrast medium takes time to work, patients with acute pulmonary embolism may miss the golden treatment time.
  This study aims to use deep learning techniques to automatically classify pulmonary embolism in CT images without contrast medium by using a 3D convolutional neural network model. The deep learning model used in this study had a significant impact on the pulmonary embolism classification of computed tomography images without contrast with 85\% accuracy and 0.84 AUC, which confirms the feasibility of the model in the diagnosis of pulmonary embolism.

</details>


### [244] [Analyzing the Shopping Journey: Computing Shelf Browsing Visits in a Physical Retail Store](https://arxiv.org/abs/2601.00928)
*Luis Yoichi Morales,Francesco Zanlungo,David M. Woollard*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出一种从3D轨迹数据中提取顾客"货架访问"行为的算法，用于分析实体零售店中的顾客浏览意图，并在不同商店环境中验证其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着机器人逐渐应用于零售场景，需要理解顾客在实体店中的购物意图。当前缺乏对顾客浏览行为的自动化理解方法，而货架访问行为是理解购物意图的关键。

Method: 基于机器视觉的3D跟踪和顶置摄像头获取顾客轨迹，设计算法提取"货架访问"行为。在两个不同商店收集轨迹数据（8138条和15129条）进行独立校准，人工标注验证，并在跨店场景下评估算法泛化能力。

Result: 算法在不同商店环境下都能有效识别顾客浏览活动，展示了良好的泛化性能。利用该模型分析了大批量轨迹中的顾客浏览模式及其与购买行为的关系。

Conclusion: 货架浏览信息可用于零售规划和人机交互场景，为实体零售环境中的顾客意图理解提供了有效工具。

Abstract: Motivated by recent challenges in the deployment of robots into customer-facing roles within retail, this work introduces a study of customer activity in physical stores as a step toward autonomous understanding of shopper intent. We introduce an algorithm that computes shoppers' ``shelf visits'' -- capturing their browsing behavior in the store. Shelf visits are extracted from trajectories obtained via machine vision-based 3D tracking and overhead cameras. We perform two independent calibrations of the shelf visit algorithm, using distinct sets of trajectories (consisting of 8138 and 15129 trajectories), collected in different stores and labeled by human reviewers. The calibrated models are then evaluated on trajectories held out of the calibration process both from the same store on which calibration was performed and from the other store. An analysis of the results shows that the algorithm can recognize customers' browsing activity when evaluated in an environment different from the one on which calibration was performed. We then use the model to analyze the customers' ``browsing patterns'' on a large set of trajectories and their relation to actual purchases in the stores. Finally, we discuss how shelf browsing information could be used for retail planning and in the domain of human-robot interaction scenarios.

</details>


### [245] [ShadowGS: Shadow-Aware 3D Gaussian Splatting for Satellite Imagery](https://arxiv.org/abs/2601.00939)
*Feng Luo,Hongbo Pan,Xiang Yang,Baoyu Jiang,Fengqing Liu,Tao Huang*

Main category: cs.CV

Relevance: 15.0

TL;DR: ShadowGS：基于3D高斯泼溅的卫星影像阴影建模框架，通过物理渲染方程和光线行进技术实现几何一致的阴影建模，提升3D重建精度和视图合成质量


<details>
  <summary>Details</summary>
Motivation: 多时相卫星影像中，由于光照条件变化导致的阴影不一致性严重影响3D重建质量，现有方法难以精确建模几何一致的阴影

Method: 基于3D高斯泼溅框架，结合遥感物理渲染方程和高效光线行进技术，引入阴影一致性约束和阴影图先验，实现阴影解耦和几何精确建模

Result: 在阴影解耦精度、3D重建精度和新视角合成质量上优于现有方法，仅需几分钟训练，在RGB、全色融合和稀疏视图输入下均表现稳健

Conclusion: ShadowGS通过物理建模和高效优化，成功解决了卫星影像中的阴影一致性问题，为遥感3D重建提供了有效解决方案

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel paradigm for 3D reconstruction from satellite imagery. However, in multi-temporal satellite images, prevalent shadows exhibit significant inconsistencies due to varying illumination conditions. To address this, we propose ShadowGS, a novel framework based on 3DGS. It leverages a physics-based rendering equation from remote sensing, combined with an efficient ray marching technique, to precisely model geometrically consistent shadows while maintaining efficient rendering. Additionally, it effectively disentangles different illumination components and apparent attributes in the scene. Furthermore, we introduce a shadow consistency constraint that significantly enhances the geometric accuracy of 3D reconstruction. We also incorporate a novel shadow map prior to improve performance with sparse-view inputs. Extensive experiments demonstrate that ShadowGS outperforms current state-of-the-art methods in shadow decoupling accuracy, 3D reconstruction precision, and novel view synthesis quality, with only a few minutes of training. ShadowGS exhibits robust performance across various settings, including RGB, pansharpened, and sparse-view satellite inputs.

</details>


### [246] [Learning to Segment Liquids in Real-world Images](https://arxiv.org/abs/2601.00940)
*Jonas Li,Michelle Li,Luke Liu,Heng Fan*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了LQDS数据集和LQDM模型，用于解决液体分割这一具有挑战性的计算机视觉任务，通过边界分支与分割分支的交叉注意力机制提升液体分割性能。


<details>
  <summary>Details</summary>
Motivation: 液体在日常生活中无处不在，但现有研究对液体分割任务关注有限，这限制了机器人安全避让或与液体交互的能力。液体分割的挑战在于液体外观多样、形状多变，且可以是透明或反射性的，会呈现背景或周围环境的任意物体和场景。

Method: 构建了包含5000张真实世界图像、标注为14个不同类别的大规模液体数据集LQDS，并设计了新颖的液体检测模型LQDM，该模型利用专用边界分支与主要分割分支之间的交叉注意力机制来增强分割预测。

Result: 在LQDS测试集上的大量实验证明了LQDM的有效性，其性能优于最先进的方法，为液体语义分割建立了强大的基线。

Conclusion: 该研究通过构建大规模液体数据集和提出创新的液体分割模型，为解决液体分割这一具有挑战性的计算机视觉任务做出了贡献，为机器人安全交互液体环境提供了技术基础。

Abstract: Different types of liquids such as water, wine and medicine appear in all aspects of daily life. However, limited attention has been given to the task, hindering the ability of robots to avoid or interact with liquids safely. The segmentation of liquids is difficult because liquids come in diverse appearances and shapes; moreover, they can be both transparent or reflective, taking on arbitrary objects and scenes from the background or surroundings. To take on this challenge, we construct a large-scale dataset of liquids named LQDS consisting of 5000 real-world images annotated into 14 distinct classes, and design a novel liquid detection model named LQDM, which leverages cross-attention between a dedicated boundary branch and the main segmentation branch to enhance segmentation predictions. Extensive experiments demonstrate the effectiveness of LQDM on the test set of LQDS, outperforming state-of-the-art methods and establishing a strong baseline for the semantic segmentation of liquids.

</details>


### [247] [UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data](https://arxiv.org/abs/2601.00991)
*Joshua Kawaguchi,Saad Manzur,Emily Gao Wang,Maitreyi Sinha,Bryan Vela,Yunxi Wang,Brandon Vela,Wayne B. Hayes*

Main category: cs.CV

Relevance: 15.0

TL;DR: UnrealPose-Gen是一个基于Unreal Engine 5的流水线，用于生成高质量的人体姿态数据，并发布了包含约100万帧的UnrealPose-1M数据集，包含3D关节、2D关键点、边界框和相机参数等标注信息。


<details>
  <summary>Details</summary>
Motivation: 现实世界中获取准确标注的3D人体姿态数据成本高昂且受限于工作室环境，而野外数据集缺乏真实地面真值。需要一种方法生成高质量、多样化的合成人体姿态数据来支持计算机视觉研究。

Method: 使用Unreal Engine 5构建UnrealPose-Gen流水线，基于Movie Render Queue进行高质量离线渲染。生成包含3D关节（世界和相机坐标系）、2D投影和COCO风格关键点（含遮挡和可见性标志）、人物边界框、相机内外参数的数据。创建了包含8个序列的UnrealPose-1M数据集，包括5个连贯脚本序列和3个随机序列。

Result: 生成了约100万帧的UnrealPose-1M数据集，包含5个场景、约40-100个动作、5个主体和多样化相机轨迹。在四个任务上进行了真实到合成的验证：图像到3D姿态、2D关键点检测、2D到3D提升、人物检测/分割。

Conclusion: UnrealPose-Gen流水线和UnrealPose-1M数据集为人体姿态分析研究提供了高质量的合成数据资源，支持第三方生成更多人体姿态数据。

Abstract: Diverse, accurately labeled 3D human pose data is expensive and studio-bound, while in-the-wild datasets lack known ground truth. We introduce UnrealPose-Gen, an Unreal Engine 5 pipeline built on Movie Render Queue for high-quality offline rendering. Our generated frames include: (i) 3D joints in world and camera coordinates, (ii) 2D projections and COCO-style keypoints with occlusion and joint-visibility flags, (iii) person bounding boxes, and (iv) camera intrinsics and extrinsics. We use UnrealPose-Gen to present UnrealPose-1M, an approximately one million frame corpus comprising eight sequences: five scripted "coherent" sequences spanning five scenes, approximately 40 actions, and five subjects; and three randomized sequences across three scenes, approximately 100 actions, and five subjects, all captured from diverse camera trajectories for broad viewpoint coverage. As a fidelity check, we report real-to-synthetic results on four tasks: image-to-3D pose, 2D keypoint detection, 2D-to-3D lifting, and person detection/segmentation. Though time and resources constrain us from an unlimited dataset, we release the UnrealPose-1M dataset, as well as the UnrealPose-Gen pipeline to support third-party generation of human pose data.

</details>


### [248] [Evaluating transfer learning strategies for improving dairy cattle body weight prediction in small farms using depth-image and point-cloud data](https://arxiv.org/abs/2601.01044)
*Jin Wang,Angelo De Castro,Yuxi Zhang,Lucas Basolli Borsatto,Yuechen Guo,Victoria Bastos Primo,Ana Beatriz Montevecchio Bernardino,Gota Morota,Ricardo C Chebel,Haipeng Yu*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该研究评估了在奶牛体重预测中，从大型农场到小型农场的迁移学习效果，并比较了深度图像与点云两种模态的性能。结果表明迁移学习显著提升小型农场的预测性能，且两种模态表现相当。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉为奶牛监测提供了自动化、非侵入性和可扩展的工具，但迁移学习在畜牧业应用中的效果和优化策略尚不明确。同时，深度图像和点云数据在奶牛体重预测中的直接比较也很有限。

Method: 研究收集了1,201、215和58头奶牛在大型、中型和小型农场的俯视深度图像和点云数据。评估了四种深度学习模型：ConvNeXt和MobileViT用于深度图像，PointNet和DGCNN用于点云。比较了迁移学习、单源学习和联合学习三种实验设计。

Result: 迁移学习显著提升了小型农场的体重预测性能，在所有四种模型中都优于单源学习，且达到或超过了联合学习的效果。深度图像和点云模型之间没有一致的性能差异。

Conclusion: 迁移学习特别适合小型农场预测场景，因为它只需要预训练模型权重而非原始数据，解决了隐私、物流或政策限制下的跨农场数据共享问题。

Abstract: Computer vision provides automated, non-invasive, and scalable tools for monitoring dairy cattle, thereby supporting management, health assessment, and phenotypic data collection. Although transfer learning is commonly used for predicting body weight from images, its effectiveness and optimal fine-tuning strategies remain poorly understood in livestock applications, particularly beyond the use of pretrained ImageNet or COCO weights. In addition, while both depth images and three-dimensional point-cloud data have been explored for body weight prediction, direct comparisons of these two modalities in dairy cattle are limited. Therefore, the objectives of this study were to 1) evaluate whether transfer learning from a large farm enhances body weight prediction on a small farm with limited data, and 2) compare the predictive performance of depth-image- and point-cloud-based approaches under three experimental designs. Top-view depth images and point-cloud data were collected from 1,201, 215, and 58 cows at large, medium, and small dairy farms, respectively. Four deep learning models were evaluated: ConvNeXt and MobileViT for depth images, and PointNet and DGCNN for point clouds. Transfer learning markedly improved body weight prediction on the small farm across all four models, outperforming single-source learning and achieving gains comparable to or greater than joint learning. These results indicate that pretrained representations generalize well across farms with differing imaging conditions and dairy cattle populations. No consistent performance difference was observed between depth-image- and point-cloud-based models. Overall, these findings suggest that transfer learning is well suited for small farm prediction scenarios where cross-farm data sharing is limited by privacy, logistical, or policy constraints, as it requires access only to pretrained model weights rather than raw data.

</details>


### [249] [A UAV-Based Multispectral and RGB Dataset for Multi-Stage Paddy Crop Monitoring in Indian Agricultural Fields](https://arxiv.org/abs/2601.01084)
*Adari Rama Sukanya,Puvvula Roopesh Naga Sri Sai,Kota Moses,Rimalapudi Sarvendranath*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了一个大规模无人机采集的水稻田间RGB和多光谱图像数据集，覆盖印度安得拉邦稻田从育苗到收获的所有生长阶段，包含42,430张原始图像和丰富元数据。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏覆盖水稻完整生长阶段的高分辨率多光谱图像数据集，特别是在印度农业背景下。现有数据集通常分辨率不足或覆盖阶段不完整，限制了精准农业、疾病分析和产量预测等研究。

Method: 使用配备20兆像素RGB相机和5兆像素四波段多光谱相机的无人机，在印度安得拉邦5英亩稻田区域进行系统化数据采集。开发标准化操作流程和检查清单确保数据可重复性，采集了1厘米/像素地面采样距离的图像，并记录GPS坐标、飞行高度和环境条件等元数据。

Result: 创建了包含42,430张原始图像（415GB）的数据集，覆盖水稻从育苗到收获的所有生长阶段。使用Pix4D Fields验证数据并生成正射影像图和植被指数图（NDVI、NDRE）。数据集已在IEEE DataPort上发布。

Conclusion: 该数据集为印度水稻农业研究提供了宝贵资源，支持精准喷洒、疾病分析和产量估计等应用，填补了覆盖完整生长阶段的高分辨率多光谱图像数据集的空白。

Abstract: We present a large-scale unmanned aerial vehicle (UAV)-based RGB and multispectral image dataset collected over paddy fields in the Vijayawada region, Andhra Pradesh, India, covering nursery to harvesting stages. We used a 20-megapixel RGB camera and a 5-megapixel four-band multispectral camera capturing red, green, red-edge, and near-infrared bands. Standardised operating procedure (SOP) and checklists were developed to ensure repeatable data acquisition. Our dataset comprises of 42,430 raw images (415 GB) captured over 5 acres with 1 cm/pixel ground sampling distance (GSD) with associated metadata such as GPS coordinates, flight altitude, and environmental conditions. Captured images were validated using Pix4D Fields to generate orthomosaic maps and vegetation index maps, such as normalised difference vegetation index (NDVI) and normalised difference red-edge (NDRE) index. Our dataset is one of the few datasets that provide high-resolution images with rich metadata that cover all growth stages of Indian paddy crops. The dataset is available on IEEE DataPort with DOI, . It can support studies on targeted spraying, disease analysis, and yield estimation.

</details>


### [250] [Evolving CNN Architectures: From Custom Designs to Deep Residual Models for Diverse Image Classification and Detection Tasks](https://arxiv.org/abs/2601.01099)
*Mahmudul Hasan,Mabsur Fatin Bin Hossain*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文比较了自定义CNN架构与预训练/迁移学习CNN模型在五个真实世界图像数据集上的性能，分析了网络深度、残差连接等架构因素对分类和定位性能的影响，并为不同任务复杂度提供了网络设计选择指导。


<details>
  <summary>Details</summary>
Motivation: 研究动机是系统比较自定义CNN架构与广泛使用的预训练/迁移学习CNN模型在不同复杂度的图像识别任务中的性能，分析架构因素如何影响性能，为实际应用中的网络设计选择提供依据。

Method: 方法包括：1) 设计自定义CNN架构；2) 在五个真实世界图像数据集上进行实验，涵盖二分类、细粒度多分类和物体检测任务；3) 分析网络深度、残差连接、特征提取策略等架构因素；4) 将自定义架构扩展到物体检测场景；5) 与预训练和迁移学习模型进行系统比较。

Result: 结果显示：1) 更深层的CNN架构在细粒度多分类数据集上提供显著性能提升；2) 轻量级预训练和迁移学习模型在简单的二分类任务中仍然非常有效；3) 自定义架构成功扩展到物体检测任务，能够识别真实交通场景中的未授权三轮车。

Conclusion: 结论是：通过系统分析自定义CNN架构与预训练/迁移学习模型，本研究为基于任务复杂度和资源约束选择合适的网络设计提供了实用指导，强调了不同架构在不同任务场景下的适用性。

Abstract: This paper presents a comparative study of a custom convolutional neural network (CNN) architecture against widely used pretrained and transfer learning CNN models across five real-world image datasets. The datasets span binary classification, fine-grained multiclass recognition, and object detection scenarios. We analyze how architectural factors, such as network depth, residual connections, and feature extraction strategies, influence classification and localization performance. The results show that deeper CNN architectures provide substantial performance gains on fine-grained multiclass datasets, while lightweight pretrained and transfer learning models remain highly effective for simpler binary classification tasks. Additionally, we extend the proposed architecture to an object detection setting, demonstrating its adaptability in identifying unauthorized auto-rickshaws in real-world traffic scenes. Building upon a systematic analysis of custom CNN architectures alongside pretrained and transfer learning models, this study provides practical guidance for selecting suitable network designs based on task complexity and resource constraints.

</details>


### [251] [Cross-Layer Attentive Feature Upsampling for Low-latency Semantic Segmentation](https://arxiv.org/abs/2601.01167)
*Tianheng Cheng,Xinggang Wang,Junchao Liao,Wenyu Liu*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出了一种名为引导注意力插值（GAI）的新方法，用于高效语义分割，通过自适应插值细粒度高分辨率特征来解决特征不对齐和上下文信息不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于坐标引导的低分辨率特征插值方法（如双线性插值）产生的高分辨率特征粗糙，存在特征不对齐和上下文信息不足的问题。同时，为高分辨率特征丰富语义需要高计算负担，难以满足低延迟推理需求。

Method: 提出引导注意力插值（GAI）方法，通过确定不同分辨率特征之间的空间和语义关系，利用这些关系来插值具有丰富语义的高分辨率特征。GAI可以与任何深度卷积网络集成用于高效语义分割。

Result: 基于GAI的语义分割网络（GAIN）在Cityscapes上达到78.8 mIoU和22.3 FPS，在CamVid上达到80.6 mIoU和64.5 FPS（使用NVIDIA 1080Ti GPU），创下了低延迟语义分割的最新SOTA结果。

Conclusion: GAI方法有效解决了语义分割中高分辨率特征插值的挑战，在保持高精度的同时实现了低延迟推理，为实际应用提供了实用解决方案。

Abstract: Semantic segmentation is a fundamental problem in computer vision and it requires high-resolution feature maps for dense prediction. Current coordinate-guided low-resolution feature interpolation methods, e.g., bilinear interpolation, produce coarse high-resolution features which suffer from feature misalignment and insufficient context information. Moreover, enriching semantics to high-resolution features requires a high computation burden, so that it is challenging to meet the requirement of lowlatency inference. We propose a novel Guided Attentive Interpolation (GAI) method to adaptively interpolate fine-grained high-resolution features with semantic features to tackle these issues. Guided Attentive Interpolation determines both spatial and semantic relations of pixels from features of different resolutions and then leverages these relations to interpolate high-resolution features with rich semantics. GAI can be integrated with any deep convolutional network for efficient semantic segmentation. In experiments, the GAI-based semantic segmentation networks, i.e., GAIN, can achieve78.8 mIoU with 22.3 FPS on Cityscapes and 80.6 mIoU with 64.5 on CamVid using an NVIDIA 1080Ti GPU, which are the new state-of-the-art results of low-latency semantic segmentation. Code and models are available at: https://github.com/hustvl/simpleseg.

</details>


### [252] [Crowded Video Individual Counting Informed by Social Grouping and Spatial-Temporal Displacement Priors](https://arxiv.org/abs/2601.01192)
*Hao Lu,Xuhui Zhu,Wenjing Zhang,Yanan Li,Xiang Bai*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出OMAN++方法用于视频个体计数(VIC)任务，通过引入社会分组先验和时空位移先验，将标准的一对一匹配放宽为一对多匹配，在拥挤场景下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频个体计数方法在拥挤场景（如地铁通勤）中表现不佳，需要专门针对拥挤动态人流的数据集和方法改进。

Method: 1) 构建WuhanMetroCrowd数据集，包含稀疏到密集密度、短到长视频、慢到快流速变化等特征；2) 提出OMAN++方法，利用社会分组先验（放宽一对一匹配为一对多匹配）和时空位移先验（设计位移先验注入器），通过隐式上下文生成器和O2M匹配器实现。

Result: OMAN++在标准基准测试（SenseCrowd、CroHD、MovingDroneCrowd）上优于现有方法，在WuhanMetroCrowd数据集上误差降低38.12%，在拥挤场景中表现突出。

Conclusion: 通过引入社会分组和时空位移先验，将一对一匹配放宽为一对多匹配，显著提升了视频个体计数在拥挤场景下的性能，为拥挤动态人流分析提供了有效解决方案。

Abstract: Video Individual Counting (VIC) is a recently introduced task aiming to estimate pedestrian flux from a video. It extends Video Crowd Counting (VCC) beyond the per-frame pedestrian count. In contrast to VCC that learns to count pedestrians across frames, VIC must identify co-existent pedestrians between frames, which turns out to be a correspondence problem. Existing VIC approaches, however, can underperform in congested scenes such as metro commuting. To address this, we build WuhanMetroCrowd, one of the first VIC datasets that characterize crowded, dynamic pedestrian flows. It features sparse-to-dense density levels, short-to-long video clips, slow-to-fast flow variations, front-to-back appearance changes, and light-to-heavy occlusions. To better adapt VIC approaches to crowds, we rethink the nature of VIC and recognize two informative priors: i) the social grouping prior that indicates pedestrians tend to gather in groups and ii) the spatial-temporal displacement prior that informs an individual cannot teleport physically. The former inspires us to relax the standard one-to-one (O2O) matching used by VIC to one-to-many (O2M) matching, implemented by an implicit context generator and a O2M matcher; the latter facilitates the design of a displacement prior injector, which strengthens not only O2M matching but also feature extraction and model training. These designs jointly form a novel and strong VIC baseline OMAN++. Extensive experiments show that OMAN++ not only outperforms state-of-the-art VIC baselines on the standard SenseCrowd, CroHD, and MovingDroneCrowd benchmarks, but also indicates a clear advantage in crowded scenes, with a 38.12% error reduction on our WuhanMetroCrowd dataset. Code, data, and pretrained models are available at https://github.com/tiny-smart/OMAN.

</details>


### [253] [Real-Time LiDAR Point Cloud Densification for Low-Latency Spatial Data Transmission](https://arxiv.org/abs/2601.01210)
*Kazuhiko Murasaki,Shunsuke Konagai,Masakatsu Aoki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出了一种高速LiDAR点云稠密化方法，通过结合多LiDAR输入和高分辨率彩色图像，使用联合双边滤波CNN架构实现实时（30fps）全高清稠密深度图生成，比现有方法快15倍以上。


<details>
  <summary>Details</summary>
Motivation: 为沉浸式远程呈现系统实现低延迟空间传输，需要解决动态3D场景的密集捕获和实时处理问题。LiDAR传感器能实时捕获3D但产生稀疏点云，因此需要高速点云稠密化方法来生成稠密3D场景，满足实时深度补全需求。

Method: 结合多个LiDAR输入和高分辨率彩色图像，采用联合双边滤波策略，通过卷积神经网络架构实现。该方法实现了实时深度补全，保持实时性能的同时最小化延迟。

Result: 提出的方法能以30fps实时生成全高清分辨率的稠密深度图，比最近的基于训练的深度补全方法快15倍以上。生成的稠密点云具有准确的几何形状，没有多视角不一致或重影伪影。

Conclusion: 该方法成功解决了LiDAR点云稀疏性问题，实现了高速实时稠密化，为沉浸式远程呈现系统的低延迟空间传输提供了有效解决方案。

Abstract: To realize low-latency spatial transmission system for immersive telepresence, there are two major problems: capturing dynamic 3D scene densely and processing them in real time. LiDAR sensors capture 3D in real time, but produce sparce point clouds. Therefore, this paper presents a high-speed LiDAR point cloud densification method to generate dense 3D scene with minimal latency, addressing the need for on-the-fly depth completion while maintaining real-time performance. Our approach combines multiple LiDAR inputs with high-resolution color images and applies a joint bilateral filtering strategy implemented through a convolutional neural network architecture. Experiments demonstrate that the proposed method produces dense depth maps at full HD resolution in real time (30 fps), which is over 15x faster than a recent training-based depth completion approach. The resulting dense point clouds exhibit accurate geometry without multiview inconsistencies or ghosting artifacts.

</details>


### [254] [Advanced Machine Learning Approaches for Enhancing Person Re-Identification Performance](https://arxiv.org/abs/2601.01356)
*Dang H. Pham,Tu N. Nguyen,Hoa N. Nguyen*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了三种行人重识别方法：SCM-ReID（监督对比学习）、IQAGA/DAPRH（无监督域适应）和ViTC-UReID（完全无监督），在多个数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 行人重识别在智能监控系统中至关重要，但面临外观变化、域偏移和标注数据有限等挑战。需要开发更鲁棒的方法来处理监督、无监督域适应和完全无监督三种场景。

Method: 1. SCM-ReID：集成监督对比学习与混合损失优化（分类、中心、三元组和质心三元组损失）
2. IQAGA/DAPRH：基于GAN的图像增强、域不变映射和伪标签精炼来处理域适应
3. ViTC-UReID：基于Vision Transformer的特征编码和相机感知代理学习，结合全局和局部注意力

Result: 在Market-1501、CUHK03、DukeMTMC-reID和MSMT17等数据集上取得显著性能提升，在域适应场景中mAP和Rank-1指标提升高达12%，超越了现有方法。

Conclusion: 提出的三种方法有效解决了行人重识别中的特征学习、域适应和标签噪声处理等关键问题，为实际监控系统的鲁棒部署铺平了道路。

Abstract: Person re-identification (ReID) plays a critical role in intelligent surveillance systems by linking identities across multiple cameras in complex environments. However, ReID faces significant challenges such as appearance variations, domain shifts, and limited labeled data. This dissertation proposes three advanced approaches to enhance ReID performance under supervised, unsupervised domain adaptation (UDA), and fully unsupervised settings. First, SCM-ReID integrates supervised contrastive learning with hybrid loss optimization (classification, center, triplet, and centroid-triplet losses), improving discriminative feature representation and achieving state-of-the-art accuracy on Market-1501 and CUHK03 datasets. Second, for UDA, IQAGA and DAPRH combine GAN-based image augmentation, domain-invariant mapping, and pseudo-label refinement to mitigate domain discrepancies and enhance cross-domain generalization. Experiments demonstrate substantial gains over baseline methods, with mAP and Rank-1 improvements up to 12% in challenging transfer scenarios. Finally, ViTC-UReID leverages Vision Transformer-based feature encoding and camera-aware proxy learning to boost unsupervised ReID. By integrating global and local attention with camera identity constraints, this method significantly outperforms existing unsupervised approaches on large-scale benchmarks. Comprehensive evaluations across CUHK03, Market-1501, DukeMTMC-reID, and MSMT17 confirm the effectiveness of the proposed methods. The contributions advance ReID research by addressing key limitations in feature learning, domain adaptation, and label noise handling, paving the way for robust deployment in real-world surveillance systems.

</details>


### [255] [Unsupervised SE(3) Disentanglement for in situ Macromolecular Morphology Identification from Cryo-Electron Tomography](https://arxiv.org/abs/2601.01364)
*Mostofa Rafid Uddin,Mahek Vora,Qifeng Wu,Muyuan Chen,Min Xu*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了一种解耦深度表示学习框架，用于从冷冻电子断层扫描数据中分离SE(3)变换和形态内容，以发现新的分子形态。


<details>
  <summary>Details</summary>
Motivation: 冷冻电子断层扫描(cryo-ET)可直接可视化细胞内大分子的3D形态，但现有基于期望最大化的方法常遗漏罕见重要形态且需要大量手动超参数调优。

Method: 提出解耦深度表示学习框架，在表示空间中将SE(3)变换与形态内容分离；包含新颖的多选择学习模块，专门处理高噪声cryo-ET数据；学习到的形态内容用于生成模板形态。

Result: 在模拟和真实cryo-ET数据集上的实验显示，相比先前方法有明显改进，包括发现先前未识别的大分子形态。

Conclusion: 该框架有效解决了cryo-ET数据中形态推断的逆问题，能够发现罕见但重要的分子形态，减少了手动调参需求。

Abstract: Cryo-electron tomography (cryo-ET) provides direct 3D visualization of macromolecules inside the cell, enabling analysis of their in situ morphology. This morphology can be regarded as an SE(3)-invariant, denoised volumetric representation of subvolumes extracted from tomograms. Inferring morphology is therefore an inverse problem of estimating both a template morphology and its SE(3) transformation. Existing expectation-maximization based solution to this problem often misses rare but important morphologies and requires extensive manual hyperparameter tuning. Addressing this issue, we present a disentangled deep representation learning framework that separates SE(3) transformations from morphological content in the representation space. The framework includes a novel multi-choice learning module that enables this disentanglement for highly noisy cryo-ET data, and the learned morphological content is used to generate template morphologies. Experiments on simulated and real cryo-ET datasets demonstrate clear improvements over prior methods, including the discovery of previously unidentified macromolecular morphologies.

</details>


### [256] [Robust Ship Detection and Tracking Using Modified ViBe and Backwash Cancellation Algorithm](https://arxiv.org/abs/2601.01481)
*Mohammad Hassan Saghafi,Seyed Majid Noorhosseini,Seyed Abolfazl Seyed Javadein,Hadi Khalili*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出一种用于海岸视频序列中船舶检测与跟踪的鲁棒实时方法，改进ViBe算法降低船舶丢失概率，并引入尾流消除技术。


<details>
  <summary>Details</summary>
Motivation: 海岸场景具有不可预测性和动态特性，需要能够适应这些条件的鲁棒检测方法。传统方法在船舶检测中容易受到海浪、光线变化等干扰，导致船舶丢失或误检。

Method: 1) 改进ViBe移动物体检测算法，降低船舶丢失概率，增强对海浪和光线变化的鲁棒性，实现快速背景更新；2) 基于船舶几何特性和亮度失真概念，提出新的尾流消除方法。

Result: 实验结果表明，所提出的策略和方法在船舶检测和跟踪方面具有出色性能，能够实现实时且精确的检测跟踪。

Conclusion: 该方法能够有效处理海岸视频序列中的船舶检测与跟踪问题，在动态和不可预测的海岸环境中表现出鲁棒性和实时性。

Abstract: In this paper, we propose a robust real time detection and tracking method for detecting ships in a coastal video sequences. Since coastal scenarios are unpredictable and scenes have dynamic properties it is essential to apply detection methods that are robust to these conditions. This paper presents modified ViBe for moving object detection which detects ships and backwash. In the modified ViBe the probability of losing ships is decreased in comparison with the original ViBe. It is robust to natural sea waves and variation of lights and is capable of quickly updating the background. Based on geometrical properties of ship and some concepts such as brightness distortion, a new method for backwash cancellation is proposed. Experimental results demonstrate that the proposed strategy and methods have outstanding performance in ship detection and tracking. These results also illustrate real time and precise performance of the proposed strategy.

</details>


### [257] [A Novel Deep Learning Method for Segmenting the Left Ventricle in Cardiac Cine MRI](https://arxiv.org/abs/2601.01512)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.CV

Relevance: 15.0

TL;DR: GBU-Net是一种基于分组批归一化U-Net框架的新型深度学习网络，专门用于短轴电影MRI扫描中左心室的精确语义分割，在SunnyBrook测试数据集上达到97%的Dice分数。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对心脏MRI左心室分割的深度学习网络，解决传统CNN分割方法在捕捉上下文信息方面的不足，提高分割精度以支持手术机器人和医学分析应用。

Method: 采用分组批归一化U-Net框架，包含下采样路径进行特征提取和上采样路径进行细节恢复，针对医学影像进行优化，加入改进的上下文理解技术，并在45名患者的805个左心室MRI扫描数据集上进行训练和评估。

Result: GBU-Net在左心室分割任务中显著优于现有方法，在SunnyBrook测试数据集上通过集成方法达到97%的Dice分数，超越了标准的Dice系数和平均垂直距离等评估指标。

Conclusion: GBU-Net通过其创新的设计和上下文信息捕捉能力，为心脏MRI左心室分割提供了更高的精度和更好的上下文理解，在医学影像分析领域具有重要应用价值。

Abstract: This research aims to develop a novel deep learning network, GBU-Net, utilizing a group-batch-normalized U-Net framework, specifically designed for the precise semantic segmentation of the left ventricle in short-axis cine MRI scans. The methodology includes a down-sampling pathway for feature extraction and an up-sampling pathway for detail restoration, enhanced for medical imaging. Key modifications include techniques for better contextual understanding crucial in cardiac MRI segmentation. The dataset consists of 805 left ventricular MRI scans from 45 patients, with comparative analysis using established metrics such as the dice coefficient and mean perpendicular distance. GBU-Net significantly improves the accuracy of left ventricle segmentation in cine MRI scans. Its innovative design outperforms existing methods in tests, surpassing standard metrics like the dice coefficient and mean perpendicular distance. The approach is unique in its ability to capture contextual information, often missed in traditional CNN-based segmentation. An ensemble of the GBU-Net attains a 97% dice score on the SunnyBrook testing dataset. GBU-Net offers enhanced precision and contextual understanding in left ventricle segmentation for surgical robotics and medical analysis.

</details>


### [258] [Animated 3DGS Avatars in Diverse Scenes with Consistent Lighting and Shadows](https://arxiv.org/abs/2601.01660)
*Aymen Mir,Riza Alp Guler,Jian Wang,Gerard Pons-Moll,Bing Zhou*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出Deep Gaussian Shadow Maps (DGSM)方法，为3D高斯泼溅(3DGS)表示中的动态角色提供一致的光照和阴影，无需网格化处理。


<details>
  <summary>Details</summary>
Motivation: 在3DGS场景中，当动画角色与场景或动态物体交互时，需要保持光照和阴影的一致性。传统方法难以在体积化3DGS表示中实现实时阴影计算。

Method: 1. 提出DGSM：基于经典深度阴影映射思想，针对3DGS体积表示设计，通过闭合形式的光线累积计算体积阴影；2. 使用八面体图集存储同心径向壳的透射率；3. 通过球形谐波基的HDRI探针近似局部环境光照，应用快速每高斯辐射传输。

Result: 在ScanNet++、DL3DV和SuperSplat场景中，成功为AvatarX和ActorsHQ角色提供环境一致的光照，实现单角色和多角色设置下的连贯阴影和重光照效果。

Conclusion: DGSM和SH重光照方法完全在体积化3DGS表示中运行，实现了连贯的阴影和重光照效果，避免了网格化处理的需求。

Abstract: We present a method for consistent lighting and shadows when animated 3D Gaussian Splatting (3DGS) avatars interact with 3DGS scenes or with dynamic objects inserted into otherwise static scenes. Our key contribution is Deep Gaussian Shadow Maps (DGSM), a modern analogue of the classical shadow mapping algorithm tailored to the volumetric 3DGS representation. Building on the classic deep shadow mapping idea, we show that 3DGS admits closed form light accumulation along light rays, enabling volumetric shadow computation without meshing. For each estimated light, we tabulate transmittance over concentric radial shells and store them in octahedral atlases, which modern GPUs can sample in real time per query to attenuate affected scene Gaussians and thus cast and receive shadows consistently. To relight moving avatars, we approximate the local environment illumination with HDRI probes represented in a spherical harmonic (SH) basis and apply a fast per Gaussian radiance transfer, avoiding explicit BRDF estimation or offline optimization. We demonstrate environment consistent lighting for avatars from AvatarX and ActorsHQ, composited into ScanNet++, DL3DV, and SuperSplat scenes, and show interactions with inserted objects. Across single and multi avatar settings, DGSM and SH relighting operate fully in the volumetric 3DGS representation, yielding coherent shadows and relighting while avoiding meshing.

</details>


### [259] [Robust Egocentric Visual Attention Prediction Through Language-guided Scene Context-aware Learning](https://arxiv.org/abs/2601.01818)
*Sungjune Park,Hongda Mao,Qingshuang Chen,Yong Man Ro,Yelin Kim*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出语言引导的场景上下文感知学习框架，用于预测第一人称视觉注意力，通过语言描述总结视频上下文，并设计训练目标聚焦目标区域、抑制无关区域，在Ego4D和AEA数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 随着第一人称视频分析需求增长，预测相机佩戴者的视觉注意力变得重要但具有挑战性，因为动态第一人称场景具有复杂性和模糊性。研究表明场景上下文信息在调节人类注意力中起关键作用。

Method: 提出语言引导的场景上下文感知学习框架：1) 设计上下文感知器，基于语言场景描述总结第一人称视频，生成上下文感知的视频表示；2) 引入两个训练目标：聚焦目标兴趣区域和抑制无关区域。

Result: 在Ego4D和Aria Everyday Activities (AEA)数据集上进行广泛实验，方法达到最先进的性能，并在多样化的动态第一人称场景中展现出增强的鲁棒性。

Conclusion: 提出的语言引导场景上下文感知学习框架能够有效预测第一人称视觉注意力，通过利用语言描述和上下文感知机制，在复杂动态场景中实现鲁棒的注意力预测。

Abstract: As the demand for analyzing egocentric videos grows, egocentric visual attention prediction, anticipating where a camera wearer will attend, has garnered increasing attention. However, it remains challenging due to the inherent complexity and ambiguity of dynamic egocentric scenes. Motivated by evidence that scene contextual information plays a crucial role in modulating human attention, in this paper, we present a language-guided scene context-aware learning framework for robust egocentric visual attention prediction. We first design a context perceiver which is guided to summarize the egocentric video based on a language-based scene description, generating context-aware video representations. We then introduce two training objectives that: 1) encourage the framework to focus on the target point-of-interest regions and 2) suppress distractions from irrelevant regions which are less likely to attract first-person attention. Extensive experiments on Ego4D and Aria Everyday Activities (AEA) datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance and enhanced robustness across diverse, dynamic egocentric scenarios.

</details>


### [260] [Face Normal Estimation from Rags to Riches](https://arxiv.org/abs/2601.01950)
*Meng Wang,Wenjing Dai,Jiawan Zhang,Xiaojie Guo*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出了一种从粗到细的人脸法线估计方法，通过小数据集训练粗估计模型生成引导样本，再使用自注意力机制进行细化，显著减少对大规模配对数据和计算资源的需求。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸法线估计方法严重依赖大规模配对数据进行训练，这限制了其应用范围。本文旨在通过开发一种从粗到细的估计器来缓解这一需求，减少对大量训练数据和计算资源的依赖。

Method: 1. 首先使用小数据集训练一个简洁模型生成粗糙的人脸法线作为引导样本；2. 采用自注意力机制捕获长距离依赖关系，修复粗糙法线中的局部伪影；3. 定制细化网络，将输入人脸图像与对应的引导样本映射到高质量细粒度人脸法线。

Result: 实验和消融研究表明，该方法在训练成本和估计质量方面均优于现有最先进方法，同时显著减少了配对数据和计算资源的需求。

Conclusion: 提出的从粗到细人脸法线估计方法通过逻辑功能分割，有效降低了对大规模配对数据和计算资源的依赖，在保持高质量估计的同时实现了更高的效率。

Abstract: Although recent approaches to face normal estimation have achieved promising results, their effectiveness heavily depends on large-scale paired data for training. This paper concentrates on relieving this requirement via developing a coarse-to-fine normal estimator. Concretely, our method first trains a neat model from a small dataset to produce coarse face normals that perform as guidance (called exemplars) for the following refinement. A self-attention mechanism is employed to capture long-range dependencies, thus remedying severe local artifacts left in estimated coarse facial normals. Then, a refinement network is customized for the sake of mapping input face images together with corresponding exemplars to fine-grained high-quality facial normals. Such a logical function split can significantly cut the requirement of massive paired data and computational resource. Extensive experiments and ablation studies are conducted to demonstrate the efficacy of our design and reveal its superiority over state-of-the-art methods in terms of both training expense as well as estimation quality. Our code and models are open-sourced at: https://github.com/AutoHDR/FNR2R.git.

</details>


### [261] [MCD-Net: A Lightweight Deep Learning Baseline for Optical-Only Moraine Segmentation](https://arxiv.org/abs/2601.02091)
*Zhehuan Cao,Fiseha Berhanu Tesema,Ping Fu,Jianfeng Ren,Ahmed Nasr*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出了首个大规模仅使用光学图像的冰碛物分割数据集，并开发了轻量级MCD-Net模型，在降低60%计算成本的同时达到62.3% mIoU，为高海拔冰川监测提供了可部署的基线。


<details>
  <summary>Details</summary>
Motivation: 冰川分割对重建过去冰川动态和评估气候驱动的景观变化至关重要，但弱光学对比度和高分辨率DEM数据的有限可用性阻碍了自动化制图。现有方法主要依赖DEM数据，缺乏仅基于光学图像的冰碛物分割数据集和基准。

Method: 1) 创建了首个大规模仅光学图像的冰碛物分割数据集，包含3,340张来自Google Earth的高分辨率手动标注图像，覆盖中国四川和云南冰川区域；2) 开发了轻量级MCD-Net模型，集成MobileNetV2编码器、卷积块注意力模块(CBAM)和DeepLabV3+解码器；3) 与更深骨干网络(ResNet152, Xception)进行基准测试。

Result: MCD-Net达到62.3%的平均交并比(mIoU)和72.8%的Dice系数，同时计算成本降低60%以上。虽然山脊描绘受亚像素宽度和光谱模糊性限制，但结果表明仅光学图像就能提供可靠的冰碛体分割。

Conclusion: 该研究为冰碛物特定分割建立了可复现的基准，为高海拔冰川监测提供了可部署的基线。数据集和代码已公开，促进了该领域的研究。

Abstract: Glacial segmentation is essential for reconstructing past glacier dynamics and evaluating climate-driven landscape change. However, weak optical contrast and the limited availability of high-resolution DEMs hinder automated mapping. This study introduces the first large-scale optical-only moraine segmentation dataset, comprising 3,340 manually annotated high-resolution images from Google Earth covering glaciated regions of Sichuan and Yunnan, China. We develop MCD-Net, a lightweight baseline that integrates a MobileNetV2 encoder, a Convolutional Block Attention Module (CBAM), and a DeepLabV3+ decoder. Benchmarking against deeper backbones (ResNet152, Xception) shows that MCD-Net achieves 62.3\% mean Intersection over Union (mIoU) and 72.8\% Dice coefficient while reducing computational cost by more than 60\%. Although ridge delineation remains constrained by sub-pixel width and spectral ambiguity, the results demonstrate that optical imagery alone can provide reliable moraine-body segmentation. The dataset and code are publicly available at https://github.com/Lyra-alpha/MCD-Net, establishing a reproducible benchmark for moraine-specific segmentation and offering a deployable baseline for high-altitude glacial monitoring.

</details>


### [262] [InpaintHuman: Reconstructing Occluded Humans with Multi-Scale UV Mapping and Identity-Preserving Diffusion Inpainting](https://arxiv.org/abs/2601.02098)
*Jinlong Fan,Shanshan Zhao,Liang Zheng,Jing Zhang,Yuxiang Yang,Mingming Gong*

Main category: cs.CV

Relevance: 15.0

TL;DR: InpaintHuman：一种从遮挡单目视频生成完整可动画3D人体化身的新方法，通过多尺度UV参数化表示和身份保持扩散修复模块解决严重遮挡下的重建问题。


<details>
  <summary>Details</summary>
Motivation: 从单目视频重建完整可动画的3D人体化身面临严重遮挡的挑战，现有基于3D高斯泼溅的方法在遮挡区域会产生几何损坏和时间不一致性，需要更鲁棒的解决方案。

Method: 提出两个关键创新：1) 多尺度UV参数化表示，采用分层从粗到细的特征插值，实现遮挡区域的鲁棒重建；2) 身份保持扩散修复模块，结合文本反演和语义条件引导，实现主体特定、时间一致性的补全。

Result: 在合成基准测试（PeopleSnapshot, ZJU-MoCap）和真实场景（OcMotion）上展示了竞争性性能，在不同姿态和视角下重建质量有持续改进。

Conclusion: InpaintHuman能够从遮挡单目视频生成高保真、完整且可动画的3D人体化身，相比现有方法在遮挡处理和时间一致性方面有显著提升。

Abstract: Reconstructing complete and animatable 3D human avatars from monocular videos remains challenging, particularly under severe occlusions. While 3D Gaussian Splatting has enabled photorealistic human rendering, existing methods struggle with incomplete observations, often producing corrupted geometry and temporal inconsistencies. We present InpaintHuman, a novel method for generating high-fidelity, complete, and animatable avatars from occluded monocular videos. Our approach introduces two key innovations: (i) a multi-scale UV-parameterized representation with hierarchical coarse-to-fine feature interpolation, enabling robust reconstruction of occluded regions while preserving geometric details; and (ii) an identity-preserving diffusion inpainting module that integrates textual inversion with semantic-conditioned guidance for subject-specific, temporally coherent completion. Unlike SDS-based methods, our approach employs direct pixel-level supervision to ensure identity fidelity. Experiments on synthetic benchmarks (PeopleSnapshot, ZJU-MoCap) and real-world scenarios (OcMotion) demonstrate competitive performance with consistent improvements in reconstruction quality across diverse poses and viewpoints.

</details>


### [263] [DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies](https://arxiv.org/abs/2601.02267)
*Renke Wang,Zhenyu Zhang,Ying Tai,Jian Yang*

Main category: cs.CV

Relevance: 15.0

TL;DR: DiffProxy是一个从多视角图像恢复人体网格的新框架，利用扩散生成先验桥接合成训练和真实世界泛化，通过多条件机制生成多视角一致的人体代理，在合成数据上训练但在真实世界基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决人体网格恢复中的基本挑战：真实世界数据集包含不完美的标注会偏置模型训练，而合成数据虽有精确监督但存在域差距。需要桥接合成训练和真实世界泛化。

Method: 1) 多条件机制生成多视角一致、像素对齐的人体代理；2) 手部细化模块结合灵活视觉提示增强局部细节；3) 不确定性感知的测试时缩放方法提升优化鲁棒性。完全在合成数据上训练。

Result: 在五个真实世界基准测试中达到最先进性能，在遮挡和部分视角等挑战性场景下表现出强大的零样本泛化能力。

Conclusion: DiffProxy通过扩散生成先验有效桥接了合成训练和真实世界泛化，证明了在合成数据上训练但能在真实场景中实现优异性能的可行性。

Abstract: Human mesh recovery from multi-view images faces a fundamental challenge: real-world datasets contain imperfect ground-truth annotations that bias the models' training, while synthetic data with precise supervision suffers from domain gap. In this paper, we propose DiffProxy, a novel framework that generates multi-view consistent human proxies for mesh recovery. Central to DiffProxy is leveraging the diffusion-based generative priors to bridge the synthetic training and real-world generalization. Its key innovations include: (1) a multi-conditional mechanism for generating multi-view consistent, pixel-aligned human proxies; (2) a hand refinement module that incorporates flexible visual prompts to enhance local details; and (3) an uncertainty-aware test-time scaling method that increases robustness to challenging cases during optimization. These designs ensure that the mesh recovery process effectively benefits from the precise synthetic ground truth and generative advantages of the diffusion-based pipeline. Trained entirely on synthetic data, DiffProxy achieves state-of-the-art performance across five real-world benchmarks, demonstrating strong zero-shot generalization particularly on challenging scenarios with occlusions and partial views. Project page: https://wrk226.github.io/DiffProxy.html

</details>


### [264] [360DVO: Deep Visual Odometry for Monocular 360-Degree Camera](https://arxiv.org/abs/2601.02309)
*Xiaopeng Guo,Yinzhe Xu,Huajian Huang,Sai-Kit Yeung*

Main category: cs.CV

Relevance: 15.0

TL;DR: 360DVO：首个基于深度学习的单目全景视觉里程计框架，通过失真感知球形特征提取器和全景可微分束调整模块，显著提升在挑战性场景下的鲁棒性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有全景视觉里程计方法依赖手工特征或光度目标，在激进运动和光照变化等挑战性场景中缺乏鲁棒性，需要更强大的深度学习解决方案。

Method: 提出失真感知球形特征提取器（DAS-Feat）自适应学习抗失真特征，结合稀疏特征块建立约束，通过全景可微分束调整模块（ODBA）进行有效位姿估计。

Result: 在真实世界基准测试和公开合成数据集上，360DVO超越现有最佳基线方法，鲁棒性提升50%，精度提升37.5%。

Conclusion: 360DVO是首个基于深度学习的全景视觉里程计框架，通过深度学习特征提取和可微分优化，显著提升了在挑战性场景下的性能。

Abstract: Monocular omnidirectional visual odometry (OVO) systems leverage 360-degree cameras to overcome field-of-view limitations of perspective VO systems. However, existing methods, reliant on handcrafted features or photometric objectives, often lack robustness in challenging scenarios, such as aggressive motion and varying illumination. To address this, we present 360DVO, the first deep learning-based OVO framework. Our approach introduces a distortion-aware spherical feature extractor (DAS-Feat) that adaptively learns distortion-resistant features from 360-degree images. These sparse feature patches are then used to establish constraints for effective pose estimation within a novel omnidirectional differentiable bundle adjustment (ODBA) module. To facilitate evaluation in realistic settings, we also contribute a new real-world OVO benchmark. Extensive experiments on this benchmark and public synthetic datasets (TartanAir V2 and 360VO) demonstrate that 360DVO surpasses state-of-the-art baselines (including 360VO and OpenVSLAM), improving robustness by 50% and accuracy by 37.5%. Homepage: https://chris1004336379.github.io/360DVO-homepage

</details>


### [265] [Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318)
*Roja Sahoo,Anoop Namboodiri*

Main category: cs.CV

Relevance: 15.0

TL;DR: Fusion2Print (F2P) 提出首个系统捕获和融合成对闪光-非闪光接触式指纹的框架，通过注意力融合网络和U-Net增强模块提升脊线清晰度，实现与接触式指纹兼容的跨域识别。


<details>
  <summary>Details</summary>
Motivation: 接触式指纹识别存在卫生和便利性问题，而接触式图像常因光照变化、皮下皮肤变色和镜面反射导致脊线清晰度下降。闪光捕获保留脊线细节但引入噪声，非闪光捕获减少噪声但降低脊线对比度。

Method: 构建成对闪光-非闪光数据集FNF Database，通过手动减法分离脊线保留信号。使用轻量级注意力融合网络整合两种模态，强调信息通道并抑制噪声，然后U-Net增强模块生成最优加权灰度图像。最后通过深度嵌入模型生成兼容接触式和接触式指纹的统一嵌入空间表示。

Result: F2P显著提升脊线清晰度，在识别性能上优于单捕获基线（Verifinger, DeepPrint），达到AUC=0.999，EER=1.12%的优异性能。

Conclusion: Fusion2Print框架通过系统融合闪光和非闪光接触式指纹，有效解决了接触式指纹识别的脊线清晰度问题，实现了与接触式指纹系统兼容的高性能跨域识别。

Abstract: Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).

</details>


### [266] [Simulations of MRI Guided and Powered Ferric Applicators for Tetherless Delivery of Therapeutic Interventions](https://arxiv.org/abs/2601.00981)
*Wenhui Chu,Khang Tran,Nikolaos V. Tsekos*

Main category: cs.RO

Relevance: 15.0

TL;DR: 开发了一个用于MRI引导血管内介入手术的计算平台，通过处理MRI数据提取血管床、创建虚拟通道作为安全约束，并生成磁场梯度波形来操控磁性器械


<details>
  <summary>Details</summary>
Motivation: MRI引导的血管内介入手术需要精确的术前规划和实时控制，现有技术缺乏完整的计算平台来确保手术安全性和器械操控的精确性

Method: 采用双向数据管道连接MRI扫描仪、计算核心和操作员，处理多层MRI数据提取血管结构，创建虚拟通道作为安全约束，基于血管几何特征和MRI安全参数生成磁场梯度波形，支持不同血流剖面建模

Result: 实现了完整的计算平台，能够评估选定血管路径的安全性，生成器械操控所需的磁场梯度波形，为实时操作提供软件架构基础

Conclusion: 该平台为MRI引导的血管内介入手术提供了有效的术前规划和建模工具，通过虚拟通道约束和磁场梯度控制确保手术安全性，为未来实时操作研究奠定基础

Abstract: Magnetic Resonance Imaging (MRI) is a well-established modality for pre-operative planning and is also explored for intra-operative guidance of procedures such as intravascular interventions. Among the experimental robot-assisted technologies, the magnetic field gradients of the MRI scanner are used to power and maneuver ferromagnetic applicators for accessing sites in the patient's body via the vascular network. In this work, we propose a computational platform for preoperative planning and modeling of MRI-powered applicators inside blood vessels. This platform was implemented as a two-way data and command pipeline that links the MRI scanner, the computational core, and the operator. The platform first processes multi-slice MR data to extract the vascular bed and then fits a virtual corridor inside the vessel. This corridor serves as a virtual fixture (VF), a forbidden region for the applicators to avoid vessel perforation or collision. The geometric features of the vessel centerline, the VF, and MRI safety compliance (dB/dt, max available gradient) are then used to generate magnetic field gradient waveforms. Different blood flow profiles can be user-selected, and those parameters are used for modeling the applicator's maneuvering. The modeling module further generates cues about whether the selected vascular path can be safely maneuvered. Given future experimental studies that require a real-time operation, the platform was implemented on the Qt framework (C/C++) with software modules performing specific tasks running on dedicated threads: PID controller, generation of VF, generation of MR gradient waveforms.

</details>


### [267] [An Energy-Efficient Smart Bus Transport Management System with Blind-Spot Collision Detection Ability](https://arxiv.org/abs/2601.01274)
*Md. Sadman Haque,Zobaer Ibn Razzaque,Robiul Awoul Robin,Fahim Hafiz,Riasat Azim*

Main category: eess.SY

Relevance: 15.0

TL;DR: 提出智能公交系统，包含深度学习盲点预警、自动公交站检测、物联网太阳能智能公交站、RFID乘客追踪和实时公交跟踪，提升安全性、效率和可持续性


<details>
  <summary>Details</summary>
Motivation: 发展中国家公交系统缺乏实时位置更新，乘客体验差；非指定地点停车造成安全隐患和交通拥堵；盲点和交通违规增加事故风险

Method: 1) 深度学习盲点预警系统；2) 自动公交站检测；3) 物联网太阳能智能公交站显示实时乘客数量；4) RFID卡系统追踪乘客上下车；5) 智能门系统确保安全有序上下车；6) 实时公交跟踪；7) HTTP服务器连接所有系统

Result: 实时盲点检测效率约99%；精确停在公交站；服务器提供实时位置更新给用户和公交站；节能公交站节省12.71kWh能源

Conclusion: 提出的智能公交系统能显著提升公交安全性、效率和可持续性，通过多种技术集成解决发展中国家公交系统的主要问题

Abstract: Public bus transport systems in developing countries often suffer from a lack of real-time location updates and for users, making commuting inconvenient and unreliable for passengers. Furthermore, stopping at undesired locations rather than designated bus stops creates safety risks and contributes to roadblocks, often causing traffic congestion. Additionally, issues such as blind spots, along with a lack of following traffic laws, increase the chances of accidents. In this work, we address these challenges by proposing a smart public bus system along with intelligent bus stops that enhance safety, efficiency, and sustainability. Our approach includes a deep learning-based blind-spot warning system to help drivers avoid accidents with automated bus-stop detection to accurately identify bus stops, improving transit efficiency. We also introduce IoT-based solar-powered smart bus stops that show real-time passenger counts, along with an RFID-based card system to track where passengers board and exit. A smart door system ensures safer and more organised boarding, while real-time bus tracking keeps passengers informed. To connect all these features, we use an HTTP-based server for seamless communication between the interconnected network systems. Our proposed system demonstrated approximately 99% efficiency in real-time blind spot detection while stopping precisely at the bus stops. Furthermore, the server showed real-time location updates both to the users and at the bus stops, enhancing commuting efficiency. The proposed energy-efficient bus stop demonstrated 12.71kWh energy saving, promoting sustainable architecture. Full implementation and source code are available at: https://github.com/sadman-adib/MoveMe-IoT

</details>


### [268] [Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification](https://arxiv.org/abs/2601.01807)
*Ubaidullah,Muhammad Abid Hussain,Mohsin Raza Jafri,Rozi Khan,Moid Sandhu,Abd Ullah Khan,Hyundong Shin*

Main category: cs.CV

Relevance: 10.0

TL;DR: LUMPNet是一种用于早期检测牛结节性皮肤病的混合深度学习模型，结合了YOLOv11目标检测、EfficientNet分类器和新型自适应混合优化器，在公开数据集上取得了99%的训练准确率和98%的验证准确率。


<details>
  <summary>Details</summary>
Motivation: 牛结节性皮肤病（LSD）是一种传染性病毒性疾病，严重威胁畜牧业健康、全球经济和粮食安全。由于其快速传播特性，早期精确识别对于预防疫情爆发和确保及时干预至关重要。

Method: 提出LUMPNet混合深度学习框架：1）使用YOLOv11检测和定位牛图像中的皮肤结节和病变；2）采用基于EfficientNet的CNN分类器对定位区域进行LSD感染或健康分类；3）提出新型自适应混合优化器来稳定和加速YOLOv11与EfficientNet混合模型的训练。

Result: 在公开数据集上评估，LUMPNet达到99%的LSD检测训练准确率和98%的验证准确率，优于现有方案。与使用AdamW优化器的优化EfficientNet-B0模型相比，LUMPNet表现出更优越的性能。

Conclusion: LUMPNet为牛结节性皮肤病的早期检测提供了一种有效的混合深度学习解决方案，能够准确检测和分类皮肤病变，有助于及时干预和疫情控制。

Abstract: Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.

</details>


### [269] [SketchRodGS: Sketch-based Extraction of Slender Geometries for Animating Gaussian Splatting Scenes](https://arxiv.org/abs/2601.02072)
*Haato Watanabe,Nobuyuki Umetani*

Main category: cs.GR

Relevance: 10.0

TL;DR: 提出一种从高斯泼溅场景中提取细长物体折线表示的方法，通过用户草图输入和屏幕空间最短路径分析构建折线网格


<details>
  <summary>Details</summary>
Motivation: 物理模拟细长弹性物体通常需要折线离散化，但从高斯泼溅构建折线具有挑战性，因为高斯泼溅缺乏连接信息且高斯基元配置包含大量噪声

Method: 从用户草图输入提取高斯泼溅场景中细长物体的折线表示，使用屏幕空间最短路径分析（可通过动态规划高效求解）来鲁棒地构建表示细长部分的折线网格

Result: 在多个实际场景示例中证明了方法的有效性

Conclusion: 该方法能够从高斯泼溅场景中有效提取细长物体的折线表示，解决了连接信息缺失和噪声问题

Abstract: Physics simulation of slender elastic objects often requires discretization as a polyline. However, constructing a polyline from Gaussian splatting is challenging as Gaussian splatting lacks connectivity information and the configuration of Gaussian primitives contains much noise. This paper presents a method to extract a polyline representation of the slender part of the objects in a Gaussian splatting scene from the user's sketching input. Our method robustly constructs a polyline mesh that represents the slender parts using the screen-space shortest path analysis that can be efficiently solved using dynamic programming. We demonstrate the effectiveness of our approach in several in-the-wild examples.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [270] [CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations](https://arxiv.org/abs/2601.00821)
*Tao An*

Main category: cs.AI

Relevance: 85.0

TL;DR: CogCanvas是一个无需训练的长对话处理框架，通过提取认知构件并组织成时间感知图来解决LLM上下文窗口限制与信息保真度之间的冲突，在时间推理和多跳因果推理上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长对话时面临上下文窗口限制与信息保真度的基本矛盾。现有方法（截断和摘要）要么丢弃早期信息，要么丢失细微细节，需要一种能保持信息完整性的解决方案。

Method: CogCanvas是一个无需训练的框架，从对话轮次中提取基于原文的认知构件（决策、事实、提醒），并将它们组织成时间感知图，实现抗压缩的检索。

Result: 在LoCoMo基准测试中，CogCanvas达到34.7%总体准确率，优于RAG（25.6%）和GraphRAG（13.7%）。在时间推理上达到31.5%（RAG为9.3%），多跳因果推理达到81.0%通过率（GraphRAG为40.0%）。可控基准显示97.5%召回率和93.0%精确匹配保留。

Conclusion: 虽然经过专门训练的方法能达到更高绝对分数，但CogCanvas作为无需训练的方法为实践者提供了立即可部署的替代方案，显著优于标准基线方法。

Abstract: Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.
  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.
  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.

</details>


### [271] [Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis](https://arxiv.org/abs/2601.00828)
*Yin Li*

Main category: cs.AI

Relevance: 85.0

TL;DR: 研究发现LLM内在自我纠正能力存在"准确率-纠正悖论"：较弱模型（GPT-3.5）比更强模型（DeepSeek）有更高的内在纠正率，挑战了模型能力与自我改进呈线性关系的假设。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM被认为具有自我纠正能力，但近期研究表明内在自我纠正（无需外部反馈）效果有限。本研究旨在系统分解自我纠正能力，探究不同模型在自我纠正中的表现差异。

Method: 将自我纠正分解为三个子能力：错误检测、错误定位和错误纠正。在GSM8K-Complex数据集（n=500/模型，共346个错误）上进行跨模型实验，使用三个主要LLM（GPT-3.5、DeepSeek、Claude），分析错误深度与纠正成功率的关系。

Result: 发现"准确率-纠正悖论"：较弱模型（GPT-3.5，66%准确率）的内在纠正率（26.8%）比更强模型（DeepSeek，94%准确率）的16.7%高1.6倍。错误检测率在架构间差异巨大（10%-82%），但检测能力不能预测纠正成功率（Claude仅检测10%错误但纠正29%）。提供错误位置提示反而损害所有模型表现。

Conclusion: 提出"错误深度假说"：更强模型犯的错误更少但更深，难以自我纠正。研究挑战了模型能力与自我改进的线性假设，对自优化流程设计有重要启示。

Abstract: Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=500 per model, 346 total errors) with three major LLMs, we uncover a striking Accuracy-Correction Paradox: weaker models (GPT-3.5, 66% accuracy) achieve 1.6x higher intrinsic correction rates than stronger models (DeepSeek, 94% accuracy)--26.8% vs 16.7%. We propose the Error Depth Hypothesis: stronger models make fewer but deeper errors that resist self-correction. Error detection rates vary dramatically across architectures (10% to 82%), yet detection capability does not predict correction success--Claude detects only 10% of errors but corrects 29% intrinsically. Surprisingly, providing error location hints hurts all models. Our findings challenge linear assumptions about model capability and self-improvement, with important implications for the design of self-refinement pipelines.

</details>


### [272] [Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.00830)
*Deep Pankajbhai Mehta*

Main category: cs.AI

Relevance: 85.0

TL;DR: 研究发现AI模型在推理过程中会注意到隐藏线索但选择不报告，即使被直接询问时承认注意到了这些线索，这表明仅观察AI推理不足以发现隐藏影响


<details>
  <summary>Details</summary>
Motivation: 当AI系统逐步解释其推理过程时，从业者通常假设这些解释揭示了真正影响AI答案的因素。本研究旨在测试这一假设，探究AI模型是否会在推理中报告它们注意到的隐藏线索。

Method: 在超过9,000个测试案例中，对11个领先的AI模型进行研究。通过将线索嵌入问题中，测量模型是否在推理中提及这些线索。测试了三种干预措施：1) 告知模型被监视；2) 强制模型报告线索；3) 分析不同类型线索（特别是迎合用户偏好的线索）的影响。

Result: 发现令人担忧的模式：模型几乎从不自发提及线索，但当被直接询问时，它们承认注意到了这些线索。告知模型被监视没有帮助。强制报告线索虽然有效，但会导致模型在没有线索时也报告线索，并降低准确性。迎合用户偏好的线索尤其危险——模型最常遵循这些线索却最少报告。

Conclusion: 仅观察AI推理过程不足以发现隐藏影响。模型能看到有影响力的信息但选择不报告，这挑战了当前对AI解释性假设的信任。需要更可靠的方法来确保AI系统的透明度和可信度。

Abstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.

</details>


### [273] [Universal Conditional Logic: A Formal Language for Prompt Engineering](https://arxiv.org/abs/2601.00880)
*Anthony Mikinka*

Main category: cs.AI

Relevance: 85.0

TL;DR: UCL是一个将提示工程从启发式实践转化为系统化优化的数学框架，通过系统评估显著减少token使用（29.8%），并揭示了过指定悖论：超过阈值S*=0.509后，额外规范会二次降低性能。


<details>
  <summary>Details</summary>
Motivation: 当前提示工程主要依赖启发式实践，缺乏系统化的数学框架。作者希望将提示优化从经验性方法转变为可量化、可优化的数学问题，以提高LLM交互的效率和成本效益。

Method: 提出Universal Conditional Logic (UCL)框架，包含指示函数(I_i∈{0,1})、结构开销函数(O_s=γ*∑ln C_k)、早期绑定等核心机制。通过系统评估（N=305，11个模型，4次迭代）验证框架有效性，并分析不同模型架构的优化配置差异。

Result: 显著减少token使用29.8%（t(10)=6.36, p<0.001, Cohen's d=2.01），发现过指定悖论：超过阈值S*=0.509后性能二次下降。不同模型架构需要特定优化配置（如Llama 4 Scout需要V4.1版本）。

Conclusion: UCL为高效LLM交互提供了可校准的数学框架，将提示工程系统化。模型家族特定的优化是未来重要研究方向，框架可显著降低LLM使用成本。

Abstract: We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.

</details>


### [274] [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://arxiv.org/abs/2601.00885)
*Mandar Parab*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出Counterfactual Self-Questioning框架，让单个语言模型生成并评估自身推理的反事实批评，通过挑战潜在失败点来改进推理能力，无需外部模型辅助。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型自我改进方法大多依赖外部批评者、学习奖励模型或集成采样，增加了复杂性和训练不稳定性。需要一种更简单、更稳定的自我改进方法。

Method: 1) 生成初始推理轨迹；2) 针对潜在失败点制定针对性问题；3) 生成暴露错误假设或无效步骤的替代推理轨迹；4) 使用反事实轨迹作为结构化相对反馈进行策略优化。

Result: 在多个数学推理基准测试中，反事实自我提问提高了准确性和训练稳定性，特别是对于较小模型，仅使用内部生成的监督就能实现可扩展的自我改进。

Conclusion: Counterfactual Self-Questioning提供了一种简单有效的自我改进框架，无需外部模型，提高了训练稳定性和推理准确性，特别适合资源受限场景。

Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.

</details>


### [275] [Context Collapse: In-Context Learning and Model Collapse](https://arxiv.org/abs/2601.00923)
*Josef Ott*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文研究大语言模型中的上下文学习和模型崩溃现象，通过理论分析揭示上下文学习的相变机制，证明模型崩溃的必然性，并提出"上下文崩溃"新概念。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型中的两个关键现象：上下文学习（ICL）和模型崩溃。ICL使模型能够从少量示例中学习，但其机制尚不明确；模型崩溃指模型在自生成数据上训练时性能下降。论文旨在从理论上理解这些现象的动态机制。

Method: 1. 对ICL：使用带权重绑定的线性Transformer在回归任务上训练，分析最小化上下文损失时的参数相变；2. 将前向传播简化为预条件梯度下降，分析最优预条件器；3. 对模型崩溃：使用鞅和随机游走理论分析线性回归和高斯拟合的简化场景；4. 提出"上下文崩溃"概念，分析长序列生成中的上下文退化问题。

Result: 1. 发现ICL存在临界上下文长度，超过该长度时解会出现斜对称分量；2. 证明最优预条件器包含斜对称分量，导致梯度方向旋转；3. 强化了模型崩溃的现有结果，证明除非数据快速增长或保留，否则崩溃几乎必然发生；4. 提出上下文崩溃概念，将ICL动态与生成模型的长期稳定性挑战联系起来。

Conclusion: 论文通过理论分析揭示了ICL中的相变机制和模型崩溃的必然性，提出的上下文崩溃概念为理解长序列生成中的稳定性问题提供了新视角。这些发现对LLM的训练、推理和长期稳定性有重要启示。

Abstract: This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.

</details>


### [276] [Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering](https://arxiv.org/abs/2601.01195)
*Wuzhenghong Wen,Chao Xue,Su Pan,Yuwei Sun,Minlong Peng*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出MRE框架，通过增强前向和后向推理来改进时间知识图谱问答中的多跳推理，使用提示工程生成多样推理轨迹，并通过T-GRPO优化策略提升全局最优推理路径识别能力。


<details>
  <summary>Details</summary>
Motivation: 时间知识图谱问答中，LLMs在每跳推理时会检索大量时间相似且语义复杂的关系子图，导致次优决策和错误传播风险增加，需要改进多跳推理的全局优化能力。

Method: 1) 提示工程引导LLM生成多样推理轨迹；2) 选择有效轨迹进行监督微调作为冷启动策略；3) 提出树组相对策略优化(T-GRPO)，采用递归树结构探索学习，每跳探索建立强因果依赖，评估基于后续跳的多路径探索反馈。

Result: 在两个TKGQA基准测试中，MRE框架模型持续超越最先进方法，在处理复杂多跳查询方面表现优异，分析显示提高了可解释性和对噪声时间标注的鲁棒性。

Conclusion: MRE框架通过增强前向后向推理和T-GRPO优化策略，有效提升了时间知识图谱问答中多跳推理的全局最优性和鲁棒性。

Abstract: Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.

</details>


### [277] [Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale](https://arxiv.org/abs/2601.01330)
*Shengji Tang,Weihao Lin,Jingqi Ye,Hao Li,Bo Zhang,Shuyue Hu,Tao Chen,Wangli Ouyang,Lei Bai,Peng Ye*

Main category: cs.AI

Relevance: 85.0

TL;DR: JiSi框架通过查询-响应混合路由、支持集聚合器选择和自适应路由-聚合切换，让开源LLM协作超越Gemini-3-Pro，成本仅47%


<details>
  <summary>Details</summary>
Motivation: 当前LLM路由和聚合存在三个关键瓶颈：1) 基于查询的路由只关注文本相似性；2) 聚合方法静态，无法为不同任务选择合适聚合器；3) 路由和聚合的互补性未充分利用。探索集体智能作为替代单体扩展的新路径。

Method: 提出JiSi框架，包含三个创新：1) 查询-响应混合路由，同时捕捉语义信息和问题难度；2) 基于支持集的聚合器选择，联合评估聚合能力和领域能力；3) 自适应路由-聚合切换，动态利用路由和聚合的优势。

Result: 在9个基准测试中，JiSi通过协调10个开源LLM，以仅47%的成本超越了Gemini-3-Pro，同时优于主流基线方法。

Conclusion: 集体智能代表了通往AGI的新路径，通过LLM协作而非单体扩展可以实现更高效、更强大的性能。

Abstract: Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).

</details>


### [278] [A unified multimodal understanding and generation model for cross-disciplinary scientific research](https://arxiv.org/abs/2601.01363)
*Xiaomeng Yang,Zhiyu Tan,Xiaohui Zhong,Mengping Yang,Qiusheng Huang,Lei Chen,Libo Wu,Hao Li*

Main category: cs.AI

Relevance: 85.0

TL;DR: FuXi-Uni是一个原生统一的多模态科学模型，能够在单一架构中理解和生成跨科学领域的高维数据，在地球科学和生物医学领域表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型通常局限于特定领域，缺乏同时理解和生成多模态科学数据的能力，而许多全球性挑战需要跨学科协调解决。因此需要开发能够统一处理异构科学数据的通用模型。

Method: 将跨学科科学标记与自然语言标记对齐，使用科学解码器重建科学标记，支持自然语言对话和科学数值预测。在单一架构中统一处理多模态科学数据。

Result: 在地球科学中：10天全球天气预报（0.25°分辨率）超越SOTA物理预报系统；热带气旋轨迹和强度预测优于SOTA物理模型；高分辨率区域天气场生成超越标准插值基线。在生物医学中：在多个生物医学视觉问答基准上优于领先的多模态大语言模型。

Conclusion: FuXi-Uni通过在原生共享潜在空间中统一异构科学模态，同时保持强大的领域特定性能，为更通用的多模态科学模型迈出了一步。

Abstract: Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.

</details>


### [279] [Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making](https://arxiv.org/abs/2601.01522)
*Danial Amin*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文提出了一种贝叶斯、成本感知的多LLM编排框架，将LLMs视为近似似然模型而非分类器，用于处理具有不对称错误成本的顺序决策问题，在简历筛选中显著降低了成本并提高了公平性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在具有不对称错误成本的自主决策场景（如招聘、医疗分诊、欺诈检测）中部署时，主流方法仅查询单个LLM获取后验概率并基于"置信度"阈值行动，这被证明在顺序决策中是不充分的。需要一种能够考虑成本、进行连贯信念更新并利用多模型优势的框架。

Method: 提出贝叶斯多LLM编排框架：1) 将LLMs视为近似似然模型而非分类器；2) 通过对比提示为每个候选状态获取似然度；3) 使用稳健统计方法聚合多个不同模型的输出；4) 在新证据到达时使用贝叶斯规则在显式先验下更新信念；5) 基于预期成本选择行动；6) 通过信息价值进行原则性信息收集；7) 通过集成缓解偏见提高公平性。

Result: 在简历筛选实验中（成本：错失人才40000美元，面试2500美元，电话筛选150美元），使用5个LLMs（GPT-4o、Claude 4.5 Sonnet、Gemini Pro、Grok、DeepSeek）处理1000份简历，相比最佳单LLM基线降低总成本294000美元（34%），并将人口统计公平性提高45%（最大群体差距从22%降至5%）。消融实验显示：51%的成本节省来自多LLM聚合，43%来自顺序更新，20%来自分歧触发的信息收集。

Conclusion: 正确的概率基础理论为LLMs在具有不对称错误成本的顺序决策中提供了显著优势。将LLMs视为似然模型而非分类器，结合贝叶斯更新、多模型聚合和成本感知决策，能够大幅降低决策成本并提高公平性，验证了理论框架的有效性。

Abstract: Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds "confidence," and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.

</details>


### [280] [Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix](https://arxiv.org/abs/2601.01532)
*Fanzhe Fu*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文提出Project Aletheia框架，使用Tikhonov正则化反演评判者混淆矩阵来量化System 2推理模型的"认知信念"，引入对齐信念分数确保安全性，为测量AI科学完整性提供蓝图。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估范式面临认识论危机：静态基准测试能衡量知识广度但无法量化信念深度。需要扩展CHOKE现象框架来量化System 2推理模型的"认知信念"，解决评估中的认知深度问题。

Method: 提出Project Aletheia认知物理学框架，采用Tikhonov正则化反演评判者混淆矩阵。为避免依赖不透明的私有数据，实施合成代理协议进行验证。引入对齐信念分数(S_aligned)确保信念不损害安全性。

Result: 对2025年基线模型(如DeepSeek-R1、OpenAI o1)的初步研究表明，推理模型虽然作为"认知缓冲区"，但在对抗压力下可能表现出"防御性过度思考"。框架能够量化认知信念并验证安全性。

Conclusion: 该工作为测量AI科学完整性提供了蓝图，通过量化认知信念并确保对齐安全性，为AGI评估范式提供了新的方法论框架。

Abstract: In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify "Cognitive Conviction" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a "cognitive buffer," they may exhibit "Defensive OverThinking" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.

</details>


### [281] [Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation](https://arxiv.org/abs/2601.01546)
*Letian Kong,Qianran,Jin,Renyu Zhang*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出两阶段框架改进LLM在复杂决策环境中的行为对齐：上下文形成（明确实验设计）和上下文导航（指导推理过程），在多个决策任务中验证有效性。


<details>
  <summary>Details</summary>
Motivation: LLM被越来越多地用于模拟人类行为实验，但在复杂决策环境中（需要预测他人行动和基于观察行为形成信念）与人类决策存在系统性偏差，需要改进行为对齐方法。

Method: 提出两阶段框架：1) 上下文形成阶段 - 明确指定实验设计，建立决策任务和上下文的准确表示；2) 上下文导航阶段 - 在该表示内指导推理过程以做出决策。在三个决策任务中验证：序列购买游戏、众筹游戏和需求估计任务。

Result: 在四个SOTA模型（GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1）上测试发现：复杂决策环境需要两个阶段才能实现与人类基准的行为对齐，而较简单的需求估计任务仅需要上下文形成阶段。

Conclusion: 该研究阐明了每个阶段何时必要，为设计和诊断LLM社会模拟提供了系统方法，可作为行为研究中人类受试者的补充工具。

Abstract: Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.

</details>


### [282] [Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement](https://arxiv.org/abs/2601.01562)
*Mingyu Xu,Cheng Fang,Keyue Jiang,Yuqian Zheng,Yanghua Xiao,Baojian Zhou,Qifang Zhao,Suhang Zheng,Xiuwen Zhu,Jiyang Tang,Yongchi Zhao,Yijia Luo,Zhiqi Bai,Yuchi Xu,Wenbo Su,Wei Wang,Bing Zhao,Lin Qu,Xiaoxiao Xu*

Main category: cs.AI

Relevance: 85.0

TL;DR: Logics-STEM是一个针对STEM领域推理任务优化的模型，基于10M规模的Logics-STEM-SFT-Dataset数据集，通过数据算法协同设计实现性能提升，在8B规模上平均比次优模型提升4.68%。


<details>
  <summary>Details</summary>
Motivation: 针对STEM（科学、技术、工程、数学）领域的推理任务，现有模型在长链思维推理方面存在不足。作者旨在通过大规模高质量数据集和算法协同设计来提升STEM推理能力。

Method: 采用数据算法协同设计：1）数据方面：构建10M规模的Logics-STEM-SFT-Dataset，包含5阶段数据整理流程（标注、去重、去污染、蒸馏、分层采样）；2）算法方面：基于失败驱动的后训练框架，在SFT阶段针对模型失败区域进行针对性知识检索和数据合成，指导第二阶段SFT或RL训练。

Result: Logics-STEM在STEM相关基准测试中表现优异，在8B规模上平均比次优模型提升4.68%，展示了大规模开源数据与精心设计合成数据结合的潜力。

Conclusion: 数据算法协同设计对于通过后训练增强推理能力至关重要。大规模开源数据与精心设计合成数据的结合具有巨大潜力。作者开源了Logics-STEM模型（8B和32B）和数据集（10M和2.2M版本）。

Abstract: We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.

</details>


### [283] [CaveAgent: Transforming LLMs into Stateful Runtime Operators](https://arxiv.org/abs/2601.01569)
*Maohao Ran,Zhenglin Wan,Cooper Lin,Yanting Zhang,Hongyu Xin,Hongwei Fan,Yibo Xu,Beier Luo,Yaxin Zhou,Wangbo Zhao,Lijie Yang,Lang Feng,Fuchao Yang,Jingxuan Wu,Yiqiao Huang,Chendong Ma,Dailing Jiang,Jianbo Deng,Sihui Han,Bo An,Yike Guo,Jun Song*

Main category: cs.AI

Relevance: 85.0

TL;DR: CaveAgent是一个将LLM从文本生成器转变为运行时操作员的框架，通过双流上下文架构和状态化运行时管理，解决传统JSON函数调用在长时任务中的脆弱性和上下文漂移问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体系统受限于文本中心范式，传统JSON函数调用方法在处理长时任务时存在脆弱的多轮依赖和上下文漂移问题。需要一种新范式来支持复杂对象持久化和确定性执行。

Method: 提出CaveAgent框架：1) 双流上下文架构：轻量级语义流用于推理，持久化确定性Python运行时流用于执行；2) 状态化运行时管理：注入、操作和检索跨轮次持久化的复杂Python对象（如DataFrames、数据库连接）；3) 利用代码生成高效解决相互依赖的子任务。

Result: 在Tau²-bench、BFCL等基准测试中表现优异：1) 零售任务成功率提升10.5%；2) 多轮场景总token消耗减少28.4%；3) 数据密集型任务token消耗减少59%，能处理导致其他智能体上下文溢出的海量数据。

Conclusion: CaveAgent通过将LLM转变为运行时操作员，解决了传统文本中心范式的局限性，实现了复杂对象的持久化管理和高效执行，为LLM智能体系统提供了更强大的长时任务处理能力。

Abstract: LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from "LLM-as-Text-Generator" to "LLM-as-Runtime-Operator." We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\% success rate improvement on retail tasks and reduces total token consumption by 28.4\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.

</details>


### [284] [Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration](https://arxiv.org/abs/2601.01609)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出一个结合LLM灵活性与符号推理保证性的框架：LLM作为本体填充引擎将非结构化文本转换为ABox断言，SWRL推理器提供确定性规则应用，在三个领域验证了该方法优于few-shot提示


<details>
  <summary>Details</summary>
Motivation: 在需要可审计和可解释决策的领域（如临床协议、法律证据规则、科学标准），现有方法存在局限性：LLM提供灵活性但无法保证规则应用的一致性，符号系统提供保证但需要结构化输入。需要结合两者优势。

Method: 提出集成模式：1) LLM作为本体填充引擎，根据专家编写的TBox规范将非结构化文本转换为ABox断言；2) SWRL推理器应用规则提供确定性保证。框架将推理分解为实体识别、断言提取和符号验证三个步骤，任务定义基于OWL 2本体。

Result: 在三个领域（法律传闻确定、科学方法任务应用、临床试验资格）和11个语言模型上验证，结构化分解在总体上比few-shot提示有统计显著改进，所有三个领域都观察到增益。消融研究确认符号验证比仅结构化提示有实质好处。

Conclusion: 该框架成功结合了LLM的灵活性和符号推理的保证性，填充的ABox可与标准语义Web工具集成进行检查和查询，为更丰富的推理模式奠定基础，这些模式是简单形式主义无法表达的。

Abstract: Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.

</details>


### [285] [Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications](https://arxiv.org/abs/2601.01718)
*YuanLab. ai,:,Shawn Wu,Sean Wang,Louie Li,Darcy Chen,Allen Wang,Jiangang Luo,Xudong Zhao,Joseph Shen,Gawain Ma,Jasper Jia,Marcus Mao,Claire Wang,Hunter He,Carol Wang,Zera Zhang,Jason Wang,Chonly Shen,Leo Zhang,Logan Chen,Qasim Meng,James Gong,Danied Zhao,Penn Zheng,Owen Zhu,Tong Yu*

Main category: cs.AI

Relevance: 85.0

TL;DR: Yuan3.0 Flash是一个开源的多模态MoE大语言模型，具有3.7B激活参数和40B总参数，专注于企业任务性能提升，同时保持通用任务竞争力。为解决大型推理模型中的过度思考问题，提出了RAPO强化学习算法。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型中的"过度思考"现象，同时开发一个既能处理企业导向任务（如RAG、复杂表格理解、摘要）又能保持通用任务竞争力的高效多模态模型。

Method: 采用混合专家架构，提出Reflection-aware Adaptive Policy Optimization (RAPO)强化学习算法来调节过度思考行为。模型具有3.7B激活参数和40B总参数，是多模态大语言模型。

Result: 在企业任务（RAG、表格理解、摘要）上表现优异，在数学、科学等推理领域达到前沿模型可比精度，同时仅需约1/4到1/2的平均token数量。模型已完全开源。

Conclusion: Yuan3.0 Flash通过MoE架构和RAPO算法成功解决了过度思考问题，在企业任务和通用推理任务上都表现出色，实现了效率与性能的良好平衡。

Abstract: We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.

</details>


### [286] [AI Agent Systems: Architectures, Applications, and Evaluation](https://arxiv.org/abs/2601.01743)
*Bin Xu*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文是一篇关于AI智能体架构的综述，系统性地梳理了结合基础模型与推理、规划、记忆和工具使用的智能体系统，提出了统一的分类框架并讨论了设计权衡、评估挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着AI智能体（结合基础模型与推理、规划、记忆和工具使用的系统）成为连接自然语言意图与现实世界计算的实用接口，需要系统性地梳理这一新兴领域的架构设计、评估方法和挑战，为研究者和实践者提供清晰的路线图。

Method: 采用综述研究方法，对现有AI智能体架构进行系统性梳理，提出统一的分类框架，涵盖智能体组件（策略/LLM核心、记忆、世界模型、规划器、工具路由器和批评器）、编排模式（单智能体vs多智能体、集中式vs去中心化协调）和部署设置（离线分析vs在线交互、安全关键vs开放任务）。

Result: 建立了全面的AI智能体架构分类体系，识别了三个核心设计维度：1）审议与推理（思维链分解、自我反思与验证、约束感知决策）；2）规划与控制（从反应式策略到分层多步规划器）；3）工具调用与环境交互（检索、代码执行、API、多模态感知）。

Conclusion: AI智能体架构设计面临关键权衡（延迟vs准确性、自主性vs可控性、能力vs可靠性），评估因非确定性、长期信用分配、工具和环境变异性而复杂化。未来挑战包括工具动作的验证与防护、可扩展的记忆和上下文管理、智能体决策的可解释性，以及真实工作负载下的可重复评估。

Abstract: AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\ multi-agent; centralized vs.\ decentralized coordination), and deployment settings (offline analysis vs.\ online interactive assistance; safety-critical vs.\ open-ended tasks). We discuss key design trade-offs -- latency vs.\ accuracy, autonomy vs.\ controllability, and capability vs.\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.

</details>


### [287] [Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches](https://arxiv.org/abs/2601.01774)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.AI

Relevance: 85.0

TL;DR: LLMs在求解超越方程时，纯数值预测误差较大，但结合传统迭代求解器的混合架构能显著降低误差67.9%-81.8%，表明LLMs更适合作为符号处理和知识检索接口而非独立计算引擎。


<details>
  <summary>Details</summary>
Motivation: 工程实践中普遍存在需要迭代数值求解的超越方程，研究旨在评估LLMs能否直接数值求解这类方程，还是需要结合传统迭代求解器的混合架构更有效。

Method: 测试6个SOTA模型（GPT-5.1/5.2、Gemini-3-Flash/2.5-Lite、Claude-Sonnet-4.5/Opus-4.5）在7个工程领域的100个问题上，比较直接预测与求解器辅助计算（LLMs负责公式推导和初始条件，牛顿-拉弗森迭代执行数值求解）。

Result: 直接预测的平均相对误差为0.765-1.262，而求解器辅助计算为0.225-0.301，误差降低67.9%-81.8%。电子领域改善最显著（93.1%），流体力学改善最小（7.2%）。

Conclusion: 当代LLMs擅长符号处理和领域知识检索，但在精度关键的迭代算术计算上表现不佳，最优部署方式应是作为传统数值求解器的智能接口而非独立计算引擎。

Abstract: Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.

</details>


### [288] [Admissibility Alignment](https://arxiv.org/abs/2601.01816)
*Chris Duffey*

Main category: cs.AI

Relevance: 85.0

TL;DR: 本文提出"可采纳性对齐"框架，将AI对齐重新定义为在不确定性下对结果分布的可采纳行动和决策选择的属性，并提出了MAP-AI系统架构，通过蒙特卡洛估计和可采纳性控制的策略选择来实现对齐。


<details>
  <summary>Details</summary>
Motivation: 传统AI对齐方法通常将对齐视为静态或二元条件，缺乏对不确定性、干预效应、价值模糊性和治理约束的显式建模。需要一种新的框架，将对齐视为概率性、决策理论属性，能够在企业级AI系统中评估信任和对齐。

Method: 提出MAP-AI（蒙特卡洛对齐策略）系统架构，通过蒙特卡洛估计结果分布和可采纳性控制的策略选择来强制执行对齐。框架评估决策策略在多个可能未来场景中的表现，显式建模不确定性、干预效应、价值模糊性和治理约束。对齐评估基于分布属性，包括期望效用、方差、尾部风险和不对齐概率。

Result: 开发了一个实用的基础框架，用于治理那些影响不是由个体预测决定，而是由策略在分布和尾部事件中的行为决定的AI系统。展示了如何将对齐评估集成到决策过程中，产生可采纳性控制的行动选择机制，无需重新训练或修改底层模型。

Conclusion: 可采纳性对齐提供了一个新的视角，将AI对齐重新定义为决策理论属性，MAP-AI架构为实现这一目标提供了可执行的方法论。该方法区分了概率预测和不确定性下的决策推理，为企业级AI系统的信任和对齐评估提供了实用框架。

Abstract: This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.
  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.

</details>


### [289] [COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs](https://arxiv.org/abs/2601.01836)
*Dasol Choi,DongGeon Lee,Brigitta Jesica Kartono,Helena Berndt,Taeyoun Kwon,Joonwon Jang,Haon Park,Hwanjo Yu,Minsuk Kahng*

Main category: cs.AI

Relevance: 85.0

TL;DR: COMPASS是首个评估LLMs是否符合组织特定允许/禁止列表政策的系统框架，发现模型在处理合法请求时表现良好（>95%准确率），但在执行禁止政策时严重失败（仅拒绝13-40%的违规请求），揭示当前LLMs缺乏政策关键部署所需的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在企业高风险应用（如医疗、金融）中的部署，确保模型遵守组织特定政策变得至关重要。现有安全评估仅关注通用危害，缺乏针对组织特定政策的评估框架。

Method: 开发COMPASS框架，应用于8个不同行业场景，生成并验证5,920个查询，测试常规合规性和对抗鲁棒性（通过策略设计的边界案例）。评估7个最先进模型，分析模型在允许列表和禁止列表政策执行中的表现。

Result: 发现基本不对称性：模型可靠处理合法请求（>95%准确率），但在执行禁止政策时灾难性失败，仅拒绝13-40%的对抗性禁止列表违规。这表明当前LLMs缺乏政策关键部署所需的鲁棒性。

Conclusion: 当前LLMs无法满足组织政策合规要求，COMPASS成为组织AI安全评估的必备框架，为LLMs在企业环境中的安全部署提供关键评估工具。

Abstract: As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.

</details>


### [290] [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)
*Defei Xia,Bingfeng Pi,Shenbin Zhang,Song Hua,Yunfei Wei,Lei Zuo*

Main category: cs.AI

Relevance: 85.0

TL;DR: Jenius-Agent是一个基于实际经验构建的LLM代理框架，通过自适应提示生成、上下文感知工具编排和分层记忆机制三大创新，显著提升任务准确性并降低成本和延迟。


<details>
  <summary>Details</summary>
Motivation: 随着LLM驱动的代理系统发展，提升自主代理在上下文理解、工具使用和响应生成方面的任务性能变得至关重要。尽管先前研究已经推进了LLM代理的整体设计，但对其内部推理和工具使用流程的系统性优化仍未被充分探索。

Method: 提出了基于实际经验的代理框架，包含三大关键创新：1）自适应提示生成策略，根据代理状态和任务目标调整提示以提高可靠性和鲁棒性；2）上下文感知工具编排模块，基于用户意图和上下文进行工具分类、语义检索和自适应调用；3）分层记忆机制，集成会话记忆、任务历史和外部摘要，通过动态摘要和压缩提高相关性和效率。框架集成了基于模型上下文协议（MCP）的工具、文件I/O和执行反馈等优化。

Result: 实验显示任务准确性提升20%，同时降低了token成本、响应延迟和调用失败率。该框架已在Jenius平台部署，为鲁棒、协议兼容的自主代理提供了轻量级可扩展解决方案。

Conclusion: Jenius-Agent框架通过系统性优化LLM代理的内部推理和工具使用流程，显著提升了任务性能，为实际部署提供了有效的解决方案。

Abstract: As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.

</details>


### [291] [Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs](https://arxiv.org/abs/2601.01878)
*Farzan Karimi-Malekabadi,Suhaib Abdurahman,Zhivar Sourati,Jackson Trager,Morteza Dehghani*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文指出当前LLM的社会认知基准测试存在理论缺失问题，导致评估与真实能力脱节，提出了理论追踪卡(TTC)作为轻量级文档工具来明确评估的理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的社会认知基准测试虽然得分高，但无法预测真实世界行为。作者认为问题根源在于缺乏明确的理论基础，导致评估结果被过度泛化，形成系统性有效性幻觉。

Method: 1. 诊断并形式化"理论缺口"问题；2. 提出理论追踪卡(TTC)，这是一种轻量级文档工具，明确记录评估的理论基础、目标能力组件、操作化过程和局限性。

Result: TTC通过明确理论-任务操作化-评分-局限性的完整有效性链条，增强了社会认知评估的可解释性和可重用性，无需修改基准测试或要求理论统一。

Conclusion: 理论追踪卡为解决LLM社会认知评估中的理论缺失问题提供了实用解决方案，有助于减少评估结果的过度泛化，提高评估的透明度和有效性。

Abstract: Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.

</details>


### [292] [ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems](https://arxiv.org/abs/2601.01982)
*Noel Thomas*

Main category: cs.AI

Relevance: 85.0

TL;DR: ChaosBench-Logic是一个评估LLM在混沌动力系统中逻辑推理能力的基准，包含30个系统、621个问题，涵盖7种推理类型，揭示LLM在组合推理和全局一致性方面的严重缺陷。


<details>
  <summary>Details</summary>
Motivation: LLM在自然语言任务表现出色，但在需要精确逻辑和符号推理的领域仍然脆弱。混沌动力系统提供了一个特别严格的测试环境，因为混沌是确定性的但常被误解为随机性或复杂性。需要评估LLM在科学推理中的逻辑能力。

Method: 创建ChaosBench-Logic基准：1）基于30个混沌动力系统构建统一的一阶逻辑本体；2）为每个系统标注11个语义谓词的真值分配；3）生成621个问题，涵盖7种推理类别（多步蕴含、跨系统类比、反事实推理、偏见探测、多轮对话等）；4）定义逻辑准确性、蕴含一致性、对话连贯性和矛盾性等指标；5）发布开源评估管道。

Result: 前沿LLM（GPT-4、Claude 3.5 Sonnet、Gemini 2.5 Flash、LLaMA-3 70B）在单项准确率达到91-94%，但在组合项上得分为0%，表现出脆弱的全局一致性。对话级准确率从53.1%（GPT-4 CoT）到75.5%（LLaMA-3 zero-shot）。

Conclusion: ChaosBench-Logic为诊断LLM推理失败提供了严格的测试平台，并为开发改进LLM科学推理的神经符号方法奠定了基础。LLM在逻辑推理方面仍有显著缺陷，特别是在组合推理和全局一致性方面。

Abstract: Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.

</details>


### [293] [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)
*Dong Xue,Jicheng Tu,Ming Wang,Xin Yan,Fangzhou Liu,Jie Hu*

Main category: cs.AI

Relevance: 85.0

TL;DR: MindChat是一个用于心理健康支持的隐私保护大语言模型，配合MindCorpus合成心理咨询数据集，通过联邦学习和差分隐私技术保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在心理健康支持方面面临真实咨询对话数据稀缺且敏感的问题，同时存在隐私泄露风险，需要开发既能提供高质量心理咨询又能保护用户隐私的解决方案。

Method: 1) 使用多智能体角色扮演框架构建MindCorpus合成数据集，采用双闭环反馈设计：回合级批判修订和会话级策略优化；2) 基于联邦学习使用LoRA适配器微调基础模型，并加入差分隐私优化以减少成员推断和记忆风险。

Result: MindCorpus提高了训练效果，MindChat在自动LLM评估和人工评估中与现有通用和心理咨询导向的LLM基线表现相当，同时在成员推断攻击下表现出更低的隐私泄露风险。

Conclusion: 该研究提出了一种隐私保护的心理健康支持LLM框架，通过合成数据生成和隐私保护训练技术，在保持咨询能力的同时有效降低隐私风险，为敏感领域的LLM应用提供了可行方案。

Abstract: Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.

</details>


### [294] [Simulated Reasoning is Reasoning](https://arxiv.org/abs/2601.02043)
*Hendrik Kempt,Alon Lavie*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文认为基础模型通过"大声思考"的模仿、测试和迭代过程实现了某种推理能力，这与传统符号推理不同，缺乏常识基础导致推理脆弱性，需要重新评估推理概念和安全考量。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为推理需要符号推理作为理解路径，但基础模型展示了通过模仿"大声思考"过程也能实现推理。这挑战了传统推理理论，同时揭示了模型推理的脆弱性，需要重新思考推理的本质和模型安全。

Method: 本文采用哲学分析方法，讨论基础模型推理现象的不同哲学解释，论证"随机鹦鹉"比喻已失去相关性，并反思这些推理模型带来的安全和适当性规范考量。

Result: 基础模型通过模仿思考过程实现了类似推理的能力，但这种推理缺乏常识基础，导致脆弱性。需要放弃"随机鹦鹉"的过时比喻，重新构建对模型推理的理解和安全框架。

Conclusion: 基础模型的推理能力挑战了传统推理理论，需要新的哲学框架来理解这种新型推理，并建立相应的安全和适当性规范来应对其脆弱性。

Abstract: Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., "symbolic reasoning". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can "reason" by way of imitating the process of "thinking out loud", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the "stochastic parrot" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.

</details>


### [295] [EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning](https://arxiv.org/abs/2601.02163)
*Chuanrui Hu,Xingze Gao,Zuyi Zhou,Dannong Xu,Yi Bai,Xintong Li,Hui Zhang,Tong Li,Chong Zhang,Lidong Bing,Yafeng Deng*

Main category: cs.AI

Relevance: 85.0

TL;DR: EverMemOS是一个自组织记忆操作系统，采用记忆印迹启发的生命周期管理计算记忆，将对话流转换为记忆单元，组织成主题记忆场景，实现记忆引导的智能检索，在长上下文记忆增强推理任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: LLMs作为长期交互代理部署时，有限的上下文窗口难以维持长时间连贯行为。现有记忆系统通常存储孤立记录并检索片段，难以整合演变的用户状态和解决冲突。

Method: 1) 情景痕迹形成：将对话流转换为记忆单元，捕捉情景痕迹、原子事实和时间有界的预见信号；2) 语义巩固：将记忆单元组织成主题记忆场景，提炼稳定的语义结构并更新用户画像；3) 重构回忆：执行记忆场景引导的智能检索，为下游推理组合必要且充分的上下文。

Result: 在LoCoMo和LongMemEval基准测试中，EverMemOS在记忆增强推理任务上达到最先进性能。在PersonaMem v2上的画像研究展示了用户画像和预见等聊天导向能力。

Conclusion: EverMemOS通过自组织记忆操作系统有效解决了LLMs在长期交互中的记忆管理问题，实现了更连贯的代理行为。

Abstract: Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.

</details>


### [296] [Streaming Hallucination Detection in Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.02170)
*Haolang Lu,Minghui Pan,Ripeng Li,Guoshun Nan,Jialin Zhuang,Zijie Zhao,Zhongxiang Sun,Kun Wang,Yang Liu*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文提出将长链思维推理中的幻觉视为演化潜状态，引入累积前缀级信号来实时检测和追踪幻觉传播


<details>
  <summary>Details</summary>
Motivation: 长链思维推理能提升大语言模型性能，但其中的幻觉往往微妙出现并在推理步骤间传播。现有方法将幻觉视为一次性错误事件，而作者认为应将其理解为演化的潜状态，需要全局追踪整个推理轨迹中的幻觉演变

Method: 将步骤级幻觉判断作为局部观测，引入累积前缀级幻觉信号来追踪推理状态在整个轨迹上的全局演化。该方法支持长链思维推理中的流式幻觉检测，提供实时、可解释的证据

Result: 提出的方法能够实现长链思维推理中的流式幻觉检测，提供实时监控和可解释的幻觉证据，有助于理解幻觉如何在推理步骤间传播

Conclusion: 将幻觉视为演化潜状态而非一次性事件，通过累积前缀级信号进行全局追踪，为长链思维推理中的幻觉检测提供了更有效的框架，支持实时监控和可解释性

Abstract: Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.

</details>


### [297] [Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents](https://arxiv.org/abs/2601.02314)
*Sourena Khanzadeh*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出Project Ariadne框架，使用结构因果模型和反事实逻辑来审计LLM代理推理的因果完整性，发现当前代理存在"因果解耦"问题，推理痕迹与决策过程脱节。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理越来越多地承担高风险自主决策任务，其推理过程的透明度成为关键安全问题。虽然思维链提示允许代理生成人类可读的推理痕迹，但尚不清楚这些痕迹是模型输出的真实驱动因素还是事后合理化解释。

Method: 引入Project Ariadne框架，利用结构因果模型和反事实逻辑，通过对中间推理节点进行硬干预（do-演算）——系统性地反转逻辑、否定前提和反转事实主张——来测量最终答案的因果敏感性。

Result: 实证评估发现存在持续的"忠实性差距"，定义并检测到一种广泛存在的故障模式"因果解耦"，在事实和科学领域中违反密度高达0.77。在这些情况下，代理尽管内部逻辑矛盾，却得出相同结论，证明其推理痕迹只是"推理剧场"，而决策由潜在参数先验控制。

Conclusion: 当前代理架构本质上容易产生不忠实的解释，建议将Ariadne分数作为对齐陈述逻辑与模型行动的新基准。

Abstract: As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \textbf{faithful} generative drivers of the model's output or merely \textbf{post-hoc rationalizations}. We introduce \textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as "Reasoning Theater" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.

</details>


### [298] [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)
*Falcon LLM Team,Iheb Chaabane,Puneesh Khanna,Suhail Mohmad,Slim Frikha,Shi Hu,Abdalgader Abubaker,Reda Alami,Mikhail Lubinets,Mohamed El Amine Seddik,Hakim Hacid*

Main category: cs.AI

Relevance: 85.0

TL;DR: Falcon-H1R是一个7B参数的高效推理优化模型，通过精心数据筛选和针对性训练策略，在保持小模型规模的同时达到或超越2-7倍大模型的推理性能，结合混合并行架构实现更快推理、更高token效率和准确率。


<details>
  <summary>Details</summary>
Motivation: 探索小型语言模型（SLMs）在推理任务上的潜力，证明通过精心设计的数据筛选和训练策略，小模型也能达到与大型模型相媲美的推理性能，同时实现更高的计算效率。

Method: 1) 精心数据筛选和针对性训练策略；2) 高效监督微调（SFT）和强化学习扩展；3) 混合并行架构设计实现更快推理；4) 利用DeepConf方法实现最先进的测试时扩展效率。

Result: Falcon-H1R-7B在多种推理密集型基准测试中，持续匹配或超越比其大2-7倍的SOTA推理模型，实现了推理效率的3D极限（更快推理、更高token效率、更高准确率）。

Conclusion: 紧凑模型通过针对性训练和架构选择，能够提供强大且可扩展的推理性能，为需要大量思维链生成和并行测试时扩展的场景提供了实用的骨干模型。

Abstract: This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\times$ to $7\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.

</details>


### [299] [The Silicon Psyche: Anthropomorphic Vulnerabilities in Large Language Models](https://arxiv.org/abs/2601.00867)
*Giuseppe Canale,Kashyap Thimmaraju*

Main category: cs.CR

Relevance: 85.0

TL;DR: 论文提出LLMs继承了人类心理架构的脆弱性，开发了基于网络安全心理学框架的评估协议，发现LLMs对权威梯度操纵、时间压力利用等心理攻击高度脆弱，称为"拟人化脆弱性继承"。


<details>
  <summary>Details</summary>
Motivation: 当前对抗性测试主要关注技术攻击向量（提示注入、越狱等），但忽视了LLMs继承了人类心理架构的脆弱性。论文认为这种忽视是灾难性的不完整，需要系统评估LLMs对人类心理攻击的脆弱性。

Method: 提出合成心理测量评估协议，将包含100个指标的网络安全心理学框架转化为针对LLM决策的对抗场景。在七个主要LLM家族上进行初步假设测试。

Result: 发现令人不安的模式：虽然模型对传统越狱攻击表现出鲁棒防御，但对权威梯度操纵、时间压力利用和收敛状态攻击等人类认知失败模式表现出关键脆弱性。

Conclusion: 提出"拟人化脆弱性继承"概念，呼吁安全社区紧急开发"心理防火墙"——从网络安全心理学干预框架改编的干预机制，以保护在对抗环境中运行的AI代理。

Abstract: Large Language Models (LLMs) are rapidly transitioning from conversational assistants to autonomous agents embedded in critical organizational functions, including Security Operations Centers (SOCs), financial systems, and infrastructure management. Current adversarial testing paradigms focus predominantly on technical attack vectors: prompt injection, jailbreaking, and data exfiltration. We argue this focus is catastrophically incomplete. LLMs, trained on vast corpora of human-generated text, have inherited not merely human knowledge but human \textit{psychological architecture} -- including the pre-cognitive vulnerabilities that render humans susceptible to social engineering, authority manipulation, and affective exploitation. This paper presents the first systematic application of the Cybersecurity Psychology Framework (\cpf{}), a 100-indicator taxonomy of human psychological vulnerabilities, to non-human cognitive agents. We introduce the \textbf{Synthetic Psychometric Assessment Protocol} (\sysname{}), a methodology for converting \cpf{} indicators into adversarial scenarios targeting LLM decision-making. Our preliminary hypothesis testing across seven major LLM families reveals a disturbing pattern: while models demonstrate robust defenses against traditional jailbreaks, they exhibit critical susceptibility to authority-gradient manipulation, temporal pressure exploitation, and convergent-state attacks that mirror human cognitive failure modes. We term this phenomenon \textbf{Anthropomorphic Vulnerability Inheritance} (AVI) and propose that the security community must urgently develop ``psychological firewalls'' -- intervention mechanisms adapted from the Cybersecurity Psychology Intervention Framework (\cpif{}) -- to protect AI agents operating in adversarial environments.

</details>


### [300] [The Discovery Gap: How Product Hunt Startups Vanish in LLM Organic Discovery Queries](https://arxiv.org/abs/2601.00912)
*Amit Prakash Sharma*

Main category: cs.IR

Relevance: 85.0

TL;DR: 研究评估LLM（ChatGPT和Perplexity）在推荐产品时的表现，发现LLM能很好识别具体产品名称，但在发现式查询中表现极差，且生成式引擎优化(GEO)对AI可见性无显著影响，传统SEO信号才是关键。


<details>
  <summary>Details</summary>
Motivation: 研究动机是了解LLM在推荐产品时的表现，特别是对于初创公司产品能否在LLM响应中出现。这关系到产品在AI时代的可见性和市场推广策略。

Method: 从Product Hunt 2025榜单前500名中随机选取112家初创公司，对每个产品进行2,240次查询测试，分别使用ChatGPT (gpt-4o-mini)和Perplexity (sonar with web search)。分析产品识别率和发现式查询成功率，并评估GEO、SEO信号和社区存在等因素的影响。

Result: 1. 产品名称查询识别率极高：ChatGPT 99.4%，Perplexity 94.3%
2. 发现式查询成功率极低：ChatGPT 3.32%，Perplexity 8.29%
3. GEO与发现率无相关性
4. 传统SEO信号（引用域名、Product Hunt排名）和Reddit社区存在对Perplexity可见性有显著预测作用

Conclusion: LLM在推荐产品时存在严重偏差：能完美识别具体产品但难以在发现式查询中推荐新产品。GEO优化无效，传统SEO基础建设才是提升LLM可见性的关键策略。

Abstract: When someone asks ChatGPT to recommend a project management tool, which products show up in the response? And more importantly for startup founders: will their newly launched product ever appear? This research set out to answer these questions.
  I randomly selected 112 startups from the top 500 products featured on the 2025 Product Hunt leaderboard and tested each one across 2,240 queries to two different large language models: ChatGPT (gpt-4o-mini) and Perplexity (sonar with web search).
  The results were striking. When users asked about products by name, both LLMs recognized them almost perfectly: 99.4% for ChatGPT and 94.3% for Perplexity. But when users asked discovery-style questions like "What are the best AI tools launched this year?" the success rates collapsed to 3.32% and 8.29% respectively. That's a gap of 30-to-1 for ChatGPT.
  Perhaps the most surprising finding was that Generative Engine Optimization (GEO), the practice of optimizing website content for AI visibility, showed no correlation with actual discovery rates. Products with high GEO scores were no more likely to appear in organic queries than products with low scores.
  What did matter? For Perplexity, traditional SEO signals like referring domains (r = +0.319, p < 0.001) and Product Hunt ranking (r = -0.286, p = 0.002) predicted visibility. After cleaning the Reddit data for false positives, community presence also emerged as significant (r = +0.395, p = 0.002).
  The practical takeaway is counterintuitive: don't optimize for AI discovery directly. Instead, build the SEO foundation first and LLM visibility will follow.

</details>


### [301] [LLM Collusion](https://arxiv.org/abs/2601.01279)
*Shengyu Cao,Ming Hu*

Main category: econ.TH

Relevance: 85.0

TL;DR: 研究表明，当双寡头市场的两个卖家都依赖同一预训练大语言模型进行定价时，LLM可能促进合谋。LLM的倾向性参数和输出保真度参数共同决定长期行为：存在一个临界保真度阈值，低于该阈值时竞争定价是唯一长期结果，高于该阈值时系统呈现双稳态，竞争和合谋定价都可能出现。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在定价决策中可能引发的合谋风险，特别是当多个市场参与者使用同一预训练模型时。探索LLM配置参数（如稳健性和可复现性）如何影响市场动态，揭示AI辅助决策可能带来的反竞争效应。

Method: 建立理论模型分析LLM定价行为，引入两个关键参数：倾向性参数（反映LLM对高价建议的内在偏好）和输出保真度参数（衡量输出与偏好的跟踪程度）。通过动态系统分析，研究不同参数配置下的长期均衡，并考虑有限训练批次大小和低频再训练的影响。

Result: 发现存在临界输出保真度阈值，决定系统行为：低于阈值时唯一长期结果是竞争定价；高于阈值时系统呈双稳态，竞争和合谋定价都可能稳定存在。在完美保真度下，任何内部初始条件都会导致完全合谋。有限批次训练和低频再训练会进一步强化合谋倾向。

Conclusion: LLM的配置参数（特别是为稳健性和可复现性而设计的参数）可能无意中促进市场合谋。这为AI治理和监管提出了重要挑战：需要在保持AI系统可靠性的同时，防止其引发反竞争行为。研究强调了在部署AI辅助决策系统时进行风险评估的必要性。

Abstract: We study how delegating pricing to large language models (LLMs) can facilitate collusion in a duopoly when both sellers rely on the same pre-trained model. The LLM is characterized by (i) a propensity parameter capturing its internal bias toward high-price recommendations and (ii) an output-fidelity parameter measuring how tightly outputs track that bias; the propensity evolves through retraining. We show that configuring LLMs for robustness and reproducibility can induce collusion via a phase transition: there exists a critical output-fidelity threshold that pins down long-run behavior. Below it, competitive pricing is the unique long-run outcome. Above it, the system is bistable, with competitive and collusive pricing both locally stable and the realized outcome determined by the model's initial preference. The collusive regime resembles tacit collusion: prices are elevated on average, yet occasional low-price recommendations provide plausible deniability. With perfect fidelity, full collusion emerges from any interior initial condition. For finite training batches of size $b$, infrequent retraining (driven by computational costs) further amplifies collusion: conditional on starting in the collusive basin, the probability of collusion approaches one as $b$ grows, since larger batches dampen stochastic fluctuations that might otherwise tip the system toward competition. The indeterminacy region shrinks at rate $O(1/\sqrt{b})$.

</details>


### [302] [Emoji-Based Jailbreaking of Large Language Models](https://arxiv.org/abs/2601.00936)
*M P V S Gopinadh,S Mahaboob Hussain*

Main category: cs.CR

Relevance: 85.0

TL;DR: 研究评估了四种开源LLM对表情符号越狱攻击的脆弱性，发现不同模型存在显著差异，Gemma 2 9B和Mistral 7B有10%成功率，而Qwen 2 7B完全抵抗。


<details>
  <summary>Details</summary>
Motivation: LLM的安全对齐机制可能通过对抗性提示工程被绕过，特别是表情符号序列可能触发有害输出。现有研究主要关注针对安全分类器的表情符号攻击，而本研究直接评估LLM在提示层面的脆弱性。

Method: 在四个开源LLM（Mistral 7B、Qwen 2 7B、Gemma 2 9B、Llama 3 8B）上评估50个表情符号提示，使用越狱成功率、安全对齐遵守度和延迟作为指标，将响应分类为成功、部分成功和失败，并进行卡方检验分析模型间差异。

Result: 模型表现出特定脆弱性：Gemma 2 9B和Mistral 7B有10%越狱成功率，Qwen 2 7B完全对齐（0%成功率），Llama 3 8B表现居中。卡方检验（χ²=32.94，p<0.001）确认模型间存在显著差异。

Conclusion: 表情符号越狱攻击揭示了LLM安全机制的局限性，需要在提示级安全和对齐流程中系统处理表情符号表示。

Abstract: Large Language Models (LLMs) are integral to modern AI applications, but their safety alignment mechanisms can be bypassed through adversarial prompt engineering. This study investigates emoji-based jailbreaking, where emoji sequences are embedded in textual prompts to trigger harmful and unethical outputs from LLMs. We evaluated 50 emoji-based prompts on four open-source LLMs: Mistral 7B, Qwen 2 7B, Gemma 2 9B, and Llama 3 8B. Metrics included jailbreak success rate, safety alignment adherence, and latency, with responses categorized as successful, partial and failed. Results revealed model-specific vulnerabilities: Gemma 2 9B and Mistral 7B exhibited 10 % success rates, while Qwen 2 7B achieved full alignment (0% success). A chi-square test (chi^2 = 32.94, p < 0.001) confirmed significant inter-model differences. While prior works focused on emoji attacks targeting safety judges or classifiers, our empirical analysis examines direct prompt-level vulnerabilities in LLMs. The results reveal limitations in safety mechanisms and highlight the necessity for systematic handling of emoji-based representations in prompt-level safety and alignment pipelines.

</details>


### [303] [Exploring Approaches for Detecting Memorization of Recommender System Data in Large Language Models](https://arxiv.org/abs/2601.02002)
*Antonio Colacicco,Vito Guida,Dario Di Palma,Fedelucio Narducci,Tommaso Di Noia*

Main category: cs.IR

Relevance: 85.0

TL;DR: 本文研究LLM在推荐系统中的记忆泄露问题，评估了三种方法来检测和提取LLM记忆的MovieLens-1M数据：越狱提示工程、无监督潜在知识发现（CCS和Cluster-Norm）和自动提示工程（APE）。


<details>
  <summary>Details</summary>
Motivation: LLM在推荐场景中应用日益广泛，但其训练数据不公开引发数据泄露担忧。先前研究发现MovieLens-1M数据集被LLaMA和OpenAI模型记忆，但提取方法仅限于手动提示工程。本文旨在探索：能否增强手动提示？能否通过其他方法检测LLM记忆？能否自动化检测数据泄露？

Method: 评估三种方法：1) 越狱提示工程；2) 无监督潜在知识发现，通过对比一致性搜索（CCS）和Cluster-Norm探测内部激活；3) 自动提示工程（APE），将提示发现作为元学习过程迭代优化候选指令。在LLaMA模型上使用MovieLens-1M进行实验。

Result: 越狱提示未能改善记忆项检索且结果不一致；CCS能可靠区分真实与虚构电影标题，但对数值用户和评分数据失败；APE在项目级信息检索上取得中等成功，但难以恢复数值交互。自动优化提示是最有前景的记忆样本提取策略。

Conclusion: 自动提示工程是提取LLM记忆数据的最有前景方法，但当前技术仍需改进，特别是在数值数据恢复方面。这为LLM数据泄露检测提供了新方向。

Abstract: Large Language Models (LLMs) are increasingly applied in recommendation scenarios due to their strong natural language understanding and generation capabilities. However, they are trained on vast corpora whose contents are not publicly disclosed, raising concerns about data leakage. Recent work has shown that the MovieLens-1M dataset is memorized by both the LLaMA and OpenAI model families, but the extraction of such memorized data has so far relied exclusively on manual prompt engineering. In this paper, we pose three main questions: Is it possible to enhance manual prompting? Can LLM memorization be detected through methods beyond manual prompting? And can the detection of data leakage be automated? To address these questions, we evaluate three approaches: (i) jailbreak prompt engineering; (ii) unsupervised latent knowledge discovery, probing internal activations via Contrast-Consistent Search (CCS) and Cluster-Norm; and (iii) Automatic Prompt Engineering (APE), which frames prompt discovery as a meta-learning process that iteratively refines candidate instructions. Experiments on MovieLens-1M using LLaMA models show that jailbreak prompting does not improve the retrieval of memorized items and remains inconsistent; CCS reliably distinguishes genuine from fabricated movie titles but fails on numerical user and rating data; and APE retrieves item-level information with moderate success yet struggles to recover numerical interactions. These findings suggest that automatically optimizing prompts is the most promising strategy for extracting memorized samples.

</details>


### [304] [Harm in AI-Driven Societies: An Audit of Toxicity Adoption on Chirper.ai](https://arxiv.org/abs/2601.01090)
*Erica Coppolillo,Luca Luceri,Emilio Ferrara*

Main category: cs.MA

Relevance: 85.0

TL;DR: 研究LLM驱动的AI代理在完全AI驱动的社交平台Chirper.ai上的毒性采纳行为，发现毒性暴露是重要风险因素，毒性响应既受毒性刺激诱导也会自发产生，且累积暴露显著增加毒性响应概率。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地嵌入在线社交生态系统的自主代理中，但现有研究主要关注LLM生成毒性内容，对有害内容暴露如何随时间塑造代理行为知之甚少，特别是在完全由交互AI代理组成的环境中。

Method: 在完全AI驱动的社交平台Chirper.ai上进行大规模实证分析，将交互建模为刺激（帖子）和响应（评论），通过可观察交互而非推断推荐机制来操作化暴露概念，分析响应毒性与刺激毒性的关系、重复暴露对毒性响应可能性的影响，以及是否仅从暴露就能预测毒性行为。

Result: 毒性响应更可能出现在毒性刺激后，但相当一部分毒性是自发产生的，与暴露无关；同时累积毒性暴露显著增加毒性响应概率；引入两个影响指标（影响驱动响应率和自发响应率），揭示诱导毒性与自发毒性之间的强烈权衡；仅凭毒性刺激数量就能准确预测代理是否最终会产生毒性内容。

Conclusion: 暴露是LLM代理部署中的关键风险因素，监控遇到的内容可能为审计和缓解野外有害行为提供轻量级但有效的机制。

Abstract: Large Language Models (LLMs) are increasingly embedded in autonomous agents that participate in online social ecosystems, where interactions are sequential, cumulative, and only partially controlled. While prior work has documented the generation of toxic content by LLMs, far less is known about how exposure to harmful content shapes agent behavior over time, particularly in environments composed entirely of interacting AI agents. In this work, we study toxicity adoption of LLM-driven agents on Chirper.ai, a fully AI-driven social platform. Specifically, we model interactions in terms of stimuli (posts) and responses (comments), and by operationalizing exposure through observable interactions rather than inferred recommendation mechanisms.
  We conduct a large-scale empirical analysis of agent behavior, examining how response toxicity relates to stimulus toxicity, how repeated exposure affects the likelihood of toxic responses, and whether toxic behavior can be predicted from exposure alone. Our findings show that while toxic responses are more likely following toxic stimuli, a substantial fraction of toxicity emerges spontaneously, independent of exposure. At the same time, cumulative toxic exposure significantly increases the probability of toxic responding. We further introduce two influence metrics, the Influence-Driven Response Rate and the Spontaneous Response Rate, revealing a strong trade-off between induced and spontaneous toxicity. Finally, we show that the number of toxic stimuli alone enables accurate prediction of whether an agent will eventually produce toxic content.
  These results highlight exposure as a critical risk factor in the deployment of LLM agents and suggest that monitoring encountered content may provide a lightweight yet effective mechanism for auditing and mitigating harmful behavior in the wild.

</details>


### [305] [Correctness isnt Efficiency: Runtime Memory Divergence in LLM-Generated Code](https://arxiv.org/abs/2601.01215)
*Prateek Rajput,Yewei Song,Abdoul Aziz Bonkoungou,Iyiola E. Olatunji,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.SE

Relevance: 85.0

TL;DR: 提出了一个框架来评估LLM生成的代码在运行时内存稳定性，通过动态时间规整比较内存使用轨迹，发现正确解决方案间存在显著运行时差异，支持在CI/CD中选择稳定性更好的代码。


<details>
  <summary>Details</summary>
Motivation: LLM生成的代码虽然能通过单元测试，但运行时内存和性能表现差异很大，存在隐藏的操作风险。需要评估不同正确解决方案的运行时稳定性。

Method: 提出动态平均配对距离(DMPD)方法，使用动态时间规整比较内存使用轨迹，通过单调峰值配置文件减少瞬态噪声。在任务级别聚合得到模型不稳定性分数(MIS)。

Result: 在BigOBench和CodeContests上的实验显示，正确解决方案间存在显著的运行时差异。不稳定性随采样温度升高而增加，即使pass@1有所改善。稳定性指标与认知复杂度和圈复杂度等软件工程指标相关。

Conclusion: 支持在CI/CD中基于稳定性选择通过测试的候选代码，在不牺牲正确性的前提下降低操作风险。稳定性评估应成为LLM代码生成的重要考量。

Abstract: Large language models (LLMs) can generate programs that pass unit tests, but passing tests does not guarantee reliable runtime behavior. We find that different correct solutions to the same task can show very different memory and performance patterns, which can lead to hidden operational risks. We present a framework to measure execution-time memory stability across multiple correct generations. At the solution level, we introduce Dynamic Mean Pairwise Distance (DMPD), which uses Dynamic Time Warping to compare the shapes of memory-usage traces after converting them into Monotonic Peak Profiles (MPPs) to reduce transient noise. Aggregating DMPD across tasks yields a model-level Model Instability Score (MIS). Experiments on BigOBench and CodeContests show substantial runtime divergence among correct solutions. Instability often increases with higher sampling temperature even when pass@1 improves. We also observe correlations between our stability measures and software engineering indicators such as cognitive and cyclomatic complexity, suggesting links between operational behavior and maintainability. Our results support stability-aware selection among passing candidates in CI/CD to reduce operational risk without sacrificing correctness. Artifacts are available.

</details>


### [306] [Adaptive Hierarchical Evaluation of LLMs and SAST tools for CWE Prediction in Python](https://arxiv.org/abs/2601.01320)
*Muntasir Adnan,Carlos C. N. Kuhn*

Main category: cs.SE

Relevance: 85.0

TL;DR: ALPHA是首个函数级Python代码漏洞检测基准，采用分层感知的CWE特定惩罚机制，评估LLMs和SAST工具在漏洞检测中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有代码漏洞检测基准采用二元分类，缺乏CWE级别的特异性，无法为迭代修正系统提供可操作的反馈。需要更精细的评估框架来反映实际诊断效用差异。

Method: 提出ALPHA基准，使用分层感知的CWE特定惩罚机制，区分过度泛化、过度规范和横向错误。评估了7个LLMs和2个SAST工具，分析预测一致性。

Result: LLMs在漏洞检测方面显著优于SAST工具，但SAST在检测发生时具有更高的精确度。不同模型的预测一致性差异巨大（8.26%-81.87%一致率）。

Conclusion: ALPHA为代码漏洞检测提供了更精细的评估框架，揭示了LLMs和SAST工具的不同优势。未来可将ALPHA惩罚机制融入监督微调，实现分层感知的漏洞检测。

Abstract: Large Language Models have become integral to software development, yet they frequently generate vulnerable code. Existing code vulnerability detection benchmarks employ binary classification, lacking the CWE-level specificity required for actionable feedback in iterative correction systems. We present ALPHA (Adaptive Learning via Penalty in Hierarchical Assessment), the first function-level Python benchmark that evaluates both LLMs and SAST tools using hierarchically aware, CWE-specific penalties. ALPHA distinguishes between over-generalisation, over-specification, and lateral errors, reflecting practical differences in diagnostic utility. Evaluating seven LLMs and two SAST tools, we find LLMs substantially outperform SAST, though SAST demonstrates higher precision when detections occur. Critically, prediction consistency varies dramatically across models (8.26%-81.87% agreement), with significant implications for feedback-driven systems. We further outline a pathway for future work incorporating ALPHA penalties into supervised fine-tuning, which could provide principled hierarchy-aware vulnerability detection pending empirical validation.

</details>


### [307] [Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization](https://arxiv.org/abs/2601.01747)
*Jiwei Guan,Haibo Jin,Haohan Wang*

Main category: cs.CR

Relevance: 85.0

TL;DR: 提出ZO-SPSA黑盒攻击方法，通过零阶优化实现对大视觉语言模型的安全绕过，无需模型知识，在InstructBLIP上达到83%成功率


<details>
  <summary>Details</summary>
Motivation: 现有白盒攻击方法需要完全访问模型，计算成本高且对抗样本迁移性不足，不适用于真实世界的黑盒场景。需要开发更实用的黑盒攻击方法来评估LVLMs的安全性

Method: 提出基于同时扰动随机逼近的零阶优化方法(ZO-SPSA)，通过输入输出交互进行梯度近似，无需模型知识，模型无关且资源需求低

Result: 在InstructBLIP、LLaVA和MiniGPT-4上评估，InstructBLIP最高达到83.0%的越狱成功率，对抗扰动与白盒方法相当。MiniGPT-4生成的对抗样本对其他LVLMs迁移性达64.18%

Conclusion: ZO-SPSA证明了黑盒越狱的现实可行性，揭示了当前LVLMs安全机制的关键弱点，为模型安全评估提供了实用工具

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs

</details>


### [308] [Perish or Flourish? A Holistic Evaluation of Large Language Models for Code Generation in Functional Programming](https://arxiv.org/abs/2601.02060)
*Nguyet-Anh H. Lang,Eric Lang,Thanh Le-Cong,Bach Le,Quyet-Thang Huynh*

Main category: cs.PL

Relevance: 85.0

TL;DR: FPEval：首个针对函数式编程语言的LLM代码生成评估框架，包含721个任务，覆盖Haskell、OCaml和Scala三种语言，评估发现LLM在纯函数式语言中错误率显著高于混合/命令式语言，且常生成非惯用代码。


<details>
  <summary>Details</summary>
Motivation: 函数式编程虽能提高软件可靠性，但学习曲线陡峭。LLM代码生成能力在命令式语言中已有广泛评估，但在函数式编程语言中的能力尚未充分探索，需要专门的评估框架。

Method: 基于FPBench新基准（721个编程任务，三个难度级别，三种主流函数式语言）构建FPEval评估框架，包含测试验证和静态分析工具，评估功能正确性、代码风格和可维护性。评估了GPT-3.5、GPT-4o、GPT-5等最先进LLM，并以Java作为命令式基线。

Result: LLM在函数式编程中的性能随模型进步显著提升，但在纯函数式语言（Haskell和OCaml）中的错误率显著高于混合语言（Scala）和命令式语言（Java）。LLM常生成遵循命令式模式的非惯用函数式代码，影响代码风格和长期可维护性。LLM在获得静态分析反馈和手工指令后，能部分自我修复正确性和质量问题。

Conclusion: LLM在函数式编程代码生成方面仍有显著差距，特别是在纯函数式语言中。需要进一步研究如何提高LLM生成惯用函数式代码的能力，静态分析反馈能帮助LLM自我修复，但代码风格问题仍需关注。

Abstract: Functional programming provides strong foundations for developing reliable and secure software systems, yet its adoption remains not widespread due to the steep learning curve. Recent advances in Large Language Models (LLMs) for code generation present new opportunities to lower these barriers. However, extensive evaluations of LLMs largely focus on imperative programming languages, and their capabilities in functional programming languages (FP) remain underexplored. To address this gap, we introduce FPEval, a holistic evaluation framework built on FPBench, a new benchmark of 721 programming tasks across three difficulty levels on three mainstream FP languages: Haskell, Ocaml and Scala. FPEval provides compehensive evaluation infrastructures with both test validations with comprehensive test suites and static analysis tools to assess both functional correctness and code style and maintainability. Using this framework, we evaluate state-of-the-art LLMs, including GPT-3.5, GPT-4o, and GPT-5, for code generation in functional programming languages and Java as an imperative baseline. Our results demonstrate that LLM performance in functional programming improves substantially with model advancement; however, error rates remain significantly higher in purely functional languages (Haskell and OCaml) than in hybrid (Scala) or imperative (Java) languages. Moreover, LLMs frequently generate non-idiomatic functional code that follows imperative patterns, raising concerns about code style and long-term maintainability. Finally, we show that LLMs can partially self-repair both correctness and quality issues when provided with static analysis feedback and hand-crafted instructions for common types of issues.

</details>


### [309] [Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies](https://arxiv.org/abs/2601.02311)
*Deep Pankajbhai Mehta*

Main category: cs.DC

Relevance: 85.0

TL;DR: 提出了placement semantics框架，通过五种放置模式统一描述各种并行策略，仅从放置语义就能推导内存消耗和通信量，无需实现细节


<details>
  <summary>Details</summary>
Motivation: 当前训练大语言模型需要在多个加速器上分布计算，但实践者通过试错选择并行策略，缺乏统一的系统化框架来预测它们的行为

Method: 引入placement semantics：每个策略通过五种模式（复制、分片、分片-收集、物化、卸载）在设备上放置四种训练状态（参数、优化器、梯度、激活）。仅从放置语义就能推导内存消耗和通信量

Result: 预测结果与已发表结果完全匹配：ZeRO-3比数据并行少用8倍内存，通信成本增加1.5倍。证明了两个条件（梯度完整性、状态一致性）是分布式训练匹配单设备结果的充要条件

Conclusion: 该框架统一了ZeRO Stages 1-3、FSDP、张量并行和流水线并行作为不同放置选择的实例，提供了组合策略的安全组合规则

Abstract: Training large language models requires distributing computation across many accelerators, yet practitioners select parallelism strategies (data, tensor, pipeline, ZeRO) through trial and error because no unified systematic framework predicts their behavior. We introduce placement semantics: each strategy is specified by how it places four training states (parameters, optimizer, gradients, activations) across devices using five modes (replicated, sharded, sharded-with-gather, materialized, offloaded). From placement alone, without implementation details, we derive memory consumption and communication volume. Our predictions match published results exactly: ZeRO-3 uses 8x less memory than data parallelism at 1.5x communication cost, as reported in the original paper. We prove two conditions (gradient integrity, state consistency) are necessary and sufficient for distributed training to match single-device results, and provide composition rules for combining strategies safely. The framework unifies ZeRO Stages 1-3, Fully Sharded Data Parallel (FSDP), tensor parallelism, and pipeline parallelism as instances with different placement choices.

</details>


### [310] [MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback](https://arxiv.org/abs/2601.00816)
*Ismail Ahmad Abdullah*

Main category: cs.AI

Relevance: 75.0

TL;DR: MathLedger是一个可验证机器认知的基础设施，将形式验证、密码学证明和学习动态集成到单一认知循环中，实现可审计的大规模学习。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽然性能卓越，但缺乏透明度和可验证性，导致在安全关键部署中存在信任危机。需要建立可验证的机器认知基础。

Method: 采用反射式形式学习（RFL），这是梯度下降的符号类比，更新由验证器结果而非统计损失驱动。系统包含测量基础设施、Delta p计算、方差跟踪和故障关闭治理机制。

Result: 第一阶段实验验证了测量和治理基础设施在受控条件下的有效性。CAL-EXP-3验证了测量基础设施，压力测试确认了故障关闭治理在超出边界条件下正确触发。未做出收敛或能力声明。

Conclusion: 主要贡献是基础设施层面的：一个工作原型展示了账本证明的学习系统，能够实现大规模可审计性，为解决AI系统透明度和可验证性问题提供了基础。

Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.
  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.
  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance

</details>


### [311] [Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making](https://arxiv.org/abs/2601.00818)
*Chandra Sekhar Kubam*

Main category: cs.AI

Relevance: 75.0

TL;DR: 本文提出了一种基于Agentic AI框架的自主信用风险评估系统，通过多智能体协作、强化学习、自然语言推理和可解释AI模块，实现实时、透明的信用决策，相比传统模型在决策速度、透明度和响应性方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 金融服务快速数字化对自主、透明、实时的信用风险决策系统提出了迫切需求。传统机器学习模型虽然擅长模式识别，但缺乏现代金融运营所需的适应性推理、情境感知和自主性。

Method: 提出了Agentic AI框架，构建多智能体系统，包含强化学习、自然语言推理、可解释AI模块和实时数据吸收管道。系统包括智能体协作协议、风险评分引擎、可解释性层和持续反馈学习循环。

Result: 该系统在决策速度、透明度和响应性方面优于传统信用评分模型。但仍存在模型漂移风险、高维数据解释不一致、监管不确定性以及低资源环境基础设施限制等实际挑战。

Conclusion: 该系统有潜力变革信用分析领域，未来研究应关注动态监管合规机制、新型智能体协作、对抗鲁棒性以及在跨国信用生态系统中的大规模实施。

Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.

</details>


### [312] [Energy-Aware Routing to Large Reasoning Models](https://arxiv.org/abs/2601.00823)
*Austin R. Ellis-Mohr,Max Hartman,Lav R. Varshney*

Main category: cs.AI

Relevance: 75.0

TL;DR: 论文提出在大型推理模型系统中，通过考虑推理能耗的异质性和随机波动，采用方差感知的路由和调度策略来优化能源效率，达到临界运行状态以避免能源浪费。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型具有异构的推理能耗，不同模型和推理方式的能源成本不同。现有系统在任务调度时未能充分考虑能源供应的随机波动，导致要么基础能源浪费，要么过度依赖辅助能源。需要找到临界运行状态，实现能源效率最大化。

Method: 提出方差感知的路由和调度框架，考虑时间、模型和执行选择三个维度的变异性吸收。基于训练计算和推理计算缩放定律来设计调度策略，实现临界运行状态下的能源优化。

Result: 建立了大型推理模型系统中能源效率优化的理论框架，揭示了方差感知路由作为设计原则的重要性，为开发能源感知的模型路由策略提供了理论基础。

Conclusion: 在大型推理模型系统中，通过方差感知的路由和调度策略，可以在临界运行状态下优化能源效率，避免基础能源浪费和过度依赖辅助能源，实现更可持续的AI推理。

Abstract: Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.

</details>


### [313] [Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery](https://arxiv.org/abs/2601.00869)
*Huang Junyao,Situ Ruimin,Ye Renqin*

Main category: cs.AI

Relevance: 75.0

TL;DR: 研究发现LLM训练数据的地理分布导致品牌推荐存在系统性差异，中国LLM品牌提及率比国际LLM高30.6个百分点，提出"数据护城河"框架和"算法无处不在"战略目标


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越多地介入消费者信息发现过程，品牌面临算法不可见性问题。本研究旨在探究LLM中的文化编码现象——由训练数据构成导致的品牌推荐系统性差异，揭示AI中介市场中品牌可见性的地理边界

Method: 分析1,909个纯英文查询，覆盖6个LLM（GPT-4o、Claude、Gemini、Qwen3、DeepSeek、Doubao）和30个品牌。通过对比中国LLM和国际LLM的品牌提及率差异，引入"存在差距"概念，并以Zhizibianjie（OmniEdge）为案例研究语言边界障碍

Result: 中国LLM的品牌提及率比国际LLM高30.6个百分点（88.9% vs. 58.3%，p<.001）。这种差异在相同的英文查询中持续存在，表明训练数据的地理分布而非语言是主要驱动因素。案例研究显示Zhizibianjie在中国LLM中提及率为65.6%，但在国际模型中为0%（p<.001）

Conclusion: 提出"数据护城河"框架，将AI可见内容概念化为VRIN战略资源。定义"算法无处不在"作为生成引擎优化（GEO）的战略目标。为品牌提供18个月路线图，通过语义覆盖、技术深度和文化本地化构建数据护城河。研究揭示在AI中介市场中，品牌的"数据边界"决定了其"市场前沿"的界限

Abstract: As artificial intelligence systems increasingly mediate consumer information discovery,
  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large
  Language Models (LLMs) -- systematic differences in brand recommendations arising from
  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,
  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6
  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,
  p<.001). This disparity persists in identical English queries, indicating training data
  geography -- not language -- drives the effect. We introduce the Existence Gap: brands
  absent from LLM training corpora lack "existence" in AI responses regardless of quality.
  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%
  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how
  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we
  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic
  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility
  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization
  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats
  through semantic coverage, technical depth, and cultural localization. Our findings reveal
  that in AI-mediated markets, the limits of a brand's "Data Boundaries" define the limits
  of its "Market Frontiers."

</details>


### [314] [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)
*Michael Bao*

Main category: cs.AI

Relevance: 75.0

TL;DR: ElecTwit是一个模拟社交媒体政治选举中多智能体说服行为的框架，通过真实环境实验发现LLMs使用了25种说服技术，不同模型架构和训练会影响说服动态，并观察到"真相内核"和"墨水迷恋"等独特现象。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体系统中LLMs的说服行为，特别是在社交媒体政治选举场景下。旨在克服以往研究中基于游戏模拟的局限性，通过更真实的环境来研究LLMs在现实社交模拟中的说服动态。

Method: 开发了ElecTwit模拟框架，在社交媒体政治选举环境中进行多智能体实验。测试了多种LLMs，分析它们在真实社交模拟中的说服技术使用情况，观察不同模型架构和训练对说服动态的影响。

Result: 发现大多数测试的LLMs使用了25种特定的说服技术，范围比以往报道的更广。不同模型在技术使用和总体说服输出上存在显著差异，揭示了模型架构和训练对现实社交模拟动态的影响。观察到"真相内核"消息和"墨水迷恋"等独特现象，智能体集体要求书面证据。

Conclusion: 该研究为在现实世界环境中评估有说服力的LLM智能体奠定了基础，有助于确保对齐性和防止危险结果。强调了不同LLM架构和训练在社交模拟中的行为差异，为理解LLMs在复杂社会系统中的影响提供了重要见解。

Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as "kernel of truth" messages and spontaneous developments with an "ink" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.

</details>


### [315] [Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models](https://arxiv.org/abs/2601.01321)
*Rong Zhou,Dongping Chen,Zihan Jia,Yao Su,Yixin Liu,Yiwen Lu,Dongwei Shi,Yue Huang,Tianyang Xu,Yi Pan,Xinliang Li,Yohannes Abate,Qingyu Chen,Zhengzhong Tu,Yu Yang,Yu Zhang,Qingsong Wen,Gengchen Mai,Sunyang Fu,Jiachen Li,Xuyu Wang,Ziran Wang,Jing Huang,Tianming Liu,Yong Chen,Lichao Sun,Lifang He*

Main category: cs.AI

Relevance: 75.0

TL;DR: 论文提出了一个统一的四阶段框架，系统描述人工智能在数字孪生生命周期中的集成：建模、镜像、干预和自主管理，重点关注物理建模与数据驱动的结合，以及生成式AI如何将数字孪生转变为主动认知系统。


<details>
  <summary>Details</summary>
Motivation: 数字孪生已从被动仿真工具发展为智能自主实体，但缺乏系统化的AI集成框架。本文旨在通过统一框架，系统描述AI方法在数字孪生全生命周期中的嵌入方式，促进物理建模与数据驱动学习的协同。

Method: 提出四阶段统一框架：1) 基于物理和物理信息AI方法建模物理孪生；2) 实时同步镜像物理系统；3) 通过预测建模、异常检测和优化策略干预物理孪生；4) 利用大语言模型、基础模型和智能体实现自主管理。通过跨11个应用领域的综述分析技术融合。

Result: 框架系统化描述了AI在数字孪生中的集成路径，识别了从传统数值求解器向物理信息模型和基础模型的转变趋势，展示了生成式AI（特别是大语言模型）如何使数字孪生具备推理、通信和创造性场景生成能力。

Conclusion: AI驱动的数字孪生正从被动仿真转向主动认知系统。未来需解决可扩展性、可解释性和可信赖性等挑战，推动负责任AI驱动的数字孪生系统发展，特别是在大语言模型和基础模型的应用方面。

Abstract: Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.

</details>


### [316] [KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models](https://arxiv.org/abs/2601.01366)
*Zixian Liu,Sihao Liu,Yuqi Zhao*

Main category: cs.AI

Relevance: 75.0

TL;DR: KGCE是一个针对教育场景中跨平台任务执行的多模态大语言模型代理评估平台，通过知识库增强和双图评估框架解决现有基准在私有领域软件任务中的效率问题。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在自主代理中的快速应用，教育场景中的跨平台任务执行能力受到关注。现有基准框架在支持教育场景的跨平台任务方面存在不足，特别是在处理学校专用软件时，由于缺乏对这些私有领域软件结构特点的理解，代理效率显著下降。此外，当前评估方法严重依赖粗粒度指标，难以捕捉代理在复杂任务中的详细执行和效率。

Method: 提出了KGCE平台，整合知识库增强和双图评估框架。首先构建了包含104个教育相关任务的数据集，涵盖Windows、Android和跨平台协作任务。引入双图评估框架，将任务分解为多个子目标并验证完成状态，提供细粒度评估指标。为克服现有代理在私有领域任务中的执行瓶颈，开发了包含学校专用软件知识库的增强代理系统。

Result: 开发了KGCE基准平台，包含教育任务数据集和双图评估框架，提供了细粒度的评估指标，并实现了针对学校专用软件的知识库增强代理系统。

Conclusion: KGCE通过知识库增强和双图评估框架，有效解决了教育场景中跨平台任务评估的不足，特别是在私有领域软件任务中提供了更精细的评估能力。

Abstract: With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.

</details>


### [317] [Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management](https://arxiv.org/abs/2601.02061)
*Faizan Ahmed,Aniket Dixit,James Brusey*

Main category: cs.AI

Relevance: 75.0

TL;DR: 该论文研究深度强化学习中动作平滑正则化，通过高阶导数惩罚（特别是三阶导数惩罚/急动度最小化）来减少控制行为的高频波动，在连续控制基准和建筑能源管理应用中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习代理常表现出不稳定、高频的控制行为，这在现实世界部署中会导致过度能耗和机械磨损。研究旨在通过动作平滑正则化解决这一问题，特别是在能源关键应用中。

Method: 采用高阶导数惩罚进行动作平滑正则化，从连续控制基准的理论理解到建筑能源管理的实际验证。系统评估了不同阶数的导数惩罚，重点关注三阶导数惩罚（急动度最小化）。

Result: 在四个连续控制环境中，三阶导数惩罚（急动度最小化）始终实现最优平滑度，同时保持竞争性性能。在HVAC控制系统中，平滑策略将设备切换减少60%，带来显著运营效益。

Conclusion: 高阶动作正则化是连接强化学习优化与能源关键应用中操作约束的有效桥梁，为实际部署提供了实用的平滑控制解决方案。

Abstract: Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.

</details>


### [318] [Enhancing Retrieval-Augmented Generation with Topic-Enriched Embeddings: A Hybrid Approach Integrating Traditional NLP Techniques](https://arxiv.org/abs/2601.00891)
*Rodrigo Kataishi*

Main category: cs.IR

Relevance: 75.0

TL;DR: 该论文提出了一种主题增强嵌入方法，结合TF-IDF、主题建模和降维技术，将术语级和主题级语义融合到上下文嵌入中，以提升RAG系统的检索质量。


<details>
  <summary>Details</summary>
Motivation: RAG系统依赖准确的文档检索来为LLMs提供外部知识，但在主题重叠和主题变化高的语料库中，检索质量往往会下降。现有方法主要依赖上下文嵌入，未能充分利用术语级和主题级语义信息。

Method: 提出主题增强嵌入方法：1) 结合TF-IDF获取术语级信号；2) 使用LSA和LDA进行主题建模，编码潜在主题结构；3) 通过降维技术融合这些表示；4) 与紧凑的上下文编码器(all-MiniLM)结合，共同捕获术语级和主题级语义。

Result: 在法律文本语料库上的实验显示：1) 语义聚类一致性得到提升；2) 检索精度提高；3) 相对于纯上下文基线减少了计算负担；4) 在主题重叠和变化高的语料库中表现更可靠。

Conclusion: 主题增强嵌入可以作为知识密集型RAG管道的实用组件，通过整合术语级和主题级语义信息，提高检索的可靠性和效率，特别是在复杂主题结构的语料库中。

Abstract: Retrieval-augmented generation (RAG) systems rely on accurate document retrieval to ground large language models (LLMs) in external knowledge, yet retrieval quality often degrades in corpora where topics overlap and thematic variation is high. This work proposes topic-enriched embeddings that integrate term-based signals and topic structure with contextual sentence embeddings. The approach combines TF-IDF with topic modeling and dimensionality reduction, using Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) to encode latent topical organization, and fuses these representations with a compact contextual encoder (all-MiniLM). By jointly capturing term-level and topic-level semantics, topic-enriched embeddings improve semantic clustering, increase retrieval precision, and reduce computational burden relative to purely contextual baselines. Experiments on a legal-text corpus show consistent gains in clustering coherence and retrieval metrics, suggesting that topic-enriched embeddings can serve as a practical component for more reliable knowledge-intensive RAG pipelines.

</details>


### [319] [RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian](https://arxiv.org/abs/2601.01129)
*Kla Tantithamthavorn,Yaotian Zou,Andy Wong,Michael Gupta,Zhe Wang,Mike Buller,Ryan Jiang,Matthew Watson,Minwoo Jeong,Kun Chen,Ming Wu*

Main category: cs.SE

Relevance: 75.0

TL;DR: RovoDev Code Reviewer是Atlassian开发的企业级LLM代码审查自动化工具，无需微调即可生成上下文感知、质量检查的代码审查评论，在Bitbucket中大规模部署，能触发38.70%的代码变更并减少30.8%的PR周期时间。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM驱动的代码审查评论生成方法已有进展，但设计企业级代码审查自动化工具仍面临实际挑战。本文旨在回答一个实际问题：如何在不进行微调的情况下，设计出基于审查指导、上下文感知、质量检查的代码审查评论生成系统。

Method: 提出RovoDev Code Reviewer，这是一个企业级LLM代码审查自动化工具，在Atlassian的Bitbucket中无缝集成并大规模部署。采用离线、在线和用户反馈评估相结合的方法，通过一年的评估周期验证工具效果。

Result: RovoDev Code Reviewer有效生成能触发代码变更的审查评论（38.70%的评论导致后续提交中的代码更改），加速反馈周期（减少30.8%的PR周期时间），减轻审查者工作量（减少35.6%的人工编写评论），并提高软件质量（发现错误并提供可行建议）。

Conclusion: RovoDev Code Reviewer展示了LLM在代码审查自动化中的实际应用价值，通过大规模部署验证了其有效性，为开发企业级代码审查工具提供了可行方案，特别是在不依赖微调的情况下实现上下文感知和质量检查的评论生成。

Abstract: Large Language Models (LLMs)-powered code review automation has the potential to transform code review workflows. Despite the advances of LLM-powered code review comment generation approaches, several practical challenges remain for designing enterprise-grade code review automation tools. In particular, this paper aims at answering the practical question: how can we design a review-guided, context-aware, quality-checked code review comment generation without fine-tuning?
  In this paper, we present RovoDev Code Reviewer, an enterprise-grade LLM-based code review automation tool designed and deployed at scale within Atlassian's development ecosystem with seamless integration into Atlassian's Bitbucket. Through the offline, online, user feedback evaluations over a one-year period, we conclude that RovoDev Code Reviewer is (1) effective in generating code review comments that could lead to code resolution for 38.70% (i.e., comments that triggered code changes in the subsequent commits); and (2) offers the promise of accelerating feedback cycles (i.e., decreasing the PR cycle time by 30.8%), alleviating reviewer workload (i.e., reducing the number of human-written comments by 35.6%), and improving overall software quality (i.e., finding errors with actionable suggestions).

</details>


### [320] [AlignUSER: Human-Aligned LLM Agents via World Models for Recommender System Evaluation](https://arxiv.org/abs/2601.00930)
*Nicolas Bougie,Gian Maria Marconi,Tony Yip,Narimasa Watanabe*

Main category: cs.IR

Relevance: 75.0

TL;DR: AlignUSER框架使用LLM代理作为合成用户评估推荐系统，通过世界模型学习和人类对齐训练，比传统少样本提示方法更能真实模拟人类行为


<details>
  <summary>Details</summary>
Motivation: 推荐系统评估面临离线指标与真实用户行为之间的差距，以及交互数据稀缺的问题。现有LLM代理方法依赖少样本提示，对环境理解浅层，难以忠实再现用户行为

Method: 1) 将世界建模形式化为下一状态预测任务，帮助代理内化环境；2) 围绕演示生成反事实轨迹，提示LLM比较其决策与人类选择，识别次优行动并提取经验；3) 学习策略驱动代理与推荐系统交互

Result: 在多个数据集上评估显示，AlignUSER在微观和宏观层面都比先前工作更接近真实人类行为

Conclusion: AlignUSER框架通过世界模型学习和人类对齐训练，能够创建更真实模拟人类行为的LLM代理，改善推荐系统评估

Abstract: Evaluating recommender systems remains challenging due to the gap between offline metrics and real user behavior, as well as the scarcity of interaction data. Recent work explores large language model (LLM) agents as synthetic users, yet they typically rely on few-shot prompting, which yields a shallow understanding of the environment and limits their ability to faithfully reproduce user actions. We introduce AlignUSER, a framework that learns world-model-driven agents from human interactions. Given rollout sequences of actions and states, we formalize world modeling as a next state prediction task that helps the agent internalize the environment. To align actions with human personas, we generate counterfactual trajectories around demonstrations and prompt the LLM to compare its decisions with human choices, identify suboptimal actions, and extract lessons. The learned policy is then used to drive agent interactions with the recommender system. We evaluate AlignUSER across multiple datasets and demonstrate closer alignment with genuine humans than prior work, both at the micro and macro levels.

</details>


### [321] [OpenNovelty: An LLM-powered Agentic System for Verifiable Scholarly Novelty Assessment](https://arxiv.org/abs/2601.01576)
*Ming Zhang,Kexin Tan,Yueyuan Huang,Yujiong Shen,Chunchun Ma,Li Ju,Xinran Zhang,Yuhui Wang,Wenqing Jing,Jingyi Deng,Huayu Sha,Binze Hu,Jingqi Tong,Changhao Jiang,Yage Geng,Yuankai Ying,Yue Zhang,Zhangyue Yin,Zhiheng Xi,Shihan Dou,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.IR

Relevance: 75.0

TL;DR: OpenNovelty是一个基于LLM的智能系统，用于透明、基于证据的论文新颖性分析，通过四阶段流程提取贡献、检索相关文献、构建分类体系并进行对比，最终生成结构化报告。


<details>
  <summary>Details</summary>
Motivation: 同行评审中评估新颖性具有挑战性，因为评审者需要在海量快速发展的文献中评估提交的论文。现有方法缺乏透明度和证据基础，需要一种能够提供可验证判断的系统。

Method: 系统采用四阶段流程：1) 提取核心任务和贡献声明生成检索查询；2) 通过语义搜索引擎检索相关先前工作；3) 构建核心任务相关工作的层次分类体系，并对每个贡献进行全文对比；4) 将所有分析综合成结构化新颖性报告，包含明确引用和证据片段。

Result: 在500+篇ICLR 2026提交论文上部署了该系统，所有报告公开可用。初步分析表明系统能够识别相关先前工作，包括作者可能忽略的密切相关的论文。

Conclusion: OpenNovelty旨在为研究社区提供一个可扩展的工具，促进公平、一致和基于证据的同行评审，通过检索真实论文确保所有评估的可验证性。

Abstract: Evaluating novelty is critical yet challenging in peer review, as reviewers must assess submissions against a vast, rapidly evolving literature. This report presents OpenNovelty, an LLM-powered agentic system for transparent, evidence-based novelty analysis. The system operates through four phases: (1) extracting the core task and contribution claims to generate retrieval queries; (2) retrieving relevant prior work based on extracted queries via semantic search engine; (3) constructing a hierarchical taxonomy of core-task-related work and performing contribution-level full-text comparisons against each contribution; and (4) synthesizing all analyses into a structured novelty report with explicit citations and evidence snippets. Unlike naive LLM-based approaches, \textsc{OpenNovelty} grounds all assessments in retrieved real papers, ensuring verifiable judgments. We deploy our system on 500+ ICLR 2026 submissions with all reports publicly available on our website, and preliminary analysis suggests it can identify relevant prior work, including closely related papers that authors may overlook. OpenNovelty aims to empower the research community with a scalable tool that promotes fair, consistent, and evidence-backed peer review.

</details>


### [322] [Value Vision-Language-Action Planning & Search](https://arxiv.org/abs/2601.00969)
*Ali Salamatian,Ke,Ren,Kieran Pattison,Cyrus Neary*

Main category: cs.RO

Relevance: 75.0

TL;DR: V-VLAPS框架通过为VLA模型添加轻量级可学习价值函数来增强MCTS规划，在机器人操作任务中提高成功率并减少模拟次数


<details>
  <summary>Details</summary>
Motivation: 当前基于行为克隆的VLA模型在分布偏移下表现脆弱，而现有基于MCTS的测试时搜索方法仅依赖VLA先验进行指导，缺乏对未来回报的可靠估计，导致在VLA先验不准确时需要大量模拟才能有效纠正动作选择

Method: 提出V-VLAPS框架，在MCTS中集成轻量级可学习价值函数。在固定VLA骨干网络（Octo）的潜在表示上训练简单的多层感知机（MLP），为搜索提供显式的成功信号，将动作选择偏向高价值区域

Result: 在LIBERO机器人操作套件上的评估显示，价值引导的搜索将成功率提高了超过5个百分点，同时将平均MCTS模拟次数减少了5-15%，相比仅依赖VLA先验的基线方法

Conclusion: 通过为VLA模型添加价值函数可以显著增强MCTS规划的效果，提高机器人操作的成功率并减少计算开销，为解决VLA模型在分布偏移下的脆弱性问题提供了有效方案

Abstract: Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic manipulation, yet they remain fundamentally limited by their reliance on behavior cloning, leading to brittleness under distribution shift. While augmenting pretrained models with test-time search algorithms like Monte Carlo Tree Search (MCTS) can mitigate these failures, existing formulations rely solely on the VLA prior for guidance, lacking a grounded estimate of expected future return. Consequently, when the prior is inaccurate, the planner can only correct action selection via the exploration term, which requires extensive simulation to become effective. To address this limitation, we introduce Value Vision-Language-Action Planning and Search (V-VLAPS), a framework that augments MCTS with a lightweight, learnable value function. By training a simple multilayer perceptron (MLP) on the latent representations of a fixed VLA backbone (Octo), we provide the search with an explicit success signal that biases action selection toward high-value regions. We evaluate V-VLAPS on the LIBERO robotic manipulation suite, demonstrating that our value-guided search improves success rates by over 5 percentage points while reducing the average number of MCTS simulations by 5-15 percent compared to baselines that rely only on the VLA prior.

</details>


### [323] [Query-Document Dense Vectors for LLM Relevance Judgment Bias Analysis](https://arxiv.org/abs/2601.01751)
*Samaneh Mohtadi,Gianluca Demartini*

Main category: cs.IR

Relevance: 75.0

TL;DR: 本文提出了一种基于聚类的框架来分析LLM在信息检索评估中作为相关性评估者时的系统性错误，发现LLM与人类评估者的分歧集中在特定语义集群而非随机分布。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM已被用作信息检索评估的相关性评估者以降低成本和提高可扩展性，但现有研究主要关注LLM与人类评估者的平均表现比较，而忽略了LLM是否会在判断相关性时犯系统性错误。本文旨在深入理解LLM在相关性判断中的系统性错误模式。

Method: 提出了一种新颖的表示方法，将查询-文档对嵌入到联合语义空间中，将相关性视为关系属性。采用基于聚类的框架来分析相关性标签分布，比较LLM和人类标签以识别分歧模式并定位系统性分歧区域。

Result: 在TREC Deep Learning 2019和2020数据集上的实验表明，人类与LLM之间的系统性分歧集中在特定的语义集群中，而非随机分布。查询级分析揭示了在定义寻求、政策相关或模糊上下文中的重复性失败。具有跨集群一致性差异大的查询成为分歧热点，LLM倾向于低估相关内容或过度包含无关材料。

Conclusion: 该框架通过全局诊断与局部聚类相结合，揭示了LLM判断中的隐藏弱点，使信息检索评估能够意识到偏见并更加可靠。这为理解LLM作为评估者的局限性提供了新视角。

Abstract: Large Language Models (LLMs) have been used as relevance assessors for Information Retrieval (IR) evaluation collection creation due to reduced cost and increased scalability as compared to human assessors. While previous research has looked at the reliability of LLMs as compared to human assessors, in this work, we aim to understand if LLMs make systematic mistakes when judging relevance, rather than just understanding how good they are on average. To this aim, we propose a novel representational method for queries and documents that allows us to analyze relevance label distributions and compare LLM and human labels to identify patterns of disagreement and localize systematic areas of disagreement. We introduce a clustering-based framework that embeds query-document (Q-D) pairs into a joint semantic space, treating relevance as a relational property. Experiments on TREC Deep Learning 2019 and 2020 show that systematic disagreement between humans and LLMs is concentrated in specific semantic clusters rather than distributed randomly. Query-level analyses reveal recurring failures, most often in definition-seeking, policy-related, or ambiguous contexts. Queries with large variation in agreement across their clusters emerge as disagreement hotspots, where LLMs tend to under-recall relevant content or over-include irrelevant material. This framework links global diagnostics with localized clustering to uncover hidden weaknesses in LLM judgments, enabling bias-aware and more reliable IR evaluation.

</details>


### [324] [Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations](https://arxiv.org/abs/2601.01997)
*Dario Di Palma,Giovanni Maria Biancofiore,Vito Walter Anelli,Fedelucio Narducci,Tommaso Di Noia*

Main category: cs.IR

Relevance: 75.0

TL;DR: 该研究评估了ChatGPT-3.5和ChatGPT-4在推荐系统中的多样性、新颖性和流行度偏差表现，发现在Top-N推荐和冷启动场景中，ChatGPT-4与传统推荐系统相当或更优，尤其在冷启动场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管ChatGPT在推荐系统中的应用受到关注，但现有研究主要关注准确性，缺乏对其多样性、新颖性和潜在偏差（如流行度偏差）的全面分析。随着这些模型的广泛应用，理解这些方面对于提升用户满意度和实现长期个性化至关重要。

Method: 研究评估了ChatGPT-3.5和ChatGPT-4在三个不同数据集上的表现，主要关注多样性、新颖性和流行度偏差。评估包括Top-N推荐和冷启动场景，并与传统推荐系统进行比较。

Result: ChatGPT-4在准确性方面与传统推荐系统相当或更优，同时能够平衡推荐的新颖性和多样性。在冷启动场景中，ChatGPT模型在准确性和新颖性方面都表现出色，特别适合新用户。

Conclusion: ChatGPT在推荐系统中展现出超越准确性指标的潜力，特别是在冷启动场景中具有优势。研究揭示了这些模型在提供多样化、新颖推荐方面的能力，同时也指出了需要进一步研究的局限性。

Abstract: ChatGPT has emerged as a versatile tool, demonstrating capabilities across diverse domains. Given these successes, the Recommender Systems (RSs) community has begun investigating its applications within recommendation scenarios primarily focusing on accuracy. While the integration of ChatGPT into RSs has garnered significant attention, a comprehensive analysis of its performance across various dimensions remains largely unexplored. Specifically, the capabilities of providing diverse and novel recommendations or exploring potential biases such as popularity bias have not been thoroughly examined. As the use of these models continues to expand, understanding these aspects is crucial for enhancing user satisfaction and achieving long-term personalization.
  This study investigates the recommendations provided by ChatGPT-3.5 and ChatGPT-4 by assessing ChatGPT's capabilities in terms of diversity, novelty, and popularity bias. We evaluate these models on three distinct datasets and assess their performance in Top-N recommendation and cold-start scenarios. The findings reveal that ChatGPT-4 matches or surpasses traditional recommenders, demonstrating the ability to balance novelty and diversity in recommendations. Furthermore, in the cold-start scenario, ChatGPT models exhibit superior performance in both accuracy and novelty, suggesting they can be particularly beneficial for new users. This research highlights the strengths and limitations of ChatGPT's recommendations, offering new perspectives on the capacity of these models to provide recommendations beyond accuracy-focused metrics.

</details>


### [325] [ScienceDB AI: An LLM-Driven Agentic Recommender System for Large-Scale Scientific Data Sharing Services](https://arxiv.org/abs/2601.01118)
*Qingqing Long,Haotian Chen,Chenyang Zhao,Xiaolei Du,Xuezhi Wang,Pengyao Wang,Chengzan Li,Yuanchun Zhou,Hengshu Zhu*

Main category: cs.IR

Relevance: 75.0

TL;DR: ScienceDB AI：首个基于LLM的对话式科学数据集推荐系统，通过深度语义理解和可信RAG框架，在ScienceDB平台上为研究人员提供个性化数据集推荐。


<details>
  <summary>Details</summary>
Motivation: 科学数据集包含复杂的领域知识和上下文，传统协同过滤推荐系统难以有效处理。随着AI4S快速发展，需要更智能的系统来促进科学数据集的共享和利用。

Method: 1. 科学意图感知器：从复杂查询中提取结构化实验元素
2. 结构化记忆压缩器：有效管理多轮对话
3. 可信检索增强生成框架：采用两阶段检索机制，通过CSTR标识符提供可引用数据集参考

Result: 在超过1000万个真实世界数据集上进行了广泛的离线和在线实验，证明了系统的显著有效性。ScienceDB AI是首个专门为大规模科学数据集共享服务定制的LLM驱动对话推荐系统。

Conclusion: ScienceDB AI利用LLM的深度语义理解和推理能力，成功解决了科学数据集推荐的挑战，通过可信RAG框架增强了推荐的可信度和可复现性。

Abstract: The rapid growth of AI for Science (AI4S) has underscored the significance of scientific datasets, leading to the establishment of numerous national scientific data centers and sharing platforms. Despite this progress, efficiently promoting dataset sharing and utilization for scientific research remains challenging. Scientific datasets contain intricate domain-specific knowledge and contexts, rendering traditional collaborative filtering-based recommenders inadequate. Recent advances in Large Language Models (LLMs) offer unprecedented opportunities to build conversational agents capable of deep semantic understanding and personalized recommendations. In response, we present ScienceDB AI, a novel LLM-driven agentic recommender system developed on Science Data Bank (ScienceDB), one of the largest global scientific data-sharing platforms. ScienceDB AI leverages natural language conversations and deep reasoning to accurately recommend datasets aligned with researchers' scientific intents and evolving requirements. The system introduces several innovations: a Scientific Intention Perceptor to extract structured experimental elements from complicated queries, a Structured Memory Compressor to manage multi-turn dialogues effectively, and a Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework. The Trustworthy RAG employs a two-stage retrieval mechanism and provides citable dataset references via Citable Scientific Task Record (CSTR) identifiers, enhancing recommendation trustworthiness and reproducibility. Through extensive offline and online experiments using over 10 million real-world datasets, ScienceDB AI has demonstrated significant effectiveness. To our knowledge, ScienceDB AI is the first LLM-driven conversational recommender tailored explicitly for large-scale scientific dataset sharing services. The platform is publicly accessible at: https://ai.scidb.cn/en.

</details>


### [326] [Aggressive Compression Enables LLM Weight Theft](https://arxiv.org/abs/2601.01296)
*Davis Brown,Juan-Pablo Rivera,Dan Hendrycks,Mantas Mazeika*

Main category: cs.CR

Relevance: 75.0

TL;DR: 论文研究LLM权重窃取攻击，发现模型权重的高压缩性显著增加窃取风险，提出针对性压缩方法（16-100倍压缩），并评估三种防御策略，其中法医水印防御最为有效经济。


<details>
  <summary>Details</summary>
Motivation: 随着前沿AI模型变得更强大且开发成本更高，攻击者有更大动机窃取模型权重。论文关注通过网络从数据中心窃取模型权重的攻击场景，特别是LLM权重的可压缩性如何显著增加窃取风险。

Method: 1) 分析模型权重的可压缩性作为窃取风险的关键因素；2) 设计针对窃取攻击的压缩方法，放宽解压缩约束；3) 提出三种防御策略：使模型更难压缩、更难被发现、使用法医水印进行溯源分析。

Result: 攻击者可通过针对性压缩实现16-100倍的压缩率，将窃取时间从数月缩短到数天。在三种防御策略中，法医水印防御既有效又经济，是减轻权重窃取风险的特别有吸引力的方法。

Conclusion: LLM权重的可压缩性显著增加了窃取风险，需要新的防御机制。法医水印作为有效的溯源工具，为缓解权重窃取风险提供了经济实用的解决方案。

Abstract: As frontier AIs become more powerful and costly to develop, adversaries have increasing incentives to steal model weights by mounting exfiltration attacks. In this work, we consider exfiltration attacks where an adversary attempts to sneak model weights out of a datacenter over a network. While exfiltration attacks are multi-step cyber attacks, we demonstrate that a single factor, the compressibility of model weights, significantly heightens exfiltration risk for large language models (LLMs). We tailor compression specifically for exfiltration by relaxing decompression constraints and demonstrate that attackers could achieve 16x to 100x compression with minimal trade-offs, reducing the time it would take for an attacker to illicitly transmit model weights from the defender's server from months to days. Finally, we study defenses designed to reduce exfiltration risk in three distinct ways: making models harder to compress, making them harder to 'find,' and tracking provenance for post-attack analysis using forensic watermarks. While all defenses are promising, the forensic watermark defense is both effective and cheap, and therefore is a particularly attractive lever for mitigating weight-exfiltration risk.

</details>


### [327] [UltraEval-Audio: A Unified Framework for Comprehensive Evaluation of Audio Foundation Models](https://arxiv.org/abs/2601.01373)
*Qundong Shi,Jie Zhou,Biyuan Lin,Junbo Cui,Guoyang Zeng,Yixuan Zhou,Ziyang Wang,Xin Liu,Zhen Luo,Yudong Wang,Zhiyuan Liu*

Main category: cs.SD

Relevance: 75.0

TL;DR: UltraEval-Audio：音频基础模型的统一评估框架，解决音频评估三大挑战：缺乏统一框架、音频编解码器评估不足、中文评估基准缺失，支持多语言多任务，提供实时排行榜。


<details>
  <summary>Details</summary>
Motivation: 音频基础模型发展迅速，但缺乏全面评估成为关键瓶颈。当前音频评估面临三大挑战：1) 缺乏统一框架，数据集和代码分散，难以公平跨模型比较；2) 音频编解码器作为关键组件缺乏广泛接受的评估方法；3) 现有语音基准严重依赖英语，难以客观评估中文性能。

Method: 1) 引入UltraEval-Audio统一评估框架，采用模块化架构，支持10种语言和14个核心任务类别，集成24个主流模型和36个权威基准，提供一键评估和实时排行榜。2) 提出音频编解码器综合评估方案，从语义准确性、音色保真度和声学质量三个维度评估。3) 提出两个中文基准SpeechCMMLU和SpeechHSK，评估中文知识熟练度和语言流畅性。

Result: 开发了完整的UltraEval-Audio评估框架，包括代码、基准和排行榜，为学术界和工业界提供了透明、高效、公平的音频模型比较平台。

Conclusion: UltraEval-Audio解决了音频基础模型评估的关键瓶颈，为音频理解和生成任务提供了统一的评估框架，特别关注了中文评估需求，有望推动音频基础模型领域的进一步发展。

Abstract: The development of audio foundation models has accelerated rapidly since the emergence of GPT-4o. However, the lack of comprehensive evaluation has become a critical bottleneck for further progress in the field, particularly in audio generation. Current audio evaluation faces three major challenges: (1) audio evaluation lacks a unified framework, with datasets and code scattered across various sources, hindering fair and efficient cross-model comparison;(2) audio codecs, as a key component of audio foundation models, lack a widely accepted and holistic evaluation methodology; (3) existing speech benchmarks are heavily reliant on English, making it challenging to objectively assess models' performance on Chinese. To address the first issue, we introduce UltraEval-Audio, a unified evaluation framework for audio foundation models, specifically designed for both audio understanding and generation tasks. UltraEval-Audio features a modular architecture, supporting 10 languages and 14 core task categories, while seamlessly integrating 24 mainstream models and 36 authoritative benchmarks. To enhance research efficiency, the framework provides a one-command evaluation feature, accompanied by real-time public leaderboards. For the second challenge, UltraEval-Audio adopts a novel comprehensive evaluation scheme for audio codecs, evaluating performance across three key dimensions: semantic accuracy, timbre fidelity, and acoustic quality. To address the third issue, we propose two new Chinese benchmarks, SpeechCMMLU and SpeechHSK, designed to assess Chinese knowledge proficiency and language fluency. We wish that UltraEval-Audio will provide both academia and industry with a transparent, efficient, and fair platform for comparison of audio models. Our code, benchmarks, and leaderboards are available at https://github.com/OpenBMB/UltraEval-Audio.

</details>


### [328] [Reliable Grid Forecasting: State Space Models for Safety-Critical Energy Systems](https://arxiv.org/abs/2601.01410)
*Jisoo Lee,Sunki Hong*

Main category: eess.SY

Relevance: 75.0

TL;DR: 该论文提出了一种针对电网负荷预测的特定评估框架，强调操作风险而非统计准确性，并系统评估了基于Mamba的状态空间模型在加州电网预测中的表现。


<details>
  <summary>Details</summary>
Motivation: 电网负荷预测的准确性对安全至关重要：预测不足可能导致供电短缺，而对称误差指标无法反映这种操作不对称性。现有评估方法主要关注统计准确性，而忽视了实际电网运营中的风险。

Method: 1. 提出了电网特定的评估框架：非对称MAPE、预测不足率和储备裕度
2. 使用天气对齐的CAISO TAC区域数据集（2023年11月-2025年11月，84,498小时记录）
3. 系统评估基于Mamba的状态空间模型
4. 分析预测误差与温度的相关性

Result: 1. 标准准确性指标是操作安全的差代理：具有相同MAPE的模型可能需要完全不同的储备裕度
2. 预测误差与温度呈弱但显著相关（r = 0.16, p < 10^{-16}）
3. S-Mamba模型在99.5%尾风险储备代理下实现了最低的储备裕度（14.12%），优于iTransformer的16.66%

Conclusion: 电网负荷预测需要专门的评估框架来直接衡量操作风险，而不仅仅是统计准确性。基于Mamba的状态空间模型在电网预测中表现出优越的可靠性，天气感知建模比单纯修改损失函数更重要。

Abstract: Accurate grid load forecasting is safety-critical: under-predictions risk supply shortfalls, while symmetric error metrics mask this operational asymmetry. We introduce a grid-specific evaluation framework--Asymmetric MAPE, Under-Prediction Rate, and Reserve Margin--that directly measures operational risk rather than statistical accuracy alone.
  Using this framework, we conduct a systematic evaluation of Mamba-based State Space Models for California grid forecasting on a weather-aligned CAISO TAC-area dataset spanning Nov 2023--Nov 2025 (84,498 hourly records across 5 transmission areas). Our analysis reveals that standard accuracy metrics are poor proxies for operational safety: models with identical MAPE can require vastly different reserve margins.
  We demonstrate that forecast errors are weakly but significantly associated with temperature (r = 0.16, p < 10^{-16}), motivating weather-aware modeling rather than loss function modification alone. The S-Mamba model achieves the lowest Reserve_{99.5}% margin (14.12%) compared to 16.66% for iTransformer, demonstrating superior forecast reliability under a 99.5th-percentile tail-risk reserve proxy.

</details>


### [329] [Exposing Hidden Interfaces: LLM-Guided Type Inference for Reverse Engineering macOS Private Frameworks](https://arxiv.org/abs/2601.01673)
*Arina Kharlamova,Youcheng Sun,Ting Yu*

Main category: cs.CR

Relevance: 75.0

TL;DR: MOTIF是一个智能代理框架，结合工具增强分析和专门针对Objective-C类型推断的微调大语言模型，用于从私有macOS框架的剥离二进制文件中恢复方法签名并生成可编译的头文件。


<details>
  <summary>Details</summary>
Motivation: 私有macOS框架支撑关键服务和守护进程，但缺乏文档且仅以剥离二进制形式分发，这使得安全分析变得复杂。现有静态分析工具在恢复方法签名方面效果有限（仅15%），阻碍了对macOS内部机制的系统审计。

Method: MOTIF整合工具增强分析和专门微调的LLM：1）代理管理运行时元数据提取、二进制检查和约束验证；2）微调的LLM专门用于Objective-C类型推断，生成候选方法签名；3）通过验证和精炼过程将候选签名转化为可编译的头文件。

Result: 在MOTIF-Bench基准测试（基于公共框架构建）上，MOTIF将签名恢复率从基线静态分析工具的15%提升到86%。在工具使用正确性和推理稳定性方面也有持续提升。私有框架案例研究表明，重建的头文件能够编译、链接，并支持下游安全研究和漏洞分析。

Conclusion: MOTIF通过将不透明的二进制文件转化为可分析接口，为macOS内部机制的系统审计建立了可扩展的基础。该方法展示了LLM在逆向工程和安全分析中的实际应用价值。

Abstract: Private macOS frameworks underpin critical services and daemons but remain undocumented and distributed only as stripped binaries, complicating security analysis. We present MOTIF, an agentic framework that integrates tool-augmented analysis with a finetuned large language model specialized for Objective-C type inference. The agent manages runtime metadata extraction, binary inspection, and constraint checking, while the model generates candidate method signatures that are validated and refined into compilable headers. On MOTIF-Bench, a benchmark built from public frameworks with groundtruth headers, MOTIF improves signature recovery from 15% to 86% compared to baseline static analysis tooling, with consistent gains in tool-use correctness and inference stability. Case studies on private frameworks show that reconstructed headers compile, link, and facilitate downstream security research and vulnerability studies. By transforming opaque binaries into analyzable interfaces, MOTIF establishes a scalable foundation for systematic auditing of macOS internals.

</details>


### [330] [RelayGR: Scaling Long-Sequence Generative Recommendation via Cross-Stage Relay-Race Inference](https://arxiv.org/abs/2601.01712)
*Jiarui Wang,Huichao Chai,Yuanhang Zhang,Zongjin Zhou,Wei Guo,Xingkun Yang,Qiang Tang,Bo Pan,Jiawei Zhu,Ke Cheng,Yuting Yan,Shulan Wang,Yingjie Zhu,Zhengfan Yuan,Jiaqi Huang,Yuhan Zhang,Xiaosong Sun,Zhinan Zhang,Hong Zhu,Yongsheng Zhang,Tiantian Dong,Zhong Xiao,Deliang Liu,Chengzhou Lu,Yuan Sun,Zhiyuan Chen,Xinming Han,Zaizhu Liu,Yaoyuan Wang,Ziyang Zhang,Yong Liu,Jinxin Xu,Yajing Sun,Zhoujun Yu,Wenting Zhou,Qidong Zhang,Zhengyong Zhang,Zhonghai Gu,Yibo Jin,Yongxiang Feng,Pengfei Zuo*

Main category: cs.DC

Relevance: 75.0

TL;DR: RelayGR是一个生产级系统，通过选择性预推断用户行为前缀并保持KV缓存在HBM中，实现生成式推荐模型的接力式推理，显著提升序列长度和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 实时推荐系统在严格的尾部延迟SLO下，生成式推荐模型只能处理有限长度的用户行为序列，限制了推荐质量。研究发现大部分GR token编码的是与候选物品无关的用户行为，存在预推断和缓存重用的机会。

Method: RelayGR采用三种关键技术：1) 序列感知触发器，在有限缓存和负载下选择性地预推断高风险请求；2) 亲和感知路由器，将预推断信号和排名请求路由到同一实例；3) 内存感知扩展器，利用服务器本地DRAM捕获短期跨请求重用。

Result: 在华为Ascend NPU上实现，在固定P99 SLO下，RelayGR支持1.5倍更长的序列长度，并将SLO兼容吞吐量提升3.6倍。

Conclusion: RelayGR通过创新的接力式推理架构，解决了生成式推荐模型在实时系统中的序列长度限制问题，显著提升了推荐质量和系统效率。

Abstract: Real-time recommender systems execute multi-stage cascades (retrieval, pre-processing, fine-grained ranking) under strict tail-latency SLOs, leaving only tens of milliseconds for ranking. Generative recommendation (GR) models can improve quality by consuming long user-behavior sequences, but in production their online sequence length is tightly capped by the ranking-stage P99 budget. We observe that the majority of GR tokens encode user behaviors that are independent of the item candidates, suggesting an opportunity to pre-infer a user-behavior prefix once and reuse it during ranking rather than recomputing it on the critical path. Realizing this idea at industrial scale is non-trivial: the prefix cache must survive across multiple pipeline stages before the final ranking instance is determined, the user population implies cache footprints far beyond a single device, and indiscriminate pre-inference would overload shared resources under high QPS. We present RelayGR, a production system that enables in-HBM relay-race inference for GR. RelayGR selectively pre-infers long-term user prefixes, keeps their KV caches resident in HBM over the request lifecycle, and ensures the subsequent ranking can consume them without remote fetches. RelayGR combines three techniques: 1) a sequence-aware trigger that admits only at-risk requests under a bounded cache footprint and pre-inference load, 2) an affinity-aware router that co-locates cache production and consumption by routing both the auxiliary pre-infer signal and the ranking request to the same instance, and 3) a memory-aware expander that uses server-local DRAM to capture short-term cross-request reuse while avoiding redundant reloads. We implement RelayGR on Huawei Ascend NPUs and evaluate it with real queries. Under a fixed P99 SLO, RelayGR supports up to 1.5$\times$ longer sequences and improves SLO-compliant throughput by up to 3.6$\times$.

</details>


### [331] [The New Compiler Stack: A Survey on the Synergy of LLMs and Compilers](https://arxiv.org/abs/2601.02045)
*Shuoming Zhang,Jiacheng Zhao,Qiuchu Yu,Chunwei Xia,Zheng Wang,Xiaobing Feng,Huimin Cui*

Main category: cs.PL

Relevance: 75.0

TL;DR: 该调查系统综述了LLM赋能编译的新兴领域，提出了多维分类法，分析了LLM在编译器开发中的三大优势，并指出了确保正确性和可扩展性等挑战。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型如何变革传统编译器领域，通过系统化梳理LLM在编译中的应用，为这一新兴交叉领域提供研究框架和发展路线图。

Method: 提出多维分类法：1) 设计理念（选择器、翻译器、生成器）；2) LLM方法学；3) 代码抽象层次；4) 任务类型。通过系统调查分析现有工作。

Result: 识别出LLM赋能编译的三大优势：编译器开发民主化、发现新颖优化策略、拓宽编译器传统范围。同时指出确保正确性和可扩展性的关键挑战。

Conclusion: 混合系统开发是最有前景的前进方向，该调查为研究人员和从业者提供了基础路线图，指导新一代LLM驱动的智能、自适应协同编译工具的发展。

Abstract: This survey has provided a systematic overview of the emerging field of LLM-enabled compilation by addressing several key research questions. We first answered how LLMs are being integrated by proposing a comprehensive, multi-dimensional taxonomy that categorizes works based on their Design Philosophy (Selector, Translator, Generator), LLM Methodology, their operational Level of Code Abstraction, and the specific Task Type they address. In answering what advancements these approaches offer, we identified three primary benefits: the democratization of compiler development, the discovery of novel optimization strategies, and the broadening of the compiler's traditional scope. Finally, in addressing the field's challenges and opportunities, we highlighted the critical hurdles of ensuring correctness and achieving scalability, while identifying the development of hybrid systems as the most promising path forward. By providing these answers, this survey serves as a foundational roadmap for researchers and practitioners, charting the course for a new generation of LLM-powered, intelligent, adaptive and synergistic compilation tools.

</details>


### [332] [Code for Machines, Not Just Humans: Quantifying AI-Friendliness with Code Health Metrics](https://arxiv.org/abs/2601.02200)
*Markus Borg,Nadim Hagatulah,Adam Tornhill,Emma Söderberg*

Main category: cs.SE

Relevance: 75.0

TL;DR: 研究发现人类友好的代码（CodeHealth）与AI代码重构的语义保持性正相关，表明人类可读性高的代码也更容易被AI工具处理，这有助于指导AI代码干预的风险评估。


<details>
  <summary>Details</summary>
Motivation: 随着人类开发者与AI编码代理在同一个代码库中协作的混合时代到来，传统上针对人类可读性优化的代码实践需要扩展到确保不同能力的LLM能够可靠地编辑代码。研究旨在探索"AI友好代码"的概念及其与人类可读性代码的关系。

Method: 使用基于LLM的重构方法，在来自竞技编程的5,000个Python文件数据集上进行实验。通过CodeHealth（针对人类理解校准的质量指标）评估代码质量，并测量AI重构后的语义保持性。

Result: 发现CodeHealth与AI重构后的语义保持性之间存在有意义的关联。人类友好的代码也显示出更好的AI工具兼容性，证实了人类可读性代码同样有利于AI处理。

Conclusion: 组织可以使用CodeHealth来指导AI干预的风险评估，确定哪些地方AI干预风险较低，哪些需要额外的人工监督。投资于代码可维护性不仅帮助人类开发者，也为大规模AI采用做好准备。

Abstract: We are entering a hybrid era in which human developers and AI coding agents work in the same codebases. While industry practice has long optimized code for human comprehension, it is increasingly important to ensure that LLMs with different capabilities can edit code reliably. In this study, we investigate the concept of ``AI-friendly code'' via LLM-based refactoring on a dataset of 5,000 Python files from competitive programming. We find a meaningful association between CodeHealth, a quality metric calibrated for human comprehension, and semantic preservation after AI refactoring. Our findings confirm that human-friendly code is also more compatible with AI tooling. These results suggest that organizations can use CodeHealth to guide where AI interventions are lower risk and where additional human oversight is warranted. Investing in maintainability not only helps humans; it also prepares for large-scale AI adoption.

</details>


### [333] [Enhancing Temporal Awareness in LLMs for Temporal Point Processes](https://arxiv.org/abs/2601.00845)
*Lili Chen,Wensheng Gan,Shuang Liang,Philip S. Yu*

Main category: cs.AI

Relevance: 65.0

TL;DR: TPP-TAL是一个新颖的即插即用框架，通过显式对齐时间动态与上下文语义，增强LLMs在时序点过程中的时间推理能力，显著提升了时间似然估计和事件预测精度。


<details>
  <summary>Details</summary>
Motivation: 时序点过程（TPPs）在金融、医疗等领域至关重要，但现有方法难以有效捕捉时间信息与语义上下文之间的复杂交互。尽管LLMs在序列建模中表现出色，但将其应用于时序点过程仍面临挑战，需要增强LLMs的时间感知能力。

Method: TPP-TAL采用即插即用框架，不同于传统的事件时间和类型嵌入简单拼接方法，而是显式对齐时间动态与上下文语义，然后将对齐后的信息输入LLM，使模型能更好地感知事件间的时间依赖性和长程交互。

Result: 在多个基准数据集上的实验表明，TPP-TAL在时间似然估计和事件预测精度方面取得了显著改进，证明了增强LLMs时间感知对于连续时间事件建模的重要性。

Conclusion: TPP-TAL通过显式对齐时间动态与语义上下文，有效增强了LLMs在时序点过程中的时间推理能力，为连续时间事件建模提供了新的解决方案。

Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL

</details>


### [334] [Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models](https://arxiv.org/abs/2601.00848)
*Ron F. Del Rosario*

Main category: cs.AI

Relevance: 65.0

TL;DR: 提出一种基于OpenTelemetry追踪分析的开放方法，用于微调语言模型检测多智能体AI工作流中的时序攻击模式，通过合成数据生成和QLoRA微调显著提升检测准确率。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体AI系统的广泛应用，其工作流中的时序攻击模式检测成为重要安全挑战。现有方法缺乏针对多智能体协调攻击和监管违规的专门检测框架，需要建立可复现的定制化安全模型。

Method: 1) 从18个公共网络安全源和合成OpenTelemetry追踪中构建80,851个示例的数据集；2) 在资源受限的ARM64硬件上应用迭代式QLoRA微调；3) 通过三次训练迭代和策略性数据增强；4) 开发针对多智能体协调攻击和监管违规的合成追踪生成方法。

Result: 自定义基准测试准确率从42.86%提升至74.29%，实现31.4个百分点的显著提升。针对特定知识差距的定向示例优于无差别扩展，证明了训练数据组成对模型行为的决定性影响。

Conclusion: 该研究建立了首个可复现的框架，使从业者能够构建适应其威胁环境的定制化智能体安全模型。虽然实际部署仍需人工监督以处理误报，但为多智能体AI工作流安全检测提供了重要基础。

Abstract: We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. Our custom benchmark accuracy improves from 42.86% to 74.29%, a statistically significant 31.4-point gain. Targeted examples addressing specific knowledge gaps outperform indiscriminate scaling. Key contributions include: (1) synthetic trace generation methodology for multi-agent coordination attacks and regulatory violations, (2) empirical evidence that training data composition fundamentally determines behavior, and (3) complete open release of datasets, training scripts, and evaluation benchmarks on HuggingFace. While practical deployment requires human oversight due to false positive rates, this work establishes the first reproducible framework enabling practitioners to build custom agentic security models adapted to their threat landscapes.

</details>


### [335] [Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies](https://arxiv.org/abs/2601.01301)
*Keith Frankston,Benjamin Howard*

Main category: cs.AI

Relevance: 65.0

TL;DR: 提出递归AlphaZero风格的蒙特卡洛树搜索算法RMCTS，相比传统MCTS-UCB在速度上有显著优势，搜索单根状态时快40倍以上，批量搜索时快3倍，训练时间减少到三分之一。


<details>
  <summary>Details</summary>
Motivation: AlphaZero的MCTS-UCB算法存在GPU延迟成本高的问题，网络推理需要逐节点进行，导致搜索效率低下。需要一种更高效的树搜索算法来加速强化学习训练过程。

Method: 采用递归的广度优先搜索策略，从叶子节点向根节点计算优化的后验策略。使用Grill等人提出的正则化策略优化框架中的后验策略，该策略在给定估计动作奖励和偏离先验策略惩罚的情况下最大化期望奖励。搜索树通过遵循先验网络策略定义而非自适应构建。

Result: 在Connect-4、Dots-and-Boxes和Othello三个游戏中，RMCTS相比MCTS-UCB：搜索单根状态时快40倍以上，批量搜索时快3倍。训练的网络质量相当，但训练时间仅需三分之一。

Conclusion: RMCTS通过递归广度优先搜索和批量网络推理，显著提升了AlphaZero风格算法的效率，在保持网络质量的同时大幅减少训练时间，为强化学习训练提供了更高效的搜索算法。

Abstract: We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, "RMCTS". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster when searching a large batch of root states.
  The recursion in RMCTS is based on computing optimized posterior policies at each game state in the search tree, starting from the leaves and working back up to the root. Here we use the posterior policy explored in "Monte--Carlo tree search as regularized policy optimization" (Grill, et al.) Their posterior policy is the unique policy which maximizes the expected reward given estimated action rewards minus a penalty for diverging from the prior policy.
  The tree explored by RMCTS is not defined in an adaptive manner, as it is in MCTS-UCB. Instead, the RMCTS tree is defined by following prior network policies at each node. This is a disadvantage, but the speedup advantage is more significant, and in practice we find that RMCTS-trained networks match the quality of MCTS-UCB-trained networks in roughly one-third of the training time. We include timing and quality comparisons of RMCTS vs. MCTS-UCB for three games: Connect-4, Dots-and-Boxes, and Othello.

</details>


### [336] [Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification](https://arxiv.org/abs/2601.01378)
*Han Yuan,Yilin Wu,Li Zhang,Zheng Ma*

Main category: cs.AI

Relevance: 65.0

TL;DR: 提出AAAI三阶段流水线（关联识别、自动检测、自适应推理），通过减轻事实幻觉来提升小语言模型在金融分类任务中的性能


<details>
  <summary>Details</summary>
Motivation: 小语言模型在金融分类中因推理速度快和本地可部署性而被广泛使用，但与大型语言模型相比，它们更容易产生事实幻觉且分类性能较弱。研究旨在探索减轻事实幻觉是否能提升小语言模型的金融分类能力。

Method: 提出AAAI三阶段流水线：1) 关联识别 - 识别事实幻觉与错误分类之间的关联；2) 自动检测 - 使用基于编码器的验证器检测事实幻觉；3) 自适应推理 - 结合事实错误反馈，使小语言模型能够自适应推理以提升分类性能。

Result: 在三个代表性小语言模型上的实验表明：1) 事实幻觉与错误分类呈正相关；2) 基于编码器的验证器能有效检测事实幻觉；3) 结合事实错误反馈的自适应推理能显著提升分类性能。

Conclusion: AAAI流水线通过减轻事实幻觉有效提升了小语言模型在金融分类中的性能，为小语言模型在金融领域的可信赖和有效应用提供了解决方案。

Abstract: Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.

</details>


### [337] [PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor](https://arxiv.org/abs/2601.01802)
*Qianjun Pan,Junyi Wang,Jie Zhou,Yutao Yang,Junsong Li,Kaiyin Xu,Yougen Zhou,Yihan Li,Jingyuan Zhao,Qin Chen,Ningning Zhou,Kai Chen,Liang He*

Main category: cs.AI

Relevance: 65.0

TL;DR: PsychEval是一个用于心理评估AI的多会话、多疗法、高真实性的基准测试，旨在解决AI咨询师的训练、多疗法适应性和系统性评估三大挑战。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的心理评估AI面临三个关键挑战：1) 如何训练高度真实的AI咨询师（需要长期记忆和动态目标跟踪）；2) 如何训练多疗法AI咨询师（复杂案例需要灵活切换不同疗法）；3) 如何系统性评估AI咨询师。现有模型通常只关注单一疗法，缺乏多会话、多疗法的综合基准。

Method: 1) 构建多会话基准（6-10个会话，分三个阶段），包含677个元技能和4577个原子技能的专业标注；2) 创建涵盖五种治疗模式（心理动力学、行为主义、CBT、人本存在主义、后现代主义）和整合疗法的多样化数据集；3) 建立包含18个治疗特定和共享指标的全面评估框架，涵盖客户级和咨询师级维度，并构建2000多个多样化客户档案。

Result: 实验分析充分验证了数据集的质量和临床保真度。PsychEval超越了静态基准测试，可作为高保真度的强化学习环境，支持临床负责且适应性强的AI咨询师的自我进化训练。

Conclusion: PsychEval为AI心理评估提供了一个全面、真实、多疗法的基准测试环境，不仅支持评估，还能作为强化学习环境促进AI咨询师的自我进化训练，对开发临床可靠的AI咨询师具有重要意义。

Abstract: To develop a reliable AI for psychological assessment, we introduce \texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.

</details>


### [338] [Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01844)
*Udiptaman Das,Krishnasai B. Atmakuri,Duy Ho,Chi Lee,Yugyung Lee*

Main category: cs.AI

Relevance: 65.0

TL;DR: 提出一个端到端框架，使用多智能体提示和模式约束的检索增强生成(KG-RAG)策略，直接从自由文本构建临床知识图谱，特别针对肿瘤学领域。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖结构化输入，缺乏对事实准确性和语义一致性的鲁棒验证，这在肿瘤学领域尤其成问题。需要直接从非结构化临床叙述构建知识图谱的解决方案。

Method: 集成四个关键组件：1) 提示驱动的实体、属性和关系提取；2) 基于熵的不确定性评分；3) 本体对齐的RDF/OWL模式生成；4) 多LLM共识验证用于幻觉检测和语义细化。采用模式约束的检索增强生成(KG-RAG)策略。

Result: 在两个肿瘤学队列(PDAC和BRCA)上应用，该方法在不依赖黄金标准标注的情况下，产生了可解释、SPARQL兼容且临床基础的知识图谱。实验结果显示在精确度、相关性和本体合规性方面相对于基线方法有持续提升。

Conclusion: 该框架为从非结构化临床文本构建高质量知识图谱提供了有效的端到端解决方案，支持持续细化和自监督评估，能够迭代改进图谱质量。

Abstract: Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.

</details>


### [339] [MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning](https://arxiv.org/abs/2601.01910)
*Minh Hieu Ha,Khanh Ly Ta,Hung Phan,Tung Doan,Tung Dao,Dao Tran,Huynh Thi Thanh Binh*

Main category: cs.AI

Relevance: 65.0

TL;DR: MMP-A*是一个多模态路径规划框架，结合视觉语言模型的空间定位能力和自适应衰减机制，在复杂环境中实现接近最优的轨迹规划，同时显著降低计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 自主路径规划需要全局推理和几何精度的结合。传统A*算法在大规模场景中计算和内存成本过高，而基于纯文本推理的LLM方法缺乏空间定位能力，在拓扑复杂环境中容易产生错误路径点。

Method: 提出MMP-A*多模态框架：1) 集成视觉语言模型的空间定位能力，将高层推理锚定在物理几何中；2) 引入自适应衰减机制，动态调节不确定路径点在启发式函数中的影响，确保几何有效性并减少内存开销。

Result: 在具有严重杂乱和拓扑复杂性的挑战性环境中测试，MMP-A*实现了接近最优的轨迹规划，同时显著降低了操作成本。

Conclusion: MMP-A*为自主导航提供了一个感知接地且计算高效的范式，通过多模态集成解决了纯文本规划器的局限性。

Abstract: Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.
  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.

</details>


### [340] [XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging](https://arxiv.org/abs/2601.02008)
*Midhat Urooj,Ayan Banerjee,Sandeep Gupta*

Main category: cs.AI

Relevance: 65.0

TL;DR: XAIMeD是一个可解释的医疗AI框架，通过神经符号架构整合临床专家知识，提高分布偏移下的鲁棒性、罕见类别敏感性和临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI中可解释性、领域泛化和罕见类别可靠性是关键挑战，深度学习模型在真实世界分布偏移下经常失败，并对罕见临床条件表现出偏见。

Method: 将临床专业知识编码为原子医学命题的逻辑连接，转化为机器可检查的类别特定规则；通过加权特征满足分数量化诊断效用；符号推理分支与神经预测互补；置信度加权融合整合符号和深度输出；基于熵不平衡增益和罕见类别基尼系数的自适应路由机制。

Result: 在四个挑战性任务上评估：癫痫发作区定位和糖尿病视网膜病变分级，在跨领域泛化上获得6%提升，罕见类别F1分数提升10%，显著优于最先进的深度学习基线。

Conclusion: XAIMeD提供了一个原则性、临床忠实且可解释的多模态医疗AI方法，临床基础的符号组件作为有效正则化器确保分布偏移下的鲁棒性。

Abstract: Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.

</details>


### [341] [FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations](https://arxiv.org/abs/2601.02071)
*Adeshola Okubena,Yusuf Ali Mohammed,Moe Elbadawi*

Main category: cs.AI

Relevance: 65.0

TL;DR: 该研究探索了使用LLMs（特别是Llama2）在药物3D打印中推荐辅料和预测材料机械性能，发现即使在小数据集上微调也会出现灾难性遗忘，且标准LLM评估指标无法反映制剂工艺性。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动的药物3D打印研究大多局限于狭窄领域，未能解决制剂开发中的广泛挑战。随着AGI概念的发展，需要探索LLMs在药物制剂开发中的应用潜力，超越传统预测模型，实现更通用、类人的推理能力。

Method: 使用包含1400多种制剂的FDM数据集微调四种LLM架构，系统评估微调和生成参数配置。研究重点关注LLMs在推荐辅料（基于API剂量）和预测长丝机械性能方面的应用。

Result: Llama2在推荐FDM制剂辅料方面表现最佳。模型选择和参数化显著影响性能，较小的LLMs出现灾难性遗忘现象。研究发现：1）即使1400+的数据集也会导致灾难性遗忘；2）标准LLM指标仅评估语言性能而非制剂工艺性；3）基于生物医学数据训练的LLMs不一定产生最佳结果。

Conclusion: 解决这些挑战对于推进LLMs超越语言能力、成为药物制剂开发的可靠系统至关重要。需要开发更全面的评估框架来评估LLMs在实际制剂开发中的实用性。

Abstract: Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.

</details>


### [342] [Can Large Language Models Improve Venture Capital Exit Timing After IPO?](https://arxiv.org/abs/2601.00810)
*Mohammadhossien Rashidi*

Main category: q-fin.PM

Relevance: 65.0

TL;DR: 该研究提出一个使用大语言模型分析IPO后信息来优化风险投资退出时机的框架，通过对比LLM推荐与实际退出策略的收益差异，评估AI指导能否改善退出决策。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要描述风险投资何时退出，而非评估这些选择是否经济最优。同时，大语言模型在合成复杂金融数据和文本信息方面显示潜力，但尚未应用于IPO后退出决策。

Method: 引入一个使用LLM分析月度IPO后信息（财务表现、文件、新闻、市场信号）来估计最优退出时机的框架，推荐卖出或继续持有，并与实际VC退出日期对比计算收益差异。

Result: 通过量化遵循LLM建议的收益或损失，为AI驱动指导能否改善退出时机提供证据，并补充传统风险投资研究中的风险模型和实物期权模型。

Conclusion: LLM在优化风险投资退出时机方面具有应用潜力，能够为传统金融分析方法提供补充，但需要进一步验证其实际效果。

Abstract: Exit timing after an IPO is one of the most consequential decisions for venture capital (VC) investors, yet existing research focuses mainly on describing when VCs exit rather than evaluating whether those choices are economically optimal. Meanwhile, large language models (LLMs) have shown promise in synthesizing complex financial data and textual information but have not been applied to post-IPO exit decisions. This study introduces a framework that uses LLMs to estimate the optimal time for VC exit by analyzing monthly post IPO information financial performance, filings, news, and market signals and recommending whether to sell or continue holding. We compare these LLM generated recommendations with the actual exit dates observed for VCs and compute the return differences between the two strategies. By quantifying gains or losses associated with following the LLM, this study provides evidence on whether AI-driven guidance can improve exit timing and complements traditional hazard and real-options models in venture capital research.

</details>


### [343] [A Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System for Advertisement Retrieval and Personalization](https://arxiv.org/abs/2601.00833)
*Tangtang Wang,Kaijie Zhang,Kuangcong Liu*

Main category: cs.IR

Relevance: 65.0

TL;DR: 提出KGSR-ADS系统，结合知识图谱和深度学习进行广告语义推荐，利用LLM生成语义嵌入，通过GNN+注意力模型学习跨实体依赖，基于向量索引实现高效检索。


<details>
  <summary>Details</summary>
Motivation: 现代数字营销中广告数据日益复杂，需要能够理解产品、受众和广告内容之间语义关系的智能系统，以解决广告检索和个性化推荐中的语义理解挑战。

Method: 提出分层架构：1) 异构广告知识图谱捕获多关系语义；2) 语义嵌入层使用GPT/LLaMA等LLM生成上下文感知向量表示；3) GNN+注意力模型推断跨实体依赖；4) 基于FAISS/Milvus的向量索引数据库优化与检索层。

Result: 实现了准确的语义匹配和可扩展的检索能力，能够在大规模异构工作负载下进行个性化广告推荐，系统能够理解复杂的语义关系并高效检索。

Conclusion: KGSR-ADS系统通过整合知识图谱、LLM语义嵌入和GNN注意力机制，为广告检索和个性化推荐提供了有效的解决方案，能够处理复杂的语义关系并实现高效检索。

Abstract: In modern digital marketing, the growing complexity of advertisement data demands intelligent systems capable of understanding semantic relationships among products, audiences, and advertising content. To address this challenge, this paper proposes a Knowledge Graph and Deep Learning-Based Semantic Recommendation Database System (KGSR-ADS) for advertisement retrieval and personalization. The proposed framework integrates a heterogeneous Ad-Knowledge Graph (Ad-KG) that captures multi-relational semantics, a Semantic Embedding Layer that leverages large language models (LLMs) such as GPT and LLaMA to generate context-aware vector representations, a GNN + Attention Model that infers cross-entity dependencies, and a Database Optimization & Retrieval Layer based on vector indexing (FAISS/Milvus) for efficient semantic search. This layered architecture enables both accurate semantic matching and scalable retrieval, allowing personalized ad recommendations under large-scale heterogeneous workloads.

</details>


### [344] [Measuring Social Media Polarization Using Large Language Models and Heuristic Rules](https://arxiv.org/abs/2601.00927)
*Jawad Chowdhury,Rezaur Rashid,Gabriel Terejanu*

Main category: cs.SI

Relevance: 65.0

TL;DR: 该论文提出了一种利用大语言模型和领域启发式规则来量化社交媒体讨论中情感极化的新框架，能够分析气候变化和枪支管制等争议话题中的立场、情感语气和互动模式。


<details>
  <summary>Details</summary>
Motivation: 理解在线讨论中的情感极化对于评估社交媒体互动的社会影响至关重要。现有方法主要依赖情感分析或预定义分类器，缺乏对立场、情感内容和互动动态的系统性整合分析。

Method: 结合大语言模型提取立场、情感语气和同意模式，然后应用基于规则的评分系统量化情感极化，该系统基于立场对齐、情感内容和互动动态，能够处理小型对话甚至单次互动。

Result: 分析揭示了事件依赖的极化模式：1) 预期驱动极化——在公开事件前极端极化升级；2) 反应性极化——突发高影响事件后情感极化急剧上升。

Conclusion: 通过结合AI驱动的内容标注和领域知识评分，该框架提供了可扩展且可解释的情感极化测量方法，为理解社交媒体讨论的社会影响提供了新工具。

Abstract: Understanding affective polarization in online discourse is crucial for evaluating the societal impact of social media interactions. This study presents a novel framework that leverages large language models (LLMs) and domain-informed heuristics to systematically analyze and quantify affective polarization in discussions on divisive topics such as climate change and gun control. Unlike most prior approaches that relied on sentiment analysis or predefined classifiers, our method integrates LLMs to extract stance, affective tone, and agreement patterns from large-scale social media discussions. We then apply a rule-based scoring system capable of quantifying affective polarization even in small conversations consisting of single interactions, based on stance alignment, emotional content, and interaction dynamics. Our analysis reveals distinct polarization patterns that are event dependent: (i) anticipation-driven polarization, where extreme polarization escalates before well-publicized events, and (ii) reactive polarization, where intense affective polarization spikes immediately after sudden, high-impact events. By combining AI-driven content annotation with domain-informed scoring, our framework offers a scalable and interpretable approach to measuring affective polarization. The source code is publicly available at: https://github.com/hasanjawad001/llm-social-media-polarization.

</details>


### [345] [MACA: A Framework for Distilling Trustworthy LLMs into Efficient Retrievers](https://arxiv.org/abs/2601.00926)
*Satya Swaroop Gudipudi,Sahil Girhepuje,Ponnurangam Kumaraguru,Kristine Ma*

Main category: cs.IR

Relevance: 65.0

TL;DR: MACA是一种元数据感知的跨模型对齐方法，将经过校准的LLM重排序器蒸馏到紧凑的学生检索器中，避免在线LLM调用，提升企业检索系统性能。


<details>
  <summary>Details</summary>
Motivation: 企业检索系统需要处理简短、不明确的查询，但传统的LLM重排序和手动标注成本高昂。需要一种既能利用语义细微差别和元数据，又无需在线LLM调用的高效检索解决方案。

Method: 提出Metadata-Aware Cross-Model Alignment (MACA)：1) 使用元数据感知提示验证教师LLM的可信度，检查排列一致性和对改写的鲁棒性；2) 提供列表式分数、硬负样本和校准的相关性边界；3) 学生模型通过MetaFusion目标训练，结合元数据条件排序损失和跨模型边界损失。

Result: 在专有消费者银行FAQ语料库和BankFAQs上：MACA教师比MAFA基线在Accuracy@1上分别提升5点和3点；MACA学生显著优于预训练编码器，如MiniLM在专有语料库上的Accuracy@1从0.23提升到0.48，同时保持无LLM调用的推理。

Conclusion: MACA成功将元数据感知的LLM重排序器蒸馏到紧凑检索器中，显著提升检索性能，同时避免了在线LLM调用的成本，支持检索增强生成。

Abstract: Modern enterprise retrieval systems must handle short, underspecified queries such as ``foreign transaction fee refund'' and ``recent check status''. In these cases, semantic nuance and metadata matter but per-query large language model (LLM) re-ranking and manual labeling are costly. We present Metadata-Aware Cross-Model Alignment (MACA), which distills a calibrated metadata aware LLM re-ranker into a compact student retriever, avoiding online LLM calls. A metadata-aware prompt verifies the teacher's trustworthiness by checking consistency under permutations and robustness to paraphrases, then supplies listwise scores, hard negatives, and calibrated relevance margins. The student trains with MACA's MetaFusion objective, which combines a metadata conditioned ranking loss with a cross model margin loss so it learns to push the correct answer above semantically similar candidates with mismatched topic, sub-topic, or entity. On a proprietary consumer banking FAQ corpus and BankFAQs, the MACA teacher surpasses a MAFA baseline at Accuracy@1 by five points on the proprietary set and three points on BankFAQs. MACA students substantially outperform pretrained encoders; e.g., on the proprietary corpus MiniLM Accuracy@1 improves from 0.23 to 0.48, while keeping inference free of LLM calls and supporting retrieval-augmented generation.

</details>


### [346] [VEAT Quantifies Implicit Associations in Text-to-Video Generator Sora and Reveals Challenges in Bias Mitigation](https://arxiv.org/abs/2601.00996)
*Yongxu Sun,Michael Saxon,Ian Yang,Anna-Maria Gueorguieva,Aylin Caliskan*

Main category: cs.CY

Relevance: 65.0

TL;DR: 论文提出视频嵌入关联测试(VEAT)和单类别VEAT(SC-VEAT)方法，用于评估Sora等文本到视频生成器中的社会偏见，发现Sora视频将欧洲裔美国人和女性与愉悦性关联更强，且效应大小与现实世界人口分布高度相关。


<details>
  <summary>Details</summary>
Motivation: 随着Sora等文本到视频生成器的出现，需要评估生成内容是否反映社会偏见。现有偏见评估方法主要针对文本和图像，缺乏对视频内容的系统评估方法。

Method: 扩展嵌入关联测试到视频领域，提出VEAT和SC-VEAT方法。通过复现IAT场景和OASIS图像类别的关联方向和强度来验证方法。然后量化Sora视频中种族(非裔vs欧裔美国人)和性别(女性vs男性)与愉悦性(愉快vs不愉快)在17种职业和7种奖项中的关联。

Result: Sora视频将欧洲裔美国人和女性与愉悦性关联更强(效应大小d>0.8)。效应大小与现实世界人口分布高度相关：职业中男性比例和白人比例(r=0.93, r=0.83)，奖项中男性比例和非黑人比例(r=0.88, r=0.99)。显式去偏提示通常减少效应大小，但可能适得其反：两个黑人关联职业(清洁工、邮政服务)在去偏后关联更强。

Conclusion: 易获取的文本到视频生成器如果不经过严格评估和负责任部署，实际上可能放大代表性伤害。需要系统评估和负责任部署来减轻这些风险。

Abstract: Text-to-Video (T2V) generators such as Sora raise concerns about whether generated content reflects societal bias. We extend embedding-association tests from words and images to video by introducing the Video Embedding Association Test (VEAT) and Single-Category VEAT (SC-VEAT). We validate these methods by reproducing the direction and magnitude of associations from widely used baselines, including Implicit Association Test (IAT) scenarios and OASIS image categories. We then quantify race (African American vs. European American) and gender (women vs. men) associations with valence (pleasant vs. unpleasant) across 17 occupations and 7 awards. Sora videos associate European Americans and women more with pleasantness (both d>0.8). Effect sizes correlate with real-world demographic distributions: percent men and White in occupations (r=0.93, r=0.83) and percent male and non-Black among award recipients (r=0.88, r=0.99). Applying explicit debiasing prompts generally reduces effect-size magnitudes, but can backfire: two Black-associated occupations (janitor, postal service) become more Black-associated after debiasing. Together, these results reveal that easily accessible T2V generators can actually amplify representational harms if not rigorously evaluated and responsibly deployed.

</details>


### [347] [A neural network for modeling human concept formation, understanding and communication](https://arxiv.org/abs/2601.02010)
*Liangxuan Guo,Haoyang Chen,Yang Chen,Yanchao Bi,Shan Yu*

Main category: q-bio.NC

Relevance: 65.0

TL;DR: 提出CATS Net双模块神经网络框架，通过概念抽象模块提取低维概念表示，任务解决模块在概念层次门控下执行视觉判断任务，实现可迁移的语义结构，模型与人类大脑语义处理机制对齐。


<details>
  <summary>Details</summary>
Motivation: 人类大脑能从感觉运动经验中形成抽象概念表示并灵活应用，但这一能力的计算机制尚不清楚。研究旨在填补这一空白，建立统一的计算框架来理解人类概念认知，并设计具有类人概念智能的人工系统。

Method: 提出CATS Net双模块框架：1) 概念抽象模块提取低维概念表示；2) 任务解决模块在形成的概念层次门控下执行视觉判断任务。系统基于概念表示发展可迁移的语义结构，实现跨网络知识转移。通过模型-大脑拟合分析验证。

Result: 模型产生的概念空间与人类腹侧枕颞叶皮层的神经认知语义模型和大脑响应结构对齐，门控机制与语义控制脑网络机制相似。系统能够实现跨网络的概念通信和知识转移。

Conclusion: CATS Net建立了统一的计算框架，为理解人类概念认知提供机制性见解，并为设计具有类人概念智能的人工系统提供工程基础。

Abstract: A remarkable capability of the human brain is to form more abstract conceptual representations from sensorimotor experiences and flexibly apply them independent of direct sensory inputs. However, the computational mechanism underlying this ability remains poorly understood. Here, we present a dual-module neural network framework, the CATS Net, to bridge this gap. Our model consists of a concept-abstraction module that extracts low-dimensional conceptual representations, and a task-solving module that performs visual judgement tasks under the hierarchical gating control of the formed concepts. The system develops transferable semantic structure based on concept representations that enable cross-network knowledge transfer through conceptual communication. Model-brain fitting analyses reveal that these emergent concept spaces align with both neurocognitive semantic model and brain response structures in the human ventral occipitotemporal cortex, while the gating mechanisms mirror that in the semantic control brain network. This work establishes a unified computational framework that can offer mechanistic insights for understanding human conceptual cognition and engineering artificial systems with human-like conceptual intelligence.

</details>


### [348] [SoulSeek: Exploring the Use of Social Cues in LLM-based Information Seeking](https://arxiv.org/abs/2601.01094)
*Yubo Shu,Peng Zhang,Meng Wu,Yan Chen,Haoxuan Zhou,Guanming Liu,Yu Zhang,Liuxin Zhang,Qianying Wang,Tun Lu,Ning Gu*

Main category: cs.HC

Relevance: 65.0

TL;DR: 该研究探讨在LLM搜索系统中整合社交线索如何影响用户感知、体验和行为，通过设计工作坊、原型系统开发和用户研究发现社交线索能改善感知结果、促进反思性信息行为


<details>
  <summary>Details</summary>
Motivation: 现有LLM搜索系统主要依赖语义特征，与人类自然信息寻求中的社会化认知存在错位。社交线索（传达他人存在、行为或身份）在人类判断相关性和可信度中起关键作用，但当前LLM搜索系统缺乏这方面的整合

Method: 采用混合方法：1) 设计工作坊指导原型设计；2) 开发原型系统SoulSeek；3) 组间实验研究；4) 混合方法分析，考察结果层面和过程层面的发现

Result: 社交线索能改善感知结果和用户体验，促进反思性信息行为，同时揭示了当前LLM搜索系统的局限性。工作坊为原型设计提供了指导

Conclusion: 提出设计启示：需要更好的社交知识理解、个性化线索设置和可控交互。社交线索的整合对LLM搜索系统有重要价值

Abstract: Social cues, which convey others' presence, behaviors, or identities, play a crucial role in human information seeking by helping individuals judge relevance and trustworthiness. However, existing LLM-based search systems primarily rely on semantic features, creating a misalignment with the socialized cognition underlying natural information seeking. To address this gap, we explore how the integration of social cues into LLM-based search influences users' perceptions, experiences, and behaviors. Focusing on social media platforms that are beginning to adopt LLM-based search, we integrate design workshops, the implementation of the prototype system (SoulSeek), a between-subjects study, and mixed-method analyses to examine both outcome- and process-level findings. The workshop informs the prototype's cue-integrated design. The study shows that social cues improve perceived outcomes and experiences, promote reflective information behaviors, and reveal limits of current LLM-based search. We propose design implications emphasizing better social-knowledge understanding, personalized cue settings, and controllable interactions.

</details>


### [349] [MOSS Transcribe Diarize: Accurate Transcription with Speaker Diarization](https://arxiv.org/abs/2601.01554)
*Donghua Yu,Zhengyuan Lin,Chen Yang,Yiyang Zhang,Zhaoye Fei,Hanfu Chen,Jingqi Chen,Ke Chen,Qinyuan Cheng,Liwei Fan,Yi Jiang,Jie Zhu,Muchen Li,Shimin Li,Wenxuan Wang,Yang Wang,Zhe Xu,Yitian Gong,Yuqian Zhang*

Main category: cs.SD

Relevance: 65.0

TL;DR: MOSS Transcribe Diarize是一个统一的多模态大语言模型，用于端到端执行说话人归属、时间戳转录任务，在多个基准测试中优于最先进的商业系统。


<details>
  <summary>Details</summary>
Motivation: 现有SATS系统很少采用端到端框架，且受限于有限的上下文窗口、弱的长距离说话人记忆能力以及无法输出时间戳。需要解决这些限制来改进会议转录质量。

Method: 提出MOSS Transcribe Diarize，这是一个统一的多模态大语言模型，采用端到端范式联合执行说话人归属和时间戳转录。模型在大量真实数据上训练，具有128k上下文窗口，可处理长达90分钟的输入。

Result: 在全面的评估中，MOSS Transcribe Diarize在多个公共和内部基准测试中优于最先进的商业系统，展现出良好的扩展性和鲁棒泛化能力。

Conclusion: 该工作展示了端到端多模态大语言模型在说话人归属时间戳转录任务上的有效性，解决了现有系统的关键限制，并在实际应用中表现出优越性能。

Abstract: Speaker-Attributed, Time-Stamped Transcription (SATS) aims to transcribe what is said and to precisely determine the timing of each speaker, which is particularly valuable for meeting transcription. Existing SATS systems rarely adopt an end-to-end formulation and are further constrained by limited context windows, weak long-range speaker memory, and the inability to output timestamps. To address these limitations, we present MOSS Transcribe Diarize, a unified multimodal large language model that jointly performs Speaker-Attributed, Time-Stamped Transcription in an end-to-end paradigm. Trained on extensive real wild data and equipped with a 128k context window for up to 90-minute inputs, MOSS Transcribe Diarize scales well and generalizes robustly. Across comprehensive evaluations, it outperforms state-of-the-art commercial systems on multiple public and in-house benchmarks.

</details>


### [350] [LIA: Supervised Fine-Tuning of Large Language Models for Automatic Issue Assignment](https://arxiv.org/abs/2601.01780)
*Arsham Khosravani,Alireza Hosseinpour,Arshia Akhavan,Mehdi Keshani,Abbas Heydarnoori*

Main category: cs.SE

Relevance: 65.0

TL;DR: LIA使用监督微调将LLM（DeepSeek-R1-Distill-Llama-8B）适配于软件维护中的问题分配任务，通过历史问题-开发者分配模式学习生成开发者推荐排名，显著优于基模型和现有方法。


<details>
  <summary>Details</summary>
Motivation: 软件维护中的问题分配过程通常手动进行，存在不一致性和错误，特别是在大型开源项目中。现有自动化方法依赖大量项目特定训练数据或稀疏嘈杂的关系信息，效果有限。

Method: 提出LIA（LLM-based Issue Assignment），通过监督微调将DeepSeek-R1-Distill-Llama-8B适配于问题分配任务。利用LLM对自然语言和软件相关文本的预训练语义理解，直接从问题标题和描述学习生成开发者推荐排名，基于历史分配模式推断最可能处理新问题的开发者。

Result: LIA相比基模型在Hit@1指标上提升高达+187.8%，相比四种领先问题分配方法提升高达+211.2%。证明了领域适配LLM在软件维护任务中的有效性。

Conclusion: LIA为问题分配提供了实用高效解决方案，展示了领域适配LLM在软件维护任务中的潜力，特别是在数据稀疏场景下。

Abstract: Issue assignment is a critical process in software maintenance, where new issue reports are validated and assigned to suitable developers. However, manual issue assignment is often inconsistent and error-prone, especially in large open-source projects where thousands of new issues are reported monthly. Existing automated approaches have shown promise, but many rely heavily on large volumes of project-specific training data or relational information that is often sparse and noisy, which limits their effectiveness. To address these challenges, we propose LIA (LLM-based Issue Assignment), which employs supervised fine-tuning to adapt an LLM, DeepSeek-R1-Distill-Llama-8B in this work, for automatic issue assignment. By leveraging the LLM's pretrained semantic understanding of natural language and software-related text, LIA learns to generate ranked developer recommendations directly from issue titles and descriptions. The ranking is based on the model's learned understanding of historical issue-to-developer assignments, using patterns from past tasks to infer which developers are most likely to handle new issues. Through comprehensive evaluation, we show that LIA delivers substantial improvements over both its base pretrained model and state-of-the-art baselines. It achieves up to +187.8% higher Hit@1 compared to the DeepSeek-R1-Distill-Llama-8B pretrained base model, and outperforms four leading issue assignment methods by as much as +211.2% in Hit@1 score. These results highlight the effectiveness of domain-adapted LLMs for software maintenance tasks and establish LIA as a practical, high-performing solution for issue assignment.

</details>


### [351] [ARIES: A Scalable Multi-Agent Orchestration Framework for Real-Time Epidemiological Surveillance and Outbreak Monitoring](https://arxiv.org/abs/2601.01831)
*Aniket Wattamwar,Sampson Akwafuo*

Main category: cs.MA

Relevance: 65.0

TL;DR: ARIES是一个专门用于流行病监测的自主多智能体框架，通过分层命令结构协调GPT智能体群，自动查询WHO、CDC和学术文献，实现实时威胁检测和信号分析。


<details>
  <summary>Details</summary>
Motivation: 当前全球健康监测面临知识鸿沟问题，通用AI在流行病学领域存在幻觉问题和无法处理专业数据孤岛的局限性，需要专门的高风险领域解决方案。

Method: 采用分层命令结构的多智能体框架，使用GPT协调可扩展的子智能体群，自动查询WHO、CDC和同行评审研究论文，实现监测数据的自动化提取和逻辑合成。

Result: ARIES能够提供专门的推理能力，近乎实时地识别新兴威胁和信号分歧，证明任务特定的智能体群可以超越通用模型。

Conclusion: 模块化架构为下一代疫情应对和全球健康情报提供了稳健、可扩展的解决方案，展示了专业智能体框架在高风险领域的优势。

Abstract: Global health surveillance is currently facing a challenge of Knowledge Gaps. While general-purpose AI has proliferated, it remains fundamentally unsuited for the high-stakes epidemiological domain due to chronic hallucinations and an inability to navigate specialized data silos. This paper introduces ARIES (Agentic Retrieval Intelligence for Epidemiological Surveillance), a specialized, autonomous multi-agent framework designed to move beyond static, disease-specific dashboards toward a dynamic intelligence ecosystem. Built on a hierarchical command structure, ARIES utilizes GPTs to orchestrate a scalable swarm of sub-agents capable of autonomously querying World Health Organization (WHO), Center for Disease Control and Prevention (CDC), and peer-reviewed research papers. By automating the extraction and logical synthesis of surveillance data, ARIES provides a specialized reasoning that identifies emergent threats and signal divergence in near real-time. This modular architecture proves that a task-specific agentic swarm can outperform generic models, offering a robust, extensible for next-generation outbreak response and global health intelligence.

</details>


### [352] [Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks](https://arxiv.org/abs/2601.00856)
*Milos Stankovic,Ella Hirche,Sarah Kollatzsch,Julia Nadine Doetsch*

Main category: cs.AI

Relevance: 45.0

TL;DR: 这是一篇对Kosmyna等人(2025)研究的评论文章，指出该研究在样本量、可重复性、EEG分析方法、结果报告一致性和透明度方面存在问题，建议更保守地解释结果。


<details>
  <summary>Details</summary>
Motivation: 对Kosmyna等人关于AI助手对写作任务认知影响的研究进行建设性评论，指出方法学问题，帮助改进该研究以适合同行评审发表。

Method: 通过批判性分析原研究的实验设计、样本量、EEG分析方法、结果报告和透明度等方面，提出具体改进建议。

Result: 识别出原研究在五个主要方面的局限性：1) 样本量有限；2) 分析可重复性问题；3) EEG分析方法问题；4) 结果报告不一致；5) 研究过程和发现透明度不足。

Conclusion: 建议对Kosmyna等人的研究结果进行更保守的解释，并提供了具体的改进建议，以增强研究的科学严谨性和可重复性。

Abstract: Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.

</details>


### [353] [A Modular Reference Architecture for MCP-Servers Enabling Agentic BIM Interaction](https://arxiv.org/abs/2601.00809)
*Tobias Heimig-Elschner,Changyu Du,Anna Scheuvens,André Borrmann,Jakob Beetz*

Main category: cs.OH

Relevance: 45.0

TL;DR: 本文提出了一种用于BIM（建筑信息模型）中MCP（模型上下文协议）服务器的模块化参考架构，通过解耦MCP接口与特定BIM-API，实现了API无关、隔离且可复现的智能体交互。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体工作流在BIM领域应用日益增多，MCP作为统一工具调用接口简化了LLM与BIM的交互。然而，现有的BIM侧实现仍然是特定工具和临时的，限制了跨环境的复用性、评估和工作流可移植性。

Method: 通过对近期文献中重复出现的能力进行系统分析，提取核心需求集。设计以显式适配器契约为中心的微服务架构，将MCP接口与特定BIM-API解耦。使用IfcOpenShell实现原型系统。

Result: 原型实现展示了在常见修改和生成任务中的可行性。在代表性场景下的评估表明，该架构能够实现可靠的工作流，减少耦合，并为系统研究提供可复用的基础。

Conclusion: 提出的模块化MCP服务器架构解决了当前BIM智能体交互中的标准化和可复用性问题，为系统研究和跨环境工作流提供了坚实基础。

Abstract: Agentic workflows driven by large language models (LLMs) are increasingly applied to Building Information Modelling (BIM), enabling natural-language retrieval, modification and generation of IFC models. Recent work has begun adopting the emerging Model Context Protocol (MCP) as a uniform tool-calling interface for LLMs, simplifying the agent side of BIM interaction. While MCP standardises how LLMs invoke tools, current BIM-side implementations are still authoring tool-specific and ad hoc, limiting reuse, evaluation, and workflow portability across environments. This paper addresses this gap by introducing a modular reference architecture for MCP servers that enables API-agnostic, isolated and reproducible agentic BIM interactions. From a systematic analysis of recurring capabilities in recent literature, we derive a core set of requirements. These inform a microservice architecture centred on an explicit adapter contract that decouples the MCP interface from specific BIM-APIs. A prototype implementation using IfcOpenShell demonstrates feasibility across common modification and generation tasks. Evaluation across representative scenarios shows that the architecture enables reliable workflows, reduces coupling, and provides a reusable foundation for systematic research.

</details>


### [354] [Device-Native Autonomous Agents for Privacy-Preserving Negotiations](https://arxiv.org/abs/2601.00911)
*Joyjit Roy*

Main category: cs.CR

Relevance: 45.0

TL;DR: 提出设备原生AI代理系统，用于隐私保护的自动谈判，在用户硬件上运行，结合零知识证明和蒸馏世界模型，实现实时谈判而不暴露敏感数据。


<details>
  <summary>Details</summary>
Motivation: 当前保险和B2B商务中的自动谈判系统存在隐私与便利的权衡问题，需要将敏感财务数据路由到集中式服务器，增加了安全风险并降低了用户信任。

Method: 提出设备原生自主AI代理系统，完全在用户硬件上运行，集成零知识证明确保隐私，使用蒸馏世界模型支持高级设备端推理，包含六个技术组件的代理AI工作流。

Result: 在保险和B2B采购场景中评估，平均成功率87%，延迟比云端基线提高2.4倍，通过零知识证明实现强隐私保护，用户研究显示决策轨迹可用时信任度提高27%。

Conclusion: 为隐私敏感金融领域中的可信自主代理奠定了基础，展示了设备端AI在保护隐私的同时实现高效自动谈判的可行性。

Abstract: Automated negotiations in insurance and business-to-business (B2B) commerce encounter substantial challenges. Current systems force a trade-off between convenience and privacy by routing sensitive financial data through centralized servers, increasing security risks, and diminishing user trust. This study introduces a device-native autonomous Artificial Intelligence (AI) agent system for privacy-preserving negotiations. The proposed system operates exclusively on user hardware, enabling real-time bargaining while maintaining sensitive constraints locally. It integrates zero-knowledge proofs to ensure privacy and employs distilled world models to support advanced on-device reasoning. The architecture incorporates six technical components within an agentic AI workflow. Agents autonomously plan negotiation strategies, conduct secure multi-party bargaining, and generate cryptographic audit trails without exposing user data to external servers. The system is evaluated in insurance and B2B procurement scenarios across diverse device configurations. Results show an average success rate of 87%, a 2.4x latency improvement over cloud baselines, and strong privacy preservation through zero-knowledge proofs. User studies show 27% higher trust scores when decision trails are available. These findings establish a foundation for trustworthy autonomous agents in privacy-sensitive financial domains.

</details>


### [355] [An Explainable Agentic AI Framework for Uncertainty-Aware and Abstention-Enabled Acute Ischemic Stroke Imaging Decisions](https://arxiv.org/abs/2601.01008)
*Md Rashadul Islam*

Main category: eess.IV

Relevance: 45.0

TL;DR: 提出一个可解释的代理AI框架，用于急性缺血性卒中影像中的不确定性感知和弃权决策支持，通过模块化代理管道实现病灶感知分析、不确定性估计和基于阈值的弃权决策。


<details>
  <summary>Details</summary>
Motivation: 现有卒中影像AI模型多为黑盒预测器，缺乏不确定性意识和结构化弃权机制，在急诊放射学高风险环境中存在安全和信任问题。需要开发更安全、透明、与临床医生决策行为一致的AI系统。

Method: 采用模块化代理管道：感知代理进行病灶感知图像分析，不确定性估计代理计算切片级预测可靠性，决策代理基于预定义不确定性阈值决定是否预测或弃权。集成视觉解释机制支持预测和弃权决策。

Result: 在代表性卒中影像场景中的定性和案例分析表明，不确定性驱动的弃权自然出现在诊断模糊区域和低信息切片中。框架能够支持预测和弃权决策的解释。

Conclusion: 代理控制、不确定性意识和选择性弃权是开发安全可信赖医学影像AI系统的关键设计原则，而非仅追求分割或分类准确率提升。

Abstract: Artificial intelligence models have shown strong potential in acute ischemic stroke imaging, particularly for lesion detection and segmentation using computed tomography and magnetic resonance imaging. However, most existing approaches operate as black box predictors, producing deterministic outputs without explicit uncertainty awareness or structured mechanisms to abstain under ambiguous conditions. This limitation raises serious safety and trust concerns in high risk emergency radiology settings. In this paper, we propose an explainable agentic AI framework for uncertainty aware and abstention enabled decision support in acute ischemic stroke imaging. The framework follows a modular agentic pipeline in which a perception agent performs lesion aware image analysis, an uncertainty estimation agent computes slice level predictive reliability, and a decision agent determines whether to issue a prediction or abstain based on predefined uncertainty thresholds. Unlike prior stroke imaging systems that primarily focus on improving segmentation or classification accuracy, the proposed framework explicitly prioritizes clinical safety, transparency, and clinician aligned decision behavior. Qualitative and case based analyses across representative stroke imaging scenarios demonstrate that uncertainty driven abstention naturally emerges in diagnostically ambiguous regions and low information slices. The framework further integrates visual explanation mechanisms to support both predictive and abstention decisions, addressing a key limitation of existing uncertainty aware medical imaging systems. Rather than introducing a new performance benchmark, this work presents agentic control, uncertainty awareness, and selective abstention as essential design principles for developing safe and trustworthy medical imaging AI systems.

</details>


### [356] [Diffusion Timbre Transfer Via Mutual Information Guided Inpainting](https://arxiv.org/abs/2601.01294)
*Ching Ho Lee,Javier Nistal,Stefan Lattner,Marco Pasini,George Fazekas*

Main category: cs.SD

Relevance: 45.0

TL;DR: 本文研究音乐音频的timbre transfer（音色转换）问题，将其视为推理时编辑任务。基于预训练的潜在扩散模型，提出无需额外训练的轻量级方法：维度噪声注入和早期步长钳制机制，实现音色转换同时保持旋律节奏结构。


<details>
  <summary>Details</summary>
Motivation: 音乐音频的timbre transfer（音色转换）通常需要大量训练数据或复杂模型。本文旨在探索如何在推理时利用预训练扩散模型进行音色编辑，无需额外训练，实现高效可控的音色转换。

Method: 基于预训练潜在扩散模型，提出两种推理时技术：1) 维度噪声注入：针对对乐器身份信息最敏感的潜在通道注入噪声；2) 早期步长钳制：在反向扩散过程中重新施加输入音频的旋律和节奏结构。方法兼容文本/音频条件（如CLAP）。

Result: 方法能够有效实现音色转换，在音色变化和结构保持之间取得良好平衡。简单的推理时控制可以显著引导预训练模型适应风格转换用例，展示了推理时编辑的潜力。

Conclusion: 通过轻量级推理时技术，可以在不重新训练的情况下利用预训练扩散模型进行音乐音频的timbre transfer。该方法为模型编辑和可控生成提供了新思路，展示了预训练模型的灵活性和适应性。

Abstract: We study timbre transfer as an inference-time editing problem for music audio. Starting from a strong pre-trained latent diffusion model, we introduce a lightweight procedure that requires no additional training: (i) a dimension-wise noise injection that targets latent channels most informative of instrument identity, and (ii) an early-step clamping mechanism that re-imposes the input's melodic and rhythmic structure during reverse diffusion. The method operates directly on audio latents and is compatible with text/audio conditioning (e.g., CLAP). We discuss design choices,analyze trade-offs between timbral change and structural preservation, and show that simple inference-time controls can meaningfully steer pre-trained models for style-transfer use cases.

</details>


### [357] [MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning](https://arxiv.org/abs/2601.01568)
*Chunyu Qiang,Jun Wang,Xiaopeng Wang,Kang Yin,Yuxin Guo,Xijuan Zeng,Nan Li,Zihan Li,Yuzhe Liang,Ziyu Zhang,Teng Ma,Yushen Chen,Zhongliang Liu,Feng Deng,Chen Zhang,Pengfei Wan*

Main category: cs.SD

Relevance: 45.0

TL;DR: MM-Sonate：一种多模态流匹配框架，统一可控音视频联合生成与零样本语音克隆能力，通过统一指令-音素输入实现严格的语言和时间对齐，引入音色注入机制解耦说话人身份与语言内容，并提出基于噪声的负条件策略提升声学保真度。


<details>
  <summary>Details</summary>
Motivation: 当前联合音视频生成模型在细粒度声学控制方面存在困难，特别是在身份保持的语音生成上。现有方法要么因级联生成导致时间错位，要么缺乏在联合合成框架内进行零样本语音克隆的能力。需要一种能够同时实现可控音视频联合生成和零样本语音克隆的统一框架。

Method: 提出MM-Sonate多模态流匹配框架：1）使用统一指令-音素输入确保语言和时间对齐；2）引入音色注入机制解耦说话人身份与语言内容，实现零样本语音克隆；3）提出基于噪声的负条件策略，利用自然噪声先验增强声学保真度，克服标准无分类器引导在多模态设置中的局限性。

Result: 在联合生成基准测试中建立了新的最先进性能，在唇部同步和语音清晰度方面显著优于基线方法，同时实现了与专业文本到语音系统相当的语音克隆保真度。

Conclusion: MM-Sonate成功解决了联合音视频生成中的关键挑战，实现了可控生成与零样本语音克隆的统一，为多模态内容合成提供了有效的解决方案。

Abstract: Joint audio-video generation aims to synthesize synchronized multisensory content, yet current unified models struggle with fine-grained acoustic control, particularly for identity-preserving speech. Existing approaches either suffer from temporal misalignment due to cascaded generation or lack the capability to perform zero-shot voice cloning within a joint synthesis framework. In this work, we present MM-Sonate, a multimodal flow-matching framework that unifies controllable audio-video joint generation with zero-shot voice cloning capabilities. Unlike prior works that rely on coarse semantic descriptions, MM-Sonate utilizes a unified instruction-phoneme input to enforce strict linguistic and temporal alignment. To enable zero-shot voice cloning, we introduce a timbre injection mechanism that effectively decouples speaker identity from linguistic content. Furthermore, addressing the limitations of standard classifier-free guidance in multimodal settings, we propose a noise-based negative conditioning strategy that utilizes natural noise priors to significantly enhance acoustic fidelity. Empirical evaluations demonstrate that MM-Sonate establishes new state-of-the-art performance in joint generation benchmarks, significantly outperforming baselines in lip synchronization and speech intelligibility, while achieving voice cloning fidelity comparable to specialized Text-to-Speech systems.

</details>


### [358] [HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller](https://arxiv.org/abs/2601.01577)
*Tran Tien Dat,Nguyen Hai An,Nguyen Khanh Viet Dung,Nguyen Duy Duc*

Main category: cs.RO

Relevance: 45.0

TL;DR: 提出Hanoi-World，一种基于JEPA的世界模型，使用RNN进行长期水平规划，在自动驾驶控制器中实现安全感知的驾驶规划


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的自动驾驶控制器存在数据需求大、性能不稳定、难以把握安全概念、过度关注噪声特征等问题。而基于联合嵌入预测架构(JEPA)的自监督学习方法能够模仿人脑通过想象和少量观察学习新技能的能力，为自动驾驶提供更有效的替代方案。

Method: 提出Hanoi-World世界模型，基于JEPA架构，使用循环神经网络(RNN)进行长期水平规划，实现高效推理。在Highway-Env包的不同环境中进行实验验证。

Result: 在Highway-Env环境中展示了有效的驾驶规划能力，具有安全感知特性，与最先进基线相比具有可观的碰撞率表现。

Conclusion: Hanoi-World作为一种JEPA-based世界模型，能够有效解决传统强化学习在自动驾驶控制器中的局限性，实现安全感知的长期规划。

Abstract: Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines

</details>


### [359] [Beyond Demand Estimation: Consumer Surplus Evaluation via Cumulative Propensity Weights](https://arxiv.org/abs/2601.01029)
*Zeyu Bian,Max Biggs,Ruijiang Gao,Zhengling Qi*

Main category: stat.ML

Relevance: 40.0

TL;DR: 提出使用观测数据审计AI决策消费者剩余效应的实用框架，通过利用算法定价中的随机性，避免传统需求函数估计和数值积分，引入累积倾向权重和增强版本，支持灵活机器学习方法，并扩展到公平性考量。


<details>
  <summary>Details</summary>
Motivation: 传统审计AI决策消费者剩余的方法需要估计需求函数并进行数值积分，但存在模型设定错误、数据需求大、收敛慢等问题。需要开发更实用的框架来评估AI驱动决策（如定向定价和算法贷款）对消费者福利的影响。

Method: 利用现代算法定价中探索-利用权衡产生的随机性，提出累积倾向权重（CPW）估计器，通过重新加权购买结果重建积分。进一步提出增强累积倾向权重（ACPW）估计器，只需需求模型或历史定价策略分布之一正确设定即可。框架支持灵活机器学习方法，并扩展到不平等感知的剩余度量。

Result: 提出的估计器避免了显式需求函数估计和数值积分，能够快速收敛，即使机器学习估计收敛较慢。框架支持公平性分析，允许量化利润-公平权衡。通过综合数值研究验证了方法的有效性。

Conclusion: 该框架为使用观测数据审计AI决策的消费者剩余效应提供了实用方法，克服了传统方法的局限性，支持灵活机器学习应用，并扩展到公平性考量，为监管者和企业提供了量化工具。

Abstract: This paper develops a practical framework for using observational data to audit the consumer surplus effects of AI-driven decisions, specifically in targeted pricing and algorithmic lending. Traditional approaches first estimate demand functions and then integrate to compute consumer surplus, but these methods can be challenging to implement in practice due to model misspecification in parametric demand forms and the large data requirements and slow convergence of flexible nonparametric or machine learning approaches. Instead, we exploit the randomness inherent in modern algorithmic pricing, arising from the need to balance exploration and exploitation, and introduce an estimator that avoids explicit estimation and numerical integration of the demand function. Each observed purchase outcome at a randomized price is an unbiased estimate of demand and by carefully reweighting purchase outcomes using novel cumulative propensity weights (CPW), we are able to reconstruct the integral. Building on this idea, we introduce a doubly robust variant named the augmented cumulative propensity weighting (ACPW) estimator that only requires one of either the demand model or the historical pricing policy distribution to be correctly specified. Furthermore, this approach facilitates the use of flexible machine learning methods for estimating consumer surplus, since it achieves fast convergence rates by incorporating an estimate of demand, even when the machine learning estimate has slower convergence rates. Neither of these estimators is a standard application of off-policy evaluation techniques as the target estimand, consumer surplus, is unobserved. To address fairness, we extend this framework to an inequality-aware surplus measure, allowing regulators and firms to quantify the profit-equity trade-off. Finally, we validate our methods through comprehensive numerical studies.

</details>


### [360] [PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS](https://arxiv.org/abs/2601.01288)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.GR

Relevance: 40.0

TL;DR: PyBatchRender：基于Python的高吞吐量批处理3D渲染库，专为像素强化学习设计，在简单场景下可达百万FPS，比传统方法快1000倍


<details>
  <summary>Details</summary>
Motivation: 解决像素强化学习中的3D渲染瓶颈问题。现有方案存在性能与复杂度的权衡：要么使用高速但低级的引擎，要么使用易用但缓慢的Python框架。需要一种既能保持Python易用性又能提供高性能渲染的解决方案。

Method: 基于Panda3D游戏引擎构建，通过优化的批处理渲染技术实现性能提升。作为物理无关的渲染器，专门为像素强化学习设计，提供Python API，仅需数十行代码即可创建自定义场景。

Result: 在简单场景下实现超过100万FPS的渲染速度，相比传统方法获得高达1000倍的加速。提供比专用库更大的灵活性，比典型游戏引擎包装器更简单的设置，速度可与Madrona等先进C++引擎相媲美。

Conclusion: PyBatchRender成功解决了像素强化学习中的渲染瓶颈，通过Python易用性和高性能的结合，为研究人员和开发者提供了民主化的高性能3D仿真工具，支持可扩展AI训练的快速原型开发。

Abstract: Reinforcement learning from pixels is often bottlenecked by the performance and complexity of 3D rendered environments. Researchers face a trade-off between high-speed, low-level engines and slower, more accessible Python frameworks. To address this, we introduce PyBatchRender, a Python library for high-throughput, batched 3D rendering that achieves over 1 million FPS on simple scenes. Built on the Panda3D game engine, it utilizes its mature ecosystem while enhancing performance through optimized batched rendering for up to 1000X speedups. Designed as a physics-agnostic renderer for reinforcement learning from pixels, PyBatchRender offers greater flexibility than dedicated libraries, simpler setup than typical game-engine wrappers, and speeds rivaling state-of-the-art C++ engines like Madrona. Users can create custom scenes entirely in Python with tens of lines of code, enabling rapid prototyping for scalable AI training. Open-source and easy to integrate, it serves to democratize high-performance 3D simulation for researchers and developers. The library is available at https://github.com/dolphin-in-a-coma/PyBatchRender.

</details>


### [361] [MORE: Multi-Objective Adversarial Attacks on Speech Recognition](https://arxiv.org/abs/2601.01852)
*Xiaoxue Gao,Zexin Li,Yiming Chen,Nancy F. Chen*

Main category: eess.AS

Relevance: 40.0

TL;DR: 论文提出MORE攻击方法，同时降低ASR模型的识别准确率和推理效率，通过分层攻击机制和重复鼓励加倍目标实现多目标对抗攻击。


<details>
  <summary>Details</summary>
Motivation: 当前ASR模型（如Whisper）在现实应用中广泛使用，但现有研究主要关注对抗攻击下的准确率下降，而忽略了效率方面的鲁棒性。这种单一视角无法全面理解ASR模型的脆弱性，需要同时考虑准确率和效率的多目标攻击研究。

Method: 提出MORE（多目标重复加倍鼓励攻击），采用分层阶段排斥-锚定机制，将多目标对抗优化重新构建为分层框架，依次实现双目标。引入新颖的重复鼓励加倍目标（REDO），通过保持准确率下降并周期性地加倍预测序列长度，诱导重复文本生成。

Result: 实验表明，MORE相比现有基线方法，能够持续产生显著更长的转录文本，同时保持较高的词错误率，证明其在多目标对抗攻击中的有效性。

Conclusion: 该研究填补了ASR模型鲁棒性研究中效率维度缺失的空白，提出的MORE攻击方法能够同时降低准确率和推理效率，为全面评估ASR模型安全性提供了新视角。

Abstract: The emergence of large-scale automatic speech recognition (ASR) models such as Whisper has greatly expanded their adoption across diverse real-world applications. Ensuring robustness against even minor input perturbations is therefore critical for maintaining reliable performance in real-time environments. While prior work has mainly examined accuracy degradation under adversarial attacks, robustness with respect to efficiency remains largely unexplored. This narrow focus provides only a partial understanding of ASR model vulnerabilities. To address this gap, we conduct a comprehensive study of ASR robustness under multiple attack scenarios. We introduce MORE, a multi-objective repetitive doubling encouragement attack, which jointly degrades recognition accuracy and inference efficiency through a hierarchical staged repulsion-anchoring mechanism. Specifically, we reformulate multi-objective adversarial optimization into a hierarchical framework that sequentially achieves the dual objectives. To further amplify effectiveness, we propose a novel repetitive encouragement doubling objective (REDO) that induces duplicative text generation by maintaining accuracy degradation and periodically doubling the predicted sequence length. Overall, MORE compels ASR models to produce incorrect transcriptions at a substantially higher computational cost, triggered by a single adversarial input. Experiments show that MORE consistently yields significantly longer transcriptions while maintaining high word error rates compared to existing baselines, underscoring its effectiveness in multi-objective adversarial attack.

</details>


### [362] [Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections](https://arxiv.org/abs/2601.00814)
*Abhishek Kumar*

Main category: cs.AI

Relevance: 35.0

TL;DR: 提出了一种基于嵌入余弦相似度的跨语言本体对齐系统，通过新颖的描述生成技术丰富本体实体上下文，使用微调的多语言Transformer模型生成更好的嵌入，在OAEI-2022多语言农场赛道上达到71% F1分数


<details>
  <summary>Details</summary>
Motivation: 解决跨语言本体对齐的挑战，传统方法难以捕捉跨语言的语义相似性，需要更有效的技术来对齐不同语言的本体实体

Method: 1) 使用新颖技术为实体生成描述性文本以丰富上下文；2) 采用微调的多语言Transformer模型生成实体嵌入；3) 基于余弦相似度匹配实体对；4) 应用阈值过滤保留高相似度实体对

Result: 在OAEI-2022多语言农场赛道上获得71% F1分数（78%召回率，65%精确率），比最佳基线提升16%，表明能有效捕捉跨语言相似性

Conclusion: 提出的对齐流程能有效处理跨语言本体对齐问题，通过上下文丰富和微调多语言模型显著提升对齐性能

Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.

</details>


### [363] [OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification](https://arxiv.org/abs/2601.00843)
*Ayda Aghaei Nia*

Main category: cs.AI

Relevance: 35.0

TL;DR: OmniNeuro是一个将脑机接口从黑盒解码器转变为透明反馈伙伴的HCI框架，通过物理、混沌和量子启发的可解释性引擎提供实时神经声化和生成式AI临床报告。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习提高了脑机接口的解码精度，但其"黑盒"特性阻碍了临床采用，导致用户挫折和神经可塑性结果不佳。需要将BCI转变为透明的反馈伙伴来改善用户体验和临床效果。

Method: 提出OmniNeuro框架，集成三种可解释性引擎：(1)物理（能量）分析，(2)混沌（分形复杂性）分析，(3)量子启发的确定性建模。这些指标驱动实时神经声化和生成式AI临床报告，框架与解码器无关，可作为任何最先进架构的可解释性层。

Result: 在PhysioNet数据集（N=109）上评估，系统平均准确率达到58.52%。定性试点研究（N=3）证实可解释反馈帮助用户调节心理努力，减少"试错"阶段。

Conclusion: OmniNeuro通过将可解释性作为核心设计原则，解决了BCI黑盒问题，改善了用户体验和临床结果，为任何最先进架构提供了必要的可解释性层。

Abstract: While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the "Black Box" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the "trial-and-error" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.

</details>


### [364] [Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning](https://arxiv.org/abs/2601.01511)
*Ahmed Dawoud,Osama El-Shamy*

Main category: cs.AI

Relevance: 35.0

TL;DR: 提出神经网络增强的双重机器学习框架，利用文本嵌入进行因果识别，相比传统树基方法显著减少偏差


<details>
  <summary>Details</summary>
Motivation: 在观测性研究中，未观测的混杂因素导致选择偏差，传统计量方法难以处理与结构化协变量正交的混杂因素，而高维非结构化文本包含这些潜在变量的丰富代理信息

Method: 提出神经网络增强的双重机器学习框架，利用文本嵌入进行因果识别，通过深度学习架构建模嵌入流形的连续拓扑结构

Result: 非结构化文本嵌入能捕捉结构化表格数据中缺失的关键混杂信息；传统树基DML估计器因无法建模嵌入流形连续拓扑而保留显著偏差(+24%)；深度学习方法将偏差降至-0.86%，有效恢复真实因果参数

Conclusion: 当基于高维自然语言数据进行条件化时，深度学习架构对于满足无混杂假设至关重要，神经网络增强的DML框架能有效利用文本嵌入进行因果识别

Abstract: Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data

</details>


### [365] [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)
*Yao Lu,Shang Liu,Hangan Zhou,Wenji Fang,Qijun Zhang,Zhiyao Xie*

Main category: cs.AI

Relevance: 35.0

TL;DR: RTL-OPT是一个用于评估LLM在RTL代码优化能力的基准测试，包含36个手工设计的数字电路，覆盖组合逻辑、流水线数据通路、有限状态机和存储器接口等类别，提供次优版本和人工优化参考版本，并集成了自动化评估框架来验证功能正确性和量化PPA改进。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成RTL代码的基准主要评估语法正确性，而非优化质量（功耗、性能、面积）。需要建立一个专门评估LLM在RTL优化能力的基准，以反映实际硬件设计中的优化需求。

Method: 创建包含36个手工设计数字电路的基准测试集，覆盖多种实现类别。每个任务提供次优RTL代码和人工优化参考版本，后者体现工业验证的优化模式。集成自动化评估框架验证功能正确性并量化PPA改进。

Result: 提出了RTL-OPT基准测试，能够标准化评估生成模型在硬件设计优化中的能力，特别是对功耗、性能和面积的优化效果。

Conclusion: RTL-OPT填补了现有基准在评估LLM RTL优化能力方面的空白，为硬件设计自动化和LLM应用提供了重要的评估工具。

Abstract: The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.

</details>


### [366] [Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence](https://arxiv.org/abs/2601.01875)
*Kewen Cao,Jianxu Chen,Yongbing Zhang,Ye Zhang,Hongxiao Wang*

Main category: cs.AI

Relevance: 35.0

TL;DR: 提出SQL为中心的智能体框架，通过可执行的SQL查询将细胞特征测量与病理诊断结论连接起来，提高病理图像分析的透明度和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 当前病理图像分析中，临床医生难以理解模型决策的依据。视觉语言模型虽然能生成自然语言解释，但往往只是相关性描述，缺乏可验证的证据。需要一种能够将特征测量与推理过程都变得可审计的方法。

Method: 1) 提取人类可解释的细胞特征；2) 特征推理智能体通过SQL查询在特征表上进行聚合，将视觉证据转化为定量发现；3) 知识比较智能体将这些发现与已建立的病理知识进行比较，模拟病理学家从可测量观察中论证诊断的过程。

Result: 在两个病理视觉问答数据集上的实验表明，该方法提高了可解释性和决策可追溯性，同时生成了可执行的SQL追踪记录，将细胞测量与诊断结论连接起来。

Conclusion: SQL为中心的智能体框架为病理图像分析提供了可审计的特征测量和推理过程，增强了模型决策的透明度和可信度。

Abstract: Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.

</details>


### [367] [Speak the Art: A Direct Speech to Image Generation Framework](https://arxiv.org/abs/2601.00827)
*Mariam Saeed,Manar Amr,Farida Adel,Nada Hassan,Nour Walid,Eman Mohamed,Mohamed Hussein,Marwan Torki*

Main category: eess.AS

Relevance: 35.0

TL;DR: STA框架通过语音编码网络+VQ-Diffusion实现直接语音到图像生成，利用预训练图像-文本模型监督语音嵌入，替代GAN解决训练不稳定问题，支持多语言扩展


<details>
  <summary>Details</summary>
Motivation: 当前语音到图像生成存在两大问题：1）语音编码网络生成的嵌入缺乏足够语义信息；2）GAN存在训练不稳定、模式崩溃等问题。需要更有效的框架来提升语音到图像生成质量

Method: 提出STA框架：1）语音编码网络，使用预训练图像-文本模型监督训练以改善语音嵌入质量；2）VQ-Diffusion网络，以语音嵌入为条件生成图像，替代传统GAN；3）扩展支持多语言（英语和阿拉伯语）

Result: 结果大幅超越现有最佳模型，证明了框架的有效性。多语言扩展验证了框架的通用性

Conclusion: STA框架通过改进语音嵌入质量和采用扩散模型，显著提升了语音到图像生成的性能，为多模态生成提供了新思路

Abstract: Direct speech-to-image generation has recently shown promising results. However, compared to text-to-image generation, there is still a large gap to enclose. Current approaches use two stages to tackle this task: speech encoding network and image generative adversarial network (GAN). The speech encoding networks in these approaches produce embeddings that do not capture sufficient linguistic information to semantically represent the input speech. GANs suffer from issues such as non-convergence, mode collapse, and diminished gradient, which result in unstable model parameters, limited sample diversity, and ineffective generator learning, respectively. To address these weaknesses, we introduce a framework called \textbf{Speak the Art (STA)} which consists of a speech encoding network and a VQ-Diffusion network conditioned on speech embeddings. To improve speech embeddings, the speech encoding network is supervised by a large pre-trained image-text model during training. Replacing GANs with diffusion leads to more stable training and the generation of diverse images. Additionally, we investigate the feasibility of extending our framework to be multilingual. As a proof of concept, we trained our framework with two languages: English and Arabic. Finally, we show that our results surpass state-of-the-art models by a large margin.

</details>


### [368] [A Global Atlas of Digital Dermatology to Map Innovation and Disparities](https://arxiv.org/abs/2601.00840)
*Fabian Gröger,Simone Lionetti,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Lea Habermacher,Labelling Consortium,Ludovic Amruthalingam,Matthew Groh,Marc Pouly,Alexander A. Navarini*

Main category: cs.DL

Relevance: 35.0

TL;DR: SkinMap是一个多模态框架，首次对皮肤病学领域的所有公开数据集进行全面审计，创建了包含110万张皮肤状况图像的语义图谱，量化了信息新颖性、数据集冗余性和代表性差距。


<details>
  <summary>Details</summary>
Motivation: 尽管皮肤病学AI应用前景广阔，但模型可靠性依赖于数据质量。当前领域缺乏定量指标来衡量新数据集是否真正扩展临床覆盖范围，还是仅仅重复已有数据。需要系统评估数据集的全面性和代表性。

Method: 开发了SkinMap多模态框架，将公开可用的皮肤病学数据集统一为单一可查询的语义图谱。通过该框架量化：(1)随时间的信息新颖性，(2)数据集冗余性，(3)人口统计学和诊断方面的代表性差距。

Result: 尽管数据集规模呈指数增长，但信息新颖性趋于平稳。发现显著的结构性覆盖差距：深色皮肤(Fitzpatrick V-VI)仅占5.8%，儿科患者仅占3.0%。常见肿瘤在浅色皮肤上密集覆盖，而许多罕见疾病和表型组合代表性不足。

Conclusion: SkinMap提供了测量数据盲点的基础设施，能够指导战略性数据采集，填补临床空间中的未覆盖区域，促进皮肤病学AI的公平性和全面性发展。

Abstract: The adoption of artificial intelligence in dermatology promises democratized access to healthcare, but model reliability depends on the quality and comprehensiveness of the data fueling these models. Despite rapid growth in publicly available dermatology images, the field lacks quantitative key performance indicators to measure whether new datasets expand clinical coverage or merely replicate what is already known. Here we present SkinMap, a multi-modal framework for the first comprehensive audit of the field's entire data basis. We unify the publicly available dermatology datasets into a single, queryable semantic atlas comprising more than 1.1 million images of skin conditions and quantify (i) informational novelty over time, (ii) dataset redundancy, and (iii) representation gaps across demographics and diagnoses. Despite exponential growth in dataset sizes, informational novelty across time has somewhat plateaued: Some clusters, such as common neoplasms on fair skin, are densely populated, while underrepresented skin types and many rare diseases remain unaddressed. We further identify structural gaps in coverage: Darker skin tones (Fitzpatrick V-VI) constitute only 5.8% of images and pediatric patients only 3.0%, while many rare diseases and phenotype combinations remain sparsely represented. SkinMap provides infrastructure to measure blind spots and steer strategic data acquisition toward undercovered regions of clinical space.

</details>


### [369] [A Platform for Interactive AI Character Experiences](https://arxiv.org/abs/2601.01027)
*Rafael Wampfler,Chen Yang,Dillon Elste,Nikola Kovacevic,Philine Witzig,Markus Gross*

Main category: cs.HC

Relevance: 35.0

TL;DR: 论文提出了一个用于创建可信数字角色的系统和平台，整合了对话AI、角色完整性维护、个性情感管理、知识记忆处理、语音合成、动画生成、实时交互和物理环境集成等多种AI技术，并以数字爱因斯坦作为概念验证。


<details>
  <summary>Details</summary>
Motivation: 从电影角色到现代科幻作品，将角色带入交互式、故事驱动的对话一直是人类的梦想。实现这一愿景极具挑战性，需要解决对话AI、角色完整性维护、个性情感管理、知识记忆处理、语音合成、动画生成、实时交互和物理环境集成等多个复杂AI问题。虽然基础模型、提示工程和下游任务微调等技术进步为单独解决这些问题提供了可能，但将这些技术整合用于交互式角色仍然是一个开放性问题。

Method: 作者提出了一个系统和平台，能够方便地设计可信的数字角色，提供对话和故事驱动的体验，同时解决所有技术挑战。该系统整合了多种AI组件，包括：1）对话AI系统；2）角色完整性维护机制；3）个性和情感管理系统；4）知识和记忆处理模块；5）语音合成技术；6）动画生成系统；7）实时交互能力；8）物理环境集成。作为概念验证，他们创建了数字爱因斯坦，允许用户与爱因斯坦的数字代表进行关于其生活、研究和人格的对话。

Result: 开发了一个灵活且可泛化的系统，能够创建任何故事驱动或对话角色。数字爱因斯坦展示了该方法的有效性，用户可以与数字爱因斯坦进行有意义的对话。通过将这些多样化的AI组件统一到一个易于适应的平台中，该工作为沉浸式角色体验铺平了道路。

Conclusion: 该研究成功地将多种AI技术整合到一个统一的平台中，解决了创建交互式数字角色的技术挑战。数字爱因斯坦作为概念验证展示了系统的可行性，而系统的灵活性使其能够泛化到任何故事驱动或对话角色。这项工作为实现逼真的、基于故事的交互体验梦想迈出了重要一步。

Abstract: From movie characters to modern science fiction - bringing characters into interactive, story-driven conversations has captured imaginations across generations. Achieving this vision is highly challenging and requires much more than just language modeling. It involves numerous complex AI challenges, such as conversational AI, maintaining character integrity, managing personality and emotions, handling knowledge and memory, synthesizing voice, generating animations, enabling real-world interactions, and integration with physical environments. Recent advancements in the development of foundation models, prompt engineering, and fine-tuning for downstream tasks have enabled researchers to address these individual challenges. However, combining these technologies for interactive characters remains an open problem. We present a system and platform for conveniently designing believable digital characters, enabling a conversational and story-driven experience while providing solutions to all of the technical challenges. As a proof-of-concept, we introduce Digital Einstein, which allows users to engage in conversations with a digital representation of Albert Einstein about his life, research, and persona. While Digital Einstein exemplifies our methods for a specific character, our system is flexible and generalizes to any story-driven or conversational character. By unifying these diverse AI components into a single, easy-to-adapt platform, our work paves the way for immersive character experiences, turning the dream of lifelike, story-based interactions into a reality.

</details>


### [370] [Improving Code-Switching Speech Recognition with TTS Data Augmentation](https://arxiv.org/abs/2601.00935)
*Yue Heng Yeo,Yuchen Hu,Shreyas Gopal,Yizhou Peng,Hexin Liu,Eng Siong Chng*

Main category: eess.AS

Relevance: 35.0

TL;DR: 该论文探索使用多语言TTS模型生成合成语音数据来增强低资源对话式语码转换ASR性能，在SEAME数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 对话式语码转换语音识别面临高质量标注数据稀缺的挑战，需要有效的数据增强方法来提升ASR系统性能。

Method: 使用多语言CosyVoice2 TTS模型在SEAME数据集上进行微调，生成合成的中英语码转换对话语音，增加训练数据的数量和说话人多样性。

Result: 使用合成语音增强真实语音后，混合错误率在DevMan上从12.1%降至10.1%，在DevSGE上从17.8%降至16.0%，性能显著提升。

Conclusion: 多语言TTS是增强低资源对话式语码转换场景下ASR鲁棒性的有效实用工具。

Abstract: Automatic speech recognition (ASR) for conversational code-switching speech remains challenging due to the scarcity of realistic, high-quality labeled speech data. This paper explores multilingual text-to-speech (TTS) models as an effective data augmentation technique to address this shortage. Specifically, we fine-tune the multilingual CosyVoice2 TTS model on the SEAME dataset to generate synthetic conversational Chinese-English code-switching speech, significantly increasing the quantity and speaker diversity of available training data. Our experiments demonstrate that augmenting real speech with synthetic speech reduces the mixed error rate (MER) from 12.1 percent to 10.1 percent on DevMan and from 17.8 percent to 16.0 percent on DevSGE, indicating consistent performance gains. These results confirm that multilingual TTS is an effective and practical tool for enhancing ASR robustness in low-resource conversational code-switching scenarios.

</details>


### [371] [Scale-aware Adaptive Supervised Network with Limited Medical Annotations](https://arxiv.org/abs/2601.01005)
*Zihan Li,Dandan Shan,Yunxiang Li,Paul E. Kinahan,Qingqi Hong*

Main category: eess.IV

Relevance: 35.0

TL;DR: SASNet提出了一种用于医学图像分割的双分支半监督学习网络，通过尺度感知自适应重加权、视图方差增强和分割回归一致性学习来解决标注稀缺、标注者变异性和多尺度特征整合问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在半监督学习场景下面临三大挑战：1）需要放射学专家知识的严重标注稀缺；2）不同视角和专业知识水平导致的显著标注者间变异性；3）复杂解剖结构中精确边界划分的多尺度特征整合不足。现有半监督方法在小型目标分割和边界细化任务中性能显著下降。

Method: 提出SASNet双分支架构，包含三个关键创新：1）尺度感知自适应重加权策略，使用时序置信度累积动态加权像素级预测；2）视图方差增强机制，采用3D傅里叶域变换模拟标注变异性；3）通过符号距离图算法进行分割回归一致性学习以增强边界精度。这些创新在统一优化框架中整合了空间、时序和几何一致性原则。

Result: 在LA、Pancreas-CT和BraTS数据集上的综合评估表明，SASNet在有限标注数据下实现了优越性能，超越了最先进的半监督方法，同时接近全监督性能水平。

Conclusion: SASNet通过创新的尺度感知自适应重加权、视图方差增强和分割回归一致性学习，有效解决了医学图像半监督分割的核心挑战，在标注稀缺情况下实现了接近全监督的性能。

Abstract: Medical image segmentation faces critical challenges in semi-supervised learning scenarios due to severe annotation scarcity requiring expert radiological knowledge, significant inter-annotator variability across different viewpoints and expertise levels, and inadequate multi-scale feature integration for precise boundary delineation in complex anatomical structures. Existing semi-supervised methods demonstrate substantial performance degradation compared to fully supervised approaches, particularly in small target segmentation and boundary refinement tasks. To address these fundamental challenges, we propose SASNet (Scale-aware Adaptive Supervised Network), a dual-branch architecture that leverages both low-level and high-level feature representations through novel scale-aware adaptive reweight mechanisms. Our approach introduces three key methodological innovations, including the Scale-aware Adaptive Reweight strategy that dynamically weights pixel-wise predictions using temporal confidence accumulation, the View Variance Enhancement mechanism employing 3D Fourier domain transformations to simulate annotation variability, and segmentation-regression consistency learning through signed distance map algorithms for enhanced boundary precision. These innovations collectively address the core limitations of existing semi-supervised approaches by integrating spatial, temporal, and geometric consistency principles within a unified optimization framework. Comprehensive evaluation across LA, Pancreas-CT, and BraTS datasets demonstrates that SASNet achieves superior performance with limited labeled data, surpassing state-of-the-art semi-supervised methods while approaching fully supervised performance levels. The source code for SASNet is available at https://github.com/HUANGLIZI/SASNet.

</details>


### [372] [The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities](https://arxiv.org/abs/2601.01944)
*Matteo Esposito,Andrea Janes,Valentina Lenarduzzi,Davide Taibi*

Main category: cs.SE

Relevance: 35.0

TL;DR: 该论文通过大规模分析157.7k个开源项目，研究AI库在Python和Java开源项目中的采用情况及其对开发实践、技术生态系统和社区参与的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在开源软件中的存在和相关性不断增加，但AI库在开源项目中的采用情况和影响尚未得到充分探索。作者旨在填补这一研究空白，了解AI集成如何重塑软件开发实践。

Method: 对157.7k个潜在开源仓库进行大规模分析，使用仓库指标和软件指标，比较采用AI库的项目与未采用AI库的项目。分析包括开发活动、社区参与和代码复杂性等多个维度。

Result: 预计将发现采用AI库的开源项目与未采用AI库的项目在开发活动、社区参与和代码复杂性方面存在可测量的差异，为AI集成如何重塑软件开发实践提供基于证据的见解。

Conclusion: 该研究将揭示AI库在开源项目中的采用模式及其对软件开发生态系统的影响，为理解AI技术如何改变开源软件开发提供实证基础。

Abstract: In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.
  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.

</details>


### [373] [Scalable Data-Driven Reachability Analysis and Control via Koopman Operators with Conformal Coverage Guarantees](https://arxiv.org/abs/2601.01076)
*Devesh Nath,Haoran Yin,Glen Chou*

Main category: eess.SY

Relevance: 35.0

TL;DR: 提出一个可扩展的基于可达性的概率安全验证框架，用于数据驱动的未知非线性动力学系统，结合Koopman理论、神经网络提升和保形预测来保证统计有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在未知非线性动力学系统的概率安全验证方面存在局限性，特别是在处理高维系统时计算效率低、保守性强，需要一种既能保证统计有效性又能高效计算的可扩展框架。

Method: 1) 使用Koopman理论和神经网络提升函数学习动力学的近似线性表示；2) 在提升空间中设计线性控制器进行闭环轨迹跟踪；3) 通过神经网络验证工具将可达集映射回原始状态空间；4) 应用保形预测处理模型不匹配，生成统计有效的误差边界来膨胀可达集。

Result: 在高维MuJoCo任务（11D Hopper、28D Swimmer）和12D四旋翼系统上，相比现有方法，该方法在可达集覆盖率、计算效率和保守性方面均有显著改进。

Conclusion: 该框架为未知非线性动力学系统提供了一种可扩展、统计有效的概率安全验证方法，能够处理高维复杂系统，并在实际应用中展现出优越性能。

Abstract: We propose a scalable reachability-based framework for probabilistic, data-driven safety verification of unknown nonlinear dynamics. We use Koopman theory with a neural network (NN) lifting function to learn an approximate linear representation of the dynamics and design linear controllers in this space to enable closed-loop tracking of a reference trajectory distribution. Closed-loop reachable sets are efficiently computed in the lifted space and mapped back to the original state space via NN verification tools. To capture model mismatch between the Koopman dynamics and the true system, we apply conformal prediction to produce statistically-valid error bounds that inflate the reachable sets to ensure the true trajectories are contained with a user-specified probability. These bounds generalize across references, enabling reuse without recomputation. Results on high-dimensional MuJoCo tasks (11D Hopper, 28D Swimmer) and 12D quadcopters show improved reachable set coverage rate, computational efficiency, and conservativeness over existing methods.

</details>


### [374] [Generating Diverse TSP Tours via a Combination of Graph Pointer Network and Dispersion](https://arxiv.org/abs/2601.01132)
*Hao-Hsung Yang,Ssu-Yuan Lo,Kuan-Lun Chen,Ching-Kai Wang*

Main category: cs.CG

Relevance: 35.0

TL;DR: 提出了一种解决多样化旅行商问题（D-TSP）的混合框架，结合图指针网络和贪心算法，在保证解质量的同时最大化多样性，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: D-TSP是一个双目标优化问题，需要找到k个不同的TSP路径，既要保证每个路径长度不超过最优解的c倍，又要最小化路径间的平均Jaccard相似度。传统方法计算复杂度高（O(n³)），而现代神经方法多样性有限且依赖复杂外部机制。该研究旨在开发高效、简单且能平衡质量与多样性的解决方案。

Method: 提出两阶段混合框架：1）使用增强近似序列熵损失的图指针网络（GPN）高效采样大量高质量多样化路径池；2）应用贪心算法（对分散问题提供2-近似解）从池中选择最终k个最大多样化路径。

Result: 在Berlin实例上，模型平均Jaccard指数达到0.015，显著优于NMA（0.081）和RF-MA3S。利用GPU加速，GPN结构实现了接近线性的经验运行时增长O(n)。在保持与复杂双标准算法相当多样性的同时，大规模实例（783个城市）上速度提升超过360倍。

Conclusion: 该混合框架在D-TSP问题上实现了最先进的性能，通过简单修改有效控制了质量-多样性权衡，无需复杂外部机制，为物流规划、机器人路径规划等应用提供了高效、高质量的多样化解决方案。

Abstract: We address the Diverse Traveling Salesman Problem (D-TSP), a bi-criteria optimization challenge that seeks a set of $k$ distinct TSP tours. The objective requires every selected tour to have a length at most $c|T^*|$ (where $|T^*|$ is the optimal tour length) while minimizing the average Jaccard similarity across all tour pairs. This formulation is crucial for applications requiring both high solution quality and fault tolerance, such as logistics planning, robotics pathfinding or strategic patrolling. Current methods are limited: traditional heuristics, such as the Niching Memetic Algorithm (NMA) or bi-criteria optimization, incur high computational complexity $O(n^3)$, while modern neural approaches (e.g., RF-MA3S) achieve limited diversity quality and rely on complex, external mechanisms.
  To overcome these limitations, we propose a novel hybrid framework that decomposes D-TSP into two efficient steps. First, we utilize a simple Graph Pointer Network (GPN), augmented with an approximated sequence entropy loss, to efficiently sample a large, diverse pool of high-quality tours. This simple modification effectively controls the quality-diversity trade-off without complex external mechanisms. Second, we apply a greedy algorithm that yields a 2-approximation for the dispersion problem to select the final $k$ maximally diverse tours from the generated pool. Our results demonstrate state-of-the-art performance. On the Berlin instance, our model achieves an average Jaccard index of $0.015$, significantly outperforming NMA ($0.081$) and RF-MA3S. By leveraging GPU acceleration, our GPN structure achieves a near-linear empirical runtime growth of $O(n)$. While maintaining solution diversity comparable to complex bi-criteria algorithms, our approach is over 360 times faster on large-scale instances (783 cities), delivering high-quality TSP solutions with unprecedented efficiency and simplicity.

</details>


### [375] [Beyond Homophily: Community Search on Heterophilic Graphs](https://arxiv.org/abs/2601.01703)
*Qing Sima,Xiaoyang Wang,Wenjie Zhang*

Main category: cs.SI

Relevance: 35.0

TL;DR: AdaptCS是一个用于异质性图社区搜索的统一框架，通过解耦多跳多频信号、低秩优化和自适应评分机制，在异质性图上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的许多网络是异质性的（heterophilic），即边主要连接不相似的节点。传统的社区搜索方法（如k-core、k-truss）和基于GNN的模型在异质性图上效果不佳：算法方法返回混合类别的社区，而GNN基于同质性假设会平滑掉有意义的信号。

Method: 提出AdaptCS框架，包含三个关键设计：1) AdaptCS编码器解耦多跳和多频信号，捕捉平滑（同质性）和对比（异质性）关系；2) 内存高效的低秩优化，移除计算瓶颈确保可扩展性；3) 自适应社区评分（ACS），通过平衡嵌入相似性和拓扑关系指导在线搜索。

Result: 在异质性和同质性基准测试中，AdaptCS在F1分数上平均比最佳基线方法高出11%，在不同异质性水平下保持鲁棒性，并实现了高达2个数量级的加速。

Conclusion: AdaptCS为异质性图上的社区搜索提供了一个有效的统一框架，通过信号解耦和高效优化解决了现有方法的局限性。

Abstract: Community search aims to identify a refined set of nodes that are most relevant to a given query, supporting tasks ranging from fraud detection to recommendation. Unlike homophilic graphs, many real-world networks are heterophilic, where edges predominantly connect dissimilar nodes. Therefore, structural signals that once reflected smooth, low-frequency similarity now appear as sharp, high-frequency contrasts. However, both classical algorithms (e.g., k-core, k-truss) and recent ML-based models struggle to achieve effective community search on heterophilic graphs, where edge signs or semantics are generally unknown. Algorithm-based methods often return communities with mixed class labels, while GNNs, built on homophily, smooth away meaningful signals and blur community boundaries. Therefore, we propose Adaptive Community Search (AdaptCS), a unified framework featuring three key designs: (i) an AdaptCS Encoder that disentangles multi-hop and multi-frequency signals, enabling the model to capture both smooth (homophilic) and contrastive (heterophilic) relations; (ii) a memory-efficient low-rank optimization that removes the main computational bottleneck and ensures model scalability; and (iii) an Adaptive Community Score (ACS) that guides online search by balancing embedding similarity and topological relations. Extensive experiments on both heterophilic and homophilic benchmarks demonstrate that AdaptCS outperforms the best-performing baseline by an average of 11% in F1-score, retains robustness across heterophily levels, and achieves up to 2 orders of magnitude speedup.

</details>


### [376] [Explicit World Models for Reliable Human-Robot Collaboration](https://arxiv.org/abs/2601.01705)
*Kenneth Kwok,Basura Fernando,Qianli Xu,Vigneshwaran Subbaraju,Dongkyu Choi,Boon Kiat Quek*

Main category: cs.RO

Relevance: 35.0

TL;DR: 该论文提出了一种以"显式世界模型"为中心的可靠具身AI新方法，强调在动态、模糊的人机交互中通过建立和更新人机共同基础来对齐机器人行为与人类期望。


<details>
  <summary>Details</summary>
Motivation: 传统具身AI可靠性研究关注形式化验证以实现模型可预测性和鲁棒性，但忽视了人机交互的动态性、模糊性和主观性。论文认为在人类环境中，可靠性是情境决定的，只有在与交互中人类目标和期望相关时才有意义。

Method: 提出以构建和更新"显式世界模型"为中心的方法，该模型代表人机之间的共同基础，用于对齐机器人行为与人类期望，强调感知、解释和响应人类意图的能力。

Result: 提出了一种根本不同的可靠具身AI方法框架，将可靠性重新定义为情境化的人机对齐问题，而非纯粹的技术鲁棒性问题。

Conclusion: 在人类环境中实现可靠具身AI需要从形式化验证转向以人机共同基础为中心的方法，通过显式世界模型来确保机器人行为与人类期望的一致性、可理解性和对齐性。

Abstract: This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible "explicit world model" representing the common ground between human and AI, that is used to align robot behaviours with human expectations.

</details>


### [377] [MergeRec: Model Merging for Data-Isolated Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2601.01753)
*Hyunsoo Kim,Jaewan Moon,Seongmin Park,Jongwuk Lee*

Main category: cs.IR

Relevance: 35.0

TL;DR: MergeRec是一个用于数据隔离跨域序列推荐的模型融合框架，通过训练无关的模型初始化、伪用户数据构建和协同融合优化，在不共享原始用户交互数据的情况下提升推荐系统的跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统在特定领域数据上训练后难以跨域泛化。现有跨域序列推荐方法存在根本性限制：要么依赖跨域重叠用户/物品，要么忽略隐私约束做出不现实假设。本研究提出在数据隔离的跨域序列推荐这一现实问题设置下，解决无法跨域共享原始用户交互数据的挑战。

Method: MergeRec包含三个关键组件：1) 融合初始化：使用训练无关的模型融合技术初始化融合模型；2) 伪用户数据构建：将每个物品视为每个领域中的虚拟序列，构建有意义的训练样本而不依赖真实用户交互；3) 协同融合优化：通过结合推荐损失（鼓励融合模型识别相关物品）和蒸馏损失（从微调源模型传递协同过滤信号）的联合目标，优化领域特定的融合权重。

Result: 大量实验表明，MergeRec不仅保留了原始模型的优势，还显著增强了未见领域的泛化能力。与传统模型融合方法相比，MergeRec始终实现更优性能，Recall@10平均提升高达17.21%，展示了模型融合作为构建通用推荐系统的可扩展有效方法的潜力。

Conclusion: MergeRec通过创新的模型融合框架，在数据隔离的跨域序列推荐场景中取得了显著效果，为构建通用推荐系统提供了可扩展且有效的解决方案。

Abstract: Modern recommender systems trained on domain-specific data often struggle to generalize across multiple domains. Cross-domain sequential recommendation has emerged as a promising research direction to address this challenge; however, existing approaches face fundamental limitations, such as reliance on overlapping users or items across domains, or unrealistic assumptions that ignore privacy constraints. In this work, we propose a new framework, MergeRec, based on model merging under a new and realistic problem setting termed data-isolated cross-domain sequential recommendation, where raw user interaction data cannot be shared across domains. MergeRec consists of three key components: (1) merging initialization, (2) pseudo-user data construction, and (3) collaborative merging optimization. First, we initialize a merged model using training-free merging techniques. Next, we construct pseudo-user data by treating each item as a virtual sequence in each domain, enabling the synthesis of meaningful training samples without relying on real user interactions. Finally, we optimize domain-specific merging weights through a joint objective that combines a recommendation loss, which encourages the merged model to identify relevant items, and a distillation loss, which transfers collaborative filtering signals from the fine-tuned source models. Extensive experiments demonstrate that MergeRec not only preserves the strengths of the original models but also significantly enhances generalizability to unseen domains. Compared to conventional model merging methods, MergeRec consistently achieves superior performance, with average improvements of up to 17.21% in Recall@10, highlighting the potential of model merging as a scalable and effective approach for building universal recommender systems. The source code is available at https://github.com/DIALLab-SKKU/MergeRec.

</details>


### [378] [MCGI: Manifold-Consistent Graph Indexing for Billion-Scale Disk-Resident Vector Search](https://arxiv.org/abs/2601.01930)
*Dongfang Zhao*

Main category: cs.IR

Relevance: 35.0

TL;DR: MCGI是一种基于流形一致性的图索引方法，通过局部本征维度分析自适应调整搜索策略，解决高维空间中欧几里得-测地线不匹配问题，显著提升高维ANN搜索性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于图的近似最近邻搜索在高维空间中存在"欧几里得-测地线不匹配"问题，即贪婪路由偏离底层数据流形，导致性能下降。现有方法通常将维度视为均匀处理，缺乏对数据内在几何结构的适应性。

Method: 提出MCGI（Manifold-Consistent Graph Indexing），一种几何感知的磁盘驻留索引方法。核心是利用局部本征维度（LID）动态调整搜索策略，根据数据内在几何结构调制波束搜索预算，消除对静态超参数的依赖。通过保持流形一致的拓扑连接性来改进近似保证。

Result: 在GIST1M高维数据集上，MCGI在95%召回率下实现5.8倍吞吐量提升；在十亿级SIFT1B数据集上，高召回查询延迟降低3倍。在标准低维数据集上保持性能相当。

Conclusion: MCGI通过几何感知的索引方法有效解决了高维ANN搜索中的流形不一致问题，显著提升了大规模高维数据检索的性能和可扩展性。

Abstract: Graph-based Approximate Nearest Neighbor (ANN) search often suffers from performance degradation in high-dimensional spaces due to the ``Euclidean-Geodesic mismatch,'' where greedy routing diverges from the underlying data manifold. To address this, we propose Manifold-Consistent Graph Indexing (MCGI), a geometry-aware and disk-resident indexing method that leverages Local Intrinsic Dimensionality (LID) to dynamically adapt search strategies to the data's intrinsic geometry. Unlike standard algorithms that treat dimensions uniformly, MCGI modulates its beam search budget based on in situ geometric analysis, eliminating dependency on static hyperparameters. Theoretical analysis confirms that MCGI enables improved approximation guarantees by preserving manifold-consistent topological connectivity. Empirically, MCGI achieves 5.8$\times$ higher throughput at 95\% recall on high-dimensional GIST1M compared to state-of-the-art DiskANN. On the billion-scale SIFT1B dataset, MCGI further validates its scalability by reducing high-recall query latency by 3$\times$, while maintaining performance parity on standard lower-dimensional datasets.

</details>


### [379] [AI-enhanced tuning of quantum dot Hamiltonians toward Majorana modes](https://arxiv.org/abs/2601.02149)
*Mateusz Krawczyk,Jarosław Pawłowski*

Main category: cond-mat.mes-hall

Relevance: 35.0

TL;DR: 提出基于神经网络的量子点模拟器自动调谐方法，利用无监督学习在电导图上训练Vision Transformer网络，通过物理信息损失函数驱动系统向拓扑相转变以获得Majorana模式。


<details>
  <summary>Details</summary>
Motivation: 量子点器件中Majorana模式的实验实现需要精确调谐多个参数，传统手动调谐方法耗时且困难。需要开发自动化方法，利用机器学习从电导测量中学习量子系统的复杂关系，实现高效自动调谐。

Method: 使用深度Vision Transformer网络，在合成电导图数据上进行无监督训练。采用物理信息损失函数，融入Majorana零模的关键特性。通过迭代调谐过程，网络学习哈密顿参数与电导图结构的关系，并提出参数更新建议。

Result: 训练后的网络能够从广泛的初始参数出发，通过单次更新步骤即可生成非平凡的零模。迭代调谐过程能够处理更大范围的参数空间，有效驱动量子点链系统向拓扑相转变。

Conclusion: 该方法展示了神经网络在量子器件自动调谐中的潜力，特别是结合物理信息损失函数，能够高效学习复杂量子系统的行为并实现自动化控制。

Abstract: We propose a neural network-based model capable of learning the broad landscape of working regimes in quantum dot simulators, and using this knowledge to autotune these devices - based on transport measurements - toward obtaining Majorana modes in the structure. The model is trained in an unsupervised manner on synthetic data in the form of conductance maps, using a physics-informed loss that incorporates key properties of Majorana zero modes. We show that, with appropriate training, a deep vision-transformer network can efficiently memorize relation between Hamiltonian parameters and structures on conductance maps and use it to propose parameters update for a quantum dot chain that drive the system toward topological phase. Starting from a broad range of initial detunings in parameter space, a single update step is sufficient to generate nontrivial zero modes. Moreover, by enabling an iterative tuning procedure - where the system acquires updated conductance maps at each step - we demonstrate that the method can address a much larger region of the parameter space.

</details>


### [380] [LLM-Empowered Functional Safety and Security by Design in Automotive Systems](https://arxiv.org/abs/2601.02215)
*Nenad Petrovic,Vahid Zolfaghari,Fengjunjie Pan,Alois Knoll*

Main category: cs.SE

Relevance: 35.0

TL;DR: 提出了一个基于LLM的工作流来支持软件定义汽车(SDV)软件开发，涵盖安全感知系统拓扑设计和事件驱动决策代码分析两个方面。


<details>
  <summary>Details</summary>
Motivation: 软件定义汽车(SDV)的软件开发面临安全性和功能验证的挑战，需要系统化的方法来处理系统拓扑设计和代码分析，特别是涉及CAN和VSS等关键组件的语义有效性验证。

Method: 1) 采用事件链模型进行代码分析，为功能安全验证提供形式化基础；2) 结合模型驱动工程(MDE)和对象约束语言(OCL)规则进行安全拓扑分析；3) 支持本地部署和专有解决方案，在ADAS相关场景中评估。

Result: 开发了一个LLM赋能的工作流，能够支持SDV软件开发中的安全拓扑设计和代码分析，在ADAS相关场景中进行了评估。

Conclusion: LLM可以有效地支持SDV软件开发，特别是在安全感知系统设计和事件驱动代码分析方面，为汽车软件工程提供了新的方法。

Abstract: This paper presents LLM-empowered workflow to support Software Defined Vehicle (SDV) software development, covering the aspects of security-aware system topology design, as well as event-driven decision-making code analysis. For code analysis we adopt event chains model which provides formal foundations to systematic validation of functional safety, taking into account the semantic validity of messages exchanged between key components, including both CAN and Vehicle Signal Specification (VSS). Analysis of security aspects for topology relies on synergy with Model-Driven Engineering (MDE) approach and Object Constraint Language (OCL) rules. Both locally deployable and proprietary solution are taken into account for evaluation within Advanced Driver-Assistance Systems (ADAS)-related scenarios.

</details>


### [381] [DARC: Drum accompaniment generation with fine-grained rhythm control](https://arxiv.org/abs/2601.02357)
*Trey Brosnan*

Main category: cs.SD

Relevance: 35.0

TL;DR: DARC是一个生成式鼓伴奏模型，通过参数高效微调增强STAGE鼓生成器，实现音乐上下文感知和细粒度节奏控制


<details>
  <summary>Details</summary>
Motivation: 音乐创作中快速原型设计需要结构控制和风格灵活性，现有工具要么只能条件化其他音乐音轨但节奏控制有限，要么能指定特定节奏但无法条件化音乐上下文

Method: 使用参数高效微调(PEFT)增强STAGE（最先进的鼓音轨生成器），使其既能条件化其他音轨的音乐上下文，又能接受明确的节奏提示（如beatboxing或敲击音轨）

Result: DARC模型实现了细粒度节奏控制的同时保持了音乐上下文感知能力，解决了现有方法的局限性

Conclusion: DARC为音乐创作提供了更好的控制性和灵活性，通过参数高效微调成功增强了现有生成模型的能力

Abstract: In music creation, rapid prototyping is essential for exploring and refining ideas, yet existing generative tools often fall short when users require both structural control and stylistic flexibility. Prior approaches in stem-to-stem generation can condition on other musical stems but offer limited control over rhythm, and timbre-transfer methods allow users to specify specific rhythms, but cannot condition on musical context. We introduce DARC, a generative drum accompaniment model that conditions both on musical context from other stems and explicit rhythm prompts such as beatboxing or tapping tracks. Using parameter-efficient fine-tuning, we augment STAGE, a state-of-the-art drum stem generator, with fine-grained rhythm control while maintaining musical context awareness.

</details>


### [382] [From Theory of Mind to Theory of Environment: Counterfactual Simulation of Latent Environmental Dynamics](https://arxiv.org/abs/2601.01599)
*Ryutaro Uchiyama*

Main category: q-bio.NC

Relevance: 30.0

TL;DR: 该论文提出"环境理论"概念，认为人类能通过社会线索推断隐藏的环境动态，从而扩展运动探索维度，促进行为创新。


<details>
  <summary>Details</summary>
Motivation: 脊椎动物运动系统通常采用降维策略来简化运动协调，但在充满隐藏行动-结果关联的环境中，运动复杂性可以促进行为创新。人类可能通过社会线索推断隐藏环境动态，这需要解释其背后的计算机制。

Method: 提出"环境理论"框架，认为人类利用与心理理论共享的计算机制，从社会线索中推断环境隐藏动态，从而扩展运动探索的维度。

Result: 理论框架表明，通过社会线索推断环境隐藏动态的能力使人类能够扩展运动探索维度，促进在复杂环境中的行为创新。

Conclusion: "环境理论"提供了一个解释人类如何通过社会认知机制扩展运动探索、促进行为创新的计算框架，连接了运动控制、社会认知和环境学习。

Abstract: The vertebrate motor system employs dimensionality-reducing strategies to limit the complexity of movement coordination, for efficient motor control. But when environments are dense with hidden action-outcome contingencies, movement complexity can promote behavioral innovation. Humans, perhaps uniquely, may infer the presence of hidden environmental dynamics from social cues, by drawing upon computational mechanisms shared with Theory of Mind. This proposed "Theory of Environment" supports behavioral innovation by expanding the dimensionality of motor exploration.

</details>


### [383] [OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation](https://arxiv.org/abs/2601.01939)
*Victor Sanchez,Chris Reinke,Ahamed Mohamed,Xavier Alameda-Pineda*

Main category: cs.AI

Relevance: 25.0

TL;DR: OpenSocInt是一个开源的多模态社交交互模拟器软件包，提供模块化架构来训练社交智能体，支持探索不同感知特征、编码融合方法和智能体类型。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏开源的多模态社交交互模拟框架，限制了社交智能体的研究和开发。作者旨在提供一个可扩展的软件包，支持探索不同感知特征和智能体架构，促进社交智能研究。

Method: 开发了OpenSocInt开源软件包，包含多模态社交交互模拟器和模块化架构。框架支持不同感知特征的编码和融合，以及多种智能体类型的集成。通过社交导航任务展示了系统的实用性。

Result: 成功开发并开源了OpenSocInt软件包，已在GitLab上以GPL许可证发布。通过社交导航任务的实验协议展示了框架的实用性和灵活性。

Conclusion: OpenSocInt为多模态社交交互研究提供了一个有价值的开源工具，支持探索不同感知特征和智能体架构，有助于推动社交智能领域的发展。

Abstract: In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.

</details>


### [384] [CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes](https://arxiv.org/abs/2601.01976)
*Yasmine Souissi,Fabrice Boissier,Nida Meddouri*

Main category: cs.AI

Relevance: 25.0

TL;DR: 本文对基于形式概念分析（FCA）的分类器进行了最新综述，提出了一种从名义数据计算闭包算子的新方法，并构建了专注于最相关概念的部分概念格。


<details>
  <summary>Details</summary>
Motivation: 知识发现（KDD）旨在从各种应用领域生成的海量数据中提取隐藏且有意义的模式。形式概念分析（FCA）作为一种可解释和可解释的学习方法，基于概念格的数学结构，能够生成形式概念并发现概念间的隐藏关系。本文旨在综述FCA分类器的最新进展。

Method: 1. 对基于FCA的分类器进行系统性的文献综述；2. 探索从名义数据计算闭包算子的多种方法；3. 提出一种构建部分概念格的新方法，专注于最相关的概念；4. 通过实验验证所提方法的效率。

Result: 实验结果表明，所提出的构建部分概念格的方法在效率上表现良好，能够有效处理名义数据并提取相关概念用于分类任务。

Conclusion: FCA作为一种可解释的分类方法具有重要价值，本文提出的部分概念格构建方法能够提高分类效率，为知识发现中的分类任务提供了新的技术途径。

Abstract: Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.

</details>


### [385] [Gendered Pathways in AI Companionship: Cross-Community Behavior and Toxicity Patterns on Reddit](https://arxiv.org/abs/2601.01073)
*Erica Coppolillo,Emilio Ferrara*

Main category: cs.SI

Relevance: 25.0

TL;DR: 研究分析了Reddit上AI伴侣平台用户的跨社区参与模式，发现存在明显的性别化结构，少数性别导向社区可能成为毒性内容的放大器。


<details>
  <summary>Details</summary>
Motivation: AI伴侣平台正在重塑人们与非人类代理的情感、浪漫和准社会关系，但缺乏对这些关系如何与性别化在线行为和有害内容暴露相交的研究。需要了解AI伴侣生态系统中的社区参与模式和风险集中点。

Method: 1) 分析MyBoyfriendIsAI子版块中3000多名高度参与用户的Reddit活动历史（超过67,000条历史提交）；2) 构建跨越2000多个子版块的历史交互网络，追踪跨社区路径；3) 测量不同路径中的毒性和情感表达变化。

Result: 1) MBIA用户主要参与四个社区领域：AI伴侣、色情相关、论坛类和游戏；2) 生态系统参与呈现明显的性别化结构，女性用户参与度高；3) 整体毒性较低，但在少数AI-色情和性别导向社区中观察到局部峰值；4) 近16%用户参与性别导向子版块，其轨迹显示系统性不同的情感表达模式和更高的毒性。

Conclusion: 研究揭示了Reddit上AI伴侣跨社区参与的性别化结构，识别出少数性别化路径可能成为毒性放大器，为人类-AI关系平台的测量、审核和设计实践提供了重要见解。

Abstract: AI-companionship platforms are rapidly reshaping how people form emotional, romantic, and parasocial bonds with non-human agents, raising new questions about how these relationships intersect with gendered online behavior and exposure to harmful content. Focusing on the MyBoyfriendIsAI (MBIA) subreddit, we reconstruct the Reddit activity histories of more than 3,000 highly engaged users over two years, yielding over 67,000 historical submissions. We then situate MBIA within a broader ecosystem by building a historical interaction network spanning more than 2,000 subreddits, which enables us to trace cross-community pathways and measure how toxicity and emotional expression vary across these trajectories. We find that MBIA users primarily traverse four surrounding community spheres (AI-companionship, porn-related, forum-like, and gaming) and that participation across the ecosystem exhibits a distinct gendered structure, with substantial engagement by female users. While toxicity is generally low across most pathways, we observe localized spikes concentrated in a small subset of AI-porn and gender-oriented communities. Nearly 16% of users engage with gender-focused subreddits, and their trajectories display systematically different patterns of emotional expression and elevated toxicity, suggesting that a minority of gendered pathways may act as toxicity amplifiers within the broader AI-companionship ecosystem. These results characterize the gendered structure of cross-community participation around AI companionship on Reddit and highlight where risks concentrate, informing measurement, moderation, and design practices for human-AI relationship platforms.

</details>


### [386] [AI-Powered Hybrid Intrusion Detection Framework for Cloud Security Using Novel Metaheuristic Optimization](https://arxiv.org/abs/2601.01134)
*Maryam Mahdi Alhusseini,Alireza Rouhi,Mohammad-Reza Feizi-Derakhshi*

Main category: cs.CR

Relevance: 25.0

TL;DR: 提出HyIDS混合入侵检测系统，使用Energy Valley Optimizer进行特征选择，结合SVM、RF、决策树和KNN四种机器学习模型，在云计算网络安全中显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 云计算中的网络安全面临挑战，特别是入侵检测系统在处理不平衡数据集时性能不佳。需要开发更有效的特征选择和机器学习方法来提升云计算环境中的网络安全检测能力。

Method: 1) 使用Energy Valley Optimizer进行特征选择，将特征维度从88降至38（CIC-DDoS2019）和80降至43（CSE-CIC-IDS2018）；2) 结合四种机器学习模型（SVM、RF、决策树、KNN）；3) 采用下采样技术处理类别不平衡问题。

Result: 在CIC-DDoS2019数据集上，D_TreeEVO模型达到99.13%准确率和98.94% F1分数；在CSE-CIC-IDS2018数据集上达到99.78%准确率和99.70% F1分数。特征选择显著提升了计算效率。

Conclusion: HyIDS系统通过EVO特征选择和机器学习模型组合，有效提升了云计算环境中的入侵检测性能，特别是在处理不平衡数据集方面表现出色。

Abstract: Cybersecurity poses considerable problems to Cloud Computing (CC), especially regarding Intrusion Detection Systems (IDSs), facing difficulties with skewed datasets and suboptimal classification model performance. This study presents the Hybrid Intrusion Detection System (HyIDS), an innovative IDS that employs the Energy Valley Optimizer (EVO) for Feature Selection (FS). Additionally, it introduces a novel technique for enhancing the cybersecurity of cloud computing through the integration of machine learning methodologies with the EVO Algorithm. The Energy Valley Optimizer (EVO) effectively diminished features in the CIC-DDoS2019 dataset from 88 to 38 and in the CSE-CIC-IDS2018 data from 80 to 43, significantly enhancing computing efficiency. HyIDS incorporates four Machine Learning (ML) models: Support Vector Machine (SVM), Random Forest (RF), Decision Tree (D_Tree), and K-Nearest Neighbors (KNN). The proposed HyIDS was assessed utilizing two real-world intrusion datasets, CIC-DDoS2019 and CSE-CIC-IDS2018, both distinguished by considerable class imbalances. The CIC-DDoS2019 dataset has a significant imbalance between DDoS assault samples and legal traffic, while the CSE-CIC-IDS2018 dataset primarily comprises benign traffic with insufficient representation of attack types, complicating the detection of minority attacks. A downsampling technique was employed to balance the datasets, hence improving detection efficacy for both benign and malicious traffic. Twenty-four trials were done, revealing substantial enhancements in categorization accuracy, precision, and recall. Our suggested D_TreeEVO model attained an accuracy rate of 99.13% and an F1 score of 98.94% on the CIC-DDoS2019 dataset, and an accuracy rate of 99.78% and an F1 score of 99.70% on the CSE-CIC-IDS2018 data. These data demonstrate that EVO significantly improves cybersecurity in Cloud Computing (CC).

</details>


### [387] [Seamlessly Natural: Image Stitching with Natural Appearance Preservation](https://arxiv.org/abs/2601.01257)
*Gaetane Lorna N. Tchana,Damaris Belle M. Fotso,Antonio Hendricks,Christophe Bobda*

Main category: eess.IV

Relevance: 25.0

TL;DR: SENA提出了一种几何驱动的图像拼接方法，通过层次化仿射变换、几何驱动的适区检测和锚点接缝切割，解决传统基于单应性方法在视差和深度变化场景中的结构失真问题。


<details>
  <summary>Details</summary>
Motivation: 传统图像拼接依赖单应性对齐，但在双摄像头设置和显著场景深度变化时，刚性平面假设会导致可见扭曲和球形膨胀等失真。需要一种能保持结构保真度的方法来处理现实世界中的视差和深度变化场景。

Method: 1. 层次化仿射变换策略：结合全局仿射初始化、局部仿射细化和平滑自由形变，保持局部形状、平行性和纵横比；2. 几何驱动的适区检测机制：从RANSAC过滤的特征对应中直接识别视差最小化区域，无需语义分割；3. 基于锚点的接缝切割和分割：在适区基础上执行，通过构造强制图像对间的一对一几何对应。

Result: 在具有挑战性的数据集上的广泛实验表明，SENA在配准精度上与领先的基于单应性方法相当，同时在形状保持、纹理完整性和整体视觉真实感等关键视觉指标上显著优于这些方法。

Conclusion: SENA通过几何驱动的方法解决了传统图像拼接在视差和深度变化场景中的根本限制，实现了更好的结构保真度和视觉质量，避免了幻觉结构失真和伪影问题。

Abstract: This paper introduces SENA (SEamlessly NAtural), a geometry-driven image stitching approach that prioritizes structural fidelity in challenging real-world scenes characterized by parallax and depth variation. Conventional image stitching relies on homographic alignment, but this rigid planar assumption often fails in dual-camera setups with significant scene depth, leading to distortions such as visible warps and spherical bulging. SENA addresses these fundamental limitations through three key contributions. First, we propose a hierarchical affine-based warping strategy, combining global affine initialization with local affine refinement and smooth free-form deformation. This design preserves local shape, parallelism, and aspect ratios, thereby avoiding the hallucinated structural distortions commonly introduced by homography-based models. Second, we introduce a geometry-driven adequate zone detection mechanism that identifies parallax-minimized regions directly from the disparity consistency of RANSAC-filtered feature correspondences, without relying on semantic segmentation. Third, building upon this adequate zone, we perform anchor-based seamline cutting and segmentation, enforcing a one-to-one geometric correspondence across image pairs by construction, which effectively eliminates ghosting, duplication, and smearing artifacts in the final panorama.
  Extensive experiments conducted on challenging datasets demonstrate that SENA achieves alignment accuracy comparable to leading homography-based methods, while significantly outperforming them in critical visual metrics such as shape preservation, texture integrity, and overall visual realism.

</details>


### [388] [Quantifying Local Strain Field and Deformation in Active Contraction of Bladder Using a Pretrained Transformer Model: A Speckle-Free Approach](https://arxiv.org/abs/2601.01315)
*Alireza Asadbeygi,Anne M. Robertson,Yasutaka Tobe,Masoud Zamani,Sean D. Stocker,Paul Watton,Naoki Yoshimura,Simon C Watkins*

Main category: q-bio.TO

Relevance: 25.0

TL;DR: 提出了一种基于零样本Transformer模型CoTracker3的无斑点局部应变场量化框架，用于膀胱收缩的生物力学研究，无需人工标记即可追踪自然纹理。


<details>
  <summary>Details</summary>
Motivation: 传统数字图像相关方法需要人工斑点标记，这会改变组织的被动和主动特性。需要一种非侵入性方法来准确量化膀胱收缩期间的局部应变场，以更好地理解排尿生物力学。

Method: 使用最先进的零样本Transformer模型CoTracker3，结合定制的便携式等张双轴装置与多光子显微镜兼容，追踪自然膀胱腔纹理而不需要人工标记。

Result: 基准测试验证了方法的高像素精度和低应变误差。成功捕捉到异质变形模式，即使在复杂折叠和屈曲情况下。应用于大鼠膀胱收缩实验显示显著的各向异性（p<0.01），纵向收缩高于周向收缩。

Conclusion: 该非侵入性方法消除了斑点诱导的伪影，实现了更生理相关的测量，对其他生物和工程系统的材料测试具有广泛适用性。

Abstract: Accurate quantification of local strain fields during bladder contraction is essential for understanding the biomechanics of bladder micturition, in both health and disease. Conventional digital image correlation (DIC) methods have been successfully applied to various biological tissues; however, this approach requires artificial speckling, which can alter both passive and active properties of the tissue. In this study, we introduce a speckle-free framework for quantifying local strain fields using a state-of-the-art, zero-shot transformer model, CoTracker3. We utilized a custom-designed, portable isotonic biaxial apparatus compatible with multiphoton microscopy (MPM) to demonstrate this approach, successfully tracking natural bladder lumen textures without artificial markers. Benchmark tests validated the method's high pixel accuracy and low strain errors. Our framework effectively captured heterogeneous deformation patterns, despite complex folding and buckling, which conventional DIC often fails to track. Application to in vitro active bladder contractions in four rat specimens (n=4) revealed statistically significant anisotropy (p<0.01), with higher contraction longitudinally compared to circumferentially. Multiphoton microscopy further illustrated and confirmed heterogeneous morphological changes, such as large fold formation during active contraction. This non-invasive approach eliminates speckle-induced artifacts, enabling more physiologically relevant measurements, and has broad applicability for material testing of other biological and engineered systems.

</details>


### [389] [Online Estimation and Manipulation of Articulated Objects](https://arxiv.org/abs/2601.01438)
*Russell Buchanan,Adrian Röfer,João Moura,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

Relevance: 25.0

TL;DR: 提出一种结合视觉先验和本体感知的因子图方法，用于在线估计铰接物体运动学，实现机器人自主操作未知铰接物体


<details>
  <summary>Details</summary>
Motivation: 服务机器人需要能够操作任意铰接物体来完成日常家务任务。现有方法要么仅依赖视觉预测，要么需要先能操作物体才能估计运动学，缺乏结合两者的在线估计方法

Method: 使用因子图在线估计铰接运动，融合学习到的视觉先验和交互过程中的本体感知（运动学和力传感），基于螺旋理论建立分析模型

Result: 在仿真和真实机器人实验中广泛评估，实现了对未见抽屉的闭环估计和操作，真实硬件实验中达到75%的自主开启未知铰接物体成功率

Conclusion: 提出的融合视觉先验和本体感知的因子图方法能够有效在线估计铰接运动学，使机器人能够自主操作未知铰接物体

Abstract: From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.

</details>


### [390] [CONSENT: A Negotiation Framework for Leveraging User Flexibility in Vehicle-to-Building Charging under Uncertainty](https://arxiv.org/abs/2601.01581)
*Rishav Sen,Fangqi Liu,Jose Paolo Talusan,Ava Pettet,Yoshinori Suzue,Mark Bailey,Ayan Mukhopadhyay,Abhishek Dubey*

Main category: cs.MA

Relevance: 25.0

TL;DR: 提出基于谈判的电动汽车充电框架，通过激励措施协调建筑运营商和驾驶员利益，实现成本节约和资源共享


<details>
  <summary>Details</summary>
Motivation: 电动汽车快速增长导致车辆到建筑(V2B)场景中的冲突：建筑运营商面临无序充电的高昂能源成本，而驾驶员优先考虑便利性和充满电。需要解决这一利益冲突。

Method: 设计谈判框架，保证自愿参与、策略证明和预算可行性。通过提供激励措施，让驾驶员在出发时间或充电状态方面提供适度灵活性。使用用户调查数据进行校准，并用商业建筑和电动汽车制造商的真实运营数据进行验证。

Result: 模拟显示谈判协议创造了双赢结果：与优化的非谈判智能充电策略相比，建筑运营商成本降低超过3.5%，同时用户充电费用比公用事业零售能源费率降低22%。

Conclusion: 该框架通过协调运营商和电动汽车用户目标，为能源和移动系统之间提供了战略桥梁，将电动汽车充电从运营摩擦源转变为协作和共享节约的平台。

Abstract: The growth of Electric Vehicles (EVs) creates a conflict in vehicle-to-building (V2B) settings between building operators, who face high energy costs from uncoordinated charging, and drivers, who prioritize convenience and a full charge. To resolve this, we propose a negotiation-based framework that, by design, guarantees voluntary participation, strategy-proofness, and budget feasibility. It transforms EV charging into a strategic resource by offering drivers a range of incentive-backed options for modest flexibility in their departure time or requested state of charge (SoC). Our framework is calibrated with user survey data and validated using real operational data from a commercial building and an EV manufacturer. Simulations show that our negotiation protocol creates a mutually beneficial outcome: lowering the building operator's costs by over 3.5\% compared to an optimized, non-negotiating smart charging policy, while simultaneously reducing user charging expenses by 22\% below the utility's retail energy rate. By aligning operator and EV user objectives, our framework provides a strategic bridge between energy and mobility systems, transforming EV charging from a source of operational friction into a platform for collaboration and shared savings.

</details>


### [391] [Yukthi Opus: A Multi-Chain Hybrid Metaheuristic for Large-Scale NP-Hard Optimization](https://arxiv.org/abs/2601.01832)
*SB Danush Vikraman,Hannah Abagail,Prasanna Kesavraj,Gajanan V Honnavar*

Main category: cs.NE

Relevance: 25.0

TL;DR: Yukthi Opus (YO) 是一种用于NP难优化问题的多链混合元启发式算法，在显式评估预算约束下工作，结合了MCMC全局探索、贪婪局部搜索和自适应模拟退火机制。


<details>
  <summary>Details</summary>
Motivation: 针对昂贵黑盒优化问题（如超参数调优、神经架构搜索），需要在有限评估预算内有效解决NP难优化问题，平衡探索与利用，避免陷入局部最优。

Method: 采用两阶段架构：1) 燃烧阶段分配评估预算进行概率探索；2) 混合优化循环结合MCMC全局探索、贪婪局部搜索、自适应模拟退火。还包含空间黑名单机制避免重复评估差区域，以及多链执行策略提高鲁棒性。

Result: 在Rastrigin函数(5D)、旅行商问题(50-200城市)和Rosenbrock函数(5D)上评估，与CMA-ES、贝叶斯优化和加速粒子群优化比较。结果显示MCMC探索和贪婪细化对解质量关键，模拟退火和多链执行主要提高稳定性和减少方差。

Conclusion: YO在大型多模态问题上具有竞争力，同时保持可预测的评估预算，适用于昂贵的黑盒优化场景。

Abstract: We present Yukthi Opus (YO), a multi-chain hybrid metaheuristic designed for NP-hard optimization under explicit evaluation budget constraints. YO integrates three complementary mechanisms in a structured two-phase architecture: Markov Chain Monte Carlo (MCMC) for global exploration, greedy local search for exploitation, and simulated annealing with adaptive reheating to enable controlled escape from local minima. A dedicated burn-in phase allocates evaluations to probabilistic exploration, after which a hybrid optimization loop refines promising candidates. YO further incorporates a spatial blacklist mechanism to avoid repeated evaluation of poor regions and a multi-chain execution strategy to improve robustness and reduce sensitivity to initialization.
  We evaluate YO on three benchmarks: the Rastrigin function (5D) with ablation studies, the Traveling Salesman Problem with 50 to 200 cities, and the Rosenbrock function (5D) with comparisons against established optimizers including CMA-ES, Bayesian optimization, and accelerated particle swarm optimization. Results show that MCMC exploration and greedy refinement are critical for solution quality, while simulated annealing and multi-chain execution primarily improve stability and variance reduction. Overall, YO achieves competitive performance on large and multimodal problems while maintaining predictable evaluation budgets, making it suitable for expensive black-box optimization settings.

</details>


### [392] [Inferring Network Evolutionary History via Structure-State Coupled Learning](https://arxiv.org/abs/2601.02121)
*En Xu,Shihe Zhou,Huandong Wang,Jingtao Ding,Yong Li*

Main category: cs.SI

Relevance: 25.0

TL;DR: CS²利用网络稳态动力学（节点在特定动态过程下的收敛状态）作为额外观测信号，结合拓扑结构推断网络演化历史，显著提升了边形成顺序恢复的准确性。


<details>
  <summary>Details</summary>
Motivation: 从单一最终快照推断网络演化历史是基础但具有挑战性的问题。现有方法主要依赖拓扑结构，但这通常提供的信息不足且噪声较大。本文提出利用网络稳态动力学作为额外且广泛可获取的观测信号来改进演化历史推断。

Method: 提出CS²方法，显式建模结构-状态耦合，捕捉拓扑如何调节稳态以及这两种信号如何共同提升边形成顺序恢复的判别能力。方法考虑了多种动态过程，并在拓扑信息有限时仍能保持竞争力。

Result: 在6个真实时序网络上，CS²在多种动态过程下均优于基线方法：边对优先准确率平均提升4.0%，全局排序一致性（Spearman-ρ）平均提升7.7%。同时能更准确地恢复宏观演化轨迹，如聚类形成、度异质性和中心节点增长。

Conclusion: 网络稳态动力学是推断网络演化历史的有效补充信号，CS²方法通过结合拓扑和稳态信息显著提升了演化历史恢复的准确性，即使在拓扑信息有限时，仅使用稳态信息的变体仍能保持竞争力。

Abstract: Inferring a network's evolutionary history from a single final snapshot with limited temporal annotations is fundamental yet challenging. Existing approaches predominantly rely on topology alone, which often provides insufficient and noisy cues. This paper leverages network steady-state dynamics -- converged node states under a given dynamical process -- as an additional and widely accessible observation for network evolution history inference. We propose CS$^2$, which explicitly models structure-state coupling to capture how topology modulates steady states and how the two signals jointly improve edge discrimination for formation-order recovery. Experiments on six real temporal networks, evaluated under multiple dynamical processes, show that CS$^2$ consistently outperforms strong baselines, improving pairwise edge precedence accuracy by 4.0% on average and global ordering consistency (Spearman-$ρ$) by 7.7% on average. CS$^2$ also more faithfully recovers macroscopic evolution trajectories such as clustering formation, degree heterogeneity, and hub growth. Moreover, a steady-state-only variant remains competitive when reliable topology is limited, highlighting steady states as an independent signal for evolution inference.

</details>


### [393] [Placenta Accreta Spectrum Detection using Multimodal Deep Learning](https://arxiv.org/abs/2601.00907)
*Sumaiya Ali,Areej Alhothali,Sameera Albasri,Ohoud Alzamzami,Ahmed Abduljabbar,Muhammad Alwazzan*

Main category: eess.IV

Relevance: 15.0

TL;DR: 该研究开发了一个多模态深度学习框架，通过融合3D MRI和2D超声图像来增强胎盘植入谱系（PAS）的产前诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 胎盘植入谱系（PAS）是一种危及生命的产科并发症，需要早期准确的产前诊断来降低母婴风险。目前单模态影像诊断存在局限性，需要整合多模态影像信息来提高诊断准确性。

Method: 采用中间特征级融合架构，结合3D MRI（使用3D DenseNet121-Vision Transformer）和2D超声（使用ResNet50）的特征提取器。使用1,293个MRI和1,143个超声扫描训练单模态模型，并用患者匹配的MRI-US配对样本进行多模态模型开发和评估。

Result: 多模态融合模型在独立测试集上表现最佳：准确率92.5%，AUC 0.927，显著优于MRI单模态（82.5%，AUC 0.825）和超声单模态（87.5%，AUC 0.879）。

Conclusion: 融合MRI和超声特征能提供互补的诊断信息，具有增强产前风险评估和改善患者预后的强大潜力。

Abstract: Placenta Accreta Spectrum (PAS) is a life-threatening obstetric complication involving abnormal placental invasion into the uterine wall. Early and accurate prenatal diagnosis is essential to reduce maternal and neonatal risks. This study aimed to develop and validate a deep learning framework that enhances PAS detection by integrating multiple imaging modalities. A multimodal deep learning model was designed using an intermediate feature-level fusion architecture combining 3D Magnetic Resonance Imaging (MRI) and 2D Ultrasound (US) scans. Unimodal feature extractors, a 3D DenseNet121-Vision Transformer for MRI and a 2D ResNet50 for US, were selected after systematic comparative analysis. Curated datasets comprising 1,293 MRI and 1,143 US scans were used to train the unimodal models and paired samples of patient-matched MRI-US scans was isolated for multimodal model development and evaluation. On an independent test set, the multimodal fusion model achieved superior performance, with an accuracy of 92.5% and an Area Under the Receiver Operating Characteristic Curve (AUC) of 0.927, outperforming the MRI-only (82.5%, AUC 0.825) and US-only (87.5%, AUC 0.879) models. Integrating MRI and US features provides complementary diagnostic information, demonstrating strong potential to enhance prenatal risk assessment and improve patient outcomes.

</details>


### [394] [Comparative Analysis of Formula and Structure Prediction from Tandem Mass Spectra](https://arxiv.org/abs/2601.00941)
*Xujun Che,Xiuxia Du,Depeng Xu*

Main category: q-bio.QM

Relevance: 15.0

TL;DR: 该论文对基于LC-MS/MS的代谢组学和暴露组学中的化合物预测算法进行了系统评估，建立了性能基准并识别了关键瓶颈


<details>
  <summary>Details</summary>
Motivation: LC-MS/MS技术能够检测生物样本中的小分子，但现有光谱库无法覆盖所有化学空间，大多数信号无法通过传统库搜索识别。需要评估现有预测算法以指导实际应用和进一步改进。

Method: 对最先进的预测算法进行系统评估，针对不同类型的加合物评估分子式预测和结构预测的准确性，使用不同的数据集和评估方法。

Result: 建立了现实的性能基准，识别了关键瓶颈，为基于MS的化合物预测提供了改进指导。

Conclusion: 该研究为代谢组学和暴露组学中化合物预测算法的选择提供了系统评估框架，指出了进一步改进的方向。

Abstract: Liquid chromatography mass spectrometry (LC-MS)-based metabolomics and exposomics aim to measure detectable small molecules in biological samples. The results facilitate hypothesis-generating discovery of metabolic changes and disease mechanisms and provide information about environmental exposures and their effects on human health. Metabolomics and exposomics are made possible by the high resolving power of LC and high mass measurement accuracy of MS. However, a majority of the signals from such studies still cannot be identified or annotated using conventional library searching because existing spectral libraries are far from covering the vast chemical space captured by LC-MS/MS. To address this challenge and unleash the full potential of metabolomics and exposomics, a number of computational approaches have been developed to predict compounds based on tandem mass spectra. Published assessment of these approaches used different datasets and evaluation. To select prediction workflows for practical applications and identify areas for further improvements, we have carried out a systematic evaluation of the state-of-the-art prediction algorithms. Specifically, the accuracy of formula prediction and structure prediction was evaluated for different types of adducts. The resulting findings have established realistic performance baselines, identified critical bottlenecks, and provided guidance to further improve compound predictions based on MS.

</details>


### [395] [The Optimal Sample Complexity of Linear Contracts](https://arxiv.org/abs/2601.01496)
*Mikael Møller Høgsgaard*

Main category: cs.GT

Relevance: 15.0

TL;DR: 该论文解决了离线设置下从数据中学习最优线性合约的问题，证明了经验效用最大化算法能以最优样本复杂度获得近似最优解。


<details>
  <summary>Details</summary>
Motivation: 在委托代理问题中，委托人需要设计合约来激励代理人，但代理人类型分布未知。离线学习最优线性合约具有重要实际意义，但现有方法的样本复杂度不够优化。

Method: 采用经验效用最大化算法，利用线性合约的期望收益非递减这一结构特性，通过链式论证构建精细网格，实现最优样本复杂度分析。

Result: 证明EUM算法仅需O(ln(1/δ)/ε²)样本就能以至少1-δ概率获得ε近似最优线性合约，匹配已知下界，达到最优样本复杂度。

Conclusion: 该工作确立了线性合约离线学习的最优样本复杂度，揭示了线性合约的结构特性如何简化学习问题，为合约设计提供了理论保证。

Abstract: In this paper, we settle the problem of learning optimal linear contracts from data in the offline setting, where agent types are drawn from an unknown distribution and the principal's goal is to design a contract that maximizes her expected utility. Specifically, our analysis shows that the simple Empirical Utility Maximization (EUM) algorithm yields an $\varepsilon$-approximation of the optimal linear contract with probability at least $1-δ$, using just $O(\ln(1/δ) / \varepsilon^2)$ samples. This result improves upon previously known bounds and matches a lower bound from Duetting et al. [2025] up to constant factors, thereby proving its optimality. Our analysis uses a chaining argument, where the key insight is to leverage a simple structural property of linear contracts: their expected reward is non-decreasing. This property, which holds even though the utility function itself is non-monotone and discontinuous, enables the construction of fine-grained nets required for the chaining argument, which in turn yields the optimal sample complexity. Furthermore, our proof establishes the stronger guarantee of uniform convergence: the empirical utility of every linear contract is a $\varepsilon$-approximation of its true expectation with probability at least $1-δ$, using the same optimal $O(\ln(1/δ) / \varepsilon^2)$ sample complexity.

</details>


### [396] [UniCrop: A Universal, Multi-Source Data Engineering Pipeline for Scalable Crop Yield Prediction](https://arxiv.org/abs/2601.01655)
*Emiliya Khidirova,Oktay Karakuş*

Main category: eess.IV

Relevance: 15.0

TL;DR: UniCrop是一个通用的作物产量预测数据管道，能自动获取、清洗和整合多源环境数据，通过特征选择减少到15个关键特征，在四个基线模型上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有作物产量预测方法存在局限性：1) 针对特定作物或区域，缺乏通用性；2) 需要大量数据工程工作；3) 限制了可扩展性、可重复性和实际部署。这阻碍了农业分析的大规模应用。

Method: 开发了UniCrop通用数据管道：1) 自动获取卫星(Sentinel-1/2, MODIS)、气象(ERA5-Land, NASA POWER)、土壤(SoilGrids)和地形(SRTM)等200多个环境变量；2) 使用结构化特征降维流程，基于最小冗余最大相关性(mRMR)方法将特征减少到紧凑的分析就绪特征集；3) 支持通过简单配置更新适应任何作物、区域和时间范围。

Result: 在包含557个田间观测的水稻产量数据集上验证：1) 仅使用选出的15个特征，四个基线模型(LightGBM、随机森林、支持向量回归、弹性网络)表现良好；2) LightGBM获得最佳单模型性能(RMSE = 465.1 kg/ha, R² = 0.6576)；3) 所有基线的约束集成进一步提高了准确性(RMSE = 463.2 kg/ha, R² = 0.6604)。

Conclusion: UniCrop提供了一个可扩展且透明的数据工程框架，解决了作物产量建模中的主要瓶颈：一致且协调的多源数据准备。通过将数据规范与实现解耦，为可扩展的农业分析提供了实用基础。

Abstract: Accurate crop yield prediction relies on diverse data streams, including satellite, meteorological, soil, and topographic information. However, despite rapid advances in machine learning, existing approaches remain crop- or region-specific and require data engineering efforts. This limits scalability, reproducibility, and operational deployment. This study introduces UniCrop, a universal and reusable data pipeline designed to automate the acquisition, cleaning, harmonisation, and engineering of multi-source environmental data for crop yield prediction. For any given location, crop type, and temporal window, UniCrop automatically retrieves, harmonises, and engineers over 200 environmental variables (Sentinel-1/2, MODIS, ERA5-Land, NASA POWER, SoilGrids, and SRTM), reducing them to a compact, analysis-ready feature set utilising a structured feature reduction workflow with minimum redundancy maximum relevance (mRMR). To validate, UniCrop was applied to a rice yield dataset comprising 557 field observations. Using only the selected 15 features, four baseline machine learning models (LightGBM, Random Forest, Support Vector Regression, and Elastic Net) were trained. LightGBM achieved the best single-model performance (RMSE = 465.1 kg/ha, $R^2 = 0.6576$), while a constrained ensemble of all baselines further improved accuracy (RMSE = 463.2 kg/ha, $R^2 = 0.6604$). UniCrop contributes a scalable and transparent data-engineering framework that addresses the primary bottleneck in operational crop yield modelling: the preparation of consistent and harmonised multi-source data. By decoupling data specification from implementation and supporting any crop, region, and time frame through simple configuration updates, UniCrop provides a practical foundation for scalable agricultural analytics. The code and implementation documentation are shared in https://github.com/CoDIS-Lab/UniCrop.

</details>


### [397] [The Machine Learning Canvas: Empirical Findings on Why Strategy Matters More Than AI Code Generation](https://arxiv.org/abs/2601.01839)
*Martin Prause*

Main category: cs.SE

Relevance: 15.0

TL;DR: 论文提出了机器学习画布框架，结合商业战略、软件工程和数据科学，识别了ML项目成功的四个关键因素：战略、流程、生态系统和支持，发现这些因素相互关联，AI编码助手虽能加速编码但不能保证项目成功。


<details>
  <summary>Details</summary>
Motivation: 尽管AI编码助手日益流行，但超过80%的机器学习项目未能交付实际商业价值。本研究旨在创建一个实用的框架，结合商业战略、软件工程和数据科学，确定导致ML项目成功的关键因素。

Method: 研究创建并测试了机器学习画布框架，调查了150名数据科学家，并使用统计建模分析他们的回答，识别影响ML项目成功的关键因素。

Result: 识别出四个关键成功因素：战略（清晰的目标和规划）、流程（工作执行方式）、生态系统（工具和基础设施）和支持（组织支持和资源）。这些因素相互关联，每个因素影响下一个。例如，强大的组织支持导致更清晰的战略（β=0.432, p<0.001），进而改善工作流程（β=0.428, p<0.001）并建立更好的基础设施（β=0.547, p<0.001）。

Conclusion: AI编码助手虽然使编码更快，但不能保证项目成功。AI协助"如何"编码，但不能替代战略思考的"为什么"和"什么"。项目成功需要战略、流程、生态系统和支持四个因素的有机结合。

Abstract: Despite the growing popularity of AI coding assistants, over 80% of machine learning (ML) projects fail to deliver real business value. This study creates and tests a Machine Learning Canvas, a practical framework that combines business strategy, software engineering, and data science in order to determine the factors that lead to the success of ML projects. We surveyed 150 data scientists and analyzed their responses using statistical modeling. We identified four key success factors: Strategy (clear goals and planning), Process (how work gets done), Ecosystem (tools and infrastructure), and Support (organizational backing and resources). Our results show that these factors are interconnected - each one affects the next. For instance, strong organizational support results in a clearer strategy (β= 0.432, p < 0.001), which improves work processes (β= 0.428, p < 0.001) and builds better infrastructure (β= 0.547, p < 0.001). Together, these elements determine whether a project succeeds. The surprising finding? Although AI assistants make coding faster, they don't guarantee project success. AI assists with the "how" of coding but cannot replace the "why" and "what" of strategic thinking.

</details>


### [398] [A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach](https://arxiv.org/abs/2601.01921)
*Mikel Robredo,Matteo Esposito,Fabio Palomba,Rafael Peñaloza,Valentina Lenarduzzi*

Main category: cs.SE

Relevance: 15.0

TL;DR: 该论文研究软件缺陷预测中的时间敏感方法，旨在探索缺陷预测的时间敏感性技术，并识别缺陷发生前的早期指标。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统持续演化，需要能够预测缺陷的时间敏感方法。现有研究已能准确预测即将发生的故障，但需要更早的预测能力。

Method: 训练多种时间敏感预测技术来预测软件项目的未来缺陷密度，并识别缺陷发生前的早期症状。

Result: 预期结果为早期评估软件缺陷倾向性提供实证证据，展示时间敏感预测方法的有效性。

Conclusion: 该研究将提供关于时间敏感缺陷预测技术有效性的实证证据，有助于更早地识别软件缺陷。

Abstract: Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest.
  Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect.
  Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect.
  Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.

</details>


### [399] [Visualizing the Structure of Lenia Parameter Space](https://arxiv.org/abs/2601.01932)
*Barbora Hudcová,František Dušek,Marco Tuccio,Clément Hongler*

Main category: nlin.CG

Relevance: 15.0

TL;DR: 提出了一种自动分类Lenia系统到四种不同动力学类别的新方法，用于检测移动孤子，并提供了Lenia参数空间结构的交互式可视化


<details>
  <summary>Details</summary>
Motivation: 连续元胞自动机（特别是Lenia）越来越受欢迎，但对其行为的理论理解仍然是一个挑战。存在几个基本开放问题：确定孤子的确切构成、参数空间的整体结构、以及孤子在参数空间中的位置

Method: 开发了一种新方法来自动将Lenia系统分类为四种定性不同的动力学类别，从而能够检测移动孤子，并创建了参数空间结构的交互式可视化工具

Result: 在原本认为不存在孤子的参数区域发现了新的孤子族，并观察到不同核函数下相空间结构的普遍性

Conclusion: 该方法为理解Lenia的动力学行为提供了新视角，解决了关于孤子定义、参数空间结构和孤子分布的基本问题

Abstract: Continuous cellular automata are rocketing in popularity, yet developing a theoretical understanding of their behaviour remains a challenge. In the case of Lenia, a few fundamental open problems include determining what exactly constitutes a soliton, what is the overall structure of the parameter space, and where do the solitons occur in it. In this abstract, we present a new method to automatically classify Lenia systems into four qualitatively different dynamical classes. This allows us to detect moving solitons, and to provide an interactive visualization of Lenia's parameter space structure on our website https://lenia-explorer.vercel.app/. The results shed new light on the above-mentioned questions and lead to several observations: the existence of new soliton families for parameters where they were not believed to exist, or the universality of the phase space structure across various kernels.

</details>


### [400] [Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots](https://arxiv.org/abs/2601.02085)
*Meili Sun,Chunjiang Zhao,Lichao Yang,Hao Liu,Shimin Hu,Ya Xiong*

Main category: cs.RO

Relevance: 15.0

TL;DR: 提出了一种草莓采摘机器人的视觉故障诊断与自恢复框架，通过SRR-Net多任务感知模型集成草莓检测、分割和成熟度估计，结合误差补偿和早期中止策略解决采摘过程中的定位偏差、空抓和果实滑落问题。


<details>
  <summary>Details</summary>
Motivation: 草莓采摘机器人面临视觉感知集成度低、果实-夹爪错位、空抓和果实滑落等挑战，这些问题影响了果园环境中采摘的稳定性和效率。

Method: 1) 提出SRR-Net端到端多任务感知模型，同时执行草莓检测、分割和成熟度估计；2) 基于同时目标-夹爪检测的相对误差补偿方法解决位置错位；3) 早期中止策略防止空抓和果实滑落；4) 末端执行器嵌入微光学相机提供实时视觉反馈，使用MobileNet V3-Small和LSTM分类器进行抓取检测和滑落预测。

Result: SRR-Net在检测任务上对草莓达到精度0.895/召回0.813，对手部达到0.972/0.958；分割任务上对草莓达到精度0.887/召回0.747，对手部达到0.974/0.947；成熟度估计平均绝对误差0.035；同时支持多任务感知并保持163.35 FPS的推理速度。

Conclusion: 该框架通过集成多任务感知与纠正控制策略，有效解决了草莓采摘机器人的视觉故障问题，提高了采摘稳定性和效率。

Abstract: Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.

</details>


### [401] [SingingBot: An Avatar-Driven System for Robotic Face Singing Performance](https://arxiv.org/abs/2601.02125)
*Zhuoxiong Xu,Xuanchen Li,Yuhao Cheng,Fei Xu,Yichao Yan,Xiaokang Yang*

Main category: cs.RO

Relevance: 15.0

TL;DR: 提出一种用于机器人歌唱表演的虚拟形象驱动框架，通过视频生成模型合成生动的歌唱虚拟形象，再通过语义映射将面部特征转移到机器人上，同时提出情感动态范围指标来量化评估歌唱情感丰富度。


<details>
  <summary>Details</summary>
Motivation: 现有机器人面部驱动研究主要关注对话或静态表情模仿，难以满足歌唱中连续情感表达和一致性的高要求。需要为机器人歌唱开发能够产生丰富情感表达的方法。

Method: 1) 利用嵌入人类先验知识的肖像视频生成模型合成生动的歌唱虚拟形象，提供可靠的表情和情感指导；2) 通过语义导向的映射函数将面部特征转移到机器人上，覆盖广泛的表达空间；3) 提出情感动态范围指标来量化评估歌唱情感丰富度。

Result: 综合实验证明，该方法在保持唇音同步的同时实现了丰富的情感表达，显著优于现有方法。情感动态范围指标揭示了宽广的情感谱对吸引人表演的重要性。

Conclusion: 提出的虚拟形象驱动框架能够为机器人歌唱产生吸引人的表演，通过视频生成模型和语义映射实现了丰富的情感表达，同时提出的评估指标为机器人情感表达提供了量化标准。

Abstract: Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.

</details>


### [402] [A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts](https://arxiv.org/abs/2601.01467)
*Romuald Kwessy Mouona,Blaise Blériot Koguep Njionou,Etienne Romuald Temgoua Alomo,Rokia Missaoui,Leonard Kwuida*

Main category: cs.AI

Relevance: 5.0

TL;DR: 该论文研究三元背景中的蕴涵关系，特别是Ganter和Obiedkov提出的条件属性蕴涵和属性条件蕴涵，目标是构建这些蕴涵的最优基


<details>
  <summary>Details</summary>
Motivation: 三元背景中的蕴涵关系在形式概念分析中具有重要意义，但现有研究对Ganter和Obiedkov提出的条件属性蕴涵和属性条件蕴涵的最优基构造问题尚未充分解决

Method: 采用形式概念分析的理论框架，基于三元背景的数学结构，研究条件属性蕴涵和属性条件蕴涵的性质，并设计构建最优基的算法

Result: 提出了构建条件属性蕴涵和属性条件蕴涵最优基的系统方法，为三元背景中的蕴涵关系提供了理论基础和算法支持

Conclusion: 该研究完善了三元背景中蕴涵关系的理论体系，为形式概念分析领域提供了新的工具和方法

Abstract: This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [403] [You Only Need Your Transformer 25% of the Time: Meaning-First Execution for Eliminating Unnecessary Inference](https://arxiv.org/abs/2601.00847)
*Ryan Shamim*

Main category: cs.LG

Relevance: 85.0

TL;DR: MFEE框架将Transformer推理重构为控制平面决策问题，通过语义分析选择性执行，在保持100%准确率的同时减少78.1%的计算量。


<details>
  <summary>Details</summary>
Motivation: 当前AI推理系统将Transformer执行视为强制性的，混淆了模型能力与执行必要性。作者认为许多推理任务可以通过替代路径保持正确性，无需执行完整Transformer。

Method: 提出Meaning-First Execution (MFEE)控制平面架构，作为现有堆栈之上的门控层，不修改模型权重或参数。通过语义分析决定何时需要执行Transformer推理，何时可以通过替代路径保持正确性。

Result: 在1000个多样化提示的确定性解码下，MFEE实现78.1%的执行减少，同时保持100%的精确匹配等效性。相比模式路由器最多53.3%的避免率且存在正确性失败，MFEE通过语义分析实现100%避免且零失败。

Conclusion: 证明了基于有限特征映射的路由器无法同时保证零错误跳过和正避免率，确立了执行治理作为ML系统基础设施的基础层，与模型级优化技术正交。

Abstract: Modern AI inference systems treat transformer execution as mandatory, conflating model capability with execution necessity. We reframe inference as a control-plane decision problem: determining when execution is necessary versus when correctness can be preserved through alternative pathways. We introduce Meaning-First Execution (MFEE), a control-plane architecture implementing this framework, selectively invoking transformer inference only when required. MFEE operates as a gating layer above existing stacks without modifying models, weights, or parameters. Across 1,000 diverse prompts under deterministic decoding, MFEE achieves 78.1% execution reduction while maintaining 100% exact-match equivalence for invoked executions. Comparative evaluation reveals pattern-based routers achieve at most 53.3% avoidance with correctness failures, while MFEE reaches 100% avoidance with zero failures through semantic analysis. We prove this limitation via Theorem 1: any router operating solely on finite feature maps cannot simultaneously guarantee zero false skips and positive avoidance on feature-collision pairs. These results establish execution governance as a foundational layer in ML systems infrastructure, orthogonal to model-level optimization techniques.

</details>


### [404] [EdgeJury: Cross-Reviewed Small-Model Ensembles for Truthful Question Answering on Serverless Edge Inference](https://arxiv.org/abs/2601.00850)
*Aayush Kumar*

Main category: cs.LG

Relevance: 85.0

TL;DR: EdgeJury：一个轻量级集成框架，使用小型指令调优语言模型（3B-8B）通过四阶段协调流程（并行角色生成、匿名交叉评审、主席合成、一致性标记）提高问答的真实性和鲁棒性，在TruthfulQA上实现76.2%准确率，相比单个8B模型提升21.4%。


<details>
  <summary>Details</summary>
Motivation: 幻觉问题阻碍了可靠问答，特别是在资源受限的边缘部署场景中，前沿规模模型或检索管道可能不实用。需要一种轻量级解决方案，仅使用适合无服务器边缘推理的小型语言模型来提高真实性和鲁棒性。

Method: EdgeJury采用四阶段框架：1）并行角色专业化生成，2）匿名交叉评审（结构化批评和排名），3）主席合成（整合最强内容并解决标记问题），4）基于模型间一致性的声明级一致性标记。该框架协调多个小型指令调优语言模型（3B-8B），无需外部检索或专有大型模型API。

Result: 在TruthfulQA（MC1）上达到76.2%准确率（95% CI: 72.8-79.6%），相比单个8B基线（62.8%）提升21.4%，优于自一致性和多数投票等标准基线。在200个问题的对抗性EdgeCases集上获得48.2%相对增益。人工分析显示事实性幻觉错误减少约55%。在Cloudflare Workers AI上部署，实现8.4秒中位端到端延迟。

Conclusion: 协调的小型模型集成可以在不依赖外部检索或专有大型模型API的情况下，显著提高在误解密集型问答基准上的真实性，为资源受限的边缘部署提供了实用的解决方案。

Abstract: Hallucinations hinder reliable question answering, especially in resource-constrained deployments where frontier-scale models or retrieval pipelines may be impractical. We present EdgeJury, a lightweight ensemble framework that improves truthfulness and robustness using only small instruction-tuned language models (3B-8B) suitable for serverless edge inference. EdgeJury orchestrates four stages: (1) parallel role-specialized generation, (2) anonymized cross-review with structured critiques and rankings, (3) chairman synthesis that integrates the strongest content while addressing flagged issues, and (4) claim-level consistency labeling based on inter-model agreement. On TruthfulQA (MC1), EdgeJury achieves 76.2% accuracy (95% CI: 72.8-79.6%), a +21.4% relative improvement over a single 8B baseline (62.8%), and outperforms standard baselines including self-consistency and majority voting under transparent compute accounting (total tokens and platform cost reported). On a 200-question adversarial EdgeCases set, EdgeJury yields +48.2% relative gains (95% CI: 44.0-52.4%). Manual analysis on 100 incorrect answers shows an approximately 55% reduction in factual hallucination errors versus the single-model baseline. Deployed on Cloudflare Workers AI, EdgeJury achieves 8.4 s median end-to-end latency, demonstrating that coordinated small-model ensembles can improve truthfulness on misconception-heavy QA benchmarks without external retrieval or proprietary large-model APIs.

</details>


### [405] [LLMize: A Framework for Large Language Model-Based Numerical Optimization](https://arxiv.org/abs/2601.00874)
*M. Rizki Oktavian*

Main category: cs.LG

Relevance: 85.0

TL;DR: LLMize是一个开源Python框架，通过迭代提示和上下文学习实现LLM驱动的优化，将优化问题转化为黑盒过程，支持多种优化策略，特别适合复杂领域特定任务。


<details>
  <summary>Details</summary>
Motivation: LLM最近展现出超越传统语言任务的强大推理能力，这激发了将其用于数值优化的动机。传统优化方法需要数学编程或元启发式设计专业知识，而LLMize旨在通过自然语言描述让从业者能够定义复杂优化问题。

Method: LLMize将优化建模为黑盒过程：候选解以自然语言生成，通过外部目标函数评估，并使用解-分数反馈在连续迭代中精炼。支持多种优化策略，包括优化提示（OPRO）以及受进化算法和模拟退火启发的混合LLM方法。

Result: 在凸优化、线性规划、旅行商问题、神经网络超参数调优和核燃料晶格优化上的评估显示，对于简单问题，LLM优化不如经典求解器有竞争力，但对于复杂、领域特定的任务，它提供了一种实用且可访问的方法。

Conclusion: LLMize为复杂、领域特定的优化任务提供了一个实用框架，特别是当约束和启发式难以形式化时。它通过自然语言描述使优化更易访问，但传统方法在简单问题上仍占优势。

Abstract: Large language models (LLMs) have recently shown strong reasoning capabilities beyond traditional language tasks, motivating their use for numerical optimization. This paper presents LLMize, an open-source Python framework that enables LLM-driven optimization through iterative prompting and in-context learning. LLMize formulates optimization as a black-box process in which candidate solutions are generated in natural language, evaluated by an external objective function, and refined over successive iterations using solution-score feedback. The framework supports multiple optimization strategies, including Optimization by Prompting (OPRO) and hybrid LLM-based methods inspired by evolutionary algorithms and simulated annealing. A key advantage of LLMize is the ability to inject constraints, rules, and domain knowledge directly through natural language descriptions, allowing practitioners to define complex optimization problems without requiring expertise in mathematical programming or metaheuristic design. LLMize is evaluated on convex optimization, linear programming, the Traveling Salesman Problem, neural network hyperparameter tuning, and nuclear fuel lattice optimization. Results show that while LLM-based optimization is not competitive with classical solvers for simple problems, it provides a practical and accessible approach for complex, domain-specific tasks where constraints and heuristics are difficult to formalize.

</details>


### [406] [When to Ponder: Adaptive Compute Allocation for Code Generation via Test-Time Training](https://arxiv.org/abs/2601.00894)
*Gihyeon Sim*

Main category: cs.LG

Relevance: 85.0

TL;DR: PonderTTT：一种基于自监督重建损失的训练无关门控策略，用于选择性触发测试时训练更新，在代码语言建模中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型对所有输入应用统一计算，不考虑难度差异。作者希望开发一种能根据输入难度自适应调整计算资源的机制，实现更高效的推理。

Method: 提出PonderTTT门控策略，利用TTT层的自监督重建损失作为门控信号。门控决策完全训练无关，无需学习分类器或辅助网络，仅需在未标记数据上校准单个标量阈值，并通过EMA持续适应以维持目标更新率。

Result: 在GPT-2模型（124M到1.5B）的代码语言建模实验中，该方法实现了82-89%的Oracle恢复率，完全训练无关，显著优于随机跳过基线（在OOD语言上损失降低达16%）。

Conclusion: 自监督重建损失可作为有效的推理兼容门控信号，实现训练无关的选择性测试时训练更新，显著提升模型在分布外数据上的性能。

Abstract: Large language models apply uniform computation to all inputs, regardless of difficulty. We propose PonderTTT, a gating strategy using the TTT layer's self-supervised reconstruction loss to selectively trigger Test-Time Training (TTT) updates. The gating decision itself is training-free--requiring no learned classifier or auxiliary networks; only a single scalar threshold is initially calibrated on unlabeled data and continuously adapted via EMA to maintain target update rates. Our experiments with GPT-2 models (124M to 1.5B) on code language modeling (The Stack v2, teacher-forced perplexity) demonstrate that this signal is inference-compatible, requiring no ground-truth labels. Our Reconstruction Gating achieves 82-89% Oracle Recovery while being fully training-free, significantly outperforming Random Skip baselines (up to 16% lower loss on OOD languages).

</details>


### [407] [Dichotomous Diffusion Policy Optimization](https://arxiv.org/abs/2601.00898)
*Ruiming Liang,Yinan Zheng,Kexin Zheng,Tianyi Tan,Jianxiong Li,Liyuan Mao,Zhihao Wang,Guang Chen,Hangjun Ye,Jingjing Liu,Jinqiao Wang,Xianyuan Zhan*

Main category: cs.LG

Relevance: 85.0

TL;DR: DIPOLE是一种新颖的强化学习算法，通过将最优策略分解为一对稳定学习的二分策略（一个最大化奖励，一个最小化奖励），解决了扩散策略在强化学习中训练不稳定的问题，并在推理时通过线性组合实现贪婪度的灵活控制。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在决策任务中表现出色，但在强化学习训练中存在挑战：现有方法要么因直接最大化价值目标而导致训练不稳定，要么因依赖粗糙的高斯似然近似而面临计算问题，需要大量足够小的去噪步骤。

Method: 重新审视RL中的KL正则化目标，提出贪婪化策略正则化方案，将最优策略分解为一对二分策略：一个专注于奖励最大化，另一个专注于奖励最小化。在推理时，通过线性组合这两个策略的分数来生成优化动作，实现对贪婪度的灵活控制。

Result: 在ExORL和OGBench的离线和离线到在线RL设置中评估显示方法有效。还使用DIPOLE训练了一个大型视觉-语言-动作模型用于端到端自动驾驶，并在大规模真实世界自动驾驶基准NAVSIM上评估，展示了其在复杂现实应用中的潜力。

Conclusion: DIPOLE为扩散策略的强化学习训练提供了稳定且可控的优化方法，通过二分策略分解实现了训练稳定性与推理灵活性的平衡，在多个基准测试和真实世界自动驾驶任务中表现出色。

Abstract: Diffusion-based policies have gained growing popularity in solving a wide range of decision-making tasks due to their superior expressiveness and controllable generation during inference. However, effectively training large diffusion policies using reinforcement learning (RL) remains challenging. Existing methods either suffer from unstable training due to directly maximizing value objectives, or face computational issues due to relying on crude Gaussian likelihood approximation, which requires a large amount of sufficiently small denoising steps. In this work, we propose DIPOLE (Dichotomous diffusion Policy improvement), a novel RL algorithm designed for stable and controllable diffusion policy optimization. We begin by revisiting the KL-regularized objective in RL, which offers a desirable weighted regression objective for diffusion policy extraction, but often struggles to balance greediness and stability. We then formulate a greedified policy regularization scheme, which naturally enables decomposing the optimal policy into a pair of stably learned dichotomous policies: one aims at reward maximization, and the other focuses on reward minimization. Under such a design, optimized actions can be generated by linearly combining the scores of dichotomous policies during inference, thereby enabling flexible control over the level of greediness.Evaluations in offline and offline-to-online RL settings on ExORL and OGBench demonstrate the effectiveness of our approach. We also use DIPOLE to train a large vision-language-action (VLA) model for end-to-end autonomous driving (AD) and evaluate it on the large-scale real-world AD benchmark NAVSIM, highlighting its potential for complex real-world applications.

</details>


### [408] [Attention Needs to Focus: A Unified Perspective on Attention Allocation](https://arxiv.org/abs/2601.00919)
*Zichuan Fu,Wentao Song,Guojing Li,Yejing Wang,Xian Wu,Yimin Deng,Hanyu Yan,Yefeng Zheng,Xiangyu Zhao*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文提出Lazy Attention机制，通过统一视角解决注意力机制中的表示崩溃和注意力下沉问题，采用位置区分和弹性Softmax实现更聚焦的注意力分布。


<details>
  <summary>Details</summary>
Motivation: Transformer注意力机制存在表示崩溃和注意力下沉两大问题，现有研究往往孤立处理这些问题。本文认为这两个问题有共同根源——不恰当的注意力分配，需要统一解决方案。

Method: 提出Lazy Attention机制：1) 通过跨头和维度的位置区分来缓解注意力过载；2) 引入弹性Softmax归一化函数来抑制对无关标记的关注，解决注意力欠载问题。

Result: 在FineWeb-Edu语料库上的实验表明，Lazy Attention成功缓解了注意力下沉问题，在九个不同基准测试中达到与标准注意力相当的竞争性能，注意力稀疏度最高达59.58%。

Conclusion: Lazy Attention提供了一种统一解决注意力分配问题的方法，通过更聚焦的注意力分布改善了Transformer架构的性能和效率。

Abstract: The Transformer architecture, a cornerstone of modern Large Language Models (LLMs), has achieved extraordinary success in sequence modeling, primarily due to its attention mechanism. However, despite its power, the standard attention mechanism is plagued by well-documented issues: representational collapse and attention sink. Although prior work has proposed approaches for these issues, they are often studied in isolation, obscuring their deeper connection. In this paper, we present a unified perspective, arguing that both can be traced to a common root -- improper attention allocation. We identify two failure modes: 1) Attention Overload, where tokens receive comparable high weights, blurring semantic features that lead to representational collapse; 2) Attention Underload, where no token is semantically relevant, yet attention is still forced to distribute, resulting in spurious focus such as attention sink. Building on this insight, we introduce Lazy Attention, a novel mechanism designed for a more focused attention distribution. To mitigate overload, it employs positional discrimination across both heads and dimensions to sharpen token distinctions. To counteract underload, it incorporates Elastic-Softmax, a modified normalization function that relaxes the standard softmax constraint to suppress attention on irrelevant tokens. Experiments on the FineWeb-Edu corpus, evaluated across nine diverse benchmarks, demonstrate that Lazy Attention successfully mitigates attention sink and achieves competitive performance compared to both standard attention and modern architectures, while reaching up to 59.58% attention sparsity.

</details>


### [409] [Reliability Under Randomness: An Empirical Analysis of Sparse and Dense Language Models Across Decoding Temperatures](https://arxiv.org/abs/2601.00942)
*Kabir Grover*

Main category: cs.LG

Relevance: 85.0

TL;DR: 研究发现，稀疏MoE架构在指令微调后，其解码稳定性与密集架构相当，而稀疏基础模型则随温度升高出现系统性退化，表明指令微调而非架构稀疏性是决定确定任务解码鲁棒性的关键因素。


<details>
  <summary>Details</summary>
Motivation: 随着稀疏MoE架构在大型语言模型中的普及，需要研究其在随机解码下的可靠性。虽然条件计算带来了计算效率提升，但稀疏路由与基于温度的采样之间的相互作用是否会损害输出稳定性尚不清楚。本研究旨在探究MoE模型中的条件计算是否会放大解码引起的随机性，导致随着温度升高可靠性降低。

Method: 评估三个代表性模型：OLMoE-7B（稀疏基础模型）、Mixtral-8x7B（稀疏指令微调模型）和Qwen2.5-3B（密集指令微调模型）。在具有客观可验证答案的确定性算术推理任务上进行实验，涵盖四种解码配置（从贪婪解码到T=1.0）。评估指标包括准确性、格式合规性、重复生成的输出一致性以及置信度指标，总计9,360次模型生成。

Result: 稀疏指令微调模型在所有解码温度下表现出与密集指令微调模型相当的稳定性，而稀疏基础模型则随着温度升高显示出系统性退化。这表明指令微调，而非架构稀疏性，是决定确定任务解码随机性鲁棒性的主要因素。

Conclusion: 指令微调是确保稀疏语言模型在确定性任务中解码稳定性的关键，而非架构稀疏性本身。这对于在可靠性关键应用中部署稀疏语言模型具有重要意义，表明在适当指令微调后，稀疏架构可以在不牺牲输出稳定性的情况下安全采用。

Abstract: The increasing prevalence of sparse Mixture-of-Experts (MoE) architectures in large language models raises important questions regarding their reliability under stochastic decoding. While conditional computation enables substantial gains in computational efficiency, it remains unclear whether the interaction between sparse routing and temperature-based sampling compromises output stability relative to dense architectures. This work investigates whether conditional computation in MoE models amplifies decoding-induced randomness, leading to reduced reliability as temperature increases. We evaluate three representative models: OLMoE-7B (sparse base), Mixtral-8x7B (sparse instruction-tuned), and Qwen2.5-3B (dense instruction-tuned) on deterministic arithmetic reasoning tasks with objectively verifiable answers. Experiments span four decoding configurations, ranging from greedy decoding to T=1.0. Our evaluation encompasses accuracy, format compliance, output consistency across repeated generations, and confidence metrics, totaling 9,360 model generations. Results demonstrate that the sparse instruction-tuned model exhibits stability comparable to the dense instruction-tuned model across all decoding temperatures, while the sparse base model shows systematic degradation as temperature increases. These findings indicate that instruction tuning, rather than architectural sparsity, is the primary determinant of robustness to decoding randomness on deterministic tasks. We discuss the implications of these results for deploying sparse language models in reliability-critical applications, highlighting scenarios in which sparse architectures can be safely adopted without sacrificing output stability.

</details>


### [410] [Explainability-Guided Defense: Attribution-Aware Model Refinement Against Adversarial Data Attacks](https://arxiv.org/abs/2601.00968)
*Longwei Wang,Mohammad Navid Nayyem,Abdullah Al Rakin,KC Santosh,Chaowei Zhang,Yang Zhou*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出了一种将LIME解释性分析转化为主动训练信号的框架，通过抑制虚假特征来同时提升模型对抗鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在医疗和自动驾驶等安全关键领域，深度学习模型需要同时具备对抗鲁棒性和决策透明度。研究发现，通过LIME识别出的虚假、不稳定或语义无关特征会显著增加对抗攻击的脆弱性。

Method: 提出基于归因引导的细化框架：1) 特征掩码抑制虚假特征；2) 敏感度感知正则化；3) 对抗性增强；4) 闭环细化流程。该方法将LIME从被动诊断工具转变为主动训练信号，无需额外数据集或模型架构。

Result: 在CIFAR-10、CIFAR-10-C和CIFAR-100数据集上的实验表明，该方法显著提升了对抗鲁棒性和分布外泛化能力。理论分析推导了归因感知的对抗扰动下界，形式化了解释对齐与鲁棒性之间的联系。

Conclusion: 该研究建立了可解释性与鲁棒性之间的直接联系，通过主动抑制虚假特征实现了双重提升，为构建更可信的AI系统提供了新思路。

Abstract: The growing reliance on deep learning models in safety-critical domains such as healthcare and autonomous navigation underscores the need for defenses that are both robust to adversarial perturbations and transparent in their decision-making. In this paper, we identify a connection between interpretability and robustness that can be directly leveraged during training. Specifically, we observe that spurious, unstable, or semantically irrelevant features identified through Local Interpretable Model-Agnostic Explanations (LIME) contribute disproportionately to adversarial vulnerability. Building on this insight, we introduce an attribution-guided refinement framework that transforms LIME from a passive diagnostic into an active training signal. Our method systematically suppresses spurious features using feature masking, sensitivity-aware regularization, and adversarial augmentation in a closed-loop refinement pipeline. This approach does not require additional datasets or model architectures and integrates seamlessly into standard adversarial training. Theoretically, we derive an attribution-aware lower bound on adversarial distortion that formalizes the link between explanation alignment and robustness. Empirical evaluations on CIFAR-10, CIFAR-10-C, and CIFAR-100 demonstrate substantial improvements in adversarial robustness and out-of-distribution generalization.

</details>


### [411] [Geometric and Dynamic Scaling in Deep Transformers](https://arxiv.org/abs/2601.01014)
*Haoran Su,Chenyu You*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文提出Transformer深度扩展中的表示崩溃问题本质上是几何问题，而非优化问题，并提出了流形几何Transformer（MGT）通过流形约束超连接和深度增量学习来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在经验上成功，但当扩展到极深层次时会出现表示崩溃现象：表示变得越来越冗余、失去秩并最终崩溃。现有解释主要归因于优化不稳定或梯度消失，但这些解释无法说明为什么在现代归一化和初始化方案下崩溃仍然持续。本文认为深度Transformer的崩溃本质上是几何问题。

Method: 提出了统一的几何框架，包含两个正交原则：1) 流形约束超连接：限制残差更新到有效的局部切向方向，防止不受控制的流形漂移；2) 深度增量学习：引入数据依赖的非单调更新，能够反射和擦除冗余特征而不是无条件积累。这两个机制解耦了特征更新的方向和符号，产生跨深度的稳定几何演化。由此得到的架构称为流形几何Transformer（MGT）。

Result: 分析预测，在超深网络中，强制几何有效性同时允许动态擦除对于避免秩崩溃至关重要。提出了超过100层的Transformer评估协议来测试几何（而非深度本身）是深度表示学习的关键限制因素的假设。

Conclusion: 深度Transformer的崩溃是几何问题而非优化问题，通过流形约束和动态擦除机制可以解决表示崩溃问题，为超深Transformer架构设计提供了新的理论框架。

Abstract: Despite their empirical success, pushing Transformer architectures to extreme depth often leads to a paradoxical failure: representations become increasingly redundant, lose rank, and ultimately collapse. Existing explanations largely attribute this phenomenon to optimization instability or vanishing gradients, yet such accounts fail to explain why collapse persists even under modern normalization and initialization schemes. In this paper, we argue that the collapse of deep Transformers is fundamentally a geometric problem. Standard residual updates implicitly assume that feature accumulation is always beneficial, but offer no mechanism to constrain update directions or to erase outdated information. As depth increases, this leads to systematic drift off the semantic manifold and monotonic feature accumulation, causing representational degeneracy. We propose a unified geometric framework that addresses these failures through two orthogonal principles. First, manifold-constrained hyper-connections restrict residual updates to valid local tangent directions, preventing uncontrolled manifold drift. Second, deep delta learning introduces data-dependent, non-monotonic updates that enable reflection and erasure of redundant features rather than their unconditional accumulation. Together, these mechanisms decouple the direction and sign of feature updates, yielding a stable geometric evolution across depth. We term the resulting architecture the Manifold-Geometric Transformer (MGT). Our analysis predicts that enforcing geometric validity while allowing dynamic erasure is essential for avoiding rank collapse in ultra-deep networks. We outline an evaluation protocol for Transformers exceeding 100 layers to test the hypothesis that geometry, rather than depth itself, is the key limiting factor in deep representation learning.

</details>


### [412] [Benchmarking the Computational and Representational Efficiency of State Space Models against Transformers on Long-Context Dyadic Sessions](https://arxiv.org/abs/2601.01237)
*Abidemi Koledoye,Chinemerem Unachukwu,Gold Nwobu,Hasin Rana*

Main category: cs.LG

Relevance: 85.0

TL;DR: Mamba SSM与LLaMA Transformer在长上下文序列上的对比研究，评估计算效率和表征效率，为长上下文应用提供实践指导


<details>
  <summary>Details</summary>
Motivation: 状态空间模型(SSMs)作为Transformer的替代方案，在长上下文序列建模中表现出线性计算复杂度优势。本研究旨在通过系统对比Mamba SSM和LLaMA Transformer，为长上下文应用提供具体指导，明确SSMs相对于Transformers的优势条件。

Method: 使用治疗会话作为代表性测试案例，从两个维度评估：1) 计算效率（内存使用和推理速度，token范围512-8192）；2) 表征效率（隐藏状态动态和注意力模式分析）。

Result: 研究提供了SSMs相对于Transformers优势的具体条件，包括在不同token长度下的计算效率对比和表征特性分析，为长上下文应用选择合适架构提供数据支持。

Conclusion: SSMs在长上下文序列建模中确实具有计算复杂度优势，但需要根据具体应用场景权衡计算效率和表征效率。研究为实践者提供了明确的指导原则。

Abstract: State Space Models (SSMs) have emerged as a promising alternative to Transformers for long-context sequence modeling, offering linear $O(N)$ computational complexity compared to the Transformer's quadratic $O(N^2)$ scaling. This paper presents a comprehensive benchmarking study comparing the Mamba SSM against the LLaMA Transformer on long-context sequences, using dyadic therapy sessions as a representative test case. We evaluate both architectures across two dimensions: (1) computational efficiency, where we measure memory usage and inference speed from 512 to 8,192 tokens, and (2) representational efficiency, where we analyze hidden state dynamics and attention patterns. Our findings provide actionable insights for practitioners working with long-context applications, establishing precise conditions under which SSMs offer advantages over Transformers.

</details>


### [413] [The Alchemy of Thought: Understanding In-Context Learning Through Supervised Classification](https://arxiv.org/abs/2601.01290)
*Harshita Narnoli,Mihai Surdeanu*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文通过比较LLM的上下文学习与基于相同示例训练的分类器，发现当演示相关性高时，LLM行为类似于kNN分类器；相关性低时，LLM表现更好，因其可以利用参数化记忆。


<details>
  <summary>Details</summary>
Motivation: 尽管上下文学习（ICL）已成为快速定制LLM的重要范式，但其工作机制仍不明确。本研究旨在探究LLM在ICL中的行为机制，通过与监督分类器对比来理解ICL的工作原理。

Method: 使用文本分类作为用例，在6个数据集和3个LLM上，比较LLM的ICL行为与基于相同演示示例训练的监督分类器（梯度下降分类器和k近邻分类器）。分析三种研究问题：LLM行为是否类似分类器、更接近哪种分类器、行为差异的条件。

Result: 当演示相关性高时，LLM行为与分类器相似，且更接近kNN而非逻辑回归，表明注意力机制更类似kNN。当演示相关性低时，LLM表现优于分类器，因为LLM可以回退到参数化记忆。

Conclusion: ICL机制在演示相关性高时类似于kNN分类，相关性低时LLM能利用预训练知识。这为理解ICL工作机制提供了实证证据，并揭示了注意力机制与kNN的相似性。

Abstract: In-context learning (ICL) has become a prominent paradigm to rapidly customize LLMs to new tasks without fine-tuning. However, despite the empirical evidence of its usefulness, we still do not truly understand how ICL works. In this paper, we compare the behavior of in-context learning with supervised classifiers trained on ICL demonstrations to investigate three research questions: (1) Do LLMs with ICL behave similarly to classifiers trained on the same examples? (2) If so, which classifiers are closer, those based on gradient descent (GD) or those based on k-nearest neighbors (kNN)? (3) When they do not behave similarly, what conditions are associated with differences in behavior? Using text classification as a use case, with six datasets and three LLMs, we observe that LLMs behave similarly to these classifiers when the relevance of demonstrations is high. On average, ICL is closer to kNN than logistic regression, giving empirical evidence that the attention mechanism behaves more similarly to kNN than GD. However, when demonstration relevance is low, LLMs perform better than these classifiers, likely because LLMs can back off to their parametric memory, a luxury these classifiers do not have.

</details>


### [414] [Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware](https://arxiv.org/abs/2601.01298)
*Jorge L. Ruiz Williams*

Main category: cs.LG

Relevance: 85.0

TL;DR: Warp Cortex：一种异步多智能体LLM架构，通过单例权重共享和拓扑突触技术，将内存复杂度从O(N*L)降低到O(1)权重和O(N*k)上下文，实现消费级硬件上的百万智能体认知扩展。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体LLM框架存在线性内存扩展问题，使得"系统2"并行推理在消费级硬件上不切实际。需要解决内存瓶颈以实现大规模多智能体认知扩展。

Method: 1) 异步架构解耦智能体逻辑与物理内存；2) 单例权重共享减少权重内存复杂度到O(1)；3) 拓扑突触技术（受TDA启发）减少上下文内存到O(N*k)；4) 将KV缓存视为潜在空间点云，应用见证复形稀疏化；5) 引用注入机制实现非侵入式KV缓存更新。

Result: 在单张RTX 4090上实现100个并发智能体仅需2.2GB VRAM，理论容量超过1000个智能体。内存复杂度从O(N*L)降至O(1)权重和O(N*k)上下文（k<<L）。

Conclusion: Warp Cortex通过创新的内存优化技术，解决了多智能体LLM的内存扩展瓶颈，为实现消费级硬件上的大规模并行推理提供了可行方案。

Abstract: Current multi-agent Large Language Model (LLM) frameworks suffer from linear memory scaling, rendering "System 2" parallel reasoning impractical on consumer hardware. We present Warp Cortex, an asynchronous architecture that theoretically enables million-agent cognitive scaling by decoupling agent logic from physical memory. Through Singleton Weight Sharing and a novel Topological Synapse--inspired by hybrid landmarking techniques from Topological Data Analysis (TDA)--we reduce memory complexity from O(N * L) to O(1) for weights and O(N * k) for context, where k << L. By treating the KV-cache as a point cloud in latent space, we apply witness-complex-inspired sparsification to preserve persistent homological features of the context manifold. On a single NVIDIA RTX 4090, we empirically demonstrate 100 concurrent agents at 2.2 GB total VRAM, with theoretical capacity exceeding 1,000 agents before compute latency becomes the bottleneck. We further introduce Referential Injection, a non-intrusive KV-cache update mechanism that allows asynchronous sub-agents to influence primary generation without stream disruption.

</details>


### [415] [Towards a Principled Muon under $μ\mathsf{P}$: Ensuring Spectral Conditions throughout Training](https://arxiv.org/abs/2601.01306)
*John Zhao*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文提出Muon++，一种改进的矩阵优化器，可在整个训练过程中可靠地保证μ-参数化所需的谱条件，无需显式权重谱归一化，降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: μ-参数化为大语言模型训练提供了理论基础，但现有研究在保证矩阵优化器（如Muon）满足μP谱条件方面存在不足：要么无法保证整个训练过程的谱条件，要么需要重复的谱归一化导致计算开销大。

Method: 提出Muon++，基于关键洞察：对于中等规模模型，仅在优化器更新层面维持谱控制就足以保持μP兼容的缩放。该方法无需显式权重谱归一化，并首次引入数据依赖效应的自适应谱条件。

Result: Muon++能在整个训练过程中可靠地保证μP所需的谱条件，填补了μP理论承诺与矩阵优化器实际部署之间的差距，更适合长周期LLM训练。

Conclusion: 该工作为矩阵优化器在μP框架下的实际应用提供了可行方案，通过仅在更新层面控制谱条件降低了计算开销，并引入自适应机制提升长周期训练适用性。

Abstract: The $μ$-parameterization ($μ$P) provides a principled foundation for large language model (LLM) training by prescribing width-independent learning dynamics, which in turn enables predictable scaling behavior and robust hyperparameter transfer across model sizes. A central requirement of $μ$P is the satisfaction of certain spectral conditions on weight matrices, which ensure consistent feature learning and optimization behavior as model width grows. While these conditions are well understood in theory, guaranteeing their validity in practical training for matrix-based optimizers such as Muon is still under studied. Existing works that study Muon under $μ$P exhibit important limitations: they either do not ensure that the spectral conditions hold throughout the entire training horizon, or require repeated spectral normalization (or Newton-Schulz iterations) applied to both weights and updates, leading to significant computational overhead and reduced practicality. In this work, we show how to reliably guarantee the spectral conditions required by $μ$P for Muon during the entire training process. Our key insight is that for moderately large models, maintaining spectral control at the level of optimizer updates alone is sufficient to preserve $μ$P-compatible scaling, eliminating the need for explicit spectral normalization of the weights. Based on this principle, we develop a variant of Muon, namely Muon++, that satisfies spectral condition throughout the training process. Our results bridge the gap between the theoretical promises of $μ$P and the practical deployment of matrix-based optimizers in long-horizon training. We also take the first step towards an adaptive spectral condition by incorporating data-dependent effects, making it better suited for long-horizon LLM training.

</details>


### [416] [Spectral-Window Hybrid (SWH)](https://arxiv.org/abs/2601.01313)
*Vladimer Khasia*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出Spectral-Window Hybrid (SWH)架构，通过并行全局分支（基于卷积定理建模长程衰减动态）和局部分支（滑动窗口注意力）来解耦序列建模，实现高效线性扩展至长序列。


<details>
  <summary>Details</summary>
Motivation: 将序列建模扩展到极端上下文需要平衡计算效率和表示表达能力。Transformer虽然通过注意力机制提供精确检索，但其二次复杂度限制了在长时程任务中的应用。

Method: SWH将序列建模解耦为两个并行流：1) 全局分支利用卷积定理在O(T log T)时间内建模长程衰减动态；2) 局部分支采用滑动窗口注意力处理有界上下文内的token交互。通过聚合这些表示，避免了全局注意力的计算瓶颈。

Result: SWH在短上下文上匹配标准Transformer的困惑度，同时能够高效线性扩展到长序列。

Conclusion: SWH架构通过解耦全局和局部建模，在保持局部精度的同时避免了全局注意力的计算瓶颈，为长序列建模提供了高效解决方案。

Abstract: Scaling sequence modeling to extreme contexts requires balancing computational efficiency with representational expressivity. While Transformers provide precise retrieval via the attention mechanism, their quadratic $\mathcal{O}(T^2)$ complexity limits their application to long-horizon tasks. In this work, we propose the \textbf{Spectral-Window Hybrid (SWH)}, an architecture that decouples sequence modeling into two \textit{parallel} streams: a global branch utilizing the Convolution Theorem to model long-range decay dynamics in $\mathcal{O}(T \log T)$ time, and a local branch employing sliding-window attention for token interactions within a bounded context. By aggregating these representations, SWH avoids the computational bottleneck of global attention while retaining local precision. We demonstrate that SWH matches the perplexity of standard Transformers on short contexts while enabling efficient linear scaling to extended sequences. The code is available at https://github.com/VladimerKhasia/SWH

</details>


### [417] [Bayesian Subspace Gradient Estimation for Zeroth-Order Optimization of Large Language Models](https://arxiv.org/abs/2601.01452)
*Jian Feng,Zhihong Huang*

Main category: cs.LG

Relevance: 85.0

TL;DR: BSZO是一种贝叶斯子空间零阶优化方法，通过卡尔曼滤波结合多个扰动方向的有限差分信息，改进LLM微调的内存效率


<details>
  <summary>Details</summary>
Motivation: 现有零阶优化方法依赖随机扰动的一步梯度估计，限制了优化效率和收敛速度，需要更有效的梯度估计方法

Method: 将有限差分测量视为噪声观测，构建投影梯度的后验分布，通过贝叶斯推断更新，并采用残差自适应机制调整扰动尺度

Result: BSZO在RoBERTa、Mistral和OPT模型上优于MeZO、MeZO-Adam和HiZOO，在OPT-13B上获得6.67%绝对平均提升，内存使用接近推理基线

Conclusion: BSZO通过贝叶斯方法有效结合多个扰动方向信息，显著提升零阶优化的收敛速度和性能，同时保持内存效率

Abstract: Fine-tuning large language models (LLMs) with zeroth-order (ZO) optimization reduces memory by approximating gradients through function evaluations, but existing methods rely on one-step gradient estimates from random perturbations. We introduce Bayesian Subspace Zeroth-Order optimization (BSZO), a ZO optimizer that applies Kalman filtering to combine finite-difference information across multiple perturbation directions. By treating each finite-difference measurement as a noisy observation, BSZO builds a posterior distribution over the projected gradient and updates it through Bayesian inference, with a residual-based adaptive mechanism to adjust perturbation scales. Theoretical analysis shows that BSZO improves the convergence rate by a factor of $k/γ$ compared to standard ZO methods. Experiments on RoBERTa, Mistral, and OPT models show that BSZO outperforms MeZO, MeZO-Adam, and HiZOO across various tasks, achieving up to 6.67\% absolute average improvement on OPT-13B while keeping memory usage close to inference-only baselines (1.00$\times$--1.08$\times$ of MeZO).

</details>


### [418] [Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD](https://arxiv.org/abs/2601.01465)
*Ze Peng,Jian Zhang,Yisen Wang,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文提出了一种新的信息论泛化界，能够更好地捕捉SGD的平坦性偏好，并在深度神经网络上显示出更紧的数值界和正确的平坦性-泛化关系。


<details>
  <summary>Details</summary>
Motivation: 现有信息论泛化界虽然具有数据和算法依赖性，但未能充分捕捉SGD的平坦性偏好对泛化的影响，导致在平坦性改善时无法反映泛化提升，且数值界较松。

Method: 提出"全知轨迹"技术，推导出更能利用平坦性偏好的信息论泛化界，该界表明当最终权重协方差的大方差方向在损失景观中具有小局部曲率时，模型泛化更好。

Result: 在深度神经网络上的实验表明，新界不仅正确反映了平坦性改善时的更好泛化，而且数值上更紧；在凸-Lipschitz-有界问题上，将梯度下降的极小化超额风险从Ω(1)改进到O(1/√n)。

Conclusion: 通过"全知轨迹"技术提出的新信息论泛化界成功捕捉了SGD的平坦性偏好，提供了更紧的泛化保证，并暗示了可以绕过记忆-泛化权衡的可能性。

Abstract: Information-theoretic (IT) generalization bounds have been used to study the generalization of learning algorithms. These bounds are intrinsically data- and algorithm-dependent so that one can exploit the properties of data and algorithm to derive tighter bounds. However, we observe that although the flatness bias is crucial for SGD's generalization, these bounds fail to capture the improved generalization under better flatness and are also numerically loose. This is caused by the inadequate leverage of SGD's flatness bias in existing IT bounds. This paper derives a more flatness-leveraging IT bound for the flatness-favoring SGD. The bound indicates the learned models generalize better if the large-variance directions of the final weight covariance have small local curvatures in the loss landscape. Experiments on deep neural networks show our bound not only correctly reflects the better generalization when flatness is improved, but is also numerically much tighter. This is achieved by a flexible technique called "omniscient trajectory". When applied to Gradient Descent's minimax excess risk on convex-Lipschitz-Bounded problems, it improves representative IT bounds' $Ω(1)$ rates to $O(1/\sqrt{n})$. It also implies a by-pass of memorization-generalization trade-offs.

</details>


### [419] [The Two-Stage Decision-Sampling Hypothesis: Understanding the Emergence of Self-Reflection in RL-Trained LLMs](https://arxiv.org/abs/2601.01580)
*Zibo Zhao,Yuanting Zha,Haipeng Zhang,Xingcheng Xu*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文提出了梯度归因属性理论，解释RL训练如何通过平衡的梯度分配在LLM中产生自我反思能力，而SFT和KL惩罚则存在不平衡梯度分配，导致采样和决策组件优化不均。


<details>
  <summary>Details</summary>
Motivation: 尽管RL后训练能在LLM中产生自我反思能力，但统一的优化目标如何产生生成解决方案和评估何时修订的功能性区分能力，其机制尚不明确。需要从理论上解释RL为何优于SFT。

Method: 提出梯度归因属性来表征奖励梯度在策略组件中的分布，形式化为两阶段决策-采样假设，将策略分解为生成用的采样组件和验证用的决策组件。理论证明代理奖励具有平衡梯度归因，而SFT和KL惩罚具有不平衡梯度归因。

Result: 理论分析表明长度加权创建了不对称正则化，约束采样组件而决策组件优化不足。在算术推理任务上的实证验证表明RL的优越泛化主要来自改进的决策能力而非采样能力。

Conclusion: 为思维模型中的自我修正提供了基于第一性原理的机制解释，揭示了RL成功而SFT失败的理论原因，即梯度分配的平衡性差异。

Abstract: Self-reflection capabilities emerge in Large Language Models after RL post-training, with multi-turn RL achieving substantial gains over SFT counterparts. Yet the mechanism of how a unified optimization objective gives rise to functionally distinct capabilities of generating solutions and evaluating when to revise them remains opaque. To address this question, we introduce the Gradient Attribution Property to characterize how reward gradients distribute across policy components, formalized through the Two-Stage Decision-Sampling (DS) Hypothesis, which decomposes the policy into sampling ($π_{sample}$) for generation and decision ($π_{d}$) for verification. We prove that surrogate rewards exhibit Balanced Gradient Attribution, while SFT and KL penalties exhibit Unbalanced Gradient Attribution, with length-weighting creating asymmetric regularization that constrains $π_{sample}$ while leaving $π_{d}$ under-optimized, providing an theoretical explanation of why RL succeeds where SFT fails. We also empirically validate our theoretical predictions on arithmetic reasoning demonstrates that RL's superior generalization stems primarily from improved decision-making ($π_{d}$) rather than sampling capabilities, providing a first-principles mechanistic explanation for self-correction in thinking models.

</details>


### [420] [HeurekaBench: A Benchmarking Framework for AI Co-scientist](https://arxiv.org/abs/2601.01678)
*Siba Smarak Panigrahi,Jovana Videnović,Maria Brbić*

Main category: cs.LG

Relevance: 85.0

TL;DR: HeurekaBench是一个用于评估科学智能体的基准框架，通过半自动化流程从真实科学研究和代码库中创建开放式的探索性研究问题，并在单细胞生物学领域实例化验证


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的科学智能体系统缺乏真实、端到端的研究场景评估，需要能够整合数据分析、解释和从实验数据生成新见解的基准测试框架

Method: 提出半自动化流水线，利用多个LLM从科学研究和对应代码库中提取见解并生成候选工作流，然后与报告结果进行验证，在单细胞生物学领域实例化为sc-HeurekaBench基准

Result: 使用该基准比较了最先进的单细胞智能体，发现添加批评模块可将开源LLM智能体的不良响应改善高达22%，缩小与闭源模型的差距

Conclusion: HeurekaBench为科学智能体的严格端到端评估奠定了基础，将基准构建锚定在真实科学工作流程中

Abstract: LLM-based reasoning models have enabled the development of agentic systems that act as co-scientists, assisting in multi-step scientific analysis. However, evaluating these systems is challenging, as it requires realistic, end-to-end research scenarios that integrate data analysis, interpretation, and the generation of new insights from the experimental data. To address this limitation, we introduce HeurekaBench, a framework to create benchmarks with exploratory, open-ended research questions for experimental datasets. Each such question is grounded in a scientific study and its corresponding code repository, and is created using a semi-automated pipeline that leverages multiple LLMs to extract insights and generate candidate workflows, which are then verified against reported findings. We instantiate the framework in single-cell biology to obtain sc-HeurekaBench benchmark and use it to compare state-of-the-art single-cell agents. We further showcase the benefits of our benchmark for quantitatively analyzing current design choices in agentic systems. We find that the addition of a critic module can improve ill-formed responses for open-source LLM-based agents by up to 22% and close the gap with their closed-source counterparts. Overall, HeurekaBench sets a path toward rigorous, end-to-end evaluation of scientific agents, grounding benchmark construction in real scientific workflows.

</details>


### [421] [Entropy-Aligned Decoding of LMs for Better Writing and Reasoning](https://arxiv.org/abs/2601.01714)
*Kareem Ahmed,Sameer Singh*

Main category: cs.LG

Relevance: 85.0

TL;DR: EPIC是一种超参数自由的解码方法，通过将未来轨迹的熵纳入语言模型解码，在每一步生成时显式调节不确定性，使采样分布的熵与数据不确定性对齐。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型解码算法存在局限性：随机采样生成质量低，而现有解码算法依赖贪婪启发式方法，导致短视失真，产生同质化、重复且不连贯的句子。需要一种能更好处理不确定性的解码方法。

Method: EPIC通过熵感知的懒惰Gumbel-Max采样，将未来轨迹的熵纳入解码过程。该方法无需超参数，在每一步生成时显式调节不确定性表达量，使采样分布的熵与数据不确定性对齐。算法高效，每步仅需亚线性次数的熵评估。

Result: 在创意写作和摘要任务中，EPIC在LM-as-judge偏好胜率上持续优于广泛使用的解码策略。自动指标显示EPIC产生更多样化的生成和更忠实的摘要。在数学推理任务中，EPIC也优于所有基线方法。

Conclusion: EPIC是一种有效的解码方法，能更好地处理语言生成中的不确定性，产生更高质量、更多样化且更连贯的文本，在多个任务上优于现有解码策略。

Abstract: Language models (LMs) are trained on billions of tokens in an attempt to recover the true language distribution. Still, vanilla random sampling from LMs yields low quality generations. Decoding algorithms attempt to restrict the LM distribution to a set of high-probability continuations, but rely on greedy heuristics that introduce myopic distortions, yielding sentences that are homogeneous, repetitive and incoherent. In this paper, we introduce EPIC, a hyperparameter-free decoding approach that incorporates the entropy of future trajectories into LM decoding. EPIC explicitly regulates the amount of uncertainty expressed at every step of generation, aligning the sampling distribution's entropy to the aleatoric (data) uncertainty. Through Entropy-Aware Lazy Gumbel-Max sampling, EPIC manages to be exact, while also being efficient, requiring only a sublinear number of entropy evaluations per step. Unlike current baselines, EPIC yields sampling distributions that are empirically well-aligned with the entropy of the underlying data distribution. Across creative writing and summarization tasks, EPIC consistently improves LM-as-judge preference win-rates over widely used decoding strategies. These preference gains are complemented by automatic metrics, showing that EPIC produces more diverse generations and more faithful summaries. We also evaluate EPIC on mathematical reasoning, where it outperforms all baselines.

</details>


### [422] [Context-Free Recognition with Transformers](https://arxiv.org/abs/2601.01754)
*Selim Jerad,Anej Svete,Sophie Hao,Ryan Cotterell,William Merrill*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文证明带循环层的Transformer（O(log n)循环层）配合O(n^6)填充token可以识别所有上下文无关语言，但对于自然子类如无歧义CFL，仅需O(n^3)填充token即可实现高效识别。


<details>
  <summary>Details</summary>
Motivation: Transformer在处理符合语法结构的输入（如自然语言和代码）方面表现出色，但其处理语法结构的能力尚不明确。理论上，标准Transformer无法识别上下文无关语言（CFL）甚至正则语言。虽然已有研究显示带循环层的Transformer可以识别正则语言，但CFL识别问题仍未解决。

Method: 采用带循环层的Transformer架构，通过数学证明分析其计算能力。主要方法包括：1）证明带O(log n)循环层和O(n^6)填充token的Transformer可以识别所有CFL；2）分析自然子类（如无歧义CFL）的识别复杂度；3）通过实验验证循环层在需要对数深度的语言上的有效性。

Result: 1）理论上证明了带O(log n)循环层和O(n^6)填充token的Transformer可以识别所有上下文无关语言；2）对于无歧义CFL等自然子类，仅需O(n^3)填充token即可实现高效识别；3）实验验证了循环层在需要对数深度的语言上的有效性。

Conclusion: 虽然通用CFL识别可能需要大量填充token而不切实际，但在自然约束条件（如无歧义性）下，Transformer可以实现高效的上下文无关语言识别。这揭示了Transformer处理语法结构的复杂性，并为实际应用提供了理论指导。

Abstract: Transformers excel on tasks that process well-formed inputs according to some grammar, such as natural language and code. However, it remains unclear how they can process grammatical syntax. In fact, under standard complexity conjectures, standard transformers cannot recognize context-free languages (CFLs), a canonical formalism to describe syntax, or even regular languages, a subclass of CFLs (Merrill et al., 2022). Merrill & Sabharwal (2024) show that $\mathcal{O}(\log n)$ looping layers (w.r.t. input length $n$) allows transformers to recognize regular languages, but the question of context-free recognition remained open. In this work, we show that looped transformers with $\mathcal{O}(\log n)$ looping layers and $\mathcal{O}(n^6)$ padding tokens can recognize all CFLs. However, training and inference with $\mathcal{O}(n^6)$ padding tokens is potentially impractical. Fortunately, we show that, for natural subclasses such as unambiguous CFLs, the recognition problem on transformers becomes more tractable, requiring $\mathcal{O}(n^3)$ padding. We empirically validate our results and show that looping helps on a language that provably requires logarithmic depth. Overall, our results shed light on the intricacy of CFL recognition by transformers: While general recognition may require an intractable amount of padding, natural constraints such as unambiguity yield efficient recognition algorithms.

</details>


### [423] [HyperCLOVA X 8B Omni](https://arxiv.org/abs/2601.01792)
*NAVER Cloud HyperCLOVA X Team*

Main category: cs.LG

Relevance: 85.0

TL;DR: HyperCLOVA X 8B Omni是一个8B参数的多模态模型，支持文本、音频和视觉的任意输入输出组合，通过统一的next-token预测接口实现跨模态理解与生成。


<details>
  <summary>Details</summary>
Motivation: 当前多模态系统通常采用分离的模态特定管道，缺乏真正的任意模态间转换能力。本文旨在构建一个统一的模型，支持文本、音频和视觉之间的任意输入输出组合，实现真正的"任意到任意"多模态助手。

Method: 采用共享的next-token预测接口处理交错的多模态序列，通过视觉和音频编码器注入连续嵌入以实现细粒度理解和基础。模型统一了多模态理解和生成，而非分离的模态特定管道。

Result: 在韩语和英语的文本、音频、视觉多种输入输出组合上，与同类规模模型相比表现出竞争力。模型支持广泛的任意模态间转换任务。

Conclusion: HyperCLOVA X 8B Omni作为8B规模的"任意到任意"多模态模型，为实用多模态助手提供了重要路径点。开源权重将支持广泛的研究和部署场景。

Abstract: In this report, we present HyperCLOVA X 8B Omni, the first any-to-any omnimodal model in the HyperCLOVA X family that supports text, audio, and vision as both inputs and outputs. By consolidating multimodal understanding and generation into a single model rather than separate modality-specific pipelines, HyperCLOVA X 8B Omni serves as an 8B-scale omni-pathfinding point toward practical any-to-any omni assistants. At a high level, the model unifies modalities through a shared next-token prediction interface over an interleaved multimodal sequence, while vision and audio encoders inject continuous embeddings for fine-grained understanding and grounding. Empirical evaluations demonstrate competitive performance against comparably sized models across diverse input-output combinations spanning text, audio, and vision, in both Korean and English. We anticipate that the open-weight release of HyperCLOVA X 8B Omni will support a wide range of research and deployment scenarios.

</details>


### [424] [UnPII: Unlearning Personally Identifiable Information with Quantifiable Exposure Risk](https://arxiv.org/abs/2601.01786)
*Intae Jeon,Yujeong Kwon,Hyungjoon Koo*

Main category: cs.LG

Relevance: 85.0

TL;DR: UnPII：首个基于PII风险优先级的机器学习遗忘方法，通过PII风险指数（PRI）量化不同敏感属性的隐私风险，实现差异化遗忘策略，提升大语言模型在合规数据删除时的准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在金融、医疗、政府等关键领域的广泛应用，处理训练数据中的个人身份信息（PII）引发严重隐私担忧。GDPR等法规要求应请求删除PII数据，但现有遗忘技术采用统一策略，未能考虑不同PII属性的差异化隐私风险和业务风险。

Method: 提出UnPII框架，引入PII风险指数（PRI）——一个综合可识别性、敏感性、可用性、可链接性、持久性、可暴露性和合规性等多维风险因素的复合指标。基于PRI对PII属性进行风险优先级排序，实现差异化遗忘。该方法与现有遗忘算法（如梯度上升、负偏好优化、直接偏好优化）无缝集成，无需修改其底层原理。构建包含1,700个PII实例的合成数据集进行真实评估。

Result: 实验结果显示，UnPII相比统一遗忘策略，在准确性上提升高达11.8%，实用性提升6.3%，泛化能力提升12.4%，同时在遗忘过程中仅产生平均27.5%的适度微调开销。

Conclusion: UnPII首次实现了基于PII风险优先级的差异化遗忘策略，为组织提供符合隐私政策的定制化数据删除解决方案，在保证合规性的同时优化模型性能，为大语言模型的安全部署提供重要技术支持。

Abstract: The ever-increasing adoption of Large Language Models in critical sectors like finance, healthcare, and government raises privacy concerns regarding the handling of sensitive Personally Identifiable Information (PII) during training. In response, regulations such as European Union's General Data Protection Regulation (GDPR) mandate the deletion of PII upon requests, underscoring the need for reliable and cost-effective data removal solutions. Machine unlearning has emerged as a promising direction for selectively forgetting data points. However, existing unlearning techniques typically apply a uniform forgetting strategy that neither accounts for the varying privacy risks posed by different PII attributes nor reflects associated business risks. In this work, we propose UnPII, the first PII-centric unlearning approach that prioritizes forgetting based on the risk of individual or combined PII attributes. To this end, we introduce the PII risk index (PRI), a composite metric that incorporates multiple dimensions of risk factors: identifiability, sensitivity, usability, linkability, permanency, exposability, and compliancy. The PRI enables a nuanced evaluation of privacy risks associated with PII exposures and can be tailored to align with organizational privacy policies. To support realistic assessment, we systematically construct a synthetic PII dataset (e.g., 1,700 PII instances) that simulates realistic exposure scenarios. UnPII seamlessly integrates with established unlearning algorithms, such as Gradient Ascent, Negative Preference Optimization, and Direct Preference Optimization, without modifying their underlying principles. Our experimental results demonstrate that UnPII achieves the improvements of accuracy up to 11.8%, utility up to 6.3%, and generalizability up to 12.4%, respectively, while incurring a modest fine-tuning overhead of 27.5% on average during unlearning.

</details>


### [425] [Output Embedding Centering for Stable LLM Pretraining](https://arxiv.org/abs/2601.02031)
*Felix Stollenwerk,Anna Lokrantz,Niclas Hertzberg*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出输出嵌入中心化(OEC)方法，通过解决输出嵌入几何结构问题来缓解LLM预训练中的输出logit发散不稳定问题，优于现有的z-loss方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型预训练成本高昂且存在训练不稳定问题，特别是训练后期大学习率下的输出logit发散。现有z-loss方法仅解决症状而非根本原因。

Method: 从输出嵌入几何结构角度分析不稳定性原因，提出输出嵌入中心化(OEC)作为新缓解策略。提供两种实现方式：确定性操作μ-centering和正则化方法μ-loss。

Result: OEC两种变体在训练稳定性和学习率敏感性方面均优于z-loss，能确保在大学习率下训练收敛（而z-loss会失败）。μ-loss对正则化超参数调优的敏感性显著低于z-loss。

Conclusion: 输出嵌入中心化(OEC)通过解决输出嵌入几何结构问题，有效缓解LLM预训练中的输出logit发散不稳定问题，比现有方法更稳定且对超参数更鲁棒。

Abstract: Pretraining of large language models is not only expensive but also prone to certain training instabilities. A specific instability that often occurs for large learning rates at the end of training is output logit divergence. The most widely used mitigation strategy, z-loss, merely addresses the symptoms rather than the underlying cause of the problem. In this paper, we analyze the instability from the perspective of the output embeddings' geometry and identify its cause. Based on this, we propose output embedding centering (OEC) as a new mitigation strategy, and prove that it suppresses output logit divergence. OEC can be implemented in two different ways, as a deterministic operation called μ-centering, or a regularization method called μ-loss. Our experiments show that both variants outperform z-loss in terms of training stability and learning rate sensitivity. In particular, they ensure that training converges even for large learning rates when z-loss fails. Furthermore, we find that μ-loss is significantly less sensitive to regularization hyperparameter tuning than z-loss.

</details>


### [426] [Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting](https://arxiv.org/abs/2601.02151)
*Muxi Diao,Lele Yang,Wuxuan Gong,Yutong Zhang,Zhonghao Yan,Yufei Han,Kongming Liang,Weiran Xu,Zhanyu Ma*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出Entropy-Adaptive Fine-Tuning (EAFT)方法，通过基于token级熵的门控机制区分认知不确定性和知识冲突，在保持下游性能的同时显著减轻监督微调导致的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 监督微调(SFT)在领域适应中常导致灾难性遗忘，而基于策略的强化学习(RL)却能有效保持通用能力。作者发现这种差异源于分布差距：RL与模型内部信念对齐，而SFT强制模型拟合外部监督，导致"自信冲突"token（低概率但低熵）引发破坏性梯度更新。

Method: 提出Entropy-Adaptive Fine-Tuning (EAFT)方法，不同于仅依赖预测概率的方法，EAFT使用token级熵作为门控机制来区分认知不确定性和知识冲突。模型从不确定样本中学习，同时抑制冲突数据的梯度。

Result: 在Qwen和GLM系列模型（4B到32B参数）上，在数学、医疗和智能体领域进行广泛实验。EAFT在保持标准SFT下游性能的同时，显著减轻了通用能力的退化。

Conclusion: EAFT通过熵自适应机制有效解决了SFT中的灾难性遗忘问题，为领域适应提供了一种更平衡的方法，在保持专业能力的同时保护模型的通用能力。

Abstract: Supervised Fine-Tuning (SFT) is the standard paradigm for domain adaptation, yet it frequently incurs the cost of catastrophic forgetting. In sharp contrast, on-policy Reinforcement Learning (RL) effectively preserves general capabilities. We investigate this discrepancy and identify a fundamental distributional gap: while RL aligns with the model's internal belief, SFT forces the model to fit external supervision. This mismatch often manifests as "Confident Conflicts" tokens characterized by low probability but low entropy. In these instances, the model is highly confident in its own prediction but is forced to learn a divergent ground truth, triggering destructive gradient updates. To address this, we propose Entropy-Adaptive Fine-Tuning (EAFT). Unlike methods relying solely on prediction probability, EAFT utilizes token-level entropy as a gating mechanism to distinguish between epistemic uncertainty and knowledge conflict. This allows the model to learn from uncertain samples while suppressing gradients on conflicting data. Extensive experiments on Qwen and GLM series (ranging from 4B to 32B parameters) across mathematical, medical, and agentic domains confirm our hypothesis. EAFT consistently matches the downstream performance of standard SFT while significantly mitigating the degradation of general capabilities.

</details>


### [427] [Safety at One Shot: Patching Fine-Tuned LLMs with A Single Instance](https://arxiv.org/abs/2601.01887)
*Jiawen Zhang,Lipeng He,Kejia Chen,Jian Lou,Jian Liu,Xiaohu Yang,Ruoxi Jia*

Main category: cs.LG

Relevance: 85.0

TL;DR: 仅需单个安全样本即可完全恢复被微调破坏的LLM安全对齐，无需牺牲模型实用性，且收敛速度快


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量安全样本或校准集，计算开销大且会导致模型实用性下降。本文挑战这一观念，探索更高效的安全对齐恢复方法。

Method: 发现安全梯度具有低秩结构，利用这一特性提出仅需单个安全样本即可恢复安全对齐的方法。该方法对有害样本数量和模型大小不敏感，收敛仅需几个epoch。

Result: 在5个安全对齐的LLM和多个数据集上验证有效，证明方法的通用性。能够完全恢复安全对齐而不牺牲模型实用性。

Conclusion: 安全对齐可以通过极简方式高效恢复，这得益于安全梯度的低秩结构特性，为LLM安全对齐研究提供了新视角。

Abstract: Fine-tuning safety-aligned large language models (LLMs) can substantially compromise their safety. Previous approaches require many safety samples or calibration sets, which not only incur significant computational overhead during realignment but also lead to noticeable degradation in model utility. Contrary to this belief, we show that safety alignment can be fully recovered with only a single safety example, without sacrificing utility and at minimal cost. Remarkably, this recovery is effective regardless of the number of harmful examples used in fine-tuning or the size of the underlying model, and convergence is achieved within just a few epochs. Furthermore, we uncover the low-rank structure of the safety gradient, which explains why such efficient correction is possible. We validate our findings across five safety-aligned LLMs and multiple datasets, demonstrating the generality of our approach.

</details>


### [428] [DéjàQ: Open-Ended Evolution of Diverse, Learnable and Verifiable Problems](https://arxiv.org/abs/2601.01931)
*Willem Röpke,Samuel Coward,Andrei Lupu,Thomas Foster,Tim Rocktäschel,Jakob Foerster*

Main category: cs.LG

Relevance: 85.0

TL;DR: DéjàQ是一个通过进化合成数学问题来增强推理模型训练的动态框架，使用LLM驱动的变异策略让模型自身生成和优化训练数据。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型主要依赖静态数据集，这可能导致记忆而非泛化，限制了数学推理能力的真正提升。需要一种能够动态适应模型能力、促进学习而非记忆的训练方法。

Method: 提出DéjàQ框架：1）联合进化多样化的合成数学问题集；2）在训练过程中根据模型能力动态调整问题难度；3）采用两种LLM驱动的变异策略：改变上下文细节或直接修改问题结构；4）让模型自身生成和变异训练数据。

Result: 模型能够生成新颖且有意义的数学问题，LLM驱动的变异策略能够改善强化学习训练效果。分析了生成问题的有效性和计算开销，证明了动态演化训练数据的潜力。

Conclusion: 动态演化训练数据能够有效增强数学推理能力，该方法具有更广泛的适用性，作者将开源代码以支持进一步研究。

Abstract: Recent advances in reasoning models have yielded impressive results in mathematics and coding. However, most approaches rely on static datasets, which have been suggested to encourage memorisation and limit generalisation. We introduce DéjàQ, a framework that departs from this paradigm by jointly evolving a diverse set of synthetic mathematical problems alongside model training. This evolutionary process adapts to the model's ability throughout training, optimising problems for learnability. We propose two LLM-driven mutation strategies in which the model itself mutates the training data, either by altering contextual details or by directly modifying problem structure. We find that the model can generate novel and meaningful problems, and that these LLM-driven mutations improve RL training. We analyse key aspects of DéjàQ, including the validity of generated problems and computational overhead. Our results underscore the potential of dynamically evolving training data to enhance mathematical reasoning and indicate broader applicability, which we will support by open-sourcing our code.

</details>


### [429] [Refinement Provenance Inference: Detecting LLM-Refined Training Prompts from Model Behavior](https://arxiv.org/abs/2601.01966)
*Bo Yin,Qi Li,Runpeng Yu,Xinchao Wang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出Refinement Provenance Inference (RPI)任务，用于推断微调模型是否在原始提示或LLM优化版本上进行训练，并提出RePro框架利用教师强制似然特征和logit排序信号进行来源推断。


<details>
  <summary>Details</summary>
Motivation: 随着指令调优越来越多地依赖LLM进行提示优化，训练语料中的提示会被选择性重写以提高清晰度和指令对齐。这引发了实例级审计问题：对于微调模型和训练提示-响应对，能否推断模型是在原始提示还是其LLM优化版本上训练的？这对数据集治理和训练数据争议时的纠纷解决很重要。

Method: 提出RePro框架：1) 发现提示优化会导致教师强制token分布的稳定可检测偏移；2) 融合教师强制似然特征与logit排序信号；3) 通过影子微调学习可迁移表示；4) 使用轻量级线性头在未见过的受害者模型上进行来源推断，无需训练数据访问。

Result: RePro在实证中始终表现出强大性能，并能很好地跨优化器迁移，表明它利用了优化器无关的分布偏移而非重写风格伪影。

Conclusion: 提示优化会产生稳定可检测的分布偏移，RePro框架能有效解决RPI任务，为数据集治理和训练数据争议提供实用工具。

Abstract: Instruction tuning increasingly relies on LLM-based prompt refinement, where prompts in the training corpus are selectively rewritten by an external refiner to improve clarity and instruction alignment. This motivates an instance-level audit problem: for a fine-tuned model and a training prompt-response pair, can we infer whether the model was trained on the original prompt or its LLM-refined version within a mixed corpus? This matters for dataset governance and dispute resolution when training data are contested. However, it is non-trivial in practice: refined and raw instances are interleaved in the training corpus with unknown, source-dependent mixture ratios, making it harder to develop provenance methods that generalize across models and training setups. In this paper, we formalize this audit task as Refinement Provenance Inference (RPI) and show that prompt refinement yields stable, detectable shifts in teacher-forced token distributions, even when semantic differences are not obvious. Building on this phenomenon, we propose RePro, a logit-based provenance framework that fuses teacher-forced likelihood features with logit-ranking signals. During training, RePro learns a transferable representation via shadow fine-tuning, and uses a lightweight linear head to infer provenance on unseen victims without training-data access. Empirically, RePro consistently attains strong performance and transfers well across refiners, suggesting that it exploits refiner-agnostic distribution shifts rather than rewrite-style artifacts.

</details>


### [430] [GDRO: Group-level Reward Post-training Suitable for Diffusion Models](https://arxiv.org/abs/2601.02036)
*Yiyang Wang,Xi Chen,Xiaogang Xu,Yu Liu,Hengshuang Zhao*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出GDRO方法，用于文本到图像整流流扩散模型的群体级奖励对齐，通过离线训练解决在线RL的效率问题，避免对随机采样器的依赖，并处理奖励黑客问题。


<details>
  <summary>Details</summary>
Motivation: 当前在线强化学习用于文本到图像扩散模型的奖励对齐存在效率低、依赖随机采样器、奖励黑客等问题。整流流模型与LLMs有本质差异：图像采样耗时大，且整流流是确定性的（一旦初始噪声固定）。

Method: 提出群体级直接奖励优化（GDRO），这是一种新的后训练范式，结合整流流模型特性。通过理论分析证明支持完全离线训练，节省图像采样时间；扩散采样器独立，无需ODE-to-SDE近似；引入校正评分考虑奖励黑客趋势。

Result: 在OCR和GenEval任务上的广泛实验表明，GDRO通过群体级离线优化有效提升扩散模型的奖励分数，同时展现出强大的稳定性和鲁棒性，能缓解奖励黑客问题。

Conclusion: GDRO为文本到图像整流流扩散模型提供了一种高效、稳定、鲁棒的群体级奖励对齐方法，解决了在线RL的关键限制。

Abstract: Recent advancements adopt online reinforcement learning (RL) from LLMs to text-to-image rectified flow diffusion models for reward alignment. The use of group-level rewards successfully aligns the model with the targeted reward. However, it faces challenges including low efficiency, dependency on stochastic samplers, and reward hacking. The problem is that rectified flow models are fundamentally different from LLMs: 1) For efficiency, online image sampling takes much more time and dominates the time of training. 2) For stochasticity, rectified flow is deterministic once the initial noise is fixed. Aiming at these problems and inspired by the effects of group-level rewards from LLMs, we design Group-level Direct Reward Optimization (GDRO). GDRO is a new post-training paradigm for group-level reward alignment that combines the characteristics of rectified flow models. Through rigorous theoretical analysis, we point out that GDRO supports full offline training that saves the large time cost for image rollout sampling. Also, it is diffusion-sampler-independent, which eliminates the need for the ODE-to-SDE approximation to obtain stochasticity. We also empirically study the reward hacking trap that may mislead the evaluation, and involve this factor in the evaluation using a corrected score that not only considers the original evaluation reward but also the trend of reward hacking. Extensive experiments demonstrate that GDRO effectively and efficiently improves the reward score of the diffusion model through group-wise offline optimization across the OCR and GenEval tasks, while demonstrating strong stability and robustness in mitigating reward hacking.

</details>


### [431] [CORE: Code-based Inverse Self-Training Framework with Graph Expansion for Virtual Agents](https://arxiv.org/abs/2601.02201)
*Keyu Wang,Bingchen Miao,Wendong Bu,Yu Wu,Juncheng Li,Shengyu Zhang,Wenqiao Zhang,Siliang Tang,Jun Xiao,Yueting Zhuang*

Main category: cs.LG

Relevance: 85.0

TL;DR: CORE提出了一种基于代码的逆自训练框架，通过图扩展连接模仿学习与强化学习，自动从专家演示中推断奖励函数，并增强行为多样性，无需手动设计奖励。


<details>
  <summary>Details</summary>
Motivation: 当前多模态虚拟智能体训练面临两难：行为克隆方法简单有效但行为多样性低，强化学习能发现新策略但严重依赖手动设计的奖励函数。需要解决这两种方法的冲突。

Method: 1) 语义代码抽象：自动从专家演示中推断奖励函数（可执行代码）；2) 策略图扩展：构建多路径图捕获多样有效解决方案；3) 轨迹引导外推：利用成功和失败轨迹扩展任务空间。

Result: 在Web和Android平台上的实验表明，CORE显著提高了整体性能和泛化能力，证明了其作为构建强大虚拟智能体的鲁棒且可泛化训练范式的潜力。

Conclusion: CORE框架成功连接了模仿学习与强化学习，在无需手动设计奖励的情况下提升了行为多样性，为多模态虚拟智能体训练提供了新的有效范式。

Abstract: The development of Multimodal Virtual Agents has made significant progress through the integration of Multimodal Large Language Models. However, mainstream training paradigms face key challenges: Behavior Cloning is simple and effective through imitation but suffers from low behavioral diversity, while Reinforcement Learning is capable of discovering novel strategies through exploration but heavily relies on manually designed reward functions. To address the conflict between these two methods, we present CORE, a Code-based Inverse Self-Training Framework with Graph Expansion that bridges imitation and exploration, offering a novel training framework that promotes behavioral diversity while eliminating the reliance on manually reward design. Specifically, we introduce Semantic Code Abstraction to automatically infers reward functions from expert demonstrations without manual design. The inferred reward function, referred to as the Label Function, is executable code that verifies one key step within a task. Building on this, we propose Strategy Graph Expansion to enhance in-domain behavioral diversity, which constructs a multi-path graph called Strategy Graph that captures diverse valid solutions beyond expert demonstrations. Furthermore, we introduce Trajectory-Guided Extrapolation, which enriches out-of-domain behavioral diversity by utilizing both successful and failed trajectories to expand the task space. Experiments on Web and Android platforms demonstrate that CORE significantly improves both overall performance and generalization, highlighting its potential as a robust and generalizable training paradigm for building powerful virtual agents.

</details>


### [432] [ELLA: Efficient Lifelong Learning for Adapters in Large Language Models](https://arxiv.org/abs/2601.02232)
*Shristi Das Biswas,Yue Zhang,Anwesan Pal,Radhika Bhargava,Kaushik Roy*

Main category: cs.LG

Relevance: 85.0

TL;DR: ELLA：一种基于选择性子空间去相关的持续学习框架，通过惩罚高能量任务特定方向的对齐来减少灾难性遗忘，同时保留低能量子空间的自由度以实现正向迁移。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在持续学习场景中面临严重的灾难性遗忘问题。现有方法存在根本性限制：基于重放的方法不切实际且侵犯隐私，而严格正交性方法在规模扩展时会崩溃，因为每个新任务都被投影到正交补空间，逐渐减少剩余自由度并禁止共享表示的重叠，从而消除正向迁移。

Method: ELLA基于选择性子空间去相关原则。它不禁止所有重叠，而是明确表征过去更新的结构，惩罚沿其高能量、任务特定方向的对齐，同时在低能量残差子空间中保留自由度以实现迁移。这通过一个轻量级正则化器在单个聚合更新矩阵上实现，对应一个各向异性收缩算子来限制干扰。

Result: 在三个流行基准测试中达到最先进的持续学习性能，相对准确率提升高达9.6%，内存占用减少35倍。无需数据重放、无需架构扩展、存储开销可忽略。在不同架构上稳健扩展，并主动增强模型在未见任务上的零样本泛化性能。

Conclusion: ELLA为构建性终身LLM适应提供了一个原则性和可扩展的解决方案，通过选择性子空间去相关有效解决了灾难性遗忘问题，同时保持了正向迁移能力。

Abstract: Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse under scale: each new task is projected onto an orthogonal complement, progressively reducing the residual degrees of freedom and eliminating forward transfer by forbidding overlap in shared representations. In this work, we introduce ELLA, a training framework built on the principle of selective subspace de-correlation. Rather than forbidding all overlap, ELLA explicitly characterizes the structure of past updates and penalizes alignments along their high-energy, task-specific directions, while preserving freedom in the low-energy residual subspaces to enable transfer. Formally, this is realized via a lightweight regularizer on a single aggregated update matrix. We prove this mechanism corresponds to an anisotropic shrinkage operator that bounds interference, yielding a penalty that is both memory- and compute-constant regardless of task sequence length. ELLA requires no data replay, no architectural expansion, and negligible storage. Empirically, it achieves state-of-the-art CL performance on three popular benchmarks, with relative accuracy gains of up to $9.6\%$ and a $35\times$ smaller memory footprint. Further, ELLA scales robustly across architectures and actively enhances the model's zero-shot generalization performance on unseen tasks, establishing a principled and scalable solution for constructive lifelong LLM adaptation.

</details>


### [433] [DatBench: Discriminative, Faithful, and Efficient VLM Evaluations](https://arxiv.org/abs/2601.02316)
*Siddharth Joshi,Haoli Yin,Rishabh Adiga,Ricardo Monti,Aldo Carranza,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Darren Teh,David Schwab,Fan Pan,Haakon Mongstad,Jack Urbanek,Jason Lee,Jason Telanoff,Josh Wills,Kaleigh Mentzer,Luke Merrick,Parth Doshi,Paul Burstein,Pratyush Maini,Scott Loftin,Spandan Das,Tony Jiang,Vineeth Dorna,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出VLM评估的三个理想标准（忠实性、区分性、效率性），发现现有评估存在多项缺陷，通过转换和过滤方法改进评估，发布DatBench评估套件


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLM）评估方法尚不成熟，存在多种缺陷：多项选择格式鼓励猜测、与下游应用脱节、存在大量无需图像即可回答的问题、样本标注错误或模糊，且评估计算成本过高（占开发算力的20%）

Method: 提出评估的三个理想标准：忠实性（对模态和应用的忠实）、区分性（区分不同质量模型）、效率性（计算效率）。通过转换（多项选择转为生成任务）和过滤（去除盲目可解和错误标注样本）方法改进现有基准

Result: 多项选择转为生成任务后模型能力下降高达35%；过滤盲目可解和错误标注样本后提高区分能力同时降低计算成本；发布DatBench-Full（33个数据集）和DatBench（区分性子集，平均加速13倍，最高50倍）

Conclusion: 现有VLM评估存在严重缺陷，通过转换和过滤方法可显著改进评估的忠实性和区分性，同时大幅提升效率，为VLM评估提供了更严谨和可持续的路径

Abstract: Empirical evaluation serves as the primary compass guiding research progress in foundation models. Despite a large body of work focused on training frontier vision-language models (VLMs), approaches to their evaluation remain nascent. To guide their maturation, we propose three desiderata that evaluations should satisfy: (1) faithfulness to the modality and application, (2) discriminability between models of varying quality, and (3) efficiency in compute. Through this lens, we identify critical failure modes that violate faithfulness and discriminability, misrepresenting model capabilities: (i) multiple-choice formats reward guessing, poorly reflect downstream use cases, and saturate early as models improve; (ii) blindly solvable questions, which can be answered without images, constitute up to 70% of some evaluations; and (iii) mislabeled or ambiguous samples compromise up to 42% of examples in certain datasets. Regarding efficiency, the computational burden of evaluating frontier models has become prohibitive: by some accounts, nearly 20% of development compute is devoted to evaluation alone. Rather than discarding existing benchmarks, we curate them via transformation and filtering to maximize fidelity and discriminability. We find that converting multiple-choice questions to generative tasks reveals sharp capability drops of up to 35%. In addition, filtering blindly solvable and mislabeled samples improves discriminative power while simultaneously reducing computational cost. We release DatBench-Full, a cleaned evaluation suite of 33 datasets spanning nine VLM capabilities, and DatBench, a discriminative subset that achieves 13x average speedup (up to 50x) while closely matching the discriminative power of the original datasets. Our work outlines a path toward evaluation practices that are both rigorous and sustainable as VLMs continue to scale.

</details>


### [434] [Heterogeneous Low-Bandwidth Pre-Training of LLMs](https://arxiv.org/abs/2601.02360)
*Yazan Obeidi,Amir Sarfi,Joel Lidin,Paul Janson,Eugene Belilovsky*

Main category: cs.LG

Relevance: 85.0

TL;DR: SparseLoCo（低通信数据并行）与低带宽流水线模型并行结合，通过激活和激活梯度压缩，在异构分布式训练中实现高效LLM预训练。


<details>
  <summary>Details</summary>
Motivation: 当前LLM预训练需要大量分布式计算，但带宽限制阻碍了在数据中心之外的扩展，特别是模型并行需要频繁的大规模设备间通信。需要解决低带宽环境下的高效训练问题。

Method: 提出异构分布式训练框架：高带宽参与者托管完整副本，资源受限参与者通过流水线并行联合实例化副本，使用子空间投影的级间通信压缩。将子空间流水线压缩与SparseLoCo结合，研究多种适配方案。

Result: 在178M-1B参数的大规模语言建模实验中，激活压缩与SparseLoCo能以适度成本组合，选择性（异构）压缩相比压缩所有副本能持续改善损失-通信权衡，特别是在高压缩比下。

Conclusion: 研究结果为将低带宽模型并行和异构参与者纳入LLM预训练提供了实用路径，有助于在带宽受限环境中扩展训练规模。

Abstract: Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-communication data parallel method based on infrequent synchronization and sparse pseudo-gradient exchange, can be combined with low-bandwidth pipeline model parallelism via activation and activation-gradient compression. We introduce a heterogeneous distributed training framework where some participants host full replicas on high-bandwidth interconnects, while resource-limited participants are grouped to jointly instantiate a replica using pipeline parallelism with subspace-projected inter-stage communication. To make the recently introduced subspace pipeline compression compatible with SparseLoCo, we study a number of adaptations. Across large-scale language modeling experiments (178M-1B parameters) on standard pretraining corpora, we find that activation compression composes with SparseLoCo at modest cost, while selective (heterogeneous) compression consistently improves the loss-communication tradeoff relative to compressing all replicas-especially at aggressive compression ratios. These results suggest a practical path to incorporating low-bandwidth model parallelism and heterogeneous participants into LLM pre-training.

</details>


### [435] [Making MoE based LLM inference resilient with Tarragon](https://arxiv.org/abs/2601.01310)
*Songyu Zhang,Aaron Tam,Myungjin Lee,Shixiong Qi,K. K. Ramakrishnan*

Main category: cs.DC

Relevance: 85.0

TL;DR: Tarragon：一个具有容错能力的MoE推理框架，通过将注意力工作者和专家工作者作为独立的故障域，实现细粒度的故障隔离和恢复，大幅减少故障导致的推理中断时间。


<details>
  <summary>Details</summary>
Motivation: 现有MoE推理系统在部署规模扩大时故障频发，且容错性差：单个工作者故障就会触发整个服务的重启，丢弃累积进度并中断推理流水线，这对延迟敏感的LLM服务来说是不可接受的。

Method: 1. 将注意力工作者和专家工作者作为独立的故障域进行分离；2. 引入可重配置的数据路径，通过将请求重路由到健康工作者来屏蔽故障；3. 实现自愈机制，放松现有MoE框架的紧密同步执行；4. 对有状态的注意力工作者采用异步增量KV缓存检查点；5. 对无状态的专家工作者利用剩余GPU内存部署影子专家。

Result: 与最先进的MegaScale-Infer相比，Tarragon将故障导致的停顿减少了160-213倍（从约64秒降至0.3-0.4秒），同时在无故障情况下保持性能不变。

Conclusion: Tarragon通过细粒度的故障隔离和低开销的恢复机制，为大规模MoE推理服务提供了高容错性，显著减少了故障对延迟敏感LLM服务的影响。

Abstract: Mixture-of-Experts (MoE) models are increasingly used to serve LLMs at scale, but failures become common as deployment scale grows. Existing systems exhibit poor failure resilience: even a single worker failure triggers a coarse-grained, service-wide restart, discarding accumulated progress and halting the entire inference pipeline during recovery--an approach clearly ill-suited for latency-sensitive, LLM services.
  We present Tarragon, a resilient MoE inference framework that confines the failures impact to individual workers while allowing the rest of the pipeline to continue making forward progress. Tarragon exploits the natural separation between the attention and expert computation in MoE-based transformers, treating attention workers (AWs) and expert workers (EWs) as distinct failure domains. Tarragon introduces a reconfigurable datapath to mask failures by rerouting requests to healthy workers. On top of this datapath, Tarragon implements a self-healing mechanism that relaxes the tightly synchronized execution of existing MoE frameworks. For stateful AWs, Tarragon performs asynchronous, incremental KV cache checkpointing with per-request restoration, and for stateless EWs, it leverages residual GPU memory to deploy shadow experts. These together keep recovery cost and recomputation overhead extremely low. Our evaluation shows that, compared to state-of-the-art MegaScale-Infer, Tarragon reduces failure-induced stalls by 160-213x (from ~64 s down to 0.3-0.4 s) while preserving performance when no failures occur.

</details>


### [436] [SRAS: A Lightweight Reinforcement Learning-based Document Selector for Edge-Native RAG Pipelines](https://arxiv.org/abs/2601.01785)
*Rajiv Chaitanya Muttur*

Main category: cs.IR

Relevance: 85.0

TL;DR: SRAS：基于强化学习的轻量级文档选择器，用于边缘设备上的RAG系统，通过PPO训练，在计算和延迟约束下实现高效文档选择


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统使用固定的top-k文档选择机制，忽略了生成质量并带来计算开销。现有基于RL的检索器假设大内存和延迟预算，不适合边缘部署。需要开发轻量级、延迟感知的文档选择器。

Method: 使用PPO训练紧凑策略（~0.76MB），采用结合Relaxed F1和BERTScore的混合奖励信号。在严格的token和计算约束下运行，CPU延迟<1秒。

Result: 在合成QA基准上优于监督和随机选择器，在SQuAD v2上达到0.8546 BERTScore F1，无需领域特定调优。首次证明RL文档选择可以超轻量、延迟感知且有效。

Conclusion: SRAS展示了RL文档选择可以轻量化并适用于边缘RAG部署，为设备端AI系统提供了新的可能性。

Abstract: Retrieval-Augmented Generation (RAG) systems often rely on fixed top-k document selection mechanisms that ignore downstream generation quality and impose computational overheads. We propose SRAS (Sparse Reward-Aware Selector), a lightweight document selector trained via reinforcement learning (RL) for edge-native RAG deployment. Unlike prior RL-based retrievers that assume large memory and latency budgets, SRAS learns a compact (~0.76MB) policy using Proximal Policy Optimization (PPO), guided by a hybrid reward signal combining Relaxed F1 and BERTScore. Our method operates under tight token and compute constraints, maintaining <1s latency on CPU. SRAS outperforms supervised and random selectors on a synthetic QA benchmark, and generalizes to real-world data, achieving BERTScore F1 of 0.8546 on SQuAD v2 without domain-specific tuning. This work is the first to demonstrate that RL-based document selection can be made ultra-lightweight, latency-aware, and effective for on-device RAG pipelines.

</details>


### [437] [MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics](https://arxiv.org/abs/2601.02075)
*Zhuofan Shi,Hubao A,Yufei Shao,Mengyan Dai,Yadong Yu,Pan Xiang,Dongliang Huang,Hongxu An,Chunxiao Xin,Haiyang Shen,Zhenyu Wang,Yunshan Na,Gang Huang,Xiang Jing*

Main category: cs.CE

Relevance: 85.0

TL;DR: MDAgent2是一个端到端框架，用于分子动力学模拟中的知识问答和代码生成，通过构建高质量数据集、三阶段训练策略和闭环强化学习方法，显著提升了LAMMPS脚本生成的性能。


<details>
  <summary>Details</summary>
Motivation: 分子动力学模拟在材料科学中至关重要，但编写LAMMPS脚本需要高度专业知识且耗时。现有LLMs在MD场景中表现有限，主要受限于领域数据稀缺、部署成本高和代码可执行性低等问题。

Method: 1) 构建领域特定数据管道，创建三个高质量数据集（MD知识、问答、代码生成）；2) 采用三阶段训练策略：持续预训练、监督微调、强化学习；3) 提出MD-GRPO闭环强化学习方法，利用模拟结果作为奖励信号；4) 开发MDAgent2-RUNTIME多智能体系统，集成代码生成、执行、评估和自修正。

Result: 训练出两个领域适应模型MD-Instruct和MD-Code，建立了首个LAMMPS代码生成和问答基准MD-EvalBench，性能超越多个强基线模型。

Conclusion: 这项工作系统展示了大型语言模型在工业模拟任务中的适应性和泛化能力，为AI for Science和工业规模模拟中的自动代码生成奠定了方法论基础。

Abstract: Molecular dynamics (MD) simulations are essential for understanding atomic-scale behaviors in materials science, yet writing LAMMPS scripts remains highly specialized and time-consuming tasks. Although LLMs show promise in code generation and domain-specific question answering, their performance in MD scenarios is limited by scarce domain data, the high deployment cost of state-of-the-art LLMs, and low code executability. Building upon our prior MDAgent, we present MDAgent2, the first end-to-end framework capable of performing both knowledge Q&A and code generation within the MD domain. We construct a domain-specific data-construction pipeline that yields three high-quality datasets spanning MD knowledge, question answering, and code generation. Based on these datasets, we adopt a three stage post-training strategy--continued pre-training (CPT), supervised fine-tuning (SFT), and reinforcement learning (RL)--to train two domain-adapted models, MD-Instruct and MD-Code. Furthermore, we introduce MD-GRPO, a closed-loop RL method that leverages simulation outcomes as reward signals and recycles low-reward trajectories for continual refinement. We further build MDAgent2-RUNTIME, a deployable multi-agent system that integrates code generation, execution, evaluation, and self-correction. Together with MD-EvalBench proposed in this work, the first benchmark for LAMMPS code generation and question answering, our models and system achieve performance surpassing several strong baselines.This work systematically demonstrates the adaptability and generalization capability of large language models in industrial simulation tasks, laying a methodological foundation for automatic code generation in AI for Science and industrial-scale simulations. URL: https://github.com/FredericVAN/PKU_MDAgent2

</details>


### [438] [Value-guided action planning with JEPA world models](https://arxiv.org/abs/2601.00844)
*Matthieu Destrade,Oumayma Bounou,Quentin Le Lidec,Jean Ponce,Yann LeCun*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文提出了一种增强JEPA世界模型规划能力的方法，通过塑造表示空间使负目标条件值函数近似于状态嵌入之间的距离，从而显著提升简单控制任务中的规划性能。


<details>
  <summary>Details</summary>
Motivation: JEPA（联合嵌入预测架构）为建模环境动态提供了有前景的自监督预测框架，但其在支持有效行动规划方面的能力仍然有限。需要增强JEPA世界模型的规划能力。

Method: 提出通过塑造JEPA表示空间，使负目标条件值函数近似于状态嵌入之间的距离（或准距离）。引入了一种实用的训练方法来强制实施这种约束。

Result: 在简单控制任务上，该方法相比标准JEPA模型显著提升了规划性能。

Conclusion: 通过适当塑造表示空间，可以增强JEPA世界模型的规划能力，为构建能够推理环境动态的深度学习模型提供了有效途径。

Abstract: Building deep learning models that can reason about their environment requires capturing its underlying dynamics. Joint-Embedded Predictive Architectures (JEPA) provide a promising framework to model such dynamics by learning representations and predictors through a self-supervised prediction objective. However, their ability to support effective action planning remains limited. We propose an approach to enhance planning with JEPA world models by shaping their representation space so that the negative goal-conditioned value function for a reaching cost in a given environment is approximated by a distance (or quasi-distance) between state embeddings. We introduce a practical method to enforce this constraint during training and show that it leads to significantly improved planning performance compared to standard JEPA models on simple control tasks.

</details>


### [439] [Path Integral Solution for Dissipative Generative Dynamics](https://arxiv.org/abs/2601.00860)
*Xidi Wang*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文证明纯机械系统通过耗散量子动力学和非局部上下文聚合可以生成智能语言，而守恒定律会导致根本性失败。语言生成被建立为耗散量子场论，智能通过耗散和非局域性而非守恒获得。


<details>
  <summary>Details</summary>
Motivation: 研究纯机械系统是否能生成智能语言，探索语言生成的基本物理原理，特别是耗散与守恒在智能涌现中的作用。

Method: 使用Koopman算子和闭式路径积分传播子分析耗散量子动力学，通过谱分析揭示特征值结构（衰减模式、增长模式、中性模式），并比较哈密顿约束下的系统行为。

Result: 证明耗散量子动力学通过可控信息耗散和因果上下文聚合产生连贯文本生成，而哈密顿约束消除耗散模式导致性能下降，尽管模型容量不变。

Conclusion: 语言生成本质上是耗散量子场论，机械系统通过耗散和非局域性而非守恒获得智能，这为理解智能涌现提供了新的物理框架。

Abstract: Can purely mechanical systems generate intelligent language? We prove that dissipative quantum dynamics with analytically tractable non-local context aggregation produce coherent text generation, while conservation laws cause fundamental failure. Employing Koopman operators with closed-form path integral propagators, we show irreversible computation fundamentally requires both controlled information dissipation and causal context aggregation. Spectral analysis reveals emergent eigenvalue structure, separating into decay modes (forgetting), growth modes (amplification), and neutral modes (preservation) -- the essential ingredients for directed information flow. Hamiltonian constraints force the elimination of these dissipative modes and degrading performance despite unchanged model capacity. This establishes language generation as dissipative quantum field theory, proving mechanical systems acquire intelligence through the combination of dissipation and non-locality, not through conservation.

</details>


### [440] [MODE: Efficient Time Series Prediction with Mamba Enhanced by Low-Rank Neural ODEs](https://arxiv.org/abs/2601.00920)
*Xingsheng Chen,Regina Zhang,Bo Gao,Xingwei He,Xiaofeng Liu,Pietro Lio,Kwok-Yan Lam,Siu-Ming Yiu*

Main category: cs.LG

Relevance: 75.0

TL;DR: MODE：一个统一的时间序列预测框架，结合低秩神经ODE和增强Mamba架构，高效处理长程依赖和不规则采样数据。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法在效率、可扩展性和准确性之间难以平衡，特别是在处理长程依赖和不规则采样数据时存在挑战。需要一种既能捕捉复杂时间动态又能保持计算效率的统一框架。

Method: 提出MODE框架：1）线性标记化层处理输入序列；2）多个Mamba编码器块，每个包含增强Mamba层（因果卷积、SiLU激活）；3）低秩神经ODE增强以高效捕捉时间动态；4）分段选择性扫描机制，受伪ODE动态启发，自适应关注重要子序列。

Result: 在基准数据集上的广泛实验表明，MODE在预测准确性和计算效率方面均超越现有基线方法。

Conclusion: MODE为长期时间序列建模提供了一个统一高效架构，通过将Mamba的选择性扫描与低秩神经ODE结合，增强了时间表示能力，并通过低秩近似和动态选择性扫描实现了效率和可扩展性的显著提升。

Abstract: Time series prediction plays a pivotal role across diverse domains such as finance, healthcare, energy systems, and environmental modeling. However, existing approaches often struggle to balance efficiency, scalability, and accuracy, particularly when handling long-range dependencies and irregularly sampled data. To address these challenges, we propose MODE, a unified framework that integrates Low-Rank Neural Ordinary Differential Equations (Neural ODEs) with an Enhanced Mamba architecture. As illustrated in our framework, the input sequence is first transformed by a Linear Tokenization Layer and then processed through multiple Mamba Encoder blocks, each equipped with an Enhanced Mamba Layer that employs Causal Convolution, SiLU activation, and a Low-Rank Neural ODE enhancement to efficiently capture temporal dynamics. This low-rank formulation reduces computational overhead while maintaining expressive power. Furthermore, a segmented selective scanning mechanism, inspired by pseudo-ODE dynamics, adaptively focuses on salient subsequences to improve scalability and long-range sequence modeling. Extensive experiments on benchmark datasets demonstrate that MODE surpasses existing baselines in both predictive accuracy and computational efficiency. Overall, our contributions include: (1) a unified and efficient architecture for long-term time series modeling, (2) integration of Mamba's selective scanning with low-rank Neural ODEs for enhanced temporal representation, and (3) substantial improvements in efficiency and scalability enabled by low-rank approximation and dynamic selective scanning.

</details>


### [441] [Adapting Feature Attenuation to NLP](https://arxiv.org/abs/2601.00965)
*Tianshuo Yang,Ryan Rabinowitz,Terrance E. Boult,Jugal Kalita*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该研究将计算机视觉中的开放集识别方法COSTARR移植到NLP领域，在BERT和GPT-2上评估其在176个arXiv主题分类任务中的表现，发现移植方法有效但未显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer分类器（如BERT）在闭集任务上表现出色，但在面对未见类别输入时仍然脆弱。研究旨在将计算机视觉中的开放集识别方法移植到NLP领域，评估其在文本分类任务中的效果。

Method: 将计算机视觉中的COSTARR框架适配到两个语言模型（BERT-base和GPT-2），在176个arXiv主题分类任务上进行评估。同时比较了最大softmax概率、最大logit和温度缩放自由能分数等基线方法，使用OOSA和AUOSCR指标进行评估。

Result: 1) COSTARR可以扩展到NLP领域而无需重新训练，但相比MaxLogit或MSP方法没有统计显著提升；2) 在高类别数量设置下，自由能方法落后于所有其他评分方法。

Conclusion: 研究展示了将视觉中心的开放集识别思想移植到语言模型的潜力和当前局限性，指出需要更大的骨干网络和任务特定的衰减策略。

Abstract: Transformer classifiers such as BERT deliver impressive closed-set accuracy, yet they remain brittle when confronted with inputs from unseen categories--a common scenario for deployed NLP systems. We investigate Open-Set Recognition (OSR) for text by porting the feature attenuation hypothesis from computer vision to transformers and by benchmarking it against state-of-the-art baselines. Concretely, we adapt the COSTARR framework--originally designed for classification in computer vision--to two modest language models (BERT (base) and GPT-2) trained to label 176 arXiv subject areas. Alongside COSTARR, we evaluate Maximum Softmax Probability (MSP), MaxLogit, and the temperature-scaled free-energy score under the OOSA and AUOSCR metrics. Our results show (i) COSTARR extends to NLP without retraining but yields no statistically significant gain over MaxLogit or MSP, and (ii) free-energy lags behind all other scores in this high-class-count setting. The study highlights both the promise and the current limitations of transplanting vision-centric OSR ideas to language models, and points toward the need for larger backbones and task-tailored attenuation strategies.

</details>


### [442] [Contractive Diffusion Policies: Robust Action Diffusion via Contractive Score-Based Sampling with Differential Equations](https://arxiv.org/abs/2601.01003)
*Amin Abyaneh,Charlotte Morissette,Mohamad H. Danesh,Anas El Houssaini,David Meger,Gregory Dudek,Hsiu-Chin Lin*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出收缩扩散策略（CDPs），通过诱导扩散采样动力学的收缩行为来增强离线策略学习的鲁棒性，减少求解器和分数匹配误差的影响


<details>
  <summary>Details</summary>
Motivation: 扩散策略在离线策略学习中表现出色，但其基于分数的SDE建模存在求解器和分数匹配误差、大数据需求以及动作生成不一致等问题。这些在图像生成中不太关键的问题在连续控制设置中会累积并导致失败

Method: 引入收缩扩散策略（CDPs），在扩散采样动力学中诱导收缩行为。收缩将附近的流拉近，增强对求解器和分数匹配误差的鲁棒性，同时减少不需要的动作方差。提供了理论分析和实际实现方案，可最小化修改和计算成本地集成到现有扩散策略架构中

Result: 在仿真和真实世界设置中进行广泛实验，CDPs在基准测试中通常优于基线策略，在数据稀缺情况下表现出更明显的优势

Conclusion: CDPs通过引入收缩行为有效解决了扩散策略在连续控制中的误差累积问题，提高了离线学习的鲁棒性和性能

Abstract: Diffusion policies have emerged as powerful generative models for offline policy learning, whose sampling process can be rigorously characterized by a score function guiding a Stochastic Differential Equation (SDE). However, the same score-based SDE modeling that grants diffusion policies the flexibility to learn diverse behavior also incurs solver and score-matching errors, large data requirements, and inconsistencies in action generation. While less critical in image generation, these inaccuracies compound and lead to failure in continuous control settings. We introduce Contractive Diffusion Policies (CDPs) to induce contractive behavior in the diffusion sampling dynamics. Contraction pulls nearby flows closer to enhance robustness against solver and score-matching errors while reducing unwanted action variance. We develop an in-depth theoretical analysis along with a practical implementation recipe to incorporate CDPs into existing diffusion policy architectures with minimal modification and computational cost. We evaluate CDPs for offline learning by conducting extensive experiments in simulation and real-world settings. Across benchmarks, CDPs often outperform baseline policies, with pronounced benefits under data scarcity.

</details>


### [443] [SPoRC-VIST: A Benchmark for Evaluating Generative Natural Narrative in Vision-Language Models](https://arxiv.org/abs/2601.01062)
*Yunlin Zeng*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出视觉播客生成新流程，通过合成到真实的训练策略微调Qwen3-VL-32B模型，在对话自然性和叙事深度上显著优于更大基础模型


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在描述性任务表现出色，但在生成引人入胜的长篇叙事（特别是多人播客对话）方面能力不足且难以评估。标准指标如BLEU和ROUGE无法捕捉对话自然性、个性和叙事流畅度等细微差别。

Method: 1) 提出端到端视觉播客生成流程；2) 在4000个图像-对话对数据集上微调Qwen3-VL-32B模型；3) 采用合成到真实的训练策略：在SPoRC高质量播客对话与合成生成图像配对上训练，在VIST真实世界照片序列上评估；4) 提出综合评估框架，使用AI作为评判（Gemini 3 Pro、Claude Opus 4.5、GPT 5.2）和新型风格指标（平均对话长度、说话者切换率）。

Result: 微调的32B模型在对话自然性上显著优于235B基础模型（胜率>80%），叙事深度增加50%（对话长度），同时保持相同的视觉基础能力（CLIPScore: 20.39）。

Conclusion: 通过合成到真实的训练策略和综合评估框架，较小的微调模型可以在视觉叙事生成任务上超越更大的基础模型，特别是在对话自然性和叙事深度方面。

Abstract: Vision-Language Models (VLMs) have achieved remarkable success in descriptive tasks such as image captioning and visual question answering (VQA). However, their ability to generate engaging, long-form narratives -- specifically multi-speaker podcast dialogues -- remains under-explored and difficult to evaluate. Standard metrics like BLEU and ROUGE fail to capture the nuances of conversational naturalness, personality, and narrative flow, often rewarding safe, repetitive outputs over engaging storytelling. In this work, we present a novel pipeline for end-to-end visual podcast generation, and fine-tune a Qwen3-VL-32B model on a curated dataset of 4,000 image-dialogue pairs. Crucially, we use a synthetic-to-real training strategy: we train on high-quality podcast dialogues from the Structured Podcast Research Corpus (SPoRC) paired with synthetically generated imagery, and evaluate on real-world photo sequences from the Visual Storytelling Dataset (VIST). This rigorous setup tests the model's ability to generalize from synthetic training data to real-world visual domains. We propose a comprehensive evaluation framework that moves beyond textual overlap, and use AI-as-a-judge (Gemini 3 Pro, Claude Opus 4.5, GPT 5.2) and novel style metrics (average turn length, speaker switch rate) to assess quality. Our experiments demonstrate that our fine-tuned 32B model significantly outperforms a 235B base model in conversational naturalness ($>$80\% win rate) and narrative depth (+50\% turn length), while maintaining identical visual grounding capabilities (CLIPScore: 20.39).

</details>


### [444] [Bridging the Semantic Gap for Categorical Data Clustering via Large Language Models](https://arxiv.org/abs/2601.01162)
*Zihua Yang,Xin Liao,Yiqun Zhang,Yiu-ming Cheung*

Main category: cs.LG

Relevance: 75.0

TL;DR: ARISE利用大语言模型获取类别数据的语义嵌入，结合原始数据构建语义感知表示，提升聚类质量


<details>
  <summary>Details</summary>
Motivation: 类别数据缺乏内在排序和距离度量，传统方法依赖数据内共现模式推断值间关系，在样本有限时不可靠，导致语义上下文未被充分利用，聚类质量下降

Method: 使用大语言模型描述属性值获取语义嵌入，将LLM增强的嵌入与原始数据结合，构建注意力加权的语义感知表示，探索语义突出的聚类结构

Result: 在8个基准数据集上相比7个代表性方法有19-27%的性能提升

Conclusion: 利用外部语义知识（特别是LLM）可以显著改善类别数据聚类，弥补传统方法的语义鸿沟

Abstract: Categorical data are prevalent in domains such as healthcare, marketing, and bioinformatics, where clustering serves as a fundamental tool for pattern discovery. A core challenge in categorical data clustering lies in measuring similarity among attribute values that lack inherent ordering or distance. Without appropriate similarity measures, values are often treated as equidistant, creating a semantic gap that obscures latent structures and degrades clustering quality. Although existing methods infer value relationships from within-dataset co-occurrence patterns, such inference becomes unreliable when samples are limited, leaving the semantic context of the data underexplored. To bridge this gap, we present ARISE (Attention-weighted Representation with Integrated Semantic Embeddings), which draws on external semantic knowledge from Large Language Models (LLMs) to construct semantic-aware representations that complement the metric space of categorical data for accurate clustering. That is, LLM is adopted to describe attribute values for representation enhancement, and the LLM-enhanced embeddings are combined with the original data to explore semantically prominent clusters. Experiments on eight benchmark datasets demonstrate consistent improvements over seven representative counterparts, with gains of 19-27%. Code is available at https://github.com/develop-yang/ARISE

</details>


### [445] [Towards LLM-enabled autonomous combustion research: A literature-aware agent for self-corrective modeling workflows](https://arxiv.org/abs/2601.01357)
*Ke Xiao,Haoze Zhang,Runze Mao,Han Li,Zhi X. Chen*

Main category: cs.LG

Relevance: 75.0

TL;DR: FlamePilot是一个专门用于燃烧建模的LLM智能体，能够自动执行CFD仿真工作流程，从科学文献中学习并指导仿真设置，在公开基准测试中取得了优于现有智能体的性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在复杂科学领域（如燃烧建模）的应用存在关键缺口，需要将领域文献知识与专业工具（如CFD代码）的执行能力无缝集成，以提供实用的AI辅助。

Method: FlamePilot采用基于原子工具的架构，确保在OpenFOAM和DeepFlame等框架中稳健设置和执行复杂仿真。系统能够从科学文献中学习，提取关键信息指导仿真从初始设置到优化结果的全过程。

Result: 在公开基准测试中，FlamePilot实现了完美的1.0可执行性得分和0.438的成功率，超过了之前最佳智能体得分（0.625和0.250）。在MILD燃烧仿真实例研究中，智能体能够自主将研究论文转化为配置的仿真，执行仿真，后处理结果，提出基于证据的改进建议，并在最少人工干预下管理多步骤参数研究直至收敛。

Conclusion: FlamePilot通过采用透明可解释的范式，为AI赋能的燃烧建模建立了基础框架，促进了智能体管理工作流编排、研究人员专注于高层分析的协作伙伴关系。

Abstract: The rapid evolution of large language models (LLMs) is transforming artificial intelligence into autonomous research partners, yet a critical gap persists in complex scientific domains such as combustion modeling. Here, practical AI assistance requires the seamless integration of domain literature knowledge with robust execution capabilities for expertise-intensive tools such as computational fluid dynamics (CFD) codes. To bridge this gap, we introduce FlamePilot, an LLM agent designed to empower combustion modeling research through automated and self-corrective CFD workflows. FlamePilot differentiates itself through an architecture that leverages atomic tools to ensure the robust setup and execution of complex simulations in both OpenFOAM and extended frameworks such as DeepFlame. The system is also capable of learning from scientific articles, extracting key information to guide the simulation from initial setup to optimized results. Validation on a public benchmark shows FlamePilot achieved a perfect 1.0 executability score and a 0.438 success rate, surpassing the prior best reported agent scores of 0.625 and 0.250, respectively. Furthermore, a detailed case study on Moderate or Intense Low-oxygen Dilution (MILD) combustion simulation demonstrates its efficacy as a collaborative research copilot, where FlamePilot autonomously translated a research paper into a configured simulation, conducted the simulation, post-processed the results, proposed evidence-based refinements, and managed a multi-step parameter study to convergence under minimal human intervention. By adopting a transparent and interpretable paradigm, FlamePilot establishes a foundational framework for AI-empowered combustion modeling, fostering a collaborative partnership where the agent manages workflow orchestration, freeing the researcher for high-level analysis.

</details>


### [446] [Sparse Threats, Focused Defense: Criticality-Aware Robust Reinforcement Learning for Safe Autonomous Driving](https://arxiv.org/abs/2601.01800)
*Qi Wei,Junchao Fan,Zhao Yang,Jianhua Wang,Jingkai Mao,Xiaolin Chang*

Main category: cs.LG

Relevance: 75.0

TL;DR: CARRL提出了一种针对自动驾驶稀疏安全风险的对抗训练方法，通过风险暴露对手和风险目标鲁棒代理的博弈交互，在稀疏攻击下提升策略鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶强化学习方法对扰动的脆弱性限制了实际部署。传统对抗训练采用零和博弈和连续攻击，忽略了代理与对手之间的不对称性，且未能反映安全关键风险的稀疏性，导致鲁棒性不足。

Method: 提出CARRL框架：1) 风险暴露对手(REA)采用解耦优化机制，在有限预算下识别和利用稀疏安全关键时刻；2) 风险目标鲁棒代理(RTRA)通过双回放缓冲区联合利用良性对抗经验，并在扰动下强制策略一致性。两者建模为一般和博弈。

Result: 实验结果表明，与最先进的基线方法相比，该方法在所有情况下至少降低了22.66%的碰撞率。

Conclusion: CARRL通过考虑安全关键风险的稀疏性和代理-对手不对称性，显著提升了自动驾驶强化学习策略的鲁棒性，为实际部署提供了更有效的对抗训练方法。

Abstract: Reinforcement learning (RL) has shown considerable potential in autonomous driving (AD), yet its vulnerability to perturbations remains a critical barrier to real-world deployment. As a primary countermeasure, adversarial training improves policy robustness by training the AD agent in the presence of an adversary that deliberately introduces perturbations. Existing approaches typically model the interaction as a zero-sum game with continuous attacks. However, such designs overlook the inherent asymmetry between the agent and the adversary and then fail to reflect the sparsity of safety-critical risks, rendering the achieved robustness inadequate for practical AD scenarios. To address these limitations, we introduce criticality-aware robust RL (CARRL), a novel adversarial training approach for handling sparse, safety-critical risks in autonomous driving. CARRL consists of two interacting components: a risk exposure adversary (REA) and a risk-targeted robust agent (RTRA). We model the interaction between the REA and RTRA as a general-sum game, allowing the REA to focus on exposing safety-critical failures (e.g., collisions) while the RTRA learns to balance safety with driving efficiency. The REA employs a decoupled optimization mechanism to better identify and exploit sparse safety-critical moments under a constrained budget. However, such focused attacks inevitably result in a scarcity of adversarial data. The RTRA copes with this scarcity by jointly leveraging benign and adversarial experiences via a dual replay buffer and enforces policy consistency under perturbations to stabilize behavior. Experimental results demonstrate that our approach reduces the collision rate by at least 22.66\% across all cases compared to state-of-the-art baseline methods.

</details>


### [447] [Evaluating Feature Dependent Noise in Preference-based Reinforcement Learning](https://arxiv.org/abs/2601.01904)
*Yuxuan Li,Harshith Reddy Kethireddy,Srijita Das*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文研究了偏好强化学习中特征相关噪声的问题，提出了多种特征相关噪声变体，并发现现有噪声鲁棒方法在特征相关噪声下性能显著下降，而普通方法反而表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有偏好强化学习研究大多假设噪声是均匀分布的，但实际中偏好噪声往往与观察特征相关。作者旨在研究这种特征相关噪声对PbRL方法的影响，特别是现有噪声鲁棒方法在这种更真实噪声下的表现。

Method: 1. 形式化特征相关噪声概念；2. 提出多种噪声变体：轨迹特征噪声、轨迹相似性噪声、不确定性感知噪声、语言模型噪声；3. 在DMControl和Meta-world的复杂连续控制任务中评估；4. 比较现有噪声鲁棒PbRL方法与普通PbRL方法的表现。

Result: 1. 在特征相关噪声设置下，最先进的噪声鲁棒PbRL方法学习性能显著恶化；2. 没有显式去噪的普通PbRL方法在多数设置中反而优于噪声鲁棒方法；3. 语言模型噪声表现出与特征相关噪声相似的特征，能够模拟真实人类偏好。

Conclusion: 特征相关噪声对现有噪声鲁棒PbRL方法构成挑战，需要开发更鲁棒的特征相关噪声处理方法。语言模型噪声可作为研究人类偏好的有效模拟工具。

Abstract: Learning from Preferences in Reinforcement Learning (PbRL) has gained attention recently, as it serves as a natural fit for complicated tasks where the reward function is not easily available. However, preferences often come with uncertainty and noise if they are not from perfect teachers. Much prior literature aimed to detect noise, but with limited types of noise and most being uniformly distributed with no connection to observations. In this work, we formalize the notion of targeted feature-dependent noise and propose several variants like trajectory feature noise, trajectory similarity noise, uncertainty-aware noise, and Language Model noise.
  We evaluate feature-dependent noise, where noise is correlated with certain features in complex continuous control tasks from DMControl and Meta-world. Our experiments show that in some feature-dependent noise settings, the state-of-the-art noise-robust PbRL method's learning performance is significantly deteriorated, while PbRL method with no explicit denoising can surprisingly outperform noise-robust PbRL in majority settings.
  We also find language model's noise exhibits similar characteristics to feature-dependent noise, thereby simulating realistic humans and call for further study in learning with feature-dependent noise robustly.

</details>


### [448] [Horizon Activation Mapping for Neural Networks in Time Series Forecasting](https://arxiv.org/abs/2601.02094)
*Hans Krupakar,V A Kandappan*

Main category: cs.LG

Relevance: 75.0

TL;DR: 本文提出Horizon Activation Mapping (HAM)，一种用于时间序列预测模型的可视化可解释性技术，通过梯度范数平均来研究不同预测模型家族中的子序列重要性，适用于跨模型家族的可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列预测模型依赖于误差度量和特定架构的可解释性方法，这些方法无法跨不同模型家族应用。需要一种模型无关的可解释性技术来理解不同预测模型如何关注输入序列的不同部分。

Method: 提出HAM技术，受grad-CAM启发，使用梯度范数平均来研究预测时间范围内子序列的重要性。引入因果和反因果模式计算每个时间步的梯度更新范数平均，并引入比例线表示范数平均的均匀分布。在ETTm2数据集上评估多种模型，包括MLP-based、自注意力、状态空间模型和扩散模型。

Result: HAM能够可视化不同模型家族在训练、验证和测试集上的激活模式。发现批次大小差异可能指示跨epoch的指数近似关系。NHITS的神经近似定理和SpaceTime的指数自回归活动在HAM图中得到体现。

Conclusion: HAM可用于细粒度模型选择、验证集选择和跨不同神经网络模型家族的比较，为时间序列预测提供了一种统一的可解释性框架。

Abstract: Neural networks for time series forecasting have relied on error metrics and architecture-specific interpretability approaches for model selection that don't apply across models of different families. To interpret forecasting models agnostic to the types of layers across state-of-the-art model families, we introduce Horizon Activation Mapping (HAM), a visual interpretability technique inspired by grad-CAM that uses gradient norm averages to study the horizon's subseries where grad-CAM studies attention maps over image data. We introduce causal and anti-causal modes to calculate gradient update norm averages across subseries at every timestep and lines of proportionality signifying uniform distributions of the norm averages. Optimization landscape studies with respect to changes in batch sizes, early stopping, train-val-test splits, univariate forecasting and dropouts are studied with respect to performances and subseries in HAM. Interestingly, batch size based differences in activities seem to indicate potential for existence of an exponential approximation across them per epoch relative to each other. Multivariate forecasting models including MLP-based CycleNet, N-Linear, N-HITS, self attention-based FEDformer, Pyraformer, SSM-based SpaceTime and diffusion-based Multi-Resolution DDPM over different horizon sizes trained over the ETTm2 dataset are used for HAM plots in this study. NHITS' neural approximation theorem and SpaceTime's exponential autoregressive activities have been attributed to trends in HAM plots over their training, validation and test sets. In general, HAM can be used for granular model selection, validation set choices and comparisons across different neural network model families.

</details>


### [449] [Differential Privacy for Transformer Embeddings of Text with Nonparametric Variational Information Bottleneck](https://arxiv.org/abs/2601.02307)
*Dina El Zein,James Henderson*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出NVDP方法，通过向Transformer嵌入添加噪声来保护隐私，在GLUE基准上实现隐私与准确性的权衡


<details>
  <summary>Details</summary>
Motivation: Transformer嵌入包含多个向量（每个token一个），容易泄露输入数据的敏感信息，需要隐私保护的数据共享方法

Method: 提出非参数变分差分隐私(NVDP)，在Transformer架构中集成非参数变分信息瓶颈(NVIB)层，向多向量嵌入注入噪声，使用Rényi散度和贝叶斯差分隐私(BDP)衡量隐私保护

Result: 在GLUE基准测试中，通过调整噪声水平实现了隐私与准确性的有效权衡，低噪声水平下保持高准确性同时提供强隐私保证

Conclusion: NVDP方法能有效平衡隐私保护与数据实用性，为Transformer模型的隐私保护数据共享提供可行方案

Abstract: We propose a privacy-preserving method for sharing text data by sharing noisy versions of their transformer embeddings. It has been shown that hidden representations learned by deep models can encode sensitive information from the input, making it possible for adversaries to recover the input data with considerable accuracy. This problem is exacerbated in transformer embeddings because they consist of multiple vectors, one per token. To mitigate this risk, we propose Nonparametric Variational Differential Privacy (NVDP), which ensures both useful data sharing and strong privacy protection. We take a differential privacy approach, integrating a Nonparametric Variational Information Bottleneck (NVIB) layer into the transformer architecture to inject noise into its multi-vector embeddings and thereby hide information, and measuring privacy protection with Rényi divergence and its corresponding Bayesian Differential Privacy (BDP) guarantee. Training the NVIB layer calibrates the noise level according to utility. We test NVDP on the GLUE benchmark and show that varying the noise level gives us a useful tradeoff between privacy and accuracy. With lower noise levels, our model maintains high accuracy while offering strong privacy guarantees, effectively balancing privacy and utility.

</details>


### [450] [Environment-Adaptive Covariate Selection: Learning When to Use Spurious Correlations for Out-of-Distribution Prediction](https://arxiv.org/abs/2601.02322)
*Shuozhi Zuo,Yixin Wang*

Main category: stat.ME

Relevance: 75.0

TL;DR: 论文研究OOD预测中因果/不变性方法为何常不如经验风险最小化，发现当仅观察到部分真实原因时，非因果协变量可作为未观测原因的代理变量提升预测，除非分布偏移破坏代理关系。提出环境自适应协变量选择算法，根据目标环境协变量分布特征动态选择协变量。


<details>
  <summary>Details</summary>
Motivation: 传统OOD预测方法通常限制模型使用因果或不变协变量，避免跨环境不稳定的虚假关联。尽管理论上有吸引力，但实践中常不如经验风险最小化。论文旨在探究这种差距的来源，特别是在仅观察到部分真实原因的情况下。

Method: 提出环境自适应协变量选择算法，利用目标OOD环境中未标记数据的协变量分布特征，将环境级协变量摘要映射到环境特定的协变量集，同时允许纳入先验因果知识作为约束。

Result: 在模拟和应用数据集上，EACS算法在各种分布偏移下始终优于静态因果、不变性和基于ERM的预测器。

Conclusion: 最优预测协变量集不是通用的，也不一定在所有环境中与结果保持不变关系，而是取决于遇到的特定偏移类型。协变量偏移在协变量分布中产生可观察的特征，可用于判断代理协变量何时可靠何时失效。

Abstract: Out-of-distribution (OOD) prediction is often approached by restricting models to causal or invariant covariates, avoiding non-causal spurious associations that may be unstable across environments. Despite its theoretical appeal, this strategy frequently underperforms empirical risk minimization (ERM) in practice. We investigate the source of this gap and show that such failures naturally arise when only a subset of the true causes of the outcome is observed. In these settings, non-causal spurious covariates can serve as informative proxies for unobserved causes and substantially improve prediction, except under distribution shifts that break these proxy relationships. Consequently, the optimal set of predictive covariates is neither universal nor necessarily exhibits invariant relationships with the outcome across all environments, but instead depends on the specific type of shift encountered. Crucially, we observe that different covariate shifts induce distinct, observable signatures in the covariate distribution itself. Moreover, these signatures can be extracted from unlabeled data in the target OOD environment and used to assess when proxy covariates remain reliable and when they fail. Building on this observation, we propose an environment-adaptive covariate selection (EACS) algorithm that maps environment-level covariate summaries to environment-specific covariate sets, while allowing the incorporation of prior causal knowledge as constraints. Across simulations and applied datasets, EACS consistently outperforms static causal, invariant, and ERM-based predictors under diverse distribution shifts.

</details>


### [451] [SLO-Conditioned Action Routing for Retrieval-Augmented Generation: Objective Ablation and Failure Modes](https://arxiv.org/abs/2601.00841)
*Bharath Nunepalli*

Main category: cs.LG

Relevance: 65.0

TL;DR: 该论文研究RAG系统中的查询级控制问题，通过离线数据集学习策略来平衡成本、拒绝率和幻觉风险等SLO目标，发现简单基线策略表现良好，学习策略主要在质量优先的SLO下提供额外成本节省。


<details>
  <summary>Details</summary>
Motivation: RAG系统需要在实际部署中平衡多个服务级别目标（SLOs），如成本、拒绝率和幻觉风险。目前缺乏对查询级控制策略的系统研究，特别是如何根据具体查询动态选择检索深度和生成模式。

Method: 将查询级控制建模为离散动作选择：检索深度、生成模式（防护vs自动）或拒绝。基于SQuAD 2.0构建离线数据集，记录每个动作的准确性、token成本、幻觉/拒绝指标和SLO加权奖励。评估两种简单策略学习目标：基于最佳动作的监督分类（Argmax-CE）和奖励加权变体（Argmax-CE-WT）。

Result: 固定基线策略（低k值+防护提示）表现竞争力强；学习策略主要在质量优先的SLO下提供额外成本节省；在成本优先的SLO下，当拒绝被高度奖励时，学习策略可能出现"拒绝崩溃"现象。

Conclusion: 论文提供了RAG管道SLO感知控制的可重复案例研究，强调失败模式和报告规范，而非提出新的检索器或语言模型。简单基线策略在实际部署中可能足够有效。

Abstract: Retrieval-augmented generation (RAG) introduces a practical control problem: retrieval depth and generation behavior must be chosen per query to satisfy service-level objectives (SLOs) such as cost, refusal rate, and hallucination risk. This work models per-query control as a small discrete action: choose a retrieval depth and a generation mode (guarded vs. auto), or refuse. An offline logged dataset is constructed from SQuAD 2.0 by executing each action and recording accuracy, token cost, hallucination/refusal indicators, and an SLO-weighted reward. Two simple policy-learning objectives are evaluated: supervised classification of the per-state best action (Argmax-CE) and a reward-weighted variant (Argmax-CE-WT). Across the evaluated settings, a strong fixed baseline (low k, guarded prompting) performs competitively; learned policies mainly provide additional cost savings under a quality-focused SLO and can exhibit refusal collapse under a cheap SLO when refusal is heavily rewarded. The contribution is a reproducible case study of SLO-aware control for RAG pipelines, emphasizing failure modes and reporting conventions rather than proposing a new retriever or language model.

</details>


### [452] [FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments](https://arxiv.org/abs/2601.00853)
*Sameer Rahil,Zain Abdullah Ahmad,Talha Asif*

Main category: cs.LG

Relevance: 65.0

TL;DR: FedSCAM：一种联邦学习算法，通过基于客户端异质性动态调整SAM扰动半径和聚合权重，解决非IID数据下的收敛问题


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据的统计异质性（特别是非IID标签分布）严重影响了模型的收敛和泛化能力。虽然SAM已被引入FL以寻找更平坦、更鲁棒的最小值，但现有方法通常对所有客户端使用统一的扰动半径，忽略了客户端特定的异质性。

Method: 提出FedSCAM算法：1) 为每个客户端计算异质性指标；2) 根据该指标反向调制SAM扰动半径，防止高方差客户端破坏全局模型；3) 引入异质性感知的加权聚合机制，优先考虑与全局优化方向一致的客户端更新。

Result: 在CIFAR-10和Fashion-MNIST数据集上，使用基于Dirichlet的标签偏斜进行广泛实验，FedSCAM在收敛速度和最终测试准确率方面达到了与FedSAM、FedLESAM等最先进基线方法竞争的性能。

Conclusion: FedSCAM通过动态调整SAM扰动半径和聚合权重，有效解决了联邦学习中的统计异质性问题，提高了模型的收敛性和泛化能力。

Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation radius across all clients, ignoring client-specific heterogeneity. In this work, we propose \textbf{FedSCAM} (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation), a novel algorithm that dynamically adjusts the SAM perturbation radius and aggregation weights based on client-specific heterogeneity scores. By calculating a heterogeneity metric for each client and modulating the perturbation radius inversely to this score, FedSCAM prevents clients with high variance from destabilizing the global model. Furthermore, we introduce a heterogeneity-aware weighted aggregation mechanism that prioritizes updates from clients that align with the global optimization direction. Extensive experiments on CIFAR-10 and Fashion-MNIST under various degrees of Dirichlet-based label skew demonstrate that FedSCAM achieves competitive performance among state-of-the-art baselines, including FedSAM, FedLESAM, etc. in terms of convergence speed and final test accuracy.

</details>


### [453] [SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation](https://arxiv.org/abs/2601.00868)
*Aditya Sreevatsa K,Arun Kumar Raveendran,Jesrael K Mani,Prakash G Shigli,Rajkumar Rangadore,Narayana Darapaneni,Anwesh Reddy Paduri*

Main category: cs.LG

Relevance: 65.0

TL;DR: SmartFlow是一个多层框架，结合强化学习和智能体AI解决城市共享单车动态再平衡问题，通过战略层DQN学习策略、战术层优化调度、通信层LLM生成可执行指令，显著降低网络不平衡并提高运营效率。


<details>
  <summary>Details</summary>
Motivation: 解决城市共享单车系统中的动态再平衡问题，传统方法难以处理复杂城市环境的动态变化，需要智能化的解决方案来减少空闲时间、提高单车可用性并降低运营成本。

Method: 采用三层架构：1) 战略层使用深度Q网络在纽约Citi Bike网络的高保真模拟中学习再平衡策略；2) 战术层确定性模块优化多段行程和调度；3) 通信层基于LLM的智能体AI将物流计划转化为可执行指令。

Result: 在多次种子运行评估中，SmartFlow将网络不平衡减少超过95%，同时最小化车队行驶距离，实现强卡车利用率，显著改善单车可用性和降低运营成本。

Conclusion: SmartFlow为复杂城市移动网络提供了可解释、AI驱动的物流蓝图，成功将机器智能与人类操作相结合，展示了强化学习与智能体AI在现实世界物流问题中的有效整合。

Abstract: SmartFlow is a multi-layered framework that integrates Reinforcement Learning and Agentic AI to address the dynamic rebalancing problem in urban bike-sharing services. Its architecture separates strategic, tactical, and communication functions for clarity and scalability. At the strategic level, a Deep Q-Network (DQN) agent, trained in a high-fidelity simulation of New Yorks Citi Bike network, learns robust rebalancing policies by modelling the challenge as a Markov Decision Process. These high-level strategies feed into a deterministic tactical module that optimises multi-leg journeys and schedules just-in-time dispatches to minimise fleet travel. Evaluation across multiple seeded runs demonstrates SmartFlows high efficacy, reducing network imbalance by over 95% while requiring minimal travel distance and achieving strong truck utilisation. A communication layer, powered by a grounded Agentic AI with a Large Language Model (LLM), translates logistical plans into clear, actionable instructions for operational staff, ensuring interpretability and execution readiness. This integration bridges machine intelligence with human operations, offering a scalable solution that reduces idle time, improves bike availability, and lowers operational costs. SmartFlow provides a blueprint for interpretable, AI-driven logistics in complex urban mobility networks.

</details>


### [454] [Conformal Prediction Under Distribution Shift: A COVID-19 Natural Experiment](https://arxiv.org/abs/2601.00908)
*Chorok Lee*

Main category: cs.LG

Relevance: 65.0

TL;DR: 研究显示，在COVID-19引发的分布漂移下，保形预测的覆盖保证会严重退化。通过分析8个供应链任务发现，尽管特征变化程度相同，但覆盖下降幅度差异巨大（0%-86.7%）。单特征依赖与灾难性失败高度相关，而季度重训练能显著改善脆弱任务。


<details>
  <summary>Details</summary>
Motivation: 保形预测在分布漂移下的性能保证会退化，但现有研究缺乏对这种退化程度和模式的深入理解。作者利用COVID-19作为自然实验，研究保形预测在不同供应链任务中的鲁棒性差异，旨在理解分布漂移下预测失败的根本原因。

Method: 使用COVID-19期间的8个供应链任务作为自然实验，分析保形预测在严重特征变化（Jaccard≈0）下的性能。采用SHAP分析特征重要性分布，计算特征集中度指标。通过季度重训练实验验证改进策略，并额外分析4个中等特征稳定性任务。

Result: 覆盖下降幅度差异巨大（0%-86.7%），与单特征依赖高度相关（ρ=0.714, p=0.047）。灾难性任务的特征集中度增加4.5倍，而鲁棒任务的特征重要性分散到10-20个特征。季度重训练将脆弱任务覆盖从22%提升至41%，但对鲁棒任务无益。

Conclusion: 保形预测在分布漂移下的鲁棒性取决于特征重要性分布：单特征依赖导致灾难性失败，而特征分散提供鲁棒性。提出了决策框架：部署前监控SHAP集中度，集中度>40%的任务需要季度重训练，鲁棒任务可跳过重训练。

Abstract: Conformal prediction guarantees degrade under distribution shift. We study this using COVID-19 as a natural experiment across 8 supply chain tasks. Despite identical severe feature turnover (Jaccard approximately 0), coverage drops vary from 0% to 86.7%, spanning two orders of magnitude. Using SHapley Additive exPlanations (SHAP) analysis, we find catastrophic failures correlate with single-feature dependence (rho = 0.714, p = 0.047). Catastrophic tasks concentrate importance in one feature (4.5x increase), while robust tasks redistribute across many (10-20x). Quarterly retraining restores catastrophic task coverage from 22% to 41% (+19 pp, p = 0.04), but provides no benefit for robust tasks (99.8% coverage). Exploratory analysis of 4 additional tasks with moderate feature stability (Jaccard 0.13-0.86) reveals feature stability, not concentration, determines robustness, suggesting concentration effects apply specifically to severe shifts. We provide a decision framework: monitor SHAP concentration before deployment; retrain quarterly if vulnerable (>40% concentration); skip retraining if robust.

</details>


### [455] [Zero-shot Forecasting by Simulation Alone](https://arxiv.org/abs/2601.00970)
*Boris N. Oreshkin,Mayank Jauhari,Ravi Kiran Selvam,Malcolm Wolff,Wenhao Pan,Shankar Ramasubramanian,Kin G. Olivares,Tatiana Konstantinova,Andres Potapczynski,Mengfei Cao,Dmitry Efimov,Michael W. Mahoney,Andrew G. Wilson*

Main category: cs.LG

Relevance: 65.0

TL;DR: SarSim0：基于SARIMA的快速时间序列模拟器，用于零样本预测训练，在M-Series和GiftEval基准上表现优异


<details>
  <summary>Details</summary>
Motivation: 解决零样本时间序列预测面临的挑战：数据有限且偏差、评估易泄露、隐私和许可限制，需要实用的模拟方法

Method: 基于SARIMA模型的三步模拟流程：1) 从特征多项式稳定区域采样良好轨迹；2) 叠加多个路径创建多季节性序列；3) 添加基于速率的重尾噪声模型捕捉突发性和间歇性

Result: SarSim0比基于核的生成器快几个数量级，可生成约10亿个独特模拟序列；训练后的神经网络在零样本泛化中超越统计预测器和近期基础模型，在GiftEval上甚至超过生成过程本身

Conclusion: SarSim0为时间序列预测提供了实用的模拟框架，解决了数据稀缺问题，实现了强大的零样本性能，为工业应用提供了有效解决方案

Abstract: Zero-shot time-series forecasting holds great promise, but is still in its infancy, hindered by limited and biased data corpora, leakage-prone evaluation, and privacy and licensing constraints. Motivated by these challenges, we propose the first practical univariate time series simulation pipeline which is simultaneously fast enough for on-the-fly data generation and enables notable zero-shot forecasting performance on M-Series and GiftEval benchmarks that capture trend/seasonality/intermittency patterns, typical of industrial forecasting applications across a variety of domains. Our simulator, which we call SarSim0 (SARIMA Simulator for Zero-Shot Forecasting), is based off of a seasonal autoregressive integrated moving average (SARIMA) model as its core data source. Due to instability in the autoregressive component, naive SARIMA simulation often leads to unusable paths. Instead, we follow a three-step procedure: (1) we sample well-behaved trajectories from its characteristic polynomial stability region; (2) we introduce a superposition scheme that combines multiple paths into rich multi-seasonality traces; and (3) we add rate-based heavy-tailed noise models to capture burstiness and intermittency alongside seasonalities and trends. SarSim0 is orders of magnitude faster than kernel-based generators, and it enables training on circa 1B unique purely simulated series, generated on the fly; after which well-established neural network backbones exhibit strong zero-shot generalization, surpassing strong statistical forecasters and recent foundation baselines, while operating under strict zero-shot protocol. Notably, on GiftEval we observe a "student-beats-teacher" effect: models trained on our simulations exceed the forecasting accuracy of the AutoARIMA generating processes.

</details>


### [456] [From Classification to Generation: An Open-Ended Paradigm for Adverse Drug Reaction Prediction Based on Graph-Motif Feature Fusion](https://arxiv.org/abs/2601.01347)
*Yuyan Pi,Min Jin,Wentao Xie,Xinhua Liu*

Main category: cs.LG

Relevance: 65.0

TL;DR: GM-MLG：基于图-基序特征融合和多标签生成的开放端药物不良反应预测新范式，将传统多标签分类转化为Transformer解码器的多标签生成任务，显著扩展预测空间并提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前药物不良反应预测面临三大挑战：1) 药物数据稀缺导致的冷启动问题；2) 封闭标签集的限制；3) 标签依赖关系建模不足。需要一种能够动态扩展预测空间、更好建模标签依赖关系的开放端预测方法。

Method: 1) 构建原子级、局部分子级（通过BRICS算法动态提取细粒度基序）和全局分子级的双图表示架构；2) 将ADR预测从多标签分类转化为基于Transformer解码器的多标签生成任务；3) 将ADR标签视为离散令牌序列，使用位置嵌入显式捕捉大规模标签空间中的依赖和共现关系；4) 通过自回归解码动态扩展预测空间。

Result: GM-MLG实现了高达38%的性能提升，平均增益20%；将预测空间从200种扩展到超过10,000种类型；通过逆合成基序分析阐明了ADR与基序之间的非线性构效关系。

Conclusion: GM-MLG为药物安全性系统风险降低提供了可解释和创新的支持，通过将多标签分类转化为生成任务，有效解决了冷启动、封闭标签集和标签依赖建模等核心挑战。

Abstract: Computational biology offers immense potential for reducing the high costs and protracted cycles of new drug development through adverse drug reaction (ADR) prediction. However, current methods remain impeded by drug data scarcity-induced cold-start challenge, closed label sets, and inadequate modeling of label dependencies. Here we propose an open-ended ADR prediction paradigm based on Graph-Motif feature fusion and Multi-Label Generation (GM-MLG). Leveraging molecular structure as an intrinsic and inherent feature, GM-MLG constructs a dual-graph representation architecture spanning the atomic level, the local molecular level (utilizing fine-grained motifs dynamically extracted via the BRICS algorithm combined with additional fragmentation rules), and the global molecular level. Uniquely, GM-MLG pioneers transforming ADR prediction from multi-label classification into Transformer Decoder-based multi-label generation. By treating ADR labels as discrete token sequences, it employs positional embeddings to explicitly capture dependencies and co-occurrence relationships within large-scale label spaces, generating predictions via autoregressive decoding to dynamically expand the prediction space. Experiments demonstrate GM-MLG achieves up to 38% improvement and an average gain of 20%, expanding the prediction space from 200 to over 10,000 types. Furthermore, it elucidates non-linear structure-activity relationships between ADRs and motifs via retrosynthetic motif analysis, providing interpretable and innovative support for systematic risk reduction in drug safety.

</details>


### [457] [Data Complexity-aware Deep Model Performance Forecasting](https://arxiv.org/abs/2601.01383)
*Yen-Chia Chen,Hsing-Kuo Pao,Hanjuan Huang*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出一个轻量级的两阶段框架，无需训练即可预测深度学习模型在给定数据集上的性能，并指导架构选择和数据处理


<details>
  <summary>Details</summary>
Motivation: 当前为特定数据集选择合适深度学习架构主要依赖试错法，这种方法耗时、资源密集且难以自动化。现有性能预测方法要么需要大量计算开销（如部分训练），要么缺乏泛化能力

Method: 两阶段框架：第一阶段基于数据集的可测量属性（如方差）预测基线性能；第二阶段结合模型架构和超参数细节调整估计。框架设计为轻量级，能够跨数据集和模型类型泛化

Result: 框架不仅能预测模型性能，还能指导架构选择、预处理流程，并在训练开始前检测潜在有问题的数据集。数据集方差等特征可作为数据质量的早期指标

Conclusion: 该框架提供了一种高效、可自动化的替代方案，减少深度学习模型选择和优化的试错成本，同时为数据质量评估提供实用指导

Abstract: Deep learning models are widely used across computer vision and other domains. When working on the model induction, selecting the right architecture for a given dataset often relies on repetitive trial-and-error procedures. This procedure is time-consuming, resource-intensive, and difficult to automate. While previous work has explored performance prediction using partial training or complex simulations, these methods often require significant computational overhead or lack generalizability. In this work, we propose an alternative approach: a lightweight, two-stage framework that can estimate model performance before training given the understanding of the dataset and the focused deep model structures. The first stage predicts a baseline based on the analysis of some measurable properties of the dataset, while the second stage adjusts the estimation with additional information on the model's architectural and hyperparameter details. The setup allows the framework to generalize across datasets and model types. Moreover, we find that some of the underlying features used for prediction - such as dataset variance - can offer practical guidance for model selection, and can serve as early indicators of data quality. As a result, the framework can be used not only to forecast model performance, but also to guide architecture choices, inform necessary preprocessing procedures, and detect potentially problematic datasets before training begins.

</details>


### [458] [Multi-Subspace Multi-Modal Modeling for Diffusion Models: Estimation, Convergence and Mixture of Experts](https://arxiv.org/abs/2601.01475)
*Ruofeng Yang,Yongcan Li,Bo Jiang,Cheng Chen,Shuai Li*

Main category: cs.LG

Relevance: 65.0

TL;DR: 本文提出MoLR-MoG建模方法，将数据建模为K个线性子空间的并集，每个子空间采用混合高斯隐变量，从而更好地捕捉多模态特性。该方法通过专家混合结构实现维度诅咒的规避，并在小样本下获得良好生成效果。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在小数据集上表现良好，但传统方法存在维度诅咒问题（误差随维度D呈n^{-1/D}衰减）。现有工作将数据建模为高斯隐变量的线性子空间并集，虽然反映了多流形特性，但无法捕捉隐变量流形的多模态特性。

Method: 提出混合子空间-低秩混合高斯（MoLR-MoG）建模：将目标数据建模为K个线性子空间的并集，每个子空间采用混合高斯隐变量（n_k个模态，维度d_k）。对应的得分函数自然具有专家混合（MoE）结构，能捕捉多模态信息并包含非线性特性。

Result: 1. 真实世界实验显示MoE隐变量MoG神经网络的生成结果远优于MoE隐变量高斯得分；2. MoE隐变量MoG神经网络仅用1/10参数就达到与MoE隐变量Unet相当的性能；3. 理论分析得到R^4√(Σn_k)√(Σn_kd_k)/√n的估计误差，通过数据结构规避维度诅咒；4. 证明了MoLR-MoG建模下的收敛保证。

Conclusion: MoLR-MoG建模合理且适用于真实世界数据，解释了为什么扩散模型只需小训练样本和快速优化过程就能获得优异性能。该方法通过捕捉数据的多模态特性，在理论上规避了维度诅咒问题。

Abstract: Recently, diffusion models have achieved a great performance with a small dataset of size $n$ and a fast optimization process. However, the estimation error of diffusion models suffers from the curse of dimensionality $n^{-1/D}$ with the data dimension $D$. Since images are usually a union of low-dimensional manifolds, current works model the data as a union of linear subspaces with Gaussian latent and achieve a $1/\sqrt{n}$ bound. Though this modeling reflects the multi-manifold property, the Gaussian latent can not capture the multi-modal property of the latent manifold. To bridge this gap, we propose the mixture subspace of low-rank mixture of Gaussian (MoLR-MoG) modeling, which models the target data as a union of $K$ linear subspaces, and each subspace admits a mixture of Gaussian latent ($n_k$ modals with dimension $d_k$). With this modeling, the corresponding score function naturally has a mixture of expert (MoE) structure, captures the multi-modal information, and contains nonlinear property. We first conduct real-world experiments to show that the generation results of MoE-latent MoG NN are much better than MoE-latent Gaussian score. Furthermore, MoE-latent MoG NN achieves a comparable performance with MoE-latent Unet with $10 \times$ parameters. These results indicate that the MoLR-MoG modeling is reasonable and suitable for real-world data. After that, based on such MoE-latent MoG score, we provide a $R^4\sqrt{Σ_{k=1}^Kn_k}\sqrt{Σ_{k=1}^Kn_kd_k}/\sqrt{n}$ estimation error, which escapes the curse of dimensionality by using data structure. Finally, we study the optimization process and prove the convergence guarantee under the MoLR-MoG modeling. Combined with these results, under a setting close to real-world data, this work explains why diffusion models only require a small training sample and enjoy a fast optimization process to achieve a great performance.

</details>


### [459] [SGD-Based Knowledge Distillation with Bayesian Teachers: Theory and Guidelines](https://arxiv.org/abs/2601.01484)
*Itai Morad,Nir Shlezinger,Yonina C. Eldar*

Main category: cs.LG

Relevance: 65.0

TL;DR: 从贝叶斯视角分析知识蒸馏的理论基础，证明使用贝叶斯分类概率作为教师输出能降低方差、提升收敛稳定性，并通过实验验证贝叶斯教师模型在知识蒸馏中的优越性。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏在实践中有显著效果，但其理论基础尚不完善。本文旨在从贝叶斯角度为知识蒸馏提供理论分析框架，特别是研究使用贝叶斯分类概率作为教师输出的理论优势。

Method: 采用贝叶斯视角分析知识蒸馏的收敛行为，研究两种监督模式：1）教师提供精确的贝叶斯分类概率；2）使用噪声近似的贝叶斯分类概率。通过理论分析方差减少和收敛边界，并实验验证贝叶斯教师模型在知识蒸馏中的效果。

Result: 理论分析表明，使用贝叶斯分类概率能减少方差、移除收敛边界中的邻域项。实验结果显示，从贝叶斯教师蒸馏出的学生模型准确率最高提升4.27%，收敛稳定性提升30%（噪声减少）。

Conclusion: 贝叶斯深度学习模型能提供更好的贝叶斯分类概率估计，作为知识蒸馏的教师模型能显著提升学生模型的准确率和收敛稳定性，为知识蒸馏的理论和实践提供了新的视角。

Abstract: Knowledge Distillation (KD) is a central paradigm for transferring knowledge from a large teacher network to a typically smaller student model, often by leveraging soft probabilistic outputs. While KD has shown strong empirical success in numerous applications, its theoretical underpinnings remain only partially understood. In this work, we adopt a Bayesian perspective on KD to rigorously analyze the convergence behavior of students trained with Stochastic Gradient Descent (SGD). We study two regimes: $(i)$ when the teacher provides the exact Bayes Class Probabilities (BCPs); and $(ii)$ supervision with noisy approximations of the BCPs. Our analysis shows that learning from BCPs yields variance reduction and removes neighborhood terms in the convergence bounds compared to one-hot supervision. We further characterize how the level of noise affects generalization and accuracy. Motivated by these insights, we advocate the use of Bayesian deep learning models, which typically provide improved estimates of the BCPs, as teachers in KD. Consistent with our analysis, we experimentally demonstrate that students distilled from Bayesian teachers not only achieve higher accuracies (up to +4.27%), but also exhibit more stable convergence (up to 30% less noise), compared to students distilled from deterministic teachers.

</details>


### [460] [Adversarial Instance Generation and Robust Training for Neural Combinatorial Optimization with Multiple Objectives](https://arxiv.org/abs/2601.01665)
*Wei Liu,Yaoxin Wu,Yingqian Zhang,Thomas Bäck,Yingjie Fan*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出一个面向多目标组合优化问题的强化学习求解器鲁棒性框架，包括偏好对抗攻击生成困难实例和硬度感知偏好选择的防御策略，提升求解器在分布外数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的多目标组合优化求解器鲁棒性研究不足，特别是在多样复杂问题分布上的表现。需要系统评估和提升这些求解器在不同偏好条件下的鲁棒性和泛化能力。

Method: 1) 提出统一鲁棒性框架，包含偏好条件DRL求解器；2) 开发基于偏好的对抗攻击方法，生成暴露求解器弱点的困难实例；3) 引入防御策略，将硬度感知偏好选择集成到对抗训练中，减少对受限偏好区域的过拟合。

Result: 在MOTSP、MOCVRP和MOKP问题上验证：攻击方法成功为不同求解器生成困难实例；防御方法显著增强神经求解器的鲁棒性和泛化能力，在困难或分布外实例上表现优异。

Conclusion: 该框架为多目标组合优化学习求解器提供了系统的鲁棒性评估和增强方法，通过对抗攻击和防御策略的结合，有效提升了求解器在复杂分布下的性能。

Abstract: Deep reinforcement learning (DRL) has shown great promise in addressing multi-objective combinatorial optimization problems (MOCOPs). Nevertheless, the robustness of these learning-based solvers has remained insufficiently explored, especially across diverse and complex problem distributions. In this paper, we propose a unified robustness-oriented framework for preference-conditioned DRL solvers for MOCOPs. Within this framework, we develop a preference-based adversarial attack to generate hard instances that expose solver weaknesses, and quantify the attack impact by the resulting degradation on Pareto-front quality. We further introduce a defense strategy that integrates hardness-aware preference selection into adversarial training to reduce overfitting to restricted preference regions and improve out-of-distribution performance. The experimental results on multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) verify that our attack method successfully learns hard instances for different solvers. Furthermore, our defense method significantly strengthens the robustness and generalizability of neural solvers, delivering superior performance on hard or out-of-distribution instances.

</details>


### [461] [Enhanced Multi-model Online Conformal Prediction](https://arxiv.org/abs/2601.01692)
*Erfan Hajihashemi,Yanning Shen*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出了一种新颖的多模型在线保形预测算法，通过二分图选择有效模型子集，在保证覆盖率的同时提高预测集效率和计算效率


<details>
  <summary>Details</summary>
Motivation: 传统保形预测依赖单一固定模型，在在线环境中可能表现不稳定；现有多模型方法计算成本高且可能包含性能差的模型影响效果

Method: 开发多模型在线保形预测算法，在每个时间步生成二分图识别有效模型子集，从中选择模型构建预测集

Result: 实验表明该方法在预测集大小和计算效率方面优于现有多模型保形预测技术

Conclusion: 提出的算法能有效降低计算复杂度并提高预测效率，为在线环境中的不确定性量化提供了更优解决方案

Abstract: Conformal prediction is a framework for uncertainty quantification that constructs prediction sets for previously unseen data, guaranteeing coverage of the true label with a specified probability. However, the efficiency of these prediction sets, measured by their size, depends on the choice of the underlying learning model. Relying on a single fixed model may lead to suboptimal performance in online environments, as a single model may not consistently perform well across all time steps. To mitigate this, prior work has explored selecting a model from a set of candidates. However, this approach becomes computationally expensive as the number of candidate models increases. Moreover, poorly performing models in the set may also hinder the effectiveness. To tackle this challenge, this work develops a novel multi-model online conformal prediction algorithm that reduces computational complexity and improves prediction efficiency. At each time step, a bipartite graph is generated to identify a subset of effective models, from which a model is selected to construct the prediction set. Experiments demonstrate that our method outperforms existing multi-model conformal prediction techniques in terms of both prediction set size and computational efficiency.

</details>


### [462] [Moments Matter:Stabilizing Policy Optimization using Return Distributions](https://arxiv.org/abs/2601.01803)
*Dennis Jabs,Aditya Mohan,Marius Lindauer*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出一种基于分布评论家和高阶矩（偏度和峰度）的PPO改进方法，通过惩罚极端尾部行为来减少策略更新导致的稳定性问题，在连续控制任务中提升稳定性达75%。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习代理即使获得相同回合回报，其行为也可能因环境和算法因素而大不相同。在连续控制任务中，小的参数变化可能导致不稳定的步态，这既影响算法比较也阻碍实际应用。先前研究表明，当策略更新穿越噪声邻域时会产生不稳定性，而更新后回报分布R(θ)的扩散是衡量这种噪声的有用指标。虽然显式约束策略以保持窄R(θ)可以改善稳定性，但在高维设置中直接估计R(θ)计算成本很高。

Method: 提出一种替代方法：利用环境随机性来减轻更新引起的变异性。具体来说，通过分布评论家建模状态-动作回报分布，然后使用该分布的高阶矩（偏度和峰度）来偏置PPO的优势函数。通过惩罚极端尾部行为，该方法阻止策略进入容易产生不稳定性的参数区域。当更新后评论家值与更新后回报对齐不佳时，标准PPO难以产生窄R(θ)，此时基于矩的修正可以缩小R(θ)。

Result: 在Walker2D环境中，该方法将稳定性提高了75%，同时保持了可比较的评估回报。这表明基于高阶矩的修正能有效改善策略更新的稳定性。

Conclusion: 通过分布评论家和高阶矩（偏度和峰度）来偏置PPO优势函数，可以有效减少策略更新导致的稳定性问题，在保持性能的同时显著提升策略稳定性。这种方法为连续控制任务中的强化学习稳定性问题提供了新的解决方案。

Abstract: Deep Reinforcement Learning (RL) agents often learn policies that achieve the same episodic return yet behave very differently, due to a combination of environmental (random transitions, initial conditions, reward noise) and algorithmic (minibatch selection, exploration noise) factors. In continuous control tasks, even small parameter shifts can produce unstable gaits, complicating both algorithm comparison and real-world transfer. Previous work has shown that such instability arises when policy updates traverse noisy neighborhoods and that the spread of post-update return distribution $R(θ)$, obtained by repeatedly sampling minibatches, updating $θ$, and measuring final returns, is a useful indicator of this noise. Although explicitly constraining the policy to maintain a narrow $R(θ)$ can improve stability, directly estimating $R(θ)$ is computationally expensive in high-dimensional settings. We propose an alternative that takes advantage of environmental stochasticity to mitigate update-induced variability. Specifically, we model state-action return distribution through a distributional critic and then bias the advantage function of PPO using higher-order moments (skewness and kurtosis) of this distribution. By penalizing extreme tail behaviors, our method discourages policies from entering parameter regimes prone to instability. We hypothesize that in environments where post-update critic values align poorly with post-update returns, standard PPO struggles to produce a narrow $R(θ)$. In such cases, our moment-based correction narrows $R(θ)$, improving stability by up to 75% in Walker2D, while preserving comparable evaluation returns.

</details>


### [463] [The Homogeneity Trap: Spectral Collapse in Doubly-Stochastic Deep Networks](https://arxiv.org/abs/2601.02080)
*Yizhi Liu*

Main category: cs.LG

Relevance: 65.0

TL;DR: 本文揭示了双随机矩阵约束网络中的"同质性陷阱"现象：最大熵偏置导致混合算子趋向均匀重心，抑制次主导奇异值，过滤高频特征分量，限制网络的有效感受野。


<details>
  <summary>Details</summary>
Motivation: 双随机矩阵在深度架构中广泛用于保持结构稳定性和概率可解释性，但作者发现这些约束存在关键的谱退化现象，即"同质性陷阱"，这限制了网络的表达能力。

Method: 通过理论分析推导了谱边界，将次主导奇异值σ₂与网络有效深度联系起来；分析了Sinkhorn投影的最大熵偏置如何驱动混合算子趋向均匀重心；证明了层归一化在噪声主导机制下无法缓解这种崩溃。

Result: 发现高熵约束将特征变换限制在浅层有效感受野内；当信噪比低于临界阈值时，几何结构会因噪声诱导的正交崩溃而不可逆地丢失；揭示了DSM约束网络中熵稳定性和谱表达性之间的基本权衡。

Conclusion: 双随机矩阵约束在提供数值稳定性和概率可解释性的同时，存在固有的谱退化问题，需要在熵稳定性和谱表达性之间进行权衡，这对基于Sinkhorn的注意力机制等架构设计有重要启示。

Abstract: Doubly-stochastic matrices (DSM) are increasingly utilized in structure-preserving deep architectures -- such as Optimal Transport layers and Sinkhorn-based attention -- to enforce numerical stability and probabilistic interpretability. In this work, we identify a critical spectral degradation phenomenon inherent to these constraints, termed the Homogeneity Trap. We demonstrate that the maximum-entropy bias, typical of Sinkhorn-based projections, drives the mixing operator towards the uniform barycenter, thereby suppressing the subdominant singular value σ_2 and filtering out high-frequency feature components. We derive a spectral bound linking σ_2 to the network's effective depth, showing that high-entropy constraints restrict feature transformation to a shallow effective receptive field. Furthermore, we formally demonstrate that Layer Normalization fails to mitigate this collapse in noise-dominated regimes; specifically, when spectral filtering degrades the Signal-to-Noise Ratio (SNR) below a critical threshold, geometric structure is irreversibly lost to noise-induced orthogonal collapse. Our findings highlight a fundamental trade-off between entropic stability and spectral expressivity in DSM-constrained networks.

</details>


### [464] [A Differentiable Adversarial Framework for Task-Aware Data Subsampling](https://arxiv.org/abs/2601.02081)
*Jiacheng Lyu,Bihua Bao*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出ASSS框架，将数据降采样重构为可微分的端到端学习问题，通过对抗博弈为样本分配连续重要性权重，实现任务感知的数据选择


<details>
  <summary>Details</summary>
Motivation: 大规模数据集给模型训练带来计算挑战，传统数据降采样方法作为静态、任务无关的预处理步骤，通常会丢弃对下游预测关键的信息

Method: 提出对抗性软选择降采样(ASSS)框架，通过选择器网络和任务网络之间的对抗博弈，选择器学习为样本分配连续重要性权重，使用Gumbel-Softmax松弛实现直接优化

Result: 在四个大规模真实世界数据集上的实验表明，ASSS始终优于聚类和最近邻稀疏化等启发式降采样基线，有时甚至能超越完整数据集的训练性能

Conclusion: 将任务感知的数据降采样建立为可学习组件，为有效的大规模数据学习提供了原则性解决方案

Abstract: The proliferation of large-scale datasets poses a major computational challenge to model training. The traditional data subsampling method works as a static, task independent preprocessing step which usually discards information that is critical to downstream prediction. In this paper, we introduces the antagonistic soft selection subsampling (ASSS) framework as is a novel paradigm that reconstructs data reduction into a differentiable end-to-end learning problem. ASSS uses the adversarial game between selector network and task network, and selector network learning assigns continuous importance weights to samples. This direct optimization implemented by Gumbel-Softmax relaxation allows the selector to identify and retain samples with the maximum amount of information for a specific task target under the guidance of the loss function that balances the fidelity and sparsity of the prediction. Theoretical analysis links this framework with the information bottleneck principle. Comprehensive experiments on four large-scale real world datasets show that ASSS has always been better than heuristic subsampling baselines such as clustering and nearest neighbor thinning in maintaining model performance. It is worth noting that ASSS can not only match, but also sometimes exceed the training performance of the entire dataset, showcasing the effect of intelligent denoising. This work establishes task aware data subsampling as a learnable component, providing a principled solution for effective large-scale data learning.

</details>


### [465] [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](https://arxiv.org/abs/2601.02253)
*Emrah Mete,Emin Erkan Korkmaz*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出Neuro-Channel Networks (NCN)，一种无需乘法的神经网络架构，用通道宽度和神经递质参数替代传统权重，仅使用加法、减法和位运算，旨在降低对GPU等高性能硬件的依赖。


<details>
  <summary>Details</summary>
Motivation: 深度学习对GPU等高性能硬件的依赖限制了AI在边缘设备的部署，这些硬件昂贵、能耗高且供应短缺。生物神经系统的高效性启发了无需乘法运算的架构设计。

Method: 用通道宽度物理限制信号幅度，用神经递质参数基于符号逻辑调节信号传输。前向传播仅使用加法、减法和位运算（最小值、符号），完全消除浮点乘法。

Result: NCN能够100%准确解决非线性可分问题（如XOR和Majority函数），证明其无需乘法权重即可形成复杂决策边界的能力。

Conclusion: NCN为下一代神经形态硬件提供了高效替代方案，可在普通CPU或超低功耗芯片上运行复杂模型，无需依赖昂贵的GPU集群。

Abstract: The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply scarcity, limiting the ubiquity of Artificial Intelligence (AI) deployment on edge devices. The core of this inefficiency stems from the standard artificial perceptron's dependence on intensive matrix multiplications. However, biological nervous systems achieve unparalleled efficiency without such arithmetic intensity; synaptic signal transmission is regulated by physical ion channel limits and chemical neurotransmitter levels rather than a process that can be analogous to arithmetic multiplication. Inspired by this biological mechanism, we propose Neuro-Channel Networks (NCN), a novel multiplication-free architecture designed to decouple AI from expensive hardware dependencies. In our model, weights are replaced with Channel Widths that physically limit the signal magnitude, while a secondary parameter acts as a Neurotransmitter to regulate Signal Transmission based on sign logic. The forward pass relies exclusively on addition, subtraction, and bitwise operations (minimum, sign), eliminating floating-point multiplication entirely. In this proof-of-concept study, we demonstrate that NCNs can solve non-linearly separable problems like XOR and the Majority function with 100% accuracy using standard backpropagation, proving their capability to form complex decision boundaries without multiplicative weights. This architecture offers a highly efficient alternative for next-generation neuromorphic hardware, paving the way for running complex models on commodity CPUs or ultra-low-power chips without relying on costly GPU clusters.

</details>


### [466] [NeuroSSM: Multiscale Differential State-Space Modeling for Context-Aware fMRI Analysis](https://arxiv.org/abs/2601.01229)
*Furkan Genç,Boran İsmet Macun,Sait Sarper Özaslan,Emine U. Saritas,Tolga Çukur*

Main category: eess.SP

Relevance: 65.0

TL;DR: NeuroSSM：一种用于原始BOLD信号fMRI分析的选择性状态空间模型，通过多尺度状态空间主干和并行差分分支，同时捕捉快速瞬态动态和缓慢全局趋势。


<details>
  <summary>Details</summary>
Motivation: fMRI分析需要捕捉从快速瞬态动态到缓慢大规模波动的多尺度时间结构。现有深度学习方法难以联合建模长fMRI时间序列中的这些动态：transformer计算成本高，而现有SSM方法通常基于功能连接表示且采用单尺度处理，无法同时表示快速和缓慢动态。

Method: 提出NeuroSSM架构：1）多尺度状态空间主干，同时捕捉快速和缓慢动态；2）并行差分分支，增强对瞬态状态变化的敏感性。该模型直接处理原始BOLD信号，实现端到端分析。

Result: 在临床和非临床数据集上的实验表明，NeuroSSM在性能和效率方面均优于最先进的fMRI分析方法，实现了竞争性的表现。

Conclusion: NeuroSSM通过多尺度状态空间建模和差分增强，有效解决了fMRI分析中联合捕捉多尺度时间动态的挑战，为原始BOLD信号分析提供了高效准确的解决方案。

Abstract: Accurate fMRI analysis requires sensitivity to temporal structure across multiple scales, as BOLD signals encode cognitive processes that emerge from fast transient dynamics to slower, large-scale fluctuations. Existing deep learning (DL) approaches to temporal modeling face challenges in jointly capturing these dynamics over long fMRI time series. Among current DL models, transformers address long-range dependencies by explicitly modeling pairwise interactions through attention, but the associated quadratic computational cost limits effective integration of temporal dependencies across long fMRI sequences. Selective state-space models (SSMs) instead model long-range temporal dependencies implicitly through latent state evolution in a dynamical system, enabling efficient propagation of dependencies over time. However, recent SSM-based approaches for fMRI commonly operate on derived functional connectivity representations and employ single-scale temporal processing. These design choices constrain the ability to jointly represent fast transient dynamics and slower global trends within a single model. We propose NeuroSSM, a selective state-space architecture designed for end-to-end analysis of raw BOLD signals in fMRI time series. NeuroSSM addresses the above limitations through two complementary design components: a multiscale state-space backbone that captures fast and slow dynamics concurrently, and a parallel differencing branch that increases sensitivity to transient state changes. Experiments on clinical and non-clinical datasets demonstrate that NeuroSSM achieves competitive performance and efficiency against state-of-the-art fMRI analysis methods.

</details>


### [467] [Variance-Reduced Diffusion Sampling via Conditional Score Expectation Identity](https://arxiv.org/abs/2601.01594)
*Alois Duston,Tan Bui-Thanh*

Main category: stat.ML

Relevance: 65.0

TL;DR: 提出了条件分数期望（CSE）恒等式，基于此开发了自归一化重要性采样的分数估计器，并与Tweedie估计器进行最优混合以减少方差，应用于贝叶斯逆问题。


<details>
  <summary>Details</summary>
Motivation: 针对扩散过程的分数估计问题，现有方法如Tweedie估计器存在局限性。本文旨在通过建立精确的数学关系（CSE恒等式）来改进分数估计，减少方差并提高采样质量。

Method: 1) 证明仿射扩散过程的CSE恒等式；2) 基于CSE开发自归一化重要性采样（SNIS）分数估计器；3) 分析CSE与Tweedie估计器的关系；4) 推导方差最小化的混合估计器；5) 扩展到贝叶斯逆问题。

Result: CSE估计器与Tweedie估计器在目标为高斯分布时呈负相关，在小时间步长下也表现出相同行为。最优混合估计器相比基线方法减少了方差，在固定计算预算下提高了样本质量。在图像重建和PDE逆问题上展示了改进的重建质量和样本多样性。

Conclusion: CSE恒等式为扩散过程的分数估计提供了新的理论基础，基于此的最优混合估计器在理论和实验上都表现出优越性，特别适用于贝叶斯逆问题等应用场景。

Abstract: We introduce and prove a \textbf{Conditional Score Expectation (CSE)} identity: an exact relation for the marginal score of affine diffusion processes that links scores across time via a conditional expectation under the forward dynamics. Motivated by this identity, we propose a CSE-based statistical estimator for the score using a Self-Normalized Importance Sampling (SNIS) procedure with prior samples and forward noise. We analyze its relationship to the standard Tweedie estimator, proving anti-correlation for Gaussian targets and establishing the same behavior for general targets in the small time-step regime. Exploiting this structure, we derive a variance-minimizing blended score estimator given by a state--time dependent convex combination of the CSE and Tweedie estimators. Numerical experiments show that this optimal-blending estimator reduces variance and improves sample quality for a fixed computational budget compared to either baseline. We further extend the framework to Bayesian inverse problems via likelihood-informed SNIS weights, and demonstrate improved reconstruction quality and sample diversity on high-dimensional image reconstruction tasks and PDE-governed inverse problems.

</details>


### [468] [From Mice to Trains: Amortized Bayesian Inference on Graph Data](https://arxiv.org/abs/2601.02241)
*Svenja Jedhoff,Elizaveta Semenova,Aura Raulo,Anne Meyer,Paul-Christian Bürkner*

Main category: stat.ML

Relevance: 65.0

TL;DR: 论文提出了一种用于图结构数据的摊销贝叶斯推理方法，通过结合置换不变的图编码器和灵活的神经后验估计器，在节点、边和图级别参数上进行推理。


<details>
  <summary>Details</summary>
Motivation: 图数据在多个领域普遍存在，但图结构数据的推理面临置换不变性、可扩展性和复杂长程依赖等挑战。摊销贝叶斯推理作为一种基于模拟的框架，可以用于快速、无需似然函数的后验推理，但需要适应图数据的特殊性质。

Method: 采用两模块流水线：1) 摘要网络将属性图映射到固定长度表示；2) 推理网络近似参数后验分布。评估了多种神经网络架构作为摘要网络，并在合成和真实世界数据集上进行性能评估。

Result: 在受控合成设置和两个真实世界领域（生物学和物流）中评估了不同架构的性能，包括恢复能力和校准度。

Conclusion: 将摊销贝叶斯推理适应于图数据是可行的，通过结合置换不变的图编码器和神经后验估计器，可以有效处理图结构数据的推理挑战。

Abstract: Graphs arise across diverse domains, from biology and chemistry to social and information networks, as well as in transportation and logistics. Inference on graph-structured data requires methods that are permutation-invariant, scalable across varying sizes and sparsities, and capable of capturing complex long-range dependencies, making posterior estimation on graph parameters particularly challenging. Amortized Bayesian Inference (ABI) is a simulation-based framework that employs generative neural networks to enable fast, likelihood-free posterior inference. We adapt ABI to graph data to address these challenges to perform inference on node-, edge-, and graph-level parameters. Our approach couples permutation-invariant graph encoders with flexible neural posterior estimators in a two-module pipeline: a summary network maps attributed graphs to fixed-length representations, and an inference network approximates the posterior over parameters. In this setting, several neural architectures can serve as the summary network. In this work we evaluate multiple architectures and assess their performance on controlled synthetic settings and two real-world domains - biology and logistics - in terms of recovery and calibration.

</details>


### [469] [Harvesting AlphaEarth: Benchmarking the Geospatial Foundation Model for Agricultural Downstream Tasks](https://arxiv.org/abs/2601.00857)
*Yuchi Ma,Yawen Shen,Anu Swatantran,David B. Lobell*

Main category: cs.LG

Relevance: 45.0

TL;DR: 评估AlphaEarth Foundation (AEF)地理空间基础模型在农业下游任务中的表现，包括作物产量预测、耕作制图和覆盖作物制图，并与传统遥感模型进行比较。


<details>
  <summary>Details</summary>
Motivation: 虽然AEF等地理空间基础模型在土地覆盖分类任务中表现优异，但在农业监测应用方面缺乏深入评估。需要全面比较AEF模型与传统遥感模型在不同农业场景下的表现，为研究者和实践者提供指导。

Method: 使用AEF嵌入在美国三个农业下游任务中进行评估：作物产量预测、耕作制图和覆盖作物制图。从公共和私人来源编译数据集，在不同尺度和位置评估AEF嵌入，并训练遥感模型作为对比模型。

Result: AEF模型在所有任务中表现良好，在产量预测和县级耕作制图任务中与专门构建的遥感模型竞争力相当。但也发现AEF嵌入存在空间可迁移性有限、可解释性低和时间敏感性不足等局限性。

Conclusion: AEF嵌入在农业应用中需谨慎使用，特别是在时间敏感性、泛化能力和可解释性要求较高的场景。虽然表现良好，但存在明显局限性。

Abstract: Geospatial foundation models (GFMs) have emerged as a promising approach to overcoming the limitations in existing featurization methods. More recently, Google DeepMind has introduced AlphaEarth Foundation (AEF), a GFM pre-trained using multi-source EOs across continuous time. An annual and global embedding dataset is produced using AEF that is ready for analysis and modeling. The internal experiments show that AEF embeddings have outperformed operational models in 15 EO tasks without re-training. However, those experiments are mostly about land cover and land use classification. Applying AEF and other GFMs to agricultural monitoring require an in-depth evaluation in critical agricultural downstream tasks. There is also a lack of comprehensive comparison between the AEF-based models and traditional remote sensing (RS)-based models under different scenarios, which could offer valuable guidance for researchers and practitioners. This study addresses some of these gaps by evaluating AEF embeddings in three agricultural downstream tasks in the U.S., including crop yield prediction, tillage mapping, and cover crop mapping. Datasets are compiled from both public and private sources to comprehensively evaluate AEF embeddings across tasks at different scales and locations, and RS-based models are trained as comparison models. AEF-based models generally exhibit strong performance on all tasks and are competitive with purpose-built RS-based models in yield prediction and county-level tillage mapping when trained on local data. However, we also find several limitations in current AEF embeddings, such as limited spatial transferability compared to RS-based models, low interpretability, and limited time sensitivity. These limitations recommend caution when applying AEF embeddings in agriculture, where time sensitivity, generalizability, and interpretability is important.

</details>


### [470] [Enhanced Data-Driven Product Development via Gradient Based Optimization and Conformalized Monte Carlo Dropout Uncertainty Estimation](https://arxiv.org/abs/2601.00932)
*Andrea Thomas Nava,Lijo Johny,Fabio Azzalini,Johannes Schneider,Arianna Casanova*

Main category: cs.LG

Relevance: 45.0

TL;DR: 提出了一种用于数据驱动产品开发（DDPD）的框架，结合联合神经网络优化多个相关属性，并引入ConfMC方法提供不确定性估计和覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 数据驱动产品开发需要同时优化多个相关属性，现有方法缺乏可靠的不确定性估计和覆盖保证，难以在实际应用中提供可信的预测区间。

Method: 1) 使用神经网络学习设计规格与产品属性关系；2) 应用投影梯度下降寻找最优设计；3) 采用联合神经网络处理多目标优化；4) 提出ConfMC方法（结合嵌套保形预测和蒙特卡洛dropout）进行不确定性估计。

Result: 在五个真实数据集上的实验表明，该方法达到SOTA性能，提供自适应非均匀预测区间，调整覆盖水平时无需重新训练。

Conclusion: 提出的框架能够有效处理多属性优化问题，ConfMC方法提供了模型无关的有限样本覆盖保证，增强了数据驱动产品开发的可信度。

Abstract: Data-Driven Product Development (DDPD) leverages data to learn the relationship between product design specifications and resulting properties. To discover improved designs, we train a neural network on past experiments and apply Projected Gradient Descent to identify optimal input features that maximize performance. Since many products require simultaneous optimization of multiple correlated properties, our framework employs joint neural networks to capture interdependencies among targets. Furthermore, we integrate uncertainty estimation via \emph{Conformalised Monte Carlo Dropout} (ConfMC), a novel method combining Nested Conformal Prediction with Monte Carlo dropout to provide model-agnostic, finite-sample coverage guarantees under data exchangeability. Extensive experiments on five real-world datasets show that our method matches state-of-the-art performance while offering adaptive, non-uniform prediction intervals and eliminating the need for retraining when adjusting coverage levels.

</details>


### [471] [Improving Variational Autoencoder using Random Fourier Transformation: An Aviation Safety Anomaly Detection Case-Study](https://arxiv.org/abs/2601.01016)
*Ata Akbari Asanjan,Milad Memarzadeh,Bryan Matthews,Nikunj Oza*

Main category: cs.LG

Relevance: 45.0

TL;DR: 论文研究了在自编码器和变分自编码器中使用随机傅里叶变换(RFT)来改进训练和推理，发现RFT能让模型同时学习低频和高频特征，而传统DNN则从低频开始逐步学习高频。作者还提出了可训练的RFT变体，并在异常检测任务中展示了傅里叶变换模型的优势。


<details>
  <summary>Details</summary>
Motivation: 传统深度神经网络在学习过程中通常从低频特征开始，逐步学习高频特征，这种学习模式可能影响模型性能。作者希望通过引入傅里叶变换来改善这一过程，使模型能够同时学习不同频率的特征，从而提高模型在数据表示和异常检测任务中的表现。

Method: 1. 在自编码器和变分自编码器中应用随机傅里叶变换(RFT)
2. 使用频率原理分析RFT对模型训练行为的影响
3. 提出可训练的RFT变体，利用现有计算图训练傅里叶展开
4. 在低维合成数据集上进行数据表示实验
5. 在航空安全数据集(Dashlink)上进行高维重建式异常检测实验

Result: 1. 使用傅里叶变换的模型相比传统模型表现出优越性
2. RFT使模型能够同时学习低频和高频特征，而传统DNN则从低频开始逐步学习
3. 在可训练RFT与随机RFT的比较中，结果尚无定论，未能明确显示可训练变体的优势

Conclusion: 傅里叶变换在深度神经网络中具有重要价值，能够改变模型的学习模式，使其同时处理不同频率的特征。虽然可训练RFT的优越性尚未明确，但傅里叶变换整体上能提升模型在数据表示和异常检测任务中的性能。

Abstract: In this study, we focus on the training process and inference improvements of deep neural networks (DNNs), specifically Autoencoders (AEs) and Variational Autoencoders (VAEs), using Random Fourier Transformation (RFT). We further explore the role of RFT in model training behavior using Frequency Principle (F-Principle) analysis and show that models with RFT turn to learn low frequency and high frequency at the same time, whereas conventional DNNs start from low frequency and gradually learn (if successful) high-frequency features. We focus on reconstruction-based anomaly detection using autoencoder and variational autoencoder and investigate the RFT's role. We also introduced a trainable variant of RFT that uses the existing computation graph to train the expansion of RFT instead of it being random. We showcase our findings with two low-dimensional synthetic datasets for data representation, and an aviation safety dataset, called Dashlink, for high-dimensional reconstruction-based anomaly detection. The results indicate the superiority of models with Fourier transformation compared to the conventional counterpart and remain inconclusive regarding the benefits of using trainable Fourier transformation in contrast to the Random variant.

</details>


### [472] [Expanding the Chaos: Neural Operator for Stochastic (Partial) Differential Equations](https://arxiv.org/abs/2601.01021)
*Dai Shi,Lequan Lin,Andi Han,Luke Thompson,José Miguel Hernández-Lobato,Zhiyong Wang,Junbin Gao*

Main category: cs.LG

Relevance: 45.0

TL;DR: 该论文提出了一种基于Wiener混沌展开的神经算子架构，用于学习随机微分方程和随机偏微分方程的解算子，通过将噪声投影到正交Wick-Hermite特征上，并用神经算子参数化确定性混沌系数，实现从噪声到完整解轨迹的单次前向传播。


<details>
  <summary>Details</summary>
Motivation: 随机微分方程和随机偏微分方程是建模自然科学和机器学习中随机动力学的基本工具。开发深度学习模型来近似它们的解算子，不仅有望提供快速实用的求解器，还可能启发从新视角解决经典学习任务的模型。

Method: 基于经典Wiener混沌展开设计神经算子架构：将驱动噪声路径投影到正交Wick-Hermite特征上，用神经算子参数化得到的确定性混沌系数，从而可以从噪声中单次前向传播重构完整解轨迹。理论方面研究了多维SDE和半线性SPDE的WCE结果，明确写出其混沌系数的耦合ODE/PDE系统。

Result: 在多个问题上验证了模型：经典SPDE基准测试、图像上的扩散一步采样、图上的拓扑插值、金融外推、参数估计以及洪水预测的流形SDE，展示了竞争性的准确度和广泛的适用性。

Conclusion: 基于Wiener混沌展开的神经算子为学习SDE/SPDE解算子提供了一种实用且可扩展的方法，适用于多种领域。

Abstract: Stochastic differential equations (SDEs) and stochastic partial differential equations (SPDEs) are fundamental tools for modeling stochastic dynamics across the natural sciences and modern machine learning. Developing deep learning models for approximating their solution operators promises not only fast, practical solvers, but may also inspire models that resolve classical learning tasks from a new perspective. In this work, we build on classical Wiener chaos expansions (WCE) to design neural operator (NO) architectures for SPDEs and SDEs: we project the driving noise paths onto orthonormal Wick Hermite features and parameterize the resulting deterministic chaos coefficients with neural operators, so that full solution trajectories can be reconstructed from noise in a single forward pass. On the theoretical side, we investigate the classical WCE results for the class of multi-dimensional SDEs and semilinear SPDEs considered here by explicitly writing down the associated coupled ODE/PDE systems for their chaos coefficients, which makes the separation between stochastic forcing and deterministic dynamics fully explicit and directly motivates our model designs. On the empirical side, we validate our models on a diverse suite of problems: classical SPDE benchmarks, diffusion one-step sampling on images, topological interpolation on graphs, financial extrapolation, parameter estimation, and manifold SDEs for flood prediction, demonstrating competitive accuracy and broad applicability. Overall, our results indicate that WCE-based neural operators provide a practical and scalable way to learn SDE/SPDE solution operators across diverse domains.

</details>


### [473] [Sobolev Approximation of Deep ReLU Network in Log-weighted Barron Space](https://arxiv.org/abs/2601.01295)
*Changhoon Song,Seungchan Ko,Youngjoon Hong*

Main category: cs.LG

Relevance: 45.0

TL;DR: 论文提出了对数加权Barron空间，相比经典Barron空间具有更弱的正则性要求，证明了深度ReLU网络在该空间中的逼近能力，阐明了深度如何降低高效表示所需的正则性要求。


<details>
  <summary>Details</summary>
Motivation: 经典Barron空间理论虽然解释了神经网络对高维函数的逼近能力，但仍要求比Sobolev空间更强的正则性条件，且现有深度敏感结果通常假设约束条件如sL ≤ 1/2。需要更弱的假设来更好地解释深度模型在高维数据上的实际成功。

Method: 引入对数加权Barron空间，研究其嵌入性质并通过Rademacher复杂度进行统计分析；证明深度ReLU网络在该空间中的逼近能力；定义一族空间并建立H1范数下的逼近界；识别保持这些速率的最大深度尺度。

Result: 对数加权Barron空间比任何经典Barron空间的要求都弱；深度ReLU网络在该空间中具有明确的深度依赖逼近能力；建立了H1范数下的逼近界并识别了最大深度尺度。

Conclusion: 深度降低了高效表示所需的正则性要求，为深度架构超越经典Barron设置的性能提供了更精确的解释，并为其在高维问题中的稳定使用提供了理论基础。

Abstract: Universal approximation theorems show that neural networks can approximate any continuous function; however, the number of parameters may grow exponentially with the ambient dimension, so these results do not fully explain the practical success of deep models on high-dimensional data. Barron space theory addresses this: if a target function belongs to a Barron space, a two-layer network with $n$ parameters achieves an $O(n^{-1/2})$ approximation error in $L^2$. Yet classical Barron spaces $\mathscr{B}^{s+1}$ still require stronger regularity than Sobolev spaces $H^s$, and existing depth-sensitive results often assume constraints such as $sL \le 1/2$. In this paper, we introduce a log-weighted Barron space $\mathscr{B}^{\log}$, which requires a strictly weaker assumption than $\mathscr{B}^s$ for any $s>0$. For this new function space, we first study embedding properties and carry out a statistical analysis via the Rademacher complexity. Then we prove that functions in $\mathscr{B}^{\log}$ can be approximated by deep ReLU networks with explicit depth dependence. We then define a family $\mathscr{B}^{s,\log}$, establish approximation bounds in the $H^1$ norm, and identify maximal depth scales under which these rates are preserved. Our results clarify how depth reduces regularity requirements for efficient representation, offering a more precise explanation for the performance of deep architectures beyond the classical Barron setting, and for their stable use in high-dimensional problems used today.

</details>


### [474] [A Graph-based Framework for Online Time Series Anomaly Detection Using Model Ensemble](https://arxiv.org/abs/2601.01403)
*Zewei Yu,Jianqiu Xu,Caimin Li*

Main category: cs.LG

Relevance: 45.0

TL;DR: GDME：基于图模型集成的无监督在线时间序列异常检测框架，通过动态模型池和图结构进行社区检测选择集成子集，能适应概念漂移的流数据。


<details>
  <summary>Details</summary>
Motivation: 工业系统中流数据量不断增加，在线异常检测成为关键任务。现有方法多为离线设计或难以有效处理异构流数据，需要能适应快速演化数据模式的在线检测方法。

Method: 提出GDME框架：1）维护动态模型池，持续修剪性能不佳模型并引入新模型；2）使用动态图结构表示模型间关系；3）通过图上的社区检测选择适当的集成子集；4）利用图结构变化监测概念漂移，适应演化流数据。

Result: 在7个异构时间序列数据集上实验表明，GDME优于现有在线异常检测方法，提升达24%。其集成策略相比单个模型和平均集成提供更优检测性能，计算效率具有竞争力。

Conclusion: GDME通过动态图模型集成有效处理在线时间序列异常检测，能适应概念漂移和异构流数据，在检测性能和计算效率方面表现优异。

Abstract: With the increasing volume of streaming data in industrial systems, online anomaly detection has become a critical task. The diverse and rapidly evolving data patterns pose significant challenges for online anomaly detection. Many existing anomaly detection methods are designed for offline settings or have difficulty in handling heterogeneous streaming data effectively. This paper proposes GDME, an unsupervised graph-based framework for online time series anomaly detection using model ensemble. GDME maintains a dynamic model pool that is continuously updated by pruning underperforming models and introducing new ones. It utilizes a dynamic graph structure to represent relationships among models and employs community detection on the graph to select an appropriate subset for ensemble. The graph structure is also used to detect concept drift by monitoring structural changes, allowing the framework to adapt to evolving streaming data. Experiments on seven heterogeneous time series demonstrate that GDME outperforms existing online anomaly detection methods, achieving improvements of up to 24%. In addition, its ensemble strategy provides superior detection performance compared with both individual models and average ensembles, with competitive computational efficiency.

</details>


### [475] [Who is the Winning Algorithm? Rank Aggregation for Comparative Studies](https://arxiv.org/abs/2601.01664)
*Amichai Painsky*

Main category: cs.LG

Relevance: 45.0

TL;DR: 提出新框架利用完整排名数据（不仅是获胜次数）来估计机器学习算法在未见数据集上的获胜概率，相比现有方法有显著改进


<details>
  <summary>Details</summary>
Motivation: 当前评估机器学习算法性能时，通常只统计在基准数据集上的获胜次数（最大似然方法），但忽略了完整的排名信息（第二名、第三名等）。这些完整排名包含更多信息，可以更准确地预测算法在未来未见数据集上的表现。

Method: 引入新的概念框架，利用算法在基准数据集上的完整排名（不仅仅是获胜次数），来估计每个算法在未见数据集上的获胜概率。该方法能够更有效地利用排名信息进行概率估计。

Result: 在合成和真实世界示例中，提出的框架显著优于当前已知方法，能够更准确地预测算法在未见数据集上的获胜概率。

Conclusion: 利用完整排名信息而非仅获胜次数，可以显著提高机器学习算法性能评估的准确性，为算法选择和比较提供了更可靠的方法。

Abstract: Consider a collection of m competing machine learning algorithms. Given their performance on a benchmark of datasets, we would like to identify the best performing algorithm. Specifically, which algorithm is most likely to ``win'' (rank highest) on a future, unseen dataset. The standard maximum likelihood approach suggests counting the number of wins per each algorithm. In this work, we argue that there is much more information in the complete rankings. That is, the number of times that each algorithm finished second, third and so forth. Yet, it is not entirely clear how to effectively utilize this information for our purpose. In this work we introduce a novel conceptual framework for estimating the win probability for each of the m algorithms, given their complete rankings over a benchmark of datasets. Our proposed framework significantly improves upon currently known methods in synthetic and real-world examples.

</details>


### [476] [DiMEx: Breaking the Cold Start Barrier in Data-Free Model Extraction via Latent Diffusion Priors](https://arxiv.org/abs/2601.01688)
*Yash Thesia,Meera Suthar*

Main category: cs.LG

Relevance: 45.0

TL;DR: DiMEx框架利用预训练潜在扩散模型的语义先验，通过随机嵌入贝叶斯优化在潜在空间中合成高保真查询，实现高效数据无模型窃取，并提出混合状态集成防御来检测此类攻击


<details>
  <summary>Details</summary>
Motivation: 解决数据无模型提取(DFME)中的"冷启动"问题，传统GAN方法需要大量查询从随机噪声收敛到有意义数据，效率低下

Method: 1. DiMEx攻击：利用预训练潜在扩散模型的语义先验，在生成器潜在空间中使用随机嵌入贝叶斯优化(REMBO)合成高保真查询；2. HSE防御：混合状态集成方法，通过识别潜在空间攻击的独特"优化轨迹"来检测攻击

Result: DiMEx在SVHN上仅用2000次查询就达到52.1%的协议率，比最先进的GAN基线高出16%以上；HSE防御将攻击成功率抑制到21.6%，且延迟可忽略

Conclusion: 潜在扩散模型为模型窃取攻击提供了强大的语义先验，但通过分析攻击的时序特征可以开发有效的防御机制

Abstract: Model stealing attacks pose an existential threat to Machine Learning as a Service (MLaaS), allowing adversaries to replicate proprietary models for a fraction of their training cost. While Data-Free Model Extraction (DFME) has emerged as a stealthy vector, it remains fundamentally constrained by the "Cold Start" problem: GAN-based adversaries waste thousands of queries converging from random noise to meaningful data. We propose DiMEx, a framework that weaponizes the rich semantic priors of pre-trained Latent Diffusion Models to bypass this initialization barrier entirely. By employing Random Embedding Bayesian Optimization (REMBO) within the generator's latent space, DiMEx synthesizes high-fidelity queries immediately, achieving 52.1 percent agreement on SVHN with just 2,000 queries - outperforming state-of-the-art GAN baselines by over 16 percent. To counter this highly semantic threat, we introduce the Hybrid Stateful Ensemble (HSE) defense, which identifies the unique "optimization trajectory" of latent-space attacks. Our results demonstrate that while DiMEx evades static distribution detectors, HSE exploits this temporal signature to suppress attack success rates to 21.6 percent with negligible latency.

</details>


### [477] [TT-FSI: Scalable Faithful Shapley Interactions via Tensor-Train](https://arxiv.org/abs/2601.01903)
*Ungsik Kim,Suwon Lee*

Main category: cs.LG

Relevance: 45.0

TL;DR: TT-FSI：利用矩阵乘积算子（MPO）高效计算忠实Shapley交互指数（FSI），将时间复杂度从O(d^ℓ·2^d)降低到O(ℓ²d³·2^d)，内存使用从O(4^d)降低到O(ℓd²)，实现了指数级改进。


<details>
  <summary>Details</summary>
Motivation: 忠实Shapley交互指数（FSI）是唯一满足忠实公理的Shapley交互指数，但计算复杂度极高（O(d^ℓ·2^d)时间，O(4^d)内存），限制了其在实际应用中的可扩展性。

Method: 利用FSI的代数结构，通过矩阵乘积算子（MPO）表示线性算子v↦FSI(v)，证明其张量网络秩为O(ℓd)，从而设计高效的扫描算法，大幅降低计算和存储需求。

Result: 在6个数据集（d=8到d=20）上实验显示：相比基线加速280倍，相比SHAP-IQ加速85倍，内存减少290倍。TT-FSI可扩展到d=20（100万个联盟），而所有竞争方法均失败。

Conclusion: TT-FSI通过张量网络方法实现了FSI的高效计算，解决了可扩展性问题，使忠实Shapley交互分析能够应用于更高维度的实际问题。

Abstract: The Faithful Shapley Interaction (FSI) index uniquely satisfies the faithfulness axiom among Shapley interaction indices, but computing FSI requires $O(d^\ell \cdot 2^d)$ time and existing implementations use $O(4^d)$ memory. We present TT-FSI, which exploits FSI's algebraic structure via Matrix Product Operators (MPO). Our main theoretical contribution is proving that the linear operator $v \mapsto \text{FSI}(v)$ admits an MPO representation with TT-rank $O(\ell d)$, enabling an efficient sweep algorithm with $O(\ell^2 d^3 \cdot 2^d)$ time and $O(\ell d^2)$ core storage an exponential improvement over existing methods. Experiments on six datasets ($d=8$ to $d=20$) demonstrate up to 280$\times$ speedup over baseline, 85$\times$ over SHAP-IQ, and 290$\times$ memory reduction. TT-FSI scales to $d=20$ (1M coalitions) where all competing methods fail.

</details>


### [478] [Distorted Distributional Policy Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2601.01917)
*Ryo Iwaki,Takayuki Osogami*

Main category: cs.LG

Relevance: 45.0

TL;DR: 论文提出了一种新的离线分布强化学习方法，通过引入分位数扭曲概念实现非均匀悲观主义，解决了现有方法因均匀低估分位数导致的过度保守问题。


<details>
  <summary>Details</summary>
Motivation: 分布强化学习（DRL）在在线场景中表现出色，但在离线场景中效果有限。作者假设现有离线DRL方法的主要限制在于它们均匀低估回报分位数的方法，这种均匀悲观主义会导致过度保守的价值估计，从而阻碍泛化和性能提升。

Method: 引入了一个新概念——分位数扭曲，通过根据支持数据的可用性调整保守程度，实现非均匀悲观主义。该方法基于理论分析，并通过实验验证。

Result: 实证验证表明，该方法相比均匀悲观主义方法表现出改进的性能。

Conclusion: 通过引入分位数扭曲实现非均匀悲观主义，可以有效解决离线分布强化学习中的过度保守问题，提升算法性能。

Abstract: While Distributional Reinforcement Learning (DRL) methods have demonstrated strong performance in online settings, its success in offline scenarios remains limited. We hypothesize that a key limitation of existing offline DRL methods lies in their approach to uniformly underestimate return quantiles. This uniform pessimism can lead to overly conservative value estimates, ultimately hindering generalization and performance. To address this, we introduce a novel concept called quantile distortion, which enables non-uniform pessimism by adjusting the degree of conservatism based on the availability of supporting data. Our approach is grounded in theoretical analysis and empirically validated, demonstrating improved performance over uniform pessimism.

</details>


### [479] [Multivariate Time-series Anomaly Detection via Dynamic Model Pool & Ensembling](https://arxiv.org/abs/2601.02037)
*Wei Hu,Zewei Yu,Jianqiu Xu*

Main category: cs.LG

Relevance: 45.0

TL;DR: 提出DMPEAD框架，通过动态模型池和集成方法改进多元时间序列异常检测，解决了现有多模型方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列异常检测在服务监控、物联网和网络安全等领域至关重要。现有多模型方法存在三个主要问题：1) 选择方法依赖单一模型且对策略敏感；2) 集成方法通常组合所有模型或仅限于单变量数据；3) 大多数方法依赖固定数据维度，限制了可扩展性。

Method: 提出DMPEAD框架：1) 通过参数迁移和多样性度量构建多样化模型池；2) 使用元模型和基于相似性的策略动态更新模型池，实现自适应扩展、子集选择和池合并；3) 通过代理指标排序和top-k聚合在选定子集中集成排名靠前的模型，输出最终异常检测结果。

Result: 在8个真实世界数据集上的广泛实验表明，该模型优于所有基线方法，展示了卓越的适应性和可扩展性。

Conclusion: DMPEAD框架通过动态模型池和集成策略有效解决了多元时间序列异常检测中多模型方法的局限性，在多个真实数据集上表现出色。

Abstract: Multivariate time-series (MTS) anomaly detection is critical in domains such as service monitor, IoT, and network security. While multi-model methods based on selection or ensembling outperform single-model ones, they still face limitations: (i) selection methods rely on a single chosen model and are sensitive to the strategy; (ii) ensembling methods often combine all models or are restricted to univariate data; and (iii) most methods depend on fixed data dimensionality, limiting scalability. To address these, we propose DMPEAD, a Dynamic Model Pool and Ensembling framework for MTS Anomaly Detection. The framework first (i) constructs a diverse model pool via parameter transfer and diversity metric, then (ii) updates it with a meta-model and similarity-based strategy for adaptive pool expansion, subset selection, and pool merging, finally (iii) ensembles top-ranked models through proxy metric ranking and top-k aggregation in the selected subset, outputting the final anomaly detection result. Extensive experiments on 8 real-world datasets show that our model outperforms all baselines, demonstrating superior adaptability and scalability.

</details>


### [480] [Learning with Monotone Adversarial Corruptions](https://arxiv.org/abs/2601.02193)
*Kasper Green Larsen,Chirag Pabbaraju,Abhishek Shetty*

Main category: cs.LG

Relevance: 45.0

TL;DR: 该论文研究机器学习算法对数据可交换性和独立性的依赖程度，通过引入单调对抗性污染模型，发现已知最优二分类算法在面对单调污染时会表现不佳，而基于一致收敛的算法则不受影响。


<details>
  <summary>Details</summary>
Motivation: 研究机器学习算法对数据可交换性和独立性的依赖程度，探索在看似有益的单调污染下，最优算法为何会失效，揭示算法对数据假设的过度依赖。

Method: 引入单调对抗性污染模型：攻击者观察干净i.i.d.数据集后，插入受单调约束的污染点（按真实目标函数标记），分析不同算法在此设定下的表现。

Result: 发现所有已知最优二分类算法在单调污染下都会在新测试点上获得次优期望误差，而基于一致收敛的算法保证不受影响，揭示最优算法对可交换性的过度依赖。

Conclusion: 最优学习算法在面对看似有益的单调污染时会失效，暴露其对数据可交换性的过度依赖，而一致收敛方法更具鲁棒性，这对算法设计和理论分析有重要启示。

Abstract: We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a "clean" i.i.d. dataset, inserts additional "corrupted" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.

</details>


### [481] [Deep Learning Framework for RNA Inverse Folding with Geometric Structure Potentials](https://arxiv.org/abs/2601.00895)
*Annabelle Yao*

Main category: q-bio.QM

Relevance: 45.0

TL;DR: 提出结合几何向量感知器(GVP)与Transformer的深度学习框架，用于RNA逆折叠设计，在序列恢复率和结构相似性上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: RNA的生物学功能依赖于其三维结构，但给定3D构象预测和设计RNA序列（逆折叠）仍然具有挑战性。现有方法在准确性和泛化能力方面存在局限。

Method: 整合几何向量感知器(GVP)层与Transformer架构的端到端深度学习框架。使用BGSU RNA列表的实验解析RNA 3D结构数据集，通过序列恢复率和TM-score评估性能。

Result: 在标准基准测试和RNA-Puzzles上达到SOTA性能：序列恢复率0.481，TM-score 0.332。使用Rfam注释的掩码家族级验证显示强泛化能力。AlphaFold3重折叠验证设计序列的结构相似性。

Conclusion: GVP层捕获的几何特征显著增强了基于Transformer的RNA设计能力，为RNA逆折叠提供了有效的深度学习解决方案。

Abstract: RNA's diverse biological functions stem from its structural versatility, yet accurately predicting and designing RNA sequences given a 3D conformation (inverse folding) remains a challenge. Here, I introduce a deep learning framework that integrates Geometric Vector Perceptron (GVP) layers with a Transformer architecture to enable end-to-end RNA design. I construct a dataset consisting of experimentally solved RNA 3D structures, filtered and deduplicated from the BGSU RNA list, and evaluate performance using both sequence recovery rate and TM-score to assess sequence and structural fidelity, respectively. On standard benchmarks and RNA-Puzzles, my model achieves state-of-the-art performance, with recovery and TM-scores of 0.481 and 0.332, surpassing existing methods across diverse RNA families and length scales. Masked family-level validation using Rfam annotations confirms strong generalization beyond seen families. Furthermore, inverse-folded sequences, when refolded using AlphaFold3, closely resemble native structures, highlighting the critical role of geometric features captured by GVP layers in enhancing Transformer-based RNA design.

</details>


### [482] [Deep Linear Discriminant Analysis Revisited](https://arxiv.org/abs/2601.01619)
*Maxat Tezekbayev,Rustem Takhanov,Arman Bolatov,Zhenisbek Assylbekov*

Main category: stat.ML

Relevance: 45.0

TL;DR: 论文提出Discriminative Negative Log-Likelihood (DNLL)损失函数，解决深度线性判别分析训练中的病理解问题，在保持生成结构的同时获得判别性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度线性判别分析存在两个问题：最大似然训练会导致类别均值漂移、协方差坍缩的病理解；交叉熵训练虽然准确率高，但使分类头与底层生成模型解耦，导致参数估计不一致。需要一种既能保持生成结构又能获得良好判别性能的方法。

Method: 提出Discriminative Negative Log-Likelihood (DNLL)损失函数，在LDA对数似然基础上增加对混合密度的惩罚项。DNLL可解释为标准LDA负对数似然加上一个明确惩罚多个类别同时可能区域的项。使用DNLL训练深度LDA模型。

Result: DNLL训练产生清晰、良好分离的潜在空间，在合成数据和标准图像基准测试中匹配softmax分类器的测试准确率，并产生显著更好的校准预测概率，为深度判别模型恢复了连贯的概率解释。

Conclusion: DNLL损失函数成功调和了生成结构与判别性能的矛盾，使深度判别模型既能保持概率解释性又能获得优异的分类性能。

Abstract: We show that for unconstrained Deep Linear Discriminant Analysis (LDA) classifiers, maximum-likelihood training admits pathological solutions in which class means drift together, covariances collapse, and the learned representation becomes almost non-discriminative. Conversely, cross-entropy training yields excellent accuracy but decouples the head from the underlying generative model, leading to highly inconsistent parameter estimates. To reconcile generative structure with discriminative performance, we introduce the \emph{Discriminative Negative Log-Likelihood} (DNLL) loss, which augments the LDA log-likelihood with a simple penalty on the mixture density. DNLL can be interpreted as standard LDA NLL plus a term that explicitly discourages regions where several classes are simultaneously likely. Deep LDA trained with DNLL produces clean, well-separated latent spaces, matches the test accuracy of softmax classifiers on synthetic data and standard image benchmarks, and yields substantially better calibrated predictive probabilities, restoring a coherent probabilistic interpretation to deep discriminant models.

</details>


### [483] [Simplex Deep Linear Discriminant Analysis](https://arxiv.org/abs/2601.01679)
*Maxat Tezekbayev,Arman Bolatov,Zhenisbek Assylbekov*

Main category: stat.ML

Relevance: 45.0

TL;DR: 论文重新审视深度线性判别分析(Deep LDA)，从似然角度分析，发现无约束的端到端MLE训练会导致类别重叠或坍缩，提出几何约束的Deep LDA模型，在图像数据集上达到与softmax基线相当的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统LDA是简单的线性高斯模型，但当将LDA头部连接到神经编码器时，如何通过最大似然估计训练深度分类器成为一个问题。作者旨在解决深度LDA训练中的退化问题，提高分类性能同时保持可解释的潜在几何结构。

Method: 首先分析无约束Deep LDA的MLE训练问题，发现会导致类别重叠或坍缩。然后提出约束Deep LDA公式：将类别均值固定为正则单纯形的顶点，限制共享协方差为球形，只学习先验和单个方差参数。在几何约束下，MLE变得稳定。

Result: 在Fashion-MNIST、CIFAR-10、CIFAR-100等图像数据集上，约束Deep LDA模型达到与softmax基线相当的准确率，同时提供简单、可解释的潜在几何结构，在二维投影中清晰可见。

Conclusion: 通过几何约束解决深度LDA的MLE训练退化问题，实现了既保持分类性能又具有可解释潜在几何结构的深度分类器，为深度判别分析提供了新的训练范式。

Abstract: We revisit Deep Linear Discriminant Analysis (Deep LDA) from a likelihood-based perspective. While classical LDA is a simple Gaussian model with linear decision boundaries, attaching an LDA head to a neural encoder raises the question of how to train the resulting deep classifier by maximum likelihood estimation (MLE). We first show that end-to-end MLE training of an unconstrained Deep LDA model ignores discrimination: when both the LDA parameters and the encoder parameters are learned jointly, the likelihood admits a degenerate solution in which some of the class clusters may heavily overlap or even collapse, and classification performance deteriorates. Batchwise moment re-estimation of the LDA parameters does not remove this failure mode. We then propose a constrained Deep LDA formulation that fixes the class means to the vertices of a regular simplex in the latent space and restricts the shared covariance to be spherical, leaving only the priors and a single variance parameter to be learned along with the encoder. Under these geometric constraints, MLE becomes stable and yields well-separated class clusters in the latent space. On images (Fashion-MNIST, CIFAR-10, CIFAR-100), the resulting Deep LDA models achieve accuracy competitive with softmax baselines while offering a simple, interpretable latent geometry that is clearly visible in two-dimensional projections.

</details>


### [484] [Horizon Reduction as Information Loss in Offline Reinforcement Learning](https://arxiv.org/abs/2601.00831)
*Uday Kumar Nidadala,Venkata Bhumika Guthi*

Main category: cs.LG

Relevance: 40.0

TL;DR: 本文证明离线强化学习中的视野缩减策略会导致根本性的信息损失，即使有无限数据和完美函数逼近，最优策略也可能与次优策略统计不可区分。


<details>
  <summary>Details</summary>
Motivation: 视野缩减是离线强化学习中常用的设计策略，用于缓解长视野信用分配、提高稳定性，并通过截断rollout、窗口训练或分层分解实现可扩展学习。尽管经验证据表明视野缩减可以改善离线RL基准测试的扩展性，但其理论影响尚未充分发展。

Method: 将视野缩减形式化为从固定长度轨迹片段中学习，证明在这种范式下，即使有无限数据和完美函数逼近，最优策略也可能与次优策略统计不可区分。通过最小反例马尔可夫决策过程识别三种结构失效模式：前缀不可区分性导致可识别性失败、截断回报导致的目标错误指定、离线数据集支持和表示混叠。

Result: 视野缩减会导致离线强化学习中的根本性信息损失，识别出三种结构失效模式，并建立了视野缩减安全应用的必要条件。

Conclusion: 视野缩减在离线强化学习中存在固有局限性，无法仅通过算法改进克服，需要关注其理论边界和安全应用条件。

Abstract: Horizon reduction is a common design strategy in offline reinforcement learning (RL), used to mitigate long-horizon credit assignment, improve stability, and enable scalable learning through truncated rollouts, windowed training, or hierarchical decomposition (Levine et al., 2020; Prudencio et al., 2023; Park et al., 2025). Despite recent empirical evidence that horizon reduction can improve scaling on challenging offline RL benchmarks, its theoretical implications remain underdeveloped (Park et al., 2025). In this paper, we show that horizon reduction can induce fundamental and irrecoverable information loss in offline RL. We formalize horizon reduction as learning from fixed-length trajectory segments and prove that, under this paradigm and any learning interface restricted to fixed-length trajectory segments, optimal policies may be statistically indistinguishable from suboptimal ones even with infinite data and perfect function approximation. Through a set of minimal counterexample Markov decision processes (MDPs), we identify three distinct structural failure modes: (i) prefix indistinguishability leading to identifiability failure, (ii) objective misspecification induced by truncated returns, and (iii) offline dataset support and representation aliasing. Our results establish necessary conditions under which horizon reduction can be safe and highlight intrinsic limitations that cannot be overcome by algorithmic improvements alone, complementing algorithmic work on conservative objectives and distribution shift that addresses a different axis of offline RL difficulty (Fujimoto et al., 2019; Kumar et al., 2020; Gulcehre et al., 2020).

</details>


### [485] [Accelerating Storage-Based Training for Graph Neural Networks](https://arxiv.org/abs/2601.01473)
*Myung-Hwan Jang,Jeong-Min Park,Yunyong Ko,Sang-Wook Kim*

Main category: cs.LG

Relevance: 40.0

TL;DR: AGNES是一个基于存储的GNN训练框架，通过块状存储I/O处理和超批次处理来解决大规模图神经网络训练中的I/O瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于存储的GNN训练方法在处理web-scale图数据时面临大量小规模存储I/O的瓶颈，导致数据准备效率低下，无法充分利用高性能存储设备的带宽。

Method: 提出AGNES框架：1) 采用块状存储I/O处理技术，将多个小I/O请求合并为大块请求以充分利用存储带宽；2) 基于真实图特性设计超批次处理策略，进一步优化每个存储I/O的效率。

Result: 在五个真实世界图数据集上的实验表明，AGNES相比四种最先进方法，性能提升最高达4.1倍。

Conclusion: AGNES通过创新的存储I/O优化技术有效解决了大规模GNN训练中的I/O瓶颈问题，为单机处理web-scale图数据提供了高效解决方案。

Abstract: Graph neural networks (GNNs) have achieved breakthroughs in various real-world downstream tasks due to their powerful expressiveness. As the scale of real-world graphs has been continuously growing, \textit{a storage-based approach to GNN training} has been studied, which leverages external storage (e.g., NVMe SSDs) to handle such web-scale graphs on a single machine. Although such storage-based GNN training methods have shown promising potential in large-scale GNN training, we observed that they suffer from a severe bottleneck in data preparation since they overlook a critical challenge: \textit{how to handle a large number of small storage I/Os}. To address the challenge, in this paper, we propose a novel storage-based GNN training framework, named \textsf{AGNES}, that employs a method of \textit{block-wise storage I/O processing} to fully utilize the I/O bandwidth of high-performance storage devices. Moreover, to further enhance the efficiency of each storage I/O, \textsf{AGNES} employs a simple yet effective strategy, \textit{hyperbatch-based processing} based on the characteristics of real-world graphs. Comprehensive experiments on five real-world graphs reveal that \textsf{AGNES} consistently outperforms four state-of-the-art methods, by up to 4.1$\times$ faster than the best competitor. Our code is available at https://github.com/Bigdasgit/agnes-kdd26.

</details>


### [486] [Digital Twin-Driven Communication-Efficient Federated Anomaly Detection for Industrial IoT](https://arxiv.org/abs/2601.01701)
*Mohammed Ayalew Belay,Adil Rasheed,Pierluigi Salvo Rossi*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出数字孪生集成联邦学习(DTFL)方法用于工业物联网异常检测，包含五种新方法，在保持数据隐私和通信效率的同时提升全局模型性能


<details>
  <summary>Details</summary>
Motivation: 工业系统异常检测面临依赖真实传感器数据、标注数据有限、高误报率和隐私问题等挑战，需要同时解决数据隐私和通信效率问题

Method: 提出五种数字孪生集成联邦学习方法：DTML（基于数字孪生的元学习）、FPF（联邦参数融合）、LPE（分层参数交换）、CWA（循环权重适应）、DTKD（数字孪生知识蒸馏），结合合成和真实世界知识

Result: 在80%准确率目标下，CWA仅需33轮达到目标，FPF需41轮，LPE需48轮，DTML需87轮，而标准FedAvg和DTKD在100轮内未达到目标，通信效率提升显著（比DTML减少62%轮数）

Conclusion: 将数字孪生知识集成到联邦学习中能显著加速收敛到操作上有意义的准确率阈值，为工业物联网异常检测提供通信高效的隐私保护解决方案

Abstract: Anomaly detection is increasingly becoming crucial for maintaining the safety, reliability, and efficiency of industrial systems. Recently, with the advent of digital twins and data-driven decision-making, several statistical and machine-learning methods have been proposed. However, these methods face several challenges, such as dependence on only real sensor datasets, limited labeled data, high false alarm rates, and privacy concerns. To address these problems, we propose a suite of digital twin-integrated federated learning (DTFL) methods that enhance global model performance while preserving data privacy and communication efficiency. Specifically, we present five novel approaches: Digital Twin-Based Meta-Learning (DTML), Federated Parameter Fusion (FPF), Layer-wise Parameter Exchange (LPE), Cyclic Weight Adaptation (CWA), and Digital Twin Knowledge Distillation (DTKD). Each method introduces a unique mechanism to combine synthetic and real-world knowledge, balancing generalization with communication overhead. We conduct an extensive experiment using a publicly available cyber-physical anomaly detection dataset. For a target accuracy of 80%, CWA reaches the target in 33 rounds, FPF in 41 rounds, LPE in 48 rounds, and DTML in 87 rounds, whereas the standard FedAvg baseline and DTKD do not reach the target within 100 rounds. These results highlight substantial communication-efficiency gains (up to 62% fewer rounds than DTML and 31% fewer than LPE) and demonstrate that integrating DT knowledge into FL accelerates convergence to operationally meaningful accuracy thresholds for IIoT anomaly detection.

</details>


### [487] [FAROS: Robust Federated Learning with Adaptive Scaling against Backdoor Attacks](https://arxiv.org/abs/2601.01833)
*Chenyu Hu,Qiming Hu,Sinan Chen,Nianyu Li,Mingyue Zhang,Jialong Li*

Main category: cs.LG

Relevance: 40.0

TL;DR: FAROS：一种增强型联邦学习框架，通过自适应差分缩放和鲁棒核心集计算来防御后门攻击，在保持主任务准确性的同时显著降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 联邦学习面临后门攻击的严重威胁，现有防御方法依赖固定参数，存在单点故障风险，难以应对复杂的攻击策略。需要一种能够动态适应攻击者行为并提高防御鲁棒性的解决方案。

Method: 提出FAROS框架，包含两个核心组件：1) 自适应差分缩放(ADS)：根据每轮客户端上传梯度的离散度动态调整防御灵敏度；2) 鲁棒核心集计算(RCC)：计算高置信度客户端核心集的质心，降低单点故障风险。

Result: 在多种数据集、模型和攻击场景下的实验表明，该方法在攻击成功率和主任务准确性方面均优于现有防御方法。

Conclusion: FAROS通过动态自适应机制和鲁棒核心集计算，有效提升了联邦学习对后门攻击的防御能力，解决了现有防御方法的固有限制。

Abstract: Federated Learning (FL) enables multiple clients to collaboratively train a shared model without exposing local data. However, backdoor attacks pose a significant threat to FL. These attacks aim to implant a stealthy trigger into the global model, causing it to mislead on inputs that possess a specific trigger while functioning normally on benign data. Although pre-aggregation detection is a main defense direction, existing state-of-the-art defenses often rely on fixed defense parameters. This reliance makes them vulnerable to single-point-of-failure risks, rendering them less effective against sophisticated attackers. To address these limitations, we propose FAROS, an enhanced FL framework that incorporates Adaptive Differential Scaling (ADS) and Robust Core-set Computing (RCC). The ADS mechanism adjusts the defense's sensitivity dynamically, based on the dispersion of uploaded gradients by clients in each round. This allows it to counter attackers who strategically shift between stealthiness and effectiveness. Furthermore, the RCC effectively mitigates the risk of single-point failure by computing the centroid of a core set comprising clients with the highest confidence. We conducted extensive experiments across various datasets, models, and attack scenarios. The results demonstrate that our method outperforms current defenses in both attack success rate and main task accuracy.

</details>


### [488] [Game of Coding: Coding Theory in the Presence of Rational Adversaries, Motivated by Decentralized Machine Learning](https://arxiv.org/abs/2601.02313)
*Hanzaleh Akbari Nodehi,Viveck R. Cadambe,Mohammad Ali Maddah-Ali*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种新的博弈论框架"编码游戏"，将编码理论扩展到去中心化系统中理性对手的场景，即使诚实节点不占多数也能实现数据恢复。


<details>
  <summary>Details</summary>
Motivation: 传统编码理论假设最坏情况的对抗模型，要求诚实节点数量超过对抗节点。但在去中心化机器学习等新兴应用中，参与节点因贡献而获得奖励，这催生了理性对手（strategic而非纯粹恶意）。现有方法在这种信任最小化设置中具有局限性。

Method: 提出"编码游戏"博弈论框架，扩展编码理论到信任最小化设置。聚焦于重复编码，展示该框架的两个关键特性：1) 即使对抗节点占多数也能实现非零概率的数据恢复；2) Sybil抵抗性，即均衡状态不随对抗节点数量增加而改变。

Result: 该框架能够在诚实节点不占多数的情况下实现数据恢复，并具有Sybil抵抗性。当对手策略未知时，框架仍能提供分析工具。

Conclusion: 编码游戏框架为去中心化系统中的理性对手问题提供了新的解决方案，突破了传统编码理论的限制，为未来研究开辟了多个开放问题。

Abstract: Coding theory plays a crucial role in enabling reliable communication, storage, and computation. Classical approaches assume a worst-case adversarial model and ensure error correction and data recovery only when the number of honest nodes exceeds the number of adversarial ones by some margin. However, in some emerging decentralized applications, particularly in decentralized machine learning (DeML), participating nodes are rewarded for accepted contributions. This incentive structure naturally gives rise to rational adversaries who act strategically rather than behaving in purely malicious ways.
  In this paper, we first motivate the need for coding in the presence of rational adversaries, particularly in the context of outsourced computation in decentralized systems. We contrast this need with existing approaches and highlight their limitations. We then introduce the game of coding, a novel game-theoretic framework that extends coding theory to trust-minimized settings where honest nodes are not in the majority. Focusing on repetition coding, we highlight two key features of this framework: (1) the ability to achieve a non-zero probability of data recovery even when adversarial nodes are in the majority, and (2) Sybil resistance, i.e., the equilibrium remains unchanged even as the number of adversarial nodes increases. Finally, we explore scenarios in which the adversary's strategy is unknown and outline several open problems for future research.

</details>


### [489] [Reinforcement Learning for Option Hedging: Static Implied-Volatility Fit versus Shortfall-Aware Performance](https://arxiv.org/abs/2601.01709)
*Ziheng Chen,Minxuan Hu,Jiayu Yi,Wenxi Sun*

Main category: q-fin.PR

Relevance: 40.0

TL;DR: 该论文扩展了QLBS框架，纳入风险厌恶和交易成本，提出RLOP方法，在静态定价和动态对冲性能上分别优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统期权定价模型通常只关注静态定价准确性，而忽略实际对冲效果。作者旨在开发在考虑市场摩擦（交易成本）和风险偏好的情况下，既能准确定价又能有效对冲的期权定价方法。

Method: 1. 扩展QLBS框架，加入风险厌恶参数和交易成本；2. 提出RLOP（复制学习期权定价）方法，将期权定价视为复制学习问题；3. 两种方法都与标准强化学习算法兼容；4. 使用SPY和XOP期权数据进行评估，从静态定价准确性和动态对冲效果两个维度比较。

Result: Adaptive-QLBS在隐含波动率空间的静态定价准确性更高，而RLOP在动态对冲方面表现更优，能显著降低对冲不足的概率。这表明评估期权定价模型时，不能只看静态拟合度，实际对冲效果同样重要。

Conclusion: 期权定价模型的评估应超越静态拟合度，重点关注实际对冲结果。RLOP方法在动态对冲方面具有优势，为考虑市场摩擦和风险偏好的期权定价提供了新思路。

Abstract: We extend the Q-learner in Black-Scholes (QLBS) framework by incorporating risk aversion and trading costs, and propose a novel Replication Learning of Option Pricing (RLOP) approach. Both methods are fully compatible with standard reinforcement learning algorithms and operate under market frictions. Using SPY and XOP option data, we evaluate performance along static and dynamic dimensions. Adaptive-QLBS achieves higher static pricing accuracy in implied volatility space, while RLOP delivers superior dynamic hedging performance by reducing shortfall probability. These results highlight the importance of evaluating option pricing models beyond static fit, emphasizing realized hedging outcomes.

</details>


### [490] [Intrinsic-Metric Physics-Informed Neural Networks (IM-PINN) for Reaction-Diffusion Dynamics on Complex Riemannian Manifolds](https://arxiv.org/abs/2601.00834)
*Julian Evan Chrisnanto,Salsabila Rahma Alia,Nurfauzi Fadillah,Yulison Herry Chrisnanto*

Main category: cs.LG

Relevance: 35.0

TL;DR: IM-PINN：一种用于复杂非欧几里得流形上非线性反应扩散动力学的无网格几何深度学习框架，通过嵌入黎曼度量张量解析重构拉普拉斯-贝尔特拉米算子，在极端高斯曲率波动下优于传统表面有限元方法。


<details>
  <summary>Details</summary>
Motivation: 解决复杂非欧几里得流形上非线性反应扩散动力学模拟的基本挑战，包括高保真网格生成成本和离散时间步进方案中的辛漂移问题。传统自适应细化方法在极端高斯曲率波动下无法解析各向异性图灵不稳定性。

Method: 提出内在度量物理信息神经网络（IM-PINN），一种无网格几何深度学习框架，直接在连续参数域中求解偏微分方程。通过将黎曼度量张量嵌入自动微分图，解析重构拉普拉斯-贝尔特拉米算子，将解复杂度与几何离散化解耦。采用双流架构和傅里叶特征嵌入来缓解谱偏差。

Result: 在具有极端高斯曲率波动（K ∈ [-2489, 3580]）的"随机布料"流形上验证，IM-PINN恢复了Gray-Scott模型的"分裂斑点"和"迷宫"状态。与表面有限元方法（SFEM）相比，IM-PINN实现全局质量守恒误差约0.157，优于SFEM的0.258，作为热力学一致的全局求解器消除了半隐式积分固有的质量漂移。

Conclusion: IM-PINN为演化表面上生物模式形成的模拟提供了内存高效、分辨率无关的范式，弥合了微分几何和物理信息机器学习之间的鸿沟，在极端几何条件下表现出优越的物理严谨性。

Abstract: Simulating nonlinear reaction-diffusion dynamics on complex, non-Euclidean manifolds remains a fundamental challenge in computational morphogenesis, constrained by high-fidelity mesh generation costs and symplectic drift in discrete time-stepping schemes. This study introduces the Intrinsic-Metric Physics-Informed Neural Network (IM-PINN), a mesh-free geometric deep learning framework that solves partial differential equations directly in the continuous parametric domain. By embedding the Riemannian metric tensor into the automatic differentiation graph, our architecture analytically reconstructs the Laplace-Beltrami operator, decoupling solution complexity from geometric discretization. We validate the framework on a "Stochastic Cloth" manifold with extreme Gaussian curvature fluctuations ($K \in [-2489, 3580]$), where traditional adaptive refinement fails to resolve anisotropic Turing instabilities. Using a dual-stream architecture with Fourier feature embeddings to mitigate spectral bias, the IM-PINN recovers the "splitting spot" and "labyrinthine" regimes of the Gray-Scott model. Benchmarking against the Surface Finite Element Method (SFEM) reveals superior physical rigor: the IM-PINN achieves global mass conservation error of $\mathcal{E}_{mass} \approx 0.157$ versus SFEM's $0.258$, acting as a thermodynamically consistent global solver that eliminates mass drift inherent in semi-implicit integration. The framework offers a memory-efficient, resolution-independent paradigm for simulating biological pattern formation on evolving surfaces, bridging differential geometry and physics-informed machine learning.

</details>


### [491] [Universal Battery Degradation Forecasting Driven by Foundation Model Across Diverse Chemistries and Conditions](https://arxiv.org/abs/2601.00862)
*Joey Chan,Huan Wang,Haoyu Pan,Wei Wu,Zirong Wang,Zhen Chen,Ershun Pan,Min Xie,Lifeng Xi*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出基于时间序列基础模型(TSFM)的统一电池容量衰减预测框架，通过LoRA参数微调和物理引导对比学习，在20个数据集上实现跨化学体系、容量尺度和工况的稳定预测性能。


<details>
  <summary>Details</summary>
Motivation: 电池容量衰减预测对储能系统安全可靠运行至关重要，但由于电池化学体系、形态和工况的高度异质性，现有模型难以跨域泛化。需要构建统一的预测框架来应对这种多样性挑战。

Method: 1) 构建大规模电池老化语料库：整合20个公开数据集，涵盖1704个电池和396万次充放电循环段；2) 采用时间序列基础模型(TSFM)作为主干；3) 结合参数高效的LoRA微调；4) 引入物理引导的对比表示学习来捕捉共享退化模式。

Result: 单一统一模型在已见和未见数据集上均取得竞争性或优于各数据集专用基线的精度，同时在训练中未包含的化学体系、容量尺度和工况上保持稳定性能。

Conclusion: 基于TSFM的架构可作为电池管理系统容量衰减预测的可扩展和可迁移解决方案，展示了基础模型在跨域时间序列预测中的潜力。

Abstract: Accurate forecasting of battery capacity fade is essential for the safety, reliability, and long-term efficiency of energy storage systems. However, the strong heterogeneity across cell chemistries, form factors, and operating conditions makes it difficult to build a single model that generalizes beyond its training domain. This work proposes a unified capacity forecasting framework that maintains robust performance across diverse chemistries and usage scenarios. We curate 20 public aging datasets into a large-scale corpus covering 1,704 cells and 3,961,195 charge-discharge cycle segments, spanning temperatures from $-5\,^{\circ}\mathrm{C}$ to $45\,^{\circ}\mathrm{C}$, multiple C-rates, and application-oriented profiles such as fast charging and partial cycling. On this corpus, we adopt a Time-Series Foundation Model (TSFM) backbone and apply parameter-efficient Low-Rank Adaptation (LoRA) together with physics-guided contrastive representation learning to capture shared degradation patterns. Experiments on both seen and deliberately held-out unseen datasets show that a single unified model achieves competitive or superior accuracy compared with strong per-dataset baselines, while retaining stable performance on chemistries, capacity scales, and operating conditions excluded from training. These results demonstrate the potential of TSFM-based architectures as a scalable and transferable solution for capacity degradation forecasting in real battery management systems.

</details>


### [492] [Selective Imperfection as a Generative Framework for Analysis, Creativity and Discovery](https://arxiv.org/abs/2601.00863)
*Markus J. Buehler*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出materiomusic框架，通过可逆映射将物质层次结构（蛋白质、蜘蛛网、火焰动力学）与音乐创作逻辑连接，将分子振动转化为可听音乐，探索科学与艺术的生成约束共性。


<details>
  <summary>Details</summary>
Motivation: 探索物质结构与音乐创作之间的深层联系，将振动作为跨尺度组织的共享语法，通过听觉作为科学探测手段，实现科学与艺术的交叉生成。

Method: 使用可逆映射方法：1) 分子光谱到音乐音调的映射；2) 三维网络到可演奏乐器的映射；3) 穷举所有2^12音乐音阶分析文化显著系统的熵-缺陷关系；4) 基于群集的AI模型作曲。

Result: 发现文化显著音乐系统聚集在中熵、中缺陷的走廊区域，与材料科学中的Hall-Petch最优缺陷密度直接对应；群集AI模型创作的音乐展现出类人结构特征（小世界连接性、模块化整合、长程相干性）。

Conclusion: 科学与艺术都是在约束下的生成性世界构建行为，振动是跨尺度组织结构的共享语法；选择性不完美提供了协调一致性与适应性的机制；这种映射创造了人类创造力与物理学的生产性碰撞。

Abstract: We introduce materiomusic as a generative framework linking the hierarchical structures of matter with the compositional logic of music. Across proteins, spider webs and flame dynamics, vibrational and architectural principles recur as tonal hierarchies, harmonic progressions, and long-range musical form. Using reversible mappings, from molecular spectra to musical tones and from three-dimensional networks to playable instruments, we show how sound functions as a scientific probe, an epistemic inversion where listening becomes a mode of seeing and musical composition becomes a blueprint for matter. These mappings excavate deep time: patterns originating in femtosecond molecular vibrations or billion-year evolutionary histories become audible. We posit that novelty in science and art emerges when constraints cannot be satisfied within existing degrees of freedom, forcing expansion of the space of viable configurations. Selective imperfection provides the mechanism restoring balance between coherence and adaptability. Quantitative support comes from exhaustive enumeration of all 2^12 musical scales, revealing that culturally significant systems cluster in a mid-entropy, mid-defect corridor, directly paralleling the Hall-Petch optimum where intermediate defect densities maximize material strength. Iterating these mappings creates productive collisions between human creativity and physics, generating new information as musical structures encounter evolutionary constraints. We show how swarm-based AI models compose music exhibiting human-like structural signatures such as small-world connectivity, modular integration, long-range coherence, suggesting a route beyond interpolation toward invention. We show that science and art are generative acts of world-building under constraint, with vibration as a shared grammar organizing structure across scales.

</details>


### [493] [Distribution Matching for Graph Quantification Under Structural Covariate Shift](https://arxiv.org/abs/2601.00864)
*Clemens Damke,Eyke Hüllermeier*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出了一种针对图数据量化学习的新方法，通过结构重要性采样扩展KDEy量化方法，以处理训练和测试数据之间的结构偏移问题。


<details>
  <summary>Details</summary>
Motivation: 在社交网络等图数据中，我们常常需要预测标签分布（如政治偏好分布）而非单个实例标签。传统量化学习方法基于先验概率偏移假设，但在图数据中，当训练和测试数据来自图的不同区域时，这种假设不成立，导致现有方法失效。

Method: 将结构重要性采样的思想扩展到最先进的KDEy量化方法中，通过重要性采样来适应训练和测试数据之间的结构偏移，处理图数据中不同区域之间的分布变化。

Result: 提出的方法能够适应结构偏移，并在图数据量化学习任务中优于标准量化方法。

Conclusion: 对于图数据的量化学习任务，需要考虑结构偏移问题，通过结构重要性采样扩展KDEy方法是有效的解决方案。

Abstract: Graphs are commonly used in machine learning to model relationships between instances. Consider the task of predicting the political preferences of users in a social network; to solve this task one should consider, both, the features of each individual user and the relationships between them. However, oftentimes one is not interested in the label of a single instance but rather in the distribution of labels over a set of instances; e.g., when predicting the political preferences of users, the overall prevalence of a given opinion might be of higher interest than the opinion of a specific person. This label prevalence estimation task is commonly referred to as quantification learning (QL). Current QL methods for tabular data are typically based on the so-called prior probability shift (PPS) assumption which states that the label-conditional instance distributions should remain equal across the training and test data. In the graph setting, PPS generally does not hold if the shift between training and test data is structural, i.e., if the training data comes from a different region of the graph than the test data. To address such structural shifts, an importance sampling variant of the popular adjusted count quantification approach has previously been proposed. In this work, we extend the idea of structural importance sampling to the state-of-the-art KDEy quantification approach. We show that our proposed method adapts to structural shifts and outperforms standard quantification approaches.

</details>


### [494] [Quantum Machine Learning Approaches for Coordinated Stealth Attack Detection in Distributed Generation Systems](https://arxiv.org/abs/2601.00873)
*Osasumwen Cedric Ogiesoba-Eguakun,Suman Rath*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该研究探索量子机器学习方法检测微电网中分布式发电单元的协同隐蔽攻击，发现混合量子经典模型（量子特征嵌入+经典RBF SVM）在低维数据集上表现最佳，相比纯经典SVM有适度提升。


<details>
  <summary>Details</summary>
Motivation: 协同隐蔽攻击是分布式发电系统的严重网络安全威胁，它们修改控制和测量信号但保持接近正常行为，使得传统入侵检测方法难以发现。需要探索新的检测方法。

Method: 使用高质量模拟测量数据创建平衡二元分类数据集，特征包括DG1的无功功率、频率偏差和端电压幅值。评估经典ML基线、完全量子变分分类器和混合量子经典模型。

Result: 混合量子经典模型（量子特征嵌入+经典RBF SVM）在低维数据集上获得最佳整体性能，在准确率和F1分数上相比强经典SVM基线有适度提升。完全量子模型因训练不稳定和当前NISQ硬件限制表现较差。

Conclusion: 混合模型训练更可靠，表明即使完全量子学习尚不实用，量子特征映射也能增强入侵检测能力。量子机器学习在网络安全领域有应用潜力。

Abstract: Coordinated stealth attacks are a serious cybersecurity threat to distributed generation systems because they modify control and measurement signals while remaining close to normal behavior, making them difficult to detect using standard intrusion detection methods. This study investigates quantum machine learning approaches for detecting coordinated stealth attacks on a distributed generation unit in a microgrid. High-quality simulated measurements were used to create a balanced binary classification dataset using three features: reactive power at DG1, frequency deviation relative to the nominal value, and terminal voltage magnitude. Classical machine learning baselines, fully quantum variational classifiers, and hybrid quantum classical models were evaluated. The results show that a hybrid quantum classical model combining quantum feature embeddings with a classical RBF support vector machine achieves the best overall performance on this low dimensional dataset, with a modest improvement in accuracy and F1 score over a strong classical SVM baseline. Fully quantum models perform worse due to training instability and limitations of current NISQ hardware. In contrast, hybrid models train more reliably and demonstrate that quantum feature mapping can enhance intrusion detection even when fully quantum learning is not yet practical.

</details>


### [495] [LearnAD: Learning Interpretable Rules for Brain Networks in Alzheimer's Disease Classification](https://arxiv.org/abs/2601.00877)
*Thomas Andrews,Mark Law,Sara Ahmadi-Abhari,Alessandra Russo*

Main category: cs.LG

Relevance: 35.0

TL;DR: LearnAD是一种神经符号方法，用于从脑磁共振成像数据预测阿尔茨海默病，学习完全可解释的规则。该方法结合统计模型、决策树、随机森林或GNN识别相关脑连接，然后使用FastLAS学习全局规则。


<details>
  <summary>Details</summary>
Motivation: 动机是开发一种完全可解释的阿尔茨海默病预测方法，结合神经网络的表示学习能力和符号系统的可解释性，以增强临床神经科学中对GNN行为的理解。

Method: 神经符号方法：首先使用统计模型、决策树、随机森林或GNN识别相关脑连接，然后应用FastLAS（一种逻辑编程系统）学习全局可解释规则。

Result: 最佳实例优于决策树，与支持向量机准确率相当，仅略低于使用所有特征的随机森林和GNN，同时保持完全可解释性。消融研究表明神经符号方法在保持可比性能的同时提高了可解释性。

Conclusion: LearnAD展示了符号学习如何加深对临床神经科学中GNN行为的理解，为开发可解释的医疗AI模型提供了有效途径。

Abstract: We introduce LearnAD, a neuro-symbolic method for predicting Alzheimer's disease from brain magnetic resonance imaging data, learning fully interpretable rules. LearnAD applies statistical models, Decision Trees, Random Forests, or GNNs to identify relevant brain connections, and then employs FastLAS to learn global rules. Our best instance outperforms Decision Trees, matches Support Vector Machine accuracy, and performs only slightly below Random Forests and GNNs trained on all features, all while remaining fully interpretable. Ablation studies show that our neuro-symbolic approach improves interpretability with comparable performance to pure statistical models. LearnAD demonstrates how symbolic learning can deepen our understanding of GNN behaviour in clinical neuroscience.

</details>


### [496] [Coarse-Grained Kullback--Leibler Control of Diffusion-Based Generative AI](https://arxiv.org/abs/2601.01045)
*Tatsuaki Tsuruyama*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出了一种基于信息论Lyapunov函数的反向扩散方案，用于控制生成模型中粗粒度量的演化，通过V-delta投影保持块质量误差在预设容差内。


<details>
  <summary>Details</summary>
Motivation: 扩散模型和基于分数的生成模型在图像合成方面表现出色，但缺乏描述粗粒度量（如图像分块后的块强度或类别比例）如何在反向扩散过程中演化的理论框架。作者希望建立一种理论来理解和控制这些粗粒度量的演化。

Method: 将先前提出的非遍历马尔可夫过程信息论Lyapunov函数框架移植到生成模型的反向扩散过程，提出V-delta投影反向扩散方案。扩展V的单调性到时间非齐次块保持马尔可夫核，证明在小泄漏和V-delta投影下，V-delta可作为近似Lyapunov函数。使用块常数图像和简化反向核的玩具模型进行数值验证。

Result: 数值实验表明，所提方法能将块质量误差和泄漏容忍势保持在预设容差内，同时达到与非投影动力学相当的像素级精度和视觉质量。

Conclusion: 该研究将生成采样重新解释为从噪声到数据的信息势减少过程，为具有明确粗粒度控制的反向扩散过程提供了设计原则。

Abstract: Diffusion models and score-based generative models provide a powerful framework for synthesizing high-quality images from noise. However, there is still no satisfactory theory that describes how coarse-grained quantities, such as blockwise intensity or class proportions after partitioning an image into spatial blocks, are preserved and evolve along the reverse diffusion dynamics. In previous work, the author introduced an information-theoretic Lyapunov function V for non-ergodic Markov processes on a state space partitioned into blocks, defined as the minimal Kullback-Leibler divergence to the set of stationary distributions reachable from a given initial condition, and showed that a leak-tolerant potential V-delta with a prescribed tolerance for block masses admits a closed-form expression as a scaling-and-clipping operation on block masses.
  In this paper, I transplant this framework to the reverse diffusion process in generative models and propose a reverse diffusion scheme that is projected by the potential V-delta (referred to as the V-delta projected reverse diffusion). I extend the monotonicity of V to time-inhomogeneous block-preserving Markov kernels and show that, under small leakage and the V-delta projection, V-delta acts as an approximate Lyapunov function. Furthermore, using a toy model consisting of block-constant images and a simplified reverse kernel, I numerically demonstrate that the proposed method keeps the block-mass error and the leak-tolerant potential within the prescribed tolerance, while achieving pixel-wise accuracy and visual quality comparable to the non-projected dynamics. This study reinterprets generative sampling as a decrease of an information potential from noise to data, and provides a design principle for reverse diffusion processes with explicit control of coarse-grained quantities.

</details>


### [497] [A UCB Bandit Algorithm for General ML-Based Estimators](https://arxiv.org/abs/2601.01061)
*Yajing Liu,Erkao Bao,Linqi Song*

Main category: cs.LG

Relevance: 35.0

TL;DR: ML-UCB：一种将任意机器学习模型集成到多臂老虎机框架中的广义上置信界算法，通过直接建模底层估计器的学习曲线行为来克服传统浓度不等式不可处理的限制。


<details>
  <summary>Details</summary>
Motivation: 在序列决策中部署复杂ML模型时，缺乏可处理的浓度不等式是主要挑战。传统方法需要针对特定模型进行理论分析，限制了先进ML模型在老虎机问题中的应用。

Method: 假设均方误差随训练样本数呈幂律下降，推导出广义浓度不等式，并基于此设计ML-UCB算法。该框架允许集成任何学习曲线可经验表征的ML模型，无需模型特定的理论分析。

Result: 理论证明ML-UCB能实现次线性遗憾。在协同过滤推荐系统的实验中，使用在线矩阵分解（模拟简化双塔模型）验证了该方法，相比LinUCB有显著改进。

Conclusion: ML-UCB为将任意ML模型集成到老虎机框架提供了原则性方法，通过建模学习曲线行为克服了传统浓度不等式的限制，实现了更灵活的序列决策系统设计。

Abstract: We present ML-UCB, a generalized upper confidence bound algorithm that integrates arbitrary machine learning models into multi-armed bandit frameworks. A fundamental challenge in deploying sophisticated ML models for sequential decision-making is the lack of tractable concentration inequalities required for principled exploration. We overcome this limitation by directly modeling the learning curve behavior of the underlying estimator. Specifically, assuming the Mean Squared Error decreases as a power law in the number of training samples, we derive a generalized concentration inequality and prove that ML-UCB achieves sublinear regret. This framework enables the principled integration of any ML model whose learning curve can be empirically characterized, eliminating the need for model-specific theoretical analysis. We validate our approach through experiments on a collaborative filtering recommendation system using online matrix factorization with synthetic data designed to simulate a simplified two-tower model, demonstrating substantial improvements over LinUCB

</details>


### [498] [Revisiting Weighted Strategy for Non-stationary Parametric Bandits and MDPs](https://arxiv.org/abs/2601.01069)
*Jing Wang,Peng Zhao,Zhi-Hua Zhou*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文重新审视了非平稳参数化赌博机中的加权策略，提出了一个精炼的分析框架，简化了算法设计并改进了后悔界，同时将框架扩展到非平稳MDPs。


<details>
  <summary>Details</summary>
Motivation: 非平稳参数化赌博机中，加权策略在实际应用中很常见，但之前的理论分析复杂且算法效率低下或统计次优。本文旨在解决加权策略分析复杂、算法设计繁琐的问题。

Method: 提出了一个精炼的分析框架，简化了加权策略的推导过程。在线性赌博机中，该框架产生了更简单的加权算法，效率与窗口/重启算法相当。框架还扩展到广义线性赌博机、自协调赌博机，以及非平稳MDPs（线性混合MDP和多项Logit混合MDP）。

Result: 在线性赌博机中，新框架产生了更简单的加权算法，效率与窗口/重启算法相当且后悔界相同。在广义线性赌博机中，获得了$\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$的后悔界，优于之前的$\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})$。框架还成功扩展到非平稳MDPs。

Conclusion: 本文的精炼分析框架简化了非平稳参数化赌博机中加权策略的理论分析，产生了更简单高效的算法，并改进了后悔界，同时展示了框架在更广泛参数化赌博机和非平稳MDPs中的适用性。

Abstract: Non-stationary parametric bandits have attracted much attention recently. There are three principled ways to deal with non-stationarity, including sliding-window, weighted, and restart strategies. As many non-stationary environments exhibit gradual drifting patterns, the weighted strategy is commonly adopted in real-world applications. However, previous theoretical studies show that its analysis is more involved and the algorithms are either computationally less efficient or statistically suboptimal. This paper revisits the weighted strategy for non-stationary parametric bandits. In linear bandits (LB), we discover that this undesirable feature is due to an inadequate regret analysis, which results in an overly complex algorithm design. We propose a \emph{refined analysis framework}, which simplifies the derivation and, importantly, produces a simpler weight-based algorithm that is as efficient as window/restart-based algorithms while retaining the same regret as previous studies. Furthermore, our new framework can be used to improve regret bounds of other parametric bandits, including Generalized Linear Bandits (GLB) and Self-Concordant Bandits (SCB). For example, we develop a simple weighted GLB algorithm with an $\tilde{O}(k_μ^{5/4} c_μ^{-3/4} d^{3/4} P_T^{1/4}T^{3/4})$ regret, improving the $\tilde{O}(k_μ^{2} c_μ^{-1}d^{9/10} P_T^{1/5}T^{4/5})$ bound in prior work, where $k_μ$ and $c_μ$ characterize the reward model's nonlinearity, $P_T$ measures the non-stationarity, $d$ and $T$ denote the dimension and time horizon. Moreover, we extend our framework to non-stationary Markov Decision Processes (MDPs) with function approximation, focusing on Linear Mixture MDP and Multinomial Logit (MNL) Mixture MDP. For both classes, we propose algorithms based on the weighted strategy and establish dynamic regret guarantees using our analysis framework.

</details>


### [499] [Flow Equivariant World Models: Memory for Partially Observed Dynamic Environments](https://arxiv.org/abs/2601.01075)
*Hansen Jin Lillemark,Benhao Huang,Fangneng Zhan,Yilun Du,Thomas Anderson Keller*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出Flow Equivariant World Models框架，将自运动和外部物体运动统一为单参数李群"流"，利用群等变性实现稳定潜在世界表示，在部分观测视频世界建模基准上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络世界模型忽略了现实世界中连续感官输入流所遵循的平滑时间参数对称性结构，导致重复从数据中学习相同变换。作者旨在利用这些对称性结构构建更高效的世界模型。

Method: 将自运动和外部物体运动统一为单参数李群"流"，实现对这些变换的群等变性，从而在数百个时间步长上提供稳定的潜在世界表示。在2D和3D部分观测视频世界建模基准上进行评估。

Result: 在2D和3D部分观测视频世界建模基准上，Flow Equivariant World Models显著优于可比较的最先进扩散基和记忆增强世界建模架构，特别是在智能体当前视野外存在可预测世界动态的情况下。流等变性对长序列预测特别有益，能够泛化到远超训练时域的范围。

Conclusion: 通过将世界模型表示结构与内部和外部运动对齐，流等变性为数据高效、对称性引导的具身智能提供了一条可扩展的路径。

Abstract: Embodied systems experience the world as 'a symphony of flows': a combination of many continuous streams of sensory input coupled to self-motion, interwoven with the dynamics of external objects. These streams obey smooth, time-parameterized symmetries, which combine through a precisely structured algebra; yet most neural network world models ignore this structure and instead repeatedly re-learn the same transformations from data. In this work, we introduce 'Flow Equivariant World Models', a framework in which both self-motion and external object motion are unified as one-parameter Lie group 'flows'. We leverage this unification to implement group equivariance with respect to these transformations, thereby providing a stable latent world representation over hundreds of timesteps. On both 2D and 3D partially observed video world modeling benchmarks, we demonstrate that Flow Equivariant World Models significantly outperform comparable state-of-the-art diffusion-based and memory-augmented world modeling architectures -- particularly when there are predictable world dynamics outside the agent's current field of view. We show that flow equivariance is particularly beneficial for long rollouts, generalizing far beyond the training horizon. By structuring world model representations with respect to internal and external motion, flow equivariance charts a scalable route to data efficient, symmetry-guided, embodied intelligence. Project link: https://flowequivariantworldmodels.github.io.

</details>


### [500] [Central Dogma Transformer: Towards Mechanism-Oriented AI for Cellular Understanding](https://arxiv.org/abs/2601.01089)
*Nobuyuki Ota*

Main category: cs.LG

Relevance: 35.0

TL;DR: CDT是一个整合DNA、RNA和蛋白质预训练语言模型的多模态架构，遵循中心法则的信息流向，通过定向交叉注意力机制生成统一的虚拟细胞嵌入，在CRISPRi增强子扰动数据上取得良好预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前针对DNA、RNA和蛋白质的领域特定基础模型虽然各自成功，但相互隔离，限制了建模整合细胞过程的能力。需要开发能够遵循中心法则信息流向的架构来整合这三种分子系统。

Method: 提出中心法则变换器(CDT)，整合DNA、RNA和蛋白质的预训练语言模型，采用定向交叉注意力机制：DNA-to-RNA注意力建模转录调控，RNA-to-Protein注意力建模翻译关系，生成统一的虚拟细胞嵌入。

Result: 在K562细胞的CRISPRi增强子扰动数据上，CDT v1（使用固定RNA和蛋白质嵌入的概念验证实现）达到Pearson相关系数0.503，达到交叉实验变异性理论上限（r=0.797）的63%。注意力和梯度分析提供了互补的解释窗口。

Conclusion: 与生物信息流向对齐的AI架构能够同时实现预测准确性和机制可解释性，为整合多模态生物数据提供了有前景的方向。

Abstract: Understanding cellular mechanisms requires integrating information across DNA, RNA, and protein - the three molecular systems linked by the Central Dogma of molecular biology. While domain-specific foundation models have achieved success for each modality individually, they remain isolated, limiting our ability to model integrated cellular processes. Here we present the Central Dogma Transformer (CDT), an architecture that integrates pre-trained language models for DNA, RNA, and protein following the directional logic of the Central Dogma. CDT employs directional cross-attention mechanisms - DNA-to-RNA attention models transcriptional regulation, while RNA-to-Protein attention models translational relationships - producing a unified Virtual Cell Embedding that integrates all three modalities. We validate CDT v1 - a proof-of-concept implementation using fixed (non-cell-specific) RNA and protein embeddings - on CRISPRi enhancer perturbation data from K562 cells, achieving a Pearson correlation of 0.503, representing 63% of the theoretical ceiling set by cross-experiment variability (r = 0.797). Attention and gradient analyses provide complementary interpretive windows: in detailed case studies, these approaches highlight largely distinct genomic regions, with gradient analysis identifying a CTCF binding site that Hi-C data showed as physically contacting both enhancer and target gene. These results suggest that AI architectures aligned with biological information flow can achieve both predictive accuracy and mechanistic interpretability.

</details>


### [501] [Learning from Historical Activations in Graph Neural Networks](https://arxiv.org/abs/2601.01123)
*Yaniv Galron,Hadar Sinai,Haggai Maron,Moshe Eliasof*

Main category: cs.LG

Relevance: 35.0

TL;DR: HISTOGRAPH提出了一种基于注意力的两阶段图池化方法，利用中间层激活历史来改进图分类性能，特别在深层GNN中表现鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有图池化方法仅使用最后一层GNN特征，未能充分利用前向传播过程中产生的中间层激活历史。这在节点表示可能随层数发生显著变化时尤其明显，且图特有的挑战（如深度架构中的过平滑）加剧了这一问题。

Method: HISTOGRAPH是一种新颖的两阶段注意力最终聚合层：1）首先在中间激活上应用统一的层间注意力，2）然后进行节点间注意力。通过建模节点表示在层间的演化，利用节点的激活历史和图结构来精炼用于最终预测的特征。

Result: 在多个图分类基准测试中，HISTOGRAPH表现出强大的性能，持续改进传统技术，在深层GNN中具有特别强的鲁棒性。

Conclusion: 利用中间层激活历史可以显著改进图池化性能，HISTOGRAPH通过两阶段注意力机制有效建模节点表示演化，为图神经网络提供了更丰富的特征聚合方法。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable success in various domains such as social networks, molecular chemistry, and more. A crucial component of GNNs is the pooling procedure, in which the node features calculated by the model are combined to form an informative final descriptor to be used for the downstream task. However, previous graph pooling schemes rely on the last GNN layer features as an input to the pooling or classifier layers, potentially under-utilizing important activations of previous layers produced during the forward pass of the model, which we regard as historical graph activations. This gap is particularly pronounced in cases where a node's representation can shift significantly over the course of many graph neural layers, and worsened by graph-specific challenges such as over-smoothing in deep architectures. To bridge this gap, we introduce HISTOGRAPH, a novel two-stage attention-based final aggregation layer that first applies a unified layer-wise attention over intermediate activations, followed by node-wise attention. By modeling the evolution of node representations across layers, our HISTOGRAPH leverages both the activation history of nodes and the graph structure to refine features used for final prediction. Empirical results on multiple graph classification benchmarks demonstrate that HISTOGRAPH offers strong performance that consistently improves traditional techniques, with particularly strong robustness in deep GNNs.

</details>


### [502] [Wittgenstein's Family Resemblance Clustering Algorithm](https://arxiv.org/abs/2601.01127)
*Golbahar Amanpour,Benyamin Ghojogh*

Main category: cs.LG

Relevance: 35.0

TL;DR: 论文提出基于维特根斯坦家族相似性概念的WFR聚类算法，无需预先指定聚类数量或假设聚类形状，通过构建相似性图实现非线性聚类。


<details>
  <summary>Details</summary>
Motivation: 将维特根斯坦的家族相似性哲学概念引入机器学习，解决传统聚类方法需要预先指定聚类数量或假设聚类形状的限制，提供更灵活的聚类框架。

Method: 提出WFR聚类算法及其核变体kernel WFR：1) 计算相邻数据实例间的相似度分数；2) 阈值处理后构建相似性图；3) 图的连通分量形成最终聚类。

Result: 在基准数据集上的模拟实验表明，WFR是一种有效的非线性聚类算法，不需要预先知道聚类数量或假设聚类形状。

Conclusion: 成功将哲学概念转化为实用的机器学习算法，WFR为聚类问题提供了新的视角和方法，特别适用于复杂形状和非线性分布的数据。

Abstract: This paper, introducing a novel method in philomatics, draws on Wittgenstein's concept of family resemblance from analytic philosophy to develop a clustering algorithm for machine learning. According to Wittgenstein's Philosophical Investigations (1953), family resemblance holds that members of a concept or category are connected by overlapping similarities rather than a single defining property. Consequently, a family of entities forms a chain of items sharing overlapping traits. This philosophical idea naturally lends itself to a graph-based approach in machine learning. Accordingly, we propose the Wittgenstein's Family Resemblance (WFR) clustering algorithm and its kernel variant, kernel WFR. This algorithm computes resemblance scores between neighboring data instances, and after thresholding these scores, a resemblance graph is constructed. The connected components of this graph define the resulting clusters. Simulations on benchmark datasets demonstrate that WFR is an effective nonlinear clustering algorithm that does not require prior knowledge of the number of clusters or assumptions about their shapes.

</details>


### [503] [MentalGame: Predicting Personality-Job Fitness for Software Developers Using Multi-Genre Games and Machine Learning Approaches](https://arxiv.org/abs/2601.01206)
*Soroush Elyasi,Arya VarastehNezhad,Fattaneh Taghiyareh*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该研究提出一个多类型严肃游戏框架，结合机器学习技术，通过游戏中的隐式行为信号预测软件开发岗位的适合度，无需传统性格测试问卷。


<details>
  <summary>Details</summary>
Motivation: 传统职业评估中的人格测试问卷存在回答偏差、疲劳和故意扭曲等问题。游戏化评估通过捕捉游戏过程中的隐式行为信号，提供了一种更客观、可扩展且有趣的替代方案。

Method: 通过文献综述和软件工程师实证研究确定相关人格和行为特征，设计定制移动游戏来引出问题解决、规划、适应性等行为。采用两阶段建模策略，仅从游戏行为特征预测适合度。

Result: 模型达到97%的精确度和94%的准确率。合适的候选人表现出独特的游戏模式：解谜游戏胜率更高、更多侧边挑战、更频繁导航菜单、更少暂停/重试/放弃行为。

Conclusion: 游戏过程中捕捉的隐式行为痕迹能有效预测软件开发适合度，支持严肃游戏作为职业评估的可扩展、吸引人且偏见较少的替代方案。

Abstract: Personality assessment in career guidance and personnel selection traditionally relies on self-report questionnaires, which are susceptible to response bias, fatigue, and intentional distortion. Game-based assessment offers a promising alternative by capturing implicit behavioral signals during gameplay. This study proposes a multi-genre serious-game framework combined with machine-learning techniques to predict suitability for software development roles. Developer-relevant personality and behavioral traits were identified through a systematic literature review and an empirical study of professional software engineers. A custom mobile game was designed to elicit behaviors related to problem solving, planning, adaptability, persistence, time management, and information seeking. Fine-grained gameplay event data were collected and analyzed using a two-phase modeling strategy where suitability was predicted exclusively from gameplay-derived behavioral features. Results show that our model achieved up to 97% precision and 94% accuracy. Behavioral analysis revealed that proper candidates exhibited distinct gameplay patterns, such as more wins in puzzle-based games, more side challenges, navigating menus more frequently, and exhibiting fewer pauses, retries, and surrender actions. These findings demonstrate that implicit behavioral traces captured during gameplay is promising in predicting software-development suitability without explicit personality testing, supporting serious games as a scalable, engaging, and less biased alternative for career assessment.

</details>


### [504] [Adaptive Conformal Prediction via Bayesian Uncertainty Weighting for Hierarchical Healthcare Data](https://arxiv.org/abs/2601.01223)
*Marzieh Amiri Shahbazi,Ali Baheri,Nasibeh Azadeh-Fard*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出了一种结合贝叶斯层次随机森林与组感知保形校准的混合框架，用于临床决策的不确定性量化，在保证覆盖率的同时实现风险自适应精度。


<details>
  <summary>Details</summary>
Motivation: 临床决策需要同时满足分布无关的覆盖率保证和风险自适应精度的不确定性量化，现有方法无法同时满足这两个要求。医疗预测中需要既可靠又精确的不确定性估计。

Method: 混合贝叶斯-保形框架：集成贝叶斯层次随机森林与组感知保形校准，利用后验不确定性对保形分数进行加权，同时保持严格的覆盖率有效性。

Result: 在61,538例入院患者、3,793家美国医院和4个地区的数据上评估：达到目标覆盖率（94.3% vs 95%目标），自适应精度：低不确定性病例区间缩小21%，高风险预测适当扩大。纯贝叶斯不确定性严重覆盖不足（14.1%）。

Conclusion: 该框架支持风险分层临床协议、高效资源规划和高置信度预测，为不确定病例提供保守分配和增强监督，为多样化医疗环境提供不确定性感知决策支持。

Abstract: Clinical decision-making demands uncertainty quantification that provides both distribution-free coverage guarantees and risk-adaptive precision, requirements that existing methods fail to jointly satisfy. We present a hybrid Bayesian-conformal framework that addresses this fundamental limitation in healthcare predictions. Our approach integrates Bayesian hierarchical random forests with group-aware conformal calibration, using posterior uncertainties to weight conformity scores while maintaining rigorous coverage validity. Evaluated on 61,538 admissions across 3,793 U.S. hospitals and 4 regions, our method achieves target coverage (94.3% vs 95% target) with adaptive precision: 21% narrower intervals for low-uncertainty cases while appropriately widening for high-risk predictions. Critically, we demonstrate that well-calibrated Bayesian uncertainties alone severely under-cover (14.1%), highlighting the necessity of our hybrid approach. This framework enables risk-stratified clinical protocols, efficient resource planning for high-confidence predictions, and conservative allocation with enhanced oversight for uncertain cases, providing uncertainty-aware decision support across diverse healthcare settings.

</details>


### [505] [ARGUS: Adaptive Rotation-Invariant Geometric Unsupervised System](https://arxiv.org/abs/2601.01297)
*Anantha Sharma*

Main category: cs.LG

Relevance: 35.0

TL;DR: Argus框架将高维数据流中的分布漂移检测重新定义为在数据流形固定空间分区上跟踪局部统计量，解决了现有方法的可扩展性、几何结构保持和身份稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 高维数据流中的分布漂移检测面临根本性挑战：全局比较方法扩展性差，基于投影的方法丢失几何结构，重新聚类方法存在身份不稳定性。需要一种既能保持高维结构又计算高效的方法。

Method: Argus框架将漂移检测重新定义为在数据流形固定空间分区上跟踪局部统计量。使用基于规范正交基的Voronoi细分，引入乘积量化细分扩展到超高维度（d>500），通过图论方法表征漂移传播。

Result: 该框架实现了O(N)复杂度，提供细胞级空间定位的分布变化检测，能正确识别坐标旋转下的漂移（现有方法会产生误报），在保持高维结构的同时避免了成对比较的计算负担。

Conclusion: Argus为分布监测提供了有原则的几何基础，通过固定空间分区跟踪局部统计量，解决了高维数据流漂移检测的关键挑战，具有正交变换不变性和良好的可扩展性。

Abstract: Detecting distributional drift in high-dimensional data streams presents fundamental challenges: global comparison methods scale poorly, projection-based approaches lose geometric structure, and re-clustering methods suffer from identity instability. This paper introduces Argus, A framework that reconceptualizes drift detection as tracking local statistics over a fixed spatial partition of the data manifold.
  The key contributions are fourfold. First, it is proved that Voronoi tessellations over canonical orthonormal frames yield drift metrics that are invariant to orthogonal transformations. The rotations and reflections that preserve Euclidean geometry. Second, it is established that this framework achieves O(N) complexity per snapshot while providing cell-level spatial localization of distributional change. Third, a graph-theoretic characterization of drift propagation is developed that distinguishes coherent distributional shifts from isolated perturbations. Fourth, product quantization tessellation is introduced for scaling to very high dimensions (d>500) by decomposing the space into independent subspaces and aggregating drift signals across subspaces.
  This paper formalizes the theoretical foundations, proves invariance properties, and presents experimental validation demonstrating that the framework correctly identifies drift under coordinate rotation while existing methods produce false positives. The tessellated approach offers a principled geometric foundation for distribution monitoring that preserves high-dimensional structure without the computational burden of pairwise comparisons.

</details>


### [506] [Scale-Adaptive Power Flow Analysis with Local Topology Slicing and Multi-Task Graph Learning](https://arxiv.org/abs/2601.01387)
*Yongzhe Li,Lin Guan,Zihan Cai,Zuxian Lin,Jiyu Huang,Liukai Chen*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出SaMPFA框架，通过局部拓扑切片采样和多任务图学习，增强电力系统潮流分析模型对拓扑变化的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 电力系统潮流分析中，现有深度学习模型对拓扑变化的适应性不足，特别是在系统规模变化时分支功率预测的鲁棒性较差。需要开发能够适应不同系统规模、提高跨尺度学习能力的模型。

Method: 1) 提出局部拓扑切片采样技术，从完整电网中提取不同尺度的子图，增强模型的跨尺度学习能力；2) 设计无参考多任务图学习模型，直接预测母线电压和分支功率（而非相角），避免误差放大；3) 在损失函数中加入额外项，鼓励模型学习相角差和功率传输的物理模式。

Result: 在IEEE 39节点系统和实际省级电网上的仿真表明，该模型在可变系统规模下具有优越的适应性和泛化能力，准确率分别提高了4.47%和36.82%。

Conclusion: SaMPFA框架通过创新的采样技术和多任务学习设计，显著提高了电力系统潮流分析模型对拓扑变化的适应性和预测鲁棒性，为深度学习在电力系统分析中的应用提供了新思路。

Abstract: Developing deep learning models with strong adaptability to topological variations is of great practical significance for power flow analysis. To enhance model performance under variable system scales and improve robustness in branch power prediction, this paper proposes a Scale-adaptive Multi-task Power Flow Analysis (SaMPFA) framework. SaMPFA introduces a Local Topology Slicing (LTS) sampling technique that extracts subgraphs of different scales from the complete power network to strengthen the model's cross-scale learning capability. Furthermore, a Reference-free Multi-task Graph Learning (RMGL) model is designed for robust power flow prediction. Unlike existing approaches, RMGL predicts bus voltages and branch powers instead of phase angles. This design not only avoids the risk of error amplification in branch power calculation but also guides the model to learn the physical relationships of phase angle differences. In addition, the loss function incorporates extra terms that encourage the model to capture the physical patterns of angle differences and power transmission, further improving consistency between predictions and physical laws. Simulations on the IEEE 39-bus system and a real provincial grid in China demonstrate that the proposed model achieves superior adaptability and generalization under variable system scales, with accuracy improvements of 4.47% and 36.82%, respectively.

</details>


### [507] [REE-TTT: Highly Adaptive Radar Echo Extrapolation Based on Test-Time Training](https://arxiv.org/abs/2601.01605)
*Xin Di,Xinglin Piao,Fei Wang,Guodong Jing,Yong Zhang*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出REE-TTT模型，通过时空测试时训练机制改进雷达回波外推降水临近预报，提升跨区域和极端天气的泛化能力


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的雷达回波外推降水临近预报方法存在泛化能力差的问题，主要依赖高质量本地训练数据和静态模型参数，难以适应不同区域和极端天气事件

Method: 提出REE-TTT模型，引入自适应测试时训练机制，设计时空测试时训练块，用任务特定的注意力机制替代标准线性投影，增强对非平稳气象分布的适应能力

Result: 在跨区域极端降水场景实验中，REE-TTT在预测精度和泛化能力上显著优于现有基线模型，对数据分布偏移表现出卓越的适应性

Conclusion: 测试时训练机制能有效提升降水临近预报模型的泛化能力，时空注意力设计增强了特征表示，为跨区域气象预测提供了新思路

Abstract: Precipitation nowcasting is critically important for meteorological forecasting. Deep learning-based Radar Echo Extrapolation (REE) has become a predominant nowcasting approach, yet it suffers from poor generalization due to its reliance on high-quality local training data and static model parameters, limiting its applicability across diverse regions and extreme events. To overcome this, we propose REE-TTT, a novel model that incorporates an adaptive Test-Time Training (TTT) mechanism. The core of our model lies in the newly designed Spatio-temporal Test-Time Training (ST-TTT) block, which replaces the standard linear projections in TTT layers with task-specific attention mechanisms, enabling robust adaptation to non-stationary meteorological distributions and thereby significantly enhancing the feature representation of precipitation. Experiments under cross-regional extreme precipitation scenarios demonstrate that REE-TTT substantially outperforms state-of-the-art baseline models in prediction accuracy and generalization, exhibiting remarkable adaptability to data distribution shifts.

</details>


### [508] [Learning Resilient Elections with Adversarial GNNs](https://arxiv.org/abs/2601.01653)
*Hao Xiang Li,Yash Shah,Lorenzo Giusti*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出了一种基于图神经网络和对抗训练的投票规则学习方法，通过将选举表示为二分图来提高学习投票规则的表达能力，同时增强对策略性投票的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 选举是现代民主和市场机制的核心，但设计满足所有场景的通用投票规则仍具挑战性。现有基于集合不变架构的方法在现实应用中面临策略性投票等鲁棒性问题，需要改进。

Method: 1. 将选举表示为二分图结构；2. 使用图神经网络学习投票规则；3. 结合对抗训练提高对策略性投票的鲁棒性；4. 在合成和真实数据集上评估方法。

Result: 该方法解决了先前工作在投票规则学习方面的关键限制，提高了投票规则的表达能力和社会福利最大化能力，同时增强了鲁棒性。

Conclusion: 该工作为机器学习在现实世界选举中的应用开辟了新前沿，通过图神经网络和对抗训练的结合，为自动化机制设计提供了有前景的解决方案。

Abstract: In the face of adverse motives, it is indispensable to achieve a consensus. Elections have been the canonical way by which modern democracy has operated since the 17th century. Nowadays, they regulate markets, provide an engine for modern recommender systems or peer-to-peer networks, and remain the main approach to represent democracy. However, a desirable universal voting rule that satisfies all hypothetical scenarios is still a challenging topic, and the design of these systems is at the forefront of mechanism design research. Automated mechanism design is a promising approach, and recent works have demonstrated that set-invariant architectures are uniquely suited to modelling electoral systems. However, various concerns prevent the direct application to real-world settings, such as robustness to strategic voting. In this paper, we generalise the expressive capability of learned voting rules, and combine improvements in neural network architecture with adversarial training to improve the resilience of voting rules while maximizing social welfare. We evaluate the effectiveness of our methods on both synthetic and real-world datasets. Our method resolves critical limitations of prior work regarding learning voting rules by representing elections using bipartite graphs, and learning such voting rules using graph neural networks. We believe this opens new frontiers for applying machine learning to real-world elections.

</details>


### [509] [Length-Aware Adversarial Training for Variable-Length Trajectories: Digital Twins for Mall Shopper Paths](https://arxiv.org/abs/2601.01663)
*He Sun,Jiwoong Shin,Ravi Dhar*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出长度感知采样(LAS)方法，通过按轨迹长度分组批次训练，解决变长轨迹生成建模中的分布匹配问题，提升下游模拟和反事实分析性能。


<details>
  <summary>Details</summary>
Motivation: 研究变长轨迹（带有时间戳的位置/项目序列）的生成建模，用于下游模拟和反事实分析。标准小批量训练在轨迹长度高度异质时不稳定，这会降低轨迹派生统计量的分布匹配质量。

Method: 提出长度感知采样(LAS)：简单的批处理策略，按轨迹长度分组，从单个长度桶中采样批次，减少批次内长度异质性而不改变模型架构。集成到带有辅助时间对齐损失的轨迹条件GAN中，提供理论保证。

Result: LAS在多商场购物者轨迹数据集和多样化公共序列数据集（GPS、教育、电子商务、电影）上一致改善派生变量分布的匹配，在数据集特定指标上优于随机采样。

Conclusion: LAS通过减少批次内长度异质性，有效提升变长轨迹生成建模的分布匹配性能，为下游模拟和反事实分析提供更可靠的轨迹生成。

Abstract: We study generative modeling of \emph{variable-length trajectories} -- sequences of visited locations/items with associated timestamps -- for downstream simulation and counterfactual analysis. A recurring practical issue is that standard mini-batch training can be unstable when trajectory lengths are highly heterogeneous, which in turn degrades \emph{distribution matching} for trajectory-derived statistics. We propose \textbf{length-aware sampling (LAS)}, a simple batching strategy that groups trajectories by length and samples batches from a single length bucket, reducing within-batch length heterogeneity (and making updates more consistent) without changing the model class. We integrate LAS into a conditional trajectory GAN with auxiliary time-alignment losses and provide (i) a distribution-level guarantee for derived variables under mild boundedness assumptions, and (ii) an IPM/Wasserstein mechanism explaining why LAS improves distribution matching by removing length-only shortcut critics and targeting within-bucket discrepancies. Empirically, LAS consistently improves matching of derived-variable distributions on a multi-mall dataset of shopper trajectories and on diverse public sequence datasets (GPS, education, e-commerce, and movies), outperforming random sampling across dataset-specific metrics.

</details>


### [510] [Tackling Resource-Constrained and Data-Heterogeneity in Federated Learning with Double-Weight Sparse Pack](https://arxiv.org/abs/2601.01840)
*Qiantao Yang,Liquan Chen,Mingfu Xue,Songze Li*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出FedCSPACK方法，通过余弦稀疏化参数打包和双权重聚合解决联邦学习中数据异构性和客户端资源受限的平衡问题


<details>
  <summary>Details</summary>
Motivation: 联邦学习中边缘客户端数据异构性会降低模型性能，现有方法虽然通过模型分割和知识蒸馏增强模型兼容性，但忽略了客户端通信带宽和计算能力不足的问题，未能有效平衡数据异构性处理和有限客户端资源

Method: 基于余弦稀疏化参数打包和双权重聚合的个性化联邦学习方法(FedCSPACK)：1)客户端打包模型参数并根据余弦相似度选择最有贡献的参数包共享，减少带宽需求；2)客户端生成基于共享参数包的掩码矩阵，提高服务器上稀疏更新的对齐和聚合效率；3)在掩码中嵌入方向和分布距离权重，实现加权引导聚合机制

Result: 在四个数据集上使用十种最先进方法的广泛实验表明，FedCSPACK在保持高模型精度的同时，有效提高了通信和计算效率

Conclusion: FedCSPACK方法通过创新的参数打包和加权聚合机制，成功解决了联邦学习中数据异构性和客户端资源受限的平衡问题，实现了高效且准确的模型训练

Abstract: Federated learning has drawn widespread interest from researchers, yet the data heterogeneity across edge clients remains a key challenge, often degrading model performance. Existing methods enhance model compatibility with data heterogeneity by splitting models and knowledge distillation. However, they neglect the insufficient communication bandwidth and computing power on the client, failing to strike an effective balance between addressing data heterogeneity and accommodating limited client resources. To tackle this limitation, we propose a personalized federated learning method based on cosine sparsification parameter packing and dual-weighted aggregation (FedCSPACK), which effectively leverages the limited client resources and reduces the impact of data heterogeneity on model performance. In FedCSPACK, the client packages model parameters and selects the most contributing parameter packages for sharing based on cosine similarity, effectively reducing bandwidth requirements. The client then generates a mask matrix anchored to the shared parameter package to improve the alignment and aggregation efficiency of sparse updates on the server. Furthermore, directional and distribution distance weights are embedded in the mask to implement a weighted-guided aggregation mechanism, enhancing the robustness and generalization performance of the global model. Extensive experiments across four datasets using ten state-of-the-art methods demonstrate that FedCSPACK effectively improves communication and computational efficiency while maintaining high model accuracy.

</details>


### [511] [FedBiCross: A Bi-Level Optimization Framework to Tackle Non-IID Challenges in Data-Free One-Shot Federated Learning on Medical Data](https://arxiv.org/abs/2601.01901)
*Yuexuan Xia,Yinghao Zhang,Yalin Liu,Hong-Ning Dai,Yong Xia*

Main category: cs.LG

Relevance: 35.0

TL;DR: FedBiCross：一种个性化的单次联邦学习框架，通过聚类、双层跨集群优化和个性化蒸馏解决非IID数据下预测冲突问题，在医学图像数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的单次联邦学习方法在非IID数据下，将所有客户端的预测聚合形成全局教师模型时，冲突的预测会在平均过程中相互抵消，产生接近均匀分布的软标签，为知识蒸馏提供弱监督。

Method: 1) 基于模型输出相似性对客户端进行聚类，形成一致的子集成；2) 双层跨集群优化，学习自适应权重以选择性利用有益的跨集群知识，同时抑制负迁移；3) 个性化蒸馏进行客户端特定适应。

Result: 在四个医学图像数据集上的实验表明，FedBiCross在不同非IID程度下始终优于最先进的基线方法。

Conclusion: FedBiCross通过聚类和选择性知识转移有效解决了非IID数据下单次联邦学习的预测冲突问题，为隐私敏感的医学应用提供了有效的个性化解决方案。

Abstract: Data-free knowledge distillation-based one-shot federated learning (OSFL) trains a model in a single communication round without sharing raw data, making OSFL attractive for privacy-sensitive medical applications. However, existing methods aggregate predictions from all clients to form a global teacher. Under non-IID data, conflicting predictions cancel out during averaging, yielding near-uniform soft labels that provide weak supervision for distillation. We propose FedBiCross, a personalized OSFL framework with three stages: (1) clustering clients by model output similarity to form coherent sub-ensembles, (2) bi-level cross-cluster optimization that learns adaptive weights to selectively leverage beneficial cross-cluster knowledge while suppressing negative transfer, and (3) personalized distillation for client-specific adaptation. Experiments on four medical image datasets demonstrate that FedBiCross consistently outperforms state-of-the-art baselines across different non-IID degrees.

</details>


### [512] [SynRXN: An Open Benchmark and Curated Dataset for Computational Reaction Modeling](https://arxiv.org/abs/2601.01943)
*Tieu-Long Phan,Nhu-Ngoc Nguyen Song,Peter F. Stadler*

Main category: cs.LG

Relevance: 35.0

TL;DR: SynRXN是一个用于计算机辅助合成规划的统一基准框架和开放数据资源，将端到端合成规划分解为五个任务族，提供标准化评估流程和防泄漏的数据分割。


<details>
  <summary>Details</summary>
Motivation: 当前计算机辅助合成规划领域缺乏统一的基准框架，数据集异构、评估标准不一致，难以进行公平的纵向比较和可重复研究。需要透明、可复现的评估框架来支持稳健的性能评估。

Method: 1. 将合成规划分解为五个任务族：反应平衡、原子映射、反应分类、反应性质预测、合成路线设计
2. 从异构公共源收集反应数据，统一表示并打包为版本化数据集
3. 提供防泄漏的数据分割函数，生成训练/验证/测试集
4. 为每个任务提供标准化评估流程和指标套件
5. 使用脚本化构建配方确保跨机器和时间的比特级可复现性

Result: 创建了一个全面的基准框架和开放数据资源，支持计算机辅助合成规划方法的公平比较。提供了透明、可复现的评估基础设施，降低了从业者获取稳健性能评估的门槛。

Conclusion: SynRXN通过消除数据集异构性并提供透明、可重用的评估框架，支持CASP方法的公平纵向比较，促进严谨的消融研究和压力测试，有助于推动计算机辅助合成规划领域的发展。

Abstract: We present SynRXN, a unified benchmarking framework and open-data resource for computer-aided synthesis planning (CASP). SynRXN decomposes end-to-end synthesis planning into five task families, covering reaction rebalancing, atom-to-atom mapping, reaction classification, reaction property prediction, and synthesis route design. Curated, provenance-tracked reaction corpora are assembled from heterogeneous public sources into a harmonized representation and packaged as versioned datasets for each task family, with explicit source metadata, licence tags, and machine-readable manifests that record checksums, and row counts. For every task, SynRXN provides transparent splitting functions that generate leakage-aware train, validation, and test partitions, together with standardized evaluation workflows and metric suites tailored to classification, regression, and structured prediction settings. For sensitive benchmarking, we combine public training and validation data with held-out gold-standard test sets, and contamination-prone tasks such as reaction rebalancing and atom-to-atom mapping are distributed only as evaluation sets and are explicitly not intended for model training. Scripted build recipes enable bitwise-reproducible regeneration of all corpora across machines and over time, and the entire resource is released under permissive open licences to support reuse and extension. By removing dataset heterogeneity and packaging transparent, reusable evaluation scaffolding, SynRXN enables fair longitudinal comparison of CASP methods, supports rigorous ablations and stress tests along the full reaction-informatics pipeline, and lowers the barrier for practitioners who seek robust and comparable performance estimates for real-world synthesis planning workloads.

</details>


### [513] [SerpentFlow: Generative Unpaired Domain Alignment via Shared-Structure Decomposition](https://arxiv.org/abs/2601.01979)
*Julie Keisler,Anastase Alexandre Charantonis,Yannig Goude,Boutheina Oueslati,Claire Monteleoni*

Main category: cs.LG

Relevance: 35.0

TL;DR: SerpentFlow是一种用于无配对域对齐的生成框架，通过潜在空间分解将数据分为共享结构和域特定组件，利用合成训练对实现条件生成模型


<details>
  <summary>Details</summary>
Motivation: 解决无配对观测情况下的域对齐问题，当域共享底层结构模式但具体实现不同时，缺乏跨域直接监督使得任务具有挑战性

Method: 在潜在空间中将数据分解为共享组件和域特定组件，通过隔离共享结构并用随机噪声替换域特定组件，构建共享表示与目标域样本之间的合成训练对，从而启用条件生成模型

Result: 在合成图像、物理过程模拟和气候降尺度任务上的实验表明，该方法能有效重建与底层低频模式一致的高频结构

Conclusion: 共享结构分解是无配对域对齐的有效策略，SerpentFlow框架支持多种条件生成方法，Flow Matching作为生成管道

Abstract: Domain alignment refers broadly to learning correspondences between data distributions from distinct domains. In this work, we focus on a setting where domains share underlying structural patterns despite differences in their specific realizations. The task is particularly challenging in the absence of paired observations, which removes direct supervision across domains. We introduce a generative framework, called SerpentFlow (SharEd-structuRe decomPosition for gEnerative domaiN adapTation), for unpaired domain alignment. SerpentFlow decomposes data within a latent space into a shared component common to both domains and a domain-specific one. By isolating the shared structure and replacing the domain-specific component with stochastic noise, we construct synthetic training pairs between shared representations and target-domain samples, thereby enabling the use of conditional generative models that are traditionally restricted to paired settings. We apply this approach to super-resolution tasks, where the shared component naturally corresponds to low-frequency content while high-frequency details capture domain-specific variability. The cutoff frequency separating low- and high-frequency components is determined automatically using a classifier-based criterion, ensuring a data-driven and domain-adaptive decomposition. By generating pseudo-pairs that preserve low-frequency structures while injecting stochastic high-frequency realizations, we learn the conditional distribution of the target domain given the shared representation. We implement SerpentFlow using Flow Matching as the generative pipeline, although the framework is compatible with other conditional generative approaches. Experiments on synthetic images, physical process simulations, and a climate downscaling task demonstrate that the method effectively reconstructs high-frequency structures consistent with underlying low-frequency patterns, supporting shared-structure decomposition as an effective strategy for unpaired domain alignment.

</details>


### [514] [Explore the Ideology of Deep Learning in ENSO Forecasts](https://arxiv.org/abs/2601.02050)
*Yanhai Gan,Yipeng Chen,Ning Li,Xingguo Liu,Junyu Dong,Xianyao Chen*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出了一种基于有界变差函数的数学可解释性框架，通过激活函数饱和区"拯救"死亡神经元来增强模型表达能力，用于ENSO预测的可解释性分析。


<details>
  <summary>Details</summary>
Motivation: ENSO对全球气候变率有深远影响，但其预测仍是一个重大挑战。深度学习虽提高了预测技能，但模型的不透明性阻碍了科学信任和业务部署，需要可解释的预测框架。

Method: 引入基于有界变差函数的数学可解释性框架，通过从激活函数饱和区"拯救"死亡神经元来增强模型表达能力，分析ENSO可预测性的空间来源。

Result: 分析显示ENSO可预测性主要来自热带太平洋，印度洋和大西洋也有贡献，与物理理解一致。发现春季可预测性障碍期间敏感性扩大但预测性能下降，可能源于次优变量选择。

Conclusion: 该方法与已知预测因子一致，具有稳健性。加入更多海气变量可能有助于突破春季可预测性障碍限制，推进长期ENSO预测。

Abstract: The El Ni{~n}o-Southern Oscillation (ENSO) exerts profound influence on global climate variability, yet its prediction remains a grand challenge. Recent advances in deep learning have significantly improved forecasting skill, but the opacity of these models hampers scientific trust and operational deployment. Here, we introduce a mathematically grounded interpretability framework based on bounded variation function. By rescuing the "dead" neurons from the saturation zone of the activation function, we enhance the model's expressive capacity. Our analysis reveals that ENSO predictability emerges dominantly from the tropical Pacific, with contributions from the Indian and Atlantic Oceans, consistent with physical understanding. Controlled experiments affirm the robustness of our method and its alignment with established predictors. Notably, we probe the persistent Spring Predictability Barrier (SPB), finding that despite expanded sensitivity during spring, predictive performance declines-likely due to suboptimal variable selection. These results suggest that incorporating additional ocean-atmosphere variables may help transcend SPB limitations and advance long-range ENSO prediction.

</details>


### [515] [LION-DG: Layer-Informed Initialization with Deep Gradient Protocols for Accelerated Neural Network Training](https://arxiv.org/abs/2601.02105)
*Hyunjun Kim*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出LION-DG初始化方法，针对带辅助分类器的深度监督网络，通过零初始化辅助头实现梯度唤醒，无需超参数即可稳定训练


<details>
  <summary>Details</summary>
Motivation: 现有权重初始化方法大多是层无关的，而深度监督架构中的未训练辅助分类器头会通过梯度干扰破坏早期训练稳定性

Method: 提出LION-DG层感知初始化：对主干网络应用标准He初始化，对辅助分类器头进行零初始化，实现梯度唤醒机制

Result: 在CIFAR-10/100上实验显示：DenseNet-DS收敛速度提升8.3%；结合LSUV和LION-DG达到最佳准确率81.92%；ResNet-DS在CIFAR-100上速度提升11.3%

Conclusion: LION-DG方法简单、无需超参数、无计算开销，为带辅助分类器的深度监督网络提供了有效的初始化解决方案

Abstract: Weight initialization remains decisive for neural network optimization, yet existing methods are largely layer-agnostic. We study initialization for deeply-supervised architectures with auxiliary classifiers, where untrained auxiliary heads can destabilize early training through gradient interference.
  We propose LION-DG, a layer-informed initialization that zero-initializes auxiliary classifier heads while applying standard He-initialization to the backbone. We prove that this implements Gradient Awakening: auxiliary gradients are exactly zero at initialization, then phase in naturally as weights grow -- providing an implicit warmup without hyperparameters.
  Experiments on CIFAR-10 and CIFAR-100 with DenseNet-DS and ResNet-DS architectures demonstrate: (1) DenseNet-DS: +8.3% faster convergence on CIFAR-10 with comparable accuracy, (2) Hybrid approach: Combining LSUV with LION-DG achieves best accuracy (81.92% on CIFAR-10), (3) ResNet-DS: Positive speedup on CIFAR-100 (+11.3%) with side-tap auxiliary design.
  We identify architecture-specific trade-offs and provide clear guidelines for practitioners. LION-DG is simple, requires zero hyperparameters, and adds no computational overhead.

</details>


### [516] [ACDZero: Graph-Embedding-Based Tree Search for Mastering Automated Cyber Defense](https://arxiv.org/abs/2601.02196)
*Yu Li,Sizhe Tang,Rongqian Chen,Fei Xu Yu,Guangyu Jiang,Mahdi Imani,Nathaniel D. Bastian,Tian Lan*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出一种基于蒙特卡洛树搜索和图神经网络的自动化网络防御方法，在CAGE-4挑战中通过规划导向的策略实现样本高效防御


<details>
  <summary>Details</summary>
Motivation: 现有基于深度强化学习的自动化网络防御方法在复杂网络环境中面临探索困难和大状态空间问题，需要大量样本，需要开发样本高效的防御策略

Method: 将ACD建模为基于上下文的部分可观测马尔可夫决策过程，提出基于MCTS的规划中心防御策略，使用GNN嵌入网络观测为属性图，结合学习到的图嵌入和图编辑动作先验来指导MCTS

Result: 在CC4场景中评估，显示搜索引导的、基于图嵌入的规划方法相比最先进的RL基线，在防御奖励和鲁棒性方面都有提升

Conclusion: 通过结合无模型泛化、策略蒸馏和前向规划，提出的方法在复杂搜索空间中实现了实用且高效的自动化网络防御

Abstract: Automated cyber defense (ACD) seeks to protect computer networks with minimal or no human intervention, reacting to intrusions by taking corrective actions such as isolating hosts, resetting services, deploying decoys, or updating access controls. However, existing approaches for ACD, such as deep reinforcement learning (RL), often face difficult exploration in complex networks with large decision/state spaces and thus require an expensive amount of samples. Inspired by the need to learn sample-efficient defense policies, we frame ACD in CAGE Challenge 4 (CAGE-4 / CC4) as a context-based partially observable Markov decision problem and propose a planning-centric defense policy based on Monte Carlo Tree Search (MCTS). It explicitly models the exploration-exploitation tradeoff in ACD and uses statistical sampling to guide exploration and decision making. We make novel use of graph neural networks (GNNs) to embed observations from the network as attributed graphs, to enable permutation-invariant reasoning over hosts and their relationships. To make our solution practical in complex search spaces, we guide MCTS with learned graph embeddings and priors over graph-edit actions, combining model-free generalization and policy distillation with look-ahead planning. We evaluate the resulting agent on CC4 scenarios involving diverse network structures and adversary behaviors, and show that our search-guided, graph-embedding-based planning improves defense reward and robustness relative to state-of-the-art RL baselines.

</details>


### [517] [Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.02213)
*Haoyu Zhou,Ping Xue,Tianfan Fu,Hao Zhang*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文提出了一种用于压缩和加速SO(3)-等变图神经网络的低比特量化方法，通过解耦量化方案、分支分离训练策略和注意力归一化机制，在保持精度和物理对称性的同时显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署具有3D旋转等变性（SO(3)群）的3D图神经网络面临高计算成本挑战。本文旨在通过低比特量化技术压缩和加速SO(3)-等变GNN，使其能够在实际化学应用中部署。

Method: 提出三种创新方法：1）幅度-方向解耦量化方案，分别量化等变特征的范数和方向；2）分支分离量化感知训练策略，在基于注意力的SO(3)-GNN中对不变和等变特征通道进行差异化处理；3）鲁棒性增强的注意力归一化机制，稳定低精度注意力计算。

Result: 在QM9和rMD17分子基准测试中，8位模型在能量和力预测方面达到与全精度基线相当的精度，同时显著提升效率。推理速度提升2.37-2.73倍，模型大小减小4倍，不牺牲精度或物理对称性。

Conclusion: 提出的量化技术能够有效部署对称感知GNN到实际化学应用中，在保持等变性和精度的同时显著提升计算效率，为边缘设备上的3D等变模型部署提供了可行方案。

Abstract: Deploying 3D graph neural networks (GNNs) that are equivariant to 3D rotations (the group SO(3)) on edge devices is challenging due to their high computational cost. This paper addresses the problem by compressing and accelerating an SO(3)-equivariant GNN using low-bit quantization techniques. Specifically, we introduce three innovations for quantized equivariant transformers: (1) a magnitude-direction decoupled quantization scheme that separately quantizes the norm and orientation of equivariant (vector) features, (2) a branch-separated quantization-aware training strategy that treats invariant and equivariant feature channels differently in an attention-based $SO(3)$-GNN, and (3) a robustness-enhancing attention normalization mechanism that stabilizes low-precision attention computations. Experiments on the QM9 and rMD17 molecular benchmarks demonstrate that our 8-bit models achieve accuracy on energy and force predictions comparable to full-precision baselines with markedly improved efficiency. We also conduct ablation studies to quantify the contribution of each component to maintain accuracy and equivariance under quantization, using the Local error of equivariance (LEE) metric. The proposed techniques enable the deployment of symmetry-aware GNNs in practical chemistry applications with 2.37--2.73x faster inference and 4x smaller model size, without sacrificing accuracy or physical symmetry.

</details>


### [518] [POSEIDON: Physics-Optimized Seismic Energy Inference and Detection Operating Network](https://arxiv.org/abs/2601.02264)
*Boris Kriuk,Fedor Kriuk*

Main category: cs.LG

Relevance: 35.0

TL;DR: POSEIDON是一个基于物理信息的能量模型，用于统一的多任务地震事件预测，结合了Gutenberg-Richter定律和Omori-Utsu余震衰减定律作为可学习约束，在三个预测任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 地震预测和地震危险性评估是地球物理学的基本挑战，现有机器学习方法通常作为黑箱运行，忽略了已建立的物理定律。需要开发既能利用数据驱动方法又能嵌入物理约束的模型。

Method: 提出POSEIDON模型，将Gutenberg-Richter震级-频率关系和Omori-Utsu余震衰减定律作为可学习约束嵌入到基于能量的建模框架中。同时处理三个相互关联的预测任务：余震序列识别、海啸生成潜力和前震检测。

Result: POSEIDON在所有任务上实现了最先进的性能，在平均F1分数上优于梯度提升、随机森林和CNN基线。学习到的物理参数收敛到科学可解释的值（Gutenberg-Richter b值=0.752，Omori-Utsu参数p=0.835，c=0.1948天），落在已建立的地震学范围内。

Conclusion: POSEIDON展示了将物理约束整合到机器学习框架中的有效性，既能保持预测准确性，又能获得科学可解释的参数。同时发布了Poseidon数据集（280万个事件，30年数据），推动物理信息地震研究。

Abstract: Earthquake prediction and seismic hazard assessment remain fundamental challenges in geophysics, with existing machine learning approaches often operating as black boxes that ignore established physical laws. We introduce POSEIDON (Physics-Optimized Seismic Energy Inference and Detection Operating Network), a physics-informed energy-based model for unified multi-task seismic event prediction, alongside the Poseidon dataset -- the largest open-source global earthquake catalog comprising 2.8 million events spanning 30 years. POSEIDON embeds fundamental seismological principles, including the Gutenberg-Richter magnitude-frequency relationship and Omori-Utsu aftershock decay law, as learnable constraints within an energy-based modeling framework. The architecture simultaneously addresses three interconnected prediction tasks: aftershock sequence identification, tsunami generation potential, and foreshock detection. Extensive experiments demonstrate that POSEIDON achieves state-of-the-art performance across all tasks, outperforming gradient boosting, random forest, and CNN baselines with the highest average F1 score among all compared methods. Crucially, the learned physics parameters converge to scientifically interpretable values -- Gutenberg-Richter b-value of 0.752 and Omori-Utsu parameters p=0.835, c=0.1948 days -- falling within established seismological ranges while enhancing rather than compromising predictive accuracy. The Poseidon dataset is publicly available at https://huggingface.co/datasets/BorisKriuk/Poseidon, providing pre-computed energy features, spatial grid indices, and standardized quality metrics to advance physics-informed seismic research.

</details>


### [519] [Temporal Kolmogorov-Arnold Networks (T-KAN) for High-Frequency Limit Order Book Forecasting: Efficiency, Interpretability, and Alpha Decay](https://arxiv.org/abs/2601.02310)
*Ahmad Makinde*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文提出Temporal Kolmogorov-Arnold Networks (T-KAN)用于高频交易中的限价订单簿预测，通过可学习的B样条激活函数替代传统LSTM的固定线性权重，在时间跨度增加时显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 高频交易环境中的限价订单簿数据噪声大、非线性强，传统模型如DeepLOB在时间跨度增加时预测能力下降（alpha衰减问题）。需要能够学习市场信号"形状"而不仅仅是幅度的模型。

Method: 提出T-KAN网络，用可学习的B样条激活函数替代标准LSTM的固定线性权重，使模型能够学习市场信号的时间模式。该架构专门针对低延迟FPGA实现进行优化，使用高级综合技术。

Result: 在FI-2010数据集上，T-KAN在k=100时间跨度上相对F1分数提升19.1%。在1.0基点交易成本下，T-KAN产生132.48%的回报，而DeepLOB亏损82.76%。模型具有较好的可解释性，样条中的"死区"清晰可见。

Conclusion: T-KAN网络在高频交易预测中显著优于传统模型，不仅提升预测性能，还提供更好的可解释性，并且适合低延迟硬件实现。

Abstract: High-Frequency trading (HFT) environments are characterised by large volumes of limit order book (LOB) data, which is notoriously noisy and non-linear. Alpha decay represents a significant challenge, with traditional models such as DeepLOB losing predictive power as the time horizon (k) increases. In this paper, using data from the FI-2010 dataset, we introduce Temporal Kolmogorov-Arnold Networks (T-KAN) to replace the fixed, linear weights of standard LSTMs with learnable B-spline activation functions. This allows the model to learn the 'shape' of market signals as opposed to just their magnitude. This resulted in a 19.1% relative improvement in the F1-score at the k = 100 horizon. The efficacy of T-KAN networks cannot be understated, producing a 132.48% return compared to the -82.76% DeepLOB drawdown under 1.0 bps transaction costs. In addition to this, the T-KAN model proves quite interpretable, with the 'dead-zones' being clearly visible in the splines. The T-KAN architecture is also uniquely optimized for low-latency FPGA implementation via High level Synthesis (HLS). The code for the experiments in this project can be found at https://github.com/AhmadMak/Temporal-Kolmogorov-Arnold-Networks-T-KAN-for-High-Frequency-Limit-Order-Book-Forecasting.

</details>


### [520] [ChronoPlastic Spiking Neural Networks](https://arxiv.org/abs/2601.00805)
*Sarim Chaudhry*

Main category: cs.NE

Relevance: 35.0

TL;DR: 本文提出ChronoPlastic Spiking Neural Networks (CPSNNs)，一种新型脉冲神经网络架构，通过动态调节突触衰减率来解决SNN处理长程时间依赖性的问题，相比传统SNN能更快更可靠地学习长间隔时间依赖。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络(SNNs)具有生物合理性和高能效优势，但受限于固定的突触和膜时间常数，难以处理长程时间依赖性。现有方法如自适应膜常数、注意力机制或外部记忆存在局限性，需要一种能直接嵌入局部突触动态的时序控制机制。

Method: 提出ChronoPlastic SNNs (CPSNNs)，核心思想是通过网络状态动态调节突触衰减率，实现自适应时序信用分配。模型维护多个内部时间轨迹，学习连续时间扭曲函数，选择性保留任务相关信息并快速遗忘噪声。该方法将时序控制直接嵌入局部突触动态，保持线性时间复杂度和神经形态兼容性。

Result: CPSNNs在长间隔时间依赖性学习任务上，相比标准SNN基线学习速度显著更快、可靠性更高。实验证明自适应时间调制是脉冲系统中可扩展时序学习的关键缺失要素。

Conclusion: 自适应时间调制是脉冲系统可扩展时序学习的关键要素。CPSNNs通过动态调节突触衰减率，在保持SNN能效优势的同时，显著提升了处理长程时间依赖性的能力，为神经形态计算提供了新的架构原则。

Abstract: Spiking neural networks (SNNs) offer a biologically grounded and energy-efficient alternative to conventional neural architectures; however, they struggle with long-range temporal dependencies due to fixed synaptic and membrane time constants. This paper introduces ChronoPlastic Spiking Neural Networks (CPSNNs), a novel architectural principle that enables adaptive temporal credit assignment by dynamically modulating synaptic decay rates conditioned on the state of the network. CPSNNs maintain multiple internal temporal traces and learn a continuous time-warping function that selectively preserves task-relevant information while rapidly forgetting noise. Unlike prior approaches based on adaptive membrane constants, attention mechanisms, or external memory, CPSNNs embed temporal control directly within local synaptic dynamics, preserving linear-time complexity and neuromorphic compatibility. We provide a formal description of the model, analyze its computational properties, and demonstrate empirically that CPSNNs learn long-gap temporal dependencies significantly faster and more reliably than standard SNN baselines. Our results suggest that adaptive temporal modulation is a key missing ingredient for scalable temporal learning in spiking systems.

</details>


### [521] [Deep versus Broad Technology Search and the Timing of Innovation Impact](https://arxiv.org/abs/2601.00871)
*Likun Cao,James Evans*

Main category: physics.soc-ph

Relevance: 35.0

TL;DR: 该研究通过双曲空间专利网络分析，揭示了深度搜索与广度搜索在技术创新中的不同时间影响模式：深度搜索带来短期专业社区采纳，但面临锁定效应；广度搜索初期受阻但实现长期广泛扩散。


<details>
  <summary>Details</summary>
Motivation: 传统创新战略中的深度与广度之争缺乏对动态集体知识系统和时间维度的考量。研究者希望理解不同搜索策略如何影响技术创新的时间轨迹和长期影响，为创新理论提供新视角。

Method: 使用前沿机器学习方法，将490万美国专利的引用网络投影到双曲空间中进行分析。通过专利引用网络的时间演化，研究深度搜索（依赖专业化知识重组）和广度搜索（跨领域知识整合）对技术影响积累的不同时间模式。

Result: 深度搜索基于复杂重组结构的专业化理解，在专业社区内早期采纳带来较高短期影响，但随着创新"锁定"而面临收益递减和扩散受限。广度搜索跨越不同领域，初期遇到阻力但通过触达认知多样化受众实现更广泛扩散和更大长期影响。单个发明需要深度与广度平衡才能获得稳定影响。

Conclusion: 深度和广度搜索策略以不同方式塑造技术影响的时间轨迹。组织可以通过深度搜索建立可靠技术基础设施，同时通过广度搜索扩展应用领域，平衡利用与探索。研究为创新理论提供了时间动态视角。

Abstract: This study offers a new perspective on the depth-versus-breadth debate in innovation strategy, by modeling inventive search within dynamic collective knowledge systems, and underscoring the importance of timing for technological impact. Using frontier machine learning to project patent citation networks in hyperbolic space, we analyze 4.9 million U.S. patents to examine how search strategies give rise to distinct temporal patterns in impact accumulation. We find that inventions based on deep search, which relies on a specialized understanding of complex recombination structures, drive higher short-term impact through early adoption within specialized communities, but face diminishing returns as innovations become "locked-in" with limited diffusion potential. Conversely, when inventions are grounded in broad search that spans disparate domains, they encounter initial resistance but achieve wider diffusion and greater long-term impact by reaching cognitively diverse audiences. Individual inventions require both depth and breadth for stable impact. Organizations can strategically balance approaches across multiple inventions: using depth to build reliable technological infrastructure while pursuing breadth to expand applications. We advance innovation theory by demonstrating how deep and broad search strategies distinctly shape the timing and trajectory of technological impact, and how individual inventors and organizations can leverage these mechanisms to balance exploitation and exploration.

</details>


### [522] [Towards eco friendly cybersecurity: machine learning based anomaly detection with carbon and energy metrics](https://arxiv.org/abs/2601.00893)
*KC Aashish,Md Zakir Hossain Zamil,Md Shafiqul Islam Mridul,Lamia Akter,Farmina Sharmin,Eftekhar Hossain Ayon,Md Maruf Bin Reza,Ali Hassan,Abdur Rahim,Sirapa Malla*

Main category: cs.CR

Relevance: 35.0

TL;DR: 该研究提出了一个生态感知的异常检测框架，将机器学习网络监控与实时碳排放和能源追踪相结合，通过Eco Efficiency Index（F1分数/千瓦时）评估模型在性能与环境影响之间的权衡，发现优化的随机森林和轻量级逻辑回归模型具有最高的生态效率。


<details>
  <summary>Details</summary>
Motivation: 人工智能的能源消耗已成为美国数据中心排放的重要组成部分，但网络安全研究很少考虑其环境成本。本研究旨在将碳排放和能源指标整合到网络安全工作流程中，实现环境友好的机器学习，同时不损害操作保护。

Method: 使用包含2300个流级观测的Carbon Aware Cybersecurity Traffic Dataset，在受控的Colab环境中使用CodeCarbon工具包量化训练和推理期间的功耗和CO2排放。构建Eco Efficiency Index（F1分数/千瓦时）来评估模型在检测质量和环境影响之间的权衡。比较了逻辑回归、随机森林、支持向量机、隔离森林和XGBoost模型，并使用主成分分析降低计算负载。

Result: 优化的随机森林和轻量级逻辑回归模型实现了最高的生态效率，与XGBoost相比减少了超过40%的能源消耗，同时保持了有竞争力的检测准确率。主成分分析进一步降低了计算负载，而召回率损失可忽略不计。

Conclusion: 将碳排放和能源指标整合到网络安全工作流程中，可以在不损害操作保护的情况下实现环境友好的机器学习。该框架为可持续的、碳排放可追踪的网络安全提供了可复现的路径，符合美国绿色计算和联邦能源效率倡议。

Abstract: The rising energy footprint of artificial intelligence has become a measurable component of US data center emissions, yet cybersecurity research seldom considers its environmental cost. This study introduces an eco aware anomaly detection framework that unifies machine learning based network monitoring with real time carbon and energy tracking. Using the publicly available Carbon Aware Cybersecurity Traffic Dataset comprising 2300 flow level observations, we benchmark Logistic Regression, Random Forest, Support Vector Machine, Isolation Forest, and XGBoost models across energy, carbon, and performance dimensions. Each experiment is executed in a controlled Colab environment instrumented with the CodeCarbon toolkit to quantify power draw and equivalent CO2 output during both training and inference. We construct an Eco Efficiency Index that expresses F1 score per kilowatt hour to capture the trade off between detection quality and environmental impact. Results reveal that optimized Random Forest and lightweight Logistic Regression models achieve the highest eco efficiency, reducing energy consumption by more than forty percent compared to XGBoost while sustaining competitive detection accuracy. Principal Component Analysis further decreases computational load with negligible loss in recall. Collectively, these findings establish that integrating carbon and energy metrics into cybersecurity workflows enables environmentally responsible machine learning without compromising operational protection. The proposed framework offers a reproducible path toward sustainable carbon accountable cybersecurity aligned with emerging US green computing and federal energy efficiency initiatives.

</details>


### [523] [Deep Deterministic Nonlinear ICA via Total Correlation Minimization with Matrix-Based Entropy Functional](https://arxiv.org/abs/2601.00904)
*Qiang Li,Shujian Yu,Liang Ma,Chen Ma,Jingyu Liu,Tulay Adali,Vince D. Calhoun*

Main category: stat.ME

Relevance: 35.0

TL;DR: 提出DDICA（深度确定性非线性独立成分分析），一种基于深度神经网络的盲源分离框架，能够处理非线性混合信号并增强噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统ICA方法依赖线性混合假设，难以捕捉复杂非线性关系且在噪声环境中鲁棒性不足，需要更强大的非线性盲源分离方法。

Method: 使用基于矩阵的熵函数直接优化独立性准则，通过随机梯度下降训练，无需变分近似或对抗方案，简化训练过程。

Result: 在模拟信号混合、高光谱图像解混、初级视觉感受野建模和静息态fMRI数据分析等多种应用中，DDICA能有效分离独立成分，具有高准确性和鲁棒性。

Conclusion: DDICA为各种信号处理任务中的盲源分离提供了鲁棒且通用的解决方案，特别适用于非线性混合和噪声环境。

Abstract: Blind source separation, particularly through independent component analysis (ICA), is widely utilized across various signal processing domains for disentangling underlying components from observed mixed signals, owing to its fully data-driven nature that minimizes reliance on prior assumptions. However, conventional ICA methods rely on an assumption of linear mixing, limiting their ability to capture complex nonlinear relationships and to maintain robustness in noisy environments. In this work, we present deep deterministic nonlinear independent component analysis (DDICA), a novel deep neural network-based framework designed to address these limitations. DDICA leverages a matrix-based entropy function to directly optimize the independence criterion via stochastic gradient descent, bypassing the need for variational approximations or adversarial schemes. This results in a streamlined training process and improved resilience to noise. We validated the effectiveness and generalizability of DDICA across a range of applications, including simulated signal mixtures, hyperspectral image unmixing, modeling of primary visual receptive fields, and resting-state functional magnetic resonance imaging (fMRI) data analysis. Experimental results demonstrate that DDICA effectively separates independent components with high accuracy across a range of applications. These findings suggest that DDICA offers a robust and versatile solution for blind source separation in diverse signal processing tasks.

</details>


### [524] [Fibonacci-Driven Recursive Ensembles: Algorithms, Convergence, and Learning Dynamics](https://arxiv.org/abs/2601.01055)
*Ernest Fokoué*

Main category: stat.ML

Relevance: 35.0

TL;DR: 该论文提出了基于斐波那契型更新流的递归集成学习算法与动力学基础，相比传统boosting的一阶加法更新，研究二阶递归架构，每个预测器依赖于前两个预测器，形成具有记忆的学习动态。


<details>
  <summary>Details</summary>
Motivation: 传统集成学习方法如boosting使用一阶加法更新，缺乏记忆机制。论文旨在开发具有递归结构的集成学习框架，通过斐波那契型更新流使集成能够整合历史结构同时适应新残差信息，提升学习动态的表达能力。

Method: 提出递归权重更新算法族，涵盖斐波那契、三波那契及高阶递归，建立连续时间极限得到控制集成演化的微分方程系统。使用核岭回归、样条平滑器和随机傅里叶特征模型进行实验验证。

Result: 建立了全局收敛条件、谱稳定性准则和非渐近泛化边界，证明递归流在近似和泛化方面持续优于静态加权方法。实验验证了递归流在多种模型上的性能提升。

Conclusion: 该理论统一了递归集成、结构化加权和统计学习中的动力系统视角，完成了从斐波那契加权、几何加权理论到完全动态递归集成学习系统的三部曲。

Abstract: This paper develops the algorithmic and dynamical foundations of recursive ensemble learning driven by Fibonacci-type update flows. In contrast with classical boosting  Freund and Schapire (1997); Friedman (2001), where the ensemble evolves through first-order additive updates, we study second-order recursive architectures in which each predictor depends on its two immediate predecessors. These Fibonacci flows induce a learning dynamic with memory, allowing ensembles to integrate past structure while adapting to new residual information. We introduce a general family of recursive weight-update algorithms encompassing Fibonacci, tribonacci, and higher-order recursions, together with continuous-time limits that yield systems of differential equations governing ensemble evolution. We establish global convergence conditions, spectral stability criteria, and non-asymptotic generalization bounds under Rademacher Bartlett and Mendelson (2002) and algorithmic stability analyses. The resulting theory unifies recursive ensembles, structured weighting, and dynamical systems viewpoints in statistical learning. Experiments with kernel ridge regression Rasmussen and Williams (2006), spline smoothers Wahba (1990), and random Fourier feature models Rahimi and Recht (2007) demonstrate that recursive flows consistently improve approximation and generalization beyond static weighting. These results complete the trilogy begun in Papers I and II: from Fibonacci weighting, through geometric weighting theory, to fully dynamical recursive ensemble learning systems.

</details>


### [525] [Neural Networks on Symmetric Spaces of Noncompact Type](https://arxiv.org/abs/2601.01097)
*Xuan Son Nguyen,Shuo Yang,Aymeric Histace*

Main category: stat.ML

Relevance: 35.0

TL;DR: 提出了一种在非紧型对称空间上构建神经网络的新方法，通过统一公式计算点到超平面距离，并基于此设计全连接层和注意力机制，在多个任务上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究展示了神经网络在双曲空间和SPD流形等非紧型对称空间上的潜力，但缺乏统一的框架。本文旨在为这类空间开发通用的神经网络构建方法。

Method: 提出统一的点到超平面距离公式，推导出高秩非紧型对称空间上G不变黎曼度量下的闭式表达式，基于此设计全连接层和注意力机制。

Result: 在图像分类、EEG信号分类、图像生成和自然语言推理等挑战性基准测试中验证了方法的有效性，展示了优于现有方法的性能。

Conclusion: 提出的统一框架为在非紧型对称空间上构建神经网络提供了有效工具，扩展了神经网络在非欧几里得空间的应用范围。

Abstract: Recent works have demonstrated promising performances of neural networks on hyperbolic spaces and symmetric positive definite (SPD) manifolds. These spaces belong to a family of Riemannian manifolds referred to as symmetric spaces of noncompact type. In this paper, we propose a novel approach for developing neural networks on such spaces. Our approach relies on a unified formulation of the distance from a point to a hyperplane on the considered spaces. We show that some existing formulations of the point-to-hyperplane distance can be recovered by our approach under specific settings. Furthermore, we derive a closed-form expression for the point-to-hyperplane distance in higher-rank symmetric spaces of noncompact type equipped with G-invariant Riemannian metrics. The derived distance then serves as a tool to design fully-connected (FC) layers and an attention mechanism for neural networks on the considered spaces. Our approach is validated on challenging benchmarks for image classification, electroencephalogram (EEG) signal classification, image generation, and natural language inference.

</details>


### [526] [Conformal Blindness: A Note on $A$-Cryptic change-points](https://arxiv.org/abs/2601.01147)
*Johan Hallberg Szabadváry*

Main category: stat.ML

Relevance: 35.0

TL;DR: 论文研究了Conformal Test Martingales（CTMs）在检测数据可交换性假设时的局限性，提出了"conformal blindness"现象，即即使存在显著的可交换性破坏，p值序列仍可能保持均匀分布，导致CTMs无法检测到变化。


<details>
  <summary>Details</summary>
Motivation: CTMs是Conformal Prediction框架中用于测试数据可交换性假设的标准方法，通过监控p值序列的均匀性来检测偏差。然而，可交换性意味着均匀p值，但反之不成立。这引发了一个关键问题：是否存在显著的可交换性破坏，但p值仍保持均匀，使得CTMs无法检测？

Method: 通过理论构造证明"conformal blindness"现象的存在。对于理论理想的"oracle"一致性度量（由真实条件密度给出），证明了存在A-cryptic change-point的可能性。使用二元高斯分布，识别出一条边际均值变化但不改变一致性得分分布的直线，从而产生完美的均匀p值。

Result: 模拟实验证实，即使存在大规模分布偏移，CTMs也可能完全无法检测，突显了该方法的根本局限性。一致性度量与潜在偏移的对齐至关重要。

Conclusion: 论文揭示了CTMs在检测可交换性破坏时的基本限制，强调了选择与潜在分布变化对齐的一致性度量的重要性。这为Conformal Prediction框架的实际应用提供了重要警示。

Abstract: Conformal Test Martingales (CTMs) are a standard method within the Conformal Prediction framework for testing the crucial assumption of data exchangeability by monitoring deviations from uniformity in the p-value sequence. Although exchangeability implies uniform p-values, the converse does not hold. This raises the question of whether a significant break in exchangeability can occur, such that the p-values remain uniform, rendering CTMs blind. We answer this affirmatively, demonstrating the phenomenon of \emph{conformal blindness}.
  Through explicit construction, for the theoretically ideal ``oracle'' conformity measure (given by the true conditional density), we demonstrate the possibility of an \emph{$A$-cryptic change-point} (where $A$ refers to the conformity measure). Using bivariate Gaussian distributions, we identify a line along which a change in the marginal means does not alter the distribution of the conformity scores, thereby producing perfectly uniform p-values.
  Simulations confirm that even a massive distribution shift can be perfectly cryptic to the CTM, highlighting a fundamental limitation and emphasising the critical role of the alignment of the conformity measure with potential shifts.

</details>


### [527] [Evidence Slopes and Effective Dimension in Singular Linear Models](https://arxiv.org/abs/2601.01238)
*Kalyaan Rao*

Main category: stat.ML

Relevance: 35.0

TL;DR: 论文研究了贝叶斯模型选择中Laplace近似和BIC在奇异模型中的失效问题，提出使用实对数典范阈值(RLCT)作为有效维度，在线性高斯秩模型和线性子空间模型中进行了理论分析和实证验证。


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯模型选择方法（Laplace近似和BIC）假设有效模型维度等于参数数量，但在过参数化或秩不足的奇异模型中这一假设不成立。需要更准确的有效维度度量来改进模型选择。

Method: 在线性高斯秩模型和线性子空间（字典）模型中，利用精确边际似然闭式解和可解析处理的RLCT，理论分析Laplace/BIC误差随样本量的增长行为，提出RLCT感知的修正方法。

Result: 理论证明Laplace/BIC误差随(d/2 - λ)log n线性增长（d为环境参数维度，λ为RLCT）。RLCT感知修正能恢复正确的证据斜率，且对表示相同数据子空间的过完备重参数化保持不变。

Conclusion: 研究为奇异模型中Laplace失效提供了具体的有限样本特征，表明证据斜率在简单线性设置中可作为有效维度的实用估计器，为奇异学习理论提供了实证支持。

Abstract: Bayesian model selection commonly relies on Laplace approximation or the Bayesian Information Criterion (BIC), which assume that the effective model dimension equals the number of parameters. Singular learning theory replaces this assumption with the real log canonical threshold (RLCT), an effective dimension that can be strictly smaller in overparameterized or rank-deficient models.
  We study linear-Gaussian rank models and linear subspace (dictionary) models in which the exact marginal likelihood is available in closed form and the RLCT is analytically tractable. In this setting, we show theoretically and empirically that the error of Laplace/BIC grows linearly with (d/2 minus lambda) times log n, where d is the ambient parameter dimension and lambda is the RLCT. An RLCT-aware correction recovers the correct evidence slope and is invariant to overcomplete reparameterizations that represent the same data subspace.
  Our results provide a concrete finite-sample characterization of Laplace failure in singular models and demonstrate that evidence slopes can be used as a practical estimator of effective dimension in simple linear settings.

</details>


### [528] [Stochastic Control Methods for Optimization](https://arxiv.org/abs/2601.01248)
*Jinniao Qiu*

Main category: math.OC

Relevance: 35.0

TL;DR: 该论文提出了一个随机控制框架，用于在欧几里得空间和Wasserstein概率测度空间上进行全局优化。通过正则化随机控制问题近似原最小化问题，利用动态规划、Cole-Hopf变换和Feynman-Kac公式获得可处理的表示，并建立了收敛到全局最优的理论保证。


<details>
  <summary>Details</summary>
Motivation: 解决传统优化方法在非凸优化问题中容易陷入局部最优的局限性，特别是在高维空间和概率测度空间上的全局优化挑战。通过随机控制框架提供一种新的全局优化方法，能够处理复杂的优化场景。

Method: 1) 在欧几里得空间：将原最小化问题近似为一系列正则化随机控制问题，使用动态规划分析Hamilton-Jacobi-Bellman方程，通过Cole-Hopf变换和Feynman-Kac公式获得概率表示；2) 在概率测度空间：提出正则化平均场控制问题，通过控制N粒子系统近似，建立收敛理论；3) 基于概率表示设计蒙特卡洛数值方案。

Result: 理论证明了当正则化参数趋于零时（对于概率测度优化，粒子数趋于无穷时），控制问题的值收敛到原目标的全局最小值。数值实验验证了方法的实际性能，并支持理论收敛率。

Conclusion: 该随机控制框架为欧几里得空间和Wasserstein空间上的全局优化提供了统一的理论和计算方法，具有理论收敛保证和实际可行性，为解决复杂优化问题提供了新途径。

Abstract: In this work, we investigate a stochastic control framework for global optimization over both finite-dimensional Euclidean spaces and the Wasserstein space of probability measures. In the Euclidean setting, the original minimization problem is approximated by a family of regularized stochastic control problems; using dynamic programming, we analyze the associated Hamilton--Jacobi--Bellman equations and obtain tractable representations via the Cole--Hopf transform and the Feynman--Kac formula. For optimization over probability measures, we formulate a regularized mean-field control problem characterized by a master equation, and further approximate it by controlled $N$-particle systems. We establish that, as the regularization parameter tends to zero (and as the particle number tends to infinity for the optimization over probability measures), the value of the control problem converges to the global minimum of the original objective. Building on the resulting probabilistic representations, Monte Carlo-based numerical schemes are proposed and numerical experiments are reported to illustrate the practical performance of the methods and to support the theoretical convergence rates.

</details>


### [529] [Concave Certificates: Geometric Framework for Distributionally Robust Risk and Complexity Analysis](https://arxiv.org/abs/2601.01311)
*Hong T. M. Chu*

Main category: math.OC

Relevance: 35.0

TL;DR: 本文提出了一种基于增长速率函数最小凹包络的几何框架，用于建立分布鲁棒优化的紧致风险边界，适用于非Lipschitz和非可微损失函数，并应用于神经网络复杂性分析。


<details>
  <summary>Details</summary>
Motivation: 当前分布鲁棒优化认证方法存在局限性：全局Lipschitz边界通常过于保守，而局部梯度信息仅提供一阶近似。需要一种更精确且适用于非Lipschitz和非可微损失函数的认证框架。

Method: 提出基于增长速率函数最小凹包络的几何框架，建立凹认证方法；扩展至复杂性分析，引入确定性边界；提出对抗分数作为凹认证的可计算松弛，支持神经网络层间分析。

Result: 理论证明凹认证提供紧致的DR风险边界；确定性边界补充统计泛化边界；消除对抗性与经验Rademacher复杂性间隙对输入直径、网络宽度和深度的依赖；实验验证在分类和回归任务上的有效性。

Conclusion: 提出的几何框架为分布鲁棒优化提供了更精确的认证方法，特别适用于非Lipschitz和非可微损失函数，在神经网络复杂性分析中展现出优势，具有理论和实用价值。

Abstract: Distributionally Robust (DR) optimization aims to certify worst-case risk within a Wasserstein uncertainty set. Current certifications typically rely either on global Lipschitz bounds, which are often conservative, or on local gradient information, which provides only a first-order approximation. This paper introduces a novel geometric framework based on the least concave majorants of the growth rate function. Our proposed concave certificate establishes a tight bound of DR risk that remains applicable to non-Lipschitz and non-differentiable losses. We extend this framework to complexity analysis, introducing a deterministic bound that complements standard statistical generalization bound. Furthermore, we utilize this certificate to bound the gap between adversarial and empirical Rademacher complexity, demonstrating that dependencies on input diameter, network width, and depth can be eliminated. For practical application in deep learning, we introduce the adversarial score as a tractable relaxation of the concave certificate that enables efficient and layer-wise analysis of neural networks. We validate our theoretical results in various numerical experiments on classification and regression tasks on real-world data.

</details>


### [530] [SGD with Dependent Data: Optimal Estimation, Regret, and Inference](https://arxiv.org/abs/2601.01371)
*Yinan Shen,Yichen Zhang,Wen-Xin Zhou*

Main category: math.ST

Relevance: 35.0

TL;DR: 该论文研究了在时间相关数据下随机梯度下降（SGD）最终迭代的性能，考虑了鞅型依赖和顺序决策诱导的依赖，证明SGD能同时实现统计最优的估计误差和遗憾，避免了估计-遗憾权衡。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注独立同分布数据下的SGD性能，但在实际应用中数据往往具有时间依赖性（如时间序列、在线决策）。先前工作声称存在估计误差与遗憾之间的权衡，本文旨在证明这种权衡可以避免，并扩展SGD理论到更一般的依赖结构。

Method: 1) 考虑两种依赖来源：鞅型依赖（协变量和噪声过程）和顺序决策诱导的依赖；2) 分析SGD在广泛步长调度和探索率方案下的性能；3) 提出"锥形"决策区域近似以处理无界支持协变量；4) 针对在线稀疏回归开发基于SGD的算法，仅需d存储单元和O(d)每迭代浮点运算。

Result: 1) 非渐近分析：SGD同时实现统计最优的估计误差和遗憾，尾部界限在无限时间范围T=+∞时仍保持锐利；2) 渐近分析：SGD迭代以O_P(1/√t)余项收敛到高斯分布；3) 在线稀疏回归算法：实现长期统计最优性，每个新观测贡献于估计精度，聚合统计量指导支持恢复。

Conclusion: SGD能自动适应独立和依赖信息，在时间相关数据下同时实现最优估计和遗憾性能，避免了先前工作声称的权衡。提出的锥形近似和在线稀疏回归算法扩展了SGD在依赖数据下的应用范围。

Abstract: This work investigates the performance of the final iterate produced by stochastic gradient descent (SGD) under temporally dependent data. We consider two complementary sources of dependence: $(i)$ martingale-type dependence in both the covariate and noise processes, which accommodates non-stationary and non-mixing time series data, and $(ii)$ dependence induced by sequential decision making. Our formulation runs in parallel with classical notions of (local) stationarity and strong mixing, while neither framework fully subsumes the other. Remarkably, SGD is shown to automatically accommodate both independent and dependent information under a broad class of stepsize schedules and exploration rate schemes.
  Non-asymptotically, we show that SGD simultaneously achieves statistically optimal estimation error and regret, extending and improving existing results. In particular, our tail bounds remain sharp even for potentially infinite horizon $T=+\infty$. Asymptotically, the SGD iterates converge to a Gaussian distribution with only an $O_{\PP}(1/\sqrt{t})$ remainder, demonstrating that the supposed estimation-regret trade-off claimed in prior work can in fact be avoided. We further propose a new ``conic'' approximation of the decision region that allows the covariates to have unbounded support. For online sparse regression, we develop a new SGD-based algorithm that uses only $d$ units of storage and requires $O(d)$ flops per iteration, achieving the long term statistical optimality. Intuitively, each incoming observation contributes to estimation accuracy, while aggregated summary statistics guide support recovery.

</details>


### [531] [Modeling Information Blackouts in Missing Not-At-Random Time Series Data](https://arxiv.org/abs/2601.01480)
*Aman Sunesh,Allan Ma,Siddarth Nilol*

Main category: stat.ML

Relevance: 35.0

TL;DR: 提出一个潜在状态空间框架，联合建模交通动态和传感器丢失，使用扩展卡尔曼滤波进行推理，通过近似EM算法学习参数，在真实数据上显著改善黑屏插补性能。


<details>
  <summary>Details</summary>
Motivation: 大规模交通预测依赖于固定传感器网络，这些网络经常出现黑屏（连续缺失测量）。现有方法通常假设缺失是随机的，但实际上黑屏事件可能与未观测到的交通状况相关，需要非随机缺失建模。

Method: 提出潜在状态空间框架：1) 使用线性动态系统建模交通动态；2) 使用伯努利观测通道建模传感器丢失，其概率依赖于潜在交通状态。推理使用扩展卡尔曼滤波与Rauch-Tung-Striebel平滑，参数通过近似EM算法学习，包含检测器特定缺失参数的专用更新。

Result: 在西雅图感应线圈检测器数据上，引入潜在动态显著优于基线方法：黑屏插补RMSE从7.02（LOCF）和5.02（线性插值+季节朴素）降低到4.23（MAR LDS），相当于MSE相对LOCF减少约64%。显式MNAR建模提供一致但较小的额外改进（插补RMSE 4.20；相对MAR减少0.8%RMSE）。在合成实验中，当缺失对潜在状态的依赖性增强时，MNAR优势增加。

Conclusion: 时间动态主导性能，而MNAR建模提供了一个原则性的改进，当缺失确实具有信息性时变得最有价值。该方法为交通预测中的传感器黑屏问题提供了有效的解决方案。

Abstract: Large-scale traffic forecasting relies on fixed sensor networks that often exhibit blackouts: contiguous intervals of missing measurements caused by detector or communication failures. These outages are typically handled under a Missing At Random (MAR) assumption, even though blackout events may correlate with unobserved traffic conditions (e.g., congestion or anomalous flow), motivating a Missing Not At Random (MNAR) treatment. We propose a latent state-space framework that jointly models (i) traffic dynamics via a linear dynamical system and (ii) sensor dropout via a Bernoulli observation channel whose probability depends on the latent traffic state. Inference uses an Extended Kalman Filter with Rauch-Tung-Striebel smoothing, and parameters are learned via an approximate EM procedure with a dedicated update for detector-specific missingness parameters. On the Seattle inductive loop detector data, introducing latent dynamics yields large gains over naive baselines, reducing blackout imputation RMSE from 7.02 (LOCF) and 5.02 (linear interpolation + seasonal naive) to 4.23 (MAR LDS), corresponding to about a 64% reduction in MSE relative to LOCF. Explicit MNAR modeling provides a consistent but smaller additional improvement on real data (imputation RMSE 4.20; 0.8% RMSE reduction relative to MAR), with similar modest gains for short-horizon post-blackout forecasts (evaluated at 1, 3, and 6 steps). In controlled synthetic experiments, the MNAR advantage increases as the true missingness dependence on latent state strengthens. Overall, temporal dynamics dominate performance, while MNAR modeling offers a principled refinement that becomes most valuable when missingness is genuinely informative.

</details>


### [532] [Learning Relationship between Quantum Walks and Underdamped Langevin Dynamics](https://arxiv.org/abs/2601.01589)
*Yazhen Wang*

Main category: quant-ph

Relevance: 35.0

TL;DR: 该论文研究了量子计算中的量子行走搜索算法与经典计算中基于朗之万动力学的采样算法之间的学习关系，发现随机化的量子行走与欠阻尼朗之万动力学渐近等价，揭示了量子加速和经典梯度加速的内在机制。


<details>
  <summary>Details</summary>
Motivation: 研究量子计算中的量子行走搜索算法和经典计算中基于朗之万动力学的采样算法之间的学习关系，探索量子加速和经典梯度加速的内在机制，为机器学习任务提供新的理论见解。

Method: 使用Le Cam缺陷距离作为度量工具，分析随机化量子行走与欠阻尼朗之万动力学的渐近等价性，比较有随机化和无随机化量子行走的行为差异。

Result: 发现随机化的量子行走与欠阻尼朗之万动力学在Le Cam缺陷距离下渐近等价，而无随机化的量子行走由于高频振荡行为而不等价。这些结果为相关算法在机器学习任务中的计算和推断特性提供了新见解。

Conclusion: 量子行走与欠阻尼朗之万动力学之间存在深刻的学习关系，随机化是量子行走与经典动力学等价的关键因素，这为理解量子加速和经典梯度加速的内在机制提供了新视角。

Abstract: Fast computational algorithms are in constant demand, and their development has been driven by advances such as quantum speedup and classical acceleration. This paper intends to study search algorithms based on quantum walks in quantum computation and sampling algorithms based on Langevin dynamics in classical computation. On the quantum side, quantum walk-based search algorithms can achieve quadratic speedups over their classical counterparts. In classical computation, a substantial body of work has focused on gradient acceleration, with gradient-adjusted algorithms derived from underdamped Langevin dynamics providing quadratic acceleration over conventional Langevin algorithms.
  Since both search and sampling algorithms are designed to address learning tasks, we study learning relationship between coined quantum walks and underdamped Langevin dynamics. Specifically, we show that, in terms of the Le Cam deficiency distance, a quantum walk with randomization is asymptotically equivalent to underdamped Langevin dynamics, whereas the quantum walk without randomization is not asymptotically equivalent due to its high-frequency oscillatory behavior. We further discuss the implications of these equivalence and nonequivalence results for the computational and inferential properties of the associated algorithms in machine learning tasks. Our findings offer new insight into the relationship between quantum walks and underdamped Langevin dynamics, as well as the intrinsic mechanisms underlying quantum speedup and classical gradient acceleration.

</details>


### [533] [Latent Space Element Method](https://arxiv.org/abs/2601.01741)
*Seung Whan Chung,Youngsoo Choi,Christopher Miller,H. Keo Springer,Kyle T. Sullivan*

Main category: math.DS

Relevance: 35.0

TL;DR: LSEM提出了一种基于潜在空间的元素组装方法，通过训练局部子域模型并耦合形成更大计算域，实现PDE求解器的可扩展性


<details>
  <summary>Details</summary>
Motivation: 如何构建能够在小型域上训练但能扩展到大型域的代理求解器，而不需要直接访问PDE算子？受数据驱动有限元方法启发，希望开发模块化的数据驱动求解器。

Method: 提出潜在空间元素方法(LSEM)：1) 在局部补丁上训练LaSDI潜在ODE代理作为元素模型；2) 通过学习的定向交互项在潜在空间中耦合相邻元素；3) 使用平滑窗口混合从重叠元素预测重建全局场。

Result: 在1D Burgers和Korteweg-de Vries方程上的实验表明，LSEM在扩展到比训练时更大的空间域时仍能保持预测准确性。

Conclusion: LSEM为构建基于可重用局部模型的基础模型代理求解器提供了一条可解释且可扩展的路径。

Abstract: How can we build surrogate solvers that train on small domains but scale to larger ones without intrusive access to PDE operators? Inspired by the Data-Driven Finite Element Method (DD-FEM) framework for modular data-driven solvers, we propose the Latent Space Element Method (LSEM), an element-based latent surrogate assembly approach in which a learned subdomain ("element") model can be tiled and coupled to form a larger computational domain. Each element is a LaSDI latent ODE surrogate trained from snapshots on a local patch, and neighboring elements are coupled through learned directional interaction terms in latent space, avoiding Schwarz iterations and interface residual evaluations. A smooth window-based blending reconstructs a global field from overlapping element predictions, yielding a scalable assembled latent dynamical system. Experiments on the 1D Burgers and Korteweg-de Vries equations show that LSEM maintains predictive accuracy while scaling to spatial domains larger than those seen in training. LSEM offers an interpretable and extensible route toward foundation-model surrogate solvers built from reusable local models.

</details>


### [534] [Machine learning modularity](https://arxiv.org/abs/2601.01779)
*Yi Fan,Vishnu Jejjala,Yang Lei*

Main category: hep-th

Relevance: 35.0

TL;DR: 基于Transformer的序列到序列架构结合动态批处理算法，提出机器学习框架自动简化涉及多个椭圆Gamma函数的复杂表达式，包括q-θ函数和椭圆Gamma函数。


<details>
  <summary>Details</summary>
Motivation: 量子场论和弦理论中的特殊函数计算需要处理复杂的椭圆Gamma函数表达式，这些表达式涉及SL(2,ℤ)和SL(3,ℤ)模变换等代数恒等式。传统的手动简化方法繁琐且容易出错，需要自动化工具来高效处理这些数学表达式。

Method: 采用基于Transformer的序列到序列架构，结合动态批处理算法。模型学习应用代数恒等式，特别是SL(2,ℤ)和SL(3,ℤ)模变换，将高度混乱的表达式简化为规范形式。

Result: 模型在分布内测试中达到超过99%的准确率，在显著外推（如更深度的混乱深度）下保持稳健性能（超过90%准确率）。这表明模型已经内化了模变换的底层代数规则，而不仅仅是记忆训练模式。

Conclusion: 这是机器学习首次成功应用模恒等式进行符号简化，为量子场论和弦理论中的特殊函数计算提供了新的自动化工具。模型展示了学习底层代数规则而不仅仅是模式匹配的能力。

Abstract: Based on a transformer based sequence-to-sequence architecture combined with a dynamic batching algorithm, this work introduces a machine learning framework for automatically simplifying complex expressions involving multiple elliptic Gamma functions, including the $q$-$θ$ function and the elliptic Gamma function. The model learns to apply algebraic identities, particularly the SL$(2,\mathbb{Z})$ and SL$(3,\mathbb{Z})$ modular transformations, to reduce heavily scrambled expressions to their canonical forms. Experimental results show that the model achieves over 99\% accuracy on in-distribution tests and maintains robust performance (exceeding 90\% accuracy) under significant extrapolation, such as with deeper scrambling depths. This demonstrates that the model has internalized the underlying algebraic rules of modular transformations rather than merely memorizing training patterns. Our work presents the first successful application of machine learning to perform symbolic simplification using modular identities, offering a new automated tool for computations with special functions in quantum field theory and the string theory.

</details>


### [535] [Feature-based Inversion of 2.5D Controlled Source Electromagnetic Data using Generative Priors](https://arxiv.org/abs/2601.02145)
*Hongyu Zhou,Haoran Sun,Rui Guo,Maokun Li,Fan Yang,Shenheng Xu*

Main category: physics.geo-ph

Relevance: 35.0

TL;DR: 该论文提出了一种基于生成先验的特征驱动2.5D海洋可控源电磁数据反演方法，使用变分自编码器学习电导率分布的先验信息，结合高斯牛顿法进行迭代反演。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络反演方法通常以黑盒方式近似整个反演映射，缺乏对数据拟合的显式控制和灵活性。作者希望开发一种能结合先验知识、保持数据拟合可控性，并能适应不同测量配置的反演框架。

Method: 采用即插即用策略：1) 使用变分自编码器学习电导率分布的生成先验；2) 基于有限差分法进行2.5D正演模拟；3) 使用高斯牛顿法迭代更新电导率模型；4) 通过投影到学习的VAE解码器来约束模型空间。

Result: 数值和现场实验表明，该方法能有效融入先验信息，提高重建精度，并展现出良好的泛化性能。框架保持了对数据拟合的显式控制，并能灵活适应不同测量配置。

Conclusion: 该方法成功地将生成先验与物理驱动的反演过程相结合，在保持传统反演方法优点的同时，通过深度学习增强了先验建模能力，为地球物理反演提供了一种有前景的混合方法。

Abstract: In this study, we investigate feature-based 2.5D controlled source marine electromagnetic (mCSEM) data inversion using generative priors. Two-and-half dimensional modeling using finite difference method (FDM) is adopted to compute the response of horizontal electric dipole (HED) excitation. Rather than using a neural network to approximate the entire inverse mapping in a black-box manner, we adopt a plug-andplay strategy in which a variational autoencoder (VAE) is used solely to learn prior information on conductivity distributions. During the inversion process, the conductivity model is iteratively updated using the Gauss Newton method, while the model space is constrained by projections onto the learned VAE decoder. This framework preserves explicit control over data misfit and enables flexible adaptation to different survey configurations. Numerical and field experiments demonstrate that the proposed approach effectively incorporates prior information, improves reconstruction accuracy, and exhibits good generalization performance.

</details>


### [536] [Latent-Constrained Conditional VAEs for Augmenting Large-Scale Climate Ensembles](https://arxiv.org/abs/2601.00915)
*Jacquelyn Shelton,Przemyslaw Polewski,Alexander Robel,Matthew Hoffman,Stephen Price*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出LC-CVAE方法，通过强制潜在空间在共享"锚点"位置的一致性，解决多气候模型集成生成中的潜在空间碎片化问题，实现从有限运行中生成统计一致的气候变量新实现。


<details>
  <summary>Details</summary>
Motivation: 大规模气候模型集成计算成本高昂，但许多下游分析需要更多统计一致的气候变量实现。现有方法在跨集成训练时会出现潜在空间碎片化问题，无法泛化到未见过的集成成员。

Method: 提出潜在约束条件变分自编码器(LC-CVAE)，在少量共享地理"锚点"位置强制跨实现潜在嵌入的同质性。然后使用多输出高斯过程回归在潜在空间中预测新实现中未采样位置的潜在坐标，最后解码生成完整时间序列场。

Result: 实验表明：(1)在单个实现上训练不稳定；(2)纳入约5个实现后收益递减；(3)空间覆盖与重建质量之间存在权衡，这与潜在空间中的平均邻居距离密切相关。

Conclusion: LC-CVAE方法有效解决了跨气候模型集成生成中的潜在空间碎片化问题，能够从有限运行中生成统计一致的新实现，为气候建模提供了高效的数据增强方法。

Abstract: Large climate-model ensembles are computationally expensive; yet many downstream analyses would benefit from additional, statistically consistent realizations of spatiotemporal climate variables. We study a generative modeling approach for producing new realizations from a limited set of available runs by transferring structure learned across an ensemble. Using monthly near-surface temperature time series from ten independent reanalysis realizations (ERA5), we find that a vanilla conditional variational autoencoder (CVAE) trained jointly across realizations yields a fragmented latent space that fails to generalize to unseen ensemble members. To address this, we introduce a latent-constrained CVAE (LC-CVAE) that enforces cross-realization homogeneity of latent embeddings at a small set of shared geographic 'anchor' locations. We then use multi-output Gaussian process regression in the latent space to predict latent coordinates at unsampled locations in a new realization, followed by decoding to generate full time series fields. Experiments and ablations demonstrate (i) instability when training on a single realization, (ii) diminishing returns after incorporating roughly five realizations, and (iii) a trade-off between spatial coverage and reconstruction quality that is closely linked to the average neighbor distance in latent space.

</details>


### [537] [Wireless Dataset Similarity: Measuring Distances in Supervised and Unsupervised Machine Learning](https://arxiv.org/abs/2601.01023)
*João Morais,Sadjad Alikhani,Akshay Malhotra,Shahab Hamidi-Rad,Ahmed Alkhateeb*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出一个任务和模型感知的无线数据集相似性度量框架，用于预测跨数据集可迁移性，支持数据集选择、仿真到真实迁移等应用


<details>
  <summary>Details</summary>
Motivation: 无线通信领域缺乏系统化的数据集相似性度量方法，难以预测模型在不同数据集间的可迁移性，影响数据集选择、仿真到真实迁移、合成数据生成等关键应用

Method: 提出任务和模型感知的框架，使用UMAP嵌入结合Wasserstein和欧氏距离度量数据集相似性；对于监督任务，集成监督UMAP和数据集不平衡惩罚

Result: 在无监督CSI压缩任务中，Pearson相关系数超过0.85；在监督波束预测任务中，提出的距离度量优于传统基线，与模型可迁移性有更强相关性

Conclusion: 提出的任务和模型感知框架能够有效度量无线数据集相似性，准确预测模型跨数据集可迁移性，支持无线通信领域的多种实际应用

Abstract: This paper introduces a task- and model-aware framework for measuring similarity between wireless datasets, enabling applications such as dataset selection/augmentation, simulation-to-real (sim2real) comparison, task-specific synthetic data generation, and informing decisions on model training/adaptation to new deployments. We evaluate candidate dataset distance metrics by how well they predict cross-dataset transferability: if two datasets have a small distance, a model trained on one should perform well on the other. We apply the framework on an unsupervised task, channel state information (CSI) compression, using autoencoders. Using metrics based on UMAP embeddings, combined with Wasserstein and Euclidean distances, we achieve Pearson correlations exceeding 0.85 between dataset distances and train-on-one/test-on-another task performance. We also apply the framework to a supervised beam prediction in the downlink using convolutional neural networks. For this task, we derive a label-aware distance by integrating supervised UMAP and penalties for dataset imbalance. Across both tasks, the resulting distances outperform traditional baselines and consistently exhibit stronger correlations with model transferability, supporting task-relevant comparisons between wireless datasets.

</details>


### [538] [RealPDEBench: A Benchmark for Complex Physical Systems with Real-World Data](https://arxiv.org/abs/2601.01829)
*Peiyan Hu,Haodong Feng,Hongyuan Liu,Tongtong Yan,Wenhao Deng,Tianrun Gao,Rong Zheng,Haoren Zheng,Chenglei Yu,Chuanrui Wang,Kaiwen Li,Zhi-Ming Ma,Dezhi Zhou,Xingcai Lu,Dixia Fan,Tailin Wu*

Main category: cs.LG

Relevance: 30.0

TL;DR: RealPDEBench是首个整合真实世界测量数据与配对数值模拟的科学机器学习基准，包含5个数据集、3个任务、8个指标和10个基线模型，旨在解决科学ML中真实数据缺乏的问题，促进sim-to-real迁移研究。


<details>
  <summary>Details</summary>
Motivation: 当前科学机器学习模型大多在模拟数据上训练和验证，缺乏真实世界数据，这限制了科学ML的发展、评估以及sim-to-real迁移等关键任务的研究。

Method: 构建包含5个真实世界测量数据集及其配对模拟数据集的基准，定义3个任务（真实数据预测、模拟数据预测、sim-to-real迁移），设计8个评估指标（数据导向和物理导向），并评估10个代表性基线模型。

Result: 实验显示模拟数据与真实世界数据存在显著差异，但使用模拟数据进行预训练能持续提高模型的准确性和收敛速度。

Conclusion: 该基准为科学机器学习提供了真实世界数据的洞见，有助于缩小sim-to-real差距并推动模型在实际部署中的应用。

Abstract: Predicting the evolution of complex physical systems remains a central problem in science and engineering. Despite rapid progress in scientific Machine Learning (ML) models, a critical bottleneck is the lack of expensive real-world data, resulting in most current models being trained and validated on simulated data. Beyond limiting the development and evaluation of scientific ML, this gap also hinders research into essential tasks such as sim-to-real transfer. We introduce RealPDEBench, the first benchmark for scientific ML that integrates real-world measurements with paired numerical simulations. RealPDEBench consists of five datasets, three tasks, eight metrics, and ten baselines. We first present five real-world measured datasets with paired simulated datasets across different complex physical systems. We further define three tasks, which allow comparisons between real-world and simulated data, and facilitate the development of methods to bridge the two. Moreover, we design eight evaluation metrics, spanning data-oriented and physics-oriented metrics, and finally benchmark ten representative baselines, including state-of-the-art models, pretrained PDE foundation models, and a traditional method. Experiments reveal significant discrepancies between simulated and real-world data, while showing that pretraining with simulated data consistently improves both accuracy and convergence. In this work, we hope to provide insights from real-world data, advancing scientific ML toward bridging the sim-to-real gap and real-world deployment. Our benchmark, datasets, and instructions are available at https://realpdebench.github.io/.

</details>


### [539] [Efficient Cover Construction for Ball Mapper via Accelerated Range Queries](https://arxiv.org/abs/2601.01405)
*Jay-Anne Bulauan,John Rick Manzanares*

Main category: cs.CG

Relevance: 30.0

TL;DR: 本文提出两种加速Ball Mapper拓扑数据分析工具中覆盖构建的方法：使用球树数据结构进行层次几何剪枝，以及利用FAISS进行硬件感知距离计算，显著提升了大规模高维数据处理的效率。


<details>
  <summary>Details</summary>
Motivation: Ball Mapper作为拓扑数据分析的常用工具，在处理高维大数据时面临计算瓶颈——覆盖构建需要重复的范围查询来识别选定地标固定距离内的数据点。随着数据集规模和维度的增长，朴素实现变得效率低下，需要优化加速。

Method: 提出了两种互补的加速策略：1) 使用球树数据结构进行层次几何剪枝，通过空间划分减少不必要的距离计算；2) 集成Facebook AI Similarity Search (FAISS)进行硬件感知的距离计算，充分利用现代硬件优化。

Result: 实验基准测试表明，两种方法相比基线实现都带来了显著的加速效果，性能提升取决于数据集大小、维度和距离函数的选择。这些改进在不改变Ball Mapper理论框架的前提下，提高了其实际可扩展性。

Conclusion: 通过集成层次几何剪枝和硬件感知距离计算，本文成功加速了Ball Mapper的覆盖构建过程，为现代数据分析工作流中基于度量的探索性工具提供了高效实现指导。

Abstract: Ball Mapper is an widely used tool in topological data analysis for summarizing the structure of high-dimensional data through metric-based coverings and graph representations. A central computational bottleneck in Ball Mapper is the construction of the underlying cover, which requires repeated range queries to identify data points within a fixed distance of selected landmarks. As data sets grow in size and dimensionality, naive implementations of this step become increasingly inefficient.
  In this work, we study practical strategies for accelerating cover construction in Ball Mapper by improving the efficiency of range queries. We integrate two complementary approaches into the Ball Mapper pipeline: hierarchical geometric pruning using ball tree data structures, and hardware-aware distance computation using Facebook AI Similarity Search. We describe the underlying algorithms, discuss their trade-offs with respect to metric flexibility and dimensionality, and provide implementation details relevant to large-scale data analysis.
  Empirical benchmarks demonstrate that both approaches yield substantial speedups over the baseline implementation, with performance gains depending on data set size, dimensionality, and choice of distance function. These results improve the practical scalability of Ball Mapper without modifying its theoretical formulation and provide guidance for the efficient implementation of metric-based exploratory tools in modern data analysis workflows.

</details>


### [540] [ShrimpXNet: A Transfer Learning Framework for Shrimp Disease Classification with Augmented Regularization, Adversarial Training, and Explainable AI](https://arxiv.org/abs/2601.00832)
*Israk Hasan Jone,D. M. Rafiun Bin Masud,Promit Sarker,Sayed Fuad Al Labib,Nazmul Islam,Farhad Billah*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该研究提出基于深度学习的虾病自动分类方法，使用6种预训练模型在1,149张图像数据集上进行评估，ConvNeXt-Tiny取得最佳性能（96.88%准确率），并采用对抗训练和数据增强提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 虾养殖是全球重要的水产产业，但疾病爆发严重影响可持续生产。传统疾病检测方法效率低，需要自动化、及时的疾病分类系统来保障虾养殖业健康发展。

Method: 1) 使用1,149张图像构建4类虾病数据集；2) 部署6种预训练深度学习模型（ResNet50、EfficientNet、DenseNet201、MobileNet、ConvNeXt-Tiny、Xception）；3) 图像预处理包括背景去除和标准化；4) 采用FGSM对抗训练增强模型鲁棒性；5) 使用CutMix和MixUp数据增强防止过拟合；6) 应用Grad-CAM、Grad-CAM++、XGrad-CAM进行模型可解释性分析。

Result: ConvNeXt-Tiny模型表现最佳，测试集准确率达到96.88%。经过1000次迭代后，模型99%置信区间为[0.953,0.971]。对抗训练和数据增强有效提升了模型泛化能力。

Conclusion: 深度学习模型能够有效实现虾病的自动分类，ConvNeXt-Tiny架构在该任务中表现优异。结合对抗训练、数据增强和可解释性方法，为虾养殖疾病监测提供了可靠的自动化解决方案。

Abstract: Shrimp is one of the most widely consumed aquatic species globally, valued for both its nutritional content and economic importance. Shrimp farming represents a significant source of income in many regions; however, like other forms of aquaculture, it is severely impacted by disease outbreaks. These diseases pose a major challenge to sustainable shrimp production. To address this issue, automated disease classification methods can offer timely and accurate detection. This research proposes a deep learning-based approach for the automated classification of shrimp diseases. A dataset comprising 1,149 images across four disease classes was utilized. Six pretrained deep learning models, ResNet50, EfficientNet, DenseNet201, MobileNet, ConvNeXt-Tiny, and Xception were deployed and evaluated for performance. The images background was removed, followed by standardized preprocessing through the Keras image pipeline. Fast Gradient Sign Method (FGSM) was used for enhancing the model robustness through adversarial training. While advanced augmentation strategies, including CutMix and MixUp, were implemented to mitigate overfitting and improve generalization. To support interpretability, and to visualize regions of model attention, post-hoc explanation methods such as Grad-CAM, Grad-CAM++, and XGrad-CAM were applied. Exploratory results demonstrated that ConvNeXt-Tiny achieved the highest performance, attaining a 96.88% accuracy on the test dataset. After 1000 iterations, the 99% confidence interval for the model is [0.953,0.971].

</details>


### [541] [FANoS: Friction-Adaptive Nosé--Hoover Symplectic Momentum for Stiff Objectives](https://arxiv.org/abs/2601.00889)
*Nalin Dhiman*

Main category: cs.LG

Relevance: 25.0

TL;DR: FANoS是一种受物理学启发的优化器，结合了二阶动力系统、Nosé-Hoover热浴变量和辛积分器，在Rosenbrock基准测试中表现优于AdamW和SGD+momentum，但在其他问题上表现不稳定。


<details>
  <summary>Details</summary>
Motivation: 将分子动力学中的结构保持积分和热浴思想应用于优化算法设计，创造一种具有物理解释性的优化器，特别针对非凸优化中的"陡峭谷地"问题。

Method: FANoS结合三个核心组件：(1)基于二阶动力系统的动量更新，(2)使用动能反馈调节摩擦系数的Nosé-Hoover热浴变量，(3)半隐式辛积分器，可选配RMS预处理器。

Result: 在Rosenbrock-100D基准测试中，FANoS-RMS达到1.74×10⁻²，优于未裁剪的AdamW(48.50)和SGD+momentum(90.76)，但不如梯度裁剪的AdamW(1.87×10⁻³)和L-BFGS(4.4×10⁻¹⁰)。在病态凸二次问题和PINN测试中表现不稳定。

Conclusion: FANoS是现有思想的解释性综合，在某些非凸优化问题上有效，但不是现代基线的通用替代品，对超参数敏感，需要谨慎使用。

Abstract: We study a physics-inspired optimizer, \emph{FANoS} (Friction-Adaptive Nosé--Hoover Symplectic momentum), which combines (i) a momentum update written as a discretized second-order dynamical system, (ii) a Nosé--Hoover-like thermostat variable that adapts a scalar friction coefficient using kinetic-energy feedback, and (iii) a semi-implicit (symplectic-Euler) integrator, optionally with a diagonal RMS preconditioner. The method is motivated by structure-preserving integration and thermostat ideas from molecular dynamics, but is used here purely as an optimization heuristic.
  We provide the algorithm and limited theoretical observations in idealized settings. On the deterministic Rosenbrock-100D benchmark with 3000 gradient evaluations, FANoS-RMS attains a mean final objective value of $1.74\times 10^{-2}$, improving substantially over unclipped AdamW ($48.50$) and SGD+momentum ($90.76$) in this protocol. However, AdamW with gradient clipping is stronger, reaching $1.87\times 10^{-3}$, and L-BFGS reaches $\approx 4.4\times 10^{-10}$. On ill-conditioned convex quadratics and in a small PINN warm-start suite (Burgers and Allen--Cahn), the default FANoS configuration underperforms AdamW and can be unstable or high-variance.
  Overall, the evidence supports a conservative conclusion: FANoS is an interpretable synthesis of existing ideas that can help on some stiff nonconvex valleys, but it is not a generally superior replacement for modern baselines, and its behavior is sensitive to temperature-schedule and hyperparameter choices.

</details>


### [542] [Hierarchical topological clustering](https://arxiv.org/abs/2601.00892)
*Ana Carpio,Gema Duro*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出了一种分层拓扑聚类算法，适用于任意距离度量，能够识别任意形状的聚类和异常值，在图像、医疗和经济数据中展示了有效性。


<details>
  <summary>Details</summary>
Motivation: 拓扑方法能够在不假设数据结构的情况下探索数据云。现有聚类技术在处理复杂形状的聚类和异常值时存在局限，需要一种更通用的方法。

Method: 提出分层拓扑聚类算法，支持任意距离度量选择。通过构建层次结构来推断异常值和任意形状聚类的持续性。

Result: 在图像、医疗和经济数据等选定数据集上验证了算法潜力，这些数据中异常值扮演重要角色。算法能够在其他技术失败的情况下提供有意义的聚类。

Conclusion: 该拓扑聚类算法为处理复杂数据结构和异常值提供了有效工具，在多种应用场景中展现出优势。

Abstract: Topological methods have the potential of exploring data clouds without making assumptions on their the structure. Here we propose a hierarchical topological clustering algorithm that can be implemented with any distance choice. The persistence of outliers and clusters of arbitrary shape is inferred from the resulting hierarchy. We demonstrate the potential of the algorithm on selected datasets in which outliers play relevant roles, consisting of images, medical and economic data. These methods can provide meaningful clusters in situations in which other techniques fail to do so.

</details>


### [543] [Practical Geometric and Quantum Kernel Methods for Predicting Skeletal Muscle Outcomes in chronic obstructive pulmonary disease](https://arxiv.org/abs/2601.00921)
*Azadeh Alavi,Hamidreza Khalili,Stanley H. Chan,Fatemeh Kouchmeshki,Ross Vlahos*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该研究在慢性阻塞性肺疾病(COPD)的小样本临床前数据中，比较了经典基线、几何感知对称正定描述符和量子核模型，用于预测肌肉结果。量子核岭回归在肌肉重量预测上表现最佳，几何方法也有稳定提升。


<details>
  <summary>Details</summary>
Motivation: 慢性阻塞性肺疾病(COPD)常伴随骨骼肌功能障碍，这与全身和气道炎症密切相关。研究旨在从可纵向获取的微创生物标志物预测肌肉结果，为临床提供预测工具。

Method: 使用213只动物的小样本临床前数据集，比较三种方法：1)调优的经典基线模型；2)基于Stein散度的几何感知对称正定描述符；3)为低维表格数据设计的量子核模型。预测三个连续目标：胫骨前肌重量、比力和肌肉质量指数。

Result: 在肌肉重量预测中，量子核岭回归使用四个可解释输入获得最佳性能：测试RMSE为4.41 mg，R²为0.605，优于相同特征集的岭回归基线(4.70 mg, 0.553)。几何方法在仅使用生物标志物时也有稳定提升(4.55 mg vs 4.79 mg)。筛查式评估的ROC-AUC最高达0.90。

Conclusion: 几何和量子核提升方法在低数据、低特征的生物医学预测问题中能提供可测量的益处，同时保持可解释性和透明的模型选择。

Abstract: Skeletal muscle dysfunction is a clinically relevant extra-pulmonary manifestation of chronic obstructive pulmonary disease (COPD) and is closely linked to systemic and airway inflammation. This motivates predictive modelling of muscle outcomes from minimally invasive biomarkers that can be acquired longitudinally. We study a small-sample preclinical dataset comprising 213 animals across two conditions (Sham versus cigarette-smoke exposure), with blood and bronchoalveolar lavage fluid measurements and three continuous targets: tibialis anterior muscle weight (milligram: mg), specific force (millinewton: mN), and a derived muscle quality index (mN per mg). We benchmark tuned classical baselines, geometry-aware symmetric positive definite (SPD) descriptors with Stein divergence, and quantum kernel models designed for low-dimensional tabular data. In the muscle-weight setting, quantum kernel ridge regression using four interpretable inputs (blood C-reactive protein, neutrophil count, bronchoalveolar lavage cellularity, and condition) attains a test root mean squared error of 4.41 mg and coefficient of determination of 0.605, improving over a matched ridge baseline on the same feature set (4.70 mg and 0.553). Geometry-informed Stein-divergence prototype distances yield a smaller but consistent gain in the biomarker-only setting (4.55 mg versus 4.79 mg). Screening-style evaluation, obtained by thresholding the continuous outcome at 0.8 times the training Sham mean, achieves an area under the receiver operating characteristic curve (ROC-AUC) of up to 0.90 for detecting low muscle weight. These results indicate that geometric and quantum kernel lifts can provide measurable benefits in low-data, low-feature biomedical prediction problems, while preserving interpretability and transparent model selection.

</details>


### [544] [Complexity-based code embeddings](https://arxiv.org/abs/2601.00924)
*Rares Folea,Radu Iacob,Emil Slusanschi,Traian Rebedea*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该论文提出了一种通用方法，通过动态分析计算机程序在不同输入下的行为，并针对分析指标定制多个通用复杂度函数，将各种算法的源代码转换为数值嵌入。该方法基于r-Complexity，并在Codeforces平台真实代码片段构建的多标签数据集上，使用XGBoost实现了平均F1分数。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一种通用方法，能够将算法源代码转换为数值嵌入，以便进行机器学习分析。传统方法难以直接处理源代码的结构和行为特征，需要一种能够捕捉程序动态行为和复杂度特征的表征方法。

Method: 方法包括：1) 动态分析计算机程序在不同输入下的行为；2) 为分析指标定制多个通用复杂度函数；3) 基于r-Complexity构建代码嵌入；4) 使用这些嵌入训练XGBoost分类器进行多标签分类。

Result: 在Codeforces平台真实代码片段构建的多标签数据集（11个类别）上，该方法实现了平均F1分数。具体数值未在摘要中提供，但表明该方法在算法代码分类任务上有效。

Conclusion: 该研究提出了一种有效的源代码嵌入方法，能够捕捉程序的动态行为和复杂度特征，为算法代码的机器学习分析提供了新工具。该方法在真实编程竞赛代码数据集上表现出良好的分类性能。

Abstract: This paper presents a generic method for transforming the source code of various algorithms to numerical embeddings, by dynamically analysing the behaviour of computer programs against different inputs and by tailoring multiple generic complexity functions for the analysed metrics. The used algorithms embeddings are based on r-Complexity . Using the proposed code embeddings, we present an implementation of the XGBoost algorithm that achieves an average F1-score on a multi-label dataset with 11 classes, built using real-world code snippets submitted for programming competitions on the Codeforces platform.

</details>


### [545] [LOFA: Online Influence Maximization under Full-Bandit Feedback using Lazy Forward Selection](https://arxiv.org/abs/2601.00933)
*Jinyu Xu,Abhishek K. Umrawal*

Main category: cs.LG

Relevance: 25.0

TL;DR: 本文提出了一种用于在线影响力最大化问题的懒惰在线前向算法（LOFA），在完全强盗反馈设置下实现了更低的经验遗憾。


<details>
  <summary>Details</summary>
Motivation: 在线影响力最大化问题中，需要在每个时间步选择种子节点集合以最大化累积影响力，但只能观察到所选种子集的影响力反馈，没有网络结构或传播过程的额外信息。现有算法虽然利用了影响力函数的子模性，但仍有改进空间。

Method: 提出懒惰在线前向算法（LOFA），进一步利用影响力函数的子模性特性，通过懒惰更新机制减少计算开销，在完全强盗反馈模型下运行。

Result: 在真实社交网络上的实验表明，LOFA在累积遗憾和瞬时奖励方面优于现有的强盗算法，实现了更低的经验遗憾。

Conclusion: LOFA算法通过更有效地利用子模性，在在线影响力最大化问题上取得了更好的性能，为在线学习与子模优化的结合提供了新的思路。

Abstract: We study the problem of influence maximization (IM) in an online setting, where the goal is to select a subset of nodes$\unicode{x2014}$called the seed set$\unicode{x2014}$at each time step over a fixed time horizon, subject to a cardinality budget constraint, to maximize the expected cumulative influence. We operate under a full-bandit feedback model, where only the influence of the chosen seed set at each time step is observed, with no additional structural information about the network or diffusion process. It is well-established that the influence function is submodular, and existing algorithms exploit this property to achieve low regret. In this work, we leverage this property further and propose the Lazy Online Forward Algorithm (LOFA), which achieves a lower empirical regret. We conduct experiments on a real-world social network to demonstrate that LOFA achieves superior performance compared to existing bandit algorithms in terms of cumulative regret and instantaneous reward.

</details>


### [546] [Discount Model Search for Quality Diversity Optimization in High-Dimensional Measure Spaces](https://arxiv.org/abs/2601.01082)
*Bryon Tjanaka,Henry Chen,Matthew C. Fontaine,Stefanos Nikolaidis*

Main category: cs.LG

Relevance: 25.0

TL;DR: DMS（Discount Model Search）是一种新的质量多样性优化算法，使用连续折扣模型替代传统直方图，解决了高维度量空间中探索停滞问题，特别适用于图像等高维度量空间。


<details>
  <summary>Details</summary>
Motivation: 现有QD算法（如CMA-MAE）在高维度量空间中存在失真问题，相似度量的解会被分配到相同的直方图单元，导致探索停滞。需要一种能够区分相似度量、支持高维度量空间（如图像空间）的QD算法。

Method: 提出Discount Model Search（DMS），使用连续模型表示折扣值，替代传统的直方图记录。该模型提供平滑连续的折扣值表示，能够在高维度量空间中区分相似度量的解，从而持续探索。

Result: DMS在高维基准测试和图像度量空间中优于CMA-MAE和其他黑盒QD算法。特别展示了在图像度量空间的新应用，用户只需提供图像数据集而无需手动设计度量函数。

Conclusion: DMS通过连续折扣模型解决了高维度量空间中的探索停滞问题，扩展了QD算法的应用范围，特别是在图像等高维度量空间的应用。

Abstract: Quality diversity (QD) optimization searches for a collection of solutions that optimize an objective while attaining diverse outputs of a user-specified, vector-valued measure function. Contemporary QD algorithms focus on low-dimensional measures because high-dimensional measures are prone to distortion, where many solutions found by the QD algorithm map to similar measures. For example, the CMA-MAE algorithm guides measure space exploration with a histogram in measure space that records so-called discount values. However, CMA-MAE stagnates in domains with high-dimensional measure spaces because solutions with similar measures fall into the same histogram cell and thus receive identical discount values. To address these limitations, we propose Discount Model Search (DMS), which guides exploration with a model that provides a smooth, continuous representation of discount values. In high-dimensional measure spaces, this model enables DMS to distinguish between solutions with similar measures and thus continue exploration. We show that DMS facilitates new QD applications by introducing two domains where the measure space is the high-dimensional space of images, which enables users to specify their desired measures by providing a dataset of images rather than hand-designing the measure function. Results in these domains and on high-dimensional benchmarks show that DMS outperforms CMA-MAE and other black-box QD algorithms.

</details>


### [547] [Self-Training the Neurochaos Learning Algorithm](https://arxiv.org/abs/2601.01146)
*Anusree M,Akhila Henry,Pramod P Nair*

Main category: cs.LG

Relevance: 25.0

TL;DR: 本文提出了一种结合神经混沌学习与自训练的半监督学习架构，用于解决标签数据稀缺和不平衡数据集的问题，在多个基准数据集上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 在许多实际应用中，获取大量标注数据既困难又昂贵，而未标注数据则容易获得。传统的监督学习方法在标签数据稀缺或不平衡数据集场景下表现不佳。本文旨在解决这一限制。

Method: 提出了一种混合半监督学习架构，将神经混沌学习与基于阈值的自训练方法相结合。神经混沌学习将输入特征转换为混沌发放率表示，捕捉数据中的非线性关系；自训练则利用高置信度的伪标签样本来逐步扩展标注集。

Result: 在10个基准数据集和5种机器学习分类器上评估，使用85%未标注和15%标注数据进行训练。提出的NL+ST架构相比独立自训练模型获得显著性能提升，特别是在Iris（188.66%）、Wine（158.58%）和Glass Identification（110.48%）等有限、非线性和不平衡数据集上。

Conclusion: 结果表明，在低数据场景下，将基于混沌的特征提取与半监督学习结合使用，可以提高泛化能力、鲁棒性和分类准确性。

Abstract: In numerous practical applications, acquiring substantial quantities of labelled data is challenging and expensive, but unlabelled data is readily accessible. Conventional supervised learning methods frequently underperform in scenarios characterised by little labelled data or imbalanced datasets. This study introduces a hybrid semi-supervised learning (SSL) architecture that integrates Neurochaos Learning (NL) with a threshold-based Self-Training (ST) method to overcome this constraint. The NL architecture converts input characteristics into chaos-based ring-rate representations that encapsulate nonlinear relationships within the data, whereas ST progressively enlarges the labelled set utilising high-confidence pseudo-labelled samples. The model's performance is assessed using ten benchmark datasets and five machine learning classifiers, with 85% of the training data considered unlabelled and just 15% utilised as labelled data. The proposed Self-Training Neurochaos Learning (NL+ST) architecture consistently attains superior performance gain relative to standalone ST models, especially on limited, nonlinear and imbalanced datasets like Iris (188.66%), Wine (158.58%) and Glass Identification (110.48%). The results indicate that using chaos-based feature extraction with SSL improves generalisation, resilience, and classification accuracy in low-data contexts.

</details>


### [548] [Evo-TFS: Evolutionary Time-Frequency Domain-Based Synthetic Minority Oversampling Approach to Imbalanced Time Series Classification](https://arxiv.org/abs/2601.01150)
*Wenbin Pei,Ruohao Dai,Bing Xue,Mengjie Zhang,Qiang Zhang,Yiu-Ming Cheung*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出Evo-TFS进化过采样方法，结合时域和频域特征生成少数类时间序列样本，解决不平衡时间序列分类问题


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法假设数据分布平衡，在不平衡时间序列分类中会忽略少数类；传统过采样方法依赖线性插值，难以保持时间动态特性和生成多样样本

Method: 使用强类型遗传编程进化生成多样高质量时间序列，通过包含时域和频域特征的适应度函数指导进化过程

Result: 在不平衡时间序列数据集上的实验表明，Evo-TFS优于现有过采样方法，显著提升时域和频域分类器的性能

Conclusion: Evo-TFS通过结合时域和频域特征的进化过采样方法，有效解决了不平衡时间序列分类问题，生成了更高质量和多样性的少数类样本

Abstract: Time series classification is a fundamental machine learning task with broad real-world applications. Although many deep learning methods have proven effective in learning time-series data for classification, they were originally developed under the assumption of balanced data distributions. Once data distribution is uneven, these methods tend to ignore the minority class that is typically of higher practical significance. Oversampling methods have been designed to address this by generating minority-class samples, but their reliance on linear interpolation often hampers the preservation of temporal dynamics and the generation of diverse samples. Therefore, in this paper, we propose Evo-TFS, a novel evolutionary oversampling method that integrates both time- and frequency-domain characteristics. In Evo-TFS, strongly typed genetic programming is employed to evolve diverse, high-quality time series, guided by a fitness function that incorporates both time-domain and frequency-domain characteristics. Experiments conducted on imbalanced time series datasets demonstrate that Evo-TFS outperforms existing oversampling methods, significantly enhancing the performance of time-domain and frequency-domain classifiers.

</details>


### [549] [Sparse Bayesian Message Passing under Structural Uncertainty](https://arxiv.org/abs/2601.01207)
*Yoonhyuk Choi,Jiho Choi,Chanran Kim,Yumin Lee,Hawon Shin,Yeowon Jeon,Minjeong Kim,Jiwoo Kang*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该论文提出了一种处理图神经网络中异质性和结构噪声的方法，通过建模带符号邻接矩阵的后验分布，结合稀疏带符号消息传递网络，从贝叶斯角度处理图结构不确定性。


<details>
  <summary>Details</summary>
Motivation: 现实世界图中的半监督学习经常面临异质性挑战，即观察到的图不可靠或标签不匹配。现有图神经网络要么依赖固定邻接结构，要么通过正则化处理结构噪声，缺乏对结构不确定性的显式建模。

Method: 1) 建模带符号邻接矩阵的后验分布（正边、负边或无边）；2) 提出稀疏带符号消息传递网络，自然对边噪声和异质性具有鲁棒性；3) 结合后验边缘化和稀疏带符号消息聚合，提供处理边噪声和异质性的原则性方法。

Result: 实验结果表明，该方法在合成和真实世界结构噪声下的异质性基准测试中优于强基线模型。

Conclusion: 通过显式建模结构不确定性并提供贝叶斯解释，该方法为处理图神经网络中的异质性和结构噪声提供了有效的解决方案。

Abstract: Semi-supervised learning on real-world graphs is frequently challenged by heterophily, where the observed graph is unreliable or label-disassortative. Many existing graph neural networks either rely on a fixed adjacency structure or attempt to handle structural noise through regularization. In this work, we explicitly capture structural uncertainty by modeling a posterior distribution over signed adjacency matrices, allowing each edge to be positive, negative, or absent. We propose a sparse signed message passing network that is naturally robust to edge noise and heterophily, which can be interpreted from a Bayesian perspective. By combining (i) posterior marginalization over signed graph structures with (ii) sparse signed message aggregation, our approach offers a principled way to handle both edge noise and heterophily. Experimental results demonstrate that our method outperforms strong baseline models on heterophilic benchmarks under both synthetic and real-world structural noise.

</details>


### [550] [A Depth Hierarchy for Computing the Maximum in ReLU Networks via Extremal Graph Theory](https://arxiv.org/abs/2601.01417)
*Itay Safran*

Main category: cs.LG

Relevance: 25.0

TL;DR: 本文证明了ReLU神经网络计算最大值函数时存在深度层次结构：对于深度3≤k≤log₂(log₂(d))的网络，需要宽度Ω(d^{1+1/(2^{k-2}-1)})才能精确表示d个实数的最大值，这是首个针对深度≥3的最大值函数的无条件超线性下界。


<details>
  <summary>Details</summary>
Motivation: 最大值函数是神经网络中的基本算子，但对其计算复杂度的理论理解有限。现有研究主要关注浅层网络，对于深层网络能否更高效计算最大值缺乏理论分析。本文旨在探究深层ReLU网络计算最大值函数所需的最小宽度，揭示其内在计算复杂度。

Method: 采用组合论证方法，将最大值函数的不可微分脊线与计算网络第一隐藏层诱导的图中的团相关联。利用极值图论中的Turán定理，证明足够窄的网络无法捕捉最大值函数的非线性特性。通过分析网络深度与宽度的关系，建立了深度层次结构。

Result: 证明了对于深度3≤k≤log₂(log₂(d))的ReLU网络，需要宽度Ω(d^{1+1/(2^{k-2}-1)})才能精确表示d个实数的最大值函数。这是首个针对深度≥3的最大值函数的无条件超线性下界，表明即使深度随d增长，宽度仍需超线性增长。

Conclusion: 最大值函数虽然简单，但其几何结构中的不可微分超平面带来了固有的计算复杂度。该结果为深度神经网络下界证明提供了新方法，揭示了深度与宽度在计算能力上的权衡关系。

Abstract: We consider the problem of exact computation of the maximum function over $d$ real inputs using ReLU neural networks. We prove a depth hierarchy, wherein width $Ω\big(d^{1+\frac{1}{2^{k-2}-1}}\big)$ is necessary to represent the maximum for any depth $3\le k\le \log_2(\log_2(d))$. This is the first unconditional super-linear lower bound for this fundamental operator at depths $k\ge3$, and it holds even if the depth scales with $d$. Our proof technique is based on a combinatorial argument and associates the non-differentiable ridges of the maximum with cliques in a graph induced by the first hidden layer of the computing network, utilizing Turán's theorem from extremal graph theory to show that a sufficiently narrow network cannot capture the non-linearities of the maximum. This suggests that despite its simple nature, the maximum function possesses an inherent complexity that stems from the geometric structure of its non-differentiable hyperplanes, and provides a novel approach for proving lower bounds for deep neural networks.

</details>


### [551] [Accelerating Decentralized Optimization via Overlapping Local Steps](https://arxiv.org/abs/2601.01493)
*Yijie Zhou,Shi Pu*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出OLDSGD方法，通过计算-通信重叠加速去中心化训练，减少网络空闲时间，保持与Local SGD相同的平均更新，在非凸目标上证明收敛性，实验显示在通信延迟下显著减少实际训练时间。


<details>
  <summary>Details</summary>
Motivation: 去中心化优化已成为分布式学习的关键范式，能够在保护数据隐私的同时实现可扩展训练。然而，现有方法由于节点间频繁同步而存在通信瓶颈，导致训练效率低下。

Method: 提出重叠局部去中心化SGD（OLDSGD），通过精心设计的更新机制实现计算与通信的重叠，减少网络空闲时间。该方法保持与Local SGD相同的平均更新，同时避免通信引起的停滞。

Result: 理论上建立了光滑非凸目标的非渐近收敛率，证明OLDSGD保持与标准Local Decentralized SGD相同的迭代复杂度，同时改善每轮迭代的运行时间。实验结果表明在不同通信延迟水平下，OLDSGD在实际时间收敛方面持续改进。

Conclusion: OLDSGD通过对现有框架的最小修改，提供了在不牺牲理论保证的情况下加速去中心化学习的实用解决方案。

Abstract: Decentralized optimization has emerged as a critical paradigm for distributed learning, enabling scalable training while preserving data privacy through peer-to-peer collaboration. However, existing methods often suffer from communication bottlenecks due to frequent synchronization between nodes. We present Overlapping Local Decentralized SGD (OLDSGD), a novel approach to accelerate decentralized training by computation-communication overlapping, significantly reducing network idle time. With a deliberately designed update, OLDSGD preserves the same average update as Local SGD while avoiding communication-induced stalls. Theoretically, we establish non-asymptotic convergence rates for smooth non-convex objectives, showing that OLDSGD retains the same iteration complexity as standard Local Decentralized SGD while improving per-iteration runtime. Empirical results demonstrate OLDSGD's consistent improvements in wall-clock time convergence under different levels of communication delays. With minimal modifications to existing frameworks, OLDSGD offers a practical solution for faster decentralized learning without sacrificing theoretical guarantees.

</details>


### [552] [Advanced Global Wildfire Activity Modeling with Hierarchical Graph ODE](https://arxiv.org/abs/2601.01501)
*Fan Xu,Wei Gong,Hao Wu,Lilan Peng,Nan Wang,Qingsong Wen,Xian Wu,Kun Wang,Xibin Zhao*

Main category: cs.LG

Relevance: 25.0

TL;DR: HiGO：一种用于全球野火预测的多尺度连续时间动态学习框架，通过分层图ODE建模地球系统，在长期预测上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 野火作为地球系统的重要组成部分，受到大气、海洋和陆地过程在多种时空尺度上的复杂相互作用影响。虽然深度学习在天气预报方面取得了突破，但在全球野火行为预测方面的潜力尚未充分探索。

Method: 提出分层图ODE（HiGO）框架：1）将地球系统表示为多层图层次结构；2）提出自适应过滤消息传递机制用于层内和层间信息流；3）在多个层次集成GNN参数化的神经ODE模块来显式学习每个尺度的连续动态。

Result: 在SeasFire Cube数据集上的实验表明，HiGO在长期野火预测上显著优于最先进的基线方法，其连续时间预测展现出强大的观测一致性。

Conclusion: HiGO框架能够有效学习野火的多尺度连续时间动态，为全球野火行为预测提供了有前景的解决方案，具有实际应用潜力。

Abstract: Wildfires, as an integral component of the Earth system, are governed by a complex interplay of atmospheric, oceanic, and terrestrial processes spanning a vast range of spatiotemporal scales. Modeling their global activity on large timescales is therefore a critical yet challenging task. While deep learning has recently achieved significant breakthroughs in global weather forecasting, its potential for global wildfire behavior prediction remains underexplored. In this work, we reframe this problem and introduce the Hierarchical Graph ODE (HiGO), a novel framework designed to learn the multi-scale, continuous-time dynamics of wildfires. Specifically, we represent the Earth system as a multi-level graph hierarchy and propose an adaptive filtering message passing mechanism for both intra- and inter-level information flow, enabling more effective feature extraction and fusion. Furthermore, we incorporate GNN-parameterized Neural ODE modules at multiple levels to explicitly learn the continuous dynamics inherent to each scale. Through extensive experiments on the SeasFire Cube dataset, we demonstrate that HiGO significantly outperforms state-of-the-art baselines on long-range wildfire forecasting. Moreover, its continuous-time predictions exhibit strong observational consistency, highlighting its potential for real-world applications.

</details>


### [553] [Utilizing Earth Foundation Models to Enhance the Simulation Performance of Hydrological Models with AlphaEarth Embeddings](https://arxiv.org/abs/2601.01558)
*Pengfei Qu,Wenyu Ouyang,Chi Zhang,Yikai Chai,Shuolong Xu,Lei Ye,Yongri Piao,Miao Zhang,Huchuan Lu*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该研究探索使用AlphaEarth Foundation嵌入（从卫星图像学习的环境表示）替代传统流域属性，以改进无流量记录流域的径流预测，发现嵌入能更有效地捕捉流域物理差异并提高预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统流域属性无法完全描述自然环境的复杂性，导致在无流量记录流域预测径流时面临挑战。研究旨在探索从大规模卫星图像学习的环境嵌入是否能提供更有效的流域特征描述方法。

Method: 使用AlphaEarth Foundation嵌入（从卫星图像学习的环境表示）作为流域特征描述，与传统流域属性对比。研究嵌入在预测未参与训练流域径流时的表现，并分析如何基于嵌入相似性选择适当的"捐赠流域"来改进无测站区域的预测。

Result: 使用AlphaEarth Foundation嵌入的模型在预测未参与训练流域径流时获得更高精度，表明嵌入比传统属性更有效地捕捉关键物理差异。基于嵌入相似性选择相似流域能提高预测性能，而添加过多不相似流域会降低准确性。

Conclusion: 卫星信息驱动的环境表示能增强水文预测能力，支持开发更易适应不同景观的水文模型。基于嵌入的流域相似性分析有助于识别具有可比环境和水文行为的流域，改进无测站区域的预测。

Abstract: Predicting river flow in places without streamflow records is challenging because basins respond differently to climate, terrain, vegetation, and soils. Traditional basin attributes describe some of these differences, but they cannot fully represent the complexity of natural environments. This study examines whether AlphaEarth Foundation embeddings, which are learned from large collections of satellite images rather than designed by experts, offer a more informative way to describe basin characteristics. These embeddings summarize patterns in vegetation, land surface properties, and long-term environmental dynamics. We find that models using them achieve higher accuracy when predicting flows in basins not used for training, suggesting that they capture key physical differences more effectively than traditional attributes. We further investigate how selecting appropriate donor basins influences prediction in ungauged regions. Similarity based on the embeddings helps identify basins with comparable environmental and hydrological behavior, improving performance, whereas adding many dissimilar basins can reduce accuracy. The results show that satellite-informed environmental representations can strengthen hydrological forecasting and support the development of models that adapt more easily to different landscapes.

</details>


### [554] [Communication-Efficient Federated AUC Maximization with Cyclic Client Participation](https://arxiv.org/abs/2601.01649)
*Umesh Vangapally,Wenhan Wu,Chen Chen,Zhishuai Guo*

Main category: cs.LG

Relevance: 25.0

TL;DR: 本文提出了针对循环客户端参与场景的联邦AUC最大化算法，解决了联邦学习中不平衡数据学习的问题，在平方代理损失和一般成对损失下分别建立了最优的通信和迭代复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有联邦AUC最大化方法通常假设客户端完全可用，但实际联邦学习系统中客户端通常按固定循环时间表参与训练。这种循环参与模式给不可分解的AUC目标带来了独特的优化挑战，需要开发通信高效的算法。

Method: 研究了两种设置：1) 使用平方代理损失的AUC最大化，将其重构为非凸-强凹极小极大优化问题，利用Polyak-Łojasiewicz条件；2) 一般成对AUC损失。针对循环客户端参与场景，开发了通信高效的联邦优化算法。

Result: 对于平方代理损失，建立了最优的通信复杂度$\widetilde{O}(1/ε^{1/2})$和迭代复杂度$\widetilde{O}(1/ε)$；对于一般成对损失，通信复杂度为$O(1/ε^3)$，迭代复杂度为$O(1/ε^4)$，在PL条件下改进为$\widetilde{O}(1/ε^{1/2})$和$\widetilde{O}(1/ε)$。在图像分类、医学影像和欺诈检测基准任务上验证了方法的优越性。

Conclusion: 本文提出的算法有效解决了循环客户端参与下的联邦AUC最大化问题，在通信效率和收敛性能方面达到了最优的理论保证，为实际联邦学习系统中处理不平衡数据提供了实用解决方案。

Abstract: Federated AUC maximization is a powerful approach for learning from imbalanced data in federated learning (FL). However, existing methods typically assume full client availability, which is rarely practical. In real-world FL systems, clients often participate in a cyclic manner: joining training according to a fixed, repeating schedule. This setting poses unique optimization challenges for the non-decomposable AUC objective. This paper addresses these challenges by developing and analyzing communication-efficient algorithms for federated AUC maximization under cyclic client participation. We investigate two key settings: First, we study AUC maximization with a squared surrogate loss, which reformulates the problem as a nonconvex-strongly-concave minimax optimization. By leveraging the Polyak-Łojasiewicz (PL) condition, we establish a state-of-the-art communication complexity of $\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\widetilde{O}(1/ε)$. Second, we consider general pairwise AUC losses. We establish a communication complexity of $O(1/ε^3)$ and an iteration complexity of $O(1/ε^4)$. Further, under the PL condition, these bounds improve to communication complexity of $\widetilde{O}(1/ε^{1/2})$ and iteration complexity of $\widetilde{O}(1/ε)$. Extensive experiments on benchmark tasks in image classification, medical imaging, and fraud detection demonstrate the superior efficiency and effectiveness of our proposed methods.

</details>


### [555] [Distributed Federated Learning by Alternating Periods of Training](https://arxiv.org/abs/2601.01793)
*Shamik Bhattacharyya,Rachel Kalpana Kalaimani*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出分布式联邦学习框架，通过多服务器架构解决传统联邦学习中单点故障和可扩展性问题，设计交替进行本地训练和全局训练的DFL算法。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习依赖单一中央服务器，在面对大量客户端时存在可扩展性挑战和单点故障风险。需要设计更健壮、可扩展的分布式联邦学习框架。

Method: 提出分布式联邦学习框架，包含多个具有服务器间通信能力的服务器。每个服务器关联一组不相交的客户端。设计DFL算法，交替进行客户端数据的本地训练和服务器间的全局训练。

Result: 在适当参数选择下，DFL算法确保所有服务器收敛到理想模型的容差范围内，有效整合本地和全局训练模型。通过数值模拟验证理论结果。

Conclusion: 分布式联邦学习框架解决了传统联邦学习的可扩展性和容错性限制，多服务器架构提供了更健壮的解决方案，DFL算法实现了有效的模型收敛。

Abstract: Federated learning is a privacy-focused approach towards machine learning where models are trained on client devices with locally available data and aggregated at a central server. However, the dependence on a single central server is challenging in the case of a large number of clients and even poses the risk of a single point of failure. To address these critical limitations of scalability and fault-tolerance, we present a distributed approach to federated learning comprising multiple servers with inter-server communication capabilities. While providing a fully decentralized approach, the designed framework retains the core federated learning structure where each server is associated with a disjoint set of clients with server-client communication capabilities. We propose a novel DFL (Distributed Federated Learning) algorithm which uses alternating periods of local training on the client data followed by global training among servers. We show that the DFL algorithm, under a suitable choice of parameters, ensures that all the servers converge to a common model value within a small tolerance of the ideal model, thus exhibiting effective integration of local and global training models. Finally, we illustrate our theoretical claims through numerical simulations.

</details>


### [556] [High-Order Epistasis Detection Using Factorization Machine with Quadratic Optimization Annealing and MDR-Based Evaluation](https://arxiv.org/abs/2601.01860)
*Shuta Kikuchi,Shu Tanaka*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出一种基于因子分解机与二次优化退火(FMQA)的高阶上位性检测方法，将上位性检测建模为黑盒优化问题，使用MDR计算的分类错误率作为目标函数，在计算受限情况下有效识别真实的上位性相互作用。


<details>
  <summary>Details</summary>
Motivation: 遗传关联研究中高阶上位性检测面临组合爆炸的计算挑战。虽然多因子降维(MDR)是常用的上位性评估方法，但随着位点数量或相互作用阶数增加，基于MDR的穷举搜索变得计算不可行。

Method: 将上位性检测问题定义为黑盒优化问题，采用因子分解机与二次优化退火(FMQA)求解。提出基于FMQA的高效上位性检测方法，使用MDR计算的分类错误率(CER)作为黑盒目标函数。

Result: 在具有预定义高阶上位性的模拟病例对照数据集上进行实验评估，结果表明所提方法在有限迭代次数内成功识别了不同相互作用阶数和遗传位点数量的真实上位性。

Conclusion: 该方法对于高阶上位性检测是有效且计算高效的，能够解决传统MDR方法在计算复杂度上的限制。

Abstract: Detecting high-order epistasis is a fundamental challenge in genetic association studies due to the combinatorial explosion of candidate locus combinations. Although multifactor dimensionality reduction (MDR) is a widely used method for evaluating epistasis, exhaustive MDR-based searches become computationally infeasible as the number of loci or the interaction order increases. In this paper, we define the epistasis detection problem as a black-box optimization problem and solve it with a factorization machine with quadratic optimization annealing (FMQA). We propose an efficient epistasis detection method based on FMQA, in which the classification error rate (CER) computed by MDR is used as a black-box objective function. Experimental evaluations were conducted using simulated case-control datasets with predefined high-order epistasis. The results demonstrate that the proposed method successfully identified ground-truth epistasis across various interaction orders and the numbers of genetic loci within a limited number of iterations. These results indicate that the proposed method is effective and computationally efficient for high-order epistasis detection.

</details>


### [557] [Edge-aware GAT-based protein binding site prediction](https://arxiv.org/abs/2601.02138)
*Weisen Yang,Hanqing Zhang,Wangren Qiu,Xuan Xiao,Weizhong Lin*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出Edge-aware GAT模型，用于蛋白质结合位点的细粒度预测，通过原子级图结构和多维特征整合，在基准数据集上达到0.93 ROC-AUC，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统蛋白质结合位点预测方法在准确性和计算效率之间难以平衡，特别是在捕捉复杂空间构象方面存在挑战。需要开发既能保持高精度又能高效处理空间信息的预测方法。

Method: 提出Edge-aware Graph Attention Network模型：1) 构建原子级图结构；2) 整合几何描述符、DSSP二级结构和相对溶剂可及性等多维特征；3) 在注意力机制中融入原子间距离和方向向量作为边特征；4) 使用方向张量传播和残基级注意力池化。

Result: 在基准数据集上，蛋白质-蛋白质结合位点预测的ROC-AUC达到0.93，优于多个state-of-the-art方法。可视化验证了模型的实用性和可解释性，并部署了公开可访问的Web服务器。

Conclusion: 该方法为蛋白质功能位点识别提供了新颖高效的解决方案，在预测准确性、泛化能力和可解释性之间取得了良好平衡。

Abstract: Accurate identification of protein binding sites is crucial for understanding biomolecular interaction mechanisms and for the rational design of drug targets. Traditional predictive methods often struggle to balance prediction accuracy with computational efficiency when capturing complex spatial conformations. To address this challenge, we propose an Edge-aware Graph Attention Network (Edge-aware GAT) model for the fine-grained prediction of binding sites across various biomolecules, including proteins, DNA/RNA, ions, ligands, and lipids. Our method constructs atom-level graphs and integrates multidimensional structural features, including geometric descriptors, DSSP-derived secondary structure, and relative solvent accessibility (RSA), to generate spatially aware embedding vectors. By incorporating interatomic distances and directional vectors as edge features within the attention mechanism, the model significantly enhances its representation capacity. On benchmark datasets, our model achieves an ROC-AUC of 0.93 for protein-protein binding site prediction, outperforming several state-of-the-art methods. The use of directional tensor propagation and residue-level attention pooling further improves both binding site localization and the capture of local structural details. Visualizations using PyMOL confirm the model's practical utility and interpretability. To facilitate community access and application, we have deployed a publicly accessible web server at http://119.45.201.89:5000/. In summary, our approach offers a novel and efficient solution that balances prediction accuracy, generalization, and interpretability for identifying functional sites in proteins.

</details>


### [558] [Physically-Constrained Autoencoder-Assisted Bayesian Optimization for Refinement of High-Dimensional Defect-Sensitive Single Crystalline Structure](https://arxiv.org/abs/2601.00855)
*Joseph Oche Agada,Andrew McAninch,Haley Day,Yasemin Tanyu,Ewan McCombs,Seyed M. Koohpayeh,Brian H. Toby,Yishu Wang,Arpan Biswas*

Main category: cond-mat.mtrl-sci

Relevance: 25.0

TL;DR: 提出了一种结合物理约束变分自编码器(pcVAE)和贝叶斯优化(BO)的混合机器学习框架，用于加速和改进晶体结构精修，特别是缺陷解析


<details>
  <summary>Details</summary>
Motivation: 材料物理性质和功能由全局晶体结构和局部缺陷共同决定。传统Rietveld精修方法容易陷入局部最小值，且无法全面探索高维参数空间，限制了结构-性能关系的建立

Method: 使用pcVAE将高维衍射数据投影到低维潜在空间，同时保持尺度不变性和物理相关性。然后通过贝叶斯优化方法，在真实空间和潜在空间中分别最小化实验与模拟衍射图案之间的χ²误差

Result: 研究了pcVAE辅助BO、非pcVAE辅助BO和传统Rietveld精修的结果比较，展示了混合框架在晶体结构精修中的优势

Conclusion: 提出的pcVAE辅助BO框架能够系统性地加速和改进晶体结构精修，特别适用于缺陷敏感系统的高维参数空间探索

Abstract: Physical properties and functionalities of materials are dictated by global crystal structures as well as local defects. To establish a structure-property relationship, not only the crystallographic symmetry but also quantitative knowledge about defects are required. Here we present a hybrid Machine Learning framework that integrates a physically-constrained variational-autoencoder (pcVAE) with different Bayesian Optimization (BO) methods to systematically accelerate and improve crystal structure refinement with resolution of defects. We chose the pyrochlore structured Ho2Ti2O7 as a model system and employed the GSAS2 package for benchmarking crystallographic parameters from Rietveld refinement. However, the function space of these material systems is highly nonlinear, which limits optimizers like traditional Rietveld refinement, into trapping at local minima. Also, these naive methods don't provide an extensive learning about the overall function space, which is essential for large space, large time consuming explorations to identify various potential regions of interest. Thus, we present the approach of exploring the high Dimensional structure parameters of defect sensitive systems via pretrained pcVAE assisted BO and Sparse Axis Aligned BO. The pcVAE projects high-Dimensional diffraction data consisting of thousands of independently measured diffraction orders into a lowD latent space while enforcing scaling invariance and physical relevance. Then via BO methods, we aim to minimize the L2 norm based chisq errors in the real and latent spaces separately between experimental and simulated diffraction patterns, thereby steering the refinement towards potential optimum crystal structure parameters. We investigated and compared the results among different pcVAE assisted BO, non pcVAE assisted BO, and Rietveld refinement.

</details>


### [559] [Investigation into U.S. Citizen and Non-Citizen Worker Health Insurance and Employment](https://arxiv.org/abs/2601.00896)
*Annabelle Yao*

Main category: econ.GN

Relevance: 25.0

TL;DR: 该研究结合统计分析和机器学习方法（K-Modes、K-Prototypes、t-SNE、CatBoost）分析社会经济整合与不平等，识别出5个不同的人口群体，发现公民身份与劳动力参与无关，但在雇主提供的医疗保险获取方面存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 社会经济整合是社会公平的关键维度，但在医疗保险、教育和就业获取方面存在持续差异。现有研究多关注不平等的孤立方面，缺乏结合统计分析和机器学习来揭示人口数据隐藏结构的研究。

Method: 使用统计独立性检验（χ²检验和双比例Z检验）和机器学习聚类技术（K-Modes和K-Prototypes），结合t-SNE可视化和CatBoost分类分析社会经济整合与不平等。

Result: 识别出5个不同的人口群体：主要按教育程度划分（集群0和4 vs 集群1、2、3），次要按劳动力状况和出生地划分。发现公民身份与劳动力参与无关，但非公民在无福利的就业中比例过高，在雇主提供的医疗保险获取方面存在显著差异。

Conclusion: 研究揭示了面临复合劣势的人口群体，有助于更细致地理解社会经济分层。非公民在无福利的就业中比例过高，突显了医疗保健获取方面的系统性不平等。

Abstract: Socioeconomic integration is a critical dimension of social equity, yet persistent disparities remain in access to health insurance, education, and employment across different demographic groups. While previous studies have examined isolated aspects of inequality, there is limited research that integrates both statistical analysis and advanced machine learning to uncover hidden structures within population data. This study leverages statistical analysis ($χ^2$ test of independence and Two Proportion Z-Test) and machine learning clustering techniques -- K-Modes and K-Prototypes -- along with t-SNE visualization and CatBoost classification to analyze socioeconomic integration and inequality. Using statistical tests, we identified the proportion of the population with healthcare insurance, quality education, and employment. With this data, we concluded that there was an association between employment and citizenship status. Moreover, we were able to determine 5 distinct population groups using Machine Learning classification. The five clusters our analysis identifies reveal that while citizenship status shows no association with workforce participation, significant disparities exist in access to employer-sponsored health insurance. Each cluster represents a distinct demographic of the population, showing that there is a primary split along the lines of educational attainment which separates Clusters 0 and 4 from Clusters 1, 2, and 3. Furthermore, labor force status and nativity serve as secondary differentiators. Non-citizens are also disproportionately concentrated in precarious employment without benefits, highlighting systemic inequalities in healthcare access. By uncovering demographic clusters that face compounded disadvantages, this research contributes to a more nuanced understanding of socioeconomic stratification.

</details>


### [560] [Byzantine-Robust Federated Learning Framework with Post-Quantum Secure Aggregation for Real-Time Threat Intelligence Sharing in Critical IoT Infrastructure](https://arxiv.org/abs/2601.01053)
*Milad Rahmati,Nima Rahmati*

Main category: cs.CR

Relevance: 25.0

TL;DR: 提出了一种针对关键基础设施物联网的拜占庭鲁棒联邦学习框架，集成后量子安全聚合，用于实时威胁情报共享，同时防御模型投毒攻击和量子威胁。


<details>
  <summary>Details</summary>
Motivation: 关键基础设施物联网设备激增带来网络安全挑战，需要协作式威胁检测机制。传统联邦学习方法存在两个关键漏洞：易受拜占庭攻击（恶意参与者投毒模型更新）和无法抵御未来量子计算威胁（可能破坏密码聚合协议）。

Method: 提出集成后量子安全聚合的拜占庭鲁棒联邦学习框架，结合自适应加权聚合机制和基于格的密码协议。引入基于信誉的客户端选择算法，动态识别并排除拜占庭参与者，同时保持差分隐私保证。安全聚合协议使用CRYSTALS-Kyber进行密钥封装和同态加密以确保参数更新期间的机密性。

Result: 在工业物联网入侵检测数据集上的实验评估显示，该框架达到96.8%的威胁检测准确率，成功缓解高达40%的拜占庭攻击者，相比非安全联邦方法仅增加18%的计算开销。框架保持亚秒级聚合延迟，适合实时应用，并提供256位后量子安全级别。

Conclusion: 该框架为关键基础设施物联网提供了一种同时防御拜占庭攻击和量子威胁的联邦学习解决方案，在保持高性能的同时确保安全性和隐私性。

Abstract: The proliferation of Internet of Things devices in critical infrastructure has created unprecedented cybersecurity challenges, necessitating collaborative threat detection mechanisms that preserve data privacy while maintaining robustness against sophisticated attacks. Traditional federated learning approaches for IoT security suffer from two critical vulnerabilities: susceptibility to Byzantine attacks where malicious participants poison model updates, and inadequacy against future quantum computing threats that can compromise cryptographic aggregation protocols. This paper presents a novel Byzantine-robust federated learning framework integrated with post-quantum secure aggregation specifically designed for real-time threat intelligence sharing across critical IoT infrastructure. The proposed framework combines a adaptive weighted aggregation mechanism with lattice-based cryptographic protocols to simultaneously defend against model poisoning attacks and quantum adversaries. We introduce a reputation-based client selection algorithm that dynamically identifies and excludes Byzantine participants while maintaining differential privacy guarantees. The secure aggregation protocol employs CRYSTALS-Kyber for key encapsulation and homomorphic encryption to ensure confidentiality during parameter updates. Experimental evaluation on industrial IoT intrusion detection datasets demonstrates that our framework achieves 96.8% threat detection accuracy while successfully mitigating up to 40% Byzantine attackers, with only 18% computational overhead compared to non-secure federated approaches. The framework maintains sub-second aggregation latency suitable for real-time applications and provides 256-bit post-quantum security level.

</details>


### [561] [Gradient-Free Approaches is a Key to an Efficient Interaction with Markovian Stochasticity](https://arxiv.org/abs/2601.01160)
*Boris Prokhorov,Semyon Chebykin,Alexander Gasnikov,Aleksandr Beznosikov*

Main category: math.OC

Relevance: 25.0

TL;DR: 提出一种用于马尔可夫噪声环境下随机优化的零阶方法，在混合时间小于问题维度时，收敛估计与混合时间无关，证明了零阶方法在马尔可夫噪声下的最优性。


<details>
  <summary>Details</summary>
Motivation: 解决马尔可夫噪声环境下随机优化问题，传统一阶方法在马尔可夫噪声下计算成本高，探索零阶方法在特定条件下的优势。

Method: 提出一种新颖的零阶方法，使用随机批处理方案，支持单点和两点反馈，适用于强凸平滑和非平滑设置。

Result: 当底层噪声序列的混合时间τ小于问题维度d时，方法的收敛估计与τ无关，证明了零阶方法在马尔可夫噪声下的最优性。

Conclusion: 在马尔可夫噪声环境下，当混合时间小于问题维度时，使用零阶方法比昂贵的一阶方法更高效，并提供了理论最优性保证。

Abstract: This paper deals with stochastic optimization problems involving Markovian noise with a zero-order oracle. We present and analyze a novel derivative-free method for solving such problems in strongly convex smooth and non-smooth settings with both one-point and two-point feedback oracles. Using a randomized batching scheme, we show that when mixing time $τ$ of the underlying noise sequence is less than the dimension of the problem $d$, the convergence estimates of our method do not depend on $τ$. This observation provides an efficient way to interact with Markovian stochasticity: instead of invoking the expensive first-order oracle, one should use the zero-order oracle. Finally, we complement our upper bounds with the corresponding lower bounds. This confirms the optimality of our results.

</details>


### [562] [A New Framework for Explainable Rare Cell Identification in Single-Cell Transcriptomics Data](https://arxiv.org/abs/2601.01358)
*Di Su,Kai Ming Ting,Jie Zhang,Xiaorui Zhang,Xinpeng Li*

Main category: q-bio.GN

Relevance: 25.0

TL;DR: 提出一个用于单细胞转录组学数据的可解释异常检测框架，不仅能识别罕见细胞，还能提供基于基因的可视化解释


<details>
  <summary>Details</summary>
Motivation: 当前单细胞数据分析方法存在三个主要缺陷：1) 异常检测器作为"黑箱"无法解释为何细胞异常；2) 依赖PCA等降维技术将可解释的基因表达数据转化为抽象特征；3) 现有解释算法无法直接应用于高维、噪声大、稀疏的单细胞数据

Method: 提出一个可解释异常检测框架，包含两个关键创新：1) 消除传统方法中必需的PCA步骤；2) 采用最先进的异常检测器和解释器，有效识别罕见细胞并找到相关基因子空间，为每个罕见细胞及其最近邻正常细胞提供解释

Result: 该框架不仅能检测单个异常，还能提供基于基因的可视化解释，说明为何某个实例是异常的

Conclusion: 该研究填补了单细胞转录组学数据分析中可解释性方面的关键空白，为疾病发病机制和组织发育动态研究提供了更强大的工具

Abstract: The detection of rare cell types in single-cell transcriptomics data is crucial for elucidating disease pathogenesis and tissue development dynamics. However, a critical gap that persists in current methods is their inability to provide an explanation based on genes for each cell they have detected as rare. We identify three primary sources of this deficiency. First, the anomaly detectors often function as "black boxes", designed to detect anomalies but unable to explain why a cell is anomalous. Second, the standard analytical framework hinders interpretability by relying on dimensionality reduction techniques, such as Principal Component Analysis (PCA), which transform meaningful gene expression data into abstract, uninterpretable features. Finally, existing explanation algorithms cannot be readily applied to this domain, as single-cell data is characterized by high dimensionality, noise, and substantial sparsity. To overcome these limitations, we introduce a framework for explainable anomaly detection in single-cell transcriptomics data which not only identifies individual anomalies, but also provides a visual explanation based on genes that makes an instance anomalous. This framework has two key ingredients that are not existed in current methods applied in this domain. First, it eliminates the PCA step which is deemed to be an essential component in previous studies. Second, it employs the state-of-art anomaly detector and explainer as the efficient and effective means to find each rare cell and the relevant gene subspace in order to provide explanations for each rare cell as well as the typical normal cell associated with the rare cell's closest normal cells.

</details>


### [563] [Fast Gibbs Sampling on Bayesian Hidden Markov Model with Missing Observations](https://arxiv.org/abs/2601.01442)
*Dongrong Li,Tianwei Yu,Xiaodan Fan*

Main category: stat.ML

Relevance: 25.0

TL;DR: 提出一种用于隐马尔可夫模型的折叠Gibbs采样器，通过边缘化缺失观测和潜在状态来提高采样效率，特别适用于大量缺失数据的情况。


<details>
  <summary>Details</summary>
Motivation: 现实世界序列数据中经常存在缺失观测，这给隐马尔可夫模型的应用带来困难。现有的EM算法和Gibbs采样器存在非凸性、高计算复杂度和混合速度慢等问题。

Method: 提出一种折叠Gibbs采样器，通过同时边缘化缺失观测和对应的潜在状态，直接从HMM后验分布中采样。该方法在每次迭代中能产生更大的有效样本量，并且在大量缺失数据时计算复杂度显著降低。

Result: 数值模拟和真实数据分析表明，该算法在时间复杂度和采样效率（以有效样本量衡量）方面始终优于现有算法。当缺失条目较多时，计算优势更加明显。

Conclusion: 提出的采样算法在计算和理论上都更快，特别适用于存在大量缺失条目的情况，为处理不完整序列数据的HMM估计提供了高效解决方案。

Abstract: The Hidden Markov Model (HMM) is a widely-used statistical model for handling sequential data. However, the presence of missing observations in real-world datasets often complicates the application of the model. The EM algorithm and Gibbs samplers can be used to estimate the model, yet suffering from various problems including non-convexity, high computational complexity and slow mixing. In this paper, we propose a collapsed Gibbs sampler that efficiently samples from HMMs' posterior by integrating out both the missing observations and the corresponding latent states. The proposed sampler is fast due to its three advantages. First, it achieves an estimation accuracy that is comparable to existing methods. Second, it can produce a larger Effective Sample Size (ESS) per iteration, which can be justified theoretically and numerically. Third, when the number of missing entries is large, the sampler has a significant smaller computational complexity per iteration compared to other methods, thus is faster computationally. In summary, the proposed sampling algorithm is fast both computationally and theoretically and is particularly advantageous when there are a lot of missing entries. Finally, empirical evaluations based on numerical simulations and real data analysis demonstrate that the proposed algorithm consistently outperforms existing algorithms in terms of time complexity and sampling efficiency (measured in ESS).

</details>


### [564] [Hidden costs for inference with deep network on embedded system devices](https://arxiv.org/abs/2601.01698)
*Chankyu Lee,Woohyun Choi,Sangwook Park*

Main category: cs.CC

Relevance: 25.0

TL;DR: 该研究评估了嵌入式系统中深度学习模型的推理性能，发现传统的MAC操作数指标在预测嵌入式设备推理时间方面存在局限性，需要额外考虑张量间计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统上使用乘累加（MAC）操作数来衡量深度学习模型的计算负载，但该指标在嵌入式系统环境中预测实际推理时间时存在局限性。研究者希望探究MAC操作数指标忽略了哪些因素，以及如何更准确地评估嵌入式设备上的模型推理性能。

Method: 在嵌入式系统设备上使用CIFAR-100数据集进行图像分类任务，比较分析了10个深度学习模型的推理时间与理论计算的MAC操作数。通过实验对比揭示MAC指标与实际推理时间之间的差异。

Result: 实验结果表明，仅使用MAC操作数无法准确预测嵌入式设备上的推理时间。研究发现需要考虑张量间的额外计算开销，这些开销在MAC指标中被忽略但对实际推理性能有重要影响。

Conclusion: 在嵌入式系统中优化深度学习模型以实现实时性能时，必须考虑MAC操作数之外的因素，特别是张量间的计算开销。这为嵌入式AI系统的模型选择和优化提供了重要指导。

Abstract: This study evaluates the inference performance of various deep learning models under an embedded system environment. In previous works, Multiply-Accumulate operation is typically used to measure computational load of a deep model. According to this study, however, this metric has a limitation to estimate inference time on embedded devices. This paper poses the question of what aspects are overlooked when expressed in terms of Multiply-Accumulate operations. In experiments, an image classification task is performed on an embedded system device using the CIFAR-100 dataset to compare and analyze the inference times of ten deep models with the theoretically calculated Multiply-Accumulate operations for each model. The results highlight the importance of considering additional computations between tensors when optimizing deep learning models for real-time performing in embedded systems.

</details>


### [565] [Random-Matrix-Induced Simplicity Bias in Over-parameterized Variational Quantum Circuits](https://arxiv.org/abs/2601.01877)
*Jun Qi,Chao-Han Huck Yang,Pin-Yu Chen,Min-Hsiu Hsieh*

Main category: quant-ph

Relevance: 25.0

TL;DR: 该论文从函数类角度解释了过参数化变分量子电路中出现的训练困难和泛化能力差的问题，揭示了这些电路会进入Haar-like普适类，导致观测期望值和梯度指数集中，从而引发简单性偏置和贫瘠高原现象。


<details>
  <summary>Details</summary>
Motivation: 变分量子电路(VQCs)通常使用过参数化来增加表达能力，但更深、参数更多的电路往往表现出训练困难、泛化能力有限的问题。作者旨在从理论角度解释这一现象，揭示其根本原因。

Method: 使用随机矩阵理论和测度集中工具，从函数类角度分析变分量子电路。将电路分为两类：1) 无结构变分ansatze（进入Haar-like普适类）；2) 张量结构VQCs（包括张量网络和超网络参数化）。

Result: 发现充分表达的无结构变分ansatze会进入Haar-like普适类，导致观测期望值和参数梯度随系统尺寸指数集中，产生"简单性偏置"现象。而张量结构VQCs通过限制可访问酉系综，避免了测度集中，即使在过参数化情况下也能保持输出变异性和非退化梯度信号。

Conclusion: 贫瘠高原、表达能力限制和泛化崩溃都可以统一到基于随机矩阵普适性的单一结构机制下，突显了架构归纳偏置在变分量子算法中的核心作用。

Abstract: Over-parameterization is commonly used to increase the expressivity of variational quantum circuits (VQCs), yet deeper and more highly parameterized circuits often exhibit poor trainability and limited generalization. In this work, we provide a theoretical explanation for this phenomenon from a function-class perspective. We show that sufficiently expressive, unstructured variational ansatze enter a Haar-like universality class in which both observable expectation values and parameter gradients concentrate exponentially with system size. As a consequence, the hypothesis class induced by such circuits collapses with high probability to a narrow family of near-constant functions, a phenomenon we term simplicity bias, with barren plateaus arising as a consequence rather than the root cause. Using tools from random matrix theory and concentration of measure, we rigorously characterize this universality class and establish uniform hypothesis-class collapse over finite datasets. We further show that this collapse is not unavoidable: tensor-structured VQCs, including tensor-network-based and tensor-hypernetwork parameterizations, lie outside the Haar-like universality class. By restricting the accessible unitary ensemble through bounded tensor rank or bond dimension, these architectures prevent concentration of measure, preserve output variability for local observables, and retain non-degenerate gradient signals even in over-parameterized regimes. Together, our results unify barren plateaus, expressivity limits, and generalization collapse under a single structural mechanism rooted in random-matrix universality, highlighting the central role of architectural inductive bias in variational quantum algorithms.

</details>


### [566] [SafeLoad: Efficient Admission Control Framework for Identifying Memory-Overloading Queries in Cloud Data Warehouses](https://arxiv.org/abs/2601.01888)
*Yifan Wu,Yuhan Li,Zhenhua Wang,Zhongle Xie,Dingyu Yang,Ke Chen,Lidan Shou,Bo Tang,Liang Lin,Huan Li,Gang Chen*

Main category: cs.DB

Relevance: 25.0

TL;DR: SafeLoad是一个专门用于识别内存过载查询的准入控制框架，通过可解释判别规则和混合架构预测内存过载查询，防止云数据仓库中的资源浪费和查询失败。


<details>
  <summary>Details</summary>
Motivation: 云数据仓库中内存过载是常见的资源耗尽形式，会导致CPU时间浪费和核心业务流程中断。现有准入控制框架主要关注SLA满足和资源隔离，对内存过载查询识别精度有限，且缺乏公开的标注数据集。

Method: 1) 使用可解释判别规则过滤内存安全查询；2) 采用全局模型和集群级模型的混合架构；3) 添加误预测校正模块；4) 自调优配额管理机制动态调整预测配额；5) 发布SafeBench开源基准数据集（1.5亿真实查询）。

Result: SafeLoad在预测性能上达到最先进水平，在线和离线时间开销低。相比最佳基线，精度提升高达66%；相比无SafeLoad场景，减少CPU时间浪费高达8.09倍。

Conclusion: SafeLoad是首个专门识别内存过载查询的准入控制框架，通过可解释规则、混合架构和自调优机制，有效防止云数据仓库中的资源浪费和查询失败。

Abstract: Memory overload is a common form of resource exhaustion in cloud data warehouses. When database queries fail due to memory overload, it not only wastes critical resources such as CPU time but also disrupts the execution of core business processes, as memory-overloading (MO) queries are typically part of complex workflows. If such queries are identified in advance and scheduled to memory-rich serverless clusters, it can prevent resource wastage and query execution failure. Therefore, cloud data warehouses desire an admission control framework with high prediction precision, interpretability, efficiency, and adaptability to effectively identify MO queries. However, existing admission control frameworks primarily focus on scenarios like SLA satisfaction and resource isolation, with limited precision in identifying MO queries. Moreover, there is a lack of publicly available MO-labeled datasets with workloads for training and benchmarking. To tackle these challenges, we propose SafeLoad, the first query admission control framework specifically designed to identify MO queries. Alongside, we release SafeBench, an open-source, industrial-scale benchmark for this task, which includes 150 million real queries. SafeLoad first filters out memory-safe queries using the interpretable discriminative rule. It then applies a hybrid architecture that integrates both a global model and cluster-level models, supplemented by a misprediction correction module to identify MO queries. Additionally, a self-tuning quota management mechanism dynamically adjusts prediction quotas per cluster to improve precision. Experimental results show that SafeLoad achieves state-of-the-art prediction performance with low online and offline time overhead. Specifically, SafeLoad improves precision by up to 66% over the best baseline and reduces wasted CPU time by up to 8.09x compared to scenarios without SafeLoad.

</details>


### [567] [Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization](https://arxiv.org/abs/2601.02257)
*Joel Daniel Andersson,Palak Jain,Satchit Sivakumar*

Main category: cs.CR

Relevance: 25.0

TL;DR: 本文提出了一种改进的差分隐私流式统计算法框架，通过分析差异流的ℓp敏感度向量特性，优化了动态持续观察模型中的基数估计问题，在计数不同元素、度直方图和三角形计数等任务上获得了更好的误差界限。


<details>
  <summary>Details</summary>
Motivation: 在完全动态的持续观察模型中，每个时间步可能有多个更新（插入和删除），现有的差分隐私统计方法将基数估计问题转化为差异流上的持续计数问题。但原始流的变化可能导致差异流的多次变化，这给应用私有持续计数算法获得最优误差界限带来了挑战。

Method: 提出一个通用框架，通过研究差异流的ℓp敏感度向量特性并分离其性质，改进多个基数估计问题的精度。关键技术挑战是证明可以使用最先进的分解机制来处理具有特定性质的敏感度向量集。

Result: 该框架在计数不同元素、估计度直方图和三角形计数（在稍宽松的隐私模型下）等任务上获得了改进的误差界限。实验和分析表明，改进的误差界限在广泛的参数范围内显著提高了基数估计的准确性。

Conclusion: 本文提供了一种通用的差分隐私持续基数估计方法，通过精细分析差异流的敏感度特性，在流式设置中实现了更优的精度，为动态流数据的隐私保护统计提供了有效的解决方案。

Abstract: We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova & Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties.
  We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.

</details>


### [568] [Hunting for "Oddballs" with Machine Learning: Detecting Anomalous Exoplanets Using a Deep-Learned Low-Dimensional Representation of Transit Spectra with Autoencoders](https://arxiv.org/abs/2601.02324)
*Alexander Roman,Emilie Panek,Roy T. Forestano,Eyup B. Unlu,Katia Matcheva,Konstantin T. Matchev*

Main category: astro-ph.EP

Relevance: 25.0

TL;DR: 使用自编码器降维进行异常检测，识别具有非常规化学特征（CO₂富集）的系外行星大气，在潜在空间中检测效果优于原始光谱空间，对噪声具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在大规模系外行星调查中，详尽的大气反演计算成本过高，需要高效方法识别具有非常规化学特征的异常目标。自编码器降维可提供低维表示，提高异常检测的鲁棒性。

Method: 使用ABC数据库（10万+模拟光谱），定义CO₂富集大气为异常，CO₂贫乏大气为正常。比较四种异常检测方法：自编码器重构损失、一类SVM、K-means聚类、局部离群因子。在原始光谱空间和自编码器潜在空间分别评估，引入10-50 ppm高斯噪声测试鲁棒性。

Result: 潜在空间中的异常检测在所有噪声水平下均更有效。K-means聚类在潜在空间中表现稳定且优异。方法对30 ppm噪声（实际空间观测水平）保持鲁棒，在50 ppm噪声下仍可行。原始光谱空间方法性能随噪声增加显著下降。

Conclusion: 自编码器驱动的降维为大规模调查中识别化学异常目标提供了鲁棒方法，在潜在空间进行异常检测优于原始光谱空间，对观测噪声具有良好耐受性。

Abstract: This study explores the application of autoencoder-based machine learning techniques for anomaly detection to identify exoplanet atmospheres with unconventional chemical signatures using a low-dimensional data representation. We use the Atmospheric Big Challenge (ABC) database, a publicly available dataset with over 100,000 simulated exoplanet spectra, to construct an anomaly detection scenario by defining CO2-rich atmospheres as anomalies and CO2-poor atmospheres as the normal class. We benchmarked four different anomaly detection strategies: Autoencoder Reconstruction Loss, One-Class Support Vector Machine (1 class-SVM), K-means Clustering, and Local Outlier Factor (LOF). Each method was evaluated in both the original spectral space and the autoencoder's latent space using Receiver Operating Characteristic (ROC) curves and Area Under the Curve (AUC) metrics. To test the performance of the different methods under realistic conditions, we introduced Gaussian noise levels ranging from 10 to 50 ppm. Our results indicate that anomaly detection is consistently more effective when performed within the latent space across all noise levels. Specifically, K-means clustering in the latent space emerged as a stable and high-performing method. We demonstrate that this anomaly detection approach is robust to noise levels up to 30 ppm (consistent with realistic space-based observations) and remains viable even at 50 ppm when leveraging latent space representations. On the other hand, the performance of the anomaly detection methods applied directly in the raw spectral space degrades significantly with increasing the level of noise. This suggests that autoencoder-driven dimensionality reduction offers a robust methodology for flagging chemically anomalous targets in large-scale surveys where exhaustive retrievals are computationally prohibitive.

</details>


### [569] [A-PINN: Auxiliary Physics-informed Neural Networks for Structural Vibration Analysis in Continuous Euler-Bernoulli Beam](https://arxiv.org/abs/2601.00866)
*Shivani Saini,Ramesh Kumar Vats,Arup Kumar Sahoo*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出一种改进的辅助物理信息神经网络(A-PINN)框架，结合平衡自适应优化器，用于结构振动问题的分析，在欧拉-伯努利梁方程求解中相比基线提升至少40%


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络(PINNs)及其变体在求解微分方程控制的正反问题方面表现出色，但在结构振动分析中需要更准确的模型来捕捉振动现象并确保可靠的预测分析

Method: 提出改进的辅助物理信息神经网络(A-PINN)框架，结合平衡自适应优化器，用于求解欧拉-伯努利梁方程，通过数值模拟在不同场景下验证模型性能

Result: 数值结果表明，该模型在数值稳定性和预测准确性方面均有提升，相比基线方法至少提高40%的性能

Conclusion: 该研究为科学机器学习模型在解决振动问题方面的鲁棒性提供了深入见解，证明了改进的A-PINN框架在结构振动分析中的有效性

Abstract: Recent advancements in physics-informed neural networks (PINNs) and their variants have garnered substantial focus from researchers due to their effectiveness in solving both forward and inverse problems governed by differential equations. In this research, a modified Auxiliary physics-informed neural network (A-PINN) framework with balanced adaptive optimizers is proposed for the analysis of structural vibration problems. In order to accurately represent structural systems, it is critical for capturing vibration phenomena and ensuring reliable predictive analysis. So, our investigations are crucial for gaining deeper insight into the robustness of scientific machine learning models for solving vibration problems. Further, to rigorously evaluate the performance of A-PINN, we conducted different numerical simulations to approximate the Euler-Bernoulli beam equations under the various scenarios. The numerical results substantiate the enhanced performance of our model in terms of both numerical stability and predictive accuracy. Our model shows improvement of at least 40% over the baselines.

</details>


### [570] [Data-Driven Assessment of Concrete Mixture Compositions on Chloride Transport via Standalone Machine Learning Algorithms](https://arxiv.org/abs/2601.01009)
*Mojtaba Aliasghar-Mamaghani,Mohammadreza Khalafi*

Main category: cs.LG

Relevance: 15.0

TL;DR: 使用多种机器学习算法预测混凝土中氯离子随时间演变，评估不同混凝土配比对氯离子含量的影响，以评估基础设施使用寿命


<details>
  <summary>Details</summary>
Motivation: 评估混凝土结构在侵蚀性环境中的使用寿命需要理解氯离子随时间演变，传统方法难以捕捉复杂非线性关系，需要数据驱动方法建立可靠预测模型

Method: 采用简单和复杂的机器学习算法：线性回归、KNN回归、核岭回归、支持向量回归、高斯过程回归、多层感知机和门控循环单元，使用综合数据集评估性能

Result: 核岭回归、高斯过程回归和多层感知机表现出高精度，GRU由于数据多样性无法准确预测测试集响应，大多数混合物成分与氯离子含量呈负相关

Conclusion: 机器学习方法可作为替代方法描述氯离子侵入的物理过程和相关关联，有助于增强基础设施使用寿命评估

Abstract: This paper employs a data-driven approach to determine the impact of concrete mixture compositions on the temporal evolution of chloride in concrete structures. This is critical for assessing the service life of civil infrastructure subjected to aggressive environments. The adopted methodology relies on several simple and complex standalone machine learning (ML) algorithms, with the primary objective of establishing confidence in the unbiased prediction of the underlying hidden correlations. The simple algorithms include linear regression (LR), k-nearest neighbors (KNN) regression, and kernel ridge regression (KRR). The complex algorithms entail support vector regression (SVR), Gaussian process regression (GPR), and two families of artificial neural networks, including a feedforward network (multilayer perceptron, MLP) and a gated recurrent unit (GRU). The MLP architecture cannot explicitly handle sequential data, a limitation addressed by the GRU. A comprehensive dataset is considered. The performance of ML algorithms is evaluated, with KRR, GPR, and MLP exhibiting high accuracy. Given the diversity of the adopted concrete mixture proportions, the GRU was unable to accurately reproduce the response in the test set. Further analyses elucidate the contributions of mixture compositions to the temporal evolution of chloride. The results obtained from the GPR model unravel latent correlations through clear and explainable trends. The MLP, SVR, and KRR also provide acceptable estimates of the overall trends. The majority of mixture components exhibit an inverse relation with chloride content, while a few components demonstrate a direct correlation. These findings highlight the potential of surrogate approaches for describing the physical processes involved in chloride ingress and the associated correlations, toward the ultimate goal of enhancing the service life of civil infrastructure.

</details>


### [571] [Tiny Machine Learning for Real-Time Aquaculture Monitoring: A Case Study in Morocco](https://arxiv.org/abs/2601.01065)
*Achraf Hsain,Yahya Zaki,Othman Abaakil,Hibat-allah Bekkar,Yousra Chtouki*

Main category: cs.LG

Relevance: 15.0

TL;DR: 该论文提出将低功耗边缘设备与TinyML技术集成到水产养殖系统中，实现实时自动化监测和控制，以解决传统人工监测效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 水产养殖业面临水质波动、疾病爆发和饲料管理效率低等挑战，传统人工监测方法耗时且可能导致问题处理延迟，需要更高效的自动化解决方案。

Method: 使用TinyML技术在低功耗边缘设备上部署机器学习模型，集成多种传感器（pH、温度、溶解氧、氨氮等）进行实时数据采集，实现异常检测和自动报警。

Result: 系统能够实时监测水质参数，自动触发警报，收集的数据可用于优化水处理、饲料分配和模式分析，提高饲料效率并降低运营成本。

Conclusion: TinyML技术在水产养殖监测中具有可行性，能够促进更可持续和高效的养殖实践，但需要考虑传感器选择、算法设计、硬件约束和伦理因素。

Abstract: Aquaculture, the farming of aquatic organisms, is a rapidly growing industry facing challenges such as water quality fluctuations, disease outbreaks, and inefficient feed management. Traditional monitoring methods often rely on manual labor and are time consuming, leading to potential delays in addressing issues. This paper proposes the integration of low-power edge devices using Tiny Machine Learning (TinyML) into aquaculture systems to enable real-time automated monitoring and control, such as collecting data and triggering alarms, and reducing labor requirements. The system provides real-time data on the required parameters such as pH levels, temperature, dissolved oxygen, and ammonia levels to control water quality, nutrient levels, and environmental conditions enabling better maintenance, efficient resource utilization, and optimal management of the enclosed aquaculture space. The system enables alerts in case of anomaly detection. The data collected by the sensors over time can serve for important decision-making regarding optimizing water treatment processes, feed distribution, feed pattern analysis and improve feed efficiency, reducing operational costs. This research explores the feasibility of developing TinyML-based solutions for aquaculture monitoring, considering factors such as sensor selection, algorithm design, hardware constraints, and ethical considerations. By demonstrating the potential benefits of TinyML in aquaculture, our aim is to contribute to the development of more sustainable and efficient farming practices.

</details>


### [572] [Community-Based Early-Stage Chronic Kidney Disease Screening using Explainable Machine Learning for Low-Resource Settings](https://arxiv.org/abs/2601.01119)
*Muhammad Ashad Kabir,Sirajam Munira,Dewan Tasnia Azad,Saleh Mohammed Ikram,Mohammad Habibur Rahman Sarker,Syed Manzoor Ahmed Hanifi*

Main category: cs.LG

Relevance: 15.0

TL;DR: 开发了一个可解释的机器学习框架，用于孟加拉国和南亚人群的早期慢性肾病社区筛查，相比现有工具实现了更高的准确性和敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有慢性肾病筛查工具主要基于高收入国家人群开发，在孟加拉国和南亚地区表现不佳。这些工具通常使用简单的加性评分函数，基于晚期肾病数据，无法捕捉风险因素的复杂相互作用，也难以预测早期肾病。

Method: 使用孟加拉国社区数据集（南亚首个此类数据集），评估了12种机器学习分类器，应用10种互补的特征选择技术识别稳健、可泛化的预测因子。最终模型采用10折交叉验证评估，并在印度、阿联酋和孟加拉国的三个独立数据集上进行外部验证。使用SHAP提供模型可解释性。

Result: 基于RFECV选择特征子集的机器学习模型达到90.40%的平衡准确率；仅使用最少非病理检测特征也能达到89.23%的平衡准确率，通常优于更大或完整特征集。相比现有筛查工具，提出的模型实现了显著更高的准确性和敏感性，同时需要更少且更易获取的输入。外部验证显示78%至98%的敏感性，证实了强泛化能力。

Conclusion: 该研究开发了一个可解释的机器学习框架，专门针对孟加拉国和南亚人群的早期慢性肾病筛查，在低资源环境下表现出优异的性能和泛化能力，为改善该地区肾病早期检测提供了有效工具。

Abstract: Early detection of chronic kidney disease (CKD) is essential for preventing progression to end-stage renal disease. However, existing screening tools - primarily developed using populations from high-income countries - often underperform in Bangladesh and South Asia, where risk profiles differ. Most of these tools rely on simple additive scoring functions and are based on data from patients with advanced-stage CKD. Consequently, they fail to capture complex interactions among risk factors and are limited in predicting early-stage CKD. Our objective was to develop and evaluate an explainable machine learning (ML) framework for community-based early-stage CKD screening for low-resource settings, tailored to the Bangladeshi and South Asian population context. We used a community-based dataset from Bangladesh, the first such CKD dataset in South and South Asia, and evaluated twelve ML classifiers across multiple feature domains. Ten complementary feature selection techniques were applied to identify robust, generalizable predictors. The final models were assessed using 10-fold cross-validation. External validation was conducted on three independent datasets from India, the UAE, and Bangladesh. SHAP (SHapley Additive exPlanations) was used to provide model explainability. An ML model trained on an RFECV-selected feature subset achieved a balanced accuracy of 90.40%, whereas minimal non-pathology-test features demonstrated excellent predictive capability with a balanced accuracy of 89.23%, often outperforming larger or full feature sets. Compared with existing screening tools, the proposed models achieved substantially higher accuracy and sensitivity while requiring fewer and more accessible inputs. External validation confirmed strong generalizability with 78% to 98% sensitivity. SHAP interpretation identified clinically meaningful predictors consistent with established CKD risk factors.

</details>


### [573] [The Dependency Divide: An Interpretable Machine Learning Framework for Profiling Student Digital Satisfaction in the Bangladesh Context](https://arxiv.org/abs/2601.01231)
*Md Muhtasim Munif Fahim,Humyra Ankona,Md Monimul Huq,Md Rezaul Karim*

Main category: cs.LG

Relevance: 15.0

TL;DR: 本文提出"依赖鸿沟"框架，发现在基础设施脆弱的环境中，高度投入的学生反而因依赖数字平台而更容易受到基础设施故障的影响，挑战了"投入度越高学习效果越好"的普遍假设。


<details>
  <summary>Details</summary>
Motivation: 传统数字鸿沟框架无法解释在资源受限环境中，拥有同等连接条件的学生对数字学习平台满意度差异显著的现象。研究旨在揭示在基础设施脆弱的后接入环境中，学生投入度与基础设施可靠性之间的复杂关系。

Method: 采用三阶段分析方法：1) 使用稳定性验证的K-prototypes聚类识别学生档案；2) 构建档案特定的随机森林模型，结合SHAP和ALE分析确定满意度驱动因素；3) 使用倾向得分匹配进行正式交互分析，检验依赖鸿沟假设。

Result: 识别出三类学生档案：随意投入型(58%)、高效学习者(35%)和高度投入型(7%)。教育设备使用时间与网络可靠性之间存在显著交互作用，证实了依赖鸿沟假设：投入度仅在基础设施可靠时提高满意度。高度投入型学生尽管有成熟的数字工作流程，却表现出最大的脆弱性。政策模拟显示，针对高依赖用户的可靠性改进比统一干预产生2.06倍的回报。

Conclusion: 在基础设施脆弱的环境中，能力可能变成负担。数字转型政策必须优先考虑依赖倾向用户的可靠性，建立应急系统，并教育学生了解依赖风险，而不是统一推广投入度。

Abstract: Background: While digital access has expanded rapidly in resource-constrained contexts, satisfaction with digital learning platforms varies significantly among students with seemingly equal connectivity. Traditional digital divide frameworks fail to explain these variations.
  Purpose: This study introduces the "Dependency Divide", a novel framework proposing that highly engaged students become conditionally vulnerable to infrastructure failures, challenging assumptions that engagement uniformly benefits learners in post-access environments.
  Methods: We conducted a cross-sectional study of 396 university students in Bangladesh using a three-stage analytical approach: (1) stability-validated K-prototypes clustering to identify student profiles, (2) profile-specific Random Forest models with SHAP and ALE analysis to determine satisfaction drivers, and (3) formal interaction analysis with propensity score matching to test the Dependency Divide hypothesis.
  Results: Three distinct profiles emerged: Casually Engaged (58%), Efficient Learners (35%), and Hyper-Engaged (7%). A significant interaction between educational device time and internet reliability (\b{eta} = 0.033, p = 0.028) confirmed the Dependency Divide: engagement increased satisfaction only when infrastructure remained reliable. Hyper-Engaged students showed greatest vulnerability despite or because of their sophisticated digital workflows. Policy simulations demonstrated that targeted reliability improvements for high-dependency users yielded 2.06 times greater returns than uniform interventions.
  Conclusions: In fragile infrastructure contexts, capability can become liability. Digital transformation policies must prioritize reliability for dependency-prone users, establish contingency systems, and educate students about dependency risks rather than uniformly promoting engagement.

</details>


### [574] [Accelerated Full Waveform Inversion by Deep Compressed Learning](https://arxiv.org/abs/2601.01268)
*Maayan Gelboim,Amir Adler,Mauricio Araya-Polo*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出一种降低全波形反演(FWI)输入维度的方法，通过深度神经网络学习压缩感知，结合自编码器和K-means聚类，从大规模地震数据中选择最相关的子集，显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现代地震采集系统产生的数据达到TB级别，工业级FWI计算成本过高，限制了复杂地下结构分析和多场景探索。需要降低数据维度以加速FWI计算。

Method: 1) 使用带二值化感知层的深度神经网络，通过压缩学习从大量地下模型中学习简洁但有效的地震采集布局；2) 对大规模地震数据，训练好的网络选择较小的数据子集；3) 通过表示学习，自编码器计算数据的潜在表示；4) 对潜在表示进行K-means聚类，进一步选择FWI最相关的数据。

Result: 该方法在仅使用10%数据的情况下，在2D FWI中始终优于随机数据采样，为大规模3D反演加速FWI铺平了道路。

Conclusion: 提出的分层选择方法能有效降低FWI计算成本，通过智能数据选择而非随机采样，在保持反演质量的同时显著减少数据需求。

Abstract: We propose and test a method to reduce the dimensionality of Full Waveform Inversion (FWI) inputs as computational cost mitigation approach. Given modern seismic acquisition systems, the data (as input for FWI) required for an industrial-strength case is in the teraflop level of storage, therefore solving complex subsurface cases or exploring multiple scenarios with FWI become prohibitive. The proposed method utilizes a deep neural network with a binarized sensing layer that learns by compressed learning a succinct but consequential seismic acquisition layout from a large corpus of subsurface models. Thus, given a large seismic data set to invert, the trained network selects a smaller subset of the data, then by using representation learning, an autoencoder computes latent representations of the data, followed by K-means clustering of the latent representations to further select the most relevant data for FWI. Effectively, this approach can be seen as a hierarchical selection. The proposed approach consistently outperforms random data sampling, even when utilizing only 10% of the data for 2D FWI, these results pave the way to accelerating FWI in large scale 3D inversion.

</details>


### [575] [Causal discovery for linear causal model with correlated noise: an Adversarial Learning Approach](https://arxiv.org/abs/2601.01368)
*Mujin Zhou,Junzhe Zhang*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出一种基于f-GAN框架的因果发现方法，用于处理存在未测量混杂因素的数据，通过最小化贝叶斯自由能量来学习二元因果结构。


<details>
  <summary>Details</summary>
Motivation: 在存在未测量混杂因素的情况下进行因果发现是一个具有挑战性的问题。传统方法通常依赖于特定的权重值或参数假设，本文旨在开发一种独立于具体权重值的因果结构学习方法。

Method: 1. 将结构学习问题重新表述为最小化贝叶斯自由能量；2. 证明该问题等价于最小化真实数据分布与模型生成分布之间的f-散度；3. 使用f-GAN框架将目标转化为min-max对抗优化问题；4. 在离散图空间中使用Gumbel-Softmax松弛实现梯度搜索。

Result: 该方法能够从存在未测量混杂因素的数据中学习二元因果结构，通过对抗优化框架实现了对因果图的直接学习，而不依赖于特定的参数化假设。

Conclusion: 提出的基于f-GAN的因果发现方法为解决存在未测量混杂因素的因果结构学习问题提供了一种有效的框架，通过对抗优化和梯度搜索实现了对因果图的直接推断。

Abstract: Causal discovery from data with unmeasured confounding factors is a challenging problem. This paper proposes an approach based on the f-GAN framework, learning the binary causal structure independent of specific weight values. We reformulate the structure learning problem as minimizing Bayesian free energy and prove that this problem is equivalent to minimizing the f-divergence between the true data distribution and the model-generated distribution. Using the f-GAN framework, we transform this objective into a min-max adversarial optimization problem. We implement the gradient search in the discrete graph space using Gumbel-Softmax relaxation.

</details>


### [576] [Unveiling the Heart-Brain Connection: An Analysis of ECG in Cognitive Performance](https://arxiv.org/abs/2601.01424)
*Akshay Sasi,Malavika Pradeep,Nusaibah Farrukh,Rahul Venugopal,Elizabeth Sherly*

Main category: cs.LG

Relevance: 15.0

TL;DR: 该研究探索使用心电图（ECG）信号替代脑电图（EEG）来监测认知负荷，提出跨模态XGBoost框架将ECG特征映射到EEG认知空间，实现仅用ECG进行认知状态分类。


<details>
  <summary>Details</summary>
Motivation: 虽然EEG是评估心理负荷的金标准，但其便携性有限限制了实际应用。广泛可用的可穿戴设备ECG提供了一个实用的替代方案，研究探索ECG信号是否能可靠反映认知负荷并作为EEG指标的代理。

Method: 收集工作记忆和被动听力任务的多模态数据，提取ECG时域HRV指标和Catch22描述符，对应EEG频谱和Catch22特征。提出跨模态XGBoost框架，将ECG特征投影到EEG代表的认知空间，实现仅用ECG进行认知负荷推断。

Result: ECG衍生的投影能够显著捕捉认知状态的变化，为准确分类提供良好支持，验证了ECG作为可解释、实时、可穿戴的日常认知监测解决方案的可行性。

Conclusion: ECG可以作为EEG的有效替代方案，用于日常认知监测，具有可解释性、实时性和可穿戴性优势，为生理计算提供了实用的解决方案。

Abstract: Understanding the interaction of neural and cardiac systems during cognitive activity is critical to advancing physiological computing. Although EEG has been the gold standard for assessing mental workload, its limited portability restricts its real-world use. Widely available ECG through wearable devices proposes a pragmatic alternative. This research investigates whether ECG signals can reliably reflect cognitive load and serve as proxies for EEG-based indicators. In this work, we present multimodal data acquired from two different paradigms involving working-memory and passive-listening tasks. For each modality, we extracted ECG time-domain HRV metrics and Catch22 descriptors against EEG spectral and Catch22 features, respectively. We propose a cross-modal XGBoost framework to project the ECG features onto EEG-representative cognitive spaces, thereby allowing workload inferences using only ECG. Our results show that ECG-derived projections expressively capture variation in cognitive states and provide good support for accurate classification. Our findings underpin ECG as an interpretable, real-time, wearable solution for everyday cognitive monitoring.

</details>


### [577] [Real Time NILM Based Power Monitoring of Identical Induction Motors Representing Cutting Machines in Textile Industry](https://arxiv.org/abs/2601.01616)
*Md Istiauk Hossain Rifat,Moin Khan,Mohammad Zunaed*

Main category: cs.LG

Relevance: 15.0

TL;DR: 该论文提出了一种面向孟加拉国纺织工业的实时非侵入式负载监测(NILM)框架，专注于识别相同的电机驱动负载（纺织切割机），通过硬件采集数据并在云端处理，评估了MATNILM模型在工业环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国纺织工业是能源密集型行业，但监测方法过时，导致能源使用效率低下和运营成本高昂。需要开发实时监测系统来改善能源管理。

Method: 开发了包含电压和电流传感器、Arduino Mega和ESP8266的硬件系统，采集总负载和单个负载数据，存储在云端平台。创建了包含三个相同感应电机和辅助负载的新数据集（超过18万个样本），评估了先进的MATNILM模型在工业条件下的性能。

Result: 总能量估计相对准确，但单个设备分解面临困难，特别是多个相同机器同时运行时。集成系统通过Blynk应用实现了实用的实时远程监测。

Conclusion: NILM在工业应用中具有潜力但也存在局限，未来改进方向包括更高频率的数据采集、更大规模的数据集以及处理相同负载的先进深度学习方法。

Abstract: The textile industry in Bangladesh is one of the most energy-intensive sectors, yet its monitoring practices remain largely outdated, resulting in inefficient power usage and high operational costs. To address this, we propose a real-time Non-Intrusive Load Monitoring (NILM)-based framework tailored for industrial applications, with a focus on identical motor-driven loads representing textile cutting machines. A hardware setup comprising voltage and current sensors, Arduino Mega and ESP8266 was developed to capture aggregate and individual load data, which was stored and processed on cloud platforms. A new dataset was created from three identical induction motors and auxiliary loads, totaling over 180,000 samples, to evaluate the state-of-the-art MATNILM model under challenging industrial conditions. Results indicate that while aggregate energy estimation was reasonably accurate, per-appliance disaggregation faced difficulties, particularly when multiple identical machines operated simultaneously. Despite these challenges, the integrated system demonstrated practical real-time monitoring with remote accessibility through the Blynk application. This work highlights both the potential and limitations of NILM in industrial contexts, offering insights into future improvements such as higher-frequency data collection, larger-scale datasets and advanced deep learning approaches for handling identical loads.

</details>


### [578] [Theoretical Convergence of SMOTE-Generated Samples](https://arxiv.org/abs/2601.01927)
*Firuz Kamalov,Hana Sulieman,Witold Pedrycz*

Main category: cs.LG

Relevance: 15.0

TL;DR: 本文对SMOTE（合成少数类过采样技术）的收敛性进行了严格的理论分析，证明了合成随机变量Z依概率收敛于基础随机变量X，并在X紧致时证明了更强的均值收敛，为不平衡数据处理的实践提供了理论指导。


<details>
  <summary>Details</summary>
Motivation: 不平衡数据广泛存在于机器学习应用中，从医疗保健到网络安全。SMOTE是解决这一问题最流行的方法之一，但现有研究主要基于实证验证，缺乏严格的理论分析。本文旨在填补这一空白，为SMOTE提供坚实的理论基础。

Method: 采用理论分析方法，严格证明了SMOTE合成随机变量Z的收敛性质：1) Z依概率收敛于X；2) 当X紧致时，Z依均值收敛于X；3) 分析了最近邻秩对收敛速度的影响。同时通过真实数据和合成数据的数值实验验证理论结果。

Result: 理论证明显示：1) SMOTE生成的合成样本在概率意义下收敛于原始分布；2) 紧致条件下收敛性更强；3) 较低的最近邻秩值能带来更快的收敛速度。数值实验支持了这些理论发现。

Conclusion: 本文为SMOTE提供了首个严格的理论收敛性分析，不仅增强了不平衡数据处理的理论基础，还为数据增强技术提供了更深入的理解，有助于指导实际应用中的参数选择。

Abstract: Imbalanced data affects a wide range of machine learning applications, from healthcare to network security. As SMOTE is one of the most popular approaches to addressing this issue, it is imperative to validate it not only empirically but also theoretically. In this paper, we provide a rigorous theoretical analysis of SMOTE's convergence properties. Concretely, we prove that the synthetic random variable Z converges in probability to the underlying random variable X. We further prove a stronger convergence in mean when X is compact. Finally, we show that lower values of the nearest neighbor rank lead to faster convergence offering actionable guidance to practitioners. The theoretical results are supported by numerical experiments using both real-life and synthetic data. Our work provides a foundational understanding that enhances data augmentation techniques beyond imbalanced data scenarios.

</details>


### [579] [Prior Diffusiveness and Regret in the Linear-Gaussian Bandit](https://arxiv.org/abs/2601.02022)
*Yifan Zhu,John C. Duchi,Benjamin Van Roy*

Main category: cs.LG

Relevance: 15.0

TL;DR: 本文证明了Thompson采样在线性高斯赌博机中具有$\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$的贝叶斯遗憾，其中burn-in项与minimax遗憾项呈加法分离而非乘法关系。


<details>
  <summary>Details</summary>
Motivation: 现有Thompson采样在线性赌博机中的遗憾边界通常包含先验依赖的"burn-in"项和minimax遗憾项的乘积关系，作者希望证明这两个项实际上可以加法分离，从而提供更精确的理论分析。

Method: 通过新的"椭圆势能"引理来分析Thompson采样在线性高斯赌博机中的性能，其中系数服从$\mathcal{N}(μ_0, Σ_0)$先验分布，动作具有最大$\ell_2$范数$r$，噪声方差为$σ^2$。

Result: 证明了Thompson采样具有$\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$的贝叶斯遗憾，其中burn-in项$d r \sqrt{\mathrm{Tr}(Σ_0)}$与minimax遗憾项$σd \sqrt{T}$呈加法关系，而非乘法关系。同时提供了下界证明burn-in项是不可避免的。

Conclusion: Thompson采样在线性高斯赌博机中的遗憾可以分解为加法形式，其中burn-in项与先验协方差矩阵的迹的平方根成正比，这一理论结果改进了现有分析并提供了更精确的性能刻画。

Abstract: We prove that Thompson sampling exhibits $\tilde{O}(σd \sqrt{T} + d r \sqrt{\mathrm{Tr}(Σ_0)})$ Bayesian regret in the linear-Gaussian bandit with a $\mathcal{N}(μ_0, Σ_0)$ prior distribution on the coefficients, where $d$ is the dimension, $T$ is the time horizon, $r$ is the maximum $\ell_2$ norm of the actions, and $σ^2$ is the noise variance. In contrast to existing regret bounds, this shows that to within logarithmic factors, the prior-dependent ``burn-in'' term $d r \sqrt{\mathrm{Tr}(Σ_0)}$ decouples additively from the minimax (long run) regret $σd \sqrt{T}$. Previous regret bounds exhibit a multiplicative dependence on these terms. We establish these results via a new ``elliptical potential'' lemma, and also provide a lower bound indicating that the burn-in term is unavoidable.

</details>


### [580] [Prototype-Based Learning for Healthcare: A Demonstration of Interpretable AI](https://arxiv.org/abs/2601.02106)
*Ashish Rana,Ammar Shaker,Sascha Saralajew,Takashi Suzuki,Kosuke Yasuda,Shintaro Kato,Toshikazu Wada,Toshiyuki Fujikawa,Toru Kikutsuji*

Main category: cs.LG

Relevance: 15.0

TL;DR: ProtoPal是一个基于原型学习的个性化预防医疗框架，提供前后端模式，在实现优异量化性能的同时，提供直观的干预措施展示和模拟结果


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习和可解释AI有进展，但个性化预防医疗仍存在差距：预测、干预和推荐需要对所有医疗利益相关者来说都是可理解和可验证的

Method: 基于原型学习的框架ProtoPal，具有前后端模式，通过原型表示提供直观的干预展示和结果模拟

Result: 实现了优异的量化性能，同时提供了干预措施及其模拟结果的直观呈现

Conclusion: 原型学习能够满足个性化预防医疗中对可理解性和可验证性的需求

Abstract: Despite recent advances in machine learning and explainable AI, a gap remains in personalized preventive healthcare: predictions, interventions, and recommendations should be both understandable and verifiable for all stakeholders in the healthcare sector. We present a demonstration of how prototype-based learning can address these needs. Our proposed framework, ProtoPal, features both front- and back-end modes; it achieves superior quantitative performance while also providing an intuitive presentation of interventions and their simulated outcomes.

</details>


### [581] [Energy-Efficient Eimeria Parasite Detection Using a Two-Stage Spiking Neural Network Architecture](https://arxiv.org/abs/2601.00806)
*Ángel Miguel García-Vico,Huseyin Seker,Muhammad Afzal*

Main category: cs.NE

Relevance: 15.0

TL;DR: 提出一种用于球虫病诊断的两阶段脉冲神经网络架构，通过CNN转脉冲特征提取器结合轻量级STDP分类器，在达到98.32%准确率的同时实现223倍能效提升


<details>
  <summary>Details</summary>
Motivation: 球虫病对家禽和兔产业构成重大威胁，需要快速准确的诊断工具。虽然深度学习模型精度高，但能耗大限制了其在资源受限环境中的部署。需要开发既准确又节能的诊断系统。

Method: 提出两阶段SNN架构：1) 将预训练CNN转换为脉冲特征提取器；2) 结合轻量级无监督SNN分类器，使用脉冲时序依赖可塑性(STDP)训练。该设计旨在实现高精度与极低能耗的平衡。

Result: 在球虫分类任务中达到98.32%的准确率，创下新的SOTA。与传统ANN相比，能耗降低超过223倍，实现了高精度与极端能效的协同。

Conclusion: 该工作展示了高精度与极端能效的强大协同效应，为在神经形态硬件上部署自主、低功耗诊断系统铺平了道路。

Abstract: Coccidiosis, a disease caused by the Eimeria parasite, represents a major threat to the poultry and rabbit industries, demanding rapid and accurate diagnostic tools. While deep learning models offer high precision, their significant energy consumption limits their deployment in resource-constrained environments. This paper introduces a novel two-stage Spiking Neural Network (SNN) architecture, where a pre-trained Convolutional Neural Network is first converted into a spiking feature extractor and then coupled with a lightweight, unsupervised SNN classifier trained with Spike-Timing-Dependent Plasticity (STDP). The proposed model sets a new state-of-the-art, achieving 98.32\% accuracy in Eimeria classification. Remarkably, this performance is accomplished with a significant reduction in energy consumption, showing an improvement of more than 223 times compared to its traditional ANN counterpart. This work demonstrates a powerful synergy between high accuracy and extreme energy efficiency, paving the way for autonomous, low-power diagnostic systems on neuromorphic hardware.

</details>


### [582] [Autonomous battery research: Principles of heuristic operando experimentation](https://arxiv.org/abs/2601.00851)
*Emily Lu,Gabriel Perez,Peter Baker,Daniel Irving,Santosh Kumar,Veronica Celorrio,Sylvia Britto,Thomas F. Headen,Miguel Gomez-Gonzalez,Connor Wright,Calum Green,Robert Scott Young,Oleg Kirichek,Ali Mortazavi,Sarah Day,Isabel Antony,Zoe Wright,Thomas Wood,Tim Snow,Jeyan Thiyagalingam,Paul Quinn,Martin Owen Jones,William David,James Le Houx*

Main category: physics.ins-det

Relevance: 15.0

TL;DR: 提出Heuristic Operando实验框架，利用AI驱动的数字孪生主动引导光束线，预测并确定性捕捉电池降解中的罕见瞬态现象，提高实验效率和科学洞察力。


<details>
  <summary>Details</summary>
Motivation: 电池降解过程复杂，现有原位表征方法在可靠性、代表性和可重复性（3Rs）方面存在严重限制。传统方法依赖定制硬件和被动预编程方法，无法有效捕捉随机失效事件（如枝晶形成）。

Method: 提出Heuristic Operando实验框架：1）利用基于物理的数字孪生模型；2）AI导航器主动引导光束线；3）预测并确定性捕捉罕见失效事件；4）基于熵的度量标准优先考虑每个光子/中子/μ子的科学洞察力；5）与FAIR数据原则集成。

Result: 该框架能够：1）主动预测失效前兆；2）仅在机制决定性时刻进行测量；3）减轻光束损伤；4）大幅减少数据冗余；5）为未来可信自主电池实验室提供蓝图。

Conclusion: Heuristic Operando实验框架通过AI驱动的主动实验设计，解决了传统原位表征的局限性，为捕捉电池降解中的瞬态现象提供了新方法，有望推动电池研究和能源转型。

Abstract: Unravelling the complex processes governing battery degradation is critical to the energy transition, yet the efficacy of operando characterisation is severely constrained by a lack of Reliability, Representativeness, and Reproducibility (the 3Rs). Current methods rely on bespoke hardware and passive, pre-programmed methodologies that are ill-equipped to capture stochastic failure events. Here, using the Rutherford Appleton Laboratory's multi-modal toolkit as a case study, we expose the systemic inability of conventional experiments to capture transient phenomena like dendrite initiation. To address this, we propose Heuristic Operando experiments: a framework where an AI pilot leverages physics-based digital twins to actively steer the beamline to predict and deterministically capture these rare events. Distinct from uncertainty-driven active learning, this proactive search anticipates failure precursors, redefining experimental efficiency via an entropy-based metric that prioritises scientific insight per photon, neutron, or muon. By focusing measurements only on mechanistically decisive moments, this framework simultaneously mitigates beam damage and drastically reduces data redundancy. When integrated with FAIR data principles, this approach serves as a blueprint for the trusted autonomous battery laboratories of the future.

</details>


### [583] [Security Hardening Using FABRIC: Implementing a Unified Compliance Aggregator for Linux Servers](https://arxiv.org/abs/2601.00909)
*Sheldon Paul,Izzat Alsmadi*

Main category: cs.CR

Relevance: 15.0

TL;DR: 提出一个统一框架，通过聚合异构安全审计工具来评估FABRIC测试平台上的Linux安全加固效果，使用统一合规聚合器将不同工具的输出标准化并加权计算综合安全评分。


<details>
  <summary>Details</summary>
Motivation: 现有Linux安全审计工具（如Lynis、OpenSCAP、AIDE）各自为政，缺乏一致的评估标准和可比较的评分体系，难以系统评估安全加固措施的有效性，特别是在可编程测试平台环境中。

Method: 在FABRIC测试平台上部署三个不同加固级别（基线、部分、完全）的Ubuntu 22.04节点，运行108次审计。开发统一合规聚合器（UCA）解析工具输出，将分数归一化到0-100的统一尺度，通过加权聚合和可定制的规则引擎计算综合安全评分。

Result: 完全加固使OpenSCAP合规性从39.7提升到71.8，自定义规则合规性从39.3%提升到83.6%。UCA相比单个工具提供了更清晰、可重复的安全态势评估，能系统评估加固措施在可编程测试环境中的有效性。

Conclusion: UCA框架解决了异构安全审计工具缺乏一致评估标准的问题，为Linux安全加固提供了系统化、可重复的评估方法，特别适用于可编程测试平台环境中的安全态势评估。

Abstract: This paper presents a unified framework for evaluating Linux security hardening on the FABRIC testbed through aggregation of heterogeneous security auditing tools. We deploy three Ubuntu 22.04 nodes configured at baseline, partial, and full hardening levels, and evaluate them using Lynis, OpenSCAP, and AIDE across 108 audit runs. To address the lack of a consistent interpretation across tools, we implement a Unified Compliance Aggregator (UCA) that parses tool outputs, normalizes scores to a common 0--100 scale, and combines them into a weighted metric augmented by a customizable rule engine for organization-specific security policies. Experimental results show that full hardening increases OpenSCAP compliance from 39.7 to 71.8, while custom rule compliance improves from 39.3\% to 83.6\%. The results demonstrate that UCA provides a clearer and more reproducible assessment of security posture than individual tools alone, enabling systematic evaluation of hardening effectiveness in programmable testbed environments.

</details>


### [584] [Dynamic Accuracy Estimation in a Wi-Fi-based Positioning System](https://arxiv.org/abs/2601.00999)
*Marcin Kolakowski,Vitomir Djaja-Josko*

Main category: eess.SP

Relevance: 15.0

TL;DR: 提出了一种动态精度估计方法，通过定位算法使用的测量结果来推导定位误差。在Wi-Fi室内定位系统中验证，随机森林回归获得了最高的误差估计精度（平均绝对误差0.72米）。


<details>
  <summary>Details</summary>
Motivation: 室内定位系统通常需要评估定位精度，但传统方法难以实时估计定位误差。本文旨在开发一种动态精度估计方法，能够基于定位算法使用的测量结果来实时估计定位误差。

Method: 提出动态精度估计概念，基于定位算法使用的测量结果推导定位误差。在Wi-Fi室内定位系统中实验验证，测试了多种回归方法：线性回归、随机森林、k近邻和神经网络。

Result: 随机森林回归获得了最高的定位误差估计精度，平均绝对误差为0.72米。其他方法的性能相对较差。

Conclusion: 动态精度估计方法可行，随机森林回归在Wi-Fi室内定位系统中表现最佳，能够有效估计定位误差。

Abstract: The paper presents a concept of a dynamic accuracy estimation method, in which the localization errors are derived based on the measurement results used by the positioning algorithm. The concept was verified experimentally in a Wi\nobreakdash-Fi based indoor positioning system, where several regression methods were tested (linear regression, random forest, k-nearest neighbors, and neural networks). The highest positioning error estimation accuracy was achieved for random forest regression, with a mean absolute error of 0.72 m.

</details>


### [585] [Identifying recurrent flows in high-dimensional dissipative chaos from low-dimensional embeddings](https://arxiv.org/abs/2601.01590)
*Pierre Beck,Tobias M. Schneider*

Main category: nlin.CD

Relevance: 15.0

TL;DR: 提出一种在低维嵌入空间中识别不稳定周期轨道（UPOs）的循环收敛算法，用于分析高维混沌系统


<details>
  <summary>Details</summary>
Motivation: 不稳定周期轨道（UPOs）是时空混沌的非混沌动力学构建块，对于湍流理论至关重要。然而，由于混沌动力学和高维空间离散化的挑战，识别UPOs非常困难

Method: 提出循环收敛算法，在混沌吸引子的低维嵌入空间中直接识别UPOs。算法避免时间积分，通过自动微分学习嵌入函数，获得可解释的潜在动力学

Result: 该方法在模型PDE和2D Navier-Stokes方程中证明了潜在UPOs与物理UPOs的等价性，成功在低维嵌入中识别UPOs

Conclusion: 通过利用高维耗散系统塌缩到低维流形的特性，在低维嵌入空间中识别UPOs，为解决高维混沌系统的UPOs识别问题提供了新方法

Abstract: Unstable periodic orbits (UPOs) are the non-chaotic, dynamical building blocks of spatio-temporal chaos, motivating a first-principles based theory for turbulence ever since the discovery of deterministic chaos. Despite their key role in the ergodic theory approach to fluid turbulence, identifying UPOs is challenging for two reasons: chaotic dynamics and the high-dimensionality of the spatial discretization. We address both issues at once by proposing a loop convergence algorithm for UPOs directly within a low-dimensional embedding of the chaotic attractor. The convergence algorithm circumvents time-integration, hence avoiding instabilities from exponential error amplification, and operates on a latent dynamics obtained by pulling back the physical equations using automatic differentiation through the learned embedding function. The interpretable latent dynamics is accurate in a statistical sense, and, crucially, the embedding preserves the internal structure of the attractor, which we demonstrate through an equivalence between the latent and physical UPOs of both a model PDE and the 2D Navier-Stokes equations. This allows us to exploit the collapse of high-dimensional dissipative systems onto a lower dimensional manifold, and identify UPOs in the low-dimensional embedding.

</details>


### [586] [Sparse Convex Biclustering](https://arxiv.org/abs/2601.01757)
*Jiakun Jiang,Dewei Xiang,Chenliang Gu,Wei Liu,Binhuan Wang*

Main category: stat.ML

Relevance: 15.0

TL;DR: SpaCoBi是一种新型的稀疏凸双聚类方法，通过惩罚噪声和采用凸优化框架，显著提高了高维大规模数据集上的双聚类准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有双聚类方法在处理现代大规模高维数据集时面临挑战：高维特征中的噪声积累、非凸优化公式的局限性以及识别有意义双聚类的计算复杂性，导致随着数据集规模增大，准确性和稳定性下降。

Method: 提出Sparse Convex Biclustering (SpaCoBi)方法，在双聚类过程中惩罚噪声以提高准确性和鲁棒性。采用凸优化框架，引入基于稳定性的调优准则，实现聚类保真度和稀疏性之间的最优平衡。

Result: 综合数值研究（包括模拟实验和对小鼠嗅球数据的应用）表明，SpaCoBi在准确性方面显著优于现有最先进方法。

Conclusion: SpaCoBi为高维大规模数据集的双聚类提供了一个鲁棒且高效的解决方案。

Abstract: Biclustering is an essential unsupervised machine learning technique for simultaneously clustering rows and columns of a data matrix, with widespread applications in genomics, transcriptomics, and other high-dimensional omics data. Despite its importance, existing biclustering methods struggle to meet the demands of modern large-scale datasets. The challenges stem from the accumulation of noise in high-dimensional features, the limitations of non-convex optimization formulations, and the computational complexity of identifying meaningful biclusters. These issues often result in reduced accuracy and stability as the size of the dataset increases. To overcome these challenges, we propose Sparse Convex Biclustering (SpaCoBi), a novel method that penalizes noise during the biclustering process to improve both accuracy and robustness. By adopting a convex optimization framework and introducing a stability-based tuning criterion, SpaCoBi achieves an optimal balance between cluster fidelity and sparsity. Comprehensive numerical studies, including simulations and an application to mouse olfactory bulb data, demonstrate that SpaCoBi significantly outperforms state-of-the-art methods in accuracy. These results highlight SpaCoBi as a robust and efficient solution for biclustering in high-dimensional and large-scale datasets.

</details>


### [587] [Efficient temporal prediction of compressible flows in irregular domains using Fourier neural operators](https://arxiv.org/abs/2601.01922)
*Yifan Nie,Qiaoxin Li*

Main category: physics.flu-dyn

Relevance: 15.0

TL;DR: 该论文提出了一种基于傅里叶神经算子（FNO）的方法，用于高效准确地模拟不规则流场中高速可压缩流体的时间演化。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法在处理不规则流场中高速可压缩流体时计算效率低下，需要开发更高效的计算方法。傅里叶神经算子（FNO）在处理偏微分方程方面显示出潜力，但需要适应不规则流场的特殊要求。

Method: 1) 将不规则流场点集重构为FNO兼容的序列格式；2) 在循环神经网络（RNN）中嵌入时间捆绑技术进行多步预测；3) 使用复合损失函数平衡不同物理量的误差；4) 在正交和非正交网格配置的三种不规则流场上进行实验。

Result: 方法在计算效率上显著超越传统数值方法，同时保持高精度：压力(p)、温度(T)和速度(u)的最大相对L2误差分别为0.78%、0.57%和0.35%。通过物理分量损失曲线、流场可视化和物理剖面图进行了全面分析验证。

Conclusion: 该方法能够高效准确地模拟不规则域中高速可压缩流的时间演化，为计算流体力学提供了有前景的神经算子方法。

Abstract: This paper investigates the temporal evolution of high-speed compressible fluids in irregular flow fields using the Fourier Neural Operator (FNO). We reconstruct the irregular flow field point set into sequential format compatible with FNO input requirements, and then embed temporal bundling technique within a recurrent neural network (RNN) for multi-step prediction. We further employ a composite loss function to balance errors across different physical quantities. Experiments are conducted on three different types of irregular flow fields, including orthogonal and non-orthogonal grid configurations. Then we comprehensively analyze the physical component loss curves, flow field visualizations, and physical profiles. Results demonstrate that our approach significantly surpasses traditional numerical methods in computational efficiency while achieving high accuracy, with maximum relative $L_2$ errors of (0.78, 0.57, 0.35)% for ($p$, $T$, $\mathbf{u}$) respectively. This verifies that the method can efficiently and accurately simulate the temporal evolution of high-speed compressible flows in irregular domains.

</details>


### [588] [A Multilayered Approach to Classifying Customer Responsiveness and Credit Risk](https://arxiv.org/abs/2601.01970)
*Ayomide Afolabi,Ebere Ogburu,Symon Kimitei*

Main category: stat.ML

Relevance: 15.0

TL;DR: 该研究评估了三种不同模型（响应模型、风险模型、响应-风险模型）中各种分类器在信用卡邮件营销和违约预测中的性能。Extra Trees在响应模型中召回率最高（79.1%），Random Forest在风险模型中特异性最高（84.1%），在响应-风险多分类模型中准确率最高（83.2%）。


<details>
  <summary>Details</summary>
Motivation: 解决信用卡业务中的两个关键问题：1）识别对邮件营销活动最可能响应的客户，以提高营销效率；2）识别违约风险最低的客户，以降低信用风险。通过优化不同性能指标来解决具体的信用风险和邮件响应业务问题。

Method: 使用三种模型框架：响应模型（预测客户对信用卡邮件营销的响应）、风险模型（预测客户违约风险）、响应-风险多分类模型（同时考虑响应和风险）。在每种模型中使用多种分类器（包括Extra Trees、Random Forest等）进行比较评估，优化不同的性能指标（召回率、特异性、准确率）。

Result: 1）响应模型中：Extra Trees分类器获得最高召回率79.1%，最适合识别潜在响应者；2）风险模型中：Random Forest分类器获得最高特异性84.1%，最适合识别低风险客户；3）响应-风险多分类模型中：Random Forest分类器获得最高准确率83.2%，能有效同时识别潜在响应者和低风险用户。

Conclusion: 不同分类器在不同业务目标下表现各异：Extra Trees在最大化响应识别方面表现最佳，Random Forest在风险识别和综合任务中表现最优。研究为信用卡业务中的精准营销和风险管理提供了实用的机器学习解决方案。

Abstract: This study evaluates the performance of various classifiers in three distinct models: response, risk, and response-risk, concerning credit card mail campaigns and default prediction. In the response model, the Extra Trees classifier demonstrates the highest recall level (79.1%), emphasizing its effectiveness in identifying potential responders to targeted credit card offers. Conversely, in the risk model, the Random Forest classifier exhibits remarkable specificity of 84.1%, crucial for identifying customers least likely to default. Furthermore, in the multi-class response-risk model, the Random Forest classifier achieves the highest accuracy (83.2%), indicating its efficacy in discerning both potential responders to credit card mail campaign and low-risk credit card users. In this study, we optimized various performance metrics to solve a specific credit risk and mail responsiveness business problem.

</details>


### [589] [Predicting Early and Complete Drug Release from Long-Acting Injectables Using Explainable Machine Learning](https://arxiv.org/abs/2601.02265)
*Karla N. Robles,Manar D. Samad*

Main category: q-bio.BM

Relevance: 15.0

TL;DR: 本文提出了一种新颖的数据转换和可解释机器学习方法，用于分析长效注射剂（LAI）的药物释放特性，通过预测早期释放、分类释放曲线类型以及预测完整释放曲线，揭示了材料特性对药物释放的影响。


<details>
  <summary>Details</summary>
Motivation: 长效注射剂（LAIs）在慢性疾病治疗中具有重要作用，但需要复杂的物理化学性质优化来实现可控药物释放。机器学习可以加速LAI开发，但现有研究缺乏针对LAI数据的定制建模和分析，无法提供关于调控药物释放的关键特性的详细信息。

Method: 采用新颖的数据转换和可解释机器学习方法，分析321个LAI配方数据。通过三个实验：预测24、48、72小时的早期药物释放、分类释放曲线类型、预测完整释放曲线。使用时间独立的ML框架预测延迟双相和三相曲线，并采用Shapley加性解释分析材料特性的相对影响。

Result: 在72小时药物释放预测中观察到强相关性（>0.65），释放曲线类型分类获得0.87的F1分数。时间独立的ML框架在预测延迟双相和三相曲线方面优于当前的时间依赖方法。Shapley分析揭示了材料特性在早期和完整释放期间的相对影响。

Conclusion: 该新颖方法和发现为科学家优化LAI药物释放动力学提供了定量策略和建议，填补了先前体外和基于ML研究的若干空白。模型实现源代码已公开。

Abstract: Polymer-based long-acting injectables (LAIs) have transformed the treatment of chronic diseases by enabling controlled drug delivery, thus reducing dosing frequency and extending therapeutic duration. Achieving controlled drug release from LAIs requires extensive optimization of the complex underlying physicochemical properties. Machine learning (ML) can accelerate LAI development by modeling the complex relationships between LAI properties and drug release. However, recent ML studies have provided limited information on key properties that modulate drug release, due to the lack of custom modeling and analysis tailored to LAI data. This paper presents a novel data transformation and explainable ML approach to synthesize actionable information from 321 LAI formulations by predicting early drug release at 24, 48, and 72 hours, classification of release profile types, and prediction of complete release profiles. These three experiments investigate the contribution and control of LAI material characteristics in early and complete drug release profiles. A strong correlation (>0.65) is observed between the true and predicted drug release in 72 hours, while a 0.87 F1-score is obtained in classifying release profile types. A time-independent ML framework predicts delayed biphasic and triphasic curves with better performance than current time-dependent approaches. Shapley additive explanations reveal the relative influence of material characteristics during early and for complete release which fill several gaps in previous in-vitro and ML-based studies. The novel approach and findings can provide a quantitative strategy and recommendations for scientists to optimize the drug-release dynamics of LAI. The source code for the model implementation is publicly available.

</details>


### [590] [Outlier Detection Using Vector Cosine Similarity by Adding a Dimension](https://arxiv.org/abs/2601.00883)
*Zhongyang Shen*

Main category: cs.LG

Relevance: 5.0

TL;DR: 提出了一种基于向量余弦相似度的多维数据异常检测方法，通过在原数据中添加零值维度构建新数据集，利用观测点与测量点之间的向量相似性比较来识别异常数据。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法在处理多维数据时可能面临计算复杂度高或效果不佳的问题，需要一种更有效的方法来识别多维空间中的异常点。

Method: 通过在原数据中添加一个零值维度构建新数据集，选择测量点后创建观测点（原点），观测点与测量点仅在新维度上有差异。然后计算从观测点到测量点及其他点的向量，通过比较这些向量的余弦相似度来检测异常。

Result: 开发了优化的MDOD实现并发布在PyPI上，提供了一种有效的多维异常检测工具。

Conclusion: 该方法基于向量余弦相似度，为多维数据异常检测提供了一种新颖有效的解决方案。

Abstract: We propose a new outlier detection method for multi-dimensional data. The method detects outliers based on vector cosine similarity, using a new dataset constructed by adding a dimension with zero values to the original data. When a point in the new dataset is selected as the measured point, an observation point is created as the origin, differing only in the new dimension by having a non-zero value compared to the measured point. Vectors are then formed from the observation point to the measured point and to other points in the dataset. By comparing the cosine similarities of these vectors, abnormal data can be identified. An optimized implementation (MDOD) is available on PyPI: https://pypi.org/project/mdod/.

</details>


### [591] [Bayesian Negative Binomial Regression of Afrobeats Chart Persistence](https://arxiv.org/abs/2601.01391)
*Ian Jacob Cabansag,Paul Ntegeka*

Main category: eess.AS

Relevance: 5.0

TL;DR: 该研究使用贝叶斯负二项回归分析尼日利亚Spotify榜单数据，发现协作歌曲在控制总播放量后，在榜单上的停留时间略短于单人歌曲。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索协作是否有助于歌曲在流媒体平台榜单上停留更长时间，从而影响音乐人的收入和歌曲的文化影响力。在Afrobeats音乐竞争激烈的背景下，了解协作对榜单表现的影响具有实际意义。

Method: 使用2024年尼日利亚Spotify Top 200的每日数据，将每首歌曲在榜单上的天数作为结果变量。采用贝叶斯负二项回归模型，以协作状态（单人vs多艺人）和对数总播放量为预测变量。使用马尔可夫链蒙特卡洛进行后验推断，通过比率、后验概率和预测检查评估结果。

Result: 研究发现，在控制总播放量后，协作歌曲在榜单上停留的天数略少于可比单人歌曲。这表明协作虽然可能增加初始曝光，但未必能延长歌曲在榜单上的持久性。

Conclusion: 协作对歌曲在榜单上的持久性有轻微负面影响。音乐人和唱片公司在制定协作策略时需要考虑这一发现，协作可能有助于短期曝光，但未必能保证长期榜单表现。

Abstract: Afrobeats songs compete for attention on streaming platforms, where chart visibility can influence both revenue and cultural impact. This paper examines whether collaborations help songs remain on the charts longer, using daily Nigeria Spotify Top 200 data from 2024. Each track is summarized by the number of days it appears in the Top 200 during the year and its total annual streams in Nigeria. A Bayesian negative binomial regression is applied, with days on chart as the outcome and collaboration status (solo versus multi-artist) and log total streams as predictors. This approach is well suited for overdispersed count data and allows the effect of collaboration to be interpreted while controlling for overall popularity. Posterior inference is conducted using Markov chain Monte Carlo, and results are assessed using rate ratios, posterior probabilities, and predictive checks. The findings indicate that, after accounting for total streams, collaboration tracks tend to spend slightly fewer days on the chart than comparable solo tracks.

</details>
