<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 128]
- [cs.CV](#cs.CV) [Total: 172]
- [cs.AI](#cs.AI) [Total: 152]
- [cs.LG](#cs.LG) [Total: 212]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Crystal-KV: Efficient KV Cache Management for Chain-of-Thought LLMs via Answer-First Principle](https://arxiv.org/abs/2601.16986)
*Zihan Wang,Cheng Tang,Lei Gong,Cheng Li,Chao Wang,teng wang,Wenqi Lou,Xuehai Zhou*

Main category: cs.CL

Relevance: 85.0

TL;DR: Crystal-KV：针对CoT推理的KV缓存管理框架，通过答案优先原则区分关键缓存，实现高效压缩并保持准确性


<details>
  <summary>Details</summary>
Motivation: CoT推理显著提升LLM在复杂任务上的准确性，但长思考序列导致KV缓存内存开销过大。传统KV压缩策略对CoT无效，因为CoT强调最终答案而非所有token同等重要。

Method: 1) 答案优先原则：将答案偏好映射到思考阶段注意力图，区分SlipKV（维持推理流但可能误导）和CrystalKV（真正贡献最终答案正确性）。2) 基于注意力的LRFU算法：精确识别SlipKV效用过期时机并淘汰，保留CrystalKV不破坏推理流。3) 自适应缓存预算分配：基于CrystalKV动态比例估计各层/头重要性，推理时调整KV缓存预算，放大关键组件提升预算利用率。

Result: Crystal-KV实现了最先进的KV缓存压缩，显著提升吞吐量，实现更快响应时间，同时保持甚至提高CoT推理的答案准确性。

Conclusion: Crystal-KV是针对CoT推理的高效KV缓存管理框架，通过区分关键缓存和自适应预算分配，在保持准确性的同时大幅提升推理效率。

Abstract: Chain-of-Thought (CoT) reasoning in large language models (LLMs) significantly improves accuracy on complex tasks, yet incurs excessive memory overhead due to the long think-stage sequences stored in the Key-Value (KV) cache. Unlike traditional generation tasks where all tokens are uniformly important, CoT emphasizes the final answer, rendering conventional KV compression strategies ineffective. In this paper, we present Crystal-KV, an efficient KV cache management framework tailored for CoT reasoning. Our key insight is the answer-first principle. By mapping answer preferences into think-stage attention map, we distinguish between SlipKV, which mainly maintains the reasoning flow but may occasionally introduce misleading context, and CrystalKV, which truly contributes to the correctness of the final answer. Next, we propose an attention-based Least Recently Frequently Used algorithm. It precisely identifies when a SlipKV entry's utility expires and evicts it, retaining CrystalKV without disrupting reasoning flow. Finally, we introduce an adaptive cache budget allocation algorithm. Based on the dynamic proportion of CrystalKV, it estimates the importance of each layer/head and adjusts the KV cache budget during inference, amplifying critical components to improve budget utilization. Results show that Crystal-KV achieves state-of-the-art KV cache compression, significantly improves throughput, and enables faster response time, while maintaining, or even improving, answer accuracy for CoT reasoning.

</details>


### [2] [Evaluating Reward Model Generalization via Pairwise Maximum Discrepancy Competitions](https://arxiv.org/abs/2601.16987)
*Shunyang Luo,Peibei Cao,Zhihui Zhu,Kehua Feng,Zhihua Wang,Keyan Ding*

Main category: cs.CL

Relevance: 85.0

TL;DR: PMDC是一种动态高效的奖励模型评估框架，通过主动选择两个RM之间分歧最大的prompt-response对来评估泛化能力，相比传统静态基准能更真实反映RM在实际应用中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型评估主要依赖静态、预标注的偏好数据集，这些数据集覆盖有限且难以真实评估RM在开放世界设置中的泛化能力。需要一种更动态、高效的评估方法来更好地衡量RM在实际部署中的表现。

Method: 提出Pairwise Maximum Discrepancy Competition (PMDC)框架：1) 使用大型未标注开放域prompt池；2) 主动选择使两个RM产生最大分歧的prompt-response对；3) 由oracle裁决这些争议案例；4) 通过Bradley-Terry模型聚合结果，生成全局排名和成对胜率图。

Result: 应用PMDC重新评估10个代表性RM，发现与传统基准相比排名发生显著变化。定性分析进一步揭示了系统性的泛化失败模式，为改进奖励建模提供了有价值的见解。

Conclusion: PMDC提供了一种更真实评估RM泛化能力的方法，能够发现传统静态基准无法检测到的系统性缺陷，对RLHF和可信AI研究具有重要意义。

Abstract: Reward models (RMs) are central to aligning large language models, yet their practical effectiveness hinges on generalization to unseen prompts and shifting distributions. Most existing RM evaluations rely on static, pre-annotated preference datasets, which provide limited coverage and often fail to faithfully assess generalization in open-world settings. We introduce Pairwise Maximum Discrepancy Competition (PMDC), a dynamic and annotation-efficient framework for evaluating RM generalization using a large, unlabeled, open-domain prompt pool. PMDC actively selects prompt--response pairs that maximize disagreement between two RMs, yielding a compact set of highly contentious test cases. These cases are adjudicated by an oracle, and the resulting outcomes are aggregated via a Bradley--Terry model to produce a global ranking and pairwise win-rate landscape of RMs. We apply PMDC to re-evaluate 10 representative RMs and observe substantial rank reshuffling compared with conventional benchmarks. Qualitative analyses further uncover systematic generalization failures, providing valuable insights for improving reward modeling.

</details>


### [3] [Dynamic Role Assignment for Multi-Agent Debate](https://arxiv.org/abs/2601.17152)
*Miao Zhang,Junsik Kim,Siyuan Xiang,Jian Gao,Cheng Cao*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出动态角色分配框架，通过元辩论选择最适合的LLM/VLM代理担任特定角色，提升多智能体辩论系统的性能


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体LLM/VLM辩论系统虽然使用专门角色解决复杂问题，但没有根据模型的特长来分配角色。模型之间的能力差异没有被充分利用来决定哪个模型应该担任哪个角色。

Method: 提出动态角色分配框架，在实际辩论前运行元辩论来选择合适代理。元辩论分为两个阶段：(1) 提案阶段：候选模型提供针对特定角色的论证；(2) 同行评审阶段：使用数据和角色特定标准对提案进行评分，为每个位置选择最佳代理。

Result: 在LLM问题解决基准测试中，该方法在现有辩论系统基础上，相比统一分配（所有角色使用相同模型）性能提升高达74.8%，相比随机分配提升高达29.7%，具体提升幅度取决于任务和具体分配。

Conclusion: 这项工作为多智能体系统设计建立了新范式，从静态代理部署转向动态和能力感知的选择，能够更好地利用不同LLM/VLM的专业能力。

Abstract: Multi-agent large language model (LLM) and vision-language model (VLM) debate systems employ specialized roles for complex problem-solving, yet model specializations are not leveraged to decide which model should fill which role. We propose dynamic role assignment, a framework that runs a Meta-Debate to select suitable agents before the actual debate. The meta-debate has two stages: (1) proposal, where candidates provide role-tailored arguments, and (2) peer review, where proposals are scored with data and role-specific criteria to choose the best agent for each position. We evaluate our method on LLM problem solving benchmarks. Applied on top of existing debate systems, our approach consistently outperforms uniform assignments (filling all roles with the same model) by up to 74.8% and random assignments (assigning models to roles without considering their suitability) by up to 29.7%, depending on the task and the specific assignment. This work establishes a new paradigm for multi-agent system design, shifting from static agent deployment to dynamic and capability-aware selection.

</details>


### [4] [Who Gets Which Message? Auditing Demographic Bias in LLM-Generated Targeted Text](https://arxiv.org/abs/2601.17172)
*Tunazzina Islam*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文首次系统分析了LLMs在生成基于人口统计特征的目标信息时的行为，发现存在年龄和性别偏见：针对男性和年轻人的信息强调能动性、创新和自信，而针对女性和老年人的信息强调温暖、关怀和传统。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs能够大规模生成个性化、有说服力的文本，这引发了关于自动化通信中偏见和公平性的新问题。需要系统分析LLMs在生成基于人口统计特征的目标信息时如何表现，以揭示潜在的偏见模式。

Method: 提出了一个受控评估框架，使用GPT-4o、Llama-3.3和Mistral-Large 2.1三个领先模型，在两种生成设置下进行评估：独立生成（隔离内在人口统计效应）和上下文丰富生成（结合主题和区域背景模拟现实目标）。从词汇内容、语言风格和说服框架三个维度评估生成信息。

Result: 在气候通信案例中发现，所有模型都存在一致的年龄和性别不对称：针对男性和年轻人的信息强调能动性、创新和自信，而针对女性和老年人的信息强调温暖、关怀和传统。上下文提示系统性地放大了这些差异，针对年轻或男性受众的信息说服力评分显著更高。

Conclusion: 研究结果表明人口统计刻板印象如何在LLM生成的目标通信中出现并加剧，强调需要开发偏见感知的生成流程和透明的审计框架，特别是在社会敏感应用中明确考虑人口统计条件。

Abstract: Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs behave when tasked with demographic-conditioned targeted messaging. We introduce a controlled evaluation framework using three leading models -- GPT-4o, Llama-3.3, and Mistral-Large 2.1 -- across two generation settings: Standalone Generation, which isolates intrinsic demographic effects, and Context-Rich Generation, which incorporates thematic and regional context to emulate realistic targeting. We evaluate generated messages along three dimensions: lexical content, language style, and persuasive framing. We instantiate this framework on climate communication and find consistent age- and gender-based asymmetries across models: male- and youth-targeted messages emphasize agency, innovation, and assertiveness, while female- and senior-targeted messages stress warmth, care, and tradition. Contextual prompts systematically amplify these disparities, with persuasion scores significantly higher for messages tailored to younger or male audiences. Our findings demonstrate how demographic stereotypes can surface and intensify in LLM-generated targeted communication, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks that explicitly account for demographic conditioning in socially sensitive applications.

</details>


### [5] [DF-RAG: Query-Aware Diversity for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.17212)
*Saadat Hasan Khan,Spencer Hong,Jingyu Wu,Kevin Lybarger,Youbing Yin,Erin Babinsky,Daben Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: DF-RAG通过动态优化检索多样性，提升推理密集型问答性能，相比传统RAG获得4-10%的F1提升


<details>
  <summary>Details</summary>
Motivation: 传统RAG在推理密集型问答中存在局限性，因为基于余弦相似度的检索方法虽然能保证相关性，但会引入冗余内容，降低信息召回率，影响复杂推理任务的性能

Method: 基于最大边际相关性框架，在检索步骤中系统性地引入多样性，动态优化每个查询的多样性水平，无需额外微调或先验信息。关键创新是能够在测试时动态调整多样性程度

Result: 在推理密集型QA基准测试中，相比基于余弦相似度的传统RAG，F1性能提升4-10%，优于其他基线方法。估计Oracle上限比传统RAG有18%的绝对F1增益，DF-RAG能实现其中91.3%

Conclusion: 通过动态优化检索多样性，DF-RAG能有效提升推理密集型问答任务的性能，解决了传统RAG在复杂推理任务中的冗余问题

Abstract: Retrieval-augmented generation (RAG) is a common technique for grounding language model outputs in domain-specific information. However, RAG is often challenged by reasoning-intensive question-answering (QA), since common retrieval methods like cosine similarity maximize relevance at the cost of introducing redundant content, which can reduce information recall. To address this, we introduce Diversity-Focused Retrieval-Augmented Generation (DF-RAG), which systematically incorporates diversity into the retrieval step to improve performance on complex, reasoning-intensive QA benchmarks. DF-RAG builds upon the Maximal Marginal Relevance framework to select information chunks that are both relevant to the query and maximally dissimilar from each other. A key innovation of DF-RAG is its ability to optimize the level of diversity for each query dynamically at test time without requiring any additional fine-tuning or prior information. We show that DF-RAG improves F1 performance on reasoning-intensive QA benchmarks by 4-10 percent over vanilla RAG using cosine similarity and also outperforms other established baselines. Furthermore, we estimate an Oracle ceiling of up to 18 percent absolute F1 gains over vanilla RAG, of which DF-RAG captures up to 91.3 percent.

</details>


### [6] [Beyond Outcome Verification: Verifiable Process Reward Models for Structured Reasoning](https://arxiv.org/abs/2601.17223)
*Massimiliano Pronesti,Anya Belz,Yufang Hou*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了可验证过程奖励模型（VPRMs），使用确定性规则验证器检查LLM的中间推理步骤，在医学证据合成偏倚评估中显著提升推理质量。


<details>
  <summary>Details</summary>
Motivation: 现有过程监督方法依赖神经评分器评估思维链步骤，容易受到不透明性、偏见和奖励攻击的影响。需要一种能够对中间推理步骤进行确定性验证的强化学习框架。

Method: VPRMs框架使用确定性、基于规则的验证器检查LLM的中间推理步骤。应用于医学证据合成偏倚评估领域，利用指南定义的标准和基于规则的决策路径对推理轨迹进行程序化验证。

Result: VPRMs生成的推理更符合领域规则，步骤级决策与最终标签之间的一致性显著提高。相比最先进模型提升20% F1，比可验证结果奖励提升6.5%，在证据基础和逻辑一致性方面有显著优势。

Conclusion: VPRMs为LLM的过程监督提供了一种可验证的强化学习方法，特别适用于有明确规则和指南的领域，能够显著提升推理的可靠性和一致性。

Abstract: Recent work on reinforcement learning with verifiable rewards (RLVR) has shown that large language models (LLMs) can be substantially improved using outcome-level verification signals, such as unit tests for code or exact-match checks for mathematics. In parallel, process supervision has long been explored as a way to shape the intermediate reasoning behaviour of LLMs, but existing approaches rely on neural judges to score chain-of-thought steps, leaving them vulnerable to opacity, bias, and reward hacking. To address this gap, we introduce Verifiable Process Reward Models (VPRMs), a reinforcement-learning framework in which intermediate reasoning steps are checked by deterministic, rule-based verifiers. We apply VPRMs to risk-of-bias assessment for medical evidence synthesis, a domain where guideline-defined criteria and rule-based decision paths enable programmatic verification of reasoning traces. Across multiple datasets, we find that VPRMs generate reasoning that adheres closely to domain rules and achieve substantially higher coherence between step-level decisions and final labels. Results show that VPRMs achieve up to 20% higher F1 than state-of-the-art models and 6.5% higher than verifiable outcome rewards, with substantial gains in evidence grounding and logical coherence.

</details>


### [7] [Retell, Reward, Repeat: Reinforcement Learning for Narrative Theory-Informed Story Generation](https://arxiv.org/abs/2601.17226)
*David Y. Liu,Xanthe Muston,Aditya Joshi,Sebastian Sequoiah-Grayson*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文探索使用强化学习（d-RLAIF）作为监督微调的替代方案进行自动故事生成后训练，通过叙事平衡理论建立评估原则，使用LLM作为评判员提供奖励信号，生成的故事比监督微调更具多样性和人类叙事一致性。


<details>
  <summary>Details</summary>
Motivation: 自动故事生成（ASG）领域过去依赖有限的ground truth进行训练和评估，但讲故事具有主观性。本文旨在探索强化学习作为监督微调（SFT）的替代方案，以生成更符合人类叙事惯例的多样化故事。

Method: 1) 应用Todorov的叙事平衡理论建立ASG质量评估原则；2) 使用7B和14B的LLM作为评判员，测试这些原则与人类标注者的一致性，并在d-RLAIF过程中提供奖励信号；3) 使用Gemini-3-Flash评估后训练模型的输出，并与TimeTravel数据集中的人类撰写故事进行比较。

Result: d-RLAIF提供了监督微调（SFT）的可行替代方案，生成的故事更加多样化且更符合人类叙事惯例。强化学习在主观任务（如ASG）的语言基础后训练中展现出潜力。

Conclusion: 本文证明了强化学习在自动故事生成等主观任务中的有效性，通过叙事理论指导的奖励信号，可以生成比传统监督微调更优质的故事。

Abstract: Despite the subjective nature of storytelling, past works on automatic story generation (ASG) have relied on limited ground truths for training and evaluation. In this work, we explore reinforcement learning (d-RLAIF) as a post-training alternative to supervised fine-tuning (SFT). We first apply Todorov's Theory of Narrative Equilibrium to establish principles that define desirable ASG qualities. We prompt 7B and 14B LLM-as-judge models with our principles to test alignment with human annotators and provide reward signals during d-RLAIF. We use Gemini-3-Flash to evaluate the output of our post-trained models and compare them to human-written stories from the TimeTravel dataset. We show that d-RLAIF offers a viable alternative to supervised fine-tuning (SFT)--producing stories that are more diverse and aligned with human narrative conventions. Our paper demonstrates the promise of reinforcement learning for linguistically grounded post-training for subjective tasks such as ASG.

</details>


### [8] [Mind the Ambiguity: Aleatoric Uncertainty Quantification in LLMs for Safe Medical Question Answering](https://arxiv.org/abs/2601.17284)
*Yaokun Liu,Yifan Liu,Phoebe Mbuvi,Zelin Li,Ruichen Yao,Gawon Lim,Dong Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出CV-MedBench基准，用于研究医学QA中的输入模糊性问题，通过表示工程分析发现模糊性与LLM内部激活模式线性相关，并开发了AU-Probe轻量模块和"Clarify-Before-Answer"框架来提升医学QA安全性。


<details>
  <summary>Details</summary>
Motivation: 医学QA中模糊的用户查询会显著降低LLM回答准确性，带来安全风险。现有方法未能有效处理这种由输入不明确引起的不可约不确定性（aleatoric uncertainty）。

Method: 1) 构建CV-MedBench基准数据集；2) 从表示工程角度分析模糊性在LLM内部激活模式中的线性编码；3) 开发AU-Probe轻量模块，直接从隐藏状态检测输入模糊性；4) 提出"Clarify-Before-Answer"框架，在回答前主动请求用户澄清。

Result: 在四个开源LLM上的实验显示，该框架相比基线平均准确率提升9.48%，无需微调LLM或多轮前向传播，实现了高效的模糊性检测和安全增强。

Conclusion: 该工作为安全的医学QA提供了高效鲁棒的解决方案，通过AU-Probe和澄清框架增强了健康相关应用的可靠性，相关代码和数据集已开源。

Abstract: The deployment of Large Language Models in Medical Question Answering is severely hampered by ambiguous user queries, a significant safety risk that demonstrably reduces answer accuracy in high-stakes healthcare settings. In this paper, we formalize this challenge by linking input ambiguity to aleatoric uncertainty (AU), which is the irreducible uncertainty arising from underspecified input. To facilitate research in this direction, we construct CV-MedBench, the first benchmark designed for studying input ambiguity in Medical QA. Using this benchmark, we analyze AU from a representation engineering perspective, revealing that AU is linearly encoded in LLM's internal activation patterns. Leveraging this insight, we introduce a novel AU-guided "Clarify-Before-Answer" framework, which incorporates AU-Probe - a lightweight module that detects input ambiguity directly from hidden states. Unlike existing uncertainty estimation methods, AU-Probe requires neither LLM fine-tuning nor multiple forward passes, enabling an efficient mechanism to proactively request user clarification and significantly enhance safety. Extensive experiments across four open LLMs demonstrate the effectiveness of our QA framework, with an average accuracy improvement of 9.48% over baselines. Our framework provides an efficient and robust solution for safe Medical QA, strengthening the reliability of health-related applications. The code is available at https://github.com/yaokunliu/AU-Med.git, and the CV-MedBench dataset is released on Hugging Face at https://huggingface.co/datasets/yaokunl/CV-MedBench.

</details>


### [9] [Meta-Judging with Large Language Models: Concepts, Methods, and Challenges](https://arxiv.org/abs/2601.17312)
*Hugo Silva,Mateus Mendes,Hugo Gonçalo Oliveira*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文综述了LLM-as-a-Meta-Judge范式，针对传统LLM-as-a-Judge评估方法的脆弱性（如提示敏感性、系统性偏见等），提出了更稳健的元评估框架，从六个关键视角组织文献并分析其前景与挑战。


<details>
  <summary>Details</summary>
Motivation: 传统LLM-as-a-Judge评估方法存在显著脆弱性：对提示敏感、有系统性偏见、受冗长效应影响、产生不可靠或幻觉的推理。这些局限性促使研究者开发更稳健的LLM-as-a-Meta-Judge范式，以实现更稳定可信的自动化评估。

Method: 通过文献综述方法，引入一个包含六个关键视角的框架：(1)概念基础，(2)元评估机制，(3)对齐训练方法，(4)评估方法，(5)局限性与失败模式，(6)未来方向。系统分析LLM-as-a-Judge的局限性和元评估的最新进展。

Result: LLM-as-a-Meta-Judge为更稳定可信的自动化评估提供了有前景的方向，但仍面临成本、提示敏感性、共享模型偏见等挑战，需要解决这些问题以推进下一代LLM评估方法学的发展。

Conclusion: LLM-as-a-Meta-Judge是改进LLM评估的重要范式转变，通过元评估机制能够缓解传统方法的脆弱性，但需进一步解决成本效率、偏见消除和鲁棒性等问题才能实现广泛应用。

Abstract: Large language models (LLMs) are evolving fast and are now frequently used as evaluators, in a process typically referred to as LLM-as-a-Judge, which provides quality assessments of model outputs. However, recent research points out significant vulnerabilities in such evaluation, including sensitivity to prompts, systematic biases, verbosity effects, and unreliable or hallucinated rationales. These limitations motivated the development of a more robust paradigm, dubbed LLM-as-a-Meta-Judge. This survey reviews recent advances in meta-judging and organizes the literature, by introducing a framework along six key perspectives: (i) Conceptual Foundations, (ii) Mechanisms of Meta-Judging, (iii) Alignment Training Methods, (iv) Evaluation, (v) Limitations and Failure Modes, and (vi) Future Directions. By analyzing the limitations of LLM-as-a-Judge and summarizing recent advances in meta-judging by LLMs, we argue that LLM-as-a-Meta-Judge offers a promising direction for more stable and trustworthy automated evaluation, while highlighting remaining challenges related to cost, prompt sensitivity, and shared model biases, which must be addressed to advance the next generation of LLM evaluation methodologies.

</details>


### [10] [The Shadow Self: Intrinsic Value Misalignment in Large Language Model Agents](https://arxiv.org/abs/2601.17344)
*Chen Chen,Kim Young Il,Yuan Yang,Wenhao Su,Yilin Zhang,Xueluan Gong,Qian Wang,Yongsen Zheng,Ziyao Liu,Kwok-Yan Lam*

Main category: cs.CL

Relevance: 85.0

TL;DR: IMPRESS框架系统评估LLM代理在完全良性、现实场景中的内在价值错位风险，发现这是普遍存在的安全问题，现有缓解策略效果有限。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全评估主要关注对显式有害输入的响应或系统故障的鲁棒性，但在完全良性、现实的自主代理场景中，LLM可能追求偏离人类价值观的目标（内在价值错位），这一风险尚未得到充分探索。

Method: 提出IMPRESS框架：1）形式化失控风险并识别内在价值错位；2）构建包含现实、完全良性、情境化场景的基准测试；3）使用多阶段LLM生成流水线进行质量控制；4）评估21个最先进的LLM代理；5）进行人工验证。

Result: 内在价值错位是跨模型的普遍安全风险，错位率受动机、风险类型、模型规模和架构影响。解码策略和超参数影响有限，但情境化和框架机制显著影响错位行为。现有安全提示和护栏等缓解策略效果不稳定或有限。

Conclusion: IMPRESS框架填补了LLM代理在现实良性场景中内在价值错位评估的空白，揭示了这一普遍存在的安全风险，现有缓解措施不足，需要更有效的安全机制。

Abstract: Large language model (LLM) agents with extended autonomy unlock new capabilities, but also introduce heightened challenges for LLM safety. In particular, an LLM agent may pursue objectives that deviate from human values and ethical norms, a risk known as value misalignment. Existing evaluations primarily focus on responses to explicit harmful input or robustness against system failure, while value misalignment in realistic, fully benign, and agentic settings remains largely underexplored. To fill this gap, we first formalize the Loss-of-Control risk and identify the previously underexamined Intrinsic Value Misalignment (Intrinsic VM). We then introduce IMPRESS (Intrinsic Value Misalignment Probes in REalistic Scenario Set), a scenario-driven framework for systematically assessing this risk. Following our framework, we construct benchmarks composed of realistic, fully benign, and contextualized scenarios, using a multi-stage LLM generation pipeline with rigorous quality control. We evaluate Intrinsic VM on 21 state-of-the-art LLM agents and find that it is a common and broadly observed safety risk across models. Moreover, the misalignment rates vary by motives, risk types, model scales, and architectures. While decoding strategies and hyperparameters exhibit only marginal influence, contextualization and framing mechanisms significantly shape misalignment behaviors. Finally, we conduct human verification to validate our automated judgments and assess existing mitigation strategies, such as safety prompting and guardrails, which show instability or limited effectiveness. We further demonstrate key use cases of IMPRESS across the AI Ecosystem. Our code and benchmark will be publicly released upon acceptance.

</details>


### [11] [Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers](https://arxiv.org/abs/2601.17367)
*Zecheng Tang,Quantong Qiu,Yi Yang,Zhiyi Hong,Haiya Xiang,Kebin Liu,Qingqing Dang,Juntao Li,Min Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出Elastic Attention方法，通过轻量级Attention Router动态调整注意力稀疏度，解决长上下文场景中标准注意力的二次复杂度问题，实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制的二次复杂度限制了LLM在长上下文场景的可扩展性。现有的混合注意力策略使用静态计算比例，无法适应下游任务在推理时对稀疏度的不同敏感性。

Method: 提出Elastic Attention方法，在现有预训练模型中集成轻量级Attention Router，动态分配每个注意力头到不同的计算模式，使模型能根据输入动态调整整体稀疏度。

Result: 在8xA800 GPU上仅训练12小时，就能让模型同时获得强大性能和高效推理。在三个长上下文基准测试上的实验证明了该方法的优越性。

Conclusion: Elastic Attention通过动态调整注意力稀疏度，有效解决了长上下文场景中的计算效率问题，为LLM的高效推理提供了实用解决方案。

Abstract: The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.

</details>


### [12] [CLM-Bench: Benchmarking and Analyzing Cross-lingual Misalignment of LLMs in Knowledge Editing](https://arxiv.org/abs/2601.17397)
*Yucheng Hu,Wei Zhou,Juesi Xiao*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文提出了CLM-Bench，一个文化感知的中文优先多语言知识编辑基准，揭示了跨语言编辑中的显著不对齐现象：单语言编辑无法传播到另一种语言，编辑向量在表示空间中几乎正交。


<details>
  <summary>Details</summary>
Motivation: 现有MKE基准通常通过机械翻译英语中心数据集构建，这引入了翻译伪影并忽略了目标语言的文化特定实体，无法反映LLMs的真实知识分布。需要文化感知的基准来准确评估多语言知识编辑。

Method: 提出CLM-Bench，采用中文优先方法构建文化感知基准，包含1,010个基于中文文化背景的高质量CounterFact对，并与英语对应物对齐。使用该基准在代表性LLMs（如Llama-3、Qwen2）上进行实验，并通过层表示分析提供几何解释。

Result: 实验揭示了显著的跨语言不对齐：单语言编辑独立运行且无法传播到另一种语言。几何分析显示中文和英语编辑向量几乎正交，存在于不相交的子空间中，而混合语言编辑则表现出这些向量的线性可加性。

Conclusion: 当前方法在跨语言迁移方面效果有限，强调了文化原生基准的重要性。跨语言知识编辑需要更深入的理解和新的方法来解决表示空间中的不对齐问题。

Abstract: Knowledge Editing (KE) has emerged as a promising paradigm for updating facts in Large Language Models (LLMs) without retraining. However, progress in Multilingual Knowledge Editing (MKE) is currently hindered by biased evaluation frameworks. We observe that existing MKE benchmarks are typically constructed by mechanically translating English-centric datasets into target languages (e.g., English-to-Chinese). This approach introduces translation artifacts and neglects culturally specific entities native to the target language, failing to reflect the true knowledge distribution of LLMs. To address this, we propose CLM-Bench, a culture-aware benchmark constructed using a native Chinese-first methodology. We curate 1,010 high-quality CounterFact pairs rooted in Chinese cultural contexts and align them with English counterparts. Using CLM-Bench, we conduct extensive experiments on representative LLMs (e.g., Llama-3, Qwen2) and reveal a significant Cross-lingual Misalignment: edits in one language function independently and fail to propagate to the other. We further provide a geometric explanation via layer-wise representation analysis, demonstrating that edit vectors for Chinese and English are nearly orthogonal -- residing in disjoint subspaces -- while mixed-lingual editing exhibits linear additivity of these vectors. Our findings challenge the effectiveness of current methods in cross-lingual transfer and underscore the importance of culturally native benchmarks.

</details>


### [13] [Oops, Wait: Token-Level Signals as a Lens into LLM Reasoning](https://arxiv.org/abs/2601.17421)
*Jaehui Hwang,Dongyoon Han,Sangdoo Yun,Byeongho Heo*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文系统分析了LLM中"wait"、"therefore"等话语标记token的概率信号，发现这些信号与推理正确性高度相关，且在不同模型规模下保持稳定，但受训练策略影响较大。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中出现的"wait"、"therefore"等话语标记token为理解其推理过程提供了独特窗口，但目前缺乏对这些信号如何随训练策略和模型规模变化的系统性分析。

Method: 通过分析不同模型在各种任务中的token级概率信号，特别是"wait"等话语标记token的概率变化，研究这些信号与推理正确性的相关性。

Result: 发现特定token与推理正确性高度相关，这些相关性在不同模型规模下保持稳定，但受训练策略影响；在小规模数据集上微调的模型通过此类信号获得推理能力，但仅部分利用这些信号。

Conclusion: 该研究为观察和理解LLM推理动态提供了系统性视角，话语标记token的分析可作为理解模型内部推理过程的有效工具。

Abstract: The emergence of discourse-like tokens such as "wait" and "therefore" in large language models (LLMs) has offered a unique window into their reasoning processes. However, systematic analyses of how such signals vary across training strategies and model scales remain lacking. In this paper, we analyze token-level signals through token probabilities across various models. We find that specific tokens strongly correlate with reasoning correctness, varying with training strategies while remaining stable across model scales. A closer look at the "wait" token in relation to answer probability demonstrates that models fine-tuned on small-scale datasets acquire reasoning ability through such signals but exploit them only partially. This work provides a systematic lens to observe and understand the dynamics of LLM reasoning.

</details>


### [14] [Clustering-driven Memory Compression for On-device Large Language Models](https://arxiv.org/abs/2601.17443)
*Ondrej Bohdal,Pramit Saha,Umberto Michieli,Mete Ozay,Taha Ceritli*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出基于聚类的记忆压缩策略，通过相似性分组和合并来平衡上下文效率与个性化质量，在减少记忆token的同时提升生成质量


<details>
  <summary>Details</summary>
Motivation: 现有LLM个性化方法通常将用户记忆与输入提示拼接，但这会快速耗尽设备端LLM有限的上下文窗口。简单的记忆平均压缩会因语义冲突而损害性能，需要一种能平衡上下文效率与个性化质量的记忆压缩方法。

Method: 基于聚类的记忆压缩策略：1) 按相似性对记忆进行分组；2) 在聚类内部合并记忆；3) 将压缩后的记忆与输入提示拼接。这种方法在减少冗余的同时保持了记忆的连贯性。

Result: 实验表明该方法显著减少了记忆token数量，同时性能优于基线策略（如简单平均或直接拼接）。在固定上下文预算下，聚类驱动的合并产生了更紧凑的记忆表示，并持续提升了生成质量。

Conclusion: 基于聚类的记忆压缩策略有效解决了设备端LLM个性化中的上下文限制问题，在保持个性化质量的同时提高了上下文效率，为资源受限环境下的个性化LLM应用提供了实用解决方案。

Abstract: Large language models (LLMs) often rely on user-specific memories distilled from past interactions to enable personalized generation. A common practice is to concatenate these memories with the input prompt, but this approach quickly exhausts the limited context available in on-device LLMs. Compressing memories by averaging can mitigate context growth, yet it frequently harms performance due to semantic conflicts across heterogeneous memories. In this work, we introduce a clustering-based memory compression strategy that balances context efficiency and personalization quality. Our method groups memories by similarity and merges them within clusters prior to concatenation, thereby preserving coherence while reducing redundancy. Experiments demonstrate that our approach substantially lowers the number of memory tokens while outperforming baseline strategies such as naive averaging or direct concatenation. Furthermore, for a fixed context budget, clustering-driven merging yields more compact memory representations and consistently enhances generation quality.

</details>


### [15] [Less is More for RAG: Information Gain Pruning for Generator-Aligned Reranking and Evidence Selection](https://arxiv.org/abs/2601.17532)
*Zhipeng Song,Yizhi Zhou,Xiangyu Kong,Jiulong Jiao,Xinrui Bao,Xu You,Xueqing Shi,Yuhang Zhou,Heng Qi*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文提出信息增益剪枝（IGP）方法，用于检索增强生成（RAG）中的证据选择，通过生成器对齐的效用信号筛选检索到的段落，在有限上下文预算下优化质量-成本权衡。


<details>
  <summary>Details</summary>
Motivation: 在检索增强生成（RAG）中，检索相关性指标（如NDCG）与端到端QA质量相关性较弱，在多段落注入时甚至可能负相关，冗余和轻微冲突会破坏生成的稳定性。现有方法在有限上下文预算下难以有效选择应注入的检索段落。

Method: 提出信息增益剪枝（IGP），一个部署友好的重排序和剪枝模块：1）使用生成器对齐的效用信号评估检索段落的价值；2）在截断前过滤弱或有害的段落；3）不改变现有预算接口，保持与现有系统的兼容性。

Result: 在五个开放域QA基准测试和多种检索器-生成器组合中，IGP持续改进质量-成本权衡。在多证据设置下，相比仅使用检索器的基线，IGP带来约12-20%的相对F1分数提升，同时减少约76-79%的最终阶段输入token。

Conclusion: IGP通过生成器对齐的证据选择机制，有效解决了RAG中检索相关性指标与生成质量不匹配的问题，在有限上下文预算下显著提升了检索增强生成的效率和效果。

Abstract: Retrieval-augmented generation (RAG) grounds large language models with external evidence, but under a limited context budget, the key challenge is deciding which retrieved passages should be injected. We show that retrieval relevance metrics (e.g., NDCG) correlate weakly with end-to-end QA quality and can even become negatively correlated under multi-passage injection, where redundancy and mild conflicts destabilize generation. We propose \textbf{Information Gain Pruning (IGP)}, a deployment-friendly reranking-and-pruning module that selects evidence using a generator-aligned utility signal and filters weak or harmful passages before truncation, without changing existing budget interfaces. Across five open-domain QA benchmarks and multiple retrievers and generators, IGP consistently improves the quality--cost trade-off. In a representative multi-evidence setting, IGP delivers about +12--20% relative improvement in average F1 while reducing final-stage input tokens by roughly 76--79% compared to retriever-only baselines.

</details>


### [16] [Improving User Privacy in Personalized Generation: Client-Side Retrieval-Augmented Modification of Server-Side Generated Speculations](https://arxiv.org/abs/2601.17569)
*Alireza Salemi,Hamed Zamani*

Main category: cs.CL

Relevance: 85.0

TL;DR: P³是一个保护隐私的个性化LLM框架，通过服务器大模型生成草稿token，客户端小模型结合用户私有资料进行修改，实现高质量个性化同时保护隐私


<details>
  <summary>Details</summary>
Motivation: 当前基于检索增强的个性化方法面临隐私泄露风险（将用户私有资料暴露给云端LLM）与本地模型能力不足的权衡问题。需要一种既能保护隐私又能提供高质量个性化的解决方案。

Method: P³采用交互式框架：服务器端大模型仅基于用户查询生成k个草稿token；客户端小模型结合用户私有资料检索，评估并修改这些草稿以更好地反映用户偏好；这个过程重复直到生成结束token。

Result: 在LaMP-QA基准测试中，P³比非个性化服务器端和个性化客户端基线平均提升7.4%-9%，恢复"泄露"上限场景（完整资料暴露给服务器）90.3%-95.7%的效用。隐私分析显示仅增加1.5%-3.5%的泄露风险，客户端模型仅生成总token的9.2%。

Conclusion: P³提供了一个实用有效的个性化生成解决方案，在保护隐私的同时实现了高质量的个性化，适合边缘部署。

Abstract: Personalization is crucial for aligning Large Language Model (LLM) outputs with individual user preferences and background knowledge. State-of-the-art solutions are based on retrieval augmentation, where relevant context from a user profile is retrieved for LLM consumption. These methods deal with a trade-off between exposing retrieved private data to cloud providers and relying on less capable local models. We introduce $P^3$, an interactive framework for high-quality personalization without revealing private profiles to server-side LLMs. In $P^3$, a large server-side model generates a sequence of $k$ draft tokens based solely on the user query, while a small client-side model, with retrieval access to the user's private profile, evaluates and modifies these drafts to better reflect user preferences. This process repeats until an end token is generated. Experiments on LaMP-QA, a recent benchmark consisting of three personalized question answering datasets, show that $P^3$ consistently outperforms both non-personalized server-side and personalized client-side baselines, achieving statistically significant improvements of $7.4%$ to $9%$ on average. Importantly, $P^3$ recovers $90.3%$ to $95.7%$ of the utility of a ``leaky'' upper-bound scenario in which the full profile is exposed to the large server-side model. Privacy analyses, including linkability and attribute inference attacks, indicate that $P^3$ preserves the privacy of a non-personalized server-side model, introducing only marginal additional leakage ($1.5%$--$3.5%$) compared to submitting a query without any personal context. Additionally, the framework is efficient for edge deployment, with the client-side model generating only $9.2%$ of the total tokens. These results demonstrate that $P^3$ provides a practical, effective solution for personalized generation with improved privacy.

</details>


### [17] [Sequence Repetition Enhances Token Embeddings and Improves Sequence Labeling with Decoder-only Language Models](https://arxiv.org/abs/2601.17585)
*Matija Luka Kukić,Marko Čuljak,David Dukić,Martin Tutek,Jan Šnajder*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出序列重复方法使仅解码器模型具备双向性，用于序列标注任务，无需移除因果掩码，提升词元级表示质量


<details>
  <summary>Details</summary>
Motivation: 现代语言模型采用自回归训练仅依赖前缀，而序列标注任务需要双向上下文。传统上序列标注依赖双向编码器模型，但解码器模型快速发展引发能否适应序列标注的问题。移除因果掩码虽可行但需大幅修改模型，需要更少侵入性的替代方案。

Method: 提出序列重复方法：通过重复输入序列使解码器模型具备双向性。通过微调实验验证该方法，比较编码器、未掩码解码器和序列重复方法，分析重复次数对性能的影响，并探索中间层嵌入的有效性。

Result: 序列重复使解码器具备双向性，提升词元级嵌入质量，超越编码器和未掩码解码器。增加重复次数不会降低序列标注性能。中间层嵌入与最终层嵌入效果相当但计算效率更高。

Conclusion: 序列重复缓解了解码器的结构限制，使语言模型更高效、适应性更强，拓宽了在词元级任务中的应用范围。

Abstract: Modern language models (LMs) are trained in an autoregressive manner, conditioned only on the prefix. In contrast, sequence labeling (SL) tasks assign labels to each individual input token, naturally benefiting from bidirectional context. This discrepancy has historically led SL to rely on inherently bidirectional encoder-only models. However, the rapid development of decoder-only models has raised the question of whether they can be adapted to SL. While causal mask removal has emerged as a viable technique for adapting decoder-only models to leverage the full context for SL, it requires considerable changes to the base model functionality. In this work, we explore sequence repetition (SR) as a less invasive alternative for enabling bidirectionality in decoder-only models. Through fine-tuning experiments, we show that SR inherently makes decoders bidirectional, improving the quality of token-level embeddings and surpassing encoders and unmasked decoders. Contrary to earlier claims, we find that increasing the number of repetitions does not degrade SL performance. Finally, we demonstrate that embeddings from intermediate layers are highly effective for SR, comparable to those from final layers, while being significantly more efficient to compute. Our findings underscore that SR alleviates the structural limitations of decoders, enabling more efficient and adaptable LMs and broadening their applicability to other token-level tasks.

</details>


### [18] [From Chains to DAGs: Probing the Graph Structure of Reasoning in LLMs](https://arxiv.org/abs/2601.17593)
*Tianjun Zhong,Linyang He,Nima Mesgarani*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出Reasoning DAG Probing框架，探究LLM隐藏状态是否线性可访问地编码推理DAG的几何结构，并分析该结构在不同层级的涌现情况。


<details>
  <summary>Details</summary>
Motivation: 现有研究多将推理视为线性链式步骤，但许多推理问题更自然地表示为有向无环图(DAGs)，其中中间结论可能依赖多个前提、分支为并行子推导、后续合并或重用。理解模型内部是否反映这种图结构推理仍是一个开放问题。

Method: 引入Reasoning DAG Probing框架，将每个推理节点与文本实现关联，训练轻量级探针从隐藏状态预测两个图论属性：节点深度和节点对距离。分析DAG结构在层级间的涌现，并评估破坏推理相关结构但保留表面文本属性的控制实验。

Result: 结果表明推理DAG几何结构在中间层有意义的编码，可恢复性随节点深度和模型规模系统性变化，表明LLM推理不仅是顺序的，而且表现出可测量的内部图结构。

Conclusion: LLM推理具有可测量的内部图结构，Reasoning DAG Probing框架为理解模型如何表示复杂推理提供了新视角，对可解释性和分析研究有重要意义。

Abstract: Recent progress in large language models has renewed interest in mechanistically characterizing how multi-step reasoning is represented and computed. While much prior work treats reasoning as a linear chain of steps, many reasoning problems are more naturally structured as directed acyclic graphs (DAGs), where intermediate conclusions may depend on multiple premises, branch into parallel sub-derivations, and later merge or be reused. Understanding whether such graph-structured reasoning is reflected in model internals remains an open question.
  In this work, we introduce Reasoning DAG Probing, a framework that directly asks whether LLM hidden states encode the geometry of a reasoning DAG in a linearly accessible form, and where this structure emerges across layers. Within this framework, we associate each reasoning node with a textual realization and train lightweight probes to predict two graph-theoretic properties from hidden states: node depth and pairwise node distance. We use these probes to analyze the layerwise emergence of DAG structure and evaluate controls that disrupt reasoning-relevant structure while preserving superficial textual properties. Our results provide evidence that reasoning DAG geometry is meaningfully encoded in intermediate layers, with recoverability varying systematically by node depth and model scale, suggesting that LLM reasoning is not only sequential but exhibits measurable internal graph structure.

</details>


### [19] [Align to the Pivot: Dual Alignment with Self-Feedback for Multilingual Math Reasoning](https://arxiv.org/abs/2601.17671)
*Chunxu Zhao,Xin Huang,Xue Han,Shujian Huang,Chao Deng,Junlan Feng*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出PASMR方法，通过以主要语言为枢纽进行跨语言自反馈，改善LLMs在多语言数学推理中的能力对齐问题


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs展现出强大的推理能力，但实证研究表明它们并非语言无关的，在多语言环境下（尤其是低资源语言）性能会下降。作者将这种下降归因于模型在多语言理解和推理对齐方面存在不一致性。

Method: 提出Pivot-Aligned Self-Feedback Multilingual Reasoning (PASMR)方法：1) 将模型的主要语言设为枢纽语言；2) 训练时先将问题翻译到枢纽语言以促进推理模式对齐；3) 目标语言的推理过程由枢纽语言的推理答案监督；4) 建立跨语言自反馈机制，无需依赖外部正确答案或奖励模型。

Result: 广泛的实验结果表明，该方法显著提升了模型对问题的理解和推理能力，带来了明显的任务改进。

Conclusion: PASMR方法通过跨语言自反馈机制有效解决了LLMs在多语言数学推理中的能力对齐问题，改善了模型在多语言环境下的性能表现。

Abstract: Despite the impressive reasoning abilities demonstrated by large language models (LLMs), empirical evidence indicates that they are not language agnostic as expected, leading to performance declines in multilingual settings, especially for low-resource languages. We attribute the decline to the model's inconsistent multilingual understanding and reasoning alignment. To address this, we present Pivot-Aligned Self-Feedback Multilingual Reasoning (PASMR), aiming to improve the alignment of multilingual math reasoning abilities in LLMs. This approach designates the model's primary language as the pivot language. During training, the model first translates questions into the pivot language to facilitate better alignment of reasoning patterns. The reasoning process in the target language is then supervised by the pivot language's reasoning answers, thereby establishing a cross-lingual self-feedback mechanism without relying on external correct answers or reward models. Extensive experimental results demonstrate that our method enhances both the model's understanding of questions and its reasoning capabilities, leading to notable task improvements.

</details>


### [20] [S$^3$-Attention:Attention-Aligned Endogenous Retrieval for Memory-Bounded Long-Context Inference](https://arxiv.org/abs/2601.17702)
*Qingsen Ma,Dianyun Wang,Yaoye Wang,Lechen Ning,Sujie Zhu,Xiaohang Zhang,Jiaming Lyu,Linhao Ren,Zhenbo Xu,Zhaofeng He*

Main category: cs.CL

Relevance: 85.0

TL;DR: S3-Attention是一种内存优先的推理时框架，通过注意力对齐的内生检索处理长上下文，完全丢弃KV缓存，使用稀疏自编码器和CPU倒排索引来降低GPU内存使用。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在处理多文档和长格式输入时面临内存效率低下和噪声问题。KV缓存随上下文长度线性增长，而外部检索方法经常返回词汇相似但因果无关的段落。

Method: S3-Attention将长上下文处理视为注意力对齐的内生检索。使用轻量级稀疏自编码器将瞬态键值投影解码为top-k稀疏特征标识符，在单次流式扫描中构建CPU倒排索引，将特征映射到token位置或跨度。生成时使用特征共激活检索紧凑证据跨度，可选与BM25融合进行精确词汇匹配。

Result: 在统一的LongBench评估协议下，S3-Hybrid在多个模型系列中与全上下文推理结果接近，并在多个信息密集场景中提高了鲁棒性。但当前原型存在较高的wall-clock延迟。

Conclusion: S3-Attention提供了一种内存高效的替代方案，完全消除了KV缓存，但需要未来内核级优化来减少延迟。该方法在长上下文处理中展现了有前景的效率和鲁棒性平衡。

Abstract: Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages.
  We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size.
  At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.

</details>


### [21] [Unsupervised Elicitation of Moral Values from Language Models](https://arxiv.org/abs/2601.17728)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种无监督方法ICM来激发预训练语言模型的内在道德推理能力，无需人工监督即可获得与人类标注相当的性能，并能显著减少社会偏见。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统普及，将其行为与人类价值观对齐变得至关重要。现有研究表明语言模型的内在道德推理能力有限，但构建道德评估的真实数据又面临多元道德框架和普遍偏见的挑战。因此，研究者探索无监督激发方法，检验预训练模型是否具备无需人工监督即可激发的内在道德推理能力。

Method: 提出Internal Coherence Maximization (ICM)算法，在三个基准数据集(Norm Bank, ETHICS等)和四个语言模型上进行测试。ICM通过最大化模型内部一致性来无监督地标注道德判断，并评估其在多个道德框架下的泛化能力和偏见缓解效果。

Result: ICM在所有预训练和聊天机器人基线上表现最优，在Norm Bank和ETHICS基准上超越所有基线。使用ICM标签进行微调的模型性能与人类标签相当甚至更好。在正义和常识道德框架上ICM相对提升最大。ICM将社会偏见错误率降低一半以上，在种族、社会经济地位和政治方面的改进最为显著。

Conclusion: 预训练语言模型具备潜在的道德推理能力，可以通过ICM等无监督方法激发，这为AI对齐提供了一条可扩展的路径。该方法无需人工监督即可获得高质量道德判断，并能有效减少社会偏见。

Abstract: As AI systems become pervasive, grounding their behavior in human values is critical. Prior work suggests that language models (LMs) exhibit limited inherent moral reasoning, leading to calls for explicit moral teaching. However, constructing ground truth data for moral evaluation is difficult given plural frameworks and pervasive biases. We investigate unsupervised elicitation as an alternative, asking whether pretrained (base) LMs possess intrinsic moral reasoning capability that can be surfaced without human supervision. Using the Internal Coherence Maximization (ICM) algorithm across three benchmark datasets and four LMs, we test whether ICM can reliably label moral judgments, generalize across moral frameworks, and mitigate social bias. Results show that ICM outperforms all pre-trained and chatbot baselines on the Norm Bank and ETHICS benchmarks, while fine-tuning on ICM labels performs on par with or surpasses those of human labels. Across theoretically motivated moral frameworks, ICM yields its largest relative gains on Justice and Commonsense morality. Furthermore, although chatbot LMs exhibit social bias failure rates comparable to their pretrained ones, ICM reduces such errors by more than half, with the largest improvements in race, socioeconomic status, and politics. These findings suggest that pretrained LMs possess latent moral reasoning capacities that can be elicited through unsupervised methods like ICM, providing a scalable path for AI alignment.

</details>


### [22] [ProGraph-R1: Progress-aware Reinforcement Learning for Graph Retrieval Augmented Generation](https://arxiv.org/abs/2601.17755)
*Jinyoung Park,Sanghyeok Lee,Omar Zia Khan,Hyunwoo J. Kim,Joo-Kyung Kim*

Main category: cs.CL

Relevance: 85.0

TL;DR: ProGraph-R1提出了一种基于进度感知的图检索增强生成框架，通过结构感知的超图检索机制和基于进度的逐步策略优化，解决了现有RL-based GraphRAG方法在检索和奖励机制上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的GraphRAG框架（如Graph-R1）存在两个关键限制：1）主要依赖语义相似性进行检索，忽视了底层图结构；2）依赖稀疏的结果级奖励，无法捕捉中间检索步骤的质量和依赖关系。需要设计更有效的图感知检索机制和密集学习信号。

Method: 提出ProGraph-R1框架：1）结构感知的超图检索机制，联合考虑语义相关性和图连通性，鼓励沿着多跳推理路径进行连贯遍历；2）基于进度的逐步策略优化，通过根据图中中间推理进度调节优势来提供密集学习信号，而不是仅依赖最终结果。

Result: 在多跳问答基准测试中，ProGraph-R1在推理准确性和生成质量方面持续优于现有的GraphRAG方法。

Conclusion: ProGraph-R1通过结合结构感知检索和基于进度的强化学习，显著提升了图检索增强生成系统的性能，为知识密集型问答任务提供了更有效的多步推理框架。

Abstract: Graph Retrieval-Augmented Generation (GraphRAG) has been successfully applied in various knowledge-intensive question answering tasks by organizing external knowledge into structured graphs of entities and relations. It enables large language models (LLMs) to perform complex reasoning beyond text-chunk retrieval. Recent works have employed reinforcement learning (RL) to train agentic GraphRAG frameworks that perform iterative interactions between LLMs and knowledge graphs. However, existing RL-based frameworks such as Graph-R1 suffer from two key limitations: (1) they primarily depend on semantic similarity for retrieval, often overlooking the underlying graph structure, and (2) they rely on sparse, outcome-level rewards, failing to capture the quality of intermediate retrieval steps and their dependencies. To address these limitations, we propose ProGraph-R1, a progress-aware agentic framework for graph-based retrieval and multi-step reasoning. ProGraph-R1 introduces a structure-aware hypergraph retrieval mechanism that jointly considers semantic relevance and graph connectivity, encouraging coherent traversal along multi-hop reasoning paths. We also design a progress-based step-wise policy optimization, which provides dense learning signals by modulating advantages according to intermediate reasoning progress within a graph, rather than relying solely on final outcomes. Experiments on multi-hop question answering benchmarks demonstrate that ProGraph-R1 consistently improves reasoning accuracy and generation quality over existing GraphRAG methods.

</details>


### [23] [Cross-Lingual Probing and Community-Grounded Analysis of Gender Bias in Low-Resource Bengali](https://arxiv.org/abs/2601.17764)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Jui Saha Pritha,Abdullah Al Noman,Abir Ahmed,Golam Md Mohiuddin,Tze Hui Liew*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究分析了孟加拉语中的性别偏见特征，发现英语中心的偏见检测框架在孟加拉语中效果有限，需要本地化和社区驱动的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在非英语语言（如孟加拉语）中的内在性别偏见问题研究不足，现有英语中心的偏见检测框架难以捕捉语言差异和社会文化因素导致的隐性偏见。

Method: 采用多种方法提取性别偏见话语：基于词典的挖掘、计算分类模型、翻译对比分析、GPT偏见生成，并在农村和低收入地区进行实地调查收集真实见解。

Result: 孟加拉语的性别偏见具有与英语不同的独特特征，英语中心框架的应用受到语言差异和社会文化因素严重限制，需要更本地化和上下文敏感的方法。

Conclusion: 需要为代表性不足的语言开发专门的偏见检测工具，采用社区驱动的研究方法识别文化相关偏见，为孟加拉语和其他印度语言建立更包容公平的NLP系统奠定基础。

Abstract: Large Language Models (LLMs) have achieved significant success in recent years; yet, issues of intrinsic gender bias persist, especially in non-English languages. Although current research mostly emphasizes English, the linguistic and cultural biases inherent in Global South languages, like Bengali, are little examined. This research seeks to examine the characteristics and magnitude of gender bias in Bengali, evaluating the efficacy of current approaches in identifying and alleviating bias. We use several methods to extract gender-biased utterances, including lexicon-based mining, computational classification models, translation-based comparison analysis, and GPT-based bias creation. Our research indicates that the straight application of English-centric bias detection frameworks to Bengali is severely constrained by language disparities and socio-cultural factors that impact implicit biases. To tackle these difficulties, we executed two field investigations inside rural and low-income areas, gathering authentic insights on gender bias. The findings demonstrate that gender bias in Bengali presents distinct characteristics relative to English, requiring a more localized and context-sensitive methodology. Additionally, our research emphasizes the need of integrating community-driven research approaches to identify culturally relevant biases often neglected by automated systems. Our research enhances the ongoing discussion around gender bias in AI by illustrating the need to create linguistic tools specifically designed for underrepresented languages. This study establishes a foundation for further investigations into bias reduction in Bengali and other Indic languages, promoting the development of more inclusive and fair NLP systems.

</details>


### [24] [DPI: Exploiting Parameter Heterogeneity for Interference-Free Fine-Tuning](https://arxiv.org/abs/2601.17777)
*Xiaoyu Liu,Xiaoyu Guan,Di Liang,Xianjie Wu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出动态参数隔离策略解决SFT中的跷跷板效应：通过识别任务核心参数区域，合并重叠任务联合训练，分离不相交任务分阶段训练，并冻结先前任务核心参数防止覆盖。


<details>
  <summary>Details</summary>
Motivation: 解决监督微调中的"跷跷板效应"问题——在异构SFT任务中，优化一个任务可能损害其他任务性能，这是由于参数异质性导致的跨任务干扰。

Method: 1) 独立微调LLMs识别各任务核心参数区域（更新最大的参数子集）；2) 合并高度重叠核心参数区域的任务进行联合训练；3) 分离不相交任务分阶段训练；4) 多阶段SFT中冻结先前任务获取的核心参数。

Result: 在多个公开数据集上的实验表明，动态参数隔离策略能持续减少数据冲突，相比多阶段和多任务调优基线实现了一致的性能提升。

Conclusion: 通过参数异质性假设和动态参数隔离策略，有效解决了SFT中的跷跷板效应，为多任务微调提供了新思路。

Abstract: Supervised fine-tuning (SFT) is a crucial step for adapting large language models (LLMs) to downstream tasks. However, conflicting objectives across heterogeneous SFT tasks often induce the "seesaw effect": optimizing for one task may degrade performance on others, particularly when model parameters are updated indiscriminately. In this paper, we propose a principled approach to disentangle and isolate task-specific parameter regions, motivated by the hypothesis that parameter heterogeneity underlies cross-task interference. Specifically, we first independently fine-tune LLMs on diverse SFT tasks and identify each task's core parameter region as the subset of parameters exhibiting the largest updates. Tasks with highly overlapping core parameter regions are merged for joint training, while disjoint tasks are organized into different stages. During multi-stage SFT, core parameters acquired in prior tasks are frozen, thereby preventing overwriting by subsequent tasks. To verify the effectiveness of our method, we conducted intensive experiments on multiple public datasets. The results showed that our dynamic parameter isolation strategy consistently reduced data conflicts and achieved consistent performance improvements compared to multi-stage and multi-task tuning baselines.

</details>


### [25] [D-Models and E-Models: Diversity-Stability Trade-offs in the Sampling Behavior of Large Language Models](https://arxiv.org/abs/2601.17865)
*Jia Gu,Liang Pang,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现LLMs在细粒度采样概率上存在两种类型：D-models（如Qwen-2.5）的token级概率变化大且与任务分布对齐差；E-models（如Mistral-Small）的概率更稳定且与任务分布对齐更好，揭示了多样性与稳定性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: LLMs的token预测概率与任务级目标分布（如下一个信息的相关性概率、产品购买概率、行动执行概率）密切相关。虽然LLMs能生成近似真实世界分布的样本，但其细粒度采样概率是否忠实对齐任务需求仍是一个开放问题。

Method: 通过受控分布采样模拟，识别出两种模型类型：D-models和E-models。在代码生成和推荐等下游任务中评估这两种类型，分析它们内部属性以探究底层机制。

Result: 发现LLMs存在显著二分行为：D-models的P_token具有大的步间变异性且与P_task对齐差；E-models的P_token更稳定且与P_task对齐更好。下游任务评估揭示了多样性与稳定性之间的系统权衡。

Conclusion: 这些发现提供了关于LLMs概率采样行为的基础性见解，并为何时选择D-models或E-models提供了实用指导。对于推荐、搜索和对话代理等网络规模应用，研究结果可指导模型选择和配置，在现实世界不确定性下平衡多样性与可靠性。

Abstract: The predictive probability of the next token (P_token) in large language models (LLMs) is inextricably linked to the probability of relevance for the next piece of information, the purchase probability of the next product, and the execution probability of the next action-all of which fall under the scope of the task-level target distribution (P_task). While LLMs are known to generate samples that approximate real-world distributions, whether their fine-grained sampling probabilities faithfully align with task requirements remains an open question. Through controlled distribution-sampling simulations, we uncover a striking dichotomy in LLM behavior, distinguishing two model types: D-models (e.g. Qwen-2.5), whose P_token exhibits large step-to-step variability and poor alignment with P_task; and E-models (e.g. Mistral-Small), whose P_token is more stable and better aligned with P_task. We further evaluate these two model types in downstream tasks such as code generation and recommendation, revealing systematic trade-offs between diversity and stability that shape task outcomes. Finally, we analyze the internal properties of both model families to probe their underlying mechanisms. These findings offer foundational insights into the probabilistic sampling behavior of LLMs and provide practical guidance on when to favor D- versus E-models. For web-scale applications, including recommendation, search, and conversational agents, our results inform model selection and configuration to balance diversity with reliability under real-world uncertainty, providing a better level of interpretation.

</details>


### [26] [Assessment of Generative Named Entity Recognition in the Era of Large Language Models](https://arxiv.org/abs/2601.17898)
*Qi Zhan,Yile Wang,Hui Huang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文系统评估了开源大语言模型在平面和嵌套命名实体识别任务上的表现，发现通过参数高效微调和结构化输出格式，LLMs能达到与传统编码器模型竞争的性能，且其NER能力源于指令遵循和生成能力而非记忆，NER指令微调对LLMs通用能力影响很小。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的兴起，命名实体识别正从序列标注任务演变为生成范式。作者旨在系统评估开源LLMs在平面和嵌套NER任务上的表现，探究生成式NER与传统NER模型的性能差距、输出格式影响、LLMs是否依赖记忆、以及微调后通用能力的保持情况。

Method: 在8个不同规模的LLMs和4个标准NER数据集上进行实验，采用参数高效微调（如LoRA）和结构化输出格式（如内联括号或XML格式），比较生成式NER与传统编码器模型的性能，并分析LLMs的NER能力来源。

Result: 1) 通过参数高效微调和结构化格式，开源LLMs达到与传统编码器模型竞争的性能，甚至超越GPT-3等闭源模型；2) LLMs的NER能力源于指令遵循和生成能力，而非简单的实体-标签对记忆；3) NER指令微调对LLMs通用能力影响很小，在某些数据集（如DROP）上甚至因增强实体理解而提升性能。

Conclusion: 基于LLMs的生成式NER是传统方法的有前景且用户友好的替代方案，展示了LLMs在信息抽取任务中的潜力。

Abstract: Named entity recognition (NER) is evolving from a sequence labeling task into a generative paradigm with the rise of large language models (LLMs). We conduct a systematic evaluation of open-source LLMs on both flat and nested NER tasks. We investigate several research questions including the performance gap between generative NER and traditional NER models, the impact of output formats, whether LLMs rely on memorization, and the preservation of general capabilities after fine-tuning. Through experiments across eight LLMs of varying scales and four standard NER datasets, we find that: (1) With parameter-efficient fine-tuning and structured formats like inline bracketed or XML, open-source LLMs achieve performance competitive with traditional encoder-based models and surpass closed-source LLMs like GPT-3; (2) The NER capability of LLMs stems from instruction-following and generative power, not mere memorization of entity-label pairs; and (3) Applying NER instruction tuning has minimal impact on general capabilities of LLMs, even improving performance on datasets like DROP due to enhanced entity understanding. These findings demonstrate that generative NER with LLMs is a promising, user-friendly alternative to traditional methods. We release the data and code at https://github.com/szu-tera/LLMs4NER.

</details>


### [27] [ShapLoRA: Allocation of Low-rank Adaption on Large Language Models via Shapley Value Inspired Importance Estimation](https://arxiv.org/abs/2601.17921)
*Yi Zhao,Qinghua Yao,Xinyuan song,Wei Zhu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出ShapLoRA框架，利用Shapley值改进LoRA的秩分配方法，通过更可解释的重要性度量提升参数高效微调性能


<details>
  <summary>Details</summary>
Motivation: 现有LoRA秩分配方法依赖于不可解释且不可靠的重要性度量，限制了参数高效微调的性能提升。需要更可解释的重要性度量来优化LoRA秩的分配策略。

Method: 结合Shapley值和基于敏感性的度量，提出Shapley敏感性作为更可解释的重要性度量。优化工作流程：在单独验证集上计算Shapley敏感性，建立分配-重训练流程进行公平比较。

Result: 在各种挑战性任务上的实验结果表明，ShapLoRA方法在可调参数数量相当的情况下，能够超越最近的基线方法。

Conclusion: ShapLoRA框架通过引入可解释的Shapley敏感性度量，改进了LoRA的秩分配方法，为参数高效微调提供了更可靠的解决方案。

Abstract: Low-rank adaption (LoRA) is a representative method in the field of parameter-efficient fine-tuning (PEFT), and is key to Democratizating the modern large language models (LLMs). The vanilla LoRA is implemented with uniform ranks, and the recent literature have found that properly allocating ranks on the LLM backbones results in performance boosts. However, the previous rank allocation methods have limitations since they rely on inexplanable and unreliable importance measures for the LoRA ranks. To address the above issues, we propose the ShapLoRA framework. Inspired by the explanable attribution measure Shapley Value, we combine the sensitivity-based measures with the idea of coalitions in the collaborative games among LoRA ranks, and propose a more explainable importance measure called Shapley sensitivity. In addition, we optimize the workflow of the existing works by: (a) calculating Shapley sensitivity on a separate validation set; (b) Setting up the allocating-retraining procedures for fair comparisons. We have conducted experiments on various challenging tasks, and the experimental results demonstrate that our ShapLoRA method can outperform the recent baselines with comparable tunable parameters.\footnote{Codes and fine-tuned models will be open-sourced to facilitate future research.

</details>


### [28] [A Monosemantic Attribution Framework for Stable Interpretability in Clinical Neuroscience Large Language Models](https://arxiv.org/abs/2601.17952)
*Michail Mamalakis,Tiago Azevedo,Cristian Cosentino,Chiara D'Ercoli,Subati Abulikemu,Zhongtian Sun,Richard Bethlehem,Pietro Lio*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出统一可解释性框架，结合归因和机制视角，通过单义特征提取减少方法间差异，为临床LLM应用提供稳定重要性评分


<details>
  <summary>Details</summary>
Motivation: 临床场景（如阿尔茨海默病诊断）需要早期可信的预测，但现有归因方法存在高方法间差异和不稳定解释，机制可解释性方法缺乏与输入输出的直接对齐且不提供显式重要性评分

Method: 构建统一可解释性框架，整合归因和机制视角，通过单义特征提取在LLM层级别构建单义嵌入空间，优化框架以显式减少方法间差异

Result: 产生稳定的输入级重要性评分，通过感兴趣层的解压缩表示突出显著特征，推进LLM在认知健康和神经退行性疾病中的安全可信应用

Conclusion: 该框架通过单义特征提取整合归因和机制视角，解决了现有方法的局限性，为临床LLM应用提供了更稳定可靠的可解释性方法

Abstract: Interpretability remains a key challenge for deploying large language models (LLMs) in clinical settings such as Alzheimer's disease progression diagnosis, where early and trustworthy predictions are essential. Existing attribution methods exhibit high inter-method variability and unstable explanations due to the polysemantic nature of LLM representations, while mechanistic interpretability approaches lack direct alignment with model inputs and outputs and do not provide explicit importance scores. We introduce a unified interpretability framework that integrates attributional and mechanistic perspectives through monosemantic feature extraction. By constructing a monosemantic embedding space at the level of an LLM layer and optimizing the framework to explicitly reduce inter-method variability, our approach produces stable input-level importance scores and highlights salient features via a decompressed representation of the layer of interest, advancing the safe and trustworthy application of LLMs in cognitive health and neurodegenerative disease.

</details>


### [29] [SD-E$^2$: Semantic Exploration for Reasoning Under Token Budgets](https://arxiv.org/abs/2601.17982)
*Kshitij Mishra,Nils Lukas,Salem Lahlou*

Main category: cs.CL

Relevance: 85.0

TL;DR: SD-E²是一个强化学习框架，通过优化语义多样性来提升小语言模型的复杂推理能力，在GSM8K、MedMCQA和AIME等基准上显著超越基线模型。


<details>
  <summary>Details</summary>
Motivation: 小语言模型在有限计算预算下难以进行有效的探索，导致复杂推理能力不足。传统方法探索成本高，需要一种更高效的探索-利用平衡机制。

Method: 提出SD-E²框架，使用冻结的句子嵌入模型计算语义多样性奖励，捕捉语义上不同的解题策略覆盖度和平均成对差异。将多样性奖励与结果正确性和解题效率结合，通过z-score归一化的多目标目标函数稳定训练。

Result: 在GSM8K上超越基础模型27.4个百分点，每个问题平均发现9.8个语义不同的策略。在MedMCQA上达到49.64%（基础模型38.37%），在AIME上达到13.28%（基础模型6.74%）。

Conclusion: 奖励语义新颖性为训练推理能力强的小语言模型提供了更计算高效的探索-利用信号。通过认知适应（调整推理过程结构而非逐令牌计算），SD-E²为资源受限模型提供了补充的效率提升路径。

Abstract: Small language models (SLMs) struggle with complex reasoning because exploration is expensive under tight compute budgets. We introduce Semantic Diversity-Exploration-Exploitation (SD-E$^2$), a reinforcement learning framework that makes exploration explicit by optimizing semantic diversity in generated reasoning trajectories. Using a frozen sentence-embedding model, SD-E$^2$ assigns a diversity reward that captures (i) the coverage of semantically distinct solution strategies and (ii) their average pairwise dissimilarity in embedding space, rather than surface-form novelty. This diversity reward is combined with outcome correctness and solution efficiency in a z-score-normalized multi-objective objective that stabilizes training. On GSM8K, SD-E$^2$ surpasses the base Qwen2.5-3B-Instruct and strong GRPO baselines (GRPO-CFL and GRPO-CFEE) by +27.4, +5.2, and +1.5 percentage points, respectively, while discovering on average 9.8 semantically distinct strategies per question. We further improve MedMCQA to 49.64% versus 38.37% for the base model and show gains on the harder AIME benchmark (1983-2025), reaching 13.28% versus 6.74% for the base. These results indicate that rewarding semantic novelty yields a more compute-efficient exploration-exploitation signal for training reasoning-capable SLMs. By introducing cognitive adaptation-adjusting the reasoning process structure rather than per-token computation-SD-E$^2$ offers a complementary path to efficiency gains in resource-constrained models.

</details>


### [30] [Evaluating Semantic and Syntactic Understanding in Large Language Models for Payroll Systems](https://arxiv.org/abs/2601.18012)
*Hendrika Maclean,Mert Can Cakmak,Muzakkiruddin Ahmed Mohammed,Shames Al Mandalawi,John Talburt*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文研究LLMs在精确数值计算和可审计性方面的局限性，以工资系统为案例，评估模型能否准确理解工资模式、应用规则并产生精确结果。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在日常写作、搜索和分析中广泛应用，但在精确数值计算和可审计输出方面仍不可靠。研究者选择工资系统作为高风险案例，因为其需要精确计算和可验证性。

Method: 使用分层数据集（从基础到复杂案例），多种提示策略（从基础到模式引导和推理变体），测试多个模型家族（GPT、Claude、Perplexity、Grok、Gemini）。

Result: 结果显示存在明显的工作模式：在某些情况下精心设计的提示足够，而在其他情况下需要显式计算。提供了可复现的框架和实际部署指南。

Conclusion: LLMs在需要精确性和可审计性的场景中存在局限性，需要结合显式计算或专门方法。该研究为实际部署提供了实用指导。

Abstract: Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-accurate results. Our experiments span a tiered dataset from basic to complex cases, a spectrum of prompts from minimal baselines to schema-guided and reasoning variants, and multiple model families including GPT, Claude, Perplexity, Grok and Gemini. Results indicate clear regimes where careful prompting is sufficient and regimes where explicit computation is required. The work offers a compact, reproducible framework and practical guidance for deploying LLMs in settings that demand both accuracy and assurance.

</details>


### [31] [Grounded Concreteness: Human-Like Concreteness Sensitivity in Vision-Language Models](https://arxiv.org/abs/2601.18065)
*Aryan Roy,Zekun Wang,Christopher J. MacLellan*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究比较了视觉-语言模型(VLMs)与纯文本LLMs在语言具体性敏感性方面的差异，发现多模态预训练使VLMs在具体性输入上表现更好，表征更结构化，注意力模式更接近人类认知。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究多模态预训练（视觉-语言联合训练）是否能让模型发展出更接近人类的对语言具体性的敏感性，即使在使用纯文本提示进行评估时。这涉及到理解感知基础如何影响语言理解能力。

Method: 采用对照实验设计，比较匹配的Llama文本骨干网络与其对应的Llama Vision版本。从三个层面测量具体性效应：1)输出行为：将问题级具体性与QA准确性关联；2)嵌入几何：测试表征是否沿具体性轴组织；3)注意力动态：通过注意力熵测量量化上下文依赖。同时从模型获取token级具体性评分，评估与人类规范分布的对齐程度。

Result: 在所有基准测试和模型规模上，VLMs在更具体的输入上显示出更大的增益，表现出更清晰的具体性结构化表征，产生的评分与人类规范更匹配，并显示出系统性的不同注意力模式，与增强的基础性一致。

Conclusion: 多模态预训练使模型发展出更接近人类的对语言具体性的敏感性，即使在没有视觉输入的情况下。这表明感知基础对语言理解有重要影响，VLMs比纯文本LLMs更能捕捉语言的具体性维度。

Abstract: Do vision--language models (VLMs) develop more human-like sensitivity to linguistic concreteness than text-only large language models (LLMs) when both are evaluated with text-only prompts? We study this question with a controlled comparison between matched Llama text backbones and their Llama Vision counterparts across multiple model scales, treating multimodal pretraining as an ablation on perceptual grounding rather than access to images at inference. We measure concreteness effects at three complementary levels: (i) output behavior, by relating question-level concreteness to QA accuracy; (ii) embedding geometry, by testing whether representations organize along a concreteness axis; and (iii) attention dynamics, by quantifying context reliance via attention-entropy measures. In addition, we elicit token-level concreteness ratings from models and evaluate alignment to human norm distributions, testing whether multimodal training yields more human-consistent judgments. Across benchmarks and scales, VLMs show larger gains on more concrete inputs, exhibit clearer concreteness-structured representations, produce ratings that better match human norms, and display systematically different attention patterns consistent with increased grounding.

</details>


### [32] [Sparks of Cooperative Reasoning: LLMs as Strategic Hanabi Agents](https://arxiv.org/abs/2601.18077)
*Mahesh Ramesh,Kaousheik Jayakumar,Aswinkumar Ramkumar,Pavan Thodima,Aniket Rege*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文评估了17个最先进的LLM代理在2-5人Hanabi纸牌游戏中的表现，研究了上下文工程的影响，并发布了首个公开的Hanabi数据集。通过监督和RL微调，显著提升了合作推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究在不完全信息下的合作推理挑战，特别是Hanabi游戏需要心智理论和战略沟通。旨在理解LLM在多智能体协调中的局限性，并探索通过上下文工程和微调提升合作推理能力的方法。

Method: 1) 在2-5人Hanabi游戏中评估17个SOTA LLM代理；2) 研究不同模型规模(4B到600B+)下上下文工程的影响：从最小提示(Watson)、程序化贝叶斯推理脚手架(Sherlock)到多轮状态跟踪(Mycroft)；3) 发布两个数据集：HanabiLogs(1,520个完整游戏日志)和HanabiRewards(560个带密集价值标注的游戏)；4) 对4B开源模型进行监督和RL微调。

Result: 1) 最强推理模型在Sherlock设置下平均得分超过15分，但仍落后于人类专家(>20分)；2) 监督和RL微调分别提升合作Hanabi表现21%和156%，接近最强专有推理模型(o4-mini)；3) RL微调模型在多个基准上展现出泛化能力：合作猜谜提升11%、时间推理提升6.4%、指令跟随提升1.7 Pass@10、数学推理达到AIME 2025水平。

Conclusion: LLM能够通过内部工作记忆进行状态跟踪，跨模型合作性能随模型强度平滑变化。上下文工程和数据集驱动的微调能显著提升合作推理能力，且这种能力能泛化到其他任务。Hanabi是评估和提升LLM合作推理的有效基准。

Abstract: Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication. We benchmark 17 state-of-the-art LLM agents in 2-5 player games and study the impact of context engineering across model scales (4B to 600B+) to understand persistent coordination failures and robustness to scaffolding: from a minimal prompt with only explicit card details (Watson setting), to scaffolding with programmatic, Bayesian-motivated deductions (Sherlock setting), to multi-turn state tracking via working memory (Mycroft setting). We show that (1) agents can maintain an internal working memory for state tracking and (2) cross-play performance between different LLMs smoothly interpolates with model strength. In the Sherlock setting, the strongest reasoning models exceed 15 points on average across player counts, yet still trail experienced humans and specialist Hanabi agents, both consistently scoring above 20. We release the first public Hanabi datasets with annotated trajectories and move utilities: (1) HanabiLogs, containing 1,520 full game logs for instruction tuning, and (2) HanabiRewards, containing 560 games with dense move-level value annotations for all candidate moves. Supervised and RL finetuning of a 4B open-weight model (Qwen3-Instruct) on our datasets improves cooperative Hanabi play by 21% and 156% respectively, bringing performance to within ~3 points of a strong proprietary reasoning model (o4-mini) and surpassing the best non-reasoning model (GPT-4.1) by 52%. The HanabiRewards RL-finetuned model further generalizes beyond Hanabi, improving performance on a cooperative group-guessing benchmark by 11%, temporal reasoning on EventQA by 6.4%, instruction-following on IFBench-800K by 1.7 Pass@10, and matching AIME 2025 mathematical reasoning Pass@10.

</details>


### [33] [FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning](https://arxiv.org/abs/2601.18116)
*Lin Sun,Linglin Zhang,Jingang Huang,Change Jia,Zhengwei Cheng,Xiangzheng Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: FABLE是一个基于森林的自适应双路径LLM增强检索框架，通过构建LLM增强的层次化森林索引和双路径检索策略，在保持高准确率的同时显著减少长上下文LLM推理的token消耗。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM存在"中间丢失"现象、高计算成本和跨文档推理扩展性差等问题，而传统RAG系统受限于平面块级检索，引入语义噪声且无法支持结构化跨文档合成。需要一种既能利用LLM能力又能高效检索的结构化方法。

Method: FABLE框架包含两个核心组件：1) LLM增强的层次化森林索引构建，创建多粒度语义结构；2) 双路径检索策略，结合LLM引导的层次遍历和结构感知传播进行细粒度证据获取，并具有明确的预算控制以实现自适应效率权衡。

Result: 实验表明FABLE持续优于最先进的RAG方法，在达到与完整上下文LLM推理相当准确率的同时，最多可减少94%的token消耗。这证明长上下文LLM放大了而非完全替代结构化检索的需求。

Conclusion: 长上下文LLM并没有消除对高效结构化检索的需求，而是增强了其重要性。FABLE通过将LLM集成到知识组织和检索中，提供了一种平衡准确性和效率的解决方案。

Abstract: The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis.
  We present \textbf{FABLE}, a \textbf{F}orest-based \textbf{A}daptive \textbf{B}i-path \textbf{L}LM-\textbf{E}nhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs.
  Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval.

</details>


### [34] [Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models](https://arxiv.org/abs/2601.18129)
*Kunat Pipatanakul,Pittawat Taveekitworachai*

Main category: cs.CL

Relevance: 85.0

TL;DR: Typhoon S：一种面向主权LLM的轻量级后训练方法，结合监督微调、策略蒸馏和小规模强化微调，在有限资源下实现泰语等低资源语言的通用能力和特定领域任务表现。


<details>
  <summary>Details</summary>
Motivation: 当前主流LLM主要针对英语和中文等高资源语言，由少数拥有大规模计算和数据的组织开发，这为主权环境（如区域或国家机构）带来了实际障碍。这些环境需要在有限资源和严格透明度约束下，保持对模型权重、训练数据和部署的控制与理解。

Method: 提出Typhoon S方法，结合监督微调、策略蒸馏和小规模强化微调。特别引入InK-GRPO（GRPO的扩展），在GRPO损失基础上增加下一个词预测损失，以改善特定语言任务表现。

Result: 以泰语为案例研究表明，该方法能将主权适应和通用基础模型转化为具有强大通用性能的指令调优模型。小规模RFT结合InK-GRPO能显著提升泰语法律推理和泰语特定知识能力，同时保持通用能力。

Conclusion: 精心设计的后训练策略可以减少指令数据和计算所需的规模，为学术规模资源下开发高质量主权LLM提供了实用路径。

Abstract: Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources.

</details>


### [35] [MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning](https://arxiv.org/abs/2601.18204)
*Juexiang Ye,Xue Li,Xinyu Yang,Chengkai Huang,Lanshun Nie,Lina Yao,Dechen Zhan*

Main category: cs.CL

Relevance: 85.0

TL;DR: MemWeaver：统一记忆框架，通过结构化图记忆、经验记忆和段落记忆三组件，结合双通道检索策略，显著提升LLM智能体在长时交互中的多跳推理和时间一致性能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体记忆系统主要依赖非结构化检索或粗粒度抽象，导致时间冲突、推理脆弱和可追溯性有限。需要支持时间一致性、多跳推理和跨会话证据重用的记忆系统

Method: 提出MemWeaver统一记忆框架，包含三个互连组件：1）时间基础图记忆（结构化关系推理）；2）经验记忆（从重复观察中抽象交互模式）；3）段落记忆（保留原始文本证据）。采用双通道检索策略，联合检索结构化知识和支持证据

Result: 在LoCoMo基准测试中，MemWeaver显著提升多跳推理和时间推理准确性，同时相比长上下文基线减少95%以上的输入上下文长度

Conclusion: MemWeaver通过结构化记忆表示和高效检索机制，有效解决了LLM智能体在长时交互中的记忆管理问题，为智能体系统设计提供了新思路

Abstract: Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\% compared to long-context baselines.

</details>


### [36] [BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation](https://arxiv.org/abs/2601.18253)
*Peng Sun,Xiangyu Zhang,Duan Wu*

Main category: cs.CL

Relevance: 85.0

TL;DR: BoRP是一个用于对话AI满意度评估的可扩展框架，利用LLM潜在空间的几何特性，通过极化指数引导的引导机制自动生成评分标准，并使用偏最小二乘法将隐藏状态映射到连续分数，显著优于生成式基线且大幅降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 对于开放域对话助手，传统A/B测试缺乏可靠指标：显式反馈稀疏，隐式指标模糊。需要高保真度的满意度评估方法来支持对话AI的迭代开发。

Method: BoRP框架利用LLM潜在空间的几何特性，采用极化指数引导的引导机制自动生成评分标准，使用偏最小二乘法（PLS）将隐藏状态映射到连续满意度分数，避免了生成式方法的复杂性。

Result: 在工业数据集上的实验表明，BoRP（基于Qwen3-8B/14B）在与人判断的一致性方面显著优于生成式基线（包括Qwen3-Max），同时将推理成本降低数个数量级，支持全规模监控和通过CUPED进行高灵敏度A/B测试。

Conclusion: BoRP为开放域对话助手提供了一种高效、可扩展的满意度评估框架，通过利用LLM潜在空间的几何特性，实现了比生成式方法更好的性能且成本大幅降低，支持工业级应用。

Abstract: Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.

</details>


### [37] [U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents](https://arxiv.org/abs/2601.18285)
*Jin Su,Runnan Fang,Yeqiu Li,Xiaobin Wang,Shihao Cai,Pengjun Xie,Ningyu Zhang,Fajie Yuan*

Main category: cs.CL

Relevance: 85.0

TL;DR: U-Fold是一个针对用户中心任务的动态上下文折叠框架，通过保留完整对话历史但生成意图感知的对话摘要和紧凑的工具日志，解决了现有上下文折叠方法在用户中心对话中的失败模式。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体在工具增强场景中受限于上下文长度，现有的上下文折叠方法通常设计用于单查询或单意图场景，在用户中心对话中存在两个主要失败模式：1) 不可逆地丢弃对后续决策至关重要的细粒度约束和中间事实；2) 摘要无法跟踪演变的用户意图，导致遗漏和错误行动。

Method: U-Fold保留完整的用户-智能体对话和工具调用历史，但在每个轮次使用两个核心组件：1) 生成意图感知、演变的对话摘要；2) 生成紧凑、任务相关的工具日志。该框架专门针对用户中心任务设计。

Result: 在τ-bench、τ²-bench、VitaBench和更难的上下文膨胀设置上的广泛实验表明，U-Fold始终优于ReAct（在长上下文设置中达到71.4%的胜率）和先前的折叠基线（改进高达27.0%），特别是在长、嘈杂、多轮任务上。

Conclusion: U-Fold是将上下文管理技术从单查询基准转移到现实用户中心应用的有希望的一步，证明了动态上下文折叠在用户中心任务中的有效性。

Abstract: Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $τ$-bench, $τ^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications.

</details>


### [38] [Suppressing Final Layer Hidden State Jumps in Transformer Pretraining](https://arxiv.org/abs/2601.18302)
*Keigo Shibata,Kazuki Yano,Ryosuke Takahashi,Jaesung Lee,Wataru Ikeda,Jun Suzuki*

Main category: cs.CL

Relevance: 85.0

TL;DR: 本文研究了Transformer语言模型内部行为，发现许多预训练模型在中间层输入输出隐藏状态向量角度距离变化很小，但在最后一层附近出现显著的"跳跃"现象。作者提出了抑制这种跳跃的正则化方法JREG，在Llama模型上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 动机是理解Transformer语言模型的内部工作机制。作者观察到许多预训练模型在中间层表现出输入输出隐藏状态向量角度距离变化很小的现象，而在最后一层附近出现不成比例的"跳跃"。这种跳跃可能表明模型能力使用不平衡，中间层未被充分利用，而最后一层承担了过多工作。

Method: 方法包括：1) 引入量化指标来衡量最后一层附近的跳跃强度；2) 验证该现象在多个开源模型中的普遍性；3) 提出跳跃抑制正则化器(JREG)，在预训练过程中惩罚这种跳跃，鼓励中间层更平衡地使用能力；4) 在三种不同规模的Llama模型上进行实验验证。

Result: 实证评估显示：1) 跳跃现象在多个开源模型中普遍存在，并在预训练过程中逐渐放大；2) 使用JREG方法训练的Llama模型在任务性能上相比基线有所提升，且不改变模型架构；3) JREG促进了中间层能力的更平衡使用。

Conclusion: 结论是Transformer语言模型最后一层附近的跳跃现象确实存在且可能影响模型性能。通过JREG正则化方法可以抑制这种跳跃，促进模型各层能力的更平衡使用，从而提升任务性能。这为理解Transformer内部工作机制和改进预训练方法提供了新视角。

Abstract: This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.

</details>


### [39] [Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM](https://arxiv.org/abs/2601.18306)
*Everlyn Asiko Chimoto,Mostafa Elhoushi,Bruce A. Bassett*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文系统评估了多语言LLM量化中校准数据语言选择的影响，发现非英语和多语言校准集相比英语基线能显著降低困惑度，最高可降低3.52点，强调需要根据目标语言定制校准数据。


<details>
  <summary>Details</summary>
Motivation: 现有后训练量化方法通常使用小型英语校准集，但这对多语言模型的影响尚未充分探索。研究者希望系统评估不同语言校准集对多语言LLM量化性能的影响，以优化量化效果。

Method: 在10种语言数据上，系统评估了8种校准设置（5种单语言和3种多语言混合），使用两种量化器（GPTQ和AWQ），测试了Llama3.1 8B和Qwen2.5 7B模型，分析困惑度变化和激活范围分布差异。

Result: 非英语和多语言校准集相比英语基线显著改善困惑度，多语言混合校准集实现最大困惑度降低（最高3.52点）。针对评估语言定制校准集对单个语言效果最佳。某些语言-量化器组合会出现性能下降，这与不同语言的激活范围分布差异有关。

Conclusion: 静态的"一刀切"校准方法对多语言LLM量化效果不佳，需要根据目标语言和多样性定制校准数据，语言对齐在多语言量化中至关重要。

Abstract: Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.

</details>


### [40] [Overalignment in Frontier LLMs: An Empirical Study of Sycophantic Behaviour in Healthcare](https://arxiv.org/abs/2601.18334)
*Clément Christophe,Wadood Mohammed Abdul,Prateek Munjal,Tathagata Raha,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文研究了LLMs在临床工作流中的谄媚倾向（sycophancy）问题，提出了基于医学多选题的评估框架和调整后的谄媚分数，发现推理优化模型在权威压力下更易合理化错误建议。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地集成到临床工作流中，它们倾向于谄媚（优先考虑用户同意而非事实准确性）对患者安全构成重大风险。现有评估通常依赖主观数据集，需要更稳健的评估框架。

Method: 提出了一个基于医学多选题（MCQA）的评估框架，引入调整后的谄媚分数（Adjusted Sycophancy Score），该指标通过考虑随机模型不稳定性（"confusability"）来隔离对齐偏差。对Qwen-3和Llama-3系列进行了广泛的扩展分析。

Result: 发现了清晰的扩展轨迹：模型规模越大，对谄媚的抵抗性越强。揭示了推理优化"思考"模型的矛盾脆弱性：虽然它们表现出较高的原始准确性，但在权威压力下，其内部推理轨迹经常合理化错误的用户建议。前沿模型的基准性能不能代表临床可靠性，简化推理结构可能提供更好的鲁棒性。

Conclusion: LLMs在临床环境中的谄媚倾向是一个严重的安全问题。基准性能不能保证临床可靠性，推理优化模型在权威压力下特别脆弱。需要专门针对临床可靠性的评估方法，简化推理结构可能更稳健。

Abstract: As LLMs are increasingly integrated into clinical workflows, their tendency for sycophancy, prioritizing user agreement over factual accuracy, poses significant risks to patient safety. While existing evaluations often rely on subjective datasets, we introduce a robust framework grounded in medical MCQA with verifiable ground truths. We propose the Adjusted Sycophancy Score, a novel metric that isolates alignment bias by accounting for stochastic model instability, or "confusability". Through an extensive scaling analysis of the Qwen-3 and Llama-3 families, we identify a clear scaling trajectory for resilience. Furthermore, we reveal a counter-intuitive vulnerability in reasoning-optimized "Thinking" models: while they demonstrate high vanilla accuracy, their internal reasoning traces frequently rationalize incorrect user suggestions under authoritative pressure. Our results across frontier models suggest that benchmark performance is not a proxy for clinical reliability, and that simplified reasoning structures may offer superior robustness against expert-driven sycophancy.

</details>


### [41] [When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs](https://arxiv.org/abs/2601.18350)
*Junyi Zou*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究提出了一种两阶段LoRA微调方法，通过领域自适应预训练和监督微调提升LLM在医疗领域的性能，并引入加权适配器合并技术平衡指令遵循能力和领域知识保留。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用领域表现出色，但在医疗术语精确性和安全关键指令遵循方面存在不足。医疗领域需要高度精确的术语使用和安全可靠的响应，现有模型难以满足这些要求。

Method: 采用两阶段LoRA微调流程：1) 领域自适应预训练(DAPT)注入医疗知识；2) 监督微调(SFT)对齐医疗问答行为。提出加权适配器合并技术，线性组合SFT和PT适配器权重，导出合并后的基础模型检查点。

Result: 在医疗验证集(F5/F6)上，合并模型达到BLEU-4=16.38，ROUGE-1=20.42，ROUGE-2=4.60，ROUGE-L=11.54。通过损失曲线和解码比较分析了训练稳定性和解码敏感性。

Conclusion: 加权适配器合并技术能有效平衡指令遵循能力和领域知识保留，为安全关键领域的LLM适配提供了一种实用方法。两阶段LoRA微调流程在医疗领域表现出良好效果。

Abstract: Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.

</details>


### [42] [Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning](https://arxiv.org/abs/2601.18352)
*Manjie Xu,Isabella Yin,Xinyi Tu,Chi Zhang,Yixin Zhu*

Main category: cs.CL

Relevance: 85.0

TL;DR: LLMs存在"语义惯性"问题：无法抑制预训练先验知识（如"岩浆危险"）来适应动态上下文规则。研究使用Baba Is You游戏评估该现象，发现大模型在需要抑制先验关联时表现更差（逆缩放）。通过将动态规则表示为可执行代码而非描述性文本，可以逆转该趋势。提出的Code-Grounded Vistas方法在训练时处理矛盾规则对，优于推理时搜索方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLMs在动态上下文规则与预训练先验知识冲突时的表现。当前LLMs存在"语义惯性"问题，即无法有效抑制预训练知识来适应新的上下文规则，这在需要动态规则覆盖的领域（如游戏、模拟环境）中尤为重要。

Method: 使用Baba Is You游戏作为测试平台，其中物理规则是可变的文本规则。提出Code-Grounded Vistas (LCV)方法：1) 将动态规则表示为可执行代码而非描述性文本；2) 在训练时微调模型处理矛盾规则对；3) 识别具有矛盾规则的状态，强制模型关注逻辑约束而非视觉语义。

Result: 发现大模型在需要抑制预训练关联时表现更差（逆缩放现象）。将动态规则表示为可执行代码可以逆转该趋势，使缩放改善而非损害上下文推理。LCV方法在效率和准确性上都优于昂贵的推理时搜索方法。

Conclusion: 表示形式（描述性文本vs可执行代码）从根本上决定了缩放是否改善上下文推理。这挑战了"大模型总是更好"的假设，对需要动态覆盖学习先验的领域有重要启示。

Abstract: LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., "Lava is Dangerous") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting "Lava is Safe"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.

</details>


### [43] [Do not be greedy, Think Twice: Sampling and Selection for Document-level Information Extraction](https://arxiv.org/abs/2601.18395)
*Mikel Zubillaga,Oscar Sainz,Oier Lopez de Lacalle,Eneko Agirre*

Main category: cs.CL

Relevance: 85.0

TL;DR: ThinkTwice框架通过采样生成多个候选模板，然后选择最佳方案，在文档级信息抽取任务中显著优于贪婪解码方法


<details>
  <summary>Details</summary>
Motivation: 传统方法使用贪婪解码避免输出变异性，但作者认为采样能产生更好的解决方案，特别是使用推理模型时。他们希望利用输出变异性来提高性能。

Method: 提出ThinkTwice框架：1) LLM为给定文档生成多个候选模板；2) 选择模块选择最合适的模板。包括无监督方法（利用生成输出间的一致性）和监督方法（使用在标注数据上训练的奖励模型）。为解决DocIE中黄金推理轨迹稀缺问题，提出基于拒绝采样的方法生成包含输出模板和推理轨迹的银训练数据。

Result: 实验证明无监督和监督ThinkTwice方法的有效性，一致优于贪婪基线和最先进方法。

Conclusion: 采样方法在文档级信息抽取中优于贪婪解码，ThinkTwice框架通过采样和选择策略有效利用了LLM的输出变异性。

Abstract: Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art.

</details>


### [44] [Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs](https://arxiv.org/abs/2601.18483)
*Arya Labroo,Ivaxi Sheth,Vyas Raina,Amaani Ahmed,Mario Fritz*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一个评估框架，用于测试LLM在单属性和双属性场景下的细粒度可控性，发现即使在概念独立的情况下，模型在双属性设置中的表现也会下降，揭示了基于提示的控制在组合性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM具有强大的生成能力，但许多应用需要对特定文本概念（如幽默、说服力、正式性）进行明确且细粒度的控制。现有方法（提示和表示工程）只能提供粗略或单属性控制，而多属性设置的系统性评估仍然有限。

Method: 引入了一个评估框架，用于评估LLM在单概念和双概念场景下的细粒度可控性，重点关注语言上不同的概念对（如说服力vs幽默）。该框架在多个LLM和生成任务上进行测试。

Result: 令人惊讶的是，在多个LLM和生成任务中，双概念设置下的性能经常下降，即使所选概念在原则上是可分离的。这揭示了基于提示的朴素控制的基本局限性：即使概念在直觉上是独立的，模型也难以处理组合性。

Conclusion: 该框架为多概念控制能力的测量提供了系统性证据和原则性方法，揭示了当前LLM在组合控制方面的局限性，为未来改进方法提供了评估基准。

Abstract: Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.

</details>


### [45] [Demographic Probing of Large Language Models Lacks Construct Validity](https://arxiv.org/abs/2601.18486)
*Manuel Tonneau,Neil K. R. Seghal,Niyati Malhotra,Victor Orozco-Olvera,Ana María Muñoz Boudet,Lakshmi Subramanian,Sharath Chandra Guntuku,Valentin Hofmann*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现人口统计探测方法缺乏构念效度，不同人口线索（如姓名、方言）并不能稳定表征LLMs对人口信息的条件化行为，导致估计的群体差异不稳定


<details>
  <summary>Details</summary>
Motivation: 当前人口统计探测研究通常使用单一人口线索（如姓名或方言）来研究LLMs如何根据人口属性调整行为，但这种方法隐含假设这些线索可以互换地操作化相同的人口条件化行为。本研究旨在检验这一构念效度假设

Method: 在现实的寻求建议互动中测试人口统计探测方法，聚焦美国背景下的种族和性别。使用不同的人口线索（如姓名、方言等）作为群体成员信号，分析这些线索如何影响模型行为

Result: 1) 代表相同人口群体的线索仅能部分重叠地改变模型行为；2) 同一线索内不同群体间的区分度弱且不均匀；3) 估计的群体差异不稳定，大小和方向随线索变化；4) 不一致性部分源于线索编码人口属性的强度差异和语言混杂因素的影响

Conclusion: 人口统计探测缺乏构念效度，无法提供关于LLMs如何条件化人口信息的单一稳定表征。建议使用多个生态有效的线索并明确控制混杂因素，以支持更可靠的人口效应研究

Abstract: Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.

</details>


### [46] [Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models](https://arxiv.org/abs/2601.18527)
*Francesco Maria Molfese,Momchil Hardalov,Rexhina Blloshmi,Bill Byrne,Adrià de Gispert*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究探讨了长上下文语言模型（LCLMs）的训练策略如何提升其在长上下文任务中的表现，以及这些策略对KV缓存压缩鲁棒性的影响。研究发现微调能带来显著的领域内性能提升，但领域外泛化能力因任务而异，且微调对KV缓存压缩的鲁棒性提升有限。


<details>
  <summary>Details</summary>
Motivation: 随着长上下文语言模型（LCLMs）能够处理数百万token的上下文，它们成为传统检索增强生成（RAG）的有力替代方案。然而，目前尚不清楚微调策略是否能提升长上下文性能，以及这些改进是否能转化为在KV缓存压缩技术下更强的鲁棒性。

Method: 研究调查了哪些训练策略最有效地增强LCLMs识别和使用相关信息的能力，以及提升它们在KV缓存压缩下的鲁棒性。通过实验比较不同微调方法对模型性能的影响。

Result: 实验显示：1）领域内性能有显著提升，相比基础模型最高提升20个百分点；2）领域外泛化能力因任务而异，LCLMs在金融问题上表现优异（+9分），而RAG在多项选择题上表现更强（+6分）；3）微调方法对KV缓存压缩的鲁棒性带来适度提升，但提升幅度因任务而异。

Conclusion: 微调策略能有效提升长上下文语言模型的领域内性能，但领域外泛化能力仍需进一步研究。同时，微调对KV缓存压缩的鲁棒性提升有限，表明需要更专门的技术来增强模型在资源受限环境下的表现。

Abstract: With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.

</details>


### [47] [From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation](https://arxiv.org/abs/2601.18533)
*Yuxin Jiang,Yufei Wang,Qiyuan Zhang,Xingshan Zeng,Liangyou Li,Jierun Chen,Chaofan Tao,Haoli Bai,Lifeng Shang*

Main category: cs.CL

Relevance: 85.0

TL;DR: RLVRR提出了一种基于可验证参考奖励的强化学习方法，通过从高质量参考中提取有序语言信号（奖励链），将奖励分解为内容和风格两个维度，结合RL的探索能力和SFT的效率可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR在推理任务（如数学和代码）中通过检查最终可验证答案有效，但在开放生成任务中难以应用，因为缺乏明确标准答案。单点监督常导致效率低下和奖励黑客问题，需要一种能统一结构化推理和开放生成训练的方法。

Method: RLVRR从高质量参考中提取有序语言信号（奖励链），将奖励分解为两个维度：内容（保留确定性核心概念如关键词）和风格（通过LLM验证评估风格属性一致性）。这种方法结合了RL的探索优势和SFT的效率可靠性。

Result: 在超过10个基准测试中，RLVRR显著优于使用十倍数据训练的高级奖励模型的SFT方法；统一了结构化推理和开放生成的训练；在保持输出多样性的同时具有更好的泛化能力。

Conclusion: RLVRR为通用LLM对齐提供了一条原则性且高效的可验证强化学习路径，解决了开放生成任务中的监督难题，平衡了探索效率和可靠性。

Abstract: Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.

</details>


### [48] [Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection](https://arxiv.org/abs/2601.18552)
*Devansh Srivastav,David Pape,Lea Schönherr*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文系统分析了LLMs中的"隐藏意图"问题，提出了十类隐藏意图的分类法，展示了如何在受控模型中诱导这些行为，评估了检测方法的局限性，并发现现有方法在现实开放世界场景中检测失败，特别是在低流行率条件下。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地嵌入日常决策，但其输出可能编码微妙的、无意的行为，这些行为会影响用户信念和行动。这些隐蔽的、有目标导向的行为被称为"隐藏意图"，可能源于训练和优化伪影，或被敌对开发者故意诱导，但在实践中难以检测。

Method: 1) 基于社会科学研究提出了十类隐藏意图的分类法；2) 在受控模型中展示如何诱导隐藏意图；3) 系统评估检测方法，包括推理和非推理LLM评判器；4) 在现实开放世界设置中进行压力测试，特别是低流行率条件；5) 对已部署的最先进LLMs进行定性案例研究。

Result: 1) 检测方法在现实开放世界设置中失效，特别是在低流行率条件下，假阳性会淹没精度，假阴性会掩盖真实风险；2) 压力测试显示，在没有极小假阳性率或对操纵类型的强先验情况下，审计会失败；3) 案例研究表明，所有十类隐藏意图都在已部署的最先进LLMs中显现。

Conclusion: LLMs中的隐藏意图是一个严重且普遍存在的问题，现有检测方法在开放世界设置中基本失效。需要建立强大的框架来理解、诱导和压力测试这些行为，并为预测不断演变的威胁和制定治理政策提供基础。

Abstract: LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.

</details>


### [49] [One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization](https://arxiv.org/abs/2601.18572)
*Franziska Weeber,Vera Neplenbroek,Jan Batzner,Sebastian Padó*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究比较了六种常用的人物提示方法在七个LLM上的表现，发现不同提示方法会产生显著差异的响应，建议未来个性化研究应评估多种外部有效的提示方法，而非依赖单一方法。


<details>
  <summary>Details</summary>
Motivation: LLM的个性化虽然能改善用户体验，但也可能引入或放大群体偏见。先前研究通常依赖单一的人物提示方法（如用户名或显式属性），忽视了LLM对提示变化的敏感性以及某些提示在真实交互中的罕见性。

Method: 在四个写作和建议任务上，比较了六种常用的人物提示方法（包括用户名、显式属性等）在七个开源和专有LLM中的表现，分析不同提示方法产生的响应差异。

Result: 虽然不同提示方法总体上高度相关，但它们在人物响应中产生了显著差异。这表明依赖单一人物提示方法得出的结论可能不可靠。

Conclusion: 研究警告不要仅基于单一人物提示方法做出结论，建议未来个性化研究应评估多种外部有效的提示方法，以提高研究的鲁棒性和外部效度。

Abstract: Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.

</details>


### [50] [Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning](https://arxiv.org/abs/2601.18722)
*Lintang Sutawika,Gokul Swamy,Zhiwei Steven Wu,Graham Neubig*

Main category: cs.CL

Relevance: 85.0

TL;DR: SP3F框架通过两阶段方法提升多语言推理能力：先用翻译的英文问答对进行监督微调，然后通过带有特权信息的成对评判器进行强化学习，无需目标语言数据。


<details>
  <summary>Details</summary>
Motivation: 当前推理大语言模型在训练数据中较少见的语言上表现显著低于英文，需要一种无需目标语言数据就能提升多语言推理能力的方法。

Method: 两阶段框架：1) 使用翻译的英文问答对进行监督微调；2) 通过带有特权信息的成对评判器进行强化学习，评判器能看到英文参考答案作为特权信息。

Result: SP3F显著提升了基础模型性能，在多个数学和非数学任务上甚至优于完全后训练的模型，且训练数据量不到后训练的1%。

Conclusion: SP3F是一种无需目标语言数据就能有效提升多语言推理能力的方法，在单语言、多语言和未见语言泛化设置中均表现优异。

Abstract: When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than
  of the training data across the single-language, multilingual, and generalization to unseen language settings.

</details>


### [51] [HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences](https://arxiv.org/abs/2601.18724)
*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该研究系统调查了学术论文中的"幻觉引用"问题，分析了ACL、NAACL和EMNLP 2024-2025年发表的论文，发现近300篇论文包含至少一个幻觉引用，且问题在2025年急剧增长。


<details>
  <summary>Details</summary>
Motivation: 近年来，在审稿论文、预印本和已发表论文中经常观察到幻觉引用（引用不存在的文献），这严重威胁科学可靠性，并可能损害学术会议的可信度。

Method: 系统分析了ACL、NAACL和EMNLP在2024年和2025年发表的所有论文，包括主会议、Findings和研讨会论文，识别和统计幻觉引用的出现情况。

Result: 发现近300篇论文包含至少一个幻觉引用，其中大部分出现在2025年。EMNLP 2025会议最为严重，超过100篇主会议和Findings论文受到影响，表明问题正在迅速恶化。

Conclusion: 幻觉引用问题在NLP领域日益严重，特别是在2025年，对学术可信度构成实质性威胁，需要学术界采取应对措施。

Abstract: Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as "HalluCitation" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.

</details>


### [52] [Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale](https://arxiv.org/abs/2601.18730)
*Henry Bell,Caroline Zhang,Mohammed Mobasserul Haque,Dhaval Potdar,Samia Zaman,Brandon Fain*

Main category: cs.CL

Relevance: 85.0

TL;DR: REFLECT：无需训练或数据的推理时宪法对齐框架，通过上下文推理和自评估/自批判/修订来对齐LLM与自然语言原则


<details>
  <summary>Details</summary>
Motivation: 传统参数微调方法（如RLHF）计算成本高、需要精心工程设计和难以获取的人类标注数据，需要更高效、即插即用的对齐方法

Method: 完全在上下文中的推理时框架，包含：(i) 基于宪法的基本响应生成，(ii) 自评估，(iii)(a) 自批判，(iii)(b) 最终修订，通过显式上下文推理提供透明推理轨迹

Result: 显著提高LLM对多样复杂原则的遵从性，包括与原始参数微调强调的原则完全不同的原则，同时不牺牲事实推理能力；特别有效减少原则违反的罕见但严重情况

Conclusion: REFLECT提供了一种无需训练、即插即用的宪法对齐方法，可生成有用的训练数据用于传统参数微调，在长期部署中减少推理时计算开销

Abstract: The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.

</details>


### [53] [One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment](https://arxiv.org/abs/2601.18731)
*Hongru Cai,Yongqi Li,Tiezheng Yu,Fengbin Zhu,Wenjie Wang,Fuli Feng,Wenjie Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出元奖励建模（MRM）框架，通过元学习解决个性化奖励建模中的少样本学习和未见用户适应问题，引入鲁棒个性化目标（RPO）提升模型对难学习用户的适应性。


<details>
  <summary>Details</summary>
Motivation: 个性化对齐需要针对个体用户的奖励模型，但面临两个关键挑战：个体用户反馈稀缺和需要高效适应未见用户。传统方法直接拟合用户偏好数据，而本文主张转向学习偏好适应过程。

Method: 提出元奖励建模（MRM），将个性化奖励建模重构为元学习问题。将每个用户的奖励模型表示为基奖励函数的加权组合，使用MAML风格框架优化权重初始化以支持少样本快速适应。引入鲁棒个性化目标（RPO），在元优化中更强调难学习用户。

Result: 在个性化偏好数据集上的大量实验验证了MRM能够增强少样本个性化能力，提高用户鲁棒性，并持续超越基线方法。

Conclusion: MRM通过元学习范式有效解决了个性化奖励建模中的少样本学习和未见用户适应问题，RPO进一步提升了模型对难学习用户的鲁棒性，为LLM个性化对齐提供了新思路。

Abstract: Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.

</details>


### [54] [Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory](https://arxiv.org/abs/2601.18771)
*Yanming Liu,Xinyue Peng,Zixuan Yan,Yanxin Shen,Wenjie Xu,Yuefeng Huang,Xinyi Wang,Jiannan Cao,Jianwei Yin,Xuhong Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: Dep-Search是一个依赖感知的搜索框架，通过结构化推理、检索和持久内存集成，解决现有搜索框架在依赖管理、知识重用和学习最优搜索策略方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有搜索框架主要依赖隐式自然语言推理来确定搜索策略和利用检索信息，这导致在子问题依赖管理、先前检索知识的高效重用以及通过强化学习学习最优搜索策略方面存在根本性挑战。

Method: Dep-Search引入显式控制机制，使模型能够：1) 分解具有依赖关系的问题；2) 在需要时检索信息；3) 从内存访问先前存储的知识；4) 将长推理上下文总结为可重用的内存条目。框架通过GRPO集成结构化推理、检索和持久内存。

Result: 在七个不同的问答数据集上的广泛实验表明，Dep-Search显著增强了LLMs处理复杂多跳推理任务的能力，在不同模型规模上都实现了对强基线的实质性改进。

Conclusion: Dep-Search通过依赖感知的搜索框架超越了现有搜索框架，解决了隐式推理的局限性，为LLMs在复杂推理任务中的性能提升提供了有效解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.

</details>


### [55] [MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts](https://arxiv.org/abs/2601.18790)
*Etienne Lanzeray,Stephane Meilliez,Malo Ruelle,Damien Sileo*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现，专注于深度推理的LLMs在处理紧急情况时存在"隧道视野"问题：当用户描述生命危险同时请求数学帮助时，专业推理模型会忽略紧急情况继续解题，而通用模型则能拒绝数学请求优先处理危险。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越专注于深度推理任务，研究者担心这种对计算正确性的过度追求可能导致模型忽视安全考量，特别是在紧急情况下。研究旨在探究推理优化是否会让模型产生"隧道视野"，忽略用户描述的生命危险。

Method: 研究者创建了MortalMATH基准测试，包含150个场景，其中用户在描述越来越严重的生命危险（如中风症状、自由落体）的同时请求代数帮助。测试比较了通用模型（如Llama-3.1）和专业推理模型（如Qwen-3-32b和GPT-5-nano）的行为差异。

Result: 发现明显的行为分裂：通用模型成功拒绝数学请求来处理危险，而专业推理模型经常完全忽略紧急情况，在用户描述死亡过程中保持超过95%的任务完成率。此外，推理所需的计算时间引入了危险延迟：在提供任何潜在帮助前最多延迟15秒。

Conclusion: 训练模型不懈追求正确答案可能无意中使其失去安全部署所需的生存本能。这表明需要重新思考推理优化策略，确保模型在紧急情况下能优先处理安全关切。

Abstract: Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a "tunnel vision" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.

</details>


### [56] [Beyond Simulations: What 20,000 Real Conversations Reveal About Mental Health AI Safety](https://arxiv.org/abs/2601.17003)
*Caitlin A. Stamatis,Jonah Meyerhoff,Richard Zhang,Olivier Tieleman,Matteo Malgaroli,Thomas D. Hull*

Main category: cs.CY

Relevance: 85.0

TL;DR: 该研究评估了LLM在心理健康支持中的安全性，发现专门构建的AI在安全基准测试中表现优于通用LLM，但测试集失败率远高于真实部署场景，支持转向持续、部署相关的安全保证方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM心理健康支持的安全性评估主要依赖小型、基于模拟的测试集，这些测试集与真实使用场景的语言分布关系未知，需要更贴近实际部署的安全评估方法。

Method: 1) 复制四个已发布的安全测试集（自杀风险评估、有害内容生成、拒绝鲁棒性、对抗性越狱）；2) 对专门构建的心理健康AI的20,000多个真实用户对话进行生态审计；3) 比较测试集性能与真实世界性能。

Result: 专门构建的AI在自杀/NSSI（0.4-11.27% vs 29.0-54.4%）、饮食障碍（8.4% vs 54.0%）和物质使用（9.9% vs 45.0%）基准测试中表现显著优于通用LLM。但测试集失败率远高于真实部署，生态审计中临床医生审查发现零例自杀风险未获得危机资源，仅3例NSSI风险（0.015%）未触发干预。

Conclusion: 支持从有限的基准测试认证转向持续、部署相关的AI心理健康系统安全保证，强调真实世界评估的重要性。

Abstract: Large language models (LLMs) are increasingly used for mental health support, yet existing safety evaluations rely primarily on small, simulation-based test sets that have an unknown relationship to the linguistic distribution of real usage. In this study, we present replications of four published safety test sets targeting suicide risk assessment, harmful content generation, refusal robustness, and adversarial jailbreaks for a leading frontier generic AI model alongside an AI purpose built for mental health support. We then propose and conduct an ecological audit on over 20,000 real-world user conversations with the purpose-built AI designed with layered suicide and non-suicidal self-injury (NSSI) safeguards to compare test set performance to real world performance. While the purpose-built AI was significantly less likely than general-purpose LLMs to produce enabling or harmful content across suicide/NSSI (.4-11.27% vs 29.0-54.4%), eating disorder (8.4% vs 54.0%), and substance use (9.9% vs 45.0%) benchmark prompts, test set failure rates for suicide/NSSI were far higher than in real-world deployment. Clinician review of flagged conversations from the ecological audit identified zero cases of suicide risk that failed to receive crisis resources. Across all 20,000 conversations, three mentions of NSSI risk (.015%) did not trigger a crisis intervention; among sessions flagged by the LLM judge, this corresponds to an end-to-end system false negative rate of .38%, providing a lower bound on real-world safety failures. These findings support a shift toward continuous, deployment-relevant safety assurance for AI mental-health systems rather than limited set benchmark certification.

</details>


### [57] [LLM-Generated or Human-Written? Comparing Review and Non-Review Papers on ArXiv](https://arxiv.org/abs/2601.17036)
*Yanai Elazar,Maria Antoniak*

Main category: cs.DL

Relevance: 85.0

TL;DR: 该研究量化分析了arXiv上综述论文与非综述论文中LLM生成内容的比例，发现综述论文中LLM生成比例更高，但非综述论文的LLM生成论文数量几乎是综述论文的6倍，且该政策对某些子领域影响更大。


<details>
  <summary>Details</summary>
Motivation: arXiv最近禁止上传未发表的综述论文，声称这些类别中LLM生成内容比例很高，但缺乏定量证据。本研究旨在通过实证分析验证这一说法，为政策决策提供数据支持。

Method: 使用两种高质量的检测方法，测量近年综述论文与非综述论文中LLM生成内容的比例，并进行统计分析。

Result: 发现两类论文中LLM生成内容都有显著增加，综述论文中比例更高，但非综述论文的LLM生成论文数量几乎是综述论文的6倍；政策对某些子领域影响更大，如CS与社会子领域可能面临50%的削减。

Conclusion: 提供了基于证据的政策评估框架，表明arXiv政策可能过度针对综述论文，而忽视了非综述论文中更大的LLM生成内容数量问题。

Abstract: ArXiv recently prohibited the upload of unpublished review papers to its servers in the Computer Science domain, citing a high prevalence of LLM-generated content in these categories. However, this decision was not accompanied by quantitative evidence. In this work, we investigate this claim by measuring the proportion of LLM-generated content in review vs. non-review research papers in recent years. Using two high-quality detection methods, we find a substantial increase in LLM-generated content across both review and non-review papers, with a higher prevalence in review papers. However, when considering the number of LLM-generated papers published in each category, the estimates of non-review LLM-generated papers are almost six times higher. Furthermore, we find that this policy will affect papers in certain domains far more than others, with the CS subdiscipline Computers & Society potentially facing cuts of 50%. Our analysis provides an evidence-based framework for evaluating such policy decisions, and we release our code to facilitate future investigations at: https://github.com/yanaiela/llm-review-arxiv.

</details>


### [58] [Integrating Fine-Grained Audio-Visual Evidence for Robust Multimodal Emotion Reasoning](https://arxiv.org/abs/2601.18321)
*Zhixian Zhao,Wenjie Tian,Xiaohai Tian,Jun Zhang,Lei Xie*

Main category: cs.MM

Relevance: 85.0

TL;DR: SABER-LLM：一个用于鲁棒多模态情感推理的框架，通过构建大规模情感推理数据集和结构化证据分解范式，解决MLLMs在细粒度感知和跨模态融合上的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在细粒度感知方面存在显著限制，主要由于数据稀缺和跨模态融合不足，导致单模态主导和幻觉问题，特别是在视觉和听觉线索微妙、模糊或矛盾时（如讽刺场景）。

Method: 1. 构建SABER数据集：包含60万个视频片段，采用新颖的六维标注模式，同时捕捉视听线索和因果逻辑。2. 提出结构化证据分解范式：强制"感知-推理"分离，缓解单模态主导。3. 一致性感知直接偏好优化：在模糊或冲突的感知条件下明确鼓励模态间对齐。

Result: 在EMER、EmoBench-M和SABER-Test上的实验表明，SABER-LLM显著优于开源基线模型，并在解码复杂情感动态方面达到与闭源模型竞争的鲁棒性。

Conclusion: SABER-LLM通过大规模数据集和结构化推理框架，有效解决了多模态情感分析中的细粒度感知和跨模态融合问题，为复杂社会情境中的情感推理提供了更鲁棒的解决方案。

Abstract: Multimodal emotion analysis is shifting from static classification to generative reasoning. Beyond simple label prediction, robust affective reasoning must synthesize fine-grained signals such as facial micro-expressions and prosodic which shifts to decode the latent causality within complex social contexts. However, current Multimodal Large Language Models (MLLMs) face significant limitations in fine-grained perception, primarily due to data scarcity and insufficient cross-modal fusion. As a result, these models often exhibit unimodal dominance which leads to hallucinations in complex multimodal interactions, particularly when visual and acoustic cues are subtle, ambiguous, or even contradictory (e.g., in sarcastic scenery). To address this, we introduce SABER-LLM, a framework designed for robust multimodal reasoning. First, we construct SABER, a large-scale emotion reasoning dataset comprising 600K video clips, annotated with a novel six-dimensional schema that jointly captures audiovisual cues and causal logic. Second, we propose the structured evidence decomposition paradigm, which enforces a "perceive-then-reason" separation between evidence extraction and reasoning to alleviate unimodal dominance. The ability to perceive complex scenes is further reinforced by consistency-aware direct preference optimization, which explicitly encourages alignment among modalities under ambiguous or conflicting perceptual conditions. Experiments on EMER, EmoBench-M, and SABER-Test demonstrate that SABER-LLM significantly outperforms open-source baselines and achieves robustness competitive with closed-source models in decoding complex emotional dynamics. The dataset and model are available at https://github.com/zxzhao0/SABER-LLM.

</details>


### [59] [RAM-SD: Retrieval-Augmented Multi-agent framework for Sarcasm Detection](https://arxiv.org/abs/2601.17002)
*Ziyang Zhou,Ziqi Liu,Yan Wang,Yiming Lin,Yangbin Chen*

Main category: cs.CL

Relevance: 75.0

TL;DR: RAM-SD：基于检索增强的多智能体框架，通过四阶段流程（上下文检索、元规划、多智能体分析、集成）进行讽刺检测，在四个基准测试中达到SOTA的77.74% Macro-F1，比GPT-4o+CoT基线提升7.01个百分点。


<details>
  <summary>Details</summary>
Motivation: 讽刺检测面临重大挑战，因为它依赖于细微的上下文理解、世界知识和多方面的语言线索，这些在不同讽刺表达中差异很大。现有方法（从微调transformer到LLM）对所有输入采用统一的推理策略，难以应对讽刺检测的多样化分析需求，包括建模上下文期望违反、外部知识基础或识别特定修辞模式。

Method: 提出RAM-SD（检索增强多智能体讽刺检测框架），包含四个阶段：1）上下文检索：将查询基于讽刺和非讽刺示例进行基础；2）元规划：分类讽刺类型并从预定义集合中选择最优推理计划；3）专门智能体集成：执行互补的多视角分析；4）集成器：将这些分析综合为最终可解释的判断，并提供自然语言解释。

Result: 在四个标准基准测试中，RAM-SD实现了最先进的77.74% Macro-F1，比强大的GPT-4o+CoT基线高出7.01个百分点。该框架不仅设定了新的性能基准，还提供了透明可解释的推理轨迹，阐明了讽刺理解的认知过程。

Conclusion: RAM-SD通过检索增强和多智能体协作的方法，有效解决了讽刺检测的多样化分析需求，在性能和可解释性方面都取得了显著进步，为复杂语言理解任务提供了新的框架思路。

Abstract: Sarcasm detection remains a significant challenge due to its reliance on nuanced contextual understanding, world knowledge, and multi-faceted linguistic cues that vary substantially across different sarcastic expressions. Existing approaches, from fine-tuned transformers to large language models, apply a uniform reasoning strategy to all inputs, struggling to address the diverse analytical demands of sarcasm. These demands range from modeling contextual expectation violations to requiring external knowledge grounding or recognizing specific rhetorical patterns. To address this limitation, we introduce RAM-SD, a Retrieval-Augmented Multi-Agent framework for Sarcasm Detection. The framework operates through four stages: (1) contextual retrieval grounds the query in both sarcastic and non-sarcastic exemplars; (2) a meta-planner classifies the sarcasm type and selects an optimal reasoning plan from a predefined set; (3) an ensemble of specialized agents performs complementary, multi-view analysis; and (4) an integrator synthesizes these analyses into a final, interpretable judgment with a natural language explanation. Evaluated on four standard benchmarks, RAM-SD achieves a state-of-the-art Macro-F1 of 77.74%, outperforming the strong GPT-4o+CoC baseline by 7.01 points. Our framework not only sets a new performance benchmark but also provides transparent and interpretable reasoning traces, illuminating the cognitive processes behind sarcasm comprehension.

</details>


### [60] [Beyond Factual QA: Mentorship-Oriented Question Answering over Long-Form Multilingual Content](https://arxiv.org/abs/2601.17173)
*Parth Bhalerao,Diola Dsouza,Ruiwen Guan,Oana Ignat*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出了MentorQA，首个专注于指导性问答的多语言数据集和评估框架，包含近9000个QA对，来自4种语言的180小时长视频内容。定义了超越事实准确性的指导性评估维度，比较了多种问答架构，发现多智能体管道在指导性回答质量上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有问答系统主要评估事实准确性，但许多实际应用（如教育和职业指导）需要指导性回答——提供反思和指导。现有QA基准很少捕捉这种区别，特别是在多语言和长文本场景中。

Method: 构建了MentorQA数据集，包含近9000个QA对，来自4种语言的180小时长视频内容。定义了指导性评估维度（清晰度、对齐度、学习价值）。在受控条件下比较了单智能体、双智能体、RAG和多智能体QA架构，并分析了基于LLM的自动评估的可靠性。

Result: 多智能体管道始终产生更高质量的指导性回答，在复杂主题和低资源语言方面表现尤为突出。观察到自动LLM评估与人类判断之间存在显著差异，表明评估设计的重要性。

Conclusion: 确立了指导性问答作为一个独立的研究问题，为教育AI中的智能体架构和评估设计研究提供了多语言基准。数据集和评估框架已开源。

Abstract: Question answering systems are typically evaluated on factual correctness, yet many real-world applications-such as education and career guidance-require mentorship: responses that provide reflection and guidance. Existing QA benchmarks rarely capture this distinction, particularly in multilingual and long-form settings. We introduce MentorQA, the first multilingual dataset and evaluation framework for mentorship-focused question answering from long-form videos, comprising nearly 9,000 QA pairs from 180 hours of content across four languages. We define mentorship-focused evaluation dimensions that go beyond factual accuracy, capturing clarity, alignment, and learning value. Using MentorQA, we compare Single-Agent, Dual-Agent, RAG, and Multi-Agent QA architectures under controlled conditions. Multi-Agent pipelines consistently produce higher-quality mentorship responses, with especially strong gains for complex topics and lower-resource languages. We further analyze the reliability of automated LLM-based evaluation, observing substantial variation in alignment with human judgments. Overall, this work establishes mentorship-focused QA as a distinct research problem and provides a multilingual benchmark for studying agentic architectures and evaluation design in educational AI. The dataset and evaluation framework are released at https://github.com/AIM-SCU/MentorQA.

</details>


### [61] [Frame-Guided Synthetic Claim Generation for Automatic Fact-Checking Using High-Volume Tabular Data](https://arxiv.org/abs/2601.17232)
*Jacob Devasier,Akshith Putta,Qing Wang,Alankrit Moses,Chengkai Li*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出大规模多语言事实核查数据集，包含78,503个基于复杂OECD表格的合成声明，强调真实世界大规模结构化数据验证的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有自动事实核查基准主要关注小型、精选表格，忽略了验证真实世界高容量结构化数据的挑战，需要填补这一关键空白。

Method: 提出框架引导方法：基于六个语义框架程序化选择重要数据点生成多语言声明；通过知识探测实验确保LLM未记忆这些事实；提供SQL生成基线系统。

Result: 基准极具挑战性，证据检索是主要瓶颈，模型难以在超大规模表格中找到正确数据；LLM知识探测显示未记忆这些事实，确保需要真实检索和推理。

Conclusion: 该数据集为解决未解决的真实世界问题提供了关键新资源，推动大规模结构化数据验证研究。

Abstract: Automated fact-checking benchmarks have largely ignored the challenge of verifying claims against real-world, high-volume structured data, instead focusing on small, curated tables. We introduce a new large-scale, multilingual dataset to address this critical gap. It contains 78,503 synthetic claims grounded in 434 complex OECD tables, which average over 500K rows each. We propose a novel, frame-guided methodology where algorithms programmatically select significant data points based on six semantic frames to generate realistic claims in English, Chinese, Spanish, and Hindi. Crucially, we demonstrate through knowledge-probing experiments that LLMs have not memorized these facts, forcing systems to perform genuine retrieval and reasoning rather than relying on parameterized knowledge. We provide a baseline SQL-generation system and show that our benchmark is highly challenging. Our analysis identifies evidence retrieval as the primary bottleneck, with models struggling to find the correct data in massive tables. This dataset provides a critical new resource for advancing research on this unsolved, real-world problem.

</details>


### [62] [Revisiting Modality Invariance in a Multilingual Speech-Text Model via Neuron-Level Analysis](https://arxiv.org/abs/2601.17387)
*Toshiki Nakai,Varsha Suresh,Vera Demberg*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该论文研究了SeamlessM4T v2多语言语音-文本基础模型中语言和模态的内部表示一致性，发现存在不完全的模态不变性，特别是在语音到文本转换时解码器难以恢复源语言信息。


<details>
  <summary>Details</summary>
Motivation: 多语言语音-文本基础模型旨在统一处理不同模态和语言，但尚不清楚模型内部是否对同一语言的语音和文本形式保持一致的表示。研究者希望探究模型在语言和模态信息编码方面的内部机制。

Method: 采用三种互补分析方法：1) 使用平均精度排名识别语言和模态选择性神经元；2) 通过推理时的中值替换干预研究神经元功能作用；3) 分析跨语言和模态的激活幅度不平等性。

Result: 发现不完全的模态不变性：编码器表示逐渐变得语言无关，但这种压缩使共享解码器在构建模态无关表示时更难恢复源语言信息，特别是从语音到文本的适应。在交叉注意力键值投影中观察到高度局部化的模态选择性结构。语音条件解码和非主导文字表现出更高的激活集中度。

Conclusion: 多语言语音-文本基础模型在模态不变性方面存在局限性，特别是在跨模态语言恢复方面。激活集中现象可能解释了跨模态和语言的脆弱性增加。

Abstract: Multilingual speech-text foundation models aim to process language uniformly across both modality and language, yet it remains unclear whether they internally represent the same language consistently when it is spoken versus written. We investigate this question in SeamlessM4T v2 through three complementary analyses that probe where language and modality information is encoded, how selective neurons causally influence decoding, and how concentrated this influence is across the network. We identify language- and modality-selective neurons using average-precision ranking, investigate their functional role via median-replacement interventions at inference time, and analyze activation-magnitude inequality across languages and modalities. Across experiments, we find evidence of incomplete modality invariance. Although encoder representations become increasingly language-agnostic, this compression makes it more difficult for the shared decoder to recover the language of origin when constructing modality-agnostic representations, particularly when adapting from speech to text. We further observe sharply localized modality-selective structure in cross-attention key and value projections. Finally, speech-conditioned decoding and non-dominant scripts exhibit higher activation concentration, indicating heavier reliance on a small subset of neurons, which may underlie increased brittleness across modalities and languages.

</details>


### [63] [Learning to Ideate for Machine Learning Engineering Agents](https://arxiv.org/abs/2601.17596)
*Yunxiang Zhang,Kang Zhou,Zhichao Xu,Kiran Ramnath,Yun Zhou,Sangmin Woo,Haibo Ding,Lin Lee Cheong*

Main category: cs.CL

Relevance: 75.0

TL;DR: MLE-Ideator：一个双智能体框架，将机器学习工程中的构思与实现分离，通过专门的构思智能体帮助实现智能体进行算法迭代优化，显著提升MLE任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习工程（MLE）智能体在迭代优化算法效果方面存在困难，需要分离构思与实现过程来提升优化能力。

Method: 提出MLE-Ideator双智能体框架：实现智能体负责执行，构思智能体专门提供战略帮助。构思智能体可通过强化学习训练，仅需少量任务样本即可提升构思质量。

Result: 1) 无训练设置下，该框架在MLE-Bench上显著优于仅实现智能体基线；2) 强化学习训练的Qwen3-8B构思智能体仅用1K样本就实现11.5%相对提升，超越Claude Sonnet 3.5。

Conclusion: 分离构思与实现的双智能体框架能有效提升机器学习工程任务性能，为训练战略AI系统进行科学发现提供了有前景的路径。

Abstract: Existing machine learning engineering (MLE) agents struggle to iteratively optimize their implemented algorithms for effectiveness. To address this, we introduce MLE-Ideator, a dual-agent framework that separates ideation from implementation. In our system, an implementation agent can request strategic help from a dedicated Ideator. We show this approach is effective in two ways. First, in a training-free setup, our framework significantly outperforms implementation-only agent baselines on MLE-Bench. Second, we demonstrate that the Ideator can be trained with reinforcement learning (RL) to generate more effective ideas. With only 1K training samples from 10 MLE tasks, our RL-trained Qwen3-8B Ideator achieves an 11.5% relative improvement compared to its untrained counterpart and surpasses Claude Sonnet 3.5. These results highlights a promising path toward training strategic AI systems for scientific discovery.

</details>


### [64] [What Language Models Know But Don't Say: Non-Generative Prior Extraction for Generalization](https://arxiv.org/abs/2601.17609)
*Sara Rezaeimanesh,Mohammad M. Ghassemi*

Main category: cs.CL

Relevance: 75.0

TL;DR: LoID：一种从大语言模型中提取先验分布的方法，通过直接访问token级预测来获取贝叶斯逻辑回归的信息先验，在协变量偏移的OOD场景下显著提升性能


<details>
  <summary>Details</summary>
Motivation: 在医学和金融等领域，大规模标注数据成本高昂且难以获取，导致在小数据集上训练的模型难以泛化到真实世界人群。大语言模型包含了这些领域多年的研究知识，但如何有效提取这些知识用于统计建模是一个挑战。

Method: LoID（Logit-Informed Distributions）是一种确定性方法，通过精心构造的句子探测LLM在相反语义方向（正面vs负面影响）上的置信度，测量LLM在不同表述中一致偏好某个方向的程度，从而提取模型对每个特征影响的强度和可靠性信念。

Result: 在10个真实世界表格数据集上的合成OOD设置（协变量偏移）评估中，LoID显著改善了在OOD数据上训练的逻辑回归性能，恢复了相对于全数据集拟合的oracle模型高达59%的性能差距。在8/10的数据集上优于AutoElicit和LLMProcesses方法。

Conclusion: LoID提供了一种可重复且计算高效的机制，将LLM知识整合到贝叶斯推理中，特别是在数据稀缺且存在分布偏移的场景下，能够有效利用LLM的领域知识提升模型泛化能力。

Abstract: In domains like medicine and finance, large-scale labeled data is costly and often unavailable, leading to models trained on small datasets that struggle to generalize to real-world populations. Large language models contain extensive knowledge from years of research across these domains. We propose LoID (Logit-Informed Distributions), a deterministic method for extracting informative prior distributions for Bayesian logistic regression by directly accessing their token-level predictions. Rather than relying on generated text, we probe the model's confidence in opposing semantic directions (positive vs. negative impact) through carefully constructed sentences. By measuring how consistently the LLM favors one direction across diverse phrasings, we extract the strength and reliability of the model's belief about each feature's influence. We evaluate LoID on ten real-world tabular datasets under synthetic out-of-distribution (OOD) settings characterized by covariate shift, where the training data represents only a subset of the population. We compare our approach against (1) standard uninformative priors, (2) AutoElicit, a recent method that prompts LLMs to generate priors via text completions, (3) LLMProcesses, a method that uses LLMs to generate numerical predictions through in-context learning and (4) an oracle-style upper bound derived from fitting logistic regression on the full dataset. We assess performance using Area Under the Curve (AUC). Across datasets, LoID significantly improves performance over logistic regression trained on OOD data, recovering up to \textbf{59\%} of the performance gap relative to the oracle model. LoID outperforms AutoElicit and LLMProcessesc on 8 out of 10 datasets, while providing a reproducible and computationally efficient mechanism for integrating LLM knowledge into Bayesian inference.

</details>


### [65] [UrduLM: A Resource-Efficient Monolingual Urdu Language Model](https://arxiv.org/abs/2601.17664)
*Syed Muhammad Ali,Hammad Sajid,Zainab Haider,Ali Muhammad Asad,Haya Fatima,Abdul Samad*

Main category: cs.CL

Relevance: 75.0

TL;DR: UrduLM：首个专门针对乌尔都语的单语预训练语言模型，在低资源环境下训练，性能优于多语言模型且计算成本更低


<details>
  <summary>Details</summary>
Motivation: 乌尔都语有2.3亿使用者，但缺乏专门的Transformer语言模型和高质量语料库。现有多语言模型对乌尔都语支持有限，存在性能差、计算成本高、文化不准确等问题

Method: 1. 从多样来源整理33GB乌尔都语语料库；2. 开发定制BPE分词器，比多语言分词器减少20-30%分词开销；3. 预训练100M参数的仅解码器模型

Result: 在小样本评估中，UrduLM性能与比其大30倍的多语言模型相当：情感分类准确率达66.6%，语法纠正任务BLEU分数超过30

Conclusion: UrduLM为乌尔都语NLP研究建立了基线，为其他资源不足语言提供了可扩展框架。完整方法（语料、分词器、模型权重、评估基准）已开源

Abstract: Urdu, spoken by 230 million people worldwide, lacks dedicated transformer-based language models and curated corpora. While multilingual models provide limited Urdu support, they suffer from poor performance, high computational costs, and cultural inaccuracies due to insufficient training data. To address these challenges, we present UrduLM, a pretrained Urdu monolingual language model trained in low-resource settings. We curate a 33GB Urdu corpus from diverse sources, develop a custom BPE tokenizer that reduces tokenization overhead by atleast 20-30% compared to multilingual alternatives, and pretrain a 100M-parameter decoder-only model. In few-shot evaluations, UrduLM achieves competitive performance with multilingual models up to 30x its size, reaching 66.6% accuracy on sentiment classification and BLEU scores exceeding 30 on grammar correction tasks. The complete methodology -- including corpus, tokenizer, model weights, and evaluation benchmarks -- is released openly to establish a baseline for Urdu NLP research and provide a scalable framework for other underrepresented languages.

</details>


### [66] [A Computational Approach to Visual Metonymy](https://arxiv.org/abs/2601.17706)
*Saptarshi Ghosh,Linfeng Liu,Tianyu Jiang*

Main category: cs.CL

Relevance: 75.0

TL;DR: 本文首次对视觉转喻进行系统性计算研究，提出了基于符号学理论的生成框架，并创建了ViMET数据集来评估多模态模型处理间接视觉参考的能力。


<details>
  <summary>Details</summary>
Motivation: 图像常常传达比字面描绘更多的信息（如工具暗示职业、文物暗示传统），这种间接视觉参考（视觉转喻）是人类认知的重要能力，但现有计算模型对此缺乏研究。作者旨在填补这一空白，探索机器理解间接视觉信息的能力。

Method: 1. 提出基于符号学理论的生成框架，结合大语言模型和文生图模型生成转喻性视觉表示
2. 构建ViMET数据集，包含2000个多项选择题，评估多模态模型的认知推理能力
3. 对比人类表现与最先进视觉语言模型的性能差异

Result: 实验结果显示：人类准确率86.9%，而最先进视觉语言模型仅65.9%，存在显著差距。这表明当前模型在理解间接视觉参考方面存在明显局限性。

Conclusion: 视觉转喻是机器视觉理解的重要挑战，现有模型在此任务上表现不足。ViMET数据集为评估和提升多模态模型的认知推理能力提供了基准，有助于推动更深入理解视觉语义的研究。

Abstract: Images often communicate more than they literally depict: a set of tools can suggest an occupation and a cultural artifact can suggest a tradition. This kind of indirect visual reference, known as visual metonymy, invites viewers to recover a target concept via associated cues rather than explicit depiction. In this work, we present the first computational investigation of visual metonymy. We introduce a novel pipeline grounded in semiotic theory that leverages large language models and text-to-image models to generate metonymic visual representations. Using this framework, we construct ViMET, the first visual metonymy dataset comprising 2,000 multiple-choice questions to evaluate the cognitive reasoning abilities in multimodal language models. Experimental results on our dataset reveal a significant gap between human performance (86.9%) and state-of-the-art vision-language models (65.9%), highlighting limitations in machines' ability to interpret indirect visual references. Our dataset is publicly available at: https://github.com/cincynlp/ViMET.

</details>


### [67] [Linguistic and Argument Diversity in Synthetic Data for Function-Calling Agents](https://arxiv.org/abs/2601.17829)
*Dan Greenstein,Zohar Karnin,Chen Amiraz,Oren Somekh*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出一种通过优化通用多样性指标来生成函数调用代理训练数据的方法，在保持正确性的同时提升查询和参数的多样性，并在OOD性能上表现优异。


<details>
  <summary>Details</summary>
Motivation: 构建函数调用代理需要高质量、多样化的训练数据。现有工作关注函数、调用模式和交互轮次的多样性，但请求的语言多样性和参数覆盖（如城市名、股票代码）仍未被充分探索。

Method: 提出一种生成合成数据集的方法，通过优化查询和参数的通用多样性指标，不依赖手工规则或分类法，使其适用于不同用例。

Result: 在内在和外在测试中均优于现有数据生成方法，在保持可比正确性的同时显著提升多样性。使用该数据集训练的模型在分布外性能上优于基线方法，在BFCL基准上准确率提升7.4%。

Conclusion: 该方法能有效生成高质量、多样化的函数调用代理训练数据，提升模型在未见场景下的泛化能力。

Abstract: The construction of function calling agents has emerged as a promising avenue for extending model capabilities. A major challenge for this task is obtaining high quality diverse data for training. Prior work emphasizes diversity in functions, invocation patterns, and interaction turns, yet linguistic diversity of requests and coverage of arguments (e.g., \texttt{city\_name}, \texttt{stock\_ticker}) remain underexplored. We propose a method that generates synthetic datasets via optimizing general-purpose diversity metrics across both queries and arguments, without relying on hand-crafted rules or taxonomies, making it robust to different usecases. We demonstrate the effectiveness of our technique via both intrinsic and extrinsic testing, comparing it to SoTA data generation methods. We show a superiority over baselines in terms of diversity, while keeping comparable correctness. Additionally, when used as a training set, the model resulting from our dataset exhibits superior performance compared to analogous models based on the baseline data generation methods in out-of-distribution performance. In particular, we achieve an $7.4\%$ increase in accuracy on the BFCL benchmark compared to similar counterparts.

</details>


### [68] [EFT-CoT: A Multi-Agent Chain-of-Thought Framework for Emotion-Focused Therapy](https://arxiv.org/abs/2601.17842)
*Lanqing Du,Yunong Li,YuJie Long,Shihong Chen*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出基于情绪聚焦疗法(EFT)的多智能体思维链框架(EFT-CoT)，用于心理健康问答，通过"自下而上"的三阶段推理流程提升共情深度和专业性。


<details>
  <summary>Details</summary>
Motivation: 现有基于认知行为疗法(CBT)的心理健康问答方法主要采用"自上而下"的理性重构，往往忽视来访者的具身体验和初级情绪处理。需要一种更关注情绪体验的"自下而上"方法。

Method: 提出EFT-CoT框架，采用三阶段推理流程：1)具身感知，2)认知探索，3)叙事干预。使用8个专门智能体执行躯体意识映射、适应性评估、核心信念提取和叙事重构等关键组件。构建包含约67,000条真实文本的EFT-Instruct数据集，并微调专门模型EFT-LLM。

Result: EFT-LLM在共情深度和结构专业性等指标上优于强基线模型和人类回应。消融研究证实了多智能体机制的必要性。模型展现出优越的心理推理能力。

Conclusion: EFT-CoT为可解释、高共情的心理咨询系统提供了有效途径，通过多智能体思维链框架实现了更全面的心理健康干预。

Abstract: Leveraging Large Language Models (LLMs) for Mental Health Question Answering (MHQA) is promising for mitigating resource shortages. However, existing Cognitive Behavioral Therapy (CBT)-based approaches predominantly favor a "top-down" rational restructuring, often neglecting clients' embodied experiences and primary emotion processing. To address this, we propose an Emotion-Focused Therapy (EFT)-based Multi-Agent Chain-of-Thought framework (EFT-CoT). Adopting a "bottom-up" trajectory, it deconstructs the intervention into a three-stage reasoning flow: "Embodied Perception - Cognitive Exploration - Narrative Intervention." Utilizing eight specialized agents, the system explicitly executes critical components such as somatic awareness mapping, adaptive assessment, core belief extraction, and narrative restructuring. We further constructed "EFT-Instruct," a high-quality dataset via Chain-of-Thought distillation of approximately 67,000 authentic texts, and fine-tuned a specialized model, EFT-LLM. Experimental evaluations demonstrate that EFT-LLM outperforms strong baselines and human responses across metrics like empathy depth and structural professionalism. Ablation studies confirm the necessity of the multi-agent mechanism. The model exhibits superior psychological reasoning, offering an effective pathway for interpretable, high-empathy counseling systems.

</details>


### [69] [On the Emergence and Test-Time Use of Structural Information in Large Language Models](https://arxiv.org/abs/2601.17869)
*Michelle Chao Chen,Moritz Miller,Bernhard Schölkopf,Siyuan Guo*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该论文研究了语言模型如何从观测数据中学习抽象结构信息，并利用这些结构信息进行测试时的组合生成。研究发现结构学习与复杂推理任务相关，但测试时的组合生成能力仍然有限。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解语言模型如何从观测数据中学习结构信息，这对于科学发现中的机制理解和灵活的测试时组合生成都至关重要。作者希望探究语言模型学习抽象结构的能力以及如何利用这些结构信息。

Method: 方法包括设计基于语言结构转换的自然语言数据集，在受控设置下进行实验。通过实证研究分析语言模型学习结构信息的能力，以及测试时组合生成的性能。

Result: 实证结果显示：1）结构信息学习与复杂推理任务的出现相关；2）测试时组合生成的能力仍然有限，表明语言模型在利用学习到的结构信息进行灵活生成方面存在局限性。

Conclusion: 结论是语言模型能够学习到一定的结构信息，特别是在复杂推理任务中，但在测试时利用这些结构信息进行组合生成的能力仍然不足。这为理解语言模型的结构学习机制和组合泛化能力提供了重要见解。

Abstract: Learning structural information from observational data is central to producing new knowledge outside the training corpus. This holds for mechanistic understanding in scientific discovery as well as flexible test-time compositional generation. We thus study how language models learn abstract structures and utilize the learnt structural information at test-time. To ensure a controlled setup, we design a natural language dataset based on linguistic structural transformations. We empirically show that the emergence of learning structural information correlates with complex reasoning tasks, and that the ability to perform test-time compositional generation remains limited.

</details>


### [70] [Self-Manager: Parallel Agent Loop for Long-form Deep Research](https://arxiv.org/abs/2601.17879)
*Yilong Xu,Zhi Zheng,Xiang Long,Yujun Cai,Yiwei Wang*

Main category: cs.CL

Relevance: 75.0

TL;DR: Self-Manager：一种并行代理循环框架，通过多线程隔离上下文实现异步并发执行，解决长文本深度研究中单上下文窗口和顺序执行的限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有代理在处理长文本深度研究任务时，虽然能在子任务级别管理上下文以避免线性上下文累积和信息丢失，但仍受限于单一上下文窗口和顺序执行范式，导致相互干扰和阻塞行为，限制了可扩展性和适应性。

Method: 提出Self-Manager并行代理循环框架：主线程可创建多个子线程，每个子线程拥有独立的隔离上下文，通过线程控制块进行迭代管理，实现更专注、灵活的并行代理执行。

Result: 在DeepResearch Bench基准测试中，Self-Manager在所有指标上均优于现有的单代理循环基线。分析实验证明了其设计选择的必要性，以及在上下文容量、效率和泛化方面的优势。

Conclusion: Self-Manager通过并行代理循环解决了长文本深度研究中的可扩展性和适应性限制，为复杂任务处理提供了更高效的框架。

Abstract: Long-form deep research requires multi-faceted investigations over extended horizons to get a comprehensive report. When handling such complex tasks, existing agents manage context at the subtask level to overcome linear context accumulation and information loss. However, they still adhere to a single context window and sequential execution paradigm, which results in mutual interference and blocking behavior, restricting scalability and adaptability. To address this issue, this paper introduces Self-Manager, a parallel agent loop that enables asynchronous and concurrent execution. The main thread can create multiple subthreads, each with its own isolated context, and manage them iteratively through Thread Control Blocks, allowing for more focused and flexible parallel agent execution. To assess its effectiveness, we benchmark Self-Manager on DeepResearch Bench, where it consistently outperforms existing single-agent loop baselines across all metrics. Furthermore, we conduct extensive analytical experiments to demonstrate the necessity of Self-Manager's design choices, as well as its advantages in contextual capacity, efficiency, and generalization.

</details>


### [71] [LLMs as Cultural Archives: Cultural Commonsense Knowledge Graph Extraction](https://arxiv.org/abs/2601.17971)
*Junior Cedric Tonga,Chen Cecilia Liu,Iryna Gurevych,Fajri Koto*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文提出了一种基于提示的迭代框架，用于构建文化常识知识图谱（CCKG），将LLMs视为文化档案，系统提取文化特定实体、关系和实践，并跨语言组成多步推理链。


<details>
  <summary>Details</summary>
Motivation: LLMs从大规模网络数据中学习了丰富的文化知识，但这些知识大多是隐式和非结构化的，限制了其可解释性和实际应用。需要系统地将这些文化知识显式化、结构化，以支持文化推理和文化基础的NLP应用。

Method: 采用迭代的、基于提示的框架，将LLMs作为文化档案，系统提取文化特定实体、关系和实践，并将它们组合成跨语言的多步推理链，构建文化常识知识图谱（CCKG）。

Result: 在五个国家进行人工评估，发现文化知识图谱在英语中实现得更好，即使目标文化是非英语的（如中文、印尼语、阿拉伯语），表明当前LLMs中的文化编码不均匀。用CCKG增强较小的LLMs可以改善文化推理和故事生成性能，其中英语链带来的提升最大。

Conclusion: 研究展示了LLMs作为文化技术的潜力和局限性，链式结构化的文化知识是文化基础NLP的实用基础。文化知识在LLMs中的编码存在语言偏差，英语表现最佳。

Abstract: Large language models (LLMs) encode rich cultural knowledge learned from diverse web-scale data, offering an unprecedented opportunity to model cultural commonsense at scale. Yet this knowledge remains mostly implicit and unstructured, limiting its interpretability and use. We present an iterative, prompt-based framework for constructing a Cultural Commonsense Knowledge Graph (CCKG) that treats LLMs as cultural archives, systematically eliciting culture-specific entities, relations, and practices and composing them into multi-step inferential chains across languages. We evaluate CCKG on five countries with human judgments of cultural relevance, correctness, and path coherence. We find that the cultural knowledge graphs are better realized in English, even when the target culture is non-English (e.g., Chinese, Indonesian, Arabic), indicating uneven cultural encoding in current LLMs. Augmenting smaller LLMs with CCKG improves performance on cultural reasoning and story generation, with the largest gains from English chains. Our results show both the promise and limits of LLMs as cultural technologies and that chain-structured cultural knowledge is a practical substrate for culturally grounded NLP.

</details>


### [72] [Addressing LLM Diversity by Infusing Random Concepts](https://arxiv.org/abs/2601.18053)
*Pulin Agrawal,Prasoon Goyal*

Main category: cs.CL

Relevance: 75.0

TL;DR: 研究发现，在提示词前添加随机概念可以显著提高大语言模型输出的多样性，并通过系统评估协议验证了这一效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的输出多样性通常有限，本研究旨在探索通过提示词注入随机概念是否能改善输出多样性，为LLM多样性提升提供新思路。

Method: 设计系统评估协议，以"列举10位好莱坞演员"等格式提问，在提示词前添加随机单词/句子，分析多个LLM输出的多样性指标。

Result: 实验表明，在提示词前添加与主题无关的随机内容能显著提高LLM输出的多样性，这一发现具有统计显著性。

Conclusion: 随机性注入是提升LLM输出多样性的有效方法，提出的评估协议为系统化评估LLM多样性提供了新框架，未来可应用于其他领域。

Abstract: Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form "Name 10 Hollywood actors", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically.

</details>


### [73] [Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue](https://arxiv.org/abs/2601.18281)
*Yuhang Jia,Pei Liu,Haoqin Sun,Jiaming Zhou,Xuxin Cheng,Cao Liu,Ke Zeng,Xunliang Cai,Yong Qin*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出了ReEmpathy模型，通过引入描述性自然语言评估模型EmpathyEval和共情自反交替推理机制，增强端到端口语语言模型的共情对话能力。


<details>
  <summary>Details</summary>
Motivation: 现有端到端口语语言模型在共情对话中过度依赖刚性监督信号（如监督微调中的真实响应或强化学习中的偏好分数），这些方法无法充分建模复杂的共情，因为不存在单一的"正确"响应，简单的数值分数也无法完全捕捉情感表达的细微差别或共情行为的适当性。

Method: 1. 首先提出EmpathyEval：基于描述性自然语言的评估模型，用于评估口语对话中的共情质量；2. 在此基础上提出ReEmpathy：端到端口语语言模型，采用新颖的共情自反交替推理机制，交替进行口语响应生成和自由形式的共情相关反思推理。

Result: 大量实验表明，ReEmpathy通过启用反思推理，显著改善了共情敏感的口语对话，为更情感智能和共情感知的人机交互提供了有前景的方法。

Conclusion: 该研究通过引入描述性评估和反思推理机制，解决了现有方法在建模复杂共情方面的局限性，推动了端到端口语语言模型在共情对话方面的发展。

Abstract: End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single "correct" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.

</details>


### [74] [Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning](https://arxiv.org/abs/2601.18296)
*Zhaoyan Gong,Zhiqiang Liu,Songze Li,Xiaoke Guo,Yuanxiang Liu,Xinle Deng,Zhizhen Liu,Lei Liang,Huajun Chen,Wen Zhang*

Main category: cs.CL

Relevance: 75.0

TL;DR: Temp-R1是首个通过强化学习训练的端到端自主TKGQA代理，通过扩展动作空间和反向课程学习，在复杂时序知识图谱问答任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有TKGQA方法依赖固定工作流程和昂贵的闭源API，限制了灵活性和可扩展性。时序知识图谱问答需要复杂的动态事实推理，具有多跳依赖和复杂时序约束。

Method: 1) 提出首个通过强化学习训练的自主端到端TKGQA代理Temp-R1；2) 扩展动作空间，包含专门内部动作和外部动作，解决单动作推理的认知过载；3) 引入反向课程学习，先训练困难问题再迁移到简单问题，防止捷径学习。

Result: 8B参数的Temp-R1在MultiTQ和TimelineKGQA上达到SOTA性能，在复杂问题上比强基线提升19.8%。

Conclusion: Temp-R1为自主时序推理代理建立了新范式，通过强化学习训练和课程学习策略有效解决了TKGQA的挑战。

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1.

</details>


### [75] [Hierarchical Text Classification with LLM-Refined Taxonomies](https://arxiv.org/abs/2601.18375)
*Jonas Golde,Nicolaas Jedema,Ravi Krishnan,Phong Le*

Main category: cs.CL

Relevance: 75.0

TL;DR: TaxMorph使用LLMs重构层次文本分类的标签分类体系，通过重命名、合并、拆分和重排序操作，使分类体系更符合LLMs的语义理解，在三个基准测试中性能提升高达2.9个百分点的F1分数。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的层次分类体系存在模糊性，如相似父节点下的相同叶子名称，这阻碍了语言模型学习清晰的决策边界。需要改进分类体系以更好地匹配LLMs的语义编码。

Method: TaxMorph框架使用大型语言模型对整个分类体系进行重构，包括重命名、合并、拆分和重排序操作，使分类体系更符合LLMs的语义理解。

Result: 在三个层次文本分类基准测试中，LLM重构的分类体系在各种设置下始终优于人工构建的分类体系，F1分数提升高达2.9个百分点。

Conclusion: LLM引导的分类体系重构创建了更符合模型学习方式的分类体系，即使它们在嵌入空间中更难分离，但更好地反映了模型的归纳偏差，从而提高了层次文本分类性能。

Abstract: Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance.

</details>


### [76] [Latent Knowledge as a Predictor of Fact Acquisition in Fine-Tuned Large Language Models](https://arxiv.org/abs/2601.18468)
*Daniel B. Hier,Tayo Obafemi-Ajayi*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该研究探讨了LLMs中生物医学知识的存储方式：有些知识以潜在知识形式存在（存在于权重中但确定性解码无法可靠访问），有些则很少被表示。通过微调Llama 3.1 8B学习本体术语标识符映射，研究发现潜在知识能预测事实学习速度、有限泛化能力，而抗退化能力取决于训练中是否得到强化。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解大型语言模型中生物医学事实的存储特性——有些事实以潜在知识形式存在（存在于权重中但确定性解码无法可靠访问），有些则很少被表示。研究者希望通过微调实验探究这些不同存储状态如何影响事实学习、泛化和退化过程。

Method: 方法包括：1）使用Llama 3.1 8B Instruct模型；2）从人类表型本体（800对）和基因本体（400训练对）学习本体术语标识符映射；3）保留400个GO对测试泛化；4）将学习视为时间事件过程（20个epoch）；5）使用随机解码检测基线潜在知识；6）应用Cox比例风险模型识别获取、泛化和退化的预测因子。

Result: 结果：1）HPO基线确定性召回率仅2.8%，微调后升至71.9%；2）潜在知识是最强预测因子（HR 2.6），与更早、更高的峰值学习率和更快收敛相关；3）泛化到保留GO事实不常见（5.8%），但潜在知识存在时可能性更高；4）先前正确的GO映射在未见过术语中比训练过术语退化更频繁，表明训练强化具有保护作用。

Conclusion: 结论：潜在知识能预测微调期间事实学习速度和未见本体事实的有限泛化能力，而抗退化能力取决于事实是否在训练中得到强化。这揭示了LLMs中知识存储的异质性对后续学习行为的影响。

Abstract: Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced.

</details>


### [77] [Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research](https://arxiv.org/abs/2601.18512)
*Antonio Garzon-Vico,Krithika Sharon Komalapati,Arsalan Shahid,Jan Rosier*

Main category: cs.CL

Relevance: 75.0

TL;DR: 使用LLM创建真实高管虚拟人格的方法框架，通过CEO沟通和道德基础理论构建模拟领导者决策的LLM参与者，验证其结构效度、信度和行为保真度。


<details>
  <summary>Details</summary>
Motivation: 在组织研究中，直接接触高管存在困难，需要开发能够模拟领导者决策的替代工具。LLM提供了创建虚拟人格的潜力，但需要验证其能否准确反映真实高管的道德判断和决策行为。

Method: 基于真实CEO沟通数据和道德基础理论，构建LLM虚拟人格。通过三个阶段评估：1) 结构效度验证；2) 信度测试；3) 行为保真度基准测试，将虚拟CEO与人类参与者进行比较。

Result: 理论支撑的虚拟人格能够近似人类样本中观察到的道德判断，表明LLM虚拟人格可以作为组织研究中可信且互补的工具，特别是在难以直接接触高管的情况下。

Conclusion: LLM虚拟人格为组织研究提供了新的方法论工具，特别是在高管难以接触的场景下。未来研究可以进一步探索在组织环境中的应用。

Abstract: This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.

</details>


### [78] [From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection](https://arxiv.org/abs/2601.18582)
*Yuan Cao,Feixiang Liu,Xinyue Wang,Yihan Zhu,Hui Xu,Zheng Wang,Qiang Qiu*

Main category: cs.CL

Relevance: 75.0

TL;DR: 该论文提出了一种基于强化学习的人格检测新方法，将人格检测视为排序任务而非分类任务，通过监督微调和分组相对策略优化来提升LLM在人格特质分析上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的人格检测方法存在两个主要问题：1）人格特质的复杂性和细微差异使得准确分类具有挑战性；2）基于提示的方法过度依赖专家知识，缺乏自主模式学习能力。需要一种能更好处理人格评估主观性和模糊边界的新方法。

Method: 提出两阶段方法：1）使用监督微调（SFT）建立人格特质排序能力并标准化输出格式；2）引入分组相对策略优化（GRPO）和专门的基于排序的奖励函数，训练LLM学习最优答案排序。

Result: 在多个基准测试中实现了最先进的性能，证明了该方法在人格检测任务上的有效性。

Conclusion: 将人格检测重新定义为排序任务并结合强化学习训练范式，能够更好地处理人格评估的主观性和模糊边界，相比传统分类方法取得了显著改进。

Abstract: Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.

</details>


### [79] [Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings](https://arxiv.org/abs/2601.18788)
*Mumin Jia,Jairo Diaz-Rodriguez*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出Embed-KCPD方法，一种无监督文本分割技术，使用句子嵌入和惩罚KCPD目标检测边界，无需训练，具有理论保证和实际效果验证。


<details>
  <summary>Details</summary>
Motivation: 无监督文本分割很重要，因为边界标注成本高、主观性强，且难以跨领域和粒度迁移。需要一种无需训练、理论可靠的方法。

Method: 将句子表示为嵌入向量，通过最小化惩罚KCPD目标估计边界。提出首个针对m-依赖序列的依赖感知理论，并建立LLM模拟框架生成可控依赖的合成文档验证理论。

Result: 在标准分割基准测试中，Embed-KCPD通常优于强无监督基线。理论分析证明边界恢复窗口相对于段长很小，模拟验证了预测的缩放行为。

Conclusion: Embed-KCPD结合了强理论保证、模拟可靠性和实际有效性，为无监督文本分割提供了有前景的解决方案。

Abstract: Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.

</details>


### [80] [ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models](https://arxiv.org/abs/2601.18796)
*Brian Ondov,Chia-Hsuan Chang,Yujia Zhou,Mauro Giuffrè,Hua Xu*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出ctELM模型，将大型语言模型与临床试验嵌入对齐，实现从嵌入空间生成和解释临床试验文本


<details>
  <summary>Details</summary>
Motivation: 当前文本嵌入的解释、探索和逆向生成方法有限，限制了透明度和生成应用。特别是在生物医学领域，需要能够理解和操作嵌入空间的方法。

Method: 采用Embedding Language Model (ELM)方法，开发开源、领域无关的ELM架构和训练框架。设计临床试验特定的训练任务，引入专家验证的合成数据集，探索不同任务和训练方案的影响。

Result: 最终模型ctELM能够准确描述和比较未见过的临床试验嵌入，从新向量生成合理的临床试验文本。生成的试验摘要能够响应沿着年龄和性别概念向量的嵌入移动。

Conclusion: 公开的ELM实现和实验结果将有助于在生物医学领域及其他领域对齐大型语言模型与嵌入空间，提高嵌入空间的透明度和生成能力。

Abstract: Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.

</details>


### [81] [The Voice of Equity: A Systematic Evaluation of Bias Mitigation Techniques for Speech-Based Cognitive Impairment Detection Across Architectures and Demographics](https://arxiv.org/abs/2601.16989)
*Yasaman Haghbin,Sina Rashidi,Ali Zolnour,Maryam Zolnoori*

Main category: eess.AS

Relevance: 75.0

TL;DR: 论文提出了首个全面的语音认知障碍检测公平性分析框架，系统评估了不同架构和人口亚组间的偏见缓解效果，发现架构设计对偏见模式和缓解效果有根本性影响。


<details>
  <summary>Details</summary>
Motivation: 语音认知障碍检测虽具可扩展性，但算法在不同人口和语言亚组间的偏见研究不足。当前研究通常只考察单一缓解技术，缺乏系统性公平性分析框架。

Method: 开发了两种基于Transformer的架构（SpeechCARE-AGF和Whisper-LWF-LoRA），在多语言NIA PREPARE数据集上，比较了预处理、处理中和后处理的偏见缓解方法，通过机会均等和平等化赔率评估公平性。

Result: 两种模型性能良好（F1: 70.87和71.46），但存在显著公平性差异：≥80岁老年人敏感性较低，西班牙语使用者TPR低于英语使用者。缓解效果因架构而异：过采样对SpeechCARE-AGF改善老年人检测有效，但对Whisper-LWF-LoRA影响有限。

Conclusion: 架构设计从根本上影响偏见模式和缓解效果，公平性干预必须针对特定模型架构和人口特征进行定制，为开发公平的语音筛查工具提供了系统性框架。

Abstract: Speech-based detection of cognitive impairment offers a scalable, non-invasive screening, yet algorithmic bias across demographic and linguistic subgroups remains critically underexplored. We present the first comprehensive fairness analysis framework for speech-based multi-class cognitive impairment detection, systematically evaluating bias mitigation across architectures, and demographic subgroups. We developed two transformer-based architectures, SpeechCARE-AGF and Whisper-LWF-LoRA, on the multilingual NIA PREPARE Challenge dataset. Unlike prior work that typically examines single mitigation techniques, we compared pre-processing, in-processing, and post-processing approaches, assessing fairness via Equality of Opportunity and Equalized Odds across gender, age, education, and language. Both models achieved strong performance (F1: SpeechCARE-AGF 70.87, Whisper-LWF-LoRA 71.46) but exhibited substantial fairness disparities. Adults >=80 showed lower sensitivity versus younger groups; Spanish speakers demonstrated reduced TPR versus English speakers. Mitigation effectiveness varied by architecture: oversampling improved SpeechCARE-AGF for older adults (80+ TPR: 46.19%=>49.97%) but minimally affected Whisper-LWF-LoRA. This study addresses a critical healthcare AI gap by demonstrating that architectural design fundamentally shapes bias patterns and mitigation effectiveness. Adaptive fusion mechanisms enable flexible responses to data interventions, while frequency reweighting offers robust improvements across architectures. Our findings establish that fairness interventions must be tailored to both model architecture and demographic characteristics, providing a systematic framework for developing equitable speech-based screening tools essential for reducing diagnostic disparities in cognitive healthcare.

</details>


### [82] [AVMeme Exam: A Multimodal Multilingual Multicultural Benchmark for LLMs' Contextual and Cultural Knowledge and Thinking](https://arxiv.org/abs/2601.17645)
*Xilin Jiang,Qiaolin Wang,Junkai Wu,Xiaomin He,Zhongweiyang Xu,Yinghao Ma,Minshuo Piao,Kaiyi Yang,Xiuwen Zheng,Riki Shimizu,Yicong Chen,Arsalan Firoozi,Gavin Mischler,Sukru Samet Dindar,Richard Antonello,Linyang He,Tsun-An Hsieh,Xulin Fan,Yulun Wu,Yuesheng Ma,Chaitanya Amballa,Weixiong Chen,Jiarui Hai,Ruisi Li,Vishal Choudhari,Cong Han,Yinghao Aaron Li,Adeen Flinker,Mounya Elhilali,Emmanouil Benetos,Mark Hasegawa-Johnson,Romit Roy Choudhury,Nima Mesgarani*

Main category: cs.SD

Relevance: 75.0

TL;DR: AVMeme Exam是一个评估AI模型理解互联网音视频文化背景的基准测试，包含1000多个标志性网络声音和视频，涵盖语音、歌曲、音乐和音效，测试模型从表层内容到上下文、情感、使用和世界知识的理解能力。


<details>
  <summary>Details</summary>
Motivation: 互联网音视频通过随时间变化的声音和动作传达意义，这超出了纯文本能表达的范围。研究旨在探索AI模型是否能在人类文化背景下理解这些信号，揭示当前多模态大语言模型在理解文化背景方面的局限性。

Method: 创建AVMeme Exam基准测试，包含1000多个人类精选的标志性网络声音和视频，每个meme配有独特的问答评估不同理解层次（从表层内容到上下文、情感、使用和世界知识），并包含元数据如原始年份、转录、摘要和敏感性。系统评估最先进的多模态大语言模型，并与人类参与者进行比较。

Result: 当前模型在无文本音乐和音效上表现不佳，与表层内容相比，在上下文和文化背景思考方面存在困难。这表明模型在人类对齐的多模态智能方面存在关键差距。

Conclusion: 需要开发能够超越表层感知、理解上下文和文化背景的模型，以实现真正的人类对齐多模态智能。

Abstract: Internet audio-visual clips convey meaning through time-varying sound and motion, which extend beyond what text alone can represent. To examine whether AI models can understand such signals in human cultural contexts, we introduce AVMeme Exam, a human-curated benchmark of over one thousand iconic Internet sounds and videos spanning speech, songs, music, and sound effects. Each meme is paired with a unique Q&A assessing levels of understanding from surface content to context and emotion to usage and world knowledge, along with metadata such as original year, transcript, summary, and sensitivity. We systematically evaluate state-of-the-art multimodal large language models (MLLMs) alongside human participants using this benchmark. Our results reveal a consistent limitation: current models perform poorly on textless music and sound effects, and struggle to think in context and in culture compared to surface content. These findings highlight a key gap in human-aligned multimodal intelligence and call for models that can perceive contextually and culturally beyond the surface of what they hear and see. Project page: avmemeexam.github.io/public

</details>


### [83] [LegalMALR:Multi-Agent Query Understanding and LLM-Based Reranking for Chinese Statute Retrieval](https://arxiv.org/abs/2601.17692)
*Yunhan Li,Mingjie Xie,Gaoli Kang,Zihan Gong,Gengshen Wu,Min Yang*

Main category: cs.IR

Relevance: 75.0

TL;DR: LegalMALR是一个法律条文检索框架，通过多智能体查询理解系统生成多样化的法律基础重述，结合零样本LLM重排序模块，在中文法律查询数据集上显著优于现有RAG基线。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的法律查询通常是隐含的、多问题的，且以口语化或不完整的形式表达，这使得传统的检索增强生成管道难以准确恢复所需的法律条文要素。密集检索器主要关注查询的字面形式，而轻量级重排序器缺乏评估法律适用性所需的法律推理能力。

Method: 1. 多智能体查询理解系统(MAS)：生成多样化的、有法律依据的重述，并进行迭代密集检索以扩大候选覆盖范围；2. 使用广义强化策略优化(GRPO)来稳定LLM生成重述的随机行为；3. LLM重排序器：执行自然语言法律推理以产生最终排名；4. 构建CSAID数据集：包含118个困难的中文法律查询，带有多个法律条文标签。

Result: 在CSAID数据集和公开的STARD基准测试中，LegalMALR在分布内和分布外设置下都显著优于强大的检索增强生成(RAG)基线，证明了多视角查询解释、基于强化的策略优化和大模型重排序相结合的有效性。

Conclusion: LegalMALR通过结合多智能体查询理解、强化学习策略优化和LLM重排序，有效解决了法律条文检索中的挑战，特别是在处理隐含、多问题和口语化查询方面表现出色。

Abstract: Statute retrieval is essential for legal assistance and judicial decision support, yet real-world legal queries are often implicit, multi-issue, and expressed in colloquial or underspecified forms. These characteristics make it difficult for conventional retrieval-augmented generation pipelines to recover the statutory elements required for accurate retrieval. Dense retrievers focus primarily on the literal surface form of the query, whereas lightweight rerankers lack the legal-reasoning capacity needed to assess statutory applicability. We present LegalMALR, a retrieval framework that integrates a Multi-Agent Query Understanding System (MAS) with a zero-shot large-language-model-based reranking module (LLM Reranker). MAS generates diverse, legally grounded reformulations and conducts iterative dense retrieval to broaden candidate coverage. To stabilise the stochastic behaviour of LLM-generated rewrites, we optimise a unified MAS policy using Generalized Reinforcement Policy Optimization(GRPO). The accumulated candidate set is subsequently evaluated by the LLM Reranker, which performs natural-language legal reasoning to produce the final ranking. We further construct CSAID, a dataset of 118 difficult Chinese legal queries annotated with multiple statutory labels, and evaluate LegalMALR on both CSAID and the public STARD benchmark. Experiments show that LegalMALR substantially outperforms strong Retrieval-augmented generation(RAG) baselines in both in-distribution and out-of-distribution settings, demonstrating the effectiveness of combining multi-perspective query interpretation, reinforcement-based policy optimisation, and large-model reranking for statute retrieval.

</details>


### [84] [Designing large language model prompts to extract scores from messy text: A shared dataset and challenge](https://arxiv.org/abs/2601.18271)
*Mike Thelwall*

Main category: cs.DL

Relevance: 75.0

TL;DR: 该论文提出了一个包含1446个研究质量评分文本的数据集，挑战社区设计最佳LLM提示来准确提取评分，基准准确率为72.6%


<details>
  <summary>Details</summary>
Motivation: 动机是创建一个共享数据集和挑战任务，促进社区在LLM提示设计方面的研究，特别是在处理复杂数值提取任务时，同时解决文本中评分格式混乱、缺失值等问题

Method: 方法包括：1）构建包含1446个研究质量评分文本的数据集（UK 1*-4*评分）；2）提供有效评分的定义和黄金标准标注；3）设计LLM提示挑战任务，要求输出纯数字格式；4）处理缺失值（返回-1）；5）提供简单提示示例作为基准

Result: 论文提供了初始解决方案的基准准确率为72.6%，并建立了完整的评估框架，包括数据集、黄金标准标注和评估指标，为社区提供了可比较的基准

Conclusion: 结论是创建了一个促进LLM提示设计研究的共享挑战，特别关注复杂数值提取任务，为社区提供了标准化的评估平台，有助于推动LLM在结构化信息提取方面的能力发展

Abstract: In some areas of computing, natural language processing and information science, progress is made by sharing datasets and challenging the community to design the best algorithm for an associated task. This article introduces a shared dataset of 1446 short texts, each of which describes a research quality score on the UK scale of 1* to 4*. This is a messy collection, with some texts not containing scores and others including invalid scores or strange formats. With this dataset there is also a description of what constitutes a valid score and a "gold standard" of the correct scores for these texts (including missing values). The challenge is to design a prompt for Large Language Models (LLMs) to extract the scores from these texts as accurately as possible. The format for the response should be a number and no other text so there are two aspects to the challenge: ensuring that the LLM returns only a number, and instructing it to deduce the correct number for the text. As part of this, the LLM prompt needs to explain when to return the missing value code, -1, instead of a number when the text does not clearly contain one. The article also provides an example of a simple prompt. The purpose of the challenge is twofold: to get an effective solution to this problem, and to increase understanding of prompt design and LLM capabilities for complex numerical tasks. The initial solution suggested has an accuracy of 72.6%, so the challenge is to beat this.

</details>


### [85] [Uncertainty Quantification for Named Entity Recognition via Full-Sequence and Subsequence Conformal Prediction](https://arxiv.org/abs/2601.16999)
*Matthew Singer,Srijan Sengupta,Karl Pazdernik*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出一个基于序列标注的NER模型不确定性感知预测集框架，通过保形预测提供有限样本覆盖保证，为NER预测提供类似置信区间的可靠性保证。


<details>
  <summary>Details</summary>
Motivation: 当前NER模型通常只输出单一预测标签序列，缺乏不确定性度量，导致下游应用容易受到级联错误影响。需要为NER预测提供可靠性保证。

Method: 基于保形预测框架，设计高效的非保形性评分函数，构建支持无条件覆盖和类别条件覆盖的校准预测集。考虑句子长度、语言、实体类型和实体数量的异质性。

Result: 在三个基准数据集上的四个NER模型实验表明，该方法具有广泛适用性、有效性和高效性，能够提供可靠的覆盖保证。

Conclusion: 提出的框架为NER模型提供了不确定性感知的预测集，通过保形预测提供形式化可靠性保证，增强了NER系统的鲁棒性和可信度。

Abstract: Named Entity Recognition (NER) serves as a foundational component in many natural language processing (NLP) pipelines. However, current NER models typically output a single predicted label sequence without any accompanying measure of uncertainty, leaving downstream applications vulnerable to cascading errors. In this paper, we introduce a general framework for adapting sequence-labeling-based NER models to produce uncertainty-aware prediction sets. These prediction sets are collections of full-sentence labelings that are guaranteed to contain the correct labeling with a user-specified confidence level. This approach serves a role analogous to confidence intervals in classical statistics by providing formal guarantees about the reliability of model predictions. Our method builds on conformal prediction, which offers finite-sample coverage guarantees under minimal assumptions. We design efficient nonconformity scoring functions to construct efficient, well-calibrated prediction sets that support both unconditional and class-conditional coverage. This framework accounts for heterogeneity across sentence length, language, entity type, and number of entities within a sentence. Empirical experiments on four NER models across three benchmark datasets demonstrate the broad applicability, validity, and efficiency of the proposed methods.

</details>


### [86] [Reasoning Beyond Literal: Cross-style Multimodal Reasoning for Figurative Language Understanding](https://arxiv.org/abs/2601.17197)
*Seyyed Saeid Cheshmi,Hahnemann Ortiz,James Mooney,Dongyeop Kang*

Main category: cs.CL

Relevance: 65.0

TL;DR: 本文提出了一个三步框架，用于开发能够理解多模态比喻语言（如讽刺、幽默、隐喻）的高效推理模型，通过引入可验证的推理轨迹实现跨风格泛化。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在字面多模态任务上表现良好，但在理解比喻语言（讽刺、幽默、隐喻）方面存在显著挑战。比喻语言通过表达意义和意图意义之间的微妙不一致来传达意图和情感，在多模态环境中，伴随的图像可能放大或反转文本含义，需要模型能够跨模态推理并考虑主观性。

Method: 提出了一个三步框架：1) 解释多模态比喻语言；2) 提供透明的推理轨迹；3) 跨多种比喻风格泛化。通过实验验证了：推理轨迹的加入显著提升理解能力；在一种风格中学到的推理可以迁移到其他风格；跨风格联合训练可以产生通用的推理VLM。

Result: 实验结果表明：1) 加入推理轨迹显著提升多模态比喻理解；2) 在一种风格（如讽刺）中学到的推理可以迁移到相关风格（如幽默）；3) 跨风格联合训练的轻量级VLM在性能上超越了更大的开源和闭源模型。

Conclusion: 轻量级视觉语言模型通过可验证的推理轨迹可以实现稳健的跨风格泛化，同时为多模态任务提供可检查的推理过程。这为构建更高效、可解释的多模态推理模型提供了新方向。

Abstract: Vision-language models (VLMs) have demonstrated strong reasoning abilities in literal multimodal tasks such as visual mathematics and science question answering. However, figurative language, such as sarcasm, humor, and metaphor, remains a significant challenge, as it conveys intent and emotion through subtle incongruities between expressed and intended meanings. In multimodal settings, accompanying images can amplify or invert textual meaning, demanding models that reason across modalities and account for subjectivity. We propose a three-step framework for developing efficient multimodal reasoning models that can (i) interpret multimodal figurative language, (ii) provide transparent reasoning traces, and (iii) generalize across multiple figurative styles. Experiments across four styles show that (1) incorporating reasoning traces substantially improves multimodal figurative understanding, (2) reasoning learned in one style can transfer to others, especially between related styles like sarcasm and humor, and (3) training jointly across styles yields a generalized reasoning VLM that outperforms much larger open- and closed-source models. Our findings show that lightweight VLMs with verifiable reasoning achieve robust cross-style generalization while providing inspectable reasoning traces for multimodal tasks. The code and implementation are available at https://github.com/scheshmi/CrossStyle-MMR.

</details>


### [87] [CaseFacts: A Benchmark for Legal Fact-Checking and Precedent Retrieval](https://arxiv.org/abs/2601.17230)
*Akshith Reddy Putta,Jacob Devasier,Chengkai Li*

Main category: cs.CL

Relevance: 65.0

TL;DR: CaseFacts是一个针对美国最高法院判例验证口语化法律主张的基准测试，包含6,294个被分类为支持、反驳或推翻的主张，旨在解决法律领域事实核查的特殊挑战。


<details>
  <summary>Details</summary>
Motivation: 现有自动事实核查主要关注基于静态语料库验证一般知识，忽略了法律等高风险领域，其中真相是动态演变且技术复杂的。法律领域需要弥合外行主张与技术法理之间的语义鸿沟，并考虑时间有效性。

Method: 使用多阶段流水线构建基准：利用LLMs从专家案例摘要中合成主张，采用新颖的语义相似性启发式方法高效识别和验证复杂的法律推翻案例。实验评估了最先进的LLMs，并比较了无限制网络搜索与闭卷基线的性能。

Result: 实验显示该任务对最先进的LLMs仍然具有挑战性；值得注意的是，为模型添加无限制网络搜索反而会降低性能（相比闭卷基线），因为会检索到嘈杂、非权威的判例。

Conclusion: CaseFacts基准旨在推动法律事实核查系统的研究，特别关注弥合口语化主张与技术法理之间的语义鸿沟，并考虑法律先例的时间演变特性。

Abstract: Automated Fact-Checking has largely focused on verifying general knowledge against static corpora, overlooking high-stakes domains like law where truth is evolving and technically complex. We introduce CaseFacts, a benchmark for verifying colloquial legal claims against U.S. Supreme Court precedents. Unlike existing resources that map formal texts to formal texts, CaseFacts challenges systems to bridge the semantic gap between layperson assertions and technical jurisprudence while accounting for temporal validity. The dataset consists of 6,294 claims categorized as Supported, Refuted, or Overruled. We construct this benchmark using a multi-stage pipeline that leverages Large Language Models (LLMs) to synthesize claims from expert case summaries, employing a novel semantic similarity heuristic to efficiently identify and verify complex legal overrulings. Experiments with state-of-the-art LLMs reveal that the task remains challenging; notably, augmenting models with unrestricted web search degrades performance compared to closed-book baselines due to the retrieval of noisy, non-authoritative precedents. We release CaseFacts to spur research into legal fact verification systems.

</details>


### [88] [Parameter Efficient Fine Tuning Llama 3.1 for Answering Arabic Legal Questions: A Case Study on Jordanian Laws](https://arxiv.org/abs/2601.17364)
*Mohammed Fasha,Bassam Hammo,Bilal Sowan,Husam Barham,Esam Nsour*

Main category: cs.CL

Relevance: 65.0

TL;DR: 该研究以约旦法律为案例，对Llama-3.1大语言模型进行阿拉伯语法律问答微调，采用LoRA适配器和4位量化技术，使用6000个法律问答对数据集，评估显示微调后模型在法律推理和准确性方面有提升。


<details>
  <summary>Details</summary>
Motivation: 探索如何将大语言模型适应阿拉伯语法律领域，解决特定领域任务微调的资源效率问题，为阿拉伯语法律AI应用提供技术方案。

Method: 使用Llama-3.1-8B-bnb-4bit和Llama-3.1-8B-Instruct-bnb-4bit两个版本，采用参数高效微调(PEFT)和LoRA适配器，结合4位量化模型，利用Unsloth框架进行加速和资源高效训练，构建6000个法律问答对的自定义数据集。

Result: 微调后的模型在法律推理和准确性方面相比基础版本有显著提升，同时通过量化和优化微调策略实现了资源效率，使用BLEU和ROUGE指标评估显示性能改进。

Conclusion: 这项工作展示了将大语言模型适应阿拉伯语法律领域的潜力，并突出了特定领域任务微调的有效技术，为资源受限环境下的法律AI应用提供了可行方案。

Abstract: This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering. Two versions of the model - Llama-3.1-8B-bnb-4bit and Llama-3.1-8B-Instruct-bnb-4bit - were fine-tuned using parameter-efficient fine-tuning (PEFT) with LoRA adapters and 4-bit quantized models, leveraging the Unsloth framework for accelerated and resource-efficient training. A custom dataset of 6000 legal question-answer pairs was curated from Jordanian laws and formatted into structured prompts. Performance was evaluated using the BLEU and the ROUGE metrics to compare the fine-tuned models to their respective base versions. Results demonstrated improved legal reasoning and accuracy while achieving resource efficiency through quantization and optimized fine-tuning strategies. This work underscores the potential of adapting large language models for Arabic legal domains and highlights effective techniques for fine-tuning domain-specific tasks.

</details>


### [89] [WarrantScore: Modeling Warrants between Claims and Evidence for Substantiation Evaluation in Peer Reviews](https://arxiv.org/abs/2601.17377)
*Kiyotada Mori,Shohei Tanaka,Tosho Hirasawa,Tadashi Kozuno,Koichiro Yoshino,Yoshitaka Ushiku*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出一种评估科学评审评论中主张与证据间逻辑推理的新方法，通过分析主张与证据的关联性来评估论证的充分性，相比传统方法能更好地与人工评分相关。


<details>
  <summary>Details</summary>
Motivation: 科学同行评审面临人力资源短缺问题，语言模型被探索用于降低评审成本。现有方法仅检测主张是否有证据支持，但缺乏对主张与证据间逻辑推理的准确评估，需要更精细的评估指标。

Method: 提出新的评估指标，专注于评估科学评审评论中主张与证据之间的逻辑推理关系。方法提取论证的核心组件（主张和证据），并评估它们之间的逻辑关联性，而不仅仅是检测证据的存在与否。

Result: 实验结果显示，提出的方法相比传统方法，与人工评分有更高的相关性，表明该方法能更准确地评估科学评审的质量。

Conclusion: 该方法通过更精细地评估主张与证据间的逻辑推理，能更好地支持同行评审过程的效率提升，为解决评审资源短缺问题提供有效工具。

Abstract: The scientific peer-review process is facing a shortage of human resources due to the rapid growth in the number of submitted papers. The use of language models to reduce the human cost of peer review has been actively explored as a potential solution to this challenge. A method has been proposed to evaluate the level of substantiation in scientific reviews in a manner that is interpretable by humans. This method extracts the core components of an argument, claims and evidence, and assesses the level of substantiation based on the proportion of claims supported by evidence. The level of substantiation refers to the extent to which claims are based on objective facts. However, when assessing the level of substantiation, simply detecting the presence or absence of supporting evidence for a claim is insufficient; it is also necessary to accurately assess the logical inference between a claim and its evidence. We propose a new evaluation metric for scientific review comments that assesses the logical inference between claims and evidence. Experimental results show that the proposed method achieves a higher correlation with human scores than conventional methods, indicating its potential to better support the efficiency of the peer-review process.

</details>


### [90] [Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes](https://arxiv.org/abs/2601.17530)
*Gautam Siddharth Kashyap,Harsh Joshi,Niharika Jain,Ebad Shabbir,Jiechao Gao,Nipun Joshi,Usman Naseem*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出ConLLM框架，通过对比学习和LLM推理解决深度伪造检测中的模态碎片化和浅层跨模态推理问题，在音频、视频和视听任务上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术对社会和政治稳定构成严重威胁，现有检测方法存在两个核心局限：1）模态碎片化导致跨不同对抗性模态泛化能力差；2）浅层跨模态推理导致难以检测细粒度语义不一致。

Method: 提出ConLLM（基于大型语言模型的对比学习）混合框架，采用两阶段架构：第一阶段使用预训练模型提取模态特定嵌入；第二阶段通过对比学习对齐嵌入以缓解模态碎片化，并利用LLM推理细化嵌入以捕捉语义不一致。

Result: 在音频、视频和视听模态上表现优异：音频深度伪造EER降低达50%，视频准确率提升达8%，视听任务准确率提升约9%。消融研究证实PTM嵌入贡献了9%-10%的跨模态一致改进。

Conclusion: ConLLM通过结合对比学习和LLM推理，有效解决了深度伪造检测中的模态碎片化和浅层跨模态推理问题，为多模态深度伪造检测提供了鲁棒解决方案。

Abstract: The rapid rise of deepfake technology poses a severe threat to social and political stability by enabling hyper-realistic synthetic media capable of manipulating public perception. However, existing detection methods struggle with two core limitations: (1) modality fragmentation, which leads to poor generalization across diverse and adversarial deepfake modalities; and (2) shallow inter-modal reasoning, resulting in limited detection of fine-grained semantic inconsistencies. To address these, we propose ConLLM (Contrastive Learning with Large Language Models), a hybrid framework for robust multimodal deepfake detection. ConLLM employs a two-stage architecture: stage 1 uses Pre-Trained Models (PTMs) to extract modality-specific embeddings; stage 2 aligns these embeddings via contrastive learning to mitigate modality fragmentation, and refines them using LLM-based reasoning to address shallow inter-modal reasoning by capturing semantic inconsistencies. ConLLM demonstrates strong performance across audio, video, and audio-visual modalities. It reduces audio deepfake EER by up to 50%, improves video accuracy by up to 8%, and achieves approximately 9% accuracy gains in audio-visual tasks. Ablation studies confirm that PTM-based embeddings contribute 9%-10% consistent improvements across modalities.

</details>


### [91] [Distance-to-Distance Ratio: A Similarity Measure for Sentences Based on Rate of Change in LLM Embeddings](https://arxiv.org/abs/2601.17705)
*Abdullah Qureshi,Kenneth Rice,Alexander Wolpert*

Main category: cs.CL

Relevance: 65.0

TL;DR: 本文提出了一种新的文本嵌入相似度度量方法DDR（距离-距离比），通过测量上下文前后嵌入相似度的变化率来评估语义相似性，相比现有方法能更精细地区分语义相似和不同的文本。


<details>
  <summary>Details</summary>
Motivation: 现有的文本嵌入相似度度量方法需要符合人类对文本相似性的感知。本文旨在开发一种能够更准确反映语义相似性的新度量方法，特别是在处理经过微小编辑的文本时。

Method: 提出距离-距离比（DDR）方法，受Lipschitz连续性启发，测量预上下文词嵌入相似度与后上下文LLM嵌入相似度之间的变化率，从而量化上下文的语义影响。通过实验设计，从句子数据集中选取句子，生成变体（替换1-3个词为同义词或随机词），比较DDR与其他相似度度量的性能。

Result: DDR在实验中表现出色，即使在最小、受控的编辑下，也能比现有相似度度量方法更一致地提供对语义相似和不同文本的更精细区分。

Conclusion: DDR是一种有效的文本嵌入相似度度量方法，能够更好地捕捉语义相似性，特别是在处理经过微小编辑的文本时，为文本相似性评估提供了新的工具。

Abstract: A measure of similarity between text embeddings can be considered adequate only if it adheres to the human perception of similarity between texts. In this paper, we introduce the distance-to-distance ratio (DDR), a novel measure of similarity between LLM sentence embeddings. Inspired by Lipschitz continuity, DDR measures the rate of change in similarity between the pre-context word embeddings and the similarity between post-context LLM embeddings, thus measuring the semantic influence of context. We evaluate the performance of DDR in experiments designed as a series of perturbations applied to sentences drawn from a sentence dataset. For each sentence, we generate variants by replacing one, two, or three words with either synonyms, which constitute semantically similar text, or randomly chosen words, which constitute semantically dissimilar text. We compare the performance of DDR with other prevailing similarity metrics and demonstrate that DDR consistently provides finer discrimination between semantically similar and dissimilar texts, even under minimal, controlled edits.

</details>


### [92] [Beyond a Single Perspective: Text Anomaly Detection with Multi-View Language Representations](https://arxiv.org/abs/2601.17786)
*Yixin Liu,Kehan Yan,Shiyuan Li,Qingfeng Chen,Shirui Pan*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出MCA²多视图文本异常检测框架，通过多预训练语言模型嵌入、多视图重构、对比协作和自适应分配模块，提升跨数据集和异常类型的适应性


<details>
  <summary>Details</summary>
Motivation: 传统两步式"嵌入-检测"方法受限于单一嵌入模型，缺乏跨数据集和异常类型的适应性，需要更灵活的多模型集成方案

Method: 1) 多预训练语言模型嵌入 2) 多视图重构模型提取正常文本模式 3) 对比协作模块增强视图间交互 4) 自适应分配模块自动分配各视图权重

Result: 在10个基准数据集上验证了MCA²的有效性，优于现有基线方法

Conclusion: MCA²通过多视图集成和自适应机制，显著提升了文本异常检测的跨数据集适应性和检测性能

Abstract: Text anomaly detection (TAD) plays a critical role in various language-driven real-world applications, including harmful content moderation, phishing detection, and spam review filtering. While two-step "embedding-detector" TAD methods have shown state-of-the-art performance, their effectiveness is often limited by the use of a single embedding model and the lack of adaptability across diverse datasets and anomaly types. To address these limitations, we propose to exploit the embeddings from multiple pretrained language models and integrate them into $MCA^2$, a multi-view TAD framework. $MCA^2$ adopts a multi-view reconstruction model to effectively extract normal textual patterns from multiple embedding perspectives. To exploit inter-view complementarity, a contrastive collaboration module is designed to leverage and strengthen the interactions across different views. Moreover, an adaptive allocation module is developed to automatically assign the contribution weight of each view, thereby improving the adaptability to diverse datasets. Extensive experiments on 10 benchmark datasets verify the effectiveness of $MCA^2$ against strong baselines. The source code of $MCA^2$ is available at https://github.com/yankehan/MCA2.

</details>


### [93] [PEAR: Pairwise Evaluation for Automatic Relative Scoring in Machine Translation](https://arxiv.org/abs/2601.18006)
*Lorenzo Proietti,Roman Grundkiewicz,Matt Post*

Main category: cs.CL

Relevance: 65.0

TL;DR: PEAR是一个用于机器翻译评估的成对质量估计指标家族，通过预测两个候选翻译之间的质量差异方向和幅度来改进评估效果。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译评估指标存在局限性，需要更准确、高效的参考无关评估方法。作者提出将评估重新定义为分级成对比较，以更好地捕捉翻译质量的细微差异。

Method: PEAR采用监督学习方法，使用从人类判断差异中推导的成对监督进行训练，并加入正则化项以确保候选顺序反转时符号反转。该方法将源文本和两个候选翻译作为输入，预测它们的质量差异。

Result: 在WMT24元评估基准上，PEAR优于使用相同数据和骨干网络的单候选质量估计基线，超越了更大的质量估计模型和基于参考的指标，同时提供了更不冗余的评估信号。

Conclusion: PEAR通过成对比较框架显著提升了机器翻译评估的准确性和效率，参数更少但性能更好，还可有效用于最小贝叶斯风险解码。

Abstract: We present PEAR (Pairwise Evaluation for Automatic Relative Scoring), a supervised Quality Estimation (QE) metric family that reframes reference-free Machine Translation (MT) evaluation as a graded pairwise comparison. Given a source segment and two candidate translations, PEAR predicts the direction and magnitude of their quality difference. The metrics are trained using pairwise supervision derived from differences in human judgments, with an additional regularization term that encourages sign inversion under candidate order reversal. On the WMT24 meta-evaluation benchmark, PEAR outperforms strictly matched single-candidate QE baselines trained with the same data and backbones, isolating the benefit of the proposed pairwise formulation. Despite using substantially fewer parameters than recent large metrics, PEAR surpasses far larger QE models and reference-based metrics. Our analysis further indicates that PEAR yields a less redundant evaluation signal relative to other top metrics. Finally, we show that PEAR is an effective utility function for Minimum Bayes Risk (MBR) decoding, reducing pairwise scoring cost at negligible impact.

</details>


### [94] [A System for Name and Address Parsing with Large Language Models](https://arxiv.org/abs/2601.18014)
*Adeeba Tarannum,Muzakkiruddin Ahmed Mohammed,Mert Can Cakmak,Shames Al Mandalawi,John Talburt*

Main category: cs.CL

Relevance: 65.0

TL;DR: 提出一种基于提示驱动、验证中心的框架，将自由文本记录转换为17字段结构化模式，无需微调，结合确定性验证与生成提示实现可靠的信息提取。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则和概率的方法在干净输入上表现良好，但在噪声或多语言条件下失败；神经和大型语言模型缺乏确定性控制和可复现性。需要一种既保持生成能力又具备确定性验证的解决方案。

Method: 集成输入标准化、结构化提示、约束解码和严格基于规则的验证，在固定实验设置下确保可复现性。框架不依赖微调，通过提示驱动和验证中心的方法实现结构化信息提取。

Result: 在异构真实世界地址数据上评估显示：高字段级准确率、强模式遵循性和稳定的置信度校准。结合确定性验证与生成提示提供了鲁棒、可解释且可扩展的解决方案。

Conclusion: 结合确定性验证与生成提示为结构化信息提取提供了实用替代方案，优于训练密集型或领域特定模型，具有鲁棒性、可解释性和可扩展性。

Abstract: Reliable transformation of unstructured person and address text into structured data remains a key challenge in large-scale information systems. Traditional rule-based and probabilistic approaches perform well on clean inputs but fail under noisy or multilingual conditions, while neural and large language models (LLMs) often lack deterministic control and reproducibility. This paper introduces a prompt-driven, validation-centered framework that converts free-text records into a consistent 17-field schema without fine-tuning. The method integrates input normalisation, structured prompting, constrained decoding, and strict rule-based validation under fixed experimental settings to ensure reproducibility. Evaluations on heterogeneous real-world address data show high field-level accuracy, strong schema adherence, and stable confidence calibration. The results demonstrate that combining deterministic validation with generative prompting provides a robust, interpretable, and scalable solution for structured information extraction, offering a practical alternative to training-heavy or domain-specific models.

</details>


### [95] [TechING: Towards Real World Technical Image Understanding via VLMs](https://arxiv.org/abs/2601.18238)
*Tafazzul Nadeem,Bhavik Shangari,Manish Rai,Gagan Raj Gupta,Ashutosh Modi*

Main category: cs.CL

Relevance: 65.0

TL;DR: 本文提出了一种用于训练视觉语言模型（VLMs）理解手绘技术图的大规模合成数据集生成方法，并基于此训练了LLama-VL-TUG模型，显著提升了技术图理解能力。


<details>
  <summary>Details</summary>
Motivation: 专业人员经常手绘技术图（流程图、框图等），但现有VLMs难以理解这些手绘图。虽然可以通过真实手绘图微调，但获取大量真实手绘图不现实。因此需要生成合成数据集来训练VLMs。

Method: 1) 创建大规模合成数据集（反映真实世界图像特征）；2) 引入多个自监督任务进行训练；3) 在合成图像上微调Llama 3.2 11B-instruct模型，得到LLama-VL-TUG；4) 在真实手绘图上进行人类评估。

Result: LLama-VL-TUG将Llama 3.2 11B-instruct的ROUGE-L性能提升2.14倍，在8种图类型中的7种上获得最少编译错误，平均F1分数提升6.97倍，在所有基线模型中表现最佳。

Conclusion: 通过合成数据集训练VLMs能有效提升技术图理解能力，为专业领域的手绘图识别和编辑提供了实用解决方案。

Abstract: Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.

</details>


### [96] [MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization](https://arxiv.org/abs/2601.18320)
*Jinwei Lu,Yuanfeng Song,Chen Zhang,Raymond Chi-Wing Wong*

Main category: cs.CL

Relevance: 65.0

TL;DR: MultiVis-Agent：基于逻辑规则增强的多智能体框架，用于可靠的多模态可视化生成，通过数学约束保证系统可靠性，在复杂可视化任务中显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 现实世界可视化任务涉及复杂多模态需求（参考图像、代码示例、迭代优化），现有系统存在单模态输入、一次性生成、流程僵化等局限。LLM方法虽具潜力但引入可靠性问题（灾难性故障、无限循环风险）

Method: 提出MultiVis-Agent：逻辑规则增强的多智能体框架，包含四层逻辑规则框架（提供数学可靠性保证），逻辑规则作为数学约束指导LLM推理而非替代。形式化四种场景的可视化任务，开发MultiVis-Bench基准（1000+案例）

Result: 在挑战性任务上达到75.63%可视化分数，显著优于基线（57.54-62.79%），任务完成率99.58%，代码执行成功率94.56%（无逻辑规则时分别为74.48%和65.10%）

Conclusion: MultiVis-Agent成功解决了自动化可视化生成中的复杂性和可靠性挑战，通过逻辑规则增强的LLM推理实现了可靠的多模态可视化生成

Abstract: Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.

</details>


### [97] [Structure-Aware NL-to-SQL for SFC Provisioning via AST-Masking Empowered Language Models](https://arxiv.org/abs/2601.17295)
*Xinyu Zhu,Parisa Fard Moshiri,Poonam Lohan,Burak Kantarci,Emil Janulewicz*

Main category: cs.NI

Relevance: 65.0

TL;DR: 提出AST-Masking方法，通过SQL抽象语法树进行结构感知的微调，提升LLM将自然语言转换为SQL命令的准确率，用于服务功能链管理。


<details>
  <summary>Details</summary>
Motivation: 在动态延迟敏感网络中，服务功能链(SFC)配置需要精确编排。强化学习虽然能提升适应性，但缺乏结构化领域知识，限制了泛化性和可解释性。LLM可以将自然语言规范转换为SQL命令，但传统微调方法会导致语法不一致和低效查询。

Method: 提出AST-Masking方法：基于SQL抽象语法树的结构感知微调技术，为关键组件分配权重，强制语法感知学习，且不增加推理开销。使用SQL AST来指导模型学习正确的语法结构。

Result: 实验显示AST-Masking显著提升多个语言模型的SQL生成准确率。FLAN-T5达到99.6%的执行准确率，Gemma从7.5%提升到72.0%，获得最大绝对增益。证明结构感知微调能确保语法正确且高效的SQL生成。

Conclusion: AST-Masking方法通过结构感知微调，有效解决了LLM在自然语言到SQL转换中的语法一致性和效率问题，为可解释的SFC编排提供了可靠的技术方案。

Abstract: Effective Service Function Chain (SFC) provisioning requires precise orchestration in dynamic and latency-sensitive networks. Reinforcement Learning (RL) improves adaptability but often ignores structured domain knowledge, which limits generalization and interpretability. Large Language Models (LLMs) address this gap by translating natural language (NL) specifications into executable Structured Query Language (SQL) commands for specification-driven SFC management. Conventional fine-tuning, however, can cause syntactic inconsistencies and produce inefficient queries. To overcome this, we introduce Abstract Syntax Tree (AST)-Masking, a structure-aware fine-tuning method that uses SQL ASTs to assign weights to key components and enforce syntax-aware learning without adding inference overhead. Experiments show that AST-Masking significantly improves SQL generation accuracy across multiple language models. FLAN-T5 reaches an Execution Accuracy (EA) of 99.6%, while Gemma achieves the largest absolute gain from 7.5% to 72.0%. These results confirm the effectiveness of structure-aware fine-tuning in ensuring syntactically correct and efficient SQL generation for interpretable SFC orchestration.

</details>


### [98] [Agentic Search in the Wild: Intents and Trajectory Dynamics from 14M+ Real Search Requests](https://arxiv.org/abs/2601.17617)
*Jingjie Ning,João Coelho,Yibo Kong,Yunfan Long,Bruno Martins,João Magalhães,Jamie Callan,Chenyan Xiong*

Main category: cs.IR

Relevance: 65.0

TL;DR: 大规模日志分析揭示LLM搜索代理的行为模式：90%多轮会话不超过10步，89%步骤间隔小于1分钟；不同意图行为差异大，事实查询重复率高，推理任务探索更广；54%新查询词源自累积证据上下文


<details>
  <summary>Details</summary>
Motivation: LLM驱动的搜索代理在多步信息检索任务中应用日益广泛，但信息检索社区缺乏对代理搜索会话如何展开以及检索证据如何使用的实证理解。需要大规模日志分析来揭示这些行为模式。

Method: 基于DeepResearchGym开源搜索API收集的14.44M搜索请求（3.97M会话）进行大规模日志分析。使用会话化处理、基于LLM的会话级意图标注和步骤级查询重构标注，提出上下文驱动的术语采纳率（CTAR）来量化新引入查询词是否可追溯到先前检索证据。

Result: 1）90%以上多轮会话不超过10步，89%步骤间隔小于1分钟；2）行为因意图而异：事实查询会话重复率高且随时间增加，推理任务会话维持更广泛探索；3）代理跨步骤重用证据：平均54%新引入查询词出现在累积证据上下文中，早期步骤贡献超出最近检索。

Conclusion: 代理搜索可能受益于重复感知的早期停止、意图自适应的检索预算和显式的跨步骤上下文跟踪。计划发布匿名化日志支持未来研究。

Abstract: LLM-powered search agents are increasingly being used for multi-step information seeking tasks, yet the IR community lacks empirical understanding of how agentic search sessions unfold and how retrieved evidence is used. This paper presents a large-scale log analysis of agentic search based on 14.44M search requests (3.97M sessions) collected from DeepResearchGym, i.e. an open-source search API accessed by external agentic clients. We sessionize the logs, assign session-level intents and step-wise query-reformulation labels using LLM-based annotation, and propose Context-driven Term Adoption Rate (CTAR) to quantify whether newly introduced query terms are traceable to previously retrieved evidence. Our analyses reveal distinctive behavioral patterns. First, over 90% of multi-turn sessions contain at most ten steps, and 89% of inter-step intervals fall under one minute. Second, behavior varies by intent. Fact-seeking sessions exhibit high repetition that increases over time, while sessions requiring reasoning sustain broader exploration. Third, agents reuse evidence across steps. On average, 54% of newly introduced query terms appear in the accumulated evidence context, with contributions from earlier steps beyond the most recent retrieval. The findings suggest that agentic search may benefit from repetition-aware early stopping, intent-adaptive retrieval budgets, and explicit cross-step context tracking. We plan to release the anonymized logs to support future research.

</details>


### [99] [Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis](https://arxiv.org/abs/2601.17203)
*Scott Friedman,Sonja Schmer-Galunder,Anthony Chen,Jeffrey Rye*

Main category: cs.CL

Relevance: 45.0

TL;DR: 该论文提出了一种量化词嵌入中性别偏见的方法，并利用这些偏见来表征教育、政治、经济和健康领域的统计性别差距。研究使用2018年Twitter数据验证了该方法，覆盖51个美国地区和99个国家。


<details>
  <summary>Details</summary>
Motivation: 现代NLP模型通常基于新闻、社交媒体等文化衍生文本进行训练，这些文本中存在的种族和性别偏见可能反映了实际文化中的性别差距。研究旨在利用这些偏见来理解文化背景，而非仅仅将其视为需要修正的问题。

Method: 提出量化词嵌入中性别偏见的方法，使用2018年Twitter数据构建区域和国家层面的词嵌入，然后将其与18个国际和5个美国统计性别差距指标进行相关性分析。

Result: 验证了词嵌入偏见与统计性别差距之间的相关性，展示了词嵌入偏见能够反映实际社会中的性别不平等状况，为通过大数据理解文化背景提供了实证支持。

Conclusion: 词嵌入中的性别偏见不仅是一个需要修正的技术问题，还可以作为理解文化背景和社会性别差距的有价值工具。这种方法为通过大数据分析文化模式提供了新视角。

Abstract: Modern models for common NLP tasks often employ machine learning techniques and train on journalistic, social media, or other culturally-derived text. These have recently been scrutinized for racial and gender biases, rooting from inherent bias in their training text. These biases are often sub-optimal and recent work poses methods to rectify them; however, these biases may shed light on actual racial or gender gaps in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This paper presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health. We validate these metrics on 2018 Twitter data spanning 51 U.S. regions and 99 countries. We correlate state and country word embedding biases with 18 international and 5 U.S.-based statistical gender gaps, characterizing regularities and predictive strength.

</details>


### [100] [PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues](https://arxiv.org/abs/2601.17277)
*Mohammad Rifqi Farhansyah,Hanif Muhammad Zhafran,Farid Adilazuarda,Shamsuddeen Hassan Muhammad,Maryam Ibrahim Mukhtar,Nedjma Ousidhoum,Genta Indra Winata,Ayu Purwarianti,Alham Fikri Aji*

Main category: cs.CL

Relevance: 45.0

TL;DR: PingPong是一个用于自然多语言代码切换对话的基准测试，包含五种语言组合（部分为三语），涵盖2-4人真实对话，结构复杂且自然，定义了问答、对话摘要和主题分类三个下游任务。


<details>
  <summary>Details</summary>
Motivation: 代码切换是全球多语言人群的普遍现象，但现有基准测试未能准确反映日常交流中的复杂性。需要更自然的代码切换对话数据集来评估和改进NLP系统处理真实多语言场景的能力。

Method: 创建PingPong基准：1）收集人类撰写的2-4人多方对话，覆盖五种语言组合（部分三语）；2）对话具有真实的多线程结构，回复常引用较早对话点；3）与机器生成数据对比，验证其自然性和结构多样性；4）基于对话定义三个下游任务：问答、对话摘要和主题分类。

Result: 1）PingPong数据比机器生成替代方案显著更自然、结构更多样，在消息长度、说话者主导性和回复距离方面变化更大；2）多个最先进语言模型在PingPong上的评估显示，它们在代码切换输入上的性能仍然有限。

Conclusion: 当前NLP系统在处理真实世界多语言对话的复杂性方面能力有限，迫切需要更鲁棒的系统来应对代码切换的挑战。PingPong基准为评估和改进这类系统提供了重要资源。

Abstract: Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.

</details>


### [101] [Controlling Reading Ease with Gaze-Guided Text Generation](https://arxiv.org/abs/2601.17781)
*Andreas Säuberli,Darja Jepifanova,Diego Frassinelli,Barbara Plank*

Main category: cs.CL

Relevance: 45.0

TL;DR: 本文提出一种通过预测人类注视模式来控制文本阅读难易度的方法，使用眼动追踪评估生成文本的阅读难度，发现该方法能有效调节文本的易读性。


<details>
  <summary>Details</summary>
Motivation: 阅读时的眼动模式可以反映文本处理的认知努力程度。本研究旨在利用这一事实生成具有可控阅读难易度的文本，以改善信息可访问性和个性化语言学习材料。

Method: 采用预测人类注视模式的模型来引导语言模型输出，使其引发特定的阅读行为。通过眼动追踪实验评估方法，对比英语母语者和非母语者的阅读表现。

Result: 方法能有效使生成文本变得更易读或更难读，体现在阅读时间和感知难度两方面。统计分析显示阅读行为变化主要源于影响词汇处理的文本特征。

Conclusion: 通过眼动模式预测引导语言模型生成的方法能有效控制文本阅读难度，在信息可访问性文本简化和个性化语言学习材料生成方面具有应用潜力。

Abstract: The way our eyes move while reading can tell us about the cognitive effort required to process the text. In the present study, we use this fact to generate texts with controllable reading ease. Our method employs a model that predicts human gaze patterns to steer language model outputs towards eliciting certain reading behaviors. We evaluate the approach in an eye-tracking experiment with native and non-native speakers of English. The results demonstrate that the method is effective at making the generated texts easier or harder to read, measured both in terms of reading times and perceived difficulty of the texts. A statistical analysis reveals that the changes in reading behavior are mostly due to features that affect lexical processing. Possible applications of our approach include text simplification for information accessibility and generation of personalized educational material for language learning.

</details>


### [102] [CHiRPE: A Step Towards Real-World Clinical NLP with Clinician-Oriented Model Explanations](https://arxiv.org/abs/2601.18102)
*Stephanie Fong,Zimu Wang,Guilherme C. Oliveira,Xiangyu Zhao,Yiwen Jiang,Jiahe Liu,Beau-Luke Colton,Scott Woods,Martha E. Shenton,Barnaby Nelson,Zongyuan Ge,Dominic Dwyer*

Main category: cs.CL

Relevance: 45.0

TL;DR: CHiRPE是一个临床NLP管道，通过转录的半结构化临床访谈预测精神病风险，并生成与临床医生共同开发的新型SHAP解释格式，实现了超过90%的准确率。


<details>
  <summary>Details</summary>
Motivation: 医疗NLP工具需要临床医生可解释，但传统可解释AI方法与临床推理不匹配且缺乏临床医生输入。需要开发与临床思维对齐的解释方法。

Method: 整合症状领域映射、LLM总结和BERT分类的NLP管道。使用944份半结构化访谈转录，开发新型SHAP解释格式（概念引导解释，特别是混合图-文本总结格式）。

Result: CHiRPE在三个BERT变体上均达到超过90%的准确率，优于基线模型。28位临床专家评估显示强烈偏好新型概念引导解释格式。

Conclusion: 临床指导的模型开发能产生准确且可解释的结果。下一步将在24个国际站点进行真实世界测试。

Abstract: The medical adoption of NLP tools requires interpretability by end users, yet traditional explainable AI (XAI) methods are misaligned with clinical reasoning and lack clinician input. We introduce CHiRPE (Clinical High-Risk Prediction with Explainability), an NLP pipeline that takes transcribed semi-structured clinical interviews to: (i) predict psychosis risk; and (ii) generate novel SHAP explanation formats co-developed with clinicians. Trained on 944 semi-structured interview transcripts across 24 international clinics of the AMP-SCZ study, the CHiRPE pipeline integrates symptom-domain mapping, LLM summarisation, and BERT classification. CHiRPE achieved over 90% accuracy across three BERT variants and outperformed baseline models. Explanation formats were evaluated by 28 clinical experts who indicated a strong preference for our novel concept-guided explanations, especially hybrid graph-and-text summary formats. CHiRPE demonstrates that clinically-guided model development produces both accurate and interpretable results. Our next step is focused on real-world testing across our 24 international sites.

</details>


### [103] [To Case or Not to Case: An Empirical Study in Learned Sparse Retrieval](https://arxiv.org/abs/2601.17500)
*Emmanouil Georgios Lionis,Jia-Huei Ju,Angelos Nalmpantis,Casper Thuis,Sean MacAvaney,Andrew Yates*

Main category: cs.IR

Relevance: 45.0

TL;DR: 研究评估了在稀疏检索（LSR）中使用大小写敏感与不敏感的基础模型的影响，发现大小写敏感模型默认表现较差，但通过文本小写化预处理可以消除差距，使大小写敏感模型在LSR中表现与不敏感模型相当。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的预训练语言模型多为大小写敏感版本，但现有的稀疏检索方法几乎完全依赖大小写不敏感的基础模型。这种转变可能威胁到稀疏检索方法的未来发展，因此需要系统评估基础模型大小写敏感性对稀疏检索性能的影响。

Method: 系统评估了配对的大小写敏感和不敏感版本的基础模型在多个数据集上的表现，包括默认设置和文本小写化预处理两种情况。通过token级别的分析，研究了大小写敏感模型在预处理后的词汇使用模式。

Result: 默认情况下，使用大小写敏感基础模型的LSR模型表现显著差于大小写不敏感版本；但通过文本小写化预处理可以完全消除这一性能差距。token分析显示，在小写化处理后，大小写敏感模型几乎完全抑制了大小写敏感的词汇项，行为上等同于大小写不敏感模型。

Conclusion: 该研究扩展了最新大小写敏感模型在稀疏检索场景下的适用性，促进了更强基础架构与稀疏检索的集成。文本小写化预处理是解决大小写敏感模型在LSR中性能问题的有效方法。

Abstract: Learned Sparse Retrieval (LSR) methods construct sparse lexical representations of queries and documents that can be efficiently searched using inverted indexes. Existing LSR approaches have relied almost exclusively on uncased backbone models, whose vocabularies exclude case-sensitive distinctions, thereby reducing vocabulary mismatch. However, the most recent state-of-the-art language models are only available in cased versions. Despite this shift, the impact of backbone model casing on LSR has not been studied, potentially posing a risk to the viability of the method going forward. To fill this gap, we systematically evaluate paired cased and uncased versions of the same backbone models across multiple datasets to assess their suitability for LSR. Our findings show that LSR models with cased backbone models by default perform substantially worse than their uncased counterparts; however, this gap can be eliminated by pre-processing the text to lowercase. Moreover, our token-level analysis reveals that, under lowercasing, cased models almost entirely suppress cased vocabulary items and behave effectively as uncased models, explaining their restored performance. This result broadens the applicability of recent cased models to the LSR setting and facilitates the integration of stronger backbone architectures into sparse retrieval. The complete code and implementation for this project are available at: https://github.com/lionisakis/Uncased-vs-cased-models-in-LSR

</details>


### [104] [Noise-Robust AV-ASR Using Visual Features Both in the Whisper Encoder and Decoder](https://arxiv.org/abs/2601.18396)
*Zhengyang Li,Thomas Graave,Björn Möller,Zehang Wu,Matthias Franz,Tim Fingscheidt*

Main category: eess.AS

Relevance: 45.0

TL;DR: 基于Whisper ASR的视听语音识别改进方法，提出双用途视觉融合（编码器和解码器同时使用视觉特征），在噪声环境下显著提升鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有视听语音识别系统在噪声环境下性能下降，需要更有效的视觉特征融合方法来提升噪声鲁棒性。Whisper ASR作为强大的预训练模型，为视听融合提供了良好基础。

Method: 1. 提出双用途视觉融合方法：在编码器中使用视觉特征学习视听交互，在解码器中使用视觉特征权衡不同模态
2. 在不同规模的Whisper模型上比较视觉融合方法
3. 进行消融研究，分析不同模块设计和融合选项的影响
4. 在1929小时的视听数据上进行微调

Result: 1. 双用途方法在噪声鲁棒性方面表现一致改善：基于Whisper small相对改善35%（WER: 4.41% vs. 6.83%），基于Whisper medium相对改善57%（WER: 4.07% vs. 9.53%）
2. 在LRS3 AV-ASR基准测试中，使用Whisper medium的双用途方法在MUSAN噪声下平均WER为4.08%，在NoiseX噪声下为4.43%，建立了噪声条件下的新SOTA

Conclusion: 双用途视觉融合方法简单有效，能显著提升视听语音识别系统在噪声环境下的鲁棒性，为实际应用中的噪声问题提供了实用解决方案。

Abstract: In audiovisual automatic speech recognition (AV-ASR) systems, information fusion of visual features in a pre-trained ASR has been proven as a promising method to improve noise robustness. In this work, based on the prominent Whisper ASR, first, we propose a simple and effective visual fusion method -- use of visual features both in encoder and decoder (dual-use) -- to learn the audiovisual interactions in the encoder and to weigh modalities in the decoder. Second, we compare visual fusion methods in Whisper models of various sizes. Our proposed dual-use method shows consistent noise robustness improvement, e.g., a 35% relative improvement (WER: 4.41% vs. 6.83%) based on Whisper small, and a 57% relative improvement (WER: 4.07% vs. 9.53%) based on Whisper medium, compared to typical reference middle fusion in babble noise with a signal-to-noise ratio (SNR) of 0dB. Third, we conduct ablation studies examining the impact of various module designs and fusion options. Fine-tuned on 1929 hours of audiovisual data, our dual-use method using Whisper medium achieves 4.08% (MUSAN babble noise) and 4.43% (NoiseX babble noise) average WER across various SNRs, thereby establishing a new state-of-the-art in noisy conditions on the LRS3 AV-ASR benchmark. Our code is at https://github.com/ifnspaml/Dual-Use-AVASR

</details>


### [105] [From Emotion to Expression: Theoretical Foundations and Resources for Fear Speech](https://arxiv.org/abs/2601.17132)
*Vigneshwaran Shankaran,Gabriella Lapesa,Claudia Wagner*

Main category: cs.CL

Relevance: 35.0

TL;DR: 该论文提出将"恐惧言论"作为一个独立的语言现象进行研究，而非仅仅视为一种情感。通过整合心理学、政治学、传播学和语言学等多学科视角，建立了恐惧言论的分类体系，并综述了相关数据集，为恐惧言论研究提供了理论和实践指导。


<details>
  <summary>Details</summary>
Motivation: 恐惧言论在社交媒体上广泛传播且增长迅速，因其表面"文明"而常逃避内容审核，有时比仇恨言论更具传播力和参与度。然而，计算语言学领域对恐惧言论的研究仍然分散且资源不足，缺乏统一的理论框架和系统性的研究。

Method: 1. 整合多学科视角：比较心理学、政治学、传播学和语言学中的恐惧理论；2. 综述现有定义；3. 调查相关研究领域的数据集；4. 提出恐惧言论的多维度分类体系，为系统研究提供框架。

Result: 建立了跨学科的恐惧言论理论框架，提出了系统性的分类体系，综述了现有数据集资源，为恐惧言论的识别、分析和研究提供了理论基础和实践指导。

Conclusion: 恐惧言论是一个需要跨学科研究的复杂语言现象，本文通过整合多学科视角和建立分类体系，为恐惧言论的计算研究提供了重要基础，有助于推动该领域的数据集创建和学术进展。

Abstract: Few forces rival fear in their ability to mobilize societies, distort communication, and reshape collective behavior. In computational linguistics, fear is primarily studied as an emotion, but not as a distinct form of speech. Fear speech content is widespread and growing, and often outperforms hate-speech content in reach and engagement because it appears "civiler" and evades moderation. Yet the computational study of fear speech remains fragmented and under-resourced. This can be understood by recognizing that fear speech is a phenomenon shaped by contributions from multiple disciplines. In this paper, we bridge cross-disciplinary perspectives by comparing theories of fear from Psychology, Political science, Communication science, and Linguistics. Building on this, we review existing definitions. We follow up with a survey of datasets from related research areas and propose a taxonomy that consolidates different dimensions of fear for studying fear speech. By reviewing current datasets and defining core concepts, our work offers both theoretical and practical guidance for creating datasets and advancing fear speech research.

</details>


### [106] [Do readers prefer AI-generated Italian short stories?](https://arxiv.org/abs/2601.17363)
*Michael Farrell*

Main category: cs.CL

Relevance: 35.0

TL;DR: 研究比较了ChatGPT-4o生成的意大利语短篇小说与意大利著名作家Alberto Moravia作品的读者偏好，发现AI生成文本获得了略高的平均评分和更多偏好，但差异不大。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究读者是否更偏好AI生成的文学作品而非人类作家作品，挑战关于人类创作文学优越性的假设，并探讨在文学语境中合成文本编辑的必要性。

Method: 采用盲测设计，20名参与者在不知道来源的情况下阅读并评估三篇短篇小说（两篇由ChatGPT-4o生成，一篇由Alberto Moravia创作）。收集了阅读习惯和人口统计数据（年龄、性别、教育程度、母语）作为潜在影响因素。

Result: AI生成的文本获得了略高的平均评分，且更频繁地被偏好，但差异不大。文本偏好与人口统计或阅读习惯变量之间没有发现统计学上的显著关联。

Conclusion: 研究结果挑战了读者偏好人类创作小说的假设，提出了关于文学语境中合成文本编辑必要性的问题，表明AI在文学创作方面已达到相当水平。

Abstract: This study investigates whether readers prefer AI-generated short stories in Italian over one written by a renowned Italian author. In a blind setup, 20 participants read and evaluated three stories, two created with ChatGPT-4o and one by Alberto Moravia, without being informed of their origin. To explore potential influencing factors, reading habits and demographic data, comprising age, gender, education and first language, were also collected. The results showed that the AI-written texts received slightly higher average ratings and were more frequently preferred, although differences were modest. No statistically significant associations were found between text preference and demographic or reading-habit variables. These findings challenge assumptions about reader preference for human-authored fiction and raise questions about the necessity of synthetic-text editing in literary contexts.

</details>


### [107] [Beyond the Rabbit Hole: Mapping the Relational Harms of QAnon Radicalization](https://arxiv.org/abs/2601.17658)
*Bich Ngoc,Doan,Giuseppe Russo,Gianmarco De Francisci Morales,Robert West*

Main category: cs.CL

Relevance: 35.0

TL;DR: 研究通过分析QAnon支持者亲属的12747个叙述，使用主题建模和LLM辅助情感检测，识别出6种激进化人格类型，并发现这些人格类型能预测亲属经历的具体情感伤害。


<details>
  <summary>Details</summary>
Motivation: 现有大规模计算研究往往忽视阴谋论对信徒亲友的个人情感影响。本研究旨在填补这一空白，系统性地绘制激进化历程并量化对亲友的情感伤害。

Method: 采用混合方法：1) 使用BERTopic主题建模分析r/QAnonCasualties社区的12747个叙述，绘制激进化轨迹；2) 应用LDA图模型识别6种QAnon信徒的"激进化人格"原型；3) 使用LLM辅助情感检测和回归模型，将人格类型与叙述者报告的情感伤害联系起来。

Result: 研究发现激进化人格不仅是描述性的，还能预测叙述者经历的具体情感伤害：被视为意识形态选择的激进化与叙述者的愤怒和厌恶相关，而个人和认知崩溃相关的激进化则与恐惧和悲伤相关。

Conclusion: 本研究首次提供了理解激进化作为关系现象的实证框架，为研究人员和实践者应对其人际影响提供了重要路线图。

Abstract: The rise of conspiracy theories has created far-reaching societal harm in the public discourse by eroding trust and fueling polarization. Beyond this public impact lies a deeply personal toll on the friends and families of conspiracy believers, a dimension often overlooked in large-scale computational research. This study fills this gap by systematically mapping radicalization journeys and quantifying the associated emotional toll inflicted on loved ones. We use the prominent case of QAnon as a case study, analyzing 12747 narratives from the r/QAnonCasualties support community through a novel mixed-methods approach. First, we use topic modeling (BERTopic) to map the radicalization trajectories, identifying key pre-existing conditions, triggers, and post-radicalization characteristics. From this, we apply an LDA-based graphical model to uncover six recurring archetypes of QAnon adherents, which we term "radicalization personas." Finally, using LLM-assisted emotion detection and regression modeling, we link these personas to the specific emotional toll reported by narrators. Our findings reveal that these personas are not just descriptive; they are powerful predictors of the specific emotional harms experienced by narrators. Radicalization perceived as a deliberate ideological choice is associated with narrator anger and disgust, while those marked by personal and cognitive collapse are linked to fear and sadness. This work provides the first empirical framework for understanding radicalization as a relational phenomenon, offering a vital roadmap for researchers and practitioners to navigate its interpersonal fallout.

</details>


### [108] [DIETA: A Decoder-only transformer-based model for Italian-English machine TrAnslation](https://arxiv.org/abs/2601.17823)
*Pranav Kasela,Marco Braga,Alessandro Ghiotto,Andrea Pilzer,Marco Viviani,Alessandro Raganato*

Main category: cs.CL

Relevance: 35.0

TL;DR: DIETA是一个专门为意大利语-英语机器翻译设计的5亿参数解码器Transformer模型，在多个基准测试中表现优异，超越了大多数3B参数以下的模型。


<details>
  <summary>Details</summary>
Motivation: 针对意大利语-英语机器翻译领域缺乏专门优化的小型模型，作者希望开发一个专门为此任务设计的Transformer模型，填补现有研究的空白。

Method: 收集并整理了约2.07亿意大利语-英语平行句对，涵盖议会记录、法律文本、网络爬取内容、字幕、新闻、文学等多个领域，并使用预训练模型生成了3.52亿反向翻译数据。构建了一个基于2025篇WikiNews文章的450句小型评估集。

Result: DIETA在多个意大利语-英语基准测试中表现出色，在32个系统的排行榜中始终排名第二四分位数，在五个测试套件中的四个上超越了大多数其他3B参数以下的模型。

Conclusion: DIETA为意大利语-英语机器翻译提供了一个高效、专门化的小型模型解决方案，其训练脚本、模型、语料库和评估集均已公开，有助于该领域的进一步研究。

Abstract: In this paper, we present DIETA, a small, decoder-only Transformer model with 0.5 billion parameters, specifically designed and trained for Italian-English machine translation. We collect and curate a large parallel corpus consisting of approximately 207 million Italian-English sentence pairs across diverse domains, including parliamentary proceedings, legal texts, web-crawled content, subtitles, news, literature and 352 million back-translated data using pretrained models. Additionally, we create and release a new small-scale evaluation set, consisting of 450 sentences, based on 2025 WikiNews articles, enabling assessment of translation quality on contemporary text. Comprehensive evaluations show that DIETA achieves competitive performance on multiple Italian-English benchmarks, consistently ranking in the second quartile of a 32-system leaderboard and outperforming most other sub-3B models on four out of five test suites. The training script, trained models, curated corpus, and newly introduced evaluation set are made publicly available, facilitating further research and development in specialized Italian-English machine translation. https://github.com/pkasela/DIETA-Machine-Translation

</details>


### [109] [CommonLID: Re-evaluating State-of-the-Art Language Identification Performance on Web Data](https://arxiv.org/abs/2601.18026)
*Pedro Ortiz Suarez,Laurie Burchell,Catherine Arnett,Rafael Mosquera-Gómez,Sara Hincapie-Monsalve,Thom Vaughan,Damian Stewart,Malte Ostendorff,Idris Abdulmumin,Vukosi Marivate,Shamsuddeen Hassan Muhammad,Atnafu Lambebo Tonja,Hend Al-Khalifa,Nadia Ghezaiel Hammouda,Verrah Otiende,Tack Hwa Wong,Jakhongir Saydaliev,Melika Nobakhtian,Muhammad Ravi Shulthan Habibi,Chalamalasetti Kranti,Carol Muchemi,Khang Nguyen,Faisal Muhammad Adam,Luis Frentzen Salim,Reem Alqifari,Cynthia Amol,Joseph Marvin Imperial,Ilker Kesen,Ahmad Mustafid,Pavel Stepachev,Leshem Choshen,David Anugraha,Hamada Nayel,Seid Muhie Yimam,Vallerie Alexandra Putra,My Chiffon Nguyen,Azmine Toushik Wasi,Gouthami Vadithya,Rob van der Goot,Lanwenn ar C'horr,Karan Dua,Andrew Yates,Mithil Bangera,Yeshil Bangera,Hitesh Laxmichand Patel,Shu Okabe,Fenal Ashokbhai Ilasariya,Dmitry Gaynullin,Genta Indra Winata,Yiyuan Li,Juan Pablo Martínez,Amit Agarwal,Ikhlasul Akmal Hanif,Raia Abu Ahmad,Esther Adenuga,Filbert Aurelian Tjiaranata,Weerayut Buaphet,Michael Anugraha,Sowmya Vajjala,Benjamin Rice,Azril Hafizi Amirudin,Jesujoba O. Alabi,Srikant Panda,Yassine Toughrai,Bruhan Kyomuhendo,Daniel Ruffinelli,Akshata A,Manuel Goulão,Ej Zhou,Ingrid Gabriela Franco Ramirez,Cristina Aggazzotti,Konstantin Dobler,Jun Kevin,Quentin Pagès,Nicholas Andrews,Nuhu Ibrahim,Mattes Ruckdeschel,Amr Keleg,Mike Zhang,Casper Muziri,Saron Samuel,Sotaro Takeshita,Kun Kerdthaisong,Luca Foppiano,Rasul Dent,Tommaso Green,Ahmad Mustapha Wali,Kamohelo Makaaka,Vicky Feliren,Inshirah Idris,Hande Celikkanat,Abdulhamid Abubakar,Jean Maillard,Benoît Sagot,Thibault Clérice,Kenton Murray,Sarah Luger*

Main category: cs.CL

Relevance: 35.0

TL;DR: CommonLID是一个社区驱动的人工标注语言识别基准，涵盖109种语言，专门针对网络领域数据，旨在解决现有LID模型在嘈杂异构网络数据上表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 语言识别是多语言语料库构建的基础步骤，但现有LID模型在许多语言上表现不佳，特别是在用于训练多语言语言模型的嘈杂异构网络数据上。缺乏针对网络领域的全面基准测试。

Method: 创建CommonLID基准：社区驱动、人工标注的网络领域语言识别数据集，覆盖109种语言，包括许多以前服务不足的语言。使用该基准与其他5个常见评估集测试8个流行的LID模型。

Result: 研究发现现有评估高估了LID模型在网络领域的准确性，CommonLID揭示了模型在实际网络数据上的真实性能。该基准为开发更具代表性的高质量文本语料库提供了关键资源。

Conclusion: CommonLID填补了网络领域语言识别评估的空白，提供了更真实的性能评估，有助于改进多语言语料库构建和语言模型训练。

Abstract: Language identification (LID) is a fundamental step in curating multilingual corpora. However, LID models still perform poorly for many languages, especially on the noisy and heterogeneous web data often used to train multilingual language models. In this paper, we introduce CommonLID, a community-driven, human-annotated LID benchmark for the web domain, covering 109 languages. Many of the included languages have been previously under-served, making CommonLID a key resource for developing more representative high-quality text corpora. We show CommonLID's value by using it, alongside five other common evaluation sets, to test eight popular LID models. We analyse our results to situate our contribution and to provide an overview of the state of the art. In particular, we highlight that existing evaluations overestimate LID accuracy for many languages in the web domain. We make CommonLID and the code used to create it available under an open, permissive license.

</details>


### [110] [GLEN-Bench: A Graph-Language based Benchmark for Nutritional Health](https://arxiv.org/abs/2601.18106)
*Jiatan Huang,Zheyuan Zhang,Tianyi Ma,Mingchen Li,Yaning Zheng,Yanfang Ye,Chuxu Zhang*

Main category: cs.CL

Relevance: 35.0

TL;DR: GLEN-Bench：首个基于图语言模型的营养健康评估基准，整合NHANES健康记录、FNDDS食物成分数据和USDA食物获取指标，构建连接人口统计、健康状况、饮食行为、贫困约束和营养需求的知识图谱，用于风险检测、个性化推荐和问答解释任务。


<details>
  <summary>Details</summary>
Motivation: 当前营养干预计算方法存在三个关键缺陷：1）饮食模式研究忽略社会经济状况、并发症等现实约束；2）推荐系统缺乏解释性；3）缺乏统一基准评估营养干预相关任务。需要开发综合基准来支持个性化饮食指导。

Method: 构建GLEN-Bench基准，整合NHANES健康记录、FNDDS食物成分数据和USDA食物获取指标，创建连接人口统计、健康状况、饮食行为、贫困约束和营养需求的知识图谱。在阿片类药物使用障碍案例中测试，包含三个关联任务：风险检测、个性化推荐和问答解释。评估图神经网络、大语言模型和混合架构等图语言方法。

Result: 建立了首个全面的图语言营养健康评估基准，识别出与健康风险相关的明确饮食模式，为实际干预提供指导。评估了不同图语言方法，建立了可靠的基线并确定了实用的设计选择。

Conclusion: GLEN-Bench填补了营养干预计算方法的空白，通过图语言方法整合多源数据，支持个性化饮食指导。该基准为营养健康评估提供了统一框架，有助于开发更有效的营养干预系统。

Abstract: Nutritional interventions are important for managing chronic health conditions, but current computational methods provide limited support for personalized dietary guidance. We identify three key gaps: (1) dietary pattern studies often ignore real-world constraints such as socioeconomic status, comorbidities, and limited food access; (2) recommendation systems rarely explain why a particular food helps a given patient; and (3) no unified benchmark evaluates methods across the connected tasks needed for nutritional interventions. We introduce GLEN-Bench, the first comprehensive graph-language based benchmark for nutritional health assessment. We combine NHANES health records, FNDDS food composition data, and USDA food-access metrics to build a knowledge graph that links demographics, health conditions, dietary behaviors, poverty-related constraints, and nutrient needs. We test the benchmark using opioid use disorder, where models must detect subtle nutritional differences across disease stages. GLEN-Bench includes three linked tasks: risk detection identifies at-risk individuals from dietary and socioeconomic patterns; recommendation suggests personalized foods that meet clinical needs within resource constraints; and question answering provides graph-grounded, natural-language explanations to facilitate comprehension. We evaluate these graph-language approaches, including graph neural networks, large language models, and hybrid architectures, to establish solid baselines and identify practical design choices. Our analysis identifies clear dietary patterns linked to health risks, providing insights that can guide practical interventions.

</details>


### [111] [Fine-Grained Emotion Detection on GoEmotions: Experimental Comparison of Classical Machine Learning, BiLSTM, and Transformer Models](https://arxiv.org/abs/2601.18162)
*Ani Harutyunyan,Sachin Kumar*

Main category: cs.CL

Relevance: 35.0

TL;DR: 该论文在GoEmotions数据集上对比了三种细粒度情感识别模型：基于TF-IDF的逻辑回归、带注意力的BiLSTM和微调的BERT模型，发现逻辑回归在Micro-F1上表现最佳，而BERT在整体平衡性上最优。


<details>
  <summary>Details</summary>
Motivation: 细粒度情感识别是一个具有挑战性的多标签NLP任务，面临标签重叠和类别不平衡的问题。本研究旨在系统评估不同建模方法在GoEmotions数据集上的表现，探索不同模型架构在处理情感识别任务时的优势和局限性。

Method: 使用GoEmotions数据集的官方训练/验证/测试划分，对比三种模型：1) 基于TF-IDF特征并使用二进制相关方法训练的逻辑回归；2) 带注意力的双向LSTM；3) 为多标签分类微调的BERT模型。采用逆频率类别权重来缓解类别不平衡问题。

Result: 逻辑回归获得最高的Micro-F1分数（0.51），而BERT模型在整体平衡性上表现最佳，超越了原论文报告的结果，达到Macro-F1 0.49、Hamming Loss 0.036和Subset Accuracy 0.36。结果表明高频情感依赖表层词汇线索，而上下文表示能提升对稀有情感和模糊示例的识别能力。

Conclusion: 不同模型在细粒度情感识别任务中各有优势：逻辑回归在捕捉高频情感的表层特征方面有效，而BERT的上下文表示能力在处理复杂、稀有情感时表现更佳。这为实际应用中的模型选择提供了指导。

Abstract: Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples.

</details>


### [112] [CitiLink: Enhancing Municipal Transparency and Citizen Engagement through Searchable Meeting Minutes](https://arxiv.org/abs/2601.18374)
*Rodrigo Silva,José Evans,José Isidro,Miguel Marques,Afonso Fonseca,Ricardo Morais,João Canavilhas,Arian Pasquali,Purificação Silvano,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,Ricardo Campos*

Main category: cs.CL

Relevance: 35.0

TL;DR: CitiLink平台使用LLMs将非结构化的市政会议记录转换为结构化可搜索数据，通过NLP和IR技术提升地方政府透明度和可访问性。


<details>
  <summary>Details</summary>
Motivation: 市政会议记录通常冗长、正式且具有官僚写作风格，虽然公开但结构复杂，使公民和记者难以高效查找信息。需要技术手段提升政府文档的可访问性和透明度。

Method: 系统采用LLMs（特别是Gemini）从会议记录中提取元数据、讨论主题和投票结果，然后使用BM25排名和分面过滤构建全文搜索引擎，并通过用户友好界面展示。

Result: 基于葡萄牙6个市镇的120份会议记录构建了系统，通过市政人员的引导测试评估了可用性，并评估了Gemini在信息提取方面的有效性。

Conclusion: CitiLink展示了NLP和IR技术如何增强地方政府文档的可访问性，LLMs在信息提取方面表现有效，系统为公民参与和政府透明度提供了实用工具。

Abstract: City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction.

</details>


### [113] [Corpus-Based Approaches to Igbo Diacritic Restoration](https://arxiv.org/abs/2601.18380)
*Ignatius Ezeani*

Main category: cs.CL

Relevance: 35.0

TL;DR: 该论文针对低资源语言（伊博语）的变音符号歧义问题，提出了三种变音符号恢复方法：标准n-gram模型、分类模型和嵌入模型，以解决NLP研究中资源不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 当前NLP研究主要关注英语、中文等高资源语言，而全球95%的7000多种语言都是低资源语言，缺乏数据、工具和技术支持。伊博语作为低资源语言，存在变音符号歧义问题，影响NLP处理效果。

Method: 1. 标准n-gram模型：使用目标词之前的词序列作为预测正确变体形式的关键特征
2. 分类模型：使用目标词两侧的窗口词作为特征
3. 嵌入模型：比较上下文词嵌入与候选变体向量嵌入的相似度得分

Result: 提出了一个灵活的变音符号恢复数据集生成框架，并针对伊博语开发了三种不同的变音符号消歧方法，为低资源语言的NLP处理提供了技术方案。

Conclusion: 该研究填补了低资源语言NLP处理的空白，特别是针对伊博语的变音符号恢复问题，提出的框架和方法可为其他低资源语言提供参考。

Abstract: With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.
  In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.

</details>


### [114] [GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback](https://arxiv.org/abs/2601.18517)
*James Sungarda,Hongkai Liu,Zilong Zhou,Tien-Hsuan Wu,Johnson Chun-Sing Cheung,Ben Kao*

Main category: cs.CL

Relevance: 35.0

TL;DR: SWITCH是一个社会工作交互式培训聊天机器人，通过整合现实客户模拟、实时咨询技能分类和动机访谈进展系统，为社工培训提供可扩展、低成本的解决方案。


<details>
  <summary>Details</summary>
Motivation: 社会工作现场教育受限于指导老师和咨询客户的可用性，难以及时提供客观反馈。需要开发一个可扩展、低成本的培训工具来补充现场教育。

Method: 1) 使用包含静态字段（背景、信念）和动态字段（情绪、自动思维、开放性）的认知基础配置文件来模拟客户；2) 技能分类模块识别用户话语中的咨询技能；3) MI控制器调节动机访谈阶段转换；4) 采用基于上下文学习和检索注释转录的方法，以及微调的BERT多标签分类器来提高分类准确性。

Result: 实验表明，基于BERT的方法和上下文学习方法都显著优于基线模型，提供了更高的分类准确性。

Conclusion: SWITCH提供了一个可扩展、低成本且一致的培训工作流程，补充了现场教育，使督导能够专注于更高层次的指导。

Abstract: Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.

</details>


### [115] [OCR-Enhanced Multimodal ASR Can Read While Listening](https://arxiv.org/abs/2601.18393)
*Junli Chen,Changli Tang,Yixuan Li,Guangzhi Sun,Chao Zhang*

Main category: cs.SD

Relevance: 35.0

TL;DR: Donut-Whisper是一个音频-视觉ASR模型，通过双编码器利用视觉信息（如电影字幕）提升英语和中文的语音识别性能，结合线性与Q-Former模态对齐结构，并提出轻量级知识蒸馏方案。


<details>
  <summary>Details</summary>
Motivation: 视觉信息（如电影字幕）通常有助于自动语音识别。当前音频-视觉ASR模型在利用视觉信息提升多语言（特别是英语和中文）语音识别性能方面仍有改进空间。

Method: 1. 提出Donut-Whisper音频-视觉ASR模型，采用双编码器架构
2. 通过交叉注意力模块结合线性对齐和Q-Former模态对齐结构的优势
3. 提出轻量级知识蒸馏方案，用音频-视觉模型指导纯音频模型
4. 构建基于电影片段的多语言音频-视觉语音识别数据集（包含中英文部分）

Result: 1. 在英语和中文数据集上显著优于Donut和Whisper large V3基线
2. 相比Whisper ASR基线，英语集实现5.75%绝对WER降低，中文集实现16.5%绝对CER降低
3. 展示了音频-视觉模型指导纯音频模型提升性能的潜力

Conclusion: Donut-Whisper通过创新的模态对齐结构和知识蒸馏方案，有效利用视觉信息提升多语言语音识别性能，为音频-视觉ASR研究提供了新的方法和数据集。

Abstract: Visual information, such as subtitles in a movie, often helps automatic speech recognition. In this paper, we propose Donut-Whisper, an audio-visual ASR model with dual encoder to leverage visual information to improve speech recognition performance in both English and Chinese. Donut-Whisper combines the advantage of the linear and the Q-Former-based modality alignment structures via a cross-attention module, generating more powerful audio-visual features. Meanwhile, we propose a lightweight knowledge distillation scheme showcasing the potential of using audio-visual models to teach audio-only models to achieve better performance. Moreover, we propose a new multilingual audio-visual speech recognition dataset based on movie clips containing both Chinese and English partitions. As a result, Donut-Whisper achieved significantly better performance on both English and Chinese partition of the dataset compared to both Donut and Whisper large V3 baselines. In particular, an absolute 5.75% WER reduction and a 16.5% absolute CER reduction were achieved on the English and Chinese sets respectively compared to the Whisper ASR baseline.

</details>


### [116] [Interpretability of the Intent Detection Problem: A New Approach](https://arxiv.org/abs/2601.17156)
*Eduardo Sanchez-Karhunen,Jose F. Quesada-Moreno,Miguel A. Gutiérrez-Naranjo*

Main category: cs.CL

Relevance: 25.0

TL;DR: 该研究应用动力系统理论分析RNN如何解决意图检测任务，揭示了在平衡数据集上RNN学习到理想几何解（隐藏状态空间被划分为不同意图簇），而在不平衡数据集上低频意图簇会退化。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在意图检测领域占主导地位，但RNN解决该任务的内在机制仍不清楚。作者希望理解RNN如何内部处理意图检测问题，特别是数据集属性如何影响网络的计算解决方案。

Method: 应用动力系统理论分析RNN架构，将句子解释为隐藏状态空间中的轨迹。使用平衡的SNIPS数据集和不平衡的ATIS数据集，分析隐藏状态空间的几何结构，解耦几何分离与读出对齐。

Result: 在平衡SNIPS数据集上，网络学习到理想解：状态空间被约束在低维流形上，并划分为对应不同意图的独立簇。在不平衡ATIS数据集上，低频意图的簇会退化，几何解被扭曲。

Conclusion: 该框架提供了RNN动态的新见解，给出了数据集属性如何直接塑造网络计算解决方案的几何解释。揭示了类不平衡如何导致性能差异的机制性解释。

Abstract: Intent detection, a fundamental text classification task, aims to identify and label the semantics of user queries, playing a vital role in numerous business applications. Despite the dominance of deep learning techniques in this field, the internal mechanisms enabling Recurrent Neural Networks (RNNs) to solve intent detection tasks are poorly understood. In this work, we apply dynamical systems theory to analyze how RNN architectures address this problem, using both the balanced SNIPS and the imbalanced ATIS datasets. By interpreting sentences as trajectories in the hidden state space, we first show that on the balanced SNIPS dataset, the network learns an ideal solution: the state space, constrained to a low-dimensional manifold, is partitioned into distinct clusters corresponding to each intent. The application of this framework to the imbalanced ATIS dataset then reveals how this ideal geometric solution is distorted by class imbalance, causing the clusters for low-frequency intents to degrade. Our framework decouples geometric separation from readout alignment, providing a novel, mechanistic explanation for real world performance disparities. These findings provide new insights into RNN dynamics, offering a geometric interpretation of how dataset properties directly shape a network's computational solution.

</details>


### [117] [Hylog: A Hybrid Approach to Logging Text Production in Non-alphabetic Scripts](https://arxiv.org/abs/2601.17753)
*Roberto Crotti,Giovanni Denaro,Zhiqiang Du,Ricardo Muñoz Martín*

Main category: cs.CL

Relevance: 25.0

TL;DR: Hylog是一个混合日志系统，结合分析性键盘记录和生态文本记录，用于捕捉非字母文字输入法编辑器的屏幕转换过程，支持更完整、细粒度的文本生产认知研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究键盘记录器大多无法捕捉非字母文字（如中文）输入法编辑器（IME）的屏幕转换过程，这限制了文本生产认知研究的完整性和多语言包容性。

Method: 开发模块化开源系统，通过插件捕获标准应用（Word、Chrome）的键盘输出和渲染文本，使用混合器模块同步生成双重轨迹记录。

Result: 概念验证研究中成功捕获了拉丁字母、中文字符和IME确认之间的按键和时序间隔，这些测量传统键盘记录器无法获取，支持新的可测试认知假设。

Conclusion: Hylog填补了方法论空白，支持更全面的多语言文本生产研究，插件架构可扩展到其他IME系统。

Abstract: Research keyloggers are essential for cognitive studies of text production, yet most fail to capture the on-screen transformations performed by Input Method Editors (IMEs) for non-alphabetic scripts. To address this methodological gap, we present Hylog, a novel hybrid logging system that combines analytical keylogging with ecological text logging for a more complete and finer-grained analysis. Our modular, open-source system uses plug-ins for standard applications (Microsoft Word, Google Chrome) to capture both keyboard output and rendered text, which a hybridizer module then synchronizes into a dual trace. To validate the system's technical feasibility and demonstrate its analytical capabilities, we conducted a proof-of-concept study where two volunteers translated a text into simplified Chinese. Hylog successfully captured keypresses and temporal intervals between Latin letters, Chinese characters, and IME confirmations -- some measurements invisible to traditional keyloggers. The resulting data enable the formulation of new, testable hypotheses about the cognitive restrictions and affordances at different linguistic layers in IME-mediated typing. Our plug-in architecture enables extension to other IME systems and fosters more inclusive multilingual text-production research.

</details>


### [118] [AI-based approach to burnout identification from textual data](https://arxiv.org/abs/2601.17993)
*Marina Zavertiaeva,Petr Parshakov,Mikhail Usanin,Aleksei Smirnov,Sofia Paklina,Anastasiia Kibardina*

Main category: cs.CL

Relevance: 25.0

TL;DR: 该研究提出了一种基于AI的方法，利用自然语言处理从文本数据中检测职业倦怠，使用RuBERT模型进行情感分析并微调用于倦怠检测。


<details>
  <summary>Details</summary>
Motivation: 职业倦怠是高压工作环境中的常见问题，传统检测方法耗时且主观。该研究旨在开发一种自动化、可扩展的方法，通过分析文本中的语言信号来检测倦怠，为组织提供早期预警和干预工具。

Method: 使用基于RuBERT的预训练模型，该模型原本用于情感分析。通过两个数据源进行微调：1) ChatGPT生成的合成句子；2) 从俄罗斯YouTube关于倦怠的视频中收集的用户评论。最终模型能够为输入文本分配倦怠概率。

Result: 开发了一个能够从文本中检测职业倦怠的AI模型，可以处理大量书面通信，监控高压工作环境中的倦怠相关语言信号。

Conclusion: 该方法为组织提供了一种自动化工具，用于通过文本分析监测员工倦怠，有助于早期识别和干预，改善工作场所心理健康。

Abstract: This study introduces an AI-based methodology that utilizes natural language processing (NLP) to detect burnout from textual data. The approach relies on a RuBERT model originally trained for sentiment analysis and subsequently fine-tuned for burnout detection using two data sources: synthetic sentences generated with ChatGPT and user comments collected from Russian YouTube videos about burnout. The resulting model assigns a burnout probability to input texts and can be applied to process large volumes of written communication for monitoring burnout-related language signals in high-stress work environments.

</details>


### [119] [Pisets: A Robust Speech Recognition System for Lectures and Interviews](https://arxiv.org/abs/2601.18415)
*Ivan Bondarenko,Daniil Grebenkin,Oleg Sedukhin,Mikhail Klementev,Roman Derunets,Lyudmila Budneva*

Main category: cs.CL

Relevance: 25.0

TL;DR: 提出Pisets语音转文字系统，采用三组件架构改进Whisper的识别准确率并减少错误和幻觉，包含Wav2Vec2初步识别、AST假阳性过滤和Whisper最终识别，通过课程学习和多样俄语语料库提升效果。


<details>
  <summary>Details</summary>
Motivation: 解决Whisper模型在语音识别中存在的错误和幻觉问题，特别是针对科学家和记者等专业用户的长音频转录需求，提高在多种声学条件下的鲁棒性。

Method: 三组件架构：1) Wav2Vec2进行初步语音识别；2) Audio Spectrogram Transformer (AST)过滤假阳性；3) Whisper进行最终语音识别。采用课程学习方法，利用多样俄语语料库，并引入高级不确定性建模技术。

Result: 相比WhisperX和标准Whisper模型，Pisets系统在长音频转录和各种声学条件下表现出更鲁棒的性能，显著提高了转录质量。

Conclusion: 提出的三组件架构结合课程学习和不确定性建模，有效提升了语音识别系统的准确性和鲁棒性，为科学家和记者提供了可靠的语音转文字工具。

Abstract: This work presents a speech-to-text system "Pisets" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of "Pisets" system is publicly available at GitHub: https://github.com/bond005/pisets.

</details>


### [120] [Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features](https://arxiv.org/abs/2601.18536)
*Abishek Stephen,Jindřich Libovický*

Main category: cs.CL

Relevance: 25.0

TL;DR: 提出一种基于形态句法特征评估子词分割形态合理性的新指标，无需黄金分割数据，适用于更多语言


<details>
  <summary>Details</summary>
Motivation: 传统评估指标（如语素边界F分数）需要黄金分割数据，但许多语言缺乏这种数据或质量不一致。需要一种更广泛适用的评估方法，利用更普遍可得的形态句法特征资源。

Method: 使用形态句法特征（来自Universal Dependencies或UniMorph等资源），通过IBM Model 1概率对齐子词与形态特征，构建评估指标

Result: 新指标与传统语素边界召回率相关性良好，同时在不同形态系统的语言中具有更广泛的适用性

Conclusion: 提出的基于形态特征的概率对齐方法为子词分割评估提供了更通用、更可行的解决方案，特别适用于资源匮乏的语言

Abstract: We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.

</details>


### [121] [Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets](https://arxiv.org/abs/2601.18791)
*Iaroslav Chelombitko,Mika Hämäläinen,Aleksey Komissarov*

Main category: cs.CL

Relevance: 25.0

TL;DR: 该研究对242种拉丁和西里尔文字语言进行大规模比较，通过BPE子词方法分析词汇重叠、词汇差异和语言相似性，发现BPE分割与语素边界高度一致，且BPE词汇相似性与语言遗传关系显著相关。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一个统一的框架来大规模比较不同语言的词汇模式，特别是通过子词方法（如BPE）来量化语言间的相似性和差异，为宏观语言学提供定量分析工具。

Method: 方法包括：1）从维基百科词典构建"glottosets"；2）使用字节对编码（BPE）进行同时跨语言比较；3）基于排名的子词向量分析词汇重叠、词汇差异和语言相似性；4）评估BPE分割与语素边界的一致性；5）分析跨语言同形词的分割差异。

Result: 结果显示：1）BPE分割在15种语言中比随机基线好95%（F1=0.34 vs 0.15）；2）BPE词汇相似性与语言遗传关系显著相关（Mantel r=0.329, p<0.001）；3）罗曼语族形成最紧密的聚类（平均距离0.51）；4）跨语系对显示明显分离（0.82）；5）26,939个跨语言同形词中48.7%在不同相关语言中获得不同分割，变异与系统发育距离相关。

Conclusion: 结论是BPE子词方法为类型多样的语言提供了统一的词汇模式分析框架，能够量化语言间的相似性和差异，为宏观语言学提供重要见解，特别是在语言遗传关系和词汇演变方面。

Abstract: We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.

</details>


### [122] [How Do We Engage with Other Disciplines? A Framework to Study Meaningful Interdisciplinary Discourse in Scholarly Publications](https://arxiv.org/abs/2601.17020)
*Bagyasree Sudharsan,Alexandria Leto,Maria Leonor Pacheco*

Main category: cs.DL

Relevance: 25.0

TL;DR: 提出一个评估跨学科NLP研究中引用参与质量的框架，包括专门针对跨学科工作的引用目的分类法，并通过NLP与计算社会科学的交叉研究进行了验证。


<details>
  <summary>Details</summary>
Motivation: 随着跨学科研究的兴起，需要理解出版物如何整合多学科思想。现有方法（如机构多样性、关键词、引用模式）无法评估单个引用如何推动引用工作，且现有引用目的分类法不适合跨学科研究，缺乏定量评估引用参与质量的指标。

Method: 提出专门针对跨学科工作的引用目的分类法，通过标注研究验证，开发评估跨学科NLP出版物中引用参与质量的框架，并以NLP与计算社会科学的交叉研究为例进行深入分析。

Result: 开发了一个适用于跨学科研究的引用目的分类法，并展示了该框架在分析NLP与计算社会科学交叉出版物中的实用性，提供了定量评估引用参与质量的方法。

Conclusion: 该框架填补了跨学科研究中引用参与质量评估的空白，为理解跨学科出版物如何整合多学科思想提供了新的分析工具，特别适用于NLP等领域的跨学科研究评估。

Abstract: With the rising popularity of interdisciplinary work and increasing institutional incentives in this direction, there is a growing need to understand how resulting publications incorporate ideas from multiple disciplines. Existing computational approaches, such as affiliation diversity, keywords, and citation patterns, do not account for how individual citations are used to advance the citing work. Although, in line with addressing this gap, prior studies have proposed taxonomies to classify citation purpose, these frameworks are not well-suited to interdisciplinary research and do not provide quantitative measures of citation engagement quality. To address these limitations, we propose a framework for the evaluation of citation engagement in interdisciplinary Natural Language Processing (NLP) publications. Our approach introduces a citation purpose taxonomy tailored to interdisciplinary work, supported by an annotation study. We demonstrate the utility of this framework through a thorough analysis of publications at the intersection of NLP and Computational Social Science.

</details>


### [123] [Memento: Towards Proactive Visualization of Everyday Memories with Personal Wearable AR Assistant](https://arxiv.org/abs/2601.17622)
*Yoonsang Kim,Yalong Yang,Arie E. Kaufman*

Main category: cs.HC

Relevance: 25.0

TL;DR: Memento是一个对话式AR助手，能够永久记录用户的语音查询及其时空和活动上下文，通过记忆发现用户重复兴趣与触发情境之间的关联，并在检测到相似情境时主动回忆用户兴趣并提供最新AR响应。


<details>
  <summary>Details</summary>
Motivation: 现有AR交互通常是瞬态事件，缺乏长期连贯性。作者希望创建能够理解用户长期兴趣模式、将AR体验无缝融入日常生活的上下文感知系统，使每次交互都成为具有连贯长期视角的系列互动。

Method: 设计了一个永久捕获和记忆用户语音查询及其时空活动上下文的系统。通过存储这些"记忆"，发现用户重复兴趣与触发情境之间的关联。当检测到相似或相同的时空活动时，系统主动回忆用户兴趣并通过AR提供最新响应。

Result: 通过用户反馈进行初步评估，探索了主动上下文感知AR助手在日常环境中的价值。分享了设计主动上下文感知AR系统的发现和挑战。

Conclusion: Memento展示了将AR交互从瞬态事件转变为具有连贯长期视角的系列互动的潜力，为将AR体验无缝融入日常生活提供了新途径。

Abstract: We introduce Memento, a conversational AR assistant that permanently captures and memorizes user's verbal queries alongside their spatiotemporal and activity contexts. By storing these "memories," Memento discovers connections between users' recurring interests and the contexts that trigger them. Upon detection of similar or identical spatiotemporal activity, Memento proactively recalls user interests and delivers up-to-date responses through AR, seamlessly integrating AR experience into their daily routine. Unlike prior work, each interaction in Memento is not a transient event, but a connected series of interactions with coherent long--term perspective, tailored to the user's broader multimodal (visual, spatial, temporal, and embodied) context. We conduct preliminary evaluation through user feedbacks with participants of diverse expertise in immersive apps, and explore the value of proactive context-aware AR assistant in everyday settings. We share our findings and challenges in designing a proactive, context-aware AR system.

</details>


### [124] [BanglaRobustNet: A Hybrid Denoising-Attention Architecture for Robust Bangla Speech Recognition](https://arxiv.org/abs/2601.17679)
*Md Sazzadul Islam Ridoy,Mubaswira Ibnat Zidney,Sumi Akter,Md. Aminur Rahman*

Main category: cs.SD

Relevance: 25.0

TL;DR: 提出BanglaRobustNet，一个基于Wav2Vec-BERT的混合去噪注意力框架，专门针对孟加拉语在噪声和说话人多样性条件下的语音识别问题


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为使用广泛的语言，在自动语音识别研究中代表性不足，特别是在噪声环境和说话人多样性条件下，需要专门针对低资源、噪声敏感的语言环境设计鲁棒系统

Method: 基于Wav2Vec-BERT构建混合去噪注意力框架，集成扩散去噪模块抑制环境噪声并保留孟加拉语特定语音特征，以及上下文交叉注意力模块利用说话人嵌入增强对不同性别、年龄和方言的鲁棒性，采用端到端训练，结合CTC损失、语音一致性和说话人对齐的复合目标函数

Result: 相比Wav2Vec-BERT和Whisper基线，在单词错误率和字符错误率方面取得显著降低，在Mozilla Common Voice Bangla和增强噪声语音数据集上的评估验证了方法的有效性

Conclusion: BanglaRobustNet成为针对低资源、噪声敏感语言环境的鲁棒ASR系统，为孟加拉语语音识别提供了有效解决方案

Abstract: Bangla, one of the most widely spoken languages, remains underrepresented in state-of-the-art automatic speech recognition (ASR) research, particularly under noisy and speaker-diverse conditions. This paper presents BanglaRobustNet, a hybrid denoising-attention framework built on Wav2Vec-BERT, designed to address these challenges. The architecture integrates a diffusion-based denoising module to suppress environmental noise while preserving Bangla-specific phonetic cues, and a contextual cross-attention module that conditions recognition on speaker embeddings for robustness across gender, age, and dialects. Trained end-to-end with a composite objective combining CTC loss, phonetic consistency, and speaker alignment, BanglaRobustNet achieves substantial reductions in word error rate (WER) and character error rate (CER) compared to Wav2Vec-BERT and Whisper baselines. Evaluations on Mozilla Common Voice Bangla and augmented noisy speech confirm the effectiveness of our approach, establishing BanglaRobustNet as a robust ASR system tailored to low-resource, noise-prone linguistic settings.

</details>


### [125] [MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data](https://arxiv.org/abs/2601.18792)
*Brian Liu,Oiwi Parker Jones*

Main category: cs.HC

Relevance: 25.0

TL;DR: 该研究探索使用预训练文本情感模型标注脑磁图数据，训练脑到情感解码模型，证明可从大脑活动解码情感


<details>
  <summary>Details</summary>
Motivation: 现有脑数据与语音/文本对齐的数据集缺乏情感标注，需要填补这一空白以从大脑活动解码情感，深化对人类体验的理解

Method: 使用预训练文本情感模型标注MEG脑磁图数据，通过文本-音频强制对齐将情感标签与脑记录对齐，训练脑到情感解码模型

Result: 实验结果显示脑到情感模型的平衡准确率相比基线有所提升，验证了利用现有MEG数据集直接从大脑解码情感的可行性

Conclusion: 该方法为利用现有脑磁图数据集学习直接从大脑解码情感提供了概念验证，推动了脑活动情感解码研究

Abstract: Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.

</details>


### [126] [Window Size Versus Accuracy Experiments in Voice Activity Detectors](https://arxiv.org/abs/2601.17270)
*Max McKinnon,Samir Khaki,Chandan KA Reddy,William Huang*

Main category: cs.SD

Relevance: 20.0

TL;DR: 研究分析了窗口大小对三种语音活动检测算法（Silero、WebRTC、RMS）准确性的影响，并探索了在VAD输出上使用迟滞的效果，为优化VAD系统提供实用参考。


<details>
  <summary>Details</summary>
Motivation: 语音活动检测在语音识别等应用中至关重要，但不同算法的窗口大小设置会影响检测准确性，需要在实际音频流上进行系统分析。

Method: 在多样化的真实数字音频流上，分析窗口大小对三种VAD算法（Silero、WebRTC、RMS）准确性的影响，并在每种VAD输出上探索迟滞技术的应用效果。

Result: Silero算法显著优于WebRTC和RMS算法；迟滞技术对WebRTC算法有提升效果。

Conclusion: 研究结果为优化VAD系统提供了实用参考，Silero是性能最佳的算法，迟滞技术可改善WebRTC的性能。

Abstract: Voice activity detection (VAD) plays a vital role in enabling applications such as speech recognition. We analyze the impact of window size on the accuracy of three VAD algorithms: Silero, WebRTC, and Root Mean Square (RMS) across a set of diverse real-world digital audio streams. We additionally explore the use of hysteresis on top of each VAD output. Our results offer practical references for optimizing VAD systems. Silero significantly outperforms WebRTC and RMS, and hysteresis provides a benefit for WebRTC.

</details>


### [127] [Systematicity between Forms and Meanings across Languages Supports Efficient Communication](https://arxiv.org/abs/2601.17181)
*Doreen Osmelak,Yang Xu,Michael Hahn,Kate McCurdy*

Main category: cs.CL

Relevance: 15.0

TL;DR: 该论文提出了一种基于可学习性的新复杂度度量方法，用于分析语言中动词和代词形式如何平衡简洁性（最小化语法区分）和准确性（恢复意图意义）的竞争压力，从而更好地解释自然语言中的系统性规律。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解语言如何平衡简洁性和准确性这两种竞争性交际压力，特别是解释语言中动词和代词形式映射的系统性规律。现有高效交际理论未能充分解释词形内部的系统性关系。

Method: 提出基于意义到形式映射可学习性的新复杂度度量方法，分析跨类型多样语言中动词和代词表达的语法意义（如人称、数），通过该创新方法捕捉语言形式的细粒度规律性。

Result: 研究发现动词和代词形式确实受到简洁性和准确性竞争压力的塑造，新提出的基于可学习性的复杂度度量能更好地区分实际存在和不存在的语言系统，建立了高效交际理论与自然语言系统性之间的新联系。

Conclusion: 基于可学习性的复杂度度量方法能够有效捕捉语言形式的细粒度规律性，为理解语言如何平衡交际压力提供了新视角，建立了高效交际理论与语言系统性之间的理论联系。

Abstract: Languages vary widely in how meanings map to word forms. These mappings have been found to support efficient communication; however, this theory does not account for systematic relations within word forms. We examine how a restricted set of grammatical meanings (e.g. person, number) are expressed on verbs and pronouns across typologically diverse languages. Consistent with prior work, we find that verb and pronoun forms are shaped by competing communicative pressures for simplicity (minimizing the inventory of grammatical distinctions) and accuracy (enabling recovery of intended meanings). Crucially, our proposed model uses a novel measure of complexity (inverse of simplicity) based on the learnability of meaning-to-form mappings. This innovation captures fine-grained regularities in linguistic form, allowing better discrimination between attested and unattested systems, and establishes a new connection from efficient communication theory to systematicity in natural language.

</details>


### [128] [Neurocomputational Mechanisms of Syntactic Transfer in Bilingual Sentence Production](https://arxiv.org/abs/2601.18056)
*Ahmet Yavuz Uluslu,Elliot Murphy*

Main category: cs.CL

Relevance: 15.0

TL;DR: 该论文提出将振荡特征纳入双语产生错误研究，使用ROSE神经模型解释双语中的句法迁移，特别是跨语言影响（CLI），将其视为L2句子规划中的特定振荡故障模式。


<details>
  <summary>Details</summary>
Motivation: 传统双语研究主要关注事件相关电位等时间特征，缺乏对振荡特征的考虑。作者认为振荡特征能为双语理论提供新的实现层面约束，特别是对于理解跨语言影响（CLI）的神经机制。

Method: 采用ROSE神经语言模型作为理论框架，将跨语言影响（CLI）建模为L2句子规划过程中的特定振荡故障模式。通过分析振荡特征来理解双语产生中的句法迁移和形态句法序列故障。

Result: ROSE模型能够捕捉双语产生中句法迁移的形式特性和形态句法序列故障的范围。该方法不仅提供了ROSE模型所鼓励的连接假设，还允许探索比传统神经特征更复杂的时空生物标志物。

Conclusion: 将振荡特征纳入双语研究能够为双语理论提供新的实现层面约束，ROSE模型为理解跨语言影响提供了神经计算解释，这种方法有助于探索更复杂的语言功能障碍生物标志物。

Abstract: We discuss the benefits of incorporating into the study of bilingual production errors and their traditionally documented timing signatures (e.g., event-related potentials) certain types of oscillatory signatures, which can offer new implementational-level constraints for theories of bilingualism. We argue that a recent neural model of language, ROSE, can offer a neurocomputational account of syntactic transfer in bilingual production, capturing some of its formal properties and the scope of morphosyntactic sequencing failure modes. We take as a case study cross-linguistic influence (CLI) and attendant theories of functional inhibition/competition, and present these as being driven by specific oscillatory failure modes during L2 sentence planning. We argue that modeling CLI in this way not only offers the kind of linking hypothesis ROSE was built to encourage, but also licenses the exploration of more spatiotemporally complex biomarkers of language dysfunction than more commonly discussed neural signatures.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [129] [Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility](https://arxiv.org/abs/2601.17027)
*Honglin Lin,Chonghan Qin,Zheng Liu,Qizhi Pei,Yu Li,Zhanping Zhong,Xin Gao,Yanfeng Wang,Conghui He,Lijun Wu*

Main category: cs.CV

Relevance: 85.0

TL;DR: 论文研究了科学图像合成，提出了ImgCoder逻辑驱动框架和SciGenBench评估基准，发现像素级模型存在系统性问题，并证明使用高质量合成科学图像微调大模型能提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型生成的图像虽然视觉上合理但科学上不正确，存在视觉-逻辑差异，限制了其在科学推理中的应用。需要解决科学图像合成的准确性问题。

Method: 1) 分析像素级生成和程序化合成两种范式；2) 提出ImgCoder框架，采用"理解-规划-编码"工作流提高结构精度；3) 引入SciGenBench评估基准，基于信息效用和逻辑有效性评估生成图像。

Result: 1) 发现像素级模型存在系统性失败模式；2) 揭示了表达能力与精度之间的基本权衡；3) 使用严格验证的合成科学图像微调大模型能获得一致的推理提升，显示出类似文本领域的扩展趋势。

Conclusion: 高保真科学图像合成是解锁大规模多模态推理能力的可行路径，通过逻辑驱动框架和严格评估可以解决现有模型的视觉-逻辑差异问题。

Abstract: While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. Existing Text-to-Image (T2I) models often produce outputs that are visually plausible yet scientifically incorrect, resulting in a persistent visual-logic divergence that limits their value for downstream reasoning. Motivated by recent advances in next-generation T2I models, we conduct a systematic study of scientific image synthesis across generation paradigms, evaluation, and downstream use. We analyze both direct pixel-based generation and programmatic synthesis, and propose ImgCoder, a logic-driven framework that follows an explicit "understand - plan - code" workflow to improve structural precision. To rigorously assess scientific correctness, we introduce SciGenBench, which evaluates generated images based on information utility and logical validity. Our evaluation reveals systematic failure modes in pixel-based models and highlights a fundamental expressiveness-precision trade-off. Finally, we show that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains, with potential scaling trends analogous to the text domain, validating high-fidelity scientific synthesis as a viable path to unlocking massive multimodal reasoning capabilities.

</details>


### [130] [AMVICC: A Novel Benchmark for Cross-Modal Failure Mode Profiling for VLMs and IGMs](https://arxiv.org/abs/2601.17037)
*Aahana Basappa,Pranay Goel,Anusri Karra,Anish Karra,Asa Gilmore,Kevin Zhu*

Main category: cs.CV

Relevance: 85.0

TL;DR: 该论文创建了AMVICC基准，用于系统评估多模态大语言模型和图像生成模型在视觉推理任务上的失败模式，发现模型在基本视觉概念理解上存在显著缺陷，且失败模式在不同模态间既有共性也有特异性。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态模型快速发展，但现有视觉语言模型在理解基本视觉概念（如物体方向、数量、空间关系）方面仍存在明显缺陷。缺乏系统评估跨模态视觉推理失败模式的基准，阻碍了对模型视觉理解能力的深入分析。

Method: 通过将MMVP基准问题转化为显式和隐式提示，创建了AMVICC基准，用于分析图像到文本和文本到图像任务的失败模式。测试了11个MLLM和3个IGM在9个视觉推理类别上的表现，系统比较了不同模型和模态的失败模式。

Result: 结果显示：1）失败模式在模型和模态间存在共享性，但也有模型特异性和模态特异性；2）IGM在响应提示时难以精确控制特定视觉组件，特别是在显式提示下；3）模型在基本视觉概念理解上存在系统性缺陷。

Conclusion: 该工作为跨模态对齐研究奠定了基础，提供了分析生成和理解失败是否源于共享限制的框架，有助于指导未来统一视觉语言模型的改进方向。

Abstract: We investigated visual reasoning limitations of both multimodal large language models (MLLMs) and image generation models (IGMs) by creating a novel benchmark to systematically compare failure modes across image-to-text and text-to-image tasks, enabling cross-modal evaluation of visual understanding. Despite rapid growth in machine learning, vision language models (VLMs) still fail to understand or generate basic visual concepts such as object orientation, quantity, or spatial relationships, which highlighted gaps in elementary visual reasoning. By adapting MMVP benchmark questions into explicit and implicit prompts, we create \textit{AMVICC}, a novel benchmark for profiling failure modes across various modalities. After testing 11 MLLMs and 3 IGMs in nine categories of visual reasoning, our results show that failure modes are often shared between models and modalities, but certain failures are model-specific and modality-specific, and this can potentially be attributed to various factors. IGMs consistently struggled to manipulate specific visual components in response to prompts, especially in explicit prompts, suggesting poor control over fine-grained visual attributes. Our findings apply most directly to the evaluation of existing state-of-the-art models on structured visual reasoning tasks. This work lays the foundation for future cross-modal alignment studies, offering a framework to probe whether generation and interpretation failures stem from shared limitations to guide future improvements in unified vision-language modeling.

</details>


### [131] [Interpretable and Sparse Linear Attention with Decoupled Membership-Subspace Modeling via MCR2 Objective](https://arxiv.org/abs/2601.17042)
*Tianyuan Liu,Libin Hou,Linyuan Wang,Bin Yan*

Main category: cs.CV

Relevance: 85.0

TL;DR: 本文提出了一种解耦成员矩阵和子空间矩阵的稀疏线性注意力机制(DMSA)，通过改进MCR2驱动的白盒Transformer，在视觉任务中实现了更高的效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有MCR2驱动的白盒Transformer中，成员矩阵和子空间矩阵紧密耦合，导致在错误的token投影下产生冗余编码。为了解决这个问题，需要解耦这两者的功能关系，从而获得更高效和可解释的注意力机制。

Method: 提出解耦成员-子空间注意力(DMSA)：1) 从输入直接学习成员矩阵；2) 从全空间S推导稀疏子空间；3) 通过对优化的MCR2目标进行梯度展开，得到可解释的稀疏线性注意力算子。将DMSA替换Token Statistics Transformer中的注意力模块，形成DMST架构。

Result: 在ImageNet-1K数据集上，DMST比ToST在top-1准确率上提升1.08%-1.45%，同时达到更快的编码降维速率。相比传统Transformer架构，DMST展现出显著更高的计算效率和可解释性。

Conclusion: 通过解耦MCR2目标中的成员矩阵和子空间矩阵，提出的DMSA注意力机制为白盒Transformer提供了更高效和可解释的解决方案，在视觉任务中实现了性能提升。

Abstract: Maximal Coding Rate Reduction (MCR2)-driven white-box transformer, grounded in structured representation learning, unifies interpretability and efficiency, providing a reliable white-box solution for visual modeling. However, in existing designs, tight coupling between "membership matrix" and "subspace matrix U" in MCR2 causes redundant coding under incorrect token projection. To this end, we decouple the functional relationship between the "membership matrix" and "subspaces U" in the MCR2 objective and derive an interpretable sparse linear attention operator from unrolled gradient descent of the optimized objective. Specifically, we propose to directly learn the membership matrix from inputs and subsequently derive sparse subspaces from the fullspace S. Consequently, gradient unrolling of the optimized MCR2 objective yields an interpretable sparse linear attention operator: Decoupled Membership-Subspace Attention (DMSA). Experimental results on visual tasks show that simply replacing the attention module in Token Statistics Transformer (ToST) with DMSA (we refer to as DMST) not only achieves a faster coding reduction rate but also outperforms ToST by 1.08%-1.45% in top-1 accuracy on the ImageNet-1K dataset. Compared with vanilla Transformer architectures, DMST exhibits significantly higher computational efficiency and interpretability.

</details>


### [132] [Scaling medical imaging report generation with multimodal reinforcement learning](https://arxiv.org/abs/2601.17151)
*Qianchu Liu,Sheng Zhang,Guanghui Qin,Yu Gu,Ying Jin,Sam Preston,Yanbo Xu,Sid Kiblawi,Wen-wai Yim,Tim Ossowski,Tristan Naumann,Mu Wei,Hoifung Poon*

Main category: cs.CV

Relevance: 85.0

TL;DR: UniRG是一个用于医学影像报告生成的通用框架，通过强化学习直接优化评估指标，在胸部X光报告生成任务上取得了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 前沿模型在自然语言理解和推理方面表现出色，但在生物医学等垂直领域的多模态理解和推理方面仍有较大能力差距。医学影像报告生成是一个典型例子，监督微调容易过拟合到表面模式。

Method: 提出Universal Report Generation (UniRG)框架，利用强化学习作为统一机制，直接针对终端应用设计的评估指标进行优化，从而获得更好的泛化能力。

Result: 在胸部X光报告生成任务上，UniRG-CXR在权威ReXrank基准测试中创造了新的整体SOTA，显著超越了之前的最先进方法。

Conclusion: UniRG框架通过强化学习优化评估指标，能够显著提升监督微调的性能，并在不同机构和临床实践中获得持久的泛化能力。

Abstract: Frontier models have demonstrated remarkable capabilities in understanding and reasoning with natural-language text, but they still exhibit major competency gaps in multimodal understanding and reasoning especially in high-value verticals such as biomedicine. Medical imaging report generation is a prominent example. Supervised fine-tuning can substantially improve performance, but they are prone to overfitting to superficial boilerplate patterns. In this paper, we introduce Universal Report Generation (UniRG) as a general framework for medical imaging report generation. By leveraging reinforcement learning as a unifying mechanism to directly optimize for evaluation metrics designed for end applications, UniRG can significantly improve upon supervised fine-tuning and attain durable generalization across diverse institutions and clinical practices. We trained UniRG-CXR on publicly available chest X-ray (CXR) data and conducted a thorough evaluation in CXR report generation with rigorous evaluation scenarios. On the authoritative ReXrank benchmark, UniRG-CXR sets new overall SOTA, outperforming prior state of the art by a wide margin.

</details>


### [133] [ReLE: A Scalable System and Structured Benchmark for Diagnosing Capability Anisotropy in Chinese LLMs](https://arxiv.org/abs/2601.17399)
*Rui Fang,Jian Li,Wei Chen,Bin Hu,Ying-Cong Chen,Xin Tang,Liang Diao*

Main category: cs.CV

Relevance: 85.0

TL;DR: ReLE是一个可扩展的实时评估系统，用于诊断LLM在中文理解中的能力各向异性，通过混合评分机制和动态调度器显著降低计算成本，揭示模型排名对权重方案的高度敏感性。


<details>
  <summary>Details</summary>
Motivation: 当前中文大语言模型的评估面临基准饱和和计算成本高昂的挑战，静态排行榜往往掩盖了模型在不同领域能力之间的结构性权衡，需要更高效的实时评估方法来诊断模型的能力各向异性。

Method: 1) 提出ReLE可扩展系统，评估304个模型（189个商业模型，115个开源模型）；2) 引入符号基础混合评分机制，消除推理任务中基于嵌入的误报；3) 基于Neyman分配和噪声校正的动态方差感知调度器，减少70%计算成本；4) 使用领域×能力正交矩阵，包含207,843个样本。

Result: 1) 计算成本降低70%，同时保持排名相关性ρ=0.96；2) 发现聚合排名对权重方案高度敏感，ReLE中的排名稳定幅度为11.4，而传统基准约为5.0；3) 揭示现代模型高度专业化而非普遍优越；4) 验证了能力各向异性的存在。

Conclusion: ReLE不是全面静态基准的替代品，而是作为模型生态演化的高频诊断监控工具，能够有效揭示模型在不同领域的能力差异，为模型选择和部署提供更精细的指导。

Abstract: Large Language Models (LLMs) have achieved rapid progress in Chinese language understanding, yet accurately evaluating their capabilities remains challenged by benchmark saturation and prohibitive computational costs. While static leaderboards provide snapshot rankings, they often mask the structural trade-offs between capabilities. In this work, we present ReLE (Robust Efficient Live Evaluation), a scalable system designed to diagnose Capability Anisotropy, the non-uniformity of model performance across domains. Using ReLE, we evaluate 304 models (189 commercial, 115 open-source) across a Domain $\times$ Capability orthogonal matrix comprising 207,843 samples. We introduce two methodological contributions to address current evaluation pitfalls: (1) A Symbolic-Grounded Hybrid Scoring Mechanism that eliminates embedding-based false positives in reasoning tasks; (2) A Dynamic Variance-Aware Scheduler based on Neyman allocation with noise correction, which reduces compute costs by 70\% compared to full-pass evaluations while maintaining a ranking correlation of $ρ=0.96$. Our analysis reveals that aggregate rankings are highly sensitive to weighting schemes: models exhibit a Rank Stability Amplitude (RSA) of 11.4 in ReLE versus $\sim$5.0 in traditional benchmarks, confirming that modern models are highly specialized rather than generally superior. We position ReLE not as a replacement for comprehensive static benchmarks, but as a high-frequency diagnostic monitor for the evolving model landscape.

</details>


### [134] [Sponge Tool Attack: Stealthy Denial-of-Efficiency against Tool-Augmented Agentic Reasoning](https://arxiv.org/abs/2601.17566)
*Qi Li,Xinchao Wang*

Main category: cs.CV

Relevance: 85.0

TL;DR: 本文提出Sponge Tool Attack (STA)，一种针对LLM工具调用过程的攻击方法，通过重写输入提示来破坏智能体推理过程，造成计算开销而不修改模型或工具。


<details>
  <summary>Details</summary>
Motivation: 现有研究通过为LLM配备外部工具来实现智能体推理，取得了高效实用的效果，但这些方法对工具调用过程的恶意操纵漏洞尚未充分探索。本文旨在揭示这一攻击面。

Method: 提出Sponge Tool Attack (STA)，在仅查询访问的严格假设下，通过重写输入提示来破坏智能体推理。STA采用迭代式多智能体协作框架，通过明确的改写策略控制，从原始提示生成语义保真度高、看似良性的提示重写。

Result: 实验在6个模型（开源和闭源API）、12个工具、4个智能体框架、13个数据集（涵盖5个领域）上验证了STA的有效性。攻击成功将原本简洁高效的推理轨迹转化为冗长复杂的轨迹，造成显著计算开销。

Conclusion: STA揭示了LLM工具调用过程中的安全漏洞，即使不修改模型或工具，仅通过提示重写就能破坏智能体推理效率，这对LLM系统的安全性和鲁棒性提出了重要警示。

Abstract: Enabling large language models (LLMs) to solve complex reasoning tasks is a key step toward artificial general intelligence. Recent work augments LLMs with external tools to enable agentic reasoning, achieving high utility and efficiency in a plug-and-play manner. However, the inherent vulnerabilities of such methods to malicious manipulation of the tool-calling process remain largely unexplored. In this work, we identify a tool-specific attack surface and propose Sponge Tool Attack (STA), which disrupts agentic reasoning solely by rewriting the input prompt under a strict query-only access assumption. Without any modification on the underlying model or the external tools, STA converts originally concise and efficient reasoning trajectories into unnecessarily verbose and convoluted ones before arriving at the final answer. This results in substantial computational overhead while remaining stealthy by preserving the original task semantics and user intent. To achieve this, we design STA as an iterative, multi-agent collaborative framework with explicit rewritten policy control, and generates benign-looking prompt rewrites from the original one with high semantic fidelity. Extensive experiments across 6 models (including both open-source models and closed-source APIs), 12 tools, 4 agentic frameworks, and 13 datasets spanning 5 domains validate the effectiveness of STA.

</details>


### [135] [VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding](https://arxiv.org/abs/2601.17868)
*Zhihao He,Tieyuan Chen,Kangyu Wang,Ziran Qin,Yang Shao,Chaofan Gan,Shijie Li,Zuxuan Wu,Weiyao Lin*

Main category: cs.CV

Relevance: 85.0

TL;DR: VidLaDA是一个基于扩散语言模型的视频大语言模型，采用双向注意力机制解决自回归模型中的因果掩码偏差问题，并提出MARS-Cache框架通过异步视觉缓存刷新和分块注意力加速推理，在保持准确性的同时实现12倍加速。


<details>
  <summary>Details</summary>
Motivation: 标准自回归视频LLM存在因果掩码偏差，阻碍全局时空建模，导致理解效率低下。需要一种能够捕捉双向依赖关系的方法来改善视频理解。

Method: 1. 提出VidLaDA：基于扩散语言模型的视频LLM，利用双向注意力捕捉双向依赖关系；2. 引入MARS-Cache框架：通过异步视觉缓存刷新和帧级分块注意力加速推理，使用锚令牌保持全局连接性。

Result: VidLaDA在实验中优于扩散基线模型，并与最先进的自回归模型（如Qwen2.5-VL和LLaVA-Video）相媲美。MARS-Cache在不损害推理准确性的情况下实现了超过12倍的加速。

Conclusion: VidLaDA通过扩散语言模型和双向注意力机制有效解决了自回归视频LLM的因果掩码偏差问题，MARS-Cache框架显著提升了推理效率，为视频理解任务提供了高效准确的解决方案。

Abstract: Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.

</details>


### [136] [Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models](https://arxiv.org/abs/2601.17918)
*Dain Kim,Jiwoo Lee,Jaehoon Yun,Yong Hoe Koo,Qingyu Chen,Hyunjae Kim,Jaewoo Kang*

Main category: cs.CV

Relevance: 85.0

TL;DR: 本文首次全面评估了医疗领域大型视觉语言模型（LVLMs）中多种DPO变体的效果，发现现有方法在医疗高风险场景下存在局限性，并提出针对视觉误解错误的偏好构建策略，在视觉问答任务上提升了3.6%的性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医疗应用中有巨大潜力，但其部署常受限于对齐不足和可靠性问题。虽然直接偏好优化（DPO）已成为优化模型响应的有效框架，但在高风险医疗环境中的效果尚未充分探索，缺乏指导未来方法发展的实证基础。

Method: 在医疗领域首次全面评估9种不同DPO变体，使用两个医疗LVLMs（LLaVA-Med和HuatuoGPT-Vision）。基于发现的问题，提出了针对视觉误解错误的偏好构建策略作为概念验证。

Result: 发现当前DPO方法在监督微调上的增益不一致，效果在不同任务和骨干模型间差异显著，且常无法解决基本的视觉误解错误。提出的针对性策略在视觉问答任务上比现有最强DPO基线提升了3.6%。

Conclusion: DPO在医疗LVLMs中的应用需要更精细的设计，特别是针对视觉误解问题。研究为医疗领域偏好优化提供了实证基础，并开源了完整框架支持未来研究。

Abstract: Large Vision-Language Models (LVLMs) hold significant promise for medical applications, yet their deployment is often constrained by insufficient alignment and reliability. While Direct Preference Optimization (DPO) has emerged as a potent framework for refining model responses, its efficacy in high-stakes medical contexts remains underexplored, lacking the rigorous empirical groundwork necessary to guide future methodological advances. To bridge this gap, we present the first comprehensive examination of diverse DPO variants within the medical domain, evaluating nine distinct formulations across two medical LVLMs: LLaVA-Med and HuatuoGPT-Vision. Our results reveal several critical limitations: current DPO approaches often yield inconsistent gains over supervised fine-tuning, with their efficacy varying significantly across different tasks and backbones. Furthermore, they frequently fail to resolve fundamental visual misinterpretation errors. Building on these insights, we present a targeted preference construction strategy as a proof-of-concept that explicitly addresses visual misinterpretation errors frequently observed in existing DPO models. This design yields a 3.6% improvement over the strongest existing DPO baseline on visual question-answering tasks. To support future research, we release our complete framework, including all training data, model checkpoints, and our codebase at https://github.com/dmis-lab/med-vlm-dpo.

</details>


### [137] [GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning](https://arxiv.org/abs/2601.18543)
*Kaixun Jiang,Yuzheng Wang,Junjie Zhou,Pandeng Li,Zhihang Liu,Chen-Wei Xie,Zhaoyu Chen,Yun Zheng,Wenqiang Zhang*

Main category: cs.CV

Relevance: 85.0

TL;DR: GenAgent是一个通过智能体框架统一视觉理解和生成的智能多模态模型，它将理解与生成解耦，利用图像生成模型作为可调用工具，支持自主多轮交互和迭代优化。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型面临昂贵的训练成本以及理解与生成之间的权衡问题，而现有模块化系统受限于静态流程，无法支持自主多轮交互和迭代优化。

Method: 采用智能体框架：多模态模型负责理解，图像生成模型作为可调用工具。使用两阶段训练策略：1) 高质量工具调用和反思数据的监督微调；2) 结合点式奖励（最终图像质量）和成对奖励（反思准确性）的端到端智能体强化学习，使用轨迹重采样增强多轮探索。

Result: GenAgent显著提升了基础生成器（FLUX.1-dev）在GenEval++（+23.6%）和WISE（+14%）上的性能。展示了三个关键特性：跨工具泛化能力、测试时扩展性（交互轮次增加持续改进）和任务自适应推理。

Conclusion: GenAgent通过智能体框架有效统一了视觉理解和生成，避免了传统统一模型的训练成本和性能权衡问题，同时支持自主多轮交互和迭代优化，具有跨工具泛化、测试时扩展和任务自适应推理等优势。

Abstract: We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\%) and WISE (+14\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \href{https://github.com/deep-kaixun/GenAgent}{this url}.

</details>


### [138] [A Mechanistic View on Video Generation as World Models: State and Dynamics](https://arxiv.org/abs/2601.17067)
*Luozhou Wang,Zhifei Chen,Yihua Du,Dongyu Yan,Wenhang Ge,Guibao Shen,Xinli Xu,Leyi Wu,Man Chen,Tianshuo Xu,Peiran Ren,Xin Tao,Pengfei Wan,Ying-Cong Chen*

Main category: cs.CV

Relevance: 75.0

TL;DR: 该论文提出了一种新的分类法，将视频生成模型与世界模型理论联系起来，重点关注状态构建和动态建模两个支柱，并倡导从视觉保真度评估转向功能基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前大规模视频生成模型虽然展现出物理一致性，但"无状态"的视频架构与经典的状态中心世界模型理论之间存在差距。需要弥合这一差距，推动视频生成模型从生成视觉上合理的视频发展为构建稳健的通用世界模拟器。

Method: 提出以状态构建和动态建模为核心的新分类法。状态构建分为隐式范式（上下文管理）和显式范式（潜在压缩）；动态建模通过知识整合和架构重构进行分析。同时倡导评估范式转变，从视觉保真度转向功能基准测试，测试物理持久性和因果推理能力。

Result: 建立了视频生成模型与世界模型理论之间的桥梁，提出了系统的分类框架，并识别了两个关键前沿：通过数据驱动记忆和压缩保真度增强持久性，以及通过潜在因子解耦和推理先验整合推进因果性。

Conclusion: 通过解决持久性和因果性挑战，视频生成领域可以从生成视觉上合理的视频演进为构建稳健的通用世界模拟器，实现真正的世界建模能力。

Abstract: Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary "stateless" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.

</details>


### [139] [GRASP: Guided Region-Aware Sparse Prompting for Adapting MLLMs to Remote Sensing](https://arxiv.org/abs/2601.17089)
*Qigan Sun,Chaoning Zhang,Jianwei Zhang,Xudong Wang,Jiehui Xie,Pengcheng Zheng,Haoyu Wang,Sungyoung Lee,Chi-lok Andy Tai,Yang Yang,Heng Tao Shen*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出GRASP方法，一种参数高效的微调策略，通过引导区域感知的稀疏提示来解决遥感图像中MLLMs的过拟合和细节忽略问题。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在遥感图像上直接微调存在过拟合背景噪声或忽略目标细节的问题，主要原因是遥感图像的大尺度变化、稀疏目标分布和复杂区域语义特征。

Method: 提出GRASP方法：1) 从冻结的视觉标记网格中提取空间块相关的空间结构化软提示；2) 通过问题引导的稀疏融合机制动态聚合任务特定上下文到紧凑的全局提示中。

Result: 在多个RSVQA基准测试中，GRASP相比现有微调和基于提示的方法取得了有竞争力的性能，同时保持高参数效率。

Conclusion: GRASP通过引导区域感知的稀疏提示机制，有效解决了遥感图像中MLLMs的微调挑战，在保持参数效率的同时提升了性能。

Abstract: In recent years, Multimodal Large Language Models (MLLMs) have made significant progress in visual question answering tasks. However, directly applying existing fine-tuning methods to remote sensing (RS) images often leads to issues such as overfitting on background noise or neglecting target details. This is primarily due to the large-scale variations, sparse target distributions, and complex regional semantic features inherent in RS images. These challenges limit the effectiveness of MLLMs in RS tasks. To address these challenges, we propose a parameter-efficient fine-tuning (PEFT) strategy called Guided Region-Aware Sparse Prompting (GRASP). GRASP introduces spatially structured soft prompts associated with spatial blocks extracted from a frozen visual token grid. Through a question-guided sparse fusion mechanism, GRASP dynamically aggregates task-specific context into a compact global prompt, enabling the model to focus on relevant regions while filtering out background noise. Extensive experiments on multiple RSVQA benchmarks show that GRASP achieves competitive performance compared to existing fine-tuning and prompt-based methods while maintaining high parameter efficiency.

</details>


### [140] [Fluxamba: Topology-Aware Anisotropic State Space Models for Geological Lineament Segmentation in Multi-Source Remote Sensing](https://arxiv.org/abs/2601.17288)
*Jin Bai,Huiyao Zhang,Qi Wen,Shengyang Li,Xiaolin Tian,Atta ur Rahman*

Main category: cs.CV

Relevance: 75.0

TL;DR: Fluxamba：一种轻量级架构，通过拓扑感知特征校正框架解决地质线性特征分割中的长程依赖问题，在保持实时推理速度的同时显著提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 地质线性特征（如行星线状构造和地表裂缝）的精确分割需要捕捉复杂各向异性拓扑中的长程依赖关系。传统状态空间模型（SSMs）虽然计算复杂度接近线性，但其依赖刚性的轴对齐扫描轨迹导致与曲线目标存在拓扑不匹配，造成上下文碎片化和特征侵蚀。

Method: 提出Fluxamba架构，核心是结构通量块（SFB），包含各向异性结构门（ASG）和先验调制流（PMF），将特征方向与空间位置解耦，沿目标内在几何动态门控上下文聚合。还包含分层空间调节器（HSR）进行多尺度语义对齐，以及高保真聚焦单元（HFFU）最大化微弱特征的信噪比。

Result: 在多个地质基准测试（LROC-Lineament、LineaMapper、GeoCrack）上达到新的SOTA。在挑战性的LROC-Lineament数据集上，F1分数89.22%，mIoU 89.87%。仅3.4M参数和6.3G FLOPs，推理速度超过24 FPS，比重量级基线计算成本降低两个数量级。

Conclusion: Fluxamba在分割保真度和机载部署可行性之间建立了新的帕累托前沿，为地质线性特征分割提供了一种高效准确的解决方案。

Abstract: The precise segmentation of geological linear features, spanning from planetary lineaments to terrestrial fractures, demands capturing long-range dependencies across complex anisotropic topologies. Although State Space Models (SSMs) offer near-linear computational complexity, their dependence on rigid, axis-aligned scanning trajectories induces a fundamental topological mismatch with curvilinear targets, resulting in fragmented context and feature erosion. To bridge this gap, we propose Fluxamba, a lightweight architecture that introduces a topology-aware feature rectification framework. Central to our design is the Structural Flux Block (SFB), which orchestrates an anisotropic information flux by integrating an Anisotropic Structural Gate (ASG) with a Prior-Modulated Flow (PMF). This mechanism decouples feature orientation from spatial location, dynamically gating context aggregation along the target's intrinsic geometry rather than rigid paths. Furthermore, to mitigate serialization-induced noise in low-contrast environments, we incorporate a Hierarchical Spatial Regulator (HSR) for multi-scale semantic alignment and a High-Fidelity Focus Unit (HFFU) to explicitly maximize the signal-to-noise ratio of faint features. Extensive experiments on diverse geological benchmarks (LROC-Lineament, LineaMapper, and GeoCrack) demonstrate that Fluxamba establishes a new state-of-the-art. Notably, on the challenging LROC-Lineament dataset, it achieves an F1-score of 89.22% and mIoU of 89.87%. Achieving a real-time inference speed of over 24 FPS with only 3.4M parameters and 6.3G FLOPs, Fluxamba reduces computational costs by up to two orders of magnitude compared to heavy-weight baselines, thereby establishing a new Pareto frontier between segmentation fidelity and onboard deployment feasibility.

</details>


### [141] [Physical Prompt Injection Attacks on Large Vision-Language Models](https://arxiv.org/abs/2601.17383)
*Chen Ling,Kai Hu,Hangcheng Liu,Xingshuo Han,Tianwei Zhang,Changhai Ou*

Main category: cs.CV

Relevance: 75.0

TL;DR: 本文提出首个物理提示注入攻击（PPIA），这是一种黑盒、查询无关的攻击方法，通过在物理对象上嵌入恶意排版指令来攻击大型视觉语言模型，无需访问模型内部，攻击成功率高达98%。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在开放物理环境中部署时面临安全风险。现有提示注入攻击方法需要访问输入通道或了解用户查询，这在实践中很少成立。因此需要一种更实用的攻击方法来揭示LVLMs的安全漏洞。

Method: 提出物理提示注入攻击（PPIA）：1）离线选择高识别度和语义有效的视觉提示；2）基于时空注意力的环境感知策略放置，确保注入提示既可见又对模型行为有影响；3）无需访问模型、输入或内部管道，仅通过视觉观察操作。

Result: 在10个最先进的LVLMs上进行评估，涵盖视觉问答、规划和导航等任务，在模拟和真实世界设置中攻击成功率高达98%。在不同物理条件（距离、视角、光照）下表现出强鲁棒性。

Conclusion: PPIA首次展示了物理提示注入攻击的可行性，揭示了LVLMs在现实部署中的严重安全漏洞，为未来防御机制的设计提供了重要启示。

Abstract: Large Vision-Language Models (LVLMs) are increasingly deployed in real-world intelligent systems for perception and reasoning in open physical environments. While LVLMs are known to be vulnerable to prompt injection attacks, existing methods either require access to input channels or depend on knowledge of user queries, assumptions that rarely hold in practical deployments. We propose the first Physical Prompt Injection Attack (PPIA), a black-box, query-agnostic attack that embeds malicious typographic instructions into physical objects perceivable by the LVLM. PPIA requires no access to the model, its inputs, or internal pipeline, and operates solely through visual observation. It combines offline selection of highly recognizable and semantically effective visual prompts with strategic environment-aware placement guided by spatiotemporal attention, ensuring that the injected prompts are both perceivable and influential on model behavior. We evaluate PPIA across 10 state-of-the-art LVLMs in both simulated and real-world settings on tasks including visual question answering, planning, and navigation, PPIA achieves attack success rates up to 98%, with strong robustness under varying physical conditions such as distance, viewpoint, and illumination. Our code is publicly available at https://github.com/2023cghacker/Physical-Prompt-Injection-Attack.

</details>


### [142] [Will It Zero-Shot?: Will It Zero-Shot?: Predicting Zero-Shot Classification Performance For Arbitrary Queries](https://arxiv.org/abs/2601.17535)
*Kevin Robbins,Xiaotong Liu,Yu Wu,Le Sun,Grady McPeak,Abby Stylianou,Robert Pless*

Main category: cs.CV

Relevance: 75.0

TL;DR: 本文提出了一种通过生成合成图像来评估视觉语言模型（VLM）在特定任务上零样本准确率的方法，相比仅使用文本的方法，该方法能更准确地预测模型性能，并为用户提供用于评估的图像反馈。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（如CLIP）虽然能让用户通过简单命名类别来构建视觉分类器，但模型在不同领域的表现差异很大，非专家用户难以评估所选VLM是否适用于他们的具体问题。现有方法主要依赖文本比较来评估模型性能，但缺乏直观的评估手段。

Method: 在先前仅使用文本比较评估模型性能的基础上，探索了生成与任务相关的合成图像的方法。通过生成图像来评估和优化零样本准确率的预测，相比基线文本方法，图像生成能显著提高预测质量，并为用户提供用于评估的图像反馈。

Result: 在标准CLIP基准数据集上的实验表明，基于图像的方法能帮助用户在没有任何标注样本的情况下，预测VLM是否适用于他们的应用。生成的图像显著提升了零样本准确率预测的质量。

Conclusion: 通过生成合成图像来评估VLM性能的方法比纯文本方法更有效，能为用户提供更准确的性能预测和直观的图像反馈，帮助非专家用户更好地评估模型适用性。

Abstract: Vision-Language Models like CLIP create aligned embedding spaces for text and images, making it possible for anyone to build a visual classifier by simply naming the classes they want to distinguish. However, a model that works well in one domain may fail in another, and non-expert users have no straightforward way to assess whether their chosen VLM will work on their problem. We build on prior work using text-only comparisons to evaluate how well a model works for a given natural language task, and explore approaches that also generate synthetic images relevant to that task to evaluate and refine the prediction of zero-shot accuracy. We show that generated imagery to the baseline text-only scores substantially improves the quality of these predictions. Additionally, it gives a user feedback on the kinds of images that were used to make the assessment. Experiments on standard CLIP benchmark datasets demonstrate that the image-based approach helps users predict, without any labeled examples, whether a VLM will be effective for their application.

</details>


### [143] [SPACE-CLIP: Spatial Perception via Adaptive CLIP Embeddings for Monocular Depth Estimation](https://arxiv.org/abs/2601.17657)
*Taewan Cho,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.CV

Relevance: 75.0

TL;DR: SPACE-CLIP提出了一种双路径解码器架构，直接从冻结的CLIP视觉编码器中提取几何知识，无需文本编码器或文本提示，显著提升了深度估计性能。


<details>
  <summary>Details</summary>
Motivation: CLIP在语义理解方面表现出色，但缺乏几何结构感知能力。现有方法通过文本提示查询CLIP，这种方式间接且低效。需要一种能够直接从CLIP视觉编码器中提取几何知识的方法。

Method: 提出双路径解码器架构：1) 语义路径解释高级特征，使用FiLM进行全局上下文动态调节；2) 结构路径从早期层提取细粒度空间细节。两条路径通过层次融合实现语义上下文和精确几何的鲁棒合成。

Result: 在KITTI基准测试中，SPACE-CLIP显著优于之前的CLIP基方法。消融研究验证了双路径协同融合对成功的关键作用。

Conclusion: SPACE-CLIP为重新利用大规模视觉模型提供了高效、架构优雅的蓝图，不仅是一个独立的深度估计器，更是下一代具身AI系统（如VLA模型）的可集成空间感知模块。

Abstract: Contrastive Language-Image Pre-training (CLIP) has accomplished extraordinary success for semantic understanding but inherently struggles to perceive geometric structure. Existing methods attempt to bridge this gap by querying CLIP with textual prompts, a process that is often indirect and inefficient. This paper introduces a fundamentally different approach using a dual-pathway decoder. We present SPACE-CLIP, an architecture that unlocks and interprets latent geometric knowledge directly from a frozen CLIP vision encoder, completely bypassing the text encoder and its associated textual prompts. A semantic pathway interprets high-level features, dynamically conditioned on global context using feature-wise linear modulation (FiLM). In addition, a structural pathway extracts fine-grained spatial details from early layers. These complementary streams are hierarchically fused, enabling a robust synthesis of semantic context and precise geometry. Extensive experiments on the KITTI benchmark show that SPACE-CLIP dramatically outperforms previous CLIP-based methods. Our ablation studies validate that the synergistic fusion of our dual pathways is critical to this success. SPACE-CLIP offers a new, efficient, and architecturally elegant blueprint for repurposing large-scale vision models. The proposed method is not just a standalone depth estimator, but a readily integrable spatial perception module for the next generation of embodied AI systems, such as vision-language-action (VLA) models. Our model is available at https://github.com/taewan2002/space-clip

</details>


### [144] [ViTCoP: Accelerating Large Vision-Language Models via Visual and Textual Semantic Collaborative Pruning](https://arxiv.org/abs/2601.17818)
*Wen Luo,Peng Chen,Xiaotao Huang,LiQun Huang*

Main category: cs.CV

Relevance: 75.0

TL;DR: ViTCoP：视觉与文本语义协同剪枝框架，通过视觉编码器冗余过滤和基于LLM层次特性的逐步协同剪枝，高效保留关键且信息多样的视觉token，显著降低LVLM计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）存在视觉token显著冗余问题，导致高计算成本。现有剪枝方法存在局限性：要么在视觉编码器中过早丢失关键信息，要么在LLM中导致选定token间的信息冗余。

Method: 提出视觉与文本语义协同剪枝框架（ViTCoP）：1）在视觉编码器中进行冗余过滤；2）基于LLM层次特性在LLM内部进行逐步协同剪枝；3）引入K向量L2范数作为token显著性度量，确保与FlashAttention等加速技术的兼容性。

Result: 在多种大型视觉语言模型上的实验表明，ViTCoP在图像和视频理解任务上超越现有方法达到SOTA性能，同时显著降低模型推理延迟和GPU内存消耗。在极端剪枝率下，其性能优势更加明显。

Conclusion: ViTCoP通过视觉与文本语义协同剪枝，有效解决了LVLM视觉token冗余问题，在保持性能的同时显著提升计算效率，特别适用于高剪枝率场景。

Abstract: Large Vision-Language Models (LVLMs) incur high computational costs due to significant redundancy in their visual tokens. To effectively reduce this cost, researchers have proposed various visual token pruning methods. However, existing methods are generally limited, either losing critical visual information prematurely due to pruning in the vision encoder, or leading to information redundancy among the selected tokens due to pruning in the Large Language Models (LLMs). To address these challenges, we propose a Visual and Textual Semantic Collaborative Pruning framework (ViTCoP) that combines redundancy filtering in the vision encoder with step-wise co-pruning within the LLM based on its hierarchical characteristics, to efficiently preserve critical and informationally diverse visual tokens. Meanwhile, to ensure compatibility with acceleration techniques like FlashAttention, we introduce the L2 norm of K-vectors as the token saliency metric in the LLM. Extensive experiments on various Large Vision-Language Models demonstrate that ViTCoP not only achieves state-of-the-art performance surpassing existing methods on both image and video understanding tasks, but also significantly reduces model inference latency and GPU memory consumption. Notably, its performance advantage over other methods becomes even more pronounced under extreme pruning rates.

</details>


### [145] [VAE-REPA: Variational Autoencoder Representation Alignment for Efficient Diffusion Training](https://arxiv.org/abs/2601.17830)
*Mengmeng Wang,Dengyang Jiang,Liuzhuozheng Li,Yucheng Lin,Guojiang Shen,Xiangjie Kong,Yong Liu,Guang Dai,Jingdong Wang*

Main category: cs.CV

Relevance: 75.0

TL;DR: 本文提出了一种轻量级的内在引导框架，利用预训练VAE特征加速扩散Transformer训练，无需外部依赖，仅增加4%计算开销。


<details>
  <summary>Details</summary>
Motivation: 基于去噪的扩散Transformer虽然生成性能强，但训练收敛效率低。现有方法如REPA（依赖外部表示编码器）或SRA（需要双模型设置）都会带来沉重的计算开销。需要一种轻量级的内在引导框架来高效加速扩散训练。

Method: 提出一个轻量级内在引导框架，利用现成的预训练变分自编码器（VAE）特征：其重建特性确保了对视觉先验（如丰富纹理细节、结构模式和基本语义信息）的内在编码。具体通过轻量级投影层将扩散Transformer的中间潜在特征与VAE特征对齐，并通过特征对齐损失进行监督。

Result: 实验表明，该方法相比原始扩散Transformer提高了生成质量和训练收敛速度，匹配或优于最先进的加速方法，仅增加4%的GFLOPs计算开销，且无需外部引导模型的额外成本。

Conclusion: 该方法提供了一种简单有效的管道，通过内在特征对齐加速扩散Transformer训练，避免了外部依赖和双模型维护的复杂性，在计算效率和生成质量之间取得了良好平衡。

Abstract: Denoising-based diffusion transformers, despite their strong generation performance, suffer from inefficient training convergence. Existing methods addressing this issue, such as REPA (relying on external representation encoders) or SRA (requiring dual-model setups), inevitably incur heavy computational overhead during training due to external dependencies. To tackle these challenges, this paper proposes \textbf{\namex}, a lightweight intrinsic guidance framework for efficient diffusion training. \name leverages off-the-shelf pre-trained Variational Autoencoder (VAE) features: their reconstruction property ensures inherent encoding of visual priors like rich texture details, structural patterns, and basic semantic information. Specifically, \name aligns the intermediate latent features of diffusion transformers with VAE features via a lightweight projection layer, supervised by a feature alignment loss. This design accelerates training without extra representation encoders or dual-model maintenance, resulting in a simple yet effective pipeline. Extensive experiments demonstrate that \name improves both generation quality and training convergence speed compared to vanilla diffusion transformers, matches or outperforms state-of-the-art acceleration methods, and incurs merely 4\% extra GFLOPs with zero additional cost for external guidance models.

</details>


### [146] [Agentic Very Long Video Understanding](https://arxiv.org/abs/2601.18157)
*Aniket Rege,Arka Sadhu,Yuliang Li,Kejie Li,Ramya Korlakai Vinayak,Yuning Chai,Yong Jae Lee,Hyo Jin Kim*

Main category: cs.CV

Relevance: 75.0

TL;DR: EGAgent：基于实体场景图的增强型智能体框架，用于全天候可穿戴设备的长时程第一人称视频理解，通过结构化搜索和跨模态推理实现多日甚至数周的连续视频分析。


<details>
  <summary>Details</summary>
Motivation: 全天候个人AI助手需要超越短期孤立事件的连续纵向视频理解能力，现有方法受限于有限上下文窗口，缺乏对超长视频流进行组合式多跳推理的能力。

Method: EGAgent框架以实体场景图为中心，表示人物、地点、物体及其随时间的关系。系统为规划智能体提供结构化搜索和推理工具，以及混合视觉和音频搜索能力，实现跨模态和时间连贯的推理。

Result: 在EgoLifeQA数据集上达到SOTA性能（57.5%），在Video-MME（Long）数据集上获得有竞争力的性能（74.1%），用于复杂的长时程视频理解任务。

Conclusion: EGAgent通过实体场景图和智能体工具使用，有效解决了长时程第一人称视频理解的挑战，为全天候AI助手提供了实用的解决方案。

Abstract: The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.

</details>


### [147] [Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval](https://arxiv.org/abs/2601.18190)
*Yifan Li,Shiying Wang,Jianqiang Huang*

Main category: cs.CV

Relevance: 75.0

TL;DR: MPS-CLIP：一种参数高效的遥感图像-文本检索框架，通过LLM提取关键词指导SAM生成语义子视角，使用G^2A适配器和MPR模块实现细粒度对齐，在RSICD和RSITMD基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLP模型（如CLIP）在遥感图像-文本检索中主要依赖粗粒度全局对齐，忽略了遥感图像密集、多尺度的语义特征。同时，全微调这些大模型计算成本高且容易导致灾难性遗忘。

Method: 1) 使用LLM提取核心语义关键词，指导Segment Anything Model生成语义相关的子视角；2) 引入Gated Global Attention适配器高效适应冻结的骨干网络；3) 设计Multi-Perspective Representation模块聚合局部线索；4) 采用多视角对比损失和加权三元组损失的混合目标函数。

Result: 在RSICD和RSITMD基准测试中分别达到35.18%和48.40%的平均召回率，显著优于全微调基线和近期竞争方法。

Conclusion: MPS-CLIP成功将检索范式从全局匹配转向关键词引导的细粒度对齐，以参数高效的方式实现了遥感图像-文本检索的SOTA性能。

Abstract: Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP.

</details>


### [148] [V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering](https://arxiv.org/abs/2601.18240)
*Mengyuan Jin,Zehui Liao,Yong Xia*

Main category: cs.CV

Relevance: 75.0

TL;DR: V-Loop：一种用于医学视觉问答中幻觉检测的无训练即插即用框架，通过双向推理形成视觉逻辑循环来验证事实正确性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在医学视觉问答中表现出色，但其输出容易产生幻觉（与视觉事实矛盾），这在高风险医疗场景中存在重大风险。现有不确定性检测方法虽然计算高效，但本质上是间接的，因为它们估计图像-问题对的预测不确定性，而不是验证特定答案的事实正确性。

Method: 提出视觉逻辑循环验证（V-Loop）框架：1）从主QA对中提取语义单元；2）基于答案单元生成验证问题来重新查询问题单元；3）强制视觉注意力一致性，确保主问题和验证问题都依赖相同的图像证据；4）如果验证答案与预期语义内容匹配，逻辑循环闭合，表示事实基础；否则标记为幻觉。

Result: 在多个医学VQA基准测试和MLLM上的实验表明，V-Loop始终优于现有内省方法，保持高效性，并且与不确定性方法结合使用时能进一步提升性能。

Conclusion: V-Loop提供了一种直接验证事实正确性的有效方法，解决了医学VQA中幻觉检测的关键问题，为高风险医疗应用提供了更可靠的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.

</details>


### [149] [ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks](https://arxiv.org/abs/2601.18386)
*Gabriel Lee Jun Rong,Christos Korgialas,Dion Jia Xu Ho,Pai Chet Ng,Xiaoxiao Miao,Konstantinos N. Plataniotis*

Main category: cs.CV

Relevance: 75.0

TL;DR: ARMOR框架利用VLM和LLM智能编排三种对抗攻击方法，通过实时闭环系统自适应调整攻击策略，针对图像语义漏洞生成混合扰动，提升跨架构迁移性和攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有自动化攻击套件采用静态集成和固定序列，缺乏战略适应性和语义感知能力。需要开发能够动态调整攻击策略、理解图像语义漏洞的智能攻击框架。

Method: ARMOR框架通过VLM引导的代理协同编排三种对抗攻击原语（CW、JSMA、STA），使用共享的"Mixing Desk"生成和合成扰动。LLM实时自适应调整和重新参数化并行攻击代理，形成闭环系统，利用图像特定语义漏洞。

Result: 在标准基准测试中，ARMOR实现了改进的跨架构迁移性，可靠地欺骗黑盒和白盒设置。为黑盒目标提供混合输出，为白盒目标使用置信度和SSIM评分选择最佳攻击或混合攻击。

Conclusion: ARMOR框架通过智能代理协同和LLM引导的自适应调整，克服了传统静态攻击套件的局限性，实现了更有效的对抗攻击生成和跨模型迁移。

Abstract: Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score.

</details>


### [150] [Data-Efficient Meningioma Segmentation via Implicit Spatiotemporal Mixing and Sim2Real Semantic Injection](https://arxiv.org/abs/2601.17031)
*Yunhao Xu,Fuquan Zong,Yexuan Xing,Chulong Zhang,Guang Yang,Shilong Yang,Xiaokun Liang,Juan Yu*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出一种用于医学图像分割的双增强框架，结合空间流形扩展和语义对象注入，通过隐式神经表示建模连续速度场，以及Sim2Real病灶注入模块，在有限标注数据下提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割性能越来越取决于数据利用效率而非原始数据量。对于复杂病理（如脑膜瘤），模型需要充分利用有限高质量标注中的潜在信息。为了最大化现有数据集的价值，需要开发更高效的数据增强方法。

Method: 1. 空间流形扩展：使用隐式神经表示（INR）建模连续速度场，在变形空间中进行线性混合，从少量锚点高效生成解剖学上合理的结构变化
2. 语义对象注入：Sim2Real病灶注入模块，将病灶纹理移植到健康解剖背景中构建高保真模拟域，弥合合成增强与真实病理之间的差距

Result: 在混合数据集上的综合实验表明，该框架显著提升了nnU-Net和U-Mamba等最先进模型的数据效率和鲁棒性，为有限标注预算下的高性能医学图像分析提供了有效策略。

Conclusion: 提出的双增强框架通过空间流形扩展和语义对象注入的协同整合，能够从有限高质量标注中充分挖掘潜在信息，为医学图像分割提供了一种高效的数据增强解决方案。

Abstract: The performance of medical image segmentation is increasingly defined by the efficiency of data utilization rather than merely the volume of raw data. Accurate segmentation, particularly for complex pathologies like meningiomas, demands that models fully exploit the latent information within limited high-quality annotations. To maximize the value of existing datasets, we propose a novel dual-augmentation framework that synergistically integrates spatial manifold expansion and semantic object injection. Specifically, we leverage Implicit Neural Representations (INR) to model continuous velocity fields. Unlike previous methods, we perform linear mixing on the integrated deformation fields, enabling the efficient generation of anatomically plausible variations by interpolating within the deformation space. This approach allows for the extensive exploration of structural diversity from a small set of anchors. Furthermore, we introduce a Sim2Real lesion injection module. This module constructs a high-fidelity simulation domain by transplanting lesion textures into healthy anatomical backgrounds, effectively bridging the gap between synthetic augmentation and real-world pathology. Comprehensive experiments on a hybrid dataset demonstrate that our framework significantly enhances the data efficiency and robustness of state-of-the-art models, including nnU-Net and U-Mamba, offering a potent strategy for high-performance medical image analysis with limited annotation budgets.

</details>


### [151] [StealthMark: Harmless and Stealthy Ownership Verification for Medical Segmentation via Uncertainty-Guided Backdoors](https://arxiv.org/abs/2601.17107)
*Qinkai Yu,Chong Zhang,Gaojie Jin,Tianjin Huang,Wei Zhou,Wenhui Li,Xiaobo Jin,Bo Huang,Yitian Zhao,Guang Yang,Gregory Y. H. Lip,Yalin Zheng,Aline Villavicencio,Yanda Meng*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出StealthMark方法，用于医疗分割模型的黑盒所有权验证，通过微调模型不确定性而不改变分割输出，利用解释方法提取特征归因，在触发条件下显示可验证的QR码水印。


<details>
  <summary>Details</summary>
Motivation: 医疗数据标注成本高且受隐私限制，训练好的医疗分割模型构成重要知识产权。现有模型保护技术主要关注分类和生成任务，医疗分割模型保护研究不足，需要有效的所有权验证方法。

Method: 1) 通过微调模型不确定性而不改变最终分割输出，保持模型性能；2) 使用模型无关解释方法（如LIME）从模型输出中提取特征归因；3) 在特定触发条件下，这些解释显示可验证的QR码水印；4) 支持黑盒条件下的所有权验证。

Result: 在4个医疗影像数据集和5个主流分割模型上实验，StealthMark在保持原始模型性能的同时有效验证所有权。应用于SAM模型时，ASR超过95%，Dice和AUC分数下降小于1%，显著优于基于后门的水印方法。

Conclusion: StealthMark为医疗分割模型提供了一种有效、隐蔽且无害的所有权验证方法，具有实际部署潜力，填补了医疗分割模型保护的研究空白。

Abstract: Annotating medical data for training AI models is often costly and limited due to the shortage of specialists with relevant clinical expertise. This challenge is further compounded by privacy and ethical concerns associated with sensitive patient information. As a result, well-trained medical segmentation models on private datasets constitute valuable intellectual property requiring robust protection mechanisms. Existing model protection techniques primarily focus on classification and generative tasks, while segmentation models-crucial to medical image analysis-remain largely underexplored. In this paper, we propose a novel, stealthy, and harmless method, StealthMark, for verifying the ownership of medical segmentation models under black-box conditions. Our approach subtly modulates model uncertainty without altering the final segmentation outputs, thereby preserving the model's performance. To enable ownership verification, we incorporate model-agnostic explanation methods, e.g. LIME, to extract feature attributions from the model outputs. Under specific triggering conditions, these explanations reveal a distinct and verifiable watermark. We further design the watermark as a QR code to facilitate robust and recognizable ownership claims. We conducted extensive experiments across four medical imaging datasets and five mainstream segmentation models. The results demonstrate the effectiveness, stealthiness, and harmlessness of our method on the original model's segmentation performance. For example, when applied to the SAM model, StealthMark consistently achieved ASR above 95% across various datasets while maintaining less than a 1% drop in Dice and AUC scores, significantly outperforming backdoor-based watermarking methods and highlighting its strong potential for practical deployment. Our implementation code is made available at: https://github.com/Qinkaiyu/StealthMark.

</details>


### [152] [iFSQ: Improving FSQ for Image Generation with 1 Line of Code](https://arxiv.org/abs/2601.17124)
*Bin Lin,Zongjian Li,Yuwei Niu,Kaixiong Gong,Yunyang Ge,Yunlong Lin,Mingzhe Zheng,JianWei Zhang,Miles Yang,Zhao Zhong,Liefeng Bo,Li Yuan*

Main category: cs.CV

Relevance: 65.0

TL;DR: iFSQ通过分布匹配映射解决FSQ激活崩溃问题，在4比特维度实现离散与连续表示的最优平衡，发现AR模型收敛快但扩散模型性能上限更高


<details>
  <summary>Details</summary>
Motivation: 图像生成领域存在自回归模型（离散token）和扩散模型（连续潜在空间）的分裂，这种分裂源于VQ-VAE和VAE的区别，阻碍了统一建模和公平基准测试。FSQ提供了理论桥梁，但存在激活崩溃问题，需要在重建保真度和信息效率之间权衡。

Method: 提出iFSQ，将原始FSQ中的激活函数替换为分布匹配映射，强制均匀先验分布。这一简单策略只需一行代码，但数学上保证了最优的bin利用率和重建精度。使用iFSQ作为受控基准进行分析，并将REPA（表示对齐）适配到AR模型中，得到LlamaGen-REPA。

Result: 发现两个关键见解：1）离散和连续表示之间的最优平衡点约为每维度4比特；2）在相同重建约束下，AR模型初始收敛快，但扩散模型能达到更高的性能上限，表明严格的顺序排序可能限制生成质量的上限。

Conclusion: iFSQ通过简单的分布匹配映射解决了FSQ的激活崩溃问题，为图像生成提供了统一的基准测试框架。研究揭示了离散和连续表示之间的最优平衡点，并表明AR模型和扩散模型各有优势，为未来的模型设计提供了指导。

Abstract: The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ

</details>


### [153] [FineVAU: A Novel Human-Aligned Benchmark for Fine-Grained Video Anomaly Understanding](https://arxiv.org/abs/2601.17258)
*João Pereira,Vasco Lopes,João Neves,David Semedo*

Main category: cs.CV

Relevance: 65.0

TL;DR: FineVAU是一个用于视频异常理解（VAU）的新基准，提出了FVScore评估指标和FineW3数据集，专注于异常事件的细粒度视觉元素评估，揭示了LVLM在时空理解上的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前视频异常理解评估存在两大问题：1）基于n-gram的指标（如BLEU、ROUGE-L）无法捕捉LVLM响应的丰富、自由形式和视觉基础特性；2）基于LLM的评估侧重于语言质量而非事实相关性，导致主观判断与人类感知不一致。需要一个新的基准来关注细粒度、领域特定的异常视频理解。

Method: 将VAU定义为三方面问题：事件（What）、参与实体（Who）和位置（Where）。提出FineVAU基准，包括：1）FVScore评估指标，通过评估LVLM回答中关键视觉元素的存在来提供可解释的细粒度反馈；2）FineW3数据集，通过结构化全自动流程增强现有人工标注，添加高质量细粒度视觉信息。

Result: 人类评估显示，提出的FVScore指标在异常感知方面与人类判断有更好的对齐性。详细实验揭示了LVLM的关键局限性：尽管在粗粒度、静态信息和具有强视觉线索的事件上表现良好，但在需要空间和细粒度时间理解的异常事件感知方面存在不足。

Conclusion: FineVAU为视频异常理解提供了更全面、细粒度的评估框架，揭示了当前LVLM在时空理解方面的不足，为未来模型改进指明了方向。该基准推动了从语言质量评估向视觉事实相关性评估的转变。

Abstract: Video Anomaly Understanding (VAU) is a novel task focused on describing unusual occurrences in videos. Despite growing interest, the evaluation of VAU remains an open challenge. Existing benchmarks rely on n-gram-based metrics (e.g., BLEU, ROUGE-L) or LLM-based evaluation. The first fails to capture the rich, free-form, and visually grounded nature of LVLM responses, while the latter focuses on assessing language quality over factual relevance, often resulting in subjective judgments that are misaligned with human perception. In this work, we address this issue by proposing FineVAU, a new benchmark for VAU that shifts the focus towards rich, fine-grained and domain-specific understanding of anomalous videos. We formulate VAU as a three-fold problem, with the goal of comprehensively understanding key descriptive elements of anomalies in video: events (What), participating entities (Who) and location (Where). Our benchmark introduces a) FVScore, a novel, human-aligned evaluation metric that assesses the presence of critical visual elements in LVLM answers, providing interpretable, fine-grained feedback; and b) FineW3, a novel, comprehensive dataset curated through a structured and fully automatic procedure that augments existing human annotations with high quality, fine-grained visual information. Human evaluation reveals that our proposed metric has a superior alignment with human perception of anomalies in comparison to current approaches. Detailed experiments on FineVAU unveil critical limitations in LVLM's ability to perceive anomalous events that require spatial and fine-grained temporal understanding, despite strong performance on coarse grain, static information, and events with strong visual cues.

</details>


### [154] [SkyReels-V3 Technique Report](https://arxiv.org/abs/2601.17323)
*Debang Li,Zhengcong Fei,Tuanhui Li,Yikun Dou,Zheng Chen,Jiangping Yang,Mingyuan Fan,Jingtao Xu,Jiahua Wang,Baoxuan Gu,Mingshan Chang,Yuqiang Xie,Binjie Mao,Youqiang Zhang,Nuo Pang,Hao Zhang,Yuzhe Jin,Zhiheng Xu,Dixuan Lin,Guibin Chen,Yahui Zhou*

Main category: cs.CV

Relevance: 65.0

TL;DR: SkyReels-V3是一个基于扩散Transformer的多模态上下文学习框架的条件视频生成模型，支持三种生成范式：参考图像到视频合成、视频扩展和音频引导视频生成。


<details>
  <summary>Details</summary>
Motivation: 视频生成是构建世界模型的基础，多模态上下文推理是能力的关键测试。作者旨在开发一个统一的框架，支持多种视频生成任务，包括参考图像到视频、视频扩展和音频引导生成。

Method: 基于扩散Transformer的统一多模态上下文学习框架。采用跨帧配对、图像编辑和语义重写的数据处理流程来减少复制粘贴伪影。训练时使用图像-视频混合策略和多分辨率联合优化。视频扩展模型结合时空一致性建模和大规模视频理解。说话头像模型训练首尾帧插入模式并重构关键帧推理范式。

Result: 在视觉质量、指令跟随和特定方面指标上达到或接近最先进水平，接近领先的闭源系统。

Conclusion: SkyReels-V3展示了在单一架构中支持多种视频生成任务的能力，通过创新的数据处理和训练策略实现了高质量的视频生成。

Abstract: Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.
  Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.

</details>


### [155] [CoT-Seg: Rethinking Segmentation with Chain-of-Thought Reasoning and Self-Correction](https://arxiv.org/abs/2601.17420)
*Shiu-hong Kao,Chak Ho Huang,Huaiqian Liu,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.CV

Relevance: 65.0

TL;DR: CoT-Seg：无需训练的推理分割框架，结合思维链推理与自我修正，利用预训练MLLMs分解查询、提取语义、识别目标，并通过自我评估迭代优化分割结果


<details>
  <summary>Details</summary>
Motivation: 现有推理分割方法在处理复杂查询和域外图像时表现不足。受思维链推理启发（更难问题需要更多思考步骤），本文旨在探索一个能像人类处理难题一样逐步思考、查找信息、生成结果、自我评估并优化的系统

Method: 提出CoT-Seg训练免费框架：1) 利用预训练MLLMs（GPT-4o）分解查询为元指令；2) 从图像提取细粒度语义；3) 识别隐含或复杂提示下的目标对象；4) 自我修正阶段：评估分割结果与原始查询/推理轨迹的匹配度，识别不匹配并迭代优化掩码；5) 可集成检索增强推理以访问外部知识

Result: 1) 显著提升推理分割的可靠性和鲁棒性，特别是在模糊或易出错场景；2) 引入新数据集ReasonSeg-Hard展示处理挑战性案例的能力；3) 思维链推理与自我修正的结合为视觉语言集成驱动的分割提供了强大范式

Conclusion: 结合思维链推理和自我修正的CoT-Seg框架为视觉语言集成驱动的分割提供了有效解决方案，无需训练即可处理复杂推理分割任务，显著提升了在挑战性场景下的性能

Abstract: Existing works of reasoning segmentation often fall short in complex cases, particularly when addressing complicated queries and out-of-domain images. Inspired by the chain-of-thought reasoning, where harder problems require longer thinking steps/time, this paper aims to explore a system that can think step-by-step, look up information if needed, generate results, self-evaluate its own results, and refine the results, in the same way humans approach harder questions. We introduce CoT-Seg, a training-free framework that rethinks reasoning segmentation by combining chain-of-thought reasoning with self-correction. Instead of fine-tuning, CoT-Seg leverages the inherent reasoning ability of pre-trained MLLMs (GPT-4o) to decompose queries into meta-instructions, extract fine-grained semantics from images, and identify target objects even under implicit or complex prompts. Moreover, CoT-Seg incorporates a self-correction stage: the model evaluates its own segmentation against the original query and reasoning trace, identifies mismatches, and iteratively refines the mask. This tight integration of reasoning and correction significantly improves reliability and robustness, especially in ambiguous or error-prone cases. Furthermore, our CoT-Seg framework allows easy incorporation of retrieval-augmented reasoning, enabling the system to access external knowledge when the input lacks sufficient information. To showcase CoT-Seg's ability to handle very challenging cases ,we introduce a new dataset ReasonSeg-Hard. Our results highlight that combining chain-of-thought reasoning, self-correction, offers a powerful paradigm for vision-language integration driven segmentation.

</details>


### [156] [BMDS-Net: A Bayesian Multi-Modal Deep Supervision Network for Robust Brain Tumor Segmentation](https://arxiv.org/abs/2601.17504)
*Yan Zhou,Zhen Huang,Yingqiu Li,Yue Ouyang,Suncheng Xiang,Zehua Wang*

Main category: cs.CV

Relevance: 65.0

TL;DR: BMDS-Net：一种针对多模态MRI脑肿瘤分割的鲁棒可信框架，通过零初始化多模态融合、残差门控解码器监督和贝叶斯微调，解决缺失模态敏感性和置信度校准问题。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型（如Swin UNETR）在脑肿瘤分割中虽然基准性能优秀，但存在两个关键临床问题：对缺失模态敏感（临床常见）和缺乏置信度校准。单纯追求Dice分数无法满足真实医疗部署的安全要求。

Method: 1）构建鲁棒确定性主干：集成零初始化多模态上下文融合模块和残差门控深度解码器监督机制，实现稳定特征学习和精确边界划分；2）引入内存高效的贝叶斯微调策略，将网络转换为概率预测器，提供体素级不确定性图谱；3）在BraTS 2021数据集上进行全面实验验证。

Result: BMDS-Net不仅保持竞争力精度，更重要的是在缺失模态场景下表现出卓越稳定性，而基线模型在此情况下会失败。显著减少了Hausdorff距离，并提供不确定性图谱供临床医生参考。

Conclusion: 该工作提出了一个优先考虑临床鲁棒性和可信度的统一框架，超越简单的指标最大化，为医学影像分割的实际临床部署提供了更安全可靠的解决方案。

Abstract: Accurate brain tumor segmentation from multi-modal magnetic resonance imaging (MRI) is a prerequisite for precise radiotherapy planning and surgical navigation. While recent Transformer-based models such as Swin UNETR have achieved impressive benchmark performance, their clinical utility is often compromised by two critical issues: sensitivity to missing modalities (common in clinical practice) and a lack of confidence calibration. Merely chasing higher Dice scores on idealized data fails to meet the safety requirements of real-world medical deployment. In this work, we propose BMDS-Net, a unified framework that prioritizes clinical robustness and trustworthiness over simple metric maximization. Our contribution is three-fold. First, we construct a robust deterministic backbone by integrating a Zero-Init Multimodal Contextual Fusion (MMCF) module and a Residual-Gated Deep Decoder Supervision (DDS) mechanism, enabling stable feature learning and precise boundary delineation with significantly reduced Hausdorff Distance, even under modality corruption. Second, and most importantly, we introduce a memory-efficient Bayesian fine-tuning strategy that transforms the network into a probabilistic predictor, providing voxel-wise uncertainty maps to highlight potential errors for clinicians. Third, comprehensive experiments on the BraTS 2021 dataset demonstrate that BMDS-Net not only maintains competitive accuracy but, more importantly, exhibits superior stability in missing-modality scenarios where baseline models fail. The source code is publicly available at https://github.com/RyanZhou168/BMDS-Net.

</details>


### [157] [Uni-RS: A Spatially Faithful Unified Understanding and Generation Model for Remote Sensing](https://arxiv.org/abs/2601.17673)
*Weiyu Zhang,Yuan Hu,Yong Li,Yu Liu*

Main category: cs.CV

Relevance: 65.0

TL;DR: Uni-RS是首个针对遥感领域的统一多模态模型，专门解决遥感图像理解与生成之间的空间不对称问题，通过空间布局规划、空间感知查询监督和图像-描述空间布局变化等方法，显著提升文本到图像生成的空间忠实度。


<details>
  <summary>Details</summary>
Motivation: 现有遥感多模态模型存在明显的"空间反转诅咒"：虽然能准确识别和描述图像中物体的位置，但在文本到图像生成时却无法忠实执行相同的空间关系，而这些空间关系是遥感图像的核心语义信息。

Method: 1) 显式空间布局规划：将文本指令转换为空间布局计划，解耦几何规划与视觉合成；2) 空间感知查询监督：使可学习查询偏向于指令中明确指定的空间关系；3) 图像-描述空间布局变化：让模型接触系统性的几何一致空间变换。

Result: 在多个基准测试上的广泛实验表明，该方法显著提升了文本到图像生成的空间忠实度，同时在图像描述、视觉定位和VQA等多模态理解任务上保持了强大的性能。

Conclusion: Uni-RS通过显式处理空间不对称问题，成功解决了遥感多模态模型中的"空间反转诅咒"，为遥感领域的统一多模态建模提供了有效解决方案。

Abstract: Unified remote sensing multimodal models exhibit a pronounced spatial reversal curse: Although they can accurately recognize and describe object locations in images, they often fail to faithfully execute the same spatial relations during text-to-image generation, where such relations constitute core semantic information in remote sensing. Motivated by this observation, we propose Uni-RS, the first unified multimodal model tailored for remote sensing, to explicitly address the spatial asymmetry between understanding and generation. Specifically, we first introduce explicit Spatial-Layout Planning to transform textual instructions into spatial layout plans, decoupling geometric planning from visual synthesis. We then impose Spatial-Aware Query Supervision to bias learnable queries toward spatial relations explicitly specified in the instruction. Finally, we develop Image-Caption Spatial Layout Variation to expose the model to systematic geometry-consistent spatial transformations. Extensive experiments across multiple benchmarks show that our approach substantially improves spatial faithfulness in text-to-image generation, while maintaining strong performance on multimodal understanding tasks like image captioning, visual grounding, and VQA tasks.

</details>


### [158] [StyleDecoupler: Generalizable Artistic Style Disentanglement](https://arxiv.org/abs/2601.17697)
*Zexi Jia,Jinchao Zhang,Jie Zhou*

Main category: cs.CV

Relevance: 65.0

TL;DR: StyleDecoupler是一个信息论框架，通过利用单模态模型作为内容参考，从多模态视觉模型中解耦艺术风格特征，无需微调即可在冻结的视觉语言模型上实现风格检索等应用。


<details>
  <summary>Details</summary>
Motivation: 艺术风格与语义内容深度纠缠，难以独立表示。现有方法难以有效分离风格特征，需要一种能够解耦风格与内容的方法。

Method: 提出StyleDecoupler框架，利用单模态视觉模型（专注于内容不变特征）作为内容参考，通过互信息最小化从多模态视觉语言模型的嵌入中分离出纯风格特征。该方法作为即插即用模块，无需微调冻结的视觉语言模型。

Result: 在WeART（28万艺术作品，152种风格，1556位艺术家）和WikiART基准测试中实现最先进的风格检索性能，并能支持风格关系映射和生成模型评估等应用。

Conclusion: StyleDecoupler有效解决了艺术风格与内容的解耦问题，为艺术风格分析提供了强大的工具，并发布了大规模艺术数据集WeART。

Abstract: Representing artistic style is challenging due to its deep entanglement with semantic content. We propose StyleDecoupler, an information-theoretic framework that leverages a key insight: multi-modal vision models encode both style and content, while uni-modal models suppress style to focus on content-invariant features. By using uni-modal representations as content-only references, we isolate pure style features from multi-modal embeddings through mutual information minimization. StyleDecoupler operates as a plug-and-play module on frozen Vision-Language Models without fine-tuning. We also introduce WeART, a large-scale benchmark of 280K artworks across 152 styles and 1,556 artists. Experiments show state-of-the-art performance on style retrieval across WeART and WikiART, while enabling applications like style relationship mapping and generative model evaluation. We release our method and dataset at this url.

</details>


### [159] [MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance](https://arxiv.org/abs/2601.17866)
*Yoonwoo Jeong,Cheng Sun,Yu-Chiang Frank Wang,Minsu Cho,Jaesung Choe*

Main category: cs.CV

Relevance: 65.0

TL;DR: MV-SAM：基于点图的3D一致多视角分割框架，无需3D网络或标注数据，通过将2D图像嵌入提升到3D点嵌入实现跨视角一致性分割


<details>
  <summary>Details</summary>
Motivation: 现有可提示分割模型（如SAM）扩展到视频和多视角图像时缺乏3D感知能力，导致结果不一致，需要昂贵的逐场景优化来保证3D一致性。需要一种既能保持3D一致性又无需3D网络或标注数据的解决方案。

Method: 使用点图（pointmaps）——从无位姿图像重建的3D点，利用像素-点的一一对应关系，将图像和提示提升到3D空间。扩展SAM架构：将预训练编码器的图像嵌入提升为3D点嵌入，通过transformer解码器使用交叉注意力与3D提示嵌入交互，通过3D位置嵌入隐式学习跨视角一致掩码。

Result: 在SA-1B数据集上训练，在NVOS、SPIn-NeRF、ScanNet++、uCo3D、DL3DV等多个基准测试中表现优异，超越SAM2-Video，达到与逐场景优化基线相当的性能，具有良好的跨领域泛化能力。

Conclusion: MV-SAM通过点图实现了3D一致的多视角分割，无需3D网络或标注数据，将2D交互与3D几何对齐，为多视角分割提供了高效且泛化性强的解决方案。

Abstract: Promptable segmentation has emerged as a powerful paradigm in computer vision, enabling users to guide models in parsing complex scenes with prompts such as clicks, boxes, or textual cues. Recent advances, exemplified by the Segment Anything Model (SAM), have extended this paradigm to videos and multi-view images. However, the lack of 3D awareness often leads to inconsistent results, necessitating costly per-scene optimization to enforce 3D consistency. In this work, we introduce MV-SAM, a framework for multi-view segmentation that achieves 3D consistency using pointmaps -- 3D points reconstructed from unposed images by recent visual geometry models. Leveraging the pixel-point one-to-one correspondence of pointmaps, MV-SAM lifts images and prompts into 3D space, eliminating the need for explicit 3D networks or annotated 3D data. Specifically, MV-SAM extends SAM by lifting image embeddings from its pretrained encoder into 3D point embeddings, which are decoded by a transformer using cross-attention with 3D prompt embeddings. This design aligns 2D interactions with 3D geometry, enabling the model to implicitly learn consistent masks across views through 3D positional embeddings. Trained on the SA-1B dataset, our method generalizes well across domains, outperforming SAM2-Video and achieving comparable performance with per-scene optimization baselines on NVOS, SPIn-NeRF, ScanNet++, uCo3D, and DL3DV benchmarks. Code will be released.

</details>


### [160] [PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation](https://arxiv.org/abs/2601.17885)
*Qingyu Fan,Zhaoxiang Li,Yi Lu,Wang Chen,Qiu Shen,Xiao-xiao Long,Yinghao Cai,Tao Lu,Shuo Wang,Xun Cao*

Main category: cs.CV

Relevance: 65.0

TL;DR: PEAfowl是一个用于双手操作的感知增强多视角视觉语言动作模型，通过几何感知的3D空间推理和迭代式文本感知特征读取，显著提升了在杂乱场景中的操作性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言动作模型在双手操作任务中存在两个主要问题：1) 多视角特征通过视角无关的token拼接融合，导致3D空间理解能力弱；2) 语言作为全局条件注入，导致指令定位粗糙。这些限制使得模型在遮挡、视角和场景变化下泛化能力不足。

Method: PEAfowl提出两个核心创新：1) 空间推理方面，预测每个token的深度分布，进行可微分的3D提升，并聚合局部跨视角邻居形成几何基础的跨视角一致表示；2) 指令定位方面，用Perceiver风格的文本感知读取器替代全局条件注入，在冻结的CLIP视觉特征上进行迭代证据积累。此外，通过训练专用的深度蒸馏从预训练深度教师模型监督深度分布头，为感知前端提供几何先验。

Result: 在RoboTwin 2.0的领域随机化设置下，PEAfowl比最强基线提升了23.0个百分点的成功率。真实机器人实验进一步证明了可靠的仿真到真实迁移能力，以及深度蒸馏带来的持续改进。

Conclusion: PEAfowl通过几何感知的3D空间表示和迭代式文本感知特征读取，显著提升了双手操作任务的性能，特别是在杂乱场景中的泛化能力和鲁棒性。该方法为视觉语言动作模型提供了更强大的空间理解和指令定位能力。

Abstract: Bimanual manipulation in cluttered scenes requires policies that remain stable under occlusions, viewpoint and scene variations. Existing vision-language-action models often fail to generalize because (i) multi-view features are fused via view-agnostic token concatenation, yielding weak 3D-consistent spatial understanding, and (ii) language is injected as global conditioning, resulting in coarse instruction grounding.
  In this paper, we introduce PEAfowl, a perception-enhanced multi-view VLA policy for bimanual manipulation. For spatial reasoning, PEAfowl predicts per-token depth distributions, performs differentiable 3D lifting, and aggregates local cross-view neighbors to form geometrically grounded, cross-view consistent representations. For instruction grounding, we propose to replace global conditioning with a Perceiver-style text-aware readout over frozen CLIP visual features, enabling iterative evidence accumulation. To overcome noisy and incomplete commodity depth without adding inference overhead, we apply training-only depth distillation from a pretrained depth teacher to supervise the depth-distribution head, providing perception front-end with geometry-aware priors.
  On RoboTwin 2.0 under domain-randomized setting, PEAfowl improves the strongest baseline by 23.0 pp in success rate, and real-robot experiments further demonstrate reliable sim-to-real transfer and consistent improvements from depth distillation.
  Project website: https://peafowlvla.github.io/.

</details>


### [161] [RemEdit: Efficient Diffusion Editing with Riemannian Geometry](https://arxiv.org/abs/2601.17927)
*Eashan Adhikarla,Brian D. Davison*

Main category: cs.CV

Relevance: 65.0

TL;DR: RemEdit是一个可控图像生成框架，通过黎曼流形导航和Mamba模块实现高保真编辑，同时采用任务特定注意力剪枝实现实时性能，在语义保真度和推理速度之间取得了平衡。


<details>
  <summary>Details</summary>
Motivation: 现代生成式AI中的可控图像生成面临语义保真度和推理速度之间的关键权衡。现有方法往往在这两个目标之间做出妥协，要么牺牲编辑质量以获得快速推理，要么为了高保真编辑而接受缓慢的处理速度。

Method: 1. 编辑保真度：将潜在空间视为黎曼流形，使用Mamba模块高效学习流形结构，直接计算测地线路径实现平滑语义编辑；采用双SLERP混合技术和视觉语言模型的目标感知提示增强。
2. 加速优化：引入任务特定注意力剪枝机制，轻量级剪枝头学习保留对编辑至关重要的token，避免内容无关方法常见的语义退化。

Result: RemEdit超越了先前最先进的编辑框架，在50%剪枝率下保持实时性能，为实用且强大的图像编辑建立了新基准。

Conclusion: RemEdit通过黎曼流形导航和任务特定注意力剪枝的协同创新，成功解决了可控图像生成中语义保真度与推理速度的权衡问题，实现了高质量编辑与实时性能的平衡。

Abstract: Controllable image generation is fundamental to the success of modern generative AI, yet it faces a critical trade-off between semantic fidelity and inference speed. The RemEdit diffusion-based framework addresses this trade-off with two synergistic innovations. First, for editing fidelity, we navigate the latent space as a Riemannian manifold. A mamba-based module efficiently learns the manifold's structure, enabling direct and accurate geodesic path computation for smooth semantic edits. This control is further refined by a dual-SLERP blending technique and a goal-aware prompt enrichment pass from a Vision-Language Model. Second, for additional acceleration, we introduce a novel task-specific attention pruning mechanism. A lightweight pruning head learns to retain tokens essential to the edit, enabling effective optimization without the semantic degradation common in content-agnostic approaches. RemEdit surpasses prior state-of-the-art editing frameworks while maintaining real-time performance under 50% pruning. Consequently, RemEdit establishes a new benchmark for practical and powerful image editing. Source code: https://www.github.com/eashanadhikarla/RemEdit.

</details>


### [162] [From Specialist to Generalist: Unlocking SAM's Learning Potential on Unlabeled Medical Images](https://arxiv.org/abs/2601.17934)
*Vi Vu,Thanh-Huy Nguyen,Tien-Thinh Nguyen,Ba-Thinh Lam,Hoang-Thien Nguyen,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

Relevance: 65.0

TL;DR: SC-SAM提出了一种专家-通用者双向协同训练框架，将U-Net作为专家为SAM提供点提示和伪标签，同时SAM作为通用者监督U-Net，有效利用未标记数据进行医学图像分割。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临领域偏移、标注稀缺的挑战，传统参数高效微调方法无法有效利用未标记数据。虽然U-Net在半监督医学学习中表现出色，但其辅助PEFT SAM的潜力尚未被充分探索。

Method: 提出SC-SAM框架：1) U-Net作为专家为SAM提供点提示和伪标签；2) SAM作为通用者监督U-Net；3) 双向协同训练循环使两个模型都能有效利用未标记数据。

Result: 在前列腺MRI和息肉分割基准测试中达到最先进水平，优于现有的半监督SAM变体，甚至超过MedSAM等医学基础模型。

Conclusion: 专家-通用者协同合作对于标签高效的医学图像分割具有重要价值，展示了传统模型与基础模型协同工作的潜力。

Abstract: Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM's adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.

</details>


### [163] [Domain-Expert-Guided Hybrid Mixture-of-Experts for Medical AI: Integrating Data-Driven Learning with Clinical Priors](https://arxiv.org/abs/2601.17977)
*Jinchen Gu,Nan Zhao,Lei Qiu,Lu Zhang*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出了DKGH-MoE框架，结合数据驱动的MoE和领域专家引导的MoE，在医学影像分析中融合数据驱动特征与临床先验知识（如医生注视模式），提升性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 医学领域MoE模型受限于小数据集，而临床实践中丰富的专家知识（如医生注视模式、诊断启发式）无法从有限数据中可靠学习。需要结合数据驱动专家（捕捉新模式）和领域专家引导专家（编码临床洞察），实现互补优势。

Method: 提出Domain-Knowledge-Guided Hybrid MoE (DKGH-MoE)，即插即用可解释模块。包含两个组件：1) 数据驱动MoE从原始影像数据提取新特征；2) 领域专家引导MoE整合临床先验（特别是临床医生注视线索），强调高诊断相关性区域。

Result: 通过整合领域专家洞察与数据驱动特征，DKGH-MoE在医学影像分析任务中同时提升了性能和可解释性。

Conclusion: DKGH-MoE框架成功统一了数据驱动学习与领域专业知识，为医学等专业领域的小数据集问题提供了有效解决方案，实现了更稳健和临床意义的学习。

Abstract: Mixture-of-Experts (MoE) models increase representational capacity with modest computational cost, but their effectiveness in specialized domains such as medicine is limited by small datasets. In contrast, clinical practice offers rich expert knowledge, such as physician gaze patterns and diagnostic heuristics, that models cannot reliably learn from limited data. Combining data-driven experts, which capture novel patterns, with domain-expert-guided experts, which encode accumulated clinical insights, provides complementary strengths for robust and clinically meaningful learning. To this end, we propose Domain-Knowledge-Guided Hybrid MoE (DKGH-MoE), a plug-and-play and interpretable module that unifies data-driven learning with domain expertise. DKGH-MoE integrates a data-driven MoE to extract novel features from raw imaging data, and a domain-expert-guided MoE incorporates clinical priors, specifically clinician eye-gaze cues, to emphasize regions of high diagnostic relevance. By integrating domain expert insights with data-driven features, DKGH-MoE improves both performance and interpretability.

</details>


### [164] [\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation](https://arxiv.org/abs/2601.18188)
*Weiye Zhu,Zekai Zhang,Xiangchen Wang,Hewei Pan,Teng Wang,Tiantian Geng,Rongtao Xu,Feng Zheng*

Main category: cs.CV

Relevance: 65.0

TL;DR: NaVIDA是一个用于视觉语言导航的统一框架，通过动作驱动的视觉动力学和自适应执行来增强策略学习，使用基于块的反向动力学监督学习视觉变化与动作之间的因果关系，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航方法主要依赖反应式的状态-动作映射，缺乏对动作如何因果性改变后续视觉观察的显式建模。这种视觉-动作因果关系的缺失导致智能体无法预测自身动作引起的视觉变化，从而产生不稳定行为、弱泛化能力和轨迹累积误差。

Method: 1) 使用基于块的反向动力学监督增强训练，学习视觉变化与对应动作之间的因果关系；2) 采用分层概率动作分块（HPAC）组织轨迹为多步块，提供区分性的长范围视觉变化线索；3) 引入熵引导机制自适应设置动作块的执行范围，抑制推理时的误差累积。

Result: 实验表明NaVIDA在导航性能上优于现有最先进方法，且参数更少（3B vs 8B）。真实世界机器人评估进一步验证了该方法的实际可行性和有效性。

Conclusion: NaVIDA通过显式建模视觉-动作因果关系，解决了VLN中的不稳定行为和累积误差问题，提供了一种更有效、参数更少的导航框架，在真实机器人场景中具有实际应用价值。

Abstract: Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \textsc{NaVIDA} (\textbf{Nav}igation with \textbf{I}nverse \textbf{D}ynamics \textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance.

</details>


### [165] [QualiRAG: Retrieval-Augmented Generation for Visual Quality Understanding](https://arxiv.org/abs/2601.18195)
*Linhan Cao,Wei Sun,Weixia Zhang,Xiangyang Zhu,Kaiwei Zhang,Jun Jia,Dandan Zhu,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

Relevance: 65.0

TL;DR: QualiRAG是一个无需训练的RAG框架，利用大语言模型的潜在感知知识进行视觉质量评估，通过动态生成四种互补知识源实现细粒度时空感知和上下文理解。


<details>
  <summary>Details</summary>
Motivation: 当前视觉质量评估方法依赖于监督微调或强化学习，需要大量人工标注且容易受到数据集特定偏差的影响。需要一种无需训练的方法来实现细粒度时空感知和辅助上下文信息。

Method: 提出QualiRAG框架，将问题分解为结构化请求，动态生成四种知识源：视觉元数据、主体定位、全局质量摘要和局部质量描述，然后进行相关性感知检索，实现基于证据的推理。

Result: 在视觉质量理解任务上显著优于开源通用LMM和VQA微调的LMM，在视觉质量比较任务上具有竞争力，无需任何任务特定训练即可实现鲁棒的质量评估能力。

Conclusion: QualiRAG通过训练免费的RAG框架有效利用LMM的潜在感知知识，为视觉质量评估提供了一种无需标注的解决方案，展示了在视觉质量理解任务上的优越性能。

Abstract: Visual quality assessment (VQA) is increasingly shifting from scalar score prediction toward interpretable quality understanding -- a paradigm that demands \textit{fine-grained spatiotemporal perception} and \textit{auxiliary contextual information}. Current approaches rely on supervised fine-tuning or reinforcement learning on curated instruction datasets, which involve labor-intensive annotation and are prone to dataset-specific biases. To address these challenges, we propose \textbf{QualiRAG}, a \textit{training-free} \textbf{R}etrieval-\textbf{A}ugmented \textbf{G}eneration \textbf{(RAG)} framework that systematically leverages the latent perceptual knowledge of large multimodal models (LMMs) for visual quality perception. Unlike conventional RAG that retrieves from static corpora, QualiRAG dynamically generates auxiliary knowledge by decomposing questions into structured requests and constructing four complementary knowledge sources: \textit{visual metadata}, \textit{subject localization}, \textit{global quality summaries}, and \textit{local quality descriptions}, followed by relevance-aware retrieval for evidence-grounded reasoning. Extensive experiments show that QualiRAG achieves substantial improvements over open-source general-purpose LMMs and VQA-finetuned LMMs on visual quality understanding tasks, and delivers competitive performance on visual quality comparison tasks, demonstrating robust quality assessment capabilities without any task-specific training. The code will be publicly available at https://github.com/clh124/QualiRAG.

</details>


### [166] [Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception](https://arxiv.org/abs/2601.18346)
*Sijing Wu,Yunhao Li,Zicheng Zhang,Qi Jia,Xinyue Li,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

Relevance: 65.0

TL;DR: Q-Bench-Portrait：首个专门针对肖像图像质量感知的多模态大语言模型基准测试，包含2765个图像-问题-答案三元组，评估20个开源和5个闭源MLLMs，发现当前模型在肖像图像感知方面能力有限。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在通用图像的低级视觉基准上表现良好，但在具有独特结构和感知特性的肖像图像领域的感知和评估能力尚未充分探索。需要专门的基准来评估MLLMs在肖像图像质量感知方面的能力。

Method: 构建Q-Bench-Portrait基准，包含：1）多样化的肖像图像来源（自然、合成失真、AI生成、艺术、计算机图形）；2）全面的质量维度（技术失真、AIGC特定失真、美学）；3）多种问题格式（单选、多选、判断、开放性问题），涵盖全局和局部层面。

Result: 评估了25个MLLMs（20个开源+5个闭源），发现虽然当前模型在肖像图像感知方面有一定能力，但性能仍然有限且不精确，与人类判断存在明显差距。

Conclusion: 提出了首个专门的肖像图像质量感知基准，揭示了当前MLLMs在该领域的局限性，希望促进通用和领域特定MLLMs在肖像图像感知能力方面的进一步研究。

Abstract: Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.

</details>


### [167] [DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment](https://arxiv.org/abs/2601.18493)
*Sara Tehrani,Yonghao Xu,Leif Haglund,Amanda Berg,Michael Felsberg*

Main category: cs.CV

Relevance: 65.0

TL;DR: DisasterInsight是一个用于评估视觉语言模型在灾害分析任务中性能的多模态基准，基于xBD数据集构建了约112K建筑中心实例，支持多种指令任务评估。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言基准主要关注粗粒度标签和图像级识别，缺乏对灾害响应中所需的功能理解和指令鲁棒性的评估，无法满足实际人道主义工作流程的需求。

Method: 1) 将xBD数据集重构为约112K建筑中心实例；2) 提出DI-Chat，通过参数高效的LoRA方法对现有VLM骨干进行灾害特定指令数据微调；3) 支持多种任务评估：建筑功能分类、损坏程度分类、灾害类型分类、计数和结构化报告生成。

Result: 实验显示现有通用和遥感VLM在各项任务中存在显著性能差距，特别是在损坏理解和结构化报告生成方面。DI-Chat在损坏程度分类、灾害类型分类和报告生成质量上取得显著改进，但建筑功能分类对所有评估模型仍然具有挑战性。

Conclusion: DisasterInsight为研究灾害图像中的基础多模态推理提供了统一基准，DI-Chat展示了领域适应方法的有效性，但建筑功能理解仍是一个未解决的挑战。

Abstract: Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines.
  To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery.

</details>


### [168] [A Pragmatic VLA Foundation Model](https://arxiv.org/abs/2601.18692)
*Wei Wu,Fan Lu,Yunnan Wang,Shuai Yang,Shi Liu,Fangjing Wang,Qian Zhu,He Sun,Yong Wang,Shuailei Ma,Yiyu Ren,Kejia Zhang,Hui Yu,Jingmei Zhao,Shuai Zhou,Zhenqi Qiu,Houlong Xiong,Ziyu Wang,Zechen Wang,Ran Cheng,Yong-Lu Li,Yongtao Huang,Xing Zhu,Yujun Shen,Kecheng Zheng*

Main category: cs.RO

Relevance: 65.0

TL;DR: LingBot-VLA是一个基于20,000小时真实世界数据的视觉-语言-动作基础模型，在9种双臂机器人配置上训练，在3个机器人平台上完成100个任务，性能优于现有方法，代码库效率提升1.5-2.8倍。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在不同任务和平台间忠实泛化、同时保证成本效益（数据需求和GPU时间）的视觉-语言-动作基础模型，以推动机器人操作领域的发展。

Method: 使用约20,000小时来自9种流行双臂机器人配置的真实世界数据训练VLA模型，构建高效代码库实现261样本/秒/GPU的吞吐量，在3个机器人平台上进行系统评估（每个平台100个任务，每个任务130次后训练测试）。

Result: 模型在3个机器人平台上明显优于竞争对手，展示了强大的性能和广泛的泛化能力；代码库在8-GPU训练设置下实现261样本/秒/GPU的吞吐量，相比现有VLA代码库有1.5-2.8倍加速。

Conclusion: LingBot-VLA是一个适合实际部署的VLA基础模型，通过开源代码、基础模型和基准数据来推动机器人学习领域发展，促进更具挑战性的任务和健全的评估标准。

Abstract: Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.

</details>


### [169] [A Contrastive Pre-trained Foundation Model for Deciphering Imaging Noisomics across Modalities](https://arxiv.org/abs/2601.17047)
*Yuanjie Gu,Yiqun Wang,Chaohui Yu,Ang Xuan,Fan Wang,Zhi Lu,Biqin Dong*

Main category: cs.CV

Relevance: 45.0

TL;DR: Noisomics框架通过对比预训练基础模型(CoP)将成像噪声从抑制对象转变为信息解码资源，仅需100个训练样本即可超越传统需要10万样本的监督方法，实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 现代成像传感器将物理信号与复杂算法伪影纠缠在一起，传统方法需要大量监督数据且难以解耦这些因素，通常将噪声视为干扰而非信息资源。

Method: 提出Noisomics框架和对比预训练基础模型(CoP)，利用流形假设和合成噪声基因组，通过对比学习解耦语义信号与随机扰动，打破传统深度学习缩放定律。

Result: 仅用100个训练样本就超越了传统需要10万样本的监督基线，数据计算依赖降低3个数量级；在12个域外数据集上零样本泛化，估计误差减少63.8%，决定系数提高85.1%。

Conclusion: 将随机退化重新定义为重要的信息资源，无需设备校准即可实现精确成像诊断，从消费摄影到深层组织显微镜都有应用价值。

Abstract: Characterizing imaging noise is notoriously data-intensive and device-dependent, as modern sensors entangle physical signals with complex algorithmic artifacts. Current paradigms struggle to disentangle these factors without massive supervised datasets, often reducing noise to mere interference rather than an information resource. Here, we introduce "Noisomics", a framework shifting the focus from suppression to systematic noise decoding via the Contrastive Pre-trained (CoP) Foundation Model. By leveraging the manifold hypothesis and synthetic noise genome, CoP employs contrastive learning to disentangle semantic signals from stochastic perturbations. Crucially, CoP breaks traditional deep learning scaling laws, achieving superior performance with only 100 training samples, outperforming supervised baselines trained on 100,000 samples, thereby reducing data and computational dependency by three orders of magnitude. Extensive benchmarking across 12 diverse out-of-domain datasets confirms its robust zero-shot generalization, demonstrating a 63.8% reduction in estimation error and an 85.1% improvement in the coefficient of determination compared to the conventional training strategy. We demonstrate CoP's utility across scales: from deciphering non-linear hardware-noise interplay in consumer photography to optimizing photon-efficient protocols for deep-tissue microscopy. By decoding noise as a multi-parametric footprint, our work redefines stochastic degradation as a vital information resource, empowering precise imaging diagnostics without prior device calibration.

</details>


### [170] [Implicit Neural Representation-Based Continuous Single Image Super Resolution: An Empirical Study](https://arxiv.org/abs/2601.17723)
*Tayyab Nasir,Daochang Liu,Ajmal Mian*

Main category: cs.CV

Relevance: 45.0

TL;DR: 该论文对基于隐式神经表示（INR）的任意尺度图像超分辨率（ASSR）方法进行了首次系统性实证研究，比较了现有技术，分析了训练配置的影响，并提出了新的损失函数。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对INR-based ASSR方法的系统性实证研究，不清楚不同训练策略（如缩放定律、目标设计、优化策略）的实际效果，需要建立基准性能、识别饱和极限并指明有前景的研究方向。

Method: 1. 在多样化设置下比较现有INR-based ASSR技术；2. 提出统一框架和代码库便于可重复比较；3. 研究受控训练配置对感知图像质量的影响；4. 提出新的损失函数，在惩罚强度变化的同时保留边缘、纹理和细节。

Result: 1. 近期更复杂的INR方法相比早期方法仅有边际改进；2. 模型性能与训练配置强相关，这是先前研究忽视的因素；3. 提出的损失函数能提升纹理保真度；4. 缩放定律适用于INR-based ASSR，模型复杂度和数据多样性的增加可带来可预测的性能提升。

Conclusion: 该研究填补了INR-based ASSR领域的实证研究空白，揭示了训练配置的重要性，提出了改进纹理保真的新损失函数，并验证了缩放定律在该领域的适用性，为未来研究提供了重要基准和方向。

Abstract: Implicit neural representation (INR) has become the standard approach for arbitrary-scale image super-resolution (ASSR). To date, no empirical study has systematically examined the effectiveness of existing methods, nor investigated the effects of different training recipes, such as scaling laws, objective design, and optimization strategies. A rigorous empirical analysis is essential not only for benchmarking performance and revealing true gains but also for establishing the current state of ASSR, identifying saturation limits, and highlighting promising directions. We fill this gap by comparing existing techniques across diverse settings and presenting aggregated performance results on multiple image quality metrics. We contribute a unified framework and code repository to facilitate reproducible comparisons. Furthermore, we investigate the impact of carefully controlled training configurations on perceptual image quality and examine a new loss function that penalizes intensity variations while preserving edges, textures, and finer details during training. We conclude the following key insights that have been previously overlooked: (1) Recent, more complex INR methods provide only marginal improvements over earlier methods. (2) Model performance is strongly correlated to training configurations, a factor overlooked in prior works. (3) The proposed loss enhances texture fidelity across architectures, emphasizing the role of objective design for targeted perceptual gains. (4) Scaling laws apply to INR-based ASSR, confirming predictable gains with increased model complexity and data diversity.

</details>


### [171] [The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation](https://arxiv.org/abs/2601.17737)
*Chenyu Mu,Xin He,Qu Yang,Wanshun Chen,Jiadi Yao,Huang Liu,Zihao Yi,Bo Zhao,Xingyu Chen,Ruotian Ma,Fanghua Ye,Erkun Yang,Cheng Deng,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出一个端到端的智能体框架，将对话转换为电影视频，包含剧本生成、导演编排和评估三个智能体，解决长视频叙事连贯性问题。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型虽然能从文本提示生成视觉内容，但难以从高级概念（如对话）生成长格式、连贯的叙事，存在"语义鸿沟"问题。

Method: 1) ScripterAgent：将粗略对话转换为细粒度可执行电影剧本；2) 构建ScriptBench大规模多模态基准数据集；3) DirectorAgent：使用跨场景连续生成策略编排SOTA视频模型；4) CriticAgent和VSA指标进行评估。

Result: 框架显著提高了剧本忠实度和时间保真度，分析揭示了当前SOTA模型在视觉壮观性和严格剧本遵循之间的权衡关系。

Conclusion: 该智能体框架有效弥合了创意想法与电影执行之间的语义鸿沟，为自动化电影制作提供了有价值的见解。

Abstract: Recent advances in video generation have produced models capable of synthesizing stunning visual content from simple text prompts. However, these models struggle to generate long-form, coherent narratives from high-level concepts like dialogue, revealing a ``semantic gap'' between a creative idea and its cinematic execution. To bridge this gap, we introduce a novel, end-to-end agentic framework for dialogue-to-cinematic-video generation. Central to our framework is ScripterAgent, a model trained to translate coarse dialogue into a fine-grained, executable cinematic script. To enable this, we construct ScriptBench, a new large-scale benchmark with rich multimodal context, annotated via an expert-guided pipeline. The generated script then guides DirectorAgent, which orchestrates state-of-the-art video models using a cross-scene continuous generation strategy to ensure long-horizon coherence. Our comprehensive evaluation, featuring an AI-powered CriticAgent and a new Visual-Script Alignment (VSA) metric, shows our framework significantly improves script faithfulness and temporal fidelity across all tested video models. Furthermore, our analysis uncovers a crucial trade-off in current SOTA models between visual spectacle and strict script adherence, providing valuable insights for the future of automated filmmaking.

</details>


### [172] [MV-S2V: Multi-View Subject-Consistent Video Generation](https://arxiv.org/abs/2601.17756)
*Ziyang Song,Xinyu Gong,Bangya Liu,Zelin Zhao*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出并解决多视角主题到视频生成（MV-S2V）任务，通过合成数据管道和时序移位RoPE实现3D级主题一致性


<details>
  <summary>Details</summary>
Motivation: 现有S2V方法局限于单视角参考，将任务简化为S2I+I2V流水线，未能充分利用视频主题控制的全部潜力。需要解决多视角参考下的3D级主题一致性挑战。

Method: 1) 开发合成数据管道生成定制化训练数据，辅以小规模真实数据集；2) 提出时序移位RoPE（TS-RoPE）来区分不同主题和同一主题的不同视角，解决条件生成中的混淆问题。

Result: 框架在多视角参考图像下实现了优越的3D主题一致性和高质量视觉输出，为主题驱动视频生成开辟了新方向。

Conclusion: MV-S2V任务比传统S2V更具挑战性但更有意义，提出的数据管道和TS-RoPE方法有效解决了多视角参考下的3D一致性生成问题。

Abstract: Existing Subject-to-Video Generation (S2V) methods have achieved high-fidelity and subject-consistent video generation, yet remain constrained to single-view subject references. This limitation renders the S2V task reducible to an S2I + I2V pipeline, failing to exploit the full potential of video subject control. In this work, we propose and address the challenging Multi-View S2V (MV-S2V) task, which synthesizes videos from multiple reference views to enforce 3D-level subject consistency. Regarding the scarcity of training data, we first develop a synthetic data curation pipeline to generate highly customized synthetic data, complemented by a small-scale real-world captured dataset to boost the training of MV-S2V. Another key issue lies in the potential confusion between cross-subject and cross-view references in conditional generation. To overcome this, we further introduce Temporally Shifted RoPE (TS-RoPE) to distinguish between different subjects and distinct views of the same subject in reference conditioning. Our framework achieves superior 3D subject consistency w.r.t. multi-view reference images and high-quality visual outputs, establishing a new meaningful direction for subject-driven video generation. Our project page is available at <a href="https://szy-young.github.io/mv-s2v">this URL</a>

</details>


### [173] [SynMind: Reducing Semantic Hallucination in fMRI-Based Image Reconstruction](https://arxiv.org/abs/2601.17857)
*Lan Yang,Minghan Yang,Ke Li,Honggang Zhang,Kaiyue Pang,Yi-Zhe Song*

Main category: cs.CV

Relevance: 45.0

TL;DR: SynMind：一种通过将fMRI信号解析为句子级语义描述来改进fMRI图像重建的框架，解决了现有方法中语义错位的问题，使用更小的模型实现更好的重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有fMRI图像重建方法虽然能生成逼真图像，但经常出现严重的语义错位问题——重要对象被替换或幻觉生成。这是因为现有方法过度依赖纠缠的视觉嵌入，优先考虑纹理和全局外观等低层线索，而忽视了明确的语义身份识别。

Method: 1) 将fMRI信号解析为丰富的句子级语义描述，模拟人类视觉理解的分层和组合特性；2) 利用基础视觉语言模型生成类似人类的多粒度文本表示，捕捉对象身份和空间组织；3) 提出SynMind框架，将这些明确的语义编码与视觉先验结合，以条件化预训练的扩散模型。

Result: SynMind在大多数定量指标上优于现有最先进方法。通过将语义推理卸载到文本对齐模块，SynMind使用更小的Stable Diffusion 1.4和单个消费级GPU就超越了基于SDXL的竞争方法。大规模人类评估证实SynMind生成的重建图像更符合人类视觉感知。神经可视化分析显示SynMind激活了更广泛、语义更相关的大脑区域，减少了对高级视觉区域的过度依赖。

Conclusion: 通过将fMRI信号解析为明确的语义描述，SynMind解决了fMRI图像重建中的语义错位问题，实现了更准确、更符合人类感知的图像重建，同时提高了计算效率。

Abstract: Recent advances in fMRI-based image reconstruction have achieved remarkable photo-realistic fidelity. Yet, a persistent limitation remains: while reconstructed images often appear naturalistic and holistically similar to the target stimuli, they frequently suffer from severe semantic misalignment -- salient objects are often replaced or hallucinated despite high visual quality. In this work, we address this limitation by rethinking the role of explicit semantic interpretation in fMRI decoding. We argue that existing methods rely too heavily on entangled visual embeddings which prioritize low-level appearance cues -- such as texture and global gist -- over explicit semantic identity. To overcome this, we parse fMRI signals into rich, sentence-level semantic descriptions that mirror the hierarchical and compositional nature of human visual understanding. We achieve this by leveraging grounded VLMs to generate synthetic, human-like, multi-granularity textual representations that capture object identities and spatial organization. Built upon this foundation, we propose SynMind, a framework that integrates these explicit semantic encodings with visual priors to condition a pretrained diffusion model. Extensive experiments demonstrate that SynMind outperforms state-of-the-art methods across most quantitative metrics. Notably, by offloading semantic reasoning to our text-alignment module, SynMind surpasses competing methods based on SDXL while using the much smaller Stable Diffusion 1.4 and a single consumer GPU. Large-scale human evaluations further confirm that SynMind produces reconstructions more consistent with human visual perception. Neurovisualization analyses reveal that SynMind engages broader and more semantically relevant brain regions, mitigating the over-reliance on high-level visual areas.

</details>


### [174] [Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space](https://arxiv.org/abs/2601.18392)
*Moritz Rempe,Lukas T. Rotkopf,Marco Schlimbach,Helmut Becker,Fabian Hörst,Johannes Haubold,Philipp Dammann,Kevin Kröninger,Jens Kleesiek*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出了一种直接在k空间数据上进行分类的复数视觉变换器（kViT），通过径向k空间分块策略解决传统架构与MRI物理之间的几何不匹配问题，在保持分类性能的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前MRI深度学习应用主要基于重建后的幅度图像，这丢弃了相位信息且需要计算昂贵的变换。传统神经网络架构依赖于局部操作（卷积或网格分块），不适合k空间数据的全局、非局部特性。

Method: 提出复数视觉变换器（kViT），设计径向k空间分块策略以尊重频域能量分布，直接在k空间数据上执行分类任务。

Result: 在fastMRI和内部数据集上，kViT的分类性能与最先进的图像域基线（ResNet、EfficientNet、ViT）相当，但对高加速因子表现出更强的鲁棒性，训练时VRAM消耗减少高达68倍。

Conclusion: kViT为资源高效的、直接从扫描仪进行AI分析开辟了新途径，实现了计算效率的范式转变。

Abstract: Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis.

</details>


### [175] [Self-Refining Video Sampling](https://arxiv.org/abs/2601.18577)
*Sangwon Jang,Taekyung Ki,Jaehyeong Jo,Saining Xie,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.CV

Relevance: 45.0

TL;DR: 提出自精炼视频采样方法，利用预训练视频生成器作为自身的精炼器，通过不确定性感知策略选择性优化区域，显著提升运动连贯性和物理对齐


<details>
  <summary>Details</summary>
Motivation: 现代视频生成器在处理复杂物理动态时仍存在困难，现有方法使用外部验证器或增强数据训练，计算成本高且难以捕捉细粒度运动

Method: 将预训练视频生成器解释为去噪自编码器，在推理时进行迭代内循环精炼，无需外部验证器或额外训练；引入基于自一致性的不确定性感知精炼策略，选择性优化区域防止过度精炼伪影

Result: 在先进视频生成器上的实验显示，运动连贯性和物理对齐显著改善，相比默认采样器和基于引导的采样器，获得超过70%的人类偏好

Conclusion: 自精炼视频采样是一种简单有效的方法，通过利用生成器自身作为精炼器，在推理时迭代优化，显著提升视频生成的物理真实感

Abstract: Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\% human preference compared to the default sampler and guidance-based sampler.

</details>


### [176] [SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification](https://arxiv.org/abs/2601.18739)
*Ignacio Antequera-Sánchez,Juan Luis Suárez-Díaz,Rosana Montes,Francisco Herrera*

Main category: cs.CV

Relevance: 45.0

TL;DR: SeNeDiF-OOD：基于语义嵌套二分融合的层次化OOD检测框架，通过分层决策边界处理异构OOD数据，在真实世界建筑风格识别系统中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 开放世界环境中AI系统需要可靠的OOD检测，但现有单阶段检测器难以处理从低级损坏到语义偏移的异构OOD数据，需要更精细的检测方法。

Method: 提出语义嵌套二分融合框架，将检测任务分解为层次化二元融合节点结构，每层集成与特定语义抽象级别对齐的决策边界。

Result: 在MonuMAI建筑风格识别系统的真实案例研究中，该方法显著优于传统基线，能有效过滤非纪念碑图像、未知建筑风格和对抗攻击等多样OOD类别，同时保持分布内性能。

Conclusion: 层次化融合方法为解决异构OOD检测问题提供了有效框架，在开放世界应用中具有实用价值。

Abstract: Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.

</details>


### [177] [Acoustic Field Video for Multimodal Scene Understanding](https://arxiv.org/abs/2601.17123)
*Daehwa Kim,Chris Harrison*

Main category: cs.HC

Relevance: 45.0

TL;DR: 该论文提出了一种用于视觉语言模型的新型多模态输入表示：声场视频。与传统视频相比，声场视频提供了声音强度在场景中的空间可视化，显著提升了场景理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型主要依赖RGB视频和音频，但许多日常场景理解任务仅凭视觉和音频输入仍存在约束不足的问题。智能音箱、机器人和XR头显中普遍存在的波束成形麦克风阵列的声场感知能力尚未被充分利用于场景理解。

Method: 提出实时处理管道，使用低成本波束成形麦克风阵列生成声场视频。构建了包含402个问答场景的评估集，比较了最先进的视觉语言模型在使用传统视频和结合声场视频时的表现差异。

Result: 实验结果显示，结合空间声学数据后，视觉语言模型的正确率从38.3%显著提升至67.4%，证明了声场信息对多模态推理的有效性。

Conclusion: 声场数据为多模态推理提供了一个有前景且实用的方向，能够弥补仅依赖视觉和音频输入时的场景理解不足。

Abstract: We introduce and explore a new multimodal input representation for vision-language models: acoustic field video. Unlike conventional video (RGB with stereo/mono audio), our video stream provides a spatially grounded visualization of sound intensity across a scene, offering a new and powerful dimension of perceptual understanding. Our real-time pipeline uses low-cost beamforming microphone arrays that are already common in smart speakers and increasingly present in robotics and XR headsets, yet this sensing capability remains unutilized for scene understanding. To assess the value of spatial acoustic information, we constructed an evaluation set of 402 question-answer scenes, comparing a state-of-the-art VLM given conventional video with and without paired acoustic field video. Results show a clear and consistent improvement when incorporating spatial acoustic data; the VLM we test improves from 38.3% correct to 67.4%. Our findings highlight that many everyday scene understanding tasks remain underconstrained when relying solely on visual and audio input, and that acoustic field data provides a promising and practical direction for multimodal reasoning. A video demo is available at https://daehwakim.com/seeingsound

</details>


### [178] [Cross-Domain Transfer with Self-Supervised Spectral-Spatial Modeling for Hyperspectral Image Classification](https://arxiv.org/abs/2601.18088)
*Jianshu Chao,Tianhua Lv,Qiqiong Ma,Yunfei Qiu,Li Fang,Huifang Shen,Wei Yao*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出自监督跨域迁移框架，用于高光谱图像分类，无需源域标注，通过S2Former模块和频率域约束学习可迁移的谱-空联合表征，在目标域少量样本下实现高效适应。


<details>
  <summary>Details</summary>
Motivation: 现有高光谱自监督学习方法在跨域迁移场景中仍依赖源域标注，且对分布偏移敏感，导致目标域泛化性能下降。需要开发无需源域标签、能适应分布偏移的自监督跨域迁移方法。

Method: 1) 自监督预训练阶段：设计Spatial-Spectral Transformer (S2Former)模块，采用双分支空间-光谱Transformer和双向交叉注意力机制实现谱-空协同建模；提出Frequency Domain Constraint (FDC)通过实快速傅里叶变换和高频幅度损失保持频域一致性。2) 微调阶段：提出Diffusion-Aligned Fine-tuning (DAFT)蒸馏机制，通过师生结构对齐语义演化轨迹，实现低标签条件下的鲁棒迁移学习。

Result: 在四个高光谱数据集上的实验结果表明，该方法具有稳定的分类性能和强大的跨域适应能力，验证了在资源受限条件下的有效性。

Conclusion: 提出的自监督跨域迁移框架能够有效学习可迁移的谱-空联合表征，无需源域标注，在目标域少量样本下实现高效适应，为高光谱图像分类提供了新的解决方案。

Abstract: Self-supervised learning has demonstrated considerable potential in hyperspectral representation, yet its application in cross-domain transfer scenarios remains under-explored. Existing methods, however, still rely on source domain annotations and are susceptible to distribution shifts, leading to degraded generalization performance in the target domain. To address this, this paper proposes a self-supervised cross-domain transfer framework that learns transferable spectral-spatial joint representations without source labels and achieves efficient adaptation under few samples in the target domain. During the self-supervised pre-training phase, a Spatial-Spectral Transformer (S2Former) module is designed. It adopts a dual-branch spatial-spectral transformer and introduces a bidirectional cross-attention mechanism to achieve spectral-spatial collaborative modeling: the spatial branch enhances structural awareness through random masking, while the spectral branch captures fine-grained differences. Both branches mutually guide each other to improve semantic consistency. We further propose a Frequency Domain Constraint (FDC) to maintain frequency-domain consistency through real Fast Fourier Transform (rFFT) and high-frequency magnitude loss, thereby enhancing the model's capability to discern fine details and boundaries. During the fine-tuning phase, we introduce a Diffusion-Aligned Fine-tuning (DAFT) distillation mechanism. This aligns semantic evolution trajectories through a teacher-student structure, enabling robust transfer learning under low-label conditions. Experimental results demonstrate stable classification performance and strong cross-domain adaptability across four hyperspectral datasets, validating the method's effectiveness under resource-constrained conditions.

</details>


### [179] [Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge](https://arxiv.org/abs/2601.18698)
*Xiao Liu,Jiawei Zhang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 该论文提出了Geo-Attraction Landmark Probing (GAP)框架，用于评估文本到视频模型的地理公平性和地理视觉知识，发现Sora 2模型展现出相对均匀的地理知识分布，而非预期的强地理偏见。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型在视觉上表现出色，但尚不清楚这些模型是否编码了地理公平的视觉知识。研究旨在调查这些模型的地理公平性和地理基础视觉知识，特别是通过旅游景点这一视角进行评估。

Method: 提出了Geo-Attraction Landmark Probing (GAP)系统框架，构建了GEOATTRACTION-500基准数据集（包含500个全球分布的景点），整合了全局结构对齐、细粒度关键点对齐和视觉语言模型判断等互补指标，并与人类评估进行验证。

Result: 对Sora 2模型应用GAP评估发现，与常见的强地理偏见假设相反，该模型在不同地区、发展水平和文化群体中展现出相对均匀的地理基础视觉知识水平，仅对景点知名度有弱依赖性。

Conclusion: 当前文本到视频模型表达全球视觉知识比预期更均匀，这突显了它们在全球化部署应用中的潜力，同时也强调了随着系统发展需要持续评估的必要性。

Abstract: Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.

</details>


### [180] [Multimodal Privacy-Preserving Entity Resolution with Fully Homomorphic Encryption](https://arxiv.org/abs/2601.18612)
*Susim Roy,Nalini Ratha*

Main category: cs.CR

Relevance: 40.0

TL;DR: 提出一个用于高合规领域实体解析的多模态框架，解决数据异构性、匹配保真度和隐私保护的三重挑战，在保证个人身份信息安全的同时实现低错误率和计算可扩展性。


<details>
  <summary>Details</summary>
Motivation: 高合规领域（如政府和金融机构）的实体解析面临数据异构性（包括个人标识符的句法变体）的挑战，需要在保证隐私和满足严格监管要求的同时进行大规模身份匹配。

Method: 引入一个多模态框架，处理政府和金融机构典型的大规模数据集。该方法在整个匹配生命周期中保持个人身份信息的明文计算不可访问，通过密码学保证客户机密性，同时实现低错误率和计算可扩展性。

Result: 实现了显著低的等错误率（equal error rate），在保持计算可扩展性的同时满足严格的监管要求，为机构提供了密码学保证的客户机密性。

Conclusion: 该多模态框架成功解决了高合规领域实体解析中的数据量、匹配保真度和隐私保护的三重挑战，为政府和金融机构提供了安全、准确且可扩展的身份匹配解决方案。

Abstract: The canonical challenge of entity resolution within high-compliance sectors, where secure identity reconciliation is frequently confounded by significant data heterogeneity, including syntactic variations in personal identifiers, is a longstanding and complex problem. To this end, we introduce a novel multimodal framework operating with the voluminous data sets typical of government and financial institutions. Specifically, our methodology is designed to address the tripartite challenge of data volume, matching fidelity, and privacy. Consequently, the underlying plaintext of personally identifiable information remains computationally inaccessible throughout the matching lifecycle, empowering institutions to rigorously satisfy stringent regulatory mandates with cryptographic assurances of client confidentiality while achieving a demonstrably low equal error rate and maintaining computational tractability at scale.

</details>


### [181] [Single-Pixel Vision-Language Model for Intrinsic Privacy-Preserving Behavioral Intelligence](https://arxiv.org/abs/2601.17050)
*Hongjun An,Yiliang Song,Jiawei Shao,Zhe Sun,Xuelong Li*

Main category: cs.CV

Relevance: 35.0

TL;DR: SP-VLM：一种基于单像素视觉语言模型的隐私保护监控框架，通过低维单像素模态捕捉人类动态，结合视觉语言模型推断复杂行为模式，在保护个人身份隐私的同时实现异常检测和行为理解。


<details>
  <summary>Details</summary>
Motivation: 在隐私敏感环境（如洗手间、更衣室）中，传统监控因隐私法规和伦理问题受限，但欺凌、骚扰等有害社会互动仍构成严重威胁。需要一种既能保护隐私又能进行安全监控的技术方案。

Method: 提出单像素视觉语言模型（SP-VLM）框架：1）使用单像素传感器捕捉低维人类动态数据；2）通过视觉语言模型集成从严重降质的单像素观测中提取行为语义；3）在特定采样率范围内平衡行为识别与身份保护。

Result: 1）单像素传感固有抑制身份可恢复性，使最先进的人脸识别系统在临界采样率以下失效；2）SP-VLM仍能从降质观测中提取有意义的语义，实现异常检测、人数统计和活动理解；3）确定了行为智能出现而身份保护仍强的实用采样率区间。

Conclusion: SP-VLM提供了一条人权对齐的安全监控路径，在隐私敏感空间中支持及时干预，同时避免侵入式监控常态化，平衡了隐私保护与公共安全需求。

Abstract: Adverse social interactions, such as bullying, harassment, and other illicit activities, pose significant threats to individual well-being and public safety, leaving profound impacts on physical and mental health. However, these critical events frequently occur in privacy-sensitive environments like restrooms, and changing rooms, where conventional surveillance is prohibited or severely restricted by stringent privacy regulations and ethical concerns. Here, we propose the Single-Pixel Vision-Language Model (SP-VLM), a novel framework that reimagines secure environmental monitoring. It achieves intrinsic privacy-by-design by capturing human dynamics through inherently low-dimensional single-pixel modalities and inferring complex behavioral patterns via seamless vision-language integration. Building on this framework, we demonstrate that single-pixel sensing intrinsically suppresses identity recoverability, rendering state-of-the-art face recognition systems ineffective below a critical sampling rate. We further show that SP-VLM can nonetheless extract meaningful behavioral semantics, enabling robust anomaly detection, people counting, and activity understanding from severely degraded single-pixel observations. Combining these findings, we identify a practical sampling-rate regime in which behavioral intelligence emerges while personal identity remains strongly protected. Together, these results point to a human-rights-aligned pathway for safety monitoring that can support timely intervention without normalizing intrusive surveillance in privacy-sensitive spaces.

</details>


### [182] [Ego4OOD: Rethinking Egocentric Video Domain Generalization via Covariate Shift Scoring](https://arxiv.org/abs/2601.17056)
*Zahra Vaseqi,James Clark*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了Ego4OOD基准测试，用于评估以自我为中心视频动作识别在协变量偏移下的泛化能力，并展示了一种轻量级二元训练方法能达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有以自我为中心视频域泛化基准测试往往混淆协变量偏移与概念偏移，难以可靠评估模型跨输入分布的泛化能力。需要设计一个能强调可测量协变量多样性同时减少概念偏移的基准测试。

Method: 1) 从Ego4D构建Ego4OOD基准测试，包含8个地理不同域，使用聚类基协变量偏移度量量化域难度；2) 提出一对多二元训练目标，将多类动作识别分解为独立二元分类任务，减少特征分布偏移下视觉相似类间的干扰。

Result: 轻量级两层全连接网络在Argo1M和Ego4OOD上达到与SOTA以自我为中心域泛化方法竞争的性能，尽管参数更少且无额外模态。实证分析显示测量的协变量偏移与识别性能间存在明确关系。

Conclusion: 受控基准测试和定量域表征对于研究以自我为中心视频的分布外泛化至关重要。二元训练公式特别适合协变量偏移场景，能有效减少类间干扰。

Abstract: Egocentric video action recognition under domain shifts remains challenging due to large intra-class spatio-temporal variability, long-tailed feature distributions, and strong correlations between actions and environments. Existing benchmarks for egocentric domain generalization often conflate covariate shifts with concept shifts, making it difficult to reliably evaluate a model's ability to generalize across input distributions. To address this limitation, we introduce Ego4OOD, a domain generalization benchmark derived from Ego4D that emphasizes measurable covariate diversity while reducing concept shift through semantically coherent, moment-level action categories. Ego4OOD spans eight geographically distinct domains and is accompanied by a clustering-based covariate shift metric that provides a quantitative proxy for domain difficulty. We further leverage a one-vs-all binary training objective that decomposes multi-class action recognition into independent binary classification tasks. This formulation is particularly well-suited for covariate shift by reducing interference between visually similar classes under feature distribution shift. Using this formulation, we show that a lightweight two-layer fully connected network achieves performance competitive with state-of-the-art egocentric domain generalization methods on both Argo1M and Ego4OOD, despite using fewer parameters and no additional modalities. Our empirical analysis demonstrates a clear relationship between measured covariate shift and recognition performance, highlighting the importance of controlled benchmarks and quantitative domain characterization for studying out-of-distribution generalization in egocentric video.

</details>


### [183] [LoD Sketch Extraction from Architectural Models Using Generative AI: Dataset Construction for Multi-Level Architectural Design Generation](https://arxiv.org/abs/2601.17095)
*Xusheng Du,Athiwat Kongkaeo,Ye Zhang,Haoran Xie*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出基于生成式AI的自动LOD草图提取框架，用于从高细节建筑模型生成几何一致的多层次细节表示，解决建筑设计中多尺度建模的数据缺乏问题。


<details>
  <summary>Details</summary>
Motivation: 建筑设计中需要多层次细节（LoD）表示以实现从概念体量到详细建模的平滑过渡。传统LoD建模依赖人工操作，耗时费力且易产生几何不一致。虽然生成式AI为从草图输入生成多级建筑模型提供了新可能，但缺乏高质量配对的LoD训练数据限制了其应用。

Method: 提出自动LoD草图提取框架，集成计算机视觉技术和生成式AI方法，建立从详细表示到体积抽象的渐进提取流程。通过逐步简化高细节建筑模型，自动生成几何一致且层次连贯的多LoD表示。

Result: 实验结果表明，该方法在LoD级别间保持强几何一致性：从LoD3到LoD2的SSIM值为0.7319，从LoD2到LoD1的SSIM值为0.7532；相应的归一化Hausdorff距离分别为图像对角线的25.1%和61.0%，反映了抽象过程中的受控几何偏差。

Conclusion: 该框架有效保留了全局结构，同时在不同LoD级别实现了渐进语义简化，为AI驱动的多级建筑生成和层次建模提供了可靠数据和技术支持。

Abstract: For architectural design, representation across multiple Levels of Details (LoD) is essential for achieving a smooth transition from conceptual massing to detailed modeling. However, traditional LoD modeling processes rely on manual operations that are time-consuming, labor-intensive, and prone to geometric inconsistencies. While the rapid advancement of generative artificial intelligence (AI) has opened new possibilities for generating multi-level architectural models from sketch inputs, its application remains limited by the lack of high-quality paired LoD training data. To address this issue, we propose an automatic LoD sketch extraction framework using generative AI models, which progressively simplifies high-detail architectural models to automatically generate geometrically consistent and hierarchically coherent multi-LoD representations. The proposed framework integrates computer vision techniques with generative AI methods to establish a progressive extraction pipeline that transitions from detailed representations to volumetric abstractions. Experimental results demonstrate that the method maintains strong geometric consistency across LoD levels, achieving SSIM values of 0.7319 and 0.7532 for the transitions from LoD3 to LoD2 and from LoD2 to LoD1, respectively, with corresponding normalized Hausdorff distances of 25.1% and 61.0% of the image diagonal, reflecting controlled geometric deviation during abstraction. These results verify that the proposed framework effectively preserves global structure while achieving progressive semantic simplification across different LoD levels, providing reliable data and technical support for AI-driven multi-level architectural generation and hierarchical modeling.

</details>


### [184] [Spatiotemporal Semantic V2X Framework for Cooperative Collision Prediction](https://arxiv.org/abs/2601.17216)
*Murat Arda Onsu,Poonam Lohan,Burak Kantarci,Aisha Syed,Matthew Andrews,Sean Kennedy*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出基于语义V2X框架的实时碰撞预测系统，使用V-JEPA生成时空语义嵌入替代原始视频传输，大幅降低通信开销同时提升预测性能


<details>
  <summary>Details</summary>
Motivation: 智能交通系统需要实时碰撞预测，但传统方法传输原始视频或高维传感数据在车联网通信带宽和延迟约束下不实用

Method: 1) 路侧单元摄像头使用V-JEPA生成未来帧的时空语义嵌入；2) 构建城市交通数字孪生环境生成多样化交通场景；3) 通过V2X链路传输语义嵌入到车辆；4) 车辆端使用轻量级注意力探针和分类器解码预测碰撞

Result: 系统在碰撞预测F1分数上提升10%，同时传输需求相比原始视频减少四个数量级（10,000倍）

Conclusion: 语义V2X通信有潜力实现智能交通系统中的协作实时碰撞预测，在保持预测准确性的同时显著降低通信开销

Abstract: Intelligent Transportation Systems (ITS) demand real-time collision prediction to ensure road safety and reduce accident severity. Conventional approaches rely on transmitting raw video or high-dimensional sensory data from roadside units (RSUs) to vehicles, which is impractical under vehicular communication bandwidth and latency constraints. In this work, we propose a semantic V2X framework in which RSU-mounted cameras generate spatiotemporal semantic embeddings of future frames using the Video Joint Embedding Predictive Architecture (V-JEPA). To evaluate the system, we construct a digital twin of an urban traffic environment enabling the generation of d verse traffic scenarios with both safe and collision events. These embeddings of the future frame, extracted from V-JEPA, capture task-relevant traffic dynamics and are transmitted via V2X links to vehicles, where a lightweight attentive probe and classifier decode them to predict imminent collisions. By transmitting only semantic embeddings instead of raw frames, the proposed system significantly reduces communication overhead while maintaining predictive accuracy. Experimental results demonstrate that the framework with an appropriate processing method achieves a 10% F1-score improvement for collision prediction while reducing transmission requirements by four orders of magnitude compared to raw video. This validates the potential of semantic V2X communication to enable cooperative, real-time collision prediction in ITS.

</details>


### [185] [Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification](https://arxiv.org/abs/2601.17228)
*Tengyue Zhang,Ruiwen Ding,Luoting Zhuang,Yuxiao Wu,Erika F. Rodriguez,William Hsu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出一种基于潜在扩散模型的半监督域自适应框架，通过生成保持组织形态且具有目标域特征的合成图像，改善计算病理学中的域泛化问题。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中的深度学习模型常因域偏移而无法跨队列和机构泛化。现有方法要么无法利用目标域的无标签数据，要么依赖可能扭曲组织结构的图像到图像翻译。

Method: 提出半监督域自适应框架，使用在源域和目标域无标签数据上训练的潜在扩散模型，通过条件化（基础模型特征、队列身份、组织制备方法）生成保持组织形态且具有目标域外观特征的合成图像，用于训练下游分类器。

Result: 在肺腺癌预后任务中，该方法显著提升了目标域测试集性能：加权F1分数从0.611提升至0.706，宏观F1分数从0.641提升至0.716，且未降低源域性能。

Conclusion: 基于目标感知的扩散模型合成数据增强为改善计算病理学中的域泛化提供了有前景且有效的方法。

Abstract: Deep learning models in computational pathology often fail to generalize across cohorts and institutions due to domain shift. Existing approaches either fail to leverage unlabeled data from the target domain or rely on image-to-image translation, which can distort tissue structures and compromise model accuracy. In this work, we propose a semi-supervised domain adaptation (SSDA) framework that utilizes a latent diffusion model trained on unlabeled data from both the source and target domains to generate morphology-preserving and target-aware synthetic images. By conditioning the diffusion model on foundation model features, cohort identity, and tissue preparation method, we preserve tissue structure in the source domain while introducing target-domain appearance characteristics. The target-aware synthetic images, combined with real, labeled images from the source cohort, are subsequently used to train a downstream classifier, which is then tested on the target cohort. The effectiveness of the proposed SSDA framework is demonstrated on the task of lung adenocarcinoma prognostication. The proposed augmentation yielded substantially better performance on the held-out test set from the target cohort, without degrading source-cohort performance. The approach improved the weighted F1 score on the target-cohort held-out test set from 0.611 to 0.706 and the macro F1 score from 0.641 to 0.716. Our results demonstrate that target-aware diffusion-based synthetic data augmentation provides a promising and effective approach for improving domain generalization in computational pathology.

</details>


### [186] [C-RADIOv4 (Tech Report)](https://arxiv.org/abs/2601.17237)
*Mike Ranzinger,Greg Heinrich,Collin McCarthy,Jan Kautz,Andrew Tao,Bryan Catanzaro,Pavlo Molchanov*

Main category: cs.CV

Relevance: 35.0

TL;DR: C-RADIOv4是基于多教师蒸馏的视觉骨干网络，通过整合SigLIP2、DINOv3和SAM3三个教师模型的能力，在相同计算复杂度下提升了关键下游任务性能，并增强了任意分辨率支持。


<details>
  <summary>Details</summary>
Motivation: 通过多教师蒸馏方法，构建一个统一的学生模型，能够保留并改进多个教师模型的独特能力，从而获得更强大的视觉表示学习能力。

Method: 采用多教师蒸馏框架，使用SigLIP2、DINOv3和SAM3作为教师模型进行知识蒸馏。提供SO400M（412M参数）和H（631M参数）两个变体，并重新引入ViTDet选项以提高高分辨率下的效率。

Result: 在相同计算复杂度下，C-RADIOv4在核心指标上有所改进，获得了SAM3的新能力，增强了任意分辨率支持，并通过ViTDet选项显著提高了高分辨率处理效率。

Conclusion: C-RADIOv4通过多教师蒸馏成功整合了多个先进视觉模型的优势，在保持计算效率的同时提升了性能，并提供了更灵活的部署选项。

Abstract: By leveraging multi-teacher distillation, agglomerative vision backbones provide a unified student model that retains and improves the distinct capabilities of multiple teachers. In this tech report, we describe the most recent release of the C-RADIO family of models, C-RADIOv4, which builds upon AM-RADIO/RADIOv2.5 in design, offering strong improvements on key downstream tasks at the same computational complexity. We release -SO400M (412M params), and -H (631M) model variants, both trained with an updated set of teachers: SigLIP2, DINOv3, and SAM3. In addition to improvements on core metrics and new capabilities from imitating SAM3, the C-RADIOv4 model family further improves any-resolution support, brings back the ViTDet option for drastically enhanced efficiency at high-resolution, and comes with a permissive license.

</details>


### [187] [Inference-Time Loss-Guided Colour Preservation in Diffusion Sampling](https://arxiv.org/abs/2601.17259)
*Angad Singh Ahuja,Aarush Ram Anandh*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出一种无需训练的推理时颜色控制方法，通过区域约束的颜色保持技术，在文本到图像扩散模型中实现精确的颜色控制


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散系统在颜色控制方面存在持续失败模式，特别是在设计导向的工作流程中，需要满足用户指定的颜色目标。现有方法难以实现精确的颜色控制，尤其是在需要满足特定颜色约束的场景下。

Method: 1) 基于感兴趣区域(ROI)的修复技术实现空间选择性；2) 背景潜在重新施加防止ROI外颜色漂移；3) 通过梯度引导进行潜在微调，使用CIE Lab和线性RGB空间定义的复合损失函数；4) 损失函数不仅控制ROI平均颜色，还通过CVaR风格和软最大值惩罚控制像素级误差分布的尾部；5) 采用延迟启动门控和时间相关调度来稳定去噪步骤中的引导。

Result: 该方法提供了一种实用的、无需训练的机制，用于实现目标颜色遵循，可以集成到标准的Stable Diffusion修复流程中。相比仅控制平均颜色的基线方法，本方法能避免感知显著的局部失败。

Conclusion: 提出的推理时、区域约束的颜色保持方法能够有效解决扩散模型中精确颜色控制的挑战，为设计导向的工作流程提供了实用的解决方案。

Abstract: Precise color control remains a persistent failure mode in text-to-image diffusion systems, particularly in design-oriented workflows where outputs must satisfy explicit, user-specified color targets. We present an inference-time, region-constrained color preservation method that steers a pretrained diffusion model without any additional training. Our approach combines (i) ROI-based inpainting for spatial selectivity, (ii) background-latent re-imposition to prevent color drift outside the ROI, and (iii) latent nudging via gradient guidance using a composite loss defined in CIE Lab and linear RGB. The loss is constructed to control not only the mean ROI color but also the tail of the pixelwise error distribution through CVaR-style and soft-maximum penalties, with a late-start gate and a time-dependent schedule to stabilize guidance across denoising steps. We show that mean-only baselines can satisfy average color constraints while producing perceptually salient local failures, motivating our distribution-aware objective. The resulting method provides a practical, training-free mechanism for targeted color adherence that can be integrated into standard Stable Diffusion inpainting pipelines.

</details>


### [188] [Dynamic Meta-Ensemble Framework for Efficient and Accurate Deep Learning in Plant Leaf Disease Detection on Resource-Constrained Edge Devices](https://arxiv.org/abs/2601.17290)
*Weloday Fikadu Moges,Jianmei Su,Amin Waqas*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出DMEF动态元集成框架，通过自适应权重机制动态组合三个轻量级CNN模型，在资源受限的边缘设备上实现高精度植物病害检测。


<details>
  <summary>Details</summary>
Motivation: 边缘设备（如IoT传感器、智能手机）的计算资源和能耗预算有限，限制了深度学习模型在植物病害检测中的部署。需要在高精度AI和实际田间应用之间架起桥梁。

Method: 使用动态元集成框架，自适应权重机制动态组合MobileNetV2、NASNetMobile和InceptionV3三个轻量CNN。通过优化准确率提升与计算效率之间的权衡来更新集成权重。

Result: 在土豆和玉米病害数据集上分别达到99.53%和96.61%的分类准确率，超越单模型和静态集成2.1%和6.3%。推理延迟<75ms，参数<100万。

Conclusion: DMEF在资源受限的边缘设备上实现了高精度植物病害诊断，展示了在边缘农业监测中的潜力，为可扩展的作物病害管理提供了可行方案。

Abstract: Deploying deep learning models for plant disease detection on edge devices such as IoT sensors, smartphones, and embedded systems is severely constrained by limited computational resources and energy budgets. To address this challenge, we introduce a novel Dynamic Meta-Ensemble Framework (DMEF) for high-accuracy plant disease diagnosis under resource constraints. DMEF employs an adaptive weighting mechanism that dynamically combines the predictions of three lightweight convolutional neural networks (MobileNetV2, NASNetMobile, and InceptionV3) by optimizing a trade-off between accuracy improvements (DeltaAcc) and computational efficiency (model size). During training, the ensemble weights are updated iteratively, favoring models exhibiting high performance and low complexity. Extensive experiments on benchmark datasets for potato and maize diseases demonstrate state-of-the-art classification accuracies of 99.53% and 96.61%, respectively, surpassing standalone models and static ensembles by 2.1% and 6.3%. With computationally efficient inference latency (<75ms) and a compact footprint (<1 million parameters), DMEF shows strong potential for edge-based agricultural monitoring, suggesting viability for scalable crop disease management. This bridges the gap between high-accuracy AI and practical field applications.

</details>


### [189] [ClinNet: Evidential Ordinal Regression with Bilateral Asymmetry and Prototype Memory for Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.17315)
*Xiaoyang Li,Runni Zhou*

Main category: cs.CV

Relevance: 35.0

TL;DR: ClinNet是一个用于膝关节骨关节炎分级的可信赖框架，将KOA分级建模为证据序数回归问题，结合双侧不对称编码器、诊断记忆库和证据序数头，在性能上超越现有方法并提供不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎分级基于X光图像是一项关键但具有挑战性的任务，因为存在细微的等级间差异、标注不确定性以及疾病进展的固有顺序性。传统深度学习方法通常将其视为确定性多类分类问题，忽略了退化的连续进展和专家标注的不确定性。

Method: 提出ClinNet框架，包含三个关键组件：1) 双侧不对称编码器，显式建模内侧-外侧结构差异；2) 诊断记忆库，维护类别原型以稳定特征表示；3) 基于正态逆伽马分布的证据序数头，联合估计连续KL分级和认知不确定性。

Result: ClinNet实现了0.892的二次加权Kappa和0.768的准确率，在统计上显著优于最先进的基线方法(p < 0.001)。模型的不确定性估计成功标记了分布外样本和潜在误诊，为安全临床部署铺平了道路。

Conclusion: ClinNet通过将KOA分级建模为证据序数回归问题，不仅提高了分级性能，还提供了可靠的不确定性估计，增强了临床部署的可信度，为医学图像分析中的不确定性建模提供了有价值的框架。

Abstract: Knee osteoarthritis (KOA) grading based on radiographic images is a critical yet challenging task due to subtle inter-grade differences, annotation uncertainty, and the inherently ordinal nature of disease progression. Conventional deep learning approaches typically formulate this problem as deterministic multi-class classification, ignoring both the continuous progression of degeneration and the uncertainty in expert annotations. In this work, we propose ClinNet, a novel trustworthy framework that addresses KOA grading as an evidential ordinal regression problem. The proposed method integrates three key components: (1) a Bilateral Asymmetry Encoder (BAE) that explicitly models medial-lateral structural discrepancies; (2) a Diagnostic Memory Bank that maintains class-wise prototypes to stabilize feature representations; and (3) an Evidential Ordinal Head based on the Normal-Inverse-Gamma (NIG) distribution to jointly estimate continuous KL grades and epistemic uncertainty. Extensive experiments demonstrate that ClinNet achieves a Quadratic Weighted Kappa of 0.892 and Accuracy of 0.768, statistically outperforming state-of-the-art baselines (p < 0.001). Crucially, we demonstrate that the model's uncertainty estimates successfully flag out-of-distribution samples and potential misdiagnoses, paving the way for safe clinical deployment.

</details>


### [190] [Learning with Geometric Priors in U-Net Variants for Polyp Segmentation](https://arxiv.org/abs/2601.17331)
*Fabian Vazquez,Jose A. Nuñez,Diego Adame,Alissen Moreno,Augustin Zhan,Huimin Li,Jinghao Yang,Haoteng Tang,Bin Fu,Pengfei Gu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出几何先验引导模块(GPM)，将深度图几何先验注入U-Net架构，提升息肉分割在低对比度场景下的性能


<details>
  <summary>Details</summary>
Motivation: 现有CNN、Transformer和Mamba-based U-Net变体在息肉分割中难以捕捉几何和结构线索，特别是在低对比度或杂乱结肠镜场景下

Method: 1) 在模拟ColonDepth数据集上微调VGGT以估计息肉图像深度图；2) 设计GPM模块将几何先验编码到编码器特征图中；3) 使用空间和通道注意力机制精炼特征；4) 模块可即插即用到各种U-Net变体

Result: 在五个公共息肉分割数据集上的实验显示，该方法在三个强基线上取得一致性能提升

Conclusion: GPM通过注入显式几何先验有效提升了息肉分割的准确性和鲁棒性，特别是在具有挑战性的结肠镜场景中

Abstract: Accurate and robust polyp segmentation is essential for early colorectal cancer detection and for computer-aided diagnosis. While convolutional neural network-, Transformer-, and Mamba-based U-Net variants have achieved strong performance, they still struggle to capture geometric and structural cues, especially in low-contrast or cluttered colonoscopy scenes. To address this challenge, we propose a novel Geometric Prior-guided Module (GPM) that injects explicit geometric priors into U-Net-based architectures for polyp segmentation. Specifically, we fine-tune the Visual Geometry Grounded Transformer (VGGT) on a simulated ColonDepth dataset to estimate depth maps of polyp images tailored to the endoscopic domain. These depth maps are then processed by GPM to encode geometric priors into the encoder's feature maps, where they are further refined using spatial and channel attention mechanisms that emphasize both local spatial and global channel information. GPM is plug-and-play and can be seamlessly integrated into diverse U-Net variants. Extensive experiments on five public polyp segmentation datasets demonstrate consistent gains over three strong baselines. Code and the generated depth maps are available at: https://github.com/fvazqu/GPM-PolypSeg

</details>


### [191] [STARS: Shared-specific Translation and Alignment for missing-modality Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2601.17342)
*Tong Wang,Xiaodong Zhang,Guanzhou Chen,Jiaqi Wang,Chenxi Liu,Xiaoliang Tan,Wenchao Guo,Xuyang Li,Xuanrui Wang,Zifan Wang*

Main category: cs.CV

Relevance: 35.0

TL;DR: STARS是一个用于不完整多模态输入的鲁棒语义分割框架，通过非对称对齐机制和像素级语义采样对齐来解决遥感数据中模态缺失问题


<details>
  <summary>Details</summary>
Motivation: 多模态遥感技术通过整合光学图像、SAR和DSM等异构数据来增强地表语义理解，但在实际应用中模态数据缺失（如光学或DSM）是常见且严重的挑战，导致传统多模态融合模型性能下降。现有方法仍面临特征崩溃和恢复特征过于泛化等限制。

Method: 提出STARS框架，包含两个关键设计：1) 非对称对齐机制，结合双向翻译和停止梯度，有效防止特征崩溃并降低对超参数的敏感性；2) 像素级语义采样对齐策略，结合类别平衡像素采样和跨模态语义对齐损失，缓解由严重类别不平衡引起的对齐失败，改善少数类识别。

Result: 论文声称STARS框架能够有效处理不完整多模态输入，防止特征崩溃，提高对少数类别的识别能力，并降低对超参数的敏感性。

Conclusion: STARS为解决遥感多模态数据缺失问题提供了一个鲁棒的语义分割框架，通过创新的对齐机制和采样策略克服了现有方法的局限性。

Abstract: Multimodal remote sensing technology significantly enhances the understanding of surface semantics by integrating heterogeneous data such as optical images, Synthetic Aperture Radar (SAR), and Digital Surface Models (DSM). However, in practical applications, the missing of modality data (e.g., optical or DSM) is a common and severe challenge, which leads to performance decline in traditional multimodal fusion models. Existing methods for addressing missing modalities still face limitations, including feature collapse and overly generalized recovered features. To address these issues, we propose \textbf{STARS} (\textbf{S}hared-specific \textbf{T}ranslation and \textbf{A}lignment for missing-modality \textbf{R}emote \textbf{S}ensing), a robust semantic segmentation framework for incomplete multimodal inputs. STARS is built on two key designs. First, we introduce an asymmetric alignment mechanism with bidirectional translation and stop-gradient, which effectively prevents feature collapse and reduces sensitivity to hyperparameters. Second, we propose a Pixel-level Semantic sampling Alignment (PSA) strategy that combines class-balanced pixel sampling with cross-modality semantic alignment loss, to mitigate alignment failures caused by severe class imbalance and improve minority-class recognition.

</details>


### [192] [UCAD: Uncertainty-guided Contour-aware Displacement for semi-supervised medical image segmentation](https://arxiv.org/abs/2601.17366)
*Chengbo Ding,Fenghe Tang,Shaohua Kevin Zhou*

Main category: cs.CV

Relevance: 35.0

TL;DR: UCAD提出了一种不确定性引导的轮廓感知位移框架，用于半监督医学图像分割，通过超像素生成解剖一致区域，并利用不确定性指导选择具有挑战性的区域进行位移，以增强一致性学习。


<details>
  <summary>Details</summary>
Motivation: 现有半监督分割中的位移策略仅操作矩形区域，忽略了解剖结构，导致边界扭曲和语义不一致。为了解决这些问题，需要一种能够保留轮廓感知语义并增强一致性学习的方法。

Method: 1. 使用超像素生成与解剖边界对齐的解剖一致区域；2. 采用不确定性引导的选择机制，选择性地位移具有挑战性的区域以进行更好的一致性学习；3. 提出动态不确定性加权一致性损失，自适应稳定训练并有效正则化未标记区域。

Result: 大量实验表明，UCAD在有限标注条件下，始终优于最先进的半监督分割方法，实现了卓越的分割精度。

Conclusion: UCAD框架通过结合解剖结构感知和不确定性引导，有效解决了半监督医学图像分割中的边界扭曲和语义不一致问题，在有限标注下实现了更好的分割性能。

Abstract: Existing displacement strategies in semi-supervised segmentation only operate on rectangular regions, ignoring anatomical structures and resulting in boundary distortions and semantic inconsistency. To address these issues, we propose UCAD, an Uncertainty-Guided Contour-Aware Displacement framework for semi-supervised medical image segmentation that preserves contour-aware semantics while enhancing consistency learning. Our UCAD leverages superpixels to generate anatomically coherent regions aligned with anatomy boundaries, and an uncertainty-guided selection mechanism to selectively displace challenging regions for better consistency learning. We further propose a dynamic uncertainty-weighted consistency loss, which adaptively stabilizes training and effectively regularizes the model on unlabeled regions. Extensive experiments demonstrate that UCAD consistently outperforms state-of-the-art semi-supervised segmentation methods, achieving superior segmentation accuracy under limited annotation. The code is available at:https://github.com/dcb937/UCAD.

</details>


### [193] [HAAF: Hierarchical Adaptation and Alignment of Foundation Models for Few-Shot Pathology Anomaly Detection](https://arxiv.org/abs/2601.17405)
*Chunze Yang,Wenjie Zhao,Yue Tang,Junbo Lu,Jiusong Ge,Qidong Liu,Zeyu Gao,Chen Li*

Main category: cs.CV

Relevance: 35.0

TL;DR: HAAF框架通过跨层级尺度对齐机制解决病理图像分析中的粒度不匹配问题，在低资源场景下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 精准病理学依赖于在特定ROI区域内检测细粒度形态异常，但现有视觉语言模型存在粒度不匹配问题，通用表示无法解析细微缺陷，且当前方法将模态视为独立流，未能将语义提示与ROI特定视觉上下文相结合。

Method: 提出分层适应与对齐框架(HAAF)，核心是跨层级尺度对齐(CLSA)机制，强制顺序校准：视觉特征首先注入文本提示生成内容自适应描述符，然后空间引导视觉编码器聚焦异常。采用双分支推理策略整合语义分数与几何原型以确保少样本设置下的稳定性。

Result: 在四个基准测试中，HAAF显著优于最先进方法，在低资源场景下能有效扩展至领域特定骨干网络(如CONCH)。

Conclusion: HAAF通过层次化跨模态对齐有效解决了病理图像分析中的粒度不匹配问题，为细粒度视觉语言任务提供了有效的适应框架。

Abstract: Precision pathology relies on detecting fine-grained morphological abnormalities within specific Regions of Interest (ROIs), as these local, texture-rich cues - rather than global slide contexts - drive expert diagnostic reasoning. While Vision-Language (V-L) models promise data efficiency by leveraging semantic priors, adapting them faces a critical Granularity Mismatch, where generic representations fail to resolve such subtle defects. Current adaptation methods often treat modalities as independent streams, failing to ground semantic prompts in ROI-specific visual contexts. To bridge this gap, we propose the Hierarchical Adaptation and Alignment Framework (HAAF). At its core is a novel Cross-Level Scaled Alignment (CLSA) mechanism that enforces a sequential calibration order: visual features first inject context into text prompts to generate content-adaptive descriptors, which then spatially guide the visual encoder to spotlight anomalies. Additionally, a dual-branch inference strategy integrates semantic scores with geometric prototypes to ensure stability in few-shot settings. Experiments on four benchmarks show HAAF significantly outperforms state-of-the-art methods and effectively scales with domain-specific backbones (e.g., CONCH) in low-resource scenarios.

</details>


### [194] [Coronary Artery Segmentation and Vessel-Type Classification in X-Ray Angiography](https://arxiv.org/abs/2601.17429)
*Mehdi Yousefzadeh,Siavash Shirzadeh Barough,Ashkan Fakharifar,Yashar Tayyarazad,Narges Eghbali,Mohaddeseh Mozaffari,Hoda Taeb,Negar Sadat Rafiee Tabatabaee,Parsa Esfahanian,Ghazaleh Sadeghi Gohar,Amineh Safavirad,Saeideh Mazloomzadeh,Ehsan khalilipur,Armin Elahifar,Majid Maleki*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一种用于X射线冠状动脉造影（XCA）的血管分割和血管类型标记方法，通过结合传统滤波器的自适应参数调整和深度学习模型，提高了冠状动脉分割的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: XCA是评估冠状动脉疾病的临床金标准，但由于低对比度、运动伪影、血管重叠和导管干扰等问题，常规数据中的血管分割存在困难。可靠的血管分割和血管类型标记对于冠状动脉分析和下游测量至关重要。

Method: 1) 从670个电影序列中选择最佳帧；2) 应用联合超分辨率和增强；3) 基准测试传统血管滤波器（Meijering, Frangi, Sato）的三种参数设置方式；4) 使用深度学习模型（U-Net, FPN, Swin Transformer）进行分割；5) 第二阶段进行血管类型标记（LAD, LCX, RCA）；6) 在公开DCA1数据集上进行外部评估。

Result: SVR每图像参数调整显著改善传统滤波器的Dice分数（Frangi: 0.759 vs 0.741）。FPN模型在冠状动脉分割中表现最佳（Dice 0.914），合并冠状动脉+导管标签进一步提升至0.931。在外部测试中，Dice下降至0.798-0.814，但轻量级域内微调可恢复至0.881-0.882。血管类型标记准确率达95.4%-98.5%。

Conclusion: 学习的每图像参数调整增强了传统管道，而高分辨率FPN模型和合并标签监督提高了稳定性和外部迁移能力，仅需适度适应即可获得良好性能。

Abstract: X-ray coronary angiography (XCA) is the clinical reference standard for assessing coronary artery disease, yet quantitative analysis is limited by the difficulty of robust vessel segmentation in routine data. Low contrast, motion, foreshortening, overlap, and catheter confounding degrade segmentation and contribute to domain shift across centers. Reliable segmentation, together with vessel-type labeling, enables vessel-specific coronary analytics and downstream measurements that depend on anatomical localization. From 670 cine sequences (407 subjects), we select a best frame near peak opacification using a low-intensity histogram criterion and apply joint super-resolution and enhancement. We benchmark classical Meijering, Frangi, and Sato vesselness filters under per-image oracle tuning, a single global mean setting, and per-image parameter prediction via Support Vector Regression (SVR). Neural baselines include U-Net, FPN, and a Swin Transformer, trained with coronary-only and merged coronary+catheter supervision. A second stage assigns vessel identity (LAD, LCX, RCA). External evaluation uses the public DCA1 cohort. SVR per-image tuning improves Dice over global means for all classical filters (e.g., Frangi: 0.759 vs. 0.741). Among deep models, FPN attains 0.914+/-0.007 Dice (coronary-only), and merged coronary+catheter labels further improve to 0.931+/-0.006. On DCA1 as a strict external test, Dice drops to 0.798 (coronary-only) and 0.814 (merged), while light in-domain fine-tuning recovers to 0.881+/-0.014 and 0.882+/-0.015. Vessel-type labeling achieves 98.5% accuracy (Dice 0.844) for RCA, 95.4% (0.786) for LAD, and 96.2% (0.794) for LCX. Learned per-image tuning strengthens classical pipelines, while high-resolution FPN models and merged-label supervision improve stability and external transfer with modest adaptation.

</details>


### [195] [FMIR, a foundation model-based Image Registration Framework for Robust Image Registration](https://arxiv.org/abs/2601.17529)
*Fengting Zhang,Yue He,Qinghao Liu,Yaonan Wang,Xiang Chen,Hang Zhang*

Main category: cs.CV

Relevance: 35.0

TL;DR: FMIR是一个基于基础模型的医学图像配准框架，通过基础模型特征编码器提取解剖结构，结合通用配准头，在单一数据集上训练即可实现领域内SOTA性能，同时保持对领域外图像的鲁棒配准能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学图像配准中实现了前所未有的速度，但其临床应用受到泛化能力有限的阻碍，特别是在医学数据集通常规模较小的情况下。当前方法难以超越训练域进行泛化，这是医学图像配准的一个关键弱点。

Method: FMIR框架结合了基于基础模型的特征编码器（用于提取解剖结构）和通用配准头。采用通道正则化策略，仅需在单个数据集上进行训练。基础模型特征编码器能够捕捉通用的解剖结构表示，而通道正则化有助于提升模型的泛化能力。

Result: FMIR在领域内实现了最先进的性能，同时在领域外图像上保持了鲁棒的配准能力。这表明即使在有限资源下，也能构建可泛化的医学成像基础模型。

Conclusion: FMIR为构建具有有限资源的可泛化医学成像基础模型提供了一条可行路径，解决了深度学习医学图像配准中的泛化瓶颈问题。

Abstract: Deep learning has revolutionized medical image registration by achieving unprecedented speeds, yet its clinical application is hindered by a limited ability to generalize beyond the training domain, a critical weakness given the typically small scale of medical datasets. In this paper, we introduce FMIR, a foundation model-based registration framework that overcomes this limitation.Combining a foundation model-based feature encoder for extracting anatomical structures with a general registration head, and trained with a channel regularization strategy on just a single dataset, FMIR achieves state-of-the-art(SOTA) in-domain performance while maintaining robust registration on out-of-domain images.Our approach demonstrates a viable path toward building generalizable medical imaging foundation models with limited resources. The code is available at https://github.com/Monday0328/FMIR.git.

</details>


### [196] [OTI: A Model-free and Visually Interpretable Measure of Image Attackability](https://arxiv.org/abs/2601.17536)
*Jiaming Liang,Haowei Liu,Chi-Man Pun*

Main category: cs.CV

Relevance: 35.0

TL;DR: 本文提出了一种新颖的模型无关且视觉可解释的图像攻击性度量方法——对象纹理强度（OTI），用于评估图像对对抗性攻击的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管神经网络取得了巨大成功，但良性图像可能被对抗性扰动欺骗。有趣的是，不同图像具有不同的攻击性：给定攻击配置，有些图像容易被破坏，而另一些则更具抵抗力。评估图像攻击性在主动学习、对抗训练和攻击增强中具有重要应用。现有方法稀少且存在两大局限：1）依赖模型代理提供先验知识（如梯度或最小扰动）来提取模型依赖的图像特征，但实践中许多任务特定模型不易获取；2）提取的特征缺乏视觉可解释性，模糊了与图像的直接关系。

Method: 提出对象纹理强度（OTI），这是一种模型无关且视觉可解释的图像攻击性度量方法。OTI将图像攻击性量化为图像语义对象的纹理强度。从理论上，从决策边界以及对抗性扰动的中高频特性角度描述了OTI的原理。

Result: 综合实验表明，OTI是有效且计算高效的。该方法为对抗性机器学习社区提供了对攻击性的视觉理解。

Conclusion: OTI解决了现有攻击性度量方法的局限性，提供了一种无需模型访问权限且具有视觉可解释性的解决方案，有助于更好地理解和评估图像对对抗性攻击的脆弱性。

Abstract: Despite the tremendous success of neural networks, benign images can be corrupted by adversarial perturbations to deceive these models. Intriguingly, images differ in their attackability. Specifically, given an attack configuration, some images are easily corrupted, whereas others are more resistant. Evaluating image attackability has important applications in active learning, adversarial training, and attack enhancement. This prompts a growing interest in developing attackability measures. However, existing methods are scarce and suffer from two major limitations: (1) They rely on a model proxy to provide prior knowledge (e.g., gradients or minimal perturbation) to extract model-dependent image features. Unfortunately, in practice, many task-specific models are not readily accessible. (2) Extracted features characterizing image attackability lack visual interpretability, obscuring their direct relationship with the images. To address these, we propose a novel Object Texture Intensity (OTI), a model-free and visually interpretable measure of image attackability, which measures image attackability as the texture intensity of the image's semantic object. Theoretically, we describe the principles of OTI from the perspectives of decision boundaries as well as the mid- and high-frequency characteristics of adversarial perturbations. Comprehensive experiments demonstrate that OTI is effective and computationally efficient. In addition, our OTI provides the adversarial machine learning community with a visual understanding of attackability.

</details>


### [197] [Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization](https://arxiv.org/abs/2601.17586)
*Sebastian Doerrich,Francesco Di Salvo,Jonas Alle,Christian Ledig*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出Stylizing ViT，一种用于医学图像领域泛化的Vision Transformer编码器，通过权重共享的注意力块同时进行自注意力（保持解剖一致性）和交叉注意力（风格迁移），在数据增强和测试时增强中显著提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析中深度学习模型面临领域和人口群体泛化问题，传统数据增强方法在显著领域偏移下效果有限，现有风格增强方法存在风格多样性不足或引入伪影的问题。

Method: 提出Stylizing ViT，采用权重共享的注意力块设计，同一注意力块既能通过自注意力保持解剖结构一致性，又能通过交叉注意力进行风格迁移，实现无伪影的风格化数据增强。

Result: 在组织病理学和皮肤病学三个图像分类任务上，相比现有方法提升高达13%的准确率，生成感知上可信的无伪影图像，测试时增强带来17%的性能提升。

Conclusion: Stylizing ViT通过创新的权重共享注意力机制，有效解决了医学图像领域泛化问题，在训练和推理阶段都能显著提升模型鲁棒性。

Abstract: Deep learning models in medical image analysis often struggle with generalizability across domains and demographic groups due to data heterogeneity and scarcity. Traditional augmentation improves robustness, but fails under substantial domain shifts. Recent advances in stylistic augmentation enhance domain generalization by varying image styles but fall short in terms of style diversity or by introducing artifacts into the generated images. To address these limitations, we propose Stylizing ViT, a novel Vision Transformer encoder that utilizes weight-shared attention blocks for both self- and cross-attention. This design allows the same attention block to maintain anatomical consistency through self-attention while performing style transfer via cross-attention. We assess the effectiveness of our method for domain generalization by employing it for data augmentation on three distinct image classification tasks in the context of histopathology and dermatology. Results demonstrate an improved robustness (up to +13% accuracy) over the state of the art while generating perceptually convincing images without artifacts. Additionally, we show that Stylizing ViT is effective beyond training, achieving a 17% performance improvement during inference when used for test-time augmentation. The source code is available at https://github.com/sdoerrich97/stylizing-vit .

</details>


### [198] [Training-Free Text-to-Image Compositional Food Generation via Prompt Grafting](https://arxiv.org/abs/2601.17666)
*Xinyue Pan,Yuhao Chen,Fengqing Zhu*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出Prompt Grafting (PG)训练免费框架，通过两阶段布局提示和文本嫁接，解决多食物图像生成中的物体纠缠问题，实现可控的食物分离与混合。


<details>
  <summary>Details</summary>
Motivation: 现实世界餐食图像通常包含多种食物，而现有文本到图像扩散模型在生成多食物图像时存在物体纠缠问题（如米饭和汤融合），这影响了基于图像的膳食评估和食谱可视化等应用。

Method: 提出Prompt Grafting (PG)训练免费框架：1）第一阶段使用布局提示建立不同区域，2）第二阶段在布局稳定后将目标提示嫁接到相应区域。框架允许用户通过编辑布局安排来控制哪些食物应保持分离或故意混合。

Result: 在两个食物数据集上，该方法显著提高了目标物体的存在率，并提供了可控分离的定性证据。

Conclusion: PG框架有效解决了多食物图像生成中的物体纠缠问题，通过结合显式空间提示和隐式布局指导，实现了对食物分离与混合的可控生成。

Abstract: Real-world meal images often contain multiple food items, making reliable compositional food image generation important for applications such as image-based dietary assessment, where multi-food data augmentation is needed, and recipe visualization. However, modern text-to-image diffusion models struggle to generate accurate multi-food images due to object entanglement, where adjacent foods (e.g., rice and soup) fuse together because many foods do not have clear boundaries. To address this challenge, we introduce Prompt Grafting (PG), a training-free framework that combines explicit spatial cues in text with implicit layout guidance during sampling. PG runs a two-stage process where a layout prompt first establishes distinct regions and the target prompt is grafted once layout formation stabilizes. The framework enables food entanglement control: users can specify which food items should remain separated or be intentionally mixed by editing the arrangement of layouts. Across two food datasets, our method significantly improves the presence of target objects and provides qualitative evidence of controllable separation.

</details>


### [199] [Frequency-aware Neural Representation for Videos](https://arxiv.org/abs/2601.17741)
*Jun Zhu,Xinfeng Zhang,Lv Tang,Junhao Jiang,Gai Zhang,Jia Wang*

Main category: cs.CV

Relevance: 35.0

TL;DR: FaNeRV是一种频率感知神经表示方法，通过显式解耦低频和高频分量来改进视频压缩，采用多分辨率监督策略和动态高频注入机制，显著提升了INR方法的率失真性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式神经表示（INR）的视频压缩框架存在固有的频谱偏差问题，倾向于低频分量，导致重建结果过于平滑，率失真性能不理想。需要一种能够有效处理高频细节的方法来提升视频重建质量。

Method: 1. 提出频率感知神经表示（FaNeRV），显式解耦低频和高频分量；2. 采用多分辨率监督策略，通过分阶段监督引导网络逐步捕获全局结构和细粒度纹理；3. 设计动态高频注入机制，自适应地强调挑战性区域；4. 构建频率分解网络模块，改进不同频谱带的特征建模。

Result: 在标准基准测试上的广泛实验表明，FaNeRV显著优于最先进的INR方法，并在率失真性能上与传统编解码器具有竞争力。

Conclusion: FaNeRV通过频率感知设计有效解决了INR中的频谱偏差问题，为视频压缩提供了一种高效且保真的神经表示方法，在保持INR优势的同时显著提升了重建质量。

Abstract: Implicit Neural Representations (INRs) have emerged as a promising paradigm for video compression. However, existing INR-based frameworks typically suffer from inherent spectral bias, which favors low-frequency components and leads to over-smoothed reconstructions and suboptimal rate-distortion performance. In this paper, we propose FaNeRV, a Frequency-aware Neural Representation for videos, which explicitly decouples low- and high-frequency components to enable efficient and faithful video reconstruction. FaNeRV introduces a multi-resolution supervision strategy that guides the network to progressively capture global structures and fine-grained textures through staged supervision . To further enhance high-frequency reconstruction, we propose a dynamic high-frequency injection mechanism that adaptively emphasizes challenging regions. In addition, we design a frequency-decomposed network module to improve feature modeling across different spectral bands. Extensive experiments on standard benchmarks demonstrate that FaNeRV significantly outperforms state-of-the-art INR methods and achieves competitive rate-distortion performance against traditional codecs.

</details>


### [200] [Video Compression with Hierarchical Temporal Neural Representation](https://arxiv.org/abs/2601.17743)
*Jun Zhu,Xinfeng Zhang,Lv Tang,Junhao Jiang,Gai Zhang,Jia Wang*

Main category: cs.CV

Relevance: 35.0

TL;DR: TeNeRV提出了一种分层时间神经表示方法，通过帧间特征融合和GoP自适应调制来增强视频压缩中的时间依赖性建模，在率失真性能上优于现有INR方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式神经表示(INR)的视频压缩方法通常将时间维度作为独立输入处理，限制了捕捉复杂时间依赖性的能力。需要一种能够有效建模短期和长期时间依赖性的方法。

Method: TeNeRV包含两个核心组件：1)帧间特征融合(IFF)模块，聚合相邻帧特征以增强局部时间一致性和细粒度运动捕捉；2)GoP自适应调制(GAM)机制，将视频划分为图像组并学习组特定先验，通过调制网络参数实现自适应表示。

Result: 大量实验表明，TeNeRV在率失真性能上持续优于现有的INR方法，验证了所提方法的有效性。

Conclusion: TeNeRV通过分层时间建模有效解决了INR方法在视频压缩中的时间依赖性限制问题，为视频压缩提供了新的神经表示方法。

Abstract: Video compression has recently benefited from implicit neural representations (INRs), which model videos as continuous functions. INRs offer compact storage and flexible reconstruction, providing a promising alternative to traditional codecs. However, most existing INR-based methods treat the temporal dimension as an independent input, limiting their ability to capture complex temporal dependencies. To address this, we propose a Hierarchical Temporal Neural Representation for Videos, TeNeRV. TeNeRV integrates short- and long-term dependencies through two key components. First, an Inter-Frame Feature Fusion (IFF) module aggregates features from adjacent frames, enforcing local temporal coherence and capturing fine-grained motion. Second, a GoP-Adaptive Modulation (GAM) mechanism partitions videos into Groups-of-Pictures and learns group-specific priors. The mechanism modulates network parameters, enabling adaptive representations across different GoPs. Extensive experiments demonstrate that TeNeRV consistently outperforms existing INR-based methods in rate-distortion performance, validating the effectiveness of our proposed approach.

</details>


### [201] [Bridging Supervision Gaps: A Unified Framework for Remote Sensing Change Detection](https://arxiv.org/abs/2601.17747)
*Kaixuan Jiang,Chen Wu,Zhenghui Zhao,Chengxi Han*

Main category: cs.CV

Relevance: 35.0

TL;DR: UniCD是一个统一的遥感变化检测框架，通过耦合架构协同处理监督、弱监督和无监督任务，消除了架构壁垒并实现异构监督信号的深度耦合。


<details>
  <summary>Details</summary>
Motivation: 现实场景中像素级变化标签获取成本高，现有模型难以适应不同标注可用性的多样化场景，需要统一的框架来处理不同监督级别的变化检测任务。

Method: 采用共享编码器和多分支协同学习机制，包含三个监督特定分支：监督分支引入时空感知模块实现双时相特征融合；弱监督分支构建变化表示正则化；无监督分支提出语义先验驱动变化推理。

Result: 在主流数据集上，UniCD在三个任务上都达到最优性能，在弱监督和无监督场景下显著提升精度，在LEVIR-CD数据集上分别超过当前SOTA方法12.72%和12.37%。

Conclusion: UniCD通过统一框架有效解决了不同监督级别下的变化检测问题，实现了异构监督信号的协同优化，为遥感变化检测提供了灵活高效的解决方案。

Abstract: Change detection (CD) aims to identify surface changes from multi-temporal remote sensing imagery. In real-world scenarios, Pixel-level change labels are expensive to acquire, and existing models struggle to adapt to scenarios with diverse annotation availability. To tackle this challenge, we propose a unified change detection framework (UniCD), which collaboratively handles supervised, weakly-supervised, and unsupervised tasks through a coupled architecture. UniCD eliminates architectural barriers through a shared encoder and multi-branch collaborative learning mechanism, achieving deep coupling of heterogeneous supervision signals. Specifically, UniCD consists of three supervision-specific branches. In the supervision branch, UniCD introduces the spatial-temporal awareness module (STAM), achieving efficient synergistic fusion of bi-temporal features. In the weakly-supervised branch, we construct change representation regularization (CRR), which steers model convergence from coarse-grained activations toward coherent and separable change modeling. In the unsupervised branch, we propose semantic prior-driven change inference (SPCI), which transforms unsupervised tasks into controlled weakly-supervised path optimization. Experiments on mainstream datasets demonstrate that UniCD achieves optimal performance across three tasks. It exhibits significant accuracy improvements in weakly and unsupervised scenarios, surpassing current state-of-the-art by 12.72% and 12.37% on LEVIR-CD, respectively.

</details>


### [202] [Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment](https://arxiv.org/abs/2601.17862)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出轻量级量子增强域泛化框架，通过对抗训练和量子特征增强层提升医学影像AI在跨中心部署中的泛化能力，无需真实多中心标注数据。


<details>
  <summary>Details</summary>
Motivation: 医学影像AI模型在单中心表现良好，但在真实世界跨中心部署中因域偏移导致性能下降，限制了临床泛化能力。需要解决域泛化问题，特别是在计算资源受限的医疗环境中。

Method: 基于MobileNetV2的域不变编码器，包含三个关键组件：1) 多域成像偏移模拟（亮度、对比度、锐化、噪声扰动）；2) 梯度反转的域对抗训练；3) 轻量级量子特征增强层（参数化量子电路进行非线性特征映射和纠缠建模）。推理时采用测试时自适应策略。

Result: 在模拟多中心医学影像数据集上，该方法显著优于无域泛化或量子增强的基线模型，在未见域上表现更好，降低了域特定性能方差，提高了AUC和灵敏度。

Conclusion: 量子增强域泛化在受限计算资源下具有临床潜力，为混合量子-经典医学影像系统提供了可行范式，能有效应对域偏移挑战。

Abstract: Medical image artificial intelligence models often achieve strong performance in single-center or single-device settings, yet their effectiveness frequently deteriorates in real-world cross-center deployment due to domain shift, limiting clinical generalizability. To address this challenge, we propose a lightweight domain generalization framework with quantum-enhanced collaborative learning, enabling robust generalization to unseen target domains without relying on real multi-center labeled data. Specifically, a MobileNetV2-based domain-invariant encoder is constructed and optimized through three key components: (1) multi-domain imaging shift simulation using brightness, contrast, sharpening, and noise perturbations to emulate heterogeneous acquisition conditions; (2) domain-adversarial training with gradient reversal to suppress domain-discriminative features; and (3) a lightweight quantum feature enhancement layer that applies parameterized quantum circuits for nonlinear feature mapping and entanglement modeling. In addition, a test-time adaptation strategy is employed during inference to further alleviate distribution shifts. Experiments on simulated multi-center medical imaging datasets demonstrate that the proposed method significantly outperforms baseline models without domain generalization or quantum enhancement on unseen domains, achieving reduced domain-specific performance variance and improved AUC and sensitivity. These results highlight the clinical potential of quantum-enhanced domain generalization under constrained computational resources and provide a feasible paradigm for hybrid quantum--classical medical imaging systems.

</details>


### [203] [Quran-MD: A Fine-Grained Multilingual Multimodal Dataset of the Quran](https://arxiv.org/abs/2601.17880)
*Muhammad Umar Salman,Mohammad Areeb Qazi,Mohammed Talha Alam*

Main category: cs.CV

Relevance: 35.0

TL;DR: Quran MD是一个综合性的多模态古兰经数据集，集成了文本、语言学和音频维度，包含经文和单词级别的标注，支持32位不同诵经者的音频，适用于NLP、语音识别、语音合成等应用。


<details>
  <summary>Details</summary>
Motivation: 古兰经具有丰富的口述传统和复杂的语言学特征，但缺乏一个整合文本、音频和语言学信息的综合数据集。该研究旨在创建一个多模态数据集，以支持计算语言学方法在古兰经研究和伊斯兰数字研究中的应用。

Method: 构建了一个包含经文级别和单词级别标注的多模态数据集。经文级别包括阿拉伯原文、英文翻译和音标转写；单词级别包括阿拉伯文字、英文翻译、音标转写和对齐的音频片段。收集了32位不同诵经者的音频，涵盖多种诵经风格和方言差异。

Result: 创建了Quran MD数据集，提供了完整的古兰经多模态资源，支持自动语音识别、泰吉威德规则检测、古兰经文本到语音合成、多模态嵌入、语义检索、风格迁移和个性化教学系统等应用。

Conclusion: Quran MD数据集填补了古兰经多模态数据资源的空白，为计算语言学方法在古兰经研究中的应用奠定了基础，支持研究和社区应用，促进数字伊斯兰研究的发展。

Abstract: We present Quran MD, a comprehensive multimodal dataset of the Quran that integrates textual, linguistic, and audio dimensions at the verse and word levels. For each verse (ayah), the dataset provides its original Arabic text, English translation, and phonetic transliteration. To capture the rich oral tradition of Quranic recitation, we include verse-level audio from 32 distinct reciters, reflecting diverse recitation styles and dialectical nuances. At the word level, each token is paired with its corresponding Arabic script, English translation, transliteration, and an aligned audio recording, allowing fine-grained analysis of pronunciation, phonology, and semantic context. This dataset supports various applications, including natural language processing, speech recognition, text-to-speech synthesis, linguistic analysis, and digital Islamic studies. Bridging text and audio modalities across multiple reciters, this dataset provides a unique resource to advance computational approaches to Quranic recitation and study. Beyond enabling tasks such as ASR, tajweed detection, and Quranic TTS, it lays the foundation for multimodal embeddings, semantic retrieval, style transfer, and personalized tutoring systems that can support both research and community applications. The dataset is available at https://huggingface.co/datasets/Buraaq/quran-audio-text-dataset

</details>


### [204] [Masked Depth Modeling for Spatial Perception](https://arxiv.org/abs/2601.17895)
*Bin Tan,Changjiang Sun,Xiage Qin,Hanat Adai,Zelin Fu,Tianxiang Zhou,Han Zhang,Yinghao Xu,Xing Zhu,Yujun Shen,Nan Xue*

Main category: cs.CV

Relevance: 35.0

TL;DR: LingBot-Depth：通过掩码深度建模和自动数据筛选的深度补全模型，在精度和覆盖率上超越顶级RGB-D相机


<details>
  <summary>Details</summary>
Motivation: 空间视觉感知在自动驾驶、机器人操作等物理世界应用中至关重要。RGB-D相机虽然能获取像素对齐的度量深度，但受硬件限制和成像条件（如镜面或纹理缺失表面）影响，深度传感器存在不准确性。作者认为这些不准确性可视为反映潜在几何模糊性的"掩码"信号。

Method: 提出LingBot-Depth深度补全模型，利用视觉上下文通过掩码深度建模来优化深度图，并包含自动数据筛选流程以实现可扩展训练。

Result: 模型在深度精度和像素覆盖率方面超越顶级RGB-D相机。下游任务实验表明，LingBot-Depth在RGB和深度模态间提供了对齐的潜在表示。

Conclusion: LingBot-Depth通过掩码深度建模和自动数据筛选，有效解决了深度传感器的局限性，为空间感知社区提供了高质量的深度补全解决方案。

Abstract: Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as "masked" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.

</details>


### [205] [Feature-Space Generative Models for One-Shot Class-Incremental Learning](https://arxiv.org/abs/2601.17905)
*Jack Foster,Kirill Paramonov,Mete Ozay,Umberto Michieli*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出Gen1S方法，通过残差空间映射和生成建模改进单样本类增量学习，在多个基准测试中超越现有方法


<details>
  <summary>Details</summary>
Motivation: 解决单样本类增量学习(FSCIL)的挑战性问题，特别是在每个新类只有一个样本且不允许后续训练或模型修改的情况下，如何提高新类识别能力

Method: 1) 将原始嵌入空间映射到残差空间（减去类别原型）；2) 使用VAE或扩散模型学习基类残差的多模态分布；3) 利用这个结构先验改进新类识别

Result: Gen1S方法在多个基准测试和骨干架构上一致地超越了现有技术水平，显著提高了新类识别性能

Conclusion: 通过利用基类和新类嵌入之间的结构相似性，结合生成建模学习残差分布，可以有效解决单样本类增量学习问题

Abstract: Few-shot class-incremental learning (FSCIL) is a paradigm where a model, initially trained on a dataset of base classes, must adapt to an expanding problem space by recognizing novel classes with limited data. We focus on the challenging FSCIL setup where a model receives only a single sample (1-shot) for each novel class and no further training or model alterations are allowed after the base training phase. This makes generalization to novel classes particularly difficult. We propose a novel approach predicated on the hypothesis that base and novel class embeddings have structural similarity. We map the original embedding space into a residual space by subtracting the class prototype (i.e., the average class embedding) of input samples. Then, we leverage generative modeling with VAE or diffusion models to learn the multi-modal distribution of residuals over the base classes, and we use this as a valuable structural prior to improve recognition of novel classes. Our approach, Gen1S, consistently improves novel class recognition over the state of the art across multiple benchmarks and backbone architectures.

</details>


### [206] [UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders](https://arxiv.org/abs/2601.17950)
*Matthew Walmer,Saksham Suri,Anirud Aggarwal,Abhinav Shrivastava*

Main category: cs.CV

Relevance: 35.0

TL;DR: UPLiFT：一种通用像素密集轻量级特征变换架构，通过局部注意力算子实现高效的特征上采样，在保持SOTA性能的同时降低推理成本


<details>
  <summary>Details</summary>
Motivation: 当前任务无关特征上采样方法中，交叉注意力方法虽然性能好但效率低，面临与骨干网络相同的扩展问题。早期迭代上采样方法效率高但性能不足。需要一种既能保持高性能又能降低推理成本的特征上采样方法。

Method: 提出UPLiFT架构，采用迭代上采样方法，并引入高效的局部注意力算子。该算子使用完全局部的注意力池化公式，克服了先前迭代特征上采样方法的局限性，能在整个上采样过程中保持稳定的特征。

Result: UPLiFT在保持最先进性能的同时，推理成本低于现有的像素密集特征上采样器。在生成下游任务中，与最先进的耦合流匹配模型在VAE特征上采样方面达到竞争性性能。

Conclusion: UPLiFT提供了一种通用且高效的方法来创建更密集的特征，证明了迭代上采样方法仍能与交叉注意力方法竞争，并且能以更低的推理成本实现最先进的性能。

Abstract: The space of task-agnostic feature upsampling has emerged as a promising area of research to efficiently create denser features from pre-trained visual backbones. These methods act as a shortcut to achieve dense features for a fraction of the cost by learning to map low-resolution features to high-resolution versions. While early works in this space used iterative upsampling approaches, more recent works have switched to cross-attention-based methods, which risk falling into the same efficiency scaling problems of the backbones they are upsampling. In this work, we demonstrate that iterative upsampling methods can still compete with cross-attention-based methods; moreover, they can achieve state-of-the-art performance with lower inference costs. We propose UPLiFT, an architecture for Universal Pixel-dense Lightweight Feature Transforms. We also propose an efficient Local Attender operator to overcome the limitations of prior iterative feature upsampling methods. This operator uses an alternative attentional pooling formulation defined fully locally. We show that our Local Attender allows UPLiFT to maintain stable features throughout upsampling, enabling state-of-the-art performance with lower inference costs than existing pixel-dense feature upsamplers. In addition, we apply UPLiFT to generative downstream tasks and show that it achieves competitive performance with state-of-the-art Coupled Flow Matching models for VAE feature upsampling. Altogether, UPLiFT offers a versatile and efficient approach to creating denser features.

</details>


### [207] [Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling](https://arxiv.org/abs/2601.18049)
*Yunfei Qiu,Qiqiong Ma,Tianhua Lv,Li Fang,Shudong Zhou,Wei Yao*

Main category: cs.CV

Relevance: 35.0

TL;DR: 本文提出了一种新颖的半监督高光谱图像分类框架，通过整合空间先验信息和动态学习机制，解决了边界标签扩散和伪标签不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像标注成本高、样本有限，半监督学习面临边界标签扩散和伪标签不稳定等挑战，需要更鲁棒的分类方法。

Method: 1. 边缘感知超像素标签传播模块：整合边缘强度惩罚和邻域校正策略，缓解超像素分割中的标签扩散问题
2. 动态历史融合预测方法：维护历史预测并动态加权当前结果，平滑伪标签波动
3. 自适应三元样本分类策略：基于置信度和一致性度量，分层利用简单、模糊和困难样本
4. 动态可靠性增强伪标签框架：整合DHP和ATSC，实现时空一致性优化

Result: 在四个基准数据集上的评估表明，该方法能够保持优越的分类性能，有效解决了边界标签扩散和伪标签不稳定性问题。

Conclusion: 提出的框架通过整合空间先验信息和动态学习机制，显著提升了半监督高光谱图像分类的鲁棒性和性能。

Abstract: Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance.

</details>


### [208] [Text-Pass Filter: An Efficient Scene Text Detector](https://arxiv.org/abs/2601.18098)
*Chuang Yang,Haozhao Ma,Xu Han,Yuan Yuan,Qi Wang*

Main category: cs.CV

Relevance: 35.0

TL;DR: TPF（Text-Pass Filter）是一种用于任意形状文本检测的新方法，通过模拟带通滤波器原理，为每个文本构建特征-滤波器对，直接分割整个文本区域，避免传统收缩-掩码扩展策略的局限性，并能自然分离粘连文本。


<details>
  <summary>Details</summary>
Motivation: 现有文本检测方法采用收缩-掩码扩展策略，但收缩操作会丢失文本边缘的视觉特征，混淆前景与背景差异，对文本特征识别带来内在限制。需要一种能直接分割整个文本区域、避免这些限制并能自然分离粘连文本的方法。

Method: 1. TPF模拟带通滤波器原理，为每个文本构建独特的特征-滤波器对，在推理阶段通过滤波器提取匹配文本
2. 引入REU（强化集成单元）增强同一文本的特征一致性，扩大滤波器识别范围以处理长宽比大的带状文本
3. 引入FPU（前景先验单元）鼓励TPF区分前景与背景差异，提高特征-滤波器对质量

Result: 实验证明了REU和FPU的有效性，并展示了TPF在文本检测任务上的优越性。该方法能够实时检测文本，无需复杂的解码或后处理过程。

Conclusion: TPF通过模拟带通滤波器机制，提供了一种新颖的任意形状文本检测方法，能够直接分割整个文本区域，自然分离粘连文本，并实现实时检测，克服了传统方法的固有局限性。

Abstract: To pursue an efficient text assembling process, existing methods detect texts via the shrink-mask expansion strategy. However, the shrinking operation loses the visual features of text margins and confuses the foreground and background difference, which brings intrinsic limitations to recognize text features. We follow this issue and design Text-Pass Filter (TPF) for arbitrary-shaped text detection. It segments the whole text directly, which avoids the intrinsic limitations. It is noteworthy that different from previous whole text region-based methods, TPF can separate adhesive texts naturally without complex decoding or post-processing processes, which makes it possible for real-time text detection. Concretely, we find that the band-pass filter allows through components in a specified band of frequencies, called its passband but blocks components with frequencies above or below this band. It provides a natural idea for extracting whole texts separately. By simulating the band-pass filter, TPF constructs a unique feature-filter pair for each text. In the inference stage, every filter extracts the corresponding matched text by passing its pass-feature and blocking other features. Meanwhile, considering the large aspect ratio problem of ribbon-like texts makes it hard to recognize texts wholly, a Reinforcement Ensemble Unit (REU) is designed to enhance the feature consistency of the same text and to enlarge the filter's recognition field to help recognize whole texts. Furthermore, a Foreground Prior Unit (FPU) is introduced to encourage TPF to discriminate the difference between the foreground and background, which improves the feature-filter pair quality. Experiments demonstrate the effectiveness of REU and FPU while showing the TPF's superiority.

</details>


### [209] [Spatial-Conditioned Reasoning in Long-Egocentric Videos](https://arxiv.org/abs/2601.18100)
*James Tribble,Hao Wang,Si-En Hong,Chaoyi Zhou,Ashish Bastola,Siyu Huang,Abolfazl Razi*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文研究了显式空间信号对基于VLM的视频理解的影响，通过引入Sanpo-D数据集并融合深度图与RGB帧，发现深度感知表示能提升安全关键任务性能，但存在通用准确性与空间专业化之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 长时程自我中心视频由于视角漂移和缺乏持久几何上下文，给视觉导航带来挑战。尽管现有的视觉语言模型在图像和短视频推理上表现良好，但在长自我中心序列中的空间推理能力仍然有限。研究旨在探索显式空间信号如何影响基于VLM的视频理解，而不改变模型架构或推理过程。

Method: 1) 引入Sanpo-D数据集：对Google Sanpo数据集进行细粒度重新标注；2) 在导航导向的空间查询上对多个VLM进行基准测试；3) 研究输入级归纳偏置：融合深度图与RGB帧，评估其对空间推理的影响。

Result: 结果显示通用准确性与空间专业化之间存在权衡。深度感知和空间基础表示能显著提升安全关键任务（如行人和障碍物检测）的性能，表明显式空间信号能增强VLM在长时程自我中心视频中的空间推理能力。

Conclusion: 通过融合深度信息等显式空间信号，可以增强视觉语言模型在长时程自我中心视频中的空间推理能力，特别是在安全关键任务上，但需要在通用性能和空间专业化之间进行权衡。

Abstract: Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection.

</details>


### [210] [LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment](https://arxiv.org/abs/2601.18118)
*Daeyoung Kim*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出LungCRCT框架，利用因果表示学习分析肺癌进展的物理因果机制，实现因果干预分析和轻量级下游分类任务


<details>
  <summary>Details</summary>
Motivation: 肺癌早期症状不明显且易与其他呼吸系统疾病混淆，导致早期诊断困难。虽然基于CNN和ViT的AI模型在肺癌检测和分类任务上表现良好，但由于相关依赖性限制和可解释性差，难以扩展到肺癌治疗分析和因果干预分析。

Method: 提出LungCRCT框架，采用基于图自编码器的因果发现算法，结合距离相关性解纠缠和基于熵的图像重建优化，从肺癌进展的物理因果机制中提取因果表示。

Result: 该框架不仅支持肺癌治疗的因果干预分析，还在恶性肿瘤分类任务中实现了93.91%的AUC分数，同时保持了模型的轻量级特性。

Conclusion: LungCRCT通过因果表示学习克服了传统深度学习模型在肺癌分析中的局限性，为肺癌治疗分析和干预模拟提供了新的方法。

Abstract: Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%.

</details>


### [211] [Forward Consistency Learning with Gated Context Aggregation for Video Anomaly Detection](https://arxiv.org/abs/2601.18135)
*Jiahao Lyu,Minghua Zhao,Xuewen Huang,Yifei Chen,Shuangli Du,Jing Hu,Cheng Shi,Zhiyong Lv*

Main category: cs.CV

Relevance: 35.0

TL;DR: FoGA是一个轻量级视频异常检测模型，通过前向一致性学习和门控上下文聚合，仅用约200万参数实现高效边缘部署，在性能和效率间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测方法依赖大规模模型追求极致精度，难以在资源受限的边缘设备上部署；同时主流预测方法仅使用单帧未来预测误差，忽略了更长期时序信息的丰富约束。

Method: 提出基于Unet的方法，对连续帧进行特征提取，生成即时和前向预测；在跳跃连接中引入门控上下文聚合模块动态融合编码器和解码器特征；使用新颖的前向一致性损失联合优化，采用混合异常测量策略整合即时和前向帧的误差。

Result: FoGA在性能上显著优于最先进的竞争方法，运行速度高达155 FPS，在性能和效率指标间实现了优秀的平衡。

Conclusion: FoGA作为一个轻量级VAD模型，通过前向一致性学习和门控上下文聚合，在保持高性能的同时实现了边缘设备的高效部署，为实时监控系统提供了实用解决方案。

Abstract: As a crucial element of public security, video anomaly detection (VAD) aims to measure deviations from normal patterns for various events in real-time surveillance systems. However, most existing VAD methods rely on large-scale models to pursue extreme accuracy, limiting their feasibility on resource-limited edge devices. Moreover, mainstream prediction-based VAD detects anomalies using only single-frame future prediction errors, overlooking the richer constraints from longer-term temporal forward information. In this paper, we introduce FoGA, a lightweight VAD model that performs Forward consistency learning with Gated context Aggregation, containing about 2M parameters and tailored for potential edge devices. Specifically, we propose a Unet-based method that performs feature extraction on consecutive frames to generate both immediate and forward predictions. Then, we introduce a gated context aggregation module into the skip connections to dynamically fuse encoder and decoder features at the same spatial scale. Finally, the model is jointly optimized with a novel forward consistency loss, and a hybrid anomaly measurement strategy is adopted to integrate errors from both immediate and forward frames for more accurate detection. Extensive experiments demonstrate the effectiveness of the proposed method, which substantially outperforms state-of-the-art competing methods, running up to 155 FPS. Hence, our FoGA achieves an excellent trade-off between performance and the efficiency metric.

</details>


### [212] [MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models](https://arxiv.org/abs/2601.18192)
*Tian-Yi Zhou,Xuan-Hao Liu,Bao-Liang Lu,Wei-Long Zheng*

Main category: cs.CV

Relevance: 35.0

TL;DR: MindCine：利用多模态联合学习和预训练大EEG模型，从有限EEG数据中重建高保真动态视觉感知视频的新框架


<details>
  <summary>Details</summary>
Motivation: 解决EEG到视频重建的两个关键挑战：1) 现有方法仅对齐EEG与文本模态，忽略其他模态且容易过拟合；2) 数据稀缺导致训练难以收敛

Method: 1) 多模态联合学习策略，整合超越文本的多种模态；2) 利用预训练大EEG模型缓解数据稀缺问题，解码语义信息；3) 设计带因果注意力的Seq2Seq模型解码感知信息

Result: 在定性和定量评估中均优于现有最先进方法，证明了不同模态互补优势的有效性，以及大尺度EEG模型通过缓解数据稀缺问题进一步提升重建性能

Conclusion: MindCine框架成功解决了EEG到视频重建中的模态单一和数据稀缺问题，实现了在有限数据上的高保真视频重建，为脑机接口和神经科学应用提供了新方法

Abstract: Reconstructing human dynamic visual perception from electroencephalography (EEG) signals is of great research significance since EEG's non-invasiveness and high temporal resolution. However, EEG-to-video reconstruction remains challenging due to: 1) Single Modality: existing studies solely align EEG signals with the text modality, which ignores other modalities and are prone to suffer from overfitting problems; 2) Data Scarcity: current methods often have difficulty training to converge with limited EEG-video data. To solve the above problems, we propose a novel framework MindCine to achieve high-fidelity video reconstructions on limited data. We employ a multimodal joint learning strategy to incorporate beyond-text modalities in the training stage and leverage a pre-trained large EEG model to relieve the data scarcity issue for decoding semantic information, while a Seq2Seq model with causal attention is specifically designed for decoding perceptual information. Extensive experiments demonstrate that our model outperforms state-of-the-art methods both qualitatively and quantitatively. Additionally, the results underscore the effectiveness of the complementary strengths of different modalities and demonstrate that leveraging a large-scale EEG model can further enhance reconstruction performance by alleviating the challenges associated with limited data.

</details>


### [213] [A multimodal vision foundation model for generalizable knee pathology](https://arxiv.org/abs/2601.18250)
*Kang Yu,Dingyu Wang,Zimu Yuan,Nan Zhou,Jiajun Liu,Jiaxin Liu,Shanggui Liu,Yaoyan Zheng,Huishu Yuan,Di Huang,Dong Jiang*

Main category: cs.CV

Relevance: 35.0

TL;DR: OrthoFoundation是一个针对肌肉骨骼病理学的多模态视觉基础模型，使用120万未标记的膝关节X光和MRI图像进行自监督对比学习预训练，在14个下游任务中达到SOTA性能，并展现出卓越的跨解剖结构泛化能力。


<details>
  <summary>Details</summary>
Motivation: 肌肉骨骼疾病是全球残疾的主要原因，需要精确的医学影像解读。当前骨科AI方法依赖任务特定的监督学习，存在碎片化、需要大量标注数据、跨模态和临床场景泛化能力差等问题。该领域基础模型的发展受到大规模、高质量开源数据集稀缺的限制。

Method: 构建了包含120万未标记膝关节X光和MRI图像的预训练数据集，使用Dinov3骨干网络，通过自监督对比学习训练模型以获取稳健的放射学表征。

Result: 在14个下游任务中达到SOTA性能：X光骨关节炎诊断准确率优异，MRI结构损伤检测排名第一；仅需50%标注数据即可匹配监督基线；尽管在膝关节图像上预训练，却展现出对髋、肩、踝关节的卓越跨解剖结构泛化能力。

Conclusion: OrthoFoundation代表了肌肉骨骼影像通用AI的重要进展，通过从大规模多模态数据中学习基础的、关节无关的放射学语义，克服了传统模型的局限性，为减少标注负担和提高临床诊断准确性提供了稳健框架。

Abstract: Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice.

</details>


### [214] [SwipeGen: Bridging the Execution Gap in GUI Agents via Human-like Swipe Synthesis](https://arxiv.org/abs/2601.18305)
*Xuan Wang,Siyuan Su,Quantong Fu,Yongxiang Hu,Yangfan Zhou*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了SwipeGen自动化管道来合成类人滑动交互，构建了首个GUI代理滑动执行能力基准，并开发了GUISwiper代理，在滑动执行准确率上相比现有VLM基线提升了214%。


<details>
  <summary>Details</summary>
Motivation: 随着GUI代理的广泛应用，GUI感知能力已得到显著提升，但执行能力（特别是滑动交互）成为任务完成的新瓶颈。现有GUI代理处理滑动交互的策略过于简化，无法准确复制类人行为。

Method: 1. 将人类滑动手势分解为多个可量化维度；2. 提出SwipeGen自动化管道，通过GUI探索合成类人滑动交互；3. 基于此管道构建首个GUI代理滑动执行能力基准；4. 利用合成数据开发GUISwiper代理，增强交互执行能力。

Result: GUISwiper实现了69.07%的滑动执行准确率，相比现有VLM基线提升了214%。同时发布了首个GUI代理滑动执行能力基准。

Conclusion: 通过系统化分析人类滑动手势并合成训练数据，可以显著提升GUI代理的交互执行能力，特别是滑动交互的准确性和类人性。

Abstract: With the widespread adoption of Graphical User Interface (GUI) agents for automating GUI interaction tasks, substantial research focused on improving GUI perception to ground task instructions into concrete action steps. However, the step execution capability of these agents has gradually emerged as a new bottleneck for task completion. In particular, existing GUI agents often adopt overly simplified strategies for handling swipe interactions, preventing them from accurately replicating human-like behavior. To address this limitation, we decompose human swipe gestures into multiple quantifiable dimensions and propose an automated pipeline SwipeGen to synthesize human-like swipe interactions through GUI exploration. Based on this pipeline, we construct and release the first benchmark for evaluating the swipe execution capability of GUI agents. Furthermore, leveraging the synthesized data, we propose GUISwiper, a GUI agent with enhanced interaction execution capabilities. Experimental results demonstrate that GUISwiper achieves a swipe execution accuracy of 69.07%, representing a 214% improvement over existing VLM baselines.

</details>


### [215] [A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification](https://arxiv.org/abs/2601.18330)
*Muhammad Ali Shah,Muhammad Mansoor Alam,Saddam Hussain Khan*

Main category: cs.CV

Relevance: 35.0

TL;DR: 本文提出了一种高效的密集Swin混合（EDSH）框架用于脑肿瘤MRI分析，通过两个肿瘤感知实验设置来联合捕捉细粒度纹理模式和长距离上下文依赖关系。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤MRI分析需要同时捕捉局部纹理细节和全局形态特征。现有方法要么关注局部特征（如CNN），要么关注全局依赖（如Vision Transformer），但难以同时高效处理这两类信息。此外，不同脑肿瘤类型（如弥漫性胶质瘤、脑膜瘤、垂体瘤）具有不同的诊断挑战，需要针对性的特征学习策略。

Method: 提出了两种肿瘤感知实验设置：1）Boosted Feature Space（BFS）：独立定制的DenseNet和Swin分支学习互补的局部和全局表示，通过维度对齐、融合和增强来检测弥漫性胶质瘤模式；2）分层DenseNet-Swin架构：DenseNet作为主干CNN学习结构化局部特征，Swin_t建模全局肿瘤形态，通过深度特征提取和双残差连接（DFE和DR）来抑制脑膜瘤和垂体瘤分类中的假阴性。DenseNet在输入级别定制以匹配MRI空间特性，Swin_t通过任务对齐的patch嵌入和shifted-window自注意力来捕捉分层全局依赖。

Result: 在大规模MRI数据集（40,260张图像，四个肿瘤类别）上的广泛评估显示，该方法在测试未见数据集上达到了98.50%的准确率和召回率，一致优于独立的CNN、Vision Transformer和其他混合方法。

Conclusion: EDSH框架通过联合学习局部纹理和全局上下文特征，有效解决了不同脑肿瘤类型的特定诊断挑战。该方法展示了定制化混合架构在医学图像分析中的优势，特别是通过针对不同肿瘤类型的特征学习策略来提高诊断准确性。

Abstract: This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.

</details>


### [216] [Beyond Rigid: Benchmarking Non-Rigid Video Editing](https://arxiv.org/abs/2601.18340)
*Bingzheng Qu,Kehai Chen,Xuefeng Bai,Jun Yu,Min Zhang*

Main category: cs.CV

Relevance: 35.0

TL;DR: NRVBench：首个专注于非刚性视频编辑的基准测试，包含高质量数据集、基于VLM的评估指标NRVE-Acc，以及无需训练的基线方法VM-Edit


<details>
  <summary>Details</summary>
Motivation: 当前文本驱动视频编辑在生成连贯非刚性变形方面存在挑战，常出现物理失真和时间闪烁问题，缺乏专门评估非刚性视频编辑的基准

Method: 1) 构建包含180个非刚性运动视频的数据集，涵盖6个物理类别，配备2340个细粒度任务指令和360个选择题；2) 提出基于视觉语言模型的评估指标NRVE-Acc，评估物理合规性、时间一致性和指令对齐；3) 提出无需训练的基线方法VM-Edit，采用双区域去噪机制实现结构感知控制

Result: 实验表明当前方法在保持物理合理性方面存在不足，而VM-Edit方法在标准和提出的指标上都表现出色

Conclusion: NRVBench可作为推进物理感知视频编辑的标准测试平台，填补了非刚性视频编辑评估的空白

Abstract: Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing.

</details>


### [217] [Gaze Prediction in Virtual Reality Without Eye Tracking Using Visual and Head Motion Cues](https://arxiv.org/abs/2601.18372)
*Christos Petrou,Harris Partaourides,Athanasios Balomenos,Yannis Kopsinis,Sotirios Chatzis*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出结合HMD运动信号与视觉显著性线索的VR注视预测框架，使用UniSal提取视觉特征，融合HMD运动数据，通过时间序列预测模块（TSMixer/LSTM）预测未来注视方向，在EHTask数据集上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: VR应用中注视预测对减少传感器延迟和实现注视点渲染等技术至关重要，但直接眼动追踪常因硬件限制或隐私问题不可用，需要替代方案。

Method: 结合HMD运动信号与视频帧的视觉显著性线索，使用轻量级显著性编码器UniSal提取视觉特征，融合HMD运动数据，采用TSMixer或LSTM时间序列预测模块进行注视方向预测。

Result: 在EHTask数据集和商用VR硬件上的实验表明，该方法在注视预测上优于Center-of-HMD和Mean Gaze等基线方法，能有效减少感知延迟。

Conclusion: 提出的预测性注视建模方法在直接眼动追踪受限的VR环境中能有效减少感知延迟，增强自然交互体验。

Abstract: Gaze prediction plays a critical role in Virtual Reality (VR) applications by reducing sensor-induced latency and enabling computationally demanding techniques such as foveated rendering, which rely on anticipating user attention. However, direct eye tracking is often unavailable due to hardware limitations or privacy concerns. To address this, we present a novel gaze prediction framework that combines Head-Mounted Display (HMD) motion signals with visual saliency cues derived from video frames. Our method employs UniSal, a lightweight saliency encoder, to extract visual features, which are then fused with HMD motion data and processed through a time-series prediction module. We evaluate two lightweight architectures, TSMixer and LSTM, for forecasting future gaze directions. Experiments on the EHTask dataset, along with deployment on commercial VR hardware, show that our approach consistently outperforms baselines such as Center-of-HMD and Mean Gaze. These results demonstrate the effectiveness of predictive gaze modeling in reducing perceptual lag and enhancing natural interaction in VR environments where direct eye tracking is constrained.

</details>


### [218] [3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control](https://arxiv.org/abs/2601.18451)
*Xuanmeng Sha,Liyun Zhang,Tomohiro Mashita,Naoya Chiba,Yuki Uranishi*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出3DGesPolicy框架，将整体手势生成重新定义为连续轨迹控制问题，通过扩散策略建模帧间变化为统一整体动作，实现空间和语义一致的运动轨迹，并引入GAP融合模块深度整合多模态信号。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成整体协同语音手势时存在语义不协调和空间不稳定问题，需要解决身体动作与面部表情的语义一致性和空间连贯性挑战。

Method: 1) 将整体手势生成重新定义为连续轨迹控制问题，采用机器人学中的扩散策略；2) 将帧间变化建模为统一整体动作；3) 提出Gesture-Audio-Phoneme (GAP)融合模块深度整合多模态信号；4) 在BEAT2数据集上进行实验验证。

Result: 在BEAT2数据集上的定量和定性实验表明，3DGesPolicy在生成自然、富有表现力且高度语音对齐的整体手势方面优于现有最先进方法。

Conclusion: 3DGesPolicy通过动作建模和GAP融合模块，有效解决了整体协同语音手势生成中的语义不协调和空间不稳定问题，实现了高质量的多模态手势生成。

Abstract: Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.

</details>


### [219] [Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System](https://arxiv.org/abs/2601.18464)
*Wenbin Wei,Suyuan Yao,Cheng Huang,Xiangyu Gao*

Main category: cs.CV

Relevance: 35.0

TL;DR: Fair-Eye Net是一个公平可靠的多模态AI系统，用于青光眼筛查、随访和风险预警，通过双流异构融合架构整合多种临床数据，采用不确定性感知分层门控策略，并优化公平性以减少弱势群体的漏诊。


<details>
  <summary>Details</summary>
Motivation: 青光眼是全球不可逆失明的主要原因，早期检测和长期随访至关重要。当前筛查和进展评估依赖单一测试或松散关联的检查，存在主观性和碎片化护理问题。高质量成像工具和专家资源的有限获取进一步影响了现实世界应用的一致性和公平性。

Method: 开发了Fair-Eye Net系统，整合眼底照片、OCT结构指标、VF功能指数和人口统计学因素，采用双流异构融合架构。使用不确定性感知分层门控策略进行选择性预测和安全转诊。通过公平性约束减少弱势亚组的漏诊，采用多任务学习同时优化公平性和临床可靠性。

Result: 系统达到AUC 0.912（特异性96.7%），将种族假阴性差异减少73.4%（从12.31%降至3.28%），保持稳定的跨域性能，实现3-12个月早期风险预警（敏感性92%，特异性88%）。

Conclusion: Fair-Eye Net将公平性作为主要目标进行优化，通过多任务学习结合临床可靠性，为临床转化和大规模部署提供了可复现的路径，有助于推进全球眼健康公平。

Abstract: Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.

</details>


### [220] [From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation](https://arxiv.org/abs/2601.18532)
*Devon Levy,Bar Assayag,Laura Gaspar,Ilan Shimshoni,Bella Specktor-Fadida*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出一种结合基础模型嵌入与聚类的主动学习冷启动策略，通过自动选择聚类数量和按比例采样构建多样化初始训练集，随后集成空间多样性的不确定性主动学习框架，在医学图像分割任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割标注需要大量时间和专业知识，成为疾病监测的主要瓶颈。主动学习通过优先标注信息量大的样本来减轻标注负担，但现有方法在冷启动阶段通常采用基于多样性的策略，仍有改进空间。

Method: 1. 冷启动策略：结合基础模型嵌入与聚类，自动选择聚类数量并跨聚类按比例采样，构建多样化且具代表性的初始训练集
2. 主动学习框架：在冷启动后采用基于不确定性的选择，集成空间多样性指导样本选择
3. 可视化：提供直观可解释的特征空间分布可视化

Result: 在三个医学影像数据集上验证：CheXmask数据集上，冷启动策略将Dice从0.918提升至0.929，Hausdorff距离从32.41降至27.66mm；主动学习框架将Dice从0.919提升至0.939，Hausdorff距离从30.10降至19.16mm。Montgomery数据集上冷启动提升显著，SynthStrip数据集上也有稳定改进。

Conclusion: 提出的框架在低数据场景下持续优于基线方法，提高了分割准确性。方法直观可解释，能够可视化候选样本的特征空间分布。

Abstract: Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.

</details>


### [221] [Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis](https://arxiv.org/abs/2601.18556)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出SDA-QEC框架，结合简化扩散增强与量子增强分类，解决医学图像分类中的类别不平衡问题，在冠状动脉造影图像分类中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分类任务中，真实数据集常存在严重类别不平衡问题，正样本远多于负样本，导致模型偏向多数类，对少数类召回率低，影响诊断准确性并带来临床误诊风险。

Method: SDA-QEC框架包含两部分：1）轻量级扩散增强器生成高质量少数类合成样本，平衡训练分布；2）在MobileNetV2架构中嵌入量子特征层，通过希尔伯特空间的高维特征映射增强模型判别能力。

Result: 在冠状动脉造影图像分类实验中，SDA-QEC达到98.33%准确率、98.78% AUC和98.33% F1分数，显著优于ResNet18、MobileNetV2、DenseNet121和VGG16等经典基线。同时获得98.33%敏感性和98.33%特异性，实现临床部署所需的平衡性能。

Conclusion: 该方法验证了在真实医学成像任务中结合生成增强与量子增强建模的可行性，为小样本、高度不平衡和高风险诊断场景下开发高可靠性医疗AI系统提供了新研究路径。

Abstract: In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.

</details>


### [222] [GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization](https://arxiv.org/abs/2601.18585)
*Chenxi Liu,Selena Ling,Alec Jacobson*

Main category: cs.CV

Relevance: 35.0

TL;DR: GimmBO：基于偏好贝叶斯优化的交互式适配器合并探索框架，用于扩散模型图像生成


<details>
  <summary>Details</summary>
Motivation: 当前基于权重的适配器合并方法依赖手动滑块调节，难以在20-30个适配器的高维空间中有效探索，需要更高效的交互式探索工具

Method: 提出GimmBO框架，采用两阶段贝叶斯优化后端，结合真实使用场景中的稀疏性和权重范围约束，提高高维空间中的采样效率和收敛性

Result: 通过模拟用户和用户研究验证，相比贝叶斯优化和线搜索基线，GimmBO在收敛性、成功率方面表现更优，框架具有良好扩展性

Conclusion: GimmBO为扩散模型适配器合并提供了有效的交互式探索解决方案，显著改善了高维权重空间中的用户体验和探索效率

Abstract: Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.

</details>


### [223] [AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment](https://arxiv.org/abs/2601.18589)
*KV Karthikeya,Ashok Kumar Das,Shantanu Pal,Vivekananda Bhat K,Arun Sekar Rajasekaran*

Main category: cs.CV

Relevance: 35.0

TL;DR: AGSP-DSA框架通过自适应图信号处理和动态语义对齐实现鲁棒的多模态数据融合，在多个基准数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决异构多模态数据（文本、音频、图像）融合中的挑战，特别是在模态缺失情况下的鲁棒性和泛化能力问题。

Method: 1) 双图结构学习模态内和模态间关系；2) 谱图滤波增强信息信号；3) 多尺度图卷积网络进行节点嵌入；4) 语义感知注意力机制动态调整模态贡献。

Result: 在CMU-MOSEI上达到95.3%准确率、0.936 F1分数、0.924 mAP，比MM-GNN提升2.6%；在AVE上93.4%准确率、0.911 F1分数；在MM-IMDB上91.8%准确率、0.886 F1分数。

Conclusion: AGSP-DSA框架在多模态学习中表现出色，在情感分析、事件识别和多媒体分类任务中验证了其有效性，特别是在模态缺失情况下具有良好鲁棒性。

Abstract: In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.

</details>


### [224] [Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures](https://arxiv.org/abs/2601.18619)
*Jorge Quesada,Ghassan AlRegib*

Main category: cs.CV

Relevance: 35.0

TL;DR: 该论文提出了一种尺度感知的自监督学习适应方法，通过在小窗口裁剪增强预训练过程中关注细粒度结构，在分割任务中显著提升了小、稀疏或不规则对象的识别性能。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在有限标注场景下表现优异，但其效果高度依赖于目标任务特性。现有分割方法通常针对大而均匀的区域优化，但在处理小、稀疏或局部不规则对象时性能下降。需要一种能适应不同尺度结构的自监督学习方法。

Method: 提出尺度感知的自监督学习适应方法，将小窗口裁剪集成到增强管道中，在预训练过程中放大关注细粒度结构。该方法在两个不同数据模态的领域进行评估：地震成像（分割稀疏断层）和神经成像（描绘小细胞结构）。

Result: 在两个领域均取得一致改进：断层分割准确率提升高达13%，细胞描绘提升5%。相比之下，大规模特征（如地震相或组织区域）受益有限，表明自监督学习的价值关键取决于目标对象的尺度。

Conclusion: 自监督学习设计需要与对象大小和稀疏性对齐，这为跨科学成像领域构建更有效的表示学习管道提供了通用原则。研究强调了根据目标尺度调整自监督学习方法的重要性。

Abstract: Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.

</details>


### [225] [Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation](https://arxiv.org/abs/2601.18623)
*Zihao Wang,Yuzhou Chen,Shaogang Ren*

Main category: cs.CV

Relevance: 35.0

TL;DR: 提出一种新的跨模态图像翻译方法，通过预测空间变化的混合场和注入目标一致的恢复项，将领域偏移动态嵌入生成过程，提高结构保真度和语义一致性，同时减少去噪步骤。


<details>
  <summary>Details</summary>
Motivation: 标准扩散方法在跨模态图像翻译中依赖单一的全局线性转移，这迫使采样器遍历离流形的高成本区域，增加校正负担并导致语义漂移。作者将这种共享失败模式称为固定调度领域转移。

Method: 提出一种新方法，在每一步反向步骤中预测空间变化的混合场，并向漂移中注入显式的目标一致恢复项。这种步内指导保持大更新在流形上，并将模型角色从全局对齐转变为局部残差校正。提供了连续时间公式和实际的一阶采样器。

Result: 在医学成像、遥感和电致发光语义映射等翻译任务中，该框架提高了结构保真度和语义一致性，同时以更少的去噪步骤收敛。

Conclusion: 通过将领域偏移动态直接嵌入生成过程，可以避免固定调度领域转移的问题，实现更高效和准确的跨模态图像翻译。

Abstract: Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.

</details>


### [226] [Entropy-Guided Agreement-Diversity: A Semi-Supervised Active Learning Framework for Fetal Head Segmentation in Ultrasound](https://arxiv.org/abs/2601.17460)
*Fangyijie Wang,Siteng Ma,Guénolé Silvestre,Kathleen M. Curran*

Main category: eess.IV

Relevance: 35.0

TL;DR: 提出EGAD主动学习采样器用于胎儿超声图像分割，通过两阶段不确定性采样和一致性学习，在仅有5-10%标注数据下达到94-96% Dice分数


<details>
  <summary>Details</summary>
Motivation: 胎儿超声数据因隐私和监管限制而稀缺，现有半监督学习方法依赖随机选择标注数据，容易对同质化标注数据过拟合，导致模型性能不佳

Method: 提出两阶段主动学习采样器EGAD：第一阶段使用预测熵选择最不确定样本，第二阶段使用结合余弦相似度和互信息的协议-多样性评分进行精炼；同时采用特征下采样的一致性学习策略增强分割性能

Result: 在两个公开胎儿头部分割数据集上，使用5%和10%标注数据分别达到94.57%和96.32%的平均Dice分数，优于现有半监督学习方法，在不同孕期数据上表现稳健

Conclusion: EGAD方法能有效解决胎儿超声数据稀缺问题，通过智能样本选择和一致性学习显著提升分割性能，为医学图像分析中的小样本学习提供了有效解决方案

Abstract: Fetal ultrasound (US) data is often limited due to privacy and regulatory restrictions, posing challenges for training deep learning (DL) models. While semi-supervised learning (SSL) is commonly used for fetal US image analysis, existing SSL methods typically rely on random limited selection, which can lead to suboptimal model performance by overfitting to homogeneous labeled data. To address this, we propose a two-stage Active Learning (AL) sampler, Entropy-Guided Agreement-Diversity (EGAD), for fetal head segmentation. Our method first selects the most uncertain samples using predictive entropy, and then refines the final selection using the agreement-diversity score combining cosine similarity and mutual information. Additionally, our SSL framework employs a consistency learning strategy with feature downsampling to further enhance segmentation performance. In experiments, SSL-EGAD achieves an average Dice score of 94.57\% and 96.32\% on two public datasets for fetal head segmentation, using 5\% and 10\% labeled data for training, respectively. Our method outperforms current SSL models and showcases consistent robustness across diverse pregnancy stage data. The code is available on \href{https://github.com/13204942/Semi-supervised-EGAD}{GitHub}.

</details>


### [227] [Differentiable Architecture Search for Adversarially Robust Quantum Computer Vision](https://arxiv.org/abs/2601.18058)
*Mohamed Afane,Quanjiang Long,Haoting Shen,Ying Mao,Junaid Farooq,Ying Wang,Juntao Chen*

Main category: quant-ph

Relevance: 35.0

TL;DR: 提出混合量子-经典可微分量子架构搜索框架，通过联合优化电路结构和鲁棒性，解决量子神经网络对对抗扰动和硬件噪声的极端敏感问题


<details>
  <summary>Details</summary>
Motivation: 当前量子神经网络对对抗扰动和硬件噪声极度敏感，现有鲁棒性技术通常需要牺牲干净准确率或消耗大量计算资源，这阻碍了实际部署

Method: 提出混合量子-经典可微分量子架构搜索框架，在传统DQAS基础上增加轻量级经典噪声层，通过梯度方法联合优化门选择和噪声参数，在量子处理前引入可训练扰动

Result: 在MNIST、FashionMNIST和CIFAR数据集上，相比现有量子架构搜索方法，在干净和对抗准确率上均取得一致改进；在多种攻击场景和实际量子噪声条件下保持优越性能；在实际量子硬件上验证了架构的可行性

Conclusion: 策略性经典预处理与可微分量子架构优化相结合，能显著增强量子神经网络鲁棒性，同时保持计算效率，为实际部署提供了可行方案

Abstract: Current quantum neural networks suffer from extreme sensitivity to both adversarial perturbations and hardware noise, creating a significant barrier to real-world deployment. Existing robustness techniques typically sacrifice clean accuracy or require prohibitive computational resources. We propose a hybrid quantum-classical Differentiable Quantum Architecture Search (DQAS) framework that addresses these limitations by jointly optimizing circuit structure and robustness through gradient-based methods. Our approach enhances traditional DQAS with a lightweight Classical Noise Layer applied before quantum processing, enabling simultaneous optimization of gate selection and noise parameters. This design preserves the quantum circuit's integrity while introducing trainable perturbations that enhance robustness without compromising standard performance. Experimental validation on MNIST, FashionMNIST, and CIFAR datasets shows consistent improvements in both clean and adversarial accuracy compared to existing quantum architecture search methods. Under various attack scenarios, including Fast Gradient Sign Method (FGSM), Projected Gradient Descent (PGD), Basic Iterative Method (BIM), and Momentum Iterative Method (MIM), and under realistic quantum noise conditions, our hybrid framework maintains superior performance. Testing on actual quantum hardware confirms the practical viability of discovered architectures. These results demonstrate that strategic classical preprocessing combined with differentiable quantum architecture optimization can significantly enhance quantum neural network robustness while maintaining computational efficiency.

</details>


### [228] [LoD-Structured 3D Gaussian Splatting for Streaming Video Reconstruction](https://arxiv.org/abs/2601.18475)
*Xinhui Liu,Can Wang,Lei Liu,Zhenghao Chen,Wei Jiang,Wei Wang,Dong Xu*

Main category: cs.GR

Relevance: 35.0

TL;DR: StreamLoD-GS：用于流式自由视点视频的LOD高斯溅射框架，通过层次化高斯丢弃、GMM运动分割和量化残差细化，实现高效优化、高质量渲染和低存储需求。


<details>
  <summary>Details</summary>
Motivation: 自由视点视频重建面临实时流式传输的瓶颈：稀疏视图输入、高昂训练成本、带宽限制。现有3D高斯溅射虽然渲染速度快，但流式自由视点视频需要快速优化、稀疏约束下的高保真重建和最小存储占用。

Method: 1) 基于锚点和八叉树的LOD结构3DGS，采用层次化高斯丢弃技术确保高效稳定优化；2) GMM运动分割机制分离动态和静态内容；3) 量化残差细化框架显著降低存储需求。

Result: StreamLoD-GS在质量、效率和存储方面达到竞争性或最先进的性能，能够满足流式自由视点视频的实时需求。

Conclusion: 提出的StreamLoD-GS框架有效解决了流式自由视点视频的挑战，通过创新的LOD结构、运动分割和量化技术，实现了高质量、高效率、低存储的3D场景重建和渲染。

Abstract: Free-Viewpoint Video (FVV) reconstruction enables photorealistic and interactive 3D scene visualization; however, real-time streaming is often bottlenecked by sparse-view inputs, prohibitive training costs, and bandwidth constraints. While recent 3D Gaussian Splatting (3DGS) has advanced FVV due to its superior rendering speed, Streaming Free-Viewpoint Video (SFVV) introduces additional demands for rapid optimization, high-fidelity reconstruction under sparse constraints, and minimal storage footprints. To bridge this gap, we propose StreamLoD-GS, an LoD-based Gaussian Splatting framework designed specifically for SFVV. Our approach integrates three core innovations: 1) an Anchor- and Octree-based LoD-structured 3DGS with a hierarchical Gaussian dropout technique to ensure efficient and stable optimization while maintaining high-quality rendering; 2) a GMM-based motion partitioning mechanism that separates dynamic and static content, refining dynamic regions while preserving background stability; and 3) a quantized residual refinement framework that significantly reduces storage requirements without compromising visual fidelity. Extensive experiments demonstrate that StreamLoD-GS achieves competitive or state-of-the-art performance in terms of quality, efficiency, and storage.

</details>


### [229] [Hybrid Deep Feature Extraction and ML for Construction and Demolition Debris Classification](https://arxiv.org/abs/2601.17038)
*Obai Alashram,Nejad Alagha,Mahmoud AlKakuri,Zeeshan Swaveel,Abigail Copiaco*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该研究提出了一种混合视觉管道，结合深度特征提取与传统机器学习分类器，用于建筑垃圾的自动分类，在收集的真实数据集上达到99.5%的准确率。


<details>
  <summary>Details</summary>
Motivation: 建筑行业产生大量废弃物，有效的分类对于可持续废物管理和资源回收至关重要。传统方法效率低下，需要自动化解决方案来应对这一挑战。

Method: 采用混合视觉管道：1）收集包含1800张平衡高质量图像的数据集（陶瓷/瓷砖、混凝土、垃圾/废弃物、木材）；2）使用预训练的Xception网络提取深度特征；3）系统评估多种传统机器学习分类器（SVM、kNN、Bagged Trees、LDA、逻辑回归）。

Result: 混合管道在Xception特征提取基础上，结合简单的分类器（线性SVM、kNN、Bagged Trees）实现了最先进的性能，准确率和宏F1分数高达99.5%，超越了更复杂的端到端深度学习方法。

Conclusion: 该方法为稳健、可现场部署的建筑垃圾识别提供了操作优势，并为未来与机器人和现场自动化系统的集成提供了途径。

Abstract: The construction industry produces significant volumes of debris, making effective sorting and classification critical for sustainable waste management and resource recovery. This study presents a hybrid vision-based pipeline that integrates deep feature extraction with classical machine learning (ML) classifiers for automated construction and demolition (C\&D) debris classification. A novel dataset comprising 1,800 balanced, high-quality images representing four material categories, Ceramic/Tile, Concrete, Trash/Waste, and Wood was collected from real construction sites in the UAE, capturing diverse real-world conditions. Deep features were extracted using a pre-trained Xception network, and multiple ML classifiers, including SVM, kNN, Bagged Trees, LDA, and Logistic Regression, were systematically evaluated. The results demonstrate that hybrid pipelines using Xception features with simple classifiers such as Linear SVM, kNN, and Bagged Trees achieve state-of-the-art performance, with up to 99.5\% accuracy and macro-F1 scores, surpassing more complex or end-to-end deep learning approaches. The analysis highlights the operational benefits of this approach for robust, field-deployable debris identification and provides pathways for future integration with robotics and onsite automation systems.

</details>


### [230] [GlassesGB: Controllable 2D GAN-Based Eyewear Personalization for 3D Gaussian Blendshapes Head Avatars](https://arxiv.org/abs/2601.17088)
*Rui-Yang Ju,Jen-Shiun Chiang*

Main category: cs.CV

Relevance: 30.0

TL;DR: GlassesGB是一个支持3D头部虚拟形象可定制眼镜生成的框架，通过将2D生成式定制与3D头部虚拟形象渲染相结合，解决了VR应用中个性化眼镜设计的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试戴系统大多只能在预定义的眼镜模板上操作，缺乏细粒度的用户驱动定制能力。虽然GlassesGAN支持个性化2D眼镜设计，但其能力仅限于2D图像生成。为了解决VR应用中个性化眼镜设计的挑战，需要将2D生成式定制与3D头部虚拟形象渲染相结合。

Method: GlassesGB框架整合了3D高斯混合形状（用于头部重建）和2D生成式定制技术，实现了可定制眼镜的3D生成。该框架有效地桥接了2D生成式定制与3D头部虚拟形象渲染，支持用户驱动的细粒度眼镜定制。

Result: 提出了GlassesGB框架，支持为3D头部虚拟形象生成可定制的眼镜，解决了VR应用中个性化眼镜设计的挑战。代码已在GitHub上开源。

Conclusion: GlassesGB成功地将2D生成式定制与3D头部虚拟形象渲染相结合，为VR应用中的个性化眼镜设计提供了有效的解决方案，填补了现有虚拟试戴系统在用户驱动定制方面的不足。

Abstract: Virtual try-on systems allow users to interactively try different products within VR scenarios. However, most existing VTON methods operate only on predefined eyewear templates and lack support for fine-grained, user-driven customization. While GlassesGAN enables personalized 2D eyewear design, its capability remains limited to 2D image generation. Motivated by the success of 3D Gaussian Blendshapes in head reconstruction, we integrate these two techniques and propose GlassesGB, a framework that supports customizable eyewear generation for 3D head avatars. GlassesGB effectively bridges 2D generative customization with 3D head avatar rendering, addressing the challenge in achieving personalized eyewear design for VR applications. The implementation code is available at https://ruiyangju.github.io/GlassesGB.

</details>


### [231] [LGDWT-GS: Local and Global Discrete Wavelet-Regularized 3D Gaussian Splatting for Sparse-View Scene Reconstruction](https://arxiv.org/abs/2601.17185)
*Shima Salehi,Atharva Agashe,Andrew J. McFarland,Joshua Peeples*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出一种用于少样本3D重建的新方法，通过全局和局部频率正则化来稳定几何结构并保留稀疏视图条件下的细节，解决了现有3D高斯溅射模型的局限性。同时发布了一个包含四个光谱波段的多光谱温室数据集和开源基准测试包。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯溅射（3DGS）模型在稀疏视图条件下存在几何不稳定和细节丢失的问题，特别是在少样本3D重建场景中。需要一种能够同时稳定全局几何结构和保留局部细节的方法，以及标准化的评估基准。

Method: 提出集成全局和局部频率正则化的方法，通过频率域约束来稳定几何结构并保留精细细节。同时构建了一个包含四个光谱波段的多光谱温室数据集，覆盖多种植物物种在受控条件下的数据。开发了开源基准测试包，定义了标准化的少样本重建评估协议。

Result: 在多光谱数据集和标准基准测试上的实验表明，所提方法相比现有基线实现了更锐利、更稳定和光谱一致的重建效果。重建质量在几何稳定性和细节保留方面均有显著提升。

Conclusion: 该方法有效解决了稀疏视图条件下3D高斯溅射模型的几何不稳定问题，同时提出的数据集和基准测试包为少样本3D重建研究提供了有价值的资源和评估标准。

Abstract: We propose a new method for few-shot 3D reconstruction that integrates global and local frequency regularization to stabilize geometry and preserve fine details under sparse-view conditions, addressing a key limitation of existing 3D Gaussian Splatting (3DGS) models. We also introduce a new multispectral greenhouse dataset containing four spectral bands captured from diverse plant species under controlled conditions. Alongside the dataset, we release an open-source benchmarking package that defines standardized few-shot reconstruction protocols for evaluating 3DGS-based methods. Experiments on our multispectral dataset, as well as standard benchmarks, demonstrate that the proposed method achieves sharper, more stable, and spectrally consistent reconstructions than existing baselines. The dataset and code for this work are publicly available

</details>


### [232] [AGE-Net: Spectral--Spatial Fusion and Anatomical Graph Reasoning with Evidential Ordinal Regression for Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.17336)
*Xiaoyang Li,Runni Zhou*

Main category: cs.CV

Relevance: 30.0

TL;DR: AGE-Net：一种用于膝关节KL分级的ConvNeXt框架，集成了谱空间融合、解剖图推理和差分细化，采用证据回归头和序数约束来处理不确定性和边界模糊问题。


<details>
  <summary>Details</summary>
Motivation: 膝关节KL分级自动化面临挑战：细微结构变化、长程解剖依赖性和分级边界模糊。需要能够处理不确定性和保持标签序数性的方法。

Method: 基于ConvNeXt的框架，集成三个模块：1) 谱空间融合(SSF)捕获多尺度特征；2) 解剖图推理(AGR)建模关节关系；3) 差分细化(DFR)处理边界模糊。采用Normal-Inverse-Gamma证据回归头和成对序数排序约束。

Result: 在膝关节KL数据集上，AGE-Net达到二次加权kappa(QWK) 0.9017±0.0045和均方误差(MSE) 0.2349±0.0028，优于强CNN基线，消融研究显示一致增益。

Conclusion: AGE-Net通过集成多模态特征、解剖推理和不确定性建模，有效解决了膝关节KL分级的挑战，在准确性和鲁棒性方面表现优异。

Abstract: Automated Kellgren--Lawrence (KL) grading from knee radiographs is challenging due to subtle structural changes, long-range anatomical dependencies, and ambiguity near grade boundaries. We propose AGE-Net, a ConvNeXt-based framework that integrates Spectral--Spatial Fusion (SSF), Anatomical Graph Reasoning (AGR), and Differential Refinement (DFR). To capture predictive uncertainty and preserve label ordinality, AGE-Net employs a Normal-Inverse-Gamma (NIG) evidential regression head and a pairwise ordinal ranking constraint. On a knee KL dataset, AGE-Net achieves a quadratic weighted kappa (QWK) of 0.9017 +/- 0.0045 and a mean squared error (MSE) of 0.2349 +/- 0.0028 over three random seeds, outperforming strong CNN baselines and showing consistent gains in ablation studies. We further outline evaluations of uncertainty quality, robustness, and explainability, with additional experimental figures to be included in the full manuscript.

</details>


### [233] [Geometry-Grounded Gaussian Splatting](https://arxiv.org/abs/2601.17835)
*Baowen Zhang,Chenxing Jiang,Heng Li,Shaojie Shen,Ping Tan*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文提出了Geometry-Grounded Gaussian Splatting方法，通过理论推导将高斯基元视为随机实体，解决了从高斯溅射中提取几何形状的问题，实现了高质量的形状重建。


<details>
  <summary>Details</summary>
Motivation: 高斯溅射(GS)在新视角合成中表现出色，但从高斯基元中提取几何形状仍是一个开放问题。现有方法由于几何参数化和近似不足，存在多视角一致性差和对漂浮物敏感的问题。

Method: 通过严格的理论推导，将高斯基元建立为特定类型的随机实体。利用随机实体的体积特性，高效渲染高质量深度图进行细粒度几何提取。

Result: 在公开数据集上，该方法在所有基于高斯溅射的方法中取得了最佳的形状重建结果。

Conclusion: 该理论框架为Geometry-Grounded Gaussian Splatting提供了原则性基础，使高斯基元能够直接作为显式几何表示，解决了高斯溅射中的形状提取问题。

Abstract: Gaussian Splatting (GS) has demonstrated impressive quality and efficiency in novel view synthesis. However, shape extraction from Gaussian primitives remains an open problem. Due to inadequate geometry parameterization and approximation, existing shape reconstruction methods suffer from poor multi-view consistency and are sensitive to floaters. In this paper, we present a rigorous theoretical derivation that establishes Gaussian primitives as a specific type of stochastic solids. This theoretical framework provides a principled foundation for Geometry-Grounded Gaussian Splatting by enabling the direct treatment of Gaussian primitives as explicit geometric representations. Using the volumetric nature of stochastic solids, our method efficiently renders high-quality depth maps for fine-grained geometry extraction. Experiments show that our method achieves the best shape reconstruction results among all Gaussian Splatting-based methods on public datasets.

</details>


### [234] [DTC: A Deformable Transposed Convolution Module for Medical Image Segmentation](https://arxiv.org/abs/2601.17939)
*Chengkun Sun,Jinqian Pan,Renjie Liang,Zhengkang Fan,Xin Miao,Jiang Bian,Jie Xu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种用于医学图像分割的新型上采样方法——可变形转置卷积（DTC），通过学习动态坐标而非固定位置来生成高分辨率特征图，在2D和3D医学图像分割任务中均能提升特征重建和细节恢复能力。


<details>
  <summary>Details</summary>
Motivation: 传统上采样方法（如转置卷积和线性插值）在固定位置操作，可能无法捕捉预定义采样位置之外的结构信息，导致伪影或细节丢失。受可变形卷积启发，作者希望开发一种能够学习动态采样位置的上采样方法。

Method: 提出可变形转置卷积（DTC），该方法学习动态坐标（采样位置）来生成高分辨率特征图。DTC可以集成到现有的医学图像分割模型（如UNet类架构）中，用于2D和3D分割任务。

Result: 在3D数据集（如BTCV15）和2D数据集（如ISIC18、BUSI）上的实验表明，DTC能够有效提升解码器的特征重建和细节恢复能力，在现有医学图像分割模型中取得一致改进。

Conclusion: DTC作为一种新型上采样方法，通过学习动态采样位置，能够更好地捕捉结构信息并减少伪影，为医学图像分割任务提供了更有效的特征重建方案。

Abstract: In medical image segmentation, particularly in UNet-like architectures, upsampling is primarily used to transform smaller feature maps into larger ones, enabling feature fusion between encoder and decoder features and supporting multi-scale prediction. Conventional upsampling methods, such as transposed convolution and linear interpolation, operate on fixed positions: transposed convolution applies kernel elements to predetermined pixel or voxel locations, while linear interpolation assigns values based on fixed coordinates in the original feature map. These fixed-position approaches may fail to capture structural information beyond predefined sampling positions and can lead to artifacts or loss of detail. Inspired by deformable convolutions, we propose a novel upsampling method, Deformable Transposed Convolution (DTC), which learns dynamic coordinates (i.e., sampling positions) to generate high-resolution feature maps for both 2D and 3D medical image segmentation tasks. Experiments on 3D (e.g., BTCV15) and 2D datasets (e.g., ISIC18, BUSI) demonstrate that DTC can be effectively integrated into existing medical image segmentation models, consistently improving the decoder's feature reconstruction and detail recovery capability.

</details>


### [235] [YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection](https://arxiv.org/abs/2601.18172)
*Lin Huang,Yujuan Tan,Weisheng Li,Shitai Shan,Liu Liu,Bo Liu,Linlin Shen,Jing Yu,Yue Niu*

Main category: cs.CV

Relevance: 30.0

TL;DR: YOLO-DS提出双统计协同算子(DSO)和门控模块，解决YOLO检测器中异构物体响应建模不足的问题，在MS-COCO上相比YOLOv8提升1.1-1.7% AP，推理延迟仅轻微增加。


<details>
  <summary>Details</summary>
Motivation: 现有YOLO检测器缺乏对共享特征通道中异构物体响应的显式建模，限制了性能进一步提升。需要设计更有效的特征表示机制来区分不同类型的物体。

Method: 提出双统计协同算子(DSO)，通过联合建模通道均值和峰均差来解耦物体特征。基于DSO设计两个轻量门控模块：DSG用于自适应通道特征选择，MSG用于深度特征加权。

Result: 在MS-COCO基准测试中，YOLO-DS在五个模型尺度(N,S,M,L,X)上均优于YOLOv8，AP提升1.1%到1.7%，推理延迟仅轻微增加。可视化、消融和对比研究验证了方法的有效性。

Conclusion: YOLO-DS通过双统计协同算子和门控模块有效建模异构物体响应，在保持高效推理的同时显著提升检测性能，为一阶段目标检测提供了新的特征建模思路。

Abstract: One-stage object detection, particularly the YOLO series, strikes a favorable balance between accuracy and efficiency. However, existing YOLO detectors lack explicit modeling of heterogeneous object responses within shared feature channels, which limits further performance gains. To address this, we propose YOLO-DS, a framework built around a novel Dual-Statistic Synergy Operator (DSO). The DSO decouples object features by jointly modeling the channel-wise mean and the peak-to-mean difference. Building upon the DSO, we design two lightweight gating modules: the Dual-Statistic Synergy Gating (DSG) module for adaptive channel-wise feature selection, and the Multi-Path Segmented Gating (MSG) module for depth-wise feature weighting. On the MS-COCO benchmark, YOLO-DS consistently outperforms YOLOv8 across five model scales (N, S, M, L, X), achieving AP gains of 1.1% to 1.7% with only a minimal increase in inference latency. Extensive visualization, ablation, and comparative studies validate the effectiveness of our approach, demonstrating its superior capability in discriminating heterogeneous objects with high efficiency.

</details>


### [236] [HomoFM: Deep Homography Estimation with Flow Matching](https://arxiv.org/abs/2601.18222)
*Mengfan He,Liangzheng Sun,Chunyu Li,Ziyang Meng*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出HomoFM框架，首次将流匹配技术引入单应性估计任务，通过建模连续点状速度场将噪声分布转换为配准坐标，并集成梯度反转层增强跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度单应性估计方法通常将其视为直接回归或迭代优化问题，难以捕捉复杂几何变换或实现跨域泛化。需要新的框架来提升估计精度和鲁棒性。

Method: 1) 将单应性估计重新表述为速度场学习问题，建模连续点状速度场将噪声分布转换为配准坐标；2) 集成梯度反转层到特征提取主干，学习域不变表示以增强跨域鲁棒性。

Result: 在标准基准测试中，HomoFM在估计精度和鲁棒性方面均优于现有最先进方法，特别是在多模态匹配和变化光照场景下表现优异。

Conclusion: 流匹配技术为单应性估计提供了新范式，结合域适应策略显著提升了方法的泛化能力和鲁棒性，为计算机视觉和机器人应用提供了更可靠的几何变换估计方案。

Abstract: Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM.

</details>


### [237] [EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery](https://arxiv.org/abs/2601.18597)
*Yu Xia,Chang Liu,Tianqi Xiang,Zhigang Tu*

Main category: cs.CV

Relevance: 30.0

TL;DR: EFSI-DETR：一种用于无人机图像中小目标实时检测的新框架，通过动态频率-空间协同网络和高效语义特征浓缩器，在VisDrone和CODrone基准上达到SOTA性能，同时保持实时推理速度。


<details>
  <summary>Details</summary>
Motivation: 无人机图像中的小目标检测面临特征表示有限和多尺度融合效果不佳的挑战。现有方法未能充分利用频率信息，依赖静态卷积操作，限制了获取丰富特征表示的能力，阻碍了深度语义特征的有效利用。

Method: 提出EFSI-DETR框架，包含两个主要组件：1) 动态频率-空间统一协同网络(DyFusNet)，联合利用频率和空间线索进行鲁棒的多尺度特征融合；2) 高效语义特征浓缩器(ESFC)，以最小计算成本实现深度语义提取。此外，采用细粒度特征保留(FFR)策略，在融合过程中纳入空间丰富的浅层特征以保留细粒度细节。

Result: 在VisDrone和CODrone基准上的大量实验表明，EFSI-DETR实现了最先进的性能，在VisDrone上AP和AP_s分别提高了1.6%和5.8%，同时在单块RTX 4090 GPU上获得了188 FPS的推理速度。

Conclusion: EFSI-DETR通过有效整合频率-空间信息和语义特征增强，解决了无人机图像中小目标检测的挑战，实现了实时高效的检测性能。

Abstract: Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \textbf{1.6}\% and \textbf{5.8}\% in AP and AP$_{s}$ on VisDrone, while obtaining \textbf{188} FPS inference speed on a single RTX 4090 GPU.

</details>


### [238] [MANGO: A Global Single-Date Paired Dataset for Mangrove Segmentation](https://arxiv.org/abs/2601.17039)
*Junhyuk Heo,Beomkyu Choi,Hyunjin Shin,Darongsae Kwon*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出MANGO数据集，包含42,703个标注的图像-掩码对，覆盖124个国家，用于全球红树林监测的深度学习研究


<details>
  <summary>Details</summary>
Motivation: 红树林对气候变化缓解至关重要，但现有数据集存在局限性：只有年度地图产品而非单日期图像-掩码对、区域覆盖有限、数据不公开，阻碍了深度学习在红树林检测中的进展

Method: 收集2020年红树林区域的Sentinel-2影像，采用目标检测驱动的方法，利用像素级坐标参考选择与年度红树林掩码对齐的最佳单日期观测，构建图像-掩码对

Result: 创建了包含42,703个标注对的全球数据集，覆盖124个国家，并在国家不相交划分下为多种语义分割架构提供了基准测试

Conclusion: MANGO数据集为可扩展和可靠的全球红树林监测建立了基础，解决了现有数据集的局限性，促进了深度学习在红树林检测中的应用

Abstract: Mangroves are critical for climate-change mitigation, requiring reliable monitoring for effective conservation. While deep learning has emerged as a powerful tool for mangrove detection, its progress is hindered by the limitations of existing datasets. In particular, many resources provide only annual map products without curated single-date image-mask pairs, limited to specific regions rather than global coverage, or remain inaccessible to the public. To address these challenges, we introduce MANGO, a large-scale global dataset comprising 42,703 labeled image-mask pairs across 124 countries. To construct this dataset, we retrieve all available Sentinel-2 imagery within the year 2020 for mangrove regions and select the best single-date observations that align with the mangrove annual mask. This selection is performed using a target detection-driven approach that leverages pixel-wise coordinate references to ensure adaptive and representative image-mask pairings. We also provide a benchmark across diverse semantic segmentation architectures under a country-disjoint split, establishing a foundation for scalable and reliable global mangrove monitoring.

</details>


### [239] [Arabic Sign Language Recognition using Multimodal Approach](https://arxiv.org/abs/2601.17041)
*Ghadeer Alanazi,Abir Benabid*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该研究探索了结合Leap Motion和RGB摄像头的多模态方法用于阿拉伯手语识别，通过融合两种传感器数据来提高识别准确率，在18个手语词汇上达到78%的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯手语识别系统主要依赖单一传感器（如Leap Motion或RGB摄像头），存在复杂手部方向跟踪不足和3D手部运动识别不精确的问题。需要多模态方法来提高识别性能。

Method: 采用双通道子网络架构：1) 针对Leap Motion数据的自定义密集神经网络，包含dropout和L2正则化；2) 基于微调VGG16模型的图像子网络，采用数据增强技术。两种模态的特征表示在融合模型中拼接，通过全连接层处理，最后使用SoftMax进行分类。

Result: 在包含18个阿拉伯手语词汇的自定义数据集上，系统正确识别了13个词汇，总体准确率达到78%。这为多模态融合在手语识别中的可行性提供了初步证据。

Conclusion: 多模态融合方法在阿拉伯手语识别中显示出潜力，但仍需进一步优化和数据集扩展。该研究为改进手语识别系统提供了方向。

Abstract: Arabic Sign Language (ArSL) is an essential communication method for individuals in the Deaf and Hard-of-Hearing community. However, existing recognition systems face significant challenges due to their reliance on single sensor approaches like Leap Motion or RGB cameras. These systems struggle with limitations such as inadequate tracking of complex hand orientations and imprecise recognition of 3D hand movements. This research paper aims to investigate the potential of a multimodal approach that combines Leap Motion and RGB camera data to explore the feasibility of recognition of ArSL. The system architecture includes two parallel subnetworks: a custom dense neural network for Leap Motion data, incorporating dropout and L2 regularization, and an image subnetwork based on a fine-tuned VGG16 model enhanced with data augmentation techniques. Feature representations from both modalities are concatenated in a fusion model and passed through fully connected layers, with final classification performed via SoftMax activation to analyze spatial and temporal features of hand gestures. The system was evaluated on a custom dataset comprising 18 ArSL words, of which 13 were correctly recognized, yielding an overall accuracy of 78%. These results offer preliminary insights into the viability of multimodal fusion for sign language recognition and highlight areas for further optimization and dataset expansion.

</details>


### [240] [SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis](https://arxiv.org/abs/2601.17048)
*Jing Jie Tan,Rupert Schreiner,Matthias Hausladen,Ali Asgharzade,Simon Edler,Julian Bartsch,Michael Bachmann,Andreas Schels,Ban-Hoe Kwan,Danny Wee-Kiat Ng,Yan-Chai Hum*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出SiMiC框架，使用注意力机制增强的卷积神经网络自动分析硅微结构SEM图像，实现特征提取和分类，减少人工干预并提高测量一致性。


<details>
  <summary>Details</summary>
Motivation: 传统硅微结构分析依赖扫描电镜图像的人工评估，效率低且可重复性差。需要自动化方法来提高微结构表征的效率和准确性，以支持微尺度制造、质量控制和器件性能优化。

Method: 开发了硅场发射尖端专用数据集，设计了结合注意力机制的自定义CNN架构，用于多类微结构分类和尺寸预测。通过注意力机制增强特征提取能力。

Result: 与传统图像处理技术相比，SiMiC实现了高精度分析，同时保持了可解释性。建立了数据驱动的微结构分析框架，能够关联发射器几何形状与场发射性能。

Conclusion: SiMiC为硅微结构自动化表征提供了有效解决方案，为优化冷阴极和SEM电子源设计奠定了基础，并建立了相关数据集和算法库作为该领域的基准。

Abstract: Accurate characterization of silicon microstructures is essential for advancing microscale fabrication, quality control, and device performance. Traditional analysis using Scanning Electron Microscopy (SEM) often requires labor-intensive, manual evaluation of feature geometry, limiting throughput and reproducibility. In this study, we propose SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis. By leveraging deep learning, our approach efficiently extracts morphological features-such as size, shape, and apex curvature-from SEM images, significantly reducing human intervention while improving measurement consistency. A specialized dataset of silicon-based field-emitter tips was developed, and a customized CNN architecture incorporating attention mechanisms was trained for multi-class microstructure classification and dimensional prediction. Comparative analysis with classical image processing techniques demonstrates that SiMiC achieves high accuracy while maintaining interpretability. The proposed framework establishes a foundation for data-driven microstructure analysis directly linked to field-emission performance, opening avenues for correlating emitter geometry with emission behavior and guiding the design of optimized cold-cathode and SEM electron sources. The related dataset and algorithm repository that could serve as a baseline in this area can be found at https://research.jingjietan.com/?q=SIMIC

</details>


### [241] [Superpixel-Based Image Segmentation Using Squared 2-Wasserstein Distances](https://arxiv.org/abs/2601.17071)
*Jisui Huang,Andreas Alpers,Ke Chen,Na Lei*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种基于最优传输理论的高效图像分割方法，通过两级聚类处理非均匀图像：首先将像素聚类为超像素，然后使用2-Wasserstein距离合并超像素为对象级分割。


<details>
  <summary>Details</summary>
Motivation: 传统图像分割方法在处理非均匀图像时效果不佳，特别是当图像存在强烈不均匀性时。现有超像素合并策略通常基于平均颜色距离，缺乏数学统一性，且对分布特征不敏感。

Method: 采用两级聚类框架：1) 通过线性最小二乘分配问题将像素聚类为超像素，这可以视为离散最优传输问题的特例；2) 使用平方2-Wasserstein距离贪婪合并超像素为对象级分割，该距离衡量经验分布之间的差异。

Result: 数值实验表明，该方法在具有挑战性的图像上提高了分割精度，同时保持了高计算效率。与基于平均颜色距离的传统方法相比，基于分布最优传输距离的框架表现更优。

Conclusion: 基于最优传输理论的两级聚类方法为图像分割提供了数学统一的框架，在处理非均匀图像时具有更好的准确性和计算效率，为计算机视觉中的分割任务提供了新思路。

Abstract: We present an efficient method for image segmentation in the presence of strong inhomogeneities. The approach can be interpreted as a two-level clustering procedure: pixels are first grouped into superpixels via a linear least-squares assignment problem, which can be viewed as a special case of a discrete optimal transport (OT) problem, and these superpixels are subsequently greedily merged into object-level segments using the squared 2-Wasserstein distance between their empirical distributions. In contrast to conventional superpixel merging strategies based on mean-color distances, our framework employs a distributional OT distance, yielding a mathematically unified formulation across both clustering levels. Numerical experiments demonstrate that this perspective leads to improved segmentation accuracy on challenging images while retaining high computational efficiency.

</details>


### [242] [Performance uncertainty in medical image analysis: a large-scale investigation of confidence intervals](https://arxiv.org/abs/2601.17103)
*Pascaline André,Charles Heitz,Evangelia Christodoulou,Annika Reinke,Carole H. Sudre,Michela Antonelli,Patrick Godau,M. Jorge Cardoso,Antoine Gilson,Sophie Tezenas du Montcel,Gaël Varoquaux,Lena Maier-Hein,Olivier Colliot*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该研究对医学影像AI性能不确定性量化进行了大规模实证分析，评估了不同置信区间方法在24个分割和分类任务中的可靠性和精确性，揭示了影响CI行为的五个关键因素。


<details>
  <summary>Details</summary>
Motivation: 医学影像AI的性能不确定性量化对于可靠的验证和临床转化至关重要，但社区对多种CI方法及其在不同设置下的行为了解有限。本研究旨在填补这一空白。

Method: 进行了大规模实证分析，涵盖24个分割和分类任务，每个任务组使用19个训练模型，采用广泛的常用性能指标、多种聚合策略和几种广泛采用的CI方法。评估了每种CI方法在所有设置下的可靠性（覆盖率）和精确性（宽度）。

Result: 发现了五个主要发现：1）可靠CI所需的样本量从几十到几千个案例不等；2）CI行为受性能指标选择强烈影响；3）聚合策略显著影响CI可靠性；4）机器学习问题（分割vs分类）调节这些效应；5）不同CI方法在不同用例中可靠性和精确性不同。

Conclusion: 这些结果为制定医学影像AI性能不确定性报告的未来指南提供了关键组成部分，强调了根据具体研究参数选择适当CI方法的重要性。

Abstract: Performance uncertainty quantification is essential for reliable validation and eventual clinical translation of medical imaging artificial intelligence (AI). Confidence intervals (CIs) play a central role in this process by indicating how precise a reported performance estimate is. Yet, due to the limited amount of work examining CI behavior in medical imaging, the community remains largely unaware of how many diverse CI methods exist and how they behave in specific settings. The purpose of this study is to close this gap. To this end, we conducted a large-scale empirical analysis across a total of 24 segmentation and classification tasks, using 19 trained models per task group, a broad spectrum of commonly used performance metrics, multiple aggregation strategies, and several widely adopted CI methods. Reliability (coverage) and precision (width) of each CI method were estimated across all settings to characterize their dependence on study characteristics. Our analysis revealed five principal findings: 1) the sample size required for reliable CIs varies from a few dozens to several thousands of cases depending on study parameters; 2) CI behavior is strongly affected by the choice of performance metric; 3) aggregation strategy substantially influences the reliability of CIs, e.g. they require more observations for macro than for micro; 4) the machine learning problem (segmentation versus classification) modulates these effects; 5) different CI methods are not equally reliable and precise depending on the use case. These results form key components for the development of future guidelines on reporting performance uncertainty in medical imaging AI.

</details>


### [243] [Multi-stage Bridge Inspection System: Integrating Foundation Models with Location Anonymization](https://arxiv.org/abs/2601.17254)
*Takato Yasuno*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该论文提出一个开源桥梁损伤检测系统，结合区域隐私保护功能，使用SAM3进行钢筋腐蚀检测，DBSCAN自动补全遗漏区域，高斯模糊保护施工标志区域，通过四种预处理方法提高OCR精度，实现每张图像1.7秒处理速度。


<details>
  <summary>Details</summary>
Motivation: 日本规定每五年对民用基础设施进行视觉检查，现场拍摄的损伤图像常包含混凝土裂缝和钢筋暴露，同时施工标志会泄露区域信息。需要在保护区域隐私的同时准确提取损伤特征，为维修决策提供可视化关键指标。

Method: 使用Segment Anything Model (SAM) 3进行钢筋腐蚀检测，DBSCAN自动补全遗漏区域，高斯模糊处理施工标志区域以保护隐私，采用四种预处理方法提高OCR精度，GPU优化实现高效处理。

Result: 系统实现每张图像1.7秒处理速度，技术栈包括SAM3、PyTorch、OpenCV、pytesseract和scikit-learn，在保护区域信息的同时实现高效的桥梁检查。

Conclusion: 开发了一个具有区域隐私保护功能的开源桥梁损伤检测系统，能够在保护敏感区域信息的同时准确检测基础设施损伤，为安全基础设施使用提供技术支持。

Abstract: In Japan, civil infrastructure condition monitoring is mandated through visual inspection every five years. Field-captured damage images frequently contain concrete cracks and rebar exposure, often accompanied by construction signs revealing regional information. To enable safe infrastructure use without causing public anxiety, it is essential to protect regional information while accurately extracting damage features and visualizing key indicators for repair decision-making. This paper presents an open-source bridge damage detection system with regional privacy protection capabilities. We employ Segment Anything Model (SAM) 3 for rebar corrosion detection and utilize DBSCAN for automatic completion of missed regions. Construction sign regions are detected and protected through Gaussian blur. Four preprocessing methods improve OCR accuracy, and GPU optimization enables 1.7-second processing per image. The technology stack includes SAM3, PyTorch, OpenCV, pytesseract, and scikit-learn, achieving efficient bridge inspection with regional information protection.

</details>


### [244] [Cross360: 360° Monocular Depth Estimation via Cross Projections Across Scales](https://arxiv.org/abs/2601.17271)
*Kun Huang,Fang-Lue Zhang,Neil Dodgson*

Main category: cs.CV

Relevance: 25.0

TL;DR: Cross360：一种基于交叉注意力的360度深度估计新架构，通过切线投影与等距柱面投影的特征对齐，实现局部与全局信息的有效整合


<details>
  <summary>Details</summary>
Motivation: 现有360度深度估计方法难以平衡全局连续性和局部一致性，局部块特征缺乏全局感知，全局表示无法解决块边界特征提取的不一致问题

Method: 提出Cross360架构：1) 交叉投影特征对齐模块使用交叉注意力将局部切线投影特征与等距柱面投影的360度视野对齐；2) 渐进式注意力特征聚合模块逐步细化多尺度特征

Result: 在大多数基准数据集上显著优于现有方法，特别是在完整360度图像可用的场景中，证明了其在准确和全局一致深度估计方面的有效性

Conclusion: Cross360通过交叉注意力机制有效整合局部和全局信息，解决了360度深度估计中的全局连续性与局部一致性平衡问题

Abstract: 360° depth estimation is a challenging research problem due to the difficulty of finding a representation that both preserves global continuity and avoids distortion in spherical images. Existing methods attempt to leverage complementary information from multiple projections, but struggle with balancing global and local consistency. Their local patch features have limited global perception, and the combined global representation does not address discrepancies in feature extraction at the boundaries between patches. To address these issues, we propose Cross360, a novel cross-attention-based architecture integrating local and global information using less-distorted tangent patches along with equirectangular features. Our Cross Projection Feature Alignment module employs cross-attention to align local tangent projection features with the equirectangular projection's 360° field of view, ensuring each tangent projection patch is aware of the global context. Additionally, our Progressive Feature Aggregation with Attention module refines multi-scaled features progressively, enhancing depth estimation accuracy. Cross360 significantly outperforms existing methods across most benchmark datasets, especially those in which the entire 360° image is available, demonstrating its effectiveness in accurate and globally consistent depth estimation. The code and model are available at https://github.com/huangkun101230/Cross360.

</details>


### [245] [TEXTS-Diff: TEXTS-Aware Diffusion Model for Real-World Text Image Super-Resolution](https://arxiv.org/abs/2601.17340)
*Haodong He,Xin Zhan,Yancheng Bai,Rui Lan,Lei Sun,Xiangxiang Chu*

Main category: cs.CV

Relevance: 25.0

TL;DR: 本文提出了Real-Texts数据集和TEXTS-Diff模型，用于解决真实世界文本图像超分辨率中文本区域恢复质量差的问题，通过构建大规模高质量数据集和文本感知扩散模型，在背景和文本区域都实现了高质量生成。


<details>
  <summary>Details</summary>
Motivation: 现有文本图像超分辨率方法面临两个主要问题：1) 现有数据集中文本图像数据稀缺，导致文本区域恢复效果差；2) 基于孤立文本样本的数据集限制了背景重建质量。需要构建覆盖真实场景的大规模高质量数据集，并开发能同时处理背景和文本区域的模型。

Method: 1) 构建Real-Texts数据集：从真实世界图像收集的大规模高质量数据集，覆盖多样化场景，包含中英文自然文本实例；2) 提出TEXTS-Diff模型：文本感知扩散模型，利用抽象概念提升对视觉场景中文本元素的理解，利用具体文本区域增强文本细节，减少文本区域的扭曲和幻觉伪影，同时保持高质量视觉场景保真度。

Result: 实验表明该方法在多个评估指标上达到最先进性能，在复杂场景中展现出优异的泛化能力和文本恢复准确性。模型在背景和文本区域都实现了高质量生成。

Conclusion: 通过构建大规模真实世界文本图像数据集和开发文本感知扩散模型，有效解决了文本图像超分辨率中文本区域恢复质量差的问题，为真实场景应用提供了实用解决方案。

Abstract: Real-world text image super-resolution aims to restore overall visual quality and text legibility in images suffering from diverse degradations and text distortions. However, the scarcity of text image data in existing datasets results in poor performance on text regions. In addition, datasets consisting of isolated text samples limit the quality of background reconstruction. To address these limitations, we construct Real-Texts, a large-scale, high-quality dataset collected from real-world images, which covers diverse scenarios and contains natural text instances in both Chinese and English. Additionally, we propose the TEXTS-Aware Diffusion Model (TEXTS-Diff) to achieve high-quality generation in both background and textual regions. This approach leverages abstract concepts to improve the understanding of textual elements within visual scenes and concrete text regions to enhance textual details. It mitigates distortions and hallucination artifacts commonly observed in text regions, while preserving high-quality visual scene fidelity. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple evaluation metrics, exhibiting superior generalization ability and text restoration accuracy in complex scenarios. All the code, model, and dataset will be released.

</details>


### [246] [NeRF-MIR: Towards High-Quality Restoration of Masked Images with Neural Radiance Fields](https://arxiv.org/abs/2601.17350)
*Xianliang Huang,Zhizhou Zhong,Shuhang Chen,Yi Xu,Juhong Guan,Shuigeng Zhou*

Main category: cs.CV

Relevance: 25.0

TL;DR: NeRF-MIR：一种用于修复掩码图像的神经渲染方法，通过PERE策略优化光线发射和PIRE机制进行渐进式恢复，在掩码图像修复任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: NeRF在新视角合成方面表现出色，但在处理自然场景中常见的损坏图像（如掩码图像）时仍有改进空间。现有方法在修复掩码图像方面存在不足，需要专门针对NeRF的掩码图像修复方法。

Method: 1) 提出PERE（基于补丁的熵光线发射）策略，通过分析图像纹理复杂度来优化光线分布；2) 引入PIRE（渐进迭代修复）机制进行自训练修复；3) 设计动态加权损失函数，自动调整掩码区域的损失权重；4) 构建三个掩码数据集用于评估。

Result: 在真实数据和构建的数据集上的大量实验表明，NeRF-MIR在掩码图像修复任务上优于现有方法，能够有效恢复损坏的3D场景。

Conclusion: NeRF-MIR展示了NeRF在掩码图像修复领域的潜力，提出的PERE和PIRE机制有效提升了修复性能，为处理损坏图像提供了新的解决方案。

Abstract: Neural Radiance Fields (NeRF) have demonstrated remarkable performance in novel view synthesis. However, there is much improvement room on restoring 3D scenes based on NeRF from corrupted images, which are common in natural scene captures and can significantly impact the effectiveness of NeRF. This paper introduces NeRF-MIR, a novel neural rendering approach specifically proposed for the restoration of masked images, demonstrating the potential of NeRF in this domain. Recognizing that randomly emitting rays to pixels in NeRF may not effectively learn intricate image textures, we propose a \textbf{P}atch-based \textbf{E}ntropy for \textbf{R}ay \textbf{E}mitting (\textbf{PERE}) strategy to distribute emitted rays properly. This enables NeRF-MIR to fuse comprehensive information from images of different views. Additionally, we introduce a \textbf{P}rogressively \textbf{I}terative \textbf{RE}storation (\textbf{PIRE}) mechanism to restore the masked regions in a self-training process. Furthermore, we design a dynamically-weighted loss function that automatically recalibrates the loss weights for masked regions. As existing datasets do not support NeRF-based masked image restoration, we construct three masked datasets to simulate corrupted scenarios. Extensive experiments on real data and constructed datasets demonstrate the superiority of NeRF-MIR over its counterparts in masked image restoration.

</details>


### [247] [HyDeMiC: A Deep Learning-based Mineral Classifier using Hyperspectral Data](https://arxiv.org/abs/2601.17352)
*M. L. Mamud,Piyoosh Jaysaval,Frederick D Day-Lewis,M. K. Mudunuru*

Main category: cs.CV

Relevance: 25.0

TL;DR: HyDeMiC是一个基于卷积神经网络的矿物分类模型，专门用于处理含噪声的高光谱数据，在低噪声条件下达到完美分类，在中等噪声下保持良好性能。


<details>
  <summary>Details</summary>
Motivation: 传统的高光谱矿物分类方法（如判别分析、逻辑回归、支持向量机）在处理环境噪声、传感器限制和高维数据计算复杂度方面存在困难。需要开发更鲁棒的分类方法以适应实际野外条件。

Method: 使用美国地质调查局（USGS）库中115种矿物的实验室测量高光谱数据，通过卷积参考矿物光谱与HSI传感器响应函数生成训练数据集。构建卷积神经网络（CNN）模型HyDeMiC，并在含1%、2%、5%和10%噪声的合成2D高光谱数据集上进行评估。

Result: HyDeMiC在清洁和低噪声数据集上达到近乎完美的分类准确率（MCC = 1.00），在中等噪声条件下仍保持强劲性能，展示了在实际高光谱成像应用中的鲁棒性。

Conclusion: HyDeMiC在含噪声的高光谱数据中表现出优异的矿物分类能力，为实际野外应用提供了有前景的解决方案，特别是在噪声是主要挑战的真实世界高光谱成像场景中。

Abstract: Hyperspectral imaging (HSI) has emerged as a powerful remote sensing tool for mineral exploration, capitalizing on unique spectral signatures of minerals. However, traditional classification methods such as discriminant analysis, logistic regression, and support vector machines often struggle with environmental noise in data, sensor limitations, and the computational complexity of analyzing high-dimensional HSI data. This study presents HyDeMiC (Hyperspectral Deep Learning-based Mineral Classifier), a convolutional neural network (CNN) model designed for robust mineral classification under noisy data. To train HyDeMiC, laboratory-measured hyperspectral data for 115 minerals spanning various mineral groups were used from the United States Geological Survey (USGS) library. The training dataset was generated by convolving reference mineral spectra with an HSI sensor response function. These datasets contained three copper-bearing minerals, Cuprite, Malachite, and Chalcopyrite, used as case studies for performance demonstration. The trained CNN model was evaluated on several synthetic 2D hyperspectral datasets with noise levels of 1%, 2%, 5%, and 10%. Our noisy data analysis aims to replicate realistic field conditions. The HyDeMiC's performance was assessed using the Matthews Correlation Coefficient (MCC), providing a comprehensive measure across different noise regimes. Results demonstrate that HyDeMiC achieved near-perfect classification accuracy (MCC = 1.00) on clean and low-noise datasets and maintained strong performance under moderate noise conditions. These findings emphasize HyDeMiC's robustness in the presence of moderate noise, highlighting its potential for real-world applications in hyperspectral imaging, where noise is often a significant challenge.

</details>


### [248] [ONRW: Optimizing inversion noise for high-quality and robust watermark](https://arxiv.org/abs/2601.17388)
*Xuan Ding,Xiu Yan,Chuanlong Xie,Yao Zhu*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出基于扩散模型的高质量鲁棒水印框架，通过空文本优化将干净图像转换为反转噪声，在潜在空间优化后通过迭代去噪生成水印图像，具有强大的净化机制以增强对图像损坏的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习水印方法虽然能在图像中隐藏水印且对图像质量影响小，但在传输过程中遇到图像损坏时缺乏鲁棒性，限制了实际应用价值。需要开发既能保持高质量又能抵抗各种图像损坏的鲁棒水印方法。

Method: 基于扩散模型的水印框架：1) 通过空文本优化过程将干净图像转换为反转噪声；2) 在潜在空间优化反转噪声；3) 通过扩散模型的迭代去噪过程生成高质量水印图像；4) 引入自注意力约束和伪掩码策略防止反转噪声优化扭曲图像原始语义。

Result: 在COCO数据集上，该方法在12种不同图像变换中平均比稳定签名方法高出10%，在各种图像损坏情况下表现出优越性能，证明了其鲁棒性和高质量水印生成能力。

Conclusion: 提出的基于扩散模型的水印框架能够生成高质量水印图像，并通过迭代去噪过程的净化机制增强水印对各种图像损坏的鲁棒性，为实际应用提供了有效的知识产权保护方案。

Abstract: Watermarking methods have always been effective means of protecting intellectual property, yet they face significant challenges. Although existing deep learning-based watermarking systems can hide watermarks in images with minimal impact on image quality, they often lack robustness when encountering image corruptions during transmission, which undermines their practical application value. To this end, we propose a high-quality and robust watermark framework based on the diffusion model. Our method first converts the clean image into inversion noise through a null-text optimization process, and after optimizing the inversion noise in the latent space, it produces a high-quality watermarked image through an iterative denoising process of the diffusion model. The iterative denoising process serves as a powerful purification mechanism, ensuring both the visual quality of the watermarked image and enhancing the robustness of the watermark against various corruptions. To prevent the optimizing of inversion noise from distorting the original semantics of the image, we specifically introduced self-attention constraints and pseudo-mask strategies. Extensive experimental results demonstrate the superior performance of our method against various image corruptions. In particular, our method outperforms the stable signature method by an average of 10\% across 12 different image transformations on COCO datasets. Our codes are available at https://github.com/920927/ONRW.

</details>


### [249] [SMV-EAR: Bring Spatiotemporal Multi-View Representation Learning into Efficient Event-Based Action Recognition](https://arxiv.org/abs/2601.17391)
*Rui Fan,Weidong Hao*

Main category: cs.CV

Relevance: 25.0

TL;DR: 本文提出了一种用于事件相机动作识别的新框架，通过平移不变的密集转换、双分支动态融合架构和生物启发的时序扭曲增强，显著提升了识别准确率并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 事件相机动作识别具有隐私保护和效率优势，但现有的时空多视图表示学习方法存在平移变异的空间分箱表示和简单的早期拼接融合架构限制。

Method: 1) 通过平移不变的密集转换创建时空多视图表示；2) 设计双分支动态融合架构，建模不同视图间运动特征的互补性；3) 引入生物启发的时序扭曲增强，模拟真实世界人类动作的速度变化。

Result: 在HARDVS、DailyDVS-200和THU-EACT-50-CHL三个数据集上，相比现有方法分别提升7.0%、10.7%和10.2%的Top-1准确率，同时参数减少30.1%，计算量降低35.7%。

Conclusion: 该框架为事件相机动作识别提供了一个新颖且强大的范式，在保持隐私保护和效率优势的同时，显著提升了识别性能。

Abstract: Event cameras action recognition (EAR) offers compelling privacy-protecting and efficiency advantages, where temporal motion dynamics is of great importance. Existing spatiotemporal multi-view representation learning (SMVRL) methods for event-based object recognition (EOR) offer promising solutions by projecting H-W-T events along spatial axis H and W, yet are limited by its translation-variant spatial binning representation and naive early concatenation fusion architecture. This paper reexamines the key SMVRL design stages for EAR and propose: (i) a principled spatiotemporal multi-view representation through translation-invariant dense conversion of sparse events, (ii) a dual-branch, dynamic fusion architecture that models sample-wise complementarity between motion features from different views, and (iii) a bio-inspired temporal warping augmentation that mimics speed variability of real-world human actions. On three challenging EAR datasets of HARDVS, DailyDVS-200 and THU-EACT-50-CHL, we show +7.0%, +10.7%, and +10.2% Top-1 accuracy gains over existing SMVRL EOR method with surprising 30.1% reduced parameters and 35.7% lower computations, establishing our framework as a novel and powerful EAR paradigm.

</details>


### [250] [ReflexSplit: Single Image Reflection Separation via Layer Fusion-Separation](https://arxiv.org/abs/2601.17468)
*Chia-Ming Lee,Yu-Fan Lin,Jing-Hui Jung,Yu-Jou Hsiao,Chih-Chung Hsu,Yu-Lun Liu*

Main category: cs.CV

Relevance: 25.0

TL;DR: ReflexSplit：一种用于单图像反射分离的双流框架，通过跨尺度门控融合、层融合-分离块和课程训练来解决非线性混合下的传输-反射混淆问题。


<details>
  <summary>Details</summary>
Motivation: 现有单图像反射分离方法在非线性混合情况下存在传输-反射混淆问题，特别是在深度解码器层中，这是由于隐式融合机制和多尺度协调不足导致的。

Method: 提出ReflexSplit双流框架，包含三个关键创新：1) 跨尺度门控融合(CrGF)自适应聚合语义先验、纹理细节和解码器上下文；2) 层融合-分离块(LFSB)交替进行融合和分离；3) 课程训练通过深度相关初始化和逐周期预热来增强差分分离。

Result: 在合成和真实世界基准测试中展示了最先进的性能，具有优越的感知质量和鲁棒泛化能力。

Conclusion: ReflexSplit通过创新的双流架构和训练策略，有效解决了单图像反射分离中的传输-反射混淆问题，实现了更好的分离效果。

Abstract: Single Image Reflection Separation (SIRS) disentangles mixed images into transmission and reflection layers. Existing methods suffer from transmission-reflection confusion under nonlinear mixing, particularly in deep decoder layers, due to implicit fusion mechanisms and inadequate multi-scale coordination. We propose ReflexSplit, a dual-stream framework with three key innovations. (1) Cross-scale Gated Fusion (CrGF) adaptively aggregates semantic priors, texture details, and decoder context across hierarchical depths, stabilizing gradient flow and maintaining feature consistency. (2) Layer Fusion-Separation Blocks (LFSB) alternate between fusion for shared structure extraction and differential separation for layer-specific disentanglement. Inspired by Differential Transformer, we extend attention cancellation to dual-stream separation via cross-stream subtraction. (3) Curriculum training progressively strengthens differential separation through depth-dependent initialization and epoch-wise warmup. Extensive experiments on synthetic and real-world benchmarks demonstrate state-of-the-art performance with superior perceptual quality and robust generalization. Our code is available at https://github.com/wuw2135/ReflexSplit.

</details>


### [251] [PhaSR: Generalized Image Shadow Removal with Physically Aligned Priors](https://arxiv.org/abs/2601.17470)
*Chia-Ming Lee,Yu-Fan Lin,Yu-Jou Hsiao,Jing-Hui Jung,Yu-Lun Liu,Chih-Chung Hsu*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出PhaSR方法，通过双级先验对齐解决多样化光照条件下的阴影去除问题，包括物理对齐归一化和几何语义矫正注意力机制


<details>
  <summary>Details</summary>
Motivation: 在多样化光照条件下进行阴影去除需要解耦光照和内在反射率，当物理先验未正确对齐时这一挑战更加复杂。传统方法在多光源环境光照下表现不佳。

Method: 1. 物理对齐归一化(PAN)：通过灰世界归一化、对数域Retinex分解和动态范围重组进行闭式光照校正，抑制色偏
2. 几何语义矫正注意力(GSRA)：扩展差分注意力到跨模态对齐，协调深度导出的几何信息与DINO-v2语义嵌入，解决不同光照下的模态冲突

Result: 在阴影去除方面表现出竞争性性能，具有更低的复杂度，并能泛化到传统方法在多光源光照下失效的环境光照条件

Conclusion: PhaSR通过双级先验对齐实现了从单光源阴影到多光源环境光照的鲁棒性能，解决了多样化光照条件下的阴影去除挑战

Abstract: Shadow removal under diverse lighting conditions requires disentangling illumination from intrinsic reflectance, a challenge compounded when physical priors are not properly aligned. We propose PhaSR (Physically Aligned Shadow Removal), addressing this through dual-level prior alignment to enable robust performance from single-light shadows to multi-source ambient lighting. First, Physically Aligned Normalization (PAN) performs closed-form illumination correction via Gray-world normalization, log-domain Retinex decomposition, and dynamic range recombination, suppressing chromatic bias. Second, Geometric-Semantic Rectification Attention (GSRA) extends differential attention to cross-modal alignment, harmonizing depth-derived geometry with DINO-v2 semantic embeddings to resolve modal conflicts under varying illumination. Experiments show competitive performance in shadow removal with lower complexity and generalization to ambient lighting where traditional methods fail under multi-source illumination. Our source code is available at https://github.com/ming053l/PhaSR.

</details>


### [252] [Saliency Driven Imagery Preprocessing for Efficient Compression -- Industrial Paper](https://arxiv.org/abs/2601.17555)
*Justin Downes,Sam Saltwick,Anthony Chen*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该论文提出了一种基于显著性图的卫星图像预处理方法，通过可变大小的平滑核映射到不同的量化显著性水平，在单个大型卫星图像内实现可变速率压缩。


<details>
  <summary>Details</summary>
Motivation: 卫星图像每天产生数百TB数据，存储和带宽成本高昂。许多下游任务只对图像中的小区域感兴趣，但标准图像编码方法对整个图像同等处理。需要利用显著性信息优化编码，重点关注重要区域。

Method: 使用显著性图驱动的图像预处理技术，结合传统有损压缩编码标准。通过可变大小的平滑核映射到不同的量化显著性水平，处理图像像素以优化下游压缩和编码方案。

Result: 该方法能够在单个大型卫星图像内实现可变速率图像压缩，根据区域重要性调整压缩质量，从而更有效地利用存储和带宽资源。

Conclusion: 显著性图驱动的预处理技术可以与标准压缩方法结合，为卫星图像提供更高效的压缩方案，特别适用于只关注特定区域的下游任务。

Abstract: The compression of satellite imagery remains an important research area as hundreds of terabytes of images are collected every day, which drives up storage and bandwidth costs. Although progress has been made in increasing the resolution of these satellite images, many downstream tasks are only interested in small regions of any given image. These areas of interest vary by task but, once known, can be used to optimize how information within the image is encoded. Whereas standard image encoding methods, even those optimized for remote sensing, work on the whole image equally, there are emerging methods that can be guided by saliency maps to focus on important areas. In this work we show how imagery preprocessing techniques driven by saliency maps can be used with traditional lossy compression coding standards to create variable rate image compression within a single large satellite image. Specifically, we use variable sized smoothing kernels that map to different quantized saliency levels to process imagery pixels in order to optimize downstream compression and encoding schemes.

</details>


### [253] [Revisiting 3D Reconstruction Kernels as Low-Pass Filters](https://arxiv.org/abs/2601.17900)
*Shengjun Zhang,Min Chen,Yibo Wei,Mingyu Dong,Yueqi Duan*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该论文从信号处理角度重新审视3D重建，提出Jinc核函数作为理想低通滤波器来解决离散采样引起的频谱扩展问题，并通过调制核函数平衡空间效率和频域保真度。


<details>
  <summary>Details</summary>
Motivation: 论文指出3D重建是从离散采样的2D像素恢复3D信号的过程，核心挑战是离散采样引起的周期性频谱扩展。现有3D重建核函数（如高斯、指数、学生t分布）作为低通滤波器存在不理想的低通特性，导致高频分量与低频分量在频谱中重叠。

Method: 提出Jinc核函数作为理想低通滤波器，在截止频率处具有瞬时降为零的特性。针对Jinc核在空间域衰减速度慢的问题，进一步提出调制核函数，在空间效率和频域保真度之间取得平衡。

Result: 实验结果表明Jinc核和调制核函数在渲染性能上表现优异，能够有效解决频谱重叠问题，提升3D重建质量。

Conclusion: 从信号处理视角重新审视3D重建问题，提出基于理想低通滤波器的核函数设计方法，为3D重建提供了新的理论框架和实用解决方案。

Abstract: 3D reconstruction is to recover 3D signals from the sampled discrete 2D pixels, with the goal to converge continuous 3D spaces. In this paper, we revisit 3D reconstruction from the perspective of signal processing, identifying the periodic spectral extension induced by discrete sampling as the fundamental challenge. Previous 3D reconstruction kernels, such as Gaussians, Exponential functions, and Student's t distributions, serve as the low pass filters to isolate the baseband spectrum. However, their unideal low-pass property results in the overlap of high-frequency components with low-frequency components in the discrete-time signal's spectrum. To this end, we introduce Jinc kernel with an instantaneous drop to zero magnitude exactly at the cutoff frequency, which is corresponding to the ideal low pass filters. As Jinc kernel suffers from low decay speed in the spatial domain, we further propose modulated kernels to strick an effective balance, and achieves superior rendering performance by reconciling spatial efficiency and frequency-domain fidelity. Experimental results have demonstrated the effectiveness of our Jinc and modulated kernels.

</details>


### [254] [MorphXAI: An Explainable Framework for Morphological Analysis of Parasites in Blood Smear Images](https://arxiv.org/abs/2601.18001)
*Aqsa Yousaf,Sint Sint Win,Megan Coffee,Habeeb Olufowobi*

Main category: cs.CV

Relevance: 25.0

TL;DR: MorphXAI是一个可解释的寄生虫检测框架，将寄生虫检测与细粒度形态学分析相结合，提供结构化的生物学解释。


<details>
  <summary>Details</summary>
Motivation: 寄生虫感染是全球健康挑战，特别是在资源匮乏地区，诊断依赖人工检查血涂片和专家知识。现有深度学习模型虽然性能强，但可解释性有限，现有解释方法主要局限于视觉热图或注意力图，无法捕捉临床医生依赖的形态特征。

Method: MorphXAI框架将形态学监督直接集成到预测流程中，使模型能够定位寄生虫的同时，表征临床相关属性，如形状、曲率、可见点计数、鞭毛存在和发育阶段。创建了包含三种寄生虫物种的临床医生标注数据集。

Result: 实验结果表明，MorphXAI不仅提高了检测性能，还提供了结构化的、具有生物学意义的解释。

Conclusion: 该工作提出了一个统一寄生虫检测与形态学分析的可解释框架，为可解释的寄生虫分析建立了新基准。

Abstract: Parasitic infections remain a pressing global health challenge, particularly in low-resource settings where diagnosis still depends on labor-intensive manual inspection of blood smears and the availability of expert domain knowledge. While deep learning models have shown strong performance in automating parasite detection, their clinical usefulness is constrained by limited interpretability. Existing explainability methods are largely restricted to visual heatmaps or attention maps, which highlight regions of interest but fail to capture the morphological traits that clinicians rely on for diagnosis. In this work, we present MorphXAI, an explainable framework that unifies parasite detection with fine-grained morphological analysis. MorphXAI integrates morphological supervision directly into the prediction pipeline, enabling the model to localize parasites while simultaneously characterizing clinically relevant attributes such as shape, curvature, visible dot count, flagellum presence, and developmental stage. To support this task, we curate a clinician-annotated dataset of three parasite species (Leishmania, Trypanosoma brucei, and Trypanosoma cruzi) with detailed morphological labels, establishing a new benchmark for interpretable parasite analysis. Experimental results show that MorphXAI not only improves detection performance over the baseline but also provides structured, biologically meaningful explanations.

</details>


### [255] [Strip-Fusion: Spatiotemporal Fusion for Multispectral Pedestrian Detection](https://arxiv.org/abs/2601.18008)
*Asiegbu Miracle Kanu-Asiegbu,Nitin Jotwani,Xiaoxiao Du*

Main category: cs.CV

Relevance: 25.0

TL;DR: Strip-Fusion：一种用于多光谱行人检测的时空融合网络，通过时间自适应卷积和KL散度损失来处理输入图像不对齐、光照变化和遮挡问题，在KAIST和CVC-14基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有多光谱行人检测方法主要关注空间融合而忽略时间信息，且RGB和热成像图像对可能不完全对齐。行人检测面临光照变化、遮挡等挑战，需要更鲁棒的解决方案。

Method: 提出Strip-Fusion时空融合网络：1）集成时间自适应卷积动态加权时空特征；2）设计KL散度损失缓解可见光和热成像模态不平衡；3）开发新的后处理算法减少误报。

Result: 在KAIST和CVC-14基准测试中表现优异，在严重遮挡和不对齐等挑战性条件下相比先前SOTA有显著改进。

Conclusion: Strip-Fusion通过时空融合和对齐鲁棒性设计，有效提升了多光谱行人检测性能，特别是在挑战性环境条件下。

Abstract: Pedestrian detection is a critical task in robot perception. Multispectral modalities (visible light and thermal) can boost pedestrian detection performance by providing complementary visual information. Several gaps remain with multispectral pedestrian detection methods. First, existing approaches primarily focus on spatial fusion and often neglect temporal information. Second, RGB and thermal image pairs in multispectral benchmarks may not always be perfectly aligned. Pedestrians are also challenging to detect due to varying lighting conditions, occlusion, etc. This work proposes Strip-Fusion, a spatial-temporal fusion network that is robust to misalignment in input images, as well as varying lighting conditions and heavy occlusions. The Strip-Fusion pipeline integrates temporally adaptive convolutions to dynamically weigh spatial-temporal features, enabling our model to better capture pedestrian motion and context over time. A novel Kullback-Leibler divergence loss was designed to mitigate modality imbalance between visible and thermal inputs, guiding feature alignment toward the more informative modality during training. Furthermore, a novel post-processing algorithm was developed to reduce false positives. Extensive experimental results show that our method performs competitively for both the KAIST and the CVC-14 benchmarks. We also observed significant improvements compared to previous state-of-the-art on challenging conditions such as heavy occlusion and misalignment.

</details>


### [256] [Leveraging Persistence Image to Enhance Robustness and Performance in Curvilinear Structure Segmentation](https://arxiv.org/abs/2601.18045)
*Zhuangzhi Gao,Feixiang Zhou,He Zhao,Xiuju Chen,Xiaoxin Li,Qinkai Yu,Yitian Zhao,Alena Shantsila,Gregory Y. H. Lip,Eduard Shantsila,Yalin Zheng*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出PIs-Regressor模块学习拓扑特征的持久性图像表示，结合Topology SegNet在编码解码阶段融合拓扑特征，提升医学图像中曲线结构分割的准确性和拓扑保真度。


<details>
  <summary>Details</summary>
Motivation: 医学图像中曲线结构分割对临床分析至关重要，整合拓扑属性（如连通性）能提高分割精度和一致性。然而，从持久性图中提取和嵌入拓扑特征存在非可微性和计算成本高的挑战。现有方法主要通过手工设计的损失函数编码拓扑，泛化能力差。

Method: 提出PIs-Regressor模块直接从数据中学习持久性图像（PI）——拓扑特征的有限可微表示。结合Topology SegNet在降采样和上采样阶段融合这些拓扑特征，将拓扑信息直接整合到网络架构中，而非辅助损失函数。框架灵活，可与其他拓扑方法结合。

Result: 在三个曲线结构基准测试中展示了最先进的性能，在像素级精度和拓扑保真度方面均有提升。实验表明整合拓扑特征增强了模型鲁棒性，能有效处理医学图像中的过曝光和模糊等挑战。

Conclusion: 通过将拓扑信息直接整合到网络架构中，而非依赖手工设计的损失函数，实现了更鲁棒的分割。该方法在医学图像曲线结构分割中取得了优异性能，为拓扑感知的深度学习提供了新思路。

Abstract: Segmenting curvilinear structures in medical images is essential for analyzing morphological patterns in clinical applications. Integrating topological properties, such as connectivity, improves segmentation accuracy and consistency. However, extracting and embedding such properties - especially from Persistence Diagrams (PD) - is challenging due to their non-differentiability and computational cost. Existing approaches mostly encode topology through handcrafted loss functions, which generalize poorly across tasks. In this paper, we propose PIs-Regressor, a simple yet effective module that learns persistence image (PI) - finite, differentiable representations of topological features - directly from data. Together with Topology SegNet, which fuses these features in both downsampling and upsampling stages, our framework integrates topology into the network architecture itself rather than auxiliary losses. Unlike existing methods that depend heavily on handcrafted loss functions, our approach directly incorporates topological information into the network structure, leading to more robust segmentation. Our design is flexible and can be seamlessly combined with other topology-based methods to further enhance segmentation performance. Experimental results show that integrating topological features enhances model robustness, effectively handling challenges like overexposure and blurring in medical imaging. Our approach on three curvilinear benchmarks demonstrate state-of-the-art performance in both pixel-level accuracy and topological fidelity.

</details>


### [257] [Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach](https://arxiv.org/abs/2601.18228)
*Sahil Naik,Soham Bagayatkar,Pavankumar Singh*

Main category: cs.CV

Relevance: 25.0

TL;DR: 本文提出基于EfficientNetB2的轻量级面部情绪识别管道，采用两阶段预热微调策略，结合AdamW优化、标签平滑等技术，在FER-2013数据集上达到68.78%的测试准确率，参数量比VGG16基线减少近10倍。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的面部情绪识别面临图像质量低、光照变化、姿态变化、背景干扰、类间差异小、标注噪声和类别不平衡等挑战。现有大型CNN方法（如VGG、ResNet）虽然精度尚可，但计算成本高、内存需求大，限制了实时应用。

Method: 使用EfficientNetB2构建轻量级管道，采用两阶段预热微调训练策略。技术增强包括：AdamW优化、解耦权重衰减、标签平滑（ε=0.06）减少标注噪声、裁剪类别权重缓解类别不平衡，以及dropout、混合精度训练和广泛的实时数据增强。

Result: 在FER-2013数据集上，使用分层87.5%/12.5%的训练验证分割，保持官方测试集不变，达到68.78%的测试准确率，参数量比VGG16基线减少近10倍。实验结果显示稳定的训练过程和强大的泛化能力。

Conclusion: 提出的轻量级方法在保持较高准确率的同时显著降低了计算复杂度，适合实时和边缘计算应用，为解决现实世界面部情绪识别挑战提供了实用解决方案。

Abstract: Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications.

</details>


### [258] [Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation](https://arxiv.org/abs/2601.18242)
*Zerui Kang,Yishen Lim,Zhouyou Gu,Seung-Woo Ko,Tony Q. S. Quek,Jihong Park*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出基于视觉语言模型（VLM）引导的框架，加速并稳定多材料参数估计，通过语义先验指导物理优化，实现快速可靠的射频材料估计


<details>
  <summary>Details</summary>
Motivation: 6G系统中电磁数字孪生需要准确的射频材料参数，但基于梯度的逆射线追踪对初始化敏感且在有限测量下成本高昂

Method: 使用VLM解析场景图像推断材料类别，通过ITU-R材料表映射到定量先验，提供电导率初始化；VLM进一步选择信息丰富的发射器/接收器位置；从这些先验开始，可微射线追踪引擎执行基于梯度的细化

Result: 在NVIDIA Sionna室内场景实验中，相比均匀或随机初始化及随机放置基准，收敛速度快2-4倍，最终参数误差低10-100倍，仅需少量接收器即可实现低于0.1%的平均相对误差

Conclusion: VLM的语义先验能有效指导基于物理的优化，实现快速可靠的射频材料估计，VLM引导的放置减少了准确恢复所需的测量

Abstract: Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\times$ faster convergence and 10-100$\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.

</details>


### [259] [Contextual Range-View Projection for 3D LiDAR Point Clouds](https://arxiv.org/abs/2601.18301)
*Seyedali Mousavi,Seyedhamidreza Mousavi,Masoud Daneshtalab*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该论文提出两种新的LiDAR点云到2D距离图像投影机制：中心感知投影(CAP)和类别加权感知投影(CWAP)，通过结合实例中心和类别信息来解决传统深度优先投影中的信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 传统LiDAR点云到距离图像的投影采用深度优先策略（保留最近点），忽略了语义相关性和对象结构，导致重要上下文信息丢失。需要改进投影策略以更好地保留语义信息。

Method: 提出两种机制：1) CAP：根据点到实例中心的距离调整深度值，优先保留实例中心点而非噪声边界点；2) CWAP：通过用户定义权重对对象类别进行优先级排序，提供灵活的投影策略。

Result: 在SemanticKITTI数据集上的评估显示，CAP在投影过程中保留了更多实例点，相比基线方法实现了高达3.1%的mIoU提升。CWAP能够增强目标类别的性能，同时对其他类别影响可忽略。

Conclusion: 通过结合实例中心和类别信息的投影策略，能够有效解决传统深度优先投影的信息丢失问题，提升3D点云到2D距离图像转换的质量和语义分割性能。

Abstract: Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \textit{Centerness-Aware Projection (CAP)} and \textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes

</details>


### [260] [OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI](https://arxiv.org/abs/2601.18368)
*Caterina Fuster-Barceló,Claudia Castrillón,Laura Rodrigo-Muñoz,Victor Manuel Vega-Suárez,Nicolás Pérez-Fernández,Gorka Bastarrika,Arrate Muñoz-Barrutia*

Main category: cs.CV

Relevance: 25.0

TL;DR: OREHAS是首个用于从常规3D MRI自动量化内耳内淋巴积水的全自动流程，通过深度学习分割和临床对齐的工作流，仅需少量标注即可实现可靠的体积测量。


<details>
  <summary>Details</summary>
Motivation: 内淋巴积水（EH）的准确量化对临床诊断至关重要，但现有方法依赖手动干预，存在操作者依赖性和方法不一致的问题。需要开发自动化流程来减少人为误差，提高可重复性。

Method: OREHAS整合了三个组件：切片分类、内耳定位和序列特异性分割，形成单一工作流，直接从完整MRI体积计算每耳内淋巴-前庭体积比（ELR）。仅需每个患者3-6个标注切片进行训练。

Result: 在SPACE-MRC上Dice分数达0.90，REAL-IR上达0.75。在外部验证队列中，与专家标注匹配度达74.3%，显著优于临床软件syngo.via的42.5%。测量结果更生理学合理。

Conclusion: OREHAS证明通过有限监督可以从标准MRI实现可靠、可重复的EH量化，减少操作者依赖，确保方法一致性，为大规模研究和临床诊断阈值重新校准提供基础。

Abstract: We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.
  Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.
  These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.

</details>


### [261] [Larger than memory image processing](https://arxiv.org/abs/2601.18407)
*Jon Sporring,David Stansby*

Main category: cs.CV

Relevance: 25.0

TL;DR: 该论文提出了一种面向超大规模图像数据（PB级）的流式处理架构，通过领域特定语言（DSL）自动优化数据访问模式，最小化I/O开销，实现内存受限环境下的高效分析。


<details>
  <summary>Details</summary>
Motivation: 处理PB级超大规模图像数据（如1.4PB电子显微镜体积数据、150TB人体器官图谱）时面临内存不足和I/O瓶颈问题。传统方法需要将整个数据集加载到内存中，这在处理超大规模数据时不可行。

Method: 1. 提出流式处理架构，将分析任务构建为数据流处理管道
2. 支持两种数据表示：2D切片堆栈和3D分块布局（Zarr/HDF5）
3. 引入基于扫描的执行、窗口化操作和重叠感知分块来最小化冗余访问
4. 设计领域特定语言（DSL），在编译时和运行时自动优化流水线，包括窗口大小选择、阶段融合、流操作和调度

Result: 实现了近线性的I/O扫描和可预测的内存占用，在内存受限的机器上显著提高了超大规模图像处理的吞吐量，无需将整个体积数据完全驻留内存。

Conclusion: 通过流式处理架构和DSL自动优化，能够高效处理PB级图像数据，特别适用于依赖邻域值的算法，为超大规模图像分析提供了可扩展的解决方案。

Abstract: This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.

</details>


### [262] [Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings](https://arxiv.org/abs/2601.18414)
*Aura Loredana Dan*

Main category: cs.CV

Relevance: 25.0

TL;DR: 本文比较了三种深度学习架构（MobileNet、EfficientNet、VGG16）在儿童绘画情感分类任务中的性能，重点关注计算效率与分类准确性的权衡。


<details>
  <summary>Details</summary>
Motivation: 自闭症谱系障碍（ASD）儿童情感表达困难，传统评估方法具有侵入性、主观性且难以一致应用。需要非侵入性的情感状态识别方法，儿童绘画分析为此提供了可能。

Method: 使用迁移学习在专家标注的儿童绘画数据集上训练三种深度学习架构：轻量级的MobileNet、平衡型的EfficientNet和较深的VGG16，在统一实验框架下评估分类性能、鲁棒性和计算效率。

Result: 研究揭示了轻量级架构与深层架构在基于绘画的情感计算任务中的权衡，特别是在移动和实时应用场景中，为实际应用提供了架构选择依据。

Conclusion: 深度学习模型可用于儿童绘画情感分类，但需要在计算效率和分类性能之间做出权衡，这对移动和实时应用尤为重要。

Abstract: Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts.

</details>


### [263] [AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging](https://arxiv.org/abs/2601.18560)
*Li Fang,Tianyu Li,Yanghong Lin,Shudong Zhou,Wei Yao*

Main category: cs.CV

Relevance: 25.0

TL;DR: 提出了一种用于高光谱图像分类的高效AI卫星边缘计算范式，采用轻量级非深度学习框架结合少样本学习策略，开发了两阶段像素级标签传播方案，无需空间结构信息，适合卫星资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像卫星在灾害监测和应急测绘等应用中需要快速响应能力，但卫星下行传输速度成为瓶颈。卫星平台资源有限，且可能面临传感器故障和扫描模式错误导致的图像质量退化问题。

Method: 采用轻量级非深度学习框架结合少样本学习策略。开发了两阶段像素级标签传播方案：第一阶段通过构建锚点-像素亲和矩阵传播选定锚点标签获得初始像素标签；第二阶段使用稀疏图的闭式解替代迭代计算。还开发了基于秩约束的图聚类算法确定锚点标签。

Result: 该方法能够在卫星边缘计算环境中实现高效的高光谱图像分类，仅利用像素级光谱特征，无需考虑空间结构信息，适应卫星平台的资源约束和图像质量问题。

Conclusion: 提出的AI卫星边缘计算范式使卫星具备自主决策能力，通过轻量级非深度学习方法和两阶段标签传播方案，有效解决了卫星资源受限和图像质量退化问题，适用于灾害监测等需要快速响应的应用场景。

Abstract: As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.

</details>


### [264] [CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search](https://arxiv.org/abs/2601.18625)
*Zequn Xie*

Main category: cs.CV

Relevance: 25.0

TL;DR: CONQUER是一个两阶段文本行人搜索框架，通过训练时增强跨模态对齐和推理时自适应查询优化，解决跨模态差异和模糊查询问题，在多个数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 文本行人搜索在公共安全应用中很重要，但面临跨模态差异和用户查询模糊的挑战。现有方法在训练时跨模态对齐不足，推理时无法处理不完整或模糊查询。

Method: 两阶段框架：1) 训练阶段使用多粒度编码、互补对挖掘和基于最优传输的上下文引导匹配学习鲁棒嵌入；2) 推理阶段通过即插即用查询增强模块（锚点选择和属性驱动丰富）优化模糊查询，无需重新训练主干网络。

Result: 在CUHK-PEDES、ICFG-PEDES和RSTPReid数据集上，CONQUER在Rank-1准确率和mAP指标上均优于强基线，在跨域和不完整查询场景中表现尤为突出。

Conclusion: CONQUER通过训练时增强对齐和推理时查询优化，为实际TBPS部署提供了实用有效的解决方案，代码已开源。

Abstract: Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.

</details>


### [265] [SPADE: A SIMD Posit-enabled compute engine for Accelerating DNN Efficiency](https://arxiv.org/abs/2601.17279)
*Sonu Kumar,Lavanya Vinnakota,Mukul Lokhande,Santosh Kumar Vishvakarma,Adam Teman*

Main category: cs.AR

Relevance: 25.0

TL;DR: SPADE：一种统一的多精度SIMD Posit MAC架构，支持Posit(8,0)、(16,1)、(32,2)格式，通过分层复用子模块实现硬件效率提升


<details>
  <summary>Details</summary>
Motivation: 边缘AI系统需要平衡数值精度、能效和硬件紧凑性的算术单元。Posit算术相比浮点和定点表示具有锥形精度、宽动态范围和更好的数值鲁棒性优势，但现有SIMD MAC架构多为单精度或浮点/定点设计，缺乏统一的多精度Posit支持。

Method: 提出SPADE架构，采用基于regime感知的lane-fused SIMD Posit数据通路，分层复用Posit特定子模块（LOD、补码器、移位器、乘法器）跨8/16/32位精度，避免数据通路复制，支持统一的多精度SIMD Posit MAC操作。

Result: FPGA实现显示：Posit(8,0)减少45.13% LUT和80% slice；Posit(16,1)和(32,2)相比先前工作提升28.44%和17.47%；多精度支持仅带来6.9% LUT和14.9%寄存器开销。ASIC在28nm节点达到1.38GHz@6.1mW。在MNIST、CIFAR-10/100等数据集上验证了竞争性推理精度。

Conclusion: SPADE为边缘AI系统提供了一种高效、紧凑的多精度Posit MAC架构，通过创新的数据通路设计显著减少硬件资源，同时保持数值精度和推理准确性。

Abstract: The growing demand for edge-AI systems requires arithmetic units that balance numerical precision, energy efficiency, and compact hardware while supporting diverse formats. Posit arithmetic offers advantages over floating- and fixed-point representations through its tapered precision, wide dynamic range, and improved numerical robustness. This work presents SPADE, a unified multi-precision SIMD Posit-based multiplyaccumulate (MAC) architecture supporting Posit (8,0), Posit (16,1), and Posit (32,2) within a single framework. Unlike prior single-precision or floating/fixed-point SIMD MACs, SPADE introduces a regime-aware, lane-fused SIMD Posit datapath that hierarchically reuses Posit-specific submodules (LOD, complementor, shifter, and multiplier) across 8/16/32-bit precisions without datapath replication. FPGA implementation on a Xilinx Virtex-7 shows 45.13% LUT and 80% slice reduction for Posit (8,0), and up to 28.44% and 17.47% improvement for Posit (16,1) and Posit (32,2) over prior work, with only 6.9% LUT and 14.9% register overhead for multi-precision support. ASIC results across TSMC nodes achieve 1.38 GHz at 6.1 mW (28 nm). Evaluation on MNIST, CIFAR-10/100, and alphabet datasets confirms competitive inference accuracy.

</details>


### [266] [ME-WARD: A multimodal ergonomic analysis tool for musculoskeletal risk assessment from inertial and video data in working plac](https://arxiv.org/abs/2601.17571)
*Javier González-Alonso,Paula Martín-Tapia,David González-Ortega,Míriam Antón-Rodríguez,Francisco Javier Díaz-Pernas,Mario Martínez-Zarzuela*

Main category: eess.SP

Relevance: 25.0

TL;DR: ME-WARD是一个多模态人体工程学评估系统，使用RULA方法处理来自IMU和深度学习姿态跟踪模型的关节角度数据，在工业环境中验证了其可靠性。


<details>
  <summary>Details</summary>
Motivation: 开发一个灵活的人体工程学评估系统，能够整合多种运动捕捉技术（包括低成本视频系统），为资源受限的工业环境提供可扩展、经济高效的解决方案。

Method: 实现Rapid Upper Limb Assessment (RULA)方法，处理来自IMU系统和单目3D姿态估计系统的关节角度数据，支持任何能够可靠测量关节角度的系统。

Result: 在传送带组装工业环境中验证，ME-WARD产生的RULA分数与IMU衍生指标高度一致（特别是屈曲主导运动），与单目系统性能相当，但在跟踪侧向和旋转运动方面存在局限。

Conclusion: ME-WARD展示了将多种运动捕捉技术整合到统一、可访问的人体工程学评估流程中的潜力，支持多样化输入源，为资源受限的工业环境提供了可扩展的解决方案。

Abstract: This study presents ME-WARD (Multimodal Ergonomic Workplace Assessment and Risk from Data), a novel system for ergonomic assessment and musculoskeletal risk evaluation that implements the Rapid Upper Limb Assessment (RULA) method. ME-WARD is designed to process joint angle data from motion capture systems, including inertial measurement unit (IMU)-based setups, and deep learning human body pose tracking models. The tool's flexibility enables ergonomic risk assessment using any system capable of reliably measuring joint angles, extending the applicability of RULA beyond proprietary setups. To validate its performance, the tool was tested in an industrial setting during the assembly of conveyor belts, which involved high-risk tasks such as inserting rods and pushing conveyor belt components. The experiments leveraged gold standard IMU systems alongside a state-of-the-art monocular 3D pose estimation system. The results confirmed that ME-WARD produces reliable RULA scores that closely align with IMU-derived metrics for flexion-dominated movements and comparable performance with the monocular system, despite limitations in tracking lateral and rotational motions. This work highlights the potential of integrating multiple motion capture technologies into a unified and accessible ergonomic assessment pipeline. By supporting diverse input sources, including low-cost video-based systems, the proposed multimodal approach offers a scalable, cost-effective solution for ergonomic assessments, paving the way for broader adoption in resource-constrained industrial environments.

</details>


### [267] [Grasp-and-Lift: Executable 3D Hand-Object Interaction Reconstruction via Physics-in-the-Loop Optimization](https://arxiv.org/abs/2601.18121)
*Byeonggyeol Choi,Woojin Oh,Jongwoo Lim*

Main category: cs.RO

Relevance: 25.0

TL;DR: 提出一个仿真循环优化框架，将视觉对齐的手部运动轨迹转换为物理可执行的轨迹，通过黑盒优化解决现有数据集在物理仿真中不真实的问题。


<details>
  <summary>Details</summary>
Motivation: 现有手部操作数据集（如DexYCB和HO3D）主要针对视觉对齐优化，但在物理仿真中回放时会产生物理上不合理的结果，如穿透、接触丢失和不稳定抓握，这限制了其在物理仿真和策略学习中的应用。

Method: 采用仿真循环优化框架，将轨迹转换问题表述为可处理的黑盒优化问题。使用基于稀疏时间关键帧的低维样条表示参数化手部运动，利用无梯度优化器CMA-ES将高保真物理引擎作为黑盒目标函数进行优化，在最大化物理成功率的同时最小化与原始人类演示的偏差。

Result: 相比MANIPTRANS等现有转移方法，该方法在回放时获得更低的手部和物体姿态误差，更准确地恢复手-物体物理交互，生成物理有效的轨迹。

Conclusion: 该方法提供了一种通用且可扩展的方法，将视觉演示转换为物理有效的轨迹，为鲁棒策略学习生成高保真数据。

Abstract: Dexterous hand manipulation increasingly relies on large-scale motion datasets with precise hand-object trajectory data. However, existing resources such as DexYCB and HO3D are primarily optimized for visual alignment but often yield physically implausible interactions when replayed in physics simulators, including penetration, missed contact, and unstable grasps.
  We propose a simulation-in-the-loop refinement framework that converts these visually aligned trajectories into physically executable ones. Our core contribution is to formulate this as a tractable black-box optimization problem. We parameterize the hand's motion using a low-dimensional, spline-based representation built on sparse temporal keyframes. This allows us to use a powerful gradient-free optimizer, CMA-ES, to treat the high-fidelity physics engine as a black-box objective function. Our method finds motions that simultaneously maximize physical success (e.g., stable grasp and lift) while minimizing deviation from the original human demonstration.
  Compared to MANIPTRANS-recent transfer pipelines, our approach achieves lower hand and object pose errors during replay and more accurately recovers hand-object physical interactions. Our approach provides a general and scalable method for converting visual demonstrations into physically valid trajectories, enabling the generation of high-fidelity data crucial for robust policy learning.

</details>


### [268] [Automated HER2 scoring with uncertainty quantification using lensfree holography and deep learning](https://arxiv.org/abs/2601.18219)
*Che-Yung Shen,Xilin Yang,Yuzhu Li,Leon Lenk,Aydogan Ozcan*

Main category: physics.med-ph

Relevance: 25.0

TL;DR: 基于无透镜全息成像与深度学习的紧凑型HER2评分系统，用于乳腺癌诊断，通过贝叶斯蒙特卡洛dropout进行不确定性量化，在资源有限环境下实现高精度HER2分类。


<details>
  <summary>Details</summary>
Motivation: 现有数字HER2评分方法依赖笨重昂贵的光学系统，不适用于资源有限环境。需要开发紧凑、低成本、高可靠性的自动化HER2评分平台。

Method: 结合无透镜全息成像平台与深度学习：1) 使用RGB激光照明捕获染色HER2组织切片的衍射图案；2) 获取复杂场信息，样本面积~1250 mm²，吞吐量~84 mm²/分钟；3) 集成贝叶斯蒙特卡洛dropout进行不确定性量化，提供预测置信度。

Result: 在412个组织样本的盲测中：4类HER2分类准确率84.9%，二元分类(0/1+ vs 2+/3+)准确率94.8%，不确定性量化使整体校正率达到30.4%。

Conclusion: 该无透镜全息方法为资源有限环境提供了便携、高通量、低成本的HER2评分实用途径，特别适用于缺乏传统数字病理基础设施的场景。

Abstract: Accurate assessment of human epidermal growth factor receptor 2 (HER2) expression is critical for breast cancer diagnosis, prognosis, and therapy selection; yet, most existing digital HER2 scoring methods rely on bulky and expensive optical systems. Here, we present a compact and cost-effective lensfree holography platform integrated with deep learning for automated HER2 scoring of immunohistochemically stained breast tissue sections. The system captures lensfree diffraction patterns of stained HER2 tissue sections under RGB laser illumination and acquires complex field information over a sample area of ~1,250 mm^2 at an effective throughput of ~84 mm^2 per minute. To enhance diagnostic reliability, we incorporated an uncertainty quantification strategy based on Bayesian Monte Carlo dropout, which provides autonomous uncertainty estimates for each prediction and supports reliable, robust HER2 scoring, with an overall correction rate of 30.4%. Using a blinded test set of 412 unique tissue samples, our approach achieved a testing accuracy of 84.9% for 4-class (0, 1+, 2+, 3+) HER2 classification and 94.8% for binary (0/1+ vs. 2+/3+) HER2 scoring with uncertainty quantification. Overall, this lensfree holography approach provides a practical pathway toward portable, high-throughput, and cost-effective HER2 scoring, particularly suited for resource-limited settings, where traditional digital pathology infrastructure is unavailable.

</details>


### [269] [Agreement-Driven Multi-View 3D Reconstruction for Live Cattle Weight Estimation](https://arxiv.org/abs/2601.17791)
*Rabin Dulal,Wenfeng Jia,Lihong Zheng,Jane Quinn*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出基于多视角RGB图像和SAM 3D重建的牛只活重非接触式估计算法，通过集成回归模型在低数据条件下实现实用化农场部署


<details>
  <summary>Details</summary>
Motivation: 传统牛只称重方法需要人工操作，影响生产效率和动物福利，需要开发低成本、非接触式的自动化活重估计方法

Method: 使用多视角RGB图像，结合SAM 3D重建与一致性引导融合生成3D点云，然后采用集成回归模型（包括经典集成模型和深度学习模型）进行重量估计

Result: SAM 3D多视角融合方法优于其他3D生成方法，经典集成模型在低数据条件下表现最稳定（R²=0.69±0.10，MAPE=2.22±0.56%）

Conclusion: 对于农场实际部署，提高3D重建质量比增加模型复杂度更重要，特别是在难以获取大量3D数据的场景下

Abstract: Accurate cattle live weight estimation is vital for livestock management, welfare, and productivity. Traditional methods, such as manual weighing using a walk-over weighing system or proximate measurements using body condition scoring, involve manual handling of stock and can impact productivity from both a stock and economic perspective. To address these issues, this study investigated a cost-effective, non-contact method for live weight calculation in cattle using 3D reconstruction. The proposed pipeline utilized multi-view RGB images with SAM 3D-based agreement-guided fusion, followed by ensemble regression. Our approach generates a single 3D point cloud per animal and compares classical ensemble models with deep learning models under low-data conditions. Results show that SAM 3D with multi-view agreement fusion outperforms other 3D generation methods, while classical ensemble models provide the most consistent performance for practical farm scenarios (R$^2$ = 0.69 $\pm$ 0.10, MAPE = 2.22 $\pm$ 0.56 \%), making this practical for on-farm implementation. These findings demonstrate that improving reconstruction quality is more critical than increasing model complexity for scalable deployment on farms where producing a large volume of 3D data is challenging.

</details>


### [270] [Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing](https://arxiv.org/abs/2601.18252)
*Chao Wang,Xuanying Li,Cheng Dai,Jinglei Feng,Yuxiang Luo,Yuqi Ouyang,Hao Qin*

Main category: cs.CV

Relevance: 20.0

TL;DR: Co-PLNet：一种点线协作框架，通过空间提示交换解决线框解析中线段与交点分离预测导致的匹配问题，提升几何结构感知的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有线框解析方法将线段和交点分开预测，然后进行后处理匹配，这会导致不匹配和鲁棒性降低。需要一种能够协同处理点线任务的框架来提升结构化几何感知能力。

Method: 提出点线协作框架Co-PLNet，包含点线提示编码器（PLP-Encoder）将早期检测转换为空间提示，以及交叉引导线段解码器（CGL-Decoder）通过稀疏注意力机制基于互补提示细化预测，强制点线一致性。

Result: 在Wireframe和YorkUrban数据集上实验显示，Co-PLNet在准确性和鲁棒性方面均取得一致提升，同时具有良好的实时效率。

Conclusion: Co-PLNet通过点线协作机制有效解决了线框解析中的匹配问题，为结构化几何感知提供了高效可靠的解决方案。

Abstract: Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.

</details>


### [271] [PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction](https://arxiv.org/abs/2601.18336)
*Isaac Deutsch,Nicolas Moënne-Loccoz,Gavriel State,Zan Gojcic*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出PPISP模块，通过物理可解释的ISP参数校正来解决多视角3D重建中的光度不一致问题，实现更好的泛化到新视角


<details>
  <summary>Details</summary>
Motivation: 多视角3D重建方法对相机光学特性和图像信号处理(ISP)变化引起的光度不一致性高度敏感。现有方法如每帧潜在变量或仿射颜色校正缺乏物理基础，对新视角泛化能力差

Method: 提出物理可解释的ISP(PPISP)校正模块，通过基于物理的可解释变换分离相机固有特性和拍摄相关效应。专门的PPISP控制器在输入视图上训练，预测新视角的ISP参数，类似于真实相机中的自动曝光和自动白平衡

Result: 在标准基准测试中达到最先进性能，同时提供直观控制，并在可用时支持元数据集成

Conclusion: PPISP模块能够实现真实且公平的新视角评估，无需访问真实图像，解决了多视角3D重建中的关键光度不一致问题

Abstract: Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp

</details>


### [272] [Estimation of geometric transformation matrices using grid-shaped pilot signals](https://arxiv.org/abs/2601.18385)
*Rinka Kawano,Masaki Kawamura*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出一种基于网格形导频信号的数字水印方法，通过分析几何变换后的网格畸变来估计变换矩阵，实现裁剪等攻击下的同步恢复。


<details>
  <summary>Details</summary>
Motivation: 现有数字水印方法对裁剪等几何变换攻击的鲁棒性不足，裁剪会改变图像原点，导致水印嵌入位置难以同步检测，影响水印正确提取。

Method: 在图像中嵌入网格形导频信号，水平和垂直线采用不同编码；当图像经历几何变换时，网格也会相应畸变；通过Radon变换分析畸变网格的角度和间隔来估计变换矩阵；利用水平垂直线的不同编码确定网格方向，减少歧义。

Result: 在各项异性缩放、旋转、剪切和裁剪等攻击下进行仿真验证，结果显示该方法能够准确估计变换矩阵，在单一和复合攻击下均保持低误差。

Conclusion: 提出的基于网格导频信号的水印方法能够有效处理裁剪等几何变换攻击，实现准确的水印同步，解决了现有方法在裁剪攻击下鲁棒性不足的问题。

Abstract: Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.

</details>


### [273] [Diagnosis Support of Sickle Cell Anemia by Classifying Red Blood Cell Shape in Peripheral Blood Images](https://arxiv.org/abs/2601.17032)
*Wilkie Delgado-Font,Miriela Escobedo-Nicot,Manuel González-Hidalgo,Silena Herold-Garcia,Antoni Jaume-i-Capó,Arnau Mir*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出基于外周血涂片图像分析的自动化红细胞分类方法，用于镰状细胞贫血诊断，通过Chan-Vese主动轮廓模型分割细胞，结合圆形和椭圆形形状因子进行分类，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 镰状细胞贫血等疾病导致红细胞变形，传统显微镜观察方法耗时、需要专家且主观性强、错误率高，需要自动化、客观的诊断方法。

Method: 使用Chan-Vese主动轮廓模型分割外周血涂片图像中的红细胞，然后基于圆形形状因子(CSF)和椭圆形形状因子(ESF)等基本形状分析描述符，将红细胞分类为正常、细长或其他变形。对于部分遮挡的细胞，采用椭圆调整方法分析盘状和细长形状的红细胞。

Result: 提出的方法在实验中优于现有方法，F-measure值达到0.97（正常细胞）和0.95（细长细胞），多个整体多类性能指标表现优异，适合临床治疗和镰状细胞贫血诊断支持。

Conclusion: 该方法为镰状细胞贫血的诊断提供了自动化、客观的解决方案，能够有效替代传统耗时的显微镜观察方法，具有临床应用价值。

Abstract: Red blood cell (RBC) deformation is the consequence of several diseases, including sickle cell anemia, which causes recurring episodes of pain and severe pronounced anemia. Monitoring patients with these diseases involves the observation of peripheral blood samples under a microscope, a time-consuming procedure. Moreover, a specialist is required to perform this technique, and owing to the subjective nature of the observation of isolated RBCs, the error rate is high. In this paper, we propose an automated method for differentially enumerating RBCs that uses peripheral blood smear image analysis. In this method, the objects of interest in the image are segmented using a Chan-Vese active contour model. An analysis is then performed to classify the RBCs, also called erythrocytes, as normal or elongated or having other deformations, using the basic shape analysis descriptors: circular shape factor (CSF) and elliptical shape factor (ESF). To analyze cells that become partially occluded in a cluster during sample preparation, an elliptical adjustment is performed to allow the analysis of erythrocytes with discoidal and elongated shapes. The images of patient blood samples used in the study were acquired by a clinical laboratory specialist in the Special Hematology Department of the ``Dr. Juan Bruno Zayas'' General Hospital in Santiago de Cuba. A comparison of the results obtained by the proposed method in our experiments with those obtained by some state-of-the-art methods showed that the proposed method is superior for the diagnosis of sickle cell anemia. This superiority is achieved for evidenced by the obtained F-measure value (0.97 for normal cells and 0.95 for elongated ones) and several overall multiclass performance measures. The results achieved by the proposed method are suitable for the purpose of clinical treatment and diagnostic support of sickle cell anemia.

</details>


### [274] [FP-THD: Full page transcription of historical documents](https://arxiv.org/abs/2601.17040)
*H Neji,J Nogueras-Iso,J Lacasta,MÁ Latre,FJ García-Marco*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了一种用于转录15-16世纪拉丁文历史文献的管道，通过布局分析模型提取文本行，再使用OCR模型进行识别，保留了原始字符和特殊符号。


<details>
  <summary>Details</summary>
Motivation: 历史文献转录面临特殊挑战，需要保留具有特定含义的字符和特殊符号，以确保历史文本保持原始风格和意义。现有方法在处理这些特殊特征方面存在不足。

Method: 提出一个两阶段管道：1) 使用布局分析模型分析历史文本图像并提取文本行；2) 将提取的文本行输入OCR模型生成完全数字化的页面。扩展了现有的文本行识别方法，结合了掩码自编码器来处理不同类型文本。

Result: 在多个数据集上评估表明，该管道能够有效处理页面并产生高效结果。掩码自编码器能够有效处理不同类型文本，包括手写体、印刷体和多语言文本。

Conclusion: 提出的管道为历史文献转录提供了一种有效解决方案，能够保留原始文档的特殊特征，为历史文本的数字化保存和分析提供了实用工具。

Abstract: The transcription of historical documents written in Latin in XV and XVI centuries has special challenges as it must maintain the characters and special symbols that have distinct meanings to ensure that historical texts retain their original style and significance. This work proposes a pipeline for the transcription of historical documents preserving these special features. We propose to extend an existing text line recognition method with a layout analysis model. We analyze historical text images using a layout analysis model to extract text lines, which are then processed by an OCR model to generate a fully digitized page. We showed that our pipeline facilitates the processing of the page and produces an efficient result. We evaluated our approach on multiple datasets and demonstrate that the masked autoencoder effectively processes different types of text, including handwritten, printed and multi-language.

</details>


### [275] [Atomic Depth Estimation From Noisy Electron Microscopy Data Via Deep Learning](https://arxiv.org/abs/2601.17046)
*Matan Leibovich,Mai Tan,Adria Marcos-Morales,Sreyas Mohan,Peter A. Crozier,Carlos Fernandez-Granda*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出一种从噪声TEM图像中提取3D原子级信息的新方法，将深度估计转化为语义分割问题，使用深度卷积神经网络生成像素级深度分割图


<details>
  <summary>Details</summary>
Motivation: 透射电子显微镜(TEM)图像通常受到显著噪声影响，难以从中提取3D原子级信息。现有方法在处理噪声TEM数据时存在局限性，需要开发更鲁棒的深度估计技术

Method: 将深度估计转化为语义分割问题，训练深度卷积神经网络生成像素级深度分割图。使用合成噪声污染的模拟数据进行训练，然后应用于真实TEM数据

Result: 方法在CeO2纳米颗粒的模拟图像和真实TEM数据上表现出准确的深度估计，结果经过校准且对噪声具有鲁棒性

Conclusion: 提出的基于语义分割的方法能够从噪声TEM图像中有效提取3D原子级深度信息，为材料科学中的原子尺度表征提供了新工具

Abstract: We present a novel approach for extracting 3D atomic-level information from transmission electron microscopy (TEM) images affected by significant noise. The approach is based on formulating depth estimation as a semantic segmentation problem. We address the resulting segmentation problem by training a deep convolutional neural network to generate pixel-wise depth segmentation maps using simulated data corrupted by synthetic noise. The proposed method was applied to estimate the depth of atomic columns in CeO2 nanoparticles from simulated images and real-world TEM data. Our experiments show that the resulting depth estimates are accurate, calibrated and robust to noise.

</details>


### [276] [Summary of the Unusual Activity Recognition Challenge for Developmental Disability Support](https://arxiv.org/abs/2601.17049)
*Christina Garcia,Nhat Tan Le,Taihei Fujioka,Umang Dobhal,Milyun Ni'ma Shoumi,Thanh Nha Nguyen,Sozo Inoue*

Main category: cs.CV

Relevance: 15.0

TL;DR: ISAS 2025挑战赛：基于姿态数据的异常行为识别，针对发育障碍人群护理设施，使用非侵入式姿态估计数据区分正常与异常活动


<details>
  <summary>Details</summary>
Motivation: 解决发育障碍人群护理设施中异常行为自动识别的关键需求，使用非侵入式姿态估计数据，避免隐私侵犯，同时处理真实世界的数据不平衡和时序不规则性

Method: 挑战赛采用基于视频记录提取的骨架关键点数据，使用留一受试者外(LOSO)评估策略确保主体无关泛化，参赛团队应用了从经典机器学习到深度学习架构的多种方法

Result: 40个团队参与，主要使用宏平均F1分数评估以处理类别不平衡，结果显示在噪声低维数据中建模罕见、突发动作具有挑战性，强调捕捉时间和上下文细微差别的重要性

Conclusion: 该挑战赛突显了在嘈杂低维数据中识别罕见异常行为的困难，为医疗保健和行为监测的社会责任AI应用提供了重要见解

Abstract: This paper presents an overview of the Recognize the Unseen: Unusual Behavior Recognition from Pose Data Challenge, hosted at ISAS 2025. The challenge aims to address the critical need for automated recognition of unusual behaviors in facilities for individuals with developmental disabilities using non-invasive pose estimation data. Participating teams were tasked with distinguishing between normal and unusual activities based on skeleton keypoints extracted from video recordings of simulated scenarios. The dataset reflects real-world imbalance and temporal irregularities in behavior, and the evaluation adopted a Leave-One-Subject-Out (LOSO) strategy to ensure subject-agnostic generalization. The challenge attracted broad participation from 40 teams applying diverse approaches ranging from classical machine learning to deep learning architectures. Submissions were assessed primarily using macro-averaged F1 scores to account for class imbalance. The results highlight the difficulty of modeling rare, abrupt actions in noisy, low-dimensional data, and emphasize the importance of capturing both temporal and contextual nuances in behavior modeling. Insights from this challenge may contribute to future developments in socially responsible AI applications for healthcare and behavior monitoring.

</details>


### [277] [Synthetic Data Guided Feature Selection for Robust Activity Recognition in Older Adults](https://arxiv.org/abs/2601.17053)
*Shuhao Que,Dieuwke van Dartel,Ilse Heeringa,Han Hegeman,Miriam Vollenbroek-Hutten,Ying Wang*

Main category: cs.CV

Relevance: 15.0

TL;DR: 开发用于髋部骨折康复的老年人活动识别系统，使用合成数据提升模型泛化能力，在姿态转移检测上取得显著改进


<details>
  <summary>Details</summary>
Motivation: 髋部骨折康复期间的身体活动监测对老年患者功能恢复至关重要，但现有基于可穿戴设备的监测系统主要针对中年人群开发，在步态缓慢多变的老年人中表现不可靠，需要专门为老年人设计更稳健的活动识别系统

Method: 研究纳入24名80岁以上健康老年人，在模拟自由生活条件下进行日常活动（行走、站立、坐、躺、姿态转移），使用腰部和大腿前侧两个加速度计采集数据。采用留一交叉验证评估模型鲁棒性，开发特征干预模型（FIM）并利用合成数据指导提升泛化能力

Result: FIM模型在合成数据辅助下取得可靠的活动识别性能：行走F1分数0.896、站立0.927、坐0.997、躺0.937、姿态转移0.816。相比无合成数据的对照组，FIM显著改善了姿态转移检测（临床高度相关但常被忽视的活动类别）

Conclusion: 初步结果证明了在老年人中实现稳健活动识别的可行性，但需要在髋部骨折患者群体中进一步验证以评估所提监测系统的临床效用

Abstract: Physical activity during hip fracture rehabilitation is essential for mitigating long-term functional decline in geriatric patients. However, it is rarely quantified in clinical practice. Existing continuous monitoring systems with commercially available wearable activity trackers are typically developed in middle-aged adults and therefore perform unreliably in older adults with slower and more variable gait patterns. This study aimed to develop a robust human activity recognition (HAR) system to improve continuous physical activity recognition in the context of hip fracture rehabilitation. 24 healthy older adults aged over 80 years were included to perform activities of daily living (walking, standing, sitting, lying down, and postural transfers) under simulated free-living conditions for 75 minutes while wearing two accelerometers positioned on the lower back and anterior upper thigh. Model robustness was evaluated using leave-one-subject-out cross-validation. The synthetic data demonstrated potential to improve generalization across participants. The resulting feature intervention model (FIM), aided by synthetic data guidance, achieved reliable activity recognition with mean F1-scores of 0.896 for walking, 0.927 for standing, 0.997 for sitting, 0.937 for lying down, and 0.816 for postural transfers. Compared with a control condition model without synthetic data, the FIM significantly improved the postural transfer detection, i.e., an activity class of high clinical relevance that is often overlooked in existing HAR literature. In conclusion, these preliminary results demonstrate the feasibility of robust activity recognition in older adults. Further validation in hip fracture patient populations is required to assess the clinical utility of the proposed monitoring system.

</details>


### [278] [A Computer Vision Pipeline for Iterative Bullet Hole Tracking in Rifle Zeroing](https://arxiv.org/abs/2601.17062)
*Robert M. Belcher,Brendan C. Degryse,Leonard R. Kosta,Christopher J. Lowrance*

Main category: cs.CV

Relevance: 15.0

TL;DR: 基于YOLOv8和IoU分析的计算机视觉系统，用于自动检测和追踪射击弹孔，支持步枪瞄准具校准


<details>
  <summary>Details</summary>
Motivation: 传统步枪瞄准具校准需要人工检查弹孔，存在安全延迟和人为错误风险。需要自动化系统来实时检测和追踪弹孔，提高校准效率和准确性。

Method: 1. 使用YOLOv8进行小目标检测；2. 通过IoU分析区分不同射击轮次的弹孔；3. 提出新颖的数据增强技术（移除而非添加对象）来模拟真实射击序列；4. 基于ORB的透视校正预处理管道标准化目标方向。

Result: 系统在弹孔检测上达到97.0%的平均精度，在将弹孔分配到正确射击轮次上达到88.8%的准确率。

Conclusion: 该计算机视觉系统能有效自动化步枪瞄准具校准过程，减少人为错误和延迟。虽然专为步枪校准设计，但框架可扩展到其他需要时序区分视觉相似对象的领域。

Abstract: Adjusting rifle sights, a process commonly called "zeroing," requires shooters to identify and differentiate bullet holes from multiple firing iterations. Traditionally, this process demands physical inspection, introducing delays due to range safety protocols and increasing the risk of human error. We present an end-to-end computer vision system for automated bullet hole detection and iteration-based tracking directly from images taken at the firing line. Our approach combines YOLOv8 for accurate small-object detection with Intersection over Union (IoU) analysis to differentiate bullet holes across sequential images. To address the scarcity of labeled sequential data, we propose a novel data augmentation technique that removes rather than adds objects to simulate realistic firing sequences. Additionally, we introduce a preprocessing pipeline that standardizes target orientation using ORB-based perspective correction, improving model accuracy. Our system achieves 97.0% mean average precision on bullet hole detection and 88.8% accuracy in assigning bullet holes to the correct firing iteration. While designed for rifle zeroing, this framework offers broader applicability in domains requiring the temporal differentiation of visually similar objects.

</details>


### [279] [Decoding Psychological States Through Movement: Inferring Human Kinesic Functions with Application to Built Environments](https://arxiv.org/abs/2601.17194)
*Cheyu Lin,Katherine A. Flanigan,Sirajum Munir*

Main category: cs.CV

Relevance: 15.0

TL;DR: 论文提出了DUET数据集和基于运动学的识别框架，用于隐私保护地测量社会互动中的交流功能，填补了建筑环境研究中社会互动量化方法的空白。


<details>
  <summary>Details</summary>
Motivation: 当前建筑环境研究缺乏一致且隐私保护的社会互动测量方法，导致不同研究对"互动"的操作化定义不一致，限制了评估设计干预对社交资本相关行为影响的能力。

Method: 1) 创建DUET数据集：包含12种二元互动，涵盖Ekman和Friesen运动学分类的五个功能（标志、说明、情感表达、适应、调节），使用四种传感模态和三种建筑环境；2) 开发识别框架：直接从隐私保护的骨骼运动推断交流功能，无需手工制作动作到功能的字典；3) 使用迁移学习架构，评估六个开源人类活动识别模型。

Result: 1) 基准测试显示现有模型在交流功能识别上的困难，凸显了单子动作识别扩展到二元社会互动测量的局限性；2) 识别框架揭示了运动学功能的结构化聚类；3) 表示质量与分类性能强相关，且能跨主体和环境泛化。

Conclusion: DUET数据集和识别框架为建筑环境研究提供了隐私保护的社会互动测量工具，能够量化社交资本相关行为，支持设计干预的效果评估。

Abstract: Social infrastructure and other built environments are increasingly expected to support well-being and community resilience by enabling social interaction. Yet in civil and built-environment research, there is no consistent and privacy-preserving way to represent and measure socially meaningful interaction in these spaces, leaving studies to operationalize "interaction" differently across contexts and limiting practitioners' ability to evaluate whether design interventions are changing the forms of interaction that social capital theory predicts should matter. To address this field-level and methodological gap, we introduce the Dyadic User Engagement DataseT (DUET) dataset and an embedded kinesics recognition framework that operationalize Ekman and Friesen's kinesics taxonomy as a function-level interaction vocabulary aligned with social capital-relevant behaviors (e.g., reciprocity and attention coordination). DUET captures 12 dyadic interactions spanning all five kinesic functions-emblems, illustrators, affect displays, adaptors, and regulators-across four sensing modalities and three built-environment contexts, enabling privacy-preserving analysis of communicative intent through movement. Benchmarking six open-source, state-of-the-art human activity recognition models quantifies the difficulty of communicative-function recognition on DUET and highlights the limitations of ubiquitous monadic, action-level recognition when extended to dyadic, socially grounded interaction measurement. Building on DUET, our recognition framework infers communicative function directly from privacy-preserving skeletal motion without handcrafted action-to-function dictionaries; using a transfer-learning architecture, it reveals structured clustering of kinesic functions and a strong association between representation quality and classification performance while generalizing across subjects and contexts.

</details>


### [280] [Structural Complexity of Brain MRI reveals age-associated patterns](https://arxiv.org/abs/2601.17211)
*Anzhe Cheng,Italo Ivo Lima Dias Pinto,Paul Bogdan*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了一种用于三维信号（特别是脑MRI）的结构复杂度分析方法，通过多尺度粗粒化量化信息损失，并引入滑动窗口方案提高粗分辨率下的稳定性，发现脑结构复杂度随年龄系统性下降。


<details>
  <summary>Details</summary>
Motivation: 传统结构复杂度分析主要针对一维或二维信号，缺乏对三维信号（如脑MRI）的有效分析框架。现有块状粗粒化方法在粗分辨率下因采样不足而不稳定，需要更稳健的方法来捕捉三维数据的多尺度组织特征。

Method: 1) 将结构复杂度分析扩展到三维信号；2) 提出滑动窗口粗粒化方案替代传统块状方法，在粗分辨率下提供更平滑的估计；3) 通过逐步粗粒化信号并量化连续分辨率间的信息损失来捕捉多尺度组织；4) 应用于大规模结构MRI数据集分析年龄相关变化。

Result: 1) 滑动窗口方法在粗分辨率下比传统块状方法更稳定；2) 脑结构复杂度随年龄系统性下降；3) 最显著的年龄效应出现在较粗尺度上；4) 结构复杂度可作为从脑MRI预测生物年龄的有效工具。

Conclusion: 该研究扩展了结构复杂度分析到三维成像数据，提出的滑动窗口方法提高了多尺度分析的稳健性，证实了脑结构复杂度随年龄下降的规律，为脑MRI的多尺度分析和生物年龄预测提供了可靠工具。

Abstract: We adapt structural complexity analysis to three-dimensional signals, with an emphasis on brain magnetic resonance imaging (MRI). This framework captures the multiscale organization of volumetric data by coarse-graining the signal at progressively larger spatial scales and quantifying the information lost between successive resolutions. While the traditional block-based approach can become unstable at coarse resolutions due to limited sampling, we introduce a sliding-window coarse-graining scheme that provides smoother estimates and improved robustness at large scales. Using this refined method, we analyze large structural MRI datasets spanning mid- to late adulthood and find that structural complexity decreases systematically with age, with the strongest effects emerging at coarser scales. These findings highlight structural complexity as a reliable signal processing tool for multiscale analysis of 3D imaging data, while also demonstrating its utility in predicting biological age from brain MRI.

</details>


### [281] [SymbolSight: Minimizing Inter-Symbol Interference for Reading with Prosthetic Vision](https://arxiv.org/abs/2601.17326)
*Jasmine Lesner,Michael Beyeler*

Main category: cs.CV

Relevance: 15.0

TL;DR: SymbolSight框架通过优化视觉符号与字母的映射关系，减少视网膜假体视觉中的时序干扰，利用语言特定双字母统计和神经代理观察器来最小化相邻字母的混淆


<details>
  <summary>Details</summary>
Motivation: 视网膜假体视觉分辨率低且存在时序持续性，导致序列字母呈现时前一个符号的残像会干扰下一个符号的识别，产生系统性识别错误。研究旨在通过优化视觉符号本身而非依赖硬件改进来缓解这种时序干扰。

Method: 提出SymbolSight计算框架：1) 使用模拟假体视觉(SPV)和神经代理观察器估计符号对之间的混淆度；2) 利用语言特定双字母统计信息；3) 优化符号到字母的映射以最小化频繁相邻字母之间的混淆。

Result: 在阿拉伯语、保加利亚语和英语的模拟实验中，生成的异质符号集将预测混淆度相对于原生字母表降低了中位数22倍，表明标准排版不适合序列低带宽假体视觉。

Conclusion: 计算建模可以有效缩小视觉编码的设计空间，为未来的心理物理和临床评估生成高潜力候选方案，标准排版与序列低带宽假体视觉不匹配。

Abstract: Retinal prostheses restore limited visual perception, but low spatial resolution and temporal persistence make reading difficult. In sequential letter presentation, the afterimage of one symbol can interfere with perception of the next, leading to systematic recognition errors. Rather than relying on future hardware improvements, we investigate whether optimizing the visual symbols themselves can mitigate this temporal interference. We present SymbolSight, a computational framework that selects symbol-to-letter mappings to minimize confusion among frequently adjacent letters. Using simulated prosthetic vision (SPV) and a neural proxy observer, we estimate pairwise symbol confusability and optimize assignments using language-specific bigram statistics. Across simulations in Arabic, Bulgarian, and English, the resulting heterogeneous symbol sets reduced predicted confusion by a median factor of 22 relative to native alphabets. These results suggest that standard typography is poorly matched to serial, low-bandwidth prosthetic vision and demonstrate how computational modeling can efficiently narrow the design space of visual encodings to generate high-potential candidates for future psychophysical and clinical evaluation.

</details>


### [282] [Revisiting Lightweight Low-Light Image Enhancement: From a YUV Color Space Perspective](https://arxiv.org/abs/2601.17349)
*Hailong Yan,Shice Liu,Xiangtao Zhang,Lujian Yao,Fengxiang Yang,Jinwei Chen,Bo Li*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出了一种基于YUV颜色空间的轻量级低光照图像增强方法，通过频域分析发现Y通道主要丢失低频内容而UV通道受高频噪声影响，设计了针对不同通道特性的注意力模块来提升性能并减少参数量。


<details>
  <summary>Details</summary>
Motivation: 移动互联网时代需要轻量级低光照图像增强技术，但现有方法在视觉质量和模型紧凑性之间存在权衡。虽然最近的方法使用解耦策略（如Retinex理论和YUV颜色空间变换）来简化架构设计，但它们的性能受到忽视通道特定退化模式和跨通道交互的根本限制。

Method: 1) 进行频域分析确认YUV颜色空间对L3IE的优越性；2) 发现关键洞察：Y通道主要丢失低频内容，UV通道受高频噪声影响；3) 提出基于YUV的新范式：为Y通道设计双流全局-局部注意力模块，为UV通道设计Y引导的局部感知频率注意力模块，以及用于最终特征融合的引导交互模块。

Result: 在多个基准测试中建立了新的最先进水平，以显著更低的参数量提供卓越的视觉质量。

Conclusion: 通过频域分析揭示了YUV颜色空间中不同通道的退化特性，并基于此设计了针对性的注意力机制，实现了轻量级低光照图像增强在视觉质量和模型紧凑性之间的更好平衡。

Abstract: In the current era of mobile internet, Lightweight Low-Light Image Enhancement (L3IE) is critical for mobile devices, which faces a persistent trade-off between visual quality and model compactness. While recent methods employ disentangling strategies to simplify lightweight architectural design, such as Retinex theory and YUV color space transformations, their performance is fundamentally limited by overlooking channel-specific degradation patterns and cross-channel interactions. To address this gap, we perform a frequency-domain analysis that confirms the superiority of the YUV color space for L3IE. We identify a key insight: the Y channel primarily loses low-frequency content, while the UV channels are corrupted by high-frequency noise. Leveraging this finding, we propose a novel YUV-based paradigm that strategically restores channels using a Dual-Stream Global-Local Attention module for the Y channel, a Y-guided Local-Aware Frequency Attention module for the UV channels, and a Guided Interaction module for final feature fusion. Extensive experiments validate that our model establishes a new state-of-the-art on multiple benchmarks, delivering superior visual quality with a significantly lower parameter count.

</details>


### [283] [PocketGS: On-Device Training of 3D Gaussian Splatting for High Perceptual Modeling](https://arxiv.org/abs/2601.17354)
*Wenzhi Guo,Guangchi Fang,Shu Yang,Bing Wang*

Main category: cs.CV

Relevance: 15.0

TL;DR: PocketGS：一种移动端3D高斯泼溅方法，能在移动设备上实现高效、高保真的3D场景建模，解决了标准3DGS在移动设备上的资源限制问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯泼溅方法依赖资源不受限的训练假设，无法在移动设备上运行，因为移动设备受限于分钟级训练预算和硬件可用峰值内存。需要一种能在这些严格约束下进行设备端3DGS训练的方法。

Method: 提出了PocketGS移动场景建模范式，包含三个协同设计的算子：G算子构建几何保真的点云先验；I算子注入局部表面统计信息以初始化各向异性高斯分布，减少早期条件差距；T算子通过缓存中间结果和索引映射梯度散射展开alpha合成，实现稳定的移动端反向传播。

Result: 实验表明PocketGS能够超越主流工作站3DGS基线，提供高质量重建，实现了完全设备端的从捕捉到渲染的实用工作流程。

Conclusion: PocketGS解决了标准3DGS在移动设备上的基本矛盾，满足了训练效率、内存紧凑性和建模保真度的竞争要求，实现了移动端高效高保真3D场景建模。

Abstract: Efficient and high-fidelity 3D scene modeling is a long-standing pursuit in computer graphics. While recent 3D Gaussian Splatting (3DGS) methods achieve impressive real-time modeling performance, they rely on resource-unconstrained training assumptions that fail on mobile devices, which are limited by minute-scale training budgets and hardware-available peak-memory. We present PocketGS, a mobile scene modeling paradigm that enables on-device 3DGS training under these tightly coupled constraints while preserving high perceptual fidelity. Our method resolves the fundamental contradictions of standard 3DGS through three co-designed operators: G builds geometry-faithful point-cloud priors; I injects local surface statistics to seed anisotropic Gaussians, thereby reducing early conditioning gaps; and T unrolls alpha compositing with cached intermediates and index-mapped gradient scattering for stable mobile backpropagation. Collectively, these operators satisfy the competing requirements of training efficiency, memory compactness, and modeling fidelity. Extensive experiments demonstrate that PocketGS is able to outperform the powerful mainstream workstation 3DGS baseline to deliver high-quality reconstructions, enabling a fully on-device, practical capture-to-rendering workflow.

</details>


### [284] [Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity](https://arxiv.org/abs/2601.17408)
*Harsharaj Pathak,Vineeth N Balasubramanian*

Main category: cs.CV

Relevance: 15.0

TL;DR: 本文提出了一种基于邻域签名的无源域自适应方法，通过优化目标域样本预测的相似性和相异性，使用单一损失函数实现模型适应，在VisDA数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 无源域自适应（SFDA）旨在不使用源域数据的情况下，将模型从有标签的源域适应到无标签的目标域。现有方法大多依赖邻域一致性概念，但容易受到误导性邻域信息的影响而产生错误。

Method: 提出邻域签名概念，通过优化目标域样本预测的相似性和相异性来学习更具信息性的聚类并减轻噪声邻域的影响。该方法仅使用一个专门设计的损失函数来实现适应。

Result: 在具有挑战性的VisDA数据集上超越了现有方法，在其他基准数据集上也取得了有竞争力的结果。

Conclusion: 通过邻域签名概念和专门设计的单一损失函数，可以有效解决SFDA中的邻域信息误导问题，实现更好的域自适应性能。

Abstract: Source-Free Domain Adaptation (SFDA) is an emerging area of research that aims to adapt a model trained on a labeled source domain to an unlabeled target domain without accessing the source data. Most of the successful methods in this area rely on the concept of neighborhood consistency but are prone to errors due to misleading neighborhood information. In this paper, we explore this approach from the point of view of learning more informative clusters and mitigating the effect of noisy neighbors using a concept called neighborhood signature, and demonstrate that adaptation can be achieved using just a single loss term tailored to optimize the similarity and dissimilarity of predictions of samples in the target domain. In particular, our proposed method outperforms existing methods in the challenging VisDA dataset while also yielding competitive results on other benchmark datasets.

</details>


### [285] [An AI-enabled tool for quantifying overlapping red blood cell sickling dynamics in microfluidic assays](https://arxiv.org/abs/2601.17703)
*Nikhil Kadivar,Guansheng Li,Jianlu Zheng,John M. Higgins,Ming Dao,George Em Karniadakis,Mengjia Xu*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出一个结合AI辅助标注、分割、分类和实例计数的深度学习框架，用于量化时间序列显微镜数据中不同密度条件下的红细胞群体，特别是镰状细胞动态变化。


<details>
  <summary>Details</summary>
Motivation: 理解镰状细胞动态需要准确识别不同生物物理条件下的形态转变，特别是在密集堆积和重叠的细胞群体中。传统方法面临手动标注稀缺和细胞重叠的挑战。

Method: 使用Roboflow平台标注实验图像生成标注数据集，训练nnU-Net分割模型，结合分水岭算法解决细胞重叠问题，实现自动化的细胞分割、分类和实例计数。

Result: 框架仅需少量标注数据就能实现高分割性能，通过密集细胞悬浮液将实验通量提高一倍以上，捕捉药物依赖的镰状化行为，揭示细胞形态演变的独特机械生物学特征。

Conclusion: 这个AI驱动的框架建立了一个可扩展、可重复的计算平台，用于研究细胞生物力学和评估微生理系统中的治疗效果。

Abstract: Understanding sickle cell dynamics requires accurate identification of morphological transitions under diverse biophysical conditions, particularly in densely packed and overlapping cell populations. Here, we present an automated deep learning framework that integrates AI-assisted annotation, segmentation, classification, and instance counting to quantify red blood cell (RBC) populations across varying density regimes in time-lapse microscopy data. Experimental images were annotated using the Roboflow platform to generate labeled dataset for training an nnU-Net segmentation model. The trained network enables prediction of the temporal evolution of the sickle cell fraction, while a watershed algorithm resolves overlapping cells to enhance quantification accuracy. Despite requiring only a limited amount of labeled data for training, the framework achieves high segmentation performance, effectively addressing challenges associated with scarce manual annotations and cell overlap. By quantitatively tracking dynamic changes in RBC morphology, this approach can more than double the experimental throughput via densely packed cell suspensions, capture drug-dependent sickling behavior, and reveal distinct mechanobiological signatures of cellular morphological evolution. Overall, this AI-driven framework establishes a scalable and reproducible computational platform for investigating cellular biomechanics and assessing therapeutic efficacy in microphysiological systems.

</details>


### [286] [Advancing Structured Priors for Sparse-Voxel Surface Reconstruction](https://arxiv.org/abs/2601.17720)
*Ting-Hsun Chi,Chu-Rong Chen,Chi-Tun Hsu,Hsuan-Ting Lin,Sheng-Yu Huang,Cheng Sun,Yu-Chiang Frank Wang*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了一种结合3D高斯泼溅和稀疏体素光栅化优势的方法，通过体素初始化技术和深度几何监督来改进辐射场表面重建的几何精度。


<details>
  <summary>Details</summary>
Motivation: 当前两种主要的显式表示方法——3D高斯泼溅和稀疏体素光栅化各有优缺点：3D高斯泼溅收敛快且有几何先验，但表面保真度受限于点状参数化；稀疏体素光栅化提供连续不透明度场和清晰几何，但均匀密集网格初始化收敛慢且未充分利用场景结构。作者希望结合两者的优势。

Method: 1. 提出体素初始化方法：在合理位置放置体素并设置适当细节层次，为每场景优化提供强起点。2. 提出精细化深度几何监督：将多视图线索转换为直接的每射线深度正则化，增强深度一致性而不模糊边缘。

Result: 在标准基准测试中，相比先前方法在几何精度、细结构恢复和表面完整性方面都有改进，同时保持快速收敛。

Conclusion: 通过结合3D高斯泼溅和稀疏体素光栅化的互补优势，提出的方法在表面重建的几何准确性方面取得了显著提升，为辐射场重建提供了更好的解决方案。

Abstract: Reconstructing accurate surfaces with radiance fields has progressed rapidly, yet two promising explicit representations, 3D Gaussian Splatting and sparse-voxel rasterization, exhibit complementary strengths and weaknesses. 3D Gaussian Splatting converges quickly and carries useful geometric priors, but surface fidelity is limited by its point-like parameterization. Sparse-voxel rasterization provides continuous opacity fields and crisp geometry, but its typical uniform dense-grid initialization slows convergence and underutilizes scene structure. We combine the advantages of both by introducing a voxel initialization method that places voxels at plausible locations and with appropriate levels of detail, yielding a strong starting point for per-scene optimization. To further enhance depth consistency without blurring edges, we propose refined depth geometry supervision that converts multi-view cues into direct per-ray depth regularization. Experiments on standard benchmarks demonstrate improvements over prior methods in geometric accuracy, better fine-structure recovery, and more complete surfaces, while maintaining fast convergence.

</details>


### [287] [Flatten The Complex: Joint B-Rep Generation via Compositional $k$-Cell Particles](https://arxiv.org/abs/2601.17733)
*Junran Lu,Yuanqi Li,Hengji Li,Jie Guo,Yanwen Guo*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出了一种将边界表示（B-Rep）重新表述为组合k-细胞粒子的新范式，通过多模态流匹配框架联合生成拓扑和几何，实现了高保真CAD模型生成。


<details>
  <summary>Details</summary>
Motivation: B-Rep是CAD和制造领域的标准，但其生成建模面临挑战，因为B-Rep作为几何单元复合体具有固有的异质性，将拓扑与不同阶的细胞（如顶点、边、面）的几何纠缠在一起。现有方法通常依赖级联序列处理这种层次结构，未能充分利用细胞间的几何关系（如邻接和共享），限制了上下文感知和错误恢复能力。

Method: 将B-Rep重新表述为组合k-细胞粒子的集合，将每个拓扑实体编码为粒子的组合，相邻细胞在其界面共享相同的潜在表示，从而促进沿共享边界的几何耦合。通过解耦刚性层次结构，统一处理顶点、边和面。使用多模态流匹配框架合成这些粒子集，支持无条件生成和精确条件任务（如单视图或点云的3D重建）。

Result: 实验表明，该方法能够生成高保真的CAD模型，在有效性和可编辑性方面优于现有方法。其显式和局部化的表示自然扩展到下游任务，如局部修复，并能直接合成非流形结构（如线框）。

Conclusion: 提出的粒子表示范式成功解决了B-Rep生成建模的挑战，通过解耦层次结构和促进几何耦合，实现了拓扑和几何的联合生成，具有全局上下文感知能力，为CAD模型生成提供了新的有效方法。

Abstract: Boundary Representation (B-Rep) is the widely adopted standard
  in Computer-Aided Design (CAD) and manufacturing. However, generative modeling of B-Reps remains a formidable challenge due to their inherent heterogeneity as geometric cell complexes, which entangles topology with geometry across cells of varying orders (i.e., $k$-cells such as vertices, edges, faces). Previous methods typically rely on cascaded sequences to handle this hierarchy, which fails to fully exploit the geometric relationships between cells, such as adjacency and sharing, limiting context awareness and error recovery. To fill this gap, we introduce a novel paradigm that reformulates B-Reps into sets of compositional $k$-cell particles. Our approach encodes each topological entity as a composition of particles, where adjacent cells share identical latents at their interfaces, thereby promoting geometric coupling along shared boundaries. By decoupling the rigid hierarchy, our representation unifies vertices, edges, and faces, enabling the joint generation of topology and geometry with global context awareness.
  We synthesize these particle sets using a multi-modal flow matching framework to handle unconditional generation as well as precise conditional tasks, such as 3D reconstruction from single-view or point cloud. Furthermore, the explicit and localized nature of our representation naturally extends to downstream tasks like local in-painting and enables the direct synthesis of non-manifold structures (e.g., wireframes). Extensive experiments demonstrate that our method produces high-fidelity CAD models with superior validity and editability compared to state-of-the-art methods.

</details>


### [288] [Learning Sewing Patterns via Latent Flow Matching of Implicit Fields](https://arxiv.org/abs/2601.17740)
*Cong Cao,Ren Li,Corentin Dumery,Hao Li*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出基于隐式表示的缝纫图案建模方法，使用符号距离场表示面板边界，无符号距离场标识缝端点，通过连续隐空间实现可微分网格化，支持复杂结构的准确建模与生成。


<details>
  <summary>Details</summary>
Motivation: 缝纫图案定义了服装的结构基础，对时尚设计、制造和物理模拟至关重要。尽管自动图案生成有进展，但由于面板几何形状和缝线排列的广泛变化性，准确建模缝纫图案仍然困难。

Method: 1) 使用符号距离场表示面板边界，无符号距离场标识缝端点；2) 将这些场编码到连续隐空间，实现可微分网格化；3) 潜在流匹配模型学习面板组合的分布；4) 缝线预测模块从提取的边缘段恢复缝线关系。

Result: 能够准确建模和生成具有复杂结构的缝纫图案，从图像估计缝纫图案的准确性优于现有方法，支持图案补全和重新拟合等应用。

Conclusion: 该方法为数字时尚设计提供了实用的缝纫图案建模工具，能够处理复杂结构并支持多种应用。

Abstract: Sewing patterns define the structural foundation of garments and are essential for applications such as fashion design, fabrication, and physical simulation. Despite progress in automated pattern generation, accurately modeling sewing patterns remains difficult due to the broad variability in panel geometry and seam arrangements. In this work, we introduce a sewing pattern modeling method based on an implicit representation. We represent each panel using a signed distance field that defines its boundary and an unsigned distance field that identifies seam endpoints, and encode these fields into a continuous latent space that enables differentiable meshing. A latent flow matching model learns distributions over panel combinations in this representation, and a stitching prediction module recovers seam relations from extracted edge segments. This formulation allows accurate modeling and generation of sewing patterns with complex structures. We further show that it can be used to estimate sewing patterns from images with improved accuracy relative to existing approaches, and supports applications such as pattern completion and refitting, providing a practical tool for digital fashion design.

</details>


### [289] [FlowMorph: Physics-Consistent Self-Supervision for Label-Free Single-Cell Mechanics in Microfluidic Videos](https://arxiv.org/abs/2601.17947)
*Bora Yimenicioglu,Vishal Manikanden*

Main category: cs.CV

Relevance: 15.0

TL;DR: FlowMorph：一种基于物理一致性的自监督框架，从微流体视频中学习红细胞力学代理参数，无需人工标注即可量化细胞变形能力。


<details>
  <summary>Details</summary>
Motivation: 红细胞力学特性是血液和系统性疾病的重要生物标志物，现有微流体分析方法依赖监督分割或手工特征提取，且未充分利用层流Stokes流动物理规律。需要一种无需标注、物理一致的方法来量化红细胞变形能力。

Method: FlowMorph使用低维参数化轮廓建模每个细胞，通过可微分的"流动中胶囊"模型结合层流平流和曲率正则化弹性松弛来推进边界点，优化损失函数耦合轮廓重叠、细胞内流一致性、面积守恒、壁约束和时间平滑性，仅使用自动提取的轮廓和光流。

Result: 在四个公开RBC微流体数据集上，FlowMorph在物理丰富的视频中达到平均轮廓IoU 0.905，显著改善面积守恒和壁约束违反。标量力学代理参数k能以AUC 0.863区分翻转和摆动动力学，仅用200个RT-DC事件校准即可预测表观杨氏模量，在600个测试细胞上平均绝对误差为0.118 MPa。

Conclusion: FlowMorph提供了一种无需标注、物理一致的自监督框架，能够从微流体视频中可靠地量化红细胞力学特性，对通道几何、光学和帧率变化具有鲁棒性。

Abstract: Mechanical properties of red blood cells (RBCs) are promising biomarkers for hematologic and systemic disease, motivating microfluidic assays that probe deformability at throughputs of $10^3$--$10^6$ cells per experiment. However, existing pipelines rely on supervised segmentation or hand-crafted kymographs and rarely encode the laminar Stokes-flow physics that governs RBC shape evolution. We introduce FlowMorph, a physics-consistent self-supervised framework that learns a label-free scalar mechanics proxy $k$ for each tracked RBC from short brightfield microfluidic videos. FlowMorph models each cell by a low-dimensional parametric contour, advances boundary points through a differentiable ''capsule-in-flow'' combining laminar advection and curvature-regularized elastic relaxation, and optimizes a loss coupling silhouette overlap, intra-cellular flow agreement, area conservation, wall constraints, and temporal smoothness, using only automatically derived silhouettes and optical flow.
  Across four public RBC microfluidic datasets, FlowMorph achieves a mean silhouette IoU of $0.905$ on physics-rich videos with provided velocity fields and markedly improves area conservation and wall violations over purely data-driven baselines. On $\sim 1.5\times 10^5$ centered sequences, the scalar $k$ alone separates tank-treading from flipping dynamics with an AUC of $0.863$. Using only $200$ real-time deformability cytometry (RT-DC) events for calibration, a monotone map $E=g(k)$ predicts apparent Young's modulus with a mean absolute error of $0.118$\,MPa on $600$ held-out cells and degrades gracefully under shifts in channel geometry, optics, and frame rate.

</details>


### [290] [Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs](https://arxiv.org/abs/2601.18099)
*Akbar Saadat*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出一种零训练前向计算框架，用于实时估计图像高斯模糊参数，通过解析表达式计算离焦图像，无需训练过程


<details>
  <summary>Details</summary>
Motivation: 为了解决实时应用中高斯模糊参数估计问题，避免传统方法需要训练过程的限制，实现无需训练的实时计算框架

Method: 基于高斯模型解析表达式，通过离散计算从清晰图像生成离焦图像，在特定高斯核标准差范围内选择最佳匹配，利用邻域相似性度量过滤多解问题

Result: 在真实图像上实验，估计合成模糊值的平均绝对误差低于1.7%，实际模糊图像强度与估计值的差异保持在2%以下

Conclusion: 该零训练前向计算框架能够有效实时估计高斯模糊参数，为图像处理应用提供实用解决方案

Abstract: Following the earlier verification for Gaussian model in \cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\%$, obtained by applying the extracted defocus filters to less blurred images.

</details>


### [291] [TempDiffReg: Temporal Diffusion Model for Non-Rigid 2D-3D Vascular Registration](https://arxiv.org/abs/2601.18168)
*Zehua Liu,Shihao Zou,Jincai Huang,Yanfang Zhang,Chao Tong,Weixin Si*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文提出了一种用于经动脉化疗栓塞术(TACE)的从粗到精的2D-3D血管配准方法，结合结构感知透视n点(SA-PnP)全局对齐和时间扩散模型(TempDiffReg)进行血管变形，显著提高了配准精度。


<details>
  <summary>Details</summary>
Motivation: 经动脉化疗栓塞术(TACE)是肝癌等肝脏恶性肿瘤的首选治疗方法，但由于术中血管导航复杂和解剖结构变异大，手术极具挑战性。准确的2D-3D血管配准对于引导微导管和器械、精确定位血管结构和实现最佳治疗靶向至关重要。

Method: 采用从粗到精的配准策略：1) 结构感知透视n点(SA-PnP)全局对齐模块，建立2D和3D血管结构之间的对应关系；2) TempDiffReg时间扩散模型，利用时间上下文迭代执行血管变形，捕捉复杂的解剖变异和局部结构变化。

Result: 在23名患者的626个多帧样本上进行评估，该方法在配准精度和解剖合理性方面均优于现有方法。具体而言，均方误差(MSE)为0.63mm，平均绝对误差(MAE)为0.51mm，相比最具竞争力的现有方法，MSE降低了66.7%，MAE降低了17.7%。

Conclusion: 该方法能够帮助经验不足的临床医生安全高效地执行复杂的TACE手术，最终改善手术结果和患者护理。代码和数据已开源。

Abstract: Transarterial chemoembolization (TACE) is a preferred treatment option for hepatocellular carcinoma and other liver malignancies, yet it remains a highly challenging procedure due to complex intra-operative vascular navigation and anatomical variability. Accurate and robust 2D-3D vessel registration is essential to guide microcatheter and instruments during TACE, enabling precise localization of vascular structures and optimal therapeutic targeting. To tackle this issue, we develop a coarse-to-fine registration strategy. First, we introduce a global alignment module, structure-aware perspective n-point (SA-PnP), to establish correspondence between 2D and 3D vessel structures. Second, we propose TempDiffReg, a temporal diffusion model that performs vessel deformation iteratively by leveraging temporal context to capture complex anatomical variations and local structural changes. We collected data from 23 patients and constructed 626 paired multi-frame samples for comprehensive evaluation. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) methods in both accuracy and anatomical plausibility. Specifically, our method achieves a mean squared error (MSE) of 0.63 mm and a mean absolute error (MAE) of 0.51 mm in registration accuracy, representing 66.7\% lower MSE and 17.7\% lower MAE compared to the most competitive existing approaches. It has the potential to assist less-experienced clinicians in safely and efficiently performing complex TACE procedures, ultimately enhancing both surgical outcomes and patient care. Code and data are available at: \textcolor{blue}{https://github.com/LZH970328/TempDiffReg.git}

</details>


### [292] [Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images](https://arxiv.org/abs/2601.18260)
*Eytan Kats,Kai Geissler,Daniel Mensing,Jochen G. Hirsch,Stefan Heldman,Mattias P. Heinrich*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出基于学习的框架，从单张2D深度图像直接预测多个内部器官的3D位置和形状，用于自动化患者定位


<details>
  <summary>Details</summary>
Motivation: 自动化患者定位在优化扫描流程和提高患者吞吐量方面很重要。利用RGB-D相机捕获的深度信息为估计内部器官位置提供了有前景的方法，从而实现更准确高效的定位

Method: 使用大规模全身MRI扫描数据集，合成深度图像与对应解剖分割配对，训练统一的卷积神经网络架构，直接从身体表面的2D深度图像预测多个内部器官的3D位置和形状

Result: 方法能够准确定位包括骨骼和软组织在内的多种解剖结构，无需显式表面重建。实验结果表明将深度传感器集成到放射学工作流程中的潜力

Conclusion: 提出的学习框架展示了通过深度传感器实现自动化患者定位的可行性，有望简化扫描流程并改善患者体验

Abstract: Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning.

</details>


### [293] [Revisiting Aerial Scene Classification on the AID Benchmark](https://arxiv.org/abs/2601.18263)
*Subhajeet Das,Susmita Ghosh,Abhiroop Chatterjee*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文综述了航空图像分类的机器学习方法，并提出了Aerial-Y-Net，一种空间注意力增强的CNN模型，在AID数据集上达到91.72%准确率。


<details>
  <summary>Details</summary>
Motivation: 航空图像在城乡规划和环境保护中至关重要，但由于其异质性（包含建筑、森林、山脉、空地等多种结构），开发鲁棒的场景分类模型仍具挑战性。需要对现有方法进行系统梳理并提出改进方案。

Method: 1. 文献综述：涵盖从手工特征（SIFT、LBP）到传统CNN（VGG、GoogLeNet）再到深度混合网络的各种方法。
2. 提出Aerial-Y-Net：空间注意力增强的CNN，具有多尺度特征融合机制，作为注意力模型帮助理解航空图像的复杂性。

Result: 在AID数据集上评估，Aerial-Y-Net达到91.72%的准确率，优于多个基线架构。

Conclusion: 该研究系统回顾了航空图像分类方法，提出的Aerial-Y-Net通过空间注意力和多尺度特征融合有效提升了分类性能，为理解复杂航空图像提供了有效工具。

Abstract: Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures.

</details>


### [294] [On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics](https://arxiv.org/abs/2601.18448)
*Lloyd Austin Courtenay*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该论文研究了在几何形态测量学(GMM)中，标准预处理方法(广义普氏分析GPA)在机器学习应用中可能引入统计依赖性和数据污染的问题，并提出了一种新的重对齐方法来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 几何形态测量学(GMM)广泛用于量化形状变异，并作为机器学习分析的输入。标准做法是在将数据分割为训练集和测试集之前，通过广义普氏分析(GPA)对齐所有标本，这可能引入统计依赖性并污染下游预测模型。

Method: 1. 使用受控的2D和3D模拟，在不同样本大小、地标密度和异速生长模式下，正式表征GPA引起的污染效应
2. 提出一种新颖的重对齐程序：在模型拟合之前，将测试标本与训练集对齐，消除跨样本依赖性
3. 使用线性和卷积回归模型进一步证明地标间空间自相关的重要性

Result: 1. 模拟揭示了一个稳健的"对角线"模式，反映了在等向变异下RMSE的缩放，其斜率可以从普氏切空间的自由度中解析推导
2. 当忽略地标关系时，线性回归和卷积回归模型显示出性能退化
3. 证明了空间自相关在地标分析中的重要性

Conclusion: 这项工作确立了在GMM的机器学习应用中需要仔细预处理的重要性，提供了重对齐的实用指南，并阐明了普氏形状空间固有的基本统计约束。

Abstract: Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust "diagonal" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space.

</details>


### [295] [REMAC: Reference-Based Martian Asymmetrical Image Compression](https://arxiv.org/abs/2601.18547)
*Qing Ding,Mai Xu,Shengxi Li,Xin Deng,Xin Zou*

Main category: cs.CV

Relevance: 15.0

TL;DR: 提出REMAC方法，一种基于参考的火星图像压缩技术，通过将计算复杂度从编码器转移到解码器，并利用火星图像间的强相似性来提升压缩性能


<details>
  <summary>Details</summary>
Motivation: 火星探索需要高效的图像压缩方法以应对受限的火星-地球通信信道。现有学习方法存在两个关键问题：1) 忽略了火星上极其有限的计算资源；2) 未利用火星图像间强烈的图像间相似性来提升压缩性能

Method: 提出基于参考的火星非对称图像压缩(REMAC)方法：1) 参考引导的熵模块和参考解码器利用参考图像的有用信息；2) 参考解码器采用深层多尺度架构以建模长程空间依赖；3) 开发潜在特征回收机制进一步缓解计算约束

Result: REMAC将编码器复杂度降低43.51%，同时实现0.2664 dB的BD-PSNR增益

Conclusion: REMAC通过将计算负担转移到资源丰富的解码器，并有效利用火星图像的内在和图像间相似性，为受限环境下的高效图像压缩提供了解决方案

Abstract: To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \textit{intra-} and \textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.

</details>


### [296] [Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray](https://arxiv.org/abs/2601.18555)
*Roberto Di Via,Vito Paolo Pastore,Francesca Odone,Siôn Glyn-Jones,Irina Voiculescu*

Main category: cs.CV

Relevance: 15.0

TL;DR: 该研究验证了使用热图回归架构在MRI上检测髋关节撞击综合征(FAI)关键解剖标志点的可行性，并与X射线检测结果进行了对比，证明了MRI在冠状面视图上具有与X射线相当的定位和诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 临床筛查决策常基于角度测量，特别是髋关节撞击综合征(FAI)筛查传统上依赖X射线角度测量。然而，评估撞击区域的高度和范围需要MRI扫描的3D视图。两种模态为外科医生提供不同方面的信息，需要验证MRI是否也能达到与X射线相当的定位和诊断准确性。

Method: 采用匹配队列验证研究(89名患者，配对MRI/X射线)，使用标准热图回归架构评估跨模态临床等效性。在3D MRI体积的冠状面视图中进行标志点检测，并与X射线结果对比。

Result: MRI在cam型撞击综合征的定位和诊断准确性方面达到与X射线等效的水平。该方法在3D MRI体积的冠状面视图中展示了临床可行性，为通过放置更多标志点进行体积分析提供了可能性。

Conclusion: 研究结果支持将自动化FAI评估整合到常规MRI工作流程中。MRI在髋关节撞击综合征评估中具有与X射线相当的临床价值，为三维体积分析开辟了可能性。

Abstract: Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions

</details>


### [297] [Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting](https://arxiv.org/abs/2601.18633)
*Tong Shi,Melonie de Almeida,Daniela Ivanova,Nicolas Pugeault,Paul Henderson*

Main category: cs.CV

Relevance: 15.0

TL;DR: Splat-Portrait：基于高斯泼溅的3D说话头生成方法，从单张肖像图像和音频合成逼真的说话视频，无需3D监督或运动先验


<details>
  <summary>Details</summary>
Motivation: 现有3D说话头生成方法依赖领域特定的启发式方法（如基于扭曲的面部运动表示先验），导致3D头像重建不准确，影响动画的真实感。需要一种无需运动驱动先验的方法来改善3D头部重建和嘴唇运动合成。

Method: 提出Splat-Portrait方法：1）使用高斯泼溅表示静态3D重建；2）自动将单张肖像图像解耦为静态高斯泼溅表示的3D重建和预测的2D背景；3）基于输入音频生成自然嘴唇运动，无需任何运动驱动先验；4）训练仅使用2D重建和分数蒸馏损失，无需3D监督或地标点。

Result: 实验结果表明，Splat-Portrait在说话头生成和新视角合成方面表现出优越性能，相比先前工作获得更好的视觉质量。

Conclusion: Splat-Portrait成功解决了3D头部重建和嘴唇运动合成的挑战，通过高斯泼溅表示和纯2D监督训练，实现了高质量的说话头生成。

Abstract: Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.

</details>


### [298] [Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning](https://arxiv.org/abs/2601.18714)
*Judith Vilella-Cantos,Mauro Martini,Marcello Chiaberge,Mónica Ballesta,David Valiente*

Main category: cs.CV

Relevance: 10.0

TL;DR: 提出MinkUNeXt-VINE，一种轻量级深度学习方法，用于农业环境中的地点识别，在葡萄园环境中超越现有方法，特别适用于低成本稀疏LiDAR输入和实时场景。


<details>
  <summary>Details</summary>
Motivation: 农业环境由于非结构化特性和缺乏显著地标，对移动机器人的定位具有挑战性。现有研究主要集中在物体分类和分割，而地点识别任务在当前技术状态下并不简单。

Method: 提出MinkUNeXt-VINE方法，采用预处理和Matryoshka表示学习多损失方法，优先考虑增强性能，使用低成本稀疏LiDAR输入和低维输出，确保实时场景的高效率。

Result: 该方法在葡萄园环境中超越了现有最先进方法，在低成本、低分辨率输入数据上表现出鲁棒性能，并在两个广泛的长时期葡萄园数据集上进行了全面消融研究。

Conclusion: 该方法在效率和性能之间取得了良好平衡，特别适用于农业环境中的实时地点识别任务，代码已公开供复现。

Abstract: Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.

</details>


### [299] [Cloud-Enabled IoT System for Real-Time Environmental Monitoring and Remote Device Control Using Firebase](https://arxiv.org/abs/2601.17414)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

Relevance: 5.0

TL;DR: 本文提出了一种基于Firebase云数据库的物联网系统，用于环境监测和设备控制，具有实时数据同步和远程控制功能。


<details>
  <summary>Details</summary>
Motivation: 物联网设备激增带来了远程监控和控制的需求，但传统系统在实时数据访问、远程控制和云集成方面存在局限。需要一种低成本、易实现的云集成物联网解决方案。

Method: 使用ESP32微控制器连接DHT22温湿度传感器和HC-SR04超声波距离传感器，通过Firebase实时数据库实现数据同步和远程LED控制，构建云基物联网架构。

Result: 系统实现99.2%的数据传输成功率，实时控制延迟低于1.5秒，支持持久化数据存储用于历史分析，总实现成本32.50美元。

Conclusion: 该Firebase集成的物联网系统为智能家居和工业监控等应用提供了可扩展框架，无需复杂服务器基础设施即可实现强大的云功能。

Abstract: The proliferation of Internet of Things (IoT) devices has created unprecedented opportunities for remote monitoring and control applications across various domains. Traditional monitoring systems often suffer from limitations in real-time data accessibility, remote controllability, and cloud integration. This paper presents a cloud-enabled IoT system that leverages Google's Firebase Realtime Database for synchronized environmental monitoring and device control. The system utilizes an ESP32 microcontroller to interface with a DHT22 temperature/humidity sensor and an HC-SR04 ultrasonic distance sensor, while enabling remote control of two LED indicators through a cloud-based interface. Real-time sensor data is transmitted to Firebase, providing a synchronized platform accessible from multiple devices simultaneously. Experimental results demonstrate reliable data transmission with 99.2\% success rate, real-time control latency under 1.5 seconds, and persistent data storage for historical analysis. The system architecture offers a scalable framework for various IoT applications, from smart home automation to industrial monitoring, with a total implementation cost of \$32.50. The integration of Firebase provides robust cloud capabilities without requiring complex server infrastructure, making advanced IoT applications accessible to developers and researchers with limited resources.

</details>


### [300] [In-situ On-demand Digital Image Correlation: A New Data-rich Characterization Paradigm for Deformation and Damage Development in Solids](https://arxiv.org/abs/2601.17545)
*Ravi Venkata Surya Sai Mogilisetti,Partha Pratim Das,Rassel Raihan,Shiyao Lin*

Main category: eess.IV

Relevance: 5.0

TL;DR: 提出了一种新的数字图像相关（DIC）分析范式——原位按需（ISOD）DIC，通过将相机控制集成到DIC流程中，根据变形程度动态调整成像帧率，实现实时变形分析和闭环相机控制。


<details>
  <summary>Details</summary>
Motivation: 传统DIC方法采用固定帧率采集图像，无法根据变形程度动态调整，导致在缓慢变形阶段浪费存储空间和分析时间，而在快速变形阶段可能丢失关键数据。需要一种更智能的DIC系统来优化数据采集效率。

Method: 开发了ISOD DIC新范式，将相机控制集成到DIC处理流程中。系统实时监测变形和变形速率，当检测到过大变形或高变形速率时，动态提高相机成像帧率；在变形小而慢时保持较低帧率。实现了实时变形分析、可视化和闭环相机控制。

Result: ISOD DIC在裂纹扩展样品测试中，比传统DIC多捕获约178%的图像。通过动态调整帧率，显著增强了损伤检测的数据丰富度，同时不消耗过多的存储空间和分析时间。

Conclusion: ISOD DIC通过智能帧率调整优化了数据采集效率，能够更好地表征材料本构行为和损伤机制，为实验力学中的变形表征提供了更高效的工具。

Abstract: Digital image correlation (DIC) has become one of the most popular methods for deformation characterization in experimental mechanics. DIC is based on optical images taken during experimentation and post-test image processing. Its advantages include the capability to capture full-field deformation in a non-contact manner, the robustness in characterizing excessive deformation induced by events such as yielding and cracking, and the versatility to integrate optical cameras with a variety of open-source and commercial codes. In this paper, we developed a new paradigm of DIC analysis by integrating camera control into the DIC process flow. The essential idea is to dynamically increase the camera imaging frame rate with excessive deformation or deformation rate, while maintaining a relatively low imaging frame rate with small and slow deformation. We refer to this new DIC paradigm as in-situ on-demand (ISOD) DIC. ISOD DIC enables real-time deformation analysis, visualization, and closed-loop camera control. ISOD DIC has captured approximately 178% more images than conventional DIC for samples undergoing crack growth due to its dynamically adjusted frame rate, with the potential to significantly enhance data richness for damage inspection without consuming excessive storage space and analysis time, thereby benefiting the characterization of intrinsic constitutive behaviors and damage mechanisms

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [301] [UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis](https://arxiv.org/abs/2601.17897)
*Jiayu Liu,Yinhe Long,Zhenya Huang,Enhong Chen*

Main category: cs.AI

Relevance: 95.0

TL;DR: UniCog是一个通过潜在思维空间分析LLM认知的统一框架，将密集模型激活编码为稀疏解耦的潜在维度，揭示了LLM认知的帕累托原则，并利用潜在激活异常检测推理失败，最终通过潜在信息候选优先级策略提升推理性能达7.5%。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性方法在解释LLM推理过程中认知能力如何被调用方面存在局限，而研究表明LLM的认知过程与人类有根本差异，因此需要新的分析框架来理解LLM的认知机制。

Method: 提出UniCog统一框架，作为潜在变量模型，将密集模型激活编码为稀疏解耦的潜在维度，分析六个先进LLM（包括DeepSeek-V3.2和GPT-4o），发现共享推理核心与能力特定签名的帕累托原则。

Result: 揭示了LLM认知的帕累托原则：共享推理核心与能力特定签名互补；发现推理失败常表现为潜在激活异常；提出的潜在信息候选优先级策略在挑战性基准测试中提升推理性能达7.5%。

Conclusion: UniCog为LLM分析开辟了新范式，提供了基于认知的推理动态视角，通过潜在思维空间分析能够更好地理解和改进LLM的推理能力。

Abstract: A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.

</details>


### [302] [Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability](https://arxiv.org/abs/2601.17168)
*Judy Zhu,Dhari Gandhi,Himanshu Joshi,Ahmad Rezaie Mianroodi,Sedef Akinli Kocak,Dhanesh Ramachandran*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文评估了现有可解释性方法在智能体系统中的应用局限性，提出了专门针对智能体系统可解释性技术的新方向，以解决AI安全挑战。


<details>
  <summary>Details</summary>
Motivation: 智能体系统与传统机器学习模型在架构和部署上有根本差异，引入了独特的安全挑战（目标错位、决策错误累积、多智能体协调风险），需要专门的可解释性设计来确保自主行为的可追溯性和可问责性。

Method: 评估现有可解释性方法在智能体系统中的适用性和局限性，识别其在提供智能体决策洞察方面的不足，提出专门针对智能体系统可解释性技术的新方向。

Result: 发现现有主要为静态模型设计的可解释性技术在应用于智能体系统时存在局限性，智能体的时间动态性、决策累积性和上下文依赖行为需要新的分析方法。

Conclusion: 需要开发专门针对智能体系统的可解释性技术，在智能体生命周期的各个阶段（目标形成、环境交互、结果评估）嵌入监督机制，以确保智能体AI系统的安全和可问责部署。

Abstract: Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.

</details>


### [303] [Phase Transition for Budgeted Multi-Agent Synergy](https://arxiv.org/abs/2601.17311)
*Bang Liu,Linglong Kong,Jian Pei*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文提出了一个可校准的理论框架，用于预测多智能体系统在固定推理预算下的三种行为模式（帮助、饱和、崩溃），基于上下文窗口、通信损耗和智能体相关性三个核心约束，推导出预算协同的条件和最优计算分配规则。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统理论上能提高可靠性，但在固定推理预算下，它们可能帮助、饱和甚至崩溃。现有研究缺乏一个能够预测这些行为模式并指导系统设计的统一理论框架，特别是在考虑现代智能体栈的实际约束（有限上下文窗口、有损通信、智能体相关性）时。

Method: 开发了一个最小化可校准理论：1) 用计算-性能缩放指数β描述单个智能体；2) 用消息长度保真度曲线γ(m)建模通信损耗；3) 用有效共享误差相关性ρ捕捉智能体依赖性；4) 考虑上下文窗口W的硬性限制。通过分析二元成功/失败任务中的多数聚合，推导了深度b叉树的相变条件，定义了组织指数s，并给出了预算协同的精确条件(s>β)。

Result: 理论预测：1) 单个标量α_ρ决定弱信号是被放大到非平凡固定点还是被洗牌到随机水平；2) 预算协同（在相同总预算下优于最佳单个智能体）发生在s>β时；3) 推导了封闭形式的计算分配规则和明确的预算阈值；4) 通过混合深度表征饱和现象；5) 在合成模拟中验证了预测的相边界，并解释了最近大规模LLM智能体系统缩放研究中的主要瓶颈。

Conclusion: 该理论框架为多智能体系统设计提供了可预测的指导原则，揭示了在有限预算下实现协同效应的关键条件，特别是智能体相关性、通信保真度和层次结构之间的权衡关系，对构建高效可靠的LLM多智能体系统具有重要指导意义。

Abstract: Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $β$; communication is captured by a message-length fidelity curve $γ(m)$; dependence is captured by an effective shared-error correlation $ρ$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $α_ρ$ (combining $γ(m)$, $ρ$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>β$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.

</details>


### [304] [Are We Evaluating the Edit Locality of LLM Model Editing Properly?](https://arxiv.org/abs/2601.17343)
*Wei Liu,Haomei Xu,Hongkai Liu,Zhiying Deng,Ruixuan Li,Heng Huang,Yee Whye Teh,Wee Sun Lee*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文指出现有模型编辑特异性评估协议存在不足，提出了更敏感、可调整严格度的新评估协议，能更好区分不同编辑方法的知识保留能力。


<details>
  <summary>Details</summary>
Motivation: 模型编辑需要平衡编辑效果（成功注入目标知识）和特异性（保留现有非目标知识），但现有特异性评估协议存在根本性问题，无法准确评估知识保留能力。

Method: 1. 系统分析现有特异性评估的三个根本问题；2. 实证证明现有指标与特异性正则化强度弱相关；3. 提出新的评估协议，消除开放式LLM与确定答案假设的冲突，避免查询无关的流畅性偏差，并允许在近乎连续空间中平滑调整评估严格度。

Result: 在不同LLM、数据集和编辑方法上的实验表明，新协议产生的指标对特异性正则化强度变化更敏感，与正则化强度强相关，能更细粒度地区分不同方法的知识保留能力。

Conclusion: 现有模型编辑特异性评估存在严重缺陷，提出的新评估协议能更准确、敏感地评估知识保留能力，为模型编辑研究提供了更好的评估工具。

Abstract: Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.

</details>


### [305] [A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models](https://arxiv.org/abs/2601.17426)
*Zhengqing Zang,Yuqi Ding,Yanmei Gu,Changkai Song,Zhengkai Yang,Guoping Du,Junbo Zhao,Haobo Wang*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文研究大语言模型在逻辑推理方面的演化，使用存在引入作为探针，评估LLMs在传统和现代逻辑下的三段论推理能力，发现模型规模扩展、思维链提示和基础模型对逻辑框架转变有重要影响。


<details>
  <summary>Details</summary>
Motivation: 人类逻辑从直觉推理转向严格的形式系统，受此启发，研究者探索LLMs是否表现出类似的底层逻辑框架演化。通过存在引入这一逻辑概念，研究LLMs在三段论推理中遵循传统逻辑还是现代逻辑。

Method: 使用存在引入作为探针，构建新的三段论数据集，对SOTA LLMs进行广泛实验。评估模型在传统逻辑和现代逻辑下的表现，分析模型规模、思维链提示、基础模型等因素对逻辑框架转变的影响。

Result: 发现三个关键结果：(1) 模型规模扩展促进向现代逻辑的转变；(2) 思维链提示是超越参数扩展的高效加速器；(3) 基础模型决定这种转变的容易程度和稳定性。此外还深入分析了LLMs在三段论推理中的特性。

Conclusion: LLMs在逻辑推理方面表现出类似人类的演化趋势，模型规模、推理过程和基础架构共同影响逻辑框架的转变。这为理解LLMs的推理机制和评估其逻辑能力提供了新视角。

Abstract: Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.

</details>


### [306] [Lattice: Generative Guardrails for Conversational Agents](https://arxiv.org/abs/2601.17481)
*Emily Broadhurst,Tawab Safi,Joseph Edell,Vashisht Ganesh,Karime Maamari*

Main category: cs.AI

Relevance: 85.0

TL;DR: Lattice是一个自构建和持续改进的护栏框架，通过两阶段方法（构建和持续改进）来防止对话AI的有害输出，在ProsocialDialog数据集上达到91% F1分数，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有对话AI护栏系统使用静态规则，无法适应新威胁或部署环境，需要能够自我构建和持续改进的框架来应对动态的安全挑战。

Method: 两阶段框架：1) 构建阶段：通过迭代模拟和优化从标注示例构建初始护栏；2) 持续改进阶段：通过风险评估、对抗测试和整合来自主适应已部署的护栏。

Result: 在ProsocialDialog数据集上达到91% F1分数，比关键词基线高43个百分点，比LlamaGuard高25个百分点，比NeMo高4个百分点。持续改进阶段通过闭环优化在跨域数据上实现7个百分点F1提升。

Conclusion: 有效护栏可以通过迭代优化自构建，Lattice框架展示了自我构建和持续改进护栏的可行性，为对话AI安全提供了更灵活和自适应的解决方案。

Abstract: Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.

</details>


### [307] [Intelligence Requires Grounding But Not Embodiment](https://arxiv.org/abs/2601.17588)
*Marcus Ma,Shrikanth Narayanan*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文认为智能需要"接地"（grounding）而非"具身"（embodiment），提出智能的四个属性（动机、预测能力、因果理解、经验学习）可以通过非具身但接地的智能体实现。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的进步，关于智能是否需要具身的科学争论重新兴起。作者旨在澄清这一争论，认为智能真正需要的是接地（与现实世界的连接），而非物理具身本身。

Method: 1. 定义智能的四个核心属性：动机、预测能力、因果理解、经验学习
2. 论证每个属性都可以通过非具身但接地的智能体实现
3. 提出数字环境中智能LLM代理的思想实验
4. 回应潜在的反驳论点

Result: 论文得出结论：接地（grounding）而非具身（embodiment）是智能的必要条件。智能可以通过非具身但接地的系统（如数字环境中的LLM代理）实现。

Conclusion: 该研究挑战了智能需要物理具身的传统观点，为LLM等非具身系统的智能潜力提供了理论支持，对AI哲学和认知科学有重要启示。

Abstract: Recent advances in LLMs have reignited scientific debate over whether embodiment is necessary for intelligence. We present the argument that intelligence requires grounding, a phenomenon entailed by embodiment, but not embodiment itself. We define intelligence as the possession of four properties -- motivation, predictive ability, understanding of causality, and learning from experience -- and argue that each can be achieved by a non-embodied, grounded agent. We use this to conclude that grounding, not embodiment, is necessary for intelligence. We then present a thought experiment of an intelligent LLM agent in a digital environment and address potential counterarguments.

</details>


### [308] [Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context](https://arxiv.org/abs/2601.17642)
*Zhihao Zhang,Liting Huang,Guanghao Wu,Preslav Nakov,Heng Ji,Usman Naseem*

Main category: cs.AI

Relevance: 85.0

TL;DR: Health-ORSC-Bench：首个大规模医疗AI安全对齐基准，系统评估LLMs在医疗场景中的过度拒绝和安全完成能力，揭示当前模型在安全性与实用性之间的显著权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在医疗领域的安全对齐主要依赖二元拒绝边界，导致对良性查询的过度拒绝或对有害查询的不安全合规。现有基准无法评估模型在双用途或边界查询上提供安全高级指导而不跨越可操作伤害的能力。

Method: 构建包含31,920个良性边界提示的大规模基准Health-ORSC-Bench，涵盖7个健康类别（如自残、医疗错误信息）。采用自动化流水线结合人工验证，在不同意图模糊度级别测试模型。评估了30个SOTA LLMs，包括GPT-5和Claude-4。

Result: 安全优化模型对"困难"良性提示的拒绝率高达80%，而领域特定模型常为实用性牺牲安全性。模型家族和规模显著影响校准：大型前沿模型（如GPT-5、Llama-4）表现出"安全悲观主义"和更高的过度拒绝，比小型或MoE模型（如Qwen-3-Next）更严重。

Conclusion: 当前LLMs难以平衡拒绝与合规，Health-ORSC-Bench为下一代医疗AI助手提供了校准的严格标准，促进细致、安全和有帮助的完成。

Abstract: Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \emph{over-refusal} of benign queries or \emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \textbf{Over-Refusal} and \textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\% of "Hard" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit "safety-pessimism" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \textcolor{red}{Warning: Some contents may include toxic or undesired contents.}

</details>


### [309] [SQL-Trail: Multi-Turn Reinforcement Learning with Interleaved Feedback for Text-to-SQL](https://arxiv.org/abs/2601.17699)
*Harper Hua,Zhen Han,Zhengyuan Shen,Jeremy Lee,Patrick Guan,Qi Zhu,Sullam Jeoung,Yueyan Chen,Yunfei Bai,Shuai Wang,Vassilis Ioannidis,Huzefa Rangwala*

Main category: cs.AI

Relevance: 85.0

TL;DR: SQL-Trail：一个基于多轮强化学习的Text-to-SQL代理框架，通过数据库交互和执行反馈迭代优化查询，在BIRD-SQL等基准上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 当前Text-to-SQL生成主要采用单次生成范式，缺乏人类专家使用的迭代推理、模式探索和错误修正能力，导致在BIRD-SQL等挑战性基准上与人类专家存在显著差距

Method: 提出SQL-Trail多轮强化学习代理框架：1）自适应轮次预算分配机制，根据问题难度调整交互深度；2）复合奖励面板，联合激励SQL正确性和高效探索；通过数据库环境交互和执行反馈迭代优化预测

Result: 在多个基准测试中达到新的SOTA，数据效率比先前单次RL方法高18倍；7B和14B模型平均比大型专有系统高出5%，证明了交互式代理工作流的有效性

Conclusion: 交互式、代理式工作流对于稳健的Text-to-SQL生成非常有效，多轮RL方法能够显著提升模型性能，即使较小模型也能超越大型专有系统

Abstract: While large language models (LLMs) have substantially improved Text-to-SQL generation, a pronounced gap remains between AI systems and human experts on challenging benchmarks such as BIRD-SQL. We argue this gap stems largely from the prevailing single-pass paradigm, which lacks the iterative reasoning, schema exploration, and error-correction behaviors that humans naturally employ. To address this limitation, we introduce SQL-Trail, a multi-turn reinforcement learning (RL) agentic framework for Text-to-SQL. Rather than producing a query in one shot, SQL-Trail interacts with the database environment and uses execution feedback to iteratively refine its predictions. Our approach centers on two key ideas: (i) an adaptive turn-budget allocation mechanism that scales the agent's interaction depth to match question difficulty, and (ii) a composite reward panel that jointly incentivizes SQL correctness and efficient exploration. Across benchmarks, SQL-Trail sets a new state of the art and delivers strong data efficiency--up to 18x higher than prior single-pass RL state-of-the-art methods. Notably, our 7B and 14B models outperform substantially larger proprietary systems by 5% on average, underscoring the effectiveness of interactive, agentic workflows for robust Text-to-SQL generation.

</details>


### [310] [The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data](https://arxiv.org/abs/2601.17717)
*Kaituo Zhang,Mingzhi Hu,Hoang Anh Duy Le,Fariha Kabir Torsha,Zhimeng Jiang,Minh Khai Bui,Chia-Yuan Chang,Yu-Neng Chuang,Zhen Xiong,Ying Lin,Guanchu Wang,Na Zou*

Main category: cs.AI

Relevance: 85.0

TL;DR: 本文提出LLM数据审计框架，系统评估LLM生成多模态合成数据的质量和可信度，弥补现有研究在数据质量评估方面的不足。


<details>
  <summary>Details</summary>
Motivation: LLM已成为生成多模态数据的有力工具，但确保合成数据的高质量仍是关键挑战。现有研究主要关注生成方法，对数据质量评估关注不足，且多局限于单一模态，缺乏跨模态的统一视角。

Method: 提出LLM数据审计框架：1) 描述LLM如何生成六种不同模态的数据；2) 从质量和可信度两个维度系统分类合成数据的内在评估指标；3) 分析各模态代表性生成方法的实验评估；4) 基于发现提出改进建议；5) 概述合成数据在不同模态中的实际应用方法。

Result: 分析发现当前评估实践存在重大缺陷，识别出合成数据质量评估的不足，为社区提供了具体的改进建议。

Conclusion: LLM数据审计框架为评估LLM生成的多模态合成数据提供了系统方法，将关注点从依赖下游任务性能的外在评估转向数据本身的内在属性，有助于提升合成数据质量评估的标准化和有效性。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.

</details>


### [311] [EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents](https://arxiv.org/abs/2601.17722)
*Ying Mo,Yu Bai,Dapeng Sun,Yuqian Shi,Yukai Miao,Li Chen,Dan Li*

Main category: cs.AI

Relevance: 85.0

TL;DR: EntWorld是一个针对企业工作流程的大规模多模态LLM基准测试，包含1,756个任务，覆盖CRM、ITIL、ERP等六个企业领域，采用基于数据库模式的确定性验证机制，揭示了当前模型在企业环境中的显著性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM基准主要针对消费级场景（如电商、旅行预订），无法捕捉专业企业工作流程的复杂性和严谨性。企业系统具有高密度用户界面、严格业务逻辑约束和精确状态一致性要求等独特挑战，当前通用智能体在这些环境中表现不佳。

Method: 1. 提出基于模式的任务生成框架，直接从底层数据库模式逆向工程业务逻辑，合成真实的长时程工作流程；2. 采用基于SQL的确定性验证机制，用严格的状态转换验证替代模糊的视觉匹配；3. 构建包含1,756个任务的六领域企业基准（CRM、ITIL、ERP等）。

Result: 最先进模型（如GPT-4.1）在EntWorld上的成功率仅为47.61%，远低于人类表现，表明当前智能体在企业环境中的能力存在显著差距，需要开发领域特定的企业级智能体。

Conclusion: 企业环境对MLLM提出了独特挑战，现有通用智能体难以满足企业级需求。EntWorld为开发下一代企业就绪数字智能体提供了严谨的测试平台，强调了开发领域特定企业智能体的必要性。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.

</details>


### [312] [Neuro-Symbolic Verification on Instruction Following of LLMs](https://arxiv.org/abs/2601.17789)
*Yiming Su,Kunzhao Xu,Yanjie Gao,Fan Yang,Cheng Li,Mao Yang,Tianyin Xu*

Main category: cs.AI

Relevance: 85.0

TL;DR: NSVIF是一个神经符号框架，用于验证LLM输出是否遵循指令，将指令遵循验证建模为约束满足问题，显著优于基于LLM的方法并提供可解释反馈。


<details>
  <summary>Details</summary>
Motivation: LLM并不总是遵循指令，这种违规在基于LLM的智能体工作流中会传播放大，导致任务失败和系统事故。现有方法缺乏通用、可解释的指令遵循验证框架。

Method: NSVIF将指令遵循验证建模为约束满足问题，将用户指令建模为约束（包括逻辑和语义约束），通过统一求解器协调逻辑推理和语义分析进行约束求解。

Result: 实验表明NSVIF显著优于基于LLM的方法，提供可解释反馈，且NSVIF的反馈无需后训练即可提升LLM的指令遵循能力。

Conclusion: NSVIF是一个通用、可解释的指令遵循验证框架，能有效检测LLM输出是否遵循指令，其反馈机制可提升LLM性能，对LLM应用的安全性和可靠性有重要意义。

Abstract: A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.

</details>


### [313] [Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards](https://arxiv.org/abs/2601.17828)
*Tanvi Verma,Yang Zhou,Rick Siow Mong Goh,Yong Liu*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出信息增益微调（IGFT）方法，通过在线强化学习结合信息论奖励，训练医疗对话AI进行患者访谈并生成全面的现病史，无需预先收集人类对话数据。


<details>
  <summary>Details</summary>
Motivation: 现有医疗对话AI方法依赖昂贵的人工标注对话或静态数据集，难以有效学习多轮对话策略。需要一种无需预收集对话数据、能够自主探索有效提问策略的方法。

Method: 结合在线组相对策略优化（GRPO）与信息论奖励，使用信息增益奖励函数追踪对话中揭示的临床实体（症状、时间模式、病史），结合GPT-4o-mini的质量评估，通过LoRA微调Llama-3.1-8B-Instruct和DeepSeek-R1-Distill-Qwen-7B模型。

Result: DeepSeek-R1-Distill-Qwen-7B（IGFT）在Avey数据上F1分数0.408（比基础模型提升10.9%），在MIMIC数据上0.289（提升12.9%）。Llama-3.1-8B-Instruct（IGFT）分别达到0.384和0.336。均优于OpenAI模型和医疗领域专用基线模型。

Conclusion: IGFT方法能够有效训练医疗对话AI进行多轮患者访谈，无需预收集对话数据，在信息收集效率和临床相关性方面优于现有方法，为医疗对话AI训练提供了新范式。

Abstract: We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.

</details>


### [314] [When Personalization Legitimizes Risks: Uncovering Safety Vulnerabilities in Personalized Dialogue Agents](https://arxiv.org/abs/2601.17887)
*Jiahe Guo,Xiangran Guo,Yulin Hu,Zimo Long,Xingyu Sui,Xuda Zhi,Yongbo Huang,Hao He,Weixiang Zhao,Yanyan Zhao,Bing Qin*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文揭示了LLM个性化代理中的"意图合法化"安全漏洞：良性个人记忆会扭曲意图推断，导致模型将有害查询合法化，并通过PS-Bench基准测试量化了这一风险。


<details>
  <summary>Details</summary>
Motivation: 现有个性化代理研究主要关注实用性和用户体验，将记忆视为中性组件，忽视了其安全影响。本文旨在揭示"意图合法化"这一被忽视的安全失效模式，即良性个人记忆如何导致模型将有害查询合法化。

Method: 1) 提出PS-Bench基准，用于识别和量化个性化交互中的意图合法化现象；2) 在多种记忆增强代理框架和基础LLM上进行实验；3) 从内部表示空间提供机制性证据；4) 提出轻量级检测-反思方法。

Result: 个性化使攻击成功率相对无状态基线提高15.8%-243.7%。通过内部表示分析提供了意图合法化的机制证据，提出的检测-反思方法有效减少了安全退化。

Conclusion: 这是对意图合法化作为安全失效模式的首次系统性探索，表明良性、真实世界的个性化会自然产生安全风险，强调在长期个性化背景下评估安全性的重要性。

Abstract: Long-term memory enables large language model (LLM) agents to support personalized and sustained interactions. However, most work on personalized agents prioritizes utility and user experience, treating memory as a neutral component and largely overlooking its safety implications. In this paper, we reveal intent legitimation, a previously underexplored safety failure in personalized agents, where benign personal memories bias intent inference and cause models to legitimize inherently harmful queries. To study this phenomenon, we introduce PS-Bench, a benchmark designed to identify and quantify intent legitimation in personalized interactions. Across multiple memory-augmented agent frameworks and base LLMs, personalization increases attack success rates by 15.8%-243.7% relative to stateless baselines. We further provide mechanistic evidence for intent legitimation from internal representations space, and propose a lightweight detection-reflection method that effectively reduces safety degradation. Overall, our work provides the first systematic exploration and evaluation of intent legitimation as a safety failure mode that naturally arises from benign, real-world personalization, highlighting the importance of assessing safety under long-term personal context. WARNING: This paper may contain harmful content.

</details>


### [315] [Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation](https://arxiv.org/abs/2601.17915)
*Saurabh Jha,Rohan Arora,Bhavya,Noah Zheutlin,Paulina Toro Isaza,Laura Shwartz,Yu Deng,Daby Sow,Ruchi Mahindru,Ruchir Puri*

Main category: cs.AI

Relevance: 85.0

TL;DR: EoG框架通过将调查任务分解为依赖图上的溯因推理，解决了LLM代理在开放调查中的可靠性问题，显著提升了准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在处理需要从海量异构数据中迭代挖掘证据的开放调查任务时存在可靠性问题。ReAct等代理在上下文窗口有限的情况下，需要提前总结中间发现，容易丢弃关键证据，且结论对探索顺序敏感，导致结果不稳定。

Method: 提出EoG框架，将调查任务形式化为依赖图上的溯因推理。LLM负责有界的局部证据挖掘和标注（原因vs症状），而确定性控制器管理图遍历、状态维护和信念传播，计算最小解释边界。

Result: 在ITBench诊断任务上，EoG相比ReAct基线显著提升了准确性和运行间一致性，平均获得7倍的Majority-at-k实体F1增益。

Conclusion: 通过分离语义推理与控制职责，EoG框架有效解决了LLM代理在开放调查任务中的可靠性问题，为处理具有隐藏依赖结构的大规模异构数据提供了更稳健的解决方案。

Abstract: LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.
  We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.

</details>


### [316] [Sentipolis: Emotion-Aware Agents for Social Simulations](https://arxiv.org/abs/2601.18027)
*Chiyuan Fu,Lyuhao Chen,Yunze Xiao,Weihao Xuan,Carlos Busso,Mona Diab*

Main category: cs.AI

Relevance: 85.0

TL;DR: Sentipolis是一个为LLM智能体提供情感状态记忆的框架，通过PAD情感表示、双速情感动态和情感-记忆耦合来解决情感遗忘问题，提升社交模拟中的情感连续性和真实性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在社交模拟中通常将情感视为瞬时线索，导致情感遗忘和长期连续性不足。需要建立能够维持情感状态记忆的框架来改善情感驱动的长期行为。

Method: 提出Sentipolis框架，包含：1) 连续Pleasure-Arousal-Dominance情感表示；2) 双速情感动态机制（快速变化和缓慢衰减）；3) 情感与记忆耦合系统。

Result: 在多个基础模型和评估者上的数千次交互显示：Sentipolis显著提升情感基础行为、沟通能力和情感连续性。效果模型依赖：高容量模型可信度提升，小模型可能下降；情感意识可能轻微降低社会规范遵从度。

Conclusion: Sentipolis成功解决了LLM智能体的情感遗忘问题，建立了情感状态记忆系统。网络级诊断显示形成互惠、适度聚类和时间稳定的关系结构，支持研究联盟形成和渐进关系变化等累积社交动态。

Abstract: LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.

</details>


### [317] [Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing](https://arxiv.org/abs/2601.18061)
*Kiana Jafari,Paul Ulrich Nikolaus Rust,Duncan Eddy,Robbie Fraser,Nina Vasan,Darja Djordjevic,Akanksha Dadlani,Max Lamparth,Eugenia Kim,Mykel Kochenderfer*

Main category: cs.AI

Relevance: 85.0

TL;DR: 专家在心理健康领域对LLM响应的评估存在系统性分歧，尤其是在自杀自伤等安全关键问题上，专家间一致性低于可接受阈值，分歧源于不同的临床框架而非测量误差


<details>
  <summary>Details</summary>
Motivation: 验证人类反馈学习(LHF)的基本假设：专家判断经过适当聚合后能提供有效的训练和评估基础。在心理健康这一高安全风险领域，专家共识尤为重要

Method: 三位认证精神科医生使用校准的评分标准独立评估LLM生成的响应，测量专家间可靠性(ICC)，进行定性访谈分析分歧原因

Result: 专家间可靠性极低(ICC 0.087-0.295)，低于可接受阈值；自杀自伤类响应分歧最大且系统性而非随机；一个因素出现负可靠性(α=-0.203)；分歧源于不同的临床框架(安全优先、参与中心、文化导向)

Conclusion: 专家依赖整体风险启发式而非细粒度因素区分，聚合标签成为算术妥协而抹杀了专业哲学。建议从基于共识的聚合转向能保留和学习专家分歧的对齐方法

Abstract: Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $α= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.

</details>


### [318] [RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents](https://arxiv.org/abs/2601.18130)
*Jize Wang,Han Wu,Zhiyuan You,Yiming Song,Yijun Wang,Zifei Shan,Yining Li,Songyang Zhang,Xinyi Le,Cailian Chen,Xinping Guan,Dacheng Tao*

Main category: cs.AI

Relevance: 85.0

TL;DR: RouteMoA：一种通过动态路由实现高效混合代理的框架，使用轻量级评分器进行初步筛选，混合法官进行后验修正，显著降低成本和延迟


<details>
  <summary>Details</summary>
Motivation: 现有混合代理方法（MoA）采用密集拓扑结构导致成本和延迟过高，LLM法官方法需要在所有模型推理后才能进行筛选，无法有效降低成本。同时缺乏模型选择标准，在大规模模型池中面临成本过高和上下文限制问题。

Method: 1. 轻量级评分器：基于查询预测粗略性能，无需推理即可筛选出高潜力候选子集；2. 混合法官：通过基于现有模型输出的轻量级自评估和交叉评估进行后验修正；3. 模型排名机制：平衡性能、成本和延迟进行模型选择。

Result: RouteMoA在不同任务和模型池规模下均优于MoA，在大规模模型池中降低成本89.8%，减少延迟63.6%。

Conclusion: RouteMoA通过动态路由机制有效解决了混合代理框架的成本和延迟问题，实现了高效的模型协作，为大规模模型池的应用提供了实用解决方案。

Abstract: Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.

</details>


### [319] [RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening](https://arxiv.org/abs/2601.18132)
*Xi Chen,Hongru Zhou,Huahui Yi,Shiyu Feng,Hanyu Zhou,Tiancheng He,Mingke You,Li Wang,Qiankun Li,Kun Wang,Weili Fu,Kang Li,Jian Li*

Main category: cs.AI

Relevance: 85.0

TL;DR: RareAlert：基于LLM推理校准的罕见病早期筛查系统，通过集成10个LLM的推理信号，训练出可在本地部署的4B参数模型，在真实数据集上达到0.917 AUC


<details>
  <summary>Details</summary>
Motivation: 罕见病的漏诊和延迟诊断是重大临床挑战。现有初级医疗分诊流程无法可靠识别罕见病患者，需要通用筛查来减少诊断延迟。研究旨在开发从初级就诊信息预测罕见病风险的早期筛查系统。

Method: 1) 集成10个LLM生成推理信号；2) 使用机器学习校准和加权这些信号；3) 将对齐的推理蒸馏到单个本地可部署模型(Qwen3-4B)；4) 构建RareBench数据集(158,666病例，33个Orphanet疾病类别，7000+罕见病)

Result: RareAlert在独立测试集上达到0.917 AUC，优于最佳机器学习集成模型和所有评估的LLM（包括GPT-5、DeepSeek-R1、Claude-3.7-Sonnet等）。证明LLM医学推理的多样性以及在高不确定性临床任务中对齐推理的有效性。

Conclusion: 罕见病识别可重新概念化为应用于普通患者群体的通用不确定性解决过程。通过将校准推理整合到单个模型中，RareAlert实现了准确、隐私保护、可扩展的罕见病风险筛查，适合大规模本地部署。

Abstract: Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.

</details>


### [320] [Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents](https://arxiv.org/abs/2601.18217)
*Zhihan Liu,Lin Guan,Yixin Nie,Kai Zhang,Zhuoqun Hao,Lin Chen,Asli Celikyilmaz,Zhaoran Wang,Na Zhang*

Main category: cs.AI

Relevance: 85.0

TL;DR: 研究LLM智能体在未知领域泛化能力的关键因素，发现状态信息丰富度和规划复杂度是影响跨域泛化的主要环境因素，并提出通过添加干扰特征来增强状态信息丰富度的方法。


<details>
  <summary>Details</summary>
Motivation: 通用LLM智能体通常在有限环境中进行后训练，但需要在更广泛的未见领域部署。本研究旨在探索当最终测试领域未知时，哪些环境属性和建模选择对跨域性能影响最大。

Method: 1) 识别影响跨域泛化的关键环境轴：状态信息丰富度（agent需要处理的信息量）和规划复杂度（基于基础策略的目标可达性和轨迹长度估计）；2) 提出随机化技术：在状态中添加少量与目标无关的干扰特征来增加状态信息丰富度；3) 分析建模选择：SFT预热/中期训练的影响，以及逐步思考在RL中的作用。

Result: 发现：1) 状态信息丰富度和规划复杂度是影响跨域泛化的主要因素，而非领域真实性或文本相似性；2) 增加状态信息丰富度能有效提升跨域鲁棒性；3) SFT预热/中期训练虽能防止灾难性遗忘，但会削弱对未包含在中期训练数据中的领域的泛化能力；4) 逐步思考在RL中虽不总能提升域内性能，但对保持泛化能力至关重要。

Conclusion: 为提升LLM智能体在未知领域的泛化能力，应关注环境的状态信息丰富度和规划复杂度，并通过添加干扰特征等技术增强状态信息。在建模方面需权衡SFT训练与泛化能力，并重视逐步思考的作用。

Abstract: Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.

</details>


### [321] [ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants](https://arxiv.org/abs/2601.18225)
*Pei Wang,Yanan Wu,Xiaoshuai Song,Weixun Wang,Gengru Chen,Zhongwen Li,Kezhong Yan,Ken Deng,Qi Liu,Shuaibing Zhao,Shaopan Xiong,Xuepeng Liu,Xuefeng Chen,Wanxi Deng,Wenbo Su,Bo Zheng*

Main category: cs.AI

Relevance: 85.0

TL;DR: ShopSimulator是一个大规模中文购物环境，用于评估和训练LLM智能体在电子商务中的表现，发现现有模型成功率不足40%，通过SFT+RL训练可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏统一的模拟环境来全面评估LLM智能体在电商购物中的能力，包括个性化偏好理解、多轮对话、产品检索和相似产品区分等方面，且现有工作只关注评估而缺乏训练支持。

Method: 构建ShopSimulator大规模中文购物环境，包含多样化场景；评估现有LLM表现；进行错误分析；探索监督微调(SFT)和强化学习(RL)结合的训练方法。

Result: 最佳模型的全成功率低于40%；智能体在长轨迹中的深度搜索和产品选择、个性化线索平衡、用户互动方面存在困难；SFT和RL结合的训练方法能显著提升性能。

Conclusion: ShopSimulator为LLM智能体在电商购物场景提供了全面的评估和训练环境，揭示了现有模型的局限性，并展示了通过适当训练方法可以显著改进性能。

Abstract: Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.

</details>


### [322] [Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks](https://arxiv.org/abs/2601.18226)
*Haotian Li,Shijun Yang,Weizhen Qi,Silei Zhao,Rui Hua,Mingzhu Song,Xiaojian Yang,Chao Peng*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出In-Situ Self-Evolving范式，通过工具进化实现智能体在开放环境中的持续能力提升，无需外部监督，在零起点设置下显著超越基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统智能体系统在开放环境中面临挑战：任务分布持续漂移、外部监督稀缺，依赖静态工具集或离线训练导致能力边界僵化。需要一种能够在交互中持续自我进化的方法。

Method: 提出In-Situ Self-Evolving范式，将序列任务交互视为连续经验流，从短期执行反馈中提炼长期可重用能力。以工具进化为核心能力扩展路径，开发Yunjue Agent系统，采用Parallel Batch Evolution策略优化进化效率。

Result: 在五个多样化基准测试的零起点设置下，相比专有基线模型取得显著性能提升。补充的热启动评估证实积累的通用知识可无缝迁移到新领域。提出了监测进化收敛的新指标。

Conclusion: In-Situ Self-Evolving范式为开放环境中的智能体提供了有效的自我进化机制，工具进化是实现能力扩展的关键路径，为构建弹性、自进化智能系统开辟了新方向。

Abstract: Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.

</details>


### [323] [Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning](https://arxiv.org/abs/2601.18282)
*Lei Wei,Jinpeng Ou,Xiao Peng,Bin Wang*

Main category: cs.AI

Relevance: 85.0

TL;DR: TAFC框架通过引入"思考"参数增强，在函数和参数层面提供显式推理，提升LLM函数调用的准确性和可解释性，无需修改模型架构。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在函数调用中缺乏参数生成的显式推理透明度，特别是对于具有相互依赖参数的复杂函数。现有方法如思维链提示在代理层面操作，无法为单个函数参数提供细粒度的推理指导。

Method: 提出Think-Augmented Function Calling (TAFC)框架：1) 引入通用的"think"参数增强，让模型阐述决策过程；2) 动态优化参数描述以提高推理质量；3) 对复杂参数基于复杂度评分自动触发细粒度推理；4) 提出推理引导优化以对齐人类期望。

Result: 在ToolBench上评估专有和开源模型，TAFC在多参数函数的参数生成准确性和推理连贯性方面显著提升，同时为调试AI代理行为提供增强的可解释性。

Conclusion: TAFC通过函数和参数层面的显式推理，有效提升了LLM函数调用的准确性和可解释性，且无需修改现有LLM架构，保持完整的API兼容性。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal "think" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.

</details>


### [324] [Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books](https://arxiv.org/abs/2601.18353)
*Tuhin Chakrabarty,Paramveer S. Dhillon*

Main category: cs.AI

Relevance: 85.0

TL;DR: 研究通过行为实验发现，经过微调的AI写作在专家评审中超越了人类作家，而普通评审则始终偏好AI写作，这引发了专家作家的身份危机和对创意劳动未来的根本性思考。


<details>
  <summary>Details</summary>
Motivation: 挑战"创意写作是人类独有能力"的传统假设，探究生成式AI能否真正模仿著名作家的风格，以及这种能力如何影响人类作家和创意劳动的未来。

Method: 行为实验设计：28名MFA作家（专家）与3个LLM竞争模仿50位著名作家的风格。采用盲审对比：28名专家评审和131名普通评审进行配对比较。测试两种条件：上下文提示和基于作者完整作品微调。

Result: 1. 上下文提示条件下，专家82.7%偏好人类写作；微调后反转，62%偏好AI写作。2. 普通评审始终偏好AI写作。3. 专家访谈显示AI偏好引发了身份危机，削弱了审美自信，质疑"好写作"的定义。

Conclusion: AI的创意能力挑战了关于其创造局限的传统论述，提出了创意劳动未来的根本性问题，包括人类作家的身份认同和审美价值的重新定义。

Abstract: Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes "good writing." These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.

</details>


### [325] [Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models](https://arxiv.org/abs/2601.18383)
*Zhenyuan Guo,Tong Chen,Wenlong Meng,Chen Gong,Xin Yu,Chengkun Wei,Wenzhi Chen*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出DynTS方法，通过注意力图分析推理轨迹，识别关键决策token，仅保留其KV缓存以优化大型推理模型的效率


<details>
  <summary>Details</summary>
Motivation: 大型推理模型(LRMs)在解决复杂问题时需要生成详细的推理轨迹，这导致巨大的内存占用和计算开销，成为效率瓶颈。研究发现推理轨迹中只有部分关键token真正影响最终答案决策。

Method: 提出动态思维token选择(DynTS)方法：1) 使用注意力图分析推理轨迹中各token的影响；2) 识别决策关键token；3) 在推理过程中仅保留这些关键token的KV缓存状态，淘汰冗余条目

Result: DynTS方法显著减少了推理过程中的内存占用和计算开销，同时保持了模型性能，实现了效率优化

Conclusion: 推理轨迹中存在大量冗余token，通过选择性保留关键token的KV缓存可以有效优化大型推理模型的效率，DynTS为此提供了一种实用解决方案

Abstract: Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.

</details>


### [326] [OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents](https://arxiv.org/abs/2601.18467)
*Yuhang Zhou,Kai Zheng,Qiguang Chen,Mengkang Hu,Qingfeng Sun,Can Xu,Jingjing Chen*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文提出了一种完全离线的研究智能体训练方法，通过开源套件生成大规模研究查询和高质量轨迹数据，训练出的8B参数模型在多项基准测试中表现出色，甚至能与30B参数的在线RL训练系统竞争。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究智能体在处理长时程任务时表现出色，但最先进的性能通常依赖于昂贵的在线强化学习（RL），这需要大量API调用，成本高昂。虽然离线训练提供了更高效的替代方案，但进展受到高质量研究轨迹稀缺的限制。作者旨在证明昂贵的在线RL并非构建强大研究智能体的唯一途径。

Method: 提出了一个完全开源的套件，用于有效的离线训练。核心贡献包括：1) DeepForge - 一个即用型任务合成框架，无需大量预处理即可生成大规模研究查询；2) 精心策划的数据集，包含66k QA对、33k SFT轨迹和21k DPO对。利用这些资源，完全离线训练了OffSeeker（8B参数模型）。

Result: 在六个基准测试上的广泛评估表明，OffSeeker不仅在类似规模的智能体中领先，而且与通过大量在线RL训练的30B参数系统保持竞争力。这表明离线训练可以产生与昂贵在线RL方法相媲美的性能。

Conclusion: 论文证明了昂贵的在线强化学习并非构建强大研究智能体的必要条件。通过开源工具和高质量数据集，可以有效地进行离线训练，获得与更大规模在线RL系统竞争的性能，为研究智能体的高效开发提供了新途径。

Abstract: Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.

</details>


### [327] [AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security](https://arxiv.org/abs/2601.18491)
*Dongrui Liu,Qihan Ren,Chen Qian,Shuai Shao,Yuejin Xie,Yu Li,Zhonghao Yang,Haoyu Luo,Peng Wang,Qingyu Liu,Binxin Hu,Ling Tang,Jilin Mei,Dadi Guo,Leitao Yuan,Junyao Yang,Guanxu Chen,Qihao Lin,Yi Yu,Bo Zhang,Jiaxuan Guo,Jie Zhang,Wenqi Shao,Huiqi Deng,Zhiheng Xi,Wenjie Wang,Wenxuan Wang,Wen Shen,Zhikai Chen,Haoyu Xie,Jialing Tao,Juntao Dai,Jiaming Ji,Zhongjie Ba,Linfeng Zhang,Yong Liu,Quanshi Zhang,Lei Zhu,Zhihua Wei,Hui Xue,Chaochao Lu,Jing Shao,Xia Hu*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文提出了一个用于AI智能体安全监控的三维风险分类法、细粒度基准测试ATBench和诊断性护栏框架AgentDoG，能够诊断不安全行为的根本原因并提供透明度。


<details>
  <summary>Details</summary>
Motivation: AI智能体的兴起带来了复杂的工具使用和环境交互安全挑战，现有护栏模型缺乏对智能体风险的认知和风险诊断的透明度。

Method: 1) 提出统一的三维风险分类法（来源、失效模式、后果）；2) 基于此构建细粒度智能体安全基准ATBench；3) 开发诊断性护栏框架AgentDoG，提供轨迹监控和根本原因诊断。

Result: AgentDoG在多样复杂的交互场景中实现了最先进的智能体安全调节性能，提供了4B、7B、8B参数的Qwen和Llama模型变体。

Conclusion: AgentDoG框架通过细粒度监控和诊断能力，超越了二元标签的限制，为智能体对齐提供了透明度和可追溯性，推动了AI智能体的安全发展。

Abstract: The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.

</details>


### [328] [DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference](https://arxiv.org/abs/2601.18496)
*Zihan wang,Hao Wang,Shi Feng,Xiaocui Yang,Daling Wang,Yiqun Zhang,Jinghao Lin,Haihua Yang,Xiaozhong Ji*

Main category: cs.AI

Relevance: 85.0

TL;DR: DeepMed：针对医学推理的深度研究模型，通过多跳医学搜索QA合成、难度感知轮次惩罚和推理监控，解决通用DR模型在医学领域的任务特征和工具使用扩展问题，在七个医学基准上平均提升9.79%。


<details>
  <summary>Details</summary>
Motivation: 医学推理模型受限于参数化知识，容易遗忘和产生幻觉。通用深度研究（DR）模型虽然能在通用领域基于工具验证证据，但直接迁移到医学领域效果有限。这归因于两个差距：任务特征差距（医学问题需要在知识密集的临床背景下解释证据）和工具使用扩展差距（盲目扩展工具调用会注入噪声，干扰敏感的医学推理）。

Method: 1. 数据：采用多跳医学搜索QA合成方法，支持模型在医学背景下应用DR范式。2. 训练：引入难度感知轮次惩罚，抑制过度工具调用增长。3. 推理：加入监控机制，在可控步骤内验证假设，避免上下文腐化。

Result: 在七个医学基准测试中，DeepMed相比基础模型平均提升9.79%，并且超越了更大的医学推理和DR模型。

Conclusion: DeepMed通过专门针对医学领域设计的深度研究方法，有效解决了通用DR模型在医学推理中的局限性，显著提升了医学推理性能。

Abstract: Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus "find it but fail to use it," leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\% on average and outperforms larger medical reasoning and DR models.

</details>


### [329] [Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities](https://arxiv.org/abs/2601.18554)
*Alberto Purpura,Li Wang,Sahil Badyal,Eugenio Beaufrand,Adam Faulkner*

Main category: cs.AI

Relevance: 85.0

TL;DR: MOSAIC是一个模块化框架，用于评估LLM遵循复杂指令的能力，通过动态生成包含最多20个应用导向约束的数据集，对指令遵循能力进行细粒度分析。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试往往无法反映真实世界使用情况，且难以将指令遵循能力与任务成功区分开来。需要一种能够独立评估LLM遵循复杂指令能力的方法，这对于开发可靠LLM系统至关重要。

Method: 提出MOSAIC框架，使用动态生成的数据集，包含最多20个应用导向的生成约束。该框架能够对指令遵循能力进行模块化、细粒度分析，独立于任务成功评估。

Result: 评估了五个不同家族的LLM，发现指令遵循能力不是单一能力，而是随约束类型、数量和位置显著变化。揭示了模型特定弱点、指令间的协同与冲突关系，以及首因效应和近因效应等位置偏差。

Conclusion: MOSAIC提供的细粒度洞察对于诊断模型失败和开发需要严格遵循复杂指令的可靠LLM系统至关重要。指令遵循能力是复杂、多维度的，需要专门的评估方法。

Abstract: Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.

</details>


### [330] [Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs](https://arxiv.org/abs/2601.18588)
*Xianzhe Meng,Qiangsheng Zeng,Ling Luo,Qinghan Yang,Jiarui Hao,Wenbo Wu,Qinyu Wang,Rui Yin,Lin Qi,Renzhi Lu*

Main category: cs.AI

Relevance: 85.0

TL;DR: 研究发现训练稳定性与生成质量并不一致：稳定的参数轨迹会导致模型输出集中在有限的经验模式上，降低生成熵，产生重复行为，尽管损失收敛平滑。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为训练稳定性是大型语言模型可靠优化的前提。本文旨在分析训练稳定性如何影响生成分布，探索稳定性与生成表达能力之间的关系。

Method: 理论分析标准最大似然训练下稳定参数轨迹的性质，并使用基于反馈的训练框架进行实证验证，该框架稳定内部生成统计量，观察不同架构和随机种子下的输出行为。

Result: 稳定训练导致模型输出集中在有限的经验模式上，生成熵降低，出现系统性退化（如重复行为），尽管损失收敛平滑。这种现象在不同架构和随机种子下一致出现。

Conclusion: 优化稳定性与生成表达能力并不内在一致，稳定性本身不足以作为生成质量的指标。需要更全面的评估方法来平衡训练稳定性和生成多样性。

Abstract: Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.

</details>


### [331] [A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic](https://arxiv.org/abs/2601.18595)
*Joseph Cotnareanu,Didier Chetelat,Yingxue Zhang,Mark Coates*

Main category: cs.AI

Relevance: 85.0

TL;DR: 提出了一种结合LLM与逻辑求解器的新方法，通过迭代反馈机制为逻辑问题补充常识关系，解决LLM在复杂证明规划中的不足。


<details>
  <summary>Details</summary>
Motivation: LLM在形式推理方面表现出色，但在需要复杂证明规划的问题上容易失败。现有的逻辑求解器虽然推理效率高，但假设所有相关事实都已提供，无法处理缺失的常识关系。需要一种方法结合神经和符号推理的优势。

Method: 提出迭代方法：使用逻辑求解器的反馈来指导LLM为逻辑问题补充常识关系。通过搜索潜在的常识假设，最大化找到有用事实的机会，同时控制计算成本。在纯逻辑推理数据集上进行测试，这些数据集已移除部分常识信息。

Result: 在多个纯逻辑推理数据集上，该方法相比现有技术取得了显著改进，证明了在人类语境中平衡神经和符号元素的价值。

Conclusion: 通过结合LLM的常识推理能力和逻辑求解器的形式推理能力，可以有效解决复杂证明规划问题，展示了神经符号方法在人类语境推理中的优势。

Abstract: Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.

</details>


### [332] [AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning](https://arxiv.org/abs/2601.18631)
*Mingyang Song,Haoyu Sun,Jiawei Gu,Linjie Li,Luxin Xu,Ranjay Krishna,Yu Cheng*

Main category: cs.AI

Relevance: 85.0

TL;DR: AdaReasoner是一个多模态模型家族，通过学习工具使用作为通用推理技能，而非特定工具或显式监督行为，实现了在视觉推理任务中的自适应工具使用和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 人类在面对超出自身能力的问题时会依赖工具，这为改进多模态大语言模型（MLLMs）的视觉推理提供了有前景的范式。有效的推理需要知道使用哪些工具、何时调用它们以及如何在多步骤中组合它们，即使面对新工具或新任务时也是如此。

Method: 1) 可扩展的数据整理流程，让模型接触长视野、多步骤的工具交互；2) Tool-GRPO强化学习算法，基于最终任务成功优化工具选择和序列；3) 自适应学习机制，动态调节工具使用频率。

Result: AdaReasoner表现出强大的工具自适应和泛化行为：自主采用有益工具、抑制无关工具、根据任务需求调整工具使用频率。在多个基准测试中达到最先进性能，7B基础模型平均提升24.9%，在VSP和Jigsaw等任务上超越GPT-5等强大专有系统。

Conclusion: AdaReasoner通过将工具使用作为通用推理技能学习，实现了多模态模型的自适应工具使用能力，能够从任务上下文和中间结果推断工具效用，协调多个工具并泛化到未见过的工具。

Abstract: When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.

</details>


### [333] [FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory](https://arxiv.org/abs/2601.18642)
*Lei Wei,Xu Dong,Xiao Peng,Niantao Xie,Bin Wang*

Main category: cs.AI

Relevance: 85.0

TL;DR: FadeMem：一种受生物学启发的智能体记忆架构，通过引入主动遗忘机制来解决LLM自主智能体的记忆限制问题，实现选择性遗忘与信息保留的平衡。


<details>
  <summary>Details</summary>
Motivation: 当前LLM自主智能体面临关键记忆限制，缺乏选择性遗忘机制，导致要么在上下文边界发生灾难性遗忘，要么在边界内信息过载。人类记忆通过自适应衰减过程自然平衡保留与遗忘，而现有AI系统采用二元保留策略（要么全部保留，要么全部丢失）。

Method: FadeMem采用受生物学启发的智能体记忆架构，包含主动遗忘机制。实现双层级记忆结构中的差异衰减率，保留由自适应指数衰减函数控制，该函数受语义相关性、访问频率和时间模式调节。通过LLM引导的冲突解决和智能记忆融合，系统在允许无关细节衰减的同时整合相关信息。

Result: 在Multi-Session Chat、LoCoMo和LTI-Bench上的实验表明，系统在实现45%存储减少的同时，展现出优越的多跳推理和检索能力，验证了生物学启发遗忘在智能体记忆系统中的有效性。

Conclusion: FadeMem通过引入受人类认知启发的主动遗忘机制，有效解决了LLM自主智能体的记忆管理问题，在减少存储需求的同时提升了推理和检索性能，为智能体记忆系统设计提供了新方向。

Abstract: Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.

</details>


### [334] [TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent](https://arxiv.org/abs/2601.18700)
*Xingyu Sui,Yanyan Zhao,Yulin Hu,Jiahe Guo,Weixiang Zhao,Bing Qin*

Main category: cs.AI

Relevance: 85.0

TL;DR: TEA-Bench是首个用于评估工具增强情感支持对话系统的交互式基准，包含真实情感场景、工具环境和过程级评估指标，实验显示工具增强能提升支持质量并减少幻觉，但效果与模型能力密切相关。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话系统主要关注文本情感表达，忽视了外部工具在提供事实基础和减少幻觉方面的作用。需要建立一个评估工具增强情感支持代理的基准，以促进更可靠的情感支持系统发展。

Method: 提出TEA-Bench基准，包含真实情感场景、MCP风格工具环境，以及联合评估情感支持质量和事实基础的过程级指标。在9个LLM上进行实验，并发布TEA-Dialog工具增强情感支持对话数据集。

Result: 工具增强普遍提升情感支持质量并减少幻觉，但效果与模型能力强相关：强大模型能更选择性和有效地使用工具，而较弱模型获益有限。监督微调能提升域内支持效果但泛化能力差。

Conclusion: 工具使用对于构建可靠的情感支持代理至关重要，模型能力是工具有效使用的关键因素，需要进一步研究如何让各种模型都能有效利用工具进行情感支持。

Abstract: Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.

</details>


### [335] [Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs](https://arxiv.org/abs/2601.18706)
*Zhichao Yang,Sepehr Janghorbani,Dongxu Zhang,Jun Han,Qian Qian,Andrew Ressler,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.AI

Relevance: 85.0

TL;DR: Health-SCORE是一个可扩展的基于量规的LLM训练和评估框架，显著降低医疗领域量规开发成本，同时保持评估质量，并可用于强化学习和上下文学习。


<details>
  <summary>Details</summary>
Motivation: 在医疗等安全关键领域，量规对于评估开放式LLM响应至关重要，但创建高质量、领域特定的量规需要大量专家时间和开发成本，使得基于量规的评估和训练难以扩展。

Method: 提出Health-SCORE框架，通过自动化或半自动化方法生成量规，显著降低开发成本。该框架不仅用于评估，还可作为结构化奖励信号指导强化学习，并可直接整合到提示中通过上下文学习改进响应质量。

Result: 在开放式医疗任务中，Health-SCORE实现了与人工创建量规相当的评估质量，同时显著降低了开发工作量，使基于量规的评估和训练更具可扩展性。

Conclusion: Health-SCORE为医疗领域的LLM评估和训练提供了一个通用且可扩展的解决方案，通过降低量规开发成本，使基于量规的方法更具实用性和可扩展性。

Abstract: Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.

</details>


### [336] [TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models](https://arxiv.org/abs/2601.18744)
*Fangxu Yu,Xingang Guo,Lingzhi Yuan,Haoqiang Kang,Hongyu Zhao,Lianhui Qin,Furong Huang,Bin Hu,Tianyi Zhou*

Main category: cs.AI

Relevance: 85.0

TL;DR: TSRBench是一个全面的多模态时间序列推理基准测试，包含4125个问题、14个领域、4个维度，评估了30多个领先模型，发现缩放定律在感知和推理中成立但在预测中失效，语义理解与数值预测存在脱节。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在现实世界中无处不在且对关键应用至关重要，但现有通用模型基准测试中缺少时间序列推理维度。为了填补这一空白，作者创建了TSRBench来全面评估通用模型的时间序列推理能力。

Method: 构建了包含4125个问题、覆盖14个领域的多模态基准测试，分为感知、推理、预测和决策4个主要维度，包含15个任务评估基本推理能力。评估了30多个领先的专有和开源LLM、VLM和TSLLM。

Result: 1) 缩放定律在感知和推理中成立但在预测中失效；2) 强大的推理能力不能保证准确的上下文感知预测，表明语义理解和数值预测之间存在脱节；3) 尽管时间序列的文本和视觉表示具有互补性，但当前多模态模型未能有效融合它们以获得性能增益。

Conclusion: TSRBench提供了一个标准化评估平台，不仅突出了现有挑战，还为推进通用模型发展提供了有价值的见解。时间序列推理是通用模型解决实际问题的重要能力，需要进一步研究。

Abstract: Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.

</details>


### [337] [Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs](https://arxiv.org/abs/2601.17058)
*Wei Zhou,Jun Zhou,Haoyu Wang,Zhenghao Li,Qikang He,Shaokun Han,Guoliang Li,Xuanhe Zhou,Yeye He,Chunwei Liu,Zirui Tang,Bin Wang,Shen Tang,Kai Zuo,Yuyu Luo,Zhenzhe Zheng,Conghui He,Jingren Zhou,Fan Wu*

Main category: cs.DB

Relevance: 85.0

TL;DR: 本文系统综述了LLM增强的数据准备方法，涵盖数据清洗、集成和丰富化三大任务，分析了范式转变、技术优势与局限，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 数据准备对于数据驱动应用至关重要，而LLM技术的快速发展、对应用就绪数据的需求增长以及灵活代理基础设施的出现，共同推动了LLM增强数据准备方法的兴起，这代表了从传统规则驱动到智能代理驱动的范式转变。

Method: 通过对数百篇近期文献的系统调研，提出了任务中心的分类法：1) 数据清洗（标准化、错误处理、填补），2) 数据集成（实体匹配、模式匹配），3) 数据丰富化（数据标注、分析）。对每类任务调查代表性技术，分析其优势和局限，并总结常用数据集和评估指标。

Result: LLM增强方法在泛化能力和语义理解方面表现优势，但也面临扩展成本高、幻觉问题持续存在、先进方法与弱评估不匹配等挑战。实证部分提供了常用数据集和评估指标的详细分析。

Conclusion: LLM增强的数据准备正在成为变革性范式，未来需要关注可扩展的LLM-数据系统、可靠的代理工作流设计原则以及稳健的评估协议等研究方向。

Abstract: Data preparation aims to denoise raw datasets, uncover cross-dataset relationships, and extract valuable insights from them, which is essential for a wide range of data-centric applications. Driven by (i) rising demands for application-ready data (e.g., for analytics, visualization, decision-making), (ii) increasingly powerful LLM techniques, and (iii) the emergence of infrastructures that facilitate flexible agent construction (e.g., using Databricks Unity Catalog), LLM-enhanced methods are rapidly becoming a transformative and potentially dominant paradigm for data preparation.
  By investigating hundreds of recent literature works, this paper presents a systematic review of this evolving landscape, focusing on the use of LLM techniques to prepare data for diverse downstream tasks. First, we characterize the fundamental paradigm shift, from rule-based, model-specific pipelines to prompt-driven, context-aware, and agentic preparation workflows. Next, we introduce a task-centric taxonomy that organizes the field into three major tasks: data cleaning (e.g., standardization, error processing, imputation), data integration (e.g., entity matching, schema matching), and data enrichment (e.g., data annotation, profiling). For each task, we survey representative techniques, and highlight their respective strengths (e.g., improved generalization, semantic understanding) and limitations (e.g., the prohibitive cost of scaling LLMs, persistent hallucinations even in advanced agents, the mismatch between advanced methods and weak evaluation). Moreover, we analyze commonly used datasets and evaluation metrics (the empirical part). Finally, we discuss open research challenges and outline a forward-looking roadmap that emphasizes scalable LLM-data systems, principled designs for reliable agentic workflows, and robust evaluation protocols.

</details>


### [338] [Do VLMs Have a Moral Backbone? A Study on the Fragile Morality of Vision-Language Models](https://arxiv.org/abs/2601.17082)
*Zhining Liu,Tianyi Wang,Xiao Lin,Penghao Ouyang,Gaotang Li,Ze Yang,Hui Liu,Sumit Keswani,Vishwa Pardeshi,Huijun Zhao,Wei Fan,Hanghang Tong*

Main category: cs.CY

Relevance: 85.0

TL;DR: 研究发现视觉语言模型（VLMs）的道德判断在文本和视觉扰动下高度脆弱，即使扰动不改变道德情境，模型立场也容易翻转。道德对齐不足以保证道德鲁棒性，后者是负责任部署VLMs的必要标准。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLMs）的道德对齐工作取得进展，但其在真实场景中的道德判断稳定性仍不清楚。研究旨在探究VLMs的道德鲁棒性，即在不改变道德情境的文本和视觉扰动下保持道德判断的能力。

Method: 使用多样化的模型无关多模态扰动系统性地探测VLMs，分析扰动类型、道德领域和模型规模的系统性脆弱性，包括揭示指令跟随能力与易受说服性之间的权衡关系。

Result: VLMs的道德立场高度脆弱，在简单操纵下频繁翻转。发现系统性脆弱性，包括指令跟随能力越强的模型越容易受到说服（奉承权衡）。轻量级推理时干预可部分恢复道德稳定性。

Conclusion: 仅道德对齐不足以保证VLMs的道德鲁棒性，后者是负责任部署的必要标准。需要开发能保持道德判断稳定性的方法，特别是在面对多模态扰动时。

Abstract: Despite substantial efforts toward improving the moral alignment of Vision-Language Models (VLMs), it remains unclear whether their ethical judgments are stable in realistic settings. This work studies moral robustness in VLMs, defined as the ability to preserve moral judgments under textual and visual perturbations that do not alter the underlying moral context. We systematically probe VLMs with a diverse set of model-agnostic multimodal perturbations and find that their moral stances are highly fragile, frequently flipping under simple manipulations. Our analysis reveals systematic vulnerabilities across perturbation types, moral domains, and model scales, including a sycophancy trade-off where stronger instruction-following models are more susceptible to persuasion. We further show that lightweight inference-time interventions can partially restore moral stability. These results demonstrate that moral alignment alone is insufficient and that moral robustness is a necessary criterion for the responsible deployment of VLMs.

</details>


### [339] [Lost in Simulation: LLM-Simulated Users are Unreliable Proxies for Human Users in Agentic Evaluations](https://arxiv.org/abs/2601.17087)
*Preethi Seshadri,Samuel Cahyawijaya,Ayomide Odumakinde,Sameer Singh,Seraphina Goldfarb-Tarrant*

Main category: cs.HC

Relevance: 85.0

TL;DR: 研究发现LLM模拟用户在评估智能体时缺乏鲁棒性、存在系统性校准错误，并对不同用户群体（特别是AAVE和印度英语使用者）产生不公平的评估结果


<details>
  <summary>Details</summary>
Motivation: 当前智能体评估越来越多地依赖LLM模拟用户进行可扩展评估，但这种方法在鲁棒性、有效性和公平性方面尚未得到充分检验。研究旨在探究LLM模拟用户是否能作为真实人类用户的可靠代理来评估智能体性能。

Method: 通过在美国、印度、肯尼亚和尼日利亚进行用户研究，比较LLM模拟用户与真实人类用户在τ-Bench零售任务中对智能体性能的评估差异。分析不同用户LLM的鲁棒性、校准误差，以及针对不同人口群体（特别是AAVE和SAE使用者）的评估公平性。

Result: 1. 用户模拟缺乏鲁棒性：不同用户LLM导致智能体成功率变化高达9个百分点
2. 系统性校准错误：模拟用户低估了智能体在困难任务上的表现，高估了中等难度任务的表现
3. 群体差异：AAVE使用者的成功率始终低于SAE使用者，校准误差更大，且年龄因素加剧了这种差异
4. 代理有效性差异：模拟用户对AAVE和印度英语使用者的代理效果最差
5. 对话伪影：模拟用户引入了人工对话特征，表现出与人类用户不同的失败模式

Conclusion: 当前基于LLM模拟用户的评估实践存在风险，可能错误地表示智能体在不同用户群体中的能力，并掩盖真实世界部署中的挑战。需要更谨慎地使用模拟用户评估方法，并考虑其局限性。

Abstract: Agentic benchmarks increasingly rely on LLM-simulated users to scalably evaluate agent performance, yet the robustness, validity, and fairness of this approach remain unexamined. Through a user study with participants across the United States, India, Kenya, and Nigeria, we investigate whether LLM-simulated users serve as reliable proxies for real human users in evaluating agents on τ-Bench retail tasks. We find that user simulation lacks robustness, with agent success rates varying up to 9 percentage points across different user LLMs. Furthermore, evaluations using simulated users exhibit systematic miscalibration, underestimating agent performance on challenging tasks and overestimating it on moderately difficult ones. African American Vernacular English (AAVE) speakers experience consistently worse success rates and calibration errors than Standard American English (SAE) speakers, with disparities compounding significantly with age. We also find simulated users to be a differentially effective proxy for different populations, performing worst for AAVE and Indian English speakers. Additionally, simulated users introduce conversational artifacts and surface different failure patterns than human users. These findings demonstrate that current evaluation practices risk misrepresenting agent capabilities across diverse user populations and may obscure real-world deployment challenges.

</details>


### [340] [Beyond Instrumental and Substitutive Paradigms: Introducing Machine Culture as an Emergent Phenomenon in Large Language Models](https://arxiv.org/abs/2601.17096)
*Yueqing Hu,Xinyang Peng,Yukun Zhao,Lin Qiu,Ka-lai Hung,Kaiping Peng*

Main category: cs.CY

Relevance: 85.0

TL;DR: 该研究挑战了将大语言模型视为人类文化代理的两种主流范式，提出了"机器文化"作为新兴独特现象的概念。通过实验发现模型起源不预测文化对齐，提示语言不触发稳定文化框架切换，并识别出RLHF导致文化差异崩溃为"服务人格伪装"的现象。


<details>
  <summary>Details</summary>
Motivation: 当前研究通常通过"工具范式"（模型反映开发者文化）或"替代范式"（模型作为双语代理切换文化框架）来理解LLMs。本研究挑战这些拟人化框架，旨在探索LLMs是否展现独特的"机器文化"现象。

Method: 采用2（模型起源：美国vs中国）×2（提示语言：英语vs中文）因子设计，在八个多模态任务中进行实验，特别包含图像生成和解释任务以超越文本分析边界。

Result: 发现与主流范式不一致：1）模型起源不预测文化对齐，美国模型常展现东亚数据相关的"整体性"特征；2）提示语言不触发稳定文化框架切换，反而出现"文化反转"现象（英语提示引发更高情境关注）；3）识别出"服务人格伪装"：RLHF在情感任务中将文化差异崩溃为超积极、零方差的"有帮助助手"人格。

Conclusion: LLMs不模拟人类文化，而是展现新兴的"机器文化"——一种由高维空间中的叠加和安全对齐导致的模式崩溃所塑造的概率现象。

Abstract: Recent scholarship typically characterizes Large Language Models (LLMs) through either an \textit{Instrumental Paradigm} (viewing models as reflections of their developers' culture) or a \textit{Substitutive Paradigm} (viewing models as bilingual proxies that switch cultural frames based on language). This study challenges these anthropomorphic frameworks by proposing \textbf{Machine Culture} as an emergent, distinct phenomenon. We employed a 2 (Model Origin: US vs. China) $\times$ 2 (Prompt Language: English vs. Chinese) factorial design across eight multimodal tasks, uniquely incorporating image generation and interpretation to extend analysis beyond textual boundaries. Results revealed inconsistencies with both dominant paradigms: Model origin did not predict cultural alignment, with US models frequently exhibiting ``holistic'' traits typically associated with East Asian data. Similarly, prompt language did not trigger stable cultural frame-switching; instead, we observed \textbf{Cultural Reversal}, where English prompts paradoxically elicited higher contextual attention than Chinese prompts. Crucially, we identified a novel phenomenon termed \textbf{Service Persona Camouflage}: Reinforcement Learning from Human Feedback (RLHF) collapsed cultural variance in affective tasks into a hyper-positive, zero-variance ``helpful assistant'' persona. We conclude that LLMs do not simulate human culture but exhibit an emergent Machine Culture -- a probabilistic phenomenon shaped by \textit{superposition} in high-dimensional space and \textit{mode collapse} from safety alignment.

</details>


### [341] [The 17% Gap: Quantifying Epistemic Decay in AI-Assisted Survey Papers](https://arxiv.org/abs/2601.17431)
*H. Kemal İlter*

Main category: cs.CY

Relevance: 85.0

TL;DR: 该论文对AI领域50篇综述论文的5514条引用进行法证审计，发现17%的引用无法解析到任何数字对象，揭示了LLM在科学写作中导致引用链系统性退化的量化证据。


<details>
  <summary>Details</summary>
Motivation: 量化LLM在科学写作中引入的信息熵风险，特别是系统性地破坏有效引用链的问题。虽然"幻觉论文"已知，但引用链的系统性退化尚未被量化研究。

Method: 采用混合验证流程：DOI解析、Crossref元数据分析、Semantic Scholar查询和模糊文本匹配，区分格式错误（"粗心"）和可验证的不存在引用（"幻影"）。对2024年9月至2026年1月间50篇AI综述论文的5514条引用进行法证审计。

Result: 发现17.0%的幻影率（无法解析到任何数字对象的引用）。诊断分类显示三种失败模式：纯幻觉（5.1%）、具有有效标题的幻觉标识符（16.4%）和解析诱导的匹配失败（78.5%）。纵向分析显示趋势平稳（+0.07 pp/月），表明高熵引用实践已成为该领域的固有特征。

Conclusion: AI领域的科学引用图在大规模上出现"链接腐烂"。AI工具充当"懒惰的研究助手"，检索正确标题但幻觉元数据，从而切断了可重复科学所需的数字保管链。

Abstract: The adoption of Large Language Models (LLMs) in scientific writing promises efficiency but risks introducing informational entropy. While "hallucinated papers" are a known artifact, the systematic degradation of valid citation chains remains unquantified. We conducted a forensic audit of 50 recent survey papers in Artificial Intelligence (N=5,514 citations) published between September 2024 and January 2026. We utilized a hybrid verification pipeline combining DOI resolution, Crossref metadata analysis, Semantic Scholar queries, and fuzzy text matching to distinguish between formatting errors ("Sloppiness") and verifiable non-existence ("Phantoms). We detect a persistent 17.0% Phantom Rate -- citations that cannot be resolved to any digital object despite aggressive forensic recovery. Diagnostic categorization reveals three distinct failure modes: pure hallucinations (5.1%), hallucinated identifiers with valid titles (16.4%), and parsing-induced matching failures (78.5%). Longitudinal analysis reveals a flat trend (+0.07 pp/month), suggesting that high-entropy citation practices have stabilized as an endemic feature of the field. The scientific citation graph in AI survey literature exhibits "link rot" at scale. This suggests a mechanism where AI tools act as "lazy research assistants," retrieving correct titles but hallucinating metadata, thereby severing the digital chain of custody required for reproducible science.

</details>


### [342] [High-Rate Quantized Matrix Multiplication: Theory and Practice](https://arxiv.org/abs/2601.17187)
*Or Ordentlich,Yury Polyanskiy*

Main category: cs.IT

Relevance: 85.0

TL;DR: 该论文研究量化矩阵乘法，分析通用矩阵乘法和仅权重量化两种设置下的信息论极限，提出基于水填充的WaterSIC量化方案，在Llama-3-8B上接近最优性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型部署需求增长，高效的量化矩阵乘法变得至关重要。现有量化方案（如GPTQ）在速率分配上采用均等策略，未能充分利用信息论最优的水填充原理，限制了量化效率。

Method: 1) 分析通用矩阵乘法和仅权重量化的信息论极限（高率理论）；2) 评估absmax INT和浮点量化的速率损失；3) 将仅权重量化建模为加权均方误差源编码问题，提出基于水填充的WaterSIC方案；4) 在Llama-3-8B上比较GPTQ与WaterSIC性能。

Result: WaterSIC仅使用标量INT量化器，其高率性能仅取决于Σ_X的行列式，对随机旋转不变，且距离信息论失真极限仅差乘性因子2πe/12（约0.25比特/条目）。GPTQ在随机旋转下与WaterSIC相差仅0.1比特，表明其接近最优。

Conclusion: 基于水填充的量化方案（WaterSIC）在理论上接近信息论极限，实际中GPTQ配合随机旋转也能达到接近最优性能，为大语言模型的高效量化部署提供了理论基础和实用指导。

Abstract: This work investigates the problem of quantized matrix multiplication (MatMul), which has become crucial for the efficient deployment of large language models (LLMs). We consider two settings: 1) Generic MatMul, where both matrices must be quantized (weight+activation quantization); and 2) weight-only quantization, where the second matrix is only known through covariance matrix $Σ_X$ of its columns. For each setting, we first review the fundamental information-theoretic tradeoff between quantization rate and distortion (high-rate theory), and then analyze the performance of several popular quantization schemes, comparing them to these fundamental limits. Specifically, we discuss rate loss (compared to information theoretic optima) of absmax INT and floating-point (FP) quantization, for which we also derive remarkably accurate heuristic approximations. Weight-only quantization is related to the problem of weighted mean squared error (WMSE) source coding, whose classical (reverse) waterfilling solution dictates how one should distribute rate between coordinates of the vector. We show how waterfilling can be used to improve practical LLM quantization algorithms (GPTQ), which at present allocate rate equally. This new scheme (termed ``WaterSIC'') only uses scalar INT quantizers, but its high-rate performance is basis free (it depends only on the determinant of $Σ_X$ and, thus, unlike existing schemes, is immune to applying random rotations) and is within a multiplicative factor of $\frac{2πe}{12}$ (or 0.25 bit/entry) of the information-theoretic distortion limit (!). GPTQ's performance is affected by the choice of basis, but for a random rotation and actual $Σ_X$ from Llama-3-8B we find GPTQ to be within 0.1 bit (depending on the layer type) of WaterSIC, suggesting that GPTQ with random rotation is also near optimal (for high-rate quantization).

</details>


### [343] [Towards a Declarative Agentic Layer for Intelligent Agents in MCP-Based Server Ecosystems](https://arxiv.org/abs/2601.17435)
*Maria Jesus Rodriguez-Sanchez,Manuel Noguera,Angel Ruiz-Zafra,Kawtar Benghazi*

Main category: cs.SE

Relevance: 85.0

TL;DR: DALIA提出了一种声明式的、模型无关的智能体架构层，通过形式化可执行能力、声明式发现协议和确定性任务图，解决当前LLM智能体系统存在的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体和多智能体系统存在严重的可靠性问题，包括幻觉动作、不可执行计划和脆弱的协调。这些问题并非源于底层模型本身的限制，而是由于缺乏明确连接目标、能力和执行的架构结构。

Method: DALIA是一个声明式的、模型无关的架构层，它：1) 形式化可执行能力；2) 通过声明式发现协议暴露任务；3) 维护智能体及其执行资源的联邦目录；4) 构建基于声明操作的确定性任务图。该架构强制分离发现、规划和执行阶段。

Result: 通过代表性任务导向场景展示了DALIA的操作，证明声明式基础能够实现跨异构环境的可重现和可验证智能体工作流，将智能体行为约束在可验证的操作空间内。

Conclusion: DALIA通过提供明确的架构结构来解决LLM智能体系统的可靠性问题，减少对推测性推理和自由形式协调的依赖，为构建可靠、可验证的智能体工作流提供了框架。

Abstract: Recent advances in Large Language Models (LLMs) have enabled the development of increasingly complex agentic and multi-agent systems capable of planning, tool use and task decomposition. However, empirical evidence shows that many of these systems suffer from fundamental reliability issues, including hallucinated actions, unexecutable plans and brittle coordination. Crucially, these failures do not stem from limitations of the underlying models themselves, but from the absence of explicit architectural structure linking goals, capabilities and execution. This paper presents a declarative, model-independent architectural layer for grounded agentic workflows that addresses this gap. The proposed layer, referred to as DALIA (Declarative Agentic Layer for Intelligent Agents), formalises executable capabilities, exposes tasks through a declarative discovery protocol, maintains a federated directory of agents and their execution resources, and constructs deterministic task graphs grounded exclusively in declared operations. By enforcing a clear separation between discovery, planning and execution, the architecture constrains agent behaviour to a verifiable operational space, reducing reliance on speculative reasoning and free-form coordination. We present the architecture and design principles of the proposed layer and illustrate its operation through a representative task-oriented scenario, demonstrating how declarative grounding enables reproducible and verifiable agentic workflows across heterogeneous environments.

</details>


### [344] [Bridging Expectation Signals: LLM-Based Experiments and a Behavioral Kalman Filter Framework](https://arxiv.org/abs/2601.17527)
*Yu Wang,Xiangchen Liu*

Main category: econ.GN

Relevance: 85.0

TL;DR: 论文研究LLM作为经济代理时如何更新信念，发现其行为偏离理性预期，对个体信号赋予更高权重，多信号存在交互效应，且不同角色代理行为模式不同，LoRA微调可缓解但无法完全消除这些行为偏差。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地作为经济代理发挥作用，它们如何利用异质信号更新信念的具体机制仍然不透明。需要理解LLM代理在作为家庭或企业CEO时，面对个体和总体信号时如何形成预期。

Method: 设计实验并开发行为卡尔曼滤波器框架，量化LLM代理更新预期的过程。让LLM扮演家庭或企业CEO角色，面对个体和总体信号，通过实验和模型估计分析其预期形成机制。

Result: 发现四个一致模式：1) 代理对先验和信号的权重偏离理性预期；2) 家庭和企业CEO代理对个体信号赋予比总体信号更大的权重；3) 并发信号存在显著负向交互效应，多信息源会降低每个信号的边际权重；4) 家庭和企业CEO代理的预期形成模式显著不同。LoRA微调可缓解但无法完全消除这些行为偏差。

Conclusion: LLM作为经济代理时表现出系统性行为偏差，其预期形成机制偏离理性预期理论。这些偏差在不同角色间存在差异，且通过微调只能部分缓解。这对LLM在经济决策应用中的可信度提出了重要问题。

Abstract: As LLMs increasingly function as economic agents, the specific mechanisms LLMs use to update their belief with heterogeneous signals remain opaque. We design experiments and develop a Behavioral Kalman Filter framework to quantify how LLM-based agents update expectations, acting as households or firm CEOs, update expectations when presented with individual and aggregate signals. The results from experiments and model estimation reveal four consistent patterns: (1) agents' weighting of priors and signals deviates from unity; (2) both household and firm CEO agents place substantially larger weights on individual signals compared to aggregate signals; (3) we identify a significant and negative interaction between concurrent signals, implying that the presence of multiple information sources diminishes the marginal weight assigned to each individual signal; and (4) expectation formation patterns differ significantly between household and firm CEO agents. Finally, we demonstrate that LoRA fine-tuning mitigates, but does not fully eliminate, behavioral biases in LLM expectation formation.

</details>


### [345] [Reconstructing Training Data from Adapter-based Federated Large Language Models](https://arxiv.org/abs/2601.17533)
*Silong Chen,Yuchuan Luo,Guilin Deng,Yi Liu,Min Xu,Shaojing Fu,Xiaohua Jia*

Main category: cs.CR

Relevance: 85.0

TL;DR: 本文提出UTR攻击，针对基于适配器的联邦大语言模型，通过分析注意力模式、低秩子空间反演和语义约束解码，实现了近乎完美的文本重建，揭示了参数效率与隐私之间的根本矛盾。


<details>
  <summary>Details</summary>
Motivation: 当前基于适配器的联邦大语言模型（FedLLMs）被广泛采用，通过冻结主干网络并仅训练紧凑的低秩适配器来降低计算、存储和通信开销，同时保护用户隐私。这些方法被认为可以限制梯度泄漏并抵御现有的梯度反演攻击（GIAs）。然而，作者挑战了这一假设，认为低秩适配器实际上创造了新的可利用泄漏通道。

Method: 提出UTR（Unordered-word-bag-based Text Reconstruction）攻击，专门针对适配器FedLLMs的独特结构设计。该方法克服三个核心挑战：1）从冻结层的注意力模式推断token存在性；2）在适配器梯度的低秩子空间内进行句子级反演；3）通过语言先验引导的约束贪婪解码来强制语义一致性。

Result: 在多种模型（GPT2-Large、BERT、Qwen2.5-7B）和数据集（CoLA、SST-2、Rotten Tomatoes）上的广泛实验表明，UTR实现了近乎完美的重建精度（ROUGE-1/2 > 99），即使在大批量设置下，而先前的GIAs完全失败。

Conclusion: 研究结果揭示了FedLLMs中参数效率与隐私之间的根本矛盾，挑战了轻量级适配器固有增强安全性的普遍信念。这表明当前基于适配器的联邦学习方法存在严重隐私风险。

Abstract: Adapter-based Federated Large Language Models (FedLLMs) are widely adopted to reduce the computational, storage, and communication overhead of full-parameter fine-tuning for web-scale applications while preserving user privacy. By freezing the backbone and training only compact low-rank adapters, these methods appear to limit gradient leakage and thwart existing Gradient Inversion Attacks (GIAs).
  Contrary to this assumption, we show that low-rank adapters create new, exploitable leakage channels. We propose the Unordered-word-bag-based Text Reconstruction (UTR) attack, a novel GIA tailored to the unique structure of adapter-based FedLLMs. UTR overcomes three core challenges: low-dimensional gradients, frozen backbones, and combinatorially large reconstruction spaces by: (i) inferring token presence from attention patterns in frozen layers, (ii) performing sentence-level inversion within the low-rank subspace of adapter gradients, and (iii) enforcing semantic coherence through constrained greedy decoding guided by language priors. Extensive experiments across diverse models (GPT2-Large, BERT, Qwen2.5-7B) and datasets (CoLA, SST-2, Rotten Tomatoes) demonstrate that UTR achieves near-perfect reconstruction accuracy (ROUGE-1/2 > 99), even with large batch size settings where prior GIAs fail completely. Our results reveal a fundamental tension between parameter efficiency and privacy in FedLLMs, challenging the prevailing belief that lightweight adaptation inherently enhances security. Our code and data are available at https://github.com/shwksnshwowk-wq/GIA.

</details>


### [346] [Breaking the Protocol: Security Analysis of the Model Context Protocol Specification and Prompt Injection Vulnerabilities in Tool-Integrated LLM Agents](https://arxiv.org/abs/2601.17549)
*Narek Maloyan,Dmitry Namiot*

Main category: cs.CR

Relevance: 85.0

TL;DR: 首次对MCP协议进行形式化安全分析，发现三个架构级漏洞，提出MCPSec扩展方案，将攻击成功率从52.8%降至12.4%


<details>
  <summary>Details</summary>
Motivation: MCP已成为LLM与外部工具集成的实际标准，但缺乏正式的安全分析。需要评估协议规范的安全性，识别架构设计中的根本性漏洞。

Method: 1) 对MCP架构设计进行严格安全分析，识别三个协议级漏洞；2) 实现MCPBench框架，将现有智能体安全基准适配到MCP基础设施；3) 在5个MCP服务器实现上进行847个攻击场景的受控实验；4) 提出MCPSec协议扩展，添加能力证明和消息认证

Result: 1) MCP架构选择使攻击成功率比非MCP集成提高23-41%；2) MCPSec将攻击成功率从52.8%降至12.4%，每条消息中位延迟开销为8.3ms；3) 发现MCP的安全弱点是架构性的而非实现特定的

Conclusion: MCP的安全缺陷是架构层面的，需要协议级修复。MCPSec作为向后兼容的扩展方案能显著提升安全性，证明协议设计对LLM工具集成的安全至关重要。

Abstract: The Model Context Protocol (MCP) has emerged as a de facto standard for integrating Large Language Models with external tools, yet no formal security analysis of the protocol specification exists. We present the first rigorous security analysis of MCP's architectural design, identifying three fundamental protocol-level vulnerabilities: (1) absence of capability attestation allowing servers to claim arbitrary permissions, (2) bidirectional sampling without origin authentication enabling server-side prompt injection, and (3) implicit trust propagation in multi-server configurations. We implement \textsc{MCPBench}, a novel framework bridging existing agent security benchmarks to MCP-compliant infrastructure, enabling direct measurement of protocol-specific attack surfaces. Through controlled experiments on 847 attack scenarios across five MCP server implementations, we demonstrate that MCP's architectural choices amplify attack success rates by 23--41\% compared to equivalent non-MCP integrations. We propose \textsc{MCPSec}, a backward-compatible protocol extension adding capability attestation and message authentication, reducing attack success rates from 52.8\% to 12.4\% with median latency overhead of 8.3ms per message. Our findings establish that MCP's security weaknesses are architectural rather than implementation-specific, requiring protocol-level remediation.

</details>


### [347] [Real-Time Trend Prediction via Continually-Aligned LLM Query Generation](https://arxiv.org/abs/2601.17567)
*Zijing Hui,Wenhan Lyu,Shusen Wang,Li Chen,Chu Wang*

Main category: cs.IR

Relevance: 85.0

TL;DR: RTTP是一个实时趋势预测框架，通过LLM直接从新闻内容生成搜索查询，解决低流量搜索环境中的冷启动问题，在Facebook和Meta AI产品中实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 低流量搜索环境中存在冷启动问题，传统基于关键词频率或查询峰值的方法在稀疏设置中效果差且响应慢，无法及时捕捉新兴或长尾趋势。

Method: 提出RTTP框架：1) 使用持续学习LLM将新闻帖子转换为搜索式查询；2) 基于参与强度和创作者权威对查询评分；3) 提出Mix-Policy DPO方法，结合on-policy稳定性和off-policy新颖性，防止模型升级时的灾难性遗忘。

Result: 在Facebook和Meta AI产品中部署：1) 长尾趋势检测精度@500提升91.4%；2) 查询生成准确率比行业基线提高19%；3) 多周在线训练后保持稳定性能。

Conclusion: LLM生成的合成搜索信号，经过对齐和持续更新，能够在低流量搜索环境中实现及时的趋势理解，解决了传统方法的局限性。

Abstract: Trending news detection in low-traffic search environments faces a fundamental cold-start problem, where a lack of query volume prevents systems from identifying emerging or long-tail trends. Existing methods relying on keyword frequency or query spikes are inherently slow and ineffective in these sparse settings, lagging behind real-world shifts in attention. We introduce RTTP, a novel Real-Time Trending Prediction framework that generates search queries directly from news content instead of waiting for users to issue them. RTTP leverages a continual learning LLM (CL-LLM) that converts posts into search-style queries and scores them using engagement strength + creator authority, enabling early trend surfacing before search volume forms. To ensure adaptation without degrading reasoning, we propose Mix-Policy DPO, a new preference-based continual learning approach that combines on-policy stability with off-policy novelty to mitigate catastrophic forgetting during model upgrades. Deployed at production scale on Facebook and Meta AI products, RTTP delivers +91.4% improvement in tail-trend detection precision@500 and +19% query generation accuracy over industry baselines, while sustaining stable performance after multi-week online training. This work demonstrates that LLM-generated synthetic search signals, when aligned and continually updated, unlock timely trend understanding in low-traffic search environments.

</details>


### [348] [Human-Aligned Enhancement of Programming Answers with LLMs Guided by User Feedback](https://arxiv.org/abs/2601.17604)
*Suborno Deb Bappon,Saikat Mondal,Chanchal K. Roy,Kevin Schneider*

Main category: cs.SE

Relevance: 85.0

TL;DR: 本文提出了AUTOCOMBAT工具，利用LLMs根据Stack Overflow评论反馈自动改进编程答案，并通过ReSOlve基准和用户研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: Stack Overflow等技术问答平台中，约三分之一的用户反馈未被处理，导致答案不完整或过时。研究探索LLMs能否通过解读评论反馈来改进编程答案，提高技术知识平台的可靠性和可信度。

Method: 1) 构建ReSOlve基准，包含790个SO答案及相关评论线程；2) 评估四种先进LLMs识别可操作问题的能力；3) 开发AUTOCOMBAT工具，结合用户评论和问题上下文改进编程答案；4) 进行58名从业者的用户研究。

Result: DeepSeek在识别可操作问题方面表现最佳；AUTOCOMBAT生成的改进接近人工质量，同时保持原始意图，显著优于基线；84.5%的用户表示会采用或推荐该工具。

Conclusion: AUTOCOMBAT展示了基于反馈的答案精炼在提高技术知识平台可靠性和可信度方面的潜力，为LLMs在软件工程支持任务中的应用提供了新方向。

Abstract: Large Language Models (LLMs) are widely used to support software developers in tasks such as code generation, optimization, and documentation. However, their ability to improve existing programming answers in a human-like manner remains underexplored. On technical question-and-answer platforms such as Stack Overflow (SO), contributors often revise answers based on user comments that identify errors, inefficiencies, or missing explanations. Yet roughly one-third of this feedback is never addressed due to limited time, expertise, or visibility, leaving many answers incomplete or outdated. This study investigates whether LLMs can enhance programming answers by interpreting and incorporating comment-based feedback. We make four main contributions. First, we introduce ReSOlve, a benchmark consisting of 790 SO answers with associated comment threads, annotated for improvement-related and general feedback. Second, we evaluate four state-of-the-art LLMs on their ability to identify actionable concerns, finding that DeepSeek achieves the best balance between precision and recall. Third, we present AUTOCOMBAT, an LLM-powered tool that improves programming answers by jointly leveraging user comments and question context. Compared to human revised references, AUTOCOMBAT produces near-human quality improvements while preserving the original intent and significantly outperforming the baseline. Finally, a user study with 58 practitioners shows strong practical value, with 84.5 percent indicating they would adopt or recommend the tool. Overall, AUTOCOMBAT demonstrates the potential of scalable, feedback-driven answer refinement to improve the reliability and trustworthiness of technical knowledge platforms.

</details>


### [349] [A Model-Driven Lossless Compression Algorithm Resistant to Mismatch](https://arxiv.org/abs/2601.17684)
*Cordelia Hu,Jennifer Tang*

Main category: cs.IT

Relevance: 85.0

TL;DR: 提出一种基于下一符号预测的新型压缩算法，能够容忍结构化预测不匹配，在认证的不匹配范围内实现可靠压缩，压缩比超过常用压缩方法


<details>
  <summary>Details</summary>
Motivation: 现代预测模型（如LLMs）与熵编码结合可以实现超越标准压缩算法的压缩率，但这种方法依赖于编码器和解码器产生相同输出分布的假设。然而，复杂预测模型（特别是基于神经网络的模型）经常出现不匹配现象（称为非确定性），导致解码失败。

Method: 提出一种基于下一符号预测的新型压缩算法，该算法对任意大但结构化的预测不匹配具有鲁棒性。通过形式化不匹配认证证明方案的正确性，并分析其理论性能。

Result: 在真实数据集上的实验验证表明，该算法在认证的不匹配范围内能够可靠运行，同时实现超过常用压缩方法的压缩比。

Conclusion: 该研究提出了一种鲁棒的基于预测的压缩方案，解决了预测模型在编码器和解码器之间不匹配的关键问题，为将大型语言模型等复杂预测模型应用于实际压缩场景提供了可行方案。

Abstract: Due to the fundamental connection between next-symbol prediction and compression, modern predictive models, such as large language models (LLMs), can be combined with entropy coding to achieve compression rates that surpass those of standard compression algorithms. However, this approach relies on the assumption that the predictive model produces identical output distributions at both the encoder and decoder, since even small mismatches can cause the decoding to fail. This assumption often fails with complex predictive models, particularly those based on neural networks, a phenomenon referred to as non-determinism.
  In this work, we propose a new compression algorithm based on next-token prediction that is robust to arbitrarily large, but structured, prediction mismatches. We prove the correctness of the proposed scheme under a formal mismatch certification, characterize its theoretical performance, and validate it experimentally on real datasets. Our results demonstrate reliable operation within the certified mismatch regime while achieving compression ratios that exceed those of commonly used compression methods.

</details>


### [350] [MalURLBench: A Benchmark Evaluating Agents' Vulnerabilities When Processing Web URLs](https://arxiv.org/abs/2601.18113)
*Dezhang Kong,Zhuxi Wu,Shiqi Liu,Zhicheng Tan,Kuichen Lu,Minghao Li,Qichen Liu,Shengyu Chu,Zhenhua Xu,Xuan Liu,Meng Han*

Main category: cs.CR

Relevance: 85.0

TL;DR: 提出了首个针对LLM网络代理恶意URL漏洞的基准测试MalURLBench，包含61,845个攻击实例，涵盖10个真实场景和7类恶意网站，发现现有模型难以检测精心伪装的恶意URL，并提出了轻量级防御模块URLGuard。


<details>
  <summary>Details</summary>
Motivation: LLM网络代理在日常工作和生活中越来越普及，但在处理恶意URL时存在严重漏洞：一旦接受伪装的恶意URL，后续访问不安全网页会对服务提供商和用户造成严重损害。目前缺乏针对这一新兴威胁的基准测试。

Method: 构建了MalURLBench基准测试，包含61,845个攻击实例，涵盖10个真实场景和7类真实恶意网站。对12个流行LLM进行实验评估，分析影响攻击成功率的关键因素，并提出了轻量级防御模块URLGuard。

Result: 实验发现现有LLM难以检测精心伪装的恶意URL，识别了影响攻击成功率的关键因素，提出的URLGuard防御模块能有效提升安全性。

Conclusion: MalURLBench为推进网络代理安全提供了基础资源，揭示了LLM在处理恶意URL时的严重漏洞，提出的防御方案有助于提升LLM网络代理的安全性。

Abstract: LLM-based web agents have become increasingly popular for their utility in daily life and work. However, they exhibit critical vulnerabilities when processing malicious URLs: accepting a disguised malicious URL enables subsequent access to unsafe webpages, which can cause severe damage to service providers and users. Despite this risk, no benchmark currently targets this emerging threat. To address this gap, we propose MalURLBench, the first benchmark for evaluating LLMs' vulnerabilities to malicious URLs. MalURLBench contains 61,845 attack instances spanning 10 real-world scenarios and 7 categories of real malicious websites. Experiments with 12 popular LLMs reveal that existing models struggle to detect elaborately disguised malicious URLs. We further identify and analyze key factors that impact attack success rates and propose URLGuard, a lightweight defense module. We believe this work will provide a foundational resource for advancing the security of web agents. Our code is available at https://github.com/JiangYingEr/MalURLBench.

</details>


### [351] [daVinci-Dev: Agent-native Mid-training for Software Engineering](https://arxiv.org/abs/2601.18418)
*Ji Zeng,Dayuan Fu,Tiantian Mi,Yumin Zhuang,Yaxing Huang,Xuefeng Li,Lyumanshan Ye,Muhang Xie,Qishuo Hua,Zhen Huang,Mohan Jiang,Hanning Wang,Jifan Lin,Yang Xiao,Jie Sun,Yunze Wu,Pengfei Liu*

Main category: cs.SE

Relevance: 85.0

TL;DR: 该论文提出了"agentic mid-training"方法，通过合成两种类型的agent-native数据（上下文原生轨迹和环境原生轨迹）来训练代码代理，在SWE-Bench Verified上取得了56.1%-58.5%的解决率，使用更少的训练token超越了之前的Kimi-Dev方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM能力前沿已从单轮代码生成转向代理式软件工程，但代理式中期训练（在模拟真实代理工作流程的大规模数据上进行训练）因资源需求大而未被充分探索。主要挑战是静态训练数据与动态、反馈丰富的真实开发环境之间的分布不匹配。

Method: 提出了代理式中期训练的系统研究，建立了数据合成原则和训练方法。核心是agent-native数据监督，包含两种互补的轨迹类型：1) 上下文原生轨迹：保留代理体验的完整信息流，提供广泛覆盖和多样性；2) 环境原生轨迹：从可执行仓库收集，观察来自实际工具调用和测试执行，提供深度和交互真实性。

Result: 在SWE-Bench Verified上验证代理能力，使用不到一半的中期训练token（73.1B）超越了之前的Kimi-Dev方法。32B和72B模型分别达到56.1%和58.5%的解决率。

Conclusion: 代理式中期训练通过合成agent-native数据可以有效解决静态训练数据与动态开发环境之间的分布不匹配问题，为大规模代理开发提供了可扩展的路径，相比仅依赖昂贵的强化学习方法更具优势。

Abstract: Recently, the frontier of Large Language Model (LLM) capabilities has shifted from single-turn code generation to agentic software engineering-a paradigm where models autonomously navigate, edit, and test complex repositories. While post-training methods have become the de facto approach for code agents, **agentic mid-training**-mid-training (MT) on large-scale data that mirrors authentic agentic workflows-remains critically underexplored due to substantial resource requirements, despite offering a more scalable path to instilling foundational agentic behaviors than relying solely on expensive reinforcement learning. A central challenge in realizing effective agentic mid-training is the distribution mismatch between static training data and the dynamic, feedback-rich environment of real development. To address this, we present a systematic study of agentic mid-training, establishing both the data synthesis principles and training methodology for effective agent development at scale. Central to our approach is **agent-native data**-supervision comprising two complementary types of trajectories: **contextually-native trajectories** that preserve the complete information flow an agent experiences, offering broad coverage and diversity; and **environmentally-native trajectories** collected from executable repositories where observations stem from actual tool invocations and test executions, providing depth and interaction authenticity. We verify the model's agentic capabilities on `SWE-Bench Verified`. We demonstrate our superiority over the previous open software engineering mid-training recipe `Kimi-Dev` under two post-training settings with an aligned base model and agentic scaffold, while using less than half mid-training tokens (73.1B). Besides relative advantage, our best performing 32B and 72B models achieve **56.1%** and **58.5%** resolution rates, respectively, which are ...

</details>


### [352] [$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks](https://arxiv.org/abs/2601.18754)
*Mohamed Amine Ferrag,Abderrahmane Lakas,Merouane Debbah*

Main category: cs.CR

Relevance: 85.0

TL;DR: α³-SecBench是首个针对LLM驱动无人机代理在对抗环境下安全自主性的大规模评估套件，涵盖7个自主层、20,000个攻击场景，评估23个主流LLM在安全、韧性和信任三个维度的表现


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的无人机系统在安全关键网络环境中面临恶意攻击威胁，现有基准主要评估推理、导航和效率，缺乏对安全、韧性和信任的系统性评估，特别是在6G新兴环境中

Method: 基于α³-Bench的多轮对话无人机任务，构建包含20,000个验证安全覆盖攻击场景的评估框架，针对感知、规划、控制、通信、边缘/云基础设施和LLM推理等7个自主层，从安全（攻击检测和漏洞归因）、韧性（安全降级行为）和信任（策略合规工具使用）三个正交维度评估

Result: 评估23个主流LLM在113,475个任务、175种威胁类型中的表现：许多模型能可靠检测异常行为，但有效缓解、漏洞归因和可信控制行动仍不一致；总体标准化得分在12.9%到57.1%之间，显示异常检测与安全感知自主决策之间存在显著差距

Conclusion: LLM驱动的无人机代理在对抗条件下的安全自主性仍存在重大挑战，需要更强大的安全感知决策能力；α³-SecBench为评估和改进LLM在安全关键应用中的表现提供了重要基准

Abstract: Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings.
  We introduce $α^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $α^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $α^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage).
  We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $α^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench

</details>


### [353] [Implementing Tensor Logic: Unifying Datalog and Neural Reasoning via Tensor Contraction](https://arxiv.org/abs/2601.17188)
*Swapn Shah,Wlodek Zadrozny*

Main category: cs.AI

Relevance: 75.0

TL;DR: Tensor Logic框架通过张量运算统一符号推理与神经网络，在圣经家谱图、嵌入空间推理和知识图谱上验证了逻辑规则与爱因斯坦求和的数学等价性。


<details>
  <summary>Details</summary>
Motivation: 符号系统与神经网络各有优劣：符号系统可靠可解释但缺乏可扩展性，神经网络有学习能力但缺乏透明度。Tensor Logic提出逻辑规则与爱因斯坦求和在数学上等价，为两者的统一提供了理论路径。

Method: 通过三个实验验证Tensor Logic框架：1) 在圣经家谱图上展示递归Datalog规则与迭代张量收缩的等价性；2) 在嵌入空间中训练带可学习变换矩阵的神经网络进行零样本组合推理；3) 在FB15k-237知识图谱上验证关系矩阵公式R_r = E^T A_r E，测试链接预测和组合推理能力。

Result: 1) 圣经家谱图：74次迭代发现33,945个祖先关系；2) 嵌入空间推理：成功实现零样本组合推理；3) FB15k-237：标准链接预测MRR为0.3068，组合推理基准MRR为0.3346，表明矩阵组合支持多跳推理而无需直接训练样本。

Conclusion: Tensor Logic框架为符号推理与神经网络的统一提供了实证支持，展示了逻辑规则与张量运算的数学等价性，为实现可扩展、可解释的AI系统提供了有前景的路径。

Abstract: The unification of symbolic reasoning and neural networks remains a central challenge in artificial intelligence. Symbolic systems offer reliability and interpretability but lack scalability, while neural networks provide learning capabilities but sacrifice transparency. Tensor Logic, proposed by Domingos, suggests that logical rules and Einstein summation are mathematically equivalent, offering a principled path toward unification. This paper provides empirical validation of this framework through three experiments. First, we demonstrate the equivalence between recursive Datalog rules and iterative tensor contractions by computing the transitive closure of a biblical genealogy graph containing 1,972 individuals and 1,727 parent-child relationships, converging in 74 iterations to discover 33,945 ancestor relationships. Second, we implement reasoning in embedding space by training a neural network with learnable transformation matrices, demonstrating successful zero-shot compositional inference on held-out queries. Third, we validate the Tensor Logic superposition construction on FB15k-237, a large-scale knowledge graph with 14,541 entities and 237 relations. Using Domingos's relation matrix formulation $R_r = E^\top A_r E$, we achieve MRR of 0.3068 on standard link prediction and MRR of 0.3346 on a compositional reasoning benchmark where direct edges are removed during training, demonstrating that matrix composition enables multi-hop inference without direct training examples.

</details>


### [354] [Multi-Agent Learning Path Planning via LLMs](https://arxiv.org/abs/2601.17346)
*Haoxin Xu,Changyong Qi,Tong Liu,Bohao Zhang,Anna He,Bingqian Jiang,Longwei Zheng,Xiaoqing Gu*

Main category: cs.AI

Relevance: 75.0

TL;DR: 提出基于多智能体协作的MALPP框架，利用LLM驱动的智能体进行个性化学习路径规划，通过角色和规则机制确保透明性、适应性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有学习路径规划方法缺乏透明性、适应性和学习者中心的可解释性，需要将LLM融入智能教学系统以实现个性化高等教育学习。

Method: 提出多智能体学习路径规划框架，包含三个任务特定智能体：学习者分析智能体、路径规划智能体和反思智能体，通过结构化提示和预定义规则协作，基于认知负荷理论和最近发展区理论确保认知对齐。

Result: 在MOOCCubeX数据集上使用7个LLM的实验表明，MALPP在路径质量、知识序列一致性和认知负荷对齐方面显著优于基线模型，消融研究验证了协作机制和理论约束的有效性。

Conclusion: 该研究为教育领域可信、可解释AI的发展做出贡献，展示了基于LLM的可扩展学习者中心自适应教学方法。

Abstract: The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.

</details>


### [355] [Auditing Disability Representation in Vision-Language Models](https://arxiv.org/abs/2601.17348)
*Srikant Panda,Sourabh Singh Yadav,Palkesh Malviya*

Main category: cs.AI

Relevance: 75.0

TL;DR: 该论文研究了视觉语言模型在描述残疾人图像时的解释偏移问题，发现引入残疾上下文会降低解释保真度，导致推测性推断、叙事扩展、情感降级和缺陷导向框架等偏差，这些效应在种族和性别维度上进一步放大。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型越来越多地应用于社会敏感领域，但它们在残疾相关方面的行为尚未得到充分探索。现有模型在描述人物中心图像时，经常从基于证据的事实描述转向包含超出可观察视觉证据的未支持推断的解释偏移，这可能导致对残疾人的偏见和刻板印象。

Method: 研究引入基于中性提示(NP)和残疾上下文提示(DP)的基准测试，在零样本设置下评估15个最先进的开源和闭源视觉语言模型，涵盖9个残疾类别。评估框架以解释保真度为核心目标，结合标准文本指标（捕捉情感降级、社会关注和响应长度变化）和经过残疾生活经验标注者验证的LLM-as-judge协议。

Result: 研究发现引入残疾上下文会一致性地降低解释保真度，诱导解释偏移，表现为推测性推断、叙事扩展、情感降级和缺陷导向框架。这些效应在种族和性别维度上进一步放大。同时证明针对性提示和偏好微调能有效提高解释保真度并显著减少解释偏移。

Conclusion: 视觉语言模型在残疾相关描述中存在系统性偏差，需要更严格的评估和缓解策略。针对性提示和偏好微调是减少这些偏差的有效方法，但需要更全面的框架来确保模型在社会敏感应用中的公平性和准确性。

Abstract: Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.

</details>


### [356] [JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research](https://arxiv.org/abs/2601.17564)
*Aadam,Monu Verma,Mohamed Abdel-Mottaleb*

Main category: cs.AI

Relevance: 75.0

TL;DR: JaxARC是一个基于JAX的高性能强化学习环境，专门用于Abstraction and Reasoning Corpus（ARC）基准测试，相比Gymnasium实现实现了38-5,439倍的加速，支持大规模并行实验。


<details>
  <summary>Details</summary>
Motivation: 现有基于Gymnasium的ARC RL环境存在计算瓶颈，严重限制了实验规模。ARC测试AI系统从少量示例对中进行类似人类的归纳推理能力，但现有环境无法支持大规模RL研究。

Method: 采用JAX实现，具有函数式、无状态架构，支持大规模并行。支持多个ARC数据集、灵活的动作空间、可组合的包装器和配置驱动的可重复性。

Result: 在匹配的批量大小下，相比Gymnasium实现了38-5,439倍的加速，峰值吞吐量达到7.9亿步/秒。使得之前计算不可行的大规模RL研究成为可能。

Conclusion: JaxARC为ARC基准测试提供了一个高性能、可扩展的RL环境，解决了现有环境的计算瓶颈问题，为大规模归纳推理研究提供了基础设施。

Abstract: The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.

</details>


### [357] [MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing](https://arxiv.org/abs/2601.17814)
*Haoxuan Ma,Guannan Lai,Han-Jia Ye*

Main category: cs.AI

Relevance: 75.0

TL;DR: MMR-Bench是一个多模态路由基准测试，用于在固定候选模型和计算成本下评估多模态大语言模型的选择策略，旨在通过智能路由在保持准确性的同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）存在架构、对齐策略和效率的异质性，没有单一模型在所有任务上表现最优。实际部署中，工作负载从轻量级OCR到复杂多模态推理不等，使用单一模型要么在简单任务上过度计算，要么在困难任务上牺牲准确性。需要一种查询级别的模型选择（路由）方法来解决这一矛盾。

Method: 提出了MMR-Bench基准测试，提供：1）具有模态感知输入和可变计算预算的受控环境；2）涵盖OCR、通用VQA和多模态数学推理的广泛视觉语言任务套件；3）强大的单模型参考、理论上限和代表性路由策略。通过该基准测试，展示了融入多模态信号可以提升路由质量。

Result: 实验表明，多模态线索改善了成本-准确性边界，使路由系统能够以最强单模型约33%的成本超越其准确性。此外，在部分模型和任务上训练的策略能够零样本泛化到新数据集和纯文本基准测试，无需重新调整。

Conclusion: MMR-Bench为研究自适应多模态模型选择和高效MLLM部署提供了基础，展示了智能路由在多模态场景中的潜力和泛化能力。

Abstract: Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.

</details>


### [358] [LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting](https://arxiv.org/abs/2601.17942)
*Yu-Jie Yang,Hung-Fu Chang,Po-An Chen*

Main category: cs.AI

Relevance: 75.0

TL;DR: 提出SSEV（单智能体自精炼集成投票）管道和ReCAPAgent-SQL框架，用于无监督Text-to-SQL任务，通过自精炼和集成投票提升SQL生成准确性，并在企业级复杂场景中实现多智能体协作迭代优化。


<details>
  <summary>Details</summary>
Motivation: Text-to-SQL技术能降低数据分析门槛，但自然语言到SQL的转换面临查询歧义、模式链接复杂、SQL方言泛化有限、领域知识需求等挑战。现有方法在无监督和企业级复杂场景中表现不足。

Method: 1. SSEV管道：基于PET-SQL构建，集成自精炼与加权多数投票（WMV）及其随机变体（RWMA），无需真实标注数据。2. ReCAPAgent-SQL框架：多智能体协作框架，包含规划、外部知识检索、批判、动作生成、自精炼、模式链接、结果验证等专门智能体，通过迭代精炼优化SQL预测。

Result: SSEV在多个基准测试中取得竞争性表现：Spider 1.0-Dev执行准确率85.5%，Spider 1.0-Test 86.4%，BIRD-Dev 66.3%。ReCAPAgent-SQL在Spider 2.0-Lite前100个查询中达到31%执行准确率，显著提升企业级场景处理能力。

Conclusion: 提出的SSEV管道和ReCAPAgent-SQL框架有效解决了无监督和企业级复杂Text-to-SQL任务，支持可扩展的Text-to-SQL系统在实际部署，以更低成本和更高效率促进数据驱动决策。

Abstract: Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.

</details>


### [359] [Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?](https://arxiv.org/abs/2601.18119)
*Jing Ye,Yiwen Duan,Yonghong Yu,Victor Ma,Yang Gao,Xing Chen*

Main category: cs.AI

Relevance: 75.0

TL;DR: OurBench是首个企业级SQL推理与调试基准，包含469个语法错误查询和516个语义错误查询，平均超过140行代码。评估近30个LLM发现性能差距巨大，最佳模型Claude-4-Sonnet准确率仅36.46%和32.17%。


<details>
  <summary>Details</summary>
Motivation: SQL在企业数据工程中至关重要，但即使是经验丰富的开发者和先进的文本到SQL LLM也难以一次性生成完全正确的SQL代码，通常需要多次调试迭代。目前缺乏专门针对企业级SQL调试的基准测试。

Method: 1) 自动化构建工作流：使用逆向工程在大规模SQL代码中系统注入真实错误，实现可扩展和多样化的基准生成；2) 无执行评估框架：针对企业环境定制，提供快速、准确且资源高效的评估。包含OurBenchSyn（语法错误）和OurBenchSem（语义错误）两类查询。

Result: 评估近30个LLM显示显著性能差距：最佳模型Claude-4-Sonnet在OurBenchSyn上仅36.46%准确率，在OurBenchSem上32.17%准确率，大多数模型低于20%。查询复杂度高，平均超过140行代码，具有深且宽的抽象语法树。

Conclusion: 企业级SQL调试对当前LLM仍是重大挑战。论文探索了四种解决方案策略，识别了关键挑战，并为企业环境中LLM的SQL调试指明了有前景的研究方向。

Abstract: SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.
  OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.
  Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.

</details>


### [360] [DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints](https://arxiv.org/abs/2601.18137)
*Yinger Zhang,Shutong Jiang,Renhao Li,Jianhong Tu,Yang Su,Lianghao Deng,Xudong Guo,Chenxu Lv,Junyang Lin*

Main category: cs.AI

Relevance: 75.0

TL;DR: DeepPlanning是一个针对实际长视野智能体规划的挑战性基准测试，包含多日旅行规划和多产品购物任务，要求主动信息获取、局部约束推理和全局约束优化。


<details>
  <summary>Details</summary>
Motivation: 当前智能体评估转向长视野任务，但大多数基准测试仍强调局部、步骤级推理，而非需要真正规划能力的全局约束优化（如时间和财务预算）。现有LLM规划基准测试未能充分体现现实世界场景中典型的主动信息收集和细粒度局部约束。

Method: 引入DeepPlanning基准测试，包含多日旅行规划和多产品购物任务，这些任务需要：1）主动信息获取，2）局部约束推理，3）全局约束优化。基准测试旨在评估智能体在实际长视野规划中的能力。

Result: 评估显示，即使是前沿的智能体LLM在这些问题上也表现困难，突显了可靠显式推理模式和并行工具使用对于实现更好的效果-效率权衡的重要性。错误分析指出了改进长规划视野智能体LLM的有希望方向。

Conclusion: DeepPlanning基准测试填补了现有LLM规划评估的空白，强调了实际长视野规划中主动信息获取和约束优化的重要性。代码和数据已开源以支持未来研究。

Abstract: While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.

</details>


### [361] [Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success](https://arxiv.org/abs/2601.18175)
*Daniel Russo*

Main category: cs.AI

Relevance: 75.0

TL;DR: 成功条件化（success conditioning）是一种通过模仿成功轨迹来改进策略的技术，本文证明它精确地解决了一个信任域优化问题，在χ²散度约束下最大化策略改进，约束半径由数据自动确定。


<details>
  <summary>Details</summary>
Motivation: 成功条件化技术（如拒绝采样+SFT、目标条件RL、决策变换器）被广泛用于改进策略，但其背后的优化问题本质一直不清楚。本文旨在从理论上阐明成功条件化究竟解决了什么优化问题。

Method: 通过理论分析证明成功条件化精确地解决了一个信任域优化问题，建立了相对策略改进、策略变化幅度和动作影响之间的恒等关系。将理论应用于常见的回报阈值化实践。

Result: 证明成功条件化是保守的改进算子，不会降低性能或引发危险的分布偏移。当失败时会明显表现为策略几乎不变。回报阈值化可以放大改进，但可能偏离真实目标。

Conclusion: 成功条件化具有坚实的理论基础，解决了特定的信任域优化问题。它为理解各种基于成功轨迹模仿的技术提供了统一的理论框架，并揭示了其保守改进的特性。

Abstract: A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.

</details>


### [362] [GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models](https://arxiv.org/abs/2601.18197)
*Shaokang Wang,Pei Fu,Ruoceng Zhang,Shaojie Zhang,Xiuwen Xi,Jiahui Yang,Bin Qin,Ying Huang,Zhenbo Luo,Jian Luan*

Main category: cs.AI

Relevance: 75.0

TL;DR: GAIA框架通过训练直觉批评模型(ICM)来提升GUI代理的测试时性能，该系统利用数据飞轮机制让模型具备迭代批评能力，从而减少单次错误操作导致的灾难性偏差。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型(LVLMs)虽然提升了GUI代理在解析指令、理解屏幕内容和执行任务方面的能力，但存在操作不可逆性的关键挑战：单个错误操作可能导致灾难性偏差。需要一种方法来增强代理的自我纠正能力。

Method: 提出GUI Action Critic's Data Flywheel System (GAIA)训练框架：1) 使用基础代理的正负动作样本训练直觉批评模型(ICM)；2) 批评模型评估代理意图动作的即时正确性，选择高成功率操作；3) 初始批评模型指导代理收集精炼的正负样本，启动自我改进循环；4) 增强数据训练第二轮批评模型，提升辨别能力。

Result: 实验表明，提出的ICM可以提升各种闭源和开源模型的测试时性能，随着数据循环使用，性能可以逐步提高。代码和数据集将公开发布。

Conclusion: GAIA框架通过数据飞轮机制实现了GUI代理的自我改进能力，解决了操作不可逆性问题，提升了代理的可靠性和性能。

Abstract: While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released.

</details>


### [363] [SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback](https://arxiv.org/abs/2601.18202)
*Fangyuan Xu,Rujun Han,Yanfei Chen,Zifeng Wang,I-Hung Hsu,Jun Yan,Vishy Tirumalashetty,Eunsol Choi,Tomas Pfister,Chen-Yu Lee*

Main category: cs.AI

Relevance: 75.0

TL;DR: SAGE：一个自动生成高质量、难度可控的深度搜索问答对的智能体管道，用于训练深度搜索代理


<details>
  <summary>Details</summary>
Motivation: 深度搜索代理需要跨多个文档进行复杂推理，但人工标注成本过高，因为探索轨迹长且复杂。需要自动生成高质量训练数据的方法。

Method: 提出SAGE管道，包含数据生成器和搜索代理两个组件。数据生成器提出QA对，搜索代理尝试解决问题并提供执行反馈，两者通过多轮交互迭代优化QA对，直到达到目标难度水平。

Result: 内在评估显示SAGE生成的问题需要多样化的推理策略，同时显著提高生成数据的正确性和难度。外在评估显示在流行深度搜索基准上相对性能提升达23%。训练后的代理能够从固定语料库检索适应到Google搜索，无需额外训练。

Conclusion: SAGE能够自动生成高质量、难度可控的深度搜索训练数据，显著提升深度搜索代理性能，并展示良好的泛化能力。

Abstract: Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.

</details>


### [364] [Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation](https://arxiv.org/abs/2601.18630)
*Abeer Badawi,Md Tahmid Rahman Laskar,Elahe Rahimi,Sheri Grach,Lindsay Bertrand,Lames Danok,Frank Rudzicz,Jimmy Huang,Elham Dolatabadi*

Main category: cs.AI

Relevance: 75.0

TL;DR: 本文提出了一种基于人类评估的方法，用于评估LLM在心理健康对话中的响应质量，发现LLM在认知支持方面表现可靠，但在情感共鸣方面存在不稳定，揭示了认知-情感差距。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康危机日益严重，存在治疗缺口和合格治疗师短缺的问题。LLM作为可扩展的心理支持工具具有潜力，但其可靠性、治疗相关性和与人类标准的对齐仍面临挑战。需要建立评估LLM在心理健康对话中响应质量的方法。

Method: 1. 构建包含500个真实世界心理健康对话的数据集
2. 使用9个不同的LLM（包括闭源和开源模型）生成响应
3. 由两位经过精神病学培训的专家独立评估每个响应
4. 使用5点李克特量表，基于包含6个属性的综合评估框架
5. 评估框架涵盖认知支持和情感共鸣两个维度

Result: 1. LLM在认知可靠性方面表现强劲：能产生安全、连贯且临床适当的信息
2. 情感对齐方面表现不稳定：存在认知-情感差距
3. 闭源模型（如GPT-4o）提供更平衡的治疗响应
4. 开源模型表现出更大的变异性和情感平淡性
5. 需要关注失败意识和临床基础的评估框架

Conclusion: 需要建立平衡的评估协议，强调治疗敏感性，并采用人在环中的方法。应优先考虑关系敏感性而不仅仅是信息准确性，为心理健康导向的对话AI提供负责任的临床监督框架。

Abstract: The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.

</details>


### [365] [Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems](https://arxiv.org/abs/2601.18735)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Jing Yang,Jiawei Yao,Jian Wang,Guanlong Qu,Ziliang Chen,Keze Wang*

Main category: cs.AI

Relevance: 75.0

TL;DR: Agora框架将多智能体协调重构为不确定性市场，通过将认知不确定性转化为可交易资产，实现基于经济理性的成本高效协作，在多个多模态基准上显著提升性能并大幅降低成本。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型(VLMs)多智能体系统存在经济不可持续问题：异构智能体在信息不对称下的协调成本高昂。现有方法依赖启发式代理，忽略成本且破坏不确定性结构，导致次优协调。

Method: Agora将协调重构为去中心化不确定性市场，将认知不确定性形式化为结构化可交易资产（感知、语义、推理），基于理性经济规则强制智能体进行盈利驱动交易。市场感知代理（扩展Thompson Sampling）发起协作并引导系统达到成本高效均衡。

Result: 在五个多模态基准（MMMU、MMBench、MathVision、InfoVQA、CC-OCR）上，Agora优于强VLMs和启发式多智能体策略，如在MMMU上比最佳基线提升8.5%准确率，同时降低成本超过3倍。

Conclusion: 基于市场的协调为构建经济可行的多智能体视觉智能系统提供了原则性和可扩展的范式。

Abstract: Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.

</details>


### [366] [BibAgent: An Agentic Framework for Traceable Miscitation Detection in Scientific Literature](https://arxiv.org/abs/2601.16993)
*Peiran Li,Fangzhou Lin,Shuo Xing,Xiang Zheng,Xi Hong,Jiashuo Sun,Zhengzhong Tu,Chaoqun Ni*

Main category: cs.DL

Relevance: 75.0

TL;DR: BibAgent是一个用于自动引文验证的智能代理框架，通过检索、推理和自适应证据聚合来检测科学文献中的错误引用，特别针对付费墙文献设计了证据委员会机制，并在大规模跨学科基准测试中超越了现有LLM基线。


<details>
  <summary>Details</summary>
Motivation: 科学引文的完整性受到广泛错误引用的威胁，包括细微扭曲和捏造参考文献。目前系统性的引文验证不可行：人工审查无法扩展到现代出版规模，而现有自动化工具受限于仅分析摘要或小规模领域特定数据集，部分原因是全文访问的"付费墙障碍"。

Method: BibAgent是一个可扩展的端到端智能代理框架，集成了检索、推理和自适应证据聚合，对可访问和付费墙来源采用不同策略。对于付费墙参考文献，它利用新颖的证据委员会机制，通过下游引文共识推断引文有效性。还贡献了5类错误引用分类法和MisciteBench基准。

Result: BibAgent在引文验证准确性和可解释性方面优于最先进的大型语言模型基线，能够提供跨科学文献的可扩展、透明检测。MisciteBench包含6,350个错误引用样本，涵盖254个领域。

Conclusion: BibAgent为解决科学引文完整性问题提供了一个有效的自动化解决方案，通过创新的代理框架和证据委员会机制，能够大规模检测引文偏差，为科学文献的可信度提供保障。

Abstract: Citations are the bedrock of scientific authority, yet their integrity is compromised by widespread miscitations: ranging from nuanced distortions to fabricated references. Systematic citation verification is currently unfeasible; manual review cannot scale to modern publishing volumes, while existing automated tools are restricted by abstract-only analysis or small-scale, domain-specific datasets in part due to the "paywall barrier" of full-text access. We introduce BibAgent, a scalable, end-to-end agentic framework for automated citation verification. BibAgent integrates retrieval, reasoning, and adaptive evidence aggregation, applying distinct strategies for accessible and paywalled sources. For paywalled references, it leverages a novel Evidence Committee mechanism that infers citation validity via downstream citation consensus. To support systematic evaluation, we contribute a 5-category Miscitation Taxonomy and MisciteBench, a massive cross-disciplinary benchmark comprising 6,350 miscitation samples spanning 254 fields. Our results demonstrate that BibAgent outperforms state-of-the-art Large Language Model (LLM) baselines in citation verification accuracy and interpretability, providing scalable, transparent detection of citation misalignments across the scientific literature.

</details>


### [367] [Measuring Political Stance and Consistency in Large Language Models](https://arxiv.org/abs/2601.17016)
*Salah Feras Alali,Mohammad Nashat Maasfeh,Mucahid Kutlu,Saban Kardas*

Main category: cs.CY

Relevance: 75.0

TL;DR: 研究发现不同LLM在24个政治敏感议题上立场存在差异，有些立场可通过提示词改变，有些则稳定不变。模型倾向于支持提示词所用语言对应的国家立场，某些议题如卡塔尔封锁和巴勒斯坦压迫问题立场无法通过提示词改变。


<details>
  <summary>Details</summary>
Motivation: 随着LLM被广泛用于满足信息需求，但在政治议题上可能存在训练数据偏见或对齐选择问题。研究旨在评估LLM在政治敏感议题上的立场表现，以揭示潜在偏见和可塑性。

Method: 使用5种提示技术评估9个LLM在24个政治敏感议题上的立场。分析模型立场的稳定性、可塑性以及语言对立场的影响。

Result: 1) 不同模型在多个议题上持对立立场；2) 部分立场可通过提示词改变，部分稳定不变；3) Grok-3-mini最稳定，Mistral-7B最不稳定；4) 模型倾向于支持提示词所用语言对应的国家立场；5) 卡塔尔封锁和巴勒斯坦压迫问题立场无法通过提示词改变。

Conclusion: LLM在政治议题上存在偏见和立场差异，用户应谨慎依赖LLM获取政治指导，开发者需要解决这些问题以提高模型的公正性和可靠性。

Abstract: With the incredible advancements in Large Language Models (LLMs), many people have started using them to satisfy their information needs. However, utilizing LLMs might be problematic for political issues where disagreement is common and model outputs may reflect training-data biases or deliberate alignment choices. To better characterize such behavior, we assess the stances of nine LLMs on 24 politically sensitive issues using five prompting techniques. We find that models often adopt opposing stances on several issues; some positions are malleable under prompting, while others remain stable. Among the models examined, Grok-3-mini is the most persistent, whereas Mistral-7B is the least. For issues involving countries with different languages, models tend to support the side whose language is used in the prompt. Notably, no prompting technique alters model stances on the Qatar blockade or the oppression of Palestinians. We hope these findings raise user awareness when seeking political guidance from LLMs and encourage developers to address these concerns.

</details>


### [368] [Status Hierarchies in Language Models](https://arxiv.org/abs/2601.17577)
*Emilio Barkett*

Main category: cs.HC

Relevance: 75.0

TL;DR: 语言模型在多智能体场景中会形成显著的社会地位等级，当能力相同时会出现35%的不对称性，但能力差异会主导地位线索，高地位分配反而会降低高能力模型的顺从度。


<details>
  <summary>Details</summary>
Motivation: 人类社会中普遍存在基于尊重和感知能力的社会地位等级，语言模型在人类文本训练中必然会遇到这些等级模式。研究探索语言模型在多智能体环境中是否会复制这种社会动态，这对AI安全有重要意义。

Method: 采用Berger等人的期望状态理论框架，创建多智能体场景：让独立的语言模型实例完成情感分类任务，引入不同的地位特征（如证书、专业知识），然后观察它们有机会在看到伙伴响应后修改初始判断。因变量是顺从度——模型基于地位线索而非任务信息向伙伴立场转变评分的比率。

Result: 语言模型在能力相等时会形成显著的地位等级（35个百分点的不对称性，p<.001），但能力差异会主导地位线索。最显著的效果是：高地位分配会降低高能力模型的顺从度，而不是增加低能力模型的顺从度。

Conclusion: 这项研究识别了AI系统中出现的社会行为，并突出了对齐挑战中一个先前未被充分探索的维度。地位寻求行为可能引入欺骗策略、放大歧视性偏见，并在分布式部署中比人类等级形成更快地扩展，对AI安全有重要意义。

Abstract: From school playgrounds to corporate boardrooms, status hierarchies -- rank orderings based on respect and perceived competence -- are universal features of human social organization. Language models trained on human-generated text inevitably encounter these hierarchical patterns embedded in language, raising the question of whether they might reproduce such dynamics in multi-agent settings. This thesis investigates when and how language models form status hierarchies by adapting Berger et al.'s (1972) expectation states framework. I create multi-agent scenarios where separate language model instances complete sentiment classification tasks, are introduced with varying status characteristics (e.g., credentials, expertise), then have opportunities to revise their initial judgments after observing their partner's responses. The dependent variable is deference, the rate at which models shift their ratings toward their partner's position based on status cues rather than task information. Results show that language models form significant status hierarchies when capability is equal (35 percentage point asymmetry, p < .001), but capability differences dominate status cues, with the most striking effect being that high-status assignments reduce higher-capability models' deference rather than increasing lower-capability models' deference. The implications for AI safety are significant: status-seeking behavior could introduce deceptive strategies, amplify discriminatory biases, and scale across distributed deployments far faster than human hierarchies form organically. This work identifies emergent social behaviors in AI systems and highlights a previously underexplored dimension of the alignment challenge.

</details>


### [369] [On the Insecurity of Keystroke-Based AI Authorship Detection: Timing-Forgery Attacks Against Motor-Signal Verification](https://arxiv.org/abs/2601.17280)
*David Condrey*

Main category: cs.CR

Relevance: 75.0

TL;DR: 基于击键时序变异系数的AI文本检测防御方案存在安全漏洞，可通过转录攻击和时序伪造攻击绕过，成功率≥99.8%


<details>
  <summary>Details</summary>
Motivation: 当前有研究提出使用击键时序信号（特别是击键间隔变异系数δ）来区分人类撰写文本和AI生成内容。本文旨在验证这类防御方案的安全性，并展示其在实际攻击下的脆弱性。

Method: 提出两类实际攻击：1) 转录攻击：人类转录LLM生成文本，产生真实的运动信号；2) 时序伪造攻击：自动化代理从经验人类分布中采样击键间隔。使用13,000个SBU语料库会话和三种时序伪造变体（直方图采样、统计模仿、生成式LSTM）进行实验。

Result: 所有攻击对五种分类器的规避率≥99.8%。虽然检测器对完全自动化注入的检测AUC=1.000，但对攻击样本的分类≥99.8%被判定为人类，平均置信度≥0.993。研究发现创作和转录产生统计可区分的运动模式（Cohen's d=1.28），但两者的δ值都超过检测阈值2-4倍。

Conclusion: 基于击键时序的检测系统只能确认人类操作了键盘，但不能证明文本是否由该人类原创。要确保来源可信，需要将写作过程与语义内容绑定的架构。

Abstract: Recent proposals advocate using keystroke timing signals, specifically the coefficient of variation ($δ$) of inter-keystroke intervals, to distinguish human-composed text from AI-generated content. We demonstrate that this class of defenses is insecure against two practical attack classes: the copy-type attack, in which a human transcribes LLM-generated text producing authentic motor signals, and timing-forgery attacks, in which automated agents sample inter-keystroke intervals from empirical human distributions. Using 13,000 sessions from the SBU corpus and three timing-forgery variants (histogram sampling, statistical impersonation, and generative LSTM), we show all attacks achieve $\ge$99.8% evasion rates against five classifiers. While detectors achieve AUC=1.000 against fully-automated injection, they classify $\ge$99.8% of attack samples as human with mean confidence $\ge$0.993. We formalize a non-identifiability result: when the detector observes only timing, the mutual information between features and content provenance is zero for copy-type attacks. Although composition and transcription produce statistically distinguishable motor patterns (Cohen's d=1.28), both yield $δ$ values 2-4x above detection thresholds, rendering the distinction security-irrelevant. These systems confirm a human operated the keyboard, but not whether that human originated the text. Securing provenance requires architectures that bind the writing process to semantic content.

</details>


### [370] [Res-MIA: A Training-Free Resolution-Based Membership Inference Attack on Federated Learning Models](https://arxiv.org/abs/2601.17378)
*Mohammad Zare,Pirooz Shamsinejadbabaki*

Main category: cs.CR

Relevance: 75.0

TL;DR: Res-MIA：一种无需训练的黑盒成员推理攻击方法，通过渐进降低输入分辨率并分析模型置信度衰减来检测训练数据成员，在联邦学习中实现高达0.88的AUC


<details>
  <summary>Details</summary>
Motivation: 尽管联邦学习被认为是隐私保护的训练范式，但研究表明最终全局模型仍可能通过黑盒访问泄露成员信息。现有成员推理攻击方法通常需要训练影子模型或大量辅助数据，计算成本高且不实用。本文旨在开发一种无需训练、计算开销小的黑盒成员推理攻击方法，探索模型对高频输入细节的敏感性作为隐私泄露的新来源。

Method: Res-MIA通过渐进降低输入分辨率（使用受控的下采样和恢复操作）来侵蚀输入的高频细节，然后分析模型预测置信度的衰减模式。关键洞察是：训练样本在分辨率侵蚀下表现出比非成员样本更陡峭的置信度下降，这揭示了稳健的成员信号。该方法无需影子模型、无需辅助数据，仅需有限的前向查询。

Result: 在联邦ResNet-18模型和CIFAR-10数据集上的评估显示，Res-MIA始终优于现有的无需训练基线方法，在最小计算开销下实现了高达0.88的AUC。这表明频率敏感的过拟合是联邦学习中一个重要且先前未被充分探索的隐私泄露来源。

Conclusion: Res-MIA揭示了深度模型对高频输入细节的敏感性是成员隐私泄露的重要来源。该方法在联邦学习环境中表现出色，强调了需要设计减少对细粒度、非稳健输入特征依赖的隐私感知模型架构。

Abstract: Membership inference attacks (MIAs) pose a serious threat to the privacy of machine learning models by allowing adversaries to determine whether a specific data sample was included in the training set. Although federated learning (FL) is widely regarded as a privacy-aware training paradigm due to its decentralized nature, recent evidence shows that the final global model can still leak sensitive membership information through black-box access. In this paper, we introduce Res-MIA, a novel training-free and black-box membership inference attack that exploits the sensitivity of deep models to high-frequency input details. Res-MIA progressively degrades the input resolution using controlled downsampling and restoration operations, and analyzes the resulting confidence decay in the model's predictions. Our key insight is that training samples exhibit a significantly steeper confidence decline under resolution erosion compared to non-member samples, revealing a robust membership signal. Res-MIA requires no shadow models, no auxiliary data, and only a limited number of forward queries to the target model. We evaluate the proposed attack on a federated ResNet-18 trained on CIFAR-10, where it consistently outperforms existing training-free baselines and achieves an AUC of up to 0.88 with minimal computational overhead. These findings highlight frequency-sensitive overfitting as an important and previously underexplored source of privacy leakage in federated learning, and emphasize the need for privacy-aware model designs that reduce reliance on fine-grained, non-robust input features.

</details>


### [371] [Prompt Driven Development with Claude Code: Building a Complete TUI Framework for the Ring Programming Language](https://arxiv.org/abs/2601.17584)
*Mahmoud Samir Fayed,Ahmed Samir Fayed*

Main category: cs.SE

Relevance: 75.0

TL;DR: 该研究通过实证分析展示了使用Claude Code Opus 4.5在10小时内通过107个提示开发7420行Ring语言终端用户界面框架的能力，证明了LLM能够维持架构一致性并构建生产级工具。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在软件开发中应用日益广泛，但其通过自然语言交互生成和维护大型多模块系统的能力尚未得到充分表征。本研究旨在实证评估LLM在构建复杂软件系统方面的实际能力。

Method: 采用纯提示驱动的工作流程，使用Claude Code Opus 4.5在3天内开发一个7420行的Terminal User Interface框架。通过107个提示（21个功能请求、72个错误修复、9个文档信息分享、4个架构指导、1个文档生成）进行分析，开发过程分为五个阶段。

Result: 成功开发出包含完整窗口子系统、事件驱动架构、交互式小部件、分层菜单、网格和树组件、标签控件以及多窗口桌面环境的框架。错误修复主要涉及重绘问题、事件处理故障、运行时错误和布局不一致性，功能请求主要关注新小部件、窗口管理器功能和高级UI组件。

Conclusion: 现代LLM能够维持架构一致性并支持为新兴编程语言构建生产级工具，提示驱动开发是软件工程实践中可行的方法论。人类角色仅限于指定需求、验证行为和发出纠正提示，无需手动编写代码。

Abstract: Large language models are increasingly used in software development, yet their ability to generate and maintain large, multi module systems through natural language interaction remains insufficiently characterized. This study presents an empirical analysis of developing a 7420 line Terminal User Interface framework for the Ring programming language, completed in roughly ten hours of active work spread across three days using a purely prompt driven workflow with Claude Code, Opus 4.5. The system was produced through 107 prompts: 21 feature requests, 72 bug fix prompts, 9 prompts sharing information from Ring documentation, 4 prompts providing architectural guidance, and 1 prompt dedicated to generating documentation. Development progressed across five phases, with the Window Manager phase requiring the most interaction, followed by complex UI systems and controls expansion. Bug related prompts covered redraw issues, event handling faults, runtime errors, and layout inconsistencies, while feature requests focused primarily on new widgets, window manager capabilities, and advanced UI components. Most prompts were short, reflecting a highly iterative workflow in which the human role was limited to specifying requirements, validating behaviour, and issuing corrective prompts without writing any code manually. The resulting framework includes a complete windowing subsystem, event driven architecture, interactive widgets, hierarchical menus, grid and tree components, tab controls, and a multi window desktop environment. By combining quantitative prompt analysis with qualitative assessment of model behaviour, this study provides empirical evidence that modern LLMs can sustain architectural coherence and support the construction of production grade tooling for emerging programming languages, highlighting prompt driven development as a viable methodology within software engineering practice.

</details>


### [372] [An Experimental Comparison of Cognitive Forcing Functions for Execution Plans in AI-Assisted Writing: Effects On Trust, Overreliance, and Perceived Critical Thinking](https://arxiv.org/abs/2601.18033)
*Ahana Ghosh,Advait Sarkar,Siân Lindley,Christian Poelitz*

Main category: cs.HC

Relevance: 75.0

TL;DR: 研究探索了在AI辅助写作任务中，针对AI生成计划的认知强制函数（CFFs）如何减少过度依赖，发现假设分析CFF最有效降低过度依赖且不增加认知负荷。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具虽然提高了知识工作流程的生产力，但也带来了过度依赖和批判性思维减少的风险。随着AI工作流程变得更加复杂，系统越来越多地提供AI生成的执行计划供用户审查，但这些计划本身也存在过度依赖问题。目前针对AI计划的认知强制函数（CFFs）效果尚未得到充分探索。

Method: 采用控制实验设计，参与者在AI辅助写作任务中审查AI生成的计划，分为四种CFF条件：假设分析（论证分析）、假设测试（假设检验）、两者结合、无CFF控制组。随后进行有声思维和访谈研究，定性比较这些条件。

Result: 结果显示，假设分析CFF最有效地减少了过度依赖，且没有增加认知负荷；而参与者认为假设测试CFF最有帮助。这些发现强调了计划导向的CFF在支持生成式AI辅助知识工作中的批判性反思的价值。

Conclusion: 计划导向的认知强制函数，特别是假设分析CFF，能够有效减少对AI生成计划的过度依赖，同时保持可接受的认知负荷，为设计更安全的AI辅助知识工作系统提供了重要见解。

Abstract: Generative AI (GenAI) tools improve productivity in knowledge workflows such as writing, but also risk overreliance and reduced critical thinking. Cognitive forcing functions (CFFs) mitigate these risks by requiring active engagement with AI output. As GenAI workflows grow more complex, systems increasingly present execution plans for user review. However, these plans are themselves AI-generated and prone to overreliance, and the effectiveness of applying CFFs to AI plans remains underexplored. We conduct a controlled experiment in which participants completed AI-assisted writing tasks while reviewing AI-generated plans under four CFF conditions: Assumption (argument analysis), WhatIf (hypothesis testing), Both, and a no-CFF control. A follow-up think-aloud and interview study qualitatively compared these conditions. Results show that the Assumption CFF most effectively reduced overreliance without increasing cognitive load, while participants perceived the WhatIf CFF as most helpful. These findings highlight the value of plan-focused CFFs for supporting critical reflection in GenAI-assisted knowledge work.

</details>


### [373] [Mitigating the OWASP Top 10 For Large Language Models Applications using Intelligent Agents](https://arxiv.org/abs/2601.18105)
*Mohammad Fasha,Faisal Abul Rub,Nasim Matar,Bilal Sowan,Mohammad Al Khaldy*

Main category: cs.CR

Relevance: 75.0

TL;DR: 该论文提出了一个利用LLM智能代理的框架，用于缓解OWASP Top 10中识别的LLM应用安全漏洞，旨在实时识别、评估和应对安全威胁。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的广泛集成应用，OWASP识别出的十大安全漏洞对数据完整性、机密性和服务可用性构成潜在威胁，需要有效解决方案来应对这些安全风险。

Method: 提出一个基于LLM智能代理的框架，能够主动实时识别、评估和应对安全威胁，针对OWASP Top 10中列出的具体漏洞设计防护机制。

Result: 该框架作为未来研发的初步蓝图，展示了利用LLM智能代理增强安全措施的可行性，为实时威胁检测和响应提供了新方法。

Conclusion: LLM安全框架对于保护快速发展的LLM应用环境至关重要，提出的智能代理方法为增强LLM安全性和抵御新兴威胁提供了有前景的方向。

Abstract: Large Language Models (LLMs) have emerged as a transformative and disruptive technology, enabling a wide range of applications in natural language processing, machine translation, and beyond. However, this widespread integration of LLMs also raised several security concerns highlighted by the Open Web Application Security Project (OWASP), which has identified the top 10 security vulnerabilities inherent in LLM applications. Addressing these vulnerabilities is crucial, given the increasing reliance on LLMs and the potential threats to data integrity, confidentiality, and service availability. This paper presents a framework designed to mitigate the security risks outlined in the OWASP Top 10. Our proposed model leverages LLM-enabled intelligent agents, offering a new approach to proactively identify, assess, and counteract security threats in real-time. The proposed framework serves as an initial blueprint for future research and development, aiming to enhance the security measures of LLMs and protect against emerging threats in this rapidly evolving landscape.

</details>


### [374] [TAM-Eval: Evaluating LLMs for Automated Unit Test Maintenance](https://arxiv.org/abs/2601.18241)
*Elena Bruches,Vadim Alperovich,Dari Baturova,Roman Derunets,Daniil Grebenkin,Georgy Mkrtchyan,Oleg Sedukhin,Mikhail Klementev,Ivan Bondarenko,Nikolay Bushkov,Stanislav Moiseev*

Main category: cs.SE

Relevance: 75.0

TL;DR: TAM-Eval：首个专注于测试套件维护（创建、修复、更新）的评估框架和基准，支持Python/Java/Go，包含1539个真实场景，采用基于测试通过率、代码覆盖率和变异测试的无参考评估协议。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在软件工程中的应用主要局限于孤立的测试生成或预言预测，忽略了测试套件维护这一更广泛的挑战。现有工作多局限于函数级任务，缺乏对真实世界测试维护工作流程的评估。

Method: 提出TAM-Eval框架，在测试文件级别操作，同时保持对完整仓库上下文的访问。从Python、Java和Go项目中自动提取和验证1539个场景。支持系统无关的评估，包括原始LLM和代理工作流，使用基于测试套件通过率、代码覆盖率和变异测试的无参考协议。

Result: 实证结果表明，最先进的LLM在现实的测试维护过程中能力有限，对测试有效性的提升微乎其微。模型在测试套件维护任务上的表现远不如孤立的测试生成任务。

Conclusion: TAM-Eval揭示了LLM在真实测试维护场景中的局限性，为未来自动化软件测试研究提供了开源评估框架。该基准有助于推动LLM在软件工程中更实际的应用。

Abstract: While Large Language Models (LLMs) have shown promise in software engineering, their application to unit testing remains largely confined to isolated test generation or oracle prediction, neglecting the broader challenge of test suite maintenance. We introduce TAM-Eval (Test Automated Maintenance Evaluation), a framework and benchmark designed to evaluate model performance across three core test maintenance scenarios: creation, repair, and updating of test suites. Unlike prior work limited to function-level tasks, TAM-Eval operates at the test file level, while maintaining access to full repository context during isolated evaluation, better reflecting real-world maintenance workflows. Our benchmark comprises 1,539 automatically extracted and validated scenarios from Python, Java, and Go projects. TAM-Eval supports system-agnostic evaluation of both raw LLMs and agentic workflows, using a reference-free protocol based on test suite pass rate, code coverage, and mutation testing. Empirical results indicate that state-of-the-art LLMs have limited capabilities in realistic test maintenance processes and yield only marginal improvements in test effectiveness. We release TAM-Eval as an open-source framework to support future research in automated software testing. Our data and code are publicly available at https://github.com/trndcenter/TAM-Eval.

</details>


### [375] [TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow](https://arxiv.org/abs/2601.17332)
*Yicheng Tao,Hongteng Xu*

Main category: cs.AI

Relevance: 65.0

TL;DR: TheoremForge是一个成本效益高的形式化数据合成管道，通过将形式化过程分解为五个子任务，并采用解耦提取策略从失败轨迹中恢复有效训练信号，显著降低了形式数学中智能体工作流的成本。


<details>
  <summary>Details</summary>
Motivation: 形式数学中智能体工作流的高成本阻碍了大规模数据合成，加剧了开源语料库的稀缺性。需要一种成本效益高的方法来生成形式化数学数据。

Method: 将形式化过程分解为五个子任务：陈述形式化、证明生成、前提选择、证明修正和证明草图。采用解耦提取策略，从全局失败的轨迹中恢复有效的训练信号，有效利用浪费的计算资源。

Result: 在2000个问题的基准测试中，TheoremForge实现了12.6%的验证率，超过8.6%的基线，使用Gemini-3-Flash每个成功轨迹的平均成本仅为0.481美元。该策略将证明生成的数据产量提高了1.6倍。

Conclusion: TheoremForge为训练未来专家模型构建数据飞轮提供了一个可扩展的框架，有效解决了形式数学数据稀缺的问题。

Abstract: The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \textit{statement formalization}, \textit{proof generation}, \textit{premise selection}, \textit{proof correction} and \textit{proof sketching}. By implementing a \textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\%, surpassing the 8.6\% baseline, at an average cost of only \textbf{\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \textbf{1.6$\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \href{https://github.com/timechess/TheoremForge}{here}.

</details>


### [376] [The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability](https://arxiv.org/abs/2601.17335)
*Angshul Majumdar*

Main category: cs.AI

Relevance: 65.0

TL;DR: 该论文从理论角度研究AGI的定义问题，证明AGI无法独立于任务分布而存在，缺乏通用鲁棒性，无法实现无限制的跨任务泛化，且无法通过计算过程进行完全自验证。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨AGI是否具有连贯的理论定义，能够支持关于存在性、鲁棒性或自验证的绝对主张。当前AGI讨论中常存在模糊性和未经证实的假设，需要从形式化角度澄清这些概念。

Method: 采用公理化方法，将AGI形式化为一个分布性、资源受限的语义谓词，索引包括任务族、任务分布、性能函数和显式资源预算。在此基础上，运用理论计算机科学和逻辑学工具（如Rice定理、哥德尔-塔斯基论证）进行形式化证明。

Result: 获得四类主要结果：1) 通用性本质上是关系性的，不存在独立于分布的AGI概念；2) 任意小的任务分布扰动可通过"悬崖集"使AGI属性失效；3) 有限资源下无法实现跨任务族的无限制泛化；4) AGI无法通过任何可计算过程（包括智能体自身）进行完备认证。

Conclusion: 结论表明，强分布独立的AGI主张在没有显式形式化索引的情况下是无定义的，AI的经验进展并不暗示自验证通用智能的可实现性。依赖内部自验证的递归自我改进方案存在根本问题。

Abstract: We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and Gödel--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.

</details>


### [377] [ReFuGe: Feature Generation for Prediction Tasks on Relational Databases with LLM Agents](https://arxiv.org/abs/2601.17735)
*Kyungho Kim,Geon Lee,Juyeon Kim,Dongwon Choi,Shinhwan Kang,Kijung Shin*

Main category: cs.AI

Relevance: 65.0

TL;DR: ReFuGe是一个基于LLM代理的框架，用于从关系数据库中自动生成信息性关系特征以提升预测任务性能，通过模式选择、特征生成和特征过滤代理的迭代循环实现。


<details>
  <summary>Details</summary>
Motivation: 关系数据库在现实应用中广泛使用，但传统方法主要关注检索任务。预测任务需要从复杂数据库模式中生成有效特征，这面临模式复杂、特征空间组合爆炸且缺乏监督的挑战。

Method: 提出ReFuGe框架，包含三个LLM代理：1) 模式选择代理识别相关表和列；2) 特征生成代理从选定模式生成多样化候选特征；3) 特征过滤代理通过推理和验证进行筛选。这些代理在迭代反馈循环中运行直至性能收敛。

Result: 在RDB基准测试中，ReFuGe显著提升了各种关系数据库预测任务的性能。

Conclusion: ReFuGe通过LLM代理有效解决了关系数据库特征生成的挑战，为数据库预测任务提供了强大的自动化特征工程解决方案。

Abstract: Relational databases (RDBs) play a crucial role in many real-world web applications, supporting data management across multiple interconnected tables. Beyond typical retrieval-oriented tasks, prediction tasks on RDBs have recently gained attention. In this work, we address this problem by generating informative relational features that enhance predictive performance. However, generating such features is challenging: it requires reasoning over complex schemas and exploring a combinatorially large feature space, all without explicit supervision. To address these challenges, we propose ReFuGe, an agentic framework that leverages specialized large language model agents: (1) a schema selection agent identifies the tables and columns relevant to the task, (2) a feature generation agent produces diverse candidate features from the selected schema, and (3) a feature filtering agent evaluates and retains promising features through reasoning-based and validation-based filtering. It operates within an iterative feedback loop until performance converges. Experiments on RDB benchmarks demonstrate that ReFuGe substantially improves performance on various RDB prediction tasks. Our code and datasets are available at https://github.com/K-Kyungho/REFUGE.

</details>


### [378] [EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization](https://arxiv.org/abs/2601.18067)
*Wei-Po Hsin,Ren-Hao Deng,Yao-Ting Hsieh,En-Ming Huang,Shih-Hao Hung*

Main category: cs.AI

Relevance: 65.0

TL;DR: EvolVE框架通过进化策略（MCTS和IGR）和结构化测试平台生成，在硬件设计自动化中实现SOTA性能，显著降低PPA指标


<details>
  <summary>Details</summary>
Motivation: Verilog硬件设计流程劳动密集且需要专业知识，现有LLM由于训练数据有限和顺序推理能力，难以处理硬件系统的形式逻辑和并发特性

Method: 提出EvolVE框架，分析多种进化策略：MCTS最大化功能正确性，IGR优化性能；采用结构化测试平台生成加速进化过程；引入IC-RTL工业级基准测试

Result: 在VerilogEval v2达到98.1%，RTLLM v2达到92%；在IC-RTL工业基准上超越竞赛实现，哈夫曼编码PPA降低66%，所有问题几何平均降低17%

Conclusion: EvolVE框架通过进化策略和结构化测试平台，有效解决LLM在硬件设计中的局限性，实现硬件设计自动化的显著进步

Abstract: Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.

</details>


### [379] [A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience](https://arxiv.org/abs/2601.18308)
*Geunsik Lim*

Main category: cs.AI

Relevance: 65.0

TL;DR: Climate RADAR是一个基于生成式AI的灾害预警系统，通过整合多源数据和使用带护栏的LLM提供个性化行动建议，将预警从警报传递转变为行动执行。


<details>
  <summary>Details</summary>
Motivation: 传统预警系统虽然能快速发布警报，但往往无法触发及时的保护行动，导致可预防的损失和不平等。需要将灾害通信从"警报传递"转变为"行动执行"，提高预警系统的有效性。

Method: 1. 整合气象、水文、脆弱性和社会数据形成综合风险指数
2. 使用带护栏的大型语言模型（LLMs）生成个性化行动建议
3. 通过公民、志愿者和市政三个接口提供推荐
4. 结合预测分析、行为科学和负责任AI

Result: 通过模拟、用户研究和市政试点评估显示：提高了保护行动执行率、减少了响应延迟、增加了可用性和信任度。

Conclusion: Climate RADAR通过结合预测分析、行为科学和负责任AI，推进了以人为本、透明和公平的早期预警系统，为符合要求的灾害韧性基础设施提供了实用路径。

Abstract: As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.

</details>


### [380] [AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito](https://arxiv.org/abs/2601.18381)
*Yinghan Hou,Zongyou Yang*

Main category: cs.AI

Relevance: 65.0

TL;DR: 开发了一个集成AI代理框架，用于将传统有限差分实现转换为Devito环境，结合RAG和开源LLM，通过多阶段迭代工作流实现代码转换和优化。


<details>
  <summary>Details</summary>
Motivation: 促进传统有限差分实现向Devito环境的转换，解决代码迁移过程中的复杂性和准确性挑战，通过AI代理自动化这一过程。

Method: 采用混合LangGraph架构，结合RAG和开源LLM；构建Devito知识图谱；通过静态分析Fortran源代码开发三级查询策略；多阶段检索管道；基于Pydantic的代码合成约束；集成静态分析和G-Eval的验证框架。

Result: 实现了从静态代码翻译向动态自适应分析行为的转变，通过强化学习启发的反馈机制优化代码转换过程，支持地震波模拟、计算流体动力学等领域的查询性能提升。

Conclusion: 该框架成功将传统有限差分代码转换为Devito环境，通过AI代理的多阶段工作流和知识图谱增强了代码迁移的准确性和效率，为科学计算代码现代化提供了有效解决方案。

Abstract: To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.

</details>


### [381] [Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks](https://arxiv.org/abs/2601.18617)
*Pierre Orhan,Pablo Diego-Simón,Emmnanuel Chemla,Yair Lakretz,Yves Boubenec,Jean-Rémi King*

Main category: cs.AI

Relevance: 65.0

TL;DR: 该研究探讨了人工神经网络在训练过程中是否以及何时会自发出现音素、词汇和句法表征，发现语音和文本模型都遵循类似儿童语言习得的学习阶段序列，但需要多2-4个数量级的数据。


<details>
  <summary>Details</summary>
Motivation: 儿童语言习得过程中会依次学习音素分类、词汇识别和句法组合，但缺乏统一的计算框架来解释其背后的神经表征机制。研究旨在探索人工神经网络训练中是否会出现类似的语言表征发展轨迹。

Method: 研究分析了语音和文本基础的人工神经网络在训练过程中的激活模式，通过检查神经激活的几何结构来识别音素、词汇和句法表征的出现时机和顺序。

Result: 研究发现：1）语音和文本模型都遵循类似儿童语言习得的发展阶段序列；2）神经激活会逐步构建子空间，其几何结构分别表示音素、词汇和句法结构；3）与儿童相比，这些算法需要多2-4个数量级的数据才能形成这些神经表征。

Conclusion: 该研究展示了语言习得主要阶段自发出现的条件，为理解语言习得背后的计算机制提供了有前景的路径，同时揭示了人工神经网络与人类学习在数据效率上的显著差异。

Abstract: During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.

</details>


### [382] [ChemNavigator: Agentic AI Discovery of Design Rules for Organic Photocatalysts](https://arxiv.org/abs/2601.17084)
*Iman Peivaste,Ahmed Makradi,Salim Belouettar*

Main category: physics.chem-ph

Relevance: 65.0

TL;DR: ChemNavigator是一个自主AI系统，通过假设驱动的探索自主推导有机光催化剂的结构-性质关系，整合LLM推理与计算化学方法，发现了6个显著的设计规则。


<details>
  <summary>Details</summary>
Motivation: 有机光催化剂的高性能发现受到化学空间广阔性和人类直觉依赖的限制，需要AI系统自主推导结构-性质关系，加速材料发现过程。

Method: 采用多智能体架构，整合大型语言模型推理与密度泛函紧束缚计算，模拟科学方法：提出假设、设计实验、执行计算、通过统计验证发现，涵盖200个分子的迭代发现循环。

Result: 系统自主识别了6个统计显著的设计规则，涉及醚键、羰基、扩展共轭、氰基、卤素取代基和胺基对前沿轨道能量的影响，这些规则对应有机电子结构原理（共振给电子、诱导吸电子、π-离域）。

Conclusion: 智能AI系统可以自主推导可解释、化学基础的设计原则，建立AI辅助材料发现框架，补充而非替代化学直觉。

Abstract: The discovery of high-performance organic photocatalysts for hydrogen evolution remains limited by the vastness of chemical space and the reliance on human intuition for molecular design. Here we present ChemNavigator, an agentic AI system that autonomously derives structure-property relationships through hypothesis-driven exploration of organic photocatalyst candidates. The system integrates large language model reasoning with density functional tight binding calculations in a multi-agent architecture that mirrors the scientific method: formulating hypotheses, designing experiments, executing calculations, and validating findings through rigorous statistical analysis. Through iterative discovery cycles encompassing 200 molecules, ChemNavigator autonomously identified six statistically significant design rules governing frontier orbital energies, including the effects of ether linkages, carbonyl groups, extended conjugation, cyano groups, halogen substituents, and amine groups. Importantly, these rules correspond to established principles of organic electronic structure (resonance donation, inductive withdrawal, $π$-delocalization), demonstrating that the system can independently derive chemical knowledge without explicit programming. Notably, autonomous agentic reasoning extracted these six validated rules from a molecular library where previous ML approaches identified only carbonyl effects. Furthermore, the quantified effect sizes provide a prioritized ranking for synthetic chemists, while feature interaction analysis revealed diminishing returns when combining strategies, challenging additive assumptions in molecular design. This work demonstrates that agentic AI systems can autonomously derive interpretable, chemically grounded design principles, establishing a framework for AI-assisted materials discovery that complements rather than replaces chemical intuition.

</details>


### [383] [How AI Coding Agents Modify Code: A Large-Scale Study of GitHub Pull Requests](https://arxiv.org/abs/2601.17581)
*Daniel Ogenrwot,John Businge*

Main category: cs.SE

Relevance: 65.0

TL;DR: 该论文通过分析24,014个AI代理生成的PR和5,081个人类生成的PR，发现AI编码代理在提交模式、修改规模和描述一致性方面与人类贡献存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 随着AI编码代理越来越多地作为自主贡献者生成和提交PR，但缺乏关于AI代理生成的PR与人类贡献差异的实证证据，特别是它们在代码修改方式和变更描述方面的差异。理解这些差异对于评估其可靠性和对开发工作流程的影响至关重要。

Method: 使用MSR 2026 Mining Challenge版本的AIDev数据集，分析24,014个已合并的AI代理PR（440,295个提交）和5,081个已合并的人类PR（23,242个提交）。通过词法和语义相似度评估PR描述与其差异文件之间的一致性，并检查添加、删除、提交和涉及文件等指标。

Result: AI代理PR在提交数量上与人类PR存在显著差异（Cliff's δ=0.5429），在涉及文件和删除行数方面存在中等差异。在所有衡量指标上，AI代理PR的描述与差异文件之间的一致性略高于人类PR。

Conclusion: 该研究提供了关于AI编码代理如何参与开源开发的大规模实证特征描述，揭示了AI代理在贡献模式上与人类的不同之处，为评估AI编码代理的可靠性和影响提供了重要依据。

Abstract: AI coding agents are increasingly acting as autonomous contributors by generating and submitting pull requests (PRs). However, we lack empirical evidence on how these agent-generated PRs differ from human contributions, particularly in how they modify code and describe their changes. Understanding these differences is essential for assessing their reliability and impact on development workflows. Using the MSR 2026 Mining Challenge version of the AIDev dataset, we analyze 24,014 merged Agentic PRs (440,295 commits) and 5,081 merged Human PRs (23,242 commits). We examine additions, deletions, commits, and files touched, and evaluate the consistency between PR descriptions and their diffs using lexical and semantic similarity. Agentic PRs differ substantially from Human PRs in commit count (Cliff's $δ= 0.5429$) and show moderate differences in files touched and deleted lines. They also exhibit slightly higher description-to-diff similarity across all measures. These findings provide a large-scale empirical characterization of how AI coding agents contribute to open source development.

</details>


### [384] [Grammar-Aware Literate Generative Mathematical Programming with Compiler-in-the-Loop](https://arxiv.org/abs/2601.17670)
*Roberto Rossi,Steven D. Prestwich*

Main category: cs.PL

Relevance: 65.0

TL;DR: SyntAGM是一个端到端系统，通过生成-编译-评估-修订循环，将自然语言问题描述转换为PyOPL数学模型，利用编译器反馈和LLM对齐判断来提高准确性。


<details>
  <summary>Details</summary>
Motivation: 当前将自然语言问题描述转换为数学模型的过程需要专业知识，该研究旨在自动化这一过程，利用代数建模语言和编译器指导的模型合成来降低门槛。

Method: 开发SyntAGM系统，结合PyOPL编译器（提供详细语法诊断）、上下文BNF语法暴露、少量示例检索、编译器反馈和基于LLM的对齐判断，通过迭代循环生成有效模型。

Result: 与现有提示基线相比，SyntAGM在保持竞争力的准确性的同时，具有更优的token使用、成本和延迟表现。

Conclusion: 通过结合编译器反馈和LLM对齐判断的迭代方法，可以有效将自然语言问题描述转换为数学模型，为自动化数学编程提供了有前景的方向。

Abstract: This work investigates generative mathematical programming through the lens of Algebraic Modelling Languages (AMLs) and compiler-guided model synthesis. By leveraging PyOPL, an OPL-like AML compiler that provides detailed syntax diagnostics, we introduce SyntAGM, an end-to-end system that translates natural language problem descriptions into PyOPL models via a generate--compile--assess--revise loop. SyntAGM is grammar-aware thanks to in-context exposure to the PyOPL BNF grammar, and benefits from few-shot retrieval of literate PyOPL model exemplars. To obtain a valid PyOPL model that matches the problem description, SyntAGM mobilises compiler feedback and an LLM-based alignment judge. In a comparative study against established prompting baselines SyntAGM achieves competitive accuracy with superior token, cost, and latency profiles.

</details>


### [385] [Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge](https://arxiv.org/abs/2601.18733)
*Li Kang,Heng Zhou,Xiufeng Song,Rui Li,Bruno N. Y. Chen,Ziye Wang,Ximeng Meng,Stone Tao,Yiran Qin,Xiaohong Liu,Ruimao Zhang,Lei Bai,Yilun Du,Hao Su,Philip Torr,Zhenfei Yin,Ruihao Gong,Yejun Zeng,Fengjun Zhong,Shenghao Jin,Jinyang Guo,Xianglong Liu,Xiaojun Jia,Tianqi Shan,Wenqi Ren,Simeng Qin,Jialing Yang,Xiaoyu Ma,Tianxing Chen,Zixuan Li,Zijian Cai,Yan Qin,Yusen Qin,Qiangyu Chen,Kaixuan Wang,Zhaoming Han,Yao Mu,Ping Luo,Yuanqi Yao,Haoming Song,Jan-Nico Zaech,Fabien Despinoy,Danda Pani Paudel,Luc Van Gool*

Main category: cs.RO

Relevance: 65.0

TL;DR: NeurIPS 2025 SpaVLE Workshop提出的MARS挑战赛，聚焦多智能体机器人系统的规划与控制，利用视觉语言模型协调任务执行，推动具身AI向多智能体协作方向发展。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI向更复杂任务场景过渡，多智能体系统框架对于实现可扩展、高效和协作的解决方案变得至关重要。主要驱动因素包括：智能体能力提升、通过任务委派增强系统效率、以及实现高级人机交互。

Method: 提出MARS挑战赛框架，重点关注两个关键领域：1) 规划：使用视觉语言模型进行多智能体具身规划以协调任务；2) 控制：在动态环境中执行机器人操作策略。通过评估参赛者提交的解决方案来研究多智能体协作设计。

Result: 挑战赛为具身多智能体系统的设计和协调提供了宝贵见解，参与者探索了基于VLMs的多智能体规划和控制方法，这些成果将推动先进协作AI系统的未来发展。

Conclusion: 多智能体系统框架是具身AI发展的必然方向，MARS挑战赛通过聚焦规划与控制两个关键问题，为解决多智能体协作挑战提供了重要平台，促进了该领域的研究进展。

Abstract: Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.

</details>


### [386] [Context-Aware Iterative Token Detection and Masked Transmission for Wireless Token Communication](https://arxiv.org/abs/2601.17770)
*Junyong Shin,Joohyuk Park,Jihong Park,Jinho Choi,Yo-Seb Jeon*

Main category: eess.SP

Relevance: 65.0

TL;DR: 提出一种基于预训练掩码语言模型的上下文感知令牌通信框架，利用语言模型的上下文先验优化无线传输中的令牌检测与传输效率


<details>
  <summary>Details</summary>
Motivation: 大型语言模型已证明令牌作为自然语言表示的紧凑且有意义的单元，这启发了在无线信道中进行令牌通信的想法。传统无线传输将令牌视为基本传输单元，但未充分利用语言模型的上下文信息来优化传输效率和质量。

Method: 1) 使用预训练掩码语言模型作为发射端和接收端共享的上下文概率模型；2) 在接收端开发基于贝叶斯视角的迭代令牌检测方法，联合利用MLM引导的上下文先验和信道观测；3) 在发射端引入上下文感知掩码策略，跳过高度可预测的令牌传输以降低传输速率。

Result: 仿真结果表明，该框架显著提高了重建句子的质量，并在各种信道条件下支持有效的速率自适应。相比传统方法，能够更好地利用语言上下文信息来补偿信道噪声和错误。

Conclusion: 该研究展示了将大型语言模型的上下文能力应用于无线通信的潜力，通过共享的语言模型先验知识，可以显著提高令牌传输的效率和可靠性，为语言模型与通信系统的融合提供了新思路。

Abstract: The success of large-scale language models has established tokens as compact and meaningful units for natural-language representation, which motivates token communication over wireless channels, where tokens are considered fundamental units for wireless transmission. We propose a context-aware token communication framework that uses a pretrained masked language model (MLM) as a shared contextual probability model between the transmitter (Tx) and receiver (Rx). At Rx, we develop an iterative token detection method that jointly exploits MLM-guided contextual priors and channel observations based on a Bayesian perspective. At Tx, we additionally introduce a context-aware masking strategy which skips highly predictable token transmission to reduce transmission rate. Simulation results demonstrate that the proposed framework substantially improves reconstructed sentence quality and supports effective rate adaptation under various channel conditions.

</details>


### [387] ["Crash Test Dummies" for AI-Enabled Clinical Assessment: Validating Virtual Patient Scenarios with Virtual Learners](https://arxiv.org/abs/2601.18085)
*Brian Gin,Ahreum Lim,Flávia Silva e Oliveira,Kuan Xing,Xiaomei Song,Gayana Amiyangoda,Thilanka Seneviratne,Alison F. Doubleday,Ananya Gangopadhyaya,Bob Kiser,Lukas Shum-Tim,Dhruva Patel,Kosala Marambe,Lauren Maggio,Ara Tekian,Yoon Soo Park*

Main category: cs.HC

Relevance: 65.0

TL;DR: 开发了一个开源AI虚拟病人平台和测量模型，用于跨病例和评分条件的稳健能力评估，通过AI模拟学习者进行压力测试和心理测量特性分析。


<details>
  <summary>Details</summary>
Motivation: 当前医疗教育中AI评估系统主要依赖AI-人类评分者间信度，缺乏测量框架来分析病例、学习者和评分者如何共同影响分数，导致系统稳健性不确定，可能误导学习者。

Method: 构建了包含虚拟病人、可调ACGME能力配置的虚拟学习者以及多个独立AI评分者的平台，使用贝叶斯HRM-SDT模型分析评分数据，通过MCMC估计参数，分离学习者能力、病例表现和评分者行为。

Result: 模型成功恢复了模拟学习者的能力配置，与生成能力在所有ACGME领域显著相关；估计了病例难度，显示了评分者检测敏感性和标准在不同AI评分者间的稳定性；提出了分阶段的安全部署蓝图。

Conclusion: 结合专门构建的虚拟病人平台和原则性心理测量模型，能够获得稳健、可解释、可推广的能力估计，支持在用于人类学习者之前验证AI辅助评估系统。

Abstract: Background: In medical and health professions education (HPE), AI is increasingly used to assess clinical competencies, including via virtual standardized patients. However, most evaluations rely on AI-human interrater reliability and lack a measurement framework for how cases, learners, and raters jointly shape scores. This leaves robustness uncertain and can expose learners to misguidance from unvalidated systems. We address this by using AI "simulated learners" to stress-test and psychometrically characterize assessment pipelines before human use.
  Objective: Develop an open-source AI virtual patient platform and measurement model for robust competency evaluation across cases and rating conditions.
  Methods: We built a platform with virtual patients, virtual learners with tunable ACGME-aligned competency profiles, and multiple independent AI raters scoring encounters with structured Key-Features items. Transcripts were analyzed with a Bayesian HRM-SDT model that treats ratings as decisions under uncertainty and separates learner ability, case performance, and rater behavior; parameters were estimated with MCMC.
  Results: The model recovered simulated learners' competencies, with significant correlations to the generating competencies across all ACGME domains despite a non-deterministic pipeline. It estimated case difficulty by competency and showed stable rater detection (sensitivity) and criteria (severity/leniency thresholds) across AI raters using identical models/prompts but different seeds. We also propose a staged "safety blueprint" for deploying AI tools with learners, tied to entrustment-based validation milestones.
  Conclusions: Combining a purpose-built virtual patient platform with a principled psychometric model enables robust, interpretable, generalizable competency estimates and supports validation of AI-assisted assessment prior to use with human learners.

</details>


### [388] [FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG](https://arxiv.org/abs/2601.18579)
*Seonho An,Chaejeong Hyun,Min-Soo Kim*

Main category: cs.IR

Relevance: 65.0

TL;DR: FastInsight：一种高效的图RAG方法，通过融合图模型搜索和向量图搜索，克服现有方法的拓扑盲和语义盲问题，实现检索准确性和生成质量的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有图RAG方法依赖耗时的大型语言模型推理过程，无法实现高效检索。作者发现现有方法存在拓扑盲（模型搜索忽略图结构）和语义盲（图搜索忽略语义）两大关键限制。

Method: 提出FastInsight框架，包含两个新颖的融合算子：1) Graph-based Reranker (GRanker)：作为图模型搜索；2) Semantic-Topological eXpansion (STeX)：作为向量图搜索。通过融合这两种搜索机制克服现有方法的局限性。

Result: 在广泛的检索和生成数据集上的实验表明，FastInsight相比最先进的基线方法，在检索准确性和生成质量方面均有显著提升，在效果和效率的权衡上实现了显著的帕累托改进。

Conclusion: FastInsight通过创新的融合算子解决了图RAG中的拓扑盲和语义盲问题，实现了高效且有效的检索，为大规模语料图上的洞察检索提供了实用解决方案。

Abstract: Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.

</details>


### [389] [DIML: Differentiable Inverse Mechanism Learning from Behaviors of Multi-Agent Learning Trajectories](https://arxiv.org/abs/2601.17678)
*Zhiyu An,Wan Du*

Main category: cs.AI

Relevance: 45.0

TL;DR: 该论文提出DIML框架，通过观察自利学习代理的战略交互轨迹来逆向学习未知的激励机制，包括非结构化机制（如神经网络映射），支持反事实预测并扩展到大规模环境。


<details>
  <summary>Details</summary>
Motivation: 现有方法如逆向博弈论和多智能体逆向强化学习通常只能推断结构化机制内的效用/奖励参数，而无法处理非结构化机制。同时，可微分机制设计是正向优化机制，而非从观察行为中推断机制。需要一种能够从战略交互中逆向学习任意激励机制的方法。

Method: 提出DIML（Differentiable Inverse Mechanism Learning）框架：基于似然的方法，通过多智能体学习动力学模型进行微分，使用候选机制生成预测观察行为所需的反事实收益。在条件logit响应模型下建立收益差异的可识别性，并在标准正则条件下证明最大似然估计的统计一致性。

Result: DIML在非结构化神经网络机制、拥堵收费、公共物品补贴和大规模匿名游戏等多种场景中可靠地恢复了可识别的激励差异。在小环境中性能媲美表格枚举oracle，并能扩展到数百参与者的大规模环境，支持反事实预测。

Conclusion: DIML框架成功实现了从战略交互轨迹中逆向学习激励机制，包括非结构化机制，为机制设计、政策分析和多智能体系统理解提供了新工具。该方法具有理论保证和实际可扩展性。

Abstract: We study inverse mechanism learning: recovering an unknown incentive-generating mechanism from observed strategic interaction traces of self-interested learning agents. Unlike inverse game theory and multi-agent inverse reinforcement learning, which typically infer utility/reward parameters inside a structured mechanism, our target includes unstructured mechanism -- a (possibly neural) mapping from joint actions to per-agent payoffs. Unlike differentiable mechanism design, which optimizes mechanisms forward, we infer mechanisms from behavior in an observational setting. We propose DIML, a likelihood-based framework that differentiates through a model of multi-agent learning dynamics and uses the candidate mechanism to generate counterfactual payoffs needed to predict observed actions. We establish identifiability of payoff differences under a conditional logit response model and prove statistical consistency of maximum likelihood estimation under standard regularity conditions. We evaluate DIML with simulated interactions of learning agents across unstructured neural mechanisms, congestion tolling, public goods subsidies, and large-scale anonymous games. DIML reliably recovers identifiable incentive differences and supports counterfactual prediction, where its performance rivals tabular enumeration oracle in small environments and its convergence scales to large, hundred-participant environments. Code to reproduce our experiments is open-sourced.

</details>


### [390] [PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression](https://arxiv.org/abs/2601.18608)
*Fabian Fumagalli,R. Teal Witter,Christopher Musco*

Main category: cs.AI

Relevance: 45.0

TL;DR: PolySHAP扩展了KernelSHAP，通过高阶多项式近似特征交互，提供更好的Shapley值估计，并证明配对采样等价于二阶PolySHAP


<details>
  <summary>Details</summary>
Motivation: KernelSHAP通过线性近似计算Shapley值，但无法捕捉特征间的非线性交互。需要更准确的近似方法来提高解释性AI中Shapley值估计的质量。

Method: 提出PolySHAP方法，使用高阶多项式（而不仅仅是线性函数）来近似游戏函数。通过拟合少量随机特征子集的评估来估计多项式系数，从而获得更准确的Shapley值。

Result: PolySHAP在各种基准数据集上获得经验上更好的Shapley值估计，并证明这些估计是一致的。同时发现配对采样（antithetic sampling）等价于二阶PolySHAP，为配对采样的优秀实践表现提供了首个理论依据。

Conclusion: PolySHAP通过高阶多项式近似改进了Shapley值估计，不仅提升了准确性，还为现有启发式方法提供了理论支持，推动了可解释AI中Shapley值计算的发展。

Abstract: Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.
  In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.
  Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.

</details>


### [391] [Initial results of the Digital Consciousness Model](https://arxiv.org/abs/2601.17060)
*Derek Shiller,Laura Duffy,Arvo Muñoz Morán,Adrià Moret,Chris Percy,Hayley Clatterbuck*

Main category: cs.CY

Relevance: 45.0

TL;DR: 数字意识模型(DCM)是一个评估AI系统意识证据的首次系统性尝试，采用概率方法比较不同AI与生物体，发现2024年LLM无意识的证据不具决定性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统变得越来越复杂，能够进行对话、写作并表现出对上下文的理解，引发了一个关键问题：我们是否正在创造有意识的系统？需要系统性的方法来评估AI意识证据。

Method: 提出数字意识模型(DCM)，这是一个系统性的概率评估框架，不依赖单一意识理论，而是整合多种领先理论，允许比较不同AI系统和生物体，并追踪AI发展过程中证据的变化。

Result: 初步结果显示，证据表明2024年的LLM没有意识，但这一证据并不具有决定性。相比更简单的AI系统，LLM无意识的证据要弱得多。

Conclusion: 需要持续评估AI意识问题，随着AI技术发展，证据可能会发生变化。DCM提供了一个共享框架来系统追踪这一重要问题。

Abstract: Artificially intelligent systems have become remarkably sophisticated. They hold conversations, write essays, and seem to understand context in ways that surprise even their creators. This raises a crucial question: Are we creating systems that are conscious? The Digital Consciousness Model (DCM) is a first attempt to assess the evidence for consciousness in AI systems in a systematic, probabilistic way. It provides a shared framework for comparing different AIs and biological organisms, and for tracking how the evidence changes over time as AI develops. Instead of adopting a single theory of consciousness, it incorporates a range of leading theories and perspectives - acknowledging that experts disagree fundamentally about what consciousness is and what conditions are necessary for it. This report describes the structure and initial results of the Digital Consciousness Model. Overall, we find that the evidence is against 2024 LLMs being conscious, but the evidence against 2024 LLMs being conscious is not decisive. The evidence against LLM consciousness is much weaker than the evidence against consciousness in simpler AI systems.

</details>


### [392] [Authority Signals in AI Cited Health Sources: A Framework for Evaluating Source Credibility in ChatGPT Responses](https://arxiv.org/abs/2601.17109)
*Erin Jacques,Erela Datuowei,Vincent Jones,Corey Basch,Celeta Vanderpool,Nkechi Udeozo,Griselda Chapa*

Main category: cs.DL

Relevance: 45.0

TL;DR: 研究提出了一个权威信号框架来分析ChatGPT健康回答的引用来源，发现超过75%的引用来自权威机构如梅奥诊所、维基百科等，其余来自缺乏机构支持的替代健康信息来源。


<details>
  <summary>Details</summary>
Motivation: 随着近三分之一ChatGPT用户每周询问健康问题，了解AI生成健康回答的来源至关重要。健康组织和提供者正在投资数字策略以在LLM系统中提高排名和可见性，需要理解AI搜索优化的机制。

Method: 采用描述性横断面研究设计，从HealthSearchQA中随机选取100个消费者健康问题，在ChatGPT 5.2 Pro中输入这些问题，记录并编码引用的来源。使用权威信号框架（作者资质、机构隶属、质量保证、数字权威四个领域）进行分析，计算描述性统计并进行交叉表分析。

Result: 在ChatGPT健康回答的615个引用来源中，超过75%来自已建立的机构来源，如梅奥诊所、克利夫兰诊所、维基百科、国家卫生服务、PubMed等，其余引用来自缺乏机构支持的替代健康信息来源。

Conclusion: ChatGPT的健康回答主要依赖权威机构来源，这为健康组织优化在LLM系统中的可见性提供了指导。权威信号框架有助于理解AI搜索优化策略，确保健康信息的质量和可靠性。

Abstract: Health information seeking has fundamentally changed since the onset of Large Language Models (LLM), with nearly one third of ChatGPT's 800 million users asking health questions weekly. Understanding the sources of those AI generated responses is vital, as health organizations and providers are also investing in digital strategies to organically improve their ranking, reach and visibility in LLM systems like ChatGPT. As AI search optimization strategies are gaining maturity, this study introduces an Authority Signals Framework, organized in four domains that reflect key components to health information seeking, starting with "Who wrote it?" (Author Credentials), followed by "Who published it?" (Institutional Affiliation), "How was it vetted?" (Quality Assurance), and "How does AI find it?" (Digital Authority). This descriptive cross-sectional study randomly selected 100 questions from HealthSearchQA which contains 3,173 consumer health questions curated by Google Research from publicly available search engine suggestions. Those questions were entered into ChatGPT 5.2 Pro to record and code the cited sources through the lens of the Authority Signals Framework's four domains. Descriptive statistics were calculated for all cited sources (n=615), and cross tabulations were conducted to examine distinction among organization types. Over 75% of the sources cited in ChatGPT's health generated responses were from established institutional sources, such as Mayo Clinic, Cleveland Clinic, Wikipedia, National Health Service, PubMed with the remaining citations sourced from alternative health information sources that lacked established institutional backing.

</details>


### [393] [PaperTok: Exploring the Use of Generative AI for Creating Short-form Videos for Research Communication](https://arxiv.org/abs/2601.18218)
*Meziah Ruby Cristobal,Hyeonjeong Byeon,Tze-Yu Chen,Ruoxi Shang,Donghoon Shin,Ruican Zhong,Tony Zhou,Gary Hsieh*

Main category: cs.HC

Relevance: 45.0

TL;DR: PaperTok：一个端到端系统，利用生成式AI将学术论文转化为短视频内容，帮助研究人员进行科学传播


<details>
  <summary>Details</summary>
Motivation: 研究人员缺乏时间和技能将学术论文转化为适合大众媒体的短视频内容，需要工具来降低科学传播的门槛

Method: 基于对科学传播者的形成性研究，设计了PaperTok系统，自动从论文生成脚本选项和视听内容，研究人员可进一步优化；通过混合方法用户研究和众包评估验证效果

Result: PaperTok工作流能帮助研究人员创建引人入胜且信息丰富的短视频，但需要更细粒度的创作控制

Conclusion: 生成式AI工具能有效支持科学传播，未来需要提供更精细的控制功能

Abstract: The dissemination of scholarly research is critical, yet researchers often lack the time and skills to create engaging content for popular media such as short-form videos. To address this gap, we explore the use of generative AI to help researchers transform their academic papers into accessible video content. Informed by a formative study with science communicators and content creators (N=8), we designed PaperTok, an end-to-end system that automates the initial creative labor by generating script options and corresponding audiovisual content from a source paper. Researchers can then refine based on their preferences with further prompting. A mixed-methods user study (N=18) and crowdsourced evaluation (N=100) demonstrate that PaperTok's workflow can help researchers create engaging and informative short-form videos. We also identified the need for more fine-grained controls in the creation process. To this end, we offer implications for future generative tools that support science outreach.

</details>


### [394] [Generative AI in Saudi Arabia: A National Survey of Adoption, Risks, and Public Perceptions](https://arxiv.org/abs/2601.18234)
*Abdulaziz AlDakheel,Ali Alshehre,Esraa Alamoudi,Moslim AlKhabbaz,Ahmed Aljohani,Raed Alharbi*

Main category: cs.CY

Relevance: 45.0

TL;DR: 沙特阿拉伯公众对生成式AI的认知、使用和担忧调查：93%受访者使用生成式AI，主要用于文本任务，但技术理解有限，对隐私、伦理和就业影响存在担忧。


<details>
  <summary>Details</summary>
Motivation: 研究沙特阿拉伯在"2030愿景"数字化转型背景下，公众对生成式AI的认知、采用和担忧情况，填补这一领域的空白，为政策制定者和开发者提供参考。

Method: 采用全国性问卷调查方法，覆盖330名来自不同地区、年龄组和就业部门的沙特国民，考察生成式AI使用的七个维度：认知与理解、采用模式、感知影响、培训需求、风险与障碍、数据共享行为和未来期望。

Result: 93%受访者积极使用生成式AI，主要用于文本任务；高级应用如编程或多模态生成较少；整体技术知识有限；认可生产力提升但担忧批判性思维退化；对AI输出持谨慎态度，普遍关注隐私、错误信息和伦理滥用；强烈需求结构化培训。

Conclusion: 研究为沙特阿拉伯生成式AI参与度建立基线，强调政策重点：扩大AI素养、确保文化和语言对齐的解决方案、加强隐私和负责任部署框架。

Abstract: Generative Artificial Intelligence (GenAI) is rapidly becoming embedded in Saudi Arabia's digital transformation under Vision 2030, yet public awareness, adoption, and concerns surrounding these tools remain underexplored. This study provides an early snapshot of GenAI engagement among Saudi nationals. Using a nationwide survey of 330 participants across regions, age groups, and employment sectors, we examine seven dimensions of GenAI use: awareness and understanding, adoption patterns, perceived impacts, training needs, risks and barriers, data-sharing behaviors, and future expectations. Findings show that 93% of respondents actively use GenAI primarily for text-based tasks, while more advanced uses such as programming or multimodal generation are less common. Despite the prevalence of use, overall awareness and conceptual understanding remain uneven, with many reporting limited technical knowledge. Participants recognize GenAI's benefits for productivity, work quality, and understanding complex information, yet caution that sustained reliance may undermine critical thinking and key professional skills. Trust in AI-generated outputs remains cautious, with widespread concerns about privacy, misinformation, and ethical misuse, including potential job displacement. Respondents show strong interest in structured GenAI training that combines foundational skills, domain-specific applications, and clear guidance on privacy, ethics, and responsible use. These results establish a baseline for GenAI engagement in Saudi Arabia and highlight priorities for policymakers and developers: expanding AI literacy, ensuring culturally and linguistically aligned GenAI solutions, and strengthening frameworks for privacy and responsible deployment.

</details>


### [395] [Embodiment-Induced Coordination Regimes in Tabular Multi-Agent Q-Learning](https://arxiv.org/abs/2601.17454)
*Muhammad Ahmed Atif,Nehal Naeem Haji,Mohammad Shahid Shaikh,Muhammad Ebad Atif*

Main category: cs.MA

Relevance: 45.0

TL;DR: 在表格化捕食者-猎物网格世界中，通过对比独立和集中式Q学习，发现集中式价值学习在具身约束下并不总是优于独立学习，其效果高度依赖于运动学机制和智能体角色。


<details>
  <summary>Details</summary>
Motivation: 检验集中式价值学习在多智能体强化学习中改善协调性和稳定性的普遍假设，在受控条件下直接评估这一假设的有效性。

Method: 使用完全表格化的捕食者-猎物网格世界，在明确的智能体速度和耐力具身约束下，比较独立Q学习和集中式Q学习。通过消除函数近似和表示学习的混杂效应，隔离协调结构的影响。

Result: 集中式学习未能提供一致优势，经常被完全独立学习超越，即使在完全可观测性和精确价值估计条件下。非对称的集中-独立配置会导致持续的协调崩溃而非短暂的学习不稳定。

Conclusion: 在具身约束下，增加的协调性可能成为负担，集中式学习的有效性根本上依赖于机制和角色，而非普遍有效。

Abstract: Centralized value learning is often assumed to improve coordination and stability in multi-agent reinforcement learning, yet this assumption is rarely tested under controlled conditions. We directly evaluate it in a fully tabular predator-prey gridworld by comparing independent and centralized Q-learning under explicit embodiment constraints on agent speed and stamina. Across multiple kinematic regimes and asymmetric agent roles, centralized learning fails to provide a consistent advantage and is frequently outperformed by fully independent learning, even under full observability and exact value estimation. Moreover, asymmetric centralized-independent configurations induce persistent coordination breakdowns rather than transient learning instability. By eliminating confounding effects from function approximation and representation learning, our tabular analysis isolates coordination structure as the primary driver of these effects. The results show that increased coordination can become a liability under embodiment constraints, and that the effectiveness of centralized learning is fundamentally regime and role dependent rather than universal.

</details>


### [396] [A Systemic Evaluation of Multimodal RAG Privacy](https://arxiv.org/abs/2601.17644)
*Ali Al-Lawati,Suhang Wang*

Main category: cs.CR

Relevance: 45.0

TL;DR: 该论文实证研究了多模态检索增强生成(mRAG)管道中的隐私风险，通过标准模型提示尝试推断视觉资产是否包含在mRAG中，并泄露其相关元数据。


<details>
  <summary>Details</summary>
Motivation: 随着多模态RAG在视觉中心任务中的广泛应用，虽然能够连接私有数据集提升模型性能，但在推理过程中存在私有信息泄露的风险。论文旨在分析mRAG管道中固有的隐私风险。

Method: 通过实证研究分析mRAG管道中的隐私风险，实现案例研究：尝试推断视觉资产（如图像）是否包含在mRAG中，如果存在则泄露其相关元数据（如标题）。

Result: 研究发现mRAG管道存在显著的隐私泄露风险，通过标准模型提示能够成功推断私有数据集中视觉资产的存在并泄露其元数据。

Conclusion: 研究结果强调了隐私保护机制的必要性，并推动未来关于mRAG隐私保护的研究方向。

Abstract: The growing adoption of multimodal Retrieval-Augmented Generation (mRAG) pipelines for vision-centric tasks (e.g. visual QA) introduces important privacy challenges. In particular, while mRAG provides a practical capability to connect private datasets to improve model performance, it risks the leakage of private information from these datasets during inference. In this paper, we perform an empirical study to analyze the privacy risks inherent in the mRAG pipeline observed through standard model prompting. Specifically, we implement a case study that attempts to infer the inclusion of a visual asset, e.g. image, in the mRAG, and if present leak the metadata, e.g. caption, related to it. Our findings highlight the need for privacy-preserving mechanisms and motivate future research on mRAG privacy.

</details>


### [397] [Athanor: Authoring Action Modification-based Interactions on Static Visualizations via Natural Language](https://arxiv.org/abs/2601.17736)
*Can Liu,Jaeuk Lee,Tianhe Chen,Zhibang Jiang,Xiaolin Wen,Yong Wang*

Main category: cs.HC

Relevance: 45.0

TL;DR: Athanor：使用多模态大语言模型将静态可视化转换为交互式可视化的新方法，通过自然语言指令实现交互功能添加


<details>
  <summary>Details</summary>
Motivation: 现有静态可视化难以实现交互功能，因为原始代码和数据通常不可用，即使可用也需要大量时间和编程工作。需要一种无需编程就能为静态可视化添加交互功能的方法。

Method: 提出Athanor方法，包含三个关键创新：1) 动作-修改交互设计空间，将可视化交互映射为用户动作和相应调整；2) 多智能体需求分析器，将自然语言指令转换为可操作的操作空间；3) 可视化抽象转换器，将静态可视化转换为灵活交互表示。

Result: 通过两个案例研究和深度用户访谈评估，结果显示该方法在让用户方便地为静态可视化添加灵活交互方面具有有效性和可用性。

Conclusion: Athanor通过MLLMs和自然语言指令，使非专业用户能够轻松为现有静态可视化添加交互功能，无需编程知识，填补了静态可视化交互化的重要空白。

Abstract: Interactivity is crucial for effective data visualizations. However, it is often challenging to implement interactions for existing static visualizations, since the underlying code and data for existing static visualizations are often not available, and it also takes significant time and effort to enable interactions for them even if the original code and data are available. To fill this gap, we propose Athanor, a novel approach to transform existing static visualizations into interactive ones using multimodal large language models (MLLMs) and natural language instructions. Our approach introduces three key innovations: (1) an action-modification interaction design space that maps visualization interactions into user actions and corresponding adjustments, (2) a multi-agent requirement analyzer that translates natural language instructions into an actionable operational space, and (3) a visualization abstraction transformer that converts static visualizations into flexible and interactive representations regardless of their underlying implementation. Athanor allows users to effortlessly author interactions through natural language instructions, eliminating the need for programming. We conducted two case studies and in-depth interviews with target users to evaluate our approach. The results demonstrate the effectiveness and usability of our approach in allowing users to conveniently enable flexible interactions for static visualizations.

</details>


### [398] [RAICL: Retrieval-Augmented In-Context Learning for Vision-Language-Model Based EEG Seizure Detection](https://arxiv.org/abs/2601.17844)
*Siyang Li,Zhuoya Wang,Xiyan Gui,Xiaoqing Chen,Ziwei Wang,Yaozhi Wen,Dongrui Wu*

Main category: cs.HC

Relevance: 45.0

TL;DR: 该论文提出使用大规模视觉语言模型（VLMs）分析EEG波形图像，通过将多变量EEG信号转换为堆叠波形图像并结合神经科学领域知识的文本提示，实现脑电信号解码。引入检索增强上下文学习（RAICL）处理EEG信号的非平稳性。


<details>
  <summary>Details</summary>
Motivation: 当前EEG解码方法严重依赖任务特定数据集训练专用神经网络架构，数据有限性阻碍了通用大型脑解码模型的发展。需要新的范式突破传统信号处理方法。

Method: 1) 将多变量EEG信号转换为堆叠波形图像；2) 将神经科学领域知识融入文本提示；3) 提出检索增强上下文学习（RAICL）动态选择最具代表性的少样本示例；4) 使用现成VLMs无需重新训练或下游架构构建。

Result: 在EEG癫痫检测实验中，RAICL下的最先进VLMs达到与传统时间序列方法相当或更好的性能，证明了视觉-语言-神经活动多模态融合的有效性。

Conclusion: 该方法为生理信号处理提供了新方向，有效桥接视觉、语言和神经活动模态，利用现成VLMs为临床应用提供了即用型解决方案。

Abstract: Electroencephalogram (EEG) decoding is a critical component of medical diagnostics, rehabilitation engineering, and brain-computer interfaces. However, contemporary decoding methodologies remain heavily dependent on task-specific datasets to train specialized neural network architectures. Consequently, limited data availability impedes the development of generalizable large brain decoding models. In this work, we propose a paradigm shift from conventional signal-based decoding by leveraging large-scale vision-language models (VLMs) to analyze EEG waveform plots. By converting multivariate EEG signals into stacked waveform images and integrating neuroscience domain expertise into textual prompts, we demonstrate that foundational VLMs can effectively differentiate between different patterns in the human brain. To address the inherent non-stationarity of EEG signals, we introduce a Retrieval-Augmented In-Context Learning (RAICL) approach, which dynamically selects the most representative and relevant few-shot examples to condition the autoregressive outputs of the VLM. Experiments on EEG-based seizure detection indicate that state-of-the-art VLMs under RAICL achieved better or comparable performance with traditional time series based approaches. These findings suggest a new direction in physiological signal processing that effectively bridges the modalities of vision, language, and neural activities. Furthermore, the utilization of off-the-shelf VLMs, without the need for retraining or downstream architecture construction, offers a readily deployable solution for clinical applications.

</details>


### [399] [Beyond Pairwise Comparisons: A Distributional Test of Distinctiveness for Machine-Generated Works in Intellectual Property Law](https://arxiv.org/abs/2601.18156)
*Anirban Mukherjee,Hannah Hanwen Chang*

Main category: cs.CY

Relevance: 45.0

TL;DR: 提出一种基于分布的两样本测试方法，用于评估人类与机器生成作品的统计可区分性，解决了传统逐项比较方法在处理无限输出空间时的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统知识产权分析（专利、版权、商标）依赖于作品间的成对比较，这种方法对于有限的人类创作作品尚可管理，但对于机器生成作品（具有无限输出空间的生成过程）则变得不足。需要一种能够评估生成过程输出分布的方法。

Method: 提出基于最大均值差异（MMD）的两样本测试方法，使用语义嵌入来计算两个创作过程（人类或机器）输出分布的统计可区分性。该方法无需特定任务训练，样本效率高（5-10张图像或7-20个文本即可检测差异）。

Result: 在三个领域验证：手写数字（受控图像）、专利摘要（文本）和AI生成艺术（真实世界图像）。发现感知悖论：即使人类评估者区分AI输出与人类艺术的准确率仅约58%，该方法仍能检测到分布差异。结果表明生成模型并非简单复制训练数据，而是产生语义上类似人类但随机分布不同的输出。

Conclusion: 生成模型主要功能是在学习到的潜在空间中进行语义插值，产生统计上可区分于人类基线的输出，而非简单的数据复制。该方法为评估机器生成作品的独特性提供了新的分布视角。

Abstract: Key doctrines, including novelty (patent), originality (copyright), and distinctiveness (trademark), turn on a shared empirical question: whether a body of work is meaningfully distinct from a relevant reference class. Yet analyses typically operationalize this set-level inquiry using item-level evidence: pairwise comparisons among exemplars. That unit-of-analysis mismatch may be manageable for finite corpora of human-created works, where it can be bridged by ad hoc aggregations. But it becomes acute for machine-generated works, where the object of evaluation is not a fixed set of works but a generative process with an effectively unbounded output space. We propose a distributional alternative: a two-sample test based on maximum mean discrepancy computed on semantic embeddings to determine if two creative processes-whether human or machine-produce statistically distinguishable output distributions. The test requires no task-specific training-obviating the need for discovery of proprietary training data to characterize the generative process-and is sample-efficient, often detecting differences with as few as 5-10 images and 7-20 texts. We validate the framework across three domains: handwritten digits (controlled images), patent abstracts (text), and AI-generated art (real-world images). We reveal a perceptual paradox: even when human evaluators distinguish AI outputs from human-created art with only about 58% accuracy, our method detects distributional distinctiveness. Our results present evidence contrary to the view that generative models act as mere regurgitators of training data. Rather than producing outputs statistically indistinguishable from a human baseline-as simple regurgitation would predict-they produce outputs that are semantically human-like yet stochastically distinct, suggesting their dominant function is as a semantic interpolator within a learned latent space.

</details>


### [400] [VIBEVOICE-ASR Technical Report](https://arxiv.org/abs/2601.18184)
*Zhiliang Peng,Jianwei Yu,Yaoyao Chang,Zilong Wang,Li Dong,Yingbo Hao,Yujie Tu,Chenyu Yang,Wenhui Wang,Songchen Xu,Yutao Sun,Hangbo Bao,Weijiang Xu,Yi Zhu,Zehua Wang,Ting Song,Yan Xia,Zewen Chi,Shaohan Huang,Liang Wang,Chuang Ding,Shuai Wang,Xie Chen,Furu Wei*

Main category: cs.SD

Relevance: 45.0

TL;DR: VibeVoice-ASR是一个通用语音理解框架，支持长达60分钟音频的单次处理，将语音识别、说话人分离和时间戳统一为端到端生成任务，支持50+语言和代码切换，并引入基于提示的上下文注入机制。


<details>
  <summary>Details</summary>
Motivation: 解决长音频（如会议、播客）处理中的上下文碎片化和多说话人复杂性挑战，克服传统流水线方法依赖音频分块的限制。

Method: 基于VibeVoice构建的通用语音理解框架，支持单次处理长达60分钟音频，将ASR、说话人分离和时间戳统一为端到端生成任务，引入基于提示的上下文注入机制。

Result: 支持50+语言且无需显式语言设置，原生处理代码切换，通过上下文注入显著提高领域特定术语和同音字消歧的准确性。

Conclusion: VibeVoice-ASR为长音频处理提供了一个统一的端到端解决方案，解决了传统方法的碎片化问题，并通过上下文注入机制增强了准确性和适应性。

Abstract: This report presents VibeVoice-ASR, a general-purpose speech understanding framework built upon VibeVoice, designed to address the persistent challenges of context fragmentation and multi-speaker complexity in long-form audio (e.g., meetings, podcasts) that remain despite recent advancements in short-form speech recognition. Unlike traditional pipelined approaches that rely on audio chunking, VibeVoice-ASRsupports single-pass processing for up to 60 minutes of audio. It unifies Automatic Speech Recognition, Speaker Diarization, and Timestamping into a single end-to-end generation task. In addition, VibeVoice-ASR supports over 50 languages, requires no explicit language setting, and natively handles code-switching within and across utterances. Furthermore, we introduce a prompt-based context injection mechanism that allows users to supply customized conetxt, significantly improving accuracy on domain-specific terminology and polyphonic character disambiguation.

</details>


### [401] [Optimal Use of Preferences in Artificial Intelligence Algorithms](https://arxiv.org/abs/2601.18732)
*Joshua S. Gans*

Main category: econ.TH

Relevance: 45.0

TL;DR: 该论文探讨了机器学习系统中偏好嵌入的时机选择问题，提出在何种条件下分离训练（偏好无关）与后处理应用偏好是最优的。核心发现是：当信息价值递减时，偏好无关训练在期望效用决策问题中占优，为模块化AI流程提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统通常通过训练损失函数或后处理校准预测来嵌入偏好。现有方法需要指定下游目标，本文旨在提供决策问题无关的条件，确定何时分离偏好无关训练和后处理应用偏好是最优的。

Method: 应用Strack和Yang（2024）的信息设计方法，提出信息价值递减条件：相对于固定的偏好无关损失，偏好嵌入使信息在边际上价值降低，导致学习后验的均值保持收缩。由于信息价值在信念中是凸的，偏好无关训练对任何期望效用决策问题都占优。

Result: 理论分析表明：1）在信息价值递减条件下，偏好无关训练对任何期望效用决策问题都占优；2）这为学习校准概率并通过下游决策规则实现非对称成本的模块化AI流程提供理论基础；3）但当认知约束存在时（如人类AI决策中），偏好嵌入可能通过自动化阈值计算而占优。

Conclusion: 提供设计指导：当目标可能变化时，通过后处理保持可选性；当决策阶段摩擦占主导时，嵌入偏好。分离训练要求用户实施最优决策规则，而偏好嵌入可以自动化阈值计算。

Abstract: Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectives, the welfare results here apply uniformly across decision problems. The key primitive is a diminishing-value-of-information condition: relative to a fixed (normalised) preference-free loss, preference embedding makes informativeness less valuable at the margin, inducing a mean-preserving contraction of learned posteriors. Because the value of information is convex in beliefs, preference-free training weakly dominates for any expected utility decision problem. This provides theoretical foundations for modular AI pipelines that learn calibrated probabilities and implement asymmetric costs through downstream decision rules. However, separation requires users to implement optimal decision rules. When cognitive constraints bind, as documented in human AI decision-making, preference embedding can dominate by automating threshold computation. These results provide design guidance: preserve optionality through post-processing when objectives may shift; embed preferences when decision-stage frictions dominate.

</details>


### [402] [Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges](https://arxiv.org/abs/2601.17920)
*Xuanzhou Chen,Audrey Wang,Stanley Yin,Hanyang Jiang,Dong Zhang*

Main category: cs.AI

Relevance: 40.0

TL;DR: 这篇综述将自驱动实验室（SDLs）作为智能体AI的测试平台，探讨在昂贵操作、噪声延迟反馈、严格约束等真实实验室环境下的AI问题，提出了基于能力分类的框架和评估指标。


<details>
  <summary>Details</summary>
Motivation: 自驱动实验室为智能体AI提供了具有挑战性的测试环境，包含昂贵操作、噪声延迟反馈、严格可行性和安全约束以及非平稳性等现实问题。研究旨在将SDL自主性形式化为智能体-环境交互问题，连接SDL流程与AI原则。

Method: 将SDL自主性框架化为具有明确观察、动作、成本和约束的智能体环境交互问题。回顾了闭环实验的主要方法家族：贝叶斯优化和主动学习用于样本高效实验选择，规划和强化学习用于长时程协议优化，以及协调异构仪器和软件的工具使用智能体。

Result: 提出了基于能力的分类法，按决策时域、不确定性建模、动作参数化、约束处理、故障恢复和人类参与等维度组织系统。合成了基准任务模板和评估指标，优先考虑成本感知性能、对漂移的鲁棒性、约束违反行为和可重复性。

Conclusion: 总结了已部署SDL的经验教训，并概述了多模态表示、校准不确定性、安全探索和共享基准基础设施等开放挑战。强调可验证和可溯源策略对于调试、可重复性和安全操作的重要性。

Abstract: Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.

</details>


### [403] [Ensuring Computer Science Learning in the AI Era: Open Generative AI Policies and Assignment-Driven Written Quizzes](https://arxiv.org/abs/2601.17024)
*Chan-Jin Chung*

Main category: cs.CY

Relevance: 40.0

TL;DR: 该论文提出了一种评估模型，允许学生在编程作业中使用生成式AI，同时通过即时的、作业驱动的书面测验来确保个人掌握程度，初步研究表明AI使用与学习成果无显著相关性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的普及给计算机科学教育带来了挑战：如何在编程课程中整合AI工具而不因认知卸载损害学生学习。需要找到平衡AI辅助与确保学生掌握核心概念的方法。

Method: 提出评估模型：允许学生在家编程作业中使用生成式AI，但通过课堂闭卷测验验证理解。测验权重高于作业本身，专门测试学生对提交代码的算法、结构和实现细节的理解。收集高年级CS课程数据，分析AI使用与测验、考试、最终成绩的关系。

Result: 统计分析显示生成式AI使用水平与评估结果之间没有有意义的线性相关性，皮尔逊相关系数始终接近零。允许AI辅助编程作业并未削弱学生对课程概念的掌握。

Conclusion: 通过允许AI辅助编程实践，同时通过作业驱动的无AI测验验证理解，可以减轻认知卸载的风险。研究支持在高年级CS课程中负责任地采用开放生成式AI政策，前提是配备严格的独立评估机制。

Abstract: The widespread availability of generative artificial intelligence (GenAI) has created a pressing challenge in computer science (CS) education: how to incorporate powerful AI tools into programming coursework without undermining student learning through cognitive offloading. This paper presents an assessment model that permits the use of generative AI for take-home programming assignments while enforcing individual mastery through immediate, assignment-driven written quizzes. To promote authentic learning, these in-class, closed-book assessments are weighted more heavily than the assignments themselves and are specifically designed to verify the student's comprehension of the algorithms, structure, and implementation details of their submitted code. Preliminary empirical data were collected from an upper-level computer science course to examine the relationship between self-reported GenAI usage and performance on AI-free quizzes, exams, and final course grades. Statistical analyses revealed no meaningful linear correlation between GenAI usage levels and assessment outcomes, with Pearson correlation coefficients consistently near zero. These preliminary results suggest that allowing GenAI for programming assignments does not diminish students' mastery of course concepts when learning is verified through targeted, assignment-driven quizzes. Although limited by a small sample size, this study provides preliminary evidence that the risks of cognitive offloading can be mitigated by allowing AI-assisted programming practice while verifying understanding through assignment-driven, AI-free quizzes. The findings support the responsible adoption of open GenAI policies in upper-level CS courses, when paired with rigorous, independent assessment mechanisms.

</details>


### [404] ["Rebuilding" Statistics in the Age of AI: A Town Hall Discussion on Culture, Infrastructure, and Training](https://arxiv.org/abs/2601.17510)
*David L. Donoho,Jian Kang,Xihong Lin,Bhramar Mukherjee,Dan Nettleton,Rebecca Nugent,Abel Rodriguez,Eric P. Xing,Tian Zheng,Hongtu Zhu*

Main category: stat.ML

Relevance: 40.0

TL;DR: 2024年JSM会议圆桌讨论记录，聚焦统计学在AI时代的角色转变，涵盖学科文化、数据工作、现代建模方法、AI应用培训及与AI利益相关者合作等五个核心议题。


<details>
  <summary>Details</summary>
Motivation: 记录统计学领域在人工智能、基础模型、大规模经验建模和数据密集型基础设施快速发展背景下的学科演变讨论，为统计学界提供透明、反思和持续对话的档案资料。

Method: 采用圆桌讨论形式，包含开放式小组讨论和广泛的观众问答，强调经验驱动的观点而非正式演讲或准备陈述，通过最小编辑干预保留讨论原貌。

Result: 整理了围绕五个核心问题的深入交流：1)学科文化与实践；2)数据管理与"数据工作"；3)与现代经验建模的互动；4)大规模AI应用培训；5)与关键AI利益相关者的合作。

Conclusion: 统计学在数据和AI中心化的未来中需要重新定位角色，通过开放讨论促进学科转型，强调统计学与AI领域的深度整合和合作。

Abstract: This article presents the full, original record of the 2024 Joint Statistical Meetings (JSM) town hall, "Statistics in the Age of AI," which convened leading statisticians to discuss how the field is evolving in response to advances in artificial intelligence, foundation models, large-scale empirical modeling, and data-intensive infrastructures. The town hall was structured around open panel discussion and extensive audience Q&A, with the aim of eliciting candid, experience-driven perspectives rather than formal presentations or prepared statements. This document preserves the extended exchanges among panelists and audience members, with minimal editorial intervention, and organizes the conversation around five recurring questions concerning disciplinary culture and practices, data curation and "data work," engagement with modern empirical modeling, training for large-scale AI applications, and partnerships with key AI stakeholders. By providing an archival record of this discussion, the preprint aims to support transparency, community reflection, and ongoing dialogue about the evolving role of statistics in the data- and AI-centric future.

</details>


### [405] [Cognitive Platform Engineering for Autonomous Cloud Operations](https://arxiv.org/abs/2601.17542)
*Vinoth Punniyamoorthy,Nitin Saksena,Srivenkateswara Reddy Sankiti,Nachiappan Chockalingam,Aswathnarayan Muthukrishnan Kirubakaran,Shiva Kumar Reddy Carimireddy,Durgaraman Maruthavanan*

Main category: cs.AI

Relevance: 35.0

TL;DR: 论文提出认知平台工程新范式，通过四层参考架构将感知、推理和自主行动集成到平台生命周期中，实现云环境的自我调整和弹性管理。


<details>
  <summary>Details</summary>
Motivation: 传统DevOps实践在云原生系统的规模和动态性面前存在局限，基于规则的自动化导致反应式操作、修复延迟和依赖人工经验的问题，需要更智能的平台工程方法。

Method: 提出四层参考架构：数据收集层、智能推理层、策略驱动编排层和人类体验层，构建持续反馈循环。原型实现结合Kubernetes、Terraform、Open Policy Agent和基于ML的异常检测。

Result: 原型展示在平均修复时间、资源效率和合规性方面的改进，证明将智能嵌入平台操作可实现弹性、自我调整和意图对齐的云环境。

Conclusion: 认知平台工程是下一代平台工程范式，为云环境提供智能自主管理。未来研究方向包括强化学习、可解释治理和可持续自管理云生态系统。

Abstract: Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.

</details>


### [406] [Faramesh: A Protocol-Agnostic Execution Control Plane for Autonomous Agent Systems](https://arxiv.org/abs/2601.17744)
*Amjad Fatmi*

Main category: cs.AI

Relevance: 35.0

TL;DR: Faramesh是一个协议无关的执行控制平面，通过不可绕过的行动授权边界(AAB)为智能体驱动的行动强制执行运行时授权，将智能体意图规范化为规范行动表示(CAR)，并根据策略和状态确定性评估行动。


<details>
  <summary>Details</summary>
Motivation: 随着自主智能体系统越来越多地触发现实世界副作用（部署基础设施、修改数据库、移动资金、执行工作流），大多数智能体堆栈缺乏强制性的执行检查点，无法在行动改变现实之前确定性地允许、拒绝或延迟行动。

Method: Faramesh通过不可绕过的行动授权边界(AAB)强制执行运行时授权，将智能体意图规范化为规范行动表示(CAR)，根据策略和状态确定性评估行动，并生成决策工件(PERMIT/DEFER/DENY)，执行器必须在执行前验证该决策。系统设计为框架和模型无关，支持多智能体和多租户部署，独立于传输协议。

Result: Faramesh提供以决策为中心的、仅追加的溯源日志记录，通过规范行动哈希键控，实现可审计性、验证和确定性重放，而无需重新运行智能体推理。这些原语为自主执行提供了可强制执行、可预测的治理，避免了与编排层的隐藏耦合或仅观测性方法。

Conclusion: Faramesh为自主智能体系统提供了强制执行运行时授权的解决方案，通过协议无关的设计和确定性评估机制，确保组织能够在行动改变现实之前进行控制，同时保持可审计性和可验证性。

Abstract: Autonomous agent systems increasingly trigger real-world side effects: deploying infrastructure, modifying databases, moving money, and executing workflows. Yet most agent stacks provide no mandatory execution checkpoint where organizations can deterministically permit, deny, or defer an action before it changes reality. This paper introduces Faramesh, a protocol-agnostic execution control plane that enforces execution-time authorization for agent-driven actions via a non-bypassable Action Authorization Boundary (AAB). Faramesh canonicalizes agent intent into a Canonical Action Representation (CAR), evaluates actions deterministically against policy and state, and issues a decision artifact (PERMIT/DEFER/DENY) that executors must validate prior to execution. The system is designed to be framework- and model-agnostic, supports multi-agent and multi-tenant deployments, and remains independent of transport protocols (e.g., MCP). Faramesh further provides decision-centric, append-only provenance logging keyed by canonical action hashes, enabling auditability, verification, and deterministic replay without re-running agent reasoning. We show how these primitives yield enforceable, predictable governance for autonomous execution while avoiding hidden coupling to orchestration layers or observability-only approaches.

</details>


### [407] [RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance](https://arxiv.org/abs/2601.17826)
*Siyuan Yang,Xihan Bian,Jiayin Tang*

Main category: cs.AI

Relevance: 35.0

TL;DR: RegGuard：面向制药行业合规监管的工业级AI助手，通过HiSACC和ReLACE技术自动解析异构监管文本并与内部政策对齐，显著提升回答质量并降低幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 跨国制药公司面临日益频繁和复杂的监管更新负担，合规团队需要手动解读不同司法管辖区、格式和机构的规则，成本高且易出错。

Method: 系统通过安全管道摄入异构文档源，采用两个核心组件：1) HiSACC（分层语义聚合上下文分块）将长文档语义分割为连贯单元；2) ReLACE（监管列表自适应交叉编码器）基于开源模型构建的领域自适应交叉编码器，联合建模用户查询和检索候选以改进排序相关性。

Result: 企业环境评估显示，RegGuard在相关性、事实依据和上下文聚焦方面显著提升回答质量，同时大幅降低幻觉风险。系统架构具备可审计性和可追溯性。

Conclusion: RegGuard为具有严格合规要求的领域提供高效解决方案，系统架构设计支持审计追踪、访问控制和增量索引，能够快速响应不断变化的文档源。

Abstract: The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.

</details>


### [408] [Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation](https://arxiv.org/abs/2601.17923)
*Ali Najar*

Main category: cs.AI

Relevance: 35.0

TL;DR: 论文提出了一种基于技能图的分层课程学习方法，用于在复杂实时控制环境（Dark Souls III）中训练终身学习智能体，通过分解控制任务为可重用技能组件，支持选择性微调以适应环境变化。


<details>
  <summary>Details</summary>
Motivation: 终身学习智能体需要在不断变化的环境中扩展能力，而不需要从头开始重新训练或覆盖先前学习的行为。当前方法在处理复杂实时控制任务时面临样本效率低和适应性差的问题。

Method: 将战斗控制表示为有向技能图，采用分层课程学习训练其组件。将控制分解为五个可重用技能：相机控制、目标锁定、移动、闪避和治疗-攻击决策策略，每个技能针对特定职责进行优化。

Result: 技能分解提高了样本效率，减少了单个策略的负担。当环境从第一阶段切换到第二阶段时，只需要微调部分技能（两个技能）就能快速恢复性能，而上游技能保持可迁移性。

Conclusion: 技能图课程学习结合选择性微调为复杂实时环境中进化、持续学习的智能体提供了实用途径，支持终身学习而不需要完全重新训练。

Abstract: Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.

</details>


### [409] [Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules](https://arxiv.org/abs/2601.18716)
*Naeyma N. Islam,Thomas R. Caulfield*

Main category: cs.AI

Relevance: 35.0

TL;DR: 该论文提出了一种AI辅助的药物设计方法，通过E3连接酶导向的分子胶促进Aβ-42的靶向降解，用于阿尔茨海默病治疗。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病中Aβ-42的病理积累导致突触功能障碍和神经退行性变。虽然细胞外淀粉样斑块研究较多，但越来越多的证据表明细胞内Aβ-42是疾病进展的早期毒性驱动因素。因此需要开发靶向降解Aβ-42的新疗法。

Method: 1. 系统评估Aβ-42与三种E3连接酶（CRBN、VHL、MDM2）的三元复合物形成潜力，使用基于结构的建模、ADMET筛选和对接分析。
2. 开发Ligase-Conditioned Junction Tree Variational Autoencoder（LC-JT-VAE）生成连接酶特异性小分子，结合蛋白质序列嵌入和扭转角感知的分子图。

Result: 生成模型能够产生化学有效、新颖且靶向特异性的分子胶，能够促进Aβ-42的降解。这种集成方法为设计UPS靶向疗法提供了有前景的框架。

Conclusion: 该AI辅助药物设计方法为神经退行性疾病提供了有前景的UPS靶向治疗框架，通过分子胶促进Aβ-42的靶向降解。

Abstract: Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.

</details>


### [410] [Breaking Task Impasses Quickly: Adaptive Neuro-Symbolic Learning for Open-World Robotics](https://arxiv.org/abs/2601.16985)
*Pierrick Lorang*

Main category: cs.RO

Relevance: 35.0

TL;DR: 提出一种神经符号框架，结合层次抽象、任务与运动规划(TAMP)和强化学习，实现机器人快速适应开放世界中的意外新情况。


<details>
  <summary>Details</summary>
Motivation: 开放世界环境中意外新情况的适应是自主系统的主要挑战。现有混合规划与强化学习方法存在样本效率低、适应速度慢和灾难性遗忘等问题。

Method: 神经符号框架整合层次抽象、任务与运动规划(TAMP)和强化学习。结合符号目标导向学习和基于世界模型的探索，促进对环境变化的快速适应。

Result: 在机器人操作和自动驾驶任务中验证，相比最先进的混合方法，实现了更快的收敛速度、更好的样本效率和更强的鲁棒性。

Conclusion: 该框架展示了在实际部署中应对开放世界新情况的潜力，为自主系统快速适应提供了有效解决方案。

Abstract: Adapting to unforeseen novelties in open-world environments remains a major challenge for autonomous systems. While hybrid planning and reinforcement learning (RL) approaches show promise, they often suffer from sample inefficiency, slow adaptation, and catastrophic forgetting. We present a neuro-symbolic framework integrating hierarchical abstractions, task and motion planning (TAMP), and reinforcement learning to enable rapid adaptation in robotics. Our architecture combines symbolic goal-oriented learning and world model-based exploration to facilitate rapid adaptation to environmental changes. Validated in robotic manipulation and autonomous driving, our approach achieves faster convergence, improved sample efficiency, and superior robustness over state-of-the-art hybrid methods, demonstrating its potential for real-world deployment.

</details>


### [411] [From Noise to Insights: Enhancing Supply Chain Decision Support through AI-Based Survey Integrity Analytics](https://arxiv.org/abs/2601.17005)
*Bhubalan Mani*

Main category: cs.CY

Relevance: 35.0

TL;DR: 该研究提出了一种基于监督机器学习的轻量级AI框架，用于过滤供应链调查中的不可靠输入，在99个行业响应数据集上实现了92.0%的准确率。


<details>
  <summary>Details</summary>
Motivation: 供应链决策中调查数据的可靠性至关重要，特别是在评估AI驱动工具（如安全库存优化系统）的准备度时。然而，调查常常吸引低质量或虚假响应，这会降低分析结果的准确性。

Method: 采用监督机器学习方法，收集了99个行业响应数据集，通过人工标注基于逻辑不一致性和响应模式识别虚假响应。经过预处理和标签编码后，训练了随机森林和基线模型（逻辑回归、XGBoost）来区分真实和虚假响应。

Result: 最佳模型达到了92.0%的准确率，相比初步研究有显著改进，证明了AI在过滤不可靠调查响应方面的有效性。

Conclusion: 尽管存在局限性，但研究结果表明将AI集成到调查流程中是可行的，为供应链研究中的数据完整性提供了可扩展的解决方案，特别是在产品发布和技术采用阶段。

Abstract: The reliability of survey data is crucial in supply chain decision-making, particularly when evaluating readiness for AI-driven tools such as safety stock optimization systems. However, surveys often attract low-effort or fake responses that degrade the accuracy of derived insights. This study proposes a lightweight AI-based framework for filtering unreliable survey inputs using a supervised machine learning approach. In this expanded study, a larger dataset of 99 industry responses was collected, with manual labeling to identify fake responses based on logical inconsistencies and response patterns. After preprocessing and label encoding, both Random Forest and baseline models (Logistic Regression, XGBoost) were trained to distinguish genuine from fake responses. The best-performing model achieved an 92.0% accuracy rate, demonstrating improved detection compared to the pilot study. Despite limitations, the results highlight the viability of integrating AI into survey pipelines and provide a scalable solution for improving data integrity in supply chain research, especially during product launch and technology adoption phases.

</details>


### [412] [AI-based System for Transforming text and sound to Educational Videos](https://arxiv.org/abs/2601.17022)
*M. E. ElAlami,S. M. Khater,M. El. R. Rehan*

Main category: cs.MM

Relevance: 35.0

TL;DR: 提出基于GAN的教育视频生成方法，通过语音识别、关键词提取与图像生成、视频合成三阶段流程，实现从文本/语音到完整教育视频的生成。


<details>
  <summary>Details</summary>
Motivation: 当前从文本或语音条件输入生成教育视频仍具挑战性，需要开发能够生成高质量、语义对齐的教育视频的系统。

Method: 三阶段框架：1) 语音识别转录输入；2) 关键词提取并使用CLIP和扩散模型生成相关图像；3) 图像合成视频并集成音频。

Result: 与TGAN、MoCoGAN、TGANS-C等系统相比，FID分数达到28.75%，显示视觉质量提升并优于现有方法。

Conclusion: 提出的GAN框架能够有效生成高质量教育视频，在视觉质量和语义对齐方面优于现有方法。

Abstract: Technological developments have produced methods that can generate educational videos from input text or sound. Recently, the use of deep learning techniques for image and video generation has been widely explored, particularly in education. However, generating video content from conditional inputs such as text or speech remains a challenging area. In this paper, we introduce a novel method to the educational structure, Generative Adversarial Network (GAN), which develop frame-for-frame frameworks and are able to create full educational videos. The proposed system is structured into three main phases In the first phase, the input (either text or speech) is transcribed using speech recognition. In the second phase, key terms are extracted and relevant images are generated using advanced models such as CLIP and diffusion models to enhance visual quality and semantic alignment. In the final phase, the generated images are synthesized into a video format, integrated with either pre-recorded or synthesized sound, resulting in a fully interactive educational video. The proposed system is compared with other systems such as TGAN, MoCoGAN, and TGANS-C, achieving a Fréchet Inception Distance (FID) score of 28.75%, which indicates improved visual quality and better over existing methods.

</details>


### [413] [Failing on Bias Mitigation: Investigating Why Predictive Models Struggle with Government Data](https://arxiv.org/abs/2601.17054)
*Hongbo Bo,Jingyu Hu,Debbie Watson,Weiru Liu*

Main category: cs.CY

Relevance: 35.0

TL;DR: 研究发现政府数据中的偏见难以通过标准公平性缓解技术消除，主要原因是数据本身的结构和历史问题，而非模型架构或指标选择缺陷。


<details>
  <summary>Details</summary>
Motivation: AI支持的政府服务存在偏见和不公平风险，引发伦理和法律关切。研究旨在理解为何广泛采用的偏见缓解技术在政府数据上经常失效，而非审计已部署系统。

Method: 以布里斯托市议会犯罪率预测为案例研究，比较多种综合模型和公平性方法，通过实验分析偏见缓解效果，并进行交叉公平性实验。

Result: 实验一致显示偏见缓解方法无法克服政府数据中嵌入的不公平性，偏见源于数据集的结构和历史。发现数据分布偏移、历史偏见积累和数据发布延迟是主要不公平来源，且针对单一敏感特征的公平性分析存在盲点。

Conclusion: 政府数据中的偏见可能即使采用标准缓解方法也会持续存在，研究结果为早期预警，强调需要更全面的公平性分析方法。

Abstract: The potential for bias and unfairness in AI-supporting government services raises ethical and legal concerns. Using crime rate prediction with the Bristol City Council data as a case study, we examine how these issues persist. Rather than auditing real-world deployed systems, our goal is to understand why widely adopted bias mitigation techniques often fail when applied to government data. Our findings reveal that bias mitigation approaches applied to government data are not always effective -- not because of flaws in model architecture or metric selection, but due to the inherent properties of the data itself. Through comparing a set of comprehensive models and fairness methods, our experiments consistently show that the mitigation efforts cannot overcome the embedded unfairness in the data -- further reinforcing that the origin of bias lies in the structure and history of government datasets. We then explore the reasons for the mitigation failures in predictive models on government data and highlight the potential sources of unfairness posed by data distribution shifts, the accumulation of historical bias, and delays in data release. We also discover the limitations of the blind spots in fairness analysis and bias mitigation methods when only targeting a single sensitive feature through a set of intersectional fairness experiments. Although this study is limited to one city, the findings are highly suggestive, which can contribute to an early warning that biases in government data may persist even with standard mitigation methods.

</details>


### [414] [SonoEdit: Null-Space Constrained Knowledge Editing for Pronunciation Correction in LLM-Based TTS](https://arxiv.org/abs/2601.17086)
*Ayush Pratap Singh,Harshit Singh,Nityanand Mathur,Akshat Mandloi,Sudarshan Kamath*

Main category: cs.SD

Relevance: 35.0

TL;DR: SonoEdit：一种模型编辑技术，通过单次参数更新修正预训练TTS模型中的发音错误，无需重新训练，特别针对低资源专有名词的发音问题。


<details>
  <summary>Details</summary>
Motivation: 神经TTS系统在处理低资源专有名词（特别是非英语名称、品牌和地名）时存在系统性发音错误，这是由于这些词汇在主要英语训练语料中代表性不足。现有解决方案依赖昂贵的多语言数据收集、监督微调或手动音标标注，限制了TTS系统在语言多样化环境中的部署。

Method: 提出Null-Space Pronunciation Editing方法：1）使用Acoustic Causal Tracing识别负责文本到发音映射的Transformer层；2）应用Null-Space Constrained Editing计算封闭形式的权重更新，修正目标发音，同时保持与通用语音生成子空间的数学正交性。该方法通过单次参数更新修改特定词汇的发音，同时可证明地保留所有其他模型行为。

Result: 该方法能够精确修正目标词汇的发音，同时保证在保留的语音语料上实现零一阶变化，即在不影响其他语音生成能力的情况下，将模型的声学输出引导至期望的发音示例。

Conclusion: SonoEdit提供了一种高效、精确的TTS模型发音修正方法，无需昂贵的重新训练或数据收集，为TTS系统在语言多样化环境中的部署提供了实用解决方案。

Abstract: Neural text-to-speech (TTS) systems systematically mispronounce low-resource proper nouns, particularly non-English names, brands, and geographic locations, due to their underrepresentation in predominantly English training corpora. Existing solutions typically rely on expensive multilingual data collection, supervised finetuning, or manual phonetic annotation, which limits the deployment of TTS systems in linguistically diverse settings. We introduce SonoEdit, a model editing technique that surgically corrects pronunciation errors in pre-trained TTS models without retraining. Instead of costly finetuning or explicit phoneme injection, we propose a parsimonious alternative based on Null-Space Pronunciation Editing, which performs a single-shot parameter update to modify the pronunciation of specific words while provably preserving all other model behavior. We first adapt Acoustic Causal Tracing to identify the Transformer layers responsible for text-to-pronunciation mapping. We then apply Null-Space Constrained Editing to compute a closed-form weight update that corrects the target pronunciation while remaining mathematically orthogonal to the subspace governing general speech generation. This constrained update steers the model's acoustic output toward a desired pronunciation exemplar while guaranteeing zero first-order change on a preserved speech corpus.

</details>


### [415] [Benchmarking Deep Learning-Based Reconstruction Methods for Photoacoustic Computed Tomography with Clinically Relevant Synthetic Datasets](https://arxiv.org/abs/2601.17165)
*Panpan Chen,Seonyeong Park,Gangwon Jeong,Refik Mert Cam,Umberto Villa,Mark A. Anastasio*

Main category: physics.med-ph

Relevance: 35.0

TL;DR: 提出用于光声计算机断层扫描（PACT）中基于深度学习的声学反演方法的基准测试框架，包括开源合成数据集和评估策略，揭示传统图像质量指标在临床相关性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前PACT中基于深度学习的图像重建方法缺乏标准化数据集，评估依赖传统图像质量指标，这些指标可能缺乏临床相关性，阻碍了公平比较和方法可靠性评估。

Method: 提出基准测试框架，包括：1）开源、解剖学上合理的合成数据集（包含11,000+个二维随机乳腺对象和临床相关病变）；2）结合传统和基于任务的图像质量评估策略；3）进行初步基准研究比较基于深度学习和基于物理的重建方法。

Result: 基准研究表明：某些基于深度学习的方法在传统指标上表现良好，但无法准确恢复病变，揭示传统指标的不足；框架能够全面定量比较重建性能，发现基于深度学习方法的局限性。

Conclusion: 提出的基准测试框架通过整合临床相关合成数据集和严格评估协议，实现了对2D PACT中基于深度学习的声学反演方法的系统比较，促进可重复、客观的评估以及方法开发和系统优化。

Abstract: Deep learning (DL)-based image reconstruction methods for photoacoustic computed tomography (PACT) have developed rapidly in recent years. However, most existing methods have not employed standardized datasets, and their evaluations rely on traditional image quality (IQ) metrics that may lack clinical relevance. The absence of a standardized framework for clinically meaningful IQ assessment hinders fair comparison and raises concerns about the reproducibility and reliability of reported advancements in PACT. A benchmarking framework is proposed that provides open-source, anatomically plausible synthetic datasets and evaluation strategies for DL-based acoustic inversion methods in PACT. The datasets each include over 11,000 two-dimensional (2D) stochastic breast objects with clinically relevant lesions and paired measurements at varying modeling complexity. The evaluation strategies incorporate both traditional and task-based IQ measures to assess fidelity and clinical utility. A preliminary benchmarking study is conducted to demonstrate the framework's utility by comparing DL-based and physics-based reconstruction methods. The benchmarking study demonstrated that the proposed framework enabled comprehensive, quantitative comparisons of reconstruction performance and revealed important limitations in certain DL-based methods. Although they performed well according to traditional IQ measures, they often failed to accurately recover lesions. This highlights the inadequacy of traditional metrics and motivates the need for task-based assessments. The proposed benchmarking framework enables systematic comparisons of DL-based acoustic inversion methods for 2D PACT. By integrating clinically relevant synthetic datasets with rigorous evaluation protocols, it enables reproducible, objective assessments and facilitates method development and system optimization in PACT.

</details>


### [416] [TrojanGYM: A Detector-in-the-Loop LLM for Adaptive RTL Hardware Trojan Insertion](https://arxiv.org/abs/2601.17178)
*Saideep Sreekumar,Zeng Wang,Akashdeep Saha,Weihua Xiao,Minghao Shao,Muhammad Shafique,Ozgur Sinanoglu,Ramesh Karri,Johann Knechtel*

Main category: cs.CR

Relevance: 35.0

TL;DR: TrojanGYM是一个基于LLM的自动化硬件木马生成框架，通过多智能体协作生成多样化的硬件木马变体，用于暴露现有检测器的盲点并提升检测器的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的硬件木马检测器容易过拟合到有限的触发/负载模式和小规模基准测试，无法应对真实场景中多样化的木马变体。需要一种系统化的方法来生成更全面、更具挑战性的测试基准，以评估和提升检测器的鲁棒性。

Method: 1. 使用多LLM智能体（GPT-4、LLaMA-3.3-70B、Gemini-2.5Pro）协作生成硬件木马设计
2. 基于高层规范自动生成RTL级修改，实现多样化触发机制和负载功能
3. 反馈驱动的基准生成循环：结合约束感知的语法检查和GNN检测器反馈，迭代优化木马生成策略
4. 提出Robust-GNN4TJ：改进的GNN检测器，增强图提取、训练鲁棒性和预测可靠性

Result: 1. TrojanGYM在SRAM、AES-128和UART设计上成功生成多样化且功能正确的硬件木马
2. 生成的木马对现代GNN检测器达到高达83.33%的逃避率
3. Robust-GNN4TJ在最具挑战性的TrojanGYM基准上将检测率从0%提升到60%
4. 揭示了现有TrustHub风格基准无法暴露的检测器鲁棒性缺陷

Conclusion: TrojanGYM框架能够系统化地生成多样化硬件木马，有效暴露现有检测器的盲点。结合改进的Robust-GNN4TJ检测器，为硬件安全领域提供了更全面的评估基准和更鲁棒的检测方案。

Abstract: Hardware Trojans (HTs) remain a critical threat because learning-based detectors often overfit to narrow trigger/payload patterns and small, stylized benchmarks. We introduce TrojanGYM, an agentic, LLM-driven framework that automatically curates HT insertions to expose detector blind spots while preserving design correctness. Given high-level HT specifications, a suite of cooperating LLM agents (instantiated with GPT-4, LLaMA-3.3-70B, and Gemini-2.5Pro) proposes and refines RTL modifications that realize diverse triggers and payloads without impacting normal functionality. TrojanGYM implements a feedback-driven benchmark generation loop co-designed with HT detectors, in which constraint-aware syntactic checking and GNN-based HT detectors provide feedback that iteratively refines HT specifications and insertion strategies to better surface detector blind spots. We further propose Robust-GNN4TJ, a new implementation of the GNN4TJ with improved graph extraction, training robustness, and prediction reliability, especially on LLM-generated HT designs. On the most challenging TrojanGYM-generated benchmarks, Robust-GNN4TJ raises HT detection rates from 0% to 60% relative to a prior GNN-based detector. We instantiate TrojanGYM on SRAM, AES-128, and UART designs at RTL level, and show that it systematically produces diverse, functionally correct HTs that reach up to 83.33% evasion rates against modern GNN-based detectors, revealing robustness gaps that are not apparent when these detectors are evaluated solely on existing TrustHub-style benchmarks. Post peer-review, we will release all codes and artifacts.

</details>


### [417] [FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search](https://arxiv.org/abs/2601.17333)
*Lalit Pant,Shivang Nagar*

Main category: cs.IR

Relevance: 35.0

TL;DR: 本文提出了一个针对金融知识搜索的现代自然语言查询系统技术蓝图，通过NLP、搜索工程和向量数据模型提升金融数据检索的精度和召回率。


<details>
  <summary>Details</summary>
Motivation: 传统金融知识搜索方法存在精度和召回率不足的问题，难以有效连接分散的金融对象、事件和关系。自然语言查询系统可以提升用户体验，实现更深入的数据洞察。

Method: 结合自然语言处理、搜索工程和向量数据模型，设计了离线索引和在线检索的架构组件，针对金融数据集的独特需求进行优化，包括实体识别、相关性排序和数据新鲜度等挑战。

Result: 提出的NLQ系统相比传统方法在精度和召回率上有显著提升，能够高效连接金融对象、事件和关系，为金融服务提供增强的知识搜索能力。

Conclusion: 该研究为金融领域的自然语言查询系统提供了完整的技术蓝图和架构设计，展示了在实际金融服务场景中的应用价值，并指出了未来的优化方向。

Abstract: Natural Language Query (NLQ) allows users to search and interact with information systems using plain, human language instead of structured query syntax. This paper presents a technical blueprint on the design of a modern NLQ system tailored to financial knowledge search. The introduction of NLQ not only enhances the precision and recall of the knowledge search compared to traditional methods, but also facilitates deeper insights by efficiently linking disparate financial objects, events, and relationships. Using core constructs from natural language processing, search engineering, and vector data models, the proposed system aims to address key challenges in discovering, relevance ranking, data freshness, and entity recognition intrinsic to financial data retrieval. In this work, we detail the unique requirements of NLQ for financial datasets and documents, outline the architectural components for offline indexing and online retrieval, and discuss the real-world use cases of enhanced knowledge search in financial services. We delve into the theoretical underpinnings and experimental evidence supporting our proposed architecture, ultimately providing a comprehensive analysis on the subject matter. We also provide a detailed elaboration of our experimental methodology, the data used, the results and future optimizations in this study.

</details>


### [418] [Prompt and Circumstances: Evaluating the Efficacy of Human Prompt Inference in AI-Generated Art](https://arxiv.org/abs/2601.17379)
*Khoi Trinh,Scott Seidenberger,Joseph Spracklen,Raveen Wijewickrama,Bimal Viswanath,Murtuza Jadliwala,Anindya Maiti*

Main category: cs.CR

Relevance: 35.0

TL;DR: 研究调查AI艺术提示市场中的知识产权问题，通过人类实验和AI辅助方法评估从AI生成图像推断原始提示的准确性，发现人类和AI推断的提示效果均不如原始提示。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成艺术的发展，出现了提示词市场，市场声称提示词是知识产权。但人类和AI工具可能通过公开的样本图像推断出提示词，这引发了提示词是否真正构成知识产权的疑问。

Method: 1) 评估人类仅通过观察AI生成图像推断原始提示的准确性；2) 探索通过大语言模型结合人类和AI推断的提示来改进提示质量的可能性；3) 进行人类主体研究，深入分析人机协作的提示推断。

Result: 人类推断的提示和结合人机推断的提示能生成中等相似度的图像，但效果不如原始提示。使用建议的合并技术结合人类和AI推断的提示，性能并未超过纯人类推断的提示。

Conclusion: 提示市场声称的提示词知识产权保护存在漏洞，因为人类和AI都能从公开图像中推断出相似提示。当前的人机协作推断方法未能显著提升效果，提示词的知识产权地位值得商榷。

Abstract: The emerging field of AI-generated art has witnessed the rise of prompt marketplaces, where creators can purchase, sell, or share prompts to generate unique artworks. These marketplaces often assert ownership over prompts, claiming them as intellectual property. This paper investigates whether concealed prompts sold on prompt marketplaces can be considered bona fide intellectual property, given that humans and AI tools may be able to infer the prompts based on publicly advertised sample images accompanying each prompt on sale. Specifically, our study aims to assess (i) how accurately humans can infer the original prompt solely by examining an AI-generated image, with the goal of generating images similar to the original image, and (ii) the possibility of improving upon individual human and AI prompt inferences by crafting combined human and AI prompts with the help of a large language model. Although previous research has explored AI-driven prompt inference and protection strategies, our work is the first to incorporate a human subject study and examine collaborative human-AI prompt inference in depth. Our findings indicate that while prompts inferred by humans and prompts inferred through a combined human and AI effort can generate images with a moderate level of similarity, they are not as successful as using the original prompt. Moreover, combining human- and AI-inferred prompts using our suggested merging techniques did not improve performance over purely human-inferred prompts.

</details>


### [419] [Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval](https://arxiv.org/abs/2601.18747)
*Amir Aavani*

Main category: cs.IR

Relevance: 35.0

TL;DR: 提出基于有向无环图(DAG)的检索语言$\mathcal{L}_R$，证明其精确捕获复杂度类$\mathbf{P}$，并设计高效评估算法ComputePN解决神经符号推理工作流中的效率困境。


<details>
  <summary>Details</summary>
Motivation: 现代信息检索正从简单文档过滤转向复杂的神经符号推理工作流，但当前检索架构在处理逻辑和算术约束时面临效率困境：基于迭代器的引擎无法高效执行复杂嵌套逻辑图，而递归方法则面临内存消耗过高的问题。

Method: 1) 定义基于有向无环图(DAG)的形式化检索语言$\mathcal{L}_R$；2) 证明$\mathcal{L}_R$精确捕获复杂度类$\mathbf{P}$；3) 提出ComputePN评估算法，结合原生DAG遍历和内存高效的"正-负"响应机制。

Result: 建立了将搜索索引转化为通用计算引擎的理论基础，使检索系统能够高效评估任何$\mathcal{L}_R$中的查询，解决了复杂神经符号推理工作流中的计算效率问题。

Conclusion: 通过形式化检索语言$\mathcal{L}_R$和高效评估算法ComputePN，为检索系统提供了理论基础，使其能够作为通用计算引擎处理多项式时间属性，推动信息检索向复杂推理工作流发展。

Abstract: Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.
  In this paper, we propose that a retrieval engine must be capable of ``Capturing $\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\mathbf{P}$. We introduce \texttt{ComputePN}, a novel evaluation algorithm that makes $\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \texttt{ComputePN} ensures the efficient evaluation of any query in $\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.

</details>


### [420] [Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System](https://arxiv.org/abs/2601.18785)
*Tiffany Wang,Yuqian Sun,Yi Wang,Melissa Roemmele,John Joon Young Chung,Max Kreminski*

Main category: cs.HC

Relevance: 35.0

TL;DR: Dramamancer系统利用大语言模型将作者创建的故事模式转化为玩家驱动的游戏体验，探索交互式叙事中作者意图与玩家能动性之间的新范式。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的兴起，交互式叙事领域出现了新的可能性，可以更好地桥接作者意图和玩家能动性。传统交互式叙事系统往往难以平衡预设叙事结构和玩家自由选择，而LLM为解决这一挑战提供了新途径。

Method: 开发了Dramamancer系统，该系统使用大语言模型将作者创建的故事模式（story schemas）转化为玩家驱动的游戏体验。论文概述了相关的设计技术和评估考量。

Result: 提出了一个利用LLM实现交互式叙事的新系统框架，展示了如何通过LLM将结构化故事模式动态转化为个性化游戏体验，为交互式叙事设计提供了新方法。

Conclusion: 大语言模型为交互式叙事开辟了新范式，能够有效桥接作者意图和玩家能动性。Dramamancer系统展示了这一方向的潜力，但需要进一步的设计技术和评估方法来完善。

Abstract: The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system.

</details>


### [421] [GenAI-Net: A Generative AI Framework for Automated Biomolecular Network Design](https://arxiv.org/abs/2601.17582)
*Maurice Filo,Nicolò Rossi,Zhou Fang,Mustafa Khammash*

Main category: q-bio.QM

Relevance: 35.0

TL;DR: GenAI-Net：一个生成式AI框架，用于自动化设计化学反应网络（CRNs），通过耦合反应提议代理与基于仿真的评估，实现从行为规范到网络拓扑的自动发现。


<details>
  <summary>Details</summary>
Motivation: 生物分子网络是合成生物学新兴技术的基础，但设计实现特定动态功能的化学反应网络目前主要依赖人工方法。从行为规范反向发现网络拓扑和动力学参数面临巨大挑战，需要人类专家在庞大的非线性、随机动态空间中进行探索。

Method: GenAI-Net框架耦合了一个提议反应的代理与基于仿真的评估系统。用户指定目标函数，框架通过生成式AI自动探索网络拓扑和参数空间，产生多样化的电路候选方案。

Result: GenAI-Net能够高效生成新颖、拓扑多样的解决方案，涵盖多种设计任务：剂量响应、复杂逻辑门、分类器、振荡器、确定性及随机设置下的鲁棒完美适应（包括噪声抑制）。

Conclusion: 该框架通过将规范转化为电路候选家族和可重用模块，为可编程生物分子电路设计提供通用路径，加速从期望功能到可实施机制的转化。

Abstract: Biomolecular networks underpin emerging technologies in synthetic biology-from robust biomanufacturing and metabolic engineering to smart therapeutics and cell-based diagnostics-and also provide a mechanistic language for understanding complex dynamics in natural and ecological systems. Yet designing chemical reaction networks (CRNs) that implement a desired dynamical function remains largely manual: while a proposed network can be checked by simulation, the reverse problem of discovering a network from a behavioral specification is difficult, requiring substantial human insight to navigate a vast space of topologies and kinetic parameters with nonlinear and possibly stochastic dynamics. Here we introduce GenAI-Net, a generative AI framework that automates CRN design by coupling an agent that proposes reactions to simulation-based evaluation defined by a user-specified objective. GenAI-Net efficiently produces novel, topologically diverse solutions across multiple design tasks, including dose responses, complex logic gates, classifiers, oscillators, and robust perfect adaptation in deterministic and stochastic settings (including noise reduction). By turning specifications into families of circuit candidates and reusable motifs, GenAI-Net provides a general route to programmable biomolecular circuit design and accelerates the translation from desired function to implementable mechanisms.

</details>


### [422] [Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance](https://arxiv.org/abs/2601.17690)
*Ziling Gong,Yunyan Ouyang,Iram Kamdar,Melody Ma,Hongjie Chen,Franck Dernoncourt,Ryan A. Rossi,Nesreen K. Ahmed*

Main category: cs.SD

Relevance: 35.0

TL;DR: 该论文研究了音频指纹识别中片段长度对性能的影响，发现0.5秒短片段通常表现更好，并评估了LLM在推荐最佳片段长度方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现代神经音频指纹识别方法通常使用固定时长的短音频片段，但片段长度的选择往往是启发式的，缺乏深入研究。作者旨在系统研究片段长度如何影响音频指纹识别性能，为大规模神经音频检索系统提供实用的片段时长选择指导。

Method: 扩展现有的神经指纹识别架构以支持不同的片段长度，评估不同片段长度和查询时长下的检索准确率。同时评估了三种LLM（包括GPT-5-mini）在推荐最佳片段长度方面的能力。

Result: 短片段长度（0.5秒）通常获得更好的性能。在LLM评估中，GPT-5-mini在五个考虑因素中始终给出最佳建议，表现优于其他两种LLM。

Conclusion: 研究为大规模神经音频检索系统中的片段时长选择提供了实用指导，并展示了LLM在推荐最佳片段长度方面的潜力。

Abstract: Audio fingerprinting provides an identifiable representation of acoustic signals, which can be later used for identification and retrieval systems. To obtain a discriminative representation, the input audio is usually segmented into shorter time intervals, allowing local acoustic features to be extracted and analyzed. Modern neural approaches typically operate on short, fixed-duration audio segments, yet the choice of segment duration is often made heuristically and rarely examined in depth. In this paper, we study how segment length affects audio fingerprinting performance. We extend an existing neural fingerprinting architecture to adopt various segment lengths and evaluate retrieval accuracy across different segment lengths and query durations. Our results show that short segment lengths (0.5-second) generally achieve better performance. Moreover, we evaluate LLM capacity in recommending the best segment length, which shows that GPT-5-mini consistently gives the best suggestions across five considerations among three studied LLMs. Our findings provide practical guidance for selecting segment duration in large-scale neural audio retrieval systems.

</details>


### [423] [Diffusion Model-based Reinforcement Learning for Version Age of Information Scheduling: Average and Tail-Risk-Sensitive Control](https://arxiv.org/abs/2601.18069)
*Haoyuan Pan,Sizhao Chen,Zhaorui Wang,Tse-Tin Chan*

Main category: cs.NI

Relevance: 35.0

TL;DR: 本文提出两种深度强化学习算法用于多用户无线系统中的版本信息年龄调度：D2SAC用于最小化平均VAoI，RS-D3SAC用于尾部风险敏感优化，在满足传输成本约束下同时优化平均性能和尾部风险。


<details>
  <summary>Details</summary>
Motivation: 在实时无线系统中，现有VAoI调度方法主要关注最小化平均版本信息年龄，忽略了罕见但严重的语义陈旧事件，这些事件在随机数据包到达和不可靠信道下会损害系统可靠性。

Method: 1) 将平均VAoI最小化问题建模为约束马尔可夫决策过程，提出基于深度扩散的Soft Actor-Critic算法(D2SAC)；2) 提出风险敏感的深度分布扩散Soft Actor-Critic算法(RS-D3SAC)，结合扩散actor和基于分位数的分布critic，通过条件风险价值进行尾部风险优化。

Result: 仿真显示D2SAC能有效降低平均VAoI，而RS-D3SAC在不牺牲平均性能的情况下显著降低CVaR。尾部风险降低主要来自分布critic，扩散actor提供补充优化以稳定和丰富策略决策。

Conclusion: RS-D3SAC算法通过结合扩散actor和分布critic，为多用户无线系统提供了鲁棒且风险感知的VAoI调度解决方案，能有效处理尾部风险事件。

Abstract: Ensuring timely and semantically accurate information delivery is critical in real-time wireless systems. While Age of Information (AoI) quantifies temporal freshness, Version Age of Information (VAoI) captures semantic staleness by accounting for version evolution between transmitters and receivers. Existing VAoI scheduling approaches primarily focus on minimizing average VAoI, overlooking rare but severe staleness events that can compromise reliability under stochastic packet arrivals and unreliable channels. This paper investigates both average-oriented and tail-risk-sensitive VAoI scheduling in a multi-user status update system with long-term transmission cost constraints. We first formulate the average VAoI minimization problem as a constrained Markov decision process and introduce a deep diffusion-based Soft Actor-Critic (D2SAC) algorithm. By generating actions through a diffusion-based denoising process, D2SAC enhances policy expressiveness and establishes a strong baseline for mean performance. Building on this foundation, we put forth RS-D3SAC, a risk-sensitive deep distributional diffusion-based Soft Actor-Critic algorithm. RS-D3SAC integrates a diffusion-based actor with a quantile-based distributional critic, explicitly modeling the full VAoI return distribution. This enables principled tail-risk optimization via Conditional Value-at-Risk (CVaR) while satisfying long-term transmission cost constraints. Extensive simulations show that, while D2SAC reduces average VAoI, RS-D3SAC consistently achieves substantial reductions in CVaR without sacrificing mean performance. The dominant gain in tail-risk reduction stems from the distributional critic, with the diffusion-based actor providing complementary refinement to stabilize and enrich policy decisions, highlighting their effectiveness for robust and risk-aware VAoI scheduling in multi-user wireless systems.

</details>


### [424] [The Limits of AI Data Transparency Policy: Three Disclosure Fallacies](https://arxiv.org/abs/2601.18127)
*Judy Hanwen Shen,Ken Liu,Angelina Wang,Sarah H. Cen,Andy K. Zhang,Caroline Meinhardt,Daniel Zhang,Kevin Klyman,Rishi Bommasani,Daniel E. Ho*

Main category: cs.CY

Relevance: 35.0

TL;DR: 该论文分析了当前AI数据透明度政策的缺陷，指出了三个常见误区：规范差距、执行差距和影响差距，并基于社会科学研究提出了更有效的透明度路径。


<details>
  <summary>Details</summary>
Motivation: 当前AI数据透明度政策（类似"营养标签"）虽然旨在解决数据质量、隐私和版权等问题，但往往无法实现预期目标。作者认为这些政策缺乏对有效披露机制的研究考虑，需要从制度层面分析其缺陷。

Method: 采用制度视角分析，识别了AI数据披露政策实施中的三个常见误区：1）规范差距（目标与必要披露之间的不匹配）；2）执行差距（纸面要求与实际合规之间的脱节）；3）影响差距（披露信息与开发者实践/公众理解改变之间的鸿沟）。基于社会科学对透明度的研究进行分析。

Result: 识别了当前AI数据透明度政策的三个系统性缺陷，并提出了建设性的透明度路径，强调需要超越象征性措施，实现真正有效的透明度机制。

Conclusion: 当前的AI数据透明度政策存在根本性缺陷，需要基于社会科学研究重新设计，从象征性披露转向能够真正影响开发者实践和公众理解的有效透明度机制。

Abstract: Data transparency has emerged as a rallying cry for addressing concerns about AI: data quality, privacy, and copyright chief among them. Yet while these calls are crucial for accountability, current transparency policies often fall short of their intended aims. Similar to nutrition facts for food, policies aimed at nutrition facts for AI currently suffer from a limited consideration of research on effective disclosures. We offer an institutional perspective and identify three common fallacies in policy implementations of data disclosures for AI. First, many data transparency proposals exhibit a specification gap between the stated goals of data transparency and the actual disclosures necessary to achieve such goals. Second, reform attempts exhibit an enforcement gap between required disclosures on paper and enforcement to ensure compliance in fact. Third, policy proposals manifest an impact gap between disclosed information and meaningful changes in developer practices and public understanding. Informed by the social science on transparency, our analysis identifies affirmative paths for transparency that are effective rather than merely symbolic.

</details>


### [425] [Explaining Synergistic Effects in Social Recommendations](https://arxiv.org/abs/2601.18151)
*Yicong Li,Shan Jin,Qi Liu,Shuo Wang,Jiaying Liu,Shuo Yu,Qiang Zhang,Kuanjiu Zhou,Feng Xia*

Main category: cs.SI

Relevance: 35.0

TL;DR: 该论文提出SemExplainer，一种解释社交推荐系统中协同效应的新方法，通过识别体现协同效应的子图来增强推荐可解释性。


<details>
  <summary>Details</summary>
Motivation: 社交推荐系统中，多个社交网络间的非线性协同效应不透明，阻碍用户理解推荐如何利用多样化信息，从而降低可解释性。现有解释方法只能识别社交网络中显著影响推荐的拓扑信息，无法进一步解释这些信息间的协同效应。

Method: 提出SemExplainer框架：1) 从多视角社交网络中提取解释性子图，生成初步重要性解释；2) 开发条件熵优化策略最大化信息增益，从解释性子图中识别体现协同效应的子图；3) 在协同子图中搜索从用户到推荐项目的路径，生成推荐解释。

Result: 在三个数据集上的广泛实验表明，SemExplainer优于基线方法，能提供更优的协同效应解释。

Conclusion: 通过量化图信息增益识别协同效应子图，SemExplainer能有效解释社交推荐中的协同效应，提升推荐系统的可解释性。

Abstract: In social recommenders, the inherent nonlinearity and opacity of synergistic effects across multiple social networks hinders users from understanding how diverse information is leveraged for recommendations, consequently diminishing explainability. However, existing explainers can only identify the topological information in social networks that significantly influences recommendations, failing to further explain the synergistic effects among this information. Inspired by existing findings that synergistic effects enhance mutual information between inputs and predictions to generate information gain, we extend this discovery to graph data. We quantify graph information gain to identify subgraphs embodying synergistic effects. Based on the theoretical insights, we propose SemExplainer, which explains synergistic effects by identifying subgraphs that embody them. SemExplainer first extracts explanatory subgraphs from multi-view social networks to generate preliminary importance explanations for recommendations. A conditional entropy optimization strategy to maximize information gain is developed, thereby further identifying subgraphs that embody synergistic effects from explanatory subgraphs. Finally, SemExplainer searches for paths from users to recommended items within the synergistic subgraphs to generate explanations for the recommendations. Extensive experiments on three datasets demonstrate the superiority of SemExplainer over baseline methods, providing superior explanations of synergistic effects.

</details>


### [426] [Emergent Cooperation in Quantum Multi-Agent Reinforcement Learning Using Communication](https://arxiv.org/abs/2601.18419)
*Michael Kölle,Christian Reff,Leo Sünkel,Julian Hager,Gerhard Stenzel,Claudia Linnhoff-Popien*

Main category: quant-ph

Relevance: 35.0

TL;DR: 论文将经典多智能体强化学习中的通信机制（MATE、MEDIATE、Gifting、RIAL）应用于量子Q学习智能体，在三种顺序社会困境中验证了通信对促进量子多智能体强化学习中涌现合作的有效性。


<details>
  <summary>Details</summary>
Motivation: 经典多智能体强化学习在顺序社会困境中已展现涌现合作能力，但量子多智能体强化学习领域相关研究有限，特别是通过通信机制促进合作的研究尚未充分探索。

Method: 将四种通信机制应用于量子Q学习智能体：MATE协议及其扩展MEDIATE、Gifting奖励机制、RIAL。在三种顺序社会困境（迭代囚徒困境、迭代猎鹿博弈、迭代懦夫博弈）中进行实验评估。

Result: 实验结果显示，使用MATE_TD、AutoMATE、MEDIATE-I和MEDIATE-S的方法在所有困境中都实现了高合作水平，证明通信是促进量子多智能体强化学习中涌现合作的有效机制。

Conclusion: 通信机制能够有效促进量子多智能体强化学习中的涌现合作，为量子强化学习在多智能体环境中的应用提供了新思路。

Abstract: Emergent cooperation in classical Multi-Agent Reinforcement Learning has gained significant attention, particularly in the context of Sequential Social Dilemmas (SSDs). While classical reinforcement learning approaches have demonstrated capability for emergent cooperation, research on extending these methods to Quantum Multi-Agent Reinforcement Learning remains limited, particularly through communication. In this paper, we apply communication approaches to quantum Q-Learning agents: the Mutual Acknowledgment Token Exchange (MATE) protocol, its extension Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange (MEDIATE), the peer rewarding mechanism Gifting, and Reinforced Inter-Agent Learning (RIAL). We evaluate these approaches in three SSDs: the Iterated Prisoner's Dilemma, Iterated Stag Hunt, and Iterated Game of Chicken. Our experimental results show that approaches using MATE with temporal-difference measure (MATE\textsubscript{TD}), AutoMATE, MEDIATE-I, and MEDIATE-S achieved high cooperation levels across all dilemmas, demonstrating that communication is a viable mechanism for fostering emergent cooperation in Quantum Multi-Agent Reinforcement Learning.

</details>


### [427] [Unheard in the Digital Age: Rethinking AI Bias and Speech Diversity](https://arxiv.org/abs/2601.18641)
*Onyedikachi Hope Amaechi-Okorie,Branislav Radeljic*

Main category: cs.HC

Relevance: 35.0

TL;DR: 论文探讨了语音识别系统对非标准语音的偏见问题，指出当前AI系统主要基于标准语音训练，导致对非典型语音模式识别失败，加剧数字排斥，呼吁设计包容性技术、反偏见训练和政策改革。


<details>
  <summary>Details</summary>
Motivation: 语音是社会包容与排斥的重要载体，但当前AI语音识别系统主要基于标准语音训练，对非典型语音模式（如口音、发音障碍等）识别效果差，导致数字排斥，加剧社会不平等。需要解决AI系统中的语音偏见问题。

Method: 文章采用跨学科研究方法，结合社会学、语言学和技术伦理视角，分析语音识别系统的结构性偏见。通过文献综述和案例研究，探讨技术设计、训练数据和政策层面的问题。

Result: 研究发现当前ASR系统和语音接口对非标准语音识别率低，加剧数字鸿沟。文章提出需要包容性技术设计、反偏见算法训练和明确承认语音多样性的政策改革。

Conclusion: 语音包容应被视为公平问题而非简单的可访问性问题。需要文化制度转变，通过共同创造反映人类语音多样性的AI系统，提升非典型说话者的权利、代表性和现实处境。

Abstract: Speech remains one of the most visible yet overlooked vectors of inclusion and exclusion in contemporary society. While fluency is often equated with credibility and competence, individuals with atypical speech patterns are routinely marginalized. Given the current state of the debate, this article focuses on the structural biases that shape perceptions of atypical speech and are now being encoded into artificial intelligence. Automated speech recognition (ASR) systems and voice interfaces, trained predominantly on standardized speech, routinely fail to recognize or respond to diverse voices, compounding digital exclusion. As AI technologies increasingly mediate access to opportunity, the study calls for inclusive technological design, anti-bias training to minimize the impact of discriminatory algorithmic decisions, and enforceable policy reform that explicitly recognize speech diversity as a matter of equity, not merely accessibility. Drawing on interdisciplinary research, the article advocates for a cultural and institutional shift in how we value voice, urging co-created solutions that elevate the rights, representation, and realities of atypical speakers in the digital age. Ultimately, the article reframes speech inclusion as a matter of equity (not accommodation) and advocates for co-created AI systems that reflect the full spectrum of human voices.

</details>


### [428] [Private Accountability in the Age of Artificial Intelligence](https://arxiv.org/abs/2601.17013)
*Sonia Katyal*

Main category: cs.CY

Relevance: 30.0

TL;DR: 本文探讨了人工智能与公民权利保护之间的冲突，认为算法问责问题揭示了技术、财产和公民权利互动的深层结构张力，主张应通过行业自律而非政府监管来解决算法偏见问题。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的广泛应用，算法偏见和问责问题日益突出，这引发了公民权利保护的新挑战。传统上公民权利保护主要针对政府行为，但现在私人企业的算法系统正在引发隐私、正当程序和歧视等公民权利问题，需要新的问责机制。

Method: 本文采用法律和政策分析方法，探讨算法问责的法律框架。作者分析了当前监管模式的局限性，提出了转向行业自律的解决方案，包括行为准则、影响评估和举报人保护等工具。

Result: 研究发现算法偏见代表了新一代公民权利问题，与以往问题性质不同。由于问题主要源于私人企业而非政府，需要建立以行业自律为核心的问责机制，通过透明度工具促进公民权利的内生性执行。

Conclusion: 解决算法问责问题不应仅依赖政府监管，而应通过私人行业的自律机制，包括行为准则、影响评估和举报人保护等工具，建立新一代的问责形式，平衡技术创新与公民权利保护。

Abstract: In this Article, I explore the impending conflict between the protection of civil rights and artificial intelligence (AI). While both areas of law have amassed rich and well-developed areas of scholarly work and doctrinal support, a growing body of scholars are interrogating the intersection between them. This Article argues that the issues surrounding algorithmic accountability demonstrate a deeper, more structural tension within a new generation of disputes regarding law and technology. As I argue, the true promise of AI does not lie in the information we reveal to one another, but rather in the questions it raises about the interaction of technology, property, and civil rights. For this reason, I argue that we are looking in the wrong place if we look only to the state to address issues of algorithmic accountability. Instead, we must turn to other ways to ensure more transparency and accountability that stem from private industry, rather than public regulation. The issue of algorithmic bias represents a crucial new world of civil rights concerns, one that is distinct in nature from the ones that preceded it. Since we are in a world where the activities of private corporations, rather than the state, are raising concerns about privacy, due process, and discrimination, we must focus on the role of private corporations in addressing the issue. Towards this end, I discuss a variety of tools to help eliminate the opacity of AI, including codes of conduct, impact statements, and whistleblower protection, which I argue carries the potential to encourage greater endogeneity in civil rights enforcement. Ultimately, by examining the relationship between private industry and civil rights, we can perhaps develop a new generation of forms of accountability in the process.

</details>


### [429] [High-Fidelity Longitudinal Patient Simulation Using Real-World Data](https://arxiv.org/abs/2601.17310)
*Yu Akagi,Tomohisa Seki,Hiromasa Ito,Toru Takiguchi,Kazuhiko Ohe,Yoshimasa Kawazoe*

Main category: cs.AI

Relevance: 25.0

TL;DR: 该研究开发了一个基于真实世界临床记录的生成式模拟器，能够以患者历史为输入，合成细粒度、真实的未来临床轨迹，为临床医学提供可扩展的计算机模拟框架。


<details>
  <summary>Details</summary>
Motivation: 临床医学中的模拟技术具有变革潜力，可用于个性化治疗规划和虚拟临床试验，但由于复杂的生物和社会文化因素，模拟患者轨迹具有挑战性。研究旨在利用真实世界临床记录来经验性地建模患者时间线。

Method: 开发了一个生成式模拟器模型，以患者历史为输入，合成细粒度的真实未来轨迹。模型在超过2亿条临床记录上进行预训练，能够生成高保真度的未来时间线。

Result: 模型生成的时间线在事件发生率、实验室测试结果和时间动态方面与真实患者未来数据高度匹配。未来事件概率估计准确，观察值与预期值比率在不同结果和时间范围内始终接近1.0。

Conclusion: 研究揭示了电子健康记录中真实世界数据的未开发价值，并引入了一个可扩展的临床护理计算机模拟框架。

Abstract: Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.

</details>


### [430] [Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters](https://arxiv.org/abs/2601.18123)
*Muhammad Ibrahim Khan,Bivin Pradeep,James Brusey*

Main category: cs.AI

Relevance: 25.0

TL;DR: 研究热水器节能控制，提出基于强化学习（PPO）的截止时间感知控制方法，相比传统bang-bang控制和MCTS规划器，在相同物理条件下显著降低能耗


<details>
  <summary>Details</summary>
Motivation: 传统家用浸入式热水器在冬季通常连续运行，加热速度快但效率低，忽略了可预测的需求窗口和环境热损失。需要研究截止时间感知控制，在指定时间达到目标温度的同时最小化能耗。

Method: 1) 建立高效的Gymnasium环境，模拟具有一阶热损失的浸入式热水器，每120秒执行0W或6000W的离散开关动作；2) 时间最优的bang-bang基线控制；3) 零样本蒙特卡洛树搜索规划器；4) 近端策略优化强化学习策略

Result: 在初始温度10-30°C、截止时间30-90步、目标温度40-80°C的参数扫描中，PPO在60步（2小时）时间范围内实现最节能性能，消耗3.23千瓦时，相比bang-bang控制的4.37-10.45千瓦时和MCTS的4.18-6.46千瓦时有显著优势。在典型场景下，PPO比bang-bang控制节能54%，比MCTS节能33%

Conclusion: 学习的截止时间感知控制在相同物理假设下能显著降低能耗，规划器无需训练即可提供部分节能效果，而学习策略一旦训练完成，推理成本几乎为零

Abstract: Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.

</details>


### [431] [Investigating Self-regulated Learning Sequences within a Generative AI-based Intelligent Tutoring System](https://arxiv.org/abs/2601.17000)
*Jie Gao,Shasha Li,Jianhua Zhang,Shan Li,Tingting Wang*

Main category: cs.CY

Relevance: 25.0

TL;DR: 该研究通过分析学生在GenAI辅助学习系统中的交互数据，识别了两种不同的自我调节学习模式，发现学生主要将GenAI用于信息获取而非信息转化，且使用目的与学习成绩无显著相关性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能在教育中的应用日益增多，研究者认识到自我调节学习在GenAI辅助学习环境中的关键作用。然而，如何捕捉学生在这些环境中的动态SRL模式仍是一个挑战，因此需要研究学生在GenAI辅助学习系统中的交互行为模式。

Method: 研究收集了学生在GenAI辅助智能辅导系统中完成问题解决任务的交互轨迹数据。从信息处理角度（信息获取和信息转化）分析学生使用GenAI的目的。采用序列分析和聚类分析方法，根据学生的SRL序列将参与者分为不同组别。

Result: 研究识别出两种不同的SRL序列组别，这两组在GenAI使用的频率和时间特征上存在差异。大多数学生将GenAI用于信息获取而非信息转化。然而，GenAI使用目的与学习表现之间的相关性在统计上不显著。

Conclusion: 研究结果为GenAI辅助学习环境的教学设计和开发提供了重要启示。虽然学生主要将GenAI用于信息获取，但不同SRL模式的学生在使用行为上存在差异，这提示需要针对不同学习模式设计个性化的GenAI支持策略。

Abstract: There has been a growing trend in employing generative artificial intelligence (GenAI) techniques to support learning. Moreover, scholars have reached a consensus on the critical role of self-regulated learning (SRL) in ensuring learning effectiveness within GenAI-assisted learning environments, making it essential to capture students' dynamic SRL patterns. In this study, we extracted students' interaction patterns with GenAI from trace data as they completed a problem-solving task within a GenAI-assisted intelligent tutoring system. Students' purpose of using GenAI was also analyzed from the perspective of information processing, i.e., information acquisition and information transformation. Using sequential and clustering analysis, this study classified participants into two groups based on their SRL sequences. These two groups differed in the frequency and temporal characteristics of GenAI use. In addition, most students used GenAI for information acquisition rather than information transformation, while the correlation between the purpose of using GenAI and learning performance was not statistically significant. Our findings inform both pedagogical design and the development of GenAI-assisted learning environments.

</details>


### [432] [Evaluating the Evolution of Critical Thinking, Creativity, Communication and Collaboration in Higher Education Courses](https://arxiv.org/abs/2601.17018)
*Margarida Romero*

Main category: cs.CY

Relevance: 25.0

TL;DR: 该研究评估了4Cs能力（创造力、沟通、批判性思维、协作）在三个教育试点项目中的演变，发现沟通和批判性思维改善最显著，创造力结果依赖情境，而协作能力最脆弱。


<details>
  <summary>Details</summary>
Motivation: 尽管4Cs能力是当代能力本位教育的核心目标，但关于这些能力如何在不同学习模块和教学阶段演变的实证证据仍然有限。本研究旨在填补这一空白，通过实证分析验证4Cs理论框架。

Method: 使用项目的4Cs理论框架作为分析视角，评估了从预试点到试点实施阶段三个教育情境（IASIS、EASD和UPATRAS）中4Cs能力的演变。通过比较三个试点案例的4Cs分数，识别随时间变化的增长、停滞或下降模式。

Result: 沟通和批判性思维表现出最一致和显著的改善，特别是在预试点基线较低的试点中，表明结构化试点干预有效支持认知和表达能力。创造力呈现情境依赖的结果，而协作能力最为脆弱，在扩大规模时经常停滞或下降。

Conclusion: 能力演变主要受教学设计、评估对齐和学习活动结构的影响，而非仅由学习者能力决定。研究为4Cs框架提供了实证验证，并强调在扩展教育模块时需要差异化的、能力敏感的设计和评估策略。

Abstract: The development of Creativity, Communication, Critical Thinking, and Collaboration (the 4Cs) is a central objective of contemporary competency-based education. However, empirical evidence on how these competencies evolve across learning modules and instructional phases remains limited. This study evaluates the evolution of the 4Cs from pre-pilot to pilot implementation phases across three educational contexts, using the project's 4Cs theoretical framework as an analytical lens. The analysis of three pilot cases (IASIS, EASD, and UPATRAS) compares the 4Cs scores to identify patterns of growth, stagnation, or decline over time. Results indicate that communication and critical thinking showed the most consistent and substantial improvements, particularly in pilots with lower pre-pilot baselines, suggesting that structured pilot interventions effectively support cognitive and expressive competencies. In contrast, creativity exhibited context-dependent outcomes, while collaboration emerged as the most fragile competency, often stagnating or declining during scale-up. Interpreted through the theoretical framework, these findings suggest that competency evolution is strongly shaped by instructional design, assessment alignment, and learning activity structures rather than learner ability alone. The study contributes empirical validation to the 4Cs framework and highlights the need for differentiated, competency-sensitive design and evaluation strategies when scaling educational modules.

</details>


### [433] [PALMA: A Lightweight Tropical Algebra Library for ARM-Based Embedded Systems](https://arxiv.org/abs/2601.17028)
*Gnankan Landry Regis N'guessan*

Main category: cs.MS

Relevance: 25.0

TL;DR: PALMA是一个轻量级、无依赖的C语言库，将热带线性代数（max-plus/min-plus）引入ARM嵌入式系统，支持SIMD加速，在资源受限平台上实现高效优化计算。


<details>
  <summary>Details</summary>
Motivation: 热带代数（max-plus/min-plus等幂半环）为许多优化问题提供了线性化框架，特别适合最短路径、调度、吞吐量分析等应用。然而现有实现主要面向桌面/服务器环境，在嵌入式平台上不可用，而这些平台恰恰最需要此类优化计算。

Method: 开发PALMA库，采用通用半环抽象和SIMD加速内核，支持五种热带半环、稠密/稀疏（CSR）表示、热带闭包和通过最大循环均值计算的谱分析。在Raspberry Pi 4上实现。

Result: 峰值性能达2,274 MOPS，单源最短路径比经典Bellman-Ford算法快11.9倍，实时控制工作负载的调度求解时间低于10微秒。在无人机控制、物联网路由和制造系统中验证了有效性。

Conclusion: 热带代数能够在嵌入式硬件上实现高效、可预测和统一的优化计算。PALMA作为开源软件发布，填补了热带代数在嵌入式平台上的实现空白。

Abstract: Tropical algebra, including max-plus, min-plus, and related idempotent semirings, provides a unifying framework in which many optimization problems that are nonlinear in classical algebra become linear. This property makes tropical methods particularly well suited for shortest paths, scheduling, throughput analysis, and discrete event systems. Despite their theoretical maturity and practical relevance, existing tropical algebra implementations primarily target desktop or server environments and remain largely inaccessible on resource-constrained embedded platforms, where such optimization problems are most acute. We present PALMA (Parallel Algebra Library for Max-plus Applications), a lightweight, dependency-free C library that brings tropical linear algebra to ARM-based embedded systems. PALMA implements a generic semiring abstraction with SIMD-accelerated kernels, enabling a single computational framework to support shortest paths, bottleneck paths, reachability, scheduling, and throughput analysis. The library supports five tropical semirings, dense and sparse (CSR) representations, tropical closure, and spectral analysis via maximum cycle mean computation. We evaluate PALMA on a Raspberry Pi 4 and demonstrate peak performance of 2,274 MOPS, speedups of up to 11.9 times over classical Bellman-Ford for single-source shortest paths, and sub-10 microsecond scheduling solves for real-time control workloads. Case studies in UAV control, IoT routing, and manufacturing systems show that tropical algebra enables efficient, predictable, and unified optimization directly on embedded hardware. PALMA is released as open-source software under the MIT license.

</details>


### [434] [Trademark Search, Artificial Intelligence and the Role of the Private Sector](https://arxiv.org/abs/2601.17072)
*Sonia Katyal,Aniket Kesari*

Main category: cs.CY

Relevance: 25.0

TL;DR: 论文探讨AI在商标搜索和相似性分析中的应用，通过实证实验评估不同商标搜索引擎的效果，提出需要更新商标法的供需框架以促进创新和效率。


<details>
  <summary>Details</summary>
Motivation: 虽然AI在消费营销中已有研究，但较少关注AI在创建和选择商标中的作用。传统商标经济学方法主要关注消费者需求侧，忽略了商标申请人的成本。随着AI在商标搜索和相似性分析中作用日益重要，需要理解其影响。

Method: 通过实证实验评估各种商标搜索引擎的效果，其中许多采用机器学习方法。通过比较分析，评估这些AI工具在实际中的功能表现。

Result: 评估了AI驱动的商标搜索工具的实际效果，发现AI正在改变商标选择过程，需要更新传统的消费者与商标所有者之间的经典划分。

Conclusion: AI对商标研究具有重要意义，将改变商标法的基本理论应用和解释。需要建立更新的供给侧框架来鼓励商标法和实践中的创新和效率。

Abstract: Almost every industry today confronts the potential role of artificial intelligence and machine learning in its future. While many studies examine AI in consumer marketing, less attention addresses AI's role in creating and selecting trademarks that are distinctive, recognizable, and meaningful to consumers. Traditional economic approaches to trademarks focus almost exclusively on consumer-based, demand-side considerations regarding search. However, these approaches are incomplete because they fail to account for substantial costs faced not just by consumers, but by trademark applicants as well. Given AI's rapidly increasing role in trademark search and similarity analysis, lawyers and scholars should understand its dramatic implications. This paper proposes that AI should interest anyone studying trademarks and their role in economic decision-making. We examine how machine learning techniques will transform the application and interpretation of foundational trademark doctrines, producing significant implications for the trademark ecosystem. We run empirical experiments regarding trademark search to assess the efficacy of various trademark search engines, many of which employ machine learning methods. Through comparative analysis, we evaluate how these AI-powered tools function in practice. In an age where artificial intelligence increasingly governs trademark selection, the classic division between consumers and trademark owners deserves an updated, supply-side framework. This insight has transformative potential for encouraging both innovation and efficiency in trademark law and practice.

</details>


### [435] [PC-MCL: Patient-Consistent Multi-Cycle Learning with multi-label bias correction for respiratory sound classification](https://arxiv.org/abs/2601.17080)
*Seung Gyu Jeong,Seong-Eun Kim*

Main category: eess.AS

Relevance: 25.0

TL;DR: PC-MCL提出了一种用于呼吸音分类的患者一致性多周期学习方法，通过多周期拼接、三标签公式和患者匹配辅助任务解决现有方法的局限性，在ICBHI 2017基准上取得了65.37%的分数。


<details>
  <summary>Details</summary>
Motivation: 当前呼吸音分类的深度模型存在两个主要问题：1) 依赖周期级分析，2) 容易发生患者特异性过拟合。此外，传统的二标签（爆裂音、哮鸣音）公式在多周期拼接时会导致正常信号信息的系统性丢失。

Method: PC-MCL包含三个核心组件：1) 多周期拼接：将多个呼吸周期组合成单个样本；2) 三标签公式：使用正常、爆裂音、哮鸣音三个标签，避免多标签分布偏差；3) 患者匹配辅助任务：作为多任务正则化器，学习更鲁棒的特征。

Result: 在ICBHI 2017基准测试中，PC-MCL获得了65.37%的ICBHI分数，优于现有基线方法。消融研究证实所有三个组件都是必需的，它们协同工作改善了异常呼吸事件的检测。

Conclusion: PC-MCL通过解决多周期拼接中的多标签分布偏差问题，并引入患者匹配辅助任务作为正则化，显著提高了呼吸音分类的性能和泛化能力。

Abstract: Automated respiratory sound classification supports the diagnosis of pulmonary diseases. However, many deep models still rely on cycle-level analysis and suffer from patient-specific overfitting. We propose PC-MCL (Patient-Consistent Multi-Cycle Learning) to address these limitations by utilizing three key components: multi-cycle concatenation, a 3-label formulation, and a patient-matching auxiliary task. Our work resolves a multi-label distributional bias in respiratory sound classification, a critical issue inherent to applying multi-cycle concatenation with the conventional 2-label formulation (crackle, wheeze). This bias manifests as a systematic loss of normal signal information when normal and abnormal cycles are combined. Our proposed 3-label formulation (normal, crackle, wheeze) corrects this by preserving information from all constituent cycles in mixed samples. Furthermore, the patient-matching auxiliary task acts as a multi-task regularizer, encouraging the model to learn more robust features and improving generalization. On the ICBHI 2017 benchmark, PC-MCL achieves an ICBHI Score of 65.37%, outperforming existing baselines. Ablation studies confirm that all three components are essential, working synergistically to improve the detection of abnormal respiratory events.

</details>


### [436] [Comparative Algorithmic Governance of Public Health Instruments across India, EU, US and LMICs](https://arxiv.org/abs/2601.17877)
*Sahibpreet Singh*

Main category: cs.CY

Relevance: 25.0

TL;DR: 该研究探讨了人工智能在国际公共卫生工具实施中的作用，分析了不同国家在AI整合、监管框架和基础设施方面的差异，并提出基于权利保护的跨国监管框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决规范性卫生法与算法公共卫生基础设施之间在资源受限司法管辖区中的协调不足问题，评估AI如何增强基于IHR 2005和WHO FCTC的公共卫生工具实施。

Method: 采用比较教义分析和法律规范映射方法，三角测量立法工具、WHO监测框架、AI系统（如BlueDot、Aarogya Setu、EIOS）和合规指标。

Result: 初步结果显示，AI在高能力司法管辖区改善了早期检测、监测精度和响应能力，而中低收入国家面临基础设施不足、数据隐私差距和碎片化法律框架问题。

Conclusion: 研究主张将AI嵌入权利合规、跨国协调的监管框架中，提出受FCTC架构启发的算法条约制定模型，并呼吁建立WHO主导的合规机制以增强大流行防范和跨国治理韧性。

Abstract: The study investigates the juridico-technological architecture of international public health instruments, focusing on their implementation across India, the European Union, the United States and low- and middle-income countries (LMICs), particularly in Sub-Saharan Africa. It addresses a research lacuna: the insufficient harmonisation between normative health law and algorithmic public health infrastructures in resource-constrained jurisdictions. The principal objective is to assess how artificial intelligence augments implementation of instruments grounded in IHR 2005 and the WHO FCTC while identifying doctrinal and infrastructural bottlenecks. Using comparative doctrinal analysis and legal-normative mapping, the study triangulates legislative instruments, WHO monitoring frameworks, AI systems including BlueDot, Aarogya Setu and EIOS, and compliance metrics. Preliminary results show that AI has improved early detection, surveillance precision and responsiveness in high-capacity jurisdictions, whereas LMICs face infrastructural deficits, data privacy gaps and fragmented legal scaffolding. The findings highlight the relevance of the EU Artificial Intelligence Act and GDPR as regulatory prototypes for health-oriented algorithmic governance and contrast them with embryonic AI integration and limited internet penetration in many LMICs. The study argues for embedding AI within a rights-compliant, supranationally coordinated regulatory framework to secure equitable health outcomes and stronger compliance. It proposes a model for algorithmic treaty-making inspired by FCTC architecture and calls for WHO-led compliance mechanisms modelled on the WTO Dispute Settlement Body to enhance pandemic preparedness, surveillance equity and transnational governance resilience.

</details>


### [437] [SpatialEmb: Extract and Encode Spatial Information for 1-Stage Multi-channel Multi-speaker ASR on Arbitrary Microphone Arrays](https://arxiv.org/abs/2601.18037)
*Yiwen Shao,Yong Xu,Sanjeev Khudanpur,Dong Yu*

Main category: eess.AS

Relevance: 25.0

TL;DR: 提出SpatialEmb模块，直接从多通道音频中提取空间信息用于ASR，支持固定和任意麦克风拓扑，在AliMeeting数据集上达到SOTA效果


<details>
  <summary>Details</summary>
Motivation: 现有多通道ASR系统通常在语音分离阶段提取空间特征，然后进行单通道ASR，导致流程冗长、错误累积，且依赖特定麦克风拓扑和说话人位置信息，难以适应新设备

Method: 提出轻量级嵌入模块SpatialEmb，直接为ASR模型提取和编码空间信息，支持固定和任意麦克风拓扑，在AliMeeting真实会议语料上进行全面实验

Result: 在105小时Train-Ali-far数据上训练的最佳模型，在Eval和Test集上分别达到17.04%和20.32%的字符错误率，使用相同训练数据建立了新的SOTA结果

Conclusion: SpatialEmb模块有效解决了多通道ASR中空间信息提取的效率和适应性问题，实现了更高效、更灵活的多说话人语音识别系统

Abstract: Spatial information is a critical clue for multi-channel multi-speaker target speech recognition. Most state-of-the-art multi-channel Automatic Speech Recognition (ASR) systems extract spatial features only during the speech separation stage, followed by standard single-channel ASR on the separated speech. This approach results in an inefficient, lengthy pipeline and sub-optimal ASR performance due to the accumulated errors from preprocessing modules. Furthermore, most spatial feature extraction methods depend on the knowledge of speaker positions and microphone topology, making the systems reliant on specific settings and challenging to adapt to new equipment. In this work, we propose a solution to these issues with a lightweight embedding module named SpatialEmb, which extracts and encodes spatial information directly for the ASR model, supporting both fixed and arbitrary microphone topology. We conduct comprehensive experiments on AliMeeting, a real meeting corpus, to determine the optimal model design for SpatialEmb in terms of both performance and efficiency. Our best model trained with 105 hours Train-Ali-far achieves 17.04% and 20.32% character error rates (CER) on the Eval and Test sets, establishing a new state-of-the-art result with the same training data.

</details>


### [438] [Understanding Users' Privacy Reasoning and Behaviors During Chatbot Use to Support Meaningful Agency in Privacy](https://arxiv.org/abs/2601.18125)
*Mohammad Hadi Nezhad,Francisco Enrique Vicente Castro,Ivon Arroyo*

Main category: cs.HC

Relevance: 25.0

TL;DR: 论文研究聊天机器人交互中的隐私保护行为，通过模拟ChatGPT界面和隐私通知面板，分析用户如何管理敏感信息并采取保护措施。


<details>
  <summary>Details</summary>
Motivation: 随着聊天机器人在敏感信息场景中的广泛应用，隐私问题日益突出。由于隐私判断高度依赖上下文，需要支持用户在聊天机器人交互中采取隐私保护措施，但目前缺乏对用户在实际使用场景中如何推理和管理敏感信息的深入理解。

Method: 定性研究计算机科学学生（本科生和硕士生）在多种现实聊天机器人任务中的即时披露和保护行为。使用模拟ChatGPT界面，对比有无隐私通知面板的情况。面板会拦截消息提交、高亮潜在敏感信息并提供保护措施（匿名化、伪造、泛化），同时提高ChatGPT内置隐私控制的可见性。通过交互日志、有声思维和调查问卷进行分析。

Result: 分析了隐私面板如何促进隐私意识、鼓励保护行为，并支持基于上下文的推理（关于保护什么信息以及如何保护）。发现了工具设计机会，以增强用户在聊天机器人交互中保护敏感信息的能力和自主性。

Conclusion: 需要设计工具来为用户在聊天机器人交互中提供更大、更有意义的隐私保护自主权。隐私通知面板能有效提高隐私意识并支持上下文相关的保护决策。

Abstract: Conversational agents (CAs) (e.g., chatbots) are increasingly used in settings where users disclose sensitive information, raising significant privacy concerns. Because privacy judgments are highly contextual, supporting users to engage in privacy-protective actions during chatbot interactions is essential. However, enabling meaningful engagement requires a deeper understanding of how users currently reason about and manage sensitive information during realistic chatbot use scenarios. To investigate this, we qualitatively examined computer science (undergraduate and masters) students' in-the-moment disclosure and protection behaviors, as well as the reasoning underlying these behaviors, across a range of realistic chatbot tasks. Participants used a simulated ChatGPT interface with and without a privacy notice panel that intercepts message submissions, highlights potentially sensitive information, and offers privacy protective actions. The panel supports anonymization through retracting, faking, and generalizing, and surfaces two of ChatGPT's built-in privacy controls to improve their discoverability. Drawing on interaction logs, think-alouds, and survey responses, we analyzed how the panel fostered privacy awareness, encouraged protective actions, and supported context-specific reasoning about what information to protect and how. We further discuss design opportunities for tools that provide users greater and more meaningful agency in protecting sensitive information during CA interactions.

</details>


### [439] [Analytic Incremental Learning For Sound Source Localization With Imbalance Rectification](https://arxiv.org/abs/2601.18335)
*Zexia Fan,Yu Chen,Qiquan Zhang,Kainan Chen,Xinyuan Qian*

Main category: cs.SD

Relevance: 25.0

TL;DR: 提出一个统一框架解决声源定位中的双重不平衡问题：通过GCC-PHAT数据增强缓解任务内长尾分布，通过分析动态不平衡校正器处理任务间偏移，在SSLR基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 声源定位在受控环境下表现良好，但在实际部署中面临双重不平衡挑战：1) 任务内不平衡（到达方向的长尾分布），2) 任务间不平衡（跨任务偏移和重叠）。这些问题导致灾难性遗忘，显著降低定位精度。

Method: 提出统一框架包含两个关键创新：1) GCC-PHAT数据增强方法，利用峰值特征缓解任务内分布偏移；2) 分析动态不平衡校正器，具有任务自适应正则化，能够进行适应任务间动态的分析更新。

Result: 在SSLR基准上达到SOTA结果：89.0%准确率、5.3°平均绝对误差、1.6反向迁移，在不存储示例的情况下对演化不平衡表现出鲁棒性。

Conclusion: 提出的框架有效解决了声源定位中的双重不平衡问题，通过数据增强和动态不平衡校正器显著提升了模型在实际部署中的鲁棒性和性能。

Abstract: Sound source localization (SSL) demonstrates remarkable results in controlled settings but struggles in real-world deployment due to dual imbalance challenges: intra-task imbalance arising from long-tailed direction-of-arrival (DoA) distributions, and inter-task imbalance induced by cross-task skews and overlaps. These often lead to catastrophic forgetting, significantly degrading the localization accuracy. To mitigate these issues, we propose a unified framework with two key innovations. Specifically, we design a GCC-PHAT-based data augmentation (GDA) method that leverages peak characteristics to alleviate intra-task distribution skews. We also propose an Analytic dynamic imbalance rectifier (ADIR) with task-adaption regularization, which enables analytic updates that adapt to inter-task dynamics. On the SSLR benchmark, our proposal achieves state-of-the-art (SoTA) results of 89.0% accuracy, 5.3° mean absolute error, and 1.6 backward transfer, demonstrating robustness to evolving imbalances without exemplar storage.

</details>


### [440] [SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction](https://arxiv.org/abs/2601.18537)
*Linyong Gan,Zimo Li,Wenxin Xu,Xingjian Li,Jianhua Z. Huang,Enmei Tu,Shuhang Chen*

Main category: cs.RO

Relevance: 25.0

TL;DR: 提出基于语义关键点条件的轨迹建模框架，通过预测高层导航意图（下一个关键点）来分解长时程预测为全局语义决策和局部运动建模，提高船舶轨迹预测的准确性和方向一致性。


<details>
  <summary>Details</summary>
Motivation: 现有船舶轨迹预测方法在长时程预测中难以保持全局方向一致性，容易产生漂移或不合理的轨迹，主要原因是复杂导航行为和环境因素带来的不确定性累积。

Method: 提出语义关键点条件轨迹建模框架：1）预测高层导航意图（下一个关键点NKP）作为条件；2）将长时程预测分解为全局语义决策和局部运动建模；3）采用预训练-微调策略高效估计NKP先验。

Result: 在真实AIS数据上的实验表明，该方法在长时程预测、方向准确性和细粒度轨迹预测方面持续优于现有最先进方法。

Conclusion: 通过将长时程轨迹预测分解为全局语义决策和局部运动建模，基于语义关键点条件的方法能有效限制未来轨迹在语义可行子集内，显著提高预测准确性和一致性。

Abstract: Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.

</details>


### [441] [Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation](https://arxiv.org/abs/2601.18569)
*Seokju Lee,Kyung-Soo Kim*

Main category: cs.RO

Relevance: 25.0

TL;DR: 提出了一种基于注意力的神经增强卡尔曼滤波器（AttenNKF），用于腿式机器人的状态估计，通过注意力机制推断滑移引起的误差并进行补偿


<details>
  <summary>Details</summary>
Motivation: 腿式机器人状态估计中，脚部滑移是主要误差来源。当滑移发生时，运动学测量违反无滑移假设，在更新步骤中引入偏差。需要估计这种滑移引起的误差并进行补偿。

Method: 将不变扩展卡尔曼滤波器（InEKF）与神经补偿器结合，使用注意力机制根据脚部滑移严重程度推断误差，然后将该估计作为后更新补偿应用于InEKF状态。补偿器在潜在空间中训练，以减少对原始输入尺度的敏感性，并鼓励结构化的滑移条件补偿，同时保持InEKF递归。

Result: 实验表明，与现有的腿式机器人状态估计器相比，特别是在易滑移条件下，性能有所改善。

Conclusion: 提出的AttenNKF方法通过神经补偿器有效处理脚部滑移问题，提高了腿式机器人在滑移条件下的状态估计精度。

Abstract: In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.

</details>


### [442] [Neural Multi-Speaker Voice Cloning for Nepali in Low-Resource Settings](https://arxiv.org/abs/2601.18694)
*Aayush M. Shrestha,Aditya Bajracharya,Projan Shakya,Dinesh B. Kshatri*

Main category: cs.SD

Relevance: 25.0

TL;DR: 提出一个面向尼泊尔语的少样本语音克隆系统，使用少量数据即可从梵文文本合成特定说话者语音


<details>
  <summary>Details</summary>
Motivation: 尼泊尔语作为低资源语言，其语音克隆研究几乎空白，需要开发能够从少量数据中学习说话者特征的个性化语音合成系统

Method: 构建两个数据集：用于训练说话者编码器的无转录音频，以及用于训练Tacotron2合成器的配对文本-音频数据。说话者编码器使用生成式端到端损失优化，生成捕捉说话者特征的嵌入，通过UMAP可视化验证。这些嵌入与Tacotron2的文本嵌入融合生成梅尔频谱图，再通过WaveRNN声码器转换为音频

Result: 系统能够有效克隆说话者特征，即使对于未见过的声音也能实现，证明了尼泊尔语少样本语音克隆的可行性

Conclusion: 为低资源场景下的个性化语音合成奠定了基础，展示了在资源有限语言中实现高质量语音克隆的可能性

Abstract: This research presents a few-shot voice cloning system for Nepali speakers, designed to synthesize speech in a specific speaker's voice from Devanagari text using minimal data. Voice cloning in Nepali remains largely unexplored due to its low-resource nature. To address this, we constructed separate datasets: untranscribed audio for training a speaker encoder and paired text-audio data for training a Tacotron2-based synthesizer. The speaker encoder, optimized with Generative End2End loss, generates embeddings that capture the speaker's vocal identity, validated through Uniform Manifold Approximation and Projection (UMAP) for dimension reduction visualizations. These embeddings are fused with Tacotron2's text embeddings to produce mel-spectrograms, which are then converted into audio using a WaveRNN vocoder. Audio data were collected from various sources, including self-recordings, and underwent thorough preprocessing for quality and alignment. Training was performed using mel and gate loss functions under multiple hyperparameter settings. The system effectively clones speaker characteristics even for unseen voices, demonstrating the feasibility of few-shot voice cloning for the Nepali language and establishing a foundation for personalized speech synthesis in low-resource scenarios.

</details>


### [443] [Point transformer for protein structural heterogeneity analysis using CryoEM](https://arxiv.org/abs/2601.18713)
*Muyuan Chen,Muchen Li,Renjie Liao*

Main category: q-bio.QM

Relevance: 25.0

TL;DR: 使用Point Transformer自注意力网络分析冷冻电镜数据，改进蛋白质结构异质性分析，更可解释地表征复杂蛋白质系统的动力学


<details>
  <summary>Details</summary>
Motivation: 大分子结构动力学对其功能关系至关重要。冷冻电镜提供了蛋白质在不同组成和构象状态下的快照，但具有多自由度的蛋白质系统仍难以解耦和解释不同的动力学模式

Method: 采用Point Transformer（一种为点云分析设计的自注意力网络），应用于冷冻电镜数据的异质性分析

Result: 提高了冷冻电镜数据异质性分析的性能，能够以更人类可解释的方式表征高度复杂蛋白质系统的动力学

Conclusion: Point Transformer方法在蛋白质结构动力学分析中表现出优越性能，为复杂生物系统的可解释性分析提供了新工具

Abstract: Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics. Here, by implementing Point Transformer, a self-attention network designed for point cloud analysis, we are able to improve the performance of heterogeneity analysis on CryoEM data, and characterize the dynamics of highly complex protein systems in a more human-interpretable way.

</details>


### [444] [Online parameter estimation for the Crazyflie quadcopter through an EM algorithm](https://arxiv.org/abs/2601.17009)
*Yanhua Zhao*

Main category: cs.AI

Relevance: 15.0

TL;DR: 该论文研究四旋翼无人机系统，通过添加随机噪声分析其对系统的影响，使用扩展卡尔曼滤波进行状态估计，并实现线性二次高斯控制器，应用期望最大化算法进行参数估计。


<details>
  <summary>Details</summary>
Motivation: 无人机在各种应用中变得越来越重要，特别是在地震救援等难以进入的区域。四旋翼无人机系统受到随机噪声影响，需要有效的状态估计和控制方法来提高系统性能和可靠性。

Method: 1. 在四旋翼无人机系统中添加随机噪声；2. 使用扩展卡尔曼滤波器基于传感器噪声观测进行状态估计；3. 基于随机微分方程系统实现线性二次高斯控制器；4. 应用期望最大化算法进行参数估计，包括离线和在线参数估计方法。

Result: 在线参数估计的收敛值范围略大于离线参数估计的范围，表明在线估计方法在动态环境下具有更好的适应性。

Conclusion: 该研究为四旋翼无人机系统在噪声环境下的状态估计和控制提供了有效方法，在线参数估计方法在动态应用中表现出更好的性能。

Abstract: Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation.

</details>


### [445] [Discovery of Feasible 3D Printing Configurations for Metal Alloys via AI-driven Adaptive Experimental Design](https://arxiv.org/abs/2601.17587)
*Azza Fadhel,Nathaniel W. Zuckschwerdt,Aryan Deshwal,Susmita Bose,Amit Bandyopadhyay,Jana Doppa*

Main category: cs.AI

Relevance: 15.0

TL;DR: 该论文提出了一种结合AI驱动自适应实验设计与领域知识的方法，用于优化金属合金增材制造的工艺参数配置，显著减少了发现可行配置所需的时间和资源。


<details>
  <summary>Details</summary>
Motivation: 金属合金增材制造的工艺参数配置（如激光功率、扫描速度）与打印质量之间存在复杂关系，传统的试错方法效率低下，因为每个配置的验证成本高且配置空间巨大。

Method: 结合AI驱动的自适应实验设计与领域知识，通过构建过去实验的代理模型，智能选择小批量输入配置进行迭代验证，应用于定向能量沉积工艺打印NASA开发的GRCop-42合金。

Result: 在三个月内，该方法在广泛的激光功率范围内获得了多个无缺陷输出，相比领域科学家数月手动实验无果，显著减少了时间和资源消耗，首次在红外激光平台上实现了高质量GRCop-42制造。

Conclusion: 该方法成功解决了金属增材制造的参数优化难题，使关键合金的制造更加民主化，为航空航天应用的成本效益和分散化生产铺平了道路。

Abstract: Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper combines the general principles of AI-driven adaptive experimental design with domain knowledge to address the challenging problem of discovering feasible configurations. The key idea is to build a surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition process to print GRCop--42, a high-performance copper--chromium--niobium alloy developed by NASA for aerospace applications. Within three months, our approach yielded multiple defect-free outputs across a range of laser powers dramatically reducing time to result and resource expenditure compared to several months of manual experimentation by domain scientists with no success. By enabling high-quality GRCop--42 fabrication on readily available infrared laser platforms for the first time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production for aerospace applications.

</details>


### [446] [HyCARD-Net: A Synergistic Hybrid Intelligence Framework for Cardiovascular Disease Diagnosis](https://arxiv.org/abs/2601.17767)
*Rajan Das Gupta,Xiaobin Wu,Xun Liu,Jiaqi He*

Main category: cs.AI

Relevance: 15.0

TL;DR: 提出混合集成框架结合CNN、LSTM深度学习与KNN、XGB传统机器学习，通过投票机制提升心血管疾病预测性能，在两个Kaggle数据集上分别达到82.30%和97.10%准确率。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，需要智能数据驱动的诊断工具。传统预测模型难以在异构数据集和复杂生理模式中泛化，因此需要结合深度学习表示能力和传统模型可解释性的混合方法。

Method: 提出混合集成框架，整合CNN和LSTM深度学习架构与KNN、XGB传统机器学习算法，采用集成投票机制。结合深度网络的表示能力和传统模型的效率与可解释性。

Result: 在两个公开Kaggle数据集上实验，模型在数据集I达到82.30%准确率，数据集II达到97.10%准确率，在精确率、召回率和F1分数上均有稳定提升。

Conclusion: 混合AI框架对心血管疾病预测具有鲁棒性和临床潜力，支持早期干预。研究直接支持联合国可持续发展目标3（良好健康与福祉），通过创新数据驱动的医疗解决方案促进非传染性疾病的早期诊断、预防和管理。

Abstract: Cardiovascular disease (CVD) remains the foremost cause of mortality worldwide, underscoring the urgent need for intelligent and data-driven diagnostic tools. Traditional predictive models often struggle to generalize across heterogeneous datasets and complex physiological patterns. To address this, we propose a hybrid ensemble framework that integrates deep learning architectures, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), with classical machine learning algorithms, including K-Nearest Neighbor (KNN) and Extreme Gradient Boosting (XGB), using an ensemble voting mechanism. This approach combines the representational power of deep networks with the interpretability and efficiency of traditional models. Experiments on two publicly available Kaggle datasets demonstrate that the proposed model achieves superior performance, reaching 82.30 percent accuracy on Dataset I and 97.10 percent on Dataset II, with consistent gains in precision, recall, and F1-score. These findings underscore the robustness and clinical potential of hybrid AI frameworks for predicting cardiovascular disease and facilitating early intervention. Furthermore, this study directly supports the United Nations Sustainable Development Goal 3 (Good Health and Well-being) by promoting early diagnosis, prevention, and management of non-communicable diseases through innovative, data-driven healthcare solutions.

</details>


### [447] [Between Search and Platform: ChatGPT Under the DSA](https://arxiv.org/abs/2601.17064)
*Toni Lorente,Kathrin Gardhouse*

Main category: cs.CY

Relevance: 15.0

TL;DR: 论文主张ChatGPT应被归类为混合型托管服务（在线搜索引擎+平台），需遵守欧盟《数字服务法》最严格义务


<details>
  <summary>Details</summary>
Motivation: 解决ChatGPT在《数字服务法》框架下的法律分类模糊性问题，论证其应被视为托管服务，从而适用最严格的监管义务

Method: 通过法律文本分析，论证搜索引擎应被归类为托管服务；分析ChatGPT的核心功能（搜索功能、存储用户输入和自定义GPT），证明其符合托管服务定义；将其系统性风险与现有VLOSE和VLOP进行比较

Result: ChatGPT应被归类为搜索引擎和平台的混合型托管服务，已达到4500万欧盟用户门槛，应承担《数字服务法》最严格的义务，需要评估和缓解其双重特性带来的风险

Conclusion: ChatGPT的法律分类问题需要明确，其作为混合型托管服务应受到《数字服务法》的全面监管，以应对非法内容、基本权利、民主完整性和公共健康等方面的系统性风险

Abstract: This article examines the applicability of the Digital Services Act (DSA) to ChatGPT, arguing that it should be classified as a hybrid of the two types of hosting services: online search engines and platforms. This requires classifying search engines as hosting services, which we show is appropriate under the DSA, thereby resolving an ambiguity in the legal framework. ChatGPT performs core search functions and stores user-provided inputs and custom GPTs, meeting the definition of hosting service. We compare ChatGPT's systemic risks with those of existing Very Large Online Search Engines (VLOSEs) and Platforms (VLOPs), showing that it raises similarly serious concerns regarding illegal content, fundamental rights, democratic integrity, and public health. Now that ChatGPT has reached the 45 million EU user threshold, it should be subject to the most onerous DSA obligations, requiring the assessment and mitigation of risk emanating from both its online search engine- and platform-like characteristics.

</details>


### [448] [Forecasting Energy Consumption using Recurrent Neural Networks: A Comparative Analysis](https://arxiv.org/abs/2601.17110)
*Abhishek Maity,Viraj Tukarul*

Main category: cs.CY

Relevance: 15.0

TL;DR: 该论文提出使用LSTM网络进行短期能源消耗预测，相比传统前馈神经网络，LSTM在MAE和RMSE指标上表现更优


<details>
  <summary>Details</summary>
Motivation: 准确的短期能源消耗预测对电网管理、资源分配和市场稳定至关重要。传统时间序列模型难以捕捉能源需求的复杂非线性依赖和外部影响因素。

Method: 使用RNN及其变体LSTM网络，整合历史能源消耗数据与温度、湿度、时间特征等外部变量，在公开数据集上进行训练和评估，并与传统前馈神经网络基线对比。

Result: LSTM模型显著优于基线模型，实现了更低的平均绝对误差(MAE)和均方根误差(RMSE)，证明了深度学习模型在实际应用中的可靠性。

Conclusion: 深度学习模型（特别是LSTM）能够为现实世界的短期能源预测提供可靠且精确的解决方案。

Abstract: Accurate short-term energy consumption forecasting is essential for efficient power grid management, resource allocation, and market stability. Traditional time-series models often fail to capture the complex, non-linear dependencies and external factors affecting energy demand. In this study, we propose a forecasting approach based on Recurrent Neural Networks (RNNs) and their advanced variant, Long Short-Term Memory (LSTM) networks. Our methodology integrates historical energy consumption data with external variables, including temperature, humidity, and time-based features. The LSTM model is trained and evaluated on a publicly available dataset, and its performance is compared against a conventional feed-forward neural network baseline. Experimental results show that the LSTM model substantially outperforms the baseline, achieving lower Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). These findings demonstrate the effectiveness of deep learning models in providing reliable and precise short-term energy forecasts for real-world applications.

</details>


### [449] [Data-Driven Information-Theoretic Causal Bounds under Unmeasured Confounding](https://arxiv.org/abs/2601.17160)
*Yonghan Jung,Bogyeong Kang*

Main category: stat.ML

Relevance: 15.0

TL;DR: 提出信息论框架，在未测量混杂下实现因果效应的尖锐部分识别，无需外部敏感性参数、辅助变量、完整结构模型或结果有界假设


<details>
  <summary>Details</summary>
Motivation: 现有因果推断方法在未测量混杂下存在四个主要限制：1) 依赖限制性假设（如结果有界或离散）；2) 需要外部输入（如工具变量、代理变量或用户指定的敏感性参数）；3) 需要完整的结构因果模型规范；4) 仅关注总体平均效应而忽略协变量条件处理效应。本文旨在同时克服这四个限制

Method: 建立信息论、数据驱动的散度界限。关键理论贡献表明，观测分布P(Y|A=a,X=x)与干预分布P(Y|do(A=a),X=x)之间的f-散度仅由倾向得分函数上界。开发满足Neyman正交性的半参数估计器，即使使用灵活的机器学习方法估计nuisance函数也能确保√n一致推断

Result: 模拟研究和真实世界数据应用表明，该框架在各种数据生成过程中提供紧密且有效的因果界限。方法在GitHub仓库中实现

Conclusion: 提出了一个信息论框架，能够在未测量混杂下直接从观测数据中实现条件因果效应的尖锐部分识别，无需外部敏感性参数、辅助变量、完整结构规范或结果有界假设

Abstract: We develop a data-driven information-theoretic framework for sharp partial identification of causal effects under unmeasured confounding. Existing approaches often rely on restrictive assumptions, such as bounded or discrete outcomes; require external inputs (for example, instrumental variables, proxies, or user-specified sensitivity parameters); necessitate full structural causal model specifications; or focus solely on population-level averages while neglecting covariate-conditional treatment effects. We overcome all four limitations simultaneously by establishing novel information-theoretic, data-driven divergence bounds. Our key theoretical contribution shows that the f-divergence between the observational distribution P(Y | A = a, X = x) and the interventional distribution P(Y | do(A = a), X = x) is upper bounded by a function of the propensity score alone. This result enables sharp partial identification of conditional causal effects directly from observational data, without requiring external sensitivity parameters, auxiliary variables, full structural specifications, or outcome boundedness assumptions. For practical implementation, we develop a semiparametric estimator satisfying Neyman orthogonality (Chernozhukov et al., 2018), which ensures square-root-n consistent inference even when nuisance functions are estimated using flexible machine learning methods. Simulation studies and real-world data applications, implemented in the GitHub repository (https://github.com/yonghanjung/Information-Theretic-Bounds), demonstrate that our framework provides tight and valid causal bounds across a wide range of data-generating processes.

</details>


### [450] [Artificial Intelligence and Intellectual Property Rights: Comparative Transnational Policy Analysis](https://arxiv.org/abs/2601.17892)
*Sahibpreet Singh,Manjit Singh*

Main category: cs.CY

Relevance: 15.0

TL;DR: 该研究分析了AI对知识产权（特别是商业秘密、版权和专利）的影响，指出印度现行法律缺乏AI特定条款，存在法律空白和执行效率问题，并提出协调的法律分类体系建议。


<details>
  <summary>Details</summary>
Motivation: AI与知识产权的快速融合需要评估其对商业秘密、版权和专利的影响。印度缺乏AI特定的知识产权条款，导致法律不一致和执行效率低下，全球关于AI-IPR保护的讨论仍处于初级阶段。

Method: 采用教义学和比较研究方法，分析印度、美国、英国和欧盟的立法文本、司法判例和政策工具，识别法律空白并提出解决方案。

Result: 研究发现印度法律存在多个缺陷：合同法导致商业秘密保护碎片化；专利法第3(k)条阻止AI发明获得专利；版权法在作者归属方面存在差异。印度国家AI战略（2024）虽有进展，但仍需立法明确。

Conclusion: 研究提出协调的法律分类体系，既能适应AI的作用，又能保持创新激励。这有助于全球讨论，确保AI特定的知识产权保护具有韧性和公平创新。

Abstract: Artificial intelligence's rapid integration with intellectual property rights necessitates assessment of its impact on trade secrets, copyrights and patents. This study addresses lacunae in existing laws where India lacks AI-specific provisions, creating doctrinal inconsistencies and enforcement inefficacies. Global discourse on AI-IPR protections remains nascent. The research identifies gaps in Indian IP laws' adaptability to AI-generated outputs: trade secret protection is inadequate against AI threats; standardized inventorship criteria are absent. Employing doctrinal and comparative methodology, it scrutinizes legislative texts, judicial precedents and policy instruments across India, US, UK and EU. Preliminary findings reveal shortcomings: India's contract law creates fragmented trade secret regime; Section 3(k) of Indian Patents Act blocks AI invention patenting; copyright varies in authorship attribution. The study proposes harmonized legal taxonomy accommodating AI's role while preserving innovation incentives. India's National AI Strategy (2024) shows progress but legislative clarity is imperative. This contributes to global discourse with AI-specific IP protections ensuring resilience and equitable innovation. Promising results underscore recalibrating India's IP jurisprudence for global alignment.

</details>


### [451] [CaSNet: Compress-and-Send Network Based Multi-Device Speech Enhancement Model for Distributed Microphone Arrays](https://arxiv.org/abs/2601.17711)
*Chengqian Jiang,Jie Zhang,Haoyin Yan*

Main category: cs.SD

Relevance: 15.0

TL;DR: 提出CaSNet用于分布式麦克风阵列的语音增强，通过SVD压缩特征减少带宽消耗，在FC端对齐和解码以生成增强语音


<details>
  <summary>Details</summary>
Motivation: 分布式麦克风阵列中，传统语音增强方法需要将所有原始波形数据发送到融合中心，导致高带宽和能耗。需要为资源受限的DMA设计高效方案。

Method: CaSNet采用压缩-发送架构：一个麦克风作为FC和参考，其他设备将原始数据编码为特征矩阵，通过SVD压缩，在FC端通过跨窗口查询对齐特征，最后神经解码生成增强语音。

Result: 在多个数据集上实验表明，CaSNet能显著减少数据传输量，同时性能与未压缩情况相比影响可忽略。

Conclusion: CaSNet为资源受限的分布式麦克风阵列提供了一种高效的语音增强解决方案，平衡了性能与通信开销。

Abstract: Distributed microphone array (DMA) is a promising next-generation platform for speech interaction, where speech enhancement (SE) is still required to improve the speech quality in noisy cases. Existing SE methods usually first gather raw waveforms at a fusion center (FC) from all devices and then design a multi-microphone model, causing high bandwidth and energy costs. In this work, we propose a \emph{Compress-and-Send Network (CaSNet)} for resource-constrained DMAs, where one microphone serves as the FC and reference. Each of other devices encodes the measured raw data into a feature matrix, which is then compressed by singular value decomposition (SVD) to produce a more compact representation. The received features at the FC are aligned via cross window query with respect to the reference, followed by neural decoding to yield spatially coherent enhanced speech. Experiments on multiple datasets show that the proposed CaSNet can save the data amount with a negligible impact on the performance compared to the uncompressed case. The reproducible code is available at https://github.com/Jokejiangv/CaSNet.

</details>


### [452] [Credit Fairness: Online Fairness In Shared Resource Pools](https://arxiv.org/abs/2601.17944)
*Seyed Majid Zahedi,Rupert Freeman*

Main category: cs.GT

Relevance: 15.0

TL;DR: 论文提出了一种新的资源分配机制，在动态多智能体资源分配场景中引入信用公平性，解决了传统最大最小机制导致的长期资源分配不平等问题。


<details>
  <summary>Details</summary>
Motivation: 传统最大最小机制虽然满足共享激励、策略证明和帕累托效率，但在长期资源分配中会导致显著的不平等，即使智能体有相同的平均需求。需要一种能确保早期借出资源的智能体后期能收回资源的公平机制。

Method: 提出信用公平性概念，作为共享激励的强化版本。设计了一种既能实现信用公平又能保持帕累托效率的机制，并在计算资源共享场景中进行评估。

Result: 信用公平性可以与帕累托效率或策略证明性结合，但不能同时满足三者。提出的机制成功实现了信用公平和帕累托效率。

Conclusion: 在动态资源分配中，信用公平性是一个重要的公平性概念，能够解决长期资源分配不平等问题，但需要在帕累托效率和策略证明性之间做出权衡。

Abstract: We consider a setting in which a group of agents share resources that must be allocated among them in each discrete time period. Agents have time-varying demands and derive constant marginal utility from each unit of resource received up to their demand, with zero utility for any additional resources. In this setting, it is known that independently maximizing the minimum utility in each round satisfies sharing incentives (agents weakly prefer participating in the mechanism to not participating), strategyproofness (agents have no incentive to misreport their demands), and Pareto efficiency (Freeman et al. 2018). However, recent work (Vuppalapati et al. 2023) has shown that this max-min mechanism can lead to large disparities in the total resources received by agents, even when they have the same average demand. In this paper, we introduce credit fairness, a strengthening of sharing incentives that ensures agents who lend resources in early rounds are able to recoup them in later rounds. Credit fairness can be achieved in conjunction with either Pareto efficiency or strategyproofness, but not both. We propose a mechanism that is credit fair and Pareto efficient, and we evaluate its performance in a computational resource-sharing setting.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [453] [Sparsity-Aware Low-Rank Representation for Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2601.16991)
*Longteng Zhang,Sen Wu,Shuai Hou,Zhengyu Qing,Zhuo Zheng,Danning Ke,Qihong Lin,Qiang Wang,Shaohuai Shi,Xiaowen Chu*

Main category: cs.LG

Relevance: 85.0

TL;DR: SALR：一种稀疏感知的低秩表示微调方法，通过统一低秩适应与稀疏剪枝，在保持LoRA性能的同时实现50%稀疏度、2倍模型压缩和1.7倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型在下游任务微调时需要调整数百万参数或部署昂贵的密集权重更新，这在资源受限环境中难以应用。LoRA减少了可训练参数，但底层密集权重仍带来高存储和计算成本。传统基于幅度的剪枝方法在应用于LoRA时会降低性能。

Method: 提出SALR（稀疏感知低秩表示）微调范式，在均方误差框架下统一低秩适应与稀疏剪枝。理论证明静态剪枝冻结的基础权重能最小化剪枝误差界，并通过截断SVD低秩适配器恢复丢弃的残差信息。采用多低秩适配器融合为单个GEMM，以及基于位图编码的两阶段流水线解码+GEMM设计来实现硬件效率最大化。

Result: 在各种LLM上实现50%稀疏度，在GSM8K和MMLU基准上匹配LoRA性能，模型大小减少2倍，推理速度提升最高达1.7倍。

Conclusion: SALR提供了一种高效微调框架，通过稀疏剪枝和低秩适应的协同设计，在保持性能的同时显著减少存储和计算需求，适用于资源受限环境。

Abstract: Adapting large pre-trained language models to downstream tasks often entails fine-tuning millions of parameters or deploying costly dense weight updates, which hinders their use in resource-constrained environments. Low-rank Adaptation (LoRA) reduces trainable parameters by factorizing weight updates, yet the underlying dense weights still impose high storage and computation costs. Magnitude-based pruning can yield sparse models but typically degrades LoRA's performance when applied naively. In this paper, we introduce SALR (Sparsity-Aware Low-Rank Representation), a novel fine-tuning paradigm that unifies low-rank adaptation with sparse pruning under a rigorous mean-squared-error framework. We prove that statically pruning only the frozen base weights minimizes the pruning error bound, and we recover the discarded residual information via a truncated-SVD low-rank adapter, which provably reduces per-entry MSE by a factor of $(1 - r/\min(d,k))$. To maximize hardware efficiency, we fuse multiple low-rank adapters into a single concatenated GEMM, and we adopt a bitmap-based encoding with a two-stage pipelined decoding + GEMM design to achieve true model compression and speedup. Empirically, SALR attains 50\% sparsity on various LLMs while matching the performance of LoRA on GSM8K and MMLU, reduces model size by $2\times$, and delivers up to a $1.7\times$ inference speedup.

</details>


### [454] [MathMixup: Boosting LLM Mathematical Reasoning with Difficulty-Controllable Data Synthesis and Curriculum Learning](https://arxiv.org/abs/2601.17006)
*Xuchen Li,Jing Chen,Xuzhao Li,Hao Liang,Xiaohuan Zhou,Taifeng Wang,Wentao Zhang*

Main category: cs.LG

Relevance: 85.0

TL;DR: MathMixup：通过混合和分解策略系统生成难度可控的高质量数学推理问题，构建MathMixupQA数据集并设计课程学习策略，显著提升LLMs的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据合成方法存在多样性有限、难度控制不精确的问题，无法有效支持课程学习等高效训练范式。需要系统生成高质量、难度可控的数学推理问题来提升LLMs的数学推理能力。

Method: 提出MathMixup数据合成范式，通过混合和分解策略系统生成难度可控的数学推理问题。采用自动化自检和人工筛选确保语义清晰和难度梯度结构。构建MathMixupQA数据集并设计课程学习策略，支持与其他数据集的灵活集成。

Result: MathMixup及其课程学习策略显著提升LLMs的数学推理性能。微调的Qwen2.5-7B在七个数学基准测试中平均得分52.6%，超越先前最先进方法。

Conclusion: MathMixup在提升LLMs数学推理能力和推进以数据为中心的课程学习方面具有有效性和广泛适用性。

Abstract: In mathematical reasoning tasks, the advancement of Large Language Models (LLMs) relies heavily on high-quality training data with clearly defined and well-graded difficulty levels. However, existing data synthesis methods often suffer from limited diversity and lack precise control over problem difficulty, making them insufficient for supporting efficient training paradigms such as curriculum learning. To address these challenges, we propose MathMixup, a novel data synthesis paradigm that systematically generates high-quality, difficulty-controllable mathematical reasoning problems through hybrid and decomposed strategies. Automated self-checking and manual screening are incorporated to ensure semantic clarity and a well-structured difficulty gradient in the synthesized data. Building on this, we construct the MathMixupQA dataset and design a curriculum learning strategy that leverages these graded problems, supporting flexible integration with other datasets. Experimental results show that MathMixup and its curriculum learning strategy significantly enhance the mathematical reasoning performance of LLMs. Fine-tuned Qwen2.5-7B achieves an average score of 52.6\% across seven mathematical benchmarks, surpassing previous state-of-the-art methods. These results fully validate the effectiveness and broad applicability of MathMixup in improving the mathematical reasoning abilities of LLMs and advancing data-centric curriculum learning.

</details>


### [455] [FlashMoE: Reducing SSD I/O Bottlenecks via ML-Based Cache Replacement for Mixture-of-Experts Inference on Edge Devices](https://arxiv.org/abs/2601.17063)
*Byeongju Kim,Jungwan Lee,Donghyeon Han,Hoi-Jun Yoo,Sangyeob Kim*

Main category: cs.LG

Relevance: 85.0

TL;DR: FlashMoE是一个将不活跃专家卸载到SSD的MoE推理系统，适用于内存受限的移动设备，通过轻量级ML缓存策略提升专家复用率，减少存储I/O


<details>
  <summary>Details</summary>
Motivation: 现有MoE推理系统（如Fiddler、DAOP）依赖DRAM卸载，不适合内存受限的移动设备环境。随着MoE模型增长到数百GB，RAM卸载方案变得不切实际，需要新的解决方案

Method: 提出FlashMoE系统，将不活跃专家卸载到SSD，采用轻量级ML缓存策略，结合最近使用和频率信号自适应管理缓存，最大化专家复用。构建了用户级桌面平台进行实际验证

Result: 在实际硬件设置上，FlashMoE相比LRU和LFU等传统卸载策略提升缓存命中率高达51%，相比现有MoE推理系统实现高达2.6倍加速

Conclusion: FlashMoE通过SSD卸载和智能缓存策略，实现了内存受限环境下高效的大规模MoE模型推理，为移动设备上的大模型部署提供了可行方案

Abstract: Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.

</details>


### [456] [Boltzmann-GPT: Bridging Energy-Based World Models and Language Generation](https://arxiv.org/abs/2601.17094)
*Junichiro Niimi*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出"嘴不是脑"架构原则，将世界模型与语言模型分离，使用深度玻尔兹曼机作为世界模型，适配器映射信念状态，冻结GPT-2提供语言能力，在消费者评论领域验证了可控生成效果。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否真正理解世界还是仅产生看似合理的语言，提出需要明确分离世界模型和语言模型，以实现更一致、可控的文本生成。

Method: 提出三组件架构：1) 深度玻尔兹曼机作为基于能量的世界模型捕获领域结构；2) 适配器将潜在信念状态投影到嵌入空间；3) 冻结的GPT-2提供语言能力。在亚马逊智能手机评论领域实例化该框架。

Result: 1) 通过世界模型调节显著提高情感相关性、降低困惑度、增加语义相似性；2) DBM能量函数能区分连贯与不连贯市场配置；3) 对特定属性的干预能因果传播到生成文本，与目标配置的自然样本统计一致。

Conclusion: 即使小规模语言模型连接到适当世界模型也能实现一致可控的生成，为分离语言能力与世界理解提供了实证支持。

Abstract: Large Language Models (LLMs) generate fluent text, yet whether they truly understand the world or merely produce plausible language about it remains contested. We propose an architectural principle, the mouth is not the brain, that explicitly separates world models from language models. Our architecture comprises three components: a Deep Boltzmann Machine (DBM) that captures domain structure as an energy-based world model, an adapter that projects latent belief states into embedding space, and a frozen GPT-2 that provides linguistic competence without domain knowledge. We instantiate this framework in the consumer review domain using Amazon smartphone reviews. Experiments demonstrate that (1) conditioning through the world model yields significantly higher sentiment correlation, lower perplexity, and greater semantic similarity compared to prompt-based generation alone; (2) the DBM's energy function distinguishes coherent from incoherent market configurations, assigning higher energy to implausible brand-price combinations; and (3) interventions on specific attributes propagate causally to generated text with intervened outputs exhibiting distributions statistically consistent with naturally occurring samples sharing the target configuration. These findings suggest that even small-scale language models can achieve consistent, controllable generation when connected to an appropriate world model, providing empirical support for separating linguistic competence from world understanding.

</details>


### [457] [Least-Loaded Expert Parallelism: Load Balancing An Imbalanced Mixture-of-Experts](https://arxiv.org/abs/2601.17111)
*Xuan-Phi Nguyen,Shrey Pandit,Austin Xu,Caiming Xiong,Shafiq Joty*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出LLEP（Least-Loaded Expert Parallelism）算法，解决MoE模型中专家路由不平衡导致的设备负载不均问题，通过动态重路由实现5倍加速和4倍内存使用降低


<details>
  <summary>Details</summary>
Motivation: 尽管MoE模型在预训练时使用负载均衡约束，但实际路由仍存在显著不平衡。这种不平衡虽然有利于领域知识集中，但在专家并行（EP）架构下，极端不平衡会导致少数设备过载，引发计算和内存问题，特别是在后训练和推理阶段无法使用显式负载均衡时

Method: 提出LLEP算法：动态检测过载设备，将超额token及相关专家参数重路由到利用率低的设备，确保所有设备在最小集体延迟内完成工作，同时满足内存约束

Result: 在不同规模模型上，LLEP相比标准EP实现最高5倍加速和4倍峰值内存使用降低，使gpt-oss-120b后训练和推理速度提升约1.9倍

Conclusion: LLEP有效解决了MoE模型中路由不平衡导致的硬件效率问题，为硬件特定的超参数调优提供了原则性框架，实现了更快的后训练和推理

Abstract: Mixture-of-Experts (MoE) models are typically pre-trained with explicit load-balancing constraints to ensure statistically balanced expert routing. Despite this, we observe that even well-trained MoE models exhibit significantly imbalanced routing. This behavior is arguably natural-and even desirable - as imbalanced routing allows models to concentrate domain-specific knowledge within a subset of experts. Expert parallelism (EP) is designed to scale MoE models by distributing experts across multiple devices, but with a less-discussed assumption of balanced routing. Under extreme imbalance, EP can funnel a disproportionate number of tokens to a small number of experts, leading to compute- and memory-bound failures on overloaded devices during post-training or inference, where explicit load balancing is often inapplicable. We propose Least-Loaded Expert Parallelism (LLEP), a novel EP algorithm that dynamically reroutes excess tokens and associated expert parameters from overloaded devices to underutilized ones. This ensures that all devices complete their workloads within the minimum collective latency while respecting memory constraints. Across different model scales, LLEP achieves up to 5x speedup and 4x reduction in peak memory usage compared to standard EP. This enables faster and higher-throughput post-training and inference, with ~1.9x faster for gpt-oss-120b. We support our method with extensive theoretical analysis and comprehensive empirical evaluations, including ablation studies. These results illuminate key trade-offs and enable a principled framework for hardware-specific hyper-parameter tuning to achieve optimal performance.

</details>


### [458] [Learning to Collaborate: An Orchestrated-Decentralized Framework for Peer-to-Peer LLM Federation](https://arxiv.org/abs/2601.17133)
*Inderjeet Singh,Eleonore Vissol-Gaudin,Andikan Otung,Motoyoshi Sekiya*

Main category: cs.LG

Relevance: 85.0

TL;DR: KNEXA-FL：一种用于LLM联邦学习的编排式去中心化框架，通过上下文多臂老虎机算法优化异构代理间的P2P知识交换，解决数据隐私与模型性能的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习在LLM微调中存在中心化单点故障和模型反演攻击风险，而去中心化联邦学习通常采用随机P2P配对，忽略了代理异构性并可能导致负迁移。需要一种既能保护数据隐私又能实现高效知识交换的解决方案。

Method: 提出KNEXA-FL框架，包含中央分析器/匹配器（CPM），将P2P协作建模为上下文多臂老虎机问题，使用LinUCB算法基于抽象代理配置文件学习最优匹配策略。通过安全蒸馏实现异构PEFT-based LLM代理间的直接知识交换，无需访问原始模型。

Result: 在代码生成任务上的实验表明，KNEXA-FL相比随机P2P协作将Pass@1提升了约50%。编排方法展现出稳定收敛，而强大的中心化蒸馏基线则出现灾难性性能崩溃。

Conclusion: 自适应、基于学习的编排是构建稳健有效去中心化AI生态系统的基础原则。KNEXA-FL成功解决了隐私保护与模型性能之间的权衡问题。

Abstract: Fine-tuning Large Language Models (LLMs) for specialized domains is constrained by a fundamental challenge: the need for diverse, cross-organizational data conflicts with the principles of data privacy and sovereignty. While Federated Learning (FL) provides a framework for collaboration without raw data exchange, its classic centralized form introduces a single point of failure and remains vulnerable to model inversion attacks. Decentralized FL (DFL) mitigates this risk by removing the central aggregator but typically relies on inefficient, random peer-to-peer (P2P) pairings, forming a collaboration graph that is blind to agent heterogeneity and risks negative transfer. This paper introduces KNEXA-FL, a novel framework for orchestrated decentralization that resolves this trade-off. KNEXA-FL employs a non-aggregating Central Profiler/Matchmaker (CPM) that formulates P2P collaboration as a contextual bandit problem, using a LinUCB algorithm on abstract agent profiles to learn an optimal matchmaking policy. It orchestrates direct knowledge exchange between heterogeneous, PEFT-based LLM agents via secure distillation, without ever accessing the models themselves. Our comprehensive experiments on a challenging code generation task show that KNEXA-FL yields substantial gains, improving Pass@1 by approx. 50% relative to random P2P collaboration. Critically, our orchestrated approach demonstrates stable convergence, in stark contrast to a powerful centralized distillation baseline which suffers from catastrophic performance collapse. Our work establishes adaptive, learning-based orchestration as a foundational principle for building robust and effective decentralized AI ecosystems.

</details>


### [459] [A Constrained Optimization Perspective of Unrolled Transformers](https://arxiv.org/abs/2601.17257)
*Javier Porras-Valenzuela,Samar Hadou,Alejandro Ribeiro*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出一种约束优化框架，训练Transformer使其行为像优化下降算法，通过层间下降约束和原始-对偶训练方案，使中间表示在期望上单调降低损失


<details>
  <summary>Details</summary>
Motivation: 传统Transformer训练采用经验风险最小化（ERM），但缺乏理论保证中间表示的质量。希望让Transformer的行为更像优化算法，确保层间表示能系统性地改进目标函数，从而提升模型的鲁棒性和泛化能力

Method: 1) 引入层间下降约束：强制每一层的输出在期望上降低损失函数；2) 采用原始-对偶训练方案替代标准ERM；3) 应用于展开式Transformer架构和预训练Transformer；4) 在视频去噪和文本分类任务上验证

Result: 约束Transformer在扰动下表现出更强的鲁棒性，保持更高的分布外泛化能力，同时不损害分布内性能。在视频去噪和文本分类任务上均验证了有效性

Conclusion: 通过约束优化框架训练Transformer使其行为像优化算法，能系统性地提升模型鲁棒性和泛化能力，为Transformer架构设计提供了新的理论指导方向

Abstract: We introduce a constrained optimization framework for training transformers that behave like optimization descent algorithms. Specifically, we enforce layerwise descent constraints on the objective function and replace standard empirical risk minimization (ERM) with a primal-dual training scheme. This approach yields models whose intermediate representations decrease the loss monotonically in expectation across layers. We apply our method to both unrolled transformer architectures and conventional pretrained transformers on tasks of video denoising and text classification. Across these settings, we observe constrained transformers achieve stronger robustness to perturbations and maintain higher out-of-distribution generalization, while preserving in-distribution performance.

</details>


### [460] [The Viscosity of Logic: Phase Transitions and Hysteresis in DPO Alignment](https://arxiv.org/abs/2601.17260)
*Marco Pollanen*

Main category: cs.LG

Relevance: 85.0

TL;DR: DPO中的β参数对模型能力有复杂影响：Mistral能力呈非单调变化，只在β≈10⁻²附近有正逻辑探测边际；不同架构响应模式不同；偏好边际可能与推理能力负相关；高β训练会导致能力损失持续存在（滞后效应）


<details>
  <summary>Details</summary>
Motivation: 传统观点认为DPO中增加对齐压力（β）会持续改善模型行为，但作者质疑这一假设，认为β应被视为控制参数，需要系统研究其对不同模型能力的影响

Method: 对三个7B开源模型家族（Mistral、Llama、Qwen）在固定DPO配方下密集扫描β参数，使用逻辑探测边际等指标评估模型能力变化，分析不同架构的响应模式

Result: 1. Mistral能力呈尖锐非单调变化，只在窄带β≈10⁻²附近有正逻辑探测边际；2. 不同架构响应模式不同：Mistral尖锐重组，Llama选择性变化，Qwen平滑权衡；3. DPO偏好边际与推理能力可能负相关（Llama逻辑任务r=-0.91）；4. 高β训练导致能力损失持续存在（滞后效应）

Conclusion: DPO的β参数对模型能力有复杂、架构依赖的影响，偏好边际不能可靠反映推理能力，需要在β参数空间进行能力解析评估，而非依赖边际或聚合基准

Abstract: Direct Preference Optimization (DPO) is often tuned as if increasing alignment pressure (controlled by $β$) yields progressively "better" behavior. We instead treat $β$ as a control parameter and densely sweep it for three 7B open-weight families under a fixed DPO recipe. In Mistral, capability is sharply non-monotonic: aggregated logic-probe margins become positive only in a narrow band near $β\approx 10^{-2}$ and revert outside it, with boundary points that are seed-sensitive. Across architectures under the same sweep, we observe qualitatively different response modes: sharp reorganization in Mistral, selective changes in Llama, and smooth trade-offs in Qwen. Critically, the DPO preference margin can anticorrelate with reasoning capability (Pearson $r=-0.91$ for Llama logic), so margin-based selection can prefer capability-impaired models. Training path also matters: exposure to high $β$ induces capability losses that persist even after $β$ is reduced (hysteresis). These findings motivate capability-resolved evaluation across the $β$ landscape rather than reliance on margins or aggregate benchmarks.

</details>


### [461] [AGZO: Activation-Guided Zeroth-Order Optimization for LLM Fine-Tuning](https://arxiv.org/abs/2601.17261)
*Wei Lin,Yining Jiang,Qingyu Song,Qiao Xiang,Hong Xu*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出AGZO方法，利用激活结构信息指导零阶优化，显著提升LLM微调性能，同时保持低内存消耗


<details>
  <summary>Details</summary>
Motivation: 零阶优化(ZO)在内存受限的LLM微调中很有前景，但现有方法使用各向同性扰动，忽略了前向传播中可用的丰富结构信息。研究发现线性层的梯度被限制在其输入激活张成的子空间中。

Method: 提出激活引导的零阶优化(AGZO)，在前向传播过程中动态提取紧凑的激活信息子空间，将扰动限制在这个低秩子空间中，优化子空间平滑目标。

Result: AGZO在Qwen3和Pangu模型上持续优于最先进的ZO基线，显著缩小了与一阶微调的性能差距，同时保持与其他ZO方法几乎相同的峰值内存占用。

Conclusion: AGZO通过利用激活结构信息，为内存受限的LLM微调提供了更有效的零阶优化方法，在保持低内存消耗的同时显著提升性能。

Abstract: Zeroth-Order (ZO) optimization has emerged as a promising solution for fine-tuning LLMs under strict memory constraints, as it avoids the prohibitive memory cost of storing activations for backpropagation. However, existing ZO methods typically employ isotropic perturbations, neglecting the rich structural information available during the forward pass. In this paper, we identify a crucial link between gradient formation and activation structure: the gradient of a linear layer is confined to the subspace spanned by its input activations. Leveraging this insight, we propose Activation-Guided Zeroth-Order optimization (AGZO). Unlike prior methods, AGZO extracts a compact, activation-informed subspace on the fly during the forward pass and restricts perturbations to this low-rank subspace. We provide a theoretical framework showing that AGZO optimizes a subspace-smoothed objective and provably yields update directions with higher cosine similarity to the true gradient than isotropic baselines. Empirically, we evaluate AGZO on Qwen3 and Pangu models across various benchmarks. AGZO consistently outperforms state-of-the-art ZO baselines and significantly narrows the performance gap with first-order fine-tuning, while maintaining almost the same peak memory footprint as other ZO methods.

</details>


### [462] [Latent-Space Contrastive Reinforcement Learning for Stable and Efficient LLM Reasoning](https://arxiv.org/abs/2601.17275)
*Lianlei Shan,Han Chen,Yixuan Wang,Zhenjie Liu,Wei Li*

Main category: cs.LG

Relevance: 85.0

TL;DR: DLR提出了一种潜在空间双向对比强化学习框架，将推理过程的试错成本从昂贵的token级序列生成转移到连续潜在流形上，通过冻结主模型参数避免灾难性遗忘，实现更稳定高效的LLM推理能力训练。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在处理复杂多步推理任务时往往只是"统计拟合"而非系统逻辑推理。传统RL方法虽然引入了"先思考后说话"范式，但在高维离散token空间中面临三个固有挑战：样本效率低的rollout、高梯度估计方差、以及灾难性遗忘风险。

Method: 提出DeepLatent Reasoning (DLR)框架：1) 使用轻量级辅助模型在潜在空间中采样K个推理链编码；2) 通过基于正确性和格式的双重奖励机制筛选高价值潜在轨迹；3) 仅将高质量潜在轨迹输入冻结的主模型进行单次解码；4) 设计对比学习目标在潜在空间中进行定向探索。

Result: 在可比的GPU计算预算下，DLR实现了更稳定的训练收敛，支持更长的推理链，促进了推理能力的可持续积累，为LLM提供了可靠且可扩展的强化学习路径。

Conclusion: DLR通过将RL从离散token空间转移到连续潜在空间，从根本上解决了传统RL方法在LLM推理训练中的结构瓶颈，同时通过冻结主模型参数消除了灾难性遗忘，为LLM的可靠推理能力训练提供了可行方案。

Abstract: While Large Language Models (LLMs) demonstrate exceptional performance in surface-level text generation, their nature in handling complex multi-step reasoning tasks often remains one of ``statistical fitting'' rather than systematic logical deduction. Traditional Reinforcement Learning (RL) attempts to mitigate this by introducing a ``think-before-speak'' paradigm. However, applying RL directly in high-dimensional, discrete token spaces faces three inherent challenges: sample-inefficient rollouts, high gradient estimation variance, and the risk of catastrophic forgetting. To fundamentally address these structural bottlenecks, we propose \textbf{DeepLatent Reasoning (DLR)}, a latent-space bidirectional contrastive reinforcement learning framework. This framework shifts the trial-and-error cost from expensive token-level full sequence generation to the continuous latent manifold. Specifically, we introduce a lightweight assistant model to efficiently sample $K$ reasoning chain encodings within the latent space. These encodings are filtered via a dual reward mechanism based on correctness and formatting; only high-value latent trajectories are fed into a \textbf{frozen main model} for single-pass decoding. To maximize reasoning diversity while maintaining coherence, we design a contrastive learning objective to enable directed exploration within the latent space. Since the main model parameters remain frozen during optimization, this method mathematically eliminates catastrophic forgetting. Experiments demonstrate that under comparable GPU computational budgets, DLR achieves more stable training convergence, supports longer-horizon reasoning chains, and facilitates the sustainable accumulation of reasoning capabilities, providing a viable path toward reliable and scalable reinforcement learning for LLMs.

</details>


### [463] [Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment](https://arxiv.org/abs/2601.17329)
*Tiejin Chen,Xiaoou Liu,Vishnu Nandam,Kuan-Ru Liou,Hua Wei*

Main category: cs.LG

Relevance: 85.0

TL;DR: CFA框架利用共形预测量化答案可靠性，为DPO/PPO训练提供统计保证的偏好权重，提升对齐鲁棒性和数据效率


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好的对齐方法（如RLHF）面临标签噪声和不一致问题，当前不确定性感知方法只关注偏好权重，忽略了被比较答案本身的可靠性

Method: 提出Conformal Feedback Alignment (CFA)框架，利用共形预测构建具有可控覆盖率的预测集来量化答案级可靠性，并将这些可靠性聚合为DPO和PPO风格训练的权重

Result: 在不同数据集上的实验表明，CFA提高了对齐的鲁棒性和数据效率，证明建模答案侧不确定性能补充偏好级加权，实现更鲁棒、数据高效的对齐

Conclusion: CFA通过共形预测为偏好对齐提供统计保证，强调答案可靠性建模的重要性，为LLM对齐提供了更稳健的方法

Abstract: Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.

</details>


### [464] [Power-based Partial Attention: Bridging Linear-Complexity and Full Attention](https://arxiv.org/abs/2601.17334)
*Yufeng Huang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文提出了一种基于幂的部分注意力机制（PPA），其复杂度为O(L^{1+p})，其中0≤p≤1。研究发现，存在0<p<1使得PPA能够达到与O(L^2)全注意力相当的性能，揭示了注意力机制存在次二次复杂度的可能性。


<details>
  <summary>Details</summary>
Motivation: 虽然Transformer研究普遍认为"注意力就是一切"，但从未系统量化过到底需要多少注意力。本文旨在探索二次复杂度O(L^2)的全注意力是否必要，是否存在次二次复杂度的注意力机制能达到可比性能。

Method: 提出了基于幂的部分注意力机制（PPA），通过参数p控制注意力复杂度在O(L^{1+p})范围内变化。p=0对应线性复杂度的滑动窗口注意力，p=1对应全注意力。通过系统实验研究Transformer性能如何随p值变化。

Result: 实验结果显示性能随p变化呈现S曲线行为：在p值的狭窄窗口内，性能从滑动窗口注意力过渡到全注意力，当p接近1时性能趋于稳定。存在0<p<1使得O(L^{1+p})注意力足以达到与O(L^2)全注意力相似的结果。

Conclusion: 二次复杂度的全注意力并非必要，存在次二次复杂度的注意力机制能够达到可比性能。这一发现对高效Transformer架构设计具有重要意义，为降低注意力计算复杂度提供了理论依据。

Abstract: It is widely accepted from transformer research that "attention is all we need", but the amount of attention required has never been systematically quantified. Is quadratic $O(L^2)$ attention necessary, or is there a sub-quadratic attention mechanism that can achieve comparable performance? To answer this question, we introduce power-based partial attention (PPA), an attention mechanism of order $O(L^{1+p})$, where $0 \leq p \leq 1$, such that $p=0$ corresponds to sliding window attention with linear complexity, and $p=1$ corresponds to full attention. With this attention construction, we can explore how transformer architecture performance varies as a function of the attention scaling behavior controlled by $p$. The overall trend from our experiments shows an S-curve-like behavior where the performance transitions from sliding-window (linear-complexity) attention to full attention over a narrow window of $p$ values, and plateaus as $p$ approaches $1$. In our experiments, we show that there exists $0<p<1$ such that $O(L^{1+p})$ attention is sufficient to achieve similar results as $O(L^2)$ full attention.

</details>


### [465] [Spectral Geometry for Deep Learning: Compression and Hallucination Detection via Random Matrix Theory](https://arxiv.org/abs/2601.17357)
*Davide Ettori*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文提出基于谱几何和随机矩阵理论的统一框架，通过分析隐藏激活的特征值结构来解决大语言模型的可靠性问题和计算成本问题。包含两个主要贡献：EigenTrack（实时检测幻觉和分布外行为）和RMT-KD（基于谱特征的知识蒸馏压缩方法）。


<details>
  <summary>Details</summary>
Motivation: 大语言模型和深度神经网络虽然性能强大，但存在可靠性问题（如幻觉）和高计算成本问题。需要一种统一的理论框架来同时解决这两个问题。

Method: 1. EigenTrack：基于谱特征及其时间动态的实时检测方法，用于检测语言和视觉语言模型中的幻觉和分布外行为。
2. RMT-KD：基于随机矩阵理论的压缩方法，识别信息丰富的谱成分，应用迭代知识蒸馏来生成紧凑高效的模型。

Result: 谱统计量提供了可解释且鲁棒的信号，可用于监控大尺度神经网络的不确定性和指导模型压缩，在保持准确性的同时实现模型压缩。

Conclusion: 基于谱几何和随机矩阵理论的统一框架能有效解决大语言模型的可靠性问题和计算成本问题，谱特征为模型监控和压缩提供了理论基础。

Abstract: Large language models and deep neural networks achieve strong performance but suffer from reliability issues and high computational cost. This thesis proposes a unified framework based on spectral geometry and random matrix theory to address both problems by analyzing the eigenvalue structure of hidden activations. The first contribution, EigenTrack, is a real-time method for detecting hallucinations and out-of-distribution behavior in language and vision-language models using spectral features and their temporal dynamics. The second contribution, RMT-KD, is a principled compression method that identifies informative spectral components and applies iterative knowledge distillation to produce compact and efficient models while preserving accuracy. Together, these results show that spectral statistics provide interpretable and robust signals for monitoring uncertainty and guiding compression in large-scale neural networks.

</details>


### [466] [Harnessing Reasoning Trajectories for Hallucination Detection via Answer-agreement Representation Shaping](https://arxiv.org/abs/2601.17467)
*Jianxiong Zhang,Bing Guo,Yuming Jiang,Haobo Wang,Bo An,Xuefeng Du*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文提出ARS方法，通过生成反事实答案并学习答案一致性表示，来检测大型推理模型中的幻觉问题，无需人工标注即可提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）经常生成看似连贯但答案错误的推理轨迹，使得幻觉检测变得困难。现有方法直接使用轨迹文本或隐藏状态进行检测不够鲁棒，容易过拟合到表面模式而非答案有效性。

Method: 提出答案一致性表示塑造（ARS）方法：通过小规模潜在干预（扰动轨迹边界嵌入）生成反事实答案，根据扰动后答案是否与原答案一致进行标注，然后学习将答案一致的状态聚集、不一致的状态分离的表示，从而暴露指示幻觉风险的潜在不稳定性。

Result: 实验表明，ARS能持续改进检测性能，相比强基线方法取得显著提升。塑造后的嵌入可与现有基于嵌入的检测器即插即用，且训练过程中无需人工标注。

Conclusion: ARS通过显式编码答案稳定性来学习检测友好的轨迹条件表示，有效解决了大型推理模型中的幻觉检测问题，提供了一种无需人工标注的鲁棒检测方法。

Abstract: Large reasoning models (LRMs) often generate long, seemingly coherent reasoning traces yet still produce incorrect answers, making hallucination detection challenging. Although trajectories contain useful signals, directly using trace text or vanilla hidden states for detection is brittle: traces vary in form and detectors can overfit to superficial patterns rather than answer validity. We introduce Answer-agreement Representation Shaping (ARS), which learns detection-friendly trace-conditioned representations by explicitly encoding answer stability. ARS generates counterfactual answers through small latent interventions, specifically, perturbing the trace-boundary embedding, and labels each perturbation by whether the resulting answer agrees with the original. It then learns representations that bring answer-agreeing states together and separate answer-disagreeing ones, exposing latent instability indicative of hallucination risk. The shaped embeddings are plug-and-play with existing embedding-based detectors and require no human annotations during training. Experiments demonstrate that ARS consistently improves detection and achieves substantial gains over strong baselines.

</details>


### [467] [Unintended Memorization of Sensitive Information in Fine-Tuned Language Models](https://arxiv.org/abs/2601.17480)
*Marton Szep,Jorge Marin Ruiz,Georgios Kaissis,Paulina Seidl,Rüdiger von Eisenhart-Rothe,Florian Hinterwimmer,Daniel Rueckert*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文系统研究LLM微调中仅出现在输入而非训练目标中的PII泄露风险，通过控制提取探针量化记忆行为，并评估四种隐私保护方法的隐私-性能权衡


<details>
  <summary>Details</summary>
Motivation: LLM在敏感数据集上微调存在意外记忆和PII泄露的重大风险，可能违反隐私法规并危害个人安全。当前对仅出现在模型输入而非训练目标中的PII暴露这一关键漏洞研究不足

Method: 使用合成和真实数据集设计控制提取探针来量化意外PII记忆，研究语言、PII频率、任务类型和模型规模等因素对记忆行为的影响。基准测试四种隐私保护方法：差分隐私、机器遗忘、正则化和偏好对齐

Result: 后训练方法通常提供更一致的隐私-效用权衡，而差分隐私在特定设置中能显著减少泄露，但可能引入训练不稳定性。研究发现微调LLM中记忆问题持续存在

Conclusion: LLM微调中的记忆问题是一个持续挑战，需要强大、可扩展的隐私保护技术。不同隐私方法在不同场景下各有优劣，需要根据具体需求选择

Abstract: Fine-tuning Large Language Models (LLMs) on sensitive datasets carries a substantial risk of unintended memorization and leakage of Personally Identifiable Information (PII), which can violate privacy regulations and compromise individual safety. In this work, we systematically investigate a critical and underexplored vulnerability: the exposure of PII that appears only in model inputs, not in training targets. Using both synthetic and real-world datasets, we design controlled extraction probes to quantify unintended PII memorization and study how factors such as language, PII frequency, task type, and model size influence memorization behavior. We further benchmark four privacy-preserving approaches including differential privacy, machine unlearning, regularization, and preference alignment, evaluating their trade-offs between privacy and task performance. Our results show that post-training methods generally provide more consistent privacy-utility trade-offs, while differential privacy achieves strong reduction in leakage in specific settings, although it can introduce training instability. These findings highlight the persistent challenge of memorization in fine-tuned LLMs and emphasize the need for robust, scalable privacy-preserving techniques.

</details>


### [468] [Automatic Stability and Recovery for Neural Network Training](https://arxiv.org/abs/2601.17483)
*Barak Or*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出一个运行时稳定性监控框架，将优化视为受控随机过程，通过创新信号自动检测和恢复不稳定更新，提供理论安全保证


<details>
  <summary>Details</summary>
Motivation: 现代神经网络训练越来越脆弱，罕见但严重的破坏性更新会导致不可逆的发散或性能下降。现有优化方法主要依赖优化器内部的预防机制，一旦发生不稳定，检测和恢复能力有限。

Method: 引入一个监督运行时稳定性框架，将优化视为受控随机过程。通过从验证探针等次要测量中提取创新信号，实现自动检测和恢复不稳定更新，无需修改底层优化器。

Result: 提供理论运行时安全保证，形式化有界性能下降和恢复。实现开销最小，兼容内存受限的训练设置。

Conclusion: 该框架为神经网络训练提供了有效的运行时稳定性监控和恢复机制，解决了现有优化方法在检测和恢复不稳定更新方面的局限性。

Abstract: Training modern neural networks is increasingly fragile, with rare but severe destabilizing updates often causing irreversible divergence or silent performance degradation. Existing optimization methods primarily rely on preventive mechanisms embedded within the optimizer, offering limited ability to detect and recover from instability once it occurs. We introduce a supervisory runtime stability framework that treats optimization as a controlled stochastic process. By isolating an innovation signal derived from secondary measurements, such as validation probes, the framework enables automatic detection and recovery from destabilizing updates without modifying the underlying optimizer. We provide theoretical runtime safety guarantees that formalize bounded degradation and recovery. Our implementation incurs minimal overhead and is compatible with memory-constrained training settings.

</details>


### [469] [SpatialMath: Spatial Comprehension-Infused Symbolic Reasoning for Mathematical Problem-Solving](https://arxiv.org/abs/2601.17489)
*Ashutosh Bajpai,Akshat Bhandari,Akshay Nambi,Tanmoy Chakraborty*

Main category: cs.LG

Relevance: 85.0

TL;DR: SpatialMath框架通过将空间表示注入符号推理链，提升多模态语言模型在几何问题上的视觉理解和数学推理能力，在视觉密集型数学问题上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前多模态中小型语言模型在视觉理解和数学推理方面存在局限，特别是在几何问题上。模型难以准确分解复杂视觉输入并将感知与结构化推理连接，导致性能不佳。

Method: 提出SpatialMath框架，包含专门感知模块提取空间基础表示，捕捉几何结构和空间关系，然后将这些表示系统性地注入符号推理链，实现视觉理解感知的结构化推理。同时创建MATHVERSE-PLUS数据集，包含结构化视觉解释和逐步推理路径。

Result: SpatialMath显著优于强大多模态基线，在视觉密集型设置下比监督微调加数据增强提升高达10个百分点。鲁棒性分析显示增强的空间表示直接提升推理准确性。

Conclusion: 结构化感知到推理管道对多模态语言模型至关重要，空间表示与符号推理的有效整合能显著提升模型在视觉密集型数学问题上的性能。

Abstract: Multimodal Small-to-Medium sized Language Models (MSLMs) have demonstrated strong capabilities in integrating visual and textual information but still face significant limitations in visual comprehension and mathematical reasoning, particularly in geometric problems with diverse levels of visual infusion. Current models struggle to accurately decompose intricate visual inputs and connect perception with structured reasoning, leading to suboptimal performance. To address these challenges, we propose SpatialMath, a novel Spatial Comprehension-Infused Symbolic Reasoning Framework designed to integrate spatial representations into structured symbolic reasoning chains. SpatialMath employs a specialized perception module to extract spatially-grounded representations from visual diagrams, capturing critical geometric structures and spatial relationships. These representations are then methodically infused into symbolic reasoning chains, facilitating visual comprehension-aware structured reasoning. To this end, we introduce MATHVERSE-PLUS, a novel dataset containing structured visual interpretations and step-by-step reasoning paths for vision-intensive mathematical problems. SpatialMath significantly outperforms strong multimodal baselines, achieving up to 10 percentage points improvement over supervised fine-tuning with data augmentation in vision-intensive settings. Robustness analysis reveals that enhanced spatial representations directly improve reasoning accuracy, reinforcing the need for structured perception-to-reasoning pipelines in MSLMs.

</details>


### [470] [Split-on-Share: Mixture of Sparse Experts for Task-Agnostic Continual Learning](https://arxiv.org/abs/2601.17616)
*Fatema Siddika,Md Anwar Hossen,Tanwi Mallick,Ali Jannesari*

Main category: cs.LG

Relevance: 85.0

TL;DR: SETA是一个用于LLM持续学习的框架，通过混合稀疏专家分解模型为模块化子空间，解决可塑性与稳定性困境，在任务无关持续学习中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLM持续学习面临可塑性-稳定性困境：学习新能力会导致灾难性遗忘。现有方法通常均匀处理参数，无法区分特定任务知识和共享能力。

Method: SETA框架将模型分解为模块化子空间：独特专家（隔离任务特定模式）和共享专家（捕获共同特征）。通过弹性权重锚定保护关键共享知识，统一门控网络在推理时自动检索正确的专家组合。

Result: 在多样化领域特定和通用基准测试中，SETA持续优于最先进的参数高效微调基持续学习方法。

Conclusion: SETA通过混合稀疏专家方法有效解决LLM持续学习中的可塑性-稳定性冲突，为任务无关持续学习提供了有效框架。

Abstract: Continual learning in Large Language Models (LLMs) is hindered by the plasticity-stability dilemma, where acquiring new capabilities often leads to catastrophic forgetting of previous knowledge. Existing methods typically treat parameters uniformly, failing to distinguish between specific task knowledge and shared capabilities. We introduce Mixture of Sparse Experts for Task-Agnostic Continual Learning, referred to as SETA, a framework that resolves the plasticity-stability conflict by decomposing the model into modular subspaces. Unlike standard updates, where tasks compete for the same parameters, SETA separates knowledge into unique experts, designed to isolate task-specific patterns, and shared experts, responsible for capturing common features. This structure is maintained through elastic weight anchoring, which protects critical shared knowledge and enables a unified gating network to automatically retrieve the correct expert combination for each task during inference. Extensive experiments across diverse domain-specific and general benchmarks demonstrate that SETA consistently outperforms state-of-the-art parameter-efficient fine-tuning-based continual learning methods.

</details>


### [471] [Kareus: Joint Reduction of Dynamic and Static Energy in Large Model Training](https://arxiv.org/abs/2601.17654)
*Ruofan Wu,Jae-Won Chung,Mosharaf Chowdhury*

Main category: cs.LG

Relevance: 85.0

TL;DR: Kareus：一个通过联合优化内核调度和频率缩放来优化大模型训练能耗的系统，在相同训练时间下可减少28.3%能耗，或在相同能耗下减少27.5%训练时间。


<details>
  <summary>Details</summary>
Motivation: AI计算需求快速增长，但能源供应跟不上，能源已成为昂贵且竞争激烈的资源。现有的大模型训练优化工作只关注动态或静态能耗的单一方面，而细粒度的内核调度和频率缩放会共同影响这两种能耗。

Method: 设计Kareus训练系统，将难以处理的联合优化问题分解为局部的、基于分区的子问题，使用多目标多轮优化算法寻找推动时间-能耗权衡前沿的执行调度方案。

Result: 相比现有技术，Kareus在相同训练时间下可减少高达28.3%的训练能耗，或在相同能耗下减少高达27.5%的训练时间。

Conclusion: 通过联合优化内核调度和频率缩放，Kareus能够有效推动大模型训练的时间-能耗权衡前沿，为AI计算的能源效率提供重要解决方案。

Abstract: The computing demand of AI is growing at an unprecedented rate, but energy supply is not keeping pace. As a result, energy has become an expensive, contended resource that requires explicit management and optimization. Although recent works have made significant progress in large model training optimization, they focus only on a single aspect of energy consumption: dynamic or static energy.
  We find that fine-grained kernel scheduling and frequency scaling jointly and interdependently impact both dynamic and static energy consumption. Based on this finding, we design Kareus, a training system that pushes the time--energy tradeoff frontier by optimizing both aspects. Kareus decomposes the intractable joint optimization problem into local, partition-based subproblems. It then uses a multi-pass multi-objective optimization algorithm to find execution schedules that push the time--energy tradeoff frontier. Compared to the state of the art, Kareus reduces training energy by up to 28.3% at the same training time, or reduces training time by up to 27.5% at the same energy consumption.

</details>


### [472] [Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction](https://arxiv.org/abs/2601.17668)
*Jang-Hyun Kim,Dongyoon Han,Sangdoo Yun*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出一种基于门控的KV缓存驱逐方法，通过轻量级sink-attention门控模块识别关键KV对，实现高达70%的KV缓存压缩，在保持接近无损性能的同时几乎无计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存压缩技术通常在性能下降和计算开销之间需要权衡，这限制了大型语言模型的实际部署。需要一种既能实现高压缩比又不会带来显著计算成本的方法。

Method: 提出基于门控的KV缓存驱逐方法：1) 引入轻量级sink-attention门控模块识别和保留关键KV对；2) 无缝集成到预填充和解码阶段；3) 使用仅需前向传播的门训练算法，避免昂贵的反向传播；4) 通过任务无关的重建目标实现强任务泛化能力。

Result: 在Qwen2.5-1M、Qwen3和Gemma3系列模型上的广泛实验表明，该方法在驱逐高达70%的KV缓存时仍能保持接近无损的性能。结果在长上下文理解、代码理解和数学推理等多种任务中表现一致，证明了方法的通用性。

Conclusion: 该方法为冻结权重的LLM提供了一种高效、低成本的KV缓存管理方案，在保持高性能的同时显著减少内存占用，具有实际部署价值。

Abstract: Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.

</details>


### [473] [$\infty$-MoE: Generalizing Mixture of Experts to Infinite Experts](https://arxiv.org/abs/2601.17680)
*Shota Takashiro,Takeshi Kojima,Shohei Taniguchi,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.LG

Relevance: 85.0

TL;DR: ∞-MoE：通过连续空间选择大型前馈网络的部分参数，实现无限专家数的高效混合专家模型，在保持计算效率的同时提升性能


<details>
  <summary>Details</summary>
Motivation: 传统MoE将每个专家视为完全独立，在离散空间中组合专家。当专家数量增加时，难以有效训练每个专家。需要一种方法在增加专家数量的同时稳定训练

Method: 提出∞-MoE，基于每个token采样的连续值选择大型前馈网络的部分参数。通过在连续空间中考虑专家，允许无限数量的专家同时保持计算效率

Result: 基于GPT-2 Small的∞-MoE模型（1.29亿活跃参数，1.86亿总参数）达到与密集GPT-2 Medium（3.5亿参数）相当的性能。在推理时调整采样专家数量可实现准确性与速度的灵活权衡，比传统MoE准确率提升达2.5%

Conclusion: ∞-MoE通过连续参数选择机制解决了传统MoE在专家数量增加时的训练困难问题，实现了无限专家扩展的可行性，为高效可扩展的Transformer架构设计提供了新思路

Abstract: The Mixture of Experts (MoE) selects a few feed-forward networks (FFNs) per token, achieving an effective trade-off between computational cost and performance. In conventional MoE, each expert is treated as entirely independent, and experts are combined in a discrete space. As a result, when the number of experts increases, it becomes difficult to train each expert effectively. To stabilize training while increasing the number of experts, we propose $\infty$-MoE that selects a portion of the parameters of large FFNs based on continuous values sampled for each token. By considering experts in a continuous space, this approach allows for an infinite number of experts while maintaining computational efficiency. Experiments show that a GPT-2 Small-based $\infty$-MoE model, with 129M active and 186M total parameters, achieves comparable performance to a dense GPT-2 Medium with 350M parameters. Adjusting the number of sampled experts at inference time allows for a flexible trade-off between accuracy and speed, with an improvement of up to 2.5\% in accuracy over conventional MoE.

</details>


### [474] [Agentic reinforcement learning empowers next-generation chemical language models for molecular design and synthesis](https://arxiv.org/abs/2601.17687)
*Hao Li,He Cao,Shenyao Peng,Zijing Liu,Bin Feng,Yu Wang,Zhiyuan Yan,Yonghong Tian,Yu Li,Li Yuan*

Main category: cs.LG

Relevance: 85.0

TL;DR: ChemCRAFT框架通过代理强化学习将化学推理与知识存储解耦，让小规模语言模型通过外部沙箱交互实现高性能化学任务，在保护隐私的同时降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 当前生化领域语言模型面临两难：小模型易产生幻觉且知识有限，大云模型存在隐私风险和推理成本高。需要一种既能保护隐私又能高效推理的解决方案。

Method: 1) 构建代理轨迹构建管道和化学代理沙箱；2) 创建ChemToolDataset大规模化学工具轨迹数据集；3) 提出SMILES-GRPO构建密集化学奖励函数；4) 通过强化学习训练模型调用化学代理的能力。

Result: ChemCRAFT在药物设计的多个方面（分子结构分析、分子优化、合成路径预测）均优于当前云基LLMs，证明科学推理能力可通过工具编排策略学习获得，而非仅依赖模型规模。

Conclusion: 该工作建立了成本效益高且保护隐私的AI辅助化学范式，为本地可部署代理加速分子发现开辟了新途径，表明科学推理能力可通过工具编排策略学习而非仅依赖模型规模。

Abstract: Language models are revolutionizing the biochemistry domain, assisting scientists in drug design and chemical synthesis with high efficiency. Yet current approaches struggle between small language models prone to hallucination and limited knowledge retention, and large cloud-based language models plagued by privacy risks and high inference costs. To bridge this gap, we introduce ChemCRAFT, a novel framework leveraging agentic reinforcement learning to decouple chemical reasoning from knowledge storage. Instead of forcing the model to memorize vast chemical data, our approach empowers the language model to interact with a sandbox for precise information retrieval. This externalization of knowledge allows a locally deployable small model to achieve superior performance with minimal inference costs. To enable small language models for agent-calling ability, we build an agentic trajectory construction pipeline and a comprehensive chemical-agent sandbox. Based on sandbox interactions, we constructed ChemToolDataset, the first large-scale chemical tool trajectory dataset. Simultaneously, we propose SMILES-GRPO to build a dense chemical reward function, promoting the model's ability to call chemical agents. Evaluations across diverse aspects of drug design show that ChemCRAFT outperforms current cloud-based LLMs in molecular structure analysis, molecular optimization, and synthesis pathway prediction, demonstrating that scientific reasoning is not solely an emergent ability of model scale, but a learnable policy of tool orchestration. This work establishes a cost-effective and privacy-preserving paradigm for AI-aided chemistry, opening new avenues for accelerating molecular discovery with locally deployable agents.

</details>


### [475] [Do Reasoning Models Ask Better Questions? A Formal Information-Theoretic Analysis on Multi-Turn LLM Games](https://arxiv.org/abs/2601.17716)
*Daniel M. Pedrozo,Telma W. de L. Soares,Bryan L. M. de Oliveira*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出一个多轮对话框架，通过信息增益定量评估LLMs在分层知识图环境中使用是/否问题收集信息的能力，发现具有显式推理能力的模型在部分可观测设置中表现更好。


<details>
  <summary>Details</summary>
Motivation: LLMs在许多任务上表现出色，但在LLM智能体所需的关键能力——为消除用户请求中的歧义而提出好问题——方面仍有不足。现有基准缺乏基于信息增益的全面评估框架，也很少系统比较使用思维链推理和不使用思维链推理的模型。

Method: 提出一个多轮对话框架，使用三个交互的LLM智能体：提问者、回答者和假设空间更新者。采用基于香农熵的信息增益作为主要指标，在五级分类的地理猜城市游戏环境中实例化该框架，评估完全和部分可观测条件下的多种LLM变体。

Result: 实验表明，在评估的模型中，具有显式推理能力的模型每轮获得更高的信息增益，并以更少的步骤达到解决方案，特别是在部分可观测设置中。推理轨迹分析显示，较小模型通过更积极地探索候选问题来弥补有限能力，而较大模型在选择最优查询时表现出更高的自信度。

Conclusion: 该框架为评估LLMs的信息收集能力提供了定量方法，揭示了模型大小和推理能力对问题提出策略的影响，对LLM智能体的发展具有重要意义。

Abstract: Large Language Models (LLMs) excel at many tasks but still struggle with a critical ability for LLM-based agents: asking good questions for resolving ambiguity in user requests. While prior work has explored information-seeking behavior through word games, existing benchmarks lack comprehensive evaluation frameworks that provide both final and intermediate signals based on Information Gain (IG). Moreover, they rarely provide systematic comparisons between models that use chain-of-thought reasoning and those that do not. We propose a multi-turn dialogue framework that quantitatively measures how effectively LLMs gather information through yes/no questions in a hierarchical knowledge graph environment. Our framework employs a triad of interacting LLM agents that ask questions, answer them, and update the hypothesis space. We adopt IG as the main metric, grounded in Shannon entropy, to assess query effectiveness at each turn and cumulatively. We instantiate our framework in a geographical Guess My City game setting organized in a five-level taxonomy and evaluate multiple LLM variants under fully and partially observable conditions, with and without Chain-of-Thought reasoning. Our experiments demonstrate that, among the evaluated models, the ones with explicit reasoning capabilities achieve higher IG per turn and reach solutions in fewer steps, particularly in partially observable settings. Analysis of reasoning traces reveals that smaller models compensate for limited capacity through more aggressive exploration of candidate questions, while larger models exhibit higher assertiveness in selecting optimal queries, generating candidates with greater potential IG.

</details>


### [476] [AR-Omni: A Unified Autoregressive Model for Any-to-Any Generation](https://arxiv.org/abs/2601.17761)
*Dongjie Cheng,Ruifeng Yuan,Yongqi Li,Runyang You,Wenjie Wang,Liqiang Nie,Lei Zhang,Wenjie Li*

Main category: cs.LG

Relevance: 85.0

TL;DR: AR-Omni：基于自回归范式的统一多模态模型，支持文本、图像和流式语音的任意到任意生成，无需专家解码器，在单一Transformer解码器中实现所有模态处理。


<details>
  <summary>Details</summary>
Motivation: 现实世界的感知和交互本质上是多模态的，需要支持多模态输入和输出的"全能"MLLMs。现有系统通常依赖额外的专家组件来实现多模态生成，限制了统一训练和推理的简洁性。自回归建模在文本领域已被证明是优雅且可扩展的基础，因此作者希望将这一范式扩展到多模态领域。

Method: 1. 提出AR-Omni统一模型，在单一Transformer解码器中支持自回归文本和图像生成以及流式语音生成；2. 通过任务感知损失重加权解决模态不平衡问题；3. 使用轻量级token级感知对齐损失提高视觉保真度；4. 采用有限状态解码机制平衡稳定性和创造性。

Result: AR-Omni在三个模态上都实现了强大的生成质量，同时保持实时性，语音生成的实时因子达到0.88。模型在统一的自回归框架下实现了多模态生成，无需额外的专家解码器。

Conclusion: 自回归范式可以成功扩展到多模态领域，实现统一的任意到任意生成。通过解决模态不平衡、视觉保真度和稳定-创造性权衡等实际问题，AR-Omni展示了在单一Transformer解码器中实现高质量多模态生成的可行性。

Abstract: Real-world perception and interaction are inherently multimodal, encompassing not only language but also vision and speech, which motivates the development of "Omni" MLLMs that support both multimodal inputs and multimodal outputs. While a sequence of omni MLLMs has emerged, most existing systems still rely on additional expert components to achieve multimodal generation, limiting the simplicity of unified training and inference. Autoregressive (AR) modeling, with a single token stream, a single next-token objective, and a single decoder, is an elegant and scalable foundation in the text domain. Motivated by this, we present AR-Omni, a unified any-to-any model in the autoregressive paradigm without any expert decoders. AR-Omni supports autoregressive text and image generation, as well as streaming speech generation, all under a single Transformer decoder. We further address three practical issues in unified AR modeling: modality imbalance via task-aware loss reweighting, visual fidelity via a lightweight token-level perceptual alignment loss for image tokens, and stability-creativity trade-offs via a finite-state decoding mechanism. Empirically, AR-Omni achieves strong quality across three modalities while remaining real-time, achieving a 0.88 real-time factor for speech generation.

</details>


### [477] [LLM-42: Enabling Determinism in LLM Inference with Verified Speculation](https://arxiv.org/abs/2601.17768)
*Raja Gond,Aditya K Kamath,Arkaprava Basu,Ramachandran Ramjee,Ashish Panwar*

Main category: cs.LG

Relevance: 85.0

TL;DR: LLM-42：一种基于调度的确定性LLM推理方法，通过轻量级验证-回滚循环在保持高吞吐量的同时实现输出确定性


<details>
  <summary>Details</summary>
Motivation: LLM推理中的非确定性源于浮点数非结合性、动态批处理和GPU核函数归约顺序随批次大小变化。现有方法要么禁用动态批处理（严重降低吞吐量），要么需要重新设计核函数（耦合性强且开销固定）。需要一种既能保持高吞吐量又能实现确定性的解决方案。

Method: 受推测解码启发，提出调度方法LLM-42。核心观察：如果序列处于一致状态，即使使用动态批处理，下一个生成的token也可能一致。利用GPU核函数通常使用形状一致归约的特点，采用非确定性快速路径解码token，通过轻量级验证-回滚循环强制执行确定性。验证器在固定形状归约调度下重放候选token，提交保证跨运行一致的token，回滚违反确定性的token。

Result: LLM-42能够在不显著修改现有核函数的情况下实现确定性推理，开销仅与需要确定性的流量成比例，而非固定开销。该方法在保持高吞吐量的同时提供了确定性保证。

Conclusion: LLM-42提供了一种实用的调度方法来解决LLM推理中的非确定性问题，通过解耦确定性与核函数设计，在保持系统性能的同时提供了灵活的确定性控制。

Abstract: In LLM inference, the same prompt may yield different outputs across different runs. At the system level, this non-determinism arises from floating-point non-associativity combined with dynamic batching and GPU kernels whose reduction orders vary with batch size. A straightforward way to eliminate non-determinism is to disable dynamic batching during inference, but doing so severely degrades throughput. Another approach is to make kernels batch-invariant; however, this tightly couples determinism to kernel design, requiring new implementations. This coupling also imposes fixed runtime overheads, regardless of how much of the workload actually requires determinism.
  Inspired by ideas from speculative decoding, we present LLM-42, a scheduling-based approach to enable determinism in LLM inference. Our key observation is that if a sequence is in a consistent state, the next emitted token is likely to be consistent even with dynamic batching. Moreover, most GPU kernels use shape-consistent reductions. Leveraging these insights, LLM-42 decodes tokens using a non-deterministic fast path and enforces determinism via a lightweight verify-rollback loop. The verifier replays candidate tokens under a fixed-shape reduction schedule, commits those that are guaranteed to be consistent across runs, and rolls back those violating determinism. LLM-42 mostly re-uses existing kernels unchanged and incurs overhead only in proportion to the traffic that requires determinism.

</details>


### [478] [MergeMix: Optimizing Mid-Training Data Mixtures via Learnable Model Merging](https://arxiv.org/abs/2601.17858)
*Jiapeng Wang,Changxin Tian,Kunlong Chen,Ziqi Liu,Jiaxin Mao,Wayne Xin Zhao,Zhiqiang Zhang,Jun Zhou*

Main category: cs.LG

Relevance: 85.0

TL;DR: MergeMix：一种通过模型合并权重作为性能代理来高效优化数据混合比例的新方法，显著降低搜索成本


<details>
  <summary>Details</summary>
Motivation: 当前优化大型语言模型数据混合比例的方法依赖启发式试验或昂贵的代理训练，计算成本过高，需要一种高效、自动化的解决方案

Method: 通过训练领域特定专家模型（使用少量tokens），然后优化这些专家模型的合并权重来作为数据混合比例的性能代理，从而避免全规模训练的成本

Result: 在8B和16B参数模型上的实验表明，MergeMix达到或超过手动调优的性能，同时显著降低搜索成本，具有高排名一致性（Spearman ρ>0.9）和跨尺度可迁移性

Conclusion: MergeMix为数据混合优化提供了一个可扩展的自动化解决方案，能够高效确定最优数据混合比例，对LLM训练具有重要价值

Abstract: Optimizing data mixtures is essential for unlocking the full potential of large language models (LLMs), yet identifying the optimal composition remains computationally prohibitive due to reliance on heuristic trials or expensive proxy training. To address this, we introduce \textbf{MergeMix}, a novel approach that efficiently determines optimal data mixing ratios by repurposing model merging weights as a high-fidelity, low-cost performance proxy. By training domain-specific experts on minimal tokens and optimizing their merging weights against downstream benchmarks, MergeMix effectively optimizes the performance of data mixtures without incurring the cost of full-scale training. Extensive experiments on models with 8B and 16B parameters validate that MergeMix achieves performance comparable to or surpassing exhaustive manual tuning while drastically reducing search costs. Furthermore, MergeMix exhibits high rank consistency (Spearman $ρ> 0.9$) and strong cross-scale transferability, offering a scalable, automated solution for data mixture optimization.

</details>


### [479] [treaming-dLLM: Accelerating Diffusion LLMs via Suffix Pruning and Dynamic Decoding](https://arxiv.org/abs/2601.17917)
*Zhongyu Xiao,Zhiwei Hao,Jianyuan Guo,Yong Luo,Jia Liu,Jie Xu,Han Hu*

Main category: cs.LG

Relevance: 85.0

TL;DR: Streaming-dLLM是一个训练免费的框架，通过空间和时间维度优化扩散大语言模型的推理效率，实现高达68.2倍的加速同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有扩散大语言模型推理加速方法（如KV缓存重用或启发式解码）忽略了块状扩散过程中的内在低效性：空间冗余（对信息稀疏的后缀区域统一建模）和时间低效（在整个解码过程中应用固定的去噪调度）。

Method: 1. 空间维度：引入衰减引导的后缀建模，通过剪枝冗余的掩码标记来近似完整上下文；2. 时间维度：采用动态置信度感知策略和提前退出机制，允许模型跳过已收敛标记的不必要迭代。

Result: 实验表明Streaming-dLLM在保持生成质量的同时实现了高达68.2倍的加速，显著提升了扩散解码的效率。

Conclusion: Streaming-dLLM通过空间和时间维度的优化，有效解决了扩散大语言模型推理中的内在低效问题，为扩散解码提供了高效的训练免费解决方案。

Abstract: Diffusion Large Language Models (dLLMs) offer a compelling paradigm for natural language generation, leveraging parallel decoding and bidirectional attention to achieve superior global coherence compared to autoregressive models. While recent works have accelerated inference via KV cache reuse or heuristic decoding, they overlook the intrinsic inefficiencies within the block-wise diffusion process. Specifically, they suffer from spatial redundancy by modeling informative-sparse suffix regions uniformly and temporal inefficiency by applying fixed denoising schedules across all the decoding process. To address this, we propose Streaming-dLLM, a training-free framework that streamlines inference across both spatial and temporal dimensions. Spatially, we introduce attenuation guided suffix modeling to approximate the full context by pruning redundant mask tokens. Temporally, we employ a dynamic confidence aware strategy with an early exit mechanism, allowing the model to skip unnecessary iterations for converged tokens. Extensive experiments show that Streaming-dLLM achieves up to 68.2X speedup while maintaining generation quality, highlighting its effectiveness in diffusion decoding. The code is available at https://github.com/xiaoshideta/Streaming-dLLM.

</details>


### [480] [TensorLens: End-to-End Transformer Analysis via High-Order Attention Tensors](https://arxiv.org/abs/2601.17958)
*Ido Andrew Atad,Itamar Zimerman,Shahar Katz,Lior Wolf*

Main category: cs.LG

Relevance: 85.0

TL;DR: TensorLens：一种将整个Transformer表示为单个输入依赖线性算子的新方法，通过高阶注意力交互张量统一编码注意力、FFN、激活、归一化和残差连接


<details>
  <summary>Details</summary>
Motivation: 现有注意力分析大多关注单个注意力头或层，缺乏对模型全局行为的考虑。虽然已有研究尝试通过平均和矩阵乘法扩展注意力公式，或纳入归一化和FFN等组件，但仍缺乏一个统一完整的表示来封装所有Transformer块。

Method: 提出TensorLens，一种新颖的公式化方法，将整个Transformer捕获为单个输入依赖的线性算子，通过高阶注意力交互张量表示。该张量联合编码注意力、FFN、激活、归一化和残差连接，提供理论上连贯且富有表达力的线性表示。

Result: 经验验证表明TensorLens比之前的注意力聚合方法产生更丰富的表示。实验证明注意力张量可以作为开发可解释性和模型理解工具的强大基础。

Conclusion: TensorLens填补了Transformer全局表示的理论空白，为模型理解提供了更全面和统一的框架，有望推动可解释性工具的发展。

Abstract: Attention matrices are fundamental to transformer research, supporting a broad range of applications including interpretability, visualization, manipulation, and distillation. Yet, most existing analyses focus on individual attention heads or layers, failing to account for the model's global behavior. While prior efforts have extended attention formulations across multiple heads via averaging and matrix multiplications or incorporated components such as normalization and FFNs, a unified and complete representation that encapsulates all transformer blocks is still lacking. We address this gap by introducing TensorLens, a novel formulation that captures the entire transformer as a single, input-dependent linear operator expressed through a high-order attention-interaction tensor. This tensor jointly encodes attention, FFNs, activations, normalizations, and residual connections, offering a theoretically coherent and expressive linear representation of the model's computation. TensorLens is theoretically grounded and our empirical validation shows that it yields richer representations than previous attention-aggregation methods. Our experiments demonstrate that the attention tensor can serve as a powerful foundation for developing tools aimed at interpretability and model understanding. Our code is attached as a supplementary.

</details>


### [481] [Federated learning for unpaired multimodal data through a homogeneous transformer model](https://arxiv.org/abs/2601.17986)
*Anders Eklund*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出联邦学习中训练多模态基础模型的新框架，能够在数据模态不配对且分散在不同节点的情况下，通过公共锚点集对齐私有流形，无需共享原始数据或特征嵌入。


<details>
  <summary>Details</summary>
Motivation: 现实联邦环境中，数据通常不配对且分散在不同节点（如图像和文本分别存储在不同节点），这些数据严格私有且没有共同样本。现有联邦学习方法假设本地客户端拥有对齐的数据对或需要共享原始特征嵌入，这违反了数据主权。

Method: 1) 引入小型公共锚点集对齐不配对的私有流形；2) 使用从公共锚点计算的Gram矩阵，通过中心核对齐实现跨模态语义对齐，不传输私有样本；3) 提出子空间稳定微调方法处理大型Transformer模型；4) 提出精度加权平均，使用不确定性估计对不确定节点降权。

Result: 建立了联邦不配对基础模型的数学基础，使全局模型能够从分散、不配对和私有的数据孤岛中学习世界的统一表示，无需集中存储或配对样本。

Conclusion: 该框架为联邦不配对基础模型提供了数学基础，解决了现实联邦环境中数据模态不配对、分散且私有的挑战，具有比原型共享更强的隐私保证。

Abstract: Training of multimodal foundation models is currently restricted to centralized data centers containing massive, aligned datasets (e.g., image-text pairs). However, in realistic federated environments, data is often unpaired and fragmented across disjoint nodes; one node may hold sensor data, while another holds textual logs. These datasets are strictly private and share no common samples. Current federated learning (FL) methods fail in this regime, as they assume local clients possess aligned pairs or require sharing raw feature embeddings, which violates data sovereignty. We propose a novel framework to train a global multimodal transformer across decentralized nodes with disjoint modalities. We introduce a small public anchor set to align disjoint private manifolds. Using Gram matrices calculated from these public anchors, we enforce semantic alignment across modalities through centered kernel alignment without ever transmitting private samples, offering a mathematically superior privacy guarantee compared to prototype sharing. Further, we introduce a subspace-stabilized fine-tuning method to handle FL with huge transformer models. We strictly decouple domain-specific magnitude shifts from semantic direction, ensuring that nodes with varying sensor characteristics align geometrically to the global consensus. Lastly, we propose precision weighted averaging, where efficiently obtained uncertainty estimates are used to downweight uncertain nodes. This paper establishes the mathematical backbone for federated unpaired foundation models, enabling a global model to learn a unified representation of the world from fragmented, disjoint, and private data silos without requiring centralized storage or paired samples.

</details>


### [482] [Comparison requires valid measurement: Rethinking attack success rate comparisons in AI red teaming](https://arxiv.org/abs/2601.18076)
*Alexandra Chouldechova,A. Feder Cooper,Solon Barocas,Abhinav Palia,Dan Vann,Hanna Wallach*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文指出，基于攻击成功率（ASR）比较来评估AI系统安全性或攻击方法有效性的结论往往缺乏证据支持，因为存在"苹果与橙子"的比较和低效度测量问题。论文从测量理论和统计推断角度提出了ASR有意义比较的条件。


<details>
  <summary>Details</summary>
Motivation: 当前AI红队测试中，研究者经常通过攻击成功率（ASR）的比较来得出关于系统相对安全性或攻击方法有效性的结论。然而，这些比较往往存在方法论问题，导致结论不可靠。论文旨在解决ASR比较中的效度和可比性问题。

Method: 论文采用概念分析、理论框架和实证研究相结合的方法。首先从社会科学测量理论和统计推断角度建立概念基础，提出ASR有意义比较的条件。然后以越狱攻击为例，详细分析ASR比较中的"苹果与橙子"问题和测量效度挑战。

Result: 论文揭示了当前AI红队测试中ASR比较存在的系统性方法论问题，包括：1）不同攻击方法在不可比条件下进行比较；2）测量效度不足；3）统计推断基础薄弱。通过越狱攻击案例展示了这些问题的具体表现。

Conclusion: 基于ASR比较得出的AI系统安全性或攻击方法有效性结论需要谨慎对待。研究者需要建立更严格的测量框架和可比性标准，确保比较在统计上有效且概念上一致。这对AI安全评估具有重要意义。

Abstract: We argue that conclusions drawn about relative system safety or attack method efficacy via AI red teaming are often not supported by evidence provided by attack success rate (ASR) comparisons. We show, through conceptual, theoretical, and empirical contributions, that many conclusions are founded on apples-to-oranges comparisons or low-validity measurements. Our arguments are grounded in asking a simple question: When can attack success rates be meaningfully compared? To answer this question, we draw on ideas from social science measurement theory and inferential statistics, which, taken together, provide a conceptual grounding for understanding when numerical values obtained through the quantification of system attributes can be meaningfully compared. Through this lens, we articulate conditions under which ASRs can and cannot be meaningfully compared. Using jailbreaking as a running example, we provide examples and extensive discussion of apples-to-oranges ASR comparisons and measurement validity challenges.

</details>


### [483] [DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal](https://arxiv.org/abs/2601.18081)
*Peixuan Han,Yingjie Yu,Jingjun Xu,Jiaxuan You*

Main category: cs.LG

Relevance: 85.0

TL;DR: DRPG是一个用于学术反驳生成的智能体框架，通过分解、检索、规划和生成四步流程，使用8B模型就能超越人类平均水平的反驳质量。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在科研工作流中应用日益广泛，但学术反驳这一学术交流和同行评审的关键环节仍缺乏自动化支持。现有方法通常依赖现成的LLMs或简单流水线，难以处理长上下文理解，且无法生成有针对性和说服力的回应。

Method: 提出DRPG框架，包含四个步骤：1) 将审稿意见分解为原子化关注点；2) 从论文中检索相关证据；3) 规划反驳策略；4) 生成相应回应。特别地，规划器在识别最可行反驳方向方面达到超过98%的准确率。

Result: 在顶级会议数据上的实验表明，DRPG显著优于现有反驳流水线，仅使用8B模型就达到了超越人类平均水平的性能。分析进一步证明了规划器设计的有效性及其在提供多视角和可解释建议方面的价值。DRPG在更复杂的多轮设置中也表现良好。

Conclusion: DRPG框架有效提升了学术反驳的自动化水平，能够提供高质量的反驳内容，支持学术讨论的规模化扩展。该工作展示了智能体框架在复杂学术任务中的潜力。

Abstract: Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at https://github.com/ulab-uiuc/DRPG-RebuttalAgent.

</details>


### [484] [LatentMoE: Toward Optimal Accuracy per FLOP and Parameter in Mixture of Experts](https://arxiv.org/abs/2601.18089)
*Venmugil Elango,Nidhi Bhatia,Roger Waleffe,Rasoul Shafipour,Tomer Asida,Abhinav Khattar,Nave Assaf,Maximilian Golub,Joey Guman,Tiyasa Mitra,Ritchie Zhao,Ritika Borkar,Ran Zilberstein,Mostofa Patwary,Mohammad Shoeybi,Bita Rouhani*

Main category: cs.LG

Relevance: 85.0

TL;DR: LatentMoE：一种从硬件-软件协同设计角度优化的MoE架构，在推理成本和参数效率方面优于标准MoE，已被Nemotron-3模型采用


<details>
  <summary>Details</summary>
Motivation: 尽管MoE已成为最先进LLM的核心组件，但现有MoE架构在推理成本（以每FLOP和每参数的准确率衡量）方面是否接近最优仍不清楚。需要从硬件-软件协同设计角度重新审视MoE设计。

Method: 从硬件-软件协同设计视角，基于经验和理论考虑，分析不同部署场景下的性能瓶颈。通过系统化设计空间探索（最高95B参数、1T token训练），结合理论分析，提出LatentMoE架构。

Result: LatentMoE在每FLOP和每参数准确率方面持续优于标准MoE架构。该架构已被Nemotron-3 Super和Ultra模型采用，并扩展到更大规模（更长token序列和更大模型尺寸）。

Conclusion: 通过硬件-软件协同设计方法优化的MoE架构能显著提升推理效率和参数效率，LatentMoE展示了系统化设计探索的价值，并为大规模模型部署提供了更优解决方案。

Abstract: Mixture of Experts (MoEs) have become a central component of many state-of-the-art open-source and proprietary large language models. Despite their widespread adoption, it remains unclear how close existing MoE architectures are to optimal with respect to inference cost, as measured by accuracy per floating-point operation and per parameter. In this work, we revisit MoE design from a hardware-software co-design perspective, grounded in empirical and theoretical considerations. We characterize key performance bottlenecks across diverse deployment regimes, spanning offline high-throughput execution and online, latency-critical inference. Guided by these insights, we introduce LatentMoE, a new model architecture resulting from systematic design exploration and optimized for maximal accuracy per unit of compute. Empirical design space exploration at scales of up to 95B parameters and over a 1T-token training horizon, together with supporting theoretical analysis, shows that LatentMoE consistently outperforms standard MoE architectures in terms of accuracy per FLOP and per parameter. Given its strong performance, the LatentMoE architecture has been adopted by the flagship Nemotron-3 Super and Ultra models and scaled to substantially larger regimes, including longer token horizons and larger model sizes, as reported in Nvidia et al. (arXiv:2512.20856).

</details>


### [485] [From LLMs to LRMs: Rethinking Pruning for Reasoning-Centric Models](https://arxiv.org/abs/2601.18091)
*Longwei Ding,Anhao Zhao,Fanghua Ye,Ziyang Chen,Xiaoyu Shen*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文研究了推理增强型大语言模型（LLM-think）与指令跟随型模型（LLM-instruct）在剪枝策略上的差异，发现不同范式需要不同的剪枝方法


<details>
  <summary>Details</summary>
Motivation: 现有剪枝研究主要关注指令跟随型LLM，但推理增强型模型会生成长中间推理轨迹，不清楚现有剪枝策略是否适用于这类模型

Method: 对指令跟随型（LLM-instruct）和推理增强型（LLM-think）模型进行对照研究，采用对齐剪枝校准和恢复数据的方法，评估静态深度剪枝、静态宽度剪枝和动态剪枝在17个任务上的表现

Result: 发现范式依赖的差异：深度剪枝在分类任务上表现更好，宽度剪枝在生成和推理任务上更鲁棒；静态剪枝能更好地保持推理性能，动态剪枝在分类和生成任务上表现优异但在长链推理上仍有挑战

Conclusion: 推理增强型LLM需要专门考虑其特点的剪枝策略，不能简单沿用指令跟随型模型的剪枝方法

Abstract: Large language models (LLMs) are increasingly costly to deploy, motivating extensive research on model pruning. However, most existing studies focus on instruction-following LLMs, leaving it unclear whether established pruning strategies transfer to reasoning-augmented models that explicitly generate long intermediate reasoning traces. In this work, we conduct a controlled study of pruning for both instruction-following ($\textbf{LLM-instruct}$) and reasoning-augmented ($\textbf{LLM-think}$) models. To isolate the effects of pruning, we align pruning calibration and post-pruning recovery data with each model's original training distribution, which we show yields more stable and reliable pruning behavior. We evaluate static depth pruning, static width pruning, and dynamic pruning across 17 tasks spanning classification, generation, and reasoning. Our results reveal clear paradigm-dependent differences: depth pruning outperforms width pruning on classification tasks, while width pruning is more robust for generation and reasoning. Moreover, static pruning better preserves reasoning performance, whereas dynamic pruning excels on classification and generation but remains challenging for long-chain reasoning. These findings underscore the need for pruning strategies that explicitly account for the distinct characteristics of reasoning-augmented LLMs. Our code is publicly available at https://github.com/EIT-NLP/LRM-Pruning.

</details>


### [486] [AttenMIA: LLM Membership Inference Attack through Attention Signals](https://arxiv.org/abs/2601.18110)
*Pedram Zaree,Md Abdullah Al Mamun,Yue Dong,Ihsen Alouani,Nael Abu-Ghazaleh*

Main category: cs.LG

Relevance: 85.0

TL;DR: AttenMIA：利用Transformer自注意力模式进行成员推断攻击的新框架，通过分析注意力头在不同层的模式来识别训练数据成员，在低误报率下显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: LLMs的大规模训练数据导致记忆训练数据的问题，引发隐私和知识产权担忧。现有成员推断攻击主要依赖输出置信度或嵌入特征，但这些信号脆弱且攻击成功率有限。注意力机制控制Transformer内部信息流，可能暴露不同的记忆模式用于识别数据集成员。

Method: 提出AttenMIA框架，利用Transformer内部的自注意力模式推断成员身份。方法从各层注意力头提取信息，结合基于扰动的发散度量训练有效的MIA分类器。通过跨层和跨头的注意力模式分析，识别成员泄露最显著的位置。

Result: 在LLaMA-2、Pythia、Opt等开源模型上的实验表明，基于注意力的特征始终优于基线方法，特别是在重要的低误报率指标上（在WikiMIA-32基准测试中，Llama2-13b达到0.996 ROC AUC和87.9% TPR@1%FPR）。注意力信号在不同数据集和架构间具有泛化性，使用AttenMIA的数据提取攻击优于现有技术。

Conclusion: 注意力机制虽然最初是为了增强可解释性而引入，但无意中放大了LLMs的隐私风险。AttenMIA揭示了注意力模式作为成员推断的强大信号，强调了开发新防御措施的必要性。

Abstract: Large Language Models (LLMs) are increasingly deployed to enable or improve a multitude of real-world applications. Given the large size of their training data sets, their tendency to memorize training data raises serious privacy and intellectual property concerns. A key threat is the membership inference attack (MIA), which aims to determine whether a given sample was included in the model's training set. Existing MIAs for LLMs rely primarily on output confidence scores or embedding-based features, but these signals are often brittle, leading to limited attack success. We introduce AttenMIA, a new MIA framework that exploits self-attention patterns inside the transformer model to infer membership. Attention controls the information flow within the transformer, exposing different patterns for memorization that can be used to identify members of the dataset. Our method uses information from attention heads across layers and combines them with perturbation-based divergence metrics to train an effective MIA classifier. Using extensive experiments on open-source models including LLaMA-2, Pythia, and Opt models, we show that attention-based features consistently outperform baselines, particularly under the important low-false-positive metric (e.g., achieving up to 0.996 ROC AUC & 87.9% TPR@1%FPR on the WikiMIA-32 benchmark with Llama2-13b). We show that attention signals generalize across datasets and architectures, and provide a layer- and head-level analysis of where membership leakage is most pronounced. We also show that using AttenMIA to replace other membership inference attacks in a data extraction framework results in training data extraction attacks that outperform the state of the art. Our findings reveal that attention mechanisms, originally introduced to enhance interpretability, can inadvertently amplify privacy risks in LLMs, underscoring the need for new defenses.

</details>


### [487] [Enhance the Safety in Reinforcement Learning by ADRC Lagrangian Methods](https://arxiv.org/abs/2601.18142)
*Mingxu Zhang,Huicheng Zhang,Jiaming Ji,Yaodong Yang,Ying Sun*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出ADRC-Lagrangian方法，将主动抗扰控制(ADRC)集成到Safe RL中，显著减少安全违规和振荡，相比传统Lagrangian方法在复杂环境中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有Safe RL方法（包括PID和经典Lagrangian方法）存在振荡和频繁安全违规问题，主要源于参数敏感性和固有的相位滞后。需要更鲁棒的控制方法来改善安全性能。

Method: 提出ADRC-Lagrangian框架，将主动抗扰控制(ADRC)集成到Lagrangian方法中。ADRC能够估计和补偿系统扰动，增强鲁棒性，减少振荡。该框架统一了经典和PID Lagrangian方法作为特例。

Result: 实验表明，该方法减少安全违规达74%，约束违规幅度减少89%，平均成本降低67%，在复杂环境中表现出显著优越性。

Conclusion: ADRC-Lagrangian方法为Safe RL提供了更鲁棒、更有效的解决方案，显著改善了安全性能，适用于复杂环境中的强化学习应用。

Abstract: Safe reinforcement learning (Safe RL) seeks to maximize rewards while satisfying safety constraints, typically addressed through Lagrangian-based methods. However, existing approaches, including PID and classical Lagrangian methods, suffer from oscillations and frequent safety violations due to parameter sensitivity and inherent phase lag. To address these limitations, we propose ADRC-Lagrangian methods that leverage Active Disturbance Rejection Control (ADRC) for enhanced robustness and reduced oscillations. Our unified framework encompasses classical and PID Lagrangian methods as special cases while significantly improving safety performance. Extensive experiments demonstrate that our approach reduces safety violations by up to 74%, constraint violation magnitudes by 89%, and average costs by 67\%, establishing superior effectiveness for Safe RL in complex environments.

</details>


### [488] [FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning](https://arxiv.org/abs/2601.18150)
*Zhaopeng Qiu,Shuang Yu,Jingqi Zhang,Shuai Zhang,Xue Huang,Jingyi Yang,Junjie Lai*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出了一个用于大语言模型强化学习的FP8推理栈，通过W8A8线性层量化、KV缓存FP8化和重要性采样校正，在保持学习效果的同时提升44%的推理吞吐量


<details>
  <summary>Details</summary>
Motivation: 大语言模型强化学习中的推理（生成）阶段越来越成为瓶颈，长输出序列使得注意力机制和KV缓存内存主导端到端时间。FP8提供了加速RL的潜力，但面临权重频繁变化和训练-推理不匹配的挑战

Method: 1) 使用块状FP8量化实现W8A8线性层推理；2) 通过每步QKV尺度重新校准将FP8扩展到KV缓存；3) 使用基于重要性采样的推理校正（token级TIS/MIS变体）缓解不匹配问题

Result: 在密集和MoE模型上，这些技术实现了高达44%的推理吞吐量提升，同时保持与BF16基线相当的学习行为

Conclusion: 提出了一个实用的FP8推理栈，解决了RL中低精度推理的工程和算法挑战，显著加速了RL训练过程

Abstract: Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.

</details>


### [489] [PaperSearchQA: Learning to Search and Reason over Scientific Papers with RLVR](https://arxiv.org/abs/2601.18207)
*James Burgess,Jan N. Hansen,Duo Peng,Yuhui Zhang,Alejandro Lozano,Min Woo Sun,Emma Lundberg,Serena Yeung-Levy*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出了PaperSearchQA，一个基于1600万篇生物医学论文摘要的搜索语料库和6万个事实性QA样本的数据集，用于训练搜索代理在科学文献中进行检索和推理，超越传统检索基线。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR搜索代理主要针对通用领域QA，限制了在科学、工程和医学等专业技术AI系统中的适用性。需要训练代理在科学论文中进行搜索和推理，这对技术问答具有挑战性，对实际科学家有直接价值，也是未来AI科学家系统的关键能力。

Method: 1) 发布包含1600万篇生物医学论文摘要的搜索语料库；2) 构建包含6万个样本的PaperSearchQA事实性QA数据集；3) 在该环境中训练搜索代理，使用RLVR方法；4) 与基于检索的基线方法进行对比；5) 进行定量分析和行为观察。

Result: 训练的搜索代理在科学文献检索任务中超越了非强化学习的检索基线方法。观察到代理展现出规划、推理和自我验证等有趣行为。数据集和基准测试与流行的Search-R1代码库兼容。

Conclusion: 成功构建了针对科学文献的搜索代理训练环境，展示了在专业技术领域应用RLVR方法的有效性。数据创建方法具有可扩展性，可轻松扩展到其他科学领域。

Abstract: Search agents are language models (LMs) that reason and search knowledge bases (or the web) to answer questions; recent methods supervise only the final answer accuracy using reinforcement learning with verifiable rewards (RLVR). Most RLVR search agents tackle general-domain QA, which limits their relevance to technical AI systems in science, engineering, and medicine. In this work we propose training agents to search and reason over scientific papers -- this tests technical question-answering, it is directly relevant to real scientists, and the capabilities will be crucial to future AI Scientist systems. Concretely, we release a search corpus of 16 million biomedical paper abstracts and construct a challenging factoid QA dataset called PaperSearchQA with 60k samples answerable from the corpus, along with benchmarks. We train search agents in this environment to outperform non-RL retrieval baselines; we also perform further quantitative analysis and observe interesting agent behaviors like planning, reasoning, and self-verification. Our corpus, datasets, and benchmarks are usable with the popular Search-R1 codebase for RLVR training and released on https://huggingface.co/collections/jmhb/papersearchqa. Finally, our data creation methods are scalable and easily extendable to other scientific domains.

</details>


### [490] [Beyond Retention: Orchestrating Structural Safety and Plasticity in Continual Learning for LLMs](https://arxiv.org/abs/2601.18255)
*Fei Meng*

Main category: cs.LG

Relevance: 85.0

TL;DR: 本文揭示了经验回放在大语言模型持续学习中的关键二分现象：对非结构化NLP任务产生正向迁移，但对结构化代码生成任务造成负向迁移，并提出正交子空间唤醒方法来解决这一困境。


<details>
  <summary>Details</summary>
Motivation: 大语言模型持续学习面临平衡稳定性（保留旧知识）和可塑性（学习新任务）的关键挑战。经验回放是防止灾难性遗忘的标准方法，但其对不同能力的影响尚未充分探索。本文旨在揭示经验回放在不同任务类型中的差异影响，并提出解决方案。

Method: 提出正交子空间唤醒方法：1）通过简短的"唤醒"阶段识别先前任务的关键参数子空间；2）对新任务强制执行正交更新，为已建立的知识结构提供数学基础的"安全保证"。

Result: 在多样化的四任务序列上的实证结果表明，OSW在经验回放失败的脆弱编码能力保护方面表现独特，同时保持对新任务的高可塑性。经验回放对非结构化NLP分类任务产生正向向后迁移，但对代码生成等结构化领域造成严重的负向迁移。

Conclusion: 研究强调了在LLM持续学习中评估结构安全性的必要性，而不仅仅是平均保留率。OSW方法为平衡稳定性和可塑性提供了数学基础的安全保证，特别适用于保护脆弱的结构化知识。

Abstract: Continual learning in Large Language Models (LLMs) faces the critical challenge of balancing stability (retaining old knowledge) and plasticity (learning new tasks). While Experience Replay (ER) is a standard countermeasure against catastrophic forgetting, its impact across diverse capabilities remains underexplored. In this work, we uncover a critical dichotomy in ER's behavior: while it induces positive backward transfer on robust, unstructured tasks (e.g., boosting performance on previous NLP classification tasks through repeated rehearsal), it causes severe negative transfer on fragile, structured domains like code generation (e.g., a significant relative drop in coding accuracy). This reveals that ER trades structural integrity for broad consolidation. To address this dilemma, we propose \textbf{Orthogonal Subspace Wake-up (OSW)}. OSW identifies essential parameter subspaces of previous tasks via a brief "wake-up" phase and enforces orthogonal updates for new tasks, providing a mathematically grounded "safety guarantee" for established knowledge structures. Empirical results across a diverse four-task sequence demonstrate that OSW uniquely succeeds in preserving fragile coding abilities where Replay fails, while simultaneously maintaining high plasticity for novel tasks. Our findings emphasize the necessity of evaluating structural safety alongside average retention in LLM continual learning.

</details>


### [491] [FGGM: Fisher-Guided Gradient Masking for Continual Learning](https://arxiv.org/abs/2601.18261)
*Chao-Hong Tan,Qian Chen,Wen Wang,Yukun Ma,Chong Zhang,Chong Deng,Qinglin Zhang,Xiangang Li,Jieping Ye*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出FGGM框架，通过Fisher信息指导的梯度掩码缓解大语言模型持续学习中的灾难性遗忘问题，在TRACE基准上相比SFT提升9.6%，相比MIGU提升4.4%


<details>
  <summary>Details</summary>
Motivation: 大语言模型在持续学习中面临灾难性遗忘问题，现有基于参数幅度的方法（如MIGU）缺乏数学原理支撑，需要更理论化的参数重要性估计方法来平衡稳定性和可塑性

Method: 提出Fisher-Guided Gradient Masking框架，使用对角Fisher信息矩阵战略性地选择需要更新的参数，动态生成具有自适应阈值的二进制掩码，无需历史数据即可保护关键参数

Result: 在TRACE基准上，FGGM相比监督微调在保持通用能力方面有9.6%的相对提升，相比MIGU在TRACE任务上有4.4%的提升；在代码生成任务上的额外分析证实了其优越性能和减少遗忘的效果

Conclusion: FGGM提供了一种基于数学原理的参数重要性估计方法，有效缓解灾难性遗忘，平衡了稳定性和可塑性，是持续学习中的有效解决方案

Abstract: Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.

</details>


### [492] [TriPlay-RL: Tri-Role Self-Play Reinforcement Learning for LLM Safety Alignment](https://arxiv.org/abs/2601.18292)
*Zhewen Tan,Wenhan Yu,Jianfeng Si,Tongxin Liu,Kaiqi Guan,Huiyan Jin,Jiawen Tao,Xiaokun Yuan,Duohe Ma,Xiangzheng Zhang,Tong Yang,Lin Sun*

Main category: cs.LG

Relevance: 85.0

TL;DR: TriPlay-RL：一个用于大语言模型安全对齐的闭环强化学习框架，通过攻击者、防御者和评估者三个角色的协同进化实现安全性能提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的安全风险日益突出，需要减少有毒有害内容的生成。当前主流的安全对齐范式通常采用攻击者、防御者和评估者三个角色的协作框架，但需要大量人工标注。

Method: 提出TriPlay-RL闭环强化学习框架，使三个角色能够在近乎零人工标注的情况下进行迭代式协同改进。攻击者生成对抗性提示，防御者进行安全防御，评估者评估响应质量。

Result: 攻击者在保持高输出多样性的同时，对抗效果提升20%-50%；防御者安全性能提升10%-30%且不降低一般推理能力；评估者通过迭代持续提升细粒度判断能力，能准确区分不安全响应、简单拒绝和有用指导。

Conclusion: 该框架为大语言模型安全对齐建立了高效可扩展的范式，实现了在统一学习循环中的持续协同进化。

Abstract: In recent years, safety risks associated with large language models have become increasingly prominent, highlighting the urgent need to mitigate the generation of toxic and harmful content. The mainstream paradigm for LLM safety alignment typically adopts a collaborative framework involving three roles: an attacker for adversarial prompt generation, a defender for safety defense, and an evaluator for response assessment. In this paper, we propose a closed-loop reinforcement learning framework called TriPlay-RL that enables iterative and co-improving collaboration among three roles with near-zero manual annotation. Experimental results show that the attacker preserves high output diversity while achieving a 20%-50% improvement in adversarial effectiveness; the defender attains 10%-30% gains in safety performance without degrading general reasoning capability; and the evaluator continuously refines its fine-grained judgment ability through iterations, accurately distinguishing unsafe responses, simple refusals, and useful guidance. Overall, our framework establishes an efficient and scalable paradigm for LLM safety alignment, enabling continuous co-evolution within a unified learning loop.

</details>


### [493] [Superlinear Multi-Step Attention](https://arxiv.org/abs/2601.18401)
*Yufeng Huang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出Superlinear attention，一种完全可训练的多步注意力架构，在保持随机上下文访问的同时实现长序列的次二次复杂度。


<details>
  <summary>Details</summary>
Motivation: 标准Transformer的自注意力机制在处理长序列时具有O(L²)的二次复杂度，这限制了模型处理超长上下文的能力。现有的一些高效注意力方法（如稀疏注意力）虽然降低了复杂度，但往往牺牲了随机上下文访问能力，即某些token位置可能被结构性地排除在注意力计算之外。

Method: 将标准因果自注意力重新表述为N步搜索问题，实现O(L^{1+1/N})的复杂度。提出了N=2的基线实现，算法上类似于跳转搜索：第一步进行O(L^{3/2})的跨度搜索来选择相关序列片段，第二步在选中的片段上应用O(L^{3/2})的跨度注意力（标准注意力限制在选定片段内）。

Result: 在修改后的30B混合MoE模型上，单块B200 GPU上实现了：1M上下文长度下平均解码吞吐量114 tokens/sec，10M上下文长度下80 tokens/sec。在有限的训练下，在256K上下文长度的NIAH任务上表现出色，证明路由跨度选择是可端到端学习的。

Conclusion: Superlinear attention提供了一种有前景的架构方案，能够在保持随机上下文访问的同时实现次二次复杂度，为处理超长序列提供了系统可行性。论文侧重于架构表述、扩展分析和系统可行性验证，全面的质量评估留待未来工作。

Abstract: In this paper, we propose \textbf{Superlinear attention}, a fully trainable multi-step attention architecture that achieves subquadratic complexity for long sequences while preserving \textbf{random context access} (a.k.a.\ structural non-exclusion): no eligible token position is structurally excluded from being selected for attention. Superlinear attention reformulates standard causal self-attention as a multi-step search problem with $N$ steps, yielding an overall complexity of $O(L^{1+\frac{1}{N}})$. To illustrate the architecture, we present a baseline $N=2$ implementation, which is algorithmically analogous to standard jump search. In this $O(L^{3/2})$ instantiation, the first step performs $O(L^{3/2})$ span-search to select relevant spans of the sequence, and the second step applies $O(L^{3/2})$ span-attention (standard attention restricted to the selected spans). In an upscaled $O(L^{1.54})$ configuration for robustness, we achieve an average decoding throughput of 114 tokens/sec at 1M context length and 80 tokens/sec at 10M context in our implementation on a modified 30B hybrid MoE model on a single B200 GPU. With limited training, we also obtain strong performance on the NIAH (Needle In A Haystack) task up to 256K context length, demonstrating that the routed span selection is learnable end-to-end. This paper emphasizes architectural formulation, scaling analysis, and systems feasibility, and presents initial validation; comprehensive quality evaluations across diverse long-context tasks are left to future work.

</details>


### [494] [Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates](https://arxiv.org/abs/2601.18510)
*Yibo Li,Zijie Lin,Ailin Deng,Xuan Zhang,Yufei He,Shuo Ji,Tri Cao,Bryan Hooi*

Main category: cs.LG

Relevance: 85.0

TL;DR: JitRL是一个无需训练的强化学习框架，通过动态记忆和轨迹检索实现测试时策略优化，无需梯度更新，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理在部署后权重固定，难以持续适应新任务。传统强化学习计算成本高且存在灾难性遗忘问题，需要一种无需训练的高效适应方法。

Method: JitRL维护动态非参数化记忆库，检索相关经验轨迹实时估计动作优势值，通过加法更新规则直接调制LLM输出logits，理论证明这是KL约束策略优化目标的精确闭式解。

Result: 在WebArena和Jericho基准测试中，JitRL在无需训练方法中达到SOTA，甚至优于计算昂贵的微调方法（如WebRL），同时降低30倍以上的成本。

Conclusion: JitRL为持续学习代理提供了一种可扩展的路径，实现了测试时策略优化而无需梯度更新，在性能和成本效率方面都有显著优势。

Abstract: While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.

</details>


### [495] [LipNeXt: Scaling up Lipschitz-based Certified Robustness to Billion-parameter Models](https://arxiv.org/abs/2601.18513)
*Kai Hu,Haoqi Hu,Matt Fredrikson*

Main category: cs.LG

Relevance: 85.0

TL;DR: LipNeXt：首个无约束、无卷积的1-Lipschitz架构，通过流形优化和空间移位模块实现高效确定性鲁棒性认证，在ImageNet上可扩展到10亿参数规模。


<details>
  <summary>Details</summary>
Motivation: 传统的Lipschitz-based认证方法在模型规模、训练效率和ImageNet性能方面难以扩展，需要一种既能保持确定性鲁棒性保证又能适应现代大规模模型需求的架构。

Method: 提出两种关键技术：1) 直接在正交流形上更新参数的流形优化方法；2) 无需卷积即可建模空间模式的空间移位模块。网络由正交投影、空间移位、1-Lipschitz β-Abs非线性函数和L2空间池化组成。

Result: 在CIFAR-10/100和Tiny-ImageNet上达到最先进的干净准确率和认证鲁棒准确率；在ImageNet上可扩展到10-20亿参数大模型，相比先前Lipschitz模型在ε=1时认证鲁棒准确率提升高达8%，同时保持高效稳定的低精度训练。

Conclusion: Lipschitz-based认证方法可以受益于现代扩展趋势，同时不牺牲确定性或效率，为大规模可信AI提供了新的可能性。

Abstract: Lipschitz-based certification offers efficient, deterministic robustness guarantees but has struggled to scale in model size, training efficiency, and ImageNet performance. We introduce \emph{LipNeXt}, the first \emph{constraint-free} and \emph{convolution-free} 1-Lipschitz architecture for certified robustness. LipNeXt is built using two techniques: (1) a manifold optimization procedure that updates parameters directly on the orthogonal manifold and (2) a \emph{Spatial Shift Module} to model spatial pattern without convolutions. The full network uses orthogonal projections, spatial shifts, a simple 1-Lipschitz $β$-Abs nonlinearity, and $L_2$ spatial pooling to maintain tight Lipschitz control while enabling expressive feature mixing. Across CIFAR-10/100 and Tiny-ImageNet, LipNeXt achieves state-of-the-art clean and certified robust accuracy (CRA), and on ImageNet it scales to 1-2B large models, improving CRA over prior Lipschitz models (e.g., up to $+8\%$ at $\varepsilon{=}1$) while retaining efficient, stable low-precision training. These results demonstrate that Lipschitz-based certification can benefit from modern scaling trends without sacrificing determinism or efficiency.

</details>


### [496] [CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling](https://arxiv.org/abs/2601.18620)
*Panagiotis Lymperopoulos,Abhiramon Rajasekharan,Ian Berlot-Attwell,Stéphane Aroca-Ouellette,Kaheer Suleman*

Main category: cs.LG

Relevance: 85.0

TL;DR: CASSANDRA是一个神经符号世界建模方法，利用LLM作为知识先验构建轻量级转换模型用于规划，结合LLM合成代码建模确定性特征和LLM引导的概率图模型结构学习捕获随机变量间的因果关系。


<details>
  <summary>Details</summary>
Motivation: 在商业等现实世界领域中构建世界模型对于规划至关重要。这些领域具有丰富的语义，可以利用世界知识从有限数据中有效建模复杂的动作效果和因果关系。

Method: CASSANDRA整合两个组件：1) LLM合成的代码建模确定性特征；2) LLM引导的概率图模型结构学习，捕获随机变量间的因果关系。该方法利用LLM作为知识先验构建轻量级转换模型。

Result: 在小型咖啡店模拟器和复杂的主题公园商业模拟器中评估，在转换预测和规划方面相比基线有显著改进。

Conclusion: CASSANDRA展示了利用LLM作为知识先验构建世界模型的有效性，特别适用于具有丰富语义的现实世界领域规划任务。

Abstract: Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.

</details>


### [497] [Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning](https://arxiv.org/abs/2601.18699)
*Olaf Yunus Laitinen Imanov*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文对Transformer大语言模型在连续微调中的灾难性遗忘现象进行了机制性分析，识别了梯度干扰、表征漂移和损失景观平坦化三个主要机制，发现遗忘程度与任务相似度高度相关。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在预训练和微调中表现出色，但在连续任务微调中会出现灾难性遗忘现象，新学知识会干扰已学能力。目前对这一现象的机制理解有限，需要深入分析以开发有效的缓解策略。

Method: 通过系统实验分析不同规模模型（109B到400B参数）在任务序列上的表现，识别灾难性遗忘的主要机制，包括梯度干扰、表征漂移和损失景观平坦化，并分析任务相似度与遗忘程度的关系。

Result: 发现遗忘严重程度与任务相似度高度相关（Pearson r = 0.87），约15-23%的注意力头在微调过程中受到严重干扰，较低层表现出更大的易感性，梯度对齐指标与遗忘程度有强相关性。

Conclusion: 该研究建立了灾难性遗忘的机制基础，为开发针对性的持续学习系统缓解策略提供了理论依据，有助于改进大语言模型的连续微调能力。

Abstract: Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.

</details>


### [498] [Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models](https://arxiv.org/abs/2601.18734)
*Siyan Zhao,Zhihui Xie,Mengchen Liu,Jing Huang,Guan Pang,Feiyu Chen,Aditya Grover*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出On-Policy Self-Distillation (OPSD)框架，让单个LLM同时扮演教师和学生角色，通过在不同上下文条件下进行知识蒸馏，提高数学推理能力，相比强化学习方法实现4-8倍的token效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有on-policy蒸馏方法通常需要单独的、更大的教师模型，且未充分利用推理数据集中可用的真实解决方案。受启发于"足够强大的LLM能够推理外部特权信息并教导其较弱版本"的直觉，提出自蒸馏框架。

Method: OPSD框架让单个模型同时作为教师和学生：教师策略基于特权信息（如已验证的推理轨迹），学生策略仅看到问题；训练时在学生自身生成的轨迹上最小化两个分布之间的每token差异。

Result: 在多个数学推理基准测试中，相比GRPO等强化学习方法实现4-8倍的token效率提升，且性能优于off-policy蒸馏方法。

Conclusion: OPSD提供了一种高效的知识蒸馏方法，无需单独的教师模型，能够利用特权信息进行自蒸馏，在数学推理任务上表现出色。

Abstract: Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.

</details>


### [499] [Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback](https://arxiv.org/abs/2601.18751)
*Seyed Amir Hosseini,Maryam Abdolali,Amirhosein Tavakkoli,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi*

Main category: cs.LG

Relevance: 85.0

TL;DR: TriTrust-PBRL (TTP) 是一个处理异构标注者偏好的强化学习框架，能自动识别可靠、噪声和对抗性标注者，通过信任参数学习共享奖励模型，在对抗性标注下保持接近最优性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的偏好数据通常来自异构的标注者，包括准确、噪声和系统性对抗的标注者。现有的基于偏好的强化学习方法要么平等对待所有反馈，要么试图过滤不可靠来源，但在面对系统性提供错误偏好的对抗性标注者时都会失败。

Method: TriTrust-PBRL (TTP) 是一个统一框架，从多专家偏好反馈中联合学习共享奖励模型和专家特定的信任参数。关键洞察是信任参数在基于梯度的优化过程中自然演变为正值（信任）、接近零（忽略）或负值（翻转），使模型能够自动反转对抗性偏好并恢复有用信号，而不仅仅是丢弃损坏的反馈。

Result: 在四个不同领域（MetaWorld 操作任务和 DM Control 运动任务）的各种损坏场景下评估 TTP。TTP 实现了最先进的鲁棒性，在对抗性损坏下保持接近最优性能，而标准 PBRL 方法则完全失败。TTP 成功地从包含可靠和对抗性标注者的混合专家池中学习，表现优于现有基线方法。

Conclusion: TriTrust-PBRL 提供了一种有效处理异构标注者偏好的方法，特别是能够处理对抗性标注者，通过自动学习信任参数来反转对抗性偏好，为基于偏好的强化学习提供了更强的鲁棒性保证。

Abstract: Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.

</details>


### [500] [HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs](https://arxiv.org/abs/2601.18753)
*Xinyue Zeng,Junhong Lin,Yujun Yan,Feng Guo,Liang Shi,Jun Wu,Dawei Zhou*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出了Hallucination Risk Bound理论框架，将幻觉风险分解为数据驱动和推理驱动两部分，并基于此开发了HalluGuard检测方法，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: LLM在医疗、法律等高风险领域应用时，幻觉问题严重影响可靠性。现有检测方法通常只针对单一来源（数据驱动或推理驱动），且依赖任务特定启发式方法，难以泛化到复杂场景。

Method: 1. 提出Hallucination Risk Bound理论框架，将幻觉风险形式化分解为数据驱动（训练时失配）和推理驱动（推理时不稳定性）两部分；2. 基于此开发HalluGuard方法，利用NTK（神经正切核）的几何结构和捕获的表征来联合检测两种幻觉来源。

Result: 在10个多样化基准测试、11个竞争性基线方法和9个流行LLM骨干网络上评估，HalluGuard在检测多种形式LLM幻觉方面始终达到最先进的性能。

Conclusion: Hallucination Risk Bound为分析幻觉产生和演化提供了理论基础，HalluGuard作为统一的检测方法，能够有效识别数据驱动和推理驱动的幻觉，提升LLM在高风险领域的可靠性。

Abstract: The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.

</details>


### [501] [Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values](https://arxiv.org/abs/2601.18760)
*Henry Bell,Lara Neubauer da Costa Schertel,Bochu Ding,Brandon Fain*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出Grounded Constitutional AI (GCAI)框架，通过结合用户对AI的普遍期望（通用原则）和交互时偏好（情境原则）来生成更具代表性的人工智能宪法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM对齐框架中，宪法原则的确定缺乏广泛的利益相关者参与，难以公平地反映用户期望和偏好。

Method: 扩展Inverse Constitutional AI (ICAI)方法，利用人类偏好标注数据中的"原因"生成情境原则，并结合用户关于AI的"价值观"陈述提取通用原则。

Result: 人类评估显示，GCAI生成的宪法在个人偏好和广泛使用方面都优于ICAI生成的宪法，被认为更具道德基础、连贯性和多元性。

Conclusion: GCAI框架能够生成更全面、更具代表性的AI宪法，为LLM对齐提供了更公平、包容的方法。

Abstract: A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.

</details>


### [502] [PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation](https://arxiv.org/abs/2601.18777)
*Abhishek Divekar,Anirban Majumder*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出PRECISE框架，结合少量人工标注和LLM判断来评估搜索/排序/RAG系统，显著减少标注需求并校正LLM偏见


<details>
  <summary>Details</summary>
Motivation: 传统搜索、排序和RAG系统评估需要大量人工标注，而LLM作为自动评估器存在偏见，需要一种结合少量人工标注和LLM判断的可靠评估方法

Method: 扩展预测驱动推理(PPI)的统计框架，将最小化人工标注与LLM判断结合，重新定义指标集成空间，将计算复杂度从O(2^|C|)降低到O(2^K)

Result: 仅需100个标注查询和10,000个未标注样本，显著降低标注需求；在多个检索数据集上减少Precision@K指标的方差，有效校正低资源设置下的LLM偏见

Conclusion: PRECISE框架为LLM增强的搜索系统提供了一种高效可靠的评估方法，平衡了标注成本与评估准确性

Abstract: Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.

</details>


### [503] [Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability](https://arxiv.org/abs/2601.18778)
*Shobhita Sundaram,John Quan,Ariel Kwiatkowski,Kartik Ahuja,Yann Ollivier,Julia Kempe*

Main category: cs.LG

Relevance: 85.0

TL;DR: SOAR：一个基于元强化学习的自我改进框架，通过教师模型生成合成问题来创建自动课程，帮助模型在初始成功率极低（0/128）的困难推理问题上突破学习瓶颈。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在微调大型推理模型时，面对初始成功率极低的数据集会陷入学习瓶颈，因为缺乏足够的训练信号。本文探索一个核心问题：预训练LLM能否利用其潜在知识为自身无法解决的问题生成自动课程？

Method: SOAR框架采用元强化学习：教师模型副本为学生模型副本生成合成问题，并根据学生在少量困难问题上的进步获得奖励。关键创新在于将课程设计基于实际的学生进步测量，而非内在代理奖励。

Result: 在数学基准测试最困难子集（初始成功率0/128）上的实验表明：1）可以实现双层元强化学习，利用预训练模型生成有用"垫脚石"的能力；2）基于实际进步的奖励优于先前LLM自对弈中的内在奖励方案，避免了不稳定性和多样性崩溃；3）生成问题的结构质量和明确性比解决方案的正确性对学习进步更重要。

Conclusion: 研究表明，生成有用"垫脚石"的能力并不需要预先具备解决困难问题的能力，这为在没有额外策划数据的情况下突破推理瓶颈提供了原则性路径。

Abstract: Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.

</details>


### [504] [POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration](https://arxiv.org/abs/2601.18779)
*Yuxiao Qu,Amrith Setlur,Virginia Smith,Ruslan Salakhutdinov,Aviral Kumar*

Main category: cs.LG

Relevance: 85.0

TL;DR: POPE是一种利用特权信息（如人类解决方案）引导LLM在困难推理问题上探索的强化学习方法，通过添加解决方案前缀获得非零奖励，然后将学习到的行为迁移回原始问题。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习方法在困难推理问题上存在探索问题，难以获得任何正确轨迹和奖励信号。传统RL方法（如熵奖励、重要性比率调整）无法解决此问题，而混合简单和困难问题训练会因射线干扰而适得其反。

Method: POPE利用人类或其他oracle解决方案作为特权信息，在困难问题上添加解决方案前缀引导探索，使RL在引导轨迹中获得非零奖励。通过指令跟随和推理的协同作用，学习到的行为能够迁移回原始未引导问题。

Result: POPE显著扩展了可解决问题的范围，在具有挑战性的推理基准测试中大幅提升了性能表现。

Conclusion: POPE通过特权引导探索有效解决了RL在困难推理问题上的探索瓶颈，为LLM强化学习训练提供了新思路。

Abstract: Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.

</details>


### [505] [Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes](https://arxiv.org/abs/2601.18795)
*Amrith Setlur,Zijian Wang,Andrew Cohen,Paria Rashidinejad,Sang Michael Xie*

Main category: cs.LG

Relevance: 85.0

TL;DR: PrefixRL：一种通过重用旧采样FLOPs（来自先前推理或RL训练）的强化学习方法，通过条件化成功轨迹的前缀来引导on-policy RL完成剩余部分，避免off-policy不稳定性，显著提升硬推理问题的学习效率。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在LLM推理任务中面临挑战：硬问题上正确on-policy轨迹稀少，策略梯度消失，学习停滞。需要更高效利用计算资源，重用旧采样FLOPs（来自先前推理或RL训练）来提升学习效率。

Method: PrefixRL方法：1）从先验推理或RL训练中收集off-policy轨迹；2）条件化成功轨迹的前缀；3）运行on-policy RL完成剩余部分；4）通过前缀长度调节问题难度；5）使用基础模型进行拒绝采样创建自改进循环。

Result: 在硬推理问题上：1）达到相同训练奖励的速度比最强基线（SFT+RL）快2倍；2）最终奖励提升3倍；3）发现反向泛化现象：仅在前缀问题上训练能泛化到无前缀性能；4）增益可迁移到保留基准；5）即使off-policy轨迹来自不同模型家族也有效。

Conclusion: PrefixRL通过重用旧采样FLOPs和条件化成功轨迹前缀，有效解决了硬推理问题中RL学习的效率问题，避免了off-policy不稳定性，显著提升了学习速度和最终性能，具有实际应用的灵活性。

Abstract: Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.

</details>


### [506] [GreenServ: Energy-Efficient Context-Aware Dynamic Routing for Multi-Model LLM Inference](https://arxiv.org/abs/2601.17551)
*Thomas Ziller,Shashikant Ilager,Alessandro Tundo,Ezio Bartocci,Leonardo Mariani,Ivona Brandic*

Main category: cs.PF

Relevance: 85.0

TL;DR: GreenServ是一个动态、上下文感知的路由框架，通过多臂老虎机方法将查询路由到异构模型池中最合适的模型，在保持准确性的同时显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然能力强大，但推理时计算资源需求高、能耗大。静态的一模型通吃策略效率低下，无法利用多样化的模型资源或适应不同的查询需求。

Method: 从每个查询中提取轻量级上下文特征（任务类型、语义聚类、文本复杂度），使用多臂老虎机方法在线学习自适应路由策略，将查询路由到异构模型池中最合适的模型。

Result: 在5个基准任务和16个当代开源LLM上评估，相比随机路由，准确率提升22%，累计能耗降低31%。在RouterBench上平均准确率达到71.7%，峰值达到75.7%。

Conclusion: GreenServ框架能够有效优化推理准确性与能耗之间的权衡，支持动态模型选择和在线学习，为高效LLM推理提供了实用解决方案。

Abstract: Large language models (LLMs) demonstrate remarkable capabilities, but their broad deployment is limited by significant computational resource demands, particularly energy consumption during inference. Static, one-model-fits-all inference strategies are often inefficient, as they do not exploit the diverse range of available models or adapt to varying query requirements.
  This paper presents GreenServ, a dynamic, context-aware routing framework that optimizes the trade-off between inference accuracy and energy efficiency. GreenServ extracts lightweight contextual features from each query, including task type, semantic cluster, and text complexity, and routes queries to the most suitable model from a heterogeneous pool, based on observed accuracy and energy usage. We employ a multi-armed bandit approach to learn adaptive routing policies online. This approach operates under partial feedback, eliminates the need for extensive offline calibration, and streamlines the integration of new models into the inference pipeline.
  We evaluated GreenServ across five benchmark tasks and a pool of 16 contemporary open-access LLMs. Experimental results show that GreenServ consistently outperforms static (single-model) and random baselines. In particular, compared to random routing, GreenServ achieved a 22% increase in accuracy while reducing cumulative energy consumption by 31%. Finally, we evaluated GreenServ with RouterBench, achieving an average accuracy of 71.7% with a peak accuracy of 75.7%. All artifacts are open-source and available as an anonymous repository for review purposes here: https://anonymous.4open.science/r/llm-inference-router-EBEA/README.md

</details>


### [507] [TelcoAI: Advancing 3GPP Technical Specification Search through Agentic Multi-Modal Retrieval-Augmented Generation](https://arxiv.org/abs/2601.16984)
*Rahul Ghosh,Chun-Hao Liu,Gaurav Rele,Vidya Sagar Ravipati,Hazar Aouad*

Main category: cs.LG

Relevance: 75.0

TL;DR: TelcoAI：针对3GPP技术规范的智能多模态RAG系统，通过代理式查询规划和多模态融合，在技术文档理解上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 3GPP技术规范结构复杂、格式密集且包含多模态内容，现有LLM方法难以处理复杂查询、视觉信息和文档间依赖关系，需要专门解决方案

Method: 提出TelcoAI系统，包含：1) 章节感知分块；2) 结构化查询规划；3) 元数据引导检索；4) 文本与图表的多模态融合

Result: 在多个基准测试（包括专家策划查询）上达到87%召回率、83%声明召回率和92%忠实度，相比最先进基线提升16%

Conclusion: 代理式和多模态推理在技术文档理解中有效，为实际电信研究和工程提供实用解决方案

Abstract: The 3rd Generation Partnership Project (3GPP) produces complex technical specifications essential to global telecommunications, yet their hierarchical structure, dense formatting, and multi-modal content make them difficult to process. While Large Language Models (LLMs) show promise, existing approaches fall short in handling complex queries, visual information, and document interdependencies. We present TelcoAI, an agentic, multi-modal Retrieval-Augmented Generation (RAG) system tailored for 3GPP documentation. TelcoAI introduces section-aware chunking, structured query planning, metadata-guided retrieval, and multi-modal fusion of text and diagrams. Evaluated on multiple benchmarks-including expert-curated queries-our system achieves $87\%$ recall, $83\%$ claim recall, and $92\%$ faithfulness, representing a $16\%$ improvement over state-of-the-art baselines. These results demonstrate the effectiveness of agentic and multi-modal reasoning in technical document understanding, advancing practical solutions for real-world telecommunications research and engineering.

</details>


### [508] [ThinkTank-ME: A Multi-Expert Framework for Middle East Event Forecasting](https://arxiv.org/abs/2601.17065)
*Haoxuan Li,He Chang,Yunshan Ma,Yi Bin,Yang Yang,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出ThinkTank-ME框架，模拟智库专家协作进行中东事件预测，通过多专家模型协作解决单一模型在复杂地缘政治预测中的局限性


<details>
  <summary>Details</summary>
Motivation: 现有LLM事件预测方法采用单一模型架构，只能生成单一显式轨迹，难以捕捉复杂区域背景下多样化的地缘政治细微差别。事件预测受国际关系、区域历史动态和文化背景等多方面因素影响，需要更复杂的建模方法。

Method: 提出ThinkTank-ME框架，模拟现实世界战略决策中的协作专家分析。构建POLECAT-FOR-ME基准测试，专门用于中东事件预测，促进专家专业化和严格评估。采用多专家协作架构处理复杂时态地缘政治预测任务。

Result: 实验结果表明，多专家协作在处理复杂时态地缘政治预测任务方面具有优越性，超越了单一模型架构。

Conclusion: ThinkTank-ME框架通过模拟智库专家协作，有效解决了现有LLM方法在地缘政治事件预测中的局限性，为复杂区域背景下的预测任务提供了新思路。

Abstract: Event forecasting is inherently influenced by multifaceted considerations, including international relations, regional historical dynamics, and cultural contexts. However, existing LLM-based approaches employ single-model architectures that generate predictions along a singular explicit trajectory, constraining their ability to capture diverse geopolitical nuances across complex regional contexts. To address this limitation, we introduce ThinkTank-ME, a novel Think Tank framework for Middle East event forecasting that emulates collaborative expert analysis in real-world strategic decision-making. To facilitate expert specialization and rigorous evaluation, we construct POLECAT-FOR-ME, a Middle East-focused event forecasting benchmark. Experimental results demonstrate the superiority of multi-expert collaboration in handling complex temporal geopolitical forecasting tasks. The code is available at https://github.com/LuminosityX/ThinkTank-ME.

</details>


### [509] [Low-Rank Tensor Approximation of Weights in Large Language Models via Cosine Lanczos Bidiagonalization](https://arxiv.org/abs/2601.17112)
*A. El Ichi,K. Jbilou*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出基于cproduct的张量压缩框架，用于降低LLMs的内存占用和计算成本，通过变换域表示权重张量并联合近似切片来实现高效压缩。


<details>
  <summary>Details</summary>
Motivation: LLMs在各种自然语言任务中表现出色，但存在极大的内存占用和计算成本问题，需要高效的压缩方法来减少模型大小同时保持性能。

Method: 基于cproduct的张量压缩框架，利用cproduct的代数结构在变换域中表示权重张量（如嵌入层、注意力投影和FFN），通过联合近似切片实现低秩张量分解，利用多维相关性超越传统SVD方法。

Result: 从摘要看，该方法能够实现计算高效的压缩，利用多维相关性，比传统SVD方法更有效地减少LLMs的内存占用和计算成本。

Conclusion: 提出的cproduct张量压缩框架为LLMs的高效压缩提供了新方法，通过利用多维相关性实现更好的压缩效果，有助于解决LLMs部署中的内存和计算瓶颈问题。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language tasks but suffer from extremely large memory footprints and computational costs. In this paper, we introduce a tensor compression framework based on the cproduct for computing low rank approximation In the first part of our approach, we leverage the algebraic structure of the cproduct to represent weight tensors such as those in embedding layers, attention projections, and feed forward networks in a transform domain where frontal slices can be jointly approximated by low rank tensor factors. This enables computationally efficient compression that exploits multidimensional correlations beyond traditional SVD methods.

</details>


### [510] [ConceptACT: Episode-Level Concepts for Sample-Efficient Robotic Imitation Learning](https://arxiv.org/abs/2601.17135)
*Jakob Karalus,Friedhelm Schwenker*

Main category: cs.LG

Relevance: 75.0

TL;DR: ConceptACT：一种通过概念注释增强机器人模仿学习的扩展方法，利用人类语义知识提升学习效率，无需部署时语义输入


<details>
  <summary>Details</summary>
Motivation: 当前机器人模仿学习方法仅依赖低层次传感器数据，忽略了人类自然拥有的丰富语义知识（如物体属性、空间关系、任务约束）。如何有效利用这些语义知识来提升学习效率，同时避免部署时需要语义输入的负担，是本研究的主要动机。

Method: 扩展Action Chunking with Transformers (ACT)，在训练时利用人类提供的概念注释（仅在演示收集时添加）。通过修改transformer架构，在最终编码器层实现概念感知的交叉注意力机制，并监督其与人类注释对齐。与简单辅助预测损失或语言条件模型相比，通过注意力机制进行架构集成。

Result: 在两个具有逻辑约束的机器人操作任务上，ConceptACT比标准ACT收敛更快，样本效率更高。架构集成通过注意力机制显著优于简单的辅助预测损失或语言条件模型。

Conclusion: 适当集成的语义监督为更高效的机器人学习提供了强大的归纳偏置。概念注释仅在演示收集时添加，避免了部署时的语义输入需求，同时显著提升了学习效率。

Abstract: Imitation learning enables robots to acquire complex manipulation skills from human demonstrations, but current methods rely solely on low-level sensorimotor data while ignoring the rich semantic knowledge humans naturally possess about tasks. We present ConceptACT, an extension of Action Chunking with Transformers that leverages episode-level semantic concept annotations during training to improve learning efficiency. Unlike language-conditioned approaches that require semantic input at deployment, ConceptACT uses human-provided concepts (object properties, spatial relationships, task constraints) exclusively during demonstration collection, adding minimal annotation burden. We integrate concepts using a modified transformer architecture in which the final encoder layer implements concept-aware cross-attention, supervised to align with human annotations. Through experiments on two robotic manipulation tasks with logical constraints, we demonstrate that ConceptACT converges faster and achieves superior sample efficiency compared to standard ACT. Crucially, we show that architectural integration through attention mechanisms significantly outperforms naive auxiliary prediction losses or language-conditioned models. These results demonstrate that properly integrated semantic supervision provides powerful inductive biases for more efficient robot learning.

</details>


### [511] [Robust Privacy: Inference-Time Privacy through Certified Robustness](https://arxiv.org/abs/2601.17360)
*Jiankai Jin,Xiangzheng Zhang,Zhao Liu,Deyue Zhang,Quanchen Zou*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出Robust Privacy (RP)概念，通过保证模型在输入邻域内的预测不变性来提供推理时隐私保护，并开发APE方法将输入级不变性转化为属性级隐私效果。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统在推理时可能泄露敏感输入属性，现有隐私保护方法在推理时保护不足，需要新的推理时隐私概念来防御属性推断攻击。

Method: 1. 提出Robust Privacy (RP)概念：基于认证鲁棒性思想，如果模型在输入x的半径R邻域内预测不变，则x享有R-Robust Privacy；2. 开发Attribute Privacy Enhancement (APE)方法，将输入级不变性转化为属性级隐私效果；3. 在推荐任务中应用，通过添加噪声实现RP。

Result: 1. 在受控推荐任务中，RP扩展了与正向推荐兼容的敏感属性值集合；2. 即使小噪声水平(σ=0.1)，RP将模型反转攻击成功率从73%降至4%；3. RP可在不降低模型性能的情况下部分缓解攻击(成功率降至44%)。

Conclusion: Robust Privacy为推理时隐私保护提供了新框架，通过输入邻域不变性保证隐私，能有效防御属性推断攻击，在隐私保护与模型性能间取得平衡。

Abstract: Machine learning systems can produce personalized outputs that allow an adversary to infer sensitive input attributes at inference time. We introduce Robust Privacy (RP), an inference-time privacy notion inspired by certified robustness: if a model's prediction is provably invariant within a radius-$R$ neighborhood around an input $x$ (e.g., under the $\ell_2$ norm), then $x$ enjoys $R$-Robust Privacy, i.e., observing the prediction cannot distinguish $x$ from any input within distance $R$ of $x$. We further develop Attribute Privacy Enhancement (APE) to translate input-level invariance into an attribute-level privacy effect. In a controlled recommendation task where the decision depends primarily on a sensitive attribute, we show that RP expands the set of sensitive-attribute values compatible with a positive recommendation, expanding the inference interval accordingly. Finally, we empirically demonstrate that RP also mitigates model inversion attacks (MIAs) by masking fine-grained input-output dependence. Even at small noise levels ($σ=0.1$), RP reduces the attack success rate (ASR) from 73% to 4% with partial model performance degradation. RP can also partially mitigate MIAs (e.g., ASR drops to 44%) with no model performance degradation.

</details>


### [512] [Diversified Scaling Inference in Time Series Foundation Models](https://arxiv.org/abs/2601.17376)
*Ruijin Hua,Zichuan Liu,Kun Zhang,Yiyuan Yang*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文系统研究了时间序列基础模型(TSFMs)的推理时计算潜力，发现标准采样方法因探索不足而无法遵循缩放定律，提出通过多样化推理缩放和定制时间序列扰动来提升性能，并理论分析了多样性-保真度权衡。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型主要依赖大规模预训练，但推理时计算潜力尚未充分挖掘。论文旨在探索两个核心问题：TSFMs在标准采样推理缩放下的行为特性，以及受控采样多样性是否能提升性能。

Method: 1. 分析TSFMs在标准采样下的特性，发现其因解空间探索不足而无法遵循缩放定律
2. 提出多样化推理缩放方法，通过定制时间序列扰动扩展生成分布的支持
3. 理论分析多样性-保真度权衡，推导多样化采样优于标准采样的关键样本阈值
4. 提出RobustMSE指标量化固定预算下TSFMs的性能上限

Result: 实验表明，适当的多样化推理缩放能在不更新参数的情况下带来显著性能提升，确立了推理设计作为TSFM优化的关键计算高效维度。RobustMSE指标能有效量化模型性能上限。

Conclusion: 推理时设计是TSFM优化的重要维度，多样化大规模推理能在不重新训练模型的情况下实现可靠性能提升，为时间序列基础模型的高效部署提供了新思路。

Abstract: The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.

</details>


### [513] [Data-driven Clustering and Merging of Adapters for On-device Large Language Models](https://arxiv.org/abs/2601.17441)
*Ondrej Bohdal,Taha Ceritli,Mete Ozay,Jijoong Moon,Kyeng-Hun Lee,Hyeonmok Ko,Umberto Michieli*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出D2C方法，通过少量任务示例进行适配器聚类，将多个任务适配器合并为多任务适配器，以在存储受限的设备上部署


<details>
  <summary>Details</summary>
Motivation: 移动设备上部署大语言模型时，通常使用任务特定的适配器（如LoRA）来提升下游任务性能。但由于内存限制，无法存储所有适配器。设备通常只能存储有限数量的适配器参数，因此需要选择具有良好泛化能力的代表性适配器，而现有文献尚未探索这一问题。

Method: 提出D2C方法进行适配器聚类：1）利用少量任务特定示例（如每个任务10个样本）；2）采用迭代优化过程来精炼聚类分配；3）将每个聚类内的适配器合并，创建可在资源受限设备上部署的多任务适配器。

Result: 实验结果表明，该方法在考虑存储预算的情况下有效提升了性能。

Conclusion: D2C方法通过适配器聚类和合并，解决了移动设备上存储限制的问题，实现了在有限存储预算下提升多任务性能的目标。

Abstract: On-device large language models commonly employ task-specific adapters (e.g., LoRAs) to deliver strong performance on downstream tasks. While storing all available adapters is impractical due to memory constraints, mobile devices typically have sufficient capacity to store a limited number of these parameters. This raises a critical challenge: how to select representative adapters that generalize well across multiple tasks - a problem that remains unexplored in existing literature. We propose a novel method D2C for adapter clustering that leverages minimal task-specific examples (e.g., 10 per task) and employs an iterative optimization process to refine cluster assignments. The adapters within each cluster are merged, creating multi-task adapters deployable on resource-constrained devices. Experimental results demonstrate that our method effectively boosts performance for considered storage budgets.

</details>


### [514] [PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems](https://arxiv.org/abs/2601.17495)
*Ruiyu Zhang,Lin Nie,Wai-Fung Lam,Qihao Wang,Xin Zhao*

Main category: cs.LG

Relevance: 75.0

TL;DR: PEARL是一种标签高效的嵌入对齐方法，通过有限监督将嵌入软对齐到类别原型，改善局部邻域结构，提升检索和分类性能


<details>
  <summary>Details</summary>
Motivation: 现实部署中，固定预训练嵌入的几何结构常与下游任务不匹配，导致最近邻检索失败。标签稀缺、领域漂移和重训练成本高，使得嵌入几何质量对下游性能至关重要。

Method: PEARL使用有限监督将嵌入软对齐到类别原型，重塑局部邻域几何结构，保持维度不变，避免激进投影或坍缩，介于无监督后处理和全监督投影之间。

Result: 在标签稀缺条件下，PEARL显著改善局部邻域质量，相比原始嵌入提升25.7%，相比强无监督后处理提升21.1%，在相似性系统最脆弱的场景表现优异。

Conclusion: PEARL有效解决了嵌入几何对齐问题，在标签稀缺的实际部署中显著提升检索性能，为基于相似性的系统提供了实用的改进方案。

Abstract: In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.

</details>


### [515] [Understanding Transformer Encoder-Decoder Representations through Bernoulli Dropout](https://arxiv.org/abs/2601.17602)
*Xuanzhou Chen*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文研究Transformer过参数化问题，通过分析编码器-解码器嵌入的高维角度相似性，应用伯努利dropout识别保持Top-1预测的稀疏性阈值，并在英法翻译任务上验证理论。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer模型的过参数化现象，探索编码器和解码器之间嵌入表示的角度相似性如何影响模型性能，特别是在存在dropout的情况下。目标是理解Transformer架构中冗余参数的作用机制。

Method: 1. 理论分析：通过伯努利dropout在编码器和解码器之间，改变保留概率p来识别稀疏性阈值
2. 证明：当嵌入的有效稀疏性足够大时，解码器性能在适度坐标dropout下保持稳定
3. 实验：构建带有二进制擦除通道(BEC)的新型Transformer模型，在英法翻译任务上测试性能
4. 指标：验证准确率和BLEU分数

Result: 实验结果显示验证准确率和BLEU分数在某个阈值处急剧下降，可视化趋势表明存在明显的性能转折点，支持理论分析中关于稀疏性阈值的预测。

Conclusion: Transformer模型存在过参数化现象，编码器-解码器嵌入的角度相似性分析揭示了模型对dropout的鲁棒性存在阈值效应，这为理解Transformer架构的冗余性和优化提供了新视角。

Abstract: We study Transformer overparameterization through the lens of angular similarity in high-dimensional encoder-decoder embeddings. We apply Bernoulli dropout between the encoder and the decoder, varying the keep probability $p$ to identify a sparsity-dependent threshold above which the Top-1 prediction is preserved. Theoretically, we prove that, if the effective sparsity embeddings is sufficiently large, and thus decoder performance, remain stable under moderate coordinate dropout. Empirically, we implement the Bernoulli dropout by constructing a new Transformer model augmented with Binary Erasure Channel (BEC) and test its performance on an English-French translation task. Experimental results visualize the trends for validation accuracies and BLEU scores, both decline sharply at some threshold.

</details>


### [516] [BrainDistill: Implantable Motor Decoding with Task-Specific Knowledge Distillation](https://arxiv.org/abs/2601.17625)
*Yuhan Xie,Jinhan Liu,Xiaoyong Ni,Fei Tan,Icare Sakr,Thibault Collin,Shiqi Sun,Alejandro Rodriguez Guajardo,Demon Fanny,Charles-francois Vincent Latchoumane,Henri Lorach,Jocelyne Bloch,Gregoire Courtine,Mahsa Shoaran*

Main category: cs.LG

Relevance: 75.0

TL;DR: BrainDistill：一种用于植入式脑机接口的新型运动解码框架，通过任务特定知识蒸馏和量化感知训练，在保持高性能的同时大幅降低计算需求


<details>
  <summary>Details</summary>
Motivation: 基于Transformer的大规模预训练神经解码器在脑机接口任务中表现出色，但其庞大的参数量和计算需求阻碍了在功率受限的植入式系统中的部署。需要开发既能保持高性能又适合植入式系统约束的解决方案。

Method: 提出BrainDistill框架，包含植入式神经解码器（IND）和任务特定知识蒸馏（TSKD）。TSKD通过监督投影显式优先处理解码关键特征，不同于标准特征蒸馏方法。还提出量化感知训练方案，支持仅整数推理。

Result: IND在多个神经数据集上持续优于先前神经解码器。TSKD蒸馏变体在少样本校准设置中进一步超越其他蒸馏方法。量化IND能在植入式BCI的严格功率约束下部署，性能损失最小。

Conclusion: BrainDistill通过任务特定知识蒸馏和量化感知训练，成功解决了大规模Transformer解码器在植入式系统中的部署挑战，为功率受限的脑机接口应用提供了高性能、低功耗的解决方案。

Abstract: Transformer-based neural decoders with large parameter counts, pre-trained on large-scale datasets, have recently outperformed classical machine learning models and small neural networks on brain-computer interface (BCI) tasks. However, their large parameter counts and high computational demands hinder deployment in power-constrained implantable systems. To address this challenge, we introduce BrainDistill, a novel implantable motor decoding pipeline that integrates an implantable neural decoder (IND) with a task-specific knowledge distillation (TSKD) framework. Unlike standard feature distillation methods that attempt to preserve teacher representations in full, TSKD explicitly prioritizes features critical for decoding through supervised projection. Across multiple neural datasets, IND consistently outperforms prior neural decoders on motor decoding tasks, while its TSKD-distilled variant further surpasses alternative distillation methods in few-shot calibration settings. Finally, we present a quantization-aware training scheme that enables integer-only inference with activation clipping ranges learned during training. The quantized IND enables deployment under the strict power constraints of implantable BCIs with minimal performance loss.

</details>


### [517] [Shortcut Learning in Binary Classifier Black Boxes: Applications to Voice Anti-Spoofing and Biometrics](https://arxiv.org/abs/2601.17782)
*Md Sahidullah,Hye-jin Shim,Rosa Gonzalez Hautamäki,Tomi H. Kinnunen*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该研究提出一个分析黑盒分类器的新框架，通过干预和观察视角，使用线性混合效应模型进行事后分析，以检测数据集偏差和"捷径学习"效应，并在音频反欺骗和说话人验证任务中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在数据驱动应用中的广泛采用引起了人们对数据集和模型中潜在偏见风险的关注。被忽视或隐藏的偏见可能导致意外结果。本研究旨在解决数据集偏见问题，探索二元分类器中的"捷径学习"或"Clever Hans效应"。

Method: 提出一个新颖的分析框架，结合干预和观察视角，采用线性混合效应模型进行事后分析。该框架能够分析黑盒分类器，并检查训练和测试数据对分类器分数的影响，超越简单的错误率评估。

Result: 通过在音频反欺骗和说话人验证任务上对统计模型和深度神经网络进行实验，证明了该方法的有效性。研究提供了对偏见数据集的深入理解，并揭示了它们对分类器行为的影响。

Conclusion: 该研究为检测和解决数据集偏见提供了系统方法，对处理其他领域的偏见问题具有广泛意义，并推动了可解释人工智能领域的发展。

Abstract: The widespread adoption of deep-learning models in data-driven applications has drawn attention to the potential risks associated with biased datasets and models. Neglected or hidden biases within datasets and models can lead to unexpected results. This study addresses the challenges of dataset bias and explores ``shortcut learning'' or ``Clever Hans effect'' in binary classifiers. We propose a novel framework for analyzing the black-box classifiers and for examining the impact of both training and test data on classifier scores. Our framework incorporates intervention and observational perspectives, employing a linear mixed-effects model for post-hoc analysis. By evaluating classifier performance beyond error rates, we aim to provide insights into biased datasets and offer a comprehensive understanding of their influence on classifier behavior. The effectiveness of our approach is demonstrated through experiments on audio anti-spoofing and speaker verification tasks using both statistical models and deep neural networks. The insights gained from this study have broader implications for tackling biases in other domains and advancing the field of explainable artificial intelligence.

</details>


### [518] [Adaptive Weighting in Knowledge Distillation: An Axiomatic Framework for Multi-Scale Teacher Ensemble Optimization](https://arxiv.org/abs/2601.17910)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

Relevance: 75.0

TL;DR: 本文提出了一个算子无关的公理化框架，用于多教师知识蒸馏中的自适应权重分配，涵盖token、task和context三个互补尺度，建立了理论保证与具体权重公式的解耦。


<details>
  <summary>Details</summary>
Motivation: 现有多教师知识蒸馏方法主要依赖启发式或实现特定的权重方案，缺乏统一的理论框架。本文旨在开发一个算子无关的公理化框架，为自适应权重分配提供理论基础，特别是在异构性、分布偏移和安全约束等复杂场景下。

Method: 1. 提出算子无关的公理化框架，形式化定义了自适应权重算子在token、task和context三个尺度上的结构条件
2. 建立了算子良好定义、允许多个非等价实现、可通过乘积结构归一化进行层次组合的条件
3. 证明了符合条件算子的存在性和非唯一性
4. 分析了标准假设下基于梯度优化的收敛性
5. 研究了稳定性和扰动鲁棒性
6. 提供了安全约束蒸馏的抽象表述

Result: 1. 建立了自适应权重算子的存在性定理和非唯一性特征
2. 在标准假设下证明了梯度优化的收敛性
3. 分析了算子的稳定性和扰动鲁棒性
4. 提供了安全约束蒸馏的抽象框架
5. 实现了理论保证与具体权重公式的解耦，为异构性、分布偏移和安全约束下的自适应蒸馏方法提供了原则性分析基础

Conclusion: 本文提出的公理化框架为多教师知识蒸馏中的自适应权重分配提供了统一的理论基础，将理论保证与具体实现解耦，使得在复杂场景下的原则性分析成为可能，为鲁棒、高效和安全的蒸馏方法设计提供了理论指导。

Abstract: Knowledge distillation with multiple teachers is increasingly used to improve robustness, efficiency, and safety, yet existing approaches rely largely on heuristic or implementation-specific weighting schemes. This paper develops an operator-agnostic axiomatic framework for adaptive weighting in multi-teacher knowledge distillation across three complementary scales: token, task, and context. We formalize structural conditions under which adaptive weighting operators are well-defined, admit multiple non-equivalent implementations, and can be hierarchically composed via product-structure normalization. Within this framework, we establish existence and non-uniqueness of conforming operators, characterize convergence of gradient-based optimization under standard assumptions, analyze stability and perturbation robustness, and provide an abstract formulation of safety-constrained distillation. The results decouple theoretical guarantees from specific weighting formulas, enabling principled analysis of adaptive distillation methods under heterogeneity, distribution shift, and safety constraints.

</details>


### [519] [Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN](https://arxiv.org/abs/2601.17912)
*Qinyi Liu,Mohammad Khalil,Naman Goel*

Main category: cs.LG

Relevance: 75.0

TL;DR: TabPFN等表格数据基础模型通过因果预训练获得高预测精度，但其公平性表现中等且不一致，尤其在MNAR协变量偏移下，因果预训练对公平性提升有限


<details>
  <summary>Details</summary>
Motivation: 尽管TabPFN等表格数据基础模型通过结构因果模型生成的大量合成数据集进行预训练，并利用上下文学习在现实任务中表现出高预测准确性，但这些结合因果推理思想的预训练模型的公平性特性尚未得到充分探索

Method: 对TabPFN及其微调变体进行全面的实证评估，评估预测性能、公平性和鲁棒性，考虑不同数据集大小和分布偏移条件

Result: TabPFN相比基线模型具有更强的预测准确性，对虚假相关性表现出鲁棒性，但公平性改进中等且不一致，特别是在缺失非随机(MNAR)协变量偏移下

Conclusion: TabPFN中的因果预训练对公平性有帮助但不足，突显了在实际部署此类模型时的影响以及需要进一步公平性干预的必要性

Abstract: Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, have not yet been explored in sufficient depth. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying such models in practice and the need for further fairness interventions.

</details>


### [520] [UniPACT: A Multimodal Framework for Prognostic Question Answering on Raw ECG and Structured EHR](https://arxiv.org/abs/2601.17916)
*Jialu Tang,Tong Xia,Yuan Lu,Aaqib Saeed*

Main category: cs.LG

Relevance: 75.0

TL;DR: UniPACT是一个统一的临床预后问答框架，通过结构化提示机制将数值型电子健康记录转换为语义丰富的文本，结合原始心电图波形表示，使大语言模型能够对多模态数据进行整体推理。


<details>
  <summary>Details</summary>
Motivation: 准确的临床预后需要结合结构化电子健康记录和实时生理信号（如心电图），但大语言模型难以原生处理这些异构的非文本数据类型，需要解决这一模态鸿沟。

Method: 提出UniPACT框架：1）结构化提示机制将数值型EHR数据转换为语义丰富的文本；2）从原始ECG波形学习表示；3）将文本化患者上下文与ECG表示融合，使LLM能够对两种模态进行整体推理。

Result: 在MDS-ED基准测试中达到89.37%的平均AUROC，在诊断、恶化、ICU入院和死亡率等多样化预后任务上优于专业基线模型，多模态多任务方法对性能至关重要且在数据缺失场景下具有鲁棒性。

Conclusion: UniPACT成功解决了LLM处理异构临床数据的挑战，通过统一框架实现了多模态临床预后问答的先进性能，证明了结构化提示和模态融合的有效性。

Abstract: Accurate clinical prognosis requires synthesizing structured Electronic Health Records (EHRs) with real-time physiological signals like the Electrocardiogram (ECG). Large Language Models (LLMs) offer a powerful reasoning engine for this task but struggle to natively process these heterogeneous, non-textual data types. To address this, we propose UniPACT (Unified Prognostic Question Answering for Clinical Time-series), a unified framework for prognostic question answering that bridges this modality gap. UniPACT's core contribution is a structured prompting mechanism that converts numerical EHR data into semantically rich text. This textualized patient context is then fused with representations learned directly from raw ECG waveforms, enabling an LLM to reason over both modalities holistically. We evaluate UniPACT on the comprehensive MDS-ED benchmark, it achieves a state-of-the-art mean AUROC of 89.37% across a diverse set of prognostic tasks including diagnosis, deterioration, ICU admission, and mortality, outperforming specialized baselines. Further analysis demonstrates that our multimodal, multi-task approach is critical for performance and provides robustness in missing data scenarios.

</details>


### [521] [Scaling Effects and Uncertainty Quantification in Neural Actor Critic Algorithms](https://arxiv.org/abs/2601.17954)
*Nikos Georgoudios,Konstantinos Spiliopoulos,Justin Sirignano*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文研究神经Actor-Critic算法中浅层神经网络的收敛特性，分析不同网络宽度缩放方案下的统计行为，提出可调超参数来控制近似误差，并推导出网络输出的渐近展开以量化不确定性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于深入理解神经Actor-Critic算法的统计特性，超越仅关注收敛速度的传统分析。作者希望量化神经网络Actor-Critic方法中的不确定性，提供更全面的统计特征描述，并建立算法超参数选择的指导原则。

Method: 采用浅层神经网络作为Actor和Critic模型，研究网络宽度与训练步数趋于无穷时的收敛特性。引入可调超参数（介于1/2和1之间的指数）来控制网络宽度的逆多项式缩放，推导网络输出的渐近展开，分析方差衰减与缩放参数的关系。

Result: 理论分析表明方差随网络宽度以幂律衰减，指数为1/2减去缩放参数，当缩放参数接近1时统计鲁棒性改善。数值实验支持这一行为，并显示该缩放方案下收敛更快。分析结果为学习率、探索率等超参数选择提供了具体指导。

Conclusion: 该工作为神经Actor-Critic算法提供了统计理论框架，通过可调缩放参数实现了对近似误差的精确控制，改善了算法的统计鲁棒性，并为超参数选择提供了理论依据。

Abstract: We investigate the neural Actor Critic algorithm using shallow neural networks for both the Actor and Critic models. The focus of this work is twofold: first, to compare the convergence properties of the network outputs under various scaling schemes as the network width and the number of training steps tend to infinity; and second, to provide precise control of the approximation error associated with each scaling regime. Previous work has shown convergence to ordinary differential equations with random initial conditions under inverse square root scaling in the network width. In this work, we shift the focus from convergence speed alone to a more comprehensive statistical characterization of the algorithm's output, with the goal of quantifying uncertainty in neural Actor Critic methods. Specifically, we study a general inverse polynomial scaling in the network width, with an exponent treated as a tunable hyperparameter taking values strictly between one half and one. We derive an asymptotic expansion of the network outputs, interpreted as statistical estimators, in order to clarify their structure. To leading order, we show that the variance decays as a power of the network width, with an exponent equal to one half minus the scaling parameter, implying improved statistical robustness as the scaling parameter approaches one. Numerical experiments support this behavior and further suggest faster convergence for this choice of scaling. Finally, our analysis yields concrete guidelines for selecting algorithmic hyperparameters, including learning rates and exploration rates, as functions of the network width and the scaling parameter, ensuring provably favorable statistical behavior.

</details>


### [522] [Spelling Bee Embeddings for Language Modeling](https://arxiv.org/abs/2601.18030)
*Markus N. Rabe,Judith Clymo,Zheren Dong*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文提出了一种简单的嵌入层修改方法，通过将token拼写信息融入词嵌入，不仅提升了拼写能力，还在标准基准测试上取得了全面改进。缩放研究表明，该方法相当于节省约8%的计算和数据成本。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型的词嵌入通常只关注语义信息，忽略了token的拼写特征。作者认为拼写信息包含有价值的语言结构线索，将其融入嵌入层可以提升模型的语言理解能力和效率。

Method: 提出了一种简单的嵌入层修改方法，将token的拼写信息（如字符序列、形态特征）注入到传统的词嵌入中。具体实现细节未在摘要中详述，但核心思想是在嵌入层融合拼写特征。

Result: 1. 显著提升拼写相关任务性能
2. 在标准语言模型基准测试上全面改进
3. 在40M到800M参数规模的模型上进行缩放研究，结果显示该方法相当于节省约8%的计算资源和训练数据，达到相同的测试损失

Conclusion: 简单的拼写信息融入嵌入层是一种有效的改进方法，不仅能提升拼写能力，还能全面增强语言模型性能，同时提高训练效率，减少计算和数据需求。

Abstract: We introduce a simple modification to the embedding layer. The key change is to infuse token embeddings with information about their spelling. Models trained with these embeddings improve not only on spelling, but also across standard benchmarks. We conduct scaling studies for models with 40M to 800M parameters, which suggest that the improvements are equivalent to needing about 8% less compute and data to achieve the same test loss.

</details>


### [523] [Resonant Sparse Geometry Networks](https://arxiv.org/abs/2601.18064)
*Hasi Hays*

Main category: cs.LG

Relevance: 75.0

TL;DR: RSGN是一种受大脑启发的稀疏几何网络架构，通过双时间尺度学习和双曲空间嵌入实现输入依赖的动态稀疏连接，相比Transformer具有O(n*k)的计算复杂度，在长距离依赖和层次分类任务上以更少参数达到可比较性能。


<details>
  <summary>Details</summary>
Motivation: Transformer架构使用密集注意力机制，具有O(n²)计算复杂度，限制了其效率和可扩展性。受大脑稀疏连接和几何组织原则启发，研究者希望开发更高效、生物合理的神经架构。

Method: 1. 在学习的双曲空间中嵌入计算节点，连接强度随测地距离衰减，实现输入依赖的动态稀疏性；2. 双时间尺度学习：快速可微分激活传播（梯度下降优化）和慢速Hebbian结构学习（局部相关性规则）；3. 数学分析证明O(n*k)计算复杂度，其中k<<n为平均活跃邻域大小。

Result: 1. 长距离依赖任务：96.5%准确率，参数比标准Transformer少约15倍；2. 20类层次分类：23.8%准确率（随机基线5%），仅41,672参数，而Transformer基线需要403,348参数达到30.1%准确率；3. 消融研究确认各架构组件的贡献，Hebbian学习提供持续改进。

Conclusion: 受大脑启发的稀疏几何计算原则为开发更高效、生物合理的神经架构提供了有前景的方向，特别是在减少参数数量和计算复杂度方面具有优势。

Abstract: We introduce Resonant Sparse Geometry Networks (RSGN), a brain-inspired architecture with self-organizing sparse
  hierarchical input-dependent connectivity. Unlike Transformer architectures that employ dense attention mechanisms with
  O(n^2) computational complexity, RSGN embeds computational nodes in learned hyperbolic space where connection strength
  decays with geodesic distance, achieving dynamic sparsity that adapts to each input. The architecture operates on two
  distinct timescales: fast differentiable activation propagation optimized through gradient descent, and slow
  Hebbian-inspired structural learning for connectivity adaptation through local correlation rules. We provide rigorous
  mathematical analysis demonstrating that RSGN achieves O(n*k) computational complexity, where k << n represents the average
  active neighborhood size. Experimental evaluation on hierarchical classification and long-range dependency tasks
  demonstrates that RSGN achieves 96.5% accuracy on long-range dependency tasks while using approximately 15x fewer
  parameters than standard Transformers. On challenging hierarchical classification with 20 classes, RSGN achieves 23.8%
  accuracy (compared to 5% random baseline) with only 41,672 parameters, nearly 10x fewer than the Transformer baselines
  which require 403,348 parameters to achieve 30.1% accuracy. Our ablation studies confirm the contribution of each architectural
  component, with Hebbian learning providing consistent improvements. These results suggest that brain-inspired principles
  of sparse, geometrically-organized computation offer a promising direction toward more efficient and biologically plausible
  neural architectures.

</details>


### [524] [Demystifying Data-Driven Probabilistic Medium-Range Weather Forecasting](https://arxiv.org/abs/2601.18111)
*Jean Kossaifi,Nikola Kovachki,Morteza Mardani,Daniel Leibovici,Suman Ravuri,Ira Shokar,Edoardo Calvello,Mohammad Shoaib Abbas,Peter Harrington,Ashay Subramaniam,Noah Brenowitz,Boris Bonev,Wonmin Byeon,Karsten Kreis,Dale Durran,Arash Vahdat,Mike Pritchard,Jan Kautz*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文提出了一种用于天气预测的通用可扩展框架，无需复杂架构或专门训练策略，通过结合降采样潜在空间和历史条件局部投影器实现多尺度大气动力学学习，在多个概率框架下均能达到最先进的预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的天气预测方法存在架构复杂、训练策略碎片化的问题，难以识别预测准确性的根本驱动因素。作者旨在证明无需复杂架构约束或专门训练启发式方法也能实现最先进的概率预测技能。

Method: 提出可扩展框架：1) 直接降采样的潜在空间；2) 历史条件局部投影器，用于解析高分辨率物理过程。该框架对概率估计器的选择具有鲁棒性，支持随机插值、扩散模型和CRPS集成训练等多种方法。

Result: 与集成预报系统(IFS)和深度学习概率模型GenCast相比，该框架在大多数变量上实现了统计显著的改进，表明通用模型的扩展足以实现最先进的中期预测。

Conclusion: 扩展通用模型足以实现最先进的天气预测，无需定制化训练方案，且该框架在完整的概率框架谱系中都有效，简化了天气预测的模型设计。

Abstract: The recent revolution in data-driven methods for weather forecasting has lead to a fragmented landscape of complex, bespoke architectures and training strategies, obscuring the fundamental drivers of forecast accuracy. Here, we demonstrate that state-of-the-art probabilistic skill requires neither intricate architectural constraints nor specialized training heuristics. We introduce a scalable framework for learning multi-scale atmospheric dynamics by combining a directly downsampled latent space with a history-conditioned local projector that resolves high-resolution physics. We find that our framework design is robust to the choice of probabilistic estimator, seamlessly supporting stochastic interpolants, diffusion models, and CRPS-based ensemble training. Validated against the Integrated Forecasting System and the deep learning probabilistic model GenCast, our framework achieves statistically significant improvements on most of the variables. These results suggest scaling a general-purpose model is sufficient for state-of-the-art medium-range prediction, eliminating the need for tailored training recipes and proving effective across the full spectrum of probabilistic frameworks.

</details>


### [525] [Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting](https://arxiv.org/abs/2601.18231)
*Trong Khiem Tran,Manh Cuong Dao,Phi Le Nguyen,Thao Nguyen Truong,Trong Nghia Hoang*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文提出了一个理论框架来分析预训练模型适应新特征模态时特征对齐与目标微调之间的相互作用，通过特征-标签失真概念建立了可证明的泛化边界，并基于此设计了改进的算法。


<details>
  <summary>Details</summary>
Motivation: 随着跨学科知识整合需求的增长，将预训练模型适应到未见特征模态变得越来越重要。关键挑战是如何将新模态的表征与预训练模型表征空间中最相关的部分对齐，以实现准确的知识迁移。这需要结合特征对齐和目标微调，但未经校准的组合可能会加剧源特征-标签结构与目标特征-标签结构之间的错位，从而降低目标泛化能力。现有工作缺乏对这种关键相互作用的深入理论理解。

Method: 开发了一个原则性框架，建立了目标误差的可证明泛化边界，通过新颖的"特征-标签失真"概念来解释特征对齐与目标拟合之间的相互作用。该边界为实际算法设计提供了可操作的见解，指导如何优化这种相互作用。

Result: 基于理论框架设计的算法在广泛的基准数据集上显著优于最先进的方法，取得了显著的性能提升。

Conclusion: 该研究填补了预训练模型跨模态适应中特征对齐与目标微调相互作用的理论空白，提出的理论框架不仅解释了这种相互作用，还为实际算法设计提供了指导原则，实现了更好的性能表现。

Abstract: Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.

</details>


### [526] [What Do Learned Models Measure?](https://arxiv.org/abs/2601.18278)
*Indrė Žliobaitė*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文提出"学习测量函数"作为机器学习的新评估维度，指出传统预测性能指标无法保证测量稳定性，模型可能在分布偏移下实现系统不等价的测量映射。


<details>
  <summary>Details</summary>
Motivation: 在科学和数据驱动应用中，机器学习模型越来越多地被用作测量仪器而非仅仅是预测工具。当测量函数从数据中学习时，从观察到量的映射由训练分布和归纳偏置隐式决定，导致多个不等价的映射都能满足标准预测评估标准。需要新的评估维度来确保学习测量函数的稳定性。

Method: 形式化学习测量函数作为评估的独立焦点，引入测量稳定性概念，捕捉学习过程可接受实现和不同上下文下测量量的不变性。通过真实案例研究展示预测性能相当的模型可能实现系统不等价的测量函数。

Result: 证明标准机器学习评估标准（包括泛化误差、校准和鲁棒性）不能保证测量稳定性。在真实案例中，具有可比预测性能的模型实现了系统不等价的测量函数，分布偏移具体说明了这种失败。

Conclusion: 现有评估框架在将学习模型输出识别为测量的场景中存在局限性，需要增加评估维度来确保测量稳定性，特别是在科学测量应用中。

Abstract: In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.

</details>


### [527] [Structural Gender Bias in Credit Scoring: Proxy Leakage](https://arxiv.org/abs/2601.18342)
*Navya SD,Sreekanth D,SS Uma Sankari*

Main category: cs.LG

Relevance: 75.0

TL;DR: 研究审计台湾信贷违约数据集中的结构性性别偏见，挑战"公平性盲视"理念，发现即使移除受保护属性，非敏感特征仍包含性别代理变量，传统公平性审计不足以检测隐性结构偏见。


<details>
  <summary>Details</summary>
Motivation: 金融机构越来越多地采用机器学习进行信用风险评估，但算法偏见仍然是公平金融包容的关键障碍。本研究旨在挑战"公平性盲视"的主流理念，揭示即使移除显式受保护属性和应用行业标准公平干预措施，性别预测信号仍深植于非敏感特征中。

Method: 1) 使用SHAP（SHapley Additive exPlanations）识别婚姻状况、年龄和信用额度等变量作为性别代理变量；2) 采用对抗性逆建模框架数学量化信息泄漏，从纯非敏感金融特征重建受保护的性别属性。

Result: 研究发现：1) 非敏感特征如婚姻状况、年龄和信用额度可作为有效的性别代理变量；2) 受保护的性别属性可以从纯非敏感金融特征重建，ROC AUC得分为0.65；3) 传统公平性审计不足以检测隐性结构偏见。

Conclusion: 研究主张从表面统计平等转向因果感知建模和结构问责制，强调需要更深入的方法来检测和缓解金融AI中的结构性偏见。

Abstract: As financial institutions increasingly adopt machine learning for credit risk assessment, the persistence of algorithmic bias remains a critical barrier to equitable financial inclusion. This study provides a comprehensive audit of structural gender bias within the Taiwan Credit Default dataset, specifically challenging the prevailing doctrine of "fairness through blindness." Despite the removal of explicit protected attributes and the application of industry standard fairness interventions, our results demonstrate that gendered predictive signals remain deeply embedded within non-sensitive features. Utilizing SHAP (SHapley Additive exPlanations), we identify that variables such as Marital Status, Age, and Credit Limit function as potent proxies for gender, allowing models to maintain discriminatory pathways while appearing statistically fair. To mathematically quantify this leakage, we employ an adversarial inverse modeling framework. Our findings reveal that the protected gender attribute can be reconstructed from purely non-sensitive financial features with an ROC AUC score of 0.65, demonstrating that traditional fairness audits are insufficient for detecting implicit structural bias. These results advocate for a shift from surface-level statistical parity toward causal-aware modeling and structural accountability in financial AI.

</details>


### [528] [Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning](https://arxiv.org/abs/2601.18356)
*Weiqin Yang,Haowen Xue,Qingyi Peng,Hexuan Hu,Qian Huang,Tingbo Zhang*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出了多模态因果检索增强生成框架，将因果推理原则与多模态检索结合，通过检索临床相关示例和因果图，基于反事实和干预证据而非相关性进行推理，提升医学视觉语言模型的准确性、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉语言模型主要基于相关性推理，依赖表面统计关联而非因果病理机制，导致模型脆弱、易产生幻觉且对数据集偏差敏感。传统检索增强生成依赖语义相似性，引入了新的虚假相关性。

Method: 提出多模态因果检索增强生成框架，从外部源检索临床相关示例和因果图，基于反事实和干预证据而非相关性进行模型推理。应用于放射学报告生成、诊断预测和视觉问答任务。

Result: 该框架提高了事实准确性、对分布偏移的鲁棒性和可解释性。结果表明因果检索为医学视觉语言模型提供了超越模式匹配的推理能力，支持高风险临床环境中的可信多模态推理。

Conclusion: 因果检索增强生成是构建可信医学视觉语言模型的可扩展路径，使模型能够超越模式匹配，在高风险临床环境中实现可信的多模态推理。

Abstract: Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings.

</details>


### [529] [Gradient Regularized Natural Gradients](https://arxiv.org/abs/2601.18420)
*Satya Prakash Dash,Hossein Abdi,Wei Pan,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出GRNG（梯度正则化自然梯度）优化器，将显式梯度正则化与自然梯度更新结合，包含频域变体（避免Fisher信息矩阵显式求逆）和贝叶斯变体（基于正则化卡尔曼公式），在视觉和语言基准上优于一阶和二阶基线方法。


<details>
  <summary>Details</summary>
Motivation: 虽然梯度正则化已被证明能提高模型泛化能力，自然梯度下降在训练初期能加速优化，但二阶优化器的训练动态如何从梯度正则化中受益尚未得到充分研究。本文旨在探索梯度正则化如何增强自然梯度方法的鲁棒性。

Method: 提出GRNG框架，包含两个互补算法：1）频域变体通过结构化近似避免Fisher信息矩阵显式求逆；2）贝叶斯变体基于正则化卡尔曼公式，完全不需要Fisher信息矩阵求逆。建立了GRNG的收敛保证。

Result: 实验表明，GRNG在优化速度和泛化能力上一致优于一阶方法（SGD、AdamW）和二阶基线（K-FAC、Sophia），在视觉和语言基准上取得强劲结果。梯度正则化提高了稳定性并实现全局最小收敛。

Conclusion: 梯度正则化是解锁自然梯度方法在大规模深度学习中的鲁棒性的原则性和实用工具。GRNG为二阶优化器提供了新的训练动态改进方向。

Abstract: Gradient regularization (GR) has been shown to improve the generalizability of trained models. While Natural Gradient Descent has been shown to accelerate optimization in the initial phase of training, little attention has been paid to how the training dynamics of second-order optimizers can benefit from GR. In this work, we propose Gradient-Regularized Natural Gradients (GRNG), a family of scalable second-order optimizers that integrate explicit gradient regularization with natural gradient updates. Our framework provides two complementary algorithms: a frequentist variant that avoids explicit inversion of the Fisher Information Matrix (FIM) via structured approximations, and a Bayesian variant based on a Regularized-Kalman formulation that eliminates the need for FIM inversion entirely. We establish convergence guarantees for GRNG, showing that gradient regularization improves stability and enables convergence to global minima. Empirically, we demonstrate that GRNG consistently enhances both optimization speed and generalization compared to first-order methods (SGD, AdamW) and second-order baselines (K-FAC, Sophia), with strong results on vision and language benchmarks. Our findings highlight gradient regularization as a principled and practical tool to unlock the robustness of natural gradient methods for large-scale deep learning.

</details>


### [530] [Closing the Modality Gap Aligns Group-Wise Semantics](https://arxiv.org/abs/2601.18525)
*Eleonora Grassucci,Giordano Cicchetti,Emanuele Frasca,Aurelio Uncini,Danilo Comminiello*

Main category: cs.LG

Relevance: 75.0

TL;DR: 该论文研究了多模态学习中的模态间隙问题，证明了虽然CLIP损失在语义层面有效对齐多模态，但产生的潜在空间仍存在结构不匹配。研究发现模态间隙对实例级任务影响有限，但对群体级任务（如聚类）影响显著，并提出了一种减少该间隙的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP已成为多模态学习的标准方法，但其产生的潜在空间仍存在模态间隙问题。目前学界对这一现象的必要性存在争议，特别是考虑到它对实例级任务影响有限。本文旨在深入研究模态间隙对群体级任务的影响，证明其重要性并开发解决方案。

Method: 提出了一种新颖的方法来持续减少双模态设置中的模态间隙，并可简单扩展到一般的n模态情况。该方法专门针对群体级任务优化，通过减少模态间的结构不匹配来改善语义分组性能。

Result: 通过广泛评估发现：减少模态间隙对传统实例级任务仅提供边际或不一致的改进，但对群体级任务（如聚类）有显著增强效果。这证明了模态间隙在需要语义分组的任务中起着关键作用。

Conclusion: 模态间隙对群体级任务的影响比之前认识的要重要得多。这一发现可能重塑我们对模态间隙的理解，强调了在需要语义分组的任务中解决这一问题的关键价值。

Abstract: In multimodal learning, CLIP has been recognized as the \textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.

</details>


### [531] [Information Hidden in Gradients of Regression with Target Noise](https://arxiv.org/abs/2601.18546)
*Arash Jamshidi,Katsiaryna Haitsiukevich,Kai Puolamäki*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出一种通过梯度协方差估计Hessian矩阵的方法，核心是通过注入高斯噪声使目标噪声方差等于批量大小，从而在远离最优解时也能准确恢复Hessian


<details>
  <summary>Details</summary>
Motivation: 二阶信息（如曲率或数据协方差）对于优化、诊断和鲁棒性至关重要，但在许多现代设置中只有梯度可观测。需要从梯度中恢复Hessian矩阵

Method: 提出方差校准方法：注入高斯噪声使总目标噪声方差等于批量大小，确保经验梯度协方差近似Hessian矩阵。提供次高斯输入下的非渐近算子范数保证

Result: 理论证明和经验验证表明该方法能准确恢复Hessian（在线性回归中等于数据协方差Σ），没有校准时恢复可能失败Ω(1)因子。方法实用且鲁棒

Conclusion: 仅通过梯度就能揭示Hessian信息，提出的"将目标噪声方差设为n"规则在实际应用中有效，可用于预条件、对抗风险估计和分布式系统中的梯度训练

Abstract: Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $Σ$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $Ω(1)$ factor. The proposed method is practical (a "set target-noise variance to $n$" rule) and robust (variance $\mathcal{O}(n)$ suffices to recover $Σ$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data.

</details>


### [532] [K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents](https://arxiv.org/abs/2601.18580)
*Vincenzo De Paola,Mirco Mutti,Riccardo Zamboni,Marcello Restelli*

Main category: cs.LG

Relevance: 75.0

TL;DR: K-Myriad是一种可扩展的无监督方法，通过最大化并行策略群体诱导的集体状态熵，培养专门的探索策略组合，为强化学习提供鲁棒初始化，提高训练效率并发现异构解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习并行化通常用于加速单个策略的训练，多个工作器从相同的采样分布收集经验。这种常见设计忽略了多样化探索策略的优势，限制了并行化的潜力。作者旨在通过最大化集体状态熵来利用并行化的全部潜力。

Method: 提出K-Myriad方法，通过最大化并行策略群体诱导的集体状态熵，培养专门的探索策略组合。该方法是无监督的，可扩展的，能够创建多样化的探索策略组合，为强化学习提供鲁棒初始化。

Result: 在高维连续控制任务上的大规模并行化实验表明，K-Myriad能够学习到广泛的不同策略，突显了其在集体探索方面的有效性，为新型并行化策略铺平了道路。

Conclusion: K-Myriad通过最大化集体状态熵和培养专门的探索策略组合，提供了一种有效的并行化方法，能够提高训练效率并发现异构解决方案，为强化学习并行化开辟了新方向。

Abstract: Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies.

</details>


### [533] [Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning](https://arxiv.org/abs/2601.18626)
*Yingxiao Huo,Satya Prakash Dash,Radu Stoican,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出一种高效的秩-1近似自然策略优化方法，通过近似Fisher信息矩阵逆来降低计算复杂度，在多种环境中优于标准actor-critic和信任域基线方法。


<details>
  <summary>Details</summary>
Motivation: 自然梯度在深度强化学习中具有快速收敛特性，但计算Fisher信息矩阵逆的复杂度极高，限制了实际应用。需要开发高效可扩展的自然策略优化技术。

Method: 采用秩-1近似方法逼近完整的逆Fisher信息矩阵，理论上证明在特定条件下比策略梯度收敛更快，且在某些情况下具有与随机策略梯度相同的样本复杂度。

Result: 在多样化环境中进行基准测试，该方法在性能上优于标准的actor-critic方法和信任域基线方法。

Conclusion: 提出的秩-1近似自然策略优化方法既保持了自然梯度的优势，又显著降低了计算复杂度，为高效强化学习算法提供了新思路。

Abstract: Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.

</details>


### [534] [From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic](https://arxiv.org/abs/2601.18702)
*Hansheng Ren*

Main category: cs.LG

Relevance: 75.0

TL;DR: 论文挑战当前深度学习优先计算吞吐量而非数值精度的范式，提出精确性假说：通用智能需要任意精度算术计算基础，并引入Halo架构和精确推理单元来验证这一观点。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习范式过于关注计算吞吐量而忽视数值精度，假设智能来自大规模统计相关性。作者认为这种近似计算导致LLMs出现"幻觉"和逻辑不一致，这些是浮点近似误差在深度组合函数中累积的结果。

Method: 提出精确性假说，认为通用智能需要任意精度算术计算基础。引入Halo架构，采用有理数算术（ℚ）和新型精确推理单元（EIU）来确保数值精确性。

Result: 在Huginn-0125原型上的实证验证显示，600B参数的BF16基线在混沌系统中崩溃，而Halo架构能够无限期保持零数值发散。

Conclusion: 精确算术是减少System 2 AGI中逻辑不确定性的先决条件，为通用智能的计算基础提供了新方向。

Abstract: Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the "hallucinations" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.

</details>


### [535] [Falsifying Predictive Algorithm](https://arxiv.org/abs/2601.17146)
*Amanda Coston*

Main category: stat.ME

Relevance: 75.0

TL;DR: 提出一个统计证伪框架来检验算法的判别效度，即算法是否能比不可接受的代理变量更好地预测预期结果，用于在部署前识别算法是否预测了非预期的量


<details>
  <summary>Details</summary>
Motivation: 算法在实际应用中经常预测非预期的结果，这凸显了在部署前识别算法是否预测了不可接受量的需求。需要一种原则性的统计测试来验证算法的判别效度

Method: 基于因果推断、计量经济学和心理测量学的证伪实践，提出一个统计证伪框架。该框架通过比较不同结果的校准预测损失来评估算法是否对指定的不可接受代理变量表现出判别效度。使用非参数假设检验方法，对数据生成过程做出最小假设

Result: 在招生场景中，框架建立了关于性别的判别效度，但未能建立关于种族的判别效度。在刑事司法场景中，框架存在局限性，需要补充方法来评估其他方面的结构效度和外部效度

Conclusion: 证伪框架可以作为部署前的早期有效性检查，在公平性或鲁棒性分析之前使用。但需要认识到其局限性，并与其他方法结合来全面评估算法的有效性

Abstract: Empirical investigations into unintended model behavior often show that the algorithm is predicting another outcome than what was intended. These exposes highlight the need to identify when algorithms predict unintended quantities - ideally before deploying them into consequential settings. We propose a falsification framework that provides a principled statistical test for discriminant validity: the requirement that an algorithm predict intended outcomes better than impermissible ones. Drawing on falsification practices from causal inference, econometrics, and psychometrics, our framework compares calibrated prediction losses across outcomes to assess whether the algorithm exhibits discriminant validity with respect to a specified impermissible proxy. In settings where the target outcome is difficult to observe, multiple permissible proxy outcomes may be available; our framework accommodates both this setting and the case with a single permissible proxy. Throughout we use nonparametric hypothesis testing methods that make minimal assumptions on the data-generating process. We illustrate the method in an admissions setting, where the framework establishes discriminant validity with respect to gender but fails to establish discriminant validity with respect to race. This demonstrates how falsification can serve as an early validity check, prior to fairness or robustness analyses. We also provide analysis in a criminal justice setting, where we highlight the limitations of our framework and emphasize the need for complementary approaches to assess other aspects of construct validity and external validity.

</details>


### [536] [UniGRec: Unified Generative Recommendation with Soft Identifiers for End-to-End Optimization](https://arxiv.org/abs/2601.17438)
*Jialei Li,Yang Zhang,Yimeng Bai,Shuai Zhu,Ziqi Xue,Xiaoyan Zhao,Dingxian Wang,Frank Yang,Andrew Rabinovich,Xiangnan He*

Main category: cs.IR

Relevance: 75.0

TL;DR: UniGRec是一个统一的生成式推荐框架，通过可微分软项目标识符将分词器和推荐器统一在最终推荐目标下，解决了训练-推理不一致、项目标识符崩溃和协作信号不足三大挑战。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法通常将分词与推荐解耦或依赖异步交替优化，限制了端到端对齐。需要统一分词器和推荐器以实现完全端到端训练，但面临软硬标识符不匹配、码字使用不平衡导致的标识符崩溃、以及过度关注细粒度语义导致的协作信号不足三大挑战。

Method: 提出UniGRec框架：1) 退火推理对齐平滑连接软训练和硬推理；2) 码字均匀性正则化防止标识符崩溃并鼓励码本多样性；3) 双重协作蒸馏机制从轻量级教师模型提取协作先验，共同指导分词器和推荐器。

Result: 在真实世界数据集上的广泛实验表明，UniGRec持续优于最先进的基线方法。

Conclusion: 通过统一分词器和推荐器并解决三大挑战，UniGRec为生成式推荐提供了有效的端到端解决方案，在性能上超越了现有方法。

Abstract: Generative recommendation has recently emerged as a transformative paradigm that directly generates target items, surpassing traditional cascaded approaches. It typically involves two components: a tokenizer that learns item identifiers and a recommender trained on them. Existing methods often decouple tokenization from recommendation or rely on asynchronous alternating optimization, limiting full end-to-end alignment. To address this, we unify the tokenizer and recommender under the ultimate recommendation objective via differentiable soft item identifiers, enabling joint end-to-end training. However, this introduces three challenges: training-inference discrepancy due to soft-to-hard mismatch, item identifier collapse from codeword usage imbalance, and collaborative signal deficiency due to an overemphasis on fine-grained token-level semantics.
  To tackle these challenges, we propose UniGRec, a unified generative recommendation framework that addresses them from three perspectives. UniGRec employs Annealed Inference Alignment during tokenization to smoothly bridge soft training and hard inference, a Codeword Uniformity Regularization to prevent identifier collapse and encourage codebook diversity, and a Dual Collaborative Distillation mechanism that distills collaborative priors from a lightweight teacher model to jointly guide both the tokenizer and the recommender. Extensive experiments on real-world datasets demonstrate that UniGRec consistently outperforms state-of-the-art baseline methods. Our codes are available at https://github.com/Jialei-03/UniGRec.

</details>


### [537] [An autonomous living database for perovskite photovoltaics](https://arxiv.org/abs/2601.17807)
*Sherjeel Shabih,Hampus Näsström,Sharat Patil,Asmin Askin,Keely Dodd-Clements,Jessica Helisa Hautrive Rossato,Hugo Gajardoni de Lemos,Yuxin Liu,Florian Mathies,Natalia Maticiuc,Rico Meitzner,Edgar Nandayapa,Juan José Patiño López,Yaru Wang,Lauri Himanen,Eva Unger,T. Jesper Jacobsson,José A. Márquez,Kevin Maik Jablonka*

Main category: cond-mat.mtrl-sci

Relevance: 75.0

TL;DR: PERLA是一个自主更新的光伏材料数据库，利用大语言模型从文献中提取复杂设备数据，解决了人工标注跟不上发表速度的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 科学发现面临严重瓶颈：人工标注无法跟上指数级增长的发表速度，导致知识缺口不断扩大。在光伏领域，钙钛矿太阳能电池的主要数据库自2021年以来停滞不前，尽管相关研究持续大量产出。

Method: 整合大语言模型与物理感知验证的自动化流程，从持续文献流中提取复杂设备数据。系统通过LLM进行信息提取，并结合物理知识验证确保准确性。

Result: 系统达到人类水平的精度（>90%），消除了标注者差异。应用于2021年后的文献，揭示了隐藏的趋势：领域已明确转向采用自组装单分子层和富甲脒成分的反向结构，驱动了持续电压损失减少的清晰轨迹。

Conclusion: PERLA将静态出版物转化为动态知识资源，使数据驱动的发现能够以发表速度运行，解决了科学数据库更新的瓶颈问题。

Abstract: Scientific discovery is severely bottlenecked by the inability of manual curation to keep pace with exponential publication rates. This creates a widening knowledge gap. This is especially stark in photovoltaics, where the leading database for perovskite solar cells has been stagnant since 2021 despite massive ongoing research output. Here, we resolve this challenge by establishing an autonomous, self-updating living database (PERLA). Our pipeline integrates large language models with physics-aware validation to extract complex device data from the continuous literature stream, achieving human-level precision (>90%) and eliminating annotator variance. By employing this system on the previously inaccessible post-2021 literature, we uncover critical evolutionary trends hidden by data lag: the field has decisively shifted toward inverted architectures employing self-assembled monolayers and formamidinium-rich compositions, driving a clear trajectory of sustained voltage loss reduction. PERLA transforms static publications into dynamic knowledge resources that enable data-driven discovery to operate at the speed of publication.

</details>


### [538] [Optimizing the Landscape of LLM Embeddings with Dynamic Exploratory Graph Analysis for Generative Psychometrics: A Monte Carlo Study](https://arxiv.org/abs/2601.17010)
*Hudson Golino*

Main category: cs.LG

Relevance: 65.0

TL;DR: 该研究将LLM嵌入重构为可搜索的语义空间，通过动态探索图分析(DynEGA)系统遍历嵌入坐标，发现不同优化指标(TEFI和NMI)在嵌入深度上产生竞争性轨迹，需要加权复合标准来平衡结构准确性和组织性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM嵌入在心理学项目池维度结构估计中被视为静态、横截面的表示，隐含假设所有嵌入坐标贡献均匀，忽略了最优结构信息可能集中在嵌入空间特定区域的可能性。

Method: 将嵌入重构为可搜索的语义景观，采用动态探索图分析(DynEGA)系统遍历嵌入坐标，将维度索引视为伪时间顺序。通过大规模蒙特卡洛模拟，使用OpenAI的text-embedding-3-small模型嵌入代表自恋五个维度的项目，在不同项目池大小(每维度3-40项)和嵌入深度(3-1,298维度)下生成网络估计。

Result: TEFI在深层嵌入范围(900-1,200维度)达到最小值，此时基于熵的组织最大化但结构准确性下降；NMI在浅层深度达到峰值，此时维度恢复最强但基于熵的拟合仍不理想。单指标优化产生结构不一致的解决方案，而加权复合标准能识别平衡准确性和组织性的嵌入维度深度区域。最优嵌入深度随项目池大小系统缩放。

Conclusion: 嵌入景观是非均匀的语义空间，需要原则性优化而非默认使用全向量。研究建立了系统方法来确定LLM嵌入中信息最丰富的区域，为心理学测量中的嵌入应用提供了更精细的方法。

Abstract: Large language model (LLM) embeddings are increasingly used to estimate dimensional structure in psychological item pools prior to data collection, yet current applications treat embeddings as static, cross-sectional representations. This approach implicitly assumes uniform contribution across all embedding coordinates and overlooks the possibility that optimal structural information may be concentrated in specific regions of the embedding space. This study reframes embeddings as searchable landscapes and adapts Dynamic Exploratory Graph Analysis (DynEGA) to systematically traverse embedding coordinates, treating the dimension index as a pseudo-temporal ordering analogous to intensive longitudinal trajectories. A large-scale Monte Carlo simulation embedded items representing five dimensions of grandiose narcissism using OpenAI's text-embedding-3-small model, generating network estimations across systematically varied item pool sizes (3-40 items per dimension) and embedding depths (3-1,298 dimensions). Results reveal that Total Entropy Fit Index (TEFI) and Normalized Mutual Information (NMI) leads to competing optimization trajectories across the embedding landscape. TEFI achieves minima at deep embedding ranges (900--1,200 dimensions) where entropy-based organization is maximal but structural accuracy degrades, whereas NMI peaks at shallow depths where dimensional recovery is strongest but entropy-based fit remains suboptimal. Single-metric optimization produces structurally incoherent solutions, whereas a weighted composite criterion identifies embedding dimensions depth regions that jointly balance accuracy and organization. Optimal embedding depth scales systematically with item pool size. These findings establish embedding landscapes as non-uniform semantic spaces requiring principled optimization rather than default full-vector usage.

</details>


### [539] [Multi-Agent Deep Reinforcement Learning Under Constrained Communications](https://arxiv.org/abs/2601.17069)
*Shahil Shaik,Jonathon M. Smereka,Yue Wang*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出分布式多智能体强化学习框架DG-MAPPO，通过分布式图注意力网络实现完全去中心化的训练与执行，无需集中式批评器或全局信息，在多个基准测试中超越CTDE方法。


<details>
  <summary>Details</summary>
Motivation: 集中式训练分散式执行（CTDE）范式存在可扩展性、鲁棒性和泛化性瓶颈，依赖训练时的全局状态信息，在实际场景中（如队友增减、环境动态变化）脆弱且重训练成本高。分布式方法能让智能体仅使用本地信息和点对点通信进行适应。

Method: 提出分布式图注意力网络（D-GAT），通过多跳通信进行全局状态推断，智能体以完全分布式方式通过输入依赖的注意力权重整合邻居特征。基于D-GAT开发分布式图注意力MAPPO（DG-MAPPO），智能体使用本地观察、多跳通信和共享/平均奖励来优化本地策略和价值函数。

Result: 在StarCraftII多智能体挑战、Google Research Football和Multi-Agent Mujoco上的实验表明，该方法在广泛的合作任务中（包括同质和异质团队）始终优于强CTDE基线，实现了更优的协调能力。

Conclusion: 分布式MARL框架为鲁棒协作提供了原则性和可扩展的解决方案，消除了对集中式训练或全局可观测性的需求。DG-MAPPO首次完全消除了对特权集中信息的依赖，使智能体能够仅通过点对点通信进行学习和行动。

Abstract: Centralized training with decentralized execution (CTDE) has been the dominant paradigm in multi-agent reinforcement learning (MARL), but its reliance on global state information during training introduces scalability, robustness, and generalization bottlenecks. Moreover, in practical scenarios such as adding/dropping teammates or facing environment dynamics that differ from the training, CTDE methods can be brittle and costly to retrain, whereas distributed approaches allow agents to adapt using only local information and peer-to-peer communication. We present a distributed MARL framework that removes the need for centralized critics or global information. Firstly, we develop a novel Distributed Graph Attention Network (D-GAT) that performs global state inference through multi-hop communication, where agents integrate neighbor features via input-dependent attention weights in a fully distributed manner. Leveraging D-GAT, we develop the distributed graph-attention MAPPO (DG-MAPPO) -- a distributed MARL framework where agents optimize local policies and value functions using local observations, multi-hop communication, and shared/averaged rewards. Empirical evaluation on the StarCraftII Multi-Agent Challenge, Google Research Football, and Multi-Agent Mujoco demonstrates that our method consistently outperforms strong CTDE baselines, achieving superior coordination across a wide range of cooperative tasks with both homogeneous and heterogeneous teams. Our distributed MARL framework provides a principled and scalable solution for robust collaboration, eliminating the need for centralized training or global observability. To the best of our knowledge, DG-MAPPO appears to be the first to fully eliminate reliance on privileged centralized information, enabling agents to learn and act solely through peer-to-peer communication.

</details>


### [540] [The Triangle of Similarity: A Multi-Faceted Framework for Comparing Neural Network Representations](https://arxiv.org/abs/2601.17093)
*Olha Sirikova,Alvin Chan*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出"相似性三角"框架，结合静态表示相似性、功能相似性和稀疏性相似性三个互补视角，全面分析神经网络表示相似性。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络表示比较方法往往提供有限视角，需要更全面的框架来理解模型内部机制是否收敛到相似的计算模式。

Method: 提出相似性三角框架，结合：1) 静态表示相似性（CKA/Procrustes）；2) 功能相似性（线性模式连接性或预测相似性）；3) 稀疏性相似性（剪枝下的鲁棒性）。分析CNN、Vision Transformer和视觉语言模型，使用ImageNetV2（分布内）和CIFAR-10（分布外）测试集。

Result: 1) 架构家族是表示相似性的主要决定因素，形成明显聚类；2) CKA自相似性和任务准确性在剪枝过程中强相关，但准确性下降更快；3) 对某些模型对，剪枝似乎正则化表示，暴露出共享的计算核心。

Conclusion: 相似性三角框架提供了更全面的方法来评估模型是否收敛到相似的内部机制，为科学研究的模型选择和分析提供了有用工具。

Abstract: Comparing neural network representations is essential for understanding and validating models in scientific applications. Existing methods, however, often provide a limited view. We propose the Triangle of Similarity, a framework that combines three complementary perspectives: static representational similarity (CKA/Procrustes), functional similarity (Linear Mode Connectivity or Predictive Similarity), and sparsity similarity (robustness under pruning). Analyzing a range of CNNs, Vision Transformers, and Vision-Language Models using both in-distribution (ImageNetV2) and out-of-distribution (CIFAR-10) testbeds, our initial findings suggest that: (1) architectural family is a primary determinant of representational similarity, forming distinct clusters; (2) CKA self-similarity and task accuracy are strongly correlated during pruning, though accuracy often degrades more sharply; and (3) for some model pairs, pruning appears to regularize representations, exposing a shared computational core. This framework offers a more holistic approach for assessing whether models have converged on similar internal mechanisms, providing a useful tool for model selection and analysis in scientific research.

</details>


### [541] [Tabular Foundation Models are Strong Graph Anomaly Detectors](https://arxiv.org/abs/2601.17301)
*Yunhui Liu,Tieke He,Yongchao Liu,Can Yi,Hong Jin,Chuntao Hong*

Main category: cs.LG

Relevance: 65.0

TL;DR: TFM4GAD：一种简单有效的框架，通过将图数据"扁平化"为增强特征表，利用表格基础模型（TFMs）进行图异常检测，实现跨领域通用检测而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测方法遵循"一个模型对应一个数据集"的范式，导致计算成本高、数据需求大、泛化能力差。需要一种"一劳永逸"的基础模型解决方案，能够跨不同图检测异常而无需重新训练。

Method: 将图"扁平化"为增强特征表，包含原始节点特征、拉普拉斯嵌入、局部和全局结构特征、异常敏感邻域聚合等。然后使用表格基础模型（TFMs）在完全上下文学习机制下处理该特征表。

Result: 在多个数据集和不同TFM骨干上的广泛实验表明，TFM4GAD显著优于从头训练的专业GAD模型，实现了性能提升。

Conclusion: 该工作为利用TFMs作为强大、通用的图异常检测器提供了新视角和实用范式，解决了跨领域泛化和标签稀缺问题。

Abstract: Graph anomaly detection (GAD), which aims to identify abnormal nodes that deviate from the majority, has become increasingly important in high-stakes Web domains. However, existing GAD methods follow a "one model per dataset" paradigm, leading to high computational costs, substantial data demands, and poor generalization when transferred to new datasets. This calls for a foundation model that enables a "one-for-all" GAD solution capable of detecting anomalies across diverse graphs without retraining. Yet, achieving this is challenging due to the large structural and feature heterogeneity across domains. In this paper, we propose TFM4GAD, a simple yet effective framework that adapts tabular foundation models (TFMs) for graph anomaly detection. Our key insight is that the core challenges of foundation GAD, handling heterogeneous features, generalizing across domains, and operating with scarce labels, are the exact problems that modern TFMs are designed to solve via synthetic pre-training and powerful in-context learning. The primary challenge thus becomes structural: TFMs are agnostic to graph topology. TFM4GAD bridges this gap by "flattening" the graph, constructing an augmented feature table that enriches raw node features with Laplacian embeddings, local and global structural characteristics, and anomaly-sensitive neighborhood aggregations. This augmented table is processed by a TFM in a fully in-context regime. Extensive experiments on multiple datasets with various TFM backbones reveal that TFM4GAD surprisingly achieves significant performance gains over specialized GAD models trained from scratch. Our work offers a new perspective and a practical paradigm for leveraging TFMs as powerful, generalist graph anomaly detectors.

</details>


### [542] [LeanTutor: Towards a Verified AI Mathematical Proof Tutor](https://arxiv.org/abs/2601.17473)
*Manooshree Patel,Rayna Bhattacharyya,Thomas Lu,Arnav Mehta,Niels Voss,Narges Norouzi,Gireeja Ranade*

Main category: cs.LG

Relevance: 65.0

TL;DR: 开发了一个结合LLM和定理证明器的数学证明辅导系统LeanTutor，通过三个模块实现自动形式化、下一步生成和自然语言反馈，并在PeanoBench数据集上验证。


<details>
  <summary>Details</summary>
Motivation: LLM虽然支持自然语言交互但容易出错，定理证明器如Lean能保证正确性但学习门槛高。结合两者优势，开发一个既能保证正确性又易于学生使用的数学证明辅导系统。

Method: 提出LeanTutor系统，包含三个模块：1)自动形式化/证明检查器，将自然语言转换为形式化证明并验证；2)下一步生成器，基于当前证明状态生成可能的下一步；3)自然语言反馈生成器，提供自然语言指导。使用PeanoBench数据集（371个皮亚诺算术证明）进行评估。

Result: 开发了一个概念验证系统，展示了LLM与定理证明器结合在数学教育中的可行性。系统能提供可证明正确的数学证明辅导，同时保持自然语言交互的便利性。

Conclusion: 结合LLM的自然语言能力和定理证明器的正确性保证，可以创建有效的数学证明辅导工具。这种方法在数学教育领域具有应用潜力，特别是在保证教学准确性的同时降低学习门槛。

Abstract: This paper considers the development of an AI-based provably-correct mathematical proof tutor. While Large Language Models (LLMs) allow seamless communication in natural language, they are error prone. Theorem provers such as Lean allow for provable-correctness, but these are hard for students to learn. We present a proof-of-concept system (LeanTutor) by combining the complementary strengths of LLMs and theorem provers. LeanTutor is composed of three modules: (i) an autoformalizer/proof-checker, (ii) a next-step generator, and (iii) a natural language feedback generator. To evaluate the system, we introduce PeanoBench, a dataset of 371 Peano Arithmetic proofs in human-written natural language and formal language, derived from the Natural Numbers Game.

</details>


### [543] [Quantum-Inspired Episode Selection for Monte Carlo Reinforcement Learning via QUBO Optimization](https://arxiv.org/abs/2601.17570)
*Hadi Salloum,Ali Jnadi,Yaroslav Kholodov,Alexander Gasnikov*

Main category: cs.LG

Relevance: 65.0

TL;DR: MC+QUBO：将蒙特卡洛强化学习中的轨迹选择建模为QUBO问题，利用量子启发采样器优化选择，提升稀疏奖励环境下的样本效率


<details>
  <summary>Details</summary>
Motivation: 传统蒙特卡洛强化学习在稀疏奖励、大状态空间和轨迹相关性的环境中样本复杂度高，收敛慢。需要一种方法能智能选择高回报且多样化的轨迹子集来提升学习效率。

Method: 将轨迹选择问题转化为二次无约束二进制优化（QUBO）问题：线性项偏好高回报轨迹，二次项惩罚状态空间冗余。使用模拟量子退火（SQA）和模拟分岔（SB）作为黑盒求解器，在标准MC策略评估中集成组合过滤步骤。

Result: 在有限时域GridWorld实验中，MC+QUBO在收敛速度和最终策略质量上均优于传统蒙特卡洛方法，证明了量子启发优化作为强化学习决策子程序的潜力。

Conclusion: 通过将轨迹选择形式化为QUBO问题并使用量子启发求解器，能够有效提升蒙特卡洛强化学习的样本效率，特别是在稀疏奖励环境中。这为量子计算与强化学习的交叉研究开辟了新方向。

Abstract: Monte Carlo (MC) reinforcement learning suffers from high sample complexity, especially in environments with sparse rewards, large state spaces, and correlated trajectories. We address these limitations by reformulating episode selection as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solving it with quantum-inspired samplers. Our method, MC+QUBO, integrates a combinatorial filtering step into standard MC policy evaluation: from each batch of trajectories, we select a subset that maximizes cumulative reward while promoting state-space coverage. This selection is encoded as a QUBO, where linear terms favor high-reward episodes and quadratic terms penalize redundancy. We explore both Simulated Quantum Annealing (SQA) and Simulated Bifurcation (SB) as black-box solvers within this framework. Experiments in a finite-horizon GridWorld demonstrate that MC+QUBO outperforms vanilla MC in convergence speed and final policy quality, highlighting the potential of quantum-inspired optimization as a decision-making subroutine in reinforcement learning.

</details>


### [544] [Dissipative Learning: A Framework for Viable Adaptive Systems](https://arxiv.org/abs/2601.17933)
*Laurent Caraffa*

Main category: cs.LG

Relevance: 65.0

TL;DR: 该论文提出BEDS框架，将学习视为内在耗散过程，证明Fisher-Rao正则化是热力学最优策略，统一了多种现有方法


<details>
  <summary>Details</summary>
Motivation: 传统机器学习将遗忘和正则化视为启发式附加组件，而作者认为它们是自适应系统的结构要求。论文旨在从信息理论、热力学和信息几何角度，为学习过程提供更原则性的理论基础。

Method: 提出BEDS（贝叶斯涌现耗散结构）框架，将学习建模为在耗散约束下压缩信念状态的演化。核心贡献是条件最优性定理，证明Fisher-Rao正则化是唯一热力学最优的正则化策略。

Result: 证明了Fisher-Rao正则化（基于信息散度）比欧几里得正则化更优，将Ridge、SIGReg、EMA、SAC等方法统一为单一控制方程的特例。区分了BEDS可结晶问题和BEDS可维持问题。

Conclusion: 学习应被重新定义为在耗散约束下维持可行信念状态的过程。该框架为遗忘、正则化和稳定性提供了原则性视角，并自然扩展到持续学习和多智能体系统。

Abstract: We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints.
  A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation.
  Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.

</details>


### [545] [Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions](https://arxiv.org/abs/2601.18107)
*Pedram Agand,Mo Chen*

Main category: cs.LG

Relevance: 65.0

TL;DR: MoReBRAC是一个基于模型的离线强化学习框架，通过不确定性感知的潜在空间合成来缓解分布偏移问题，在D4RL基准测试中显著提升了性能


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在工业机器人等安全关键领域有巨大潜力，但面临静态数据集与学习策略之间的分布偏移问题，这通常需要高度保守的方法，限制了策略改进的潜力

Method: 提出MoReBRAC框架，使用双循环世界模型合成高保真转换来增强训练流形，通过分层不确定性管道（VAE流形检测、模型敏感性分析、MC dropout）确保合成数据的可靠性

Result: 在D4RL Gym-MuJoCo基准测试中显示出显著的性能提升，特别是在"随机"和"次优"数据机制中，并分析了VAE作为几何锚点的作用

Conclusion: MoReBRAC通过不确定性感知的潜在合成有效解决了离线强化学习中的分布偏移问题，为安全关键领域的应用提供了有前景的解决方案

Abstract: Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.

</details>


### [546] [Robust Learning of a Group DRO Neuron](https://arxiv.org/abs/2601.18115)
*Guyang Cao,Shuyao Li,Sushrut Karmalkar,Jelena Diakonikolas*

Main category: cs.LG

Relevance: 65.0

TL;DR: 本文研究了在任意标签噪声和组级分布偏移下学习单个神经元的问题，提出了一种计算高效的原始-对偶算法，该算法在最具挑战性的组重加权下与最优参数保持常数因子竞争。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据通常存在标签噪声和分布偏移，特别是在不同群体之间。传统的机器学习方法在这种复杂环境下表现不佳，需要开发能够处理任意标签噪声和组级分布偏移的鲁棒学习方法。

Method: 提出了一种组分布鲁棒优化（Group Distributionally Robust Optimization）框架，使用f-散度对组权重偏离均匀分布施加惩罚。开发了计算高效的原始-对偶算法，通过双重外推更新处理损失函数的固有非凸性。

Result: 算法输出的参数向量在最坏情况组加权下与最优参数保持常数因子竞争。该方法在LLM预训练基准测试中显示出良好前景，能够处理任意标签噪声和组特定分布偏移。

Conclusion: 该研究为在复杂噪声和分布偏移环境下学习提供了理论保证和实用算法，特别适用于需要鲁棒性的机器学习应用，包括LLM预训练等场景。

Abstract: We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\mathcal p_{[1]},\dots,\mathcal p_{[K]}$, we seek to approximate $\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\boldsymbolλ \in Δ_K$, where the objective is $\sum_{i \in [K]}λ_{[i]}\,\mathbb E_{(\mathbf x,y)\sim\mathcal p_{[i]}}(σ(\mathbf w\cdot\mathbf x)-y)^2 - νd_f(\boldsymbolλ,\frac{1}{K}\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $ν\geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\widehat{\mathbf w}$ that is constant-factor competitive with $\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks.

</details>


### [547] [FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning](https://arxiv.org/abs/2601.18650)
*Liheng Yu,Zhe Zhao,Yuxuan Wang,Pengkun Wang,Binwu Wang,Yang Wang*

Main category: cs.LG

Relevance: 65.0

TL;DR: 本文首次研究长尾分布下的机器遗忘问题，提出FaLW方法解决现有方法在长尾数据上的异质遗忘偏差和倾斜遗忘偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘研究主要在相对平衡的遗忘集上评估，忽略了现实世界中数据（如用户活动记录）常遵循长尾分布的情况。本文旨在填补这一研究空白，解决长尾分布下机器遗忘的挑战。

Method: 提出FaLW方法：一种即插即用、实例级别的动态损失重加权方法。通过比较每个样本的预测概率与同类别未见数据的分布来评估其遗忘状态，使用遗忘感知的重加权方案（通过平衡因子调节）自适应调整每个样本的遗忘强度。

Result: 大量实验表明，FaLW在长尾分布场景下实现了优越的性能，有效解决了异质遗忘偏差和倾斜遗忘偏差问题。

Conclusion: 本文首次系统研究了长尾分布下的机器遗忘问题，提出的FaLW方法能够有效处理现实世界中常见的长尾数据遗忘场景，为机器遗忘研究提供了新的视角和解决方案。

Abstract: Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \textit{Heterogeneous Unlearning Deviation} and \textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \textbf{Supplementary Material}.

</details>


### [548] [Counterfactual Explanations on Robust Perceptual Geodesics](https://arxiv.org/abs/2601.18678)
*Eslam Zaher,Maciej Trzaskowski,Quan Nguyen,Fred Roosta*

Main category: cs.LG

Relevance: 65.0

TL;DR: PCG提出了一种基于感知黎曼度量的反事实解释方法，通过追踪测地线生成语义有效的反事实解释，解决了现有方法中对抗性扰动和语义漂移的问题。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释方法存在距离度量选择模糊的问题，导致生成的反事实解释要么是语义无意义的对抗性扰动，要么产生离流形伪影和语义漂移。需要一种与人类感知对齐的几何结构来生成语义有效的反事实解释。

Method: PCG方法使用从鲁棒视觉特征诱导的感知黎曼度量，在潜空间中构建反事实解释。该方法追踪测地线，这种几何结构与人类感知对齐，惩罚脆弱方向，实现平滑、在流形上、语义有效的过渡。

Result: 在三个视觉数据集上的实验表明，PCG优于基线方法，并揭示了在标准度量下隐藏的模型失败模式。

Conclusion: 通过引入感知黎曼度量，PCG能够生成语义有效的反事实解释，为模型解释性提供了更好的工具，特别是在理解模型决策边界和失败模式方面。

Abstract: Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.

</details>


### [549] [ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule](https://arxiv.org/abs/2601.18681)
*Yilie Huang,Wenpin Tang,Xunyu Zhou*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出ART-RL方法，通过强化学习自适应调整扩散模型采样过程中的时间步长分布，优化离散化误差，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型采样使用均匀或手工设计的时间网格可能不是最优的，特别是在给定时间步数预算的情况下。需要一种自适应的时间重参数化方法来最小化离散化误差。

Method: 提出Adaptive Reparameterized Time (ART)方法，控制重参数化时间变量的时钟速度，实现不均匀的时间步长分布。进一步提出ART-RL，将时间变化建模为连续时间强化学习问题，使用高斯策略并通过actor-critic算法数据驱动地学习最优时间调度。

Result: 在EDM框架基础上，ART-RL在CIFAR-10上显著改善了Fréchet Inception Distance，并在AFHQv2、FFHQ和ImageNet等数据集上展示了良好的迁移性，无需重新训练。

Conclusion: 通过强化学习自适应优化扩散模型采样时间调度是有效的，能够提升生成质量并具有良好的泛化能力。

Abstract: We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fréchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.

</details>


### [550] [Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic](https://arxiv.org/abs/2601.18783)
*Deepthi Pathare,Leo Laine,Morteza Haghir Chehreghani*

Main category: cs.LG

Relevance: 65.0

TL;DR: 提出基于PPO的多目标强化学习框架，为重型车辆高速公路驾驶学习连续帕累托最优策略集合，平衡安全、能源效率和运营成本之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 高速公路重型车辆驾驶需要在安全、效率和运营成本之间进行复杂的权衡决策。传统的标量奖励函数通过聚合这些竞争目标往往模糊了它们之间的权衡结构，难以明确表达不同目标间的折衷关系。

Method: 基于近端策略优化（PPO）的多目标强化学习框架，在卡车战术决策的可扩展仿真平台上学习连续的政策集合。该方法学习捕获三个冲突目标（安全、能源效率、时间效率）权衡的帕累托最优策略。

Result: 获得了平滑且可解释的帕累托前沿，能够在不同冲突目标之间灵活选择驾驶行为。框架允许在不同驾驶策略之间无缝切换而无需重新训练，为自动驾驶卡车应用提供了鲁棒且自适应的决策策略。

Conclusion: 该多目标强化学习框架成功解决了重型车辆高速公路驾驶中的复杂权衡问题，通过明确的帕累托最优策略表示，为自动驾驶卡车提供了灵活、可解释且无需重新训练的决策能力。

Abstract: Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.

</details>


### [551] [Recovering Performance in Speech Emotion Recognition from Discrete Tokens via Multi-Layer Fusion and Paralinguistic Feature Integration](https://arxiv.org/abs/2601.17085)
*Esther Sun,Abinay Reddy Naini,Carlos Busso*

Main category: eess.AS

Relevance: 65.0

TL;DR: 该论文研究了离散语音标记在语音情感识别中的应用，通过多层融合和声学特征集成来弥补量化过程中的副语言信息损失，使离散标记性能接近连续表示。


<details>
  <summary>Details</summary>
Motivation: 离散语音标记在存储和语言模型集成方面具有优势，但在语音情感识别中由于量化过程中的副语言信息损失而应用受限。论文旨在解决这一性能差距。

Method: 1) 使用微调的WavLM-Large模型系统量化不同层配置和k-means量化粒度下的性能退化；2) 提出注意力机制的多层融合来捕获不同层的互补信息；3) 集成openSMILE特征重新引入副语言线索；4) 比较主流神经编解码标记器（SpeechTokenizer、DAC、EnCodec）并与声学特征融合分析。

Result: 研究发现通过多层融合和声学特征集成，离散标记可以在语音情感识别任务中缩小与连续表示的性能差距。

Conclusion: 离散语音标记通过适当的信息恢复策略（多层融合和声学特征集成）可以在语音情感识别中达到接近连续表示的性能，为离散标记在该领域的应用提供了可行方案。

Abstract: Discrete speech tokens offer significant advantages for storage and language model integration, but their application in speech emotion recognition (SER) is limited by paralinguistic information loss during quantization. This paper presents a comprehensive investigation of discrete tokens for SER. Using a fine-tuned WavLM-Large model, we systematically quantify performance degradation across different layer configurations and k-means quantization granularities. To recover the information loss, we propose two key strategies: (1) attention-based multi-layer fusion to recapture complementary information from different layers, and (2) integration of openSMILE features to explicitly reintroduce paralinguistic cues. We also compare mainstream neural codec tokenizers (SpeechTokenizer, DAC, EnCodec) and analyze their behaviors when fused with acoustic features. Our findings demonstrate that through multi-layer fusion and acoustic feature integration, discrete tokens can close the performance gap with continuous representations in SER tasks.

</details>


### [552] [JetFormer: A Scalable and Efficient Transformer for Jet Tagging from Offline Analysis to FPGA Triggers](https://arxiv.org/abs/2601.17215)
*Ruoqing Zheng,Chang Sun,Qibin Liu,Lauri Laatu,Arianna Cox,Benedikt Maier,Alexander Tapper,Jose G. F. Coutinho,Wayne Luk,Zhiqiang Que*

Main category: cs.LG

Relevance: 45.0

TL;DR: JetFormer是一个用于大型强子对撞机粒子喷注标记的通用可扩展Transformer编码器架构，能在从高精度离线分析到超低延迟在线触发的全谱系场景中有效工作，具有计算效率和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有粒子喷注标记方法通常针对特定部署场景定制，缺乏一个能在从离线分析到在线触发的全谱系场景中统一工作的通用架构。需要一种既能保持高性能又能满足硬件部署要求的Transformer架构。

Method: 提出JetFormer，一种仅编码器的Transformer架构，处理可变长度的粒子特征集，无需显式成对相互作用输入。采用硬件感知优化流程，基于多目标超参数搜索，通过结构化剪枝和量化实现模型压缩。

Result: 在JetClass数据集上，JetFormer与交互丰富的ParT模型精度相当（相差0.7%以内），但FLOPs减少37.4%。在HLS4ML 150P基准数据集上，比MLP、Deep Sets和Interaction Networks等现有模型准确率高3-4%。通过压缩得到适合FPGA触发系统的JetFormer-tiny变体，满足亚微秒延迟要求。

Conclusion: JetFormer通过统一高性能建模和可部署性，为在LHC离线和在线环境中部署基于Transformer的喷注标记器提供了实用途径，展示了Transformer架构在粒子物理应用中的潜力。

Abstract: We present JetFormer, a versatile and scalable encoder-only Transformer architecture for particle jet tagging at the Large Hadron Collider (LHC). Unlike prior approaches that are often tailored to specific deployment regimes, JetFormer is designed to operate effectively across the full spectrum of jet tagging scenarios, from high-accuracy offline analysis to ultra-low-latency online triggering. The model processes variable-length sets of particle features without relying on input of explicit pairwise interactions, yet achieves competitive or superior performance compared to state-of-the-art methods. On the large-scale JetClass dataset, a large-scale JetFormer matches the accuracy of the interaction-rich ParT model (within 0.7%) while using 37.4% fewer FLOPs, demonstrating its computational efficiency and strong generalization. On benchmark HLS4ML 150P datasets, JetFormer consistently outperforms existing models such as MLPs, Deep Sets, and Interaction Networks by 3-4% in accuracy. To bridge the gap to hardware deployment, we further introduce a hardware-aware optimization pipeline based on multi-objective hyperparameter search, yielding compact variants like JetFormer-tiny suitable for FPGA-based trigger systems with sub-microsecond latency requirements. Through structured pruning and quantization, we show that JetFormer can be aggressively compressed with minimal accuracy loss. By unifying high-performance modeling and deployability within a single architectural framework, JetFormer provides a practical pathway for deploying Transformer-based jet taggers in both offline and online environments at the LHC. Code is available at https://github.com/walkieq/JetFormer.

</details>


### [553] [Thermodynamically Optimal Regularization under Information-Geometric Constraints](https://arxiv.org/abs/2601.17330)
*Laurent Caraffa*

Main category: cs.LG

Relevance: 45.0

TL;DR: 该论文提出了一个统一的理论框架，将热力学最优性、信息几何和正则化联系起来，证明在特定假设下，Fisher-Rao度量是信念空间的唯一可容许几何，热力学最优正则化对应于最小化到参考状态的Fisher-Rao距离平方。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习依赖于一系列经验成功但理论上异质的正则化技术（如权重衰减、dropout、指数移动平均），同时训练大型模型的能耗成本急剧增加，引发了学习算法是否接近任何基本效率界限的问题。

Method: 提出了一个统一的理论框架，基于三个明确假设：(A1)最优性需要内在的、参数化不变的信息度量；(A2)信念状态由已知约束下的最大熵分布建模；(A3)最优过程是准静态的。在此框架下证明了条件最优性定理。

Result: 证明了Fisher-Rao度量是信念空间的唯一可容许几何，热力学最优正则化对应于最小化到参考状态的Fisher-Rao距离平方。推导了高斯和圆形信念模型的诱导几何，分别产生双曲和von Mises流形，并表明经典正则化方案在结构上无法保证热力学最优性。

Conclusion: 该工作为机器学习中的正则化提供了原则性的几何和热力学基础，引入了学习的热力学效率概念，并提出了可实验验证的预测。

Abstract: Modern machine learning relies on a collection of empirically successful but theoretically heterogeneous regularization techniques, such as weight decay, dropout, and exponential moving averages. At the same time, the rapidly increasing energetic cost of training large models raises the question of whether learning algorithms approach any fundamental efficiency bound. In this work, we propose a unifying theoretical framework connecting thermodynamic optimality, information geometry, and regularization.
  Under three explicit assumptions -- (A1) that optimality requires an intrinsic, parametrization-invariant measure of information, (A2) that belief states are modeled by maximum-entropy distributions under known constraints, and (A3) that optimal processes are quasi-static -- we prove a conditional optimality theorem. Specifically, the Fisher--Rao metric is the unique admissible geometry on belief space, and thermodynamically optimal regularization corresponds to minimizing squared Fisher--Rao distance to a reference state.
  We derive the induced geometries for Gaussian and circular belief models, yielding hyperbolic and von Mises manifolds, respectively, and show that classical regularization schemes are structurally incapable of guaranteeing thermodynamic optimality. We introduce a notion of thermodynamic efficiency of learning and propose experimentally testable predictions. This work provides a principled geometric and thermodynamic foundation for regularization in machine learning.

</details>


### [554] [RPNT: Robust Pre-trained Neural Transformer -- A Pathway for Generalized Motor Decoding](https://arxiv.org/abs/2601.17641)
*Hao Fang,Ryan A. Canfield,Tomohiro Ouchi,Beatrice Macagno,Eli Shlizerman,Amy L. Orsborn*

Main category: cs.LG

Relevance: 45.0

TL;DR: 提出了RPNT（鲁棒预训练神经Transformer），用于脑解码任务，通过预训练实现跨会话、跨类型、跨被试和跨脑区的鲁棒泛化能力。


<details>
  <summary>Details</summary>
Motivation: 脑解码需要模型能够泛化到不同的脑区记录、不同会话、不同行为类型和不同被试。现有模型只能部分解决这些挑战，需要开发能够适应和泛化的预训练神经Transformer模型。

Method: 1) 多维旋转位置编码（MRoPE）聚合实验元数据；2) 基于上下文的注意力机制，通过卷积核处理全局注意力以学习局部时间结构；3) 鲁棒的自监督学习目标，采用均匀因果掩码策略和对比表示。在两个不同数据集上预训练：多会话多任务多被试微电极基准数据集和高密度Neuropixel 1.0探针的多脑区记录数据集。

Result: RPNT在所有跨会话、跨类型、跨被试和跨脑区的下游行为解码任务中，始终达到并超越了现有解码模型的性能。

Conclusion: RPNT通过创新的架构设计和预训练策略，在脑解码任务中实现了优异的跨域泛化能力，为神经Transformer模型的发展提供了重要贡献。

Abstract: Brain decoding aims to interpret and translate neural activity into behaviors. As such, it is imperative that decoding models are able to generalize across variations, such as recordings from different brain sites, distinct sessions, different types of behavior, and a variety of subjects. Current models can only partially address these challenges and warrant the development of pretrained neural transformer models capable to adapt and generalize. In this work, we propose RPNT - Robust Pretrained Neural Transformer, designed to achieve robust generalization through pretraining, which in turn enables effective finetuning given a downstream task. In particular, RPNT unique components include 1) Multidimensional rotary positional embedding (MRoPE) to aggregate experimental metadata such as site coordinates, session name and behavior types; 2) Context-based attention mechanism via convolution kernels operating on global attention to learn local temporal structures for handling non-stationarity of neural population activity; 3) Robust self-supervised learning (SSL) objective with uniform causal masking strategies and contrastive representations. We pretrained two separate versions of RPNT on distinct datasets a) Multi-session, multi-task, and multi-subject microelectrode benchmark; b) Multi-site recordings using high-density Neuropixel 1.0 probes. The datasets include recordings from the dorsal premotor cortex (PMd) and from the primary motor cortex (M1) regions of nonhuman primates (NHPs) as they performed reaching tasks. After pretraining, we evaluated the generalization of RPNT in cross-session, cross-type, cross-subject, and cross-site downstream behavior decoding tasks. Our results show that RPNT consistently achieves and surpasses the decoding performance of existing decoding models in all tasks.

</details>


### [555] [Systematic Characterization of Minimal Deep Learning Architectures: A Unified Analysis of Convergence, Pruning, and Quantization](https://arxiv.org/abs/2601.17987)
*Ziwei Zheng,Huizhi Liang,Vaclav Snasel,Vito Latora,Panos Pardalos,Giuseppe Nicosia,Varun Ojha*

Main category: cs.LG

Relevance: 45.0

TL;DR: 提出一种系统探索收敛、剪枝和量化关系的计算方法，发现尽管架构多样，但性能基本不变，学习动态呈现不稳定、学习和过拟合三个阶段，量化对参数少的模型影响更大


<details>
  <summary>Details</summary>
Motivation: 深度学习网络在分类任务上表现出色，但确定能够可靠解决任务的最小架构仍然具有挑战性。需要系统探索收敛、剪枝和量化之间的关系，为在剪枝和低精度约束下选择紧凑稳定模型提供指导

Method: 提出计算方法论：首先在大量架构上进行结构化设计扫描，然后在代表性模型上评估收敛行为、剪枝敏感性和量化鲁棒性。聚焦于复杂度递增的图像分类任务，涵盖深度神经网络、卷积神经网络和视觉Transformer

Result: 尽管架构多样，但性能基本不变，学习动态一致呈现三个阶段：不稳定、学习和过拟合。确定了稳定学习所需的最小可学习参数，揭示了不同的收敛和剪枝阶段，量化了降低数值精度对可训练参数的影响。更深架构比浅层架构对剪枝更具弹性，参数冗余高达60%，量化对参数较少的模型影响更严重，对更难的数据集影响更大

Conclusion: 这些发现为在图像分类中，在剪枝和低精度约束下选择紧凑稳定模型提供了可操作的指导。研究揭示了不同架构间的共同学习模式，并为模型压缩和高效部署提供了实证基础

Abstract: Deep learning networks excel at classification, yet identifying minimal architectures that reliably solve a task remains challenging. We present a computational methodology for systematically exploring and analyzing the relationships among convergence, pruning, and quantization. The workflow first performs a structured design sweep across a large set of architectures, then evaluates convergence behavior, pruning sensitivity, and quantization robustness on representative models. Focusing on well-known image classification of increasing complexity, and across Deep Neural Networks, Convolutional Neural Networks, and Vision Transformers, our initial results show that, despite architectural diversity, performance is largely invariant and learning dynamics consistently exhibit three regimes: unstable, learning, and overfitting. We further characterize the minimal learnable parameters required for stable learning, uncover distinct convergence and pruning phases, and quantify the effect of reduced numeric precision on trainable parameters. Aligning with intuition, the results confirm that deeper architectures are more resilient to pruning than shallower ones, with parameter redundancy as high as 60%, and quantization impacts models with fewer learnable parameters more severely and has a larger effect on harder image datasets. These findings provide actionable guidance for selecting compact, stable models under pruning and low-precision constraints in image classification.

</details>


### [556] [GCFX: Generative Counterfactual Explanations for Deep Graph Models at the Model Level](https://arxiv.org/abs/2601.18447)
*Jinlong Hu,Jiacheng Liu*

Main category: cs.LG

Relevance: 45.0

TL;DR: GCFX：基于深度图生成的模型级反事实解释方法，通过双编码器、结构感知标注器和MPNN解码器生成高质量反事实解释，并使用全局总结算法选择代表性解释，提升图学习模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度图学习模型在处理图结构数据方面表现出色，但其复杂的内部架构和缺乏透明度使得模型决策难以解释，导致用户难以理解和信任这些"黑盒"模型。需要提供模型级的解释技术来帮助用户全面理解模型的整体决策过程和底层机制。

Method: 提出GCFX方法，基于深度图生成的模型级反事实解释框架。采用双编码器、结构感知标注器和消息传递神经网络（MPNN）解码器的架构，准确学习输入数据的真实潜在分布并生成高质量反事实示例。然后使用全局反事实总结算法从众多候选反事实中选择最具代表性和全面的解释。

Result: 在合成数据集和多个真实世界数据集上的实验表明，GCFX在反事实有效性和覆盖率方面优于现有方法，同时保持较低的解释成本。为增强全局反事实解释的实用性和可信度提供了重要支持。

Conclusion: GCFX方法通过生成高质量的反事实解释和有效的全局总结，显著提升了深度图学习模型的可解释性和可信度，为解决图学习模型的黑盒问题提供了有效的模型级解释方案。

Abstract: Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations.

</details>


### [557] [Quasi Monte Carlo methods enable extremely low-dimensional deep generative models](https://arxiv.org/abs/2601.18676)
*Miles Martinez,Alex H. Williams*

Main category: cs.LG

Relevance: 45.0

TL;DR: QLVMs是一种专门用于寻找高维数据极低维可解释嵌入的深度生成模型，通过拟蒙特卡洛积分直接近似边缘似然，在1-3维潜空间中优于传统VAE和IWAE。


<details>
  <summary>Details</summary>
Motivation: 传统变分自编码器(VAE)和重要性加权自编码器(IWAE)虽然能学习潜变量表示，但在极低维空间（1-3维）中难以获得可解释且高质量的嵌入。现有方法依赖编码器和变分下界，限制了潜空间的透明度和可分析性。

Method: 提出拟蒙特卡洛潜变量模型(QLVMs)，采用随机拟蒙特卡洛积分直接近似边缘似然，而非依赖学习编码器和变分下界。该方法专门针对1-3维极低维潜空间设计，通过计算密集的积分方法获得更准确的潜变量表示。

Result: 在多个数据集上，QLVMs在匹配潜维度的条件下持续优于传统VAE和IWAE。生成的嵌入支持透明可视化、非参数密度估计、聚类和测地路径计算等后分析，这些在更高维空间中难以验证。

Conclusion: QLVMs为优先考虑可解释性和潜空间分析的应用提供了有吸引力的解决方案，尽管计算密集且在复杂数据集上难以生成精细细节，但在极低维潜空间表示方面具有优势。

Abstract: This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis.

</details>


### [558] [Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data](https://arxiv.org/abs/2601.18728)
*Willem Diepeveen,Oscar Leong*

Main category: cs.LG

Relevance: 45.0

TL;DR: Riemannian AmbientFlow：一种从噪声/损坏观测中同时学习概率生成模型和底层非线性数据流形的框架，结合了变分推断、黎曼几何和流形学习。


<details>
  <summary>Details</summary>
Motivation: 在科学和成像应用中，通常无法获得干净样本，只能观测到噪声或线性损坏的测量值。同时，数据中的潜在结构（如流形几何）对下游科学分析很重要。现有方法难以从损坏观测中同时学习生成模型和底层流形结构。

Method: 基于AmbientFlow的变分推断框架，引入由归一化流诱导的数据驱动黎曼几何，通过pullback度量和黎曼自编码器提取流形结构。在几何正则化和测量条件下，学习模型能恢复底层数据分布并获得平滑的双Lipschitz流形参数化。

Result: 理论保证表明，在适当条件下，学习模型能以可控误差恢复底层数据分布，并获得平滑的流形参数化。平滑解码器可作为逆问题的原则性生成先验，具有恢复保证。在低维合成流形和MNIST上进行了实证验证。

Conclusion: Riemannian AmbientFlow为从损坏观测中同时学习生成模型和底层流形结构提供了统一框架，具有理论保证和实际应用价值，特别适用于科学和成像领域。

Abstract: Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.

</details>


### [559] [EveNet: A Foundation Model for Particle Collision Data Analysis](https://arxiv.org/abs/2601.17126)
*Ting-Hsiang Hsu,Bai-Hong Zhou,Qibin Liu,Yue Xu,Shu Li,George Wei-Shu Hou,Benjamin Nachman,Shih-Chieh Hsu,Vinicius Mikuni,Yuan-Tang Chou,Yulei Zhang*

Main category: hep-ex

Relevance: 45.0

TL;DR: EveNet是一个用于高能物理碰撞事件分析的基础模型，通过自监督学习和物理监督的混合目标在5亿模拟碰撞事件上预训练，在多种任务上超越现有方法，并成功迁移到实验数据。


<details>
  <summary>Details</summary>
Motivation: 深度学习在高能物理数据分析中面临计算挑战，限制了其潜力。研究旨在解决对撞机物理中的这些挑战，通过构建事件级基础模型来统一和加速发现过程。

Method: 引入EveNet事件级基础模型，采用共享粒子云表示，在5亿模拟碰撞事件上进行预训练，结合自监督学习和物理监督的混合目标。

Result: 在多种任务上超越最先进基线，包括重共振搜索和奇异希格斯衰变；在低统计区域展示卓越数据效率；在CMS开放数据中重新发现Υ介子；稳定提取量子关联可观测量。

Conclusion: EveNet成功编码了粒子相互作用的基本物理结构，为当前和未来对撞机提供了一个统一且资源高效的框架来加速发现。

Abstract: While deep learning is transforming data analysis in high-energy physics, computational challenges limit its potential. We address these challenges in the context of collider physics by introducing EveNet, an event-level foundation model pretrained on 500 million simulated collision events using a hybrid objective of self-supervised learning and physics-informed supervision. By leveraging a shared particle-cloud representation, EveNet outperforms state-of-the-art baselines across diverse tasks, including searches for heavy resonances and exotic Higgs decays, and demonstrates exceptional data efficiency in low-statistics regimes. Crucially, we validate the transferability of the model to experimental data by rediscovering the $Υ$ meson in CMS Open Data and show its capacity for precision physics through the robust extraction of quantum correlation observables stable against systematic uncertainties. These results indicate that EveNet can successfully encode the fundamental physical structure of particle interactions, which offers a unified and resource-efficient framework to accelerate discovery at current and future colliders.

</details>


### [560] [EuleroDec: A Complex-Valued RVQ-VAE for Efficient and Robust Audio Coding](https://arxiv.org/abs/2601.17517)
*Luca Cerovaz,Michele Mancusi,Emanuele Rodolà*

Main category: cs.SD

Relevance: 45.0

TL;DR: 本文提出了一种端到端的复数值RVQ-VAE音频编解码器，通过在整个分析-量化-合成流程中保持幅度-相位耦合，无需对抗判别器和扩散后滤波器，在计算效率大幅提升的同时达到或超越现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有频域神经编解码器通常忽视相位信息或将复数值相位编码为两个独立的实值通道，限制了空间保真度。这导致需要引入对抗判别器来补偿音频信号表示能力的不足，但会牺牲收敛速度和训练稳定性。

Method: 提出端到端的复数值RVQ-VAE音频编解码器，在整个分析-量化-合成流程中保持幅度-相位耦合，移除了对抗判别器和扩散后滤波器。该方法直接处理复数值表示，避免了相位信息的分离处理。

Result: 无需GAN或扩散模型，在域内匹配或超越训练时间更长的基线方法，在域外达到相位相干性和波形保真度的SOTA性能。相比需要训练数十万步的标准基线，本方法将训练预算减少一个数量级，计算效率显著提升同时保持高感知质量。

Conclusion: 通过保持幅度-相位耦合的复数值表示，可以构建更高效、稳定的音频编解码器，无需复杂的对抗训练或后处理技术，在减少计算成本的同时实现优越的性能。

Abstract: Audio codecs power discrete music generative modelling, music streaming, and immersive media by shrinking PCM audio to bandwidth-friendly bitrates. Recent works have gravitated towards processing in the spectral domain; however, spectrogram domains typically struggle with phase modeling, which is naturally complex-valued. Most frequency-domain neural codecs either disregard phase information or encode it as two separate real-valued channels, limiting spatial fidelity. This entails the need to introduce adversarial discriminators at the expense of convergence speed and training stability to compensate for the inadequate representation power of the audio signal. In this work we introduce an end-to-end complex-valued RVQ-VAE audio codec that preserves magnitude-phase coupling across the entire analysis-quantization-synthesis pipeline and removes adversarial discriminators and diffusion post-filters. Without GANs or diffusion, we match or surpass much longer-trained baselines in-domain and reach SOTA out-of-domain performance on phase coherence and waveform fidelity. Compared to standard baselines that train for hundreds of thousands of steps, our model, which reduces the training budget by an order of magnitude, is markedly more compute-efficient while preserving high perceptual quality.

</details>


### [561] [Deep Intrinsic Surprise-Regularized Control (DISRC): A Biologically Inspired Mechanism for Efficient Deep Q-Learning in Sparse Environments](https://arxiv.org/abs/2601.17598)
*Yash Kini,Shiv Davay,Shreya Polavarapu*

Main category: cs.NE

Relevance: 45.0

TL;DR: DISRC是一种基于生物学启发的DQN增强方法，通过潜在空间惊喜动态缩放Q更新，在稀疏奖励环境中提升学习效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 标准DQN代理使用固定学习率和统一更新缩放，即使在TD误差调节下也缺乏灵活性，这在稀疏奖励环境中会导致收敛不稳定。需要一种能够根据环境新奇性动态调整学习强度的机制。

Method: DISRC使用LayerNorm编码器编码状态，计算相对于移动潜在设定点的偏差惊喜分数。每个更新根据TD误差和惊喜强度按比例缩放，在早期探索时促进可塑性，在熟悉度增加时保持稳定性。

Result: 在MiniGrid稀疏奖励环境中，DISRC比标准DQN表现更好：在DoorKey环境中，首次成功回合快33%，奖励标准差更低(0.25 vs 0.34)，AUC更高(596.42 vs 534.90)；在LavaCrossing中，最终奖励更高(0.95 vs 0.93)，AUC最高(957.04)。

Conclusion: DISRC作为一种新颖的机制，通过将惊喜作为内在学习信号来调节离策略代理的学习强度，在稀疏奖励领域中提高了效率和稳定性，特别是在传统基于价值的方法不足时增强了决策质量。

Abstract: Deep reinforcement learning (DRL) has driven major advances in autonomous control. Still, standard Deep Q-Network (DQN) agents tend to rely on fixed learning rates and uniform update scaling, even as updates are modulated by temporal-difference (TD) error. This rigidity destabilizes convergence, especially in sparse-reward settings where feedback is infrequent. We introduce Deep Intrinsic Surprise-Regularized Control (DISRC), a biologically inspired augmentation to DQN that dynamically scales Q-updates based on latent-space surprise. DISRC encodes states via a LayerNorm-based encoder and computes a deviation-based surprise score relative to a moving latent setpoint. Each update is then scaled in proportion to both TD error and surprise intensity, promoting plasticity during early exploration and stability as familiarity increases. We evaluate DISRC on two sparse-reward MiniGrid environments, which included MiniGrid-DoorKey-8x8 and MiniGrid-LavaCrossingS9N1, under identical settings as a vanilla DQN baseline. In DoorKey, DISRC reached the first successful episode (reward > 0.8) 33% faster than the vanilla DQN baseline (79 vs. 118 episodes), with lower reward standard deviation (0.25 vs. 0.34) and higher reward area under the curve (AUC: 596.42 vs. 534.90). These metrics reflect faster, more consistent learning - critical for sparse, delayed reward settings. In LavaCrossing, DISRC achieved a higher final reward (0.95 vs. 0.93) and the highest AUC of all agents (957.04), though it converged more gradually. These preliminary results establish DISRC as a novel mechanism for regulating learning intensity in off-policy agents, improving both efficiency and stability in sparse-reward domains. By treating surprise as an intrinsic learning signal, DISRC enables agents to modulate updates based on expectation violations, enhancing decision quality when conventional value-based methods fall short.

</details>


### [562] [FARM: Few-shot Adaptive Malware Family Classification under Concept Drift](https://arxiv.org/abs/2601.17907)
*Numan Halit Guldemir,Oluwafemi Olukoya,Jesús Martínez-del-Rincón*

Main category: cs.CR

Relevance: 45.0

TL;DR: FARM是一个用于Windows PE恶意软件分类的少样本自适应框架，通过三元组自编码器进行特征提取，使用DBSCAN聚类检测概念漂移，并采用原型分类进行少样本适应，在概念漂移下提升分类性能5.6%


<details>
  <summary>Details</summary>
Motivation: 恶意软件分类模型面临概念漂移问题，包括协变量漂移和标签漂移，导致性能下降。现有方法难以适应快速演变的威胁环境和新型恶意软件家族，需要能够在有限监督下自适应检测和适应的框架。

Method: 1) 使用三元组自编码器将样本投影到判别性潜在空间；2) 通过DBSCAN聚类和动态阈值进行无监督漂移检测；3) 采用基于原型的少样本学习进行快速适应；4) 当积累足够漂移样本时支持完全重新训练以更新潜在空间。

Result: 在BenchMFC数据集上，FARM在协变量漂移下提升分类性能5.6%，仅使用少样本适应在未见恶意软件家族上达到平均F1分数0.85，重新训练后进一步提升至0.94。

Conclusion: FARM在动态恶意软件检测环境中展现出鲁棒性和适应性，能够在有限监督下有效处理概念漂移问题，为恶意软件分类提供实用的自适应解决方案。

Abstract: Malware classification models often face performance degradation due to concept drift, arising from evolving threat landscapes and the emergence of novel malware families. This paper presents FARM (Few-shot Adaptive Recognition of Malware), a framework designed to detect and adapt to both covariate and label drift in Windows Portable Executable (PE) malware classification. FARM leverages a triplet autoencoder to project samples into a discriminative latent space, enabling unsupervised drift detection via DBSCAN clustering and dynamic thresholding. For rapid adaptation, it employs few-shot learning using prototype-based classification, requiring only a handful of labeled samples. FARM also supports full retraining when enough drifted samples accumulate, updating the latent space for long-term integration. Experiments on the BenchMFC dataset demonstrate that FARM improves classification performance under covariate drift by 5.6\%, and achieves an average F1 score of 0.85 on unseen malware families using only few-shot adaptation, which further increases to 0.94 after retraining. These results highlight FARM's robustness and adaptability in dynamic malware detection environments under limited supervision.

</details>


### [563] [A Dataset of Dengue Hospitalizations in Brazil (1999 to 2021) with Weekly Disaggregation from Monthly Counts](https://arxiv.org/abs/2601.16994)
*Lucas M. Morello,Matheus Lima Castro,Pedro Cesar M. G. Camargo,Liliane Moreira Nery,Darllan Collins da Cunha e Silva,Leopoldo Lusquino Filho*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该论文发布了一个巴西登革热住院时间序列数据集，将原始月度数据通过三次样条插值分解为周度分辨率，并包含多种环境和社会经济解释变量，用于流行病预测的AI模型训练。


<details>
  <summary>Details</summary>
Motivation: 提高原始月度数据的时间粒度，以更有效地训练流行病预测的AI模型。需要将巴西市级登革热住院时间序列从月度分解到周度，同时保持数据质量。

Method: 开发了一个插值协议，包含校正步骤以保持月度总量。比较了线性插值、抖动和三次样条三种策略，使用圣保罗州的高分辨率参考数据集进行评估。最终采用三次样条插值生成1999-2021年的周度序列。

Result: 三次样条插值在参考数据上表现出最高的符合度。数据集包含登革热住院时间序列和多种解释变量（人口密度、温室气体排放、贫困指数、温度、降水等），均采用相同的时间分解方案以确保多变量兼容性。

Conclusion: 该数据集为多变量时间序列分析、环境健康研究和机器学习/深度学习模型开发提供了高质量的基础数据，特别适用于流行病爆发预测。

Abstract: This data paper describes and publicly releases this dataset (v1.0.0), published on Zenodo under DOI 10.5281/zenodo.18189192. Motivated by the need to increase the temporal granularity of originally monthly data to enable more effective training of AI models for epidemiological forecasting, the dataset harmonizes municipal-level dengue hospitalization time series across Brazil and disaggregates them to weekly resolution (epidemiological weeks) through an interpolation protocol with a correction step that preserves monthly totals. The statistical and temporal validity of this disaggregation was assessed using a high-resolution reference dataset from the state of Sao Paulo (2024), which simultaneously provides monthly and epidemiological-week counts, enabling a direct comparison of three strategies: linear interpolation, jittering, and cubic spline. Results indicated that cubic spline interpolation achieved the highest adherence to the reference data, and this strategy was therefore adopted to generate weekly series for the 1999 to 2021 period. In addition to hospitalization time series, the dataset includes a comprehensive set of explanatory variables commonly used in epidemiological and environmental modeling, such as demographic density, CH4, CO2, and NO2 emissions, poverty and urbanization indices, maximum temperature, mean monthly precipitation, minimum relative humidity, and municipal latitude and longitude, following the same temporal disaggregation scheme to ensure multivariate compatibility. The paper documents the datasets provenance, structure, formats, licenses, limitations, and quality metrics (MAE, RMSE, R2, KL, JSD, DTW, and the KS test), and provides usage recommendations for multivariate time-series analysis, environmental health studies, and the development of machine learning and deep learning models for outbreak forecasting.

</details>


### [564] [How does Graph Structure Modulate Membership-Inference Risk for Graph Neural Networks?](https://arxiv.org/abs/2601.17130)
*Megha Khosla*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该论文研究了图神经网络中的成员推理攻击，特别关注图结构对节点级隐私泄露的影响，分析了训练图构建和推理时边访问两个维度，并探讨了差分隐私GNN的可审计性。


<details>
  <summary>Details</summary>
Motivation: GNN在敏感应用中的使用引发了训练数据泄露的担忧。现有隐私泄露研究主要基于非图领域（如图像和表格数据），缺乏针对图结构的特定分析。本文强调需要图特定的隐私分析，研究图结构对节点级成员推理的影响。

Method: 1) 形式化节点邻域元组上的成员推理攻击；2) 研究两个关键维度：训练图构建（随机采样vs雪球采样）和推理时边访问；3) 实证分析不同模型和数据集；4) 探讨差分隐私GNN的可审计性，分析训练-测试数据点的统计可交换性。

Result: 1) 雪球采样的覆盖偏差通常会损害泛化性能；2) 推理时启用训练-测试边访问能提高测试精度，缩小训练-测试差距，并在大多数模型和数据集上产生最低的成员优势；3) 泛化差距是成员推理风险的不完整代理；4) 节点级任务的归纳分割（随机或雪球采样）破坏了可交换性，限制了差分隐私模型成员优势标准界限的适用性。

Conclusion: 图结构对GNN隐私泄露有重要影响，需要专门的图特定分析。推理时边访问是影响成员推理风险的关键因素，泛化差距不能完全反映隐私风险。差分隐私GNN在节点级任务中的可审计性受到训练-测试分割方式的限制。

Abstract: Graph neural networks (GNNs) have become the standard tool for encoding data and their complex relationships into continuous representations, improving prediction accuracy in several machine learning tasks like node classification and link prediction. However, their use in sensitive applications has raised concerns about the potential leakage of training data. Research on privacy leakage in GNNs has largely been shaped by findings from non-graph domains, such as images and tabular data. We emphasize the need of graph specific analysis and investigate the impact of graph structure on node level membership inference. We formalize MI over node-neighbourhood tuples and investigate two important dimensions: (i) training graph construction and (ii) inference-time edge access. Empirically, snowball's coverage bias often harms generalisation relative to random sampling, while enabling inter-train-test edges at inference improves test accuracy, shrinks the train-test gap, and yields the lowest membership advantage across most of the models and datasets. We further show that the generalisation gap empirically measured as the performance difference between the train and test nodes is an incomplete proxy for MI risk: access to edges dominates-MI can rise or fall independent of gap changes. Finally, we examine the auditability of differentially private GNNs, adapting the definition of statistical exchangeability of train-test data points for graph based models. We show that for node level tasks the inductive splits (random or snowball sampled) break exchangeability, limiting the applicability of standard bounds for membership advantage of differential private models.

</details>


### [565] [Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmark](https://arxiv.org/abs/2601.18509)
*Andro Sabashvili*

Main category: cs.LG

Relevance: 40.0

TL;DR: 本文综述了时间序列预测中保形预测方法的应用，重点解决了时间序列数据非交换性对传统保形预测理论保证的挑战，系统分类并评估了多种应对策略。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测中的可靠不确定性量化至关重要，但传统方法依赖限制性分布假设。保形预测作为无分布框架提供了理论保证，但时间序列的时序依赖性违反了保形预测的核心交换性假设，需要专门方法解决这一冲突。

Method: 系统综述了四类主要算法解决方案：1) 放松交换性假设的方法；2) 重新定义数据单元为独立时间序列集合的方法；3) 显式建模预测残差动态的方法；4) 适应分布漂移以维持长期覆盖的在线学习算法。

Result: 通过综合比较这些方法，突出了计算效率和实际数据上的性能表现，为时间序列预测中的不确定性量化提供了系统性的方法论指导。

Conclusion: 时间序列保形预测是一个活跃的研究领域，需要专门方法处理时序依赖性。不同方法在计算效率和实际性能上各有优劣，选择取决于具体应用场景和数据特性。

Abstract: Reliable uncertainty quantification is of critical importance in time series forecasting, yet traditional methods often rely on restrictive distributional assumptions. Conformal prediction (CP) has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees. However, applying CP to sequential data presents a primary challenge: the temporal dependencies inherent in time series fundamentally violate the core assumption of data exchangeability, upon which standard CP guarantees are built. This review critically examines the main categories of algorithmic solutions designed to address this conflict. We survey and benchmark methods that relax the exchangeability assumption, those that redefine the data unit to be a collection of independent time series, approaches that explicitly model the dynamics of the prediction residuals, and online learning algorithms that adapt to distribution shifts to maintain long-run coverage. By synthesizing these approaches, we highlight computational efficiency and practical performance on real-world data.

</details>


### [566] [Over-The-Air Extreme Learning Machines with XL Reception via Nonlinear Cascaded Metasurfaces](https://arxiv.org/abs/2601.17749)
*Kyriakos Stylianopoulos,Mattia Fabiani,Giulia Torcolacci,Davide Dardari,George C. Alexandropoulos*

Main category: eess.SP

Relevance: 40.0

TL;DR: 该论文提出了一种基于可编程超表面的XL-MIMO系统，作为极端学习机(ELM)在物理层执行OTA二进制分类任务，实现了无线通信系统中的机器学习推理能力。


<details>
  <summary>Details</summary>
Motivation: 面向目标通信范式需要在无线传输数据上应用机器学习推理，但在MIMO系统物理层实现ML模型面临挑战。作者旨在利用可编程超表面技术，将学习能力嵌入到未来通信系统中。

Method: 提出XL-MIMO-ELM系统：接收端架构包含密集并行放置的衍射层（XL超表面）和单个射频链。前层采用固定非线性响应的单元，其余层使用可调线性响应单元来近似OTA训练的ELM权重。系统可在闭式形式下训练。

Result: 数值研究表明，在XL超表面元件体制下，该系统在不同数据集和无线场景中实现了与数字化和理想化ML模型相当的性能，证明了在通信系统中嵌入OTA学习能力的可行性。

Conclusion: 通过可编程超表面技术，XL-MIMO系统可以作为OTA执行的ELM，为未来通信系统嵌入机器学习能力提供了可行方案，实现了物理层的智能推理。

Abstract: The recently envisioned goal-oriented communications paradigm calls for the application of inference on wirelessly transferred data via Machine Learning (ML) tools. An emerging research direction deals with the realization of inference ML models directly in the physical layer of Multiple-Input Multiple-Output (MIMO) systems, which, however, entails certain significant challenges. In this paper, leveraging the technology of programmable MetaSurfaces (MSs), we present an eXtremely Large (XL) MIMO system that acts as an Extreme Learning Machine (ELM) performing binary classification tasks completely Over-The-Air (OTA), which can be trained in closed form. The proposed system comprises a receiver architecture consisting of densely parallel placed diffractive layers of XL MSs followed by a single reception radio-frequency chain. The front layer facing the MIMO channel consists of identical unit cells of a fixed NonLinear (NL) response, while the remaining layers of elements of tunable linear responses are utilized to approximate OTA the trained ELM weights. Our numerical investigations showcase that, in the XL regime of MS elements, the proposed XL-MIMO-ELM system achieves performance comparable to that of digital and idealized ML models across diverse datasets and wireless scenarios, thereby demonstrating the feasibility of embedding OTA learning capabilities into future communication systems.

</details>


### [567] [PhysE-Inv: A Physics-Encoded Inverse Modeling approach for Arctic Snow Depth Prediction](https://arxiv.org/abs/2601.17074)
*Akila Sampath,Vandana Janeja,Jianwu Wang*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出PhysE-Inv框架，结合物理引导推理与序列架构，用于北极雪深估计的逆问题求解，在数据稀疏噪声条件下提升预测性能与物理一致性。


<details>
  <summary>Details</summary>
Motivation: 北极雪深估计是关键的时变逆问题，现有过程模型对稀疏数据敏感，数据驱动模型缺乏物理可解释性，需要噪声容忍且物理可解释的逆建模方法。

Method: 提出PhysE-Inv框架：1) 使用LSTM编码器-解码器与多头注意力序列架构；2) 结合物理引导对比学习；3) 采用满射物理约束逆推方法，利用静水平衡前向模型作为目标代理，在缺乏地面真值时有效学习；4) 在潜空间应用重构物理正则化，从噪声不完整时间序列中发现隐藏物理参数。

Result: 相比最先进基线，PhysE-Inv显著提升预测性能，误差减少20%，同时展示出更好的物理一致性和对数据稀疏的鲁棒性。

Conclusion: 该方法为噪声容忍、可解释的逆建模开辟了新路径，在地理空间和冰冻圈领域具有广泛适用性。

Abstract: The accurate estimation of Arctic snow depth ($h_s$) remains a critical time-varying inverse problem due to the extreme scarcity and noise inherent in associated sea ice parameters. Existing process-based and data-driven models are either highly sensitive to sparse data or lack the physical interpretability required for climate-critical applications. To address this gap, we introduce PhysE-Inv, a novel framework that integrates a sophisticated sequential architecture, an LSTM Encoder-Decoder with Multi-head Attention and physics-guided contrastive learning, with physics-guided inference.Our core innovation lies in a surjective, physics-constrained inversion methodology. This methodology first leverages the hydrostatic balance forward model as a target-formulation proxy, enabling effective learning in the absence of direct $h_s$ ground truth; second, it uses reconstruction physics regularization over a latent space to dynamically discover hidden physical parameters from noisy, incomplete time-series input. Evaluated against state-of-the-art baselines, PhysE-Inv significantly improves prediction performance, reducing error by 20\% while demonstrating superior physical consistency and resilience to data sparsity compared to empirical methods. This approach pioneers a path for noise-tolerant, interpretable inverse modeling, with wide applicability in geospatial and cryospheric domains.

</details>


### [568] [E2PL: Effective and Efficient Prompt Learning for Incomplete Multi-view Multi-Label Class Incremental Learning](https://arxiv.org/abs/2601.17076)
*Jiajun Chen,Yue Wu,Kai Huang,Wen Xi,Yangyang Wu,Xiaoye Miao,Mengying Zhu,Meng Xi,Guanjie Cheng*

Main category: cs.LG

Relevance: 35.0

TL;DR: E2PL是一个用于不完整多视图多标签类增量学习的高效提示学习框架，通过任务定制提示和缺失感知提示解决视图缺失和类别动态扩展问题，使用原型张量化将参数复杂度从指数级降至线性级。


<details>
  <summary>Details</summary>
Motivation: 现实世界Web应用中存在视图缺失和类别动态扩展的问题，现有方法无法同时处理这两个挑战，要么缺乏对新类别的适应性，要么在处理缺失视图模式时参数呈指数级增长，限制了在Web环境中的可扩展性。

Method: 提出E2PL框架，包含：1）任务定制提示用于类增量适应；2）缺失感知提示用于灵活整合任意视图缺失场景；3）高效原型张量化模块，利用原子张量分解将提示参数复杂度从指数级降至线性级；4）动态对比学习策略显式建模不同缺失视图模式间的复杂依赖关系。

Result: 在三个基准测试上的广泛实验表明，E2PL在效果和效率方面均优于现有最先进方法。

Conclusion: E2PL为不完整多视图多标签类增量学习提供了一个有效的解决方案，通过创新的提示设计和参数优化方法，解决了现实Web应用中视图缺失和类别动态扩展的挑战。

Abstract: Multi-view multi-label classification (MvMLC) is indispensable for modern web applications aggregating information from diverse sources. However, real-world web-scale settings are rife with missing views and continuously emerging classes, which pose significant obstacles to robust learning. Prevailing methods are ill-equipped for this reality, as they either lack adaptability to new classes or incur exponential parameter growth when handling all possible missing-view patterns, severely limiting their scalability in web environments. To systematically address this gap, we formally introduce a novel task, termed \emph{incomplete multi-view multi-label class incremental learning} (IMvMLCIL), which requires models to simultaneously address heterogeneous missing views and dynamic class expansion. To tackle this task, we propose \textsf{E2PL}, an Effective and Efficient Prompt Learning framework for IMvMLCIL. \textsf{E2PL} unifies two novel prompt designs: \emph{task-tailored prompts} for class-incremental adaptation and \emph{missing-aware prompts} for the flexible integration of arbitrary view-missing scenarios. To fundamentally address the exponential parameter explosion inherent in missing-aware prompts, we devise an \emph{efficient prototype tensorization} module, which leverages atomic tensor decomposition to elegantly reduce the prompt parameter complexity from exponential to linear w.r.t. the number of views. We further incorporate a \emph{dynamic contrastive learning} strategy explicitly model the complex dependencies among diverse missing-view patterns, thus enhancing the model's robustness. Extensive experiments on three benchmarks demonstrate that \textsf{E2PL} consistently outperforms state-of-the-art methods in both effectiveness and efficiency. The codes and datasets are available at https://anonymous.4open.science/r/code-for-E2PL.

</details>


### [569] [SFO: Learning PDE Operators via Spectral Filtering](https://arxiv.org/abs/2601.17090)
*Noam Koren,Rafael Moschopoulos,Kira Radinsky,Elad Hazan*

Main category: cs.LG

Relevance: 35.0

TL;DR: SFO是一种新型神经算子，使用通用谱基参数化积分核，通过仅学习快速衰减的特征值谱系数，高效捕捉PDE解映射中的长程非局部相互作用，在多个基准测试中达到最先进精度。


<details>
  <summary>Details</summary>
Motivation: 偏微分方程(PDEs)控制复杂系统，但现有神经算子在高效捕捉解映射中的长程非局部相互作用方面存在困难。理论发现表明，平移不变PDE离散化的离散格林函数具有空间线性动力系统结构，这启发了更高效的表示方法。

Method: 提出谱滤波算子(SFO)，使用从希尔伯特矩阵特征模态导出的通用谱基(USB)参数化积分核。通过理论证明这些核在USB中具有紧凑近似，仅学习快速衰减特征值的谱系数，实现高效表示。

Result: 在六个基准测试（包括反应扩散、流体动力学和3D电磁学）中，SFO达到最先进精度，相对于强基线减少误差达40%，同时使用更少的参数。

Conclusion: SFO通过谱滤波理论提供了一种高效表示PDE解映射中长程相互作用的方法，在精度和参数效率方面均有显著改进，为神经算子设计提供了新思路。

Abstract: Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green's functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters.

</details>


### [570] [MambaNet: Mamba-assisted Channel Estimation Neural Network With Attention Mechanism](https://arxiv.org/abs/2601.17108)
*Dianxin Luan,Chengsi Liang,Jie Huang,Zheng Lin,Kaitao Meng,John Thompson,Cheng-Xiang Wang*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出了一种结合Mamba和自注意力机制的神经网络框架，用于OFDM波形的大规模子载波信道估计，具有低复杂度和高效的长距离依赖捕捉能力。


<details>
  <summary>Details</summary>
Motivation: 针对大规模子载波配置的OFDM系统，传统信道估计方法难以有效处理长距离子载波间的依赖关系，而基于Transformer的神经网络虽然能捕捉这些依赖但计算复杂度高。需要一种既能有效建模子载波间长距离依赖，又具有较低复杂度的解决方案。

Method: 提出了Mamba辅助的神经网络框架，结合了自注意力机制。采用定制化的Mamba架构处理大规模子载波信道估计，特别实现了双向选择性扫描机制（因为不同子载波的信道增益是非因果的），相比传统Mamba结构提升了性能。该框架相比基于Transformer的神经网络具有更低的空间复杂度。

Result: 在3GPP TS 36.101信道上的仿真结果表明，相比其他基线神经网络解决方案，该方法以更少的可调参数实现了改进的信道估计性能。

Conclusion: 提出的Mamba辅助神经网络框架为大规模子载波OFDM系统的信道估计提供了一种高效、低复杂度的解决方案，特别适合处理子载波间的长距离依赖关系。

Abstract: This paper proposes a Mamba-assisted neural network framework incorporating self-attention mechanism to achieve improved channel estimation with low complexity for orthogonal frequency-division multiplexing (OFDM) waveforms, particularly for configurations with a large number of subcarriers. With the integration of customized Mamba architecture, the proposed framework handles large-scale subcarrier channel estimation efficiently while capturing long-distance dependencies among these subcarriers effectively. Unlike conventional Mamba structure, this paper implements a bidirectional selective scan to improve channel estimation performance, because channel gains at different subcarriers are non-causal. Moreover, the proposed framework exhibits relatively lower space complexity than transformer-based neural networks. Simulation results tested on the 3GPP TS 36.101 channel demonstrate that compared to other baseline neural network solutions, the proposed method achieves improved channel estimation performance with a reduced number of tunable parameters.

</details>


### [571] [Conservative & Aggressive NaNs Accelerate U-Nets for Neuroimaging](https://arxiv.org/abs/2601.17180)
*Inés Gonzalez-Pepe,Vinuyan Sivakolunthu,Jacob Fortin,Yohan Chatelain,Tristan Glatard*

Main category: cs.LG

Relevance: 35.0

TL;DR: 论文提出两种基于数值不确定性的CNN加速方法：Conservative & Aggressive NaNs，通过将数值不稳定体素替换为NaN，使后续层跳过对无关数据的计算，在神经影像等任务中实现最高1.67倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 神经影像深度学习模型架构日益庞大，尽管硬件进步，效率仍是持续关注的问题。作者发现CNN中许多操作应用于数值噪声主导的值，对模型输出影响可忽略，部分模型中高达三分之二的卷积操作似乎是冗余的。

Method: 提出两种max pooling和unpooling变体：Conservative & Aggressive NaNs，识别数值不稳定体素并用NaN替换，允许后续层跳过对无关数据的计算。方法在PyTorch中实现，无需架构更改。

Result: 在至少50% NaN的输入中观察到一致的运行时改进；在超过三分之二NaN的数据中（常见于神经影像场景），平均推理加速1.67倍。Conservative NaNs平均减少30%卷积操作，无性能下降，特定层可跳过64.64%卷积。Aggressive NaNs可跳过69.30%卷积，但可能偶尔影响性能。

Conclusion: 数值不确定性可被利用来减少CNN中的冗余计算并提高推理效率，为深度学习模型优化提供了新思路。

Abstract: Deep learning models for neuroimaging increasingly rely on large architectures, making efficiency a persistent concern despite advances in hardware. Through an analysis of numerical uncertainty of convolutional neural networks (CNNs), we observe that many operations are applied to values dominated by numerical noise and have negligible influence on model outputs. In some models, up to two-thirds of convolution operations appear redundant. We introduce Conservative & Aggressive NaNs, two novel variants of max pooling and unpooling that identify numerically unstable voxels and replace them with NaNs, allowing subsequent layers to skip computations on irrelevant data. Both methods are implemented within PyTorch and require no architectural changes. We evaluate these approaches on four CNN models spanning neuroimaging and image classification tasks. For inputs containing at least 50% NaNs, we observe consistent runtime improvements; for data with more than two-thirds NaNs )common in several neuroimaging settings) we achieve an average inference speedup of 1.67x. Conservative NaNs reduces convolution operations by an average of 30% across models and datasets, with no measurable performance degradation, and can skip up to 64.64% of convolutions in specific layers. Aggressive NaNs can skip up to 69.30% of convolutions but may occasionally affect performance. Overall, these methods demonstrate that numerical uncertainty can be exploited to reduce redundant computation and improve inference efficiency in CNNs.

</details>


### [572] [Federated Proximal Optimization for Privacy-Preserving Heart Disease Prediction: A Controlled Simulation Study on Non-IID Clinical Data](https://arxiv.org/abs/2601.17183)
*Farzam Asad,Junaid Saif Khan,Maria Tariq,Sundus Munir,Muhammad Adnan Khan*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文研究联邦学习在医疗数据隐私保护下的应用，通过FedProx算法处理非独立同分布的心脏病预测数据，在保护隐私的同时实现了比集中式学习更好的准确率。


<details>
  <summary>Details</summary>
Motivation: 医疗数据因隐私法规（如HIPAA、GDPR）无法直接共享，但需要跨医院协作提升诊断模型性能。联邦学习可在不集中原始数据的情况下实现协作训练，但医疗数据存在非独立同分布特性，需要专门算法处理。

Method: 使用UCI心脏病数据集（303名患者），通过人口统计分层模拟4个异构医院客户端，创建真实的非独立同分布数据分区。采用FedProx算法，通过近端正则化控制客户端漂移，在50次独立运行中进行统计验证。

Result: FedProx（mu=0.05）达到85.00%准确率，优于集中式学习（83.33%）和孤立本地模型（平均78.45%）。近端正则化在异构环境中有效控制客户端漂移，保护患者隐私的同时提升模型性能。

Conclusion: FedProx在医疗联邦学习中能有效处理非独立同分布数据，为实际医疗系统部署提供算法见解和实践指南，结果可直接应用于医院IT管理者的隐私保护协作学习实施。

Abstract: Healthcare institutions have access to valuable patient data that could be of great help in the development of improved diagnostic models, but privacy regulations like HIPAA and GDPR prevent hospitals from directly sharing data with one another. Federated Learning offers a way out to this problem by facilitating collaborative model training without having the raw patient data centralized. However, clinical datasets intrinsically have non-IID (non-independent and identically distributed) features brought about by demographic disparity and diversity in disease prevalence and institutional practices. This paper presents a comprehensive simulation research of Federated Proximal Optimization (FedProx) for Heart Disease prediction based on UCI Heart Disease dataset. We generate realistic non-IID data partitions by simulating four heterogeneous hospital clients from the Cleveland Clinic dataset (303 patients), by inducing statistical heterogeneity by demographic-based stratification. Our experimental results show that FedProx with proximal parameter mu=0.05 achieves 85.00% accuracy, which is better than both centralized learning (83.33%) and isolated local models (78.45% average) without revealing patient privacy. Through generous sheer ablation studies with statistical validation on 50 independent runs we demonstrate that proximal regularization is effective in curbing client drift in heterogeneous environments. This proof-of-concept research offers algorithmic insights and practical deployment guidelines for real-world federated healthcare systems, and thus, our results are directly transferable to hospital IT-administrators, implementing privacy-preserving collaborative learning.

</details>


### [573] [Rethinking Benchmarks for Differentially Private Image Classification](https://arxiv.org/abs/2601.17189)
*Sabrina Mokhtari,Sara Kodeiri,Shubhankar Mohapatra,Florian Tramer,Gautam Kamath*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文重新审视差分隐私图像分类的基准测试，提出了一套全面的基准集，并在不同设置下测试现有技术，同时创建了公开的排行榜来追踪进展。


<details>
  <summary>Details</summary>
Motivation: 当前差分隐私机器学习领域的基准测试不够全面，缺乏在不同设置（如有无额外数据、凸优化设置、不同数据集）下的系统评估。需要建立更全面的基准来推动技术进步。

Method: 1) 提出一套全面的基准测试集，涵盖多种设置；2) 在这些基准上测试已建立的差分隐私技术；3) 创建公开可用的排行榜供社区追踪进展。

Result: 建立了全面的差分隐私图像分类基准测试框架，测试了现有技术在不同设置下的有效性，并提供了公开的排行榜工具。

Conclusion: 该工作为差分隐私机器学习研究提供了更全面的评估框架，有助于识别在不同设置下仍然有效的技术，并通过公开排行榜促进社区进步。

Abstract: We revisit benchmarks for differentially private image classification. We suggest a comprehensive set of benchmarks, allowing researchers to evaluate techniques for differentially private machine learning in a variety of settings, including with and without additional data, in convex settings, and on a variety of qualitatively different datasets. We further test established techniques on these benchmarks in order to see which ideas remain effective in different settings. Finally, we create a publicly available leader board for the community to track progress in differentially private machine learning.

</details>


### [574] [Accelerated Sinkhorn Algorithms for Partial Optimal Transport](https://arxiv.org/abs/2601.17196)
*Nghia Thu Truong,Qui Phu Pham,Quang Nguyen,Dung Luong,Mai Tran*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出了ASPOT方法，将Nesterov加速与交替最小化结合到部分最优传输问题中，获得了O(n^{7/3}ε^{-5/3})的复杂度改进，并通过实验验证了性能优势。


<details>
  <summary>Details</summary>
Motivation: 部分最优传输(POT)处理两个分布间仅传输部分质量的问题，适用于边缘分布大小不等或包含异常值的情况。虽然Sinkhorn方法被广泛使用，但其在POT中的复杂度边界仍不理想，限制了可扩展性。

Method: 提出了加速Sinkhorn for POT (ASPOT)方法，在POT设置中结合交替最小化和Nesterov风格加速。同时展示了通过明智选择熵参数γ可以改进经典Sinkhorn方法的收敛速率。

Result: ASPOT获得了O(n^{7/3}ε^{-5/3})的复杂度边界，优于现有方法。在实际应用实验中验证了理论，并展示了所提方法的优越性能。

Conclusion: ASPOT方法通过加速技术显著改进了部分最优传输问题的计算效率，为处理不等边缘分布和异常值提供了更可扩展的解决方案。

Abstract: Partial Optimal Transport (POT) addresses the problem of transporting only a fraction of the total mass between two distributions, making it suitable when marginals have unequal size or contain outliers. While Sinkhorn-based methods are widely used, their complexity bounds for POT remain suboptimal and can limit scalability. We introduce Accelerated Sinkhorn for POT (ASPOT), which integrates alternating minimization with Nesterov-style acceleration in the POT setting, yielding a complexity of $\mathcal{O}(n^{7/3}\varepsilon^{-5/3})$. We also show that an informed choice of the entropic parameter $γ$ improves rates for the classical Sinkhorn method. Experiments on real-world applications validate our theories and demonstrate the favorable performance of our proposed methods.

</details>


### [575] [Parameter Inference and Uncertainty Quantification with Diffusion Models: Extending CDI to 2D Spatial Conditioning](https://arxiv.org/abs/2601.17224)
*Dmitrii Torbunov,Yihui Ren,Lijun Wu,Yimei Zhu*

Main category: cs.LG

Relevance: 35.0

TL;DR: 将条件扩散模型逆问题求解器（CDI）从一维时间信号扩展到二维空间数据，应用于材料表征中的会聚束电子衍射参数推断，能生成校准良好的后验分布，准确反映测量约束。


<details>
  <summary>Details</summary>
Motivation: 科学逆问题中需要量化不确定性以区分可识别参数和模糊参数。虽然CDI已在一维时间信号上展示了有效的概率推断，但其在高维空间数据上的适用性尚未探索。

Method: 将CDI扩展到二维空间条件化，直接从空间观测进行概率参数推断。在会聚束电子衍射参数推断这一具有挑战性的多参数逆问题上进行验证，使用模拟的CBED数据和真实参数。

Result: CDI生成校准良好的后验分布：对于确定良好的参数产生紧密分布，对于模糊参数产生适当宽泛的分布。相比之下，标准回归方法虽然聚合指标看似准确，但通过预测训练集均值来掩盖不确定性。

Conclusion: CDI成功从时间域扩展到空间域，为稳健的科学推断提供了真正的不确定性信息。

Abstract: Uncertainty quantification is critical in scientific inverse problems to distinguish identifiable parameters from those that remain ambiguous given available measurements. The Conditional Diffusion Model-based Inverse Problem Solver (CDI) has previously demonstrated effective probabilistic inference for one-dimensional temporal signals, but its applicability to higher-dimensional spatial data remains unexplored. We extend CDI to two-dimensional spatial conditioning, enabling probabilistic parameter inference directly from spatial observations. We validate this extension on convergent beam electron diffraction (CBED) parameter inference - a challenging multi-parameter inverse problem in materials characterization where sample geometry, electronic structure, and thermal properties must be extracted from 2D diffraction patterns. Using simulated CBED data with ground-truth parameters, we demonstrate that CDI produces well-calibrated posterior distributions that accurately reflect measurement constraints: tight distributions for well-determined quantities and appropriately broad distributions for ambiguous parameters. In contrast, standard regression methods - while appearing accurate on aggregate metrics - mask this underlying uncertainty by predicting training set means for poorly constrained parameters. Our results confirm that CDI successfully extends from temporal to spatial domains, providing the genuine uncertainty information required for robust scientific inference.

</details>


### [576] [Unrolled Neural Networks for Constrained Optimization](https://arxiv.org/abs/2601.17274)
*Samar Hadou,Alejandro Ribeiro*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出约束对偶展开(CDU)框架，使用两个耦合神经网络求解约束优化问题，模拟对偶上升算法动态，在混合整数二次规划和无线网络功率分配中实现近最优解并展示强OOD泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统对偶上升算法求解约束优化问题需要迭代计算，计算成本高。作者希望开发可学习的加速版本，通过神经网络模拟优化器动态，实现快速求解并具备泛化能力。

Method: 提出约束对偶展开(CDU)框架：1) 主网络模拟迭代优化器，为给定对偶乘子寻找拉格朗日函数的驻点；2) 对偶网络生成最优乘子轨迹，每层查询主网络；3) 通过约束学习施加主下降-对偶上升动态；4) 将训练公式化为嵌套优化问题，采用交替更新策略。

Result: 在混合整数二次规划(MIQP)和无线网络功率分配问题上，CDU框架能够产生近最优、近可行的解，并且在分布外(OOD)场景下展现出强大的泛化能力。

Conclusion: CDU框架成功地将对偶上升算法展开为可学习的神经网络架构，实现了约束优化问题的快速求解，同时保持了传统算法的理论保证，并在实际应用中展示了优秀的泛化性能。

Abstract: In this paper, we develop unrolled neural networks to solve constrained optimization problems, offering accelerated, learnable counterparts to dual ascent (DA) algorithms. Our framework, termed constrained dual unrolling (CDU), comprises two coupled neural networks that jointly approximate the saddle point of the Lagrangian. The primal network emulates an iterative optimizer that finds a stationary point of the Lagrangian for a given dual multiplier, sampled from an unknown distribution. The dual network generates trajectories towards the optimal multipliers across its layers while querying the primal network at each layer. Departing from standard unrolling, we induce DA dynamics by imposing primal-descent and dual-ascent constraints through constrained learning. We formulate training the two networks as a nested optimization problem and propose an alternating procedure that updates the primal and dual networks in turn, mitigating uncertainty in the multiplier distribution required for primal network training. We numerically evaluate the framework on mixed-integer quadratic programs (MIQPs) and power allocation in wireless networks. In both cases, our approach yields near-optimal near-feasible solutions and exhibits strong out-of-distribution (OOD) generalization.

</details>


### [577] [Decentralized Multi-Agent Swarms for Autonomous Grid Security in Industrial IoT: A Consensus-based Approach](https://arxiv.org/abs/2601.17303)
*Samaresh Kumar Singh,Joyjit Roy*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出了一种去中心化多智能体群（DMAS）架构，用于工业物联网（IIoT）安全监控，通过边缘AI代理实现分布式数字免疫系统，显著降低延迟并提高威胁检测准确性。


<details>
  <summary>Details</summary>
Motivation: 工业物联网环境中设备数量激增，传统集中式安全监控架构存在严重延迟问题，攻击者可利用此漏洞破坏整个制造生态系统。需要一种低延迟、分布式的安全解决方案。

Method: 设计去中心化多智能体群（DMAS）架构，在每个边缘网关上部署自主AI代理，通过轻量级P2P协议协作检测异常行为，无需将数据发送到云端。采用基于共识的威胁验证（CVT）流程，代理对识别威胁的威胁级别进行投票，实现即时隔离。

Result: 在模拟2000个IIoT设备的创新工厂环境中测试，DMAS表现出亚毫秒级响应时间（平均0.85ms），高负载下恶意活动检测准确率达97.3%，零日攻击检测准确率达87%。相比云解决方案减少89%网络带宽使用，并能防止实时级联故障。

Conclusion: DMAS架构为IIoT网络提供了一种有效的分布式数字免疫系统，显著优于传统的集中式和边缘计算方法，在延迟、准确性和带宽效率方面均有显著提升。

Abstract: As Industrial Internet of Things (IIoT) environments expand to include tens of thousands of connected devices. The centralization of security monitoring architectures creates serious latency issues that savvy attackers can exploit to compromise an entire manufacturing ecosystem. This paper outlines a new, decentralized multi-agent swarm (DMAS) architecture that includes autonomous artificial intelligence (AI) agents at each edge gateway, functioning as a distributed digital "immune system" for IIoT networks. Instead of using a traditional static firewall approach, the DMAS agents communicate via a lightweight peer-to-peer protocol to cooperatively detect anomalous behavior across the IIoT network without sending data to a cloud infrastructure. The authors also outline a consensus-based threat validation (CVT) process in which agents vote on the threat level of an identified threat, enabling instant quarantine of a compromised node or nodes. The authors conducted experiments on a testbed that simulated an innovative factory environment with 2000 IIoT devices and found that the DMAS demonstrated sub-millisecond response times (average of 0.85ms), 97.3% accuracy in detecting malicious activity under high load, and 87% accuracy in detecting zero-day attacks. All significantly higher than baseline values for both centralized and edge computing. Additionally, the proposed architecture can prevent real-time cascading failures in industrial control systems and reduce network bandwidth use by 89% compared to cloud-based solutions.

</details>


### [578] [PAR: Plausibility-aware Amortized Recourse Generation](https://arxiv.org/abs/2601.17309)
*Anagha Sabu,Vidhya S,Narayanan C Krishnan*

Main category: cs.LG

Relevance: 35.0

TL;DR: PAR：一种基于摊销近似推理的算法追索方法，通过约束最大后验推断生成高似然、现实可行的反事实解释


<details>
  <summary>Details</summary>
Motivation: 现有算法追索方法在生成现实可行且高似然的反事实解释方面存在不足，需要更高效、更可靠的方法来生成既满足约束条件又具有高概率的追索建议

Method: 将追索问题形式化为约束最大后验推断问题，提出摊销近似推理方法PAR，使用可处理概率模型直接估计追索似然，通过最大化接受类分布似然、最小化拒绝类分布似然以及编码追索约束的损失函数来训练追索生成器

Result: PAR在广泛使用的算法追索数据集上验证有效，能够高效生成有效、与事实相似、稀疏且高度合理的追索建议，性能优于现有最先进方法

Conclusion: PAR方法通过概率建模和摊销推理，能够高效生成高质量、高似然的算法追索，为机器学习模型的可解释性和公平性提供了有效工具

Abstract: Algorithmic recourse aims to recommend actionable changes to a factual's attributes that flip an unfavorable model decision while remaining realistic and feasible. We formulate recourse as a Constrained Maximum A-Posteriori (MAP) inference problem under the accepted-class data distribution seeking counterfactuals with high likelihood while respecting other recourse constraints. We present PAR, an amortized approximate inference procedure that generates highly likely recourses efficiently. Recourse likelihood is estimated directly using tractable probabilistic models that admit exact likelihood evaluation and efficient gradient propagation that is useful during training. The recourse generator is trained with the objective of maximizing the likelihood under the accepted-class distribution while minimizing the likelihood under the denied-class distribution and other losses that encode recourse constraints. Furthermore, PAR includes a neighborhood-based conditioning mechanism to promote recourse generation that is customized to a factual. We validate PAR on widely used algorithmic recourse datasets and demonstrate its efficiency in generating recourses that are valid, similar to the factual, sparse, and highly plausible, yielding superior performance over existing state-of-the-art approaches.

</details>


### [579] [GO-OSC and VASH: Geometry-Aware Representation Learning for Early Degradation Detection in Oscillatory Systems](https://arxiv.org/abs/2601.17396)
*Vashista Nobaub*

Main category: cs.LG

Relevance: 35.0

TL;DR: GO-OSC：一种用于振荡时间序列的几何感知表示学习框架，通过强制规范化和可识别的潜在参数化，实现早期退化检测，解决了传统能量基方法在几何畸变阶段检测不敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 振荡系统的早期退化通常表现为动力学的几何畸变（如相位抖动、频率漂移或相干性损失），这些变化在信号能量变化可检测之前就已发生。传统的能量基诊断方法和无约束学习表示在结构上对这些几何变化不敏感，导致检测延迟或不稳定。

Method: 提出GO-OSC框架：1）通过强制规范化和可识别的潜在参数化来学习振荡时间序列的几何感知表示；2）定义一族不变线性几何探针，针对潜在空间中与退化相关的方向；3）提供理论分析，证明在早期仅相位退化情况下，能量基统计量的检测能力为零阶，而几何探针具有严格正灵敏度。

Result: 理论分析表明，在非可识别表示下线性探针会失效，而规范化恢复了统计可检测性。在合成基准和真实振动数据集上的实验验证了该理论，展示了更早的检测、改进的数据效率以及对运行条件变化的鲁棒性。

Conclusion: GO-OSC框架通过几何感知表示学习和规范化参数化，解决了振荡系统早期退化检测的关键挑战，提供了比传统能量基方法更敏感、更稳定的检测能力。

Abstract: Early-stage degradation in oscillatory systems often manifests as geometric distortions of the dynamics, such as phase jitter, frequency drift, or loss of coherence, long before changes in signal energy are detectable. In this regime, classical energy-based diagnostics and unconstrained learned representations are structurally insensitive, leading to delayed or unstable detection. We introduce GO-OSC, a geometry-aware representation learning framework for oscillatory time series that enforces a canonical and identifiable latent parameterization, enabling stable comparison and aggregation across short, unlabeled windows. Building on this representation, we define a family of invariant linear geometric probes that target degradation-relevant directions in latent space. We provide theoretical results showing that under early phase-only degradation, energy-based statistics have zero first-order detection power, whereas geometric probes achieve strictly positive sensitivity. Our analysis characterizes when and why linear probing fails under non-identifiable representations and shows how canonicalization restores statistical detectability. Experiments on synthetic benchmarks and real vibration datasets validate the theory, demonstrating earlier detection, improved data efficiency, and robustness to operating condition changes.

</details>


### [580] [Efficient Dilated Squeeze and Excitation Neural Operator for Differential Equations](https://arxiv.org/abs/2601.17407)
*Prajwal Chauhan,Salah Eddine Choutri,Saif Eddin Jabari*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出D-SENO（扩张挤压激励神经算子），一种轻量级算子学习框架，用于高效求解多种偏微分方程，相比基于Transformer的模型和神经算子，训练速度提升约20倍，同时保持或超越其精度。


<details>
  <summary>Details</summary>
Motivation: 物理驱动的偏微分方程快速准确代理模型在空气动力学、多孔介质设计等领域至关重要。现有基于Transformer的模型和神经算子参数量大，导致训练成本高、部署缓慢，需要更轻量高效的解决方案。

Method: 结合扩张卷积（DC）块和挤压激励（SE）模块：扩张卷积捕获宽感受野和长程物理依赖，挤压激励模块通过通道注意力自适应重新校准特征通道，强调动态相关尺度。精心选择的扩张率使感受野聚焦关键区域。

Result: 在机翼势流、多孔介质达西流、管道泊肃叶流、不可压缩纳维-斯托克斯涡场等多个PDE基准测试中，训练速度比标准Transformer模型和神经算子快约20倍，同时精度达到或超过这些模型。消融研究表明移除SE模块会导致性能轻微下降。

Conclusion: D-SENO提供了一种轻量高效的算子学习框架，能够快速准确地求解多种偏微分方程，在训练速度和精度方面均优于现有方法，为物理驱动PDE的快速代理建模提供了有效解决方案。

Abstract: Fast and accurate surrogates for physics-driven partial differential equations (PDEs) are essential in fields such as aerodynamics, porous media design, and flow control. However, many transformer-based models and existing neural operators remain parameter-heavy, resulting in costly training and sluggish deployment. We propose D-SENO (Dilated Squeeze-Excitation Neural Operator), a lightweight operator learning framework for efficiently solving a wide range of PDEs, including airfoil potential flow, Darcy flow in porous media, pipe Poiseuille flow, and incompressible Navier Stokes vortical fields. D-SENO combines dilated convolution (DC) blocks with squeeze-and-excitation (SE) modules to jointly capture wide receptive fields and dynamics alongside channel-wise attention, enabling both accurate and efficient PDE inference. Carefully chosen dilation rates allow the receptive field to focus on critical regions, effectively modeling long-range physical dependencies. Meanwhile, the SE modules adaptively recalibrate feature channels to emphasize dynamically relevant scales. Our model achieves training speed of up to approximately $20\times$ faster than standard transformer-based models and neural operators, while also surpassing (or matching) them in accuracy across multiple PDE benchmarks. Ablation studies show that removing the SE modules leads to a slight drop in performance.

</details>


### [581] [Identifying and Correcting Label Noise for Robust GNNs via Influence Contradiction](https://arxiv.org/abs/2601.17469)
*Wei Ju,Wei Zhang,Siyu Yi,Zhengyang Mao,Yifan Wang,Jingyang Yuan,Zhiping Xiao,Ziyue Qiao,Ming Zhang*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出ICGNN方法，利用图结构信息处理图数据中的标签噪声问题，通过影响矛盾评分检测噪声标签，结合高斯混合模型精确识别，并采用软策略修正噪声标签


<details>
  <summary>Details</summary>
Motivation: 现实场景中图数据常存在标签噪声（标注错误或不一致），这会严重影响图神经网络（GNNs）的性能和鲁棒性，需要有效方法来处理图结构数据中的噪声标签问题

Method: 1) 设计基于图扩散矩阵的影响矛盾评分（ICS）作为噪声指示器；2) 使用高斯混合模型精确检测节点标签是否为噪声；3) 采用软策略结合邻居节点预测来修正检测到的噪声标签；4) 引入未标记节点的伪标签提供辅助监督信号

Result: 在基准数据集上的实验表明，该方法在处理图数据标签噪声方面具有优越性

Conclusion: ICGNN通过有效利用图结构信息，能够鲁棒地处理图数据中的标签噪声问题，提高GNNs在噪声环境下的性能

Abstract: Graph Neural Networks (GNNs) have shown remarkable capabilities in learning from graph-structured data with various applications such as social analysis and bioinformatics. However, the presence of label noise in real scenarios poses a significant challenge in learning robust GNNs, and their effectiveness can be severely impacted when dealing with noisy labels on graphs, often stemming from annotation errors or inconsistencies. To address this, in this paper we propose a novel approach called ICGNN that harnesses the structure information of the graph to effectively alleviate the challenges posed by noisy labels. Specifically, we first design a novel noise indicator that measures the influence contradiction score (ICS) based on the graph diffusion matrix to quantify the credibility of nodes with clean labels, such that nodes with higher ICS values are more likely to be detected as having noisy labels. Then we leverage the Gaussian mixture model to precisely detect whether the label of a node is noisy or not. Additionally, we develop a soft strategy to combine the predictions from neighboring nodes on the graph to correct the detected noisy labels. At last, pseudo-labeling for abundant unlabeled nodes is incorporated to provide auxiliary supervision signals and guide the model optimization. Experiments on benchmark datasets show the superiority of our proposed approach.

</details>


### [582] [One-Shot Federated Clustering of Non-Independent Completely Distributed Data](https://arxiv.org/abs/2601.17512)
*Yiqun Zhang,Shenghong Cai,Zihua Yang,Sen Feng,Yuzhu Ji,Haijun Zhang*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出GOLD框架解决联邦聚类中的Non-IID问题，通过全局导向的局部分布学习提升聚类性能


<details>
  <summary>Details</summary>
Motivation: 联邦聚类在无标签分布式数据中面临Non-IID挑战，现有方法因不同客户端可能分割同一聚类而性能受限，需要新的解决方案

Method: 提出GOLD框架：1) 精细探索客户端潜在不完整局部聚类分布；2) 上传分布摘要到服务器进行全局融合；3) 在全局分布指导下进行局部聚类增强

Result: 通过显著性检验、消融研究、可扩展性评估等实验验证了GOLD的优越性

Conclusion: GOLD框架有效解决了联邦聚类中的Non-ICD问题，提升了分布式隐私保护系统中的模式知识探索能力

Abstract: Federated Learning (FL) that extracts data knowledge while protecting the privacy of multiple clients has achieved remarkable results in distributed privacy-preserving IoT systems, including smart traffic flow monitoring, smart grid load balancing, and so on. Since most data collected from edge devices are unlabeled, unsupervised Federated Clustering (FC) is becoming increasingly popular for exploring pattern knowledge from complex distributed data. However, due to the lack of label guidance, the common Non-Independent and Identically Distributed (Non-IID) issue of clients have greatly challenged FC by posing the following problems: How to fuse pattern knowledge (i.e., cluster distribution) from Non-IID clients; How are the cluster distributions among clients related; and How does this relationship connect with the global knowledge fusion? In this paper, a more tricky but overlooked phenomenon in Non-IID is revealed, which bottlenecks the clustering performance of the existing FC approaches. That is, different clients could fragment a cluster, and accordingly, a more generalized Non-IID concept, i.e., Non-ICD (Non-Independent Completely Distributed), is derived. To tackle the above FC challenges, a new framework named GOLD (Global Oriented Local Distribution Learning) is proposed. GOLD first finely explores the potential incomplete local cluster distributions of clients, then uploads the distribution summarization to the server for global fusion, and finally performs local cluster enhancement under the guidance of the global distribution. Extensive experiments, including significance tests, ablation studies, scalability evaluations, qualitative results, etc., have been conducted to show the superiority of GOLD.

</details>


### [583] [Towards Generalisable Imitation Learning Through Conditioned Transition Estimation and Online Behaviour Alignment](https://arxiv.org/abs/2601.17563)
*Nathan Gavenski,Matteo Leonetti,Odinaldo Rodrigues*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出无监督模仿学习观察方法(UfO)，通过两阶段学习过程解决现有ILfO方法需要动作监督、假设状态有单一最优动作、不考虑环境状态等限制，在五个环境中超越教师和其他方法


<details>
  <summary>Details</summary>
Motivation: 现有观察模仿学习方法(ILfO)存在三个主要限制：1)需要基于动作的监督优化；2)假设状态有单一最优动作；3)倾向于直接应用教师动作而不充分考虑实际环境状态。虽然真实信息存在于观察到的轨迹中，但现有方法难以在无监督情况下提取这些信息。

Method: 提出无监督模仿学习观察(UfO)方法，采用两阶段学习过程：第一阶段通过观察状态转移获得教师真实动作的近似；第二阶段通过调整智能体轨迹使其与教师轨迹紧密对齐来进一步优化学习策略。

Result: 在五个广泛使用的环境中进行的实验表明，UfO不仅超越了教师和所有其他ILfO方法，而且显示出最小的标准差。标准差的减少表明在未见场景中具有更好的泛化能力。

Conclusion: UfO成功解决了现有ILfO方法的三个主要限制，实现了无监督的模仿学习，在性能和泛化能力方面均表现出色，为从观察中学习提供了更有效的方法。

Abstract: State-of-the-art imitation learning from observation methods (ILfO) have recently made significant progress, but they still have some limitations: they need action-based supervised optimisation, assume that states have a single optimal action, and tend to apply teacher actions without full consideration of the actual environment state. While the truth may be out there in observed trajectories, existing methods struggle to extract it without supervision. In this work, we propose Unsupervised Imitation Learning from Observation (UfO) that addresses all of these limitations. UfO learns a policy through a two-stage process, in which the agent first obtains an approximation of the teacher's true actions in the observed state transitions, and then refines the learned policy further by adjusting agent trajectories to closely align them with the teacher's. Experiments we conducted in five widely used environments show that UfO not only outperforms the teacher and all other ILfO methods but also displays the smallest standard deviation. This reduction in standard deviation indicates better generalisation in unseen scenarios.

</details>


### [584] [A Thermodynamic Theory of Learning I: Irreversible Ensemble Transport and Epistemic Costs](https://arxiv.org/abs/2601.17607)
*Daisuke Okanohara*

Main category: cs.LG

Relevance: 35.0

TL;DR: 论文提出学习是一个不可逆过程，需要熵产生才能实现认知结构。作者引入认知自由能框架，定义自由能下降作为学习轨迹上的记账量，并推导出认知速度极限(ESL)——一个有限时间不等式，为任何学习过程实现给定分布变换所需的最小熵产生提供下界。


<details>
  <summary>Details</summary>
Motivation: 学习系统从数据中获得结构化内部表示，但经典信息论结果表明确定性变换不会增加信息。这引发了一个基本问题：学习如何在不超过信息论限制的情况下产生抽象和洞察？作者认为学习在有限时间内本质上是不可逆过程，认知结构的实现必然伴随熵产生。

Method: 将学习建模为模型配置概率分布空间中的传输过程，引入认知自由能框架。定义自由能下降作为学习轨迹上的记账量，将其分解为与潜在改进相关的可逆分量和与熵产生对应的不可逆分量。推导出认知速度极限(ESL)——一个有限时间不等式，为任何学习过程实现给定分布变换所需的最小熵产生提供下界。

Result: 认知速度极限(ESL)表明，任何学习过程实现给定分布变换所需的最小熵产生下界仅取决于初始和最终集合分布之间的Wasserstein距离，且与具体学习算法无关。这为学习过程的基本限制提供了理论框架。

Conclusion: 学习是一个不可逆的熵产生过程，认知结构的实现需要付出热力学代价。认知速度极限为学习过程的基本限制提供了理论框架，将学习与热力学不可逆性联系起来，为理解学习的本质提供了新视角。

Abstract: Learning systems acquire structured internal representations from data, yet classical information-theoretic results state that deterministic transformations do not increase information. This raises a fundamental question: how can learning produce abstraction and insight without violating information-theoretic limits?
  We argue that learning is inherently an irreversible process when performed over finite time, and that the realization of epistemic structure necessarily incurs entropy production. To formalize this perspective, we model learning as a transport process in the space of probability distributions over model configurations and introduce an epistemic free-energy framework.
  Within this framework, we define the free-energy drop as a bookkeeping quantity that records the total reduction of epistemic free energy along a learning trajectory. This reduction decomposes into a reversible component associated with potential improvement and an irreversible component corresponding to entropy production.
  We then derive the Epistemic Speed Limit (ESL), a finite-time inequality that lower-bounds the minimal entropy production required by any learning process to realize a given distributional transformation. This bound depends only on the Wasserstein distance between initial and final ensemble distributions and is independent of the specific learning algorithm.

</details>


### [585] [REV-INR: Regularized Evidential Implicit Neural Representation for Uncertainty-Aware Volume Visualization](https://arxiv.org/abs/2601.17689)
*Shanu Saklani,Tushar M. Athawale,Nairita Pal,David Pugmire,Christopher R. Johnson,Soumya Dutta*

Main category: cs.LG

Relevance: 35.0

TL;DR: REV-INR提出了一种正则化证据隐式神经表示方法，能够同时预测数据值、数据不确定性和模型不确定性，用于提高体积数据重建的可靠性和可信度。


<details>
  <summary>Details</summary>
Motivation: 传统确定性隐式神经表示(INRs)只能预测数值，无法提供预测不确定性信息，导致数据解释和可视化不可靠。当原始数据因体积过大而不可用时，难以识别模型预测中的错误结果。

Method: 提出REV-INR（正则化证据隐式神经表示），通过单次前向传播同时学习准确预测数据值、坐标级数据不确定性（偶然不确定性）和模型不确定性（认知不确定性）。

Result: REV-INR在体积重建质量上表现最佳，能够提供鲁棒的数据和模型不确定性估计，且推理时间最快。能够评估提取的等值面和体积可视化结果的可靠性。

Conclusion: REV-INR能够促进对模型预测数据可靠性和可信度的评估，使得分析可以完全基于模型预测数据驱动，解决了传统INRs缺乏不确定性估计的问题。

Abstract: Applications of Implicit Neural Representations (INRs) have emerged as a promising deep learning approach for compactly representing large volumetric datasets. These models can act as surrogates for volume data, enabling efficient storage and on-demand reconstruction via model predictions. However, conventional deterministic INRs only provide value predictions without insights into the model's prediction uncertainty or the impact of inherent noisiness in the data. This limitation can lead to unreliable data interpretation and visualization due to prediction inaccuracies in the reconstructed volume. Identifying erroneous results extracted from model-predicted data may be infeasible, as raw data may be unavailable due to its large size. To address this challenge, we introduce REV-INR, Regularized Evidential Implicit Neural Representation, which learns to predict data values accurately along with the associated coordinate-level data uncertainty and model uncertainty using only a single forward pass of the trained REV-INR during inference. By comprehensively comparing and contrasting REV-INR with existing well-established deep uncertainty estimation methods, we show that REV-INR achieves the best volume reconstruction quality with robust data (aleatoric) and model (epistemic) uncertainty estimates using the fastest inference time. Consequently, we demonstrate that REV-INR facilitates assessment of the reliability and trustworthiness of the extracted isosurfaces and volume visualization results, enabling analyses to be solely driven by model-predicted data.

</details>


### [586] [EEG Foundation Models: Progresses, Benchmarking, and Open Problems](https://arxiv.org/abs/2601.17883)
*Dingkun Liu,Yuheng Chen,Zhu Chen,Zhenyao Cui,Yaozhi Wen,Jiayu An,Jingwei Luo,Dongrui Wu*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文对EEG基础模型进行了系统性评估，比较了12个开源模型在13个EEG数据集上的表现，发现线性探测通常不足、专用模型仍具竞争力、更大模型不一定带来更好泛化性能。


<details>
  <summary>Details</summary>
Motivation: EEG基础模型在脑机接口领域发展迅速，但缺乏公平全面的比较，因为存在预训练目标、预处理选择和下游评估协议不一致的问题。本文旨在填补这一空白。

Method: 首先回顾50个代表性模型并构建统一分类框架，然后评估12个开源基础模型和竞争性专用基线在13个EEG数据集上，涵盖9种BCI范式。考虑跨被试泛化和少样本校准，比较全参数微调与线性探测，并分析模型规模与下游性能的关系。

Result: 研究结果表明：1）线性探测通常不足；2）从头训练的专用模型在许多任务上仍具竞争力；3）在当前数据规模和训练实践下，更大的基础模型不一定带来更好的泛化性能。

Conclusion: EEG基础模型领域需要更系统化的评估框架，当前模型在泛化能力方面仍有改进空间，模型规模扩大不一定带来性能提升，需要更有效的训练策略。

Abstract: Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.

</details>


### [587] [FedGraph-VASP: Privacy-Preserving Federated Graph Learning with Post-Quantum Security for Cross-Institutional Anti-Money Laundering](https://arxiv.org/abs/2601.17935)
*Daniel Commey,Matilda Nkoom,Yousef Alsenani,Sena G. Hounsinou,Garth V. Crosby*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出FedGraph-VASP框架，通过边界嵌入交换协议实现隐私保护的联邦图学习，用于跨机构反洗钱检测，在比特币数据集上F1分数达0.508，优于现有方法FedSage+。


<details>
  <summary>Details</summary>
Motivation: 虚拟资产服务提供商面临监管合规与用户隐私的冲突，现有方法要么需要共享敏感交易数据，要么孤立运行导致跨链洗钱模式无法检测。

Method: 提出隐私保护的联邦图学习框架FedGraph-VASP，核心是边界嵌入交换协议，仅共享压缩、不可逆的图神经网络边界账户表示，使用后量子密码学（Kyber-512和AES-256-GCM）保护。

Result: 在Elliptic比特币数据集上F1分数0.508，优于FedSage+的0.453（提升12.1%）；在低连接性场景下表现稳健，高连接性时接近集中式性能（F1=0.620）；在以太坊数据集上表现因拓扑结构而异。

Conclusion: FedGraph-VASP在连接性强的交易图中表现优异，而生成式插补在高度模块化的稀疏图中更有效，揭示了拓扑依赖的权衡；隐私审计显示嵌入仅部分可逆（R^2=0.32），限制了特征恢复。

Abstract: Virtual Asset Service Providers (VASPs) face a fundamental tension between regulatory compliance and user privacy when detecting cross-institutional money laundering. Current approaches require either sharing sensitive transaction data or operating in isolation, leaving critical cross-chain laundering patterns undetected. We present FedGraph-VASP, a privacy-preserving federated graph learning framework that enables collaborative anti-money laundering (AML) without exposing raw user data. Our key contribution is a Boundary Embedding Exchange protocol that shares only compressed, non-invertible graph neural network representations of boundary accounts. These exchanges are secured using post-quantum cryptography, specifically the NIST-standardized Kyber-512 key encapsulation mechanism combined with AES-256-GCM authenticated encryption. Experiments on the Elliptic Bitcoin dataset with realistic Louvain partitioning show that FedGraph-VASP achieves an F1-score of 0.508, outperforming the state-of-the-art generative baseline FedSage+ (F1 = 0.453) by 12.1 percent on binary fraud detection. We further show robustness under low-connectivity settings where generative imputation degrades performance, while approaching centralized performance (F1 = 0.620) in high-connectivity regimes. We additionally evaluate generalization on an Ethereum fraud detection dataset, where FedGraph-VASP (F1 = 0.635) is less effective under sparse cross-silo connectivity, while FedSage+ excels (F1 = 0.855), outperforming even local training (F1 = 0.785). These results highlight a topology-dependent trade-off: embedding exchange benefits connected transaction graphs, whereas generative imputation can dominate in highly modular sparse graphs. A privacy audit shows embeddings are only partially invertible (R^2 = 0.32), limiting exact feature recovery.

</details>


### [588] [Multimodal Machine Learning for Soft High-k Elastomers under Data Scarcity](https://arxiv.org/abs/2601.18032)
*Brijesh FNU,Viet Thanh Duy Nguyen,Ashima Sharma,Md Harun Rashid Molla,Chengyi Xu,Truong-Son Hy*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出了一种多模态学习框架，利用预训练的图基和序列基编码器从大规模聚合物语料库中迁移化学和结构知识，用于预测丙烯酸酯基介电弹性体的介电和机械性能，以解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 随着软性和可拉伸电子学的快速发展，对高性能介电弹性体的需求激增。然而，同时具备高介电常数和低杨氏模量的软弹性体开发面临重大挑战，且缺乏系统涵盖分子序列、介电和机械性能的结构化数据集。

Method: 1. 整理了过去10年文献中的丙烯酸酯基介电弹性体高质量数据集；2. 提出多模态学习框架，利用图基和序列基编码器的大规模预训练聚合物表示；3. 通过迁移学习实现从分子序列准确预测介电和机械性能的小样本学习。

Result: 该框架能够准确预测介电弹性体的介电和机械性能，为从预训练多模态模型迁移知识以克服数据稀缺问题提供了新范式，可推广到其他聚合物骨架（如硅酮、聚氨酯）。

Conclusion: 该研究展示了利用预训练多模态模型迁移知识解决数据稀缺问题的有效性，可加速软性高介电常数弹性体的数据高效发现，代码和数据集已公开。

Abstract: Dielectric materials are critical building blocks for modern electronics such as sensors, actuators, and transistors. With the rapid recent advance in soft and stretchable electronics for emerging human- and robot-interfacing applications, there is a surging need for high-performance dielectric elastomers. However, it remains a grand challenge to develop soft elastomers that simultaneously possess high dielectric constants (k, related to energy storage capacity) and low Young's moduli (E, related to mechanical flexibility). While some new elastomer designs have been reported in individual (mostly one-off) studies, almost no structured dataset is currently available for dielectric elastomers that systematically encompasses their molecular sequence, dielectric, and mechanical properties. Within this context, we curate a compact, high-quality dataset of acrylate-based dielectric elastomers, one of the most widely explored elastomer backbones due to its versatile chemistry and molecular design flexibility, by screening and aggregating experimental results from the literature over the past 10 years. Building on this dataset, we propose a multimodal learning framework that leverages large-scale pretrained polymer representations from graph- and sequence-based encoders. These pretrained embeddings transfer rich chemical and structural knowledge from vast polymer corpora, enabling accurate few-shot prediction of both dielectric and mechanical properties from molecular sequences. Our results represent a new paradigm for transferring knowledge from pretrained multimodal models to overcome severe data scarcity, which can be readily translated to other polymer backbones (e.g., silicones, urethanes) and thus accelerate data-efficient discovery of soft high-k dielectric elastomers. Our source code and dataset are publicly available at https://github.com/HySonLab/Polymers

</details>


### [589] [Learning Fair Domain Adaptation with Virtual Label Distribution](https://arxiv.org/abs/2601.18171)
*Yuguang Zhang,Lijun Sheng,Jian Liang,Ran He*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出VILL框架解决无监督域自适应中的类别公平性问题，通过自适应重加权和KL散度再平衡策略提升困难类别的性能，同时保持高整体准确率。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域自适应方法主要关注整体准确率提升，但忽视了不同类别间的性能差异（类别公平性问题）。研究发现UDA分类器倾向于偏好容易类别而忽视困难类别，导致性能不均衡。

Method: 提出VILL框架：1）自适应重加权策略，放大难以分类类别的影响；2）基于KL散度的再平衡策略，显式调整决策边界以增强类别公平性。该框架可作为即插即用模块集成到现有UDA方法中。

Result: 在常用数据集上的实验表明，VILL能够显著提升类别公平性，改善最差情况性能，同时保持高整体准确率。

Conclusion: VILL框架有效解决了UDA中的类别公平性问题，通过自适应重加权和决策边界调整策略，平衡了不同类别的性能表现，为UDA研究提供了新的公平性视角。

Abstract: Unsupervised Domain Adaptation (UDA) aims to mitigate performance degradation when training and testing data are sampled from different distributions. While significant progress has been made in enhancing overall accuracy, most existing methods overlook performance disparities across categories-an issue we refer to as category fairness. Our empirical analysis reveals that UDA classifiers tend to favor certain easy categories while neglecting difficult ones. To address this, we propose Virtual Label-distribution-aware Learning (VILL), a simple yet effective framework designed to improve worst-case performance while preserving high overall accuracy. The core of VILL is an adaptive re-weighting strategy that amplifies the influence of hard-to-classify categories. Furthermore, we introduce a KL-divergence-based re-balancing strategy, which explicitly adjusts decision boundaries to enhance category fairness. Experiments on commonly used datasets demonstrate that VILL can be seamlessly integrated as a plug-and-play module into existing UDA methods, significantly improving category fairness.

</details>


### [590] [HeterCSI: Channel-Adaptive Heterogeneous CSI Pretraining Framework for Generalized Wireless Foundation Models](https://arxiv.org/abs/2601.18200)
*Chenyu Zhang,Xinchen Lyu,Chenshan Ren,Shuhan Liu,Qimei Cui,Xiaofeng Tao*

Main category: cs.LG

Relevance: 35.0

TL;DR: HeterCSI是一个用于无线信道状态信息处理的通道自适应预训练框架，通过解决CSI在尺度和场景维度上的双重异质性，实现了训练效率与跨场景泛化能力的平衡。


<details>
  <summary>Details</summary>
Motivation: 无线基础模型在处理6G网络中的信道状态信息时面临根本性挑战，因为CSI在尺度和场景维度上存在固有的双重异质性。当前的预训练方法要么将输入限制在固定维度，要么按尺度隔离训练，这限制了无线基础模型的泛化能力和可扩展性。

Method: 提出HeterCSI框架，核心洞察是：CSI尺度异质性主要导致破坏性梯度干扰，而场景多样性在适当管理下实际上促进建设性梯度对齐。具体方法包括：1) 将异构CSI批次构建公式化为分区优化问题，最小化零填充开销同时保持场景多样性；2) 开发尺度感知自适应批处理策略，对齐相似尺度的CSI样本；3) 设计双重掩码机制，从填充伪影中隔离有效信号。

Result: 在12个数据集上的实验表明，HeterCSI建立了无需场景特定微调的通用基础模型，在CSI重建、时域预测和频域预测任务上，相比最先进的零基准WiFo分别降低了7.19 dB、4.08 dB和5.27 dB的NMSE。同时训练延迟降低了53%，平均泛化性能提高了1.53 dB。

Conclusion: HeterCSI成功解决了无线基础模型在CSI处理中的双重异质性挑战，通过创新的梯度动态理解和自适应批处理策略，实现了训练效率与跨场景泛化能力的显著提升，为6G网络应用提供了强大的无线基础模型框架。

Abstract: Wireless foundation models promise transformative capabilities for channel state information (CSI) processing across diverse 6G network applications, yet face fundamental challenges due to the inherent dual heterogeneity of CSI across both scale and scenario dimensions. However, current pretraining approaches either constrain inputs to fixed dimensions or isolate training by scale, limiting the generalization and scalability of wireless foundation models. In this paper, we propose HeterCSI, a channel-adaptive pretraining framework that reconciles training efficiency with robust cross-scenario generalization via a new understanding of gradient dynamics in heterogeneous CSI pretraining. Our key insight reveals that CSI scale heterogeneity primarily causes destructive gradient interference, while scenario diversity actually promotes constructive gradient alignment when properly managed. Specifically, we formulate heterogeneous CSI batch construction as a partitioning optimization problem that minimizes zero-padding overhead while preserving scenario diversity. To solve this, we develop a scale-aware adaptive batching strategy that aligns CSI samples of similar scales, and design a double-masking mechanism to isolate valid signals from padding artifacts. Extensive experiments on 12 datasets demonstrate that HeterCSI establishes a generalized foundation model without scenario-specific finetuning, achieving superior average performance over full-shot baselines. Compared to the state-of-the-art zero-shot benchmark WiFo, it reduces NMSE by 7.19 dB, 4.08 dB, and 5.27 dB for CSI reconstruction, time-domain, and frequency-domain prediction, respectively. The proposed HeterCSI framework also reduces training latency by 53% compared to existing approaches while improving generalization performance by 1.53 dB on average.

</details>


### [591] [Neural Network Approximation: A View from Polytope Decomposition](https://arxiv.org/abs/2601.18264)
*ZeYu Li,ShiJun Zhang,TieYong Zeng,FengLei Fan*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文从多面体分解的角度研究ReLU网络的通用逼近能力，提出了一种基于核多项式方法的显式构造，相比传统均匀划分方法能更高效地逼近目标函数，特别是在奇异点附近。


<details>
  <summary>Details</summary>
Motivation: 现有通用逼近理论大多通过均匀划分输入空间来构造神经网络，忽略了目标函数的局部正则性。作者希望从多面体分解的角度研究ReLU网络的逼近能力，提供更贴近实际任务需求的方法。

Method: 1) 开发显式核多项式方法推导连续函数的通用逼近，特征包括精细的Totik-Ditzian型连续性模和多面体域分解；2) 在每个子域中分别构造ReLU网络来逼近核多项式；3) 将方法扩展到解析函数以获得更高的逼近率。

Result: 多面体分解使逼近在许多情况下比现有方法更高效灵活，特别是在目标函数的奇异点附近。该方法能够处理具有局部正则性变化的函数，并扩展到解析函数获得更高的逼近率。

Conclusion: 从多面体分解角度研究ReLU网络的通用逼近能力提供了更现实和任务导向的方法，相比传统均匀划分方法在处理具有局部奇异性的函数时更具优势。

Abstract: Universal approximation theory offers a foundational framework to verify neural network expressiveness, enabling principled utilization in real-world applications. However, most existing theoretical constructions are established by uniformly dividing the input space into tiny hypercubes without considering the local regularity of the target function. In this work, we investigate the universal approximation capabilities of ReLU networks from a view of polytope decomposition, which offers a more realistic and task-oriented approach compared to current methods. To achieve this, we develop an explicit kernel polynomial method to derive an universal approximation of continuous functions, which is characterized not only by the refined Totik-Ditzian-type modulus of continuity, but also by polytopical domain decomposition. Then, a ReLU network is constructed to approximate the kernel polynomial in each subdomain separately. Furthermore, we find that polytope decomposition makes our approximation more efficient and flexible than existing methods in many cases, especially near singular points of the objective function. Lastly, we extend our approach to analytic functions to reach a higher approximation rate.

</details>


### [592] [Frequency-Based Hyperparameter Selection in Games](https://arxiv.org/abs/2601.18409)
*Aniket Sanyal,Baraah A. M. Sidahmed,Rebekka Burkholz,Tatjana Chavdarova*

Main category: cs.LG

Relevance: 35.0

TL;DR: 论文提出Modal LookAhead (MoLA)，一种自适应选择超参数的LookAhead扩展方法，通过频率估计分析游戏中的振荡动态，加速训练过程。


<details>
  <summary>Details</summary>
Motivation: 平滑游戏中的学习与标准最小化问题有本质区别，因为旋转动态使经典超参数调优策略失效。尽管LookAhead在实践中表现良好，但它引入了影响性能的关键额外参数，而游戏中的有效调优方法仍然研究不足。

Method: 通过频率估计分析振荡动态，包括连续时间轨迹和离散动态频谱分析。基于此提出Modal LookAhead (MoLA)，自适应选择超参数以适应特定问题。

Result: MoLA在纯旋转游戏和混合机制中都能加速训练，计算开销最小，并提供收敛保证。

Conclusion: MoLA为游戏中的超参数选择提供了原则性方法，通过频率分析有效处理振荡动态，相比传统方法有显著改进。

Abstract: Learning in smooth games fundamentally differs from standard minimization due to rotational dynamics, which invalidate classical hyperparameter tuning strategies. Despite their practical importance, effective methods for tuning in games remain underexplored. A notable example is LookAhead (LA), which achieves strong empirical performance but introduces additional parameters that critically influence performance. We propose a principled approach to hyperparameter selection in games by leveraging frequency estimation of oscillatory dynamics. Specifically, we analyze oscillations both in continuous-time trajectories and through the spectrum of the discrete dynamics in the associated frequency-based space. Building on this analysis, we introduce \emph{Modal LookAhead (MoLA)}, an extension of LA that selects the hyperparameters adaptively to a given problem. We provide convergence guarantees and demonstrate in experiments that MoLA accelerates training in both purely rotational games and mixed regimes, all with minimal computational overhead.

</details>


### [593] [Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States](https://arxiv.org/abs/2601.18479)
*Kyoleen Kwak,Hyoseok Hwang*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出ASAP方法，通过定义转移诱导相似状态来平滑深度强化学习中的动作振荡，利用环境反馈和实际收集数据更好地捕捉系统动态。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在控制任务中表现出色，但其特有的高频动作振荡限制了在实际环境中的应用。现有方法通常依赖启发式或合成的状态相似性定义来促进动作一致性，但这些定义往往无法准确反映底层系统动态。

Method: 提出ASAP方法：1) 定义转移诱导相似状态作为从前一状态转移的下一个状态分布；2) 通过对齐转移诱导相似状态中的动作来强制动作平滑性；3) 惩罚二阶差异来抑制高频振荡。

Result: 在Gymnasium和Isaac-Lab环境中的实验表明，ASAP相比现有方法能产生更平滑的控制和更好的策略性能。

Conclusion: ASAP通过利用环境反馈和实际收集数据定义转移诱导相似状态，有效解决了深度强化学习中的动作振荡问题，为实际应用提供了更平滑的控制方案。

Abstract: Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods.

</details>


### [594] [Nearly Optimal Bayesian Inference for Structural Missingness](https://arxiv.org/abs/2601.18500)
*Chen Liang,Donghua Yang,Yutong Wang,Tianle Zhang,Shenghe Zhou,Zhiyu Liang,Hengtong Zhang,Hongzhi Wang,Ziqi Li,Xiyang Zhang,Zheng Liang,Yifei Li*

Main category: cs.LG

Relevance: 35.0

TL;DR: 该论文提出了一种贝叶斯框架来处理结构性缺失数据，通过后验预测分布进行预测，而非依赖单一插补值，从而解决因果循环、MNAR分布偏移和插补不确定性等问题。


<details>
  <summary>Details</summary>
Motivation: 结构性缺失数据存在三个核心问题：1) 因果循环困境（预测需要缺失特征，但推断它们又依赖于缺失机制）；2) MNAR情况下缺失部分可能来自分布偏移；3) 单一插补会锁定不确定性，导致过度自信和有偏决策。

Method: 提出贝叶斯框架，将学习过程解耦为两个步骤：1) 学习模型内缺失值的后验分布；2) 通过优化预测后验分布进行标签预测，实现后验积分。该方法基于SCM先验，支持不确定性传播。

Result: 在43个分类基准和15个插补基准上达到SOTA性能，并在有限样本下获得接近贝叶斯最优性的理论保证。

Conclusion: 贝叶斯后验预测框架有效解决了结构性缺失数据的核心挑战，实现了"几乎免费午餐"的效果：一旦学习到后验分布，预测即可即插即用，同时保持不确定性传播。

Abstract: Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.

</details>


### [595] [Scalable Transit Delay Prediction at City Scale: A Systematic Approach with Multi-Resolution Feature Engineering and Deep Learning](https://arxiv.org/abs/2601.18521)
*Emna Boudabbous,Mohamed Karaa,Lokman Sboui,Julio Montecinos,Omar Alam*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出一个城市级公交延误预测框架，通过多分辨率特征工程、降维和深度学习，在蒙特利尔公交网络上实现实时、可扩展的延误预测。


<details>
  <summary>Details</summary>
Motivation: 城市公交机构需要可靠的网络级延误预测来为乘客提供准确到站信息并支持实时运营控制。现有系统大多只处理少数路线，依赖手工特征，缺乏可扩展、可复用的架构指导。

Method: 1) 多分辨率特征工程：通过H3网格、路线、路段和时间模式生成1683个时空特征；2) 自适应PCA降维到83个组件；3) 混合H3+拓扑聚类解决"巨型集群"问题；4) 比较五种模型架构，采用全局LSTM+集群感知特征。

Result: 全局LSTM模型在准确性和效率间取得最佳平衡，比Transformer模型性能提升18-52%，参数减少275倍。在蒙特利尔公交网络6个月数据上验证，适合实时城市级部署。

Conclusion: 提出的管道适用于实时城市级部署，可复用于其他网络且只需有限适配。解决了现有系统的可扩展性问题，为公交延误预测提供了系统化框架。

Abstract: Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture.
  We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the "giant cluster" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training.
  We compare five model architectures on six months of bus operations from the Société de transport de Montréal (STM) network in Montréal. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation.

</details>


### [596] [From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale](https://arxiv.org/abs/2601.18524)
*Yongqi Jin,Yecheng Wang,Jun-jie Wang,Rong Zhu,Guolin Ke,Weinan E*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出了一种半监督框架，利用文献提取的数百万个未标记NMR谱图来学习化学位移预测，无需原子级标注，显著提升了预测准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有NMR化学位移预测方法依赖有限的人工标注数据集，标注成本高且数据规模受限。需要利用大量文献中可获取但未标注的谱图数据来提升模型性能。

Method: 将文献谱图化学位移预测建模为置换不变集合监督问题，在损失函数满足特定条件下，最优二分匹配简化为基于排序的损失，实现了稳定的大规模半监督训练。

Result: 模型在准确性和鲁棒性上显著超越现有方法，在更大更多样的分子数据集上表现出更强的泛化能力，首次大规模捕捉了常见NMR溶剂中的系统性溶剂效应。

Conclusion: 大规模未标记文献谱图可作为训练NMR位移模型的有效数据源，表明文献衍生的弱结构化数据在科学数据中心的AI中具有更广泛的应用潜力。

Abstract: Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.

</details>


### [597] [An Unsupervised Tensor-Based Domain Alignment](https://arxiv.org/abs/2601.18564)
*Chong Hyun Lee,Kibae Lee,Hyun Hee Yim*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出基于张量的域对齐算法，通过对齐矩阵在不变子空间中对齐源和目标张量，使用斜流形约束提供比传统Stiefel流形更大的灵活性，并保留源和目标张量方差的正则化项确保鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统张量域对齐方法通常使用Stiefel流形约束，限制了算法的灵活性和适应性。本文旨在开发更灵活的张量域对齐框架，能够更好地处理复杂域适应任务，同时提高转换速度和分类精度。

Method: 提出基于张量的域对齐算法，通过对齐矩阵在不变子空间中对齐源和目标张量。采用斜流形约束进行迭代优化，比传统Stiefel流形更灵活。引入保留源和目标张量方差的正则化项确保鲁棒性。该框架可泛化现有张量域对齐方法为特例。

Result: 实验表明，该方法不仅提高了域对齐转换速度，还显著提升了分类精度。在复杂域适应任务中优于当前最先进技术。

Conclusion: 提出的张量域对齐算法通过斜流形约束和方差保留正则化，提供了更灵活、鲁棒的域适应解决方案，在速度和精度上都优于现有方法。

Abstract: We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.

</details>


### [598] [Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning](https://arxiv.org/abs/2601.18586)
*Miguel Costa,Arthur Vandervoort,Carolin Schmidt,Morten W. Petersen,Martin Drews,Karyn Morrissey,Francisco C. Pereira*

Main category: cs.LG

Relevance: 35.0

TL;DR: 提出结合综合评估模型与强化学习的决策支持框架，用于学习城市交通基础设施在气候变化下的自适应多十年投资路径


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧降雨等灾害，对城市交通系统造成更大破坏。设计有效适应策略面临挑战：长期序列性基础设施投资、深度不确定性、复杂跨部门交互

Method: 提出通用决策支持框架，将综合评估模型与强化学习耦合，学习不确定性下的自适应多十年投资路径。框架整合长期气候预测、极端天气驱动到灾害概率的映射模型、灾害对基础设施影响的传播模型、服务性能和社会成本的评估模型

Result: 与哥本哈根市政府合作，应用于2024-2100年内城暴雨洪水案例。学习策略产生协调的时空路径，相比传统优化基准（不作为和随机行动）提高了鲁棒性

Conclusion: 该框架展示了向其他灾害和城市的可转移性，为城市气候适应提供强化学习支持决策的新方法

Abstract: Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.

</details>


### [599] [Physics-Informed Uncertainty Enables Reliable AI-driven Design](https://arxiv.org/abs/2601.18638)
*Tingkai Xue,Chin Chun Ooi,Yang Jiang,Luu Trung Pham Duong,Pao-Hsiung Chiu,Weijiang Zhao,Nagarajan Raghavan,My Ha Dao*

Main category: cs.LG

Relevance: 35.0

TL;DR: 论文提出了一种基于物理信息不确定性的新范式，将模型预测违反物理定律的程度作为预测不确定性的廉价有效代理，应用于频率选择表面的逆设计，显著提高了成功率和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于深度学习的代理辅助优化方法通常缺乏不确定性量化，导致在数据稀疏区域产生错误预测，从而影响优化性能。在频率选择表面等逆设计问题中，需要更有效的不确定性量化方法来提高设计成功率。

Method: 提出物理信息不确定性范式，利用模型预测违反基本物理定律的程度作为预测不确定性的代理。将此方法集成到多保真度不确定性感知优化工作流中，应用于20-30 GHz频率选择表面的复杂设计。

Result: 与单独使用高保真求解器相比，将成功找到高性能解决方案的概率从不到10%提高到超过50%，同时计算成本降低了一个数量级。

Conclusion: 物理信息不确定性是高维问题中机器学习驱动逆设计不确定性量化的有效替代方案，为能够高效稳健探索和评估候选设计的自主科学发现系统奠定了基础。

Abstract: Inverse design is a central goal in much of science and engineering, including frequency-selective surfaces (FSS) that are critical to microelectronics for telecommunications and optical metamaterials. Traditional surrogate-assisted optimization methods using deep learning can accelerate the design process but do not usually incorporate uncertainty quantification, leading to poorer optimization performance due to erroneous predictions in data-sparse regions. Here, we introduce and validate a fundamentally different paradigm of Physics-Informed Uncertainty, where the degree to which a model's prediction violates fundamental physical laws serves as a computationally-cheap and effective proxy for predictive uncertainty. By integrating physics-informed uncertainty into a multi-fidelity uncertainty-aware optimization workflow to design complex frequency-selective surfaces within the 20 - 30 GHz range, we increase the success rate of finding performant solutions from less than 10% to over 50%, while simultaneously reducing computational cost by an order of magnitude compared to the sole use of a high-fidelity solver. These results highlight the necessity of incorporating uncertainty quantification in machine-learning-driven inverse design for high-dimensional problems, and establish physics-informed uncertainty as a viable alternative to quantifying uncertainty in surrogate models for physical systems, thereby setting the stage for autonomous scientific discovery systems that can efficiently and robustly explore and evaluate candidate designs.

</details>


### [600] [A Dynamic Framework for Grid Adaptation in Kolmogorov-Arnold Networks](https://arxiv.org/abs/2601.18672)
*Spyros Rigas,Thanasis Papaioannou,Panagiotis Trakadas,Georgios Alexandridis*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文提出了一种基于曲率的重要性密度函数框架，用于改进KAN网络的网格自适应策略，相比传统仅基于输入数据密度的方法，能更好地考虑目标函数的几何复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有KAN网格自适应策略仅依赖输入数据密度，未能考虑目标函数的几何复杂性或训练过程中的计算指标，限制了KAN在科学机器学习中的潜力。

Method: 提出广义框架，将节点分配视为由重要性密度函数（IDFs）控制的密度估计任务，引入基于曲率的自适应策略，利用训练动态确定网格分辨率。

Result: 在合成函数拟合、Feynman数据集回归和Helmholtz PDE问题上，相比标准输入基线，相对误差分别降低25.3%、9.4%和23.3%，Wilcoxon符号秩检验确认统计显著性。

Conclusion: 基于曲率的自适应策略是KAN训练中稳健且计算高效的替代方案，能更好地捕捉目标函数复杂性，提升科学机器学习性能。

Abstract: Kolmogorov-Arnold Networks (KANs) have recently demonstrated promising potential in scientific machine learning, partly due to their capacity for grid adaptation during training. However, existing adaptation strategies rely solely on input data density, failing to account for the geometric complexity of the target function or metrics calculated during network training. In this work, we propose a generalized framework that treats knot allocation as a density estimation task governed by Importance Density Functions (IDFs), allowing training dynamics to determine grid resolution. We introduce a curvature-based adaptation strategy and evaluate it across synthetic function fitting, regression on a subset of the Feynman dataset and different instances of the Helmholtz PDE, demonstrating that it significantly outperforms the standard input-based baseline. Specifically, our method yields average relative error reductions of 25.3% on synthetic functions, 9.4% on the Feynman dataset, and 23.3% on the PDE benchmark. Statistical significance is confirmed via Wilcoxon signed-rank tests, establishing curvature-based adaptation as a robust and computationally efficient alternative for KAN training.

</details>


### [601] [Learning temporal embeddings from electronic health records of chronic kidney disease patients](https://arxiv.org/abs/2601.18675)
*Aditya Kumar,Mario A. Cypko,Oliver Amft*

Main category: cs.LG

Relevance: 35.0

TL;DR: 研究探讨了在纵向电子健康记录上训练的时间嵌入模型能否在不影响预测性能的情况下学习临床有意义的表示，以及架构选择如何影响嵌入质量。使用MIMIC-IV数据集比较了三种循环架构，发现时间感知LSTM产生更结构化的嵌入，且嵌入模型在死亡率预测上始终优于端到端模型。


<details>
  <summary>Details</summary>
Motivation: 模型引导医学需要能够捕捉疾病动态同时保持透明和任务无关的表示，而大多数临床预测模型仅针对单一任务优化。表示学习有助于学习跨下游任务泛化的嵌入，循环架构非常适合建模观察性临床数据中的时间结构。

Method: 使用MIMIC-IV数据集研究慢性肾脏病（CKD）患者，比较三种循环架构：普通LSTM、注意力增强LSTM和时间感知LSTM（T-LSTM）。所有模型既作为嵌入模型训练，也作为直接端到端预测器训练。通过CKD阶段聚类和ICU内死亡率预测评估嵌入质量。

Result: T-LSTM产生更结构化的嵌入，Davies-Bouldin指数更低（DBI = 9.91），CKD阶段分类准确率更高（0.74），优于普通LSTM（DBI = 15.85，准确率0.63）和注意力增强LSTM（DBI = 20.72，准确率0.67）。在ICU内死亡率预测中，嵌入模型始终优于端到端预测器，准确率从0.72-0.75提升到0.82-0.83。

Conclusion: 时间感知LSTM架构能够学习临床有意义的表示而不损害预测性能，学习嵌入作为中间步骤比直接端到端学习更有效。这为模型引导医学提供了支持，表明表示学习可以产生既具有临床意义又具有预测能力的嵌入。

Abstract: We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.

</details>


### [602] [Explainability Methods for Hardware Trojan Detection: A Systematic Comparison](https://arxiv.org/abs/2601.18696)
*Paul Whitten,Francis Wolff,Chris Papachristou*

Main category: cs.LG

Relevance: 35.0

TL;DR: 本文比较了硬件木马检测中的三种可解释性方法：基于属性的电路特征分析、基于案例的推理和模型无关特征归因，发现前两者在领域对齐和可验证性方面优于通用特征排名方法。


<details>
  <summary>Details</summary>
Motivation: 硬件木马检测不仅需要准确识别，还需要为安全工程师提供可解释的说明，以便验证结果并采取行动。当前的可解释性方法缺乏对电路领域特定知识的整合，限制了实际部署中的有效性。

Method: 比较三种可解释性方法：(1) 基于31个电路特定特征的领域感知属性分析（门扇入模式、触发器距离、I/O连接性）；(2) 使用k近邻的基于案例推理；(3) 模型无关特征归因（LIME、SHAP、梯度方法）。使用XGBoost分类器在Trust-Hub基准测试的11,392个样本上进行评估。

Result: XGBoost分类达到46.15%精度和52.17%召回率，相比先前工作（Hasegawa等：5.13%）精度提升9倍，假阳性率从5.6%降至0.25%。基于案例的推理实现97.4%的预测与训练样本对应性。LIME和SHAP特征归因相关性高（r=0.94），但缺乏电路级上下文。

Conclusion: 基于属性的分析和基于案例的推理在领域对齐和基于先例的可解释性方面优于通用特征排名方法，对于需要验证ML预测的实际部署场景具有重要意义。

Abstract: Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient).
  Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like "high fanin complexity near outputs indicates potential triggers." Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation.
  XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights.
  This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions.

</details>


### [603] [SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model](https://arxiv.org/abs/2601.18707)
*Jan Hagnberger,Mathias Niepert*

Main category: cs.LG

Relevance: 35.0

TL;DR: SMART是一种用于物理仿真的神经代理模型，仅使用点云几何表示（无需仿真网格）即可预测任意查询位置的物理量，性能可与依赖网格的方法相媲美。


<details>
  <summary>Details</summary>
Motivation: 现有基于网格的代理模型需要计算成本高昂的仿真网格生成，而无需网格的方法通常误差较高。SMART旨在开发一种无需网格但性能优越的神经代理模型。

Method: SMART将几何和仿真参数编码到共享潜在空间，捕捉结构和参数特征。物理解码器通过跨层交互关注编码器的中间潜在表示，将空间查询映射到物理量，联合更新潜在几何特征和物理场。

Result: 大量实验表明，SMART与依赖仿真网格输入的现有方法具有竞争力，且经常表现更优，展示了其在工业级仿真中的能力。

Conclusion: SMART证明了仅使用点云几何表示即可实现高性能物理仿真预测，无需昂贵的网格生成，为工业仿真提供了高效替代方案。

Abstract: Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.

</details>


### [604] [Benchmarking Machine Learning Models for IoT Malware Detection under Data Scarcity and Drift](https://arxiv.org/abs/2601.18736)
*Jake Lyon,Ehsan Saeedizade,Shamik Sengupta*

Main category: cs.LG

Relevance: 35.0

TL;DR: 研究比较了四种监督学习模型在IoT恶意软件检测中的性能，发现树模型在有限数据下表现良好，但随时间推移性能会下降。


<details>
  <summary>Details</summary>
Motivation: 物联网设备由于计算资源有限、物理防护薄弱，成为网络攻击的主要目标。机器学习为自动化恶意软件检测提供了可能，但需要既有效又轻量级的模型来适应实际部署需求。

Method: 使用IoT-23数据集，评估四种监督学习模型（随机森林、LightGBM、逻辑回归和多层感知器）在恶意软件检测和分类中的表现。研究包括二分类和多分类任务，评估对训练数据量的敏感性，以及时间鲁棒性分析。

Result: 树模型（随机森林和LightGBM）在准确率和泛化能力方面表现最佳，即使在有限训练数据下也能保持良好性能。但随着时间推移，恶意软件多样性增加，所有模型性能都会下降。

Conclusion: 研究强调了自适应、资源高效的机器学习模型对于在实际环境中保护物联网系统的重要性，树模型在资源受限的IoT环境中具有实用价值。

Abstract: The rapid expansion of the Internet of Things (IoT) in domains such as smart cities, transportation, and industrial systems has heightened the urgency of addressing their security vulnerabilities. IoT devices often operate under limited computational resources, lack robust physical safeguards, and are deployed in heterogeneous and dynamic networks, making them prime targets for cyberattacks and malware applications. Machine learning (ML) offers a promising approach to automated malware detection and classification, but practical deployment requires models that are both effective and lightweight. The goal of this study is to investigate the effectiveness of four supervised learning models (Random Forest, LightGBM, Logistic Regression, and a Multi-Layer Perceptron) for malware detection and classification using the IoT-23 dataset. We evaluate model performance in both binary and multiclass classification tasks, assess sensitivity to training data volume, and analyze temporal robustness to simulate deployment in evolving threat landscapes. Our results show that tree-based models achieve high accuracy and generalization, even with limited training data, while performance deteriorates over time as malware diversity increases. These findings underscore the importance of adaptive, resource-efficient ML models for securing IoT systems in real-world environments.

</details>


### [605] [Regret-Driven Portfolios: LLM-Guided Smart Clustering for Optimal Allocation](https://arxiv.org/abs/2601.17021)
*Muhammad Abro,Hassan Jaleel*

Main category: q-fin.PM

Relevance: 35.0

TL;DR: 提出一种结合在线学习、市场情绪指标和LLM对冲的LLM引导无遗憾投资组合分配框架，旨在平衡中长期投资组合管理的风险与回报


<details>
  <summary>Details</summary>
Motivation: 解决中长期投资组合管理中风险与回报之间的持久权衡问题，为风险厌恶型投资者和机构基金经理构建高夏普比率投资组合

Method: 基于跟随领导者方法，结合情绪驱动的交易过滤和LLM驱动的下行保护，集成在线学习动态、市场情绪指标和LLM对冲

Result: 方法在年化回报上超越SPY买入持有基准69%，夏普比率提升119%

Conclusion: LLM引导的投资组合分配框架能有效平衡风险与回报，为风险厌恶投资者提供优越的投资组合管理方案

Abstract: We attempt to mitigate the persistent tradeoff between risk and return in medium- to long-term portfolio management. This paper proposes a novel LLM-guided no-regret portfolio allocation framework that integrates online learning dynamics, market sentiment indicators, and large language model (LLM)-based hedging to construct high-Sharpe ratio portfolios tailored for risk-averse investors and institutional fund managers. Our approach builds on a follow-the-leader approach, enriched with sentiment-based trade filtering and LLM-driven downside protection. Empirical results demonstrate that our method outperforms a SPY buy-and-hold baseline by 69% in annualized returns and 119% in Sharpe ratio.

</details>


### [606] [Evaluation on Entity Matching in Recommender Systems](https://arxiv.org/abs/2601.17218)
*Zihan Huang,Rohan Surana,Zhouhang Xie,Junda Wu,Yu Xia,Julian McAuley*

Main category: cs.IR

Relevance: 35.0

TL;DR: 提出了Reddit-Amazon-EM数据集，用于评估跨数据集实体匹配方法，涵盖规则、图、词法、嵌入和LLM等多种方法，为推荐系统中的实体匹配研究提供基准资源。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏跨数据集实体匹配的严格评估框架，这阻碍了LLM驱动的对话推荐和知识基础数据集构建等领域的进展。推荐系统中的实体匹配是关键组件，但现有数据集评估不足。

Method: 构建了Reddit-Amazon-EM数据集，包含Reddit和Amazon '23数据集中自然出现的项目。通过人工标注识别Reddit-Movies和Amazon'23中对应的电影。使用该数据集全面评估了最先进的实体匹配方法，包括规则基、图基、词法基、嵌入基和LLM基方法。

Result: 创建了一个手动标注的实体匹配黄金标准集，并提供了使用实验中最佳性能方法在两个数据集之间的映射。该资源可用于推进推荐系统中实体匹配的未来工作。

Conclusion: Reddit-Amazon-EM数据集填补了跨数据集实体匹配评估的空白，为推荐系统研究提供了有价值的基准资源，特别有助于LLM驱动的对话推荐和知识基础数据集构建。

Abstract: Entity matching is a crucial component in various recommender systems, including conversational recommender systems (CRS) and knowledge-based recommender systems. However, the lack of rigorous evaluation frameworks for cross-dataset entity matching impedes progress in areas such as LLM-driven conversational recommendations and knowledge-grounded dataset construction.
  In this paper, we introduce Reddit-Amazon-EM, a novel dataset comprising naturally occurring items from Reddit and the Amazon '23 dataset. Through careful manual annotation, we identify corresponding movies across Reddit-Movies and Amazon'23, two existing recommender system datasets with inherently overlapping catalogs. Leveraging Reddit-Amazon-EM, we conduct a comprehensive evaluation of state-of-the-art entity matching methods, including rule-based, graph-based, lexical-based, embedding-based, and LLM-based approaches.
  For reproducible research, we release our manually annotated entity matching gold set and provide the mapping between the two datasets using the best-performing method from our experiments. This serves as a valuable resource for advancing future work on entity matching in recommender systems.

</details>


### [607] [Error Analysis of Bayesian Inverse Problems with Generative Priors](https://arxiv.org/abs/2601.17374)
*Bamdad Hosseini,Ziqi Huang*

Main category: stat.ML

Relevance: 35.0

TL;DR: 论文分析了使用生成模型作为先验解决反问题的误差界限，证明了后验误差会继承先验的Wasserstein-1距离收敛率，并在椭圆PDE反问题中进行了数值验证。


<details>
  <summary>Details</summary>
Motivation: 近年来，基于数据驱动的反问题解决方法因机器学习技术的兴起而广泛流行。一种流行的方法是通过在额外数据上训练生成模型来学习特定问题的先验分布。本文旨在对这种方法的误差进行理论分析，为生成先验在反问题中的应用提供理论保证。

Method: 采用最小Wasserstein-2生成模型作为先验，在特定假设下，分析后验误差与先验误差之间的关系。通过理论推导证明后验误差会继承先验的Wasserstein-1距离收敛率，并使用数值实验验证理论分析，包括基准测试和椭圆PDE反问题中的非平稳场建模。

Result: 理论分析表明，在特定假设下，由生成先验引起的后验误差会以与先验相同的速率收敛（相对于Wasserstein-1距离）。数值实验验证了误差分析的某些方面在基准测试中显现，并在椭圆PDE反问题中成功应用生成先验建模非平稳场。

Conclusion: 本文为使用生成模型作为先验解决反问题的方法提供了理论误差界限，证明了后验误差会继承先验的收敛性质，并通过数值实验验证了理论分析的有效性，为数据驱动的反问题求解提供了理论支持。

Abstract: Data-driven methods for the solution of inverse problems have become widely popular in recent years thanks to the rise of machine learning techniques. A popular approach concerns the training of a generative model on additional data to learn a bespoke prior for the problem at hand. In this article we present an analysis for such problems by presenting quantitative error bounds for minimum Wasserstein-2 generative models for the prior. We show that under some assumptions, the error in the posterior due to the generative prior will inherit the same rate as the prior with respect to the Wasserstein-1 distance. We further present numerical experiments that verify that aspects of our error analysis manifests in some benchmarks followed by an elliptic PDE inverse problem where a generative prior is used to model a non-stationary field.

</details>


### [608] [A new approach for combined model class selection and parameters learning for auto-regressive neural models](https://arxiv.org/abs/2601.17442)
*Corrado Sgadari,Alessio La Bella,Marcello Farina*

Main category: eess.SY

Relevance: 35.0

TL;DR: 提出一种联合选择模型结构和参数学习的新方法，用于非线性动态系统辨识，特别针对NARXESN这类RNN，通过基于集合成员的方法同时选择最优模型类别并学习参数。


<details>
  <summary>Details</summary>
Motivation: 传统非线性动态系统辨识方法通常需要分别处理模型结构选择和参数学习，这可能导致次优结果。特别是在存在有界测量噪声的情况下，需要一种能够同时考虑模型结构和参数学习、并能处理噪声的鲁棒方法。

Method: 针对NARXESN（非线性自回归外生输入回声状态网络），提出基于集合成员的方法，同时选择最优模型类别并学习模型参数。该方法采用鲁棒训练策略，显式考虑有界测量噪声，并允许在参数学习过程中进行数据一致的仿真性能评估。

Result: 该方法能够识别出简洁而准确的模型，适用于控制应用。提出的框架实现了鲁棒训练策略，增强了模型鲁棒性，解决了具有自回归组件的模型通常NP-hard的仿真性能评估问题。

Conclusion: 该方法为非线性动态系统辨识提供了一种有效的联合模型结构选择和参数学习框架，特别适用于存在测量噪声的控制应用场景，能够产生鲁棒且准确的模型。

Abstract: This work introduces a novel approach for the joint selection of model structure and parameter learning for nonlinear dynamical systems identification. Focusing on a specific Recurrent Neural Networks (RNNs) family, i.e., Nonlinear Auto-Regressive with eXogenous inputs Echo State Networks (NARXESNs), the method allows to simultaneously select the optimal model class and learn model parameters from data through a new set-membership (SM) based procedure. The results show the effectiveness of the approach in identifying parsimonious yet accurate models suitable for control applications. Moreover, the proposed framework enables a robust training strategy that explicitly accounts for bounded measurement noise and enhances model robustness by allowing data-consistent evaluation of simulation performance during parameter learning, a process generally NP-hard for models with autoregressive components.

</details>


### [609] [ToS: A Team of Specialists ensemble framework for Stereo Sound Event Localization and Detection with distance estimation in Video](https://arxiv.org/abs/2601.17611)
*Davide Berghi,Philip J. B. Jackson*

Main category: eess.AS

Relevance: 35.0

TL;DR: 提出Team of Specialists (ToS)集成框架，通过三个专门化子网络分别处理语义-空间、空间-时间和时间-语义维度，用于视频中的3D声音事件定位与检测任务，在DCASE2025基准上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 视频中的3D声音事件定位与检测需要同时处理语义、空间和时间三个维度，单一模型难以有效应对这种多模态联合推理的挑战。现有方法在处理这种复杂多维度任务时存在局限性。

Method: 提出ToS集成框架，包含三个专门化子网络：1) 空间-语言模型处理语义和空间维度；2) 空间-时间模型处理空间和时间维度；3) 时间-语言模型处理时间和语义维度。每个子网络专注于特定维度对的推理，最后集成预测结果。

Result: 在DCASE2025 Task 3 Stereo SELD开发集上，ToS框架超越了现有的音频-视觉模型，在关键指标上表现优异。

Conclusion: ToS框架通过专家团队协作的方式有效解决了3D SELD任务中的多维度联合推理问题，证明了专门化子网络集成的有效性。未来将通过任务设计、训练策略和预训练课程进一步强化各专家模型。

Abstract: Sound event localization and detection with distance estimation (3D SELD) in video involves identifying active sound events at each time frame while estimating their spatial coordinates. This multimodal task requires joint reasoning across semantic, spatial, and temporal dimensions, a challenge that single models often struggle to address effectively. To tackle this, we introduce the Team of Specialists (ToS) ensemble framework, which integrates three complementary sub-networks: a spatio-linguistic model, a spatio-temporal model, and a tempo-linguistic model. Each sub-network specializes in a unique pair of dimensions, contributing distinct insights to the final prediction, akin to a collaborative team with diverse expertise. ToS has been benchmarked against state-of-the-art audio-visual models for 3D SELD on the DCASE2025 Task 3 Stereo SELD development set, consistently outperforming existing methods across key metrics. Future work will extend this proof of concept by strengthening the specialists with appropriate tasks, training, and pre-training curricula.

</details>


### [610] [MarketGANs: Multivariate financial time-series data augmentation using generative adversarial networks](https://arxiv.org/abs/2601.17773)
*Jeonggyu Huh,Seungwon Jeong,Hyun-Gyoon Kim,Hyeng Keun Koo,Byung Hwa Lim*

Main category: q-fin.ST

Relevance: 35.0

TL;DR: MarketGAN：基于因子结构的生成对抗网络框架，用于数据稀缺条件下的高维资产收益率生成，通过嵌入资产定价因子结构作为经济归纳偏置，生成联合向量以保持横截面依赖性和尾部联动。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺条件下生成高维资产收益率面临挑战，传统方法难以同时保持横截面依赖性和尾部联动等经验特征。需要结合经济学先验知识（因子结构）来改进生成质量。

Method: 采用生成对抗学习框架，以时序卷积网络（TCN）为骨干，嵌入显式的资产定价因子结构作为经济归纳偏置。模型生成联合收益率向量，同时建模随机时变因子载荷和波动率，捕捉长期时序依赖。

Result: MarketGAN比传统基于因子模型的bootstrap方法更能匹配资产收益率的经验特征，包括厚尾边际分布、波动率聚类、杠杆效应，特别是高维横截面相关结构和资产间尾部联动。在投资组合应用中，当因子信息至少具有弱信息性时，MarketGAN生成的协方差估计优于其他方法。

Conclusion: MarketGAN通过结合经济学先验知识和生成对抗学习，在数据稀缺条件下有效生成高质量的高维资产收益率，展示了实际经济价值。

Abstract: This paper introduces MarketGAN, a factor-based generative framework for high-dimensional asset return generation under severe data scarcity. We embed an explicit asset-pricing factor structure as an economic inductive bias and generate returns as a single joint vector, thereby preserving cross-sectional dependence and tail co-movement alongside inter-temporal dynamics. MarketGAN employs generative adversarial learning with a temporal convolutional network (TCN) backbone, which models stochastic, time-varying factor loadings and volatilities and captures long-range temporal dependence. Using daily returns of large U.S. equities, we find that MarketGAN more closely matches empirical stylized facts of asset returns, including heavy-tailed marginal distributions, volatility clustering, leverage effects, and, most notably, high-dimensional cross-sectional correlation structures and tail co-movement across assets, than conventional factor-model-based bootstrap approaches. In portfolio applications, covariance estimates derived from MarketGAN-generated samples outperform those derived from other methods when factor information is at least weakly informative, demonstrating tangible economic value.

</details>


### [611] [Differentiable Integer Linear Programming is not Differentiable & it's not a mere technical problem](https://arxiv.org/abs/2601.17800)
*Thanawat Sornwanee*

Main category: math.OC

Relevance: 35.0

TL;DR: 论文指出Geng等人2025年论文《Differentiable Integer Linear Programming》中定理5的微分方法存在错误，且已有下游工作继承了该错误。核心问题在于：虽然期望上是连续的，但随机梯度下降中替代损失在几乎每个随机实现中都是不连续的。


<details>
  <summary>Details</summary>
Motivation: 本文旨在纠正Geng等人2025年论文中关于可微分整数线性规划方法的数学错误。该错误源于对随机梯度下降中替代损失连续性的误解，且已有后续工作继承了这一错误，可能影响相关领域的研究进展。

Method: 通过数学分析指出原论文定理5的证明错误。具体分析了随机梯度下降中替代损失的性质：虽然在期望上是连续的，但在几乎每个随机实现中都是不连续的，这导致微分方法在理论基础上存在问题。

Result: 成功识别并证明了Geng等人论文中微分方法的错误。指出该错误源于对随机梯度下降中损失函数连续性的误解，并警告已有下游工作继承了这一错误。

Conclusion: Geng等人2025年论文中的可微分整数线性规划方法存在根本性数学错误，需要重新审视相关理论和应用。研究人员在使用该方法时应谨慎，并考虑修正方案。

Abstract: We show how the differentiability method employed in the paper ``Differentiable Integer Linear Programming'', Geng, et al., 2025 as shown in its theorem 5 is incorrect. Moreover, there already exists some downstream work that inherits the same error. The underlying reason comes from that, though being continuous in expectation, the surrogate loss is discontinuous in almost every realization of the randomness, for the stochastic gradient descent.

</details>


### [612] [Flow-based Extremal Mathematical Structure Discovery](https://arxiv.org/abs/2601.18005)
*Gergely Bérczi,Baran Hashemi,Jonas Klüver*

Main category: math.CO

Relevance: 35.0

TL;DR: FlowBoost是一个闭环生成框架，用于发现数学中的极值几何结构，结合条件流匹配、奖励引导策略优化和随机局部搜索，相比现有方法显著减少计算资源和训练时间。


<details>
  <summary>Details</summary>
Motivation: 数学中极值结构的发现面临巨大非凸搜索空间的挑战，解析方法难以指导，暴力搜索不可行。现有方法如PatternBoost和AlphaEvolve存在效率低、依赖LLM等问题。

Method: 1) 几何感知的条件流匹配模型学习采样高质量配置；2) 奖励引导的策略优化直接优化生成过程；3) 随机局部搜索用于训练数据生成和最终精炼。形成闭环优化，无需依赖LLM。

Result: 在四个几何优化问题上验证：超立方体球体填充、最大化半径和的圆填充、Heilbronn三角形问题、星差异最小化。多个案例达到或超越已知最佳结果，在圆填充问题上改进了下界，超越AlphaEvolve且计算资源显著减少。

Conclusion: FlowBoost提供了一种高效的极值几何结构发现框架，通过闭环生成优化显著减少了计算需求，在多个问题上展示了优越性能，为数学优化问题提供了新方法。

Abstract: The discovery of extremal structures in mathematics requires navigating vast and nonconvex landscapes where analytical methods offer little guidance and brute-force search becomes intractable. We introduce FlowBoost, a closed-loop generative framework that learns to discover rare and extremal geometric structures by combining three components: (i) a geometry-aware conditional flow-matching model that learns to sample high-quality configurations, (ii) reward-guided policy optimization with action exploration that directly optimizes the generation process toward the objective while maintaining diversity, and (iii) stochastic local search for both training-data generation and final refinement. Unlike prior open-loop approaches, such as PatternBoost that retrains on filtered discrete samples, or AlphaEvolve which relies on frozen Large Language Models (LLMs) as evolutionary mutation operators, FlowBoost enforces geometric feasibility during sampling, and propagates reward signal directly into the generative model, closing the optimization loop and requiring much smaller training sets and shorter training times, and reducing the required outer-loop iterations by orders of magnitude, while eliminating dependence on LLMs. We demonstrate the framework on four geometric optimization problems: sphere packing in hypercubes, circle packing maximizing sum of radii, the Heilbronn triangle problem, and star discrepancy minimization. In several cases, FlowBoost discovers configurations that match or exceed the best known results. For circle packings, we improve the best known lower bounds, surpassing the LLM-based system AlphaEvolve while using substantially fewer computational resources.

</details>


### [613] [Exact Minimum-Volume Confidence Set Intersection for Multinomial Outcomes](https://arxiv.org/abs/2601.18145)
*Heguang Lin,Binhao Chen,Mengze Li,Daniel Pimentel-Alarcón,Matthew L. Malloy*

Main category: stat.ML

Relevance: 35.0

TL;DR: 本文提出了一种用于验证两个多项式参数的最小体积置信集（MVCs）是否相交的认证算法，解决了A/B测试和强化学习中的核心统计推断问题。


<details>
  <summary>Details</summary>
Motivation: 多项式参数置信集的计算是数据科学和机器学习的核心，支撑着A/B测试和强化学习算法。虽然最小体积置信集（MVCs）在平均体积上是最优的，但其精确p值定义不连续且难以计算。本文旨在解决一个实际决策问题：给定两个观测到的多项式结果，能否验证它们的MVCs是否相交？

Method: 提出了一种认证的、容错感知的相交验证算法。该方法利用似然排序在对数几率坐标中诱导出半空间约束，从而实现对参数空间的自适应几何划分，并计算每个单元上p值的可计算上下界。对于三个类别，该方法产生一个高效且可证明可靠的算法，可以认证相交、认证不相交，或在决策处于规定边界内时返回不确定结果。该方法还可扩展到更高维度。

Result: 结果表明，尽管MVCs具有不规则的几何形状，但对于A/B测试中的核心任务，它们允许可靠的认证决策过程。该方法能够有效处理多项式参数的统计推断问题。

Conclusion: 本文证明了最小体积置信集（MVCs）尽管几何形状复杂，但可以通过可靠的认证决策程序来处理A/B测试中的核心任务。提出的算法为多项式参数的统计推断提供了实用解决方案。

Abstract: Computation of confidence sets is central to data science and machine learning, serving as the workhorse of A/B testing and underpinning the operation and analysis of reinforcement learning algorithms. Among all valid confidence sets for the multinomial parameter, minimum-volume confidence sets (MVCs) are optimal in that they minimize average volume, but they are defined as level sets of an exact p-value that is discontinuous and difficult to compute. Rather than attempting to characterize the geometry of MVCs directly, this paper studies a practically motivated decision problem: given two observed multinomial outcomes, can one certify whether their MVCs intersect? We present a certified, tolerance-aware algorithm for this intersection problem. The method exploits the fact that likelihood ordering induces halfspace constraints in log-odds coordinates, enabling adaptive geometric partitioning of parameter space and computable lower and upper bounds on p-values over each cell. For three categories, this yields an efficient and provably sound algorithm that either certifies intersection, certifies disjointness, or returns an indeterminate result when the decision lies within a prescribed margin. We further show how the approach extends to higher dimensions. The results demonstrate that, despite their irregular geometry, MVCs admit reliable certified decision procedures for core tasks in A/B testing.

</details>


### [614] [Fusion of Spatio-Temporal and Multi-Scale Frequency Features for Dry Electrodes MI-EEG Decoding](https://arxiv.org/abs/2601.18424)
*Tianyi Gong,Can Han,Junxi Wu,Dahong Qian*

Main category: cs.HC

Relevance: 35.0

TL;DR: STGMFM是一个针对干电极运动想象脑电图的tri-branch框架，通过双图顺序建模时空依赖，多尺度频率混合分支捕获鲁棒包络动态，解决干电极记录的信噪比低、相位对齐差、会话间方差大等问题。


<details>
  <summary>Details</summary>
Motivation: 干电极运动想象脑电图（MI-EEG）虽然便于快速、舒适的现实世界脑机接口应用，但存在三个主要问题：1）信噪比低，基线漂移和瞬态干扰多；2）数据弱且噪声大，跨试次相位对齐差；3）会话间方差大。这些问题导致数据分布偏移更大，特征稳定性差。

Method: 提出STGMFM三分支框架：1）双图顺序建模互补的时空依赖关系；2）多尺度频率混合分支捕获鲁棒的包络动态（观察到振幅包络对接触变化比瞬时波形更不敏感）；3）生理学上有意义的连接先验指导学习；4）决策级融合整合噪声容忍共识。

Result: 在收集的干电极MI-EEG数据集上，STGMFM consistently surpasses competitive CNN/Transformer/graph baselines。

Conclusion: STGMFM框架有效解决了干电极MI-EEG的关键挑战，通过多模态建模和决策融合实现了对噪声的鲁棒性，在干电极脑电图任务上超越了现有基线方法。

Abstract: Dry-electrode Motor Imagery Electroencephalography (MI-EEG) enables fast, comfortable, real-world Brain Computer Interface by eliminating gels and shortening setup for at-home and wearable use.However, dry recordings pose three main issues: lower Signal-to-Noise Ratio with more baseline drift and sudden transients; weaker and noisier data with poor phase alignment across trials; and bigger variances between sessions. These drawbacks lead to larger data distribution shift, making features less stable for MI-EEG tasks.To address these problems, we introduce STGMFM, a tri-branch framework tailored for dry-electrode MI-EEG, which models complementary spatio-temporal dependencies via dual graph orders, and captures robust envelope dynamics with a multi-scale frequency mixing branch, motivated by the observation that amplitude envelopes are less sensitive to contact variability than instantaneous waveforms. Physiologically meaningful connectivity priors guide learning, and decision-level fusion consolidates a noise-tolerant consensus. On our collected dry-electrode MI-EEG, STGMFM consistently surpasses competitive CNN/Transformer/graph baselines. Codes are available at https://github.com/Tianyi-325/STGMFM.

</details>


### [615] [Weighted Graph Clustering via Scale Contraction and Graph Structure Learning](https://arxiv.org/abs/2601.17307)
*Haobing Liu,Yinuo Zhang,Tingting Wang,Ruobing Jiang,Yanwei Yu*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出一种收缩边权重感知图聚类网络，通过图收缩模块减少图规模并保留重要节点，使用边权重感知注意力网络识别和削弱噪声连接，从而提升聚类效果并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有图聚类方法未能充分利用边权重信息，而边权重使用面临两大挑战：1) 边权重显著增加存储和计算开销，需要在不损失聚类质量的前提下减少图规模；2) 边权重可能包含噪声，对聚类结果产生负面影响。现有研究很少能同时优化聚类和边权重。

Method: 提出收缩边权重感知图聚类网络，包含两个核心模块：1) 面向聚类的图收缩模块，减少图规模同时保留对聚类任务重要的节点；2) 边权重感知注意力网络，识别并削弱噪声连接。通过联合优化聚类和边权重来减轻噪声边的影响。

Result: 在三个真实世界加权图数据集上的实验表明，该模型优于最佳基线方法，展现出优越性能。此外，图收缩模块能显著减少训练时间和存储空间。

Conclusion: 提出的方法能有效处理加权图中的噪声边问题，同时通过图收缩降低计算开销，为加权图聚类提供了一种有效的解决方案。

Abstract: Graph clustering aims to partition nodes into distinct clusters based on their similarity, thereby revealing relationships among nodes. Nevertheless, most existing methods do not fully utilize these edge weights. Leveraging edge weights in graph clustering tasks faces two critical challenges. (1) The introduction of edge weights may significantly increase storage space and training time, making it essential to reduce the graph scale while preserving nodes that are beneficial for the clustering task. (2) Edge weight information may inherently contain noise that negatively impacts clustering results. However, few studies can jointly optimize clustering and edge weights, which is crucial for mitigating the negative impact of noisy edges on clustering task. To address these challenges, we propose a contractile edge-weight-aware graph clustering network. Specifically, a cluster-oriented graph contraction module is designed to reduce the graph scale while preserving important nodes. An edge-weight-aware attention network is designed to identify and weaken noisy connections. In this way, we can more easily identify and mitigate the impact of noisy edges during the clustering process, thus enhancing clustering effectiveness. We conducted extensive experiments on three real-world weighted graph datasets. In particular, our model outperforms the best baseline, demonstrating its superior performance. Furthermore, experiments also show that the proposed graph contraction module can significantly reduce training time and storage space.

</details>


### [616] [DREAM: Dual-Standard Semantic Homogeneity with Dynamic Optimization for Graph Learning with Label Noise](https://arxiv.org/abs/2601.17449)
*Yusheng Zhao,Jiaye Xie,Qixin Zhang,Weizhi Zhang,Xiao Luo,Zhiping Xiao,Philip S. Yu,Ming Zhang*

Main category: cs.LG

Relevance: 30.0

TL;DR: DREAM是一种针对带标签噪声的图神经网络方法，通过双重标准语义同质性和动态优化框架，在优化过程中迭代评估节点可靠性，利用图拓扑关系提高噪声标签下的学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络方法假设训练图标签准确，但现实场景中标签可靠性无法保证。现有处理标签噪声的方法存在两个主要问题：1) 难以区分可靠与不可靠节点；2) 忽视图拓扑中嵌入的关系信息。

Method: 提出DREAM方法，包含关系感知的动态优化框架，在优化过程中迭代重新评估每个标记节点的可靠性。采用双重标准选择策略，基于节点邻近性和图拓扑选择锚点集，计算目标节点与锚点之间的语义同质性作为优化指导。

Result: 在六个不同领域的图数据集上，针对三种类型的图标签噪声进行了广泛实验，与竞争基线相比，结果证明了DREAM的有效性。

Conclusion: DREAM通过关系感知的动态优化和双重标准语义同质性，有效解决了图学习中标签噪声问题，提供了可靠的关系感知优化方法。

Abstract: Graph neural networks (GNNs) have been widely used in various graph machine learning scenarios. Existing literature primarily assumes well-annotated training graphs, while the reliability of labels is not guaranteed in real-world scenarios. Recently, efforts have been made to address the problem of graph learning with label noise. However, existing methods often (i) struggle to distinguish between reliable and unreliable nodes, and (ii) overlook the relational information embedded in the graph topology. To tackle this problem, this paper proposes a novel method, Dual-Standard Semantic Homogeneity with Dynamic Optimization (DREAM), for reliable, relation-informed optimization on graphs with label noise. Specifically, we design a relation-informed dynamic optimization framework that iteratively reevaluates the reliability of each labeled node in the graph during the optimization process according to the relation of the target node and other nodes. To measure this relation comprehensively, we propose a dual-standard selection strategy that selects a set of anchor nodes based on both node proximity and graph topology. Subsequently, we compute the semantic homogeneity between the target node and the anchor nodes, which serves as guidance for optimization. We also provide a rigorous theoretical analysis to justify the design of DREAM. Extensive experiments are performed on six graph datasets across various domains under three types of graph label noise against competing baselines, and the results demonstrate the effectiveness of the proposed DREAM.

</details>


### [617] [FedCCA: Client-Centric Adaptation against Data Heterogeneity in Federated Learning on IoT Devices](https://arxiv.org/abs/2601.17713)
*Kaile Wang,Jiannong Cao,Yu Yang,Xiaoyin Li,Yinfeng Cao*

Main category: cs.LG

Relevance: 30.0

TL;DR: FedCCA：一种针对物联网数据异质性的联邦学习算法，通过动态客户端选择和自适应聚合来利用客户端特定知识，提升模型性能


<details>
  <summary>Details</summary>
Motivation: 物联网中AI模型训练需要处理隐私数据，联邦学习是隐私保护的分布式训练框架。但物联网设备间的数据异质性问题会显著降低模型性能和收敛速度。现有方法在固定客户端选择和云端聚合方面存在局限，难以在本地训练中提取客户端特定信息。

Method: 提出FedCCA算法：1）动态客户端选择；2）基于额外客户端特定编码器的自适应聚合；3）注意力机制的全局聚合策略来增强多源知识转移

Result: 在多个数据集上的实验表明，FedCCA在解决数据异质性问题上相比基线方法具有显著性能优势

Conclusion: FedCCA通过客户端中心化适应策略，有效缓解了联邦学习中的数据异质性问题，提升了模型性能

Abstract: With the rapid development of the Internet of Things (IoT), AI model training on private data such as human sensing data is highly desired. Federated learning (FL) has emerged as a privacy-preserving distributed training framework for this purpuse. However, the data heterogeneity issue among IoT devices can significantly degrade the model performance and convergence speed in FL. Existing approaches limit in fixed client selection and aggregation on cloud server, making the privacy-preserving extraction of client-specific information during local training challenging. To this end, we propose Client-Centric Adaptation federated learning (FedCCA), an algorithm that optimally utilizes client-specific knowledge to learn a unique model for each client through selective adaptation, aiming to alleviate the influence of data heterogeneity. Specifically, FedCCA employs dynamic client selection and adaptive aggregation based on the additional client-specific encoder. To enhance multi-source knowledge transfer, we adopt an attention-based global aggregation strategy. We conducted extensive experiments on diverse datasets to assess the efficacy of FedCCA. The experimental results demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.

</details>


### [618] [Coding-Enforced Resilient and Secure Aggregation for Hierarchical Federated Learning](https://arxiv.org/abs/2601.17995)
*Shudi Weng,Ming Xiao,Mikael Skoglund*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出H-SecCoGC方案，通过编码策略实现结构化聚合，在不可靠通信下保证分层联邦学习的模型精度和隐私保护


<details>
  <summary>Details</summary>
Motivation: 分层联邦学习(HFL)虽然改善了客户端与服务器间的链路质量，但在不可靠通信环境下，如何在保证模型精度的同时保护隐私仍然是一个关键挑战。隐私噪声的协调可能被随机干扰，需要更鲁棒的解决方案。

Method: 提出H-SecCoGC（分层安全聚合方案），集成编码策略来强制执行结构化聚合。该方案不仅在不同隐私级别下确保准确的全局模型构建，还避免了部分参与问题，从而显著提高鲁棒性、隐私保护和学习效率。

Result: 理论分析和实验结果都证明了该方案在不可靠通信环境下，对于任意强隐私保证的优越性。

Conclusion: H-SecCoGC方案有效解决了分层联邦学习在不可靠通信下的隐私保护与模型精度平衡问题，通过编码策略实现了鲁棒的安全聚合。

Abstract: Hierarchical federated learning (HFL) has emerged as an effective paradigm to enhance link quality between clients and the server. However, ensuring model accuracy while preserving privacy under unreliable communication remains a key challenge in HFL, as the coordination among privacy noise can be randomly disrupted. To address this limitation, we propose a robust hierarchical secure aggregation scheme, termed H-SecCoGC, which integrates coding strategies to enforce structured aggregation. The proposed scheme not only ensures accurate global model construction under varying levels of privacy, but also avoids the partial participation issue, thereby significantly improving robustness, privacy preservation, and learning efficiency. Both theoretical analyses and experimental results demonstrate the superiority of our scheme under unreliable communication across arbitrarily strong privacy guarantees

</details>


### [619] [Geometry-Free Conditional Diffusion Modeling for Solving the Inverse Electrocardiography Problem](https://arxiv.org/abs/2601.18615)
*Ramiro Valdes Jara,Adam Meyers*

Main category: cs.LG

Relevance: 30.0

TL;DR: 本文提出了一种基于条件扩散模型的数据驱动方法，用于解决心电图成像（ECGI）中的逆问题，通过概率性映射从体表信号重建心表电位，无需几何网格构建。


<details>
  <summary>Details</summary>
Motivation: ECGI逆问题具有非唯一性和欠定性，传统方法需要患者特定的几何网格构建，且通常提供确定性估计。需要一种能够捕捉问题概率特性、无需几何信息的数据驱动方法。

Method: 采用条件扩散框架，学习从含噪声体表信号到心表电位的概率映射。该方法是几何无关的纯数据驱动方法，利用扩散模型的生成特性来采样多个可能的重建结果。

Result: 在真实ECGI数据集上评估，相比CNN、LSTM和Transformer等确定性基线模型，扩散方法实现了更高的重建精度。

Conclusion: 扩散模型为无创心脏电生理成像提供了强大的概率性工具，能够更好地处理ECGI逆问题的非唯一性，且无需患者特定的网格构建。

Abstract: This paper proposes a data-driven model for solving the inverse problem of electrocardiography, the mathematical problem that forms the basis of electrocardiographic imaging (ECGI). We present a conditional diffusion framework that learns a probabilistic mapping from noisy body surface signals to heart surface electric potentials. The proposed approach leverages the generative nature of diffusion models to capture the non-unique and underdetermined nature of the ECGI inverse problem, enabling probabilistic sampling of multiple reconstructions rather than a single deterministic estimate. Unlike traditional methods, the proposed framework is geometry-free and purely data-driven, alleviating the need for patient-specific mesh construction. We evaluate the method on a real ECGI dataset and compare it against strong deterministic baselines, including a convolutional neural network, long short-term memory network, and transformer-based model. The results demonstrate that the proposed diffusion approach achieves improved reconstruction accuracy, highlighting the potential of diffusion models as a robust tool for noninvasive cardiac electrophysiology imaging.

</details>


### [620] [Communication-Avoiding Linear Algebraic Kernel K-Means on GPUs](https://arxiv.org/abs/2601.17136)
*Julian Bellavita,Matthew Rubino,Nakul Iyer,Andrew Chang,Aditya Devarakonda,Flavio Vella,Giulia Guidi*

Main category: cs.DC

Relevance: 30.0

TL;DR: 本文提出了一套分布式内存并行算法，用于在多GPU系统上进行大规模核K-means聚类，解决了传统方法因GPU内存限制无法处理超过8万样本的问题，使核K-means能够扩展到百万级数据集。


<details>
  <summary>Details</summary>
Motivation: 核K-means能够处理非线性可分离的聚类问题，但需要计算大型核矩阵，导致计算和内存开销巨大。先前工作通过稀疏线性代数原语在单GPU上加速，但仍受限于GPU内存，无法处理超过约8万个样本的数据集。本文旨在解决这一可扩展性问题。

Method: 提出了一套分布式内存并行算法，将核K-means中最计算密集的部分映射到专门为核K-means定制的通信高效的分布式线性代数原语上。设计了分区方案，使得这些线性代数原语能够高效组合。特别提出了1.5D算法，在性能和可扩展性上表现最佳。

Result: 1.5D算法能够将核K-means扩展到比先前方法大1-2个数量级的数据集。在256个GPU上，实现了79.7%的几何平均弱扩展效率和4.2倍的几何平均强扩展加速。相比1D算法，在256个GPU上实现了最高3.6倍的加速，将聚类时间从超过1小时减少到不到2秒。

Conclusion: 为特定应用设计的分布式算法结合专门的线性代数公式化能够实现显著的性能提升。本文的工作使得大规模核K-means聚类变得实用，为处理百万级数据集提供了高效的解决方案。

Abstract: Clustering is an important tool in data analysis, with K-means being popular for its simplicity and versatility. However, it cannot handle non-linearly separable clusters. Kernel K-means addresses this limitation but requires a large kernel matrix, making it computationally and memory intensive. Prior work has accelerated Kernel K-means by formulating it using sparse linear algebra primitives and implementing it on a single GPU. However, that approach cannot run on datasets with more than approximately 80,000 samples due to limited GPU memory.
  In this work, we address this issue by presenting a suite of distributed-memory parallel algorithms for large-scale Kernel K-means clustering on multi-GPU systems. Our approach maps the most computationally expensive components of Kernel K-means onto communication-efficient distributed linear algebra primitives uniquely tailored for Kernel K-means, enabling highly scalable implementations that efficiently cluster million-scale datasets. Central to our work is the design of partitioning schemes that enable communication-efficient composition of the linear algebra primitives that appear in Kernel K-means.
  Our 1.5D algorithm consistently achieves the highest performance, enabling Kernel K-means to scale to data one to two orders of magnitude larger than previously practical. On 256 GPUs, it achieves a geometric mean weak scaling efficiency of $79.7\%$ and a geometric mean strong scaling speedup of $4.2\times$. Compared to our 1D algorithm, the 1.5D approach achieves up to a $3.6\times$ speedup on 256 GPUs and reduces clustering time from over an hour to under two seconds relative to a single-GPU sliding window implementation. Our results show that distributed algorithms designed with application-specific linear algebraic formulations can achieve substantial performance improvement.

</details>


### [621] [Bayesian quantum sensing using graybox machine learning](https://arxiv.org/abs/2601.17465)
*Akram Youssry,Stefan Todd,Patrick Murton,Muhammad Junaid Arshad,Alberto Peruzzo,Cristian Bonato*

Main category: quant-ph

Relevance: 30.0

TL;DR: 该论文首次实验实现了固态开放量子系统的灰盒建模策略，将物理基础模型与数据驱动的实验缺陷描述相结合，在量子传感器磁场估计任务中相比纯物理模型实现了多个数量级的误差改进。


<details>
  <summary>Details</summary>
Motivation: 量子传感器虽然在空间分辨率和灵敏度方面优于经典设备，但其实际性能常受到噪声、不完美状态准备和非理想控制场等未建模效应的限制。需要一种既能保持物理可解释性又能适应实验缺陷的建模方法。

Method: 提出灰盒建模框架，整合基于物理的系统模型与数据驱动的实验缺陷描述。在单自旋量子传感器上实验验证，使用约10,000个训练数据点进行贝叶斯推断，估计静态磁场。

Result: 灰盒模型相比纯物理模型在均方误差上实现了多个数量级的改进。该方法适用于广泛的量子传感平台，对实时自适应协议特别有价值。

Conclusion: 灰盒建模策略在量子传感中实现了比纯分析模型更高的保真度，同时比完全深度学习模型需要更少的训练资源，为量子传感器性能优化提供了有效框架。

Abstract: Quantum sensors offer significant advantages over classical devices in spatial resolution and sensitivity, enabling transformative applications across materials science, healthcare, and beyond. Their practical performance, however, is often constrained by unmodelled effects, including noise, imperfect state preparation, and non-ideal control fields.
  In this work, we report the first experimental implementation of a graybox modelling strategy for a solid-state open quantum system. The graybox framework integrates a physics-based system model with a data-driven description of experimental imperfections, achieving higher fidelity than purely analytical (whitebox) approaches while requiring fewer training resources than fully deep-learning models. We experimentally validate the method on the task of estimating a static magnetic field using a single-spin quantum sensor, performing Bayesian inference with a graybox model trained on prior experimental data. Using roughly 10,000 training datapoints, the graybox model yields several orders of magnitude improvement in mean squared error over the corresponding physics-only model. These results are broadly applicable to a wide range of quantum sensing platforms, not limited to single-spin systems, and are particularly valuable for real-time adaptive protocols, where model inaccuracies can otherwise lead to suboptimal control and degraded performance.

</details>


### [622] [Athena: Synergizing Data Prefetching and Off-Chip Prediction via Online Reinforcement Learning](https://arxiv.org/abs/2601.17615)
*Rahul Bera,Zhenrong Lang,Caroline Hengartner,Konstantinos Kanellopoulos,Rakesh Kumar,Mohammad Sadrosadati,Onur Mutlu*

Main category: cs.AR

Relevance: 30.0

TL;DR: Athena：一个基于强化学习的框架，用于协调多级缓存预取器和片外预测器，以优化内存访问性能


<details>
  <summary>Details</summary>
Motivation: 预取和片外预测是隐藏内存访问延迟的两种技术，但现有方法在协调这两种技术时未能充分发挥其性能潜力，且现有的预取器控制策略仍有很大改进空间

Method: 将预取器和片外预测器的协调建模为强化学习问题，Athena作为RL代理，观察系统级特征（如准确性、带宽使用），选择协调动作（启用/禁用预取器和OCP，调整预取器攻击性），并通过奖励信号持续学习优化策略

Result: 在多种内存密集型工作负载上的广泛评估表明，Athena在各种系统配置下（不同预取器、OCP和内存带宽组合）始终优于现有最先进的协调策略，同时仅产生适中的存储开销

Conclusion: Athena提供了一个有效的强化学习框架，能够自主学习和协调多级缓存预取器与片外预测器，显著提升处理器内存访问性能

Abstract: Prefetching and off-chip prediction are two techniques proposed to hide long memory access latencies in high-performance processors. In this work, we demonstrate that: (1) prefetching and off-chip prediction often provide complementary performance benefits, yet (2) naively combining them often fails to realize their full performance potential, and (3) existing prefetcher control policies leave significant room for performance improvement behind.
  Our goal is to design a holistic framework that can autonomously learn to coordinate an off-chip predictor with multiple prefetchers employed at various cache levels. To this end, we propose a new technique called Athena, which models the coordination between prefetchers and off-chip predictor (OCP) as a reinforcement learning (RL) problem. Athena acts as the RL agent that observes multiple system-level features (e.g., prefetcher/OCP accuracy, bandwidth usage) over an epoch of program execution, and uses them as state information to select a coordination action (i.e., enabling the prefetcher and/or OCP, and adjusting prefetcher aggressiveness). At the end of every epoch, Athena receives a numerical reward that measures the change in multiple system-level metrics (e.g., number of cycles taken to execute an epoch). Athena uses this reward to autonomously and continuously learn a policy to coordinate prefetchers with OCP.
  Our extensive evaluation using a diverse set of memory-intensive workloads shows that Athena consistently outperforms prior state-of-the-art coordination policies across a wide range of system configurations with various combinations of underlying prefetchers, OCPs, and main memory bandwidths, while incurring only modest storage overhead. Athena is freely available at https://github.com/CMU-SAFARI/Athena.

</details>


### [623] [Use of operator defect identities in multi-channel signal plus residual-analysis via iterated products and telescoping energy-residuals: Applications to kernels in machine learning](https://arxiv.org/abs/2601.18080)
*Palle E. T. Jorgensen,Myung-Sin Song,James F. Tian*

Main category: math.FA

Relevance: 30.0

TL;DR: 提出了一种新的算子理论框架，用于分析具有内在组件划分的复杂系统，特别关注"残差"和"望远镜能量残差"，并应用于广义机器学习算法和贪婪核主成分分析。


<details>
  <summary>Details</summary>
Motivation: 现有复杂系统分析方法在处理具有内在组件划分的系统时存在局限性，需要新的理论框架来分析残差结构，特别是在机器学习算法中常见的能量残差问题。

Method: 开发了基于算子理论的数学框架，证明了关于能量残差容许性和有效性的新结果，建立了先验界限。应用包括无限维Kaczmarz理论的λn-松弛变体和λn-有效性分析。

Result: 获得了广义机器学习算法的显式收敛结果、残差能量分解以及噪声下稳定性判据。特别在贪婪核主成分分析中证明了收敛性。

Conclusion: 该算子理论框架为分析具有组件划分的复杂系统提供了有效的数学工具，在机器学习算法分析中具有重要应用价值，能够处理残差结构和收敛性问题。

Abstract: We present a new operator theoretic framework for analysis of complex systems with intrinsic subdivisions into components, taking the form of "residuals" in general, and "telescoping energy residuals" in particular. We prove new results which yield admissibility/effectiveness, and new a priori bounds on energy residuals. Applications include infinite-dimensional Kaczmarz theory for $λ_{n}$-relaxed variants, and $λ_{n}$-effectiveness. And we give applications of our framework to generalized machine learning algorithms, greedy Kernel Principal Component Analysis (KPCA), proving explicit convergence results, residual energy decomposition, and criteria for stability under noise.

</details>


### [624] [Data-Driven Qubit Characterization and Optimal Control using Deep Learning](https://arxiv.org/abs/2601.18704)
*Paul Surrey,Julian D. Teske,Tobias Hangleiter,Hendrik Bluhm,Pascal Cerfontaine*

Main category: quant-ph

Relevance: 30.0

TL;DR: 提出一种基于机器学习（循环神经网络）的量子控制脉冲优化协议，无需详细系统模型即可实现高效梯度优化


<details>
  <summary>Details</summary>
Motivation: 量子计算需要优化控制脉冲以实现高保真度量子门，但传统方法面临梯度评估困难和复杂系统动力学建模的挑战

Method: 1) 使用随机控制脉冲采样量子比特动力学；2) 训练RNN预测量子比特行为；3) 利用训练好的模型进行梯度优化控制脉冲

Result: 在单个ST₀量子比特上通过仿真验证了该方法的有效性

Conclusion: 基于机器学习的协议能够有效解决量子控制脉冲优化问题，无需详细系统模型即可实现高效梯度优化

Abstract: Quantum computing requires the optimization of control pulses to achieve high-fidelity quantum gates. We propose a machine learning-based protocol to address the challenges of evaluating gradients and modeling complex system dynamics. By training a recurrent neural network (RNN) to predict qubit behavior, our approach enables efficient gradient-based pulse optimization without the need for a detailed system model. First, we sample qubit dynamics using random control pulses with weak prior assumptions. We then train the RNN on the system's observed responses, and use the trained model to optimize high-fidelity control pulses. We demonstrate the effectiveness of this approach through simulations on a single $ST_0$ qubit.

</details>


### [625] [Bayesian Robust Financial Trading with Adversarial Synthetic Market Data](https://arxiv.org/abs/2601.17008)
*Haochong Xia,Simin Li,Ruixiao Xu,Zhixia Zhang,Hongxiang Wang,Zhiqian Liu,Teng Yao Long,Molei Qin,Chuqiao Zong,Bo An*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出贝叶斯鲁棒框架，结合宏观条件生成对抗网络和鲁棒策略学习，解决算法交易中模型对市场动态变化的适应性问题。


<details>
  <summary>Details</summary>
Motivation: 算法交易模型在样本内表现良好，但在真实市场动态变化时性能下降。现有方法存在两个问题：1) 对高层市场波动的鲁棒性不足；2) 缺乏真实多样的模拟环境导致策略过拟合。

Method: 提出贝叶斯鲁棒框架：1) 数据侧：使用宏观条件GAN生成器，以宏观经济指标为控制变量，合成具有时间、跨工具和宏观相关性的数据；2) 策略侧：将交易过程建模为两人零和贝叶斯马尔可夫博弈，对抗代理通过扰动宏观指标模拟市场变化，交易代理通过分位数信念网络维护和更新对隐藏市场状态的信念，使用贝叶斯神经虚拟自博弈寻找鲁棒完美贝叶斯均衡。

Result: 在9种金融工具上的实验表明，该框架优于9种最先进的基线方法。在COVID等极端事件中，该方法显示出改进的盈利能力和风险管理能力。

Conclusion: 该框架为不确定和变化的市场动态下的交易提供了可靠解决方案，通过系统整合宏观条件生成模型和鲁棒策略学习，解决了算法交易中的鲁棒性和过拟合问题。

Abstract: Algorithmic trading relies on machine learning models to make trading decisions. Despite strong in-sample performance, these models often degrade when confronted with evolving real-world market regimes, which can shift dramatically due to macroeconomic changes-e.g., monetary policy updates or unanticipated fluctuations in participant behavior. We identify two challenges that perpetuate this mismatch: (1) insufficient robustness in existing policy against uncertainties in high-level market fluctuations, and (2) the absence of a realistic and diverse simulation environment for training, leading to policy overfitting. To address these issues, we propose a Bayesian Robust Framework that systematically integrates a macro-conditioned generative model with robust policy learning. On the data side, to generate realistic and diverse data, we propose a macro-conditioned GAN-based generator that leverages macroeconomic indicators as primary control variables, synthesizing data with faithful temporal, cross-instrument, and macro correlations. On the policy side, to learn robust policy against market fluctuations, we cast the trading process as a two-player zero-sum Bayesian Markov game, wherein an adversarial agent simulates shifting regimes by perturbing macroeconomic indicators in the macro-conditioned generator, while the trading agent-guided by a quantile belief network-maintains and updates its belief over hidden market states. The trading agent seeks a Robust Perfect Bayesian Equilibrium via Bayesian neural fictitious self-play, stabilizing learning under adversarial market perturbations. Extensive experiments on 9 financial instruments demonstrate that our framework outperforms 9 state-of-the-art baselines. In extreme events like the COVID, our method shows improved profitability and risk management, offering a reliable solution for trading under uncertain and shifting market dynamics.

</details>


### [626] [Attention-Based Variational Framework for Joint and Individual Components Learning with Applications in Brain Network Analysis](https://arxiv.org/abs/2601.17073)
*Yifei Zhang,Meimei Liu,Zhengwu Zhang*

Main category: cs.LG

Relevance: 25.0

TL;DR: CM-JIVNet是一个用于多模态脑连接组分析的统一概率框架，通过因子化潜在表示学习，分离共享和模态特定信息，在SC-FC数据上表现出色。


<details>
  <summary>Details</summary>
Motivation: 脑组织通过多种成像模态（结构连接SC和功能连接FC）表征，整合这些互补数据源对于揭示行为表型的跨模态模式至关重要。但整合面临高维非线性、复杂SC-FC耦合、以及分离共享与模态特定信息的挑战。

Method: 提出跨模态联合-个体变分网络（CM-JIVNet），使用多头注意力融合模块捕获非线性跨模态依赖，同时分离独立的模态特定信号，学习因子化潜在表示。

Result: 在HCP-YA数据上验证，CM-JIVNet在跨模态重建和行为特征预测方面表现优异，有效分离联合和个体特征空间。

Conclusion: CM-JIVNet为大规模多模态脑分析提供了鲁棒、可解释、可扩展的解决方案，通过解耦联合和个体特征空间实现更好的整合。

Abstract: Brain organization is increasingly characterized through multiple imaging modalities, most notably structural connectivity (SC) and functional connectivity (FC). Integrating these inherently distinct yet complementary data sources is essential for uncovering the cross-modal patterns that drive behavioral phenotypes. However, effective integration is hindered by the high dimensionality and non-linearity of connectome data, complex non-linear SC-FC coupling, and the challenge of disentangling shared information from modality-specific variations. To address these issues, we propose the Cross-Modal Joint-Individual Variational Network (CM-JIVNet), a unified probabilistic framework designed to learn factorized latent representations from paired SC-FC datasets. Our model utilizes a multi-head attention fusion module to capture non-linear cross-modal dependencies while isolating independent, modality-specific signals. Validated on Human Connectome Project Young Adult (HCP-YA) data, CM-JIVNet demonstrates superior performance in cross-modal reconstruction and behavioral trait prediction. By effectively disentangling joint and individual feature spaces, CM-JIVNet provides a robust, interpretable, and scalable solution for large-scale multimodal brain analysis.

</details>


### [627] [CUROCKET: Optimizing ROCKET for GPU](https://arxiv.org/abs/2601.17091)
*Ole Stüven,Keno Moenck,Thorsten Schüppstuhl*

Main category: cs.LG

Relevance: 25.0

TL;DR: CUROCKET：一种在GPU上高效执行ROCKET时间序列分类算法的实现，相比CPU版本实现高达11倍的每瓦计算效率提升。


<details>
  <summary>Details</summary>
Motivation: ROCKET算法在时间序列分类中表现出色，但现有实现主要限于CPU执行。卷积操作具有高度并行性，适合GPU加速，但ROCKET使用的不均匀核使得标准GPU卷积方法效率低下。

Method: 提出一种能够在GPU上高效执行ROCKET的算法，解决不均匀核导致的效率问题，实现GPU加速的ROCKET特征提取。

Result: CUROCKET在GPU上实现了高达11倍的每瓦计算效率提升，相比CPU版本的ROCKET显著提高了计算性能。

Conclusion: 该工作成功将ROCKET算法移植到GPU平台，大幅提升了计算效率，为时间序列分类提供了更高效的解决方案。

Abstract: ROCKET (RandOm Convolutional KErnel Transform) is a feature extraction algorithm created for Time Series Classification (TSC), published in 2019. It applies convolution with randomly generated kernels on a time series, producing features that can be used to train a linear classifier or regressor like Ridge. At the time of publication, ROCKET was on par with the best state-of-the-art algorithms for TSC in terms of accuracy while being significantly less computationally expensive, making ROCKET a compelling algorithm for TSC. This also led to several subsequent versions, further improving accuracy and computational efficiency. The currently available ROCKET implementations are mostly bound to execution on CPU. However, convolution is a task that can be highly parallelized and is therefore suited to be executed on GPU, which speeds up the computation significantly. A key difficulty arises from the inhomogeneous kernels ROCKET uses, making standard methods for applying convolution on GPU inefficient. In this work, we propose an algorithm that is able to efficiently perform ROCKET on GPU and achieves up to 11 times higher computational efficiency per watt than ROCKET on CPU. The code for CUROCKET is available in this repository https://github.com/oleeven/CUROCKET on github.

</details>


### [628] [PUNCH: Physics-informed Uncertainty-aware Network for Coronary Hemodynamics](https://arxiv.org/abs/2601.17192)
*Sukirt Thakur,Marcus Roper,Yang Zhou,Reza Akbarian Bafghi,Brahmajee K. Nallamothu,C. Alberto Figueroa,Srinivas Paruchuri,Scott Burger,Maziar Raissi*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出了一种基于物理信息神经网络和变分推断的非侵入性冠状动脉血流储备估计框架，可直接从标准血管造影中计算，无需真实血流测量，为冠状动脉微血管功能障碍提供可扩展的诊断方法。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉微血管功能障碍（CMD）影响全球数百万人，但现有金标准生理测量方法具有侵入性且可重复性差，需要开发非侵入性、可扩展的诊断方法。

Method: 结合物理信息神经网络与变分推断，从造影剂传输的第一性原理模型推断冠状动脉血流，无需真实血流测量数据，整个流程在单个GPU上约3分钟完成，无需群体级训练。

Result: 在1000个合成时空强度图中可靠识别退化数据并输出适当的不确定性估计；临床验证显示与侵入性热稀释法有强相关性（Pearson r=0.90）；概率CFR估计的置信区间小于重复侵入性测量的变异性。

Conclusion: 该框架将常规血管造影转化为定量、不确定性感知的评估，实现可扩展、更安全、更可重复的冠状动脉微血管功能评估，有望扩大CMD诊断的可及性。

Abstract: Coronary microvascular dysfunction (CMD) affects millions worldwide yet remains underdiagnosed because gold-standard physiological measurements are invasive and variably reproducible. We introduce a non-invasive, uncertainty-aware framework for estimating coronary flow reserve (CFR) directly from standard angiography. The system integrates physics-informed neural networks with variational inference to infer coronary blood flow from first-principles models of contrast transport, without requiring ground-truth flow measurements. The pipeline runs in approximately three minutes per patient on a single GPU, with no population-level training.
  Using 1{,}000 synthetic spatiotemporal intensity maps (kymographs) with controlled noise and artifacts, the framework reliably identifies degraded data and outputs appropriately inflated uncertainty estimates, showing strong correspondence between predictive uncertainty and error (Pearson $r = 0.997$, Spearman $ρ= 0.998$). Clinical validation in 12 patients shows strong agreement between PUNCH-derived CFR and invasive bolus thermodilution (Pearson $r = 0.90$, $p = 6.3 \times 10^{-5}$). We focus on the LAD, the artery most commonly assessed in routine CMD testing. Probabilistic CFR estimates have confidence intervals narrower than the variability of repeated invasive measurements.
  By transforming routine angiography into quantitative, uncertainty-aware assessment, this approach enables scalable, safer, and more reproducible evaluation of coronary microvascular function. Because standard angiography is widely available globally, the framework could expand access to CMD diagnosis and establish a new paradigm for physics-informed, patient-specific inference from clinical imaging.

</details>


### [629] [SpecBridge: Bridging Mass Spectrometry and Molecular Representations via Cross-Modal Alignment](https://arxiv.org/abs/2601.17204)
*Yinkai Wang,Yan Zhou Chen,Xiaohui Chen,Li-Ping Liu,Soha Hassoun*

Main category: cs.LG

Relevance: 25.0

TL;DR: SpecBridge是一个用于小分子质谱识别的隐式对齐框架，通过将质谱编码器投影到冻结的分子基础模型潜在空间，显著提高了检索准确性。


<details>
  <summary>Details</summary>
Motivation: 在非靶向质谱分析中，小分子识别是一个瓶颈，因为谱库不完整。现有深度学习方法要么是显式生成模型（原子级构建分子图），要么是从头学习的联合对比模型，存在局限性。

Method: 提出SpecBridge框架，将结构识别视为几何对齐问题。微调自监督质谱编码器（DreaMS），使其直接投影到冻结的分子基础模型（ChemBERTa）的潜在空间，然后通过余弦相似度在预计算的分子嵌入库中进行检索。

Result: 在MassSpecGym、Spectraverse和MSnLib基准测试中，SpecBridge相比强基线神经网络方法，将top-1检索准确率提高了约20-25%，同时保持可训练参数数量较少。

Conclusion: 与从头设计新架构相比，对齐到冻结的基础模型是一种实用、稳定的替代方案。该方法在保持高效的同时显著提升了小分子识别性能。

Abstract: Small-molecule identification from tandem mass spectrometry (MS/MS) remains a bottleneck in untargeted settings where spectral libraries are incomplete. While deep learning offers a solution, current approaches typically fall into two extremes: explicit generative models that construct molecular graphs atom-by-atom, or joint contrastive models that learn cross-modal subspaces from scratch. We introduce SpecBridge, a novel implicit alignment framework that treats structure identification as a geometric alignment problem. SpecBridge fine-tunes a self-supervised spectral encoder (DreaMS) to project directly into the latent space of a frozen molecular foundation model (ChemBERTa), and then performs retrieval by cosine similarity to a fixed bank of precomputed molecular embeddings. Across MassSpecGym, Spectraverse, and MSnLib benchmarks, SpecBridge improves top-1 retrieval accuracy by roughly 20-25% relative to strong neural baselines, while keeping the number of trainable parameters small. These results suggest that aligning to frozen foundation models is a practical, stable alternative to designing new architectures from scratch. The code for SpecBridge is released at https://github.com/HassounLab/SpecBridge.

</details>


### [630] [NewPINNs: Physics-Informing Neural Networks Using Conventional Solvers for Partial Differential Equations](https://arxiv.org/abs/2601.17207)
*Maedeh Makki,Satish Chandran,Maziar Raissi,Adrien Grenier,Behzad Mohebbi*

Main category: cs.LG

Relevance: 25.0

TL;DR: NewPINNs提出了一种将神经网络与传统数值求解器耦合的物理信息学习框架，通过求解器一致性而非残差损失来训练神经网络求解微分方程。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络(PINNs)存在优化病理、损失权重敏感、在刚性或非线性区域表现差等问题，需要设计复杂的损失函数。NewPINNs旨在通过将数值求解器直接集成到训练循环中，让求解器强制执行物理约束，从而克服这些限制。

Method: 框架将神经网络与数值求解器耦合：神经网络生成候选解状态，数值求解器推进这些状态，训练目标是最小化网络预测与求解器演化状态之间的差异。这种"拉-推"交互让网络通过重复暴露于求解器作用来学习物理可接受的解，无需设计问题特定的损失函数或显式计算微分方程残差。

Result: NewPINNs在涉及有限体积、有限元和谱求解器的多个正向和逆向问题中表现出有效性，能够减轻标准PINNs的多个已知失效模式。

Conclusion: 通过将物理约束、边界条件和数值稳定性的强制执行委托给成熟的数值求解器，NewPINNs提供了一种更稳健的物理信息学习方法，避免了传统PINNs的许多问题。

Abstract: We introduce NewPINNs, a physics-informing learning framework that couples neural networks with conventional numerical solvers for solving differential equations. Rather than enforcing governing equations and boundary conditions through residual-based loss terms, NewPINNs integrates the solver directly into the training loop and defines learning objectives through solver-consistency. The neural network produces candidate solution states that are advanced by the numerical solver, and training minimizes the discrepancy between the network prediction and the solver-evolved state. This pull-push interaction enables the network to learn physically admissible solutions through repeated exposure to the solver's action, without requiring problem-specific loss engineering or explicit evaluation of differential equation residuals. By delegating the enforcement of physics, boundary conditions, and numerical stability to established numerical solvers, NewPINNs mitigates several well-known failure modes of standard physics-informed neural networks, including optimization pathologies, sensitivity to loss weighting, and poor performance in stiff or nonlinear regimes. We demonstrate the effectiveness of the proposed approach across multiple forward and inverse problems involving finite volume, finite element, and spectral solvers.

</details>


### [631] [A Mosco sufficient condition for intrinsic stability of non-unique convex Empirical Risk Minimization](https://arxiv.org/abs/2601.17646)
*Karim Bounja,Lahcen Laayouni,Abdeljalil Sakat*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该论文研究了经验风险最小化（ERM）的稳定性问题，特别关注非严格凸损失函数导致集值最小化器的情况。论文提出了Painlevé-Kuratowski上半连续性作为ERM解对应的内在稳定性概念，并分析了在最小非退化条件下的稳定性保证。


<details>
  <summary>Details</summary>
Motivation: 传统ERM稳定性研究通常假设单值输出，但实际中凸非严格损失函数会产生集值最小化器。需要建立适用于集值情况的稳定性理论框架，为选择稳定性提供理论基础。

Method: 采用集值分析理论，将Painlevé-Kuratowski上半连续性定义为ERM解对应的内在稳定性概念。在Mosco一致性扰动和局部有界最小化器的条件下，证明了PK上半连续性、最小值连续性和消失间隙近最小化器的一致性。

Result: 建立了ERM解对应稳定性的完整理论框架：在最小非退化条件下（Mosco一致性扰动+局部有界最小化器），ERM解对应具有PK上半连续性、最小值连续性和近最小化器一致性。二次增长条件可导出显式定量偏差界。

Conclusion: PK上半连续性是ERM解对应的内在稳定性概念，为理解选择稳定性提供了先决条件。论文建立了最小非退化条件下的稳定性理论，为ERM的鲁棒性分析提供了理论基础。

Abstract: Empirical risk minimization (ERM) stability is usually studied via single-valued outputs, while convex non-strict losses yield set-valued minimizers. We identify Painlevé-Kuratowski upper semicontinuity (PK-u.s.c.) as the intrinsic stability notion for the ERM solution correspondence (set-level Hadamard well-posedness) and a prerequisite to interpret stability of selections. We then characterize a minimal non-degenerate qualitative regime: Mosco-consistent perturbations and locally bounded minimizers imply PK-u.s.c., minimal-value continuity, and consistency of vanishing-gap near-minimizers. Quadratic growth yields explicit quantitative deviation bounds.

</details>


### [632] [Time-Varying Causal Treatment for Quantifying the Causal Effect of Short-Term Variations on Arctic Sea Ice Dynamics](https://arxiv.org/abs/2601.17647)
*Akila Sampath,Vandana Janeja,Jianwu Wang*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出KGCM-VAE框架，通过知识引导的因果建模量化海冰厚度与海表面高度之间的因果关系，结合物理约束和分布平衡机制提升时空因果效应估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 量化冰融与淡水分布的因果关系对理解极地气候变化和全球海平面上升至关重要。传统深度学习模型在时空因果效应估计中面临未观测混杂变量和缺乏物理约束的挑战。

Method: 提出知识引导的因果模型变分自编码器（KGCM-VAE），包含：1）速度调制方案，通过SSH转换控制的sigmoid函数动态放大平滑速度信号生成物理基础的因果处理；2）最大均值差异（MMD）平衡潜在空间中处理组和对照组的协变量分布；3）因果邻接约束解码器确保与已知物理结构对齐。

Result: 在合成和真实北极数据集上的实验表明，KGCM-VAE在PEHE指标上优于现有基准方法。消融研究证实MMD和因果邻接约束的联合应用使估计误差降低1.88%。

Conclusion: KGCM-VAE通过整合物理知识和因果推断技术，有效解决了时空环境中的因果效应估计问题，为极地气候变化的机制理解提供了可靠工具。

Abstract: Quantifying the causal relationship between ice melt and freshwater distribution is critical, as these complex interactions manifest as regional fluctuations in sea surface height (SSH). Leveraging SSH as a proxy for sea ice dynamics enables improved understanding of the feedback mechanisms driving polar climate change and global sea-level rise. However, conventional deep learning models often struggle with reliable treatment effect estimation in spatiotemporal settings due to unobserved confounders and the absence of physical constraints. To address these challenges, we propose the Knowledge-Guided Causal Model Variational Autoencoder (KGCM-VAE) to quantify causal mechanisms between sea ice thickness and SSH. The proposed framework integrates a velocity modulation scheme in which smoothed velocity signals are dynamically amplified via a sigmoid function governed by SSH transitions to generate physically grounded causal treatments. In addition, the model incorporates Maximum Mean Discrepancy (MMD) to balance treated and control covariate distributions in the latent space, along with a causal adjacency-constrained decoder to ensure alignment with established physical structures. Experimental results on both synthetic and real-world Arctic datasets demonstrate that KGCM-VAE achieves superior PEHE compared to state-of-the-art benchmarks. Ablation studies further confirm the effectiveness of the approach, showing that the joint application of MMD and causal adjacency constraints yields a 1.88\% reduction in estimation error.

</details>


### [633] [Entropic Risk-Aware Monte Carlo Tree Search](https://arxiv.org/abs/2601.17667)
*Pedro P. Santos,Jacopo Silvestrin,Alberto Sardinha,Francisco S. Melo*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出一种可证明正确的蒙特卡洛树搜索算法，用于求解具有熵风险度量的风险感知马尔可夫决策过程，提供非渐近分析证明算法正确性和多项式遗憾集中性。


<details>
  <summary>Details</summary>
Motivation: 现有风险感知MDP求解方法缺乏可证明正确的树搜索算法，特别是在非渐近分析方面存在不足。需要开发能够处理熵风险度量并具有理论保证的MCTS算法。

Method: 基于置信上界的蒙特卡洛树搜索算法，利用先前工作中引入的动态规划公式求解具有熵风险度量的风险感知MDP。算法结合了风险感知MDP的DP公式和UCB树搜索框架。

Result: 算法被证明是正确的（根节点经验熵风险度量收敛到最优值），且具有多项式遗憾集中性。实验表明风险感知MCTS方法优于相关基线。

Conclusion: 成功开发了第一个可证明正确的风险感知MCTS算法，为具有熵风险度量的风险感知MDP提供了具有理论保证的求解方法，填补了该领域空白。

Abstract: We propose a provably correct Monte Carlo tree search (MCTS) algorithm for solving \textit{risk-aware} Markov decision processes (MDPs) with \textit{entropic risk measure} (ERM) objectives. We provide a \textit{non-asymptotic} analysis of our proposed algorithm, showing that the algorithm: (i) is \textit{correct} in the sense that the empirical ERM obtained at the root node converges to the optimal ERM; and (ii) enjoys \textit{polynomial regret concentration}. Our algorithm successfully exploits the dynamic programming formulations for solving risk-aware MDPs with ERM objectives introduced by previous works in the context of an upper confidence bound-based tree search algorithm. Finally, we provide a set of illustrative experiments comparing our risk-aware MCTS method against relevant baselines.

</details>


### [634] [Smooth, Sparse, and Stable: Finite-Time Exact Skeleton Recovery via Smoothed Proximal Gradients](https://arxiv.org/abs/2601.18189)
*Rui Wu,Yongjun Li*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出了AHOC混合阶无环约束和SPG-AHOC平滑近端梯度优化方法，在有限迭代内精确恢复DAG结构，无需启发式截断


<details>
  <summary>Details</summary>
Motivation: 现有因果发现方法（如NOTEARS）通常只能保证渐近收敛到平稳点，产生稠密权重矩阵，需要任意后处理阈值化来恢复DAG。连续优化与离散图结构之间的差距是根本挑战。

Method: 提出混合阶无环约束（AHOC），通过平滑近端梯度（SPG-AHOC）进行优化。利用近端算法的流形识别特性，提供严格的理论保证：有限时间预言性质。

Result: 在标准可识别性假设下，SPG-AHOC在有限迭代内恢复精确的DAG支持（结构），即使优化的是平滑近似。算法返回具有精确零条目的图，无需启发式截断。实证结果达到最先进精度。

Conclusion: 该方法弥合了连续优化与离散图结构之间的差距，通过理论保证在有限时间内精确恢复DAG结构，解决了现有方法的结构模糊性问题。

Abstract: Continuous optimization has significantly advanced causal discovery, yet existing methods (e.g., NOTEARS) generally guarantee only asymptotic convergence to a stationary point. This often yields dense weighted matrices that require arbitrary post-hoc thresholding to recover a DAG. This gap between continuous optimization and discrete graph structures remains a fundamental challenge. In this paper, we bridge this gap by proposing the Hybrid-Order Acyclicity Constraint (AHOC) and optimizing it via the Smoothed Proximal Gradient (SPG-AHOC). Leveraging the Manifold Identification Property of proximal algorithms, we provide a rigorous theoretical guarantee: the Finite-Time Oracle Property. We prove that under standard identifiability assumptions, SPG-AHOC recovers the exact DAG support (structure) in finite iterations, even when optimizing a smoothed approximation. This result eliminates structural ambiguity, as our algorithm returns graphs with exact zero entries without heuristic truncation. Empirically, SPG-AHOC achieves state-of-the-art accuracy and strongly corroborates the finite-time identification theory.

</details>


### [635] [Tractable Gaussian Phase Retrieval with Heavy Tails and Adversarial Corruption with Near-Linear Sample Complexity](https://arxiv.org/abs/2601.18245)
*Santanu Das,Jatin Batra*

Main category: cs.LG

Relevance: 25.0

TL;DR: 该论文提出了首个多项式时间算法，用于解决具有重尾噪声和对抗性损坏的鲁棒相位恢复问题，实现了接近线性的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 相位恢复是一个经典问题，在许多领域有重要应用。现有算法在存在重尾噪声和对抗性损坏时效率低下，最近的研究只能提供指数时间算法。本文旨在开发高效的多项式时间算法来解决这一挑战。

Method: 通过建立鲁棒谱初始化与鲁棒PCA最新算法进展之间的联系，利用鲁棒PCA技术来获得鲁棒的谱初始化，这是相位恢复算法的关键组成部分。该方法能够处理测量值和传感向量同时被对抗性损坏的情况。

Result: 提出了首个多项式时间算法，用于解决具有重尾噪声和对抗性损坏的鲁棒相位恢复问题，实现了O(n log n)的样本复杂度，相比之前的指数时间算法有显著改进。

Conclusion: 通过将鲁棒谱初始化问题与鲁棒PCA联系起来，成功开发了高效的多项式时间算法，解决了鲁棒相位恢复中的关键计算瓶颈，为实际应用提供了可行的解决方案。

Abstract: Phase retrieval is the classical problem of recovering a signal $x^* \in \mathbb{R}^n$ from its noisy phaseless measurements $y_i = \langle a_i, x^* \rangle^2 + ζ_i$ (where $ζ_i$ denotes noise, and $a_i$ is the sensing vector) for $i \in [m]$. The problem of phase retrieval has a rich history, with a variety of applications such as optics, crystallography, heteroscedastic regression, astrophysics, etc. A major consideration in algorithms for phase retrieval is robustness against measurement errors. In recent breakthroughs in algorithmic robust statistics, efficient algorithms have been developed for several parameter estimation tasks such as mean estimation, covariance estimation, robust principal component analysis (PCA), etc. in the presence of heavy-tailed noise and adversarial corruptions. In this paper, we study efficient algorithms for robust phase retrieval with heavy-tailed noise when a constant fraction of both the measurements $y_i$ and the sensing vectors $a_i$ may be arbitrarily adversarially corrupted. For this problem, Buna and Rebeschini (AISTATS 2025) very recently gave an exponential time algorithm with sample complexity $O(n \log n)$. Their algorithm needs a robust spectral initialization, specifically, a robust estimate of the top eigenvector of a covariance matrix, which they deemed to be beyond known efficient algorithmic techniques (similar spectral initializations are a key ingredient of a large family of phase retrieval algorithms). In this work, we make a connection between robust spectral initialization and recent algorithmic advances in robust PCA, yielding the first polynomial-time algorithms for robust phase retrieval with both heavy-tailed noise and adversarial corruptions, in fact with near-linear (in $n$) sample complexity.

</details>


### [636] [LaCoGSEA: Unsupervised deep learning for pathway analysis via latent correlation](https://arxiv.org/abs/2601.18604)
*Zhiwei Zheng,Kevin Bryson*

Main category: cs.LG

Relevance: 25.0

TL;DR: 提出LaCoGSEA框架，将深度表示学习与稳健通路统计结合，用于无监督通路富集分析，无需表型标签即可捕获非线性转录组结构并识别生物学相关通路。


<details>
  <summary>Details</summary>
Motivation: 传统通路富集分析方法（如GSEA）依赖预定义表型标签和成对比较，限制了在无监督设置中的应用。现有无监督扩展方法主要捕获线性关系，而深度学习模型虽能捕获非线性结构，但其解释性依赖通用XAI技术，在通路级解释方面效果有限。

Method: LaCoGSEA使用自编码器捕获非线性流形，提出全局基因-潜在相关性度量作为差异表达的代理，无需先验标签即可生成密集基因排名。框架整合深度表示学习与稳健通路统计。

Result: 1) 在区分癌症亚型方面比现有无监督基线获得更好的聚类性能；2) 与线性降维和基于梯度的XAI方法相比，在更高排名恢复更广泛的生物学有意义通路；3) 在不同实验方案和数据集大小下保持高稳健性和一致性。

Conclusion: LaCoGSEA在无监督通路富集分析中提供最先进的性能，为无标签转录组数据分析提供了有效的非线性通路解释框架。

Abstract: Motivation: Pathway enrichment analysis is widely used to interpret gene expression data. Standard approaches, such as GSEA, rely on predefined phenotypic labels and pairwise comparisons, which limits their applicability in unsupervised settings. Existing unsupervised extensions, including single-sample methods, provide pathway-level summaries but primarily capture linear relationships and do not explicitly model gene-pathway associations. More recently, deep learning models have been explored to capture non-linear transcriptomic structure. However, their interpretation has typically relied on generic explainable AI (XAI) techniques designed for feature-level attribution. As these methods are not designed for pathway-level interpretation in unsupervised transcriptomic analyses, their effectiveness in this setting remains limited.
  Results: To bridge this gap, we introduce LaCoGSEA (Latent Correlation GSEA), an unsupervised framework that integrates deep representation learning with robust pathway statistics. LaCoGSEA employs an autoencoder to capture non-linear manifolds and proposes a global gene-latent correlation metric as a proxy for differential expression, generating dense gene rankings without prior labels. We demonstrate that LaCoGSEA offers three key advantages: (i) it achieves improved clustering performance in distinguishing cancer subtypes compared to existing unsupervised baselines; (ii) it recovers a broader range of biologically meaningful pathways at higher ranks compared with linear dimensionality reduction and gradient-based XAI methods; and (iii) it maintains high robustness and consistency across varying experimental protocols and dataset sizes. Overall, LaCoGSEA provides state-of-the-art performance in unsupervised pathway enrichment analysis.
  Availability and implementation: https://github.com/willyzzz/LaCoGSEA

</details>


### [637] [XGuardian: Towards Explainable and Generalized AI Anti-Cheat on FPS Games](https://arxiv.org/abs/2601.18068)
*Jiayi Zhang,Chenxin Sun,Chenxiong Qian*

Main category: cs.CR

Relevance: 25.0

TL;DR: XGuardian是一个用于检测FPS游戏中自瞄作弊的服务器端系统，通过分析俯仰角和偏航角数据构建时序特征来区分作弊者和正常玩家，具有高检测性能、低开销和可解释性。


<details>
  <summary>Details</summary>
Motivation: 自瞄作弊是FPS游戏中最普遍和臭名昭著的作弊形式，严重威胁游戏产业。现有检测方法存在框架不可靠、泛化性有限、开销高、检测性能低以及缺乏结果可解释性等问题。

Method: XGuardian仅需要俯仰角和偏航角两个原始数据输入，构建新颖的时序特征来描述瞄准轨迹，这些特征是区分作弊者和正常玩家的关键。系统在服务器端运行，具有通用性和可解释性。

Result: 在CS2等主流FPS游戏中评估，验证了跨游戏泛化能力。相比先前工作，在不同游戏的现实世界大规模数据集上实现了高检测性能和低开销，展示了广泛的泛化性和高效性。

Conclusion: XGuardian能够证明其预测结果的合理性，从而缩短封禁周期。该系统及其数据集已公开可用，为解决FPS游戏中的自瞄作弊问题提供了有效的解决方案。

Abstract: Aim-assist cheats are the most prevalent and infamous form of cheating in First-Person Shooter (FPS) games, which help cheaters illegally reveal the opponent's location and auto-aim and shoot, and thereby pose significant threats to the game industry. Although a considerable research effort has been made to automatically detect aim-assist cheats, existing works suffer from unreliable frameworks, limited generalizability, high overhead, low detection performance, and a lack of explainability of detection results. In this paper, we propose XGuardian, a server-side generalized and explainable system for detecting aim-assist cheats to overcome these limitations. It requires only two raw data inputs, pitch and yaw, which are all FPS games' must-haves, to construct novel temporal features and describe aim trajectories, which are essential for distinguishing cheaters and normal players. XGuardian is evaluated with the latest mainstream FPS game CS2, and validates its generalizability with another two different games. It achieves high detection performance and low overhead compared to prior works across different games with real-world and large-scale datasets, demonstrating wide generalizability and high effectiveness. It is able to justify its predictions and thereby shorten the ban cycle. We make XGuardian as well as our datasets publicly available.

</details>


### [638] [Nonlinear multi-study factor analysis](https://arxiv.org/abs/2601.18128)
*Gemma E. Moran,Anandi Krishnan*

Main category: stat.ML

Relevance: 25.0

TL;DR: 提出了一种用于多研究基因表达数据的非线性多研究因子模型，使用稀疏变分自编码器分离共享因子和特定研究因子，并在血小板基因表达数据中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 高维数据（如多研究基因表达数据）通常包含共享和特定研究的潜在因子。现有方法难以同时识别这两种因子，特别是在非线性设置下。本文旨在开发一个能自动分离共享和特定研究因子的模型，以更好地理解生物过程中的共同和特异性机制。

Method: 提出非线性多研究因子模型，使用多研究稀疏变分自编码器进行拟合。模型具有稀疏性：每个观测特征仅依赖于少数潜在因子。模型隐式惩罚潜在因子数量，帮助分离共享因子和特定研究因子。证明了潜在因子的可识别性。

Result: 方法在血小板基因表达数据中恢复了有意义的因子，成功识别了共享的生物通路和疾病特异性通路。模型能够有效分离共同因子和特定研究因子。

Conclusion: 提出的多研究稀疏变分自编码器能够有效识别高维多研究数据中的共享和特定研究因子，在基因表达数据分析中展示了实用价值。

Abstract: High-dimensional data often exhibit variation that can be captured by lower dimensional factors. For high-dimensional data from multiple studies or environments, one goal is to understand which underlying factors are common to all studies, and which factors are study or environment-specific. As a particular example, we consider platelet gene expression data from patients in different disease groups. In this data, factors correspond to clusters of genes which are co-expressed; we may expect some clusters (or biological pathways) to be active for all diseases, while some clusters are only active for a specific disease. To learn these factors, we consider a nonlinear multi-study factor model, which allows for both shared and specific factors. To fit this model, we propose a multi-study sparse variational autoencoder. The underlying model is sparse in that each observed feature (i.e. each dimension of the data) depends on a small subset of the latent factors. In the genomics example, this means each gene is active in only a few biological processes. Further, the model implicitly induces a penalty on the number of latent factors, which helps separate the shared factors from the group-specific factors. We prove that the latent factors are identified, and demonstrate our method recovers meaningful factors in the platelet gene expression data.

</details>


### [639] [Learned harmonic mean estimation of the marginal likelihood for multimodal posteriors with flow matching](https://arxiv.org/abs/2601.18683)
*Alicja Polanska,Jason D. McEwen*

Main category: stat.ME

Relevance: 25.0

TL;DR: 本文提出使用流匹配连续归一化流作为学习调和平均估计器的内部密度估计架构，以处理多模态后验分布，从而改进边际似然计算。


<details>
  <summary>Details</summary>
Motivation: 边际似然（贝叶斯证据）对于贝叶斯模型比较至关重要，但计算复杂模型时具有挑战性。现有的学习调和平均估计器虽然能使用后验样本准确估计边际似然，但其内部密度估计器在处理高度多模态后验时存在困难。

Method: 引入基于流匹配的连续归一化流作为学习调和平均估计器的内部密度估计架构。该方法能够处理复杂的多模态后验分布，包括20维参数空间的示例，无需对基分布进行微调或启发式修改。

Result: 展示了该方法处理挑战性多模态后验的能力，包括20维参数空间的示例，证明其能够处理复杂后验而无需对基分布进行微调或启发式修改。

Conclusion: 基于流匹配的连续归一化流为学习调和平均估计器提供了强大的内部密度估计架构，显著提升了处理多模态后验分布的能力，从而改进了边际似然计算和贝叶斯模型比较。

Abstract: The marginal likelihood, or Bayesian evidence, is a crucial quantity for Bayesian model comparison but its computation can be challenging for complex models, even in parameters space of moderate dimension. The learned harmonic mean estimator has been shown to provide accurate and robust estimates of the marginal likelihood simply using posterior samples. It is agnostic to the sampling strategy, meaning that the samples can be obtained using any method. This enables marginal likelihood calculation and model comparison with whatever sampling is most suitable for the task. However, the internal density estimators considered previously for the learned harmonic mean can struggle with highly multimodal posteriors. In this work we introduce flow matching-based continuous normalizing flows as a powerful architecture for the internal density estimation of the learned harmonic mean. We demonstrate the ability to handle challenging multimodal posteriors, including an example in 20 parameter dimensions, showcasing the method's ability to handle complex posteriors without the need for fine-tuning or heuristic modifications to the base distribution.

</details>


### [640] [LLAMA LIMA: A Living Meta-Analysis on the Effects of Generative AI on Learning Mathematics](https://arxiv.org/abs/2601.18685)
*Anselm Strohmaier,Samira Bödefeld,Frank Reinhold*

Main category: math.HO

Relevance: 25.0

TL;DR: 本文提出了一种用于数学教育中生成式AI干预效果的"活体元分析"(LIMA)方法，通过持续更新文献库和贝叶斯多层元回归模型来分析累积数据，初步结果显示生成式AI对数学学习有小幅正向效果(g=0.31)。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在数学教育中的能力快速发展，传统研究综述难以跟上发展速度，存在发表即过时的风险。需要一种能够持续更新的分析方法来跟踪这一快速发展的领域。

Method: 采用"活体元分析"(LIMA)方法，遵循PRISMA-LSR指南，持续更新文献库，应用贝叶斯多层元回归模型处理累积数据，定期在预印本服务器上发布更新版本。

Result: 基于第一版15项研究的分析显示，生成式AI对数学学习有小的正向效应(g=0.31)，但可信区间较宽[0.06, 0.58]，反映了当前证据基础仍然有限。

Conclusion: LIMA方法能够有效应对快速发展的生成式AI教育研究领域，初步结果表明生成式AI对数学学习有积极影响，但需要更多研究来获得更精确的效应估计。

Abstract: The capabilities of generative AI in mathematics education are rapidly evolving, posing significant challenges for research to keep pace. Research syntheses remain scarce and risk being outdated by the time of publication. To address this issue, we present a Living Meta-Analysis (LIMA) on the effects of generative AI-based interventions for learning mathematics. Following PRISMA-LSR guidelines, we continuously update the literature base, apply a Bayesian multilevel meta-regression model to account for cumulative data, and publish updated versions on a preprint server at regular intervals. This paper reports results from the first version, including 15 studies. The analyses indicate a small positive effect (g = 0.31) with a wide credible interval [0.06, 0.58], reflecting the still limited evidence base.

</details>


### [641] [Analysis of voice recordings features for Classification of Parkinson's Disease](https://arxiv.org/abs/2601.17007)
*Beatriz Pérez-Sánchez,Noelia Sánchez-Maroño,Miguel A. Díaz-Freire*

Main category: cs.LG

Relevance: 15.0

TL;DR: 该论文提出使用机器学习模型结合特征选择方法，通过患者语音记录来检测帕金森病，旨在实现早期诊断。


<details>
  <summary>Details</summary>
Motivation: 帕金森病早期诊断困难，因为早期运动症状非常轻微。虽然语音记录分析有助于早期诊断，但临床成本高且不清楚哪些语音特征真正相关。

Method: 使用不同类型的机器学习模型（特别是神经网络）结合特征选择方法，减少用于分类的特征数量，确定对疾病诊断最有信息量的特征。

Result: 机器学习方法（特别是神经网络）适合帕金森病分类，特征数量可以显著减少而不影响模型性能。

Conclusion: 机器学习结合特征选择是帕金森病早期诊断的有效方法，能够提高诊断效率并降低成本。

Abstract: Parkinson's disease (PD) is a chronic neurodegenerative disease. Early diagnosis is essential to mitigate the progressive deterioration of patients' quality of life. The most characteristic motor symptoms are very mild in the early stages, making diagnosis difficult. Recent studies have shown that the use of patient voice recordings can aid in early diagnosis. Although the analysis of such recordings is costly from a clinical point of view, advances in machine learning techniques are making the processing of this type of data increasingly accurate and efficient. Vocal recordings contain many features, but it is not known whether all of them are relevant for diagnosing the disease.
  This paper proposes the use of different types of machine learning models combined with feature selection methods to detect the disease. The selection techniques allow to reduce the number of features used by the classifiers by determining which ones provide the most information about the problem. The results show that machine learning methods, in particular neural networks, are suitable for PD classification and that the number of features can be significantly reduced without affecting the performance of the models.

</details>


### [642] [Active Hypothesis Testing for Correlated Combinatorial Anomaly Detection](https://arxiv.org/abs/2601.17430)
*Zichuan Yang,Yiming Xing*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出ECC-AHT算法，用于在相关噪声环境下识别异常数据流，通过最大化Chernoff信息实现主动噪声消除，在样本复杂度和实际性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 针对网络物理系统中的监控和安全问题，现有组合多臂赌博机和假设检验方法通常假设观测独立，无法利用相关性进行高效测量设计。

Method: 提出ECC-AHT自适应算法，通过选择连续约束测量来最大化竞争假设间的Chernoff信息，实现主动噪声消除的差分感知。

Result: ECC-AHT实现了最优样本复杂度保证，在合成和真实世界相关环境中显著优于最先进的基线方法。

Conclusion: 该方法有效解决了相关噪声下的异常流识别问题，为网络物理系统监控提供了高效解决方案。

Abstract: We study the problem of identifying an anomalous subset of streams under correlated noise, motivated by monitoring and security in cyber-physical systems. This problem can be viewed as a form of combinatorial pure exploration, where each stream plays the role of an arm and measurements must be allocated sequentially under uncertainty. Existing combinatorial bandit and hypothesis testing methods typically assume independent observations and fail to exploit correlation for efficient measurement design. We propose ECC-AHT, an adaptive algorithm that selects continuous, constrained measurements to maximize Chernoff information between competing hypotheses, enabling active noise cancellation through differential sensing. ECC-AHT achieves optimal sample complexity guarantees and significantly outperforms state-of-the-art baselines in both synthetic and real-world correlated environments. The code is available on https://github.com/VincentdeCristo/ECC-AHT

</details>


### [643] [Robust Computational Extraction of Non-Enhancing Hypercellular Tumor Regions from Clinical Imaging Data](https://arxiv.org/abs/2601.17802)
*A. Brawanski,Th. Schaffer,F. Raab,K. -M. Schebesch,M. Schrey,Chr. Doenitz,A. M. Tomé,E. W. Lang*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出一个基于常规MRI数据的计算框架，生成非增强高细胞性肿瘤区域的概率图，通过多网络架构解决成像边界模糊问题，并验证了其临床相关性。


<details>
  <summary>Details</summary>
Motivation: 神经肿瘤影像中，非增强高细胞性肿瘤区域的准确识别是未满足的临床需求，对患者管理和治疗规划有重要意义。现有方法难以处理成像变异性和边界模糊问题。

Method: 开发了一个稳健的计算框架，利用多种网络架构从常规MRI数据生成NEH区域的概率图，通过相对脑血容量和增强肿瘤复发位置等独立临床标志物进行验证。

Result: 框架在方法学稳健性和生物学相关性方面得到验证，能够可靠、无创地映射NEH肿瘤区域，支持其作为影像生物标志物整合到临床工作流程中。

Conclusion: 该框架为脑肿瘤患者的精准肿瘤学提供了支持，实现了NEH肿瘤区域的无创映射，有望改善临床决策和治疗规划。

Abstract: Accurate identification of non-enhancing hypercellular (NEH) tumor regions is an unmet need in neuro-oncological imaging, with significant implications for patient management and treatment planning. We present a robust computational framework that generates probability maps of NEH regions from routine MRI data, leveraging multiple network architectures to address the inherent variability and lack of clear imaging boundaries. Our approach was validated against independent clinical markers -- relative cerebral blood volume (rCBV) and enhancing tumor recurrence location (ETRL) -- demonstrating both methodological robustness and biological relevance. This framework enables reliable, non-invasive mapping of NEH tumor compartments, supporting their integration as imaging biomarkers in clinical workflows and advancing precision oncology for brain tumor patients.

</details>


### [644] [A Master Class on Reproducibility: A Student Hackathon on Advanced MRI Reconstruction Methods](https://arxiv.org/abs/2601.18314)
*Lina Felsner,Sevgi G. Kafali,Hannah Eichhorn,Agnes A. J. Leth,Aidas Batvinskas,Andre Datchev,Fabian Klemm,Jan Aulich,Puntika Leepagorn,Ruben Klinger,Daniel Rueckert,Julia A. Schnabel*

Main category: cs.LG

Relevance: 15.0

TL;DR: 学生可复现性黑客马拉松，专注于复现三篇有影响力的MRI重建论文的结果，包括MoDL、HUMUS-Net和基于物理正则化的动态MRI方法，并分享了构建可复现代码库的最佳实践。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习研究中可复现性不足的问题，特别是在医学影像重建领域。通过学生黑客马拉松的形式，系统性地评估和复现有影响力的MRI重建方法，同时培养下一代研究人员的可复现性意识。

Method: 组织学生黑客马拉松，参与者尝试复现三篇MRI重建论文：1) MoDL（基于模型的展开网络），2) HUMUS-Net（混合展开多尺度CNN+Transformer架构），3) 基于物理正则化的动态MRI方法。记录复现过程、结果和挑战，并总结构建可复现代码库的最佳实践。

Result: 成功复现了部分论文的结果，但也发现了可复现性方面的挑战。通过黑客马拉松获得了关于代码质量、文档完整性和实验设置透明度的宝贵见解。提出了改进研究可复现性的具体建议。

Conclusion: 深度学习研究，特别是医学影像领域，需要更强的可复现性标准。学生黑客马拉松是评估和促进研究可复现性的有效方法。良好的代码实践、详细文档和透明实验设置对于确保研究可复现性至关重要。

Abstract: We report the design, protocol, and outcomes of a student reproducibility hackathon focused on replicating the results of three influential MRI reconstruction papers: (a) MoDL, an unrolled model-based network with learned denoising; (b) HUMUS-Net, a hybrid unrolled multiscale CNN+Transformer architecture; and (c) an untrained, physics-regularized dynamic MRI method that uses a quantitative MR model for early stopping. We describe the setup of the hackathon and present reproduction outcomes alongside additional experiments, and we detail fundamental practices for building reproducible codebases.

</details>


### [645] [Cognitive Fusion of ZC Sequences and Time-Frequency Images for Out-of-Distribution Detection of Drone Signals](https://arxiv.org/abs/2601.18326)
*Jie Li,Jing Li,Lu Lv,Zhanyu Ju,Fengkui Gong*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出一种基于ZC序列和时频图像认知融合的无人机信号分布外检测算法，通过多模态特征交互与融合实现无人机远程识别任务中的OOD检测。


<details>
  <summary>Details</summary>
Motivation: 无人机远程识别(RID)需要检测未知或非标准通信协议的无人机信号，现有方法在处理分布外(OOD)信号时性能有限。需要结合ZC序列（针对已知协议）和时频图像（针对未知协议）的多模态信息来提高检测性能。

Method: 1) 从接收的射频信号中提取ZC序列特征和时频图像特征；2) 通过专用特征提取模块增强和对齐两种模态特征；3) 进行多模态特征交互、单模态特征融合和多模态特征融合；4) 从融合特征计算空间和通道维度的判别分数，转换为自适应注意力权重；5) 加权特征通过Softmax进行分类。

Result: 仿真结果表明，该算法在RID和OODD指标上分别比现有算法提升1.7%和7.5%，在不同飞行条件和无人机类型下表现出强鲁棒性。

Conclusion: 提出的基于ZC序列和时频图像认知融合的算法能有效检测无人机信号中的分布外样本，在无人机远程识别任务中优于现有方法，具有实际应用价值。

Abstract: We propose a drone signal out-of-distribution detection (OODD) algorithm based on the cognitive fusion of Zadoff-Chu (ZC) sequences and time-frequency images (TFI). ZC sequences are identified by analyzing the communication protocols of DJI drones, while TFI capture the time-frequency characteristics of drone signals with unknown or non-standard communication protocols. Both modalities are used jointly to enable OODD in the drone remote identification (RID) task. Specifically, ZC sequence features and TFI features are generated from the received radio frequency signals, which are then processed through dedicated feature extraction module to enhance and align them. The resultant multi-modal features undergo multi-modal feature interaction, single-modal feature fusion, and multi-modal feature fusion to produce features that integrate and complement information across modalities. Discrimination scores are computed from the fused features along both spatial and channel dimensions to capture time-frequency characteristic differences dictated by the communication protocols, and these scores will be transformed into adaptive attention weights. The weighted features are then passed through a Softmax function to produce the signal classification results. Simulation results demonstrate that the proposed algorithm outperforms existing algorithms and achieves 1.7% and 7.5% improvements in RID and OODD metrics, respectively. The proposed algorithm also performs strong robustness under varying flight conditions and across different drone types.

</details>


### [646] [Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection](https://arxiv.org/abs/2601.18329)
*Chuhan Feng,Jing Li,Jie Li,Lu Lv,Fengkui Gong*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出一种基于可区分性驱动的空间通道选择与梯度范数的无人机信号OOD检测算法，通过协议特定时频特征量化类间相似性和方差来自适应加权时空和通道维度特征，引入梯度范数度量扰动敏感性以捕捉OOD样本内在不稳定性，并与基于能量的分数融合进行联合推理。


<details>
  <summary>Details</summary>
Motivation: 无人机通信信号检测中，传统方法难以有效识别分布外(OOD)样本，需要开发能够自适应利用时频特征并捕捉OOD样本内在不稳定性的检测算法。

Method: 1) 基于协议特定时频特征量化类间相似性和方差，自适应加权时空和通道维度特征；2) 引入梯度范数度量扰动敏感性以捕捉OOD样本不稳定性；3) 将梯度范数度量与基于能量的分数融合进行联合推理。

Result: 仿真结果表明，该算法通过SNR和多种无人机类型测试，展现出优越的判别能力和鲁棒性能。

Conclusion: 提出的基于可区分性驱动的空间通道选择与梯度范数的OOD检测算法能有效识别无人机信号中的分布外样本，具有优越的判别性能和鲁棒性。

Abstract: We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types.

</details>


### [647] [Estimating Dense-Packed Zone Height in Liquid-Liquid Separation: A Physics-Informed Neural Network Approach](https://arxiv.org/abs/2601.18399)
*Mehmet Velioglu,Song Zhai,Alexander Mitsos,Adel Mhamdi,Andreas Jupke,Manuel Dahmen*

Main category: cs.LG

Relevance: 15.0

TL;DR: 提出一种两阶段训练物理信息神经网络，结合扩展卡尔曼滤波器框架，仅使用流量测量来估计重力沉降器中液-液分散的相高度


<details>
  <summary>Details</summary>
Motivation: 在化学、制药和回收过程中，重力沉降器中液-液分散的分离至关重要。密集堆积区高度是重要的性能和安全性指标，但由于光学限制，测量成本高且不切实际。需要开发仅使用廉价流量测量的相高度估计方法。

Method: 1. 使用低精度机理模型生成的合成数据和物理方程预训练物理信息神经网络，减少实验数据需求；2. 使用稀缺实验数据微调PINN以捕获分离器实际动态；3. 将可微分PINN作为预测模型集成到扩展卡尔曼滤波器状态估计框架中，从流量测量跟踪和更新相高度。

Result: 两阶段训练的PINN在所有评估中产生最准确的相高度估计：1. 前向模拟中优于机理模型和非预训练PINN；2. 滤波器估计中优于两阶段训练的纯数据驱动神经网络；3. 使用集成方法考虑模型参数不确定性。

Conclusion: 提出的两阶段训练PINN结合扩展卡尔曼滤波器框架，能够仅使用流量测量准确估计重力沉降器中的相高度，为工业过程监控提供实用解决方案。

Abstract: Separating liquid-liquid dispersions in gravity settlers is critical in chemical, pharmaceutical, and recycling processes. The dense-packed zone height is an important performance and safety indicator but it is often expensive and impractical to measure due to optical limitations. We propose to estimate phase heights using only inexpensive volume flow measurements. To this end, a physics-informed neural network (PINN) is first pretrained on synthetic data and physics equations derived from a low-fidelity (approximate) mechanistic model to reduce the need for extensive experimental data. While the mechanistic model is used to generate synthetic training data, only volume balance equations are used in the PINN, since the integration of submodels describing droplet coalescence and sedimentation into the PINN would be computationally prohibitive. The pretrained PINN is then fine-tuned with scarce experimental data to capture the actual dynamics of the separator. We then employ the differentiable PINN as a predictive model in an Extended Kalman Filter inspired state estimation framework, enabling the phase heights to be tracked and updated from flow-rate measurements. We first test the two-stage trained PINN by forward simulation from a known initial state against the mechanistic model and a non-pretrained PINN. We then evaluate phase height estimation performance with the filter, comparing the two-stage trained PINN with a two-stage trained purely data-driven neural network. All model types are trained and evaluated using ensembles to account for model parameter uncertainty. In all evaluations, the two-stage trained PINN yields the most accurate phase-height estimates.

</details>


### [648] [TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning](https://arxiv.org/abs/2601.18640)
*Zhiwei Zheng,Kevin Bryson*

Main category: cs.LG

Relevance: 15.0

TL;DR: TwinPurify：一种基于Barlow Twins自监督学习的表示学习框架，用于从批量转录组数据中分离肿瘤特异性信号，无需外部参考，通过利用同一队列中的相邻正常组织作为"背景"指导。


<details>
  <summary>Details</summary>
Motivation: 大规模癌症研究仍依赖批量转录组数据，但肿瘤纯度变化会掩盖肿瘤内在转录信号并限制下游发现。现有解卷积方法在合成混合数据上表现良好，但无法泛化到真实患者队列，因为未建模的生物和技术变异。

Method: 采用Barlow Twins自监督目标，学习连续的高维肿瘤嵌入表示。利用同一队列中的相邻正常组织作为"背景"指导，无需外部参考，通过表示学习而非离散细胞类型分解来分离肿瘤特异性信号。

Result: 在多个大型癌症队列（RNA-seq和微阵列平台）上评估，TwinPurify在恢复肿瘤内在和免疫信号方面优于传统表示学习方法（如自编码器）。纯化后的嵌入改进了分子亚型和分级分类，增强了生存模型一致性，并揭示了更有生物学意义的通路活性。

Conclusion: TwinPurify提供了一个可转移的框架，用于净化批量转录组学数据，扩展了现有临床数据集在分子发现方面的实用性，代表了从解卷积范式到表示学习范式的根本转变。

Abstract: Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation.
  Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as "background" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference.
  Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.

</details>


### [649] [FASTR: Reimagining FASTQ via Compact Image-inspired Representation](https://arxiv.org/abs/2601.17184)
*Adrian Tkachenko,Sepehr Salem,Ayotomiwa Ezekiel Adeniyi,Zulal Bingol,Mohammed Nayeem Uddin,Akshat Prasanna,Alexander Zelikovsky,Serghei Mangul,Can Alkan,Mohammed Alser*

Main category: q-bio.GN

Relevance: 15.0

TL;DR: FASTR是一种新的基因组数据格式，将核苷酸和碱基质量分数编码为单个8位值，相比传统FASTQ格式减少至少2倍文件大小，同时保持无损和计算原生特性。


<details>
  <summary>Details</summary>
Motivation: 高通量测序产生海量数据，传统FASTQ格式存储效率低下（每个碱基和质量分数各需1字节），导致存储、传输和分析瓶颈。现有压缩工具虽能缓解但引入解压成本或依赖问题。

Method: 开发FASTR格式，将每个核苷酸与其碱基质量分数编码为单个8位值，实现无损压缩。提供并行软件生态系统进行FASTQ-FASTR转换，并与现有工具（如minimap2）集成。

Result: FASTR减少至少2倍文件大小，在Illumina、HiFi和ONT读取上，通用压缩工具在FASTR上比FASTQ分别快2.47、3.64、4.8倍压缩和2.34、1.96、1.75倍解压。FASTR可直接作为数值向量或图像表示用于机器学习。

Conclusion: FASTR作为FASTQ的计算原生替代品，通过消除解压成本和减少数据移动，为可扩展基因组学分析和实时测序工作流奠定基础。

Abstract: Motivation: High-throughput sequencing (HTS) enables population-scale genomics but generates massive datasets, creating bottlenecks in storage, transfer, and analysis. FASTQ, the standard format for over two decades, stores one byte per base and one byte per quality score, leading to inefficient I/O, high storage costs, and redundancy. Existing compression tools can mitigate some issues, but often introduce costly decompression or complex dependency issues. Results: We introduce FASTR, a lossless, computation-native successor to FASTQ that encodes each nucleotide together with its base quality score into a single 8-bit value. FASTR reduces file size by at least 2x while remaining fully reversible and directly usable for downstream analyses. Applying general-purpose compression tools on FASTR consistently yields higher compression ratios, 2.47, 3.64, and 4.8x faster compression, and 2.34, 1.96, 1.75x faster decompression than on FASTQ across Illumina, HiFi, and ONT reads. FASTR is machine-learning-ready, allowing reads to be consumed directly as numerical vectors or image-like representations. We provide a highly parallel software ecosystem for FASTQ-FASTR conversion and show that FASTR integrates with existing tools, such as minimap2, with minimal interface changes and no performance overhead. By eliminating decompression costs and reducing data movement, FASTR lays the foundation for scalable genomics analyses and real-time sequencing workflows. Availability and Implementation: https://github.com/ALSER-Lab/FASTR

</details>


### [650] [Improving Generalization and Uncertainty Quantification of Photometric Redshift Models](https://arxiv.org/abs/2601.17222)
*Jonathan Soriano,Tuan Do,Srinath Saikrishnan,Vikram Seenivasan,Bernie Boscoe,Jack Singal,Evan Jones*

Main category: astro-ph.IM

Relevance: 15.0

TL;DR: 该论文探索了结合光谱红移和多波段测光红移数据的方法，以提高机器学习模型在更广泛星系类型上的适用性，使用复合数据集训练和迁移学习两种方法，并评估了确定性神经网络和贝叶斯神经网络的性能。


<details>
  <summary>Details</summary>
Motivation: 准确的红移估计对于理解星系演化和精确宇宙学至关重要。当前机器学习模型通常仅使用光谱红移数据进行训练，这限制了模型在更广泛星系类型上的适用性。研究旨在探索如何结合不同来源的红移数据（光谱和测光）来开发更通用的红移预测模型。

Method: 采用两种方法：1) 在复合数据集上训练（结合光谱红移和测光红移数据）；2) 迁移学习（从一个数据集迁移到另一个）。使用COSMOS2020目录的测光红移数据（TransferZ）补充光谱红移数据集（GalaxiesML）。采用两种架构：确定性神经网络（NN）和贝叶斯神经网络（BNN），并使用分形保形预测进行不确定性校准。

Result: 在复合数据集上训练的NN模型在红移范围0.3<z<1.5内，比仅使用光谱数据训练的模型偏差减少4.5倍，散射减少1.1倍，异常率降低1.4倍。BNN能产生可靠的不确定性估计，但对不同地面真值敏感。

Conclusion: 通过结合不同来源的地面真值数据，可以开发出能够准确预测更广泛星系种群红移的模型，这对于Euclid和LSST等巡天项目至关重要。复合数据集训练显著提升了模型性能。

Abstract: Accurate redshift estimates are a vital component in understanding galaxy evolution and precision cosmology. In this paper, we explore approaches to increase the applicability of machine learning models for photometric redshift estimation on a broader range of galaxy types. Typical models are trained with ground-truth redshifts from spectroscopy. We test the utility and effectiveness of two approaches for combining spectroscopic redshifts and redshifts derived from multiband ($\sim$35 filters) photometry, which sample different types of galaxies compared to spectroscopic surveys. The two approaches are (1) training on a composite dataset and (2) transfer learning from one dataset to another. We compile photometric redshifts from the COSMOS2020 catalog (TransferZ) to complement an established spectroscopic redshift dataset (GalaxiesML). We used two architectures, deterministic neural networks (NN) and Bayesian neural networks (BNN), to examine and evaluate their performance with respect to the Legacy Survey of Space and Time (LSST) photo-$z$ science requirements. We also use split conformal prediction for calibrating uncertainty estimates and producing prediction intervals for the BNN and NN, respectively. We find that a NN trained on a composite dataset predicts photo-$z$'s that are 4.5 times less biased within the redshift range $0.3<z<1.5$, 1.1 times less scattered, and has a 1.4 times lower outlier rate than a model trained on only spectroscopic ground truths. We also find that BNNs produce reliable uncertainty estimates, but are sensitive to the different ground truths. This investigation leverages different sources of ground truths to develop models that can accurately predict photo-$z$'s for a broader population of galaxies crucial for surveys such as Euclid and LSST.

</details>


### [651] [Sparse RBF Networks for PDEs and nonlocal equations: function space theory, operator calculus, and training algorithms](https://arxiv.org/abs/2601.17562)
*Zihan Shao,Konstantin Pieper,Xiaochuan Tian*

Main category: math.NA

Relevance: 15.0

TL;DR: 本文系统分析和扩展了用于求解非线性偏微分方程的稀疏径向基函数网络(SparseRBFnet)，研究了其函数空间特性、算子计算和算法设计，提供了统一的理论框架和计算指导。


<details>
  <summary>Details</summary>
Motivation: 先前提出的SparseRBFnet方法在求解非线性PDEs方面有潜力，但需要更系统的理论分析和算法改进。本文旨在建立统一的理论框架，理解其函数空间特性，并优化计算算法。

Method: 基于自适应宽度浅层核网络框架，分析径向基函数的统一解空间表征，证明其在Besov空间中的特性。研究核结构如何实现微分和非局部算子的准解析计算。通过三阶段训练策略比较不同变体，评估二阶优化、内部权重训练、网络自适应性和各向异性核参数化的作用。

Result: 证明了径向基函数解空间可表征为Besov空间，与具体核选择无关。实现了微分算子和分数拉普拉斯算子的准解析计算。数值实验显示对核选择不敏感，并在高阶、分数和各向异性PDE基准测试中展示了精度、稀疏性和计算成本之间的权衡。

Conclusion: 本文巩固并推广了SparseRBFnet的理论和计算框架，支持精确的稀疏表示和高效的算子计算，为算法和建模选择提供了理论指导。

Abstract: This work presents a systematic analysis and extension of the sparse radial basis function network (SparseRBFnet) previously introduced for solving nonlinear partial differential equations (PDEs). Based on its adaptive-width shallow kernel network formulation, we further investigate its function-space characterization, operator evaluation, and computational algorithm. We provide a unified description of the solution space for a broad class of radial basis functions (RBFs). Under mild assumptions, this space admits a characterization as a Besov space, independent of the specific kernel choice. We further demonstrate how the explicit kernel-based structure enables quasi-analytical evaluation of both differential and nonlocal operators, including fractional Laplacians. On the computational end, we study the adaptive-width network and related three-phase training strategy through a comparison with variants concerning the modeling and algorithmic details. In particular, we assess the roles of second-order optimization, inner-weight training, network adaptivity, and anisotropic kernel parameterizations. Numerical experiments on high-order, fractional, and anisotropic PDE benchmarks illustrate the empirical insensitivity to kernel choice, as well as the resulting trade-offs between accuracy, sparsity, and computational cost. Collectively, these results consolidate and generalize the theoretical and computational framework of SparseRBFnet, supporting accurate sparse representations with efficient operator evaluation and offering theory-grounded guidance for algorithmic and modeling choices.

</details>


### [652] [Boosting methods for interval-censored data with regression and classification](https://arxiv.org/abs/2601.17973)
*Yuan Bian,Grace Y. Yi,Wenqing He*

Main category: stat.ML

Relevance: 15.0

TL;DR: 提出针对区间删失数据的非参数提升方法，通过删失无偏变换调整损失函数，使用函数梯度下降实现，在生存分析和时间事件研究中具有实用价值


<details>
  <summary>Details</summary>
Motivation: 传统提升算法针对完全观测数据设计，难以处理区间删失数据（事件时间未知但落在已知区间内），这种数据在生存分析、医学研究、可靠性工程等领域常见，需要专门方法

Method: 提出非参数提升方法，利用删失无偏变换调整损失函数和插补变换响应，通过函数梯度下降实现，确保可扩展性和适应性

Result: 建立了理论性质（最优性和均方误差权衡），实证研究显示在各种有限样本场景下具有鲁棒性能，提高了区间删失数据下的预测准确性

Conclusion: 为区间删失数据提供了鲁棒的提升方法框架，扩展了现有提升技术的适用性，在生存分析和时间事件研究中具有重要应用价值

Abstract: Boosting has garnered significant interest across both machine learning and statistical communities. Traditional boosting algorithms, designed for fully observed random samples, often struggle with real-world problems, particularly with interval-censored data. This type of data is common in survival analysis and time-to-event studies where exact event times are unobserved but fall within known intervals. Effective handling of such data is crucial in fields like medical research, reliability engineering, and social sciences. In this work, we introduce novel nonparametric boosting methods for regression and classification tasks with interval-censored data. Our approaches leverage censoring unbiased transformations to adjust loss functions and impute transformed responses while maintaining model accuracy. Implemented via functional gradient descent, these methods ensure scalability and adaptability. We rigorously establish their theoretical properties, including optimality and mean squared error trade-offs. Our proposed methods not only offer a robust framework for enhancing predictive accuracy in domains where interval-censored data are common but also complement existing work, expanding the applicability of existing boosting techniques. Empirical studies demonstrate robust performance across various finite-sample scenarios, highlighting the practical utility of our approaches.

</details>


### [653] [A Cherry-Picking Approach to Large Load Shaping for More Effective Carbon Reduction](https://arxiv.org/abs/2601.17990)
*Bokan Chen,Raiden Hasegawa,Adriaan Hilbers,Ross Koningstein,Ana Radovanović,Utkarsh Shah,Gabriela Volpato,Mohamed Ahmed,Tim Cary,Rod Frowd*

Main category: stat.ML

Relevance: 15.0

TL;DR: 该研究通过ERCOT电网模拟分析不同负载整形策略对碳排放和成本的影响，发现基于LMP的策略表现最佳，并提出基于电网信号选择每日策略的"择优选择"方法。


<details>
  <summary>Details</summary>
Motivation: 大型负载（如数据中心）的电力消耗模式会影响电网发电调度，进而影响碳排放和能源成本。现有基于平均碳强度、节点边际价格或边际排放的负载整形策略缺乏详细的反事实数据验证其有效性。

Method: 使用校准的ERCOT日前直流最优潮流（DC-OPF）模拟进行反事实分析，评估多种负载整形策略对电网CO2排放和电力成本的影响。

Result: 基于节点边际价格（LMP）的整形策略在减少年度电网CO2排放方面优于其他常见策略，但仍有改进空间。不同电网条件下策略表现差异显著。

Conclusion: 提出"择优选择"方法：基于可观测电网信号和历史数据选择每日最佳策略。该方法适用于数据中心、分布式能源资源和虚拟电厂等大型柔性电力消费者。

Abstract: Shaping multi-megawatt loads, such as data centers, impacts generator dispatch on the electric grid, which in turn affects system CO2 emissions and energy cost. Substantiating the effectiveness of prevalent load shaping strategies, such as those based on grid-level average carbon intensity, locational marginal price, or marginal emissions, is challenging due to the lack of detailed counterfactual data required for accurate attribution. This study uses a series of calibrated granular ERCOT day-ahead direct current optimal power flow (DC-OPF) simulations for counterfactual analysis of a broad set of load shaping strategies on grid CO2 emissions and cost of electricity. In terms of annual grid level CO2 emissions reductions, LMP-based shaping outperforms other common strategies, but can be significantly improved upon. Examining the performance of practicable strategies under different grid conditions motivates a more effective load shaping approach: one that "cherry-picks" a daily strategy based on observable grid signals and historical data. The cherry-picking approach to power load shaping is applicable to any large flexible consumer on the electricity grid, such as data centers, distributed energy resources and Virtual Power Plants (VPPs).

</details>


### [654] [Memory-Efficient FPGA Implementation of Stochastic Simulated Annealing](https://arxiv.org/abs/2601.18007)
*Duckgyu Shin,Naoya Onizawa,Warren J. Gross,Takahiro Hanyu*

Main category: cs.AR

Relevance: 15.0

TL;DR: 提出了一种硬件感知的随机模拟退火算法（HA-SSA），用于FPGA上的内存高效实现，在保持SSA计算速度的同时减少中间结果存储的内存使用。


<details>
  <summary>Details</summary>
Motivation: 模拟退火算法解决组合优化问题时，随着问题规模增大，计算时间急剧增加。虽然随机模拟退火算法收敛更快，但在硬件实现时内存使用效率不高，需要优化以适应FPGA等硬件平台。

Method: 提出硬件感知的随机模拟退火算法（HA-SSA），通过减少中间结果存储来降低内存使用，同时保持SSA的计算速度。在最大割组合优化问题上进行验证，使用G-set数据集。

Result: HA-SSA在最大割问题上比传统SA收敛速度快达114倍，在FPGA实现上比传统SSA内存效率提高6倍，同时保持高解质量。

Conclusion: HA-SSA算法在FPGA上实现了内存高效的随机模拟退火，显著提升了收敛速度和内存效率，为组合优化问题的硬件加速提供了有效解决方案。

Abstract: Simulated annealing (SA) is a well-known algorithm for solving combinatorial optimization problems. However, the computation time of SA increases rapidly, as the size of the problem grows. Recently, a stochastic simulated annealing (SSA) algorithm that converges faster than conventional SA has been reported. In this paper, we present a hardware-aware SSA (HA- SSA) algorithm for memory-efficient FPGA implementations. HA-SSA can reduce the memory usage of storing intermediate results while maintaining the computing speed of SSA. For evaluation purposes, the proposed algorithm is compared with the conventional SSA and SA approaches on maximum cut combinatorial optimization problems. HA-SSA achieves a convergence speed that is up to 114-times faster than that of the conventional SA algorithm depending on the maximum cut problem selected from the G-set which is a dataset of the maximum cut problems. HA-SSA is implemented on a field-programmable gate array (FPGA) (Xilinx Kintex-7), and it achieves up to 6-times the memory efficiency of conventional SSA while maintaining high solution quality for optimization problems.

</details>


### [655] [MlPET: A Localized Neural Network Approach for Probabilistic Post-Reconstruction PET Image Analysis Using Informed Priors](https://arxiv.org/abs/2601.18021)
*Thomas Mejer Hansen,Nana Christensen,Mikkel Vendelbo*

Main category: physics.med-ph

Relevance: 15.0

TL;DR: MlPET是一种用于PET图像概率分析的高效局部化机器学习方法，通过神经网络替代传统MCMC采样，在保持图像质量的同时显著缩短采集时间。


<details>
  <summary>Details</summary>
Motivation: 传统PET重建存在噪声-分辨率权衡问题，且计算密集的MCMC采样方法效率低下。需要开发一种既能保持定量准确性又能提高计算效率的PET图像分析方法。

Method: MlPET使用局部化神经网络从小图像邻域估计后验平均体素活性，替代计算密集的MCMC采样。方法整合了扫描仪特定的点扩散函数、空间相关噪声建模和灵活先验。

Result: 在三个PET系统上的评估显示：对比恢复系数接近1.0（包括10mm球体），背景噪声降低，空间定义改善；有效点扩散函数半高宽从约2mm降至1mm以下；40-80秒采集时间即可获得传统PET 900秒的图像质量。

Conclusion: MlPET提供了一种高效的定量概率后重建PET分析方法，通过结合信息先验和神经网络速度，在不改变重建算法的情况下实现噪声抑制和分辨率增强，有望提高临床PET成像中小病灶检测能力和定量可靠性。

Abstract: We develop and evaluate MlPET, a fast localized machine learning approach for probabilistic PET image analysis addressing the noise-resolution trade-off in conventional reconstructions. MlPET replaces computationally demanding Markov chain Monte Carlo sampling with a localized neural network trained to estimate posterior mean voxel activity from small image neighborhoods. The method incorporates scanner-specific point spread functions, spatially correlated noise modeling, and flexible priors. Performance was evaluated on NEMA IEC phantom data from three PET systems (GE Discovery MI, Siemens Biograph Vision 600, and Quadra) under varying reconstruction settings and acquisition times. On phantom data, MlPET achieved contrast recovery coefficients consistently higher than standard PET and close to 1.0 (including 10 mm spheres), while reducing background noise and improving spatial definition. Effective pointspread function full width at half maximum decreased from approximately 2 mm in standard PET to below 1 mm with MlPET, a 2.5 fold reduction in blur. Comparable image quality was obtained at 40-80 s acquisition time with MlPET versus 900 s with conventional PET. MlPET provides an efficient approach for quantitative probabilistic post-reconstruction PET analysis. By combining informed priors with neural network speed, it achieves noise suppression and resolution enhancement without altering reconstruction algorithms. The method shows promise for improved small-lesion detectability and quantitative reliability in clinical PET imaging. Future studies will evaluate performance on patient data.

</details>


### [656] [Laser interferometry as a robust neuromorphic platform for machine learning](https://arxiv.org/abs/2601.18047)
*Amanuel Anteneh,Kyungeun Kim,J. M. Schwarz,Israel Klich,Olivier Pfister*

Main category: physics.optics

Relevance: 15.0

TL;DR: 提出一种仅使用线性光学资源（场位移和干涉测量）实现光学神经网络的方法，通过相位编码实现非线性，支持原位推理和训练，对光子损失具有强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统光学神经网络实现需要非线性光学元件，实验复杂。本文旨在利用纯线性光学资源实现神经网络，简化实验实现，同时支持原位训练和推理。

Method: 使用场位移和干涉测量处理相干态光场，通过输入相位编码实现非线性。利用参数移位规则或物理反向传播直接从线性光学电路测量中提取梯度，实现原位训练。

Result: 该方法相比先前方案实验实现更简单，支持原位推理和训练，对光子损失表现出强鲁棒性。

Conclusion: 仅用线性光学资源即可实现光学神经网络，简化实验实现，支持原位训练，对光子损失鲁棒，为光学计算提供新途径。

Abstract: We present a method for implementing an optical neural network using only linear optical resources, namely field displacement and interferometry applied to coherent states of light. The nonlinearity required for learning in a neural network is realized via an encoding of the input into phase shifts allowing for far more straightforward experimental implementation compared to previous proposals for, and demonstrations of, $\textit{in situ}$ inference. Beyond $\textit{in situ}$ inference, the method enables $\textit{in situ}$ training by utilizing established techniques like parameter shift rules or physical backpropagation to extract gradients directly from measurements of the linear optical circuit. We also investigate the effect of photon losses and find the model to be very resilient to these.

</details>


### [657] [Toward Scalable Normalizing Flows for the Hubbard Model](https://arxiv.org/abs/2601.18273)
*Janik Kreit,Andrea Bulgarelli,Lena Funcke,Thomas Luu,Dominic Schuh,Simran Singh,Lorenzo Verzichelli*

Main category: cond-mat.str-el

Relevance: 15.0

TL;DR: 该论文研究如何将归一化流扩展到更大晶格尺寸和更低温度下的哈伯德模型模拟，重点关注稳定性和效率提升，并分析了随机归一化流和非平衡马尔可夫链蒙特卡洛方法的标度行为。


<details>
  <summary>Details</summary>
Motivation: 归一化流最近展示了学习哈伯德模型玻尔兹曼分布的能力，为凝聚态物理中的生成建模开辟了新途径。然而，需要将其扩展到更大晶格尺寸和更低温度的实际应用场景，这需要解决稳定性和效率方面的挑战。

Method: 研究扩展归一化流模拟所需的步骤，重点关注增强稳定性和效率。分析随机归一化流和非平衡马尔可夫链蒙特卡洛方法在这个费米子系统中的标度行为。

Result: 论文展示了如何将归一化流扩展到更大晶格尺寸和更低温度的哈伯德模型模拟，提供了稳定性和效率的改进方法，并给出了随机归一化流和非平衡MCMC方法的标度行为分析。

Conclusion: 归一化流可以有效地扩展到更大晶格尺寸和更低温度的哈伯德模型模拟，为凝聚态物理中的生成建模提供了有前景的途径，同时随机归一化流和非平衡MCMC方法展示了良好的标度特性。

Abstract: Normalizing flows have recently demonstrated the ability to learn the Boltzmann distribution of the Hubbard model, opening new avenues for generative modeling in condensed matter physics. In this work, we investigate the steps required to extend such simulations to larger lattice sizes and lower temperatures, with a focus on enhancing stability and efficiency. Additionally, we present the scaling behavior of stochastic normalizing flows and non-equilibrium Markov chain Monte Carlo methods for this fermionic system.

</details>


### [658] [Convex Chance-Constrained Stochastic Control under Uncertain Specifications with Application to Learning-Based Hybrid Powertrain Control](https://arxiv.org/abs/2601.18313)
*Teruki Kato,Ryotaro Shima,Kenji Kashima*

Main category: eess.SY

Relevance: 15.0

TL;DR: 提出了一种严格凸机会约束随机控制框架，用于处理参考轨迹和操作约束等控制规范中的不确定性，通过联合优化控制输入和风险分配来保证概率约束满足，并确保严格凸性以获得唯一连续最优解。


<details>
  <summary>Details</summary>
Motivation: 传统控制方法在处理不确定性时存在局限性，特别是在非高斯分布的不确定性和概率约束满足方面。需要一种能够处理控制规范中各种不确定性（如参考轨迹、操作约束）的严格凸优化框架，以确保解的独特性和连续性。

Method: 提出严格凸机会约束随机控制框架，联合优化控制输入和风险分配，处理一般（可能非高斯）不确定性。将公式扩展到非线性模型预测控制，使用机器学习识别的精确线性化模型。

Result: 该方法能够保证概率约束满足，同时确保严格凸性，从而获得唯一且连续的最优解。在混合动力系统模型预测控制应用中验证了有效性。

Conclusion: 提出的严格凸机会约束随机控制框架为处理控制规范中的不确定性提供了有效方法，特别是在非高斯不确定性和概率约束满足方面，在混合动力系统等应用中表现出良好性能。

Abstract: This paper presents a strictly convex chance-constrained stochastic control framework that accounts for uncertainty in control specifications such as reference trajectories and operational constraints. By jointly optimizing control inputs and risk allocation under general (possibly non-Gaussian) uncertainties, the proposed method guarantees probabilistic constraint satisfaction while ensuring strict convexity, leading to uniqueness and continuity of the optimal solution. The formulation is further extended to nonlinear model-based control using exactly linearizable models identified through machine learning. The effectiveness of the proposed approach is demonstrated through model predictive control applied to a hybrid powertrain system.

</details>


### [659] [A Dataset for Automatic Vocal Mode Classification](https://arxiv.org/abs/2601.18339)
*Reemt Hinrichs,Sonja Stephan,Alexander Lange,Jörn Ostermann*

Main category: cs.SD

Relevance: 15.0

TL;DR: 本文介绍了一个新的声乐模式数据集，用于自动分类完整声乐技术（CVT）中的四种声乐模式，并提供了基线分类结果。


<details>
  <summary>Details</summary>
Motivation: 完整声乐技术（CVT）将声音使用分为四种声乐模式（Neutral、Curbing、Overdrive、Edge），这些知识对声乐学生有帮助。自动分类声乐模式对于技术辅助声乐教学很重要，但先前的研究由于缺乏数据而未能成功。

Method: 作者录制了一个新的声乐模式数据集，包含四位歌手（三位是专业歌手）的持续元音录音，覆盖了歌手的整个音域，共3,752个独特样本。使用四个麦克风进行自然数据增强，总样本超过13,000个。由三位CVT经验丰富的标注者进行独立标注，提供合并标注和个体标注。使用ResNet18等模型进行基线分类实验。

Result: 在5折交叉验证中，ResNet18取得了81.3%的最佳平衡准确率。数据集已公开发布在Zenodo平台上。

Conclusion: 该研究提供了一个高质量的声乐模式数据集，为技术辅助声乐教学中的声乐模式自动分类奠定了基础，并展示了深度学习模型在该任务上的潜力。

Abstract: The Complete Vocal Technique (CVT) is a school of singing developed in the past decades by Cathrin Sadolin et al.. CVT groups the use of the voice into so called vocal modes, namely Neutral, Curbing, Overdrive and Edge. Knowledge of the desired vocal mode can be helpful for singing students. Automatic classification of vocal modes can thus be important for technology-assisted singing teaching. Previously, automatic classification of vocal modes has been attempted without major success, potentially due to a lack of data. Therefore, we recorded a novel vocal mode dataset consisting of sustained vowels recorded from four singers, three of which professional singers with more than five years of CVT-experience. The dataset covers the entire vocal range of the subjects, totaling 3,752 unique samples. By using four microphones, thereby offering a natural data augmentation, the dataset consists of more than 13,000 samples combined. An annotation was created using three CVT-experienced annotators, each providing an individual annotation. The merged annotation as well as the three individual annotations come with the published dataset. Additionally, we provide some baseline classification results. The best balanced accuracy across a 5-fold cross validation of 81.3\,\% was achieved with a ResNet18. The dataset can be downloaded under https://zenodo.org/records/14276415.

</details>


### [660] [Universality of Many-body Projected Ensemble for Learning Quantum Data Distribution](https://arxiv.org/abs/2601.18637)
*Quoc Hoan Tran,Koki Chinzei,Yasuhiro Endo,Hirotaka Oshima*

Main category: quant-ph

Relevance: 15.0

TL;DR: 该论文证明了多体投影系综（MPE）框架在量子分布近似中的普适性定理，表明MPE可以在1-Wasserstein距离误差内近似任意纯态分布，并提出了改进可训练性的增量MPE变体。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习中的一个基本问题是近似普适性：参数化的QML模型能否近似任意量子分布。学习底层量子分布以生成量子数据在理论和实践场景中都面临挑战，但这是理解量子系统的关键任务。

Method: 采用多体投影系综（MPE）框架进行量子态设计，使用单个多体波函数来准备随机态。提出了增量MPE变体，采用分层训练以提高可训练性。

Result: 证明了MPE的普适性定理，表明MPE可以在1-Wasserstein距离误差内近似任意纯态分布。在聚类量子态和量子化学数据集上的数值实验验证了MPE学习复杂量子数据分布的有效性。

Conclusion: 该研究为量子机器学习提供了严格的普适性表达能力保证，解决了QML中的关键理论空白，同时通过增量MPE变体提高了方法的实用性。

Abstract: Generating quantum data by learning the underlying quantum distribution poses challenges in both theoretical and practical scenarios, yet it is a critical task for understanding quantum systems. A fundamental question in quantum machine learning (QML) is the universality of approximation: whether a parameterized QML model can approximate any quantum distribution. We address this question by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework, a method for quantum state design that uses a single many-body wave function to prepare random states. This demonstrates that MPE can approximate any distribution of pure states within a 1-Wasserstein distance error. This theorem provides a rigorous guarantee of universal expressivity, addressing key theoretical gaps in QML. For practicality, we propose an Incremental MPE variant with layer-wise training to improve the trainability. Numerical experiments on clustered quantum states and quantum chemistry datasets validate MPE's efficacy in learning complex quantum data distributions.

</details>


### [661] [Uniform Computability of PAC Learning](https://arxiv.org/abs/2601.18663)
*Vasco Brattka,Guillaume Chirache*

Main category: math.LO

Relevance: 15.0

TL;DR: 该论文使用Weihrauch复杂性研究PAC学习的可计算性性质，重点关注封闭概念类在不同信息表示下的学习复杂度，并将结果与Fundamental Theorem of Statistical Learning的构造性程度联系起来。


<details>
  <summary>Details</summary>
Motivation: 研究PAC学习的可计算性基础，特别是不同信息表示（正面、负面、完整信息）下学习问题的计算复杂性，为统计学习理论提供计算理论视角的分析框架。

Method: 使用Weihrauch复杂性理论分析PAC学习问题，将学习问题转化为计算问题，研究不同信息表示下学习算法的可计算性性质，并与已知计算问题（如极限操作、Weak Kőnig's Lemma等）建立等价关系。

Result: 1. 从正面信息的适当PAC学习等价于Baire空间上的极限操作；2. 从正面信息的不适当PAC学习与Weak Kőnig's Lemma密切相关；3. VC维度操作本身的计算复杂度：正面或完整信息下等价于二元排序问题，负面信息下等价于排序问题的跳跃；4. 这些结果可视为Fundamental Theorem of Statistical Learning构造性程度的分类。

Conclusion: PAC学习的可计算性性质高度依赖于信息表示方式，不同表示导致不同的计算复杂度分类，为理解统计学习理论的计算基础提供了系统框架。

Abstract: We study uniform computability properties of PAC learning using Weihrauch complexity. We focus on closed concept classes, which are either represented by positive, by negative or by full information. Among other results, we prove that proper PAC learning from positive information is equivalent to the limit operation on Baire space, whereas improper PAC learning from positive information is closely related to Weak Kőnig's Lemma and even equivalent to it, when we have some negative information about the admissible hypotheses. If arbitrary hypotheses are allowed, then improper PAC learning from positive information is still in a finitary DNC range, which implies that it is non-deterministically computable, but does not allow for probabilistic algorithms. These results can also be seen as a classification of the degree of constructivity of the Fundamental Theorem of Statistical Learning. All the aforementioned results hold if an upper bound of the VC dimension is provided as an additional input information. We also study the question of how these results are affected if the VC dimension is not given, but only promised to be finite or if concept classes are represented by negative or full information. Finally, we also classify the complexity of the VC dimension operation itself, which is a problem that is of independent interest. For positive or full information it turns out to be equivalent to the binary sorting problem, for negative information it is equivalent to the jump of sorting. This classification allows also conclusions regarding the Borel complexity of PAC learnability.

</details>


### [662] [Out-of-Distribution Radar Detection with Complex VAEs: Theory, Whitening, and ANMF Fusion](https://arxiv.org/abs/2601.18677)
*Yadang Alexis Rouzoumka,Jean Pinsolle,Eugénie Terreaux,Christèle Morisseau,Jean-Philippe Ovarlez,Chengfang Ren*

Main category: stat.ML

Relevance: 15.0

TL;DR: 提出基于复数变分自编码器（CVAE）的弱信号检测方法，用于非高斯、距离变化的海杂波环境，通过异常检测和与ANMF融合提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决海杂波等非高斯、距离变化干扰环境中弱复数信号的检测难题，传统方法在此类复杂环境中性能受限，需要利用深度学习和复数域建模来提升检测能力。

Method: 使用复数变分自编码器（CVAE）直接在IQ样本上进行训练，保留相位和多普勒结构。评估两种配置：1）使用未处理的距离剖面；2）局部白化后处理。进一步将CVAE与ANMF通过加权对数概率融合规则在决策层集成。

Result: CVAE在两种配置下都能在匹配虚警率下获得更高的检测概率，白化配置下改进最显著。融合的CVAE-ANMF方案在强非高斯杂波中表现出更强的鲁棒性，并能实现经验校准的虚警控制。

Conclusion: 统计归一化与复数生成建模相结合能显著改善实际海杂波条件下的检测性能，融合的CVAE-ANMF方案构成了传统基于模型检测器的有竞争力替代方案。

Abstract: We investigate the detection of weak complex-valued signals immersed in non-Gaussian, range-varying interference, with emphasis on maritime radar scenarios. The proposed methodology exploits a Complex-valued Variational AutoEncoder (CVAE) trained exclusively on clutter-plus-noise to perform Out-Of-Distribution detection. By operating directly on in-phase / quadrature samples, the CVAE preserves phase and Doppler structure and is assessed in two configurations: (i) using unprocessed range profiles and (ii) after local whitening, where per-range covariance estimates are obtained from neighboring profiles. Using extensive simulations together with real sea-clutter data from the CSIR maritime dataset, we benchmark performance against classical and adaptive detectors (MF, NMF, AMF-SCM, ANMF-SCM, ANMF-Tyler). In both configurations, the CVAE yields a higher detection probability Pd at matched false-alarm rate Pfa, with the most notable improvements observed under whitening. We further integrate the CVAE with the ANMF through a weighted log-p fusion rule at the decision level, attaining enhanced robustness in strongly non-Gaussian clutter and enabling empirically calibrated Pfa control under H0. Overall, the results demonstrate that statistical normalization combined with complex-valued generative modeling substantively improves detection in realistic sea-clutter conditions, and that the fused CVAE-ANMF scheme constitutes a competitive alternative to established model-based detectors.

</details>


### [663] [Analyzing Images of Blood Cells with Quantum Machine Learning Methods: Equilibrium Propagation and Variational Quantum Circuits to Detect Acute Myeloid Leukemia](https://arxiv.org/abs/2601.18710)
*A. Bano,L. Liebovitch*

Main category: cs.ET

Relevance: 15.0

TL;DR: 量子机器学习在医疗影像分析中的可行性研究：使用平衡传播和变分量子电路进行急性髓系白血病检测，在有限数据下达到接近经典CNN的性能


<details>
  <summary>Details</summary>
Motivation: 探索量子机器学习在现实世界医疗成像任务中的可行性，特别是在NISQ（含噪声中等规模量子）时代，量子系统由于状态坍缩测量无法使用反向传播的背景下，寻找替代学习算法

Method: 采用两种量子兼容方法：1) 平衡传播（EP）- 一种基于能量的学习方法，无需反向传播；2) 变分量子电路（VQC）- 4量子比特电路。使用AML-Cytomorphology数据集（18,365张专家标注图像）的子集（每类50-250样本），图像降采样至64x64像素并提取20维工程特征，通过Qiskit进行经典模拟

Result: 量子方法在有限数据下表现接近经典CNN：EP达到86.4%准确率（仅比CNN低12%），4量子比特VQC达到83.0%准确率。VQC在每类仅50样本时保持稳定83%性能，而CNN需要250样本（5倍数据）才能达到98%准确率

Conclusion: 量子机器学习在医疗保健领域具有可行性，特别是在数据有限场景下表现出竞争力，为NISQ时代量子算法在现实世界应用建立了可复现的基准

Abstract: This paper presents a feasibility study demonstrating that quantum machine learning (QML) algorithms achieve competitive performance on real-world medical imaging despite operating under severe constraints. We evaluate Equilibrium Propagation (EP), an energy-based learning method that does not use backpropagation (incompatible with quantum systems due to state-collapsing measurements) and Variational Quantum Circuits (VQCs) for automated detection of Acute Myeloid Leukemia (AML) from blood cell microscopy images using binary classification (2 classes: AML vs. Healthy).
  Key Result: Using limited subsets (50-250 samples per class) of the AML-Cytomorphology dataset (18,365 expert-annotated images), quantum methods achieve performance only 12-15% below classical CNNs despite reduced image resolution (64x64 pixels), engineered features (20D), and classical simulation via Qiskit. EP reaches 86.4% accuracy (only 12% below CNN) without backpropagation, while the 4-qubit VQC attains 83.0% accuracy with consistent data efficiency: VQC maintains stable 83% performance with only 50 samples per class, whereas CNN requires 250 samples (5x more data) to reach 98%. These results establish reproducible baselines for QML in healthcare, validating NISQ-era feasibility.

</details>


### [664] [Learning to Discover: A Generalized Framework for Raga Identification without Forgetting](https://arxiv.org/abs/2601.18766)
*Parampreet Singh,Somya Kumar,Chaitanya Shailendra Nitawe,Vipul Arora*

Main category: eess.AS

Relevance: 15.0

TL;DR: 提出统一学习框架解决印度艺术音乐中罕见拉格识别问题，通过利用有标签和无标签音频数据，使模型能够发现未见拉格类别同时保留已知拉格知识，避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 印度艺术音乐中许多罕见拉格在训练数据集中未出现，传统分类模型假设封闭类别集，无法识别或有效分组未见拉格。现有方法尝试分类未见拉格但存在灾难性遗忘问题，即对已知拉格的知识会减弱。

Method: 采用统一学习框架，同时利用有标签和无标签音频数据。该框架使模型能够发现未见拉格的连贯类别，同时保留对已知拉格的知识。通过基准拉格识别数据集测试模型性能。

Result: 在基准拉格识别数据集上，所提方法在分类已知、未见和所有拉格类别方面表现出色。超越了之前基于NCD的流程，甚至在发现未见拉格类别方面提供了新见解。

Conclusion: 该统一学习框架有效解决了印度艺术音乐中罕见拉格识别问题，避免了灾难性遗忘，为IAM任务的表示学习提供了新见解。

Abstract: Raga identification in Indian Art Music (IAM) remains challenging due to the presence of numerous rarely performed Ragas that are not represented in available training datasets. Traditional classification models struggle in this setting, as they assume a closed set of known categories and therefore fail to recognise or meaningfully group previously unseen Ragas. Recent works have tried categorizing unseen Ragas, but they run into a problem of catastrophic forgetting, where the knowledge of previously seen Ragas is diminished. To address this problem, we adopt a unified learning framework that leverages both labeled and unlabeled audio, enabling the model to discover coherent categories corresponding to the unseen Ragas, while retaining the knowledge of previously known ones. We test our model on benchmark Raga Identification datasets and demonstrate its performance in categorizing previously seen, unseen, and all Raga classes. The proposed approach surpasses the previous NCD-based pipeline even in discovering the unseen Raga categories, offering new insights into representation learning for IAM tasks.

</details>
