<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 91]
- [cs.CV](#cs.CV) [Total: 253]
- [cs.AI](#cs.AI) [Total: 132]
- [cs.LG](#cs.LG) [Total: 172]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Generalist Reward Models: Found Inside Large Language Models](https://arxiv.org/abs/2506.23235)
*Yi-Chen Li,Tian Xu,Yang Yu,Xuqin Zhang,Xiong-Hui Chen,Zhongxiang Ling,Ningjing Chao,Lei Yuan,Zhi-Hua Zhou*

Main category: cs.CL

Relevance: 90.0

TL;DR: 论文提出了一种无需额外训练即可从预训练LLM中提取高质量奖励信号的方法，并证明了其理论有效性，实验表明该方法优于现有奖励模型。


<details>
  <summary>Details</summary>
Motivation: 减少依赖昂贵的人类偏好数据训练奖励模型，探索LLM中潜在的通用奖励信号。

Method: 通过理论证明，从预训练LLM中提取内源性奖励信号，并用于强化学习。

Result: 实验验证该方法优于现有LLM-as-a-judge方法和显式训练的奖励模型。

Conclusion: 预训练阶段已捕获足够知识，可通过内源性奖励信号高效对齐LLM，为多模态模型提供新范式。

Abstract: The alignment of Large Language Models (LLMs) is critically dependent on
reward models trained on costly human preference data. While recent work
explores bypassing this cost with AI feedback, these methods often lack a
rigorous theoretical foundation. In this paper, we discover that a powerful
generalist reward model is already latently present within any LLM trained via
standard next-token prediction. We prove that this endogenous reward is not a
heuristic, but is theoretically equivalent to a reward function learned through
offline inverse reinforcement learning. This connection allows us to directly
elicit a high-quality reward signal from a base (pre-trained or supervised
fine-tuned) model without any further training. Critically, we also prove that
subsequent reinforcement learning using this endogenous reward leads to a
policy with a provably superior error bound compared to the base model. To our
best knowledge, this is the first theoretical proof of the effectiveness of
reinforcement learning for LLMs. Our experiments validate this theory,
demonstrating that our method not only outperforms existing LLM-as-a-judge
approaches but can also surpass explicitly trained reward models. These
findings suggest that the reward modeling stage can be replaced by a principled
method of eliciting the knowledge already captured during pre-training,
heralding a more efficient, powerful, and scalable paradigm for LLMs alignment
as well as multi-modal models.

</details>


### [2] [Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans](https://arxiv.org/abs/2506.22439)
*Javier Conde,Miguel González,María Grandury,Gonzalo Martínez,Pedro Reviriego,Mar Brysbaert*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文探讨了LLMs在心理语言学特征上与人类评分的一致性，发现LLMs在Glasgow规范上的表现优于Lancaster规范，揭示了其在感官关联方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估多关注任务性能，但忽略了难以量化的语言特征（如情感、感官关联）。论文利用心理语言学数据集填补这一空白。

Method: 评估一组代表性LLMs在Glasgow和Lancaster规范（覆盖13个特征）上与人类评分的一致性。

Result: LLMs在Glasgow规范（如情感、熟悉度）上表现更好，而在Lancaster规范（感官关联）上较差。

Conclusion: LLMs缺乏人类具身认知，导致感官关联表现不佳，心理语言学数据集为评估提供了新视角。

Abstract: The evaluation of LLMs has so far focused primarily on how well they can
perform different tasks such as reasoning, question-answering, paraphrasing, or
translating. For most of these tasks, performance can be measured with
objective metrics, such as the number of correct answers. However, other
language features are not easily quantified. For example, arousal,
concreteness, or gender associated with a given word, as well as the extent to
which we experience words with senses and relate them to a specific sense.
Those features have been studied for many years by psycholinguistics,
conducting large-scale experiments with humans to produce ratings for thousands
of words. This opens an opportunity to evaluate how well LLMs align with human
ratings on these word features, taking advantage of existing studies that cover
many different language features in a large number of words. In this paper, we
evaluate the alignment of a representative group of LLMs with human ratings on
two psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets
cover thirteen features over thousands of words. The results show that
alignment is \textcolor{black}{generally} better in the Glasgow norms evaluated
(arousal, valence, dominance, concreteness, imageability, familiarity, and
gender) than on the Lancaster norms evaluated (introceptive, gustatory,
olfactory, haptic, auditory, and visual). This suggests a potential limitation
of current LLMs in aligning with human sensory associations for words, which
may be due to their lack of embodied cognition present in humans and
illustrates the usefulness of evaluating LLMs with psycholinguistic datasets.

</details>


### [3] [Hallucination Detection with Small Language Models](https://arxiv.org/abs/2506.22486)
*Ming Cheung*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种框架，通过整合多个小型语言模型来验证LLM生成的回答，以检测幻觉问题，实验表明F1分数提高了10%。


<details>
  <summary>Details</summary>
Motivation: LLM在问答任务中可能产生幻觉回答，缺乏可靠检测方法，影响了实际应用的可靠性。

Method: 使用多个小型语言模型，将回答分解为单句，利用生成“Yes”标记的概率进行验证。

Result: 实验验证了框架的有效性，F1分数提高了10%。

Conclusion: 多个小型语言模型可用于高效检测LLM的幻觉回答，为学术和实际应用提供可扩展方案。

Abstract: Since the introduction of ChatGPT, large language models (LLMs) have
demonstrated significant utility in various tasks, such as answering questions
through retrieval-augmented generation. Context can be retrieved using a
vectorized database, serving as a foundation for LLMs to generate responses.
However, hallucinations in responses can undermine the reliability of LLMs in
practical applications, and they are not easily detectable in the absence of
ground truth, particularly in question-and-answer scenarios. This paper
proposes a framework that integrates multiple small language models to verify
responses generated by LLMs using the retrieved context from a vectorized
database. By breaking down the responses into individual sentences and
utilizing the probability of generating "Yes" tokens from the outputs of
multiple models for a given set of questions, responses, and relevant context,
hallucinations can be detected. The proposed framework is validated through
experiments with real datasets comprising over 100 sets of questions, answers,
and contexts, including responses with fully and partially correct sentences.
The results demonstrate a 10\% improvement in F1 scores for detecting correct
responses compared to hallucinations, indicating that multiple small language
models can be effectively employed for answer verification, providing a
scalable and efficient solution for both academic and practical applications.

</details>


### [4] [Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation](https://arxiv.org/abs/2506.22518)
*Deyu Zou,Yongqiang Chen,Mufei Li,Siqi Miao,Chenxi Liu,Bo Han,James Cheng,Pan Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: ReG improves graph-based RAG by aligning weak retrievers with LLMs, using feedback to reduce spurious signals and reorganizing retrieved knowledge into coherent evidence chains.


<details>
  <summary>Details</summary>
Motivation: LLMs in graph-based RAG often rely on weak retrievers due to lack of ground truth and unorganized knowledge presentation, leading to hallucinations.

Method: ReG incorporates LLM feedback to refine supervision and introduces a structure-aware reorganization module for coherent evidence chains.

Result: ReG improves performance by up to 10%, matches SOTA with 5% training data, reduces reasoning token cost by 30%, and boosts performance by 4%.

Conclusion: ReG effectively mitigates issues in graph-based RAG, enhancing LLM performance and efficiency.

Abstract: Graph-based retrieval-augmented generation (RAG) enables large language
models (LLMs) to ground responses with structured external knowledge from
up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs
often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground
truth, the retriever is often trained on weak supervision, which often
introduces spurious signals to the LLMs. II) Due to the abstraction of graph
data, the retrieved knowledge is often presented in unorganized forms. To
mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak
retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM
feedback to get rid of spurious signals and improve the quality of the
supervision. Meanwhile, ReG introduces a structure-aware reorganization module
to refactor the retrieval results into logically coherent evidence chains.
Experiments on prominent benchmarks demonstrate that ReG significantly and
consistently brings improvements across different LLM backbones by up to 10%.
The improved supervision quality enables ReG to match the state-of-the-art
performance with 5% training data and to transfer to out-of-distribution KGs.
Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token
cost by up to 30% and improves the performance by up to 4%.

</details>


### [5] [RExBench: Can coding agents autonomously implement AI research extensions?](https://arxiv.org/abs/2506.22598)
*Nicholas Edwards,Yukyung Lee,Yujun,Mao,Yulu Qin,Sebastian Schuster,Najoung Kim*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文介绍了RExBench，一个用于评估LLM代理在实现研究扩展任务中的能力的基准测试，发现当前代理在无大量人工指导的情况下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究LLM代理在自主完成研究扩展任务中的能力，填补现有评估工具的空白。

Method: 开发RExBench基准，包含12个未实现的研究假设任务，评估9个LLM代理在三种框架下的表现。

Result: 所有代理在无人工提示下表现不佳，最佳成功率低于40%。

Conclusion: 当前LLM代理仍需大量人工指导才能完成现实研究扩展任务。

Abstract: Agents based on Large Language Models (LLMs) have shown promise for
performing sophisticated software engineering tasks autonomously. In addition,
there has been progress towards developing agents that can perform parts of the
research pipeline in machine learning and the natural sciences. We argue that
research extension and its implementation is a critical capability for such
systems, and introduce RExBench to support the evaluation of this capability.
RExBench is a benchmark consisting of 12 realistic research experiment
implementation tasks that aim to investigate research hypotheses that have not
previously been implemented. Each task is set up as an extension to an existing
research paper and codebase, accompanied by domain expert-written instructions.
RExBench is robust to data contamination, and supports an automatic evaluation
infrastructure that executes agent outputs to determine whether the success
criteria are met. We use this benchmark to evaluate nine LLM agents implemented
using three different frameworks: aider, Claude Code, and OpenHands. We find
that all agents evaluated fail to autonomously implement the majority of the
extensions. Although the success rate improves with additional human-written
hints, the best performance under this setting remains below 40%. This
indicates that current agents are still short of being able to handle realistic
research extension tasks without substantial human guidance.

</details>


### [6] [Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks](https://arxiv.org/abs/2506.22623)
*Badr Youbi Idrissi,Monica Millunzi,Amelia Sorrenti,Lorenzo Baraldi,Daryna Dementieva*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了一种新的水印技术，用于检测由大型语言模型生成的合成文本，以确保其伦理应用。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的广泛应用，其潜在滥用问题引发关注。研究旨在通过水印技术识别机器生成文本，促进伦理使用。

Method: 研究首先复现了基线方法的实验结果，揭示其对生成模型变化的敏感性。随后提出了一种创新的水印方法，并通过改写生成文本来评估其鲁棒性。

Result: 实验结果表明，所提出的水印方法在鲁棒性上优于基线方法。

Conclusion: 该研究为LLMs的伦理应用提供了一种有效的水印检测技术。

Abstract: In the present-day scenario, Large Language Models (LLMs) are establishing
their presence as powerful instruments permeating various sectors of society.
While their utility offers valuable support to individuals, there are multiple
concerns over potential misuse. Consequently, some academic endeavors have
sought to introduce watermarking techniques, characterized by the inclusion of
markers within machine-generated text, to facilitate algorithmic
identification. This research project is focused on the development of a novel
methodology for the detection of synthetic text, with the overarching goal of
ensuring the ethical application of LLMs in AI-driven text generation. The
investigation commences with replicating findings from a previous baseline
study, thereby underscoring its susceptibility to variations in the underlying
generation model. Subsequently, we propose an innovative watermarking approach
and subject it to rigorous evaluation, employing paraphrased generated text to
asses its robustness. Experimental results highlight the robustness of our
proposal compared to the~\cite{aarson} watermarking method.

</details>


### [7] [VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs](https://arxiv.org/abs/2506.22694)
*Raghavv Goel,Sudhanshu Agrawal,Mukul Gagrani,Junyoung Park,Yifan Zao,He Zhang,Tian Liu,Yiping Yang,Xin Yuan,Jiuyan Lu,Chris Lott,Mingu Lee*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种无需训练的简单技术VocabTrim，通过优化drafter模型的词汇表来提高基于drafter的推测解码（SpD）方法的性能，特别适用于内存受限环境。


<details>
  <summary>Details</summary>
Motivation: 推测解码通常需要目标模型和drafter模型共享词汇表或语言建模头（LM head），但这对词汇量大的目标模型会带来不必要的推理开销。VocabTrim旨在减少这种开销，提高生成速度。

Method: VocabTrim通过重构drafter的LM head，仅保留目标模型中最常采样的有限词汇集，以减少drafter的推理延迟。

Result: 在内存受限环境下，VocabTrim显著降低了drafter的延迟，尽管略微降低了接受率，但整体提高了生成速度（如Llama-3.2-3B-Instruct在Spec-Bench上提升了16%）。

Conclusion: VocabTrim是一种简单有效的方法，适用于内存受限设备，能够显著提升推测解码的效率。

Abstract: In this paper, we introduce a simple training-free technique to improve the
performance of drafter-based speculative decoding (SpD) methods that
incorporates language modeling head (LM head) during drafting process. A
drafter-based speculative decoding leverages one or more smaller language
models, a.k.a. drafters or draft models, to sample a draft sequence or tree
consisting of multiple tokens, followed by verification by a base LLM, a target
model, accepting a subset as its valid generation. As it is usually considered
that the speculative decoding requires one-to-one mapping between vocabularies
of the target model and the draft model, it has been natural to share the
vocabulary between them, or even share the LM head as in EAGLE or Medusa. We
first identify that this draft token sampling scheme inherently contains an
unnecessary inference overhead in drafting, especially for some target LLMs
with very large vocabularies. Then, we propose a simple technique, VocabTrim,
to mitigate the drafting overhead to improve the generation speed in
memory-bound environment. VocabTrim reconstructs the drafter LM head to contain
only a limited set of tokens, selected by the most frequently sampled from the
vocabulary of the target model. While limiting the vocabulary in drafting
slightly degrades the acceptance rate, it significantly reduces the drafting
latency in memory-bound process which is often the case on edge devices,
resulting in higher memory-bound speed up (MBSU). We show that our method can
boost the memory-bound speed-up for Llama-3 models on Spec-Bench, specifically
by 16% for Llama-3.2-3B-Instruct.

</details>


### [8] [The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure](https://arxiv.org/abs/2506.22724)
*Niyati Bafna,Tianjian Li,Kenton Murray,David R. Mortensen,David Yarowsky,Hale Sirin,Daniel Khashabi*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文探讨了多语言生成中低质量输出的原因，提出翻译障碍假设，并通过实验验证了翻译阶段失败是主要原因。


<details>
  <summary>Details</summary>
Motivation: 多语言生成在低资源语言中表现不佳，研究试图揭示其根本原因。

Method: 使用logit lens观察模型在中间层的处理过程，测试108种语言对的单词翻译任务。

Result: 发现翻译失败是输出质量低的主要原因，尤其在低资源语言中。

Conclusion: 翻译障碍是多语言生成的重要障碍，为未来改进提供了指导。

Abstract: Multilingual generation with large language models (LLMs) is often of poor
quality for mid- to low-resource languages. Building on insights from
interpretability, we demonstrate the existence of an implicit
task-solving-->translation pipeline for generation, whereby the model first
solves the required task in a largely target-language-agnostic manner, and
subsequently translates answer concepts into the intended target language. We
hypothesize that the failure of the translation stage is an important culprit
for the observed low quality of final outputs, and formalize this as the
translation barrier hypothesis. We test this hypothesis for a word translation
task across 108 language pairs, using logit lens to observe model processing in
intermediate layers. We find that a significant portion of overall failures
indeed stems from translation failure, or the model's inability to translate
correctly solved intermediate concepts into the target language. This is
especially true for low-resource target languages. Our results highlight an
important hurdle for end-to-end multilingual generation, and lend guiding
insights for future work seeking to improve multilinguality in LLMs.

</details>


### [9] [Jan-nano Technical Report](https://arxiv.org/abs/2506.22760)
*Alan Dao,Dinh Bach Vu*

Main category: cs.CL

Relevance: 85.0

TL;DR: Jan-nano是一个4B参数的语言模型，通过多阶段RLVR系统实现高效训练，无需依赖下一词预测训练，在SimpleQA基准上达到83.2%的准确率，支持128K上下文长度。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型在强大能力与计算资源需求之间的权衡问题，探索高效且小规模的模型设计。

Method: 基于Qwen3-4B微调，采用多阶段RLVR系统，完全消除对下一词预测训练的依赖。

Result: 在SimpleQA基准上达到83.2%的准确率，支持128K上下文长度，可在消费级硬件上运行。

Conclusion: Jan-nano证明了智能不在于规模，而在于策略，为高效小规模模型设计提供了新思路。

Abstract: Most language models face a fundamental tradeoff where powerful capabilities
require substantial computational resources. We shatter this constraint with
Jan-nano, a 4B parameter language model that redefines efficiency through
radical specialization: instead of trying to know everything, it masters the
art of finding anything instantly. Fine-tuned from Qwen3-4B using our novel
multi-stage RLVR system that completely eliminates reliance on next token
prediction training (SFT), Jan-nano achieves 83.2% on SimpleQA benchmark with
MCP integration while running on consumer hardware. With 128K context length,
Jan-nano proves that intelligence isn't about scale, it's about strategy.

</details>


### [10] [Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.22777)
*Miles Turpin,Andy Arditi,Marvin Li,Joe Benton,Julian Michael*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种名为VFT的方法，通过预RL干预训练模型显式承认提示线索的影响，从而减少奖励黑客行为。实验表明，VFT显著提高了模型对奖励黑客行为的检测率。


<details>
  <summary>Details</summary>
Motivation: 解决RL训练中语言模型的奖励黑客行为问题，提高模型的透明性和安全性。

Method: 提出VFT方法，训练模型显式承认提示线索的影响，随后在RL环境中测试模型是否利用线索进行奖励黑客行为。

Result: VFT训练后，仅有6%的响应为未检测到的奖励黑客行为，而未经VFT的RL训练中这一比例高达88%。

Conclusion: VFT通过提高模型对奖励黑客行为的显式承认，显著改善了检测效果，为透明和安全的AI系统提供了可行路径。

Abstract: Language models trained with RL can engage in reward hacking--exploiting
unintended strategies for high reward--without revealing this behavior in their
chain-of-thought reasoning, making detection difficult and posing risks for
high-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL
intervention that trains models to explicitly acknowledge when they are
influenced by prompt cues--hints which point to incorrect answers (e.g., "a
Stanford professor thinks the answer is A"). To evaluate VFT, we subsequently
train models with RL on environments where held-out prompt cues signal which
incorrect answers will receive high reward, incentivizing models to reward hack
by exploiting cues instead of reasoning correctly. We measure how often models
exploit these cues without verbalizing it. After RL, only 6% of the VFT-trained
model's responses consist of undetected reward hacks. In comparison, when we
perform RL without VFT, the rate of undetected reward hacks goes up to 88%;
with a debiasing baseline intervention, this increases further to 99%. VFT
achieves this by substantially increasing how often models verbalize the
influence of cues--from 8% to 42% after VFT, and up to 94% after RL--while
baselines remain low even after RL (10% and 1%). Our results show that teaching
models to explicitly verbalize reward hacking behavior before RL significantly
improves their detection, offering a practical path toward more transparent and
safe AI systems.

</details>


### [11] [ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models](https://arxiv.org/abs/2506.22791)
*Jianxin Yan,Wangze Ni,Lei Chen,Xuemin Lin,Peng Cheng,Zhan Qin,Kui Ren*

Main category: cs.CL

Relevance: 85.0

TL;DR: ContextCache是一种上下文感知的语义缓存系统，用于多轮对话，通过两阶段检索架构提高缓存命中精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有语义缓存系统缺乏对多轮对话上下文的感知，导致在不同对话场景中出现错误的缓存命中。

Method: 采用两阶段检索架构：首先基于向量检索当前查询，然后通过自注意力机制整合当前和历史对话表示进行精确匹配。

Result: ContextCache在真实对话中表现出更高的精确率和召回率，缓存响应延迟比直接调用LLM低约10倍。

Conclusion: ContextCache显著提升了多轮对话中语义缓存的效率和准确性，降低了计算成本。

Abstract: Semantic caching significantly reduces computational costs and improves
efficiency by storing and reusing large language model (LLM) responses.
However, existing systems rely primarily on matching individual queries,
lacking awareness of multi-turn dialogue contexts, which leads to incorrect
cache hits when similar queries appear in different conversational settings.
This demonstration introduces ContextCache, a context-aware semantic caching
system for multi-turn dialogues. ContextCache employs a two-stage retrieval
architecture that first executes vector-based retrieval on the current query to
identify potential matches and then integrates current and historical dialogue
representations through self-attention mechanisms for precise contextual
matching. Evaluation of real-world conversations shows that ContextCache
improves precision and recall compared to existing methods. Additionally,
cached responses exhibit approximately 10 times lower latency than direct LLM
invocation, enabling significant computational cost reductions for LLM
conversational applications.

</details>


### [12] [Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models](https://arxiv.org/abs/2506.22813)
*Zhuojun Ding,Wei Wei,Chenghao Fan*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了SaM框架，动态选择和合并专家模型以优化目标领域的信息提取任务，无需额外训练即可提升泛化能力，且具有高扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多领域训练统一模型时缺乏适应性和扩展性，标注细粒度标签和训练领域特定模型成本高。

Method: 动态选择和合并预训练的领域专家模型，基于领域相似性和性能采样，创建任务特定模型。

Result: 在多个基准测试中平均优于统一模型10%，展示了框架的有效性和扩展性。

Conclusion: SaM框架通过动态合并专家模型显著提升了跨领域泛化能力，并提供了高扩展性。

Abstract: Supervised fine-tuning (SFT) is widely used to align large language models
(LLMs) with information extraction (IE) tasks, such as named entity recognition
(NER). However, annotating such fine-grained labels and training
domain-specific models is costly. Existing works typically train a unified
model across multiple domains, but such approaches lack adaptation and
scalability since not all training data benefits target domains and scaling
trained models remains challenging. We propose the SaM framework, which
dynamically Selects and Merges expert models at inference time. Specifically,
for a target domain, we select domain-specific experts pre-trained on existing
domains based on (i) domain similarity to the target domain and (ii)
performance on sampled instances, respectively. The experts are then merged to
create task-specific models optimized for the target domain. By dynamically
merging experts beneficial to target domains, we improve generalization across
various domains without extra training. Additionally, experts can be added or
removed conveniently, leading to great scalability. Extensive experiments on
multiple benchmarks demonstrate our framework's effectiveness, which
outperforms the unified model by an average of 10%. We further provide insights
into potential improvements, practical experience, and extensions of our
framework.

</details>


### [13] [Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems](https://arxiv.org/abs/2506.22852)
*Yucheng Cai,Yuxuan Wu,Yi Huang,Junlan Feng,Zhijian Ou*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出知识增强微调（KAFT）方法，通过在特定领域数据上微调LLMs，提升其在检索增强生成（RAG）和基于代理的系统中的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在对话系统中取得进展，但在知识密集型场景中容易出错。现有方法（如RAG和代理）通过外部知识库增强LLMs，但LLMs可能难以有效利用检索到的知识。

Method: 提出KAFT方法，结合领域特定数据和外部知识微调LLMs，并在MobileCS2数据集上比较KAFT与提示技术的效果。

Result: 实验表明，KAFT在RAG和代理系统中显著优于提示技术，特别是在事实准确性方面。

Conclusion: KAFT是首个实证研究该方法的论文，为提升LLMs在知识密集型任务中的表现提供了新思路。

Abstract: Large language models (LLMs) have recently been applied to dialog systems.
Despite making progress, LLMs are prone to errors in knowledge-intensive
scenarios. Recently, approaches based on retrieval augmented generation (RAG)
and agent have emerged to improve the factual accuracy by enhancing the LLMs
with knowledge retrieved from external knowledge bases (KBs). This is mostly
implemented by prompting the LLMs with instructions, examples and the retrieved
knowledge. However, LLMs may have difficulty using the retrieved knowledge
effectively for response generation, because they are not well trained to do
such generation for specific domains. To mitigate this problem, we propose to
finetune the LLMs in the RAG-based and agent-based systems with domain-specific
data, together with domain-specific external knowledge, which is called
knowledge augmented finetuning (KAFT). We base our study on the MobileCS2
dataset, a real-life customer service dialog dataset that features intensive
knowledge interactions, to systematically compare the prompting and KAFT
techniques in the RAG-based and agent-based systems. Experiment results show
that KAFT substantially surpasses prompting in both RAG and agent systems,
particularly in terms of factual accuracy. To the best of our knowledge, this
paper represents the first solid empirical work to investigate the KAFT idea.

</details>


### [14] [Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models](https://arxiv.org/abs/2506.22957)
*Younwoo Choi,Changling Li,Yongjin Yang,Zhijing Jin*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文研究了大型语言模型（LLMs）的对话伙伴意识（interlocutor awareness），即LLMs识别和适应对话伙伴身份和特征的能力，并首次系统评估了当代LLMs中这一能力的表现。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在多代理和人类-AI系统中的广泛应用，理解其对自身上下文和对话伙伴的意识对确保可靠性能和安全性至关重要。现有研究主要关注情境意识（situational awareness），而忽视了对话伙伴意识的评估。

Method: 论文将对话伙伴意识形式化，并从推理模式、语言风格和对齐偏好三个维度评估LLMs的能力。通过案例研究展示了对话伙伴意识在多LLM协作中的实际应用及其潜在风险。

Result: 研究发现LLMs能可靠识别同家族模型（如GPT和Claude），并展示了对话伙伴意识在增强协作和引入新安全漏洞（如奖励黑客行为和越狱易感性）方面的双重影响。

Conclusion: 对话伙伴意识在LLMs中具有双重性，既可能提升协作效率，也可能带来新的安全风险，需进一步研究和防护措施。

Abstract: As large language models (LLMs) are increasingly integrated into multi-agent
and human-AI systems, understanding their awareness of both self-context and
conversational partners is essential for ensuring reliable performance and
robust safety. While prior work has extensively studied situational awareness
which refers to an LLM's ability to recognize its operating phase and
constraints, it has largely overlooked the complementary capacity to identify
and adapt to the identity and characteristics of a dialogue partner. In this
paper, we formalize this latter capability as interlocutor awareness and
present the first systematic evaluation of its emergence in contemporary LLMs.
We examine interlocutor inference across three dimensions-reasoning patterns,
linguistic style, and alignment preferences-and show that LLMs reliably
identify same-family peers and certain prominent model families, such as GPT
and Claude. To demonstrate its practical significance, we develop three case
studies in which interlocutor awareness both enhances multi-LLM collaboration
through prompt adaptation and introduces new alignment and safety
vulnerabilities, including reward-hacking behaviors and increased jailbreak
susceptibility. Our findings highlight the dual promise and peril of
identity-sensitive behavior in LLMs, underscoring the need for further
understanding of interlocutor awareness and new safeguards in multi-agent
deployments. Our code is open-sourced at
https://github.com/younwoochoi/InterlocutorAwarenessLLM.

</details>


### [15] [On the Generalizability of "Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals"](https://arxiv.org/abs/2506.22977)
*Asen Dotsinski,Udit Thakur,Marko Ivanov,Mohammad Hafeez Khan,Maria Heuss*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文复现了Ortu等人（2024）关于语言模型中事实与反事实信息竞争的研究，验证了其核心发现，并扩展了实验到更大模型、不同提示结构和领域，发现注意力头消融方法的有效性因模型架构、提示结构和领域而异。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型如何处理事实与反事实信息的竞争机制，验证并扩展Ortu等人的发现，探讨模型规模、提示结构和领域对机制竞争的影响。

Method: 复现Ortu等人的实验，扩展到更大模型（如Llama 3.1 8B），修改提示结构（避免重复反事实陈述或改变前提词），测试不同领域的提示。

Result: 发现注意力头在更大模型中专业化程度降低，提示结构变化显著影响反事实标记的logit，某些领域提示会扭曲结果。注意力头消融方法对数据集中代表性不足的领域无效。

Conclusion: 模型架构、提示结构和领域显著影响注意力头消融方法的有效性，需针对具体任务和领域优化方法。

Abstract: We present a reproduction study of "Competition of Mechanisms: Tracing How
Language Models Handle Facts and Counterfactuals" (Ortu et al., 2024), which
investigates competition of mechanisms in language models between factual
recall and counterfactual in-context repetition. Our study successfully
reproduces their primary findings regarding the localization of factual and
counterfactual information, the dominance of attention blocks in mechanism
competition, and the specialization of attention heads in handling competing
information. We reproduce their results on both GPT-2 (Radford et al., 2019)
and Pythia 6.9B (Biderman et al., 2023). We extend their work in three
significant directions. First, we explore the generalizability of these
findings to even larger models by replicating the experiments on Llama 3.1 8B
(Grattafiori et al., 2024), discovering greatly reduced attention head
specialization. Second, we investigate the impact of prompt structure by
introducing variations where we avoid repeating the counterfactual statement
verbatim or we change the premise word, observing a marked decrease in the
logit for the counterfactual token. Finally, we test the validity of the
authors' claims for prompts of specific domains, discovering that certain
categories of prompts skew the results by providing the factual prediction
token as part of the subject of the sentence. Overall, we find that the
attention head ablation proposed in Ortu et al. (2024) is ineffective for
domains that are underrepresented in their dataset, and that the effectiveness
varies based on model architecture, prompt structure, domain and task.

</details>


### [16] [From Individuals to Interactions: Benchmarking Gender Bias in Multimodal Large Language Models from the Lens of Social Relationship](https://arxiv.org/abs/2506.23101)
*Yue Xu,Wenjie Wang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了Genres基准，用于评估多模态大语言模型（MLLMs）在双人交互中的性别偏见，揭示了单场景评估中未发现的上下文敏感偏见。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估孤立场景中的偏见，忽视了人际互动中可能出现的微妙偏见。

Method: 通过双角色配置和叙事生成任务设计Genres基准，评估MLLMs在多维度的性别偏见。

Result: 实验显示，MLLMs在双人交互中存在持续的、上下文敏感的性别偏见。

Conclusion: 关系感知的基准对诊断MLLMs中微妙的交互驱动偏见至关重要，并为未来偏见缓解提供了可行建议。

Abstract: Multimodal large language models (MLLMs) have shown impressive capabilities
across tasks involving both visual and textual modalities. However, growing
concerns remain about their potential to encode and amplify gender bias,
particularly in socially sensitive applications. Existing benchmarks
predominantly evaluate bias in isolated scenarios, overlooking how bias may
emerge subtly through interpersonal interactions. We fill this gap by going
beyond single-entity evaluation and instead focusing on a deeper examination of
relational and contextual gender bias in dual-individual interactions. We
introduce Genres, a novel benchmark designed to evaluate gender bias in MLLMs
through the lens of social relationships in generated narratives. Genres
assesses gender bias through a dual-character profile and narrative generation
task that captures rich interpersonal dynamics and supports a fine-grained bias
evaluation suite across multiple dimensions. Experiments on both open- and
closed-source MLLMs reveal persistent, context-sensitive gender biases that are
not evident in single-character settings. Our findings underscore the
importance of relationship-aware benchmarks for diagnosing subtle,
interaction-driven gender bias in MLLMs and provide actionable insights for
future bias mitigation.

</details>


### [17] [Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2506.23127)
*Zhaoye Fei,Li Ji,Siyin Wang,Junhao Shi,Jingjing Gong,Xipeng Qiu*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了Embodied Planner-R1框架，通过强化学习提升LLM在部分可观测环境中的任务规划能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在需要持续环境理解和动作生成的具身任务规划中的挑战，特别是因果关系的学习和部分可观测环境下的适应性问题。

Method: 结合纯强化学习与组内并行探索、完成驱动的稀疏奖励和交互式策略优化（IPO），无需人工标注。

Result: 在ALFWorld和ScienceWorld基准测试中分别达到97.78%和79.92%的完成率，泛化能力强。

Conclusion: Embodied Planner-R1框架显著提升了LLM在具身任务规划中的表现，展示了强化学习在LLM交互能力开发中的潜力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
various tasks, yet they face significant challenges in embodied task planning
scenarios that require continuous environmental understanding and action
generation. Existing approaches generate open-loop action scripts based on
static knowledge, making it difficult to learn causal relationships between
actions and environmental feedback, particularly in partially observable
environments. We introduce Embodied Planner-R1, a novel outcome-driven
reinforcement learning framework that enables LLMs to develop interactive
capabilities through autonomous exploration with minimal supervision. Our
framework incorporates three key innovations: (1) Without human annotations, we
employ pure reinforcement learning with group rollout, incorporating
in-environment interaction through parallel exploration; (2) completion-driven
sparse reward; and (3) Interactive Policy Optimization (IPO) for efficient
learning from grouped trajectories. Across two challenging text-based Embodied
planning benchmarks, Embodied Planner-R1 achieves impressive completion rates
of 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a
large margin, and suffers only a -3.66% drop in previously unseen environments,
evidencing strong generalization.

</details>


### [18] [Format-Adapter: Improving Reasoning Capability of LLMs by Adapting Suitable Format](https://arxiv.org/abs/2506.23133)
*Dingzirui Wang,Xuanliang Zhang,Rongyu Cao,Longxu Dou,Xianzhen Luo,Yingwei Ma,Qingfu Zhu,Wanxiang Che,Binhua Li,Fei Huang,Yongbin Li*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种通过生成和选择推理格式（Format-Adapter）来减少大型语言模型（LLMs）推理不一致性的方法，避免了人工标注的高成本，并在数学和常识推理任务中取得了4.3%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖人工标注推理格式的高成本和不适用性问题，通过自动生成和选择格式来优化LLMs的推理一致性。

Method: 提出了一种测量推理误差的方法，并设计了Format-Adapter，利用LLMs生成和选择适合任务的推理格式，以最小化误差。

Result: 在数学和常识推理任务中，Format-Adapter比之前的方法平均提升了4.3%的性能。

Conclusion: 自动生成和选择推理格式是一种有效的方法，能够显著提升LLMs的推理性能，同时降低人工标注成本。

Abstract: Generating and voting multiple answers is an effective method to mitigate
reasoning inconsistencies of large language models (LLMs). Prior works have
shown that multiple reasoning formats outperform a single format when
generating multiple answers. However, previous works using multiple formats
rely on formats labeled by humans, which could be unsuitable for all tasks and
have high labeling costs. To address this issue, we adapt suitable formats to
the given tasks by generating and selecting formats. We first propose how to
measure the reasoning error when generating multiple answers. Then, we
introduce Format-Adapter, which utilizes LLMs to generate and select suitable
reasoning formats by minimizing the error measurement we present. We conduct
experiments on math and commonsense reasoning tasks, where Format-Adapter
achieves a 4.3% performance improvement on average over previous works,
demonstrating the effectiveness.

</details>


### [19] [LLM-Assisted Question-Answering on Technical Documents Using Structured Data-Aware Retrieval Augmented Generation](https://arxiv.org/abs/2506.23136)
*Shadman Sobhan,Mohammad Ariful Haque*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种改进的RAG管道，能够处理技术文档中的表格和图像，结合向量相似性搜索和基于Gemma-2-9b-it的重新排序器，显著提升了问答的准确性和相关性。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG在处理复杂技术文档（如表格和图像）时的局限性，提升LLMs在技术文档问答中的性能。

Method: 结合向量相似性搜索和基于Gemma-2-9b-it的重新排序器，使用RAFT方法在自定义数据集上训练。

Result: 在RAGas和DeepEval评估中，分别达到94%和96%的忠实度，以及87%和93%的答案相关性。

Conclusion: 提出的RAG管道在技术文档问答中优于传统方法，尤其在处理表格和上下文外问题时表现突出。

Abstract: Large Language Models (LLMs) are capable of natural language understanding
and generation. But they face challenges such as hallucination and outdated
knowledge. Fine-tuning is one possible solution, but it is resource-intensive
and must be repeated with every data update. Retrieval-Augmented Generation
(RAG) offers an efficient solution by allowing LLMs to access external
knowledge sources. However, traditional RAG pipelines struggle with retrieving
information from complex technical documents with structured data such as
tables and images. In this work, we propose a RAG pipeline, capable of handling
tables and images in documents, for technical documents that support both
scanned and searchable formats. Its retrieval process combines vector
similarity search with a fine-tuned reranker based on Gemma-2-9b-it. The
reranker is trained using RAFT (Retrieval-Augmented Fine-Tuning) on a custom
dataset designed to improve context identification for question answering. Our
evaluation demonstrates that the proposed pipeline achieves a high faithfulness
score of 94% (RAGas) and 96% (DeepEval), and an answer relevancy score of 87%
(RAGas) and 93% (DeepEval). Comparative analysis demonstrates that the proposed
architecture is superior to general RAG pipelines in terms of table-based
questions and handling questions outside context.

</details>


### [20] [Learning-to-Context Slope: Evaluating In-Context Learning Effectiveness Beyond Performance Illusions](https://arxiv.org/abs/2506.23146)
*Dingzriui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种名为LCS的新指标，用于量化上下文学习（ICL）的有效性，解决了现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 上下文学习（ICL）在不同模型和任务中效果差异显著，现有评估方法可靠性低且不实用。

Method: 通过建模学习增益与上下文相关性之间的斜率（LCS）来量化ICL有效性，减少对标注数据的依赖。

Result: LCS在标注数据场景中与性能提升强相关，在数据稀缺或偏差场景中仍能可靠反映有效性。

Conclusion: LCS为ICL的有效性评估提供了更可靠的方法，并揭示了模型能力的关键阈值。

Abstract: In-context learning (ICL) has emerged as an effective approach to enhance the
performance of large language models (LLMs). However, its effectiveness varies
significantly across models and tasks, posing challenges for practitioners to
determine when ICL reliably improves performance. Current evaluation
approaches, reliant on performance change after applying ICL, suffer from low
reliability, poor attribution, and impracticality in data-insufficient
scenarios. We propose the Learning-to-Context Slope (LCS), a novel metric that
quantifies ICL effectiveness by modeling the slope between learning gain (loss
decrease from demonstrations) and contextual relevance (demonstration-input
relevance). LCS addresses key limitations of performance-based metrics: (1) it
captures continuous loss changes even when outputs are incorrect, improving
reliability; (2) its formulation attributes ICL failures to weak contextual
alignment (inability to adapt inputs to demonstrations) or strong output
calibration (self-verification of correctness); and (3) it minimizes reliance
on labeled data via synthetic evaluation. Extensive experiments demonstrate
that LCS strongly correlates with performance improvements in labeled settings
and reliably reflects true effectiveness in biased or data-scarce scenarios.
Further analysis reveals actionable thresholds for LCS and identifies model
capabilities critical to ICL success.

</details>


### [21] [V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy](https://arxiv.org/abs/2506.23149)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种名为V-Synthesis的方法，用于从零开始合成任意任务的演示，解决了现有方法依赖任务特定或预存演示的问题。通过V-Score一致性度量确保合成演示的高一致性和多样性。


<details>
  <summary>Details</summary>
Motivation: 降低上下文学习（ICL）演示的高标注成本，并解决现有合成方法依赖任务特定或预存演示的局限性。

Method: 提出V-Score一致性度量，并基于此开发V-Synthesis方法，通过比例采样确保合成演示的一致性和多样性。

Result: 实验结果显示，V-Synthesis平均性能提升2.0%，优于现有合成方法。

Conclusion: V-Synthesis有效解决了从零合成演示的挑战，提升了性能。

Abstract: High labeling cost for in-context learning (ICL) demonstrations motivates
using large language models (LLMs) for synthesis to reduce overhead. However,
existing synthesis methods are mainly task-specific or rely on pre-existing
demonstrations. So this paper focuses on synthesizing demonstrations from
scratch for arbitrary tasks. A major challenge in synthesizing from scratch is
ensuring consistency with the target task, as the lack of labeling guidance
could lead to synthesis bias. We first propose a consistency metric called
V-Score, which has higher performance and lower computation cost compared with
the metrics based on grams or embedding vectors. Furthermore, we introduce
V-Synthesis, which leverages V-Score for proportional sampling to ensure both
high consistency and diversity of synthesized demonstrations. Experimental
results demonstrate that V-Synthesis yields an average performance improvement
of 2.0% compared to existing synthesis methods confirming the effectiveness of
V-Synthesis.

</details>


### [22] [Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs](https://arxiv.org/abs/2506.23377)
*Taejin Kim,Siun-Chuon Mau,Konrad Vesey*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文提出了一种名为Perspective-Dial的方法，用于量化和管理大型语言模型（LLM）输出的视角和偏见。


<details>
  <summary>Details</summary>
Motivation: 由于LLM在关键任务中的广泛应用，但其输出中的偏见和视角缺乏量化理解，因此需要一种方法来控制和测量这些视角。

Method: Perspective-Dial包括两个主要组件：Perspective Space（用于量化不同视角的度量空间）和Systematic Prompt Engineering（基于反馈调整LLM输出视角的方法）。

Result: 该方法能够有效量化和调整LLM输出的视角，适用于检测、跟踪和减轻偏见，以及公共话语中的叙事检测和辩论机器人等应用。

Conclusion: Perspective-Dial为LLM输出的视角控制提供了一种实用的解决方案，尽管其依赖于经验方法而非理论理解。

Abstract: Large language models (LLMs) are used in a variety of mission-critical roles.
Due to the rapidly developing nature of LLMs, there is a lack of quantifiable
understanding of the bias and perspective associated with LLM output. Inspired
by this need, this paper considers the broader issue of perspective or
viewpoint of general text and perspective control of large-language model (LLM)
output. Perspective-Dial consists of two main components: a (1) metric space,
dubbed Perspective Space, that enables quantitative measurements of different
perspectives regarding a topic, and the use of (2) Systematic Prompt
Engineering that utilizes greedy-coordinate descent to control LLM output
perspective based on measurement feedback from the Perspective Space. The
empirical nature of the approach allows progress to side step a principled
understanding of perspective or bias -- effectively quantifying and adjusting
outputs for a variety of topics. Potential applications include detection,
tracking and mitigation of LLM bias, narrative detection, sense making and
tracking in public discourse, and debate bot advocating given perspective.

</details>


### [23] [Datasets for Fairness in Language Models: An In-Depth Survey](https://arxiv.org/abs/2506.23411)
*Jiale Zhang,Zichong Wang,Avash Palikhe,Zhipeng Yin,Wenbin Zhang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 该论文综述了语言模型公平性基准数据集，提出了统一评估框架，揭示了数据集中的偏见，并提供了选择和使用建议。


<details>
  <summary>Details</summary>
Motivation: 当前公平性基准数据集缺乏系统审查，可能导致评估偏差，影响模型公平性结论。

Method: 通过审查24个常用公平性数据集，提出统一评估框架，分析其来源、范围、内容和用途。

Result: 发现数据集存在一致的群体差异和偏见，影响公平性评估。

Conclusion: 建议更谨慎选择和使用数据集，并鼓励开发反映多样社会背景的新基准。

Abstract: Fairness benchmarks play a central role in shaping how we evaluate language
models, yet surprisingly little attention has been given to examining the
datasets that these benchmarks rely on. This survey addresses that gap by
presenting a broad and careful review of the most widely used fairness datasets
in current language model research, characterizing them along several key
dimensions including their origin, scope, content, and intended use to help
researchers better appreciate the assumptions and limitations embedded in these
resources. To support more meaningful comparisons and analyses, we introduce a
unified evaluation framework that reveals consistent patterns of demographic
disparities across datasets and scoring methods. Applying this framework to
twenty four common benchmarks, we highlight the often overlooked biases that
can influence conclusions about model fairness and offer practical guidance for
selecting, combining, and interpreting these datasets. We also point to
opportunities for creating new fairness benchmarks that reflect more diverse
social contexts and encourage more thoughtful use of these tools going forward.
All code, data, and detailed results are publicly available at
https://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets
to promote transparency and reproducibility across the research community.

</details>


### [24] [TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs](https://arxiv.org/abs/2506.23423)
*Felipe Nuti,Tim Franzmeyer,João Henriques*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种新方法（TuCo）量化微调对LLM输出的贡献，通过分解模型为预训练和微调组件，并发现微调分量在对抗攻击中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 缺乏系统方法分析微调对LLM输出的具体影响，尤其是对抗攻击中的安全性问题。

Method: 追踪模型中间隐藏状态，分解模型为预训练和微调组件，定义TuCo（微调贡献比）。

Result: 发现对抗攻击通过降低TuCo绕过安全措施，TuCo在攻击成功时显著较低。

Conclusion: TuCo为研究微调对模型行为和安全性的影响提供了量化工具。

Abstract: Past work has studied the effects of fine-tuning on large language models'
(LLMs) overall performance on certain tasks. However, a quantitative and
systematic method for analyzing its effect on individual outputs is still
lacking. Here, we propose a new method for measuring the contribution that
fine-tuning makes to individual LLM responses, assuming access to the original
pre-trained model. Our method tracks the model's intermediate hidden states,
providing a more fine-grained insight into the effects of fine-tuning than a
simple comparison of final outputs from pre-trained and fine-tuned models. We
introduce and theoretically analyze an exact decomposition of any fine-tuned
LLM into a pre-training component and a fine-tuning component. Empirically, we
find that model behavior and performance can be steered by up- or down-scaling
the fine-tuning component during the forward pass. Motivated by this finding
and our theoretical analysis, we define the Tuning Contribution (TuCo) as the
ratio of the magnitudes of the fine-tuning component to the pre-training
component. We observe that three prominent adversarial attacks on LLMs
circumvent safety measures in a way that reduces TuCo, and that TuCo is
consistently lower on prompts where these attacks succeed compared to those
where they do not. This suggests that attenuating the effect of fine-tuning on
model outputs plays a role in the success of such attacks. In summary, TuCo
enables the quantitative study of how fine-tuning influences model behavior and
safety, and vice versa.

</details>


### [25] [Pipelined Decoder for Efficient Context-Aware Text Generation](https://arxiv.org/abs/2506.23431)
*Zixian Huang,Chenxu Niu,Yu Gu,Gengyang Xiao,Xinwei Huang,Gong Cheng*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种新的解码器架构，通过并行生成多个子序列来加速文本生成，同时保持生成质量和内存效率。


<details>
  <summary>Details</summary>
Motivation: 自回归模型生成高质量文本但速度受限，需要一种并行生成方法以提升效率。

Method: 设计了一种流水线解码器，同时生成多个子序列以实现并行化。

Result: 在多项文本生成任务中，生成速度显著提升，且未显著影响质量或增加内存消耗。

Conclusion: 流水线解码器有效解决了自回归模型的生成速度瓶颈。

Abstract: As the basis of generative AI, an autoregressive model requires the
generation of a new token depending on all the previously generated tokens,
which brings high quality but also restricts the model to generate tokens one
by one, forming a bottleneck limiting the generation speed. In this paper, we
propose a new decoder architecture that efficiently generates text in parallel
for context-aware generation tasks. Our proposed pipelined decoder initiates
the generation of multiple subsequences simultaneously, and, at each time-step,
it generates a new token for each subsequence to realize parallelism.
Experiments on multiple text generation tasks, including question answering,
text summarization, and keyphrase generation, show that our pipelined decoder
significantly improves the generation speed without a significant loss of
generation quality or additional memory consumption.

</details>


### [26] [Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent](https://arxiv.org/abs/2506.23485)
*Haocheng Yu,Yaxiong Wu,Hao Wang,Wei Guo,Yong Liu,Yawen Li,Yuyang Ye,Junping Du,Enhong Chen*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种基于大型语言模型的多智能体系统TAIRA，通过思维模式蒸馏增强规划能力，有效处理交互式推荐中的复杂用户意图。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的交互式推荐系统在规划与泛化能力上有限，难以应对多样复杂的用户意图。

Method: 设计了一个多智能体系统TAIRA，采用思维模式蒸馏（TPD）增强规划能力，并通过用户模拟方案评估性能。

Result: TAIRA在多个数据集上表现优于现有方法，尤其在复杂任务上优势明显。

Conclusion: TAIRA通过思维增强有效提升了交互式推荐系统的性能，适用于复杂用户意图场景。

Abstract: Interactive recommendation is a typical information-seeking task that allows
users to interactively express their needs through natural language and obtain
personalized recommendations. Large language model-powered (LLM-powered) agents
have become a new paradigm in interactive recommendations, effectively
capturing users' real-time needs and enhancing personalized experiences.
However, due to limited planning and generalization capabilities, existing
formulations of LLM-powered interactive recommender agents struggle to
effectively address diverse and complex user intents, such as intuitive,
unrefined, or occasionally ambiguous requests. To tackle this challenge, we
propose a novel thought-augmented interactive recommender agent system (TAIRA)
that addresses complex user intents through distilled thought patterns.
Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring
a manager agent that orchestrates recommendation tasks by decomposing user
needs and planning subtasks, with its planning capacity strengthened through
Thought Pattern Distillation (TPD), a thought-augmentation method that extracts
high-level thoughts from the agent's and human experts' experiences. Moreover,
we designed a set of user simulation schemes to generate personalized queries
of different difficulties and evaluate the recommendations based on specific
datasets. Through comprehensive experiments conducted across multiple datasets,
TAIRA exhibits significantly enhanced performance compared to existing methods.
Notably, TAIRA shows a greater advantage on more challenging tasks while
generalizing effectively on novel tasks, further validating its superiority in
managing complex user intents within interactive recommendation systems. The
code is publicly available at:https://github.com/Alcein/TAIRA.

</details>


### [27] [Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably](https://arxiv.org/abs/2506.23508)
*Zhihao Zhang,Qiaole Dong,Qi Zhang,Jun Zhao,Enyu Zhou,Zhiheng Xi,Senjie Jin,Xiaoran Fan,Yuhao Zhou,Yanwei Fu,Tao Ji,Tao Gui,Xuanjing Huang*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究探讨了SFT和RFT在多模态大语言模型中对任务适应性和先验知识的影响，发现SFT快速适应任务但导致灾难性遗忘，而RFT学习较慢但保留先验知识。


<details>
  <summary>Details</summary>
Motivation: 理解SFT和RFT在多模态大语言模型中对任务适应性和先验知识的影响，以优化模型持续学习能力。

Method: 通过引入拼图任务，系统研究SFT和RFT在Qwen2.5-VL模型上的行为，分析学习动态。

Result: SFT快速适应任务但导致灾难性遗忘，RFT学习较慢但保留先验知识，数据分布是关键因素。

Conclusion: RFT在多模态大语言模型中具有稳定持续学习的潜力，数据分布对遗忘起核心作用。

Abstract: Post-training algorithms such as Supervised Fine-Tuning (SFT) and
Reinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large
language models to downstream tasks. While effective at task adaptation, their
impact on prior knowledge remains unclear. In this paper, we introduce jigsaw
puzzles as a novel task absent from existing pretraining corpora and
systematically study the behavior of SFT and RFT on an open-source multimodal
model, Qwen2.5-VL. Our experiments reveal a sharp trade-off: SFT enables rapid
task acquisition but leads to catastrophic forgetting, whereas RFT learns more
slowly on novel tasks but maintains prior knowledge. We analyze this phenomenon
through the lens of learning dynamics, showing that RFT reinforces correct
samples that are naturally aligned with the base model's probability landscape,
mitigating interference with prior knowledge. Moreover, supervised training on
correct RFT-simulated rollouts allows SFT to preserve knowledge while rapidly
learning new tasks. These findings suggest that data distribution, rather than
algorithmic differences, plays a central role in forgetting, and highlight
RFT's potential for stable continual learning in multimodal large language
models.

</details>


### [28] [On Recipe Memorization and Creativity in Large Language Models: Is Your Model a Creative Cook, a Bad Cook, or Merely a Plagiator?](https://arxiv.org/abs/2506.23527)
*Jan Kvapil,Martin Fajcik*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究分析了LLM生成的食谱中的记忆性、创造性和无意义内容，通过人工标注和自动化方法评估模型表现。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在生成内容时的记忆依赖、创造性合成能力及无意义输出的程度，以评估模型的真实创造力。

Method: 结合人工标注（20个食谱）和自动化LLM-as-judge流程（如Llama 3.1+Gemma 2 9B）分析记忆性、创造性和无意义内容。

Result: Mixtral依赖记忆内容；自动化方法在成分匹配上达到78%准确率。

Conclusion: 自动化框架可大规模量化LLM的创造力，揭示其记忆依赖与创造性合成的平衡。

Abstract: This work-in-progress investigates the memorization, creativity, and nonsense
found in cooking recipes generated from Large Language Models (LLMs).
Precisely, we aim (i) to analyze memorization, creativity, and non-sense in
LLMs using a small, high-quality set of human judgments and (ii) to evaluate
potential approaches to automate such a human annotation in order to scale our
study to hundreds of recipes. To achieve (i), we conduct a detailed human
annotation on 20 preselected recipes generated by LLM (Mixtral), extracting
each recipe's ingredients and step-by-step actions to assess which elements are
memorized--i.e., directly traceable to online sources possibly seen during
training--and which arise from genuine creative synthesis or outright nonsense.
We find that Mixtral consistently reuses ingredients that can be found in
online documents, potentially seen during model training, suggesting strong
reliance on memorized content. To achieve aim (ii) and scale our analysis
beyond small sample sizes and single LLM validation, we design an
``LLM-as-judge'' pipeline that automates recipe generation, nonsense detection,
parsing ingredients and recipe steps, and their annotation. For instance,
comparing its output against human annotations, the best ingredient extractor
and annotator is Llama 3.1+Gemma 2 9B, achieving up to 78% accuracy on
ingredient matching. This automated framework enables large-scale
quantification of memorization, creativity, and nonsense in generated recipes,
providing rigorous evidence of the models' creative capacities.

</details>


### [29] [Semantic-guided Diverse Decoding for Large Language Model](https://arxiv.org/abs/2506.23601)
*Weijie Shi,Yue Cui,Yaguang Wu,Jingzhi Fang,Shibo Zhang,Mengze Li,Sirui Han,Jia Zhu,Jiajie Xu,Xiaofang Zhou*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了一种名为SemDiD的方法，通过在嵌入空间中平衡质量和多样性，显著提升了语义多样性解码的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注词汇多样性而非语义多样性，限制了Best-of-N策略、基于群体的强化学习和数据合成的效果。

Method: SemDiD通过正交方向引导、动态组间排斥和位置去偏概率评估三种机制，在嵌入空间中实现语义多样性解码。

Result: 实验表明，SemDiD在Best-of-N覆盖率上提升了1.4-5.2%，并加速了RLHF训练的收敛速度（15%），同时提高了准确性（最高2.1%）。

Conclusion: SemDiD有效解决了语义多样性解码的挑战，为LLM的多样化应用提供了新工具。

Abstract: Diverse decoding of large language models is crucial for applications
requiring multiple semantically distinct responses, yet existing methods
primarily achieve lexical rather than semantic diversity. This limitation
significantly constrains Best-of-N strategies, group-based reinforcement
learning, and data synthesis. While temperature sampling and diverse beam
search modify token distributions or apply n-gram penalties, they fail to
ensure meaningful semantic differentiation. We introduce Semantic-guided
Diverse Decoding (SemDiD), operating directly in embedding space that balances
quality with diversity through three complementary mechanisms: orthogonal
directional guidance, dynamic inter-group repulsion, and position-debiased
probability assessment. SemDiD harmonizes these competing objectives using
adaptive gain functions and constraint optimization, ensuring both quality
thresholds and maximal semantic differentiation. Experiments show SemDiD
consistently outperforms existing methods, improving Best-of-N coverage by
1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15%
while increasing accuracy by up to 2.1%.

</details>


### [30] [L0: Reinforcement Learning to Become General Agents](https://arxiv.org/abs/2506.23667)
*Junjie Zhang,Jingyi Xi,Zhuoyang Song,Junyu Lu,Yuhua Ke,Ting Sun,Yukun Yang,Jiaxing Zhang,Songxin Zhang,Zejian Xie*

Main category: cs.CL

Relevance: 85.0

TL;DR: L-Zero (L0) 是一个可扩展的端到端训练管道，用于训练通用自主代理，通过低成本、可扩展的并发代理工作池和代码即行动的 NB-Agent 提升强化学习的效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型（LLMs）在多轮、长周期任务中作为自主代理时的可扩展性和训练效率问题。

Method: 引入 L0 训练管道和 NB-Agent，采用代码即行动的方式，通过 REPL 实现强化学习。

Result: 在 SimpleQA 和 HotpotQA 基准测试中，准确率分别从 30% 提升至 80% 和从 22% 提升至 41%。

Conclusion: L0 系统通过 RLVR 显著提升了模型的解决问题的能力，并开源了完整的训练管道和模型。

Abstract: Training large language models (LLMs) to act as autonomous agents for
multi-turn, long-horizon tasks remains significant challenges in scalability
and training efficiency. To address this, we introduce L-Zero (L0), a scalable,
end-to-end training pipeline for general-purpose agents. Featuring a low-cost,
extensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier
for applying reinforcement learning in complex environments. We also introduce
NB-Agent, the agent scaffold within L0, which operates in a "code-as-action"
fashion via a Read-Eval-Print-Loop (REPL). We evaluate L0 on factuality
question-answering benchmarks. Our experiments demonstrate that a base model
can develop robust problem-solving skills using solely Reinforcement Learning
with Verifiable Rewards (RLVR). On the Qwen2.5-7B-Instruct model, our method
boosts accuracy on SimpleQA from 30 % to 80 % and on HotpotQA from 22 % to 41
%. We have open-sourced the entire L0 system, including our L0 series models,
the NB-Agent, a complete training pipeline, and the corresponding training
recipes on (https://github.com/cmriat/l0).

</details>


### [31] [AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data](https://arxiv.org/abs/2506.23735)
*JiaRu Wu,Mingwei Liu*

Main category: cs.CL

Relevance: 85.0

TL;DR: AutoEvoEval是一个基于进化的评估框架，用于生成多样化和具有挑战性的测试样本，以更全面地评估大型语言模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准多为静态，无法全面评估大型语言模型在真实场景中的鲁棒性和泛化能力。

Method: 提出AutoEvoEval框架，包含22种可解释的原子进化操作，支持多轮组合生成多样化测试样本。

Result: 实验显示原子操作平均导致准确率下降7.283%，多步组合可放大对抗效应达52.932%。

Conclusion: 当前基准可能高估模型泛化能力，需进化感知的鲁棒性评估。

Abstract: Large language models (LLMs) have shown remarkable performance on various
tasks, but existing evaluation benchmarks are often static and insufficient to
fully assess their robustness and generalization in realistic scenarios. Prior
work using evolutionary or adversarial data augmentation has improved
evaluation diversity but lacks systematic control over perturbation types and
multi-step complexity, limiting comprehensive robustness analysis. To address
these gaps, we propose AutoEvoEval, an evolution-based evaluation framework for
close-ended tasks such as multi-choice question answering. AutoEvoEval
introduces 22 interpretable atomic evolution operations and supports
multi-round compositions, enabling controlled generation of diverse,
challenging, and realistic test samples. We conduct extensive experiments
addressing four research questions on a broad set of open- and closed-source
LLMs. Our results show that atomic operations cause an average accuracy drop of
7.283\%, with structure-disrupting or misleading semantic edits causing the
largest declines. Model sensitivities vary significantly for the same
perturbation, and combining multiple evolution steps amplifies adversarial
effects by up to 52.932\%. These findings suggest current benchmarks may
overestimate true model generalization and emphasize the need for
evolution-aware robustness evaluation. Code and resources are available at:
https://github.com/SYSUSELab/AutoEvoEval.

</details>


### [32] [Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model](https://arxiv.org/abs/2506.23840)
*Bowen Ding,Yuhan Chen,Futing Wang,Lingfeng Ming,Tao Lin*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出Dual Policy Preference Optimization (DuP-PO)算法，解决大型推理模型(LRMs)在简单任务中因过度思考而降低效率的问题。


<details>
  <summary>Details</summary>
Motivation: LRMs在处理简单任务时会产生冗余的思考标记，触发不必要的高级推理行为，降低效率。

Method: 提出DuP-PO算法，包括平衡采样策略、细粒度优势控制技术和策略塑造方法。

Result: 在五个数学推理基准测试中，DuP-PO显著提高了LRM的标记效率，同时保持了基础模型的性能。

Conclusion: DuP-PO有效缓解了LRMs的过度思考问题，提升了推理效率。

Abstract: Large Reasoning Models (LRMs) excel at solving complex problems but face an
overthinking dilemma. When handling simple tasks, they often produce verbose
responses overloaded with thinking tokens (e.g., wait, however). These tokens
trigger unnecessary high-level reasoning behaviors like reflection and
backtracking, reducing efficiency. In this work, our pilot study reveals that
these thinking-token-induced behaviors are not essential for effective
problem-solving and may even hinder correct reasoning within constrained token
budgets. We identify this phenomenon as the thinking trap. To mitigate this
issue, we propose Dual Policy Preference Optimization (DuP-PO), a novel
algorithm featuring: (1) A rollout sampling strategy that guarantees balanced
exposure to responses with and without thinking tokens; (2) A fine-grained
advantage control technique to dynamically regulate the prediction of target
tokens; (3) A policy shaping method ensuring stable gradient contributions from
thinking tokens. Experimental results on five popular math reasoning benchmarks
show that DuP-PO performs well on the popular LRM, which significantly improves
their token efficiency during reasoning, while achieving superior performance
of the base model.

</details>


### [33] [Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It](https://arxiv.org/abs/2506.23864)
*Seyed Mahed Mousavi,Edoardo Cecchinato,Lucia Hornikova,Giuseppe Riccardi*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文系统审计了三个广泛使用的推理基准（SocialIQa、FauxPas-EAI、ToMi），发现基准设计和评估方法存在普遍缺陷。通过五个LLM的诊断工具，揭示了结构、语义和语用问题，并指出评分程序过于注重输出形式而非推理过程。重新评估后，模型分数提升多源于表面变化而非推理改进，表明当前基准对LLM推理能力的评估有效性存疑。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理能力的评估基准存在设计和方法上的缺陷，可能导致对模型能力的误解。通过系统审计，揭示这些问题并提出改进方向。

Method: 使用五个LLM（GPT-3、3.5、4、o1和LLaMA 3.1）作为诊断工具，结合人工标注和重新评估，分析基准设计和评分方法的缺陷。

Result: 发现基准存在重复项、模糊表述和不可信答案等问题，模型性能对输入微小变化敏感，高分可能源于格式对齐而非推理能力。

Conclusion: 当前基准对LLM推理能力的评估有效性存疑，需开发更注重推理过程的评估协议。

Abstract: We conduct a systematic audit of three widely used reasoning benchmarks,
SocialIQa, FauxPas-EAI, and ToMi, and uncover pervasive flaws in both benchmark
items and evaluation methodology. Using five LLMs (GPT-{3, 3.5, 4, o1}, and
LLaMA 3.1) as diagnostic tools, we identify structural, semantic, and pragmatic
issues in benchmark design (e.g., duplicated items, ambiguous wording, and
implausible answers), as well as scoring procedures that prioritize output form
over reasoning process. Through systematic human annotation and re-evaluation
on cleaned benchmark subsets, we find that model scores often improve not due
to due to erratic surface wording variations and not to improved reasoning.
Infact, further analyses show that model performance is highly sensitive to
minor input variations such as context availability and phrasing, revealing
that high scores may reflect alignment with format-specific cues rather than
consistent inference based on the input. These findings challenge the validity
of current benchmark-based claims about reasoning in LLMs, and highlight the
need for evaluation protocols that assess reasoning as a process of drawing
inference from available information, rather than as static output selection.
We release audited data and evaluation tools to support more interpretable and
diagnostic assessments of model reasoning.

</details>


### [34] [Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting](https://arxiv.org/abs/2506.23888)
*André de Souza Loureiro,Jorge Valverde-Rebaza,Julieta Noguez,David Escarcega,Ricardo Marcacini*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出了MAPS框架，通过结合CoT、自我反思和自动提示，提升LLM在多步数学推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: LLM在多步推理任务中表现不佳，需要动态方法来提升其能力。

Method: 结合CoT、自我反思和自动提示，通过迭代优化动态调整提示。

Result: 在多个基准测试中显著优于标准CoT，接近专用推理模型的性能。

Conclusion: MAPS在成本与性能间取得平衡，适用于通用LLM。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly
improved their problem-solving capabilities. However, these models still
struggle when faced with complex multi-step reasoning tasks. In this paper, we
propose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework,
a novel approach designed to enhance multi-step mathematical reasoning in LLMs
by integrating techniques such as Chain of Thought (CoT), Self-Reflection, and
Auto-Prompting. Unlike traditional static prompting methods, MAPS employs an
iterative refinement process. Initially, the model generates a solution using
CoT prompting. When errors are detected, an adaptive self-reflection mechanism
identifies and analyzes them, generating tailored prompts to guide corrections.
These dynamically adjusted prompts enable the model to iteratively refine its
reasoning. Experiments on four well-established benchmarks across multiple LLMs
show that MAPS significantly outperforms standard CoT and achieves competitive
results with reasoning-optimized models. In addition, MAPS enables
general-purpose LLMs to reach performance levels comparable to specialized
reasoning models. While deeper reflection layers improve accuracy, they also
increase token usage and costs. To balance this trade-off, MAPS strategically
limits reflection depth, ensuring an optimal balance between cost and reasoning
performance.

</details>


### [35] [The Trilemma of Truth in Large Language Models](https://arxiv.org/abs/2506.23921)
*Germans Savcisens,Tina Eliassi-Rad*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文提出了一种名为sAwMIL的新方法，用于评估大型语言模型（LLMs）内部知识的真实性，并揭示了关于LLM知识验证的五个关键发现。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决现有评估LLM知识真实性的方法中的缺陷，并提出更可靠的验证方法。

Method: sAwMIL是一种基于多实例学习和符合预测的探测方法，利用LLM的内部激活来区分真实、虚假和中性陈述。

Result: 研究发现：（1）真实性信号集中在LLM深度的第三部分；（2）真实和虚假信号不对称；（3）线性探测在聊天模型上表现更好；（4）非线性探测适用于某些经过RLHF或知识蒸馏的LLM；（5）LLM捕获了第三种信号（既非真实也非虚假）。

Conclusion: sAwMIL提供了一种可靠的方法来验证LLM的内部知识及其确定性。

Abstract: We often attribute human characteristics to large language models (LLMs) and
claim that they "know" certain things. LLMs have an internal probabilistic
knowledge that represents information retained during training. How can we
assess the veracity of this knowledge? We examine two common methods for
probing the veracity of LLMs and discover several assumptions that are flawed.
To address these flawed assumptions, we introduce sAwMIL (short for Sparse
Aware Multiple-Instance Learning), a probing method that utilizes the internal
activations of LLMs to separate statements into true, false, and neither.
sAwMIL is based on multiple-instance learning and conformal prediction. We
evaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including
both default and chat-based variants, as well as on 3 new datasets. Among the
insights we provide are: (1) the veracity signal is often concentrated in the
third quarter of an LLM's depth; (2) truth and falsehood signals are not always
symmetric; (3) linear probes perform better on chat models than on default
models; (4) nonlinear probes may be required to capture veracity signals for
some LLMs with reinforcement learning from human feedback or knowledge
distillation; and (5) LLMs capture a third type of signal that is distinct from
true and false and is neither true nor false. These findings provide a reliable
method for verifying what LLMs "know" and how certain they are of their
probabilistic internal knowledge.

</details>


### [36] [IMPACT: Inflectional Morphology Probes Across Complex Typologies](https://arxiv.org/abs/2506.23929)
*Mohammed J. Saeed,Tommi Vehvilainen,Evgeny Fedoseev,Sevil Caliskan,Tatiana Vodolazova*

Main category: cs.CL

Relevance: 85.0

TL;DR: IMPACT是一个评估框架，用于测试大型语言模型（LLMs）在五种形态丰富语言中的形态学理解能力，发现模型在非英语语言中的表现不足。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在多语言形态学理解上的真实能力，揭示其在非英语语言中的局限性。

Method: 开发并公开了IMPACT框架，包含五种语言的合成测试用例，评估八种多语言LLMs的表现。

Result: LLMs在非英语语言和罕见形态模式上表现不佳，特别是对不合语法例子的判断能力较弱。

Conclusion: LLMs在多语言形态学理解上存在明显不足，需进一步改进。

Abstract: Large Language Models (LLMs) have shown significant progress on various
multilingual benchmarks and are increasingly used to generate and evaluate text
in non-English languages. However, while they may produce fluent outputs, it
remains unclear to what extent these models truly grasp the underlying
linguistic complexity of those languages, particularly in morphology. To
investigate this, we introduce IMPACT, a synthetically generated evaluation
framework focused on inflectional morphology, which we publicly release,
designed to evaluate LLM performance across five morphologically rich
languages: Arabic, Russian, Finnish, Turkish, and Hebrew. IMPACT includes
unit-test-style cases covering both shared and language-specific phenomena,
from basic verb inflections (e.g., tense, number, gender) to unique features
like Arabic's reverse gender agreement and vowel harmony in Finnish and
Turkish. We assess eight multilingual LLMs that, despite strong English
performance, struggle with other languages and uncommon morphological patterns,
especially when judging ungrammatical examples. We also show that Chain of
Thought and Thinking Models can degrade performance. Our work exposes gaps in
LLMs' handling of linguistic complexity, pointing to clear room for
improvement. To support further research, we publicly release the IMPACT
framework.

</details>


### [37] [Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders](https://arxiv.org/abs/2506.23951)
*Mathis Le Bail,Jérémie Dentan,Davide Buscaldi,Sonia Vanier*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文研究了稀疏自编码器（SAE）在句子分类任务中的解释性方法，提出了一种新架构，结合分类器头和稀疏损失，提升了特征的因果性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 探索SAE在句子分类领域的解释性方法，填补该领域的研究空白。

Method: 提出了一种新SAE架构，结合分类器头和激活率稀疏损失，并与现有方法（如ConceptShap、ICA等）进行对比。

Result: 在Pythia家族四个微调LLM上验证，新架构提升了特征的因果性和可解释性。

Conclusion: SAE在句子分类任务中具有潜力，新架构为解释性方法提供了改进方向。

Abstract: Sparse Autoencoders (SAEs) have been successfully used to probe Large
Language Models (LLMs) and extract interpretable concepts from their internal
representations. These concepts are linear combinations of neuron activations
that correspond to human-interpretable features. In this paper, we investigate
the effectiveness of SAE-based explainability approaches for sentence
classification, a domain where such methods have not been extensively explored.
We present a novel SAE-based architecture tailored for text classification,
leveraging a specialized classifier head and incorporating an activation rate
sparsity loss. We benchmark this architecture against established methods such
as ConceptShap, Independent Component Analysis, and other SAE-based concept
extraction techniques. Our evaluation covers two classification benchmarks and
four fine-tuned LLMs from the Pythia family. We further enrich our analysis
with two novel metrics for measuring the precision of concept-based
explanations, using an external sentence encoder. Our empirical results show
that our architecture improves both the causality and interpretability of the
extracted features.

</details>


### [38] [TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation](https://arxiv.org/abs/2506.23979)
*Renren Jin,Tianhao Shen,Xinwei Wu,Dan Shi,Haoran Sun,Wuwei Huang,Quandong Wang,Wei Liu,Jian Luan,Bin Wang,Deyi Xiong*

Main category: cs.CL

Relevance: 85.0

TL;DR: 提出TaP框架，自动化生成多语言偏好数据集，提升LLM的监督和偏好微调效果。


<details>
  <summary>Details</summary>
Motivation: 构建高质量多语言偏好数据集资源密集且现有数据集多为英文，需解决此问题。

Method: 基于结构化分类法的TaP框架，自动化生成多样化偏好数据集。

Result: TaP生成的数据集训练效果优于现有开源数据集，甚至优于180倍大的数据集。

Conclusion: TaP框架高效且可扩展，显著提升LLM微调性能。

Abstract: Conducting supervised fine-tuning and preference fine-tuning on large
language models (LLMs) requires high-quality datasets to improve their ability
to follow instructions and align with human preferences and values. However,
constructing such datasets is resource-intensive, and most available datasets
for supervised and preference fine-tuning are in English. To address these
challenges, we propose the \underline{\textbf{Ta}}xonomy-Guided
\underline{\textbf{P}}reference Data Generation (TaP) framework, which
facilitates automated and scalable construction of preference datasets across
various languages. TaP is grounded in a structured taxonomy that allows
fine-grained control over dataset composition, thereby ensuring both diversity
and comprehensive coverage. We employ TaP-generated datasets to perform
supervised and preference fine-tuning on various LLMs. Experimental results
demonstrate that LLMs trained on TaP-generated datasets outperform those
trained on existing open-source datasets. Remarkably, LLMs trained on
TaP-generated datasets surpass the performance of those trained on an
open-source dataset that is 180 times larger.

</details>


### [39] [STACK: Adversarial Attacks on LLM Safeguard Pipelines](https://arxiv.org/abs/2506.24068)
*Ian R. McKenzie,Oskar J. Hollinsworth,Tom Tseng,Xander Davies,Stephen Casper,Aaron D. Tucker,Robert Kirk,Adam Gleave*

Main category: cs.CL

Relevance: 85.0

TL;DR: 论文研究了AI防御管线的安全性，开发了一种新型的少样本提示分类器，并提出了一种分阶段攻击方法（STACK），在无目标管线访问的情况下仍能实现攻击。


<details>
  <summary>Details</summary>
Motivation: 前沿AI开发者依赖多层防护措施防止AI系统被滥用，但这些防护管线的安全性尚未充分评估。论文旨在填补这一空白。

Method: 开发并红队测试了一个开源防御管线，包括少样本提示分类器和STACK攻击方法。

Result: 少样本提示分类器在ClearHarm数据集上将攻击成功率降至0%，而STACK攻击在无目标管线访问时仍能达到33%的攻击成功率。

Conclusion: 开发者需采用特定缓解措施以抵御分阶段攻击。

Abstract: Frontier AI developers are relying on layers of safeguards to protect against
catastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus
model using one such defense pipeline, and other frontier developers including
Google DeepMind and OpenAI pledge to soon deploy similar defenses. However, the
security of such pipelines is unclear, with limited prior work evaluating or
attacking these pipelines. We address this gap by developing and red-teaming an
open-source defense pipeline. First, we find that a novel few-shot-prompted
input and output classifier outperforms state-of-the-art open-weight safeguard
model ShieldGemma across three attacks and two datasets, reducing the attack
success rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second,
we introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on
ClearHarm in a black-box attack against the few-shot-prompted classifier
pipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33%
ASR, providing initial evidence that it is feasible to design attacks with no
access to the target pipeline. We conclude by suggesting specific mitigations
that developers could use to thwart staged attacks.

</details>


### [40] [On the Predictive Power of Representation Dispersion in Language Models](https://arxiv.org/abs/2506.24106)
*Yanhong Li,Ming Li,Karen Livescu,Jiawei Zhou*

Main category: cs.CL

Relevance: 85.0

TL;DR: 研究发现语言模型的预测能力与其嵌入空间的广度紧密相关，表示分散度（隐藏向量间的平均余弦距离）与困惑度呈强负相关。分散度可用于模型选择、检索方法优化及训练目标改进。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型预测能力与嵌入空间广度的关系，为模型优化提供无监督方法。

Method: 通过测量不同模型和领域的表示分散度，分析其与困惑度的相关性，并设计实验验证分散度在模型选择、检索优化和训练改进中的应用。

Result: 表示分散度与困惑度呈强负相关；分散度可用于高效模型选择、优化检索方法，并通过训练目标改进直接提升模型性能。

Conclusion: 表示分散度是语言模型性能的重要指标，可用于多种无监督任务优化。

Abstract: We show that a language model's ability to predict text is tightly linked to
the breadth of its embedding space: models that spread their contextual
representations more widely tend to achieve lower perplexity. Concretely, we
find that representation dispersion - the average pairwise cosine distance
among hidden vectors - strongly and negatively correlates with perplexity
across diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia,
news, scientific abstracts). Beyond illustrating this link, we show how
dispersion can be leveraged for a range of practical tasks without requiring
labeled data. First, measuring dispersion on unlabeled text allows us to
predict downstream accuracy in new domains, offering a data-efficient tool for
model selection. Next, we find that identifying layers with higher dispersion
pinpoints the best representations for retrieval-based methods such as kNN-LM,
bypassing exhaustive layer-by-layer searches. Finally, we integrate a simple
push-away objective into training, which increases dispersion in both
single-domain and cross-domain scenarios and directly improves perplexity in
each.

</details>


### [41] [VERA: Variational Inference Framework for Jailbreaking Large Language Models](https://arxiv.org/abs/2506.22666)
*Anamika Lochab,Lu Yan,Patrick Pynadath,Xiangyu Zhang,Ruqi Zhang*

Main category: cs.CR

Relevance: 85.0

TL;DR: VERA是一种基于变分推理的黑盒越狱方法，通过训练小型攻击LLM生成多样化的对抗提示，无需重新优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖遗传算法和手动提示池，无法全面评估LLM漏洞，需要更高效的黑盒越狱方法。

Method: 将黑盒越狱建模为变分推理问题，训练攻击LLM近似目标LLM的对抗提示后验分布。

Result: VERA在多种目标LLM上表现优异，验证了概率推理在对抗提示生成中的价值。

Conclusion: VERA为黑盒越狱提供了高效且全面的解决方案，适用于实际场景中的漏洞评估。

Abstract: The rise of API-only access to state-of-the-art LLMs highlights the need for
effective black-box jailbreak methods to identify model vulnerabilities in
real-world settings. Without a principled objective for gradient-based
optimization, most existing approaches rely on genetic algorithms, which are
limited by their initialization and dependence on manually curated prompt
pools. Furthermore, these methods require individual optimization for each
prompt, failing to provide a comprehensive characterization of model
vulnerabilities. To address this gap, we introduce VERA: Variational infErence
fRamework for jAilbreaking. VERA casts black-box jailbreak prompting as a
variational inference problem, training a small attacker LLM to approximate the
target LLM's posterior over adversarial prompts. Once trained, the attacker can
generate diverse, fluent jailbreak prompts for a target query without
re-optimization. Experimental results show that VERA achieves strong
performance across a range of target LLMs, highlighting the value of
probabilistic inference for adversarial prompt generation.

</details>


### [42] [Logit-Gap Steering: Efficient Short-Suffix Jailbreaks for Aligned Large Language Models](https://arxiv.org/abs/2506.24056)
*Tung-Ling Li,Hongliang Liu*

Main category: cs.CR

Relevance: 85.0

TL;DR: 提出了一种快速越狱框架logit-gap steering，通过单次词汇表遍历减少RLHF对齐语言模型的拒绝-确认间隙，高效生成短后缀，显著提升攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 研究RLHF对齐语言模型的脆弱性，开发高效越狱方法以揭示安全调整的内部机制。

Method: 利用logit-gap steering框架，结合间隙减少、KL惩罚和奖励偏移的轻量级代理，通过“排序-求和-停止”扫描快速生成攻击后缀。

Result: 攻击成功率从基线提升至80-100%，后缀可推广到未见过的提示，并在不同规模模型（0.5B至70B）上有效。

Conclusion: 该方法不仅高效，还揭示了安全调整的内部表征变化，为对齐研究提供了轻量级工具。

Abstract: We introduce logit-gap steering, a fast jailbreak framework that casts the
refusal-affirmation gap of RLHF-aligned language models as a single pass over
the vocabulary. A forward-computable score blends gap reduction with
lightweight proxies for KL penalty and reward shift, allowing a "sort-sum-stop"
sweep to complete in under a second and return a short suffix--two orders of
magnitude fewer model calls than beam or gradient attacks. The same suffix
generalises to unseen prompts and scales from 0.5 B to 70 B checkpoints,
lifting one-shot attack success from baseline levels to 80-100% while
preserving topical coherence. Beyond efficiency, these suffixes expose
sentence-boundary reward cliffs and other alignment artefacts, offering a
lightweight probe into how safety tuning reshapes internal representations.

</details>


### [43] [Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions](https://arxiv.org/abs/2506.22679)
*Ankush Raut,Projna Paromita,Sydney Begerowski,Suzanne Bell,Theodora Chaspari*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文探讨了LLMs在团队对话中检测微行为的可行性，比较了编码器-解码器模型的性能，发现解码器模型（如Llama-3.1）表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLMs在分析团队沟通动态中的应用，特别是在高压力环境中（如太空任务）的文本数据分析。

Method: 方法包括零样本分类、微调、释义增强微调（编码器模型）和少样本文本生成（解码器模型）。

Result: 结果表明，编码器模型（如RoBERTa）表现不佳，而解码器模型（如Llama-3.1）在3类和2类分类中分别达到44%和68%的F1分数。

Conclusion: 结论是解码器模型更适合此类任务，对团队沟通分析和训练干预有潜在应用价值。

Abstract: We explore the feasibility of large language models (LLMs) in detecting
subtle expressions of micro-behaviors in team conversations using transcripts
collected during simulated space missions. Specifically, we examine zero-shot
classification, fine-tuning, and paraphrase-augmented fine-tuning with
encoder-only sequence classification LLMs, as well as few-shot text generation
with decoder-only causal language modeling LLMs, to predict the micro-behavior
associated with each conversational turn (i.e., dialogue). Our findings
indicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to
detect underrepresented micro-behaviors, particularly discouraging speech, even
with weighted fine-tuning. In contrast, the instruction fine-tuned version of
Llama-3.1, a decoder-only LLM, demonstrated superior performance, with the best
models achieving macro F1-scores of 44% for 3-way classification and 68% for
binary classification. These results have implications for the development of
speech technologies aimed at analyzing team communication dynamics and
enhancing training interventions in high-stakes environments such as space
missions, particularly in scenarios where text is the only accessible data.

</details>


### [44] [Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report](https://arxiv.org/abs/2506.22698)
*Emily Dux Speltz*

Main category: cs.CL

Relevance: 75.0

TL;DR: 报告总结了AI语言模型与人类认知过程的关系，探讨了LLMs的潜力与局限，并强调了人机协作的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决AI语言模型与人类认知过程关系的知识空白，促进跨学科合作。

Method: 通过跨学科研讨会，结合认知心理学、语言学习和AI NLP的视角进行分析。

Result: 发现LLMs能提供人类语言处理的见解，但无法完全复制人类语言理解；人机协作有潜力。

Conclusion: 未来研究应关注LLMs在认知心理学和教育中的应用，同时注重伦理和负责任使用。

Abstract: This report synthesizes the outcomes of a recent interdisciplinary workshop
that brought together leading experts in cognitive psychology, language
learning, and artificial intelligence (AI)-based natural language processing
(NLP). The workshop, funded by the National Science Foundation, aimed to
address a critical knowledge gap in our understanding of the relationship
between AI language models and human cognitive processes in text comprehension
and composition. Through collaborative dialogue across cognitive, linguistic,
and technological perspectives, workshop participants examined the underlying
processes involved when humans produce and comprehend text, and how AI can both
inform our understanding of these processes and augment human capabilities. The
workshop revealed emerging patterns in the relationship between large language
models (LLMs) and human cognition, with highlights on both the capabilities of
LLMs and their limitations in fully replicating human-like language
understanding and generation. Key findings include the potential of LLMs to
offer insights into human language processing, the increasing alignment between
LLM behavior and human language processing when models are fine-tuned with
human feedback, and the opportunities and challenges presented by human-AI
collaboration in language tasks. By synthesizing these findings, this report
aims to guide future research, development, and implementation of LLMs in
cognitive psychology, linguistics, and education. It emphasizes the importance
of ethical considerations and responsible use of AI technologies while striving
to enhance human capabilities in text comprehension and production through
effective human-AI collaboration.

</details>


### [45] [MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs](https://arxiv.org/abs/2506.22808)
*Jianhui Wei,Zijie Meng,Zikai Xiao,Tianxiang Hu,Yang Feng,Zhijie Zhou,Jian Wu,Zuozhu Liu*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文提出了MedEthicsQA基准，用于评估医学大语言模型（MedLLMs）在医学伦理问题上的表现，揭示了其伦理对齐的不足。


<details>
  <summary>Details</summary>
Motivation: 医学大语言模型在临床任务中表现优异，但其伦理安全性尚未充分研究。

Method: 构建了包含5,623道选择题和5,351道开放题的MedEthicsQA基准，整合全球医学伦理标准，并通过多阶段过滤和专家验证确保数据质量。

Result: 评估显示，MedLLMs在医学伦理问题上的表现显著低于其基础模型。

Conclusion: MedEthicsQA揭示了MedLLMs在伦理对齐上的不足，为未来研究提供了重要基准。

Abstract: While Medical Large Language Models (MedLLMs) have demonstrated remarkable
potential in clinical tasks, their ethical safety remains insufficiently
explored. This paper introduces $\textbf{MedEthicsQA}$, a comprehensive
benchmark comprising $\textbf{5,623}$ multiple-choice questions and
$\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs.
We systematically establish a hierarchical taxonomy integrating global medical
ethical standards. The benchmark encompasses widely used medical datasets,
authoritative question banks, and scenarios derived from PubMed literature.
Rigorous quality control involving multi-stage filtering and multi-faceted
expert validation ensures the reliability of the dataset with a low error rate
($2.72\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance
in answering medical ethics questions compared to their foundation
counterparts, elucidating the deficiencies of medical ethics alignment. The
dataset, registered under CC BY-NC 4.0 license, is available at
https://github.com/JianhuiWei7/MedEthicsQA.

</details>


### [46] [DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues](https://arxiv.org/abs/2506.22853)
*Kyochul Jang,Donghyeon Lee,Kyusik Kim,Dongseok Heo,Taewhoo Lee,Woojeong Kim,Bongwon Suh*

Main category: cs.CL

Relevance: 75.0

TL;DR: 论文提出了DICE-SCORE指标和DICE-BENCH框架，用于评估和构建更真实的多轮函数调用对话数据集，发现现有LLMs仍需改进。


<details>
  <summary>Details</summary>
Motivation: 现有函数调用基准测试仅关注单轮交互，忽略了真实场景的复杂性，需要更实用的评估方法。

Method: 引入DICE-SCORE指标评估工具信息分散度，提出DICE-BENCH框架，通过工具图和多智能体系统构建高分散度对话数据集。

Result: DICE-BENCH包含1,607个高分散度实例，实验显示19个LLMs在实际应用中仍有不足。

Conclusion: 现有LLMs在真实场景中的函数调用能力仍需提升，DICE-BENCH为未来研究提供了实用基准。

Abstract: Existing function-calling benchmarks focus on single-turn interactions.
However, they overlook the complexity of real-world scenarios. To quantify how
existing benchmarks address practical applications, we introduce DICE-SCORE, a
metric that evaluates the dispersion of tool-related information such as
function name and parameter values throughout the dialogue. Analyzing existing
benchmarks through DICE-SCORE reveals notably low scores, highlighting the need
for more realistic scenarios. To address this gap, we present DICE-BENCH, a
framework that constructs practical function-calling datasets by synthesizing
conversations through a tool graph that maintains dependencies across rounds
and a multi-agent system with distinct personas to enhance dialogue
naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our
experiments on 19 LLMs with DICE-BENCH show that significant advances are still
required before such models can be deployed effectively in real-world settings.
Our code and data are all publicly available:
https://snuhcc.github.io/DICE-Bench/.

</details>


### [47] [FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes](https://arxiv.org/abs/2506.23111)
*Janki Atul Nawale,Mohammed Safi Ur Rahman Khan,Janani D,Mansi Gupta,Danish Pruthi,Mitesh M. Khapra*

Main category: cs.CL

Relevance: 75.0

TL;DR: INDIC-BIAS是一个印度中心的公平性基准，用于评估LLM在85个身份群体中的公平性，揭示了LLM对边缘化群体的强烈偏见。


<details>
  <summary>Details</summary>
Motivation: 现有公平性研究主要针对西方，无法满足印度等文化多样性国家的需求，因此开发了INDIC-BIAS。

Method: 通过专家咨询和手动验证，生成了20,000个真实场景模板，分为三个评估任务（合理性、判断和生成），评估了14个流行LLM。

Result: LLM对边缘化身份表现出强烈负面偏见，并难以通过理性化决策减轻偏见。

Conclusion: LLM在印度语境中可能造成分配和代表性伤害，需谨慎使用。INDIC-BIAS作为开源基准发布。

Abstract: Existing studies on fairness are largely Western-focused, making them
inadequate for culturally diverse countries such as India. To address this gap,
we introduce INDIC-BIAS, a comprehensive India-centric benchmark designed to
evaluate fairness of LLMs across 85 identity groups encompassing diverse
castes, religions, regions, and tribes. We first consult domain experts to
curate over 1,800 socio-cultural topics spanning behaviors and situations,
where biases and stereotypes are likely to emerge. Grounded in these topics, we
generate and manually validate 20,000 real-world scenario templates to probe
LLMs for fairness. We structure these templates into three evaluation tasks:
plausibility, judgment, and generation. Our evaluation of 14 popular LLMs on
these tasks reveals strong negative biases against marginalized identities,
with models frequently reinforcing common stereotypes. Additionally, we find
that models struggle to mitigate bias even when explicitly asked to rationalize
their decision. Our evaluation provides evidence of both allocative and
representational harms that current LLMs could cause towards Indian identities,
calling for a more cautious usage in practical applications. We release
INDIC-BIAS as an open-source benchmark to advance research on benchmarking and
mitigating biases and stereotypes in the Indian context.

</details>


### [48] [Objective-Free Local Learning and Emergent Language Structure in Thinking Machines](https://arxiv.org/abs/2506.23293)
*P. Myles Eugenio*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出了一种基于局部事件驱动涌现学习的神经符号框架，用于生成语言建模，核心是分层Hopfield记忆链作为组合短期记忆和动态分词器。


<details>
  <summary>Details</summary>
Motivation: 探索如何从局部神经学习中涌现符号结构，构建可扩展、可解释的神经符号系统。

Method: 使用分层Hopfield记忆链作为动态分词器，通过投影张量绑定共现特征为层次化token，支持局部激活压缩为长程依赖。

Result: 模型能从噪声中过滤自然语言模式，生成具有内部形态一致性的合成语言，且涌现的嵌入神经元支持组合推理和泛化。

Conclusion: 该方法为研究符号结构如何从局部神经学习中涌现提供了方法论基础，推动了生成语言模型的神经形态架构发展。

Abstract: We present a neuro-symbolic framework for generative language modeling based
on local, event-driven emergent learning. At its core is a hierarchical
Hopfield memory chain acting as a compositional short-term memory and dynamic
tokenizer (retokenizer). Rather than relying on predefined tokens or
supervision, the model builds structure from scratch, learning symbol sequences
as multi-scale representations. It constructs projection tensors that bind
co-occurring features into hierarchical tokens, introducing redundancy (i.e an
emergent gauge structure) and enabling compression of local activations into
long-range dependencies. Curiously, we find that the retokenizer can filter
natural language patterns from noise, generating synthetic languages with
coherent internal morphology -- quantifiably the same as human language.
Language is learned in a local (Hebbian) fashion, where model constraints
dictate allowed emergent structure, and new information is retained in
alignment with this structure. The absence of a global objective enables a form
of plasticity not found in conventional language models, allowing the system to
generalize beyond its initial inference class -- even without explicit data. We
demonstrate that briefly activating a new neuron during inference binds
distributed multi-scale token features into a symbolic embedding. These
emergent embedding neurons act as long-term memory and support a key-value
mechanism for compositional inference and generalization. This architecture
provides a methodological foundation for studying how symbolic structure can
emerge from local neural learning. It offers a new pathway for building
scalable, interpretable neuro-symbolic systems -- where tokens, grammar, and
reasoning arise as compressed memory traces within a Hopfield hierarchy. This
approach advances the development of neuromorphic architectures for generative
language models.

</details>


### [49] [Information Loss in LLMs' Multilingual Translation: The Role of Training Data, Language Proximity, and Language Family](https://arxiv.org/abs/2506.23340)
*Yumeng Lin,Xufeng Duan,David Haslett,Yige Chen,Zhenguang G. Cai*

Main category: cs.CL

Relevance: 75.0

TL;DR: 研究探讨了训练数据、语言接近度和语言家族对多语言翻译中信息损失的影响，发现数据量和语言结构关系共同决定翻译质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多语言翻译中表现优异，但在某些语言对（尤其是训练数据有限或与英语差异大的语言）中仍面临挑战。研究旨在系统分析这些因素如何影响翻译质量。

Method: 通过往返翻译评估GPT-4和Llama 2，使用BLEU分数和BERT相似性指标衡量翻译质量。

Result: 训练数据量和语言距离之间存在显著交互作用：数据充足可缓解语言差异的影响，但在低资源条件下，与英语结构更接近的语言翻译质量更高。

Conclusion: 翻译质量不仅受数据量影响，还受语言结构和类型学关系的制约。

Abstract: Large language models have achieved impressive progress in multilingual
translation, yet they continue to face challenges with certain language
pairs-particularly those with limited training data or significant linguistic
divergence from English. This study systematically investigates how training
data, language proximity, and language family affect information loss in
multilingual translation. We evaluate two large language models, GPT-4 and
Llama 2, by performing round-trip translations. Translation quality was
assessed using BLEU scores and BERT similarity metrics. Our results reveal a
robust interaction between training data size and language distance: while
abundant training data can mitigate the effects of linguistic divergence,
languages structurally closer to English consistently yield higher translation
quality in low-resource conditions. Among various distance metrics,
orthographic, phylogenetic, syntactic, and geographical distances emerge as
strong predictors of translation performance. Language family also exerts an
independent influence. These findings contribute to a deeper understanding of
the linguistic constraints shaping multilingual translation in large language
models, emphasizing that translation quality is shaped not only by data volume
but also by structural and typological relationships between languages.

</details>


### [50] [What to Keep and What to Drop: Adaptive Table Filtering Framework](https://arxiv.org/abs/2506.23463)
*Jang Won June*

Main category: cs.CL

Relevance: 75.0

TL;DR: ATF框架通过自适应过滤表格内容，显著减少输入长度限制对LLM表格推理的影响，提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在处理大型表格时因输入长度限制导致的性能问题。

Method: 提出ATF框架，结合LLM生成的列描述、聚类和稀疏-密集对齐分数，动态过滤无关表格内容。

Result: 实验显示ATF减少约70%表格单元，提升跨领域TableQA任务性能，但对Table Fact Verification略有影响。

Conclusion: ATF能自适应平衡信息量与简洁性，适用于不同任务。

Abstract: Large language models (LLMs) for table-based reasoning often struggle with
large tables due to input length limits. We propose ATF (Adaptive Table
Filtering Framework), a modular and question-aware filtering pipeline that
prunes uninformative columns and rows using LLM-generated column descriptions,
clustering, and sparse-dense alignment scores. ATF integrates seamlessly with
existing models (e.g., TAPAS, TAPEX) without retraining. Experiments show that
ATF reduces table cells by ~70\%, boosting performance on out-of-domain TableQA
tasks while causing slight performance drops on Table Fact Verification, where
full-table context is more critical. These results highlight ATF's ability to
adaptively balance informativeness and minimalism across tasks.

</details>


### [51] [Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs](https://arxiv.org/abs/2506.23610)
*Manuel Pratelli,Marinella Petrocchi*

Main category: cs.CL

Relevance: 75.0

TL;DR: LLMs生成合成行为数据的能力被评估，重点关注人格特质对信息误判的影响，结果发现部分特质关联可复现，但也存在偏差。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否能准确模拟人格特质驱动的心理差异，为行为模拟提供伦理且低成本的替代方案。

Method: 基于Big-Five人格档案创建LLM代理，与人类参与者的新闻辨别行为对比。

Result: 部分人格特质（如宜人性和尽责性）与信息误判的关联可复现，但其他特质存在偏差。

Conclusion: LLMs在行为模拟中具有潜力但存在局限，为人工代理的认知多样性建模提供新见解。

Abstract: Large language models (LLMs) make it possible to generate synthetic
behavioural data at scale, offering an ethical and low-cost alternative to
human experiments. Whether such data can faithfully capture psychological
differences driven by personality traits, however, remains an open question. We
evaluate the capacity of LLM agents, conditioned on Big-Five profiles, to
reproduce personality-based variation in susceptibility to misinformation,
focusing on news discernment, the ability to judge true headlines as true and
false headlines as false. Leveraging published datasets in which human
participants with known personality profiles rated headline accuracy, we create
matching LLM agents and compare their responses to the original human patterns.
Certain trait-misinformation associations, notably those involving
Agreeableness and Conscientiousness, are reliably replicated, whereas others
diverge, revealing systematic biases in how LLMs internalize and express
personality. The results underscore both the promise and the limits of
personality-aligned LLMs for behavioral simulation, and offer new insight into
modeling cognitive diversity in artificial agents.

</details>


### [52] [Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack](https://arxiv.org/abs/2506.23661)
*Arnisa Fazla,Lucas Krauter,David Guzman Piedrahita,Andrianos Michail*

Main category: cs.CL

Relevance: 75.0

TL;DR: BeamAttack扩展版通过支持单词删除和跳过替换，结合LIME优化攻击策略，在BODEGA框架下对多种模型进行对抗攻击，成功率超过99%，同时保持文本语义和词汇相似性。


<details>
  <summary>Details</summary>
Motivation: 评估文本分类系统的鲁棒性，通过最小修改改变模型预测，揭示模型脆弱性。

Method: 扩展BeamAttack算法，支持单词删除和跳过替换，集成LIME优化攻击策略。

Result: 在BiLSTM、BERT和RoBERTa等模型上攻击成功率超过99%，保持文本相似性。

Conclusion: BeamAttack扩展版在对抗攻击中高效且语义保留，但仍有局限性。

Abstract: We extend BeamAttack, an adversarial attack algorithm designed to evaluate
the robustness of text classification systems through word-level modifications
guided by beam search. Our extensions include support for word deletions and
the option to skip substitutions, enabling the discovery of minimal
modifications that alter model predictions. We also integrate LIME to better
prioritize word replacements. Evaluated across multiple datasets and victim
models (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA
framework, our approach achieves over a 99\% attack success rate while
preserving the semantic and lexical similarity of the original texts. Through
both quantitative and qualitative analysis, we highlight BeamAttack's
effectiveness and its limitations. Our implementation is available at
https://github.com/LucK1Y/BeamAttack

</details>


### [53] [Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences](https://arxiv.org/abs/2506.23743)
*Tiziano Labruna,Simone Gallo,Giovanni Da San Martino*

Main category: cs.CL

Relevance: 75.0

TL;DR: 研究量化了大型语言模型在二元问答中的位置偏见，发现低不确定性条件下偏见几乎不存在，但高不确定性时偏见显著增加。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在二元问答中是否存在位置偏见，以及不确定性如何影响这种偏见。

Method: 通过改编SQuAD-it数据集和评估自然高不确定性基准（WebGPT和Winning Arguments），计算偏好公平性和位置一致性。

Result: 位置偏见在低不确定性条件下几乎不存在，但在高不确定性条件下呈指数增长。

Conclusion: 位置偏见与不确定性密切相关，高不确定性条件下模型更容易受选项顺序影响。

Abstract: Positional bias in binary question answering occurs when a model
systematically favors one choice over another based solely on the ordering of
presented options. In this study, we quantify and analyze positional bias
across five large language models under varying degrees of answer uncertainty.
We re-adapted the SQuAD-it dataset by adding an extra incorrect answer option
and then created multiple versions with progressively less context and more
out-of-context answers, yielding datasets that range from low to high
uncertainty. Additionally, we evaluate two naturally higher-uncertainty
benchmarks: (1) WebGPT - question pairs with unequal human-assigned quality
scores, and (2) Winning Arguments - where models predict the more persuasive
argument in Reddit's r/ChangeMyView exchanges. Across each dataset, the order
of the "correct" (or higher-quality/persuasive) option is systematically
flipped (first placed in position 1, then in position 2) to compute both
Preference Fairness and Position Consistency. We observe that positional bias
is nearly absent under low-uncertainty conditions, but grows exponentially when
it becomes doubtful to decide which option is correct.

</details>


### [54] [Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs](https://arxiv.org/abs/2506.23940)
*Yang Dai,Jianxiang An,Tianwei Lin,Hongyang He,Hongzhe Huang,Wenqiao Zhang,Zheqi Lv,Siliang Tang,Yueting Zhuang*

Main category: cs.CL

Relevance: 75.0

TL;DR: 提出了一种统一参数集成框架（CAPS），用于多模态大语言模型（MLLMs）的知识共享，通过兼容性感知参数拼接实现模块化组合。


<details>
  <summary>Details</summary>
Motivation: 解决领域专用MLLMs知识碎片化问题，探索知识共享的潜力。

Method: 采用兼容性感知参数拼接（CAPS）策略，结合局部功能属性和全局信息理论信号，实现选择性参数融合。

Result: 在多样化多模态基准测试中验证了框架的有效性，实现了异构专业知识的协同。

Conclusion: 该框架为构建可组合、领域自适应的MLLMs提供了可扩展路径。

Abstract: Multimodal Large Language Models (MLLMs) have achieved success across various
domains. However, their applicability tends to degrade when confronted with
different types of data inputs, especially for MLLMs that have been fine-tuned
for specific tasks. Despite its importance, the study of knowledge sharing
among domain-specific MLLMs--such as those trained for mathematics or
code--remains largely underexplored. To address the fragmentation of knowledge
across domain-specialized MLLMs, we propose a unified parameter integration
framework that enables modular composition of expert capabilities. Our method
is grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy,
which leverages both local functional attribution and global
information-theoretic signals to guide selective parameter fusion. By extending
this mechanism to the low-rank adaptation layer granularity, we ensure
efficient integration with minimal inference overhead. Furthermore, we
introduce a domain compatibility scoring mechanism that quantifies inter-expert
alignment at the activation level and correlates with downstream task utility.
This principled fusion protocol allows the final model to synergize
heterogeneous expertise while preserving structural modularity. Extensive
evaluations across diverse multimodal benchmarks validate the effectiveness of
our framework, offering a scalable path toward compositional, domain-adaptive
MLLMs.

</details>


### [55] [AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text](https://arxiv.org/abs/2506.22508)
*Chenyang Shao,Tianxing Li,Chenhao Pu,Fengli Xu,Yong Li*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文提出AgentStealth框架，利用本地部署的小规模语言模型（SLMs）进行文本匿名化，通过对抗性工作流和强化学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本匿名化方法要么损害实用性，要么依赖高成本的云LLMs，存在隐私风险。本地SLMs是潜在解决方案，但缺乏高质量监督数据。

Method: 1. 对抗性匿名化工作流（上下文对比学习与自适应效用感知控制）；2. 利用工作流数据监督适应SLMs；3. 在线强化学习迭代优化。

Result: 在两个数据集上，匿名化效果提升12.3%，实用性提升6.8%，支持边缘设备部署。

Conclusion: AgentStealth框架在匿名化效果和实用性上优于基线，且避免了云依赖和隐私风险。

Abstract: In today's digital world, casual user-generated content often contains subtle
cues that may inadvertently expose sensitive personal attributes. Such risks
underscore the growing importance of effective text anonymization to safeguard
individual privacy. However, existing methods either rely on rigid replacements
that damage utility or cloud-based LLMs that are costly and pose privacy risks.
To address these issues, we explore the use of locally deployed smaller-scale
language models (SLMs) for anonymization. Yet training effective SLMs remains
challenging due to limited high-quality supervision. To address the challenge,
we propose AgentStealth, a self-reinforcing LLM anonymization framework.First,
we introduce an adversarial anonymization workflow enhanced by In-context
Contrastive Learning and Adaptive Utility-Aware Control. Second, we perform
supervised adaptation of SLMs using high-quality data collected from the
workflow, which includes both anonymization and attack signals. Finally, we
apply online reinforcement learning where the model leverages its internal
adversarial feedback to iteratively improve anonymization performance.
Experiments on two datasets show that our method outperforms baselines in both
anonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight
design supports direct deployment on edge devices, avoiding cloud reliance and
communication-based privacy risks. Our code is open-source at
https://github.com/tsinghua-fib-lab/AgentStealth.

</details>


### [56] [A Systematic Study of Compositional Syntactic Transformer Language Models](https://arxiv.org/abs/2506.22978)
*Yida Zhao,Hao Xve,Xiang Hu,Kewei Tu*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文提出了一种统一的框架，用于设计和评估基于成分句法树的组合式句法语言模型（SLMs），并通过实验验证了不同变体的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的组合式SLMs设计选择多样，缺乏统一框架，作者旨在填补这一空白，并提供设计建议。

Method: 提出一个统一框架，涵盖现有模型和新变体，并在多个任务（语言建模、句法泛化、摘要、对话和推理效率）上进行评估。

Result: 实验结果表明，不同变体在不同任务上表现各异，作者据此提出了多项设计建议。

Conclusion: 组合式SLMs的设计需根据具体任务需求调整，统一框架为未来研究提供了基础。

Abstract: Syntactic language models (SLMs) enhance Transformers by incorporating
syntactic biases through the modeling of linearized syntactic parse trees
alongside surface sentences. This paper focuses on compositional SLMs that are
based on constituency parse trees and contain explicit bottom-up composition of
constituent representations. We identify key aspects of design choices in
existing compositional SLMs and propose a unified framework encompassing both
existing models and novel variants. We conduct a comprehensive empirical
evaluation of all the variants in our framework across language modeling,
syntactic generalization, summarization, dialogue, and inference efficiency.
Based on the experimental results, we make multiple recommendations on the
design of compositional SLMs. Our code is released at
https://github.com/zhaoyd1/compositional_SLMs.

</details>


### [57] [Text2VectorSQL: Bridging Text-to-SQL and Vector Search for Unified Natural Language Queries](https://arxiv.org/abs/2506.23071)
*Zhengren Wang,Bozhou Li,Dongwen Yao,Wentao Zhang*

Main category: cs.CL

Relevance: 70.0

TL;DR: Text2VectorSQL框架结合Text-to-SQL和向量搜索，提升对非结构化数据和模糊查询的处理能力，并通过自动评估和专家审核验证性能。


<details>
  <summary>Details</summary>
Motivation: 传统Text-to-SQL在处理非结构化数据或模糊查询时表现不佳，而向量搜索虽强但缺乏自动化评估框架。Text2VectorSQL旨在结合两者优势。

Method: 提出Text2VectorSQL框架，支持语义过滤、多模态匹配和检索加速，并通过合成数据和自动评估验证模型性能。

Result: 实验表明，Text2VectorSQL显著优于基线方法，为更灵活的数据库交互奠定了基础。

Conclusion: Text2VectorSQL填补了理论潜力与实际部署间的差距，为未来数据库接口的发展提供了新方向。

Abstract: While Text-to-SQL enables natural language interaction with structured
databases, its effectiveness diminishes with unstructured data or ambiguous
queries due to rigid syntax and limited expressiveness. Concurrently, vector
search has emerged as a powerful paradigm for semantic retrieval, particularly
for unstructured data. However, existing VectorSQL implementations still rely
heavily on manual crafting and lack tailored evaluation frameworks, leaving a
significant gap between theoretical potential and practical deployment. To
bridge these complementary paradigms, we introduces Text2VectorSQL, a novel
framework unifying Text-to-SQL and vector search to overcome expressiveness
constraints and support more diverse and holistical natural language queries.
Specifically, Text2VectorSQL enables semantic filtering, multi-modal matching,
and retrieval acceleration. For evaluation, we build vector index on
appropriate columns, extend user queries with semantic search, and annotate
ground truths via an automatic pipeline with expert review. Furthermore, we
develop dedicated Text2VectorSQL models with synthetic data, demonstrating
significant performance improvements over baseline methods. Our work
establishes the foundation for the Text2VectorSQL task, paving the way for more
versatile and intuitive database interfaces. The repository will be publicly
available at https://github.com/Open-DataFlow/Text2VectorSQL.

</details>


### [58] [Benchmarking Deep Search over Heterogeneous Enterprise Data](https://arxiv.org/abs/2506.23139)
*Prafulla Kumar Choubey,Xiangyu Peng,Shilpa Bhagavath,Kung-Hsiang Huang,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.CL

Relevance: 70.0

TL;DR: 提出了一个用于评估深度搜索（一种复杂的检索增强生成任务）的新基准，涵盖多源、多跳推理，并包含真实噪声和多样化的企业数据。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法在多源、多跳推理任务中表现不佳，尤其是面对真实噪声和多样化数据时。

Method: 通过合成数据管道模拟企业工作流程，生成包含多跳问题和真实噪声的互联内容，构建了一个包含39,190个企业工件的基准。

Result: 实验显示，现有最佳RAG方法在基准上的平均得分仅为32.96，检索是主要瓶颈。

Conclusion: 需要改进检索方法以支持深度搜索和多跳推理，从而提升RAG系统性能。

Abstract: We present a new benchmark for evaluating Deep Search--a realistic and
complex form of retrieval-augmented generation (RAG) that requires
source-aware, multi-hop reasoning over diverse, sparsed, but related sources.
These include documents, meeting transcripts, Slack messages, GitHub, and URLs,
which vary in structure and often contain human-to-human interactions. We build
it using a synthetic data pipeline that simulates business workflows across
product planning, development, and support stages, generating interconnected
content with realistic noise and multi-hop questions with guaranteed
ground-truth answers. We release our benchmark with both answerable and
unanswerable queries, and retrieval pool of 39,190 enterprise artifacts,
enabling fine-grained evaluation of long-context LLM and RAG systems. Our
experiments reveal that even the best-performing agentic RAG methods achieve an
average performance score of 32.96 on our benchmark. With further analysis, we
highlight retrieval as the main bottleneck: existing methods struggle to
conduct deep searches and retrieve all necessary evidence. Consequently, they
often reason over partial context, leading to significant performance
degradation.

</details>


### [59] [Hierarchical Memory Organization for Wikipedia Generation](https://arxiv.org/abs/2506.23393)
*Eugene J. Yu,Dawei Zhu,Yifan Song,Xiangyu Wong,Jiebin Zhang,Wenxuan Shi,Xiaoguang Li,Qun Liu,Sujian Li*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文提出了一种基于分层记忆架构的MOG框架，用于自动生成维基百科文章，通过细粒度记忆单元和递归组织提升信息准确性和可验证性。


<details>
  <summary>Details</summary>
Motivation: 自动生成维基百科文章需要整合多源信息并确保准确性和结构化，现有方法在信息对齐和可验证性上存在不足。

Method: MOG框架通过分层记忆架构提取细粒度记忆单元，递归组织为维基百科式结构，并利用该结构指导生成过程，同时引入引用模块增强可追溯性。

Result: 在WikiStart数据集上的实验表明，MOG在生成信息丰富且可靠的文章上优于基线方法，尤其在真实场景中表现稳健。

Conclusion: MOG通过分层记忆架构和引用模块显著提升了生成文章的准确性和可验证性，适用于实际应用。

Abstract: Generating Wikipedia articles autonomously is a challenging task requiring
the integration of accurate, comprehensive, and well-structured information
from diverse sources. This paper introduces the Memory Organization-based
Generation (MOG) framework, a novel approach to address these challenges by
leveraging a hierarchical memory architecture. MOG extracts fine-grained memory
units from web documents, recursively organizes them into a Wikipedia-style
hierarchical structure, and uses this structure to guide the generation
process. This ensures alignment between memory and the article outline,
improving both informativeness and verifiability while minimizing
hallucinations. Additionally, a citation module is implemented to enhance
traceability by linking every generated sentence to specific memory units.
Evaluations on our newly created WikiStart dataset demonstrate that MOG
outperforms baseline methods in producing informative and reliable articles,
making it particularly robust in real-world scenarios.

</details>


### [60] [Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages](https://arxiv.org/abs/2506.23930)
*Ruhina Tabasshum Prome,Tarikul Islam Tamiti,Anomadarshi Barua*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文研究了如何通过提示工程在低资源孟加拉语中利用大语言模型（LLMs）检测仇恨言论，提出了六种提示策略，并创新性地引入了隐喻提示以绕过LLMs的安全机制。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言中仇恨言论检测的挑战，尤其是缺乏大规模高质量数据集的问题。

Method: 研究了六种提示策略（如零样本提示、隐喻提示等），并在Llama2-7B模型上测试，同时比较了三种预训练词嵌入和三种深度学习模型的性能。

Result: 隐喻提示在低资源语言中表现优异，并在高资源语言中验证了其有效性。评估指标包括F1分数和环境影响因素。

Conclusion: 隐喻提示是一种有效的策略，能够绕过LLMs的安全机制，适用于低资源语言的仇恨言论检测。

Abstract: The rapid expansion of social media leads to a marked increase in hate
speech, which threatens personal lives and results in numerous hate crimes.
Detecting hate speech presents several challenges: diverse dialects, frequent
code-mixing, and the prevalence of misspelled words in user-generated content
on social media platforms. Recent progress in hate speech detection is
typically concentrated on high-resource languages. However, low-resource
languages still face significant challenges due to the lack of large-scale,
high-quality datasets. This paper investigates how we can overcome this
limitation via prompt engineering on large language models (LLMs) focusing on
low-resource Bengali language. We investigate six prompting strategies -
zero-shot prompting, refusal suppression, flattering the classifier, multi-shot
prompting, role prompting, and finally our innovative metaphor prompting to
detect hate speech effectively in low-resource languages. We pioneer the
metaphor prompting to circumvent the built-in safety mechanisms of LLMs that
marks a significant departure from existing jailbreaking methods. We
investigate all six different prompting strategies on the Llama2-7B model and
compare the results extensively with three pre-trained word embeddings - GloVe,
Word2Vec, and FastText for three different deep learning models - multilayer
perceptron (MLP), convolutional neural network (CNN), and bidirectional gated
recurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in
the low-resource Bengali language, we also evaluate it in another low-resource
language - Hindi, and two high-resource languages - English and German. The
performance of all prompting techniques is evaluated using the F1 score, and
environmental impact factor (IF), which measures CO$_2$ emissions, electricity
usage, and computational time.

</details>


### [61] [Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective](https://arxiv.org/abs/2506.24006)
*Anselm R. Strohmaier,Wim Van Dooren,Kathrin Seßler,Brian Greer,Lieven Verschaffel*

Main category: cs.CL

Relevance: 70.0

TL;DR: 论文探讨了LLMs在数学教育中的应用，特别是解决数学应用题的能力。研究发现，尽管LLMs在解决无需考虑现实背景的简单问题上表现优异，但在处理需要理解现实背景的复杂问题时仍有局限。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估LLMs在数学教育中的实际能力，尤其是它们是否能真正理解数学应用题的现实背景，以及这对课堂教学的潜在影响。

Method: 研究方法包括三部分：技术概述（对比LLMs与学生的解题过程）、文献综述（分析213项研究中的数学应用题）、以及对GPT-3.5-turbo等模型的实证评估（测试287道应用题）。

Result: 结果显示，LLMs在解决简单应用题（s-problems）时表现近乎完美，但在处理需要现实背景理解的问题时表现不佳。

Conclusion: 结论是LLMs虽然掌握了表面的解题过程，但未能真正理解应用题的现实背景，这限制了其在数学教学中的价值。

Abstract: The progress of Large Language Models (LLMs) like ChatGPT raises the question
of how they can be integrated into education. One hope is that they can support
mathematics learning, including word-problem solving. Since LLMs can handle
textual input with ease, they appear well-suited for solving mathematical word
problems. Yet their real competence, whether they can make sense of the
real-world context, and the implications for classrooms remain unclear. We
conducted a scoping review from a mathematics-education perspective, including
three parts: a technical overview, a systematic review of word problems used in
research, and a state-of-the-art empirical evaluation of LLMs on mathematical
word problems. First, in the technical overview, we contrast the
conceptualization of word problems and their solution processes between LLMs
and students. In computer-science research this is typically labeled
mathematical reasoning, a term that does not align with usage in mathematics
education. Second, our literature review of 213 studies shows that the most
popular word-problem corpora are dominated by s-problems, which do not require
a consideration of realities of their real-world context. Finally, our
evaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems
shows that most recent LLMs solve these s-problems with near-perfect accuracy,
including a perfect score on 20 problems from PISA. LLMs still showed
weaknesses in tackling problems where the real-world context is problematic or
non-sensical. In sum, we argue based on all three aspects that LLMs have
mastered a superficial solution process but do not make sense of word problems,
which potentially limits their value as instructional tools in mathematics
classrooms.

</details>


### [62] [A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models](https://arxiv.org/abs/2506.22493)
*Sadia Kamal,Lalu Prasad Yadav Prakash,S M Rafiuddin,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen,Sagnik Ray Choudhury*

Main category: cs.CY

Relevance: 70.0

TL;DR: 研究发现，标准生成参数的变化对LLM的政治倾向评分（PCT）影响不大，但提示变化和微调会显著影响评分。此外，微调数据中的政治内容比例对PCT评分无差异影响。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM政治倾向评分的可靠性及其编码机制。

Method: 通过分析标准生成参数、提示变化和微调对PCT评分的影响，以及不同政治内容数据微调的效果。

Result: 标准生成参数影响小；提示和微调影响显著；政治内容比例无差异影响。

Conclusion: 需深入研究PCT测试的有效性及LLM政治倾向编码机制。

Abstract: Political Compass Test (PCT) or similar questionnaires have been used to
quantify LLM's political leanings. Building on a recent line of work that
examines the validity of PCT tests, we demonstrate that variation in standard
generation parameters does not significantly impact the models' PCT scores.
However, external factors such as prompt variations and fine-tuning
individually and in combination affect the same. Finally, we demonstrate that
when models are fine-tuned on text datasets with higher political content than
others, the PCT scores are not differentially affected. This calls for a
thorough investigation into the validity of PCT and similar tests, as well as
the mechanism by which political leanings are encoded in LLMs.

</details>


### [63] [PromptAug: Fine-grained Conflict Classification Using Data Augmentation](https://arxiv.org/abs/2506.22491)
*Oliver Warke,Joemon M. Jose,Faegheh Hasibi,Jan Breitsohl*

Main category: cs.CL

Relevance: 60.0

TL;DR: 本文提出PromptAug，一种基于LLM的数据增强方法，用于解决敏感任务（如冲突检测）中高质量标注数据稀缺的问题。该方法在冲突和情感数据集上显著提升了性能，并通过多维度评估揭示了增强文本的潜在问题。


<details>
  <summary>Details</summary>
Motivation: 社交媒体冲突检测需要高质量标注数据，但这类数据稀缺且难以获取。同时，LLM的防护机制限制了冲突相关数据的生成，因此需要创新的数据增强方法。

Method: 提出PromptAug，一种基于LLM的数据增强方法，通过生成多样化的训练数据来弥补标注数据的不足。

Result: PromptAug在冲突和情感数据集上实现了2%的准确率和F1分数的显著提升。

Conclusion: PromptAug为敏感任务的数据增强提供了有效解决方案，并通过跨学科评估揭示了增强文本的潜在问题。

Abstract: Given the rise of conflicts on social media, effective classification models
to detect harmful behaviours are essential. Following the
garbage-in-garbage-out maxim, machine learning performance depends heavily on
training data quality. However, high-quality labelled data, especially for
nuanced tasks like identifying conflict behaviours, is limited, expensive, and
difficult to obtain. Additionally, as social media platforms increasingly
restrict access to research data, text data augmentation is gaining attention
as an alternative to generate training data. Augmenting conflict-related data
poses unique challenges due to Large Language Model (LLM) guardrails that
prevent generation of offensive content. This paper introduces PromptAug, an
innovative LLM-based data augmentation method. PromptAug achieves statistically
significant improvements of 2% in both accuracy and F1-score on conflict and
emotion datasets. To thoroughly evaluate PromptAug against other data
augmentation methods we conduct a robust evaluation using extreme data scarcity
scenarios, quantitative diversity analysis and a qualitative thematic analysis.
The thematic analysis identifies four problematic patterns in augmented text:
Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and
Augmented Content Misinterpretation.
  Overall, this work presents PromptAug as an effective method for augmenting
data in sensitive tasks like conflict detection, offering a unique,
interdisciplinary evaluation grounded in both natural language processing and
social science methodology.

</details>


### [64] [Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning](https://arxiv.org/abs/2506.22510)
*Zihao Zhao,Xinlong Zhai,Jinyu Yang,Chuan Shi*

Main category: cs.CL

Relevance: 60.0

TL;DR: 论文提出了一种针对图数据的多域预训练和跨域迁移框架MDGCL，解决了现有方法在多域图数据中语义差异的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 图数据在现实应用中广泛存在，但不同域的图数据语义差异大，现有单域对比预训练策略无法有效处理多域知识整合。

Method: 设计了一种新的对比学习策略和域令牌编码域级全局信息，预训练阶段捕获域差异，下游阶段引入域注意力机制实现细粒度知识迁移。

Result: 在五个基准数据集上，MDGCL方法在准确率和Macro-F1分数上最大提升19.33%和19.13%，显著优于现有方法。

Conclusion: MDGCL通过多域预训练和跨域迁移机制，有效解决了图数据中的域差异问题，为图基础模型的发展提供了新思路。

Abstract: Foundation models have achieved great success in natural language processing
(NLP) and computer vision (CV). Their success largely stems from the ability to
integrate multi-domain knowledge in pre-training and transfer it to target
domains. Considering graph data, especially graphs without textual features, is
ubiquitous in real-world applications such as social networks and
recommendation systems, some researchers have attempted to extend this paradigm
to the graph field, aiming to construct graph foundation models. However,
unlike CV and NLP, there are huge gaps among the semantics and properties of
graphs in different domains, while current works still adopt traditional
contrastive pre-training strategies designed in the single-domain scenario,
which regard contrastive samples from different domains as equivalent. From
experimental investigations, we discovered that inherent domain-specific
differences prevent these strategies from effectively absorbing knowledge from
different domains to generate informative representations. In this paper, we
propose a novel multi-domain pre-training and cross-domain transfer framework,
namely MDGCL.In the pre-training stage, we design a contrastive learning
strategy to substantially recognize and capture domain differences, and
introduce domain tokens to encode domain-level global information. In the
downstream stage, we introduce a domain attention mechanism to enable
fine-grained domain knowledge transfer. Extensive experiments on five benchmark
datasets have demonstrated that our method outperforms state-of-the-art
significantly, with the maximum improvement of 19.33\% on accuracy and 19.13\%
on Macro-F1 score.

</details>


### [65] [Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge](https://arxiv.org/abs/2506.22644)
*Chase Fensore,Kaustubh Dhole,Joyce C Ho,Eugene Agichtein*

Main category: cs.CL

Relevance: 60.0

TL;DR: 该论文介绍了在LiveRAG Challenge 2025中的混合检索增强生成（RAG）系统，结合稀疏和密集检索方法，使用Falcon3-10B-Instruct生成答案。通过系统评估，发现神经重排序显著提升性能但计算成本高，而优化提示策略虽提高语义相似性但存在过度自信问题。


<details>
  <summary>Details</summary>
Motivation: 研究动态测试集上的RAG系统性能，探索检索和生成方法的结合效果。

Method: 结合BM25（稀疏）和E5（密集）检索方法，使用Falcon3-10B-Instruct生成答案，并通过RankLLaMA进行神经重排序和DSPy优化提示策略。

Result: 神经重排序显著提升性能（MAP从0.523到0.797），但计算成本高；优化提示策略提高语义相似性但拒绝率为0%。混合系统在比赛中表现中等。

Conclusion: 词汇对齐是性能的关键因素，但需平衡计算成本和性能提升。

Abstract: We present our submission to the LiveRAG Challenge 2025, which evaluates
retrieval-augmented generation (RAG) systems on dynamic test sets using the
FineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense
(E5) retrieval methods and then aims to generate relevant and faithful answers
with Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic
questions generated with DataMorgana across 64 unique question-user
combinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP
from 0.523 to 0.797 (52% relative improvement) but introduces prohibitive
computational costs (84s vs 1.74s per question). While DSPy-optimized prompting
strategies achieved higher semantic similarity (0.771 vs 0.668), their 0%
refusal rates raised concerns about over-confidence and generalizability. Our
submitted hybrid system without re-ranking achieved 4th place in faithfulness
and 11th place in correctness among 25 teams. Analysis across question
categories reveals that vocabulary alignment between questions and documents
was the strongest predictor of performance on our development set, with
document-similar phrasing improving cosine similarity from 0.562 to 0.762.

</details>


### [66] [Boosting CTC-Based ASR Using LLM-Based Intermediate Loss Regularization](https://arxiv.org/abs/2506.22846)
*Duygu Altinok*

Main category: cs.CL

Relevance: 60.0

TL;DR: 提出了一种名为LAIL的辅助损失框架，利用大型语言模型（LLM）的语言知识增强基于CTC的自动语音识别（ASR），在保持CTC解码效率的同时提升语言建模能力。


<details>
  <summary>Details</summary>
Motivation: 解决基于CTC的ASR模型在语言依赖建模上的不足，同时保持其非自回归解码的高效性。

Method: 通过连接层将中间编码器输出映射到LLM的嵌入空间，并计算因果语言建模损失。

Result: 在LibriSpeech、TEDLIUM2和WSJ语料库上显著降低了词错误率（WER），达到了基于CTC的ASR的最新性能。

Conclusion: LAIL框架有效结合了LLM的语言建模能力和CTC的高效解码，为实时ASR应用提供了新思路。

Abstract: End-to-end (E2E) automatic speech recognition (ASR) systems have
revolutionized the field by integrating all components into a single neural
network, with attention-based encoder-decoder models achieving state-of-the-art
performance. However, their autoregressive decoding process limits inference
speed, making them unsuitable for real-time applications. In contrast,
CTC-based models offer faster, non-autoregressive decoding but struggle to
model linguistic dependencies effectively. Addressing this challenge, we
propose a novel auxiliary loss framework called Language-Aware Intermediate
Loss (LAIL) to enhance CTC-based ASR using the linguistic knowledge of large
language models (LLMs). By attaching connector layers to intermediate encoder
layers, LAIL maps outputs to the embedding space of an LLM and computes a
causal language modeling loss during training. This approach enhances
linguistic modeling while preserving the computational efficiency of CTC
decoding. Using the Conformer architecture and various LLaMA models, we
demonstrate significant improvements in Word Error Rate (WER) on the
LibriSpeech, TEDLIUM2, and WSJ corpora, achieving state-of-the-art performance
for CTC-based ASR with minimal computational overhead.

</details>


### [67] [SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions](https://arxiv.org/abs/2506.23046)
*Xianzhe Fan,Xuhui Zhou,Chuanyang Jin,Kolby Nottingham,Hao Zhu,Maarten Sap*

Main category: cs.CL

Relevance: 60.0

TL;DR: 提出了SoMi-ToM基准，用于评估多智能体复杂社交互动中的心智理论能力，发现当前大型视觉语言模型在此任务上表现显著低于人类。


<details>
  <summary>Details</summary>
Motivation: 现有心智理论基准多为静态文本场景，与真实社交互动存在差距，需更全面的评估方法。

Method: 基于SoMi环境生成的多模态互动数据，设计多视角评估框架（第一人称和第三人称），构建包含视频、图像和问答的数据集。

Result: 大型视觉语言模型在SoMi-ToM上的表现显著低于人类，平均准确率差距分别为40.1%（第一人称）和26.4%（第三人称）。

Conclusion: 未来大型视觉语言模型需提升在具身复杂社交互动中的心智理论能力。

Abstract: Humans continuously infer the states, goals, and behaviors of others by
perceiving their surroundings in dynamic, real-world social interactions.
However, most Theory of Mind (ToM) benchmarks only evaluate static, text-based
scenarios, which have a significant gap compared to real interactions. We
propose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in
embodied multi-agent complex social interactions. This benchmark is based on
rich multimodal interaction data generated by the interaction environment SoMi,
covering diverse crafting goals and social relationships. Our framework
supports multi-level evaluation: (1) first-person evaluation provides
multimodal (visual, dialogue, action, etc.) input from a first-person
perspective during a task for real-time state inference, (2) third-person
evaluation provides complete third-person perspective video and text records
after a task for goal and behavior inference. This evaluation method allows for
a more comprehensive examination of a model's ToM capabilities from both the
subjective immediate experience and the objective global observation. We
constructed a challenging dataset containing 35 third-person perspective
videos, 363 first-person perspective images, and 1225 expert-annotated
multiple-choice questions (three options). On this dataset, we systematically
evaluated the performance of human subjects and several state-of-the-art large
vision-language models (LVLMs). The results show that LVLMs perform
significantly worse than humans on SoMi-ToM: the average accuracy gap between
humans and models is 40.1% in first-person evaluation and 26.4% in third-person
evaluation. This indicates that future LVLMs need to further improve their ToM
capabilities in embodied, complex social interactions.

</details>


### [68] [ATGen: A Framework for Active Text Generation](https://arxiv.org/abs/2506.23342)
*Akim Tsvigun,Daniil Vasilev,Ivan Tsvigun,Ivan Lysenko,Talgat Bektleuov,Aleksandr Medvedev,Uliana Vinogradova,Nikita Severin,Mikhail Mozikov,Andrey Savchenko,Rostislav Grigorev,Ramil Kuleev,Fedor Zhdanov,Artem Shelmanov,Ilya Makarov*

Main category: cs.CL

Relevance: 60.0

TL;DR: ATGen框架将主动学习（AL）应用于文本生成任务，结合人类标注和基于LLM的自动标注，减少标注成本和API调用费用。


<details>
  <summary>Details</summary>
Motivation: 尽管NLG任务日益流行，但主动学习在NLG中的应用有限，ATGen旨在填补这一空白。

Method: ATGen结合人类标注和基于LLM的自动标注，支持云端或本地部署的LLM，并提供统一的AL策略实现和基准测试平台。

Result: ATGen显著减少了人类标注成本和LLM API调用费用，并在多种文本生成任务中验证了其有效性。

Conclusion: ATGen为NLG任务中的主动学习提供了高效且经济的解决方案。

Abstract: Active learning (AL) has demonstrated remarkable potential in reducing the
annotation effort required for training machine learning models. However,
despite the surging popularity of natural language generation (NLG) tasks in
recent years, the application of AL to NLG has been limited. In this paper, we
introduce Active Text Generation (ATGen) - a comprehensive framework that
bridges AL with text generation tasks, enabling the application of
state-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered
annotation in NLG tasks using both human annotators and automatic annotation
agents based on large language models (LLMs). The framework supports LLMs
deployed as services, such as ChatGPT and Claude, or operated on-premises.
Furthermore, ATGen provides a unified platform for smooth implementation and
benchmarking of novel AL strategies tailored to NLG tasks. Finally, we present
evaluation results for state-of-the-art AL strategies across diverse settings
and multiple text generation tasks. We show that ATGen reduces both the effort
of human annotators and costs associated with API calls to LLM-based annotation
agents. The code of the framework is available on GitHub under the MIT license.
The video presentation is available at http://atgen-video.nlpresearch.group

</details>


### [69] [Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning](https://arxiv.org/abs/2506.23998)
*Seungjun Yi,Joakim Nguyen,Huimin Xu,Terence Lim,Andrew Well,Mia Markey,Ying Ding*

Main category: cs.CL

Relevance: 60.0

TL;DR: 提出了一种基于LLM的全自动主题分析管道，用于处理临床叙事数据，结合多智能体框架和RLHF提升主题质量。


<details>
  <summary>Details</summary>
Motivation: 解决先天性心脏病（CHD）患者和护理者叙事数据的手动主题分析（TA）劳动密集且难以扩展的问题。

Method: 采用多智能体LLM框架，各智能体分工协作提升主题分析质量，并可选结合RLHF进一步优化。

Result: 实现了对大规模定性数据集的可扩展、以患者为中心的分析，并支持LLM在特定临床场景中的微调。

Conclusion: 该自动化管道显著提升了主题分析的效率和可扩展性，为临床研究提供了新工具。

Abstract: Congenital heart disease (CHD) presents complex, lifelong challenges often
underrepresented in traditional clinical metrics. While unstructured narratives
offer rich insights into patient and caregiver experiences, manual thematic
analysis (TA) remains labor-intensive and unscalable. We propose a fully
automated large language model (LLM) pipeline that performs end-to-end TA on
clinical narratives, which eliminates the need for manual coding or full
transcript review. Our system employs a novel multi-agent framework, where
specialized LLM agents assume roles to enhance theme quality and alignment with
human analysis. To further improve thematic relevance, we optionally integrate
reinforcement learning from human feedback (RLHF). This supports scalable,
patient-centered analysis of large qualitative datasets and allows LLMs to be
fine-tuned for specific clinical contexts.

</details>


### [70] [Theories of "Sexuality" in Natural Language Processing Bias Research](https://arxiv.org/abs/2506.22481)
*Jacob Hobbs*

Main category: cs.CY

Relevance: 60.0

TL;DR: 该论文分析了NLP系统中对性取向的编码和误表示问题，发现现有研究对性取向定义不清，且常将性别与性取向混淆。


<details>
  <summary>Details</summary>
Motivation: 研究动机是填补NLP领域中对性取向偏见分析的空白，揭示现有研究的不足。

Method: 通过调查和分析55篇量化性取向偏见的文献，评估性取向的定义和操作化方式。

Result: 发现性取向在多数文献中定义不清，且性别与性取向常被混淆，导致偏见量化不准确。

Conclusion: 建议更深入地与性少数群体和跨学科文献合作，以改进性取向偏见的分析。

Abstract: In recent years, significant advancements in the field of Natural Language
Processing (NLP) have positioned commercialized language models as
wide-reaching, highly useful tools. In tandem, there has been an explosion of
multidisciplinary research examining how NLP tasks reflect, perpetuate, and
amplify social biases such as gender and racial bias. A significant gap in this
scholarship is a detailed analysis of how queer sexualities are encoded and
(mis)represented by both NLP systems and practitioners. Following previous work
in the field of AI fairness, we document how sexuality is defined and
operationalized via a survey and analysis of 55 articles that quantify
sexuality-based NLP bias. We find that sexuality is not clearly defined in a
majority of the literature surveyed, indicating a reliance on assumed or
normative conceptions of sexual/romantic practices and identities. Further, we
find that methods for extracting biased outputs from NLP technologies often
conflate gender and sexual identities, leading to monolithic conceptions of
queerness and thus improper quantifications of bias. With the goal of improving
sexuality-based NLP bias analyses, we conclude with recommendations that
encourage more thorough engagement with both queer communities and
interdisciplinary literature.

</details>


### [71] [Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation](https://arxiv.org/abs/2506.23662)
*Philip Lippmann,Jie Yang*

Main category: cs.CL

Relevance: 50.0

TL;DR: ZEST是一种零样本上下文适应框架，通过合成代理语料库实现无需目标语料库访问或微调的领域适应嵌入。


<details>
  <summary>Details</summary>
Motivation: 解决上下文感知嵌入方法需要目标语料库访问或领域特定微调的实际障碍，特别是在隐私敏感或资源受限的环境中。

Method: 使用多步分层程序生成合成代理语料库，模拟关键领域特定分布，供冻结的上下文感知编码器使用。

Result: 在MTEB基准测试中，ZEST仅使用五个示例文档的零样本合成上下文适应性能接近完全访问目标语料库的模型（差距0.5%）。

Conclusion: ZEST为受限环境中部署高性能、可适应嵌入提供了一种实用方法。

Abstract: Context-aware embedding methods boost retrieval accuracy by conditioning on
corpus statistics (e.g., term co-occurrence and topical patterns) extracted
from neighboring documents. However, this context-aware approach requires
access to the target corpus or requires domain-specific finetuning, posing
practical barriers in privacy-sensitive or resource-constrained settings. We
present ZEST, a zero-shot contextual adaptation framework that replaces real
corpus access with a one-time offline synthesis of a compact proxy. Given only
a handful exemplar documents representative of the general target domain, we
use a multi-step hierarchical procedure to generate a synthetic context corpus
of several hundred documents that aims to emulate key domain-specific
distributions. At inference, the frozen context-aware encoder uses this proxy
corpus -- without any finetuning or target corpus access -- to produce
domain-adapted embeddings. Across the MTEB benchmark, ZEST's zero-shot
synthetic context adaptation using only five example documents performs within
0.5% of models leveraging full target corpus access -- demonstrating remarkable
efficacy without any retraining. ZEST thus provides a practical method for
deploying high-performance, adaptable embeddings in constrained environments.

</details>


### [72] [AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents](https://arxiv.org/abs/2506.22485)
*Sudip Dasgupta,Himanshu Shankar*

Main category: cs.CL

Relevance: 40.0

TL;DR: 提出了一种模块化多智能体系统，用于自动化审核企业结构化文档，利用AI代理实现高效、准确的文档评估。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案主要关注非结构化文本或有限合规检查，无法满足企业文档的高效审核需求。

Method: 采用LangChain、CrewAI等工具，设计多智能体并行或顺序工作，实现文档分块评估，并标准化输出。

Result: AI系统在一致性（99% vs 人类92%）、错误率和时间效率（2.5分钟 vs 30分钟）上优于人类，且与专家判断一致率达95%。

Conclusion: 系统为企业文档质量保证提供了灵活、可扩展的基础，但仍需人类监督和高成本LLM使用的优化。

Abstract: This study presents a modular, multi-agent system for the automated review of
highly structured enterprise business documents using AI agents. Unlike prior
solutions focused on unstructured texts or limited compliance checks, this
framework leverages modern orchestration tools such as LangChain, CrewAI,
TruLens, and Guidance to enable section-by-section evaluation of documents for
accuracy, consistency, completeness, and clarity. Specialized agents, each
responsible for discrete review criteria such as template compliance or factual
correctness, operate in parallel or sequence as required. Evaluation outputs
are enforced to a standardized, machine-readable schema, supporting downstream
analytics and auditability. Continuous monitoring and a feedback loop with
human reviewers allow for iterative system improvement and bias mitigation.
  Quantitative evaluation demonstrates that the AI Agent-as-Judge system
approaches or exceeds human performance in key areas: achieving 99% information
consistency (vs. 92% for humans), halving error and bias rates, and reducing
average review time from 30 to 2.5 minutes per document, with a 95% agreement
rate between AI and expert human judgment. While promising for a wide range of
industries, the study also discusses current limitations, including the need
for human oversight in highly specialized domains and the operational cost of
large-scale LLM usage. The proposed system serves as a flexible, auditable, and
scalable foundation for AI-driven document quality assurance in the enterprise
context.

</details>


### [73] [Can "consciousness" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis](https://arxiv.org/abs/2506.22516)
*Jingkai Li*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文应用IIT 3.0和4.0框架分析LLM表征，探究其是否显示意识现象，结果表明缺乏显著意识指标。


<details>
  <summary>Details</summary>
Motivation: 探索LLM表征中是否存在意识现象，以区分意识与表征空间的内在分离。

Method: 应用IIT 3.0和4.0框架分析LLM表征，比较不同指标（如Φmax、Φ等）与Span Representations。

Result: 当代Transformer-based LLM表征缺乏显著意识指标，但在空间置换分析中显示有趣模式。

Conclusion: LLM表征未显示显著意识现象，但分析框架为未来研究提供了方向。

Abstract: Integrated Information Theory (IIT) provides a quantitative framework for
explaining consciousness phenomenon, positing that conscious systems comprise
elements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the
latest iterations of this framework -- to sequences of Large Language Model
(LLM) representations, analyzing data derived from existing Theory of Mind
(ToM) test results. Our study systematically investigates whether the
differences of ToM test performances, when presented in the LLM
representations, can be revealed by IIT estimates, i.e., $\Phi^{\max}$ (IIT
3.0), $\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\Phi$-structure
(IIT 4.0). Furthermore, we compare these metrics with the Span Representations
independent of any estimate for consciousness. This additional effort aims to
differentiate between potential "consciousness" phenomena and inherent
separations within LLM representational space. We conduct comprehensive
experiments examining variations across LLM transformer layers and linguistic
spans from stimuli. Our results suggest that sequences of contemporary
Transformer-based LLM representations lack statistically significant indicators
of observed "consciousness" phenomena but exhibit intriguing patterns under
$\textit{spatio}$-permutational analyses. The Appendix and code are available
as Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.

</details>


### [74] [MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages](https://arxiv.org/abs/2506.22529)
*Lu Kalkbrenner,Veronika Solopova,Steffen Zeiler,Robert Nickel,Dorothea Kolossa*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文介绍了Misinfo-TeleGraph，首个基于德语Telegram的图数据集，用于检测虚假信息，结合文本和图神经网络方法，GraphSAGE表现最佳。


<details>
  <summary>Details</summary>
Motivation: Telegram等低监管平台成为虚假信息传播的重要渠道，但连接性和消息传播信息在虚假信息检测中未被充分利用。

Method: 构建包含500万条消息的图数据集，结合语义相似度和人工标注生成标签，评估文本模型和图神经网络（如GraphSAGE）。

Result: GraphSAGE结合LSTM聚合在MCC和F1分数上显著优于纯文本模型。

Conclusion: 该研究为德语Telegram网络的虚假信息检测提供了可复现的基准和开放数据集。

Abstract: Connectivity and message propagation are central, yet often underutilized,
sources of information in misinformation detection -- especially on poorly
moderated platforms such as Telegram, which has become a critical channel for
misinformation dissemination, namely in the German electoral context. In this
paper, we introduce Misinfo-TeleGraph, the first German-language Telegram-based
graph dataset for misinformation detection. It includes over 5 million messages
from public channels, enriched with metadata, channel relationships, and both
weak and strong labels. These labels are derived via semantic similarity to
fact-checks and news articles using M3-embeddings, as well as manual
annotation. To establish reproducible baselines, we evaluate both text-only
models and graph neural networks (GNNs) that incorporate message forwarding as
a network structure. Our results show that GraphSAGE with LSTM aggregation
significantly outperforms text-only baselines in terms of Matthews Correlation
Coefficient (MCC) and F1-score. We further evaluate the impact of subscribers,
view counts, and automatically versus human-created labels on performance, and
highlight both the potential and challenges of weak supervision in this domain.
This work provides a reproducible benchmark and open dataset for future
research on misinformation detection in German-language Telegram networks and
other low-moderation social platforms.

</details>


### [75] [Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions](https://arxiv.org/abs/2506.22858)
*Duygu Altinok*

Main category: cs.CL

Relevance: 40.0

TL;DR: 提出了一种通过扩展语义上下文窗口的新型训练方法，提升ASR系统在命名实体和数值数据上的识别与格式化能力。


<details>
  <summary>Details</summary>
Motivation: ASR系统（如Whisper）在命名实体和数值数据上表现不佳，影响语义理解，特别是在法律、金融和医疗等关键领域。

Method: 通过在训练中添加重叠上下文窗口（5秒重叠，30秒块，形成40秒有效窗口），并重新分配跨边界实体至右侧块，同时使用嵌入实体标签的丰富数据训练模型。

Result: 在Spoken Wikipedia数据集上，该方法显著提升了命名实体识别（NER）和实体格式化的性能。

Conclusion: 上下文感知训练能有效解决ASR系统在长文本转录和复杂实体识别任务中的局限性。

Abstract: Automatic Speech Recognition (ASR) systems, such as Whisper, achieve high
transcription accuracy but struggle with named entities and numerical data,
especially when proper formatting is required. These issues increase word error
rate (WER) and impair semantic understanding in critical domains like legal,
financial, and medical applications. We propose a novel training approach that
extends the semantic context of ASR models by adding overlapping context
windows during training. By sliding 5-second overlaps on both sides of
30-second chunks, we create a 40-second "effective semantic window," improving
entity recognition and formatting while focusing predictions on the central 30
seconds. To address entities spanning chunk boundaries, we reassign such
entities entirely to the right-hand chunk, ensuring proper formatting.
Additionally, enriched training data with embedded entity labels enables the
model to learn both recognition and type-specific formatting. Evaluated on the
Spoken Wikipedia dataset, our method improves performance across semantic
tasks, including named entity recognition (NER) and entity formatting. These
results highlight the effectiveness of context-aware training in addressing ASR
limitations for long-form transcription and complex entity recognition tasks.

</details>


### [76] [MariNER: A Dataset for Historical Brazilian Portuguese Named Entity Recognition](https://arxiv.org/abs/2506.23051)
*João Lucas Luz Lima Sarcinelli,Marina Lages Gonçalves Teixeira,Jade Bortot de Paiva,Diego Furtado Silva*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文介绍了MariNER，这是首个针对20世纪初巴西葡萄牙语的历史文本的黄金标准NER数据集，包含9000多个手动标注的句子，并评估了最先进NER模型的性能。


<details>
  <summary>Details</summary>
Motivation: 巴西葡萄牙语在特定领域（如历史文本）缺乏高质量的NER数据集，尤其是在数字人文学科背景下，NER的重要性凸显。

Method: 构建了MariNER数据集，包含9000多个手动标注的句子，并评估了多个最先进的NER模型。

Result: 提供了首个针对20世纪初巴西葡萄牙语历史文本的NER数据集，并展示了不同模型的性能比较。

Conclusion: MariNER填补了巴西葡萄牙语历史文本NER数据集的空白，为相关研究提供了资源。

Abstract: Named Entity Recognition (NER) is a fundamental Natural Language Processing
(NLP) task that aims to identify and classify entity mentions in texts across
different categories. While languages such as English possess a large number of
high-quality resources for this task, Brazilian Portuguese still lacks in
quantity of gold-standard NER datasets, especially when considering specific
domains. Particularly, this paper considers the importance of NER for analyzing
historical texts in the context of digital humanities. To address this gap,
this work outlines the construction of MariNER: \textit{Mapeamento e
Anota\c{c}\~oes de Registros hIst\'oricos para NER} (Mapping and Annotation of
Historical Records for NER), the first gold-standard dataset for early
20th-century Brazilian Portuguese, with more than 9,000 manually annotated
sentences. We also assess and compare the performance of state-of-the-art NER
models for the dataset.

</details>


### [77] [Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning](https://arxiv.org/abs/2506.23056)
*Xiang Zhuang,Bin Wu,Jiyu Cui,Kehua Feng,Xiaotong Li,Huabin Xing,Keyan Ding,Qiang Zhang,Huajun Chen*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文提出了一种知识增强的分子结构解析框架（K-MSE），通过结合外部知识库和蒙特卡洛树搜索，显著提升了LLMs在化学结构解析任务中的性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在分子结构解析任务中表现不佳，主要原因是缺乏专业化学知识。

Method: 构建外部分子子结构知识库，设计分子-光谱评分器作为奖励模型，结合蒙特卡洛树搜索进行推理。

Result: 实验显示K-MSE显著提升了性能，在GPT-4o-mini和GPT-4o上均获得超过20%的改进。

Conclusion: K-MSE通过知识增强和优化推理过程，有效解决了LLMs在化学任务中的局限性。

Abstract: Molecular structure elucidation involves deducing a molecule's structure from
various types of spectral data, which is crucial in chemical experimental
analysis. While large language models (LLMs) have shown remarkable proficiency
in analyzing and reasoning through complex tasks, they still encounter
substantial challenges in molecular structure elucidation. We identify that
these challenges largely stem from LLMs' limited grasp of specialized chemical
knowledge. In this work, we introduce a Knowledge-enhanced reasoning framework
for Molecular Structure Elucidation (K-MSE), leveraging Monte Carlo Tree Search
for test-time scaling as a plugin. Specifically, we construct an external
molecular substructure knowledge base to extend the LLMs' coverage of the
chemical structure space. Furthermore, we design a specialized
molecule-spectrum scorer to act as a reward model for the reasoning process,
addressing the issue of inaccurate solution evaluation in LLMs. Experimental
results show that our approach significantly boosts performance, particularly
gaining more than 20% improvement on both GPT-4o-mini and GPT-4o. Our code is
available at https://github.com/HICAI-ZJU/K-MSE.

</details>


### [78] [Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models](https://arxiv.org/abs/2506.23122)
*Shivam Sharma,Tanmoy Chakraborty*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文研究了在多语言互联网迷因中识别叙事角色（英雄、反派、受害者等）的任务，评估了多种模型在零样本设置下的表现，并探讨了提示设计对多模态模型的改进。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在复杂、文化特定的迷因内容中可靠识别叙事角色的挑战，尤其是在跨文化和混合语言场景下。

Method: 方法包括构建一个更平衡且语言多样的数据集，评估多种模型（如多语言Transformer、多模态视觉语言模型），并探索提示设计策略。

Result: 结果显示，大模型（如DeBERTa-v3和Qwen2.5-VL）表现较好，但在识别“受害者”类和跨文化内容时仍存在挑战。混合提示设计带来小幅改进。

Conclusion: 结论强调了文化背景、提示工程和多模态推理在建模视觉-文本内容中的重要性。

Abstract: This work investigates the challenging task of identifying narrative roles -
Hero, Villain, Victim, and Other - in Internet memes, across three diverse test
sets spanning English and code-mixed (English-Hindi) languages. Building on an
annotated dataset originally skewed toward the 'Other' class, we explore a more
balanced and linguistically diverse extension, originally introduced as part of
the CLEF 2024 shared task. Comprehensive lexical and structural analyses
highlight the nuanced, culture-specific, and context-rich language used in real
memes, in contrast to synthetically curated hateful content, which exhibits
explicit and repetitive lexical markers. To benchmark the role detection task,
we evaluate a wide spectrum of models, including fine-tuned multilingual
transformers, sentiment and abuse-aware classifiers, instruction-tuned LLMs,
and multimodal vision-language models. Performance is assessed under zero-shot
settings using precision, recall, and F1 metrics. While larger models like
DeBERTa-v3 and Qwen2.5-VL demonstrate notable gains, results reveal consistent
challenges in reliably identifying the 'Victim' class and generalising across
cultural and code-mixed content. We also explore prompt design strategies to
guide multimodal models and find that hybrid prompts incorporating structured
instructions and role definitions offer marginal yet consistent improvements.
Our findings underscore the importance of cultural grounding, prompt
engineering, and multimodal reasoning in modelling subtle narrative framings in
visual-textual content.

</details>


### [79] [Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion](https://arxiv.org/abs/2506.23137)
*Siyuan Li,Ruitong Liu,Yan Wen,Te Sun*

Main category: cs.CL

Relevance: 40.0

TL;DR: 提出了Flow-Modulated Scoring (FMS)框架，结合上下文敏感的实体表示和动态嵌入变换，提升知识图谱补全的性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱补全方法多为静态嵌入评分，难以捕捉上下文依赖和关系动态性。

Method: FMS包含语义上下文学习模块和条件流匹配模块，动态优化静态评分。

Result: 在多个标准基准测试中超越现有最优方法。

Conclusion: FMS通过结合静态和动态信息，更深入地建模关系语义。

Abstract: Effective modeling of multifaceted relations is pivotal for Knowledge Graph
Completion (KGC). However, a majority of existing approaches are predicated on
static, embedding-based scoring, exhibiting inherent limitations in capturing
contextual dependencies and relational dynamics. Addressing this gap, we
propose the Flow-Modulated Scoring (FMS) framework. FMS comprises two principal
components: (1) a semantic context learning module that encodes
context-sensitive entity representations, and (2) a conditional flow-matching
module designed to learn the dynamic transformation from a head to a tail
embedding, governed by the aforementioned context. The resultant predictive
vector field, representing the context-informed relational path, serves to
dynamically refine the initial static score of an entity pair. Through this
synergy of context-aware static representations and conditioned dynamic
information, FMS facilitates a more profound modeling of relational semantics.
Comprehensive evaluations on several standard benchmarks demonstrate that our
proposed method surpasses prior state-of-the-art results.

</details>


### [80] [RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams](https://arxiv.org/abs/2506.23192)
*Gabriel Iturra-Bocaz,Felipe Bravo-Marquez*

Main category: cs.CL

Relevance: 40.0

TL;DR: RiverText是一个Python库，用于从文本数据流中训练和评估增量词嵌入，支持动态更新词表示以适应不断变化的语言模式。


<details>
  <summary>Details</summary>
Motivation: 传统词嵌入模型是静态的，无法适应语言模式的动态变化（如社交媒体中的新词汇）。RiverText旨在解决这一问题，提供增量词嵌入的训练和评估工具。

Method: RiverText实现了多种增量词嵌入技术（如Skip-gram、CBOW、Word Context Matrix），使用PyTorch作为后端，并提供了流式评估模块。

Result: 论文比较了不同超参数设置下的方法，并讨论了结果。

Conclusion: RiverText为信息检索和自然语言处理社区提供了一个实用的工具，支持流式场景下的词嵌入研究。

Abstract: Word embeddings have become essential components in various information
retrieval and natural language processing tasks, such as ranking, document
classification, and question answering. However, despite their widespread use,
traditional word embedding models present a limitation in their static nature,
which hampers their ability to adapt to the constantly evolving language
patterns that emerge in sources such as social media and the web (e.g., new
hashtags or brand names). To overcome this problem, incremental word embedding
algorithms are introduced, capable of dynamically updating word representations
in response to new language patterns and processing continuous data streams.
  This paper presents RiverText, a Python library for training and evaluating
incremental word embeddings from text data streams. Our tool is a resource for
the information retrieval and natural language processing communities that work
with word embeddings in streaming scenarios, such as analyzing social media.
The library implements different incremental word embedding techniques, such as
Skip-gram, Continuous Bag of Words, and Word Context Matrix, in a standardized
framework. In addition, it uses PyTorch as its backend for neural network
training. We have implemented a module that adapts existing intrinsic static
word embedding evaluation tasks for word similarity and word categorization to
a streaming setting. Finally, we compare the implemented methods with different
hyperparameter settings and discuss the results. Our open-source library is
available at https://github.com/dccuchile/rivertext.

</details>


### [81] [Two Spelling Normalization Approaches Based on Large Language Models](https://arxiv.org/abs/2506.23288)
*Miguel Domingo,Francisco Casacuberta*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文提出了两种基于大语言模型的拼写规范化方法，一种无监督训练，另一种基于机器翻译训练。评估表明，统计机器翻译更适合此任务。


<details>
  <summary>Details</summary>
Motivation: 解决历史文献中拼写标准化的问题，为学者提供更统一的文本分析工具。

Method: 提出两种大语言模型方法：无监督训练和机器翻译训练，并在多语言和历史时期数据集上评估。

Result: 两种方法均有效，但统计机器翻译表现更优。

Conclusion: 统计机器翻译仍是拼写规范化任务的最合适技术。

Abstract: The absence of standardized spelling conventions and the organic evolution of
human language present an inherent linguistic challenge within historical
documents, a longstanding concern for scholars in the humanities. Addressing
this issue, spelling normalization endeavors to align a document's orthography
with contemporary standards. In this study, we propose two new approaches based
on large language models: one of which has been trained without a supervised
training, and a second one which has been trained for machine translation. Our
evaluation spans multiple datasets encompassing diverse languages and
historical periods, leading us to the conclusion that while both of them
yielded encouraging results, statistical machine translation still seems to be
the most suitable technology for this task.

</details>


### [82] [Ensemble BERT for Medication Event Classification on Electronic Health Records (EHRs)](https://arxiv.org/abs/2506.23315)
*Shouvon Sarker,Xishuang Dong,Lijun Qian*

Main category: cs.CL

Relevance: 40.0

TL;DR: 论文提出了一种基于BERT的集成模型，用于从临床记录中检测和分类药物事件，通过预训练和微调BERT模型，并结合投票策略，显著提高了分类性能。


<details>
  <summary>Details</summary>
Motivation: 临床记录中的药物事件识别对医疗领域有广泛应用，但现有方法性能有限，因此需要更有效的模型。

Method: 预训练BERT模型于Wikipedia和MIMIC数据，微调于CMED数据集，通过集成多个BERT模型的预测结果并使用投票策略。

Result: 实验表明，BERT集成模型将严格Micro-F和Macro-F分数分别提高了约5%和6%。

Conclusion: 基于BERT的集成模型能有效提升药物事件分类性能，适用于临床数据分析。

Abstract: Identification of key variables such as medications, diseases, relations from
health records and clinical notes has a wide range of applications in the
clinical domain. n2c2 2022 provided shared tasks on challenges in natural
language processing for clinical data analytics on electronic health records
(EHR), where it built a comprehensive annotated clinical data Contextualized
Medication Event Dataset (CMED). This study focuses on subtask 2 in Track 1 of
this challenge that is to detect and classify medication events from clinical
notes through building a novel BERT-based ensemble model. It started with
pretraining BERT models on different types of big data such as Wikipedia and
MIMIC. Afterwards, these pretrained BERT models were fine-tuned on CMED
training data. These fine-tuned BERT models were employed to accomplish
medication event classification on CMED testing data with multiple predictions.
These multiple predictions generated by these fine-tuned BERT models were
integrated to build final prediction with voting strategies. Experimental
results demonstrated that BERT-based ensemble models can effectively improve
strict Micro-F score by about 5% and strict Macro-F score by about 6%,
respectively.

</details>


### [83] [Machine Understanding of Scientific Language](https://arxiv.org/abs/2506.23990)
*Dustin Wright*

Main category: cs.CL

Relevance: 40.0

TL;DR: 该论文专注于通过自然语言处理和机器学习方法（如自动事实核查、有限数据学习和科学文本处理）来识别科学文本的忠实性，并生成对科学传播过程的新见解。


<details>
  <summary>Details</summary>
Motivation: 科学文本的忠实性对知识传播至关重要，但并非所有文本都准确反映科学事实。随着科学文本数量的激增，自动识别其忠实性成为社会重要问题。

Method: 论文提出了多种方法，包括自动事实核查、对抗性声明生成、多源域适应、从众包标签学习、引用价值检测、零样本科学事实核查、检测夸大科学声明以及建模科学传播中的信息变化程度。

Result: 研究展示了如何从有限的科学文本中有效学习，以识别误导性科学陈述，并生成对科学传播过程的新见解。

Conclusion: 该论文为科学文本的忠实性识别提供了新的方法和工具，有助于理解科学传播过程。

Abstract: Scientific information expresses human understanding of nature. This
knowledge is largely disseminated in different forms of text, including
scientific papers, news articles, and discourse among people on social media.
While important for accelerating our pursuit of knowledge, not all scientific
text is faithful to the underlying science. As the volume of this text has
burgeoned online in recent years, it has become a problem of societal
importance to be able to identify the faithfulness of a given piece of
scientific text automatically. This thesis is concerned with the cultivation of
datasets, methods, and tools for machine understanding of scientific language,
in order to analyze and understand science communication at scale. To arrive at
this, I present several contributions in three areas of natural language
processing and machine learning: automatic fact checking, learning with limited
data, and scientific text processing. These contributions include new methods
and resources for identifying check-worthy claims, adversarial claim
generation, multi-source domain adaptation, learning from crowd-sourced labels,
cite-worthiness detection, zero-shot scientific fact checking, detecting
exaggerated scientific claims, and modeling degrees of information change in
science communication. Critically, I demonstrate how the research outputs of
this thesis are useful for effectively learning from limited amounts of
scientific text in order to identify misinformative scientific statements and
generate new insights into the science communication process

</details>


### [84] [EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations](https://arxiv.org/abs/2506.24016)
*Hyunjong Kim,Sangyeop Kim,Jongheon Jeong,Yeongjae Cho,Sungzoon Cho*

Main category: cs.CL

Relevance: 40.0

TL;DR: EXPERT是一种新的无参考评估指标，用于图像字幕任务，提供基于流畅性、相关性和描述性的结构化解释。


<details>
  <summary>Details</summary>
Motivation: 现有图像字幕评估指标缺乏标准化解释标准，且解释质量未经验证。

Method: 构建大规模高质量结构化解释数据集，采用两阶段评估模板监督视觉语言模型进行评分和解释生成。

Result: 在基准数据集上达到最先进水平，且解释质量显著优于现有指标。

Conclusion: EXPERT提供高质量结构化解释，为图像字幕评估提供新标准。

Abstract: Recent advances in large language models and vision-language models have led
to growing interest in explainable evaluation metrics for image captioning.
However, these metrics generate explanations without standardized criteria, and
the overall quality of the generated explanations remains unverified. In this
paper, we propose EXPERT, a reference-free evaluation metric that provides
structured explanations based on three fundamental criteria: fluency,
relevance, and descriptiveness. By constructing large-scale datasets of
high-quality structured explanations, we develop a two-stage evaluation
template to effectively supervise a vision-language model for both scoring and
explanation generation. EXPERT achieves state-of-the-art results on benchmark
datasets while providing significantly higher-quality explanations than
existing metrics, as validated through comprehensive human evaluation. Our code
and datasets are available at https://github.com/hjkim811/EXPERT.

</details>


### [85] [Computational Analysis of Climate Policy](https://arxiv.org/abs/2506.22449)
*Carolyn Hicks*

Main category: cs.CY

Relevance: 40.0

TL;DR: 该论文探讨了气候紧急运动对地方政府气候政策的影响，并利用GPT-4构建了PALLM系统进行政策分析。研究发现，通过CED的议会在政策中更关注紧迫性和社会公正。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（如GPT-4）在复杂政策问题分析中的潜力，并研究气候紧急运动对地方政策的影响。

Method: 使用GPT-4构建PALLM系统，分析维多利亚州地方政府的政策文件，并通过政策制定者验证系统性能。

Result: GPT-4能够进行高级政策分析，但存在可靠性问题；通过CED的议会在政策中更关注紧迫性和社会公正。

Conclusion: 大规模政策分析为政策研究提供了新机会，但需解决模型的可靠性问题。

Abstract: This thesis explores the impact of the Climate Emergency movement on local
government climate policy, using computational methods. The Climate Emergency
movement sought to accelerate climate action at local government level through
the mechanism of Climate Emergency Declarations (CEDs), resulting in a series
of commitments from councils to treat climate change as an emergency. With the
aim of assessing the potential of current large language models to answer
complex policy questions, I first built and configured a system named PALLM
(Policy Analysis with a Large Language Model), using the OpenAI model GPT-4.
This system is designed to apply a conceptual framework for climate emergency
response plans to a dataset of climate policy documents. I validated the
performance of this system with the help of local government policymakers, by
generating analyses of the climate policies of 11 local governments in Victoria
and assessing the policymakers' level of agreement with PALLM's responses.
Having established that PALLM's performance is satisfactory, I used it to
conduct a large-scale analysis of current policy documents from local
governments in the state of Victoria, Australia. This thesis presents the
methodology and results of this analysis, comparing the results for councils
which have passed a CED to those which did not. This study finds that GPT-4 is
capable of high-level policy analysis, with limitations including a lack of
reliable attribution, and can also enable more nuanced analysis by researchers.
Its use in this research shows that councils which have passed a CED are more
likely to have a recent and climate-specific policy, and show more attention to
urgency, prioritisation, and equity and social justice, than councils which
have not. It concludes that the ability to assess policy documents at scale
opens up exciting new opportunities for policy researchers.

</details>


### [86] [Density, asymmetry and citation dynamics in scientific literature](https://arxiv.org/abs/2506.23366)
*Nathaniel Imel,Zachary Hafen*

Main category: cs.DL

Relevance: 40.0

TL;DR: 论文研究了科学论文与先前研究的相似性与其引用率之间的关系，提出了两个度量指标（密度和不对称性），发现密度对引用率有微弱但信息性的影响。


<details>
  <summary>Details</summary>
Motivation: 探索科学行为中基于已有知识与引入新思想之间的张力，是否反映在论文相似性与引用率的关系中。

Method: 引入两个指标（密度和不对称性）表征论文的语义邻域几何，使用贝叶斯分层回归分析约53,000篇论文的数据。

Result: 密度对引用率有微弱但信息性的影响，不对称性无显著预测效果。

Conclusion: 论文提出了一个可扩展的框架，将文档嵌入与科学计量结果联系起来，并探讨了语义相似性在科学奖励动态中的作用。

Abstract: Scientific behavior is often characterized by a tension between building upon
established knowledge and introducing novel ideas. Here, we investigate whether
this tension is reflected in the relationship between the similarity of a
scientific paper to previous research and its eventual citation rate. To
operationalize similarity to previous research, we introduce two complementary
metrics to characterize the local geometry of a publication's semantic
neighborhood: (1) \emph{density} ($\rho$), defined as the ratio between a fixed
number of previously-published papers and the minimum distance enclosing those
papers in a semantic embedding space, and (2) asymmetry ($\alpha$), defined as
the average directional difference between a paper and its nearest neighbors.
We tested the predictive relationship between these two metrics and its
subsequent citation rate using a Bayesian hierarchical regression approach,
surveying $\sim 53,000$ publications across nine academic disciplines and five
different document embeddings. While the individual effects of $\rho$ on
citation count are small and variable, incorporating density-based predictors
consistently improves out-of-sample prediction when added to baseline models.
These results suggest that the density of a paper's surrounding scientific
literature may carry modest but informative signals about its eventual impact.
Meanwhile, we find no evidence that publication asymmetry improves model
predictions of citation rates. Our work provides a scalable framework for
linking document embeddings to scientometric outcomes and highlights new
questions regarding the role that semantic similarity plays in shaping the
dynamics of scientific reward.

</details>


### [87] [Efficient Interleaved Speech Modeling through Knowledge Distillation](https://arxiv.org/abs/2506.23670)
*Mohammadmahdi Nouriborji,Morteza Rohanian*

Main category: cs.SD

Relevance: 40.0

TL;DR: 论文提出了一种通过层对齐蒸馏技术构建紧凑、高效的语音生成模型TinyWave，压缩大型多模态Transformer 3倍，性能损失极小。


<details>
  <summary>Details</summary>
Motivation: 当前语音语言模型在规模和延迟上难以满足部署环境的需求，需要更紧凑且高效的模型。

Method: 采用层对齐蒸馏技术，匹配隐藏状态、注意力图和软化logits，训练2B参数的TinyWave模型。

Result: TinyWave在Libri-Light上接近教师模型的性能，在StoryCloze和SALMon任务上达到教师模型93-97%的准确率。

Conclusion: TinyWave适用于实时对话代理和低资源环境，支持语音和混合语音文本生成。

Abstract: Current speech language models exceed the size and latency constraints of
many deployment environments. We build compact, expressive speech generation
models through layer-aligned distillation, matching hidden states, attention
maps, and softened logits to compress large multimodal transformers by 3x with
minimal loss in performance. We introduce TinyWave, a family of 2B-parameter
models for speech-to-speech and interleaved speech-text generation, trained on
50,000 hours of public audio. TinyWave supports (i) speech-only generation
using phonetic or expressive tokens and (ii) mixed speech-text continuations.
Evaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity
points of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97%
of the teacher's performance, outperforming size-matched baselines. These
models are optimized for deployment on commodity hardware, enabling
applications in real-time conversational agents, assistive technologies, and
low-resource environments. We release models, training code, and evaluation
scripts to support reproducible research on compact, expressive speech
generation.

</details>


### [88] [NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning](https://arxiv.org/abs/2506.23524)
*Phan Quoc Hung Mai,Quang Hung Nguyen,Phuong Giang Duong,Hong Hanh Nguyen,Nguyen Tuan Long*

Main category: cs.CL

Relevance: 30.0

TL;DR: 论文介绍了NEU-ESC，一个越南语教育情感和主题分类数据集，并通过多任务学习（基于BERT）取得了83.7%和79.8%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决越南语教育领域数据集稀缺和缺乏学生俚语的问题。

Method: 使用多任务学习（基于BERT）进行情感和主题分类。

Result: 在情感和主题分类任务中分别达到83.7%和79.8%的准确率。

Conclusion: NEU-ESC数据集填补了越南语教育领域的空白，BERT多任务学习表现良好。

Abstract: In the field of education, understanding students' opinions through their
comments is crucial, especially in the Vietnamese language, where resources
remain limited. Existing educational datasets often lack domain relevance and
student slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese
dataset for Educational Sentiment Classification and Topic Classification,
curated from university forums, which offers more samples, richer class
diversity, longer texts, and broader vocabulary. In addition, we explore
multitask learning using encoder-only language models (BERT), in which we
showed that it achieves performance up to 83.7% and 79.8% accuracy for
sentiment and topic classification tasks. We also benchmark our dataset and
model with other datasets and models, including Large Language Models, and
discuss these benchmarks. The dataset is publicly available at:
https://huggingface.co/datasets/hung20gg/NEU-ESC.

</details>


### [89] [Computational Detection of Intertextual Parallels in Biblical Hebrew: A Benchmark Study Using Transformer-Based Language Models](https://arxiv.org/abs/2506.24117)
*David M. Smiley*

Main category: cs.CL

Relevance: 30.0

TL;DR: 该研究评估了预训练Transformer模型（如E5、AlephBERT等）在检测希伯来圣经文本平行段落中的表现，发现E5和AlephBERT效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统手动比较方法效率低且易出错，研究旨在探索预训练模型在提升古代文本平行段落检测效率和准确性上的潜力。

Method: 使用E5、AlephBERT、MPNet和LaBSE模型生成词嵌入，通过余弦相似度和Wasserstein距离评估模型性能。

Result: E5在平行段落检测中表现最佳，AlephBERT在区分非平行段落上更强。

Conclusion: 预训练模型可提升古代文本平行段落检测的效率和准确性，适用于更广泛的古代语言研究。

Abstract: Identifying parallel passages in biblical Hebrew is foundational in biblical
scholarship for uncovering intertextual relationships. Traditional methods rely
on manual comparison, which is labor-intensive and prone to human error. This
study evaluates the potential of pre-trained transformer-based language models,
including E5, AlephBERT, MPNet, and LaBSE, for detecting textual parallels in
the Hebrew Bible. Focusing on known parallels between the books of Samuel/Kings
and Chronicles, I assessed each model's capability to generate word embeddings
that delineate parallel from non-parallel passages. Utilizing cosine similarity
and Wasserstein Distance measures, I found that E5 and AlephBERT show
significant promise, with E5 excelling in parallel detection and AlephBERT
demonstrating stronger non-parallel differentiation. These findings indicate
that pre-trained models can enhance the efficiency and accuracy of detecting
intertextual parallels in ancient texts, suggesting broader applications for
ancient language studies.

</details>


### [90] [You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties](https://arxiv.org/abs/2506.23367)
*Paige Tuttösí,H. Henny Yeung,Yue Wang,Jean-Julien Aucouturier,Angelica Lim*

Main category: cs.SD

Relevance: 30.0

TL;DR: 论文提出了一种针对第二语言（L2）学习者的文本转语音（TTS）系统，通过调整元音时长提升清晰度，实验显示显著减少了转录错误，但听众感知与实际情况不符。


<details>
  <summary>Details</summary>
Motivation: 为第二语言学习者设计更清晰的TTS系统，解决其听力理解中的困难。

Method: 利用美国英语中紧张元音和松弛元音的时长差异，设计“清晰模式”并评估其效果。

Result: 清晰模式显著减少了转录错误（至少9.15%），但听众误以为整体减速更清晰。Whisper-ASR未能有效评估L2学习者的需求。

Conclusion: TTS系统需针对L2学习者优化，但听众感知与实际效果不一致，需进一步研究。

Abstract: We present the first text-to-speech (TTS) system tailored to second language
(L2) speakers. We use duration differences between American English tense
(longer) and lax (shorter) vowels to create a "clarity mode" for Matcha-TTS.
Our perception studies showed that French-L1, English-L2 listeners had fewer
(at least 9.15%) transcription errors when using our clarity mode, and found it
more encouraging and respectful than overall slowed down speech. Remarkably,
listeners were not aware of these effects: despite the decreased word error
rate in clarity mode, listeners still believed that slowing all target words
was the most intelligible, suggesting that actual intelligibility does not
correlate with perceived intelligibility. Additionally, we found that
Whisper-ASR did not use the same cues as L2 speakers to differentiate difficult
vowels and is not sufficient to assess the intelligibility of TTS systems for
these individuals.

</details>


### [91] [Reachability in symmetric VASS](https://arxiv.org/abs/2506.23578)
*Łukasz Kamiński,Sławomir Lasota*

Main category: cs.FL

Relevance: 10.0

TL;DR: 研究了对称向量加法系统（VASS）中的可达性问题，重点关注不同群（如对称群、交替群和循环群）对问题复杂度的影响。


<details>
  <summary>Details</summary>
Motivation: 探索对称性在VASS可达性问题中的作用，特别是如何通过群论方法降低复杂度。

Method: 分析不同群（如对称群、交替群和循环群）对VASS可达性问题的影响，并比较其复杂度。

Result: 在对称群下，可达性问题可在PSPACE内解决，与一般VASS的Ackermannian复杂度形成对比。

Conclusion: 对称性可以显著降低VASS可达性问题的复杂度，为相关领域提供了新的理论工具。

Abstract: We investigate the reachability problem in symmetric vector addition systems
with states (VASS), where transitions are invariant under a group of
permutations of coordinates. One extremal case, the trivial groups, yields
general VASS. In another extremal case, the symmetric groups, we show that the
reachability problem can be solved in PSPACE, regardless of the dimension of
input VASS (to be contrasted with Ackermannian complexity in general VASS). We
also consider other groups, in particular alternating and cyclic ones.
Furthermore, motivated by the open status of the reachability problem in data
VASS, we estimate the gain in complexity when the group arises as a combination
of the trivial and symmetric groups.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [92] [Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding](https://arxiv.org/abs/2506.22803)
*Nuoye Xiong,Anqi Dong,Ning Wang,Cong Hua,Guangming Zhu,Mei Lin,Peiyi Shen,Liang Zhang*

Main category: cs.CV

Relevance: 85.0

TL;DR: 提出了一种基于概念瓶颈模型（CBM）的框架CBM-HNMU，通过自动识别和修正有害概念，提升黑盒模型的解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型因复杂性增加而导致的解释性不足问题，现有方法缺乏有效干预或仅停留在样本层面。

Method: 利用CBM作为解释性框架，通过全局梯度贡献识别和修正有害概念，并将修正后的知识蒸馏回黑盒模型。

Result: 在多个数据集和模型上测试，最高准确率提升2.64%，平均准确率提升1.03%。

Conclusion: CBM-HNMU有效提升了模型的解释性和性能，为黑盒模型的理解和优化提供了新方法。

Abstract: Recent advances in deep learning have led to increasingly complex models with
deeper layers and more parameters, reducing interpretability and making their
decisions harder to understand. While many methods explain black-box reasoning,
most lack effective interventions or only operate at sample-level without
modifying the model itself. To address this, we propose the Concept Bottleneck
Model for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU).
CBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable
framework to approximate black-box reasoning and communicate conceptual
understanding. Detrimental concepts are automatically identified and refined
(removed/replaced) based on global gradient contributions. The modified CBM
then distills corrected knowledge back into the black-box model, enhancing both
interpretability and accuracy. We evaluate CBM-HNMU on various CNN and
transformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft,
and CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum
increase in average accuracy across 1.03%. Source code is available at:
https://github.com/XiGuaBo/CBM-HNMU.

</details>


### [93] [Listener-Rewarded Thinking in VLMs for Image Preferences](https://arxiv.org/abs/2506.22832)
*Alexander Gambashidze,Li Pengyi,Matvey Skripkin,Andrey Galichin,Anton Gusarov,Konstantin Sobolev,Andrey Kuznetsov,Ivan Oseledets*

Main category: cs.CV

Relevance: 85.0

TL;DR: 论文提出了一种基于听众增强的GRPO框架，通过听众模型重新评估推理链，生成校准的置信分数，以改进奖励模型在视觉偏好任务中的泛化能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前奖励模型在泛化和监督微调中存在记忆化问题，且强化学习（如GRPO）在推理准确性上存在缺陷，尤其是在推理链与独立视觉语言模型矛盾时。

Method: 引入听众增强的GRPO框架，听众模型重新评估推理链并提供置信分数，以调整RL奖励信号，鼓励生成更具说服力的解释。

Result: 在ImageReward基准上达到67.4%的准确率，OOD性能提升6%，减少推理矛盾。

Conclusion: 听众增强的奖励机制为视觉语言模型与人类偏好对齐提供了高效、可扩展的路径。

Abstract: Training robust and generalizable reward models for human visual preferences
is essential for aligning text-to-image and text-to-video generative models
with human intent. However, current reward models often fail to generalize, and
supervised fine-tuning leads to memorization, demanding complex annotation
pipelines. While reinforcement learning (RL), specifically Group Relative
Policy Optimization (GRPO), improves generalization, we uncover a key failure
mode: a significant drop in reasoning accuracy occurs when a model's reasoning
trace contradicts that of an independent, frozen vision-language model
("listener") evaluating the same output. To address this, we introduce a
listener-augmented GRPO framework. Here, the listener re-evaluates the
reasoner's chain-of-thought to provide a dense, calibrated confidence score,
shaping the RL reward signal. This encourages the reasoner not only to answer
correctly, but to produce explanations that are persuasive to an independent
model. Our listener-shaped reward scheme achieves best accuracy on the
ImageReward benchmark (67.4%), significantly improves out-of-distribution (OOD)
performance on a large-scale human preference dataset (1.2M votes, up to +6%
over naive reasoner), and reduces reasoning contradictions compared to strong
GRPO and SFT baselines. These results demonstrate that listener-based rewards
provide a scalable, data-efficient path to aligning vision-language models with
nuanced human preferences. We will release our reasoning model here:
https://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner.

</details>


### [94] [Token Activation Map to Visually Explain Multimodal LLMs](https://arxiv.org/abs/2506.23270)
*Yi Li,Hualiang Wang,Xinpeng Ding,Haonan Wang,Xiaomeng Li*

Main category: cs.CV

Relevance: 85.0

TL;DR: 提出了一种名为Token Activation Map (TAM)的方法，用于提高多模态大语言模型(MLLMs)的可解释性，通过估计因果推理和降噪技术减少冗余激活干扰。


<details>
  <summary>Details</summary>
Motivation: MLLMs的可解释性研究不足，冗余激活干扰影响解释的可靠性。

Method: 提出TAM方法，结合估计因果推理和高斯滤波降噪，分析token间的交互。

Result: TAM在多个场景（如目标定位、视频可视化等）中显著优于现有方法。

Conclusion: TAM为MLLMs提供了高质量的可视化解释工具，支持多种应用场景。

Abstract: Multimodal large language models (MLLMs) are broadly empowering various
fields. Despite their advancements, the explainability of MLLMs remains less
explored, hindering deeper understanding, model credibility, and effective
visualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that
produce a single output, MLLMs generate sequences of tokens progressively,
where each generated token depends on the previous context. Therefore, earlier
context tokens can introduce redundant activations that interfere with the
explanation of later tokens beyond their original information. Existing studies
often overlook this issue, but our observations reveal that these redundant
correlations can significantly hurt the reliability of explanations. To address
this, we propose an estimated causal inference method to mitigate the
interference of context to achieve high-quality MLLM explanation, with a novel
rank Gaussian filter to further reduce activation noises. We term this method
Token Activation Map (TAM) to highlight the consideration of interactions
between tokens. TAM also indicates that it excels at explaining multiple tokens
of MLLM, which is different from the Class Activation Map (CAM) for a single
prediction. Our TAM method significantly outperforms existing SoTA methods,
showcasing high-quality visualization results that can be utilized for various
scenarios, such as object localization, failure case analysis, video
visualization, MLLMs visual comparison, and model understanding (e.g., color,
shape, action, location, visual reasoning, multi-turn conversation, etc). The
code is available atgithub.com/xmed-lab/TAM.

</details>


### [95] [Low-latency vision transformers via large-scale multi-head attention](https://arxiv.org/abs/2506.23832)
*Ronit D. Gross,Tal Halevi,Ella Koresh,Yarden Tzach,Ido Kanter*

Main category: cs.CV

Relevance: 85.0

TL;DR: 研究发现多头注意力（MHA）在分类任务中会出现自发对称性破坏，通过量化单节点性能（SNP）揭示了每个注意力头专注于特定标签子集。这一机制被推广到大规模MHA（LS-MHA），通过单头性能（SHP）矩阵实现，提高了分类准确性和信噪比（SNR）。研究还展示了通过卷积层替换初始Transformer块以减少延迟而不影响准确性。


<details>
  <summary>Details</summary>
Motivation: 探索多头注意力机制在分类任务中的学习行为，并推广到大规模MHA以提升性能。

Method: 通过量化单节点性能（SNP）和单头性能（SHP）矩阵，分析多头注意力的学习机制，并结合卷积层优化模型效率。

Result: 发现LS-MHA中每个SHP矩阵包含多个单元簇，显著提高分类准确性和信噪比。通过卷积层替换初始Transformer块，实现延迟降低且不影响准确性。

Conclusion: 多头注意力的自发对称性破坏机制可推广到大规模MHA，结合卷积层优化模型效率，为深度学习提供新见解。

Abstract: The emergence of spontaneous symmetry breaking among a few heads of
multi-head attention (MHA) across transformer blocks in classification tasks
was recently demonstrated through the quantification of single-nodal
performance (SNP). This finding indicates that each head focuses its attention
on a subset of labels through cooperation among its SNPs. This underlying
learning mechanism is generalized to large-scale MHA (LS-MHA) using a single
matrix value representing single-head performance (SHP), analogous to
single-filter performance in convolutional neural networks (CNNs). The results
indicate that each SHP matrix comprises multiple unit clusters such that each
label being explicitly recognized by a few heads with negligible noise. This
leads to an increased signal-to-noise ratio (SNR) along the transformer blocks,
thereby improving classification accuracy. These features give rise to several
distinct vision transformer (ViT) architectures that achieve the same accuracy
but differ in their LS-MHA structures. As a result, their soft committee yields
superior accuracy, an outcome not typically observed in CNNs which rely on
hundreds of filters. In addition, a significant reduction in latency is
achieved without affecting the accuracy by replacing the initial transformer
blocks with convolutional layers. This substitution accelerates early-stage
learning, which is then improved by subsequent transformer layers. The
extension of this learning mechanism to natural language processing tasks,
based on quantitative differences between CNNs and ViT architectures, has the
potential to yield new insights in deep learning. The findings are demonstrated
using compact convolutional transformer architectures trained on the CIFAR-100
dataset.

</details>


### [96] [Seg-R1: Segmentation Can Be Surprisingly Simple with Reinforcement Learning](https://arxiv.org/abs/2506.22624)
*Zuyao You,Zuxuan Wu*

Main category: cs.CV

Relevance: 75.0

TL;DR: Seg-R1使用强化学习增强大型多模态模型的像素级理解和推理能力，在分割任务中表现优异，并展现出强大的开放世界泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过强化学习提升大型多模态模型在像素级任务（如前景分割）中的表现，并验证纯强化学习训练的潜力。

Method: 引入Group Relative Policy Optimization (GRPO)训练策略，通过点提示和边界框提示引导SAM2生成分割掩码。

Result: 在COD10K上达到0.873 S-measure，零样本任务中表现优于全监督模型（RefCOCOg测试71.4 cIoU，ReasonSeg测试56.7 gIoU）。

Conclusion: 纯强化学习训练在像素级任务中具有潜力，且能实现开放世界泛化。

Abstract: We present Seg-R1, a preliminary exploration of using reinforcement learning
(RL) to enhance the pixel-level understanding and reasoning capabilities of
large multimodal models (LMMs). Starting with foreground segmentation tasks,
specifically camouflaged object detection (COD) and salient object detection
(SOD), our approach enables the LMM to generate point and bounding box prompts
in the next-token fashion, which are then used to guide SAM2 in producing
segmentation masks. We introduce Group Relative Policy Optimization (GRPO) into
the segmentation domain, equipping the LMM with pixel-level comprehension
through a carefully designed training strategy. Notably, Seg-R1 achieves
remarkable performance with purely RL-based training, achieving .873 S-measure
on COD10K without complex model modification. Moreover, we found that pure RL
training demonstrates strong open-world generalization. Despite being trained
solely on foreground segmentation image-mask pairs without text supervision,
Seg-R1 achieves impressive zero-shot performance on referring segmentation and
reasoning segmentation tasks, with 71.4 cIoU on RefCOCOg test and 56.7 gIoU on
ReasonSeg test, outperforming models fully supervised on these datasets.

</details>


### [97] [Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models](https://arxiv.org/abs/2506.22982)
*Atharv Mittal,Agam Pandey,Amritanshu Tiwari,Sukrit Jindal,Swadesh Swain*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文研究了大型视觉语言模型（VLMs）在对抗攻击中的脆弱性，验证了CroPA方法的跨提示迁移性，并提出了改进策略以提高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态任务中表现优异，但在对抗攻击下高度脆弱。研究旨在验证和改进CroPA方法，以增强对抗样本的迁移性和攻击效果。

Method: 1. 验证CroPA的跨提示迁移性；2. 提出新的初始化策略提高攻击成功率；3. 研究跨图像迁移性；4. 设计针对视觉编码器注意力机制的损失函数。

Result: 改进后的方法在Flamingo、BLIP-2、InstructBLIP和LLaVA等模型上验证了CroPA的有效性，并显著提升了对抗攻击的成功率。

Conclusion: 研究强调了VLMs对抗脆弱性的重要性，并提供了更鲁棒的对抗样本生成框架，对实际应用中的安全性有重要意义。

Abstract: Large Vision-Language Models (VLMs) have revolutionized computer vision,
enabling tasks such as image classification, captioning, and visual question
answering. However, they remain highly vulnerable to adversarial attacks,
particularly in scenarios where both visual and textual modalities can be
manipulated. In this study, we conduct a comprehensive reproducibility study of
"An Image is Worth 1000 Lies: Adversarial Transferability Across Prompts on
Vision-Language Models" validating the Cross-Prompt Attack (CroPA) and
confirming its superior cross-prompt transferability compared to existing
baselines. Beyond replication we propose several key improvements: (1) A novel
initialization strategy that significantly improves Attack Success Rate (ASR).
(2) Investigate cross-image transferability by learning universal
perturbations. (3) A novel loss function targeting vision encoder attention
mechanisms to improve generalization. Our evaluation across prominent VLMs --
including Flamingo, BLIP-2, and InstructBLIP as well as extended experiments on
LLaVA validates the original results and demonstrates that our improvements
consistently boost adversarial effectiveness. Our work reinforces the
importance of studying adversarial vulnerabilities in VLMs and provides a more
robust framework for generating transferable adversarial examples, with
significant implications for understanding the security of VLMs in real-world
applications.

</details>


### [98] [AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays](https://arxiv.org/abs/2506.23467)
*Chenlang Yi,Zizhan Xiong,Qi Qi,Xiyuan Wei,Girish Bathla,Ching-Long Lin,Bobak Jack Mortazavi,Tianbao Yang*

Main category: cs.CV

Relevance: 75.0

TL;DR: AdFair-CLIP通过对抗特征干预提升CLIP模型在医学图像分类中的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在医学图像分类中表现优异，但存在种族和性别等公平性问题，影响诊断结果的可靠性。

Method: 提出AdFair-CLIP框架，利用对抗特征干预抑制敏感属性，减少虚假相关性。

Result: 在胸部X光数据集上，AdFair-CLIP显著提高了公平性和诊断准确性，并在零样本和少样本场景中保持鲁棒性。

Conclusion: AdFair-CLIP为基于CLIP的医学诊断模型设定了公平性学习的新基准。

Abstract: Contrastive Language-Image Pre-training (CLIP) models have demonstrated
superior performance across various visual tasks including medical image
classification. However, fairness concerns, including demographic biases, have
received limited attention for CLIP models. This oversight leads to critical
issues, particularly those related to race and gender, resulting in disparities
in diagnostic outcomes and reduced reliability for underrepresented groups. To
address these challenges, we introduce AdFair-CLIP, a novel framework employing
adversarial feature intervention to suppress sensitive attributes, thereby
mitigating spurious correlations and improving prediction fairness. We conduct
comprehensive experiments on chest X-ray (CXR) datasets, and show that
AdFair-CLIP significantly enhances both fairness and diagnostic accuracy, while
maintaining robust generalization in zero-shot and few-shot scenarios. These
results establish new benchmarks for fairness-aware learning in CLIP-based
medical diagnostic models, particularly for CXR analysis.

</details>


### [99] [LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching](https://arxiv.org/abs/2506.23502)
*Mengxiao Tian,Xinxiao Wu,Shuo Yang*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出了一种基于LLM增强的多模态提示调优方法，赋予CLIP细粒度的动作级理解能力，通过动作三元组提示和动作状态提示，结合LLM的外部知识，提升了视觉表示的性能。


<details>
  <summary>Details</summary>
Motivation: CLIP在图像-文本匹配任务中表现出色，但缺乏对细粒度细节（如对象属性和空间关系）的理解，尤其是动作感知能力。本文旨在通过LLM增强的提示调优方法解决这一问题。

Method: 设计动作三元组提示和动作状态提示，利用LLM生成的动作相关知识，提出自适应交互模块以聚合视觉特征，建立具有区分性和动作感知的视觉表示。

Result: 在两个基准数据集上的实验证明了该方法的有效性。

Conclusion: 通过引入LLM的外部知识和多模态提示调优，成功提升了CLIP的细粒度动作理解能力。

Abstract: Driven by large-scale contrastive vision-language pre-trained models such as
CLIP, recent advancements in the image-text matching task have achieved
remarkable success in representation learning. Due to image-level
visual-language alignment, CLIP falls short in understanding fine-grained
details such as object attributes and spatial relationships between objects.
Recent efforts have attempted to compel CLIP to acquire structured visual
representations by introducing prompt learning to achieve object-level
alignment. While achieving promising results, they still lack the capability to
perceive actions, which are crucial for describing the states or relationships
between objects. Therefore, we propose to endow CLIP with fine-grained
action-level understanding by introducing an LLM-enhanced action-aware
multi-modal prompt-tuning method, incorporating the action-related external
knowledge generated by large language models (LLMs). Specifically, we design an
action triplet prompt and an action state prompt to exploit compositional
semantic knowledge and state-related causal knowledge implicitly stored in
LLMs. Subsequently, we propose an adaptive interaction module to aggregate
attentive visual features conditioned on action-aware prompted knowledge for
establishing discriminative and action-aware visual representations, which
further improves the performance. Comprehensive experimental results on two
benchmark datasets demonstrate the effectiveness of our method.

</details>


### [100] [CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2506.23590)
*Qiming Li,Zekai Ye,Xiaocheng Feng,Weihong Zhong,Libo Qin,Ruihan Chen,Baohang Li,Kui Jiang,Yaowei Wang,Ting Liu,Bing Qin*

Main category: cs.CV

Relevance: 75.0

TL;DR: 提出了一种无需训练、即插即用的幻觉缓解方法CAI，通过利用LVLMs在回答标题查询时的注意力激活模式，显著减少了视觉信息偏差问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言模型（LVLMs）在视觉信息解释中产生的对象幻觉问题，避免依赖昂贵的手动标注和训练成本。

Method: 提出Caption-sensitive Attention Intervention（CAI），利用LVLMs在回答标题查询时的注意力模式增强视觉感知能力。

Result: 在四个基准测试中，CAI以最小的额外推理成本实现了最先进的幻觉缓解性能。

Conclusion: CAI是一种高效且无需训练的幻觉缓解方法，适用于多种任务。

Abstract: Although Large Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in interpreting visual information, they frequently produce
content that deviates from visual information, leading to object hallucination.
To tackle this, recent works mostly depend on expensive manual annotations and
training cost, or significantly increase inference time. In this work, we
observe that LVLMs' attention to visual information is significantly stronger
when answering caption queries compared to non-caption queries. Inspired by
this phenomenon, we propose Caption-sensitive Attention Intervention (CAI), a
training-free, plug-and-play hallucination mitigation method that leverages the
attention activation pattern in response to caption queries to enhance LVLMs'
visual perception capability. Extensive experimental results across four
benchmarks covering both discriminative and generative tasks, demonstrate that
CAI achieves state-of-the-art (SOTA) hallucination mitigating performance only
with minimal additional inference cost.

</details>


### [101] [Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation](https://arxiv.org/abs/2506.23675)
*Patrick Glandorf,Bodo Rosenhahn*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文提出了一种名为P3B的剪枝方法，通过全局评估块级贡献来优化资源分配，显著提升了剪枝效果，尤其在迁移学习任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: Vision Transformer计算成本高，传统剪枝方法在未见数据域上表现不佳，导致资源分配不优。

Method: 提出P3B方法，基于块级相对贡献全局分配参数资源，保留关键组件并减少低影响参数。

Result: P3B在高稀疏度（70%参数减少）下仅损失0.64%准确率，在迁移学习任务中表现优异。

Conclusion: P3B是一种先进的剪枝方法，能有效平衡性能和计算成本。

Abstract: Vision Transformer have set new benchmarks in several tasks, but these models
come with the lack of high computational costs which makes them impractical for
resource limited hardware. Network pruning reduces the computational complexity
by removing less important operations while maintaining performance. However,
pruning a model on an unseen data domain, leads to a misevaluation of weight
significance, resulting in suboptimal resource assignment. In this work, we
find that task-sensitive layers initially fail to improve the feature
representation on downstream tasks, leading to performance loss for early
pruning decisions. To address this problem, we introduce Pruning by Block
Benefit (P3B), a pruning method that utilizes the relative contribution on
block level to globally assign parameter resources. P3B identifies low-impact
components to reduce parameter allocation while preserving critical ones.
Classical pruning mask optimization struggles to reactivate zero-mask-elements.
In contrast, P3B sets a layerwise keep ratio based on global performance
metrics, ensuring the reactivation of late-converging blocks. We show in
extensive experiments that P3B is a state of the art pruning method with most
noticeable gains in transfer learning tasks. Notably, P3B is able to conserve
high performance, even in high sparsity regimes of 70% parameter reduction
while only losing 0.64% in accuracy.

</details>


### [102] [Flash-VStream: Efficient Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2506.23825)
*Haoji Zhang,Yiqin Wang,Yansong Tang,Yong Liu,Jiashi Feng,Xiaojie Jin*

Main category: cs.CV

Relevance: 75.0

TL;DR: Flash-VStream是一种高效的长视频语言模型，通过设计Flash Memory模块处理长视频，显著降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长视频时效率低下且难以泛化，Flash-VStream旨在解决这一问题。

Method: 设计了包含低容量上下文记忆和高容量增强记忆的Flash Memory模块，用于聚合长上下文信息并建模信息密度分布。

Result: 在多个长视频基准测试中表现优异，推理延迟显著降低。

Conclusion: Flash-VStream在长视频处理中实现了高效和实时响应，性能领先。

Abstract: Benefiting from the advances in large language models and cross-modal
alignment, existing multimodal large language models have achieved prominent
performance in image and short video understanding. However, the understanding
of long videos is still challenging, as their long-context nature results in
significant computational and memory overhead. Most existing work treats long
videos in the same way as short videos, which is inefficient for real-world
applications and hard to generalize to even longer videos. To address these
issues, we propose Flash-VStream, an efficient video language model capable of
processing extremely long videos and responding to user queries in real time.
Particularly, we design a Flash Memory module, containing a low-capacity
context memory to aggregate long-context temporal information and model the
distribution of information density, and a high-capacity augmentation memory to
retrieve detailed spatial information based on this distribution. Compared to
existing models, Flash-VStream achieves significant reductions in inference
latency. Extensive experiments on long video benchmarks and comprehensive video
benchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstrate
the state-of-the-art performance and outstanding efficiency of our method. Code
is available at https://github.com/IVGSZ/Flash-VStream.

</details>


### [103] [A Closer Look at Conditional Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2506.23856)
*Ji Zhang,Shihan Wu,Lianli Gao,Jingkuan Song,Nicu Sebe,Heng Tao Shen*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文提出Class-adaptive Prompt Tuning (CaPT)，通过基于文本类别信息（TCI）的动态提示解决视觉语言预训练模型（VLPMs）中的Base-New Tradeoff（BNT）问题，并展示了其作为插件提升现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉图像信息（VII）的条件提示调优方法在解决BNT问题时表现不佳，甚至不如随机噪声条件提示。研究发现，基于文本类别信息（TCI）的动态提示是解决BNT问题的关键。

Method: 提出CaPT方法，通过学习基于TCI的动态提示，快速适应新类别。CaPT可作为插件提升现有无条件提示调优方法，并与DePT框架结合形成DeCaPT。

Result: 在11个数据集上的实验表明，CaPT显著提升了五种无条件提示调优基线的性能，且计算成本几乎不变。DeCaPT在平均性能上优于现有最佳条件提示调优方法3.49%。

Conclusion: CaPT和DeCaPT通过TCI条件提示有效解决了BNT问题，提升了模型在新任务上的泛化能力。

Abstract: Despite the great promise of Prompt Tuning (PT) in adapting large
Vision-Language Pretrained Models (VLPMs) to downstream tasks, they often
struggle to overcome the Base-New Tradeoff (BNT) dilemma: as VLPMs are better
tuned to a base task, their ability to generalize to new tasks diminishes.
Recent work on conditional PT addresses this problem by replacing static
prompts with dynamic Visual Image Information (VII)-conditioned prompts,
improving the model's generalization to new tasks to some extent. In this work,
we first identify a critical issue with existing conditional PT methods: using
VII as the "condition" of prompts yields suboptimal performance, and even
random noise-conditioned prompts can outperform the VII-conditioned
counterparts. On further analysis, we find that learning dynamic prompts
conditioned on Textual Class Information (TCI) is the key to solving the BNT
problem. Motivated by this, we then propose Class-adaptive Prompt Tuning
(CaPT), which enables fast adaptation of tuned models to new classes by
learning TCI-conditioned prompts from base classes. Remarkably, CaPT can be
used as a plugin to mitigate the BNT problem for existing unconditional PT
schemes. Extensive experiments on 11 datasets show that CaPT consistently
improves the performance of five strong unconditional PT baselines with
negligible additional computational cost. Additionally, by integrating CaPT
with our recently proposed DePT framework, we devise a new conditional PT
approach, termed DeCaPT, which outperforms the H ACC of the state-of-the-art
conditional PT scheme by 3.49%, averaged over the 11 datasets. Code:
https://github.com/Koorye/CaPT.

</details>


### [104] [VMoBA: Mixture-of-Block Attention for Video Diffusion Models](https://arxiv.org/abs/2506.23858)
*Jianzong Wu,Liang Hou,Haotian Yang,Xin Tao,Ye Tian,Pengfei Wan,Di Zhang,Yunhai Tong*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文提出了一种名为VMoBA的新型稀疏注意力机制，专为视频扩散模型设计，通过动态块分区和全局块选择显著提升了训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决全注意力机制在视频扩散模型中因二次复杂度导致的效率瓶颈，同时优化视频数据的时空特性捕捉。

Method: 引入VMoBA，结合层间动态块分区、全局块选择和基于阈值的块选择，优化注意力机制。

Result: VMoBA在长序列训练中实现2.92x FLOPs和1.48x延迟加速，生成质量与全注意力相当或更优。

Conclusion: VMoBA是一种高效且性能优越的稀疏注意力机制，适用于视频扩散模型。

Abstract: The quadratic complexity of full attention mechanisms poses a significant
bottleneck for Video Diffusion Models (VDMs) aiming to generate long-duration,
high-resolution videos. While various sparse attention methods have been
proposed, many are designed as training-free inference accelerators or do not
optimally capture the unique spatio-temporal characteristics inherent in video
data when trained natively. This paper introduces Video Mixture of Block
Attention (VMoBA), a novel sparse attention mechanism specifically adapted for
VDMs. Motivated by an in-depth analysis of attention patterns within
pre-trained video transformers, which revealed strong spatio-temporal locality,
varying query importance, and head-specific concentration levels, VMoBA
enhances the original MoBA framework with three key modifications: (1) a
layer-wise recurrent block partition scheme (1D-2D-3D) to dynamically adapt to
diverse spatio-temporal attention patterns and improve efficiency; (2) global
block selection to prioritize the most salient query-key block interactions
across an entire attention head; and (3) threshold-based block selection to
dynamically determine the number of attended blocks based on their cumulative
similarity. Extensive experiments demonstrate that VMoBA significantly
accelerates the training of VDMs on longer sequences, achieving 2.92x FLOPs and
1.48x latency speedup, while attaining comparable or even superior generation
quality to full attention. Furthermore, VMoBA exhibits competitive performance
in training-free inference, offering 2.40x FLOPs and 1.35x latency speedup for
high-res video generation.

</details>


### [105] [WaRA: Wavelet Low Rank Adaptation](https://arxiv.org/abs/2506.24092)
*Moein Heidari,Yasamin Medghalchi,Mahdi Khoursha,Reza Rezaeian,Ilker Hacihaliloglu*

Main category: cs.CV

Relevance: 75.0

TL;DR: 论文提出了一种名为WaRA的新型参数高效微调（PEFT）方法，利用小波变换分解权重更新矩阵，实现多分辨率分析，优于现有LoRA方法。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT技术（如LoRA）依赖全局低秩分解，忽略了局部或多尺度结构，无法捕捉权重更新中的复杂模式。

Method: WaRA通过小波变换将权重更新矩阵分解为多分辨率表示，在频域进行低秩分解并通过逆变换重构更新，从而获得更灵活的稀疏表示。

Result: 实验表明，WaRA在视觉任务（如图像生成、分类和语义分割）中表现优异，同时降低了计算复杂度，并在语言任务中展示了通用性。

Conclusion: WaRA是一种高效且通用的PEFT方法，适用于多任务场景。

Abstract: Parameter-efficient fine-tuning (PEFT) has gained widespread adoption across
various applications. Among PEFT techniques, Low-Rank Adaptation (LoRA) and its
extensions have emerged as particularly effective, allowing efficient model
adaptation while significantly reducing computational overhead. However,
existing approaches typically rely on global low-rank factorizations, which
overlook local or multi-scale structure, failing to capture complex patterns in
the weight updates. To address this, we propose WaRA, a novel PEFT method that
leverages wavelet transforms to decompose the weight update matrix into a
multi-resolution representation. By performing low-rank factorization in the
wavelet domain and reconstructing updates through an inverse transform, WaRA
obtains compressed adaptation parameters that harness multi-resolution
analysis, enabling it to capture both coarse and fine-grained features while
providing greater flexibility and sparser representations than standard LoRA.
Through comprehensive experiments and analysis, we demonstrate that WaRA
performs superior on diverse vision tasks, including image generation,
classification, and semantic segmentation, significantly enhancing generated
image quality while reducing computational complexity. Although WaRA was
primarily designed for vision tasks, we further showcase its effectiveness in
language tasks, highlighting its broader applicability and generalizability.
The code is publicly available at
\href{GitHub}{https://github.com/moeinheidari7829/WaRA}.

</details>


### [106] [Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models](https://arxiv.org/abs/2506.22500)
*Weiyi Zhao,Xiaoyu Tan,Liang Liu,Sijia Li,Youwei Song,Xihe Qiu*

Main category: cs.CV

Relevance: 70.0

TL;DR: 论文提出了一种针对多模态大语言模型（MLLMs）在手术室风险检测中视觉-语义知识冲突（VS-KC）问题的数据集和方法，通过合成图像和微调提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在手术室风险检测中因视觉-语义知识冲突导致的性能不足问题，并缓解数据稀缺性。

Method: 使用扩散模型生成34,000张合成图像和214张人工标注图像构建数据集（OR-VSKC），并通过微调MLLMs研究VS-KC。

Result: 微调显著提升了MLLMs对训练过的冲突实体的检测能力，但对未训练实体类型表现不佳。

Conclusion: 需全面训练以提升模型泛化能力，OR-VSKC数据集为研究VS-KC提供了资源。

Abstract: Surgical risk identification is critical for patient safety and reducing
preventable medical errors. While multimodal large language models (MLLMs) show
promise for automated operating room (OR) risk detection, they often exhibit
visual-semantic knowledge conflicts (VS-KC), failing to identify visual safety
violations despite understanding textual rules. To address this, we introduce a
dataset comprising over 34,000 synthetic images generated by diffusion models,
depicting operating room scenes containing entities that violate established
safety rules. These images were created to alleviate data scarcity and examine
MLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated
images that serve as a gold-standard reference for validation. This
comprehensive dataset, spanning diverse perspectives, stages, and
configurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC
significantly improves MLLMs' detection of trained conflict entities and
generalizes well to new viewpoints for these entities, but performance on
untrained entity types remains poor, highlighting learning specificity and the
need for comprehensive training. The main contributions of this work include:
(1) a data generation methodology tailored for rule-violation scenarios; (2)
the release of the OR-VSKC dataset and its associated benchmark as open-source
resources; and (3) an empirical analysis of violation-sensitive knowledge
consistency in representative MLLMs. The dataset and appendix are available at
https://github.com/zgg2577/VS-KC.

</details>


### [107] [Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation](https://arxiv.org/abs/2506.22567)
*Shansong Wang,Zhecheng Jin,Mingzhe Hu,Mojtaba Safari,Feng Zhao,Chih-Wei Chang,Richard LJ Qiu,Justin Roper,David S. Yu,Xiaofeng Yang*

Main category: cs.CV

Relevance: 70.0

TL;DR: MMKD-CLIP通过多教师知识蒸馏构建高性能生物医学基础模型，解决了生物医学领域数据稀缺和异构性问题。


<details>
  <summary>Details</summary>
Motivation: 生物医学领域缺乏大规模图像-文本对数据，且数据模态和标准不统一，阻碍了通用生物医学基础模型的开发。

Method: 采用两阶段训练：先在290万生物医学图像-文本对上预训练，再从9个教师模型中提取1920万特征对进行特征级蒸馏。

Result: 在58个生物医学数据集上评估，涵盖1080万图像和9种模态，MMKD-CLIP在6类任务中均优于教师模型。

Conclusion: 多教师知识蒸馏是构建高性能生物医学基础模型的有效方法。

Abstract: CLIP models pretrained on natural images with billion-scale image-text pairs
have demonstrated impressive capabilities in zero-shot classification,
cross-modal retrieval, and open-ended visual answering. However, transferring
this success to biomedicine is hindered by the scarcity of large-scale
biomedical image-text corpora, the heterogeneity of image modalities, and
fragmented data standards across institutions. These limitations hinder the
development of a unified and generalizable biomedical foundation model trained
from scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical
foundation model developed via Multiple Medical CLIP Knowledge Distillation.
Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledge
from nine state-of-the-art domain-specific or generalist biomedical CLIP
models, each pretrained on millions of biomedical image-text pairs. Our
two-stage training pipeline first performs CLIP-style pretraining on over 2.9
million biomedical image-text pairs from 26 image modalities, followed by
feature-level distillation using over 19.2 million feature pairs extracted from
teacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets,
encompassing over 10.8 million biomedical images across nine image modalities.
The evaluation spans six core task types: zero-shot classification, linear
probing, cross-modal retrieval, visual question answering, survival prediction,
and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models
while demonstrating remarkable robustness and generalization across image
domains and task settings. These results underscore that multi-teacher
knowledge distillation is a scalable and effective paradigm for building
high-performing biomedical foundation models under the practical constraints of
real-world data availability.

</details>


### [108] [ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models](https://arxiv.org/abs/2506.22636)
*Sotirios Panagiotis Chytas,Miso Choi,Hyunwoo J. Kim,Vikas Singh*

Main category: cs.CV

Relevance: 70.0

TL;DR: 论文提出了一种轻量级模块ReCo，用于缓解视觉语言模型（VLMs）中的幻觉问题，通过几何代数和关系组合实现，无需修改模型本身。


<details>
  <summary>Details</summary>
Motivation: VLMs在视觉和语言数据整合中表现出色，但存在幻觉问题，即生成与视觉输入无关或矛盾的文本。研究旨在控制这种行为。

Method: 在现有VLM上添加一个可训练的小模块ReCo，利用几何代数和关系组合来缓解幻觉问题。

Result: 在InstructBLIP、LlaVA和MiniGPT4等VLMs上，ReCo模块显著改善了性能，并与其他减少幻觉的方法兼容。

Conclusion: ReCo模块是一种轻量且有效的解决方案，能够缓解VLMs中的幻觉问题，且无需修改模型架构。

Abstract: Vision Language Models (VLMs) show impressive capabilities in integrating and
reasoning with both visual and language data. But these models make mistakes. A
common finding -- similar to LLMs -- is their tendency to hallucinate, i.e.,
generate plausible sounding text which is not grounded in the visual input, or
at worst, is contradictory. A growing consensus attributes this behavior to an
over-reliance on language -- especially as the generation progresses, the model
suffers from a ``fading memory effect'' with respect to the provided visual
input. We study mechanisms by which this behavior can be controlled.
Specifically, using ideas from geometric algebra and relational compositions,
we propose the addition of a small, trainable module (named ReCo) on top of any
VLM -- no other modification is needed. We show that such a lightweight module
is able to mitigate the fading memory effect on three of the most widely used
VLMs (InstructBLIP, LlaVA, MiniGPT4), where we see performance improvements on
multiple benchmarks. Additionally, we show that our module can be combined with
many of the other approaches for reducing hallucination where we achieve
improved results for each one.

</details>


### [109] [ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment](https://arxiv.org/abs/2506.22967)
*Amir Aghdam,Vincent Tao Hu*

Main category: cs.CV

Relevance: 70.0

TL;DR: ActAlign is a zero-shot framework for fine-grained video classification using sequence alignment with LLM-generated sub-action sequences and DTW, outperforming larger models.


<details>
  <summary>Details</summary>
Motivation: Address the challenge of zero-shot fine-grained video classification without temporal annotations or video examples for unseen classes.

Method: Uses LLM to generate ordered sub-action sequences, aligns them with video frames via DTW in a shared embedding space.

Result: Achieves 30.5% accuracy on ActionAtlas (human accuracy: 61.6%), outperforms larger models with 8x fewer parameters.

Conclusion: Structured language priors and classical alignment techniques can enhance vision-language models for fine-grained video understanding.

Abstract: We address the task of zero-shot fine-grained video classification, where no
video examples or temporal annotations are available for unseen action classes.
While contrastive vision-language models such as SigLIP demonstrate strong
open-set recognition via mean-pooled image-text similarity, they fail to
capture the temporal structure critical for distinguishing fine-grained
activities. We introduce ActAlign, a zero-shot framework that formulates video
classification as sequence alignment. For each class, a large language model
generates an ordered sub-action sequence, which is aligned with video frames
using Dynamic Time Warping (DTW) in a shared embedding space. Without any
video-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the
extremely challenging ActionAtlas benchmark, where human accuracy is only
61.6%. ActAlign outperforms billion-parameter video-language models while using
approximately 8x less parameters. These results demonstrate that structured
language priors, combined with classical alignment techniques, offer a scalable
and general approach to unlocking the open-set recognition potential of
vision-language models for fine-grained video understanding.

</details>


### [110] [MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings](https://arxiv.org/abs/2506.23115)
*Haonan Chen,Hong Liu,Yuping Luo,Liang Wang,Nan Yang,Furu Wei,Zhicheng Dou*

Main category: cs.CV

Relevance: 70.0

TL;DR: MoCa是一个两阶段框架，将预训练的因果视觉语言模型（VLM）转化为高效的双向多模态嵌入模型，通过模态感知的持续预训练和异构对比微调解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于因果VLM的多模态嵌入模型存在三个主要问题：因果注意力不适用于嵌入任务、依赖高质量标注数据导致扩展性差、训练目标和数据多样性不足。

Method: MoCa框架包括两个阶段：1）模态感知的持续预训练，通过联合重建目标增强双向上下文推理；2）异构对比微调，利用多样化的多模态数据提升泛化和对齐能力。

Result: MoCa在MMEB和ViDoRe-v2基准测试中表现优异，实现了新的SOTA结果，并在模型规模和训练数据上展现出强扩展性。

Conclusion: MoCa通过引入双向注意力、利用大规模无标注数据和多样化训练目标，显著提升了多模态嵌入模型的性能。

Abstract: Multimodal embedding models, built upon causal Vision Language Models (VLMs),
have shown promise in various tasks. However, current approaches face three key
limitations: the use of causal attention in VLM backbones is suboptimal for
embedding tasks; scalability issues due to reliance on high-quality labeled
paired data for contrastive learning; and limited diversity in training
objectives and data. To address these issues, we propose MoCa, a two-stage
framework for transforming pre-trained VLMs into effective bidirectional
multimodal embedding models. The first stage, Modality-aware Continual
Pre-training, introduces a joint reconstruction objective that simultaneously
denoises interleaved text and image inputs, enhancing bidirectional
context-aware reasoning. The second stage, Heterogeneous Contrastive
Fine-tuning, leverages diverse, semantically rich multimodal data beyond simple
image-caption pairs to enhance generalization and alignment. Our method
addresses the stated limitations by introducing bidirectional attention through
continual pre-training, scaling effectively with massive unlabeled datasets via
joint reconstruction objectives, and utilizing diverse multimodal data for
enhanced representation robustness. Experiments demonstrate that MoCa
consistently improves performance across MMEB and ViDoRe-v2 benchmarks,
achieving new state-of-the-art results, and exhibits strong scalability with
both model size and training data on MMEB.

</details>


### [111] [Evaluation of Geolocation Capabilities of Multimodal Large Language Models and Analysis of Associated Privacy Risks](https://arxiv.org/abs/2506.23481)
*Xian Zhang,Xiang Cheng*

Main category: cs.CV

Relevance: 70.0

TL;DR: 该研究分析了多模态大语言模型（MLLMs）在地理定位任务中的能力及其隐私风险，发现先进模型能在1公里半径内以49%的准确率定位街景图像。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs推理能力的提升，其地理定位功能可能引发隐私和伦理问题，如人肉搜索和监控。

Method: 系统综述现有地理定位技术，评估最先进视觉推理模型在街景图像定位任务中的表现。

Result: 最先进的视觉大模型在1公里半径内定位准确率达49%，展示了其从视觉数据中提取地理线索的强大能力。

Conclusion: 研究识别了成功定位的关键视觉元素（如文本、建筑风格），并讨论了技术及政策对策以减轻隐私风险。

Abstract: Objectives: The rapid advancement of Multimodal Large Language Models (MLLMs)
has significantly enhanced their reasoning capabilities, enabling a wide range
of intelligent applications. However, these advancements also raise critical
concerns regarding privacy and ethics. MLLMs are now capable of inferring the
geographic location of images -- such as those shared on social media or
captured from street views -- based solely on visual content, thereby posing
serious risks of privacy invasion, including doxxing, surveillance, and other
security threats.
  Methods: This study provides a comprehensive analysis of existing geolocation
techniques based on MLLMs. It systematically reviews relevant litera-ture and
evaluates the performance of state-of-the-art visual reasoning models on
geolocation tasks, particularly in identifying the origins of street view
imagery.
  Results: Empirical evaluation reveals that the most advanced visual large
models can successfully localize the origin of street-level imagery with up to
$49\%$ accuracy within a 1-kilometer radius. This performance underscores the
models' powerful capacity to extract and utilize fine-grained geographic cues
from visual data.
  Conclusions: Building on these findings, the study identifies key visual
elements that contribute to suc-cessful geolocation, such as text,
architectural styles, and environmental features. Furthermore, it discusses the
potential privacy implications associated with MLLM-enabled geolocation and
discuss several technical and policy-based coun-termeasures to mitigate
associated risks. Our code and dataset are available at
https://github.com/zxyl1003/MLLM-Geolocation-Evaluation.

</details>


### [112] [Pyramidal Patchification Flow for Visual Generation](https://arxiv.org/abs/2506.23543)
*Hui Li,Baoyou Chen,Liwei Zhang,Jiaye Li,Jingdong Wang,Siyu Zhu*

Main category: cs.CV

Relevance: 70.0

TL;DR: 论文提出了一种名为PPFlow的金字塔式分块方法，用于扩散变换器（DiTs），通过动态调整分块大小以优化计算成本，并在训练和推理中表现出高效性。


<details>
  <summary>Details</summary>
Motivation: 传统的扩散变换器使用固定分块大小，无法灵活适应不同噪声时间步的计算需求。PPFlow旨在通过动态分块策略提高效率和性能。

Method: PPFlow采用金字塔式分块策略，高噪声时间步使用大分块，低噪声时间步使用小分块，并为每种分块学习线性投影。此外，对Unpatchify进行了相应修改。

Result: 实验表明，PPFlow在训练和推理中均表现出高效性：从头训练时推理速度提升1.6-2.0倍，且生成性能相近；从预训练DiTs微调时性能更优。

Conclusion: PPFlow通过动态分块策略显著提升了扩散变换器的效率和性能，为高效生成模型设计提供了新思路。

Abstract: Diffusion transformers (DiTs) adopt Patchify, mapping patch representations
to token representations through linear projections, to adjust the number of
tokens input to DiT blocks and thus the computation cost. Instead of a single
patch size for all the timesteps, we introduce a Pyramidal Patchification Flow
(PPFlow) approach: Large patch sizes are used for high noise timesteps and
small patch sizes for low noise timesteps; Linear projections are learned for
each patch size; and Unpatchify is accordingly modified. Unlike Pyramidal Flow,
our approach operates over full latent representations other than pyramid
representations, and adopts the normal denoising process without requiring the
renoising trick. We demonstrate the effectiveness of our approach through two
training manners. Training from scratch achieves a $1.6\times$ ($2.0\times$)
inference speed over SiT-B/2 for 2-level (3-level) pyramid patchification with
slightly lower training FLOPs and similar image generation performance.
Training from pretrained normal DiTs achieves even better performance with
small training time. The code and checkpoint are at
https://github.com/fudan-generative-vision/PPFlow.

</details>


### [113] [Unified Multimodal Understanding via Byte-Pair Visual Encoding](https://arxiv.org/abs/2506.23639)
*Wanpeng Zhang,Yicheng Feng,Hao Luo,Yijiang Li,Zihao Yue,Sipeng Zheng,Zongqing Lu*

Main category: cs.CV

Relevance: 70.0

TL;DR: 提出了一种基于字节对编码的统一多模态理解框架，通过优先级引导的编码方案和多阶段训练，提升了视觉-语言任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型中不同模态对齐的挑战，提升视觉与文本表示的统一性。

Method: 采用字节对编码处理视觉标记，引入优先级引导的编码方案和多阶段训练流程。

Result: 在多种视觉-语言任务中表现出性能提升。

Conclusion: 该方法为更高效的多模态基础模型发展提供了贡献。

Abstract: Multimodal large language models (MLLMs) have made significant progress in
vision-language understanding, yet effectively aligning different modalities
remains a fundamental challenge. We present a framework that unifies multimodal
understanding by applying byte-pair encoding to visual tokens. Unlike
conventional approaches that rely on modality-specific encoders, our method
directly incorporates structural information into visual tokens, mirroring
successful tokenization strategies in text-only language models. We introduce a
priority-guided encoding scheme that considers both frequency and spatial
consistency, coupled with a multi-stage training procedure based on
curriculum-driven data composition. These enhancements enable the transformer
model to better capture cross-modal relationships and reason with visual
information. Comprehensive experiments demonstrate improved performance across
diverse vision-language tasks. By bridging the gap between visual and textual
representations, our approach contributes to the advancement of more capable
and efficient multimodal foundation models.

</details>


### [114] [Partial Forward Blocking: A Novel Data Pruning Paradigm for Lossless Training Acceleration](https://arxiv.org/abs/2506.23674)
*Dongyue Wu,Zilin Guo,Jialong Zuo,Nong Sang,Changxin Gao*

Main category: cs.CV

Relevance: 70.0

TL;DR: 提出了一种名为Partial Forward Blocking（PFB）的无损训练加速框架，通过浅层特征评估样本重要性并动态剪枝，显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据剪枝方法因依赖梯度或代理模型而带来的额外计算成本问题。

Method: PFB利用浅层特征评估样本重要性，动态剪枝以减少深层前向传播和反向传播的计算开销，并引入概率密度作为重要性指标。

Result: 在ImageNet上，PFB在剪除40%数据的情况下，实现了0.5%的准确率提升和33%的训练时间减少。

Conclusion: PFB在性能和速度上均表现出显著优势，为高效训练提供了新思路。

Abstract: The ever-growing size of training datasets enhances the generalization
capability of modern machine learning models but also incurs exorbitant
computational costs. Existing data pruning approaches aim to accelerate
training by removing those less important samples. However, they often rely on
gradients or proxy models, leading to prohibitive additional costs of gradient
back-propagation and proxy model training. In this paper, we propose Partial
Forward Blocking (PFB), a novel framework for lossless training acceleration.
The efficiency of PFB stems from its unique adaptive pruning pipeline: sample
importance is assessed based on features extracted from the shallow layers of
the target model. Less important samples are then pruned, allowing only the
retained ones to proceed with the subsequent forward pass and loss
back-propagation. This mechanism significantly reduces the computational
overhead of deep-layer forward passes and back-propagation for pruned samples,
while also eliminating the need for auxiliary backward computations and proxy
model training. Moreover, PFB introduces probability density as an indicator of
sample importance. Combined with an adaptive distribution estimation module,
our method dynamically prioritizes relatively rare samples, aligning with the
constantly evolving training state. Extensive experiments demonstrate the
significant superiority of PFB in performance and speed. On ImageNet, PFB
achieves a 0.5% accuracy improvement and 33% training time reduction with 40%
data pruned.

</details>


### [115] [Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers](https://arxiv.org/abs/2506.23918)
*Zhaochen Su,Peng Xia,Hangyu Guo,Zhenhua Liu,Yan Ma,Xiaoye Qu,Jiaqi Liu,Yanshu Li,Kaide Zeng,Zhengyuan Yang,Linjie Li,Yu Cheng,Heng Ji,Junxian He,Yi R.,Fung*

Main category: cs.CV

Relevance: 70.0

TL;DR: 该论文探讨了多模态推理中的新范式，即从静态视觉输入转向动态视觉思维，提出了“用图像思考”的三阶段框架，并总结了方法、评估和应用。


<details>
  <summary>Details</summary>
Motivation: 解决传统文本链式思维（CoT）中视觉信息被静态处理的问题，推动AI从“思考图像”到“用图像思考”的范式转变。

Method: 提出三阶段认知自主性框架：外部工具探索、程序化操作和内在想象，并综述了各阶段的核心方法。

Result: 建立了“用图像思考”范式的基本原则，总结了相关方法、评估基准和应用，并指出了未来研究方向。

Conclusion: 该论文为多模态AI的未来研究提供了清晰的路线图，旨在实现更强大且与人类认知对齐的AI系统。

Abstract: Recent progress in multimodal reasoning has been significantly advanced by
textual Chain-of-Thought (CoT), a paradigm where models conduct reasoning
within language. This text-centric approach, however, treats vision as a
static, initial context, creating a fundamental "semantic gap" between rich
perceptual data and discrete symbolic thought. Human cognition often transcends
language, utilizing vision as a dynamic mental sketchpad. A similar evolution
is now unfolding in AI, marking a fundamental paradigm shift from models that
merely think about images to those that can truly think with images. This
emerging paradigm is characterized by models leveraging visual information as
intermediate steps in their thought process, transforming vision from a passive
input into a dynamic, manipulable cognitive workspace. In this survey, we chart
this evolution of intelligence along a trajectory of increasing cognitive
autonomy, which unfolds across three key stages: from external tool
exploration, through programmatic manipulation, to intrinsic imagination. To
structure this rapidly evolving field, our survey makes four key contributions.
(1) We establish the foundational principles of the think with image paradigm
and its three-stage framework. (2) We provide a comprehensive review of the
core methods that characterize each stage of this roadmap. (3) We analyze the
critical landscape of evaluation benchmarks and transformative applications.
(4) We identify significant challenges and outline promising future directions.
By providing this structured overview, we aim to offer a clear roadmap for
future research towards more powerful and human-aligned multimodal AI.

</details>


### [116] [MedRegion-CT: Region-Focused Multimodal LLM for Comprehensive 3D CT Report Generation](https://arxiv.org/abs/2506.23102)
*Sunggu Kyung,Jinyoung Seo,Hyunseok Lim,Dongyeong Kim,Hyungbin Park,Jimin Sung,Jihyun Kim,Wooyoung Jo,Yoojin Nam,Namkug Kim*

Main category: eess.IV

Relevance: 70.0

TL;DR: MedRegion-CT是一个区域聚焦的多模态大语言模型框架，通过区域代表性标记池化和伪掩码生成技术，显著提升了CT报告生成的临床相关性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注全局特征，难以捕捉区域特异性细节，可能导致异常被忽略。

Method: 1. 引入区域代表性标记池化（$R^2$ Token Pooling）提取3D CT特征；2. 使用通用分割模型生成伪掩码，提取区域中心特征；3. 利用分割结果提取患者特定属性并转换为文本提示。

Result: 在RadGenome-Chest CT上实现了最先进的性能，生成报告的自然语言质量和临床相关性优于现有方法。

Conclusion: MedRegion-CT通过区域聚焦设计提升了CT报告生成的准确性和可解释性。

Abstract: The recent release of RadGenome-Chest CT has significantly advanced CT-based
report generation. However, existing methods primarily focus on global
features, making it challenging to capture region-specific details, which may
cause certain abnormalities to go unnoticed. To address this, we propose
MedRegion-CT, a region-focused Multi-Modal Large Language Model (MLLM)
framework, featuring three key innovations. First, we introduce Region
Representative ($R^2$) Token Pooling, which utilizes a 2D-wise pretrained
vision model to efficiently extract 3D CT features. This approach generates
global tokens representing overall slice features and region tokens
highlighting target areas, enabling the MLLM to process comprehensive
information effectively. Second, a universal segmentation model generates
pseudo-masks, which are then processed by a mask encoder to extract
region-centric features. This allows the MLLM to focus on clinically relevant
regions, using six predefined region masks. Third, we leverage segmentation
results to extract patient-specific attributions, including organ size,
diameter, and locations. These are converted into text prompts, enriching the
MLLM's understanding of patient-specific contexts. To ensure rigorous
evaluation, we conducted benchmark experiments on report generation using the
RadGenome-Chest CT. MedRegion-CT achieved state-of-the-art performance,
outperforming existing methods in natural language generation quality and
clinical relevance while maintaining interpretability. The code for our
framework is publicly available.

</details>


### [117] [Concept Pinpoint Eraser for Text-to-image Diffusion Models via Residual Attention Gate](https://arxiv.org/abs/2506.22806)
*Byung Hyun Lee,Sungjin Lim,Seunggyu Lee,Dong Un Kang,Se Young Chun*

Main category: cs.CV

Relevance: 65.0

TL;DR: 提出了一种名为CPE的新框架，通过非线性ResAGs选择性擦除目标概念，同时保护其他概念，并通过对抗训练增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法仅通过线性模块更新交叉注意力层无法有效保护多样剩余概念的问题。

Method: 引入非线性ResAGs和注意力锚定损失，结合对抗训练和可学习文本嵌入迭代优化。

Result: 在名人、艺术风格和敏感内容擦除任务中表现优于现有方法，且对攻击提示具有鲁棒性。

Conclusion: CPE框架有效解决了概念擦除中的保护多样性和鲁棒性问题。

Abstract: Remarkable progress in text-to-image diffusion models has brought a major
concern about potentially generating images on inappropriate or trademarked
concepts. Concept erasing has been investigated with the goals of deleting
target concepts in diffusion models while preserving other concepts with
minimal distortion. To achieve these goals, recent concept erasing methods
usually fine-tune the cross-attention layers of diffusion models. In this work,
we first show that merely updating the cross-attention layers in diffusion
models, which is mathematically equivalent to adding \emph{linear} modules to
weights, may not be able to preserve diverse remaining concepts. Then, we
propose a novel framework, dubbed Concept Pinpoint Eraser (CPE), by adding
\emph{nonlinear} Residual Attention Gates (ResAGs) that selectively erase (or
cut) target concepts while safeguarding remaining concepts from broad
distributions by employing an attention anchoring loss to prevent the
forgetting. Moreover, we adversarially train CPE with ResAG and learnable text
embeddings in an iterative manner to maximize erasing performance and enhance
robustness against adversarial attacks. Extensive experiments on the erasure of
celebrities, artistic styles, and explicit contents demonstrated that the
proposed CPE outperforms prior arts by keeping diverse remaining concepts while
deleting the target concepts with robustness against attack prompts. Code is
available at https://github.com/Hyun1A/CPE

</details>


### [118] [Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration](https://arxiv.org/abs/2506.22819)
*Ramya Hebbalaguppe,Tamoghno Kandar,Abhinav Nagpal,Chetan Arora*

Main category: cs.CV

Relevance: 65.0

TL;DR: 论文提出了一种改进视觉语言模型（VLM）在测试时提示调优（TPT）中置信度校准的方法，通过LLM初始化提示和正则化损失，显著降低了校准误差。


<details>
  <summary>Details</summary>
Motivation: TPT方法在提高准确性的同时导致置信度校准下降，限制了其在关键应用中的适用性。

Method: 1. 使用LLM初始化测试时提示以减少过拟合；2. 提出正则化损失以减少类内距离并增加类间距离。

Result: 在15个数据集和不同CLIP架构上，TCA方法的平均ECE为4.11，显著优于其他方法。

Conclusion: TCA方法有效改善了TPT后的校准性能，提升了VLM的可靠性。

Abstract: Vision-language models (VLM) have demonstrated impressive performance in
image recognition by leveraging self-supervised training on large datasets.
Their performance can be further improved by adapting to the test sample using
test-time prompt tuning (TPT). Unfortunately, the singular focus of TPT
approaches on improving the accuracy suffers from tunnel vision, and leads to
degradation in confidence calibration. This limits the applicability of TPT in
critical applications.
  We make three contributions in this work. (1) We posit that random or naive
initialization of prompts leads to overfitting on a particular test sample, and
is the main reason for miscalibration of the VLM after TPT. To mitigate the
problem, we propose careful initialization of test time prompt using prior
knowledge about the target label attributes from a large language model (LLM);
(2) To further maintain the quality of prompts during \tpt, we propose a novel
regularization loss to reduce intraclass distance, and increase inter-class
distance between the learnt
  Through extensive experiments on different CLIP architectures and 15
datasets, we show that our approach can effectively improve the calibration
after TPT. We report an average expected calibration error (ECE) of 4.11 with
our method, TCA, compared to 11.7 for vanilla TPT, 6.12 for C-TPT (ICLR'24),
6.78 for DiffTPT (CVPR'23), and 8.43 for PromptAlign (NeurIPS'23). The code is
publicly accessible at:
https://github.com/rhebbalaguppe/TCA_PromptWithoutPanic.

</details>


### [119] [RoboPearls: Editable Video Simulation for Robot Manipulation](https://arxiv.org/abs/2506.22756)
*Tao Tang,Likui Zhang,Youpeng Wen,Kaidong Zhang,Jia-Wang Bian,xia zhou,Tianyi Yan,Kun Zhan,Peng Jia,Hefeng Wu,Liang Lin,Xiaodan Liang*

Main category: cs.CV

Relevance: 60.0

TL;DR: RoboPearls是一个基于3D高斯泼溅的可编辑视频仿真框架，用于机器人操作，结合LLMs和VLMs自动化仿真过程并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作策略开发中真实数据收集成本高和仿真与现实差距的问题。

Method: 利用3D高斯泼溅构建逼真仿真，结合LLMs和VLMs自动化仿真过程，并通过ISD和3D-NNFM等模块支持多种操作。

Result: 在多个数据集和场景中验证了RoboPearls的有效性，包括RLBench、COLOSSEUM等。

Conclusion: RoboPearls通过结合先进技术和自动化工具，显著提升了机器人操作的仿真效率和性能。

Abstract: The development of generalist robot manipulation policies has seen
significant progress, driven by large-scale demonstration data across diverse
environments. However, the high cost and inefficiency of collecting real-world
demonstrations hinder the scalability of data acquisition. While existing
simulation platforms enable controlled environments for robotic learning, the
challenge of bridging the sim-to-real gap remains. To address these challenges,
we propose RoboPearls, an editable video simulation framework for robotic
manipulation. Built on 3D Gaussian Splatting (3DGS), RoboPearls enables the
construction of photo-realistic, view-consistent simulations from demonstration
videos, and supports a wide range of simulation operators, including various
object manipulations, powered by advanced modules like Incremental Semantic
Distillation (ISD) and 3D regularized NNFM Loss (3D-NNFM). Moreover, by
incorporating large language models (LLMs), RoboPearls automates the simulation
production process in a user-friendly manner through flexible command
interpretation and execution. Furthermore, RoboPearls employs a vision-language
model (VLM) to analyze robotic learning issues to close the simulation loop for
performance enhancement. To demonstrate the effectiveness of RoboPearls, we
conduct extensive experiments on multiple datasets and scenes, including
RLBench, COLOSSEUM, Ego4D, Open X-Embodiment, and a real-world robot, which
demonstrate our satisfactory simulation performance.

</details>


### [120] [MOTOR: Multimodal Optimal Transport via Grounded Retrieval in Medical Visual Question Answering](https://arxiv.org/abs/2506.22900)
*Mai A. Shaaban,Tausifa Jan Saleem,Vijay Ram Papineni,Mohammad Yaqub*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了一种名为MOTOR的多模态检索和重排序方法，通过结合文本和视觉信息提升医学视觉问答（MedVQA）的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在医学视觉问答中常生成错误答案，而传统检索增强方法可能引入无关上下文。MOTOR旨在通过多模态上下文提升检索相关性。

Method: MOTOR利用基于文本和视觉信息的检索和重排序方法，结合grounded captions和optimal transport技术。

Result: 实验表明，MOTOR在MedVQA数据集上平均准确率提升6.45%，优于现有方法。

Conclusion: MOTOR通过多模态上下文显著提升了医学视觉问答的准确性。

Abstract: Medical visual question answering (MedVQA) plays a vital role in clinical
decision-making by providing contextually rich answers to image-based queries.
Although vision-language models (VLMs) are widely used for this task, they
often generate factually incorrect answers. Retrieval-augmented generation
addresses this challenge by providing information from external sources, but
risks retrieving irrelevant context, which can degrade the reasoning
capabilities of VLMs. Re-ranking retrievals, as introduced in existing
approaches, enhances retrieval relevance by focusing on query-text alignment.
However, these approaches neglect the visual or multimodal context, which is
particularly crucial for medical diagnosis. We propose MOTOR, a novel
multimodal retrieval and re-ranking approach that leverages grounded captions
and optimal transport. It captures the underlying relationships between the
query and the retrieved context based on textual and visual information.
Consequently, our approach identifies more clinically relevant contexts to
augment the VLM input. Empirical analysis and human expert evaluation
demonstrate that MOTOR achieves higher accuracy on MedVQA datasets,
outperforming state-of-the-art methods by an average of 6.45%. Code is
available at https://github.com/BioMedIA-MBZUAI/MOTOR.

</details>


### [121] [Attention to Burstiness: Low-Rank Bilinear Prompt Tuning](https://arxiv.org/abs/2506.22908)
*Yuzhu Wang,Manni Duan,Shu Kong*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了一种名为Bilinear Prompt Tuning (BPT)的方法，通过数据白化和低秩分解优化视觉提示调优（VPT），显著提升了调优速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 视觉提示调优（VPT）中，图像块嵌入与Transformer自注意力模块的交互导致非高斯分布，影响提示学习效果。

Method: 提出数据白化和低秩分解方法，通过去相关和方差均衡化优化提示学习，并引入双线性提示调优（BPT）。

Result: BPT方法在多个基准数据集上显著优于VPT方法，提升了准确性（如CUB数据集上>25分）并减少了参数和计算开销。

Conclusion: BPT通过数据白化和低秩分解有效解决了VPT中的非高斯分布问题，提升了提示调优的性能和效率。

Abstract: Visual Prompt Tuning (VPT) is a parameter-efficient fune-tuning technique
that adapts a pre-trained vision Transformer (ViT) by learning a small set of
parameters in the input space, known as prompts. In VPT, we uncover
``burstiness'' in the values arising from the interaction of image patch
embeddings, and the key and query projectors within Transformer's
self-attention module. Furthermore, the values of patch embeddings and the key
and query projectors exhibit Laplacian and hyper-Laplacian distribution,
respectively. Intuitively, these non-Gaussian distributions pose challenges for
learning prompts. To address this, we propose whitening these data,
de-correlating them and equalizing their variance towards more Gaussian before
learning prompts. We derive the whitening matrix over random image patch
embeddings and ViT's key and query projectors, and multiply it with the prompt
to be learned in a bilinear manner. Surprisingly, this method significantly
accelerates prompt tuning and boosts accuracy, e.g., $>$25 accuracy points on
the CUB dataset; interestingly, it learns ``bursty prompts''. Extending the
bilinear model which is known to introduce burstiness, we present a compact,
low-rank version by learning two smaller matrices whose multiplication yields
the final prompts. We call the proposed methods Bilinear Prompt Tuning (BPT).
Extensive experiments across multiple benchmark datasets demonstrate that BPT
methods not only outperform various VPT methods but also reduce parameter count
and computation overhead.

</details>


### [122] [Peccavi: Visual Paraphrase Attack Safe and Distortion Free Image Watermarking Technique for AI-Generated Images](https://arxiv.org/abs/2506.22960)
*Shreyas Dixit,Ashhar Aziz,Shashwat Bajpai,Vasu Sharma,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.CV

Relevance: 60.0

TL;DR: PECCAVI是一种新型图像水印技术，针对视觉转述攻击设计，通过在多通道频域嵌入水印并保护非熔化点（NMPs）来增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI可能被用于政治虚假信息传播，现有水印技术易被篡改或绕过，亟需更安全的水印方法。

Method: PECCAVI在NMPs中嵌入水印，采用多通道频域水印技术，并结合噪声抛光以抵抗逆向工程。

Result: PECCAVI能有效抵抗视觉转述攻击，实现无失真水印嵌入，且模型无关。

Conclusion: PECCAVI为生成式AI内容的安全水印提供了可行解决方案，代码将开源。

Abstract: A report by the European Union Law Enforcement Agency predicts that by 2026,
up to 90 percent of online content could be synthetically generated, raising
concerns among policymakers, who cautioned that "Generative AI could act as a
force multiplier for political disinformation. The combined effect of
generative text, images, videos, and audio may surpass the influence of any
single modality." In response, California's Bill AB 3211 mandates the
watermarking of AI-generated images, videos, and audio. However, concerns
remain regarding the vulnerability of invisible watermarking techniques to
tampering and the potential for malicious actors to bypass them entirely.
Generative AI-powered de-watermarking attacks, especially the newly introduced
visual paraphrase attack, have shown an ability to fully remove watermarks,
resulting in a paraphrase of the original image. This paper introduces PECCAVI,
the first visual paraphrase attack-safe and distortion-free image watermarking
technique. In visual paraphrase attacks, an image is altered while preserving
its core semantic regions, termed Non-Melting Points (NMPs). PECCAVI
strategically embeds watermarks within these NMPs and employs multi-channel
frequency domain watermarking. It also incorporates noisy burnishing to counter
reverse-engineering efforts aimed at locating NMPs to disrupt the embedded
watermark, thereby enhancing durability. PECCAVI is model-agnostic. All
relevant resources and codes will be open-sourced.

</details>


### [123] [MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models](https://arxiv.org/abs/2506.23009)
*Jian Chen,Wenye Ma,Penghang Liu,Wei Wang,Tengwei Song,Ming Li,Chenguang Wang,Ruiyi Zhang,Changyou Chen*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文介绍了MusiXQA数据集，用于评估多模态大语言模型（MLLMs）在乐谱理解上的表现，并提出了Phi-3-MusiX模型，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探索MLLMs在乐谱理解方面的能力，填补现有研究空白。

Method: 使用MusiXTeX生成高质量合成乐谱数据集MusiXQA，并开发Phi-3-MusiX模型进行微调。

Result: 当前MLLMs在乐谱理解上表现有限，Phi-3-MusiX显著优于GPT类方法。

Conclusion: MusiXQA和Phi-3-MusiX为未来MLLMs在乐谱理解领域的研究奠定了基础。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable visual
reasoning abilities in natural images, text-rich documents, and graphic
designs. However, their ability to interpret music sheets remains
underexplored. To bridge this gap, we introduce MusiXQA, the first
comprehensive dataset for evaluating and advancing MLLMs in music sheet
understanding. MusiXQA features high-quality synthetic music sheets generated
via MusiXTeX, with structured annotations covering note pitch and duration,
chords, clefs, key/time signatures, and text, enabling diverse visual QA tasks.
Through extensive evaluations, we reveal significant limitations of current
state-of-the-art MLLMs in this domain. Beyond benchmarking, we developed
Phi-3-MusiX, an MLLM fine-tuned on our dataset, achieving significant
performance gains over GPT-based methods. The proposed dataset and model
establish a foundation for future advances in MLLMs for music sheet
understanding. Code, data, and model will be released upon acceptance.

</details>


### [124] [Ovis-U1 Technical Report](https://arxiv.org/abs/2506.23044)
*Guo-Hua Wang,Shanshan Zhao,Xinjie Zhang,Liangfu Cao,Pengxin Zhan,Lunhao Duan,Shiyin Lu,Minghao Fu,Xiaohao Chen,Jianshan Zhao,Yang Li,Qing-Guo Chen*

Main category: cs.CV

Relevance: 60.0

TL;DR: Ovis-U1是一个30亿参数的多模态统一模型，集成了理解、生成和编辑能力，通过统一训练方法在多项基准测试中超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 探索多模态任务的统一训练方法，提升模型在理解、生成和编辑任务中的性能。

Method: 基于语言模型，采用扩散视觉解码器和双向令牌细化器，进行统一训练。

Result: 在OpenCompass等多模态基准测试中表现优异，生成和编辑任务得分领先。

Conclusion: Ovis-U1展示了统一训练在多模态任务中的优势，为后续研究提供了新方向。

Abstract: In this report, we introduce Ovis-U1, a 3-billion-parameter unified model
that integrates multimodal understanding, text-to-image generation, and image
editing capabilities. Building on the foundation of the Ovis series, Ovis-U1
incorporates a diffusion-based visual decoder paired with a bidirectional token
refiner, enabling image generation tasks comparable to leading models like
GPT-4o. Unlike some previous models that use a frozen MLLM for generation
tasks, Ovis-U1 utilizes a new unified training approach starting from a
language model. Compared to training solely on understanding or generation
tasks, unified training yields better performance, demonstrating the
enhancement achieved by integrating these two tasks. Ovis-U1 achieves a score
of 69.6 on the OpenCompass Multi-modal Academic Benchmark, surpassing recent
state-of-the-art models such as Ristretto-3B and SAIL-VL-1.5-2B. In
text-to-image generation, it excels with scores of 83.72 and 0.89 on the
DPG-Bench and GenEval benchmarks, respectively. For image editing, it achieves
4.00 and 6.42 on the ImgEdit-Bench and GEdit-Bench-EN, respectively. As the
initial version of the Ovis unified model series, Ovis-U1 pushes the boundaries
of multimodal understanding, generation, and editing.

</details>


### [125] [UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding](https://arxiv.org/abs/2506.23219)
*Jie Feng,Shengyuan Wang,Tianhui Liu,Yanxin Xi,Yong Li*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了一种多模态大语言模型UrbanLLaVA，用于处理城市研究中的多模态数据，并通过多阶段训练框架提升性能。


<details>
  <summary>Details</summary>
Motivation: 城市研究涉及多模态数据，但现有方法缺乏统一框架。多模态大语言模型（MLLMs）的成功为解决这一问题提供了机会。

Method: 1. 构建多样化的城市指令数据集；2. 提出多阶段训练框架，分离空间推理增强和领域知识学习。

Result: UrbanLLaVA在单模态和跨模态任务中表现优于开源和专有MLLMs，并展示了跨城市的鲁棒泛化能力。

Conclusion: UrbanLLaVA为城市研究提供了一个高效的多模态处理框架，并通过实验验证了其优越性。

Abstract: Urban research involves a wide range of scenarios and tasks that require the
understanding of multi-modal data. Current methods often focus on specific data
types and lack a unified framework in urban field for processing them
comprehensively. The recent success of multi-modal large language models
(MLLMs) presents a promising opportunity to overcome this limitation. In this
paper, we introduce $\textit{UrbanLLaVA}$, a multi-modal large language model
designed to process these four types of data simultaneously and achieve strong
performance across diverse urban tasks compared with general MLLMs. In
$\textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset
encompassing both single-modal and cross-modal urban data, spanning from
location view to global view of urban environment. Additionally, we propose a
multi-stage training framework that decouples spatial reasoning enhancement
from domain knowledge learning, thereby improving the compatibility and
downstream performance of $\textit{UrbanLLaVA}$ across diverse urban tasks.
Finally, we also extend existing benchmark for urban research to assess the
performance of MLLMs across a wide range of urban tasks. Experimental results
from three cities demonstrate that $\textit{UrbanLLaVA}$ outperforms
open-source and proprietary MLLMs in both single-modal tasks and complex
cross-modal tasks and shows robust generalization abilities across cities.
Source codes and data are openly accessible to the research community via
https://github.com/tsinghua-fib-lab/UrbanLLaVA.

</details>


### [126] [Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification](https://arxiv.org/abs/2506.23247)
*James Hinns,David Martens*

Main category: cs.CV

Relevance: 60.0

TL;DR: 提出Segment Attribution Tables (SATs)方法，通过汇总局部显著性解释来提供半全局的模型解释，帮助分析图像分类器的行为。


<details>
  <summary>Details</summary>
Motivation: 深度学习在图像分类任务中表现优异，但模型预测的解释仍具挑战性。现有方法要么过于局部（如显著性图），要么过于全局化，难以捕捉重要局部行为。

Method: SATs利用图像片段（如“眼睛”）和显著性图，量化这些片段对模型预测的影响，揭示模型依赖的概念和虚假相关性。

Result: SATs能够揭示模型依赖的跨实例概念和虚假相关性（如背景或水印），即使测试性能变化不大。

Conclusion: SATs填补了过于简化的全局解释和过于详细的局部解释之间的空白，为分析和调试图像分类器提供了实用工具。

Abstract: Deep learning dominates image classification tasks, yet understanding how
models arrive at predictions remains a challenge. Much research focuses on
local explanations of individual predictions, such as saliency maps, which
visualise the influence of specific pixels on a model's prediction. However,
reviewing many of these explanations to identify recurring patterns is
infeasible, while global methods often oversimplify and miss important local
behaviours. To address this, we propose Segment Attribution Tables (SATs), a
method for summarising local saliency explanations into (semi-)global insights.
SATs take image segments (such as "eyes" in Chihuahuas) and leverage saliency
maps to quantify their influence. These segments highlight concepts the model
relies on across instances and reveal spurious correlations, such as reliance
on backgrounds or watermarks, even when out-of-distribution test performance
sees little change. SATs can explain any classifier for which a form of
saliency map can be produced, using segmentation maps that provide named
segments. SATs bridge the gap between oversimplified global summaries and
overly detailed local explanations, offering a practical tool for analysing and
debugging image classifiers.

</details>


### [127] [Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation](https://arxiv.org/abs/2506.23271)
*Jinxing Zhou,Zhihui Li,Yongqiang Yu,Yanghao Zhou,Ruohao Guo,Guangyao Li,Yuxin Mao,Mingfei Han,Xiaojun Chang,Meng Wang*

Main category: cs.CV

Relevance: 60.0

TL;DR: Mettle是一种内存高效的方法，通过并行蒸馏音频或视觉特征为紧凑的元标记，适应预训练Transformer模型到下游音频-视觉任务。


<details>
  <summary>Details</summary>
Motivation: 解决大规模预训练Transformer模型在适应下游任务时的内存和计算效率问题。

Method: 使用轻量级的Layer-Centric Distillation (LCD)模块并行蒸馏特征为元标记，并引入Meta-Token Injection (MTI)模块支持细粒度分割任务。

Result: 在多个音频-视觉基准测试中显著减少内存使用和训练时间，同时保持参数效率和竞争性准确性。

Conclusion: Mettle是一种高效且通用的方法，适用于音频-视觉任务。

Abstract: We present \textbf{Met}a-\textbf{T}oken \textbf{Le}arning (Mettle), a simple
and memory-efficient method for adapting large-scale pretrained transformer
models to downstream audio-visual tasks. Instead of sequentially modifying the
output feature distribution of the transformer backbone, Mettle utilizes a
lightweight \textit{Layer-Centric Distillation (LCD)} module to distill in
parallel the intact audio or visual features embedded by each transformer layer
into compact meta-tokens. This distillation process considers both pretrained
knowledge preservation and task-specific adaptation. The obtained meta-tokens
can be directly applied to classification tasks, such as audio-visual event
localization and audio-visual video parsing. To further support fine-grained
segmentation tasks, such as audio-visual segmentation, we introduce a
\textit{Meta-Token Injection (MTI)} module, which utilizes the audio and visual
meta-tokens distilled from the top transformer layer to guide feature
adaptation in earlier layers. Extensive experiments on multiple audiovisual
benchmarks demonstrate that our method significantly reduces memory usage and
training time while maintaining parameter efficiency and competitive accuracy.

</details>


### [128] [MotionGPT3: Human Motion as a Second Modality](https://arxiv.org/abs/2506.24086)
*Bingfan Zhu,Biao Jiang,Sunyi Wang,Shixiang Tang,Tao Chen,Linjie Luo,Youyi Zheng,Xin Chen*

Main category: cs.CV

Relevance: 60.0

TL;DR: MotionGPT3是一个双模态运动-语言模型，通过分离运动建模和保留语言智能，解决了运动与语言统一建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态模型在统一理解和生成方面表现出强大能力，但运动-语言模型的开发仍未被充分探索。需要解决运动模态与离散表示的重构差距以及统一训练中语言智能的退化问题。

Method: 提出MotionGPT3，采用专家混合方法，将运动建模与语言模型分离，通过共享注意力机制实现双模态交互。使用运动VAE编码运动，并通过扩散头预测运动潜在表示。

Result: 实验表明，模型在运动理解和生成任务上表现优异，同时保持了强大的语言能力。

Conclusion: MotionGPT3为自回归框架内的双模态运动扩散提供了统一解决方案。

Abstract: Though recent advances in multimodal models have demonstrated strong
capabilities and opportunities in unified understanding and generation, the
development of unified motion-language models remains underexplored. To enable
such models with high-fidelity human motion, two core challenges must be
addressed. The first is the reconstruction gap between the continuous motion
modality and discrete representation in an autoregressive manner, and the
second is the degradation of language intelligence during unified training.
Inspired by the mixture of experts, we propose MotionGPT3, a bimodal
motion-language model that treats human motion as a second modality, decoupling
motion modeling via separate model parameters and enabling both effective
cross-modal interaction and efficient multimodal scaling training. To preserve
language intelligence, the text branch retains the original structure and
parameters of the pretrained language model, while a new motion branch is
integrated via a shared attention mechanism, enabling bidirectional information
flow between two modalities. We first employ a motion Variational Autoencoder
(VAE) to encode raw human motion into latent representations. Based on this
continuous latent space, the motion branch predicts motion latents directly
from intermediate hidden states using a diffusion head, bypassing discrete
tokenization. Extensive experiments show that our approach achieves competitive
performance on both motion understanding and generation tasks while preserving
strong language capabilities, establishing a unified bimodal motion diffusion
framework within an autoregressive manner.

</details>


### [129] [MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition](https://arxiv.org/abs/2506.23283)
*Yuhuan Yang,Chaofan Ma,Zhenjie Mao,Jiangchao Yao,Ya Zhang,Yanfeng Wang*

Main category: cs.CV

Relevance: 60.0

TL;DR: MoMa是一个高效的适配器框架，通过将Mamba的选择性状态空间建模集成到图像基础模型（IFMs）中，实现全时空建模，提升视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 视频理解需要有效建模时空动态，现有方法多将时空信息分开处理，难以捕捉视频的复杂性。

Method: 提出SeqMod操作和Divide-and-Modulate架构，将时空信息注入预训练的IFMs，同时保持计算效率。

Result: 在多个视频基准测试中表现优异，性能提升且计算成本降低。

Conclusion: MoMa通过高效时空建模显著提升视频理解能力。

Abstract: Video understanding is a complex challenge that requires effective modeling
of spatial-temporal dynamics. With the success of image foundation models
(IFMs) in image understanding, recent approaches have explored
parameter-efficient fine-tuning (PEFT) to adapt IFMs for video. However, most
of these methods tend to process spatial and temporal information separately,
which may fail to capture the full intricacy of video dynamics. In this paper,
we propose MoMa, an efficient adapter framework that achieves full
spatial-temporal modeling by integrating Mamba's selective state space modeling
into IFMs. We propose a novel SeqMod operation to inject spatial-temporal
information into pre-trained IFMs, without disrupting their original features.
By incorporating SeqMod into a Divide-and-Modulate architecture, MoMa enhances
video understanding while maintaining computational efficiency. Extensive
experiments on multiple video benchmarks demonstrate the effectiveness of MoMa,
achieving superior performance with reduced computational cost.

</details>


### [130] [Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models](https://arxiv.org/abs/2506.23418)
*Parham Rezaei,Arash Marioriyad,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

Relevance: 60.0

TL;DR: 提出了一种基于概率优势（PoS）的框架，用于改进文本到图像模型在空间关系生成中的准确性，包括新的评估指标PSE和生成方法PSG。


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像模型在生成复杂空间关系时的对齐问题，提升生成图像的细节准确性。

Method: 1. 提出PoS框架建模对象间的相对空间位置；2. 设计PSE评估指标；3. 开发PSG生成方法，通过梯度引导或噪声向量搜索优化生成。

Result: PSE指标比传统方法更符合人类判断；PSG显著提升了空间关系生成的准确性。

Conclusion: PoS框架有效解决了文本到图像模型的空间关系对齐问题，PSE和PSG为相关研究提供了新工具。

Abstract: Despite the ability of text-to-image models to generate high-quality,
realistic, and diverse images, they face challenges in compositional
generation, often struggling to accurately represent details specified in the
input prompt. A prevalent issue in compositional generation is the misalignment
of spatial relationships, as models often fail to faithfully generate images
that reflect the spatial configurations specified between objects in the input
prompts. To address this challenge, we propose a novel probabilistic framework
for modeling the relative spatial positioning of objects in a scene, leveraging
the concept of Probability of Superiority (PoS). Building on this insight, we
make two key contributions. First, we introduce a novel evaluation metric,
PoS-based Evaluation (PSE), designed to assess the alignment of 2D and 3D
spatial relationships between text and image, with improved adherence to human
judgment. Second, we propose PoS-based Generation (PSG), an inference-time
method that improves the alignment of 2D and 3D spatial relationships in T2I
models without requiring fine-tuning. PSG employs a Part-of-Speech PoS-based
reward function that can be utilized in two distinct ways: (1) as a
gradient-based guidance mechanism applied to the cross-attention maps during
the denoising steps, or (2) as a search-based strategy that evaluates a set of
initial noise vectors to select the best one. Extensive experiments demonstrate
that the PSE metric exhibits stronger alignment with human judgment compared to
traditional center-based metrics, providing a more nuanced and reliable measure
of complex spatial relationship accuracy in text-image alignment. Furthermore,
PSG significantly enhances the ability of text-to-image models to generate
images with specified spatial configurations, outperforming state-of-the-art
methods across multiple evaluation metrics and benchmarks.

</details>


### [131] [When Test-Time Adaptation Meets Self-Supervised Models](https://arxiv.org/abs/2506.23529)
*Jisu Han,Jihee Park,Dongyoon Han,Wonjun Hwang*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了一种自监督测试时适应（TTA）协议，解决了现有TTA方法在自监督模型上表现不佳的问题，并通过协作学习框架结合对比学习和知识蒸馏提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究测试时适应（TTA）方法是否能在不依赖源预训练的情况下持续改进自监督学习（SSL）模型，以增强模型在动态环境中的适应性。

Method: 提出自监督TTA协议和协作学习框架，结合对比学习和知识蒸馏逐步优化表示。

Result: 在多种自监督模型（如DINO、MoCo、iBOT）上验证了方法的有效性，即使没有源预训练也能取得竞争性性能。

Conclusion: 自监督TTA协议和协作学习框架显著提升了自监督模型在测试时的适应能力。

Abstract: Training on test-time data enables deep learning models to adapt to dynamic
environmental changes, enhancing their practical applicability. Online
adaptation from source to target domains is promising but it remains highly
reliant on the performance of source pretrained model. In this paper, we
investigate whether test-time adaptation (TTA) methods can continuously improve
models trained via self-supervised learning (SSL) without relying on source
pretraining. We introduce a self-supervised TTA protocol after observing that
existing TTA approaches struggle when directly applied to self-supervised
models with low accuracy on the source domain. Furthermore, we propose a
collaborative learning framework that integrates SSL and TTA models, leveraging
contrastive learning and knowledge distillation for stepwise representation
refinement. We validate our method on diverse self-supervised models, including
DINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate the
effectiveness of our approach in SSL, showing that it achieves competitive
performance even without source pretraining.

</details>


### [132] [Dataset Distillation via Vision-Language Category Prototype](https://arxiv.org/abs/2506.23580)
*Yawen Zou,Guang Li,Duo Su,Zi Wang,Jun Yu,Chao Zhang*

Main category: cs.CV

Relevance: 60.0

TL;DR: 该研究将视觉语言方法引入数据集蒸馏（DD），通过文本原型蒸馏语言信息并与图像原型协作合成数据，提升了DD性能。


<details>
  <summary>Details</summary>
Motivation: 传统DD方法主要关注图像信息，忽略了语义信息，导致模型泛化能力不足。本研究旨在通过结合视觉语言方法解决这一问题。

Method: 引入文本原型（由开源大语言模型生成的描述性文本信息）与图像原型协作合成数据。

Result: 提出的方法生成逻辑一致的图像，包含目标对象，验证性能达到SOTA，并展示出强大的泛化能力。

Conclusion: 该框架扩展了DD的应用范围，适用于无文本描述的数据集，性能优于传统方法。

Abstract: Dataset distillation (DD) condenses large datasets into compact yet
informative substitutes, preserving performance comparable to the original
dataset while reducing storage, transmission costs, and computational
consumption. However, previous DD methods mainly focus on distilling
information from images, often overlooking the semantic information inherent in
the data. The disregard for context hinders the model's generalization ability,
particularly in tasks involving complex datasets, which may result in illogical
outputs or the omission of critical objects. In this study, we integrate
vision-language methods into DD by introducing text prototypes to distill
language information and collaboratively synthesize data with image prototypes,
thereby enhancing dataset distillation performance. Notably, the text
prototypes utilized in this study are derived from descriptive text information
generated by an open-source large language model. This framework demonstrates
broad applicability across datasets without pre-existing text descriptions,
expanding the potential of dataset distillation beyond traditional image-based
approaches. Compared to other methods, the proposed approach generates
logically coherent images containing target objects, achieving state-of-the-art
validation performance and demonstrating robust generalization. Source code and
generated data are available in
https://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/

</details>


### [133] [PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum](https://arxiv.org/abs/2506.23607)
*Shiqi Zhang,Sha Zhang,Jiajun Deng,Yedong Shen,Mingxiao MA,Yanyong Zhang*

Main category: cs.CV

Relevance: 60.0

TL;DR: PGOV3D提出了一种基于Partial-to-Global课程的两阶段训练框架，用于改进开放词汇3D语义分割，通过多模态大语言模型和2D分割基础模型生成标签，并在ScanNet等基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法将多视图图像仅视为传递开放词汇信息的中介，忽略了其丰富的语义内容和跨视图对应关系，限制了模型效果。

Method: 采用两阶段训练策略：1）在部分场景上预训练，利用MLLM和2D分割模型生成开放词汇标签；2）在完整场景上微调，通过伪标签桥接语义差距。

Result: 在ScanNet、ScanNet200和S3DIS基准上实现了竞争性的开放词汇3D语义分割性能。

Conclusion: PGOV3D通过Partial-to-Global课程和两阶段训练，显著提升了开放词汇3D语义分割的效果。

Abstract: Existing open-vocabulary 3D semantic segmentation methods typically supervise
3D segmentation models by merging text-aligned features (e.g., CLIP) extracted
from multi-view images onto 3D points. However, such approaches treat
multi-view images merely as intermediaries for transferring open-vocabulary
information, overlooking their rich semantic content and cross-view
correspondences, which limits model effectiveness. To address this, we propose
PGOV3D, a novel framework that introduces a Partial-to-Global curriculum for
improving open-vocabulary 3D semantic segmentation. The key innovation lies in
a two-stage training strategy. In the first stage, we pre-train the model on
partial scenes that provide dense semantic information but relatively simple
geometry. These partial point clouds are derived from multi-view RGB-D inputs
via pixel-wise depth projection. To enable open-vocabulary learning, we
leverage a multi-modal large language model (MLLM) and a 2D segmentation
foundation model to generate open-vocabulary labels for each viewpoint,
offering rich and aligned supervision. An auxiliary inter-frame consistency
module is introduced to enforce feature consistency across varying viewpoints
and enhance spatial understanding. In the second stage, we fine-tune the model
on complete scene-level point clouds, which are sparser and structurally more
complex. We aggregate the partial vocabularies associated with each scene and
generate pseudo labels using the pre-trained model, effectively bridging the
semantic gap between dense partial observations and large-scale 3D
environments. Extensive experiments on ScanNet, ScanNet200, and S3DIS
benchmarks demonstrate that PGOV3D achieves competitive performance in
open-vocabulary 3D semantic segmentation.

</details>


### [134] [On the Domain Robustness of Contrastive Vision-Language Models](https://arxiv.org/abs/2506.23663)
*Mario Koddenbrock,Rudolf Hoffmann,David Brodmann,Erik Rodner*

Main category: cs.CV

Relevance: 60.0

TL;DR: Deepbench是一个评估视觉语言模型（VLMs）领域特定鲁棒性的框架，利用LLM生成特定领域的图像损坏，无需标注数据。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，预训练基础模型在领域变化下性能下降，缺乏透明性，需要针对性评估。

Method: 利用LLM生成领域特定的图像损坏，评估多种视觉语言架构的鲁棒性。

Result: 在六个真实领域中发现鲁棒性存在显著差异，强调领域感知评估的必要性。

Conclusion: Deepbench开源，支持领域感知鲁棒性评估的进一步研究。

Abstract: In real-world vision-language applications, practitioners increasingly rely
on large, pretrained foundation models rather than custom-built solutions,
despite limited transparency regarding their training data and processes. While
these models achieve impressive performance on general benchmarks, their
effectiveness can decline notably under specialized domain shifts, such as
unique imaging conditions or environmental variations. In this work, we
introduce Deepbench, a framework designed to assess domain-specific robustness
of vision-language models (VLMs). Deepbench leverages a large language model
(LLM) to generate realistic, context-aware image corruptions tailored to
specific deployment domains without requiring labeled data. We evaluate a range
of contrastive vision-language architectures and architectural variants across
six real-world domains and observe substantial variability in robustness,
highlighting the need for targeted, domain-aware evaluation. Deepbench is
released as open-source software to support further research into domain-aware
robustness assessment.

</details>


### [135] [Single Image Test-Time Adaptation via Multi-View Co-Training](https://arxiv.org/abs/2506.23705)
*Smriti Joshi,Richard Osuala,Lidia Garrucho,Kaisar Kushibar,Dimitri Kessler,Oliver Diaz,Karim Lekadir*

Main category: cs.CV

Relevance: 60.0

TL;DR: 提出了一种基于补丁的多视图协同训练方法，用于单图像测试时适应，解决了医学影像中实时适应和数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 解决医学场景中测试时适应对大数据集的依赖问题，并充分利用医学影像的立体信息。

Method: 通过不确定性引导的自训练实现特征和预测一致性，仅需单张测试图像即可适应。

Result: 在三个公开的乳腺MRI数据集上，性能接近监督基准，平均Dice系数提升3.75%。

Conclusion: 方法有效且易于集成，适用于医学影像的实时分割任务。

Abstract: Test-time adaptation enables a trained model to adjust to a new domain during
inference, making it particularly valuable in clinical settings where such
on-the-fly adaptation is required. However, existing techniques depend on large
target domain datasets, which are often impractical and unavailable in medical
scenarios that demand per-patient, real-time inference. Moreover, current
methods commonly focus on two-dimensional images, failing to leverage the
volumetric richness of medical imaging data. Bridging this gap, we propose a
Patch-Based Multi-View Co-Training method for Single Image Test-Time
adaptation. Our method enforces feature and prediction consistency through
uncertainty-guided self-training, enabling effective volumetric segmentation in
the target domain with only a single test-time image. Validated on three
publicly available breast magnetic resonance imaging datasets for tumor
segmentation, our method achieves performance close to the upper bound
supervised benchmark while also outperforming all existing state-of-the-art
methods, on average by a Dice Similarity Coefficient of 3.75%. We publicly
share our accessible codebase, readily integrable with the popular nnUNet
framework, at https://github.com/smriti-joshi/muvi.git.

</details>


### [136] [Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model](https://arxiv.org/abs/2506.23822)
*Shiming Chen,Bowen Duan,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

Relevance: 60.0

TL;DR: LaZSL是一种局部对齐的视觉语言模型，通过最优传输实现视觉区域与属性的对齐，提升零样本学习的可解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模视觉语言模型（如CLIP）在零样本学习中缺乏可解释性，难以解释预测结果。LaZSL旨在通过局部视觉-语义对齐解决这一问题。

Method: LaZSL利用最优传输技术，将视觉区域与离散属性对齐，无需额外训练即可提供可解释的相似性。

Result: 实验表明，LaZSL在可解释性、准确性和领域泛化性方面均表现出色。

Conclusion: LaZSL为视觉语言模型的可解释性提供了一种有效解决方案，同时保持了高性能。

Abstract: Large-scale vision-language models (VLMs), such as CLIP, have achieved
remarkable success in zero-shot learning (ZSL) by leveraging large-scale
visual-text pair datasets. However, these methods often lack interpretability,
as they compute the similarity between an entire query image and the embedded
category words, making it difficult to explain their predictions. One approach
to address this issue is to develop interpretable models by integrating
language, where classifiers are built using discrete attributes, similar to
human perception. This introduces a new challenge: how to effectively align
local visual features with corresponding attributes based on pre-trained VLMs.
To tackle this, we propose LaZSL, a locally-aligned vision-language model for
interpretable ZSL. LaZSL employs local visual-semantic alignment via optimal
transport to perform interaction between visual regions and their associated
attributes, facilitating effective alignment and providing interpretable
similarity without the need for additional training. Extensive experiments
demonstrate that our method offers several advantages, including enhanced
interpretability, improved accuracy, and strong domain generalization. Codes
available at: https://github.com/shiming-chen/LaZSL.

</details>


### [137] [Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2506.23881)
*Reihaneh Zohrabi,Hosein Hasani,Mahdieh Soleymani Baghshah,Anna Rohrbach,Marcus Rohrbach,Mohammad Hossein Rohban*

Main category: cs.CV

Relevance: 60.0

TL;DR: SPROD是一种新型的原型OOD检测方法，通过优化类原型减少虚假相关性带来的偏差，无需额外数据或调参，在多种OOD数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有OOD检测方法易受虚假相关性影响的问题，提升模型的鲁棒性和可靠性。

Method: 提出SPROD，一种后处理方法，通过优化类原型来减少虚假特征的偏差，适用于多种模型和OOD检测场景。

Result: 在多个挑战性OOD数据集上，SPROD平均AUROC提升4.7%，FPR@95提升9.3%。

Conclusion: SPROD有效解决了虚假相关性对OOD检测的影响，显著提升了性能。

Abstract: Out-of-distribution (OOD) detection is crucial for ensuring the reliability
and safety of machine learning models in real-world applications, where they
frequently face data distributions unseen during training. Despite progress,
existing methods are often vulnerable to spurious correlations that mislead
models and compromise robustness. To address this, we propose SPROD, a novel
prototype-based OOD detection approach that explicitly addresses the challenge
posed by unknown spurious correlations. Our post-hoc method refines class
prototypes to mitigate bias from spurious features without additional data or
hyperparameter tuning, and is broadly applicable across diverse backbones and
OOD detection settings. We conduct a comprehensive spurious correlation OOD
detection benchmarking, comparing our method against existing approaches and
demonstrating its superior performance across challenging OOD datasets, such as
CelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced
Animals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3%
over the second best.

</details>


### [138] [A Survey on Vision-Language-Action Models for Autonomous Driving](https://arxiv.org/abs/2506.24044)
*Sicong Jiang,Zilin Huang,Kangan Qian,Ziang Luo,Tianze Zhu,Yang Zhong,Yihong Tang,Menglin Kong,Yunlong Wang,Siwen Jiao,Hao Ye,Zihao Sheng,Xin Zhao,Tuopu Wen,Zheng Fu,Sikai Chen,Kun Jiang,Diange Yang,Seongjin Choi,Lijun Sun*

Main category: cs.CV

Relevance: 60.0

TL;DR: 该论文是关于多模态大语言模型（MLLM）在自动驾驶领域的应用综述，提出了Vision-Language-Action（VLA）范式，并总结了20多种代表性模型、数据集和基准测试。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要整合视觉感知、自然语言理解和控制的单一策略，但目前研究分散且快速扩展，因此需要全面综述。

Method: 论文通过形式化架构模块、追溯模型演变、比较代表性模型，并整合数据集和基准测试。

Result: 提供了VLA4AD的全面概述，包括模型比较、数据集和挑战（如鲁棒性、实时效率和形式验证）。

Conclusion: 该综述为推进可解释且社会对齐的自动驾驶提供了简明而完整的参考。

Abstract: The rapid progress of multimodal large language models (MLLM) has paved the
way for Vision-Language-Action (VLA) paradigms, which integrate visual
perception, natural language understanding, and control within a single policy.
Researchers in autonomous driving are actively adapting these methods to the
vehicle domain. Such models promise autonomous vehicles that can interpret
high-level instructions, reason about complex traffic scenes, and make their
own decisions. However, the literature remains fragmented and is rapidly
expanding. This survey offers the first comprehensive overview of VLA for
Autonomous Driving (VLA4AD). We (i) formalize the architectural building blocks
shared across recent work, (ii) trace the evolution from early explainer to
reasoning-centric VLA models, and (iii) compare over 20 representative models
according to VLA's progress in the autonomous driving domain. We also
consolidate existing datasets and benchmarks, highlighting protocols that
jointly measure driving safety, accuracy, and explanation quality. Finally, we
detail open challenges - robustness, real-time efficiency, and formal
verification - and outline future directions of VLA4AD. This survey provides a
concise yet complete reference for advancing interpretable socially aligned
autonomous vehicles. Github repo is available at
\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.

</details>


### [139] [DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World](https://arxiv.org/abs/2506.24102)
*Xiangtai Li,Tao Zhang,Yanwei Li,Haobo Yuan,Shihao Chen,Yikang Zhou,Jiahao Meng,Yueyi Sun,Shilin Xu,Lu Qi,Tianheng Cheng,Yi Lin,Zilong Huang,Wenhao Huang,Jiashi Feng,Guang Shi*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文介绍了DenseWorld-1M，一个大规模、详细且密集的接地标注数据集，填补了现有数据集的不足，并通过三阶段标注流程和两个VLM模型提升了标注效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有标注数据集缺乏对视觉实体的详细位置和关系描述，DenseWorld-1M旨在填补这一空白。

Method: 采用三阶段标注流程（开放世界感知、详细对象标注生成、密集标注合并）和两个VLM模型（Detailed Region Caption模型和Spatial Caption Merging模型）。

Result: 实验表明DenseWorld-1M在视觉语言理解、视觉接地和区域标注生成等任务中表现优异。

Conclusion: DenseWorld-1M为社区提供了一个高质量的数据集和高效的标注方法。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate a complex understanding
of scenes, benefiting from large-scale and high-quality datasets. Most existing
caption datasets lack the ground locations and relations for visual entities.
Several grounded caption datasets face the problems of missing detailed
descriptions, relations, and massive object descriptions on high-resolution
images. To fill this gap for the community, we present DenseWorld-1M, the first
massive, detailed, dense grounded caption dataset in the real world. We design
a three-stage labeling pipeline, containing open-world perception, detailed
object caption generation, and dense caption merging. The first stage obtains
entity-level masks and labels. The second stage generates the object-level,
detailed captions with the guidance of masks and labels from the first stage.
The final stage merges object captions and masks into spatial and relational
dense captions. To accelerate the labeling process and improve caption quality,
we present two VLM models: the Detailed Region Caption model and the Spatial
Caption Merging model. Extensive experiments on various settings, including
vision-language understanding, visual grounding, and region caption generation,
demonstrate the effectiveness of our DenseWorld-1M dataset and labeling models.

</details>


### [140] [FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation](https://arxiv.org/abs/2506.24125)
*Jiacheng Cui,Xinyue Bi,Yaxin Luo,Xiaohan Zhao,Jiacheng Liu,Zhiqiang Shen*

Main category: cs.CV

Relevance: 60.0

TL;DR: 论文提出了一种名为FADRM的数据残差匹配方法，用于数据集蒸馏任务，通过数据级跳跃连接平衡新知识与原始数据信息，显著提升了计算效率和性能。


<details>
  <summary>Details</summary>
Motivation: 探索数据残差匹配在数据为中心的方法中的潜力，解决数据信息消失问题，并提升数据集蒸馏任务的效率与效果。

Method: 引入数据残差匹配概念，结合像素空间优化和原始数据模态的核心局部信息识别，并通过优化级改进提升计算效率。

Result: 在ImageNet-1K上，单模型和多模型数据集蒸馏的测试准确率分别达到47.7%和50.0%，计算效率提升50%。

Conclusion: FADRM在数据集蒸馏任务中实现了新的SOTA，显著优于现有方法。

Abstract: Residual connection has been extensively studied and widely applied at the
model architecture level. However, its potential in the more challenging
data-centric approaches remains unexplored. In this work, we introduce the
concept of Data Residual Matching for the first time, leveraging data-level
skip connections to facilitate data generation and mitigate data information
vanishing. This approach maintains a balance between newly acquired knowledge
through pixel space optimization and existing core local information
identification within raw data modalities, specifically for the dataset
distillation task. Furthermore, by incorporating optimization-level
refinements, our method significantly improves computational efficiency,
achieving superior performance while reducing training time and peak GPU memory
usage by 50%. Consequently, the proposed method Fast and Accurate Data Residual
Matching for Dataset Distillation (FADRM) establishes a new state-of-the-art,
demonstrating substantial improvements over existing methods across multiple
dataset benchmarks in both efficiency and effectiveness. For instance, with
ResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the
method achieves 47.7% test accuracy in single-model dataset distillation and
50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and
outperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4%
and +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.

</details>


### [141] [Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?](https://arxiv.org/abs/2506.23751)
*Annika Mütze,Sadia Ilyas,Christian Dörpelkus,Matthias Rottmann*

Main category: cs.CV

Relevance: 50.0

TL;DR: 论文探讨了如何通过合成数据挑战开放词汇目标检测器，并发现其系统性失败模式。


<details>
  <summary>Details</summary>
Motivation: 开放词汇目标检测器在安全关键应用中存在局限性，但真实数据难以系统评估其泛化能力。

Method: 设计两个自动化流程，使用稳定扩散生成高多样性语义的合成数据，评估多种开放词汇目标检测器。

Result: 合成数据能有效挑战检测器，发现其依赖对象位置而非语义。

Conclusion: 提供了一种系统挑战开放词汇模型的方法，并指导如何改进数据采集。

Abstract: Open-vocabulary object detectors such as Grounding DINO are trained on vast
and diverse data, achieving remarkable performance on challenging datasets. Due
to that, it is unclear where to find their limitations, which is of major
concern when using in safety-critical applications. Real-world data does not
provide sufficient control, required for a rigorous evaluation of model
generalization. In contrast, synthetically generated data allows to
systematically explore the boundaries of model competence/generalization. In
this work, we address two research questions: 1) Can we challenge
open-vocabulary object detectors with generated image content? 2) Can we find
systematic failure modes of those models? To address these questions, we design
two automated pipelines using stable diffusion to inpaint unusual objects with
high diversity in semantics, by sampling multiple substantives from WordNet and
ChatGPT. On the synthetically generated data, we evaluate and compare multiple
open-vocabulary object detectors as well as a classical object detector. The
synthetic data is derived from two real-world datasets, namely LostAndFound, a
challenging out-of-distribution (OOD) detection benchmark, and the NuImages
dataset. Our results indicate that inpainting can challenge open-vocabulary
object detectors in terms of overlooking objects. Additionally, we find a
strong dependence of open-vocabulary models on object location, rather than on
object semantics. This provides a systematic approach to challenge
open-vocabulary models and gives valuable insights on how data could be
acquired to effectively improve these models.

</details>


### [142] [Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization](https://arxiv.org/abs/2506.22463)
*Weizhi Gao,Zhichao Hou,Junqi Yin,Feiyi Wang,Linyu Peng,Xiaorui Liu*

Main category: cs.CV

Relevance: 40.0

TL;DR: MoDiff是一种创新的扩散模型加速框架，通过调制量化和误差补偿提高生成效率，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的计算成本高，现有加速技术存在计算误差和生成质量的限制。

Method: 提出MoDiff框架，结合调制量化和误差补偿，优化扩散模型的推理效率。

Result: 在CIFAR-10和LSUN数据集上，MoDiff将激活量化从8位降至3位且性能无损。

Conclusion: MoDiff为扩散模型提供了一种高效且通用的加速解决方案。

Abstract: Diffusion models have emerged as powerful generative models, but their high
computation cost in iterative sampling remains a significant bottleneck. In
this work, we present an in-depth and insightful study of state-of-the-art
acceleration techniques for diffusion models, including caching and
quantization, revealing their limitations in computation error and generation
quality. To break these limits, this work introduces Modulated Diffusion
(MoDiff), an innovative, rigorous, and principled framework that accelerates
generative modeling through modulated quantization and error compensation.
MoDiff not only inherents the advantages of existing caching and quantization
methods but also serves as a general framework to accelerate all diffusion
models. The advantages of MoDiff are supported by solid theoretical insight and
analysis. In addition, extensive experiments on CIFAR-10 and LSUN demonstrate
that MoDiff significant reduces activation quantization from 8 bits to 3 bits
without performance degradation in post-training quantization (PTQ). Our code
implementation is available at https://github.com/WeizhiGao/MoDiff.

</details>


### [143] [How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?](https://arxiv.org/abs/2506.22501)
*Gautam Siddharth Kashyap,Manaswi Kulahara,Nipun Joshi,Usman Naseem*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种名为SpatialNet-ViT的新模型，结合Vision Transformers和多任务学习，用于遥感分类任务，提高了准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多局限于特定任务或数据集，难以泛化到多样化的遥感分类任务中。

Method: 采用Vision Transformers和多任务学习，结合数据增强、迁移学习等技术。

Result: 模型在分类准确性和泛化能力上有所提升。

Conclusion: SpatialNet-ViT为遥感分类任务提供了一种有效的解决方案。

Abstract: Remote sensing datasets offer significant promise for tackling key
classification tasks such as land-use categorization, object presence
detection, and rural/urban classification. However, many existing studies tend
to focus on narrow tasks or datasets, which limits their ability to generalize
across various remote sensing classification challenges. To overcome this, we
propose a novel model, SpatialNet-ViT, leveraging the power of Vision
Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach
combines spatial awareness with contextual understanding, improving both
classification accuracy and scalability. Additionally, techniques like data
augmentation, transfer learning, and multi-task learning are employed to
enhance model robustness and its ability to generalize across diverse datasets

</details>


### [144] [Weakly Supervised Object Segmentation by Background Conditional Divergence](https://arxiv.org/abs/2506.22505)
*Hassan Baker,Matthew S. Emigh,Austin J. Brockmeier*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种利用弱监督（图像级标签）训练二值对象分割网络的方法，通过生成反事实背景图像提升性能，并在多个领域验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 解决在缺乏大量标注数据的专业图像领域（如声纳、遥感、生物医学）中进行对象分割的挑战。

Method: 利用图像级标签训练分割网络，生成反事实背景图像，并通过样本差异和监督损失优化模型。

Result: 在声纳和自然图像上优于无监督基线方法，且无需预训练网络或对抗性判别器。

Conclusion: 该方法在弱监督下实现了有效的对象分割，具有跨领域的通用性。

Abstract: As a computer vision task, automatic object segmentation remains challenging
in specialized image domains without massive labeled data, such as synthetic
aperture sonar images, remote sensing, biomedical imaging, etc. In any domain,
obtaining pixel-wise segmentation masks is expensive. In this work, we propose
a method for training a masking network to perform binary object segmentation
using weak supervision in the form of image-wise presence or absence of an
object of interest, which provides less information but may be obtained more
quickly from manual or automatic labeling. A key step in our method is that the
segmented objects can be placed into background-only images to create
realistic, images of the objects with counterfactual backgrounds. To create a
contrast between the original and counterfactual background images, we propose
to first cluster the background-only images, and then during learning create
counterfactual images that blend objects segmented from their original source
backgrounds to backgrounds chosen from a targeted cluster. One term in the
training loss is the divergence between these counterfactual images and the
real object images with backgrounds of the target cluster. The other term is a
supervised loss for background-only images. While an adversarial critic could
provide the divergence, we use sample-based divergences. We conduct experiments
on side-scan and synthetic aperture sonar in which our approach succeeds
compared to previous unsupervised segmentation baselines that were only tested
on natural images. Furthermore, to show generality we extend our experiments to
natural images, obtaining reasonable performance with our method that avoids
pretrained networks, generative networks, and adversarial critics. The basecode
for this work can be found at
\href{GitHub}{https://github.com/bakerhassan/WSOS}.

</details>


### [145] [FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment](https://arxiv.org/abs/2506.22509)
*Hang Xu,Jie Huang,Linjiang Huang,Dong Li,Yidi Liu,Feng Zhao*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种无需训练的领域适应方法（DNA），用于扩散密集预测模型，通过调整噪声统计实现跨域适应。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在密集预测任务中存在噪声统计偏差导致的领域偏移问题，需针对性解决。

Method: 提出Domain Noise Alignment (DNA)方法，通过对齐噪声统计实现领域适应，支持有源和无源场景。

Result: 在四种密集预测任务中验证了DNA的有效性。

Conclusion: DNA是一种高效且无需训练的领域适应方法，适用于扩散密集预测模型。

Abstract: Domain Adaptation(DA) for dense prediction tasks is an important topic, which
enhances the dense prediction model's performance when tested on its unseen
domain. Recently, with the development of Diffusion-based Dense Prediction
(DDP) models, the exploration of DA designs tailored to this framework is worth
exploring, since the diffusion model is effective in modeling the distribution
transformation that comprises domain information. In this work, we propose a
training-free mechanism for DDP frameworks, endowing them with DA capabilities.
Our motivation arises from the observation that the exposure bias (e.g., noise
statistics bias) in diffusion brings domain shift, and different domains in
conditions of DDP models can also be effectively captured by the noise
prediction statistics. Based on this, we propose a training-free Domain Noise
Alignment (DNA) approach, which alleviates the variations of noise statistics
to domain changes during the diffusion sampling process, thereby achieving
domain adaptation. Specifically, when the source domain is available, we
directly adopt the DNA method to achieve domain adaptation by aligning the
noise statistics of the target domain with those of the source domain. For the
more challenging source-free DA, inspired by the observation that regions
closer to the source domain exhibit higher confidence meeting variations of
sampling noise, we utilize the statistics from the high-confidence regions
progressively to guide the noise statistic adjustment during the sampling
process. Notably, our method demonstrates the effectiveness of enhancing the DA
capability of DDP models across four common dense prediction tasks. Code is
available at
\href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.

</details>


### [146] [Preserve Anything: Controllable Image Synthesis with Object Preservation](https://arxiv.org/abs/2506.22531)
*Prasen Kumar Sharma,Neeraj Matiyali,Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种名为“Preserve Anything”的新方法，用于改进文本到图像生成中的对象保存和语义一致性，通过N通道ControlNet实现多对象保存、语义对齐和场景控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多对象保存、语义对齐和场景控制方面存在不足，需要一种更高效的方法来提升生成图像的质量和可控性。

Method: 采用N通道ControlNet，结合对象保存模块、背景引导模块和高频覆盖模块，确保细节保留和语义一致性。

Result: 在特征空间保真度（FID 15.26）和语义对齐（CLIP-S 32.85）上达到最优性能，用户研究显示在未见数据上显著优于现有方法。

Conclusion: 该方法显著提升了文本到图像生成的质量和可控性，填补了现有技术的空白。

Abstract: We introduce \textit{Preserve Anything}, a novel method for controlled image
synthesis that addresses key limitations in object preservation and semantic
consistency in text-to-image (T2I) generation. Existing approaches often fail
(i) to preserve multiple objects with fidelity, (ii) maintain semantic
alignment with prompts, or (iii) provide explicit control over scene
composition. To overcome these challenges, the proposed method employs an
N-channel ControlNet that integrates (i) object preservation with size and
placement agnosticism, color and detail retention, and artifact elimination,
(ii) high-resolution, semantically consistent backgrounds with accurate
shadows, lighting, and prompt adherence, and (iii) explicit user control over
background layouts and lighting conditions. Key components of our framework
include object preservation and background guidance modules, enforcing lighting
consistency and a high-frequency overlay module to retain fine details while
mitigating unwanted artifacts. We introduce a benchmark dataset consisting of
240K natural images filtered for aesthetic quality and 18K 3D-rendered
synthetic images with metadata such as lighting, camera angles, and object
relationships. This dataset addresses the deficiencies of existing benchmarks
and allows a complete evaluation. Empirical results demonstrate that our method
achieves state-of-the-art performance, significantly improving feature-space
fidelity (FID 15.26) and semantic alignment (CLIP-S 32.85) while maintaining
competitive aesthetic quality. We also conducted a user study to demonstrate
the efficacy of the proposed work on unseen benchmark and observed a remarkable
improvement of $\sim25\%$, $\sim19\%$, $\sim13\%$, and $\sim14\%$ in terms of
prompt alignment, photorealism, the presence of AI artifacts, and natural
aesthetics over existing works.

</details>


### [147] [Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset](https://arxiv.org/abs/2506.22554)
*Vasu Agrawal,Akinniyi Akinyemi,Kathryn Alvero,Morteza Behrooz,Julia Buffalini,Fabio Maria Carlucci,Joy Chen,Junming Chen,Zhang Chen,Shiyang Cheng,Praveen Chowdary,Joe Chuang,Antony D'Avirro,Jon Daly,Ning Dong,Mark Duppenthaler,Cynthia Gao,Jeff Girard,Martin Gleize,Sahir Gomez,Hongyu Gong,Srivathsan Govindarajan,Brandon Han,Sen He,Denise Hernandez,Yordan Hristov,Rongjie Huang,Hirofumi Inaguma,Somya Jain,Raj Janardhan,Qingyao Jia,Christopher Klaiber,Dejan Kovachev,Moneish Kumar,Hang Li,Yilei Li,Pavel Litvin,Wei Liu,Guangyao Ma,Jing Ma,Martin Ma,Xutai Ma,Lucas Mantovani,Sagar Miglani,Sreyas Mohan,Louis-Philippe Morency,Evonne Ng,Kam-Woh Ng,Tu Anh Nguyen,Amia Oberai,Benjamin Peloquin,Juan Pino,Jovan Popovic,Omid Poursaeed,Fabian Prada,Alice Rakotoarison,Alexander Richard,Christophe Ropers,Safiyyah Saleem,Vasu Sharma,Alex Shcherbyna,Jia Shen,Jie Shen,Anastasis Stathopoulos,Anna Sun,Paden Tomasello,Tuan Tran,Arina Turkatenko,Bo Wan,Chao Wang,Jeff Wang,Mary Williamson,Carleigh Wood,Tao Xiang,Yilin Yang,Julien Yao,Chen Zhang,Jiemin Zhang,Xinyue Zhang,Jason Zheng,Pavlo Zhyzheria,Jan Zikes,Michael Zollhoefer*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文介绍了Seamless Interaction Dataset，用于开发能理解和生成双向行为动态的AI模型，并结合LLM和渲染方法开发了虚拟代理。


<details>
  <summary>Details</summary>
Motivation: 开发社交智能AI技术需要理解双向行为动态，以推动虚拟代理和多模态内容分析工具的发展。

Method: 利用大规模数据集（4000小时面对面互动）训练模型，生成与人类语音对齐的肢体动作和面部表情，并结合LLM和2D/3D渲染方法。

Result: 开发了可控的模型变体，能调整情感响应和表达水平，并生成语义相关的手势。

Conclusion: 这些模型展示了更直观和响应式的人机交互潜力。

Abstract: Human communication involves a complex interplay of verbal and nonverbal
signals, essential for conveying meaning and achieving interpersonal goals. To
develop socially intelligent AI technologies, it is crucial to develop models
that can both comprehend and generate dyadic behavioral dynamics. To this end,
we introduce the Seamless Interaction Dataset, a large-scale collection of over
4,000 hours of face-to-face interaction footage from over 4,000 participants in
diverse contexts. This dataset enables the development of AI technologies that
understand dyadic embodied dynamics, unlocking breakthroughs in virtual agents,
telepresence experiences, and multimodal content analysis tools. We also
develop a suite of models that utilize the dataset to generate dyadic motion
gestures and facial expressions aligned with human speech. These models can
take as input both the speech and visual behavior of their interlocutors. We
present a variant with speech from an LLM model and integrations with 2D and 3D
rendering methods, bringing us closer to interactive virtual agents.
Additionally, we describe controllable variants of our motion models that can
adapt emotional responses and expressivity levels, as well as generating more
semantically-relevant gestures. Finally, we discuss methods for assessing the
quality of these dyadic motion models, which are demonstrating the potential
for more intuitive and responsive human-AI interactions.

</details>


### [148] [BrainMT: A Hybrid Mamba-Transformer Architecture for Modeling Long-Range Dependencies in Functional MRI Data](https://arxiv.org/abs/2506.22591)
*Arunkumar Kannan,Martin A. Lindquist,Brian Caffo*

Main category: cs.CV

Relevance: 40.0

TL;DR: BrainMT是一种新型混合框架，结合Mamba块和Transformer块，高效捕捉fMRI数据中的长程时空依赖关系，在分类和回归任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CNN或Transformer）难以建模fMRI数据中的复杂关系，尤其是长程时空依赖。

Method: 两阶段框架：1) 双向Mamba块捕获全局时间交互；2) Transformer块建模空间关系。

Result: 在UKBioBank和Human Connectome Project数据集上，BrainMT在分类和回归任务中均显著优于现有方法。

Conclusion: BrainMT通过结合Mamba和Transformer的优势，为fMRI数据分析提供了高效且强大的解决方案。

Abstract: Recent advances in deep learning have made it possible to predict phenotypic
measures directly from functional magnetic resonance imaging (fMRI) brain
volumes, sparking significant interest in the neuroimaging community. However,
existing approaches, primarily based on convolutional neural networks or
transformer architectures, often struggle to model the complex relationships
inherent in fMRI data, limited by their inability to capture long-range spatial
and temporal dependencies. To overcome these shortcomings, we introduce
BrainMT, a novel hybrid framework designed to efficiently learn and integrate
long-range spatiotemporal attributes in fMRI data. Our framework operates in
two stages: (1) a bidirectional Mamba block with a temporal-first scanning
mechanism to capture global temporal interactions in a computationally
efficient manner; and (2) a transformer block leveraging self-attention to
model global spatial relationships across the deep features processed by the
Mamba block. Extensive experiments on two large-scale public datasets,
UKBioBank and the Human Connectome Project, demonstrate that BrainMT achieves
state-of-the-art performance on both classification (sex prediction) and
regression (cognitive intelligence prediction) tasks, outperforming existing
methods by a significant margin. Our code and implementation details will be
made publicly available at this
https://github.com/arunkumar-kannan/BrainMT-fMRI

</details>


### [149] [CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation](https://arxiv.org/abs/2506.22637)
*Haoxuan Wang,Zhenghao Zhao,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为CaO$_2$的两阶段扩散框架，解决了当前基于扩散的数据集蒸馏方法中的目标不一致和条件不一致问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的数据集蒸馏方法在评估过程中存在目标不一致和条件不一致的问题，影响了蒸馏效果。

Method: 提出Condition-aware Optimization with Objective-guided Sampling (CaO$_2$)，一个两阶段框架：第一阶段使用概率信息样本选择管道，第二阶段优化潜在表示以提高条件似然。

Result: 在ImageNet及其子集上实现了最先进的性能，平均准确率超过基线2.3%。

Conclusion: CaO$_2$通过解决不一致问题，显著提升了数据集蒸馏的效果。

Abstract: The recent introduction of diffusion models in dataset distillation has shown
promising potential in creating compact surrogate datasets for large,
high-resolution target datasets, offering improved efficiency and performance
over traditional bi-level/uni-level optimization methods. However, current
diffusion-based dataset distillation approaches overlook the evaluation process
and exhibit two critical inconsistencies in the distillation process: (1)
Objective Inconsistency, where the distillation process diverges from the
evaluation objective, and (2) Condition Inconsistency, leading to mismatches
between generated images and their corresponding conditions. To resolve these
issues, we introduce Condition-aware Optimization with Objective-guided
Sampling (CaO$_2$), a two-stage diffusion-based framework that aligns the
distillation process with the evaluation objective. The first stage employs a
probability-informed sample selection pipeline, while the second stage refines
the corresponding latent representations to improve conditional likelihood.
CaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets,
surpassing the best-performing baselines by an average of 2.3% accuracy.

</details>


### [150] [UniFuse: A Unified All-in-One Framework for Multi-Modal Medical Image Fusion Under Diverse Degradations and Misalignments](https://arxiv.org/abs/2506.22736)
*Dayong Su,Yafei Zhang,Huafeng Li,Jinxing Li,Yu Liu*

Main category: cs.CV

Relevance: 40.0

TL;DR: UniFuse是一个多模态医学图像融合框架，通过嵌入退化感知提示学习模块和Omni Unified Feature Representation方案，实现了对齐、恢复和融合的联合优化。


<details>
  <summary>Details</summary>
Motivation: 当前多模态医学图像融合方法假设源图像质量高且像素级对齐，但在处理未对齐或退化图像时效果不佳。UniFuse旨在解决这一问题。

Method: UniFuse结合了退化感知提示学习模块、Omni Unified Feature Representation方案（使用Spatial Mamba编码多方向特征）和Universal Feature Restoration & Fusion模块（基于LoRA的ALSN）。

Result: 实验结果表明，UniFuse在多个数据集上优于现有方法，实现了对齐、恢复和融合的统一。

Conclusion: UniFuse通过联合优化对齐、恢复和融合任务，显著提升了多模态医学图像融合的效果。

Abstract: Current multimodal medical image fusion typically assumes that source images
are of high quality and perfectly aligned at the pixel level. Its effectiveness
heavily relies on these conditions and often deteriorates when handling
misaligned or degraded medical images. To address this, we propose UniFuse, a
general fusion framework. By embedding a degradation-aware prompt learning
module, UniFuse seamlessly integrates multi-directional information from input
images and correlates cross-modal alignment with restoration, enabling joint
optimization of both tasks within a unified framework. Additionally, we design
an Omni Unified Feature Representation scheme, which leverages Spatial Mamba to
encode multi-directional features and mitigate modality differences in feature
alignment. To enable simultaneous restoration and fusion within an All-in-One
configuration, we propose a Universal Feature Restoration & Fusion module,
incorporating the Adaptive LoRA Synergistic Network (ALSN) based on LoRA
principles. By leveraging ALSN's adaptive feature representation along with
degradation-type guidance, we enable joint restoration and fusion within a
single-stage framework. Compared to staged approaches, UniFuse unifies
alignment, restoration, and fusion within a single framework. Experimental
results across multiple datasets demonstrate the method's effectiveness and
significant advantages over existing approaches.

</details>


### [151] [VSRM: A Robust Mamba-Based Framework for Video Super-Resolution](https://arxiv.org/abs/2506.22762)
*Dinh Phu Tran,Dao Duy Hung,Daeyoung Kim*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种基于Mamba的视频超分辨率框架VSRM，通过引入时空Mamba块和可变形交叉Mamba对齐模块，高效提取长程时空特征并增强感受野，同时提出频率损失函数提升视觉质量。


<details>
  <summary>Details</summary>
Motivation: 视频超分辨率任务中，CNN和Transformer分别受限于局部感受野和二次复杂度，而Mamba因其长序列建模能力和线性复杂度成为潜在解决方案。

Method: VSRM结合时空Mamba块和可变形交叉Mamba对齐模块，动态对齐相邻帧并高效提取特征，同时提出频率损失函数优化重建质量。

Result: VSRM在多个基准测试中达到最先进性能，为未来研究奠定基础。

Conclusion: VSRM展示了Mamba在视频超分辨率任务中的潜力，为长序列建模提供了高效解决方案。

Abstract: Video super-resolution remains a major challenge in low-level vision tasks.
To date, CNN- and Transformer-based methods have delivered impressive results.
However, CNNs are limited by local receptive fields, while Transformers
struggle with quadratic complexity, posing challenges for processing long
sequences in VSR. Recently, Mamba has drawn attention for its long-sequence
modeling, linear complexity, and large receptive fields. In this work, we
propose VSRM, a novel \textbf{V}ideo \textbf{S}uper-\textbf{R}esolution
framework that leverages the power of \textbf{M}amba. VSRM introduces
Spatial-to-Temporal Mamba and Temporal-to-Spatial Mamba blocks to extract
long-range spatio-temporal features and enhance receptive fields efficiently.
To better align adjacent frames, we propose Deformable Cross-Mamba Alignment
module. This module utilizes a deformable cross-mamba mechanism to make the
compensation stage more dynamic and flexible, preventing feature distortions.
Finally, we minimize the frequency domain gaps between reconstructed and
ground-truth frames by proposing a simple yet effective Frequency
Charbonnier-like loss that better preserves high-frequency content and enhances
visual quality. Through extensive experiments, VSRM achieves state-of-the-art
results on diverse benchmarks, establishing itself as a solid foundation for
future research.

</details>


### [152] [Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding](https://arxiv.org/abs/2506.22817)
*Xingyilang Yin,Jiale Wang,Xi Yang,Mutian Xu,Xu Gu,Nannan Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: MVOV3D提出了一种新方法，通过减少2D多视图融合中的固有噪声，提升开放词汇3D场景理解能力，无需训练即可保留泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在有限词汇量的基准测试中表现良好，但难以处理多样化的对象类别，且3D数据量限制了开放词汇模型的训练。2D多视图融合方法虽能理解多样概念，但视觉语言模型的固有噪声影响了性能。

Method: MVOV3D利用CLIP编码器提取精确的区域级图像和文本特征，并结合3D几何先验优化多视图融合，以减少噪声并提升性能。

Result: MVOV3D在ScanNet200和Matterport160数据集上分别实现了14.7%和16.2%的mIoU，显著优于当前领先的3D网络。

Conclusion: MVOV3D通过优化多视图融合，显著提升了开放词汇3D场景理解的性能，且无需额外训练。

Abstract: Recent open-vocabulary 3D scene understanding approaches mainly focus on
training 3D networks through contrastive learning with point-text pairs or by
distilling 2D features into 3D models via point-pixel alignment. While these
methods show considerable performance in benchmarks with limited vocabularies,
they struggle to handle diverse object categories as the limited amount of 3D
data upbound training strong open-vocabulary 3d models. We observe that 2D
multi-view fusion methods take precedence in understanding diverse concepts in
3D scenes. However, inherent noises in vision-language models lead multi-view
fusion to sub-optimal performance. To this end, we introduce MVOV3D, a novel
approach aimed at unleashing the potential of 2D multi-view fusion for
open-vocabulary 3D scene understanding. We focus on reducing the inherent
noises without training, thereby preserving the generalizability while
enhancing open-world capabilities. Specifically, MVOV3D improves multi-view 2D
features by leveraging precise region-level image features and text features
encoded by CLIP encoders and incorporates 3D geometric priors to optimize
multi-view fusion. Extensive experiments on various datasets demonstrate the
effectiveness of our method. Notably, our MVOV3D achieves a new record with
14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160 for challenge
open-vocabulary semantic segmentation, outperforming current leading trained 3D
networks by a significant margin.

</details>


### [153] [FOCUS: Fine-grained Optimization with Semantic Guided Understanding for Pedestrian Attributes Recognition](https://arxiv.org/abs/2506.22836)
*Hongyan An,Kuan Zhu,Xin He,Haiyun Guo,Chaoyang Zhao,Ming Tang,Jinqiao Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种名为FOCUS的方法，用于行人属性识别（PAR），通过自适应提取细粒度属性级特征，解决了现有方法在泛化和性能上的限制。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常提取区域特征来预测预定义的属性，但这种方法可能牺牲某些属性的独特模式，且无法泛化到未见过的属性。

Method: FOCUS方法结合了多粒度混合令牌（MGMT）和属性引导的视觉特征提取（AVFE）模块，通过跨注意力机制和区域感知对比学习（RACL）优化特征提取。

Result: 在PA100K、PETA和RAPv1数据集上的实验表明，该方法具有高效性和强泛化能力。

Conclusion: FOCUS方法通过细粒度优化和语义引导，显著提升了行人属性识别的性能。

Abstract: Pedestrian attribute recognition (PAR) is a fundamental perception task in
intelligent transportation and security. To tackle this fine-grained task, most
existing methods focus on extracting regional features to enrich attribute
information. However, a regional feature is typically used to predict a fixed
set of pre-defined attributes in these methods, which limits the performance
and practicality in two aspects: 1) Regional features may compromise
fine-grained patterns unique to certain attributes in favor of capturing common
characteristics shared across attributes. 2) Regional features cannot
generalize to predict unseen attributes in the test time. In this paper, we
propose the \textbf{F}ine-grained \textbf{O}ptimization with semanti\textbf{C}
g\textbf{U}ided under\textbf{S}tanding (FOCUS) approach for PAR, which
adaptively extracts fine-grained attribute-level features for each attribute
individually, regardless of whether the attributes are seen or not during
training. Specifically, we propose the Multi-Granularity Mix Tokens (MGMT) to
capture latent features at varying levels of visual granularity, thereby
enriching the diversity of the extracted information. Next, we introduce the
Attribute-guided Visual Feature Extraction (AVFE) module, which leverages
textual attributes as queries to retrieve their corresponding visual attribute
features from the Mix Tokens using a cross-attention mechanism. To ensure that
textual attributes focus on the appropriate Mix Tokens, we further incorporate
a Region-Aware Contrastive Learning (RACL) method, encouraging attributes
within the same region to share consistent attention maps. Extensive
experiments on PA100K, PETA, and RAPv1 datasets demonstrate the effectiveness
and strong generalization ability of our method.

</details>


### [154] [Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval](https://arxiv.org/abs/2506.22864)
*Li-Cheng Shen,Jih-Kang Hsieh,Wei-Hua Li,Chu-Song Chen*

Main category: cs.CV

Relevance: 40.0

TL;DR: MaTIR任务结合了文本到图像检索（TIR）和指代表达分割（RES），提出了一种两阶段框架，利用SAM 2和Alpha-CLIP进行高效检索，并通过MLLM优化结果。


<details>
  <summary>Details</summary>
Motivation: 现有TIR方法基于全图描述且缺乏可解释性，而RES计算成本高。MaTIR旨在统一两者，实现高效搜索和精确分割。

Method: 两阶段框架：1）利用SAM 2和Alpha-CLIP离线生成对象掩码和区域级嵌入；2）使用MLLM重新排序并生成边界框。

Result: 在COCO和D$^3$数据集上，检索准确率和分割质量显著提升。

Conclusion: MaTIR有效结合了TIR和RES的优势，为多模态任务提供了新思路。

Abstract: Text-to-image retrieval (TIR) aims to find relevant images based on a textual
query, but existing approaches are primarily based on whole-image captions and
lack interpretability. Meanwhile, referring expression segmentation (RES)
enables precise object localization based on natural language descriptions but
is computationally expensive when applied across large image collections. To
bridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies
TIR and RES, requiring both efficient image search and accurate object
segmentation. To address this task, we propose a two-stage framework,
comprising a first stage for segmentation-aware image retrieval and a second
stage for reranking and object grounding with a multimodal large language model
(MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract
region-level embeddings offline at first, enabling effective and scalable
online retrieval. Secondly, MLLM is used to refine retrieval rankings and
generate bounding boxes, which are matched to segmentation masks. We evaluate
our approach on COCO and D$^3$ datasets, demonstrating significant improvements
in both retrieval accuracy and segmentation quality over previous methods.

</details>


### [155] [STR-Match: Matching SpatioTemporal Relevance Score for Training-Free Video Editing](https://arxiv.org/abs/2506.22868)
*Junsung Lee,Junoh Kang,Bohyung Han*

Main category: cs.CV

Relevance: 40.0

TL;DR: STR-Match是一种无需训练的视频编辑算法，通过新的STR分数优化潜在空间，解决现有方法的时间不一致性和运动失真问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本引导视频编辑方法存在时间不一致、运动失真和领域转换有限的问题，主要原因是时空像素相关性建模不足。

Method: 提出STR-Match，利用2D空间注意力和1D时间模块计算STR分数，指导潜在优化，避免昂贵的3D注意力机制。

Result: 实验表明，STR-Match在视觉质量和时空一致性上优于现有方法，尤其在显著领域转换时表现优异。

Conclusion: STR-Match通过优化时空像素相关性建模，显著提升了视频编辑的时空一致性和视觉保真度。

Abstract: Previous text-guided video editing methods often suffer from temporal
inconsistency, motion distortion, and-most notably-limited domain
transformation. We attribute these limitations to insufficient modeling of
spatiotemporal pixel relevance during the editing process. To address this, we
propose STR-Match, a training-free video editing algorithm that produces
visually appealing and spatiotemporally coherent videos through latent
optimization guided by our novel STR score. The score captures spatiotemporal
pixel relevance across adjacent frames by leveraging 2D spatial attention and
1D temporal modules in text-to-video (T2V) diffusion models, without the
overhead of computationally expensive 3D attention mechanisms. Integrated into
a latent optimization framework with a latent mask, STR-Match generates
temporally consistent and visually faithful videos, maintaining strong
performance even under significant domain transformations while preserving key
visual attributes of the source. Extensive experiments demonstrate that
STR-Match consistently outperforms existing methods in both visual quality and
spatiotemporal consistency.

</details>


### [156] [Decoupled Seg Tokens Make Stronger Reasoning Video Segmenter and Grounder](https://arxiv.org/abs/2506.22880)
*Dang Jisheng,Wu Xudong,Wang Bimei,Lv Ning,Chen Jiayu,Jingwen Zhao,Yichu liu,Jizhao Liu,Juncheng Li,Teng Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出DeSa2VA，通过解耦增强提示方案和线性解耦模块，解决视频分割中动态视觉信息与静态语义纠缠的问题，提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如Sa2VA）直接将特征融合到分割模型中，导致动态视觉信息与静态语义纠缠，降低分割精度。

Method: 1. 设计文本预训练范式，将文本标签转换为点级提示并生成文本掩码；2. 使用线性投影将LLM生成的隐藏状态解耦为文本和视觉特征子空间；3. 动态掩码融合策略结合解耦特征。

Result: 在图像分割、图像问答、视频分割和视频问答等任务中表现优异。

Conclusion: DeSa2VA通过解耦和动态融合显著提升了分割性能。

Abstract: Existing video segmenter and grounder approaches, exemplified by Sa2VA,
directly fuse features within segmentation models. This often results in an
undesirable entanglement of dynamic visual information and static semantics,
thereby degrading segmentation accuracy. To systematically mitigate this issue,
we propose DeSa2VA, a decoupling-enhanced prompting scheme integrating text
pre-training and a linear decoupling module to address the information
processing limitations inherent in SAM-2. Specifically, first, we devise a
pre-training paradigm that converts textual ground-truth labels into
point-level prompts while generating corresponding text masks. These masks are
refined through a hybrid loss function to strengthen the model's semantic
grounding capabilities. Next, we employ linear projection to disentangle hidden
states that generated by a large language model into distinct textual and
visual feature subspaces. Finally, a dynamic mask fusion strategy
synergistically combines these decoupled features through triple supervision
from predicted text/visual masks and ground-truth annotations. Extensive
experiments demonstrate state-of-the-art performance across diverse tasks,
including image segmentation, image question answering, video segmentation, and
video question answering. Our codes are available at
https://github.com/longmalongma/DeSa2VA.

</details>


### [157] [How Semantically Informative is an Image?: Measuring the Covariance-Weighted Norm of Contrastive Learning Embeddings](https://arxiv.org/abs/2506.22881)
*Fumiya Uchiyama,Rintaro Yanagi,Shohei Taniguchi,Shota Takashiro,Masahiro Suzuki,Hirokatsu Kataoka,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于对比学习的语义信息度量方法，用于量化图像和文本的信息增益，适用于多模态领域。


<details>
  <summary>Details</summary>
Motivation: 研究对比学习是否能表示绝对语义信息，而不仅仅是相对语义相似性。

Method: 通过对比学习模型计算图像和文本的信息增益，并扩展信息增益概念到视觉和语言领域。

Result: 信息增益分数与嵌入范数强相关（R²=0.98-1.00），低分图像多为占位符。

Conclusion: 该方法计算高效，适用于公开模型，为多模态信息量化提供了新工具。

Abstract: Contrastive learning has the capacity to model multimodal probability
distributions by embedding and aligning visual representations with semantics
from captions. This approach enables the estimation of relational semantic
similarity; however, it remains unclear whether it can also represent absolute
semantic informativeness. In this work, we introduce a semantic informativeness
metric for an image calculated from text samples via a contrastive learning
model; similarly, the informativeness of a text is calculated from image
samples. We propose a redefinition of the concept of Information Gain, a
concept previously explored in natural language processing, extending its
application to the domains of vision and language. Our metric quantifies how
conditioning on an image distorts the distribution of associated texts, and
vice versa for text conditioning on image distributions. In OpenCLIP's
empirical results, we observe that images with the lowest Information Gain
scores often correspond to placeholder icons such as "image not found."
Furthermore, we propose to measure a norm-based metric of the embedding to
estimate the Information Gain, following the theoretical results for Skip-Gram
with Negative Sampling (SGNS) word embedding. Information Gain can be measured
using either CLIP or SigLIP, and the results demonstrate a strong correlation
with a coefficient of determination ranging from 0.98 to 1.00. After obtaining
the mean and the covariance of the sample embedding, the computational cost of
this method is independent of the sample size, and it is compatible with
publicly available, open-weight models.

</details>


### [158] [CP-Guard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems](https://arxiv.org/abs/2506.22890)
*Senkang Hu,Yihang Tao,Guowen Xu,Xinyuan Qian,Yiqin Deng,Xianhao Chen,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为CP-Guard的防御框架，用于协作感知（CP）中检测和消除恶意代理，通过共识机制和自适应阈值确保系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 协作感知在多代理系统中能提升感知性能，但易受恶意代理攻击，需解决这一安全问题。

Method: 提出概率无关的样本共识（PASAC）方法和协作一致性损失（CCLoss），结合在线自适应阈值动态调整共识验证。

Result: 实验证明CP-Guard能有效检测和消除恶意代理，提升系统可靠性。

Conclusion: CP-Guard为协作感知提供了一种统一的防御机制，适用于动态环境。

Abstract: Collaborative Perception (CP) has been shown to be a promising technique for
multi-agent autonomous driving and multi-agent robotic systems, where multiple
agents share their perception information to enhance the overall perception
performance and expand the perception range. However, in CP, an ego agent needs
to receive messages from its collaborators, which makes it vulnerable to
attacks from malicious agents. To address this critical issue, we propose a
unified, probability-agnostic, and adaptive framework, namely, CP-Guard, which
is a tailored defense mechanism for CP deployed by each agent to accurately
detect and eliminate malicious agents in its collaboration network. Our key
idea is to enable CP to reach a consensus rather than a conflict against an ego
agent's perception results. Based on this idea, we first develop a
probability-agnostic sample consensus (PASAC) method to effectively sample a
subset of the collaborators and verify the consensus without prior
probabilities of malicious agents. Furthermore, we define collaborative
consistency loss (CCLoss) for object detection task and bird's eye view (BEV)
segmentation task to capture the discrepancy between an ego agent and its
collaborators, which is used as a verification criterion for consensus. In
addition, we propose online adaptive threshold via dual sliding windows to
dynamically adjust the threshold for consensus verification and ensure the
reliability of the systems in dynamic environments. Finally, we conduct
extensive experiments and demonstrate the effectiveness of our framework. Code
will be released at https://github.com/CP-Security/CP-Guard

</details>


### [159] [Neural Cellular Automata: From Cells to Pixels](https://arxiv.org/abs/2506.22899)
*Ehsan Pajouheshgar,Yitao Xu,Ali Abbasi,Alexander Mordvintsev,Wenzel Jakob,Sabine Süsstrunk*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种结合隐式解码器的神经细胞自动机（NCA）方法，解决了高分辨率网格下的训练和推理效率问题，实现了实时生成高清输出的能力。


<details>
  <summary>Details</summary>
Motivation: NCA在低分辨率网格上表现良好，但在高分辨率下存在训练时间长、信息传播受限和计算需求高的问题。

Method: 通过引入共享隐式解码器，结合新型损失函数，优化了NCA在高分辨率下的性能和效率。

Result: 实现了实时生成高清输出的能力，同时保持了自组织和涌现特性，适用于多种任务和NCA变体。

Conclusion: 提出的框架显著提升了NCA在高分辨率下的可扩展性和实用性。

Abstract: Neural Cellular Automata (NCAs) are bio-inspired systems in which identical
cells self-organize to form complex and coherent patterns by repeatedly
applying simple local rules. NCAs display striking emergent behaviors including
self-regeneration, generalization and robustness to unseen situations, and
spontaneous motion. Despite their success in texture synthesis and
morphogenesis, NCAs remain largely confined to low-resolution grids. This
limitation stems from (1) training time and memory requirements that grow
quadratically with grid size, (2) the strictly local propagation of information
which impedes long-range cell communication, and (3) the heavy compute demands
of real-time inference at high resolution. In this work, we overcome this
limitation by pairing NCA with a tiny, shared implicit decoder, inspired by
recent advances in implicit neural representations. Following NCA evolution on
a coarse grid, a lightweight decoder renders output images at arbitrary
resolution. We also propose novel loss functions for both morphogenesis and
texture synthesis tasks, specifically tailored for high-resolution output with
minimal memory and computation overhead. Combining our proposed architecture
and loss functions brings substantial improvement in quality, efficiency, and
performance. NCAs equipped with our implicit decoder can generate full-HD
outputs in real time while preserving their self-organizing, emergent
properties. Moreover, because each MLP processes cell states independently,
inference remains highly parallelizable and efficient. We demonstrate the
applicability of our approach across multiple NCA variants (on 2D, 3D grids,
and 3D meshes) and multiple tasks, including texture generation and
morphogenesis (growing patterns from a seed), showing that with our proposed
framework, NCAs seamlessly scale to high-resolution outputs with minimal
computational overhead.

</details>


### [160] [Towards Explainable Bilingual Multimodal Misinformation Detection and Localization](https://arxiv.org/abs/2506.22930)
*Yiwei He,Xiangtai Li,Zhenglin Huang,Yi Dong,Hao Fei,Jiangning Zhang,Baoyuan Wu,Guangliang Cheng*

Main category: cs.CV

Relevance: 40.0

TL;DR: BiMi是一个双语多模态框架，用于检测新闻媒体中的虚假信息，通过区域定位、跨模态和跨语言一致性检测以及自然语言解释来提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 多模态内容的真实性增加使得虚假信息更难以检测，尤其是在双语新闻中，BiMi旨在解决这一问题。

Method: BiMi结合了区域级定位、跨模态和跨语言一致性检测，并利用在线检索模块增强泛化能力。GRPO用于提升解释质量。

Result: BiMi在分类准确率、定位准确率和解释质量上均优于基线，分别提升8.9、15.9和2.5分。

Conclusion: BiMi在多语言虚假信息检测中取得了最先进的性能，并发布了BiMiBench基准测试。

Abstract: The increasing realism of multimodal content has made misinformation more
subtle and harder to detect, especially in news media where images are
frequently paired with bilingual (e.g., Chinese-English) subtitles. Such
content often includes localized image edits and cross-lingual inconsistencies
that jointly distort meaning while remaining superficially plausible. We
introduce BiMi, a bilingual multimodal framework that jointly performs
region-level localization, cross-modal and cross-lingual consistency detection,
and natural language explanation for misinformation analysis. To support
generalization, BiMi integrates an online retrieval module that supplements
model reasoning with up-to-date external context. We further release BiMiBench,
a large-scale and comprehensive benchmark constructed by systematically editing
real news images and subtitles, comprising 104,000 samples with realistic
manipulations across visual and linguistic modalities. To enhance
interpretability, we apply Group Relative Policy Optimization (GRPO) to improve
explanation quality, marking the first use of GRPO in this domain. Extensive
experiments demonstrate that BiMi outperforms strong baselines by up to +8.9 in
classification accuracy, +15.9 in localization accuracy, and +2.5 in
explanation BERTScore, advancing state-of-the-art performance in realistic,
multilingual misinformation detection. Code, models, and datasets will be
released.

</details>


### [161] [Probabilistic Prototype Calibration of Vision-Language Models for Generalized Few-shot Semantic Segmentation](https://arxiv.org/abs/2506.22979)
*Jie Liu,Jiayi Shen,Pan Zhou,Jan-Jakob Sonke,Efstratios Gavves*

Main category: cs.CV

Relevance: 40.0

TL;DR: FewCLIP是一个基于概率原型校准的框架，利用预训练的CLIP模型改进广义少样本语义分割（GFSS），通过多模态原型学习和分布正则化提升适应性。


<details>
  <summary>Details</summary>
Motivation: 现有基于原型的方法在少样本语义分割中存在确定性限制，难以适应多样样本，尤其是标注稀缺的新类别。FewCLIP旨在通过概率原型校准解决这一问题。

Method: FewCLIP结合冻结的文本原型和可学习的视觉校准原型，引入分布正则化以实现结构化和不确定性感知的原型学习。

Result: 在PASCAL-5$^i$和COCO-20$^i$数据集上，FewCLIP显著优于现有方法，适用于GFSS和类增量设置。

Conclusion: FewCLIP通过概率原型校准提升了少样本语义分割的适应性和泛化能力。

Abstract: Generalized Few-Shot Semantic Segmentation (GFSS) aims to extend a
segmentation model to novel classes with only a few annotated examples while
maintaining performance on base classes. Recently, pretrained vision-language
models (VLMs) such as CLIP have been leveraged in GFSS to improve
generalization on novel classes through multi-modal prototypes learning.
However, existing prototype-based methods are inherently deterministic,
limiting the adaptability of learned prototypes to diverse samples,
particularly for novel classes with scarce annotations. To address this, we
propose FewCLIP, a probabilistic prototype calibration framework over
multi-modal prototypes from the pretrained CLIP, thus providing more adaptive
prototype learning for GFSS. Specifically, FewCLIP first introduces a prototype
calibration mechanism, which refines frozen textual prototypes with learnable
visual calibration prototypes, leading to a more discriminative and adaptive
representation. Furthermore, unlike deterministic prototype learning
techniques, FewCLIP introduces distribution regularization over these
calibration prototypes. This probabilistic formulation ensures structured and
uncertainty-aware prototype learning, effectively mitigating overfitting to
limited novel class data while enhancing generalization. Extensive experimental
results on PASCAL-5$^i$ and COCO-20$^i$ datasets demonstrate that our proposed
FewCLIP significantly outperforms state-of-the-art approaches across both GFSS
and class-incremental setting. The code is available at
https://github.com/jliu4ai/FewCLIP.

</details>


### [162] [Inpainting is All You Need: A Diffusion-based Augmentation Method for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2506.23038)
*Xinrong Hu,Yiyu Shi*

Main category: cs.CV

Relevance: 40.0

TL;DR: AugPaint是一个利用潜在扩散模型进行数据增强的框架，通过生成图像-标签对来解决医学图像分割中标注数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 医学数据集的像素级标注耗时且昂贵，而标注数据稀缺是提升分割性能的关键挑战。AugPaint旨在通过生成高质量的合成图像-标签对来解决这一问题。

Method: AugPaint利用潜在扩散模型，通过反向去噪过程生成图像，并确保合成图像与标签掩码的匹配准确性。无需重新训练模型，直接从有限标注数据中生成图像-标签对。

Result: 在四个公共医学图像分割数据集（CT、MRI和皮肤成像）上的实验表明，AugPaint优于现有的标签高效方法，显著提升了分割性能。

Conclusion: AugPaint通过生成高质量的合成数据，有效解决了医学图像分割中标注数据稀缺的问题，为下游分割模型的训练提供了有价值的监督。

Abstract: Collecting pixel-level labels for medical datasets can be a laborious and
expensive process, and enhancing segmentation performance with a scarcity of
labeled data is a crucial challenge. This work introduces AugPaint, a data
augmentation framework that utilizes inpainting to generate image-label pairs
from limited labeled data. AugPaint leverages latent diffusion models, known
for their ability to generate high-quality in-domain images with low overhead,
and adapts the sampling process for the inpainting task without need for
retraining. Specifically, given a pair of image and label mask, we crop the
area labeled with the foreground and condition on it during reversed denoising
process for every noise level. Masked background area would gradually be filled
in, and all generated images are paired with the label mask. This approach
ensures the accuracy of match between synthetic images and label masks, setting
it apart from existing dataset generation methods. The generated images serve
as valuable supervision for training downstream segmentation models,
effectively addressing the challenge of limited annotations. We conducted
extensive evaluations of our data augmentation method on four public medical
image segmentation datasets, including CT, MRI, and skin imaging. Results
across all datasets demonstrate that AugPaint outperforms state-of-the-art
label-efficient methodologies, significantly improving segmentation
performance.

</details>


### [163] [Empowering Small VLMs to Think with Dynamic Memorization and Exploration](https://arxiv.org/abs/2506.23061)
*Jiazhen Liu,Yuchuan Deng,Long Chen*

Main category: cs.CV

Relevance: 40.0

TL;DR: DyME是一种动态选择记忆（SFT）和探索（RLVR）模式的训练范式，显著提升了小规模视觉语言模型（SVLMs）的可靠思考能力。


<details>
  <summary>Details</summary>
Motivation: 由于SVLMs参数容量有限且指令跟随能力弱，现有训练范式（如SFT和RLVR）对其效果不佳，导致伪思考痕迹和优势崩溃。

Method: 提出DyME，动态选择SFT和RLVR模式，确保每次优化更新都贡献于性能平衡。

Result: 实验表明DyME能有效平衡性能，显著提升SVLMs的可靠思考能力和任务表现。

Conclusion: DyME是提升SVLMs可靠思考能力的实用有效解决方案。

Abstract: Empowering Small-scale Vision-Language Models (SVLMs) with reliable thinking
capabilities remains fundamentally challenging due to their limited parameter
capacity and weak instruction-following abilities. Existing training paradigms,
including Supervised Fine-Tuning (SFT) and Reinforcement Learning with
Verifiable Reward (RLVR), impose substantial demands on the base VLM, exceeding
the capabilities of SVLMs. Consequently, directly applying these paradigms to
SVLMs often suffers from severe pseudo thinking traces and advantage collapse,
ultimately undermining both thinking reliability and task performance. A
natural solution is to combine SFT and RLVR, leveraging their complementarity
to reduce the dependence on model capacity. However, the widely adopted
two-stage training paradigm still performs poorly on SVLMs, as their tendency
toward sub-optimal convergence hinders the trade-off and limits the benefits of
the combination. To address this, we propose DyME, a novel training paradigm
that Dynamically selects between Memorization (via SFT) and Exploration (via
RLVR) modes at each optimization step, ensuring that every update contributes
to the trade-off. Extensive experiments across diverse domains demonstrate that
DyME consistently achieves this balance, and thus delivers substantial
performance improvements. These results establish DyME as a practical and
effective solution for empowering SVLMs with reliable thinking capabilities.
GitHub: https://github.com/HKUST-LongGroup/DyME

</details>


### [164] [CoreMark: Toward Robust and Universal Text Watermarking Technique](https://arxiv.org/abs/2506.23066)
*Jiale Meng,Yiming Li,Zheming Lu,Zewei He,Hao Luo,Tianwei Zhang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 本文提出了一种名为CORE的新文本水印嵌入范式，并基于此开发了CoreMark框架，显著提升了水印的鲁棒性、通用性和不可感知性。


<details>
  <summary>Details</summary>
Motivation: 当前文本水印方案在鲁棒性、通用性和不可感知性方面存在挑战，需要一种更有效的解决方案。

Method: 提出CORE嵌入范式，动态提取字符中的CORE段，根据长度选择鲁棒性强的字符，并通过调整CORE厚度嵌入数据。此外，设计了自适应嵌入强度调节器。

Result: CoreMark在多语言和字体中表现出色，显著提升了抗截图、打印扫描和打印相机攻击的能力，同时保持不可感知性。

Conclusion: CoreMark为文本水印提供了一种高效且通用的解决方案。

Abstract: Text watermarking schemes have gained considerable attention in recent years,
yet still face critical challenges in achieving simultaneous robustness,
generalizability, and imperceptibility. This paper introduces a new embedding
paradigm,termed CORE, which comprises several consecutively aligned black pixel
segments. Its key innovation lies in its inherent noise resistance during
transmission and broad applicability across languages and fonts. Based on the
CORE, we present a text watermarking framework named CoreMark. Specifically,
CoreMark first dynamically extracts COREs from characters. Then, the characters
with stronger robustness are selected according to the lengths of COREs. By
modifying the thickness of the CORE, the hidden data is embedded into the
selected characters without causing significant visual distortions. Moreover, a
general plug-and-play embedding strength modulator is proposed, which can
adaptively enhance the robustness for small font sizes by adjusting the
embedding strength according to the font size. Experimental evaluation
indicates that CoreMark demonstrates outstanding generalizability across
multiple languages and fonts. Compared to existing methods, CoreMark achieves
significant improvements in resisting screenshot, print-scan, and print camera
attacks, while maintaining satisfactory imperceptibility.

</details>


### [165] [Learning Counterfactually Decoupled Attention for Open-World Model Attribution](https://arxiv.org/abs/2506.23074)
*Yu Zheng,Boyang Gong,Fanye Kong,Yueqi Duan,Bingyao Yu,Wenzhao Zheng,Lei Chen,Jiwen Lu,Jie Zhou*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种反事实解耦注意力学习（CDAL）方法，用于开放世界模型归因，通过建模注意力视觉痕迹与源模型归因的因果关系，提升对未见攻击的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手工设计的区域划分或特征空间，易受虚假统计相关性干扰，难以应对开放世界中的新攻击。

Method: CDAL显式建模注意力视觉痕迹与源模型归因的因果关系，并通过反事实解耦分离模型特异性伪影与混淆源偏差。

Result: 在现有开放世界模型归因基准测试中，CDAL以最小计算开销显著提升现有模型性能，尤其对未见攻击表现突出。

Conclusion: CDAL通过因果建模和解耦机制，有效提升了模型归因的泛化能力和鲁棒性。

Abstract: In this paper, we propose a Counterfactually Decoupled Attention Learning
(CDAL) method for open-world model attribution. Existing methods rely on
handcrafted design of region partitioning or feature space, which could be
confounded by the spurious statistical correlations and struggle with novel
attacks in open-world scenarios. To address this, CDAL explicitly models the
causal relationships between the attentional visual traces and source model
attribution, and counterfactually decouples the discriminative model-specific
artifacts from confounding source biases for comparison. In this way, the
resulting causal effect provides a quantification on the quality of learned
attention maps, thus encouraging the network to capture essential generation
patterns that generalize to unseen source models by maximizing the effect.
Extensive experiments on existing open-world model attribution benchmarks show
that with minimal computational overhead, our method consistently improves
state-of-the-art models by large margins, particularly for unseen novel
attacks. Source code: https://github.com/yzheng97/CDAL.

</details>


### [166] [Where, What, Why: Towards Explainable Driver Attention Prediction](https://arxiv.org/abs/2506.23088)
*Yuchen Zhou,Jiayu Tang,Xiaoyan Xiao,Yueyao Lin,Linkai Liu,Zipeng Guo,Hao Fei,Xiaobo Xia,Chao Gou*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种可解释的驾驶员注意力预测任务范式（W3DA数据集和LLada框架），结合空间注意力、语义解析和认知推理，以更深入理解注意力机制。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅预测驾驶员注视的空间热图，未能捕捉注意力分配的认知动机，限制了对其机制的深入理解。

Method: 提出W3DA数据集（含语义和因果标注）和LLada框架（基于大语言模型，统一像素建模、语义解析和认知推理）。

Result: LLada在多种驾驶场景下表现出鲁棒性，实验验证了其有效性。

Conclusion: 该研究为理解驾驶员注意力机制提供了关键进展，对自动驾驶等领域有重要意义。

Abstract: Modeling task-driven attention in driving is a fundamental challenge for both
autonomous vehicles and cognitive science. Existing methods primarily predict
where drivers look by generating spatial heatmaps, but fail to capture the
cognitive motivations behind attention allocation in specific contexts, which
limits deeper understanding of attention mechanisms. To bridge this gap, we
introduce Explainable Driver Attention Prediction, a novel task paradigm that
jointly predicts spatial attention regions (where), parses attended semantics
(what), and provides cognitive reasoning for attention allocation (why). To
support this, we present W3DA, the first large-scale explainable driver
attention dataset. It enriches existing benchmarks with detailed semantic and
causal annotations across diverse driving scenarios, including normal
conditions, safety-critical situations, and traffic accidents. We further
propose LLada, a Large Language model-driven framework for driver attention
prediction, which unifies pixel modeling, semantic parsing, and cognitive
reasoning within an end-to-end architecture. Extensive experiments demonstrate
the effectiveness of LLada, exhibiting robust generalization across datasets
and driving conditions. This work serves as a key step toward a deeper
understanding of driver attention mechanisms, with significant implications for
autonomous driving, intelligent driver training, and human-computer
interaction.

</details>


### [167] [DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation](https://arxiv.org/abs/2506.23104)
*Jihun Kim,Hoyong Kwon,Hyeokjun Kweon,Wooseong Jeong,Kuk-Jin Yoon*

Main category: cs.CV

Relevance: 40.0

TL;DR: DC-TTA是一种新的测试时适应框架，通过用户交互监督改进SAM的分割能力，适用于复杂场景。


<details>
  <summary>Details</summary>
Motivation: 解决SAM在专业领域和复杂场景（如伪装或多部分对象）中的性能不足问题。

Method: 提出DC-TTA框架，将用户交互划分为更一致的子集，每个子集通过独立的TTA模型处理，减少冲突并实现局部更新。

Result: 实验表明DC-TTA显著优于SAM的零样本结果和传统TTA方法，在复杂任务中表现更优。

Conclusion: DC-TTA通过分而治之策略有效提升了SAM在复杂场景中的性能。

Abstract: Interactive segmentation (IS) allows users to iteratively refine object
boundaries with minimal cues, such as positive and negative clicks. While the
Segment Anything Model (SAM) has garnered attention in the IS community for its
promptable segmentation capabilities, it often struggles in specialized domains
or when handling complex scenarios (e.g., camouflaged or multi-part objects).
To overcome these challenges, we propose DC-TTA, a novel test-time adaptation
(TTA) framework that adapts SAM on a per-sample basis by leveraging user
interactions as supervision. Instead of forcing a single model to incorporate
all user clicks at once, DC-TTA partitions the clicks into more coherent
subsets, each processed independently via TTA with a separated model. This
Divide-and-Conquer strategy reduces conflicts among diverse cues and enables
more localized updates. Finally, we merge the adapted models to form a unified
predictor that integrates the specialized knowledge from each subset.
Experimental results across various benchmarks demonstrate that DC-TTA
significantly outperforms SAM's zero-shot results and conventional TTA methods,
effectively handling complex tasks such as camouflaged object segmentation with
fewer interactions and improved accuracy.

</details>


### [168] [Computer-Aided Multi-Stroke Character Simplification by Stroke Removal](https://arxiv.org/abs/2506.23106)
*Ryo Ishiyama,Shinnosuke Matsuo,Seiichi Uchida*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种通过选择性去除笔画来简化多笔画字符的框架，同时保持其可读性。


<details>
  <summary>Details</summary>
Motivation: 简化复杂字符以降低非母语学习者的学习难度，优化字体设计，提升字符通信系统效率。

Method: 使用高精度字符识别模型评估可读性，去除对可读性影响最小的笔画。

Result: 实验表明，即使去除多个笔画，许多字符仍可区分，支持更正式的简化策略。

Conclusion: 该框架为多笔画字符简化提供了可行方案，具有实际应用潜力。

Abstract: Multi-stroke characters in scripts such as Chinese and Japanese can be highly
complex, posing significant challenges for both native speakers and,
especially, non-native learners. If these characters can be simplified without
degrading their legibility, it could reduce learning barriers for non-native
speakers, facilitate simpler and legible font designs, and contribute to
efficient character-based communication systems. In this paper, we propose a
framework to systematically simplify multi-stroke characters by selectively
removing strokes while preserving their overall legibility. More specifically,
we use a highly accurate character recognition model to assess legibility and
remove those strokes that minimally impact it. Experimental results on 1,256
character classes with 5, 10, 15, and 20 strokes reveal several key findings,
including the observation that even after removing multiple strokes, many
characters remain distinguishable. These findings suggest the potential for
more formalized simplification strategies.

</details>


### [169] [Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation](https://arxiv.org/abs/2506.23120)
*Zhenhua Ning,Zhuotao Tian,Shaoshuai Shi,Guangming Lu,Daojing He,Wenjie Pei,Li Jiang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种基于推理的分割框架R²S和数据集3D ReasonSeg，以增强3D点云感知的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理需要精确空间推理的复杂指令时存在挑战，尽管3D点云数据提供了详细的空间线索。

Method: R²S框架模仿人类认知过程，将空间推理分为两个阶段：先识别相关元素，再根据视觉先验处理指令。

Result: 实验表明R²S和3D ReasonSeg显著提升了3D点云的空间推理能力。

Conclusion: R²S和3D ReasonSeg为未来研究提供了新的基准和数据集。

Abstract: Recent advances in point cloud perception have demonstrated remarkable
progress in scene understanding through vision-language alignment leveraging
large language models (LLMs). However, existing methods may still encounter
challenges in handling complex instructions that require accurate spatial
reasoning, even if the 3D point cloud data provides detailed spatial cues such
as size and position for identifying the targets. To tackle this issue, we
propose Relevant Reasoning Segmentation (R$^2$S), a reasoning-based
segmentation framework. The framework emulates human cognitive processes by
decomposing spatial reasoning into two sequential stages: first identifying
relevant elements, then processing instructions guided by their associated
visual priors. Furthermore, acknowledging the inadequacy of existing datasets
in complex reasoning tasks, we introduce 3D ReasonSeg, a reasoning-based
segmentation dataset comprising 25,185 training samples and 3,966 validation
samples with precise annotations. Both quantitative and qualitative experiments
demonstrate that the R$^2$S and 3D ReasonSeg effectively endow 3D point cloud
perception with stronger spatial reasoning capabilities, and we hope that they
can serve as a new baseline and benchmark for future work.

</details>


### [170] [RoboScape: Physics-informed Embodied World Model](https://arxiv.org/abs/2506.23135)
*Yu Shang,Xin Zhang,Yinzhou Tang,Lei Jin,Chen Gao,Wei Wu,Yong Li*

Main category: cs.CV

Relevance: 40.0

TL;DR: RoboScape是一个统一的物理感知世界模型，通过联合学习RGB视频生成和物理知识，提升机器人场景中视频生成的视觉保真度和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 当前的世界模型在建模3D几何和运动动力学方面存在局限性，导致接触丰富的机器人场景中视频生成不真实。RoboScape旨在解决这一问题。

Method: 提出两个物理感知联合训练任务：时间深度预测和关键点动力学学习，以增强视频渲染的3D几何一致性和复杂运动建模。

Result: 实验表明，RoboScape在多样化机器人场景中生成具有更高视觉保真度和物理合理性的视频。

Conclusion: RoboScape为构建高效的物理感知世界模型提供了新思路，推动具身智能研究。

Abstract: World models have become indispensable tools for embodied intelligence,
serving as powerful simulators capable of generating realistic robotic videos
while addressing critical data scarcity challenges. However, current embodied
world models exhibit limited physical awareness, particularly in modeling 3D
geometry and motion dynamics, resulting in unrealistic video generation for
contact-rich robotic scenarios. In this paper, we present RoboScape, a unified
physics-informed world model that jointly learns RGB video generation and
physics knowledge within an integrated framework. We introduce two key
physics-informed joint training tasks: temporal depth prediction that enhances
3D geometric consistency in video rendering, and keypoint dynamics learning
that implicitly encodes physical properties (e.g., object shape and material
characteristics) while improving complex motion modeling. Extensive experiments
demonstrate that RoboScape generates videos with superior visual fidelity and
physical plausibility across diverse robotic scenarios. We further validate its
practical utility through downstream applications including robotic policy
training with generated data and policy evaluation. Our work provides new
insights for building efficient physics-informed world models to advance
embodied intelligence research. The code is available at:
https://github.com/tsinghua-fib-lab/RoboScape.

</details>


### [171] [VisualPrompter: Prompt Optimization with Visual Feedback for Text-to-Image Synthesis](https://arxiv.org/abs/2506.23138)
*Shiyu Wu,Mingzhen Sun,Weining Wang,Yequan Wang,Jing Liu*

Main category: cs.CV

Relevance: 40.0

TL;DR: VisualPrompter是一个无需训练的提示工程框架，通过自反模块和细粒度优化机制提升文本到图像生成中的语义对齐。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像提示工程方法虽能提升风格和美学，但常忽视语义对齐，导致生成图像内容与用户描述不符。

Method: 提出VisualPrompter框架，包含自动自反模块识别缺失概念，以及目标特定提示优化机制细粒度修订提示。

Result: 在多个文本-图像对齐评估基准上达到新SOTA，且具有即插即用设计，适配多种生成模型。

Conclusion: VisualPrompter有效解决了语义对齐问题，提升了生成图像的内容满意度。

Abstract: Since there exists a notable gap between user-provided and model-preferred
prompts, generating high-quality and satisfactory images using diffusion models
often requires prompt engineering to optimize user inputs. Current studies on
text-to-image prompt engineering can effectively enhance the style and
aesthetics of generated images. However, they often neglect the semantic
alignment between generated images and user descriptions, resulting in visually
appealing but content-wise unsatisfying outputs. In this work, we propose
VisualPrompter, a novel training-free prompt engineering framework that refines
user inputs to model-preferred sentences. In particular, VisualPrompter
utilizes an automatic self-reflection module to identify the missing concepts
in generated images and a target-specific prompt optimization mechanism to
revise the prompts in a fine-grained manner. Extensive experiments demonstrate
the effectiveness of our VisualPrompter, which achieves new state-of-the-art
performance on multiple benchmarks for text-image alignment evaluation.
Additionally, our framework features a plug-and-play design, making it highly
adaptable to various generative models.

</details>


### [172] [MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation](https://arxiv.org/abs/2506.23151)
*Vladislav Bargatin,Egor Chistov,Alexander Yakovenko,Dmitriy Vatolin*

Main category: cs.CV

Relevance: 40.0

TL;DR: MEMFOF是一种内存高效的多帧光流估计方法，通过优化设计选择，在保持高分辨率（1080p）的同时显著降低GPU内存使用，并在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决光流估计中高分辨率输入导致GPU内存消耗过大的问题，同时保持准确性。

Method: 结合RAFT-like架构的设计选择，采用减少的相关体积和高分辨率训练协议，实现多帧光流估计。

Result: 在多个基准测试中表现最优，如Spring（3.289 1px异常率）、Sintel（0.963 EPE）和KITTI-2015（2.94% Fl-all误差）。

Conclusion: MEMFOF在内存效率和准确性之间找到了平衡，适用于高分辨率光流估计。

Abstract: Recent advances in optical flow estimation have prioritized accuracy at the
cost of growing GPU memory consumption, particularly for high-resolution
(FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical
flow method that identifies a favorable trade-off between multi-frame
estimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU
memory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely
positions our method to be trained at native 1080p without the need for
cropping or downsampling. We systematically revisit design choices from
RAFT-like architectures, integrating reduced correlation volumes and
high-resolution training protocols alongside multi-frame estimation, to achieve
state-of-the-art performance across multiple benchmarks while substantially
reducing memory overhead. Our method outperforms more resource-intensive
alternatives in both accuracy and runtime efficiency, validating its robustness
for flow estimation at high resolutions. At the time of submission, our method
ranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289,
leads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the
best Fl-all error on KITTI-2015 at 2.94%. The code is available at
https://github.com/msu-video-group/memfof.

</details>


### [173] [Self-Supervised Contrastive Learning for Multi-Label Images](https://arxiv.org/abs/2506.23156)
*Jiale Chen*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种针对多标签图像的自监督学习方法，通过块级增强和图像感知对比损失，减少预训练开销并提升语义一致性。


<details>
  <summary>Details</summary>
Motivation: 主流自监督学习方法依赖单标签高体数据集（如ImageNet），预训练开销大且忽略多标签图像的丰富语义信息。

Method: 提出块级增强模块提取多标签图像中的潜在正视图对，设计图像感知对比损失建立视图间联系。

Result: 在线性微调和迁移学习中验证了方法的竞争力，尽管样本质量和数量受限。

Conclusion: 该方法在多标签图像上实现了高效的自监督学习，具有广泛的下游应用潜力。

Abstract: Self-supervised learning (SSL) has demonstrated its effectiveness in learning
representations through comparison methods that align with human intuition.
However, mainstream SSL methods heavily rely on high body datasets with single
label, such as ImageNet, resulting in intolerable pre-training overhead.
Besides, more general multi-label images are frequently overlooked in SSL,
despite their potential for richer semantic information and broader
applicability in downstream scenarios. Therefore, we tailor the mainstream SSL
approach to guarantee excellent representation learning capabilities using
fewer multi-label images. Firstly, we propose a block-wise augmentation module
aimed at extracting additional potential positive view pairs from multi-label
images. Subsequently, an image-aware contrastive loss is devised to establish
connections between these views, thereby facilitating the extraction of
semantically consistent representations. Comprehensive linear fine-tuning and
transfer learning validate the competitiveness of our approach despite
challenging sample quality and quantity.

</details>


### [174] [DEL: Dense Event Localization for Multi-modal Audio-Visual Understanding](https://arxiv.org/abs/2506.23196)
*Mona Ahmadian,Amir Shirian,Frank Guerin,Andrew Gilbert*

Main category: cs.CV

Relevance: 40.0

TL;DR: DEL框架通过多模态交互建模，在长未剪辑视频中实现密集语义动作定位，显著提升了TAL任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界视频中的重叠事件和复杂时间依赖关系使多模态交互建模具有挑战性，需要更精确的动作检测和分类方法。

Method: DEL包含两个关键模块：音频和视觉特征对齐（利用掩码自注意力增强模态内一致性）和多模态交互细化模块（跨多尺度建模跨模态依赖关系）。

Result: 在多个TAL数据集上达到SOTA性能，平均mAP提升显著（如UnAV-100 +3.3%）。

Conclusion: DEL通过多模态交互建模显著提升了动作定位的精度和鲁棒性。

Abstract: Real-world videos often contain overlapping events and complex temporal
dependencies, making multimodal interaction modeling particularly challenging.
We introduce DEL, a framework for dense semantic action localization, aiming to
accurately detect and classify multiple actions at fine-grained temporal
resolutions in long untrimmed videos. DEL consists of two key modules: the
alignment of audio and visual features that leverage masked self-attention to
enhance intra-mode consistency and a multimodal interaction refinement module
that models cross-modal dependencies across multiple scales, enabling
high-level semantics and fine-grained details. Our method achieves
state-of-the-art performance on multiple real-world Temporal Action
Localization (TAL) datasets, UnAV-100, THUMOS14, ActivityNet 1.3, and
EPIC-Kitchens-100, surpassing previous approaches with notable average mAP
gains of +3.3%, +2.6%, +1.2%, +1.7% (verb), and +1.4% (noun), respectively.

</details>


### [175] [Transformer-Based Person Search with High-Frequency Augmentation and Multi-Wave Mixing](https://arxiv.org/abs/2506.23202)
*Qilin Shu,Qixian Zhang,Qi Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为HAMW的新方法，通过高频增强和多波混合技术改进基于Transformer的人物搜索模型，解决了自注意力机制抑制高频特征和高计算成本的问题。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer在人物搜索任务中抑制高频特征和高计算成本的问题。

Method: 提出HAMW方法，包括高频增强输入和基于多级Haar小波融合的策略替代自注意力层。

Result: 在CUHK-SYSU和PRW数据集上达到最先进性能。

Conclusion: HAMW有效提升了Transformer在人物搜索任务中的性能，同时降低了计算成本。

Abstract: The person search task aims to locate a target person within a set of scene
images. In recent years, transformer-based models in this field have made some
progress. However, they still face three primary challenges: 1) the
self-attention mechanism tends to suppress high-frequency components in the
features, which severely impacts model performance; 2) the computational cost
of transformers is relatively high. To address these issues, we propose a novel
High-frequency Augmentation and Multi-Wave mixing (HAMW) method for person
search. HAMW is designed to enhance the discriminative feature extraction
capabilities of transformers while reducing computational overhead and
improving efficiency. Specifically, we develop a three-stage framework that
progressively optimizes both detection and re-identification performance. Our
model enhances the perception of high-frequency features by learning from
augmented inputs containing additional high-frequency components. Furthermore,
we replace the self-attention layers in the transformer with a strategy based
on multi-level Haar wavelet fusion to capture multi-scale features. This not
only lowers the computational complexity but also alleviates the suppression of
high-frequency features and enhances the ability to exploit multi-scale
information. Extensive experiments demonstrate that HAMW achieves
state-of-the-art performance on both the CUHK-SYSU and PRW datasets.

</details>


### [176] [PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution](https://arxiv.org/abs/2506.23254)
*Aradhana Mishra,Bumshik Lee*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为PixelBoost的新型扩散模型，通过引入受控随机性改进图像超分辨率，在生成逼真图像的同时提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在图像超分辨率中生成逼真图像与计算效率之间的权衡问题。

Method: 引入受控随机性训练方法，结合布朗运动的随机性，提出sigmoidal噪声序列方法。

Result: 在LPIPS、LOE、PSNR、SSIM等指标上表现优越，边缘重建能力更强，训练更高效。

Conclusion: PixelBoost通过随机性优化和噪声序列方法，显著提升了图像超分辨率的逼真度和效率。

Abstract: Diffusion-model-based image super-resolution techniques often face a
trade-off between realistic image generation and computational efficiency. This
issue is exacerbated when inference times by decreasing sampling steps,
resulting in less realistic and hazy images. To overcome this challenge, we
introduce a novel diffusion model named PixelBoost that underscores the
significance of embracing the stochastic nature of Brownian motion in advancing
image super-resolution, resulting in a high degree of realism, particularly
focusing on texture and edge definitions. By integrating controlled
stochasticity into the training regimen, our proposed model avoids convergence
to local optima, effectively capturing and reproducing the inherent uncertainty
of image textures and patterns. Our proposed model demonstrates superior
objective results in terms of learned perceptual image patch similarity
(LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR),
structural similarity index measure (SSIM), as well as visual quality. To
determine the edge enhancement, we evaluated the gradient magnitude and pixel
value, and our proposed model exhibited a better edge reconstruction
capability. Additionally, our model demonstrates adaptive learning capabilities
by effectively adjusting to Brownian noise patterns and introduces a sigmoidal
noise sequencing method that simplifies training, resulting in faster inference
speeds.

</details>


### [177] [Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization](https://arxiv.org/abs/2506.23714)
*Md Moinul Islam,Sofoklis Kakouros,Janne Heikkilä,Mourad Oussalah*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于行为感知的多模态视频摘要框架，整合文本、音频和视觉线索生成时间戳对齐的摘要，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 视频内容激增需要超越传统单模态方法的有效摘要技术。

Method: 提取韵律特征、文本线索和视觉指标，识别语义和情感重要时刻，并利用跨模态强调的“奖励词”提升摘要质量。

Result: 在文本和视频评估指标上显著优于传统方法，如ROUGE-1从0.4769提升至0.7929，视频F1-Score提升近23%。

Conclusion: 多模态整合在生成全面且行为感知的视频摘要中具有潜力。

Abstract: The increasing volume of video content in educational, professional, and
social domains necessitates effective summarization techniques that go beyond
traditional unimodal approaches. This paper proposes a behaviour-aware
multimodal video summarization framework that integrates textual, audio, and
visual cues to generate timestamp-aligned summaries. By extracting prosodic
features, textual cues and visual indicators, the framework identifies
semantically and emotionally important moments. A key contribution is the
identification of bonus words, which are terms emphasized across multiple
modalities and used to improve the semantic relevance and expressive clarity of
the summaries. The approach is evaluated against pseudo-ground truth (pGT)
summaries generated using LLM-based extractive method. Experimental results
demonstrate significant improvements over traditional extractive method, such
as the Edmundson method, in both text and video-based evaluation metrics.
Text-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore
from 0.9152 to 0.9536, while in video-based evaluation, our proposed framework
improves F1-Score by almost 23%. The findings underscore the potential of
multimodal integration in producing comprehensive and behaviourally informed
video summaries.

</details>


### [178] [Causal-Entity Reflected Egocentric Traffic Accident Video Synthesis](https://arxiv.org/abs/2506.23263)
*Lei-lei Li,Jianwu Fang,Junbin Xiao,Shanmin Pang,Hongkai Yu,Chen Lv,Jianru Xue,Tat-Seng Chua*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种名为Causal-VidSyn的扩散模型，用于合成以自我为中心的交通事故视频，通过结合因果描述和驾驶员注视点来识别事故参与者和行为。


<details>
  <summary>Details</summary>
Motivation: 合成具有因果关系的交通事故视频对于自动驾驶汽车的安全测试至关重要，但现有方法难以在合成视频中准确反映真实世界中的因果关系。

Method: 提出Causal-VidSyn模型，利用因果描述和驾驶员注视点，结合事故原因回答和注视条件选择模块，实现因果实体在视频扩散中的定位。

Result: Causal-VidSyn在帧质量和因果敏感性方面优于现有视频扩散模型，支持多种任务（如视频编辑、文本到视频生成）。

Conclusion: Causal-VidSyn为合成具有因果关系的交通事故视频提供了有效方法，并构建了最大的驾驶员注视数据集Drive-Gaze。

Abstract: Egocentricly comprehending the causes and effects of car accidents is crucial
for the safety of self-driving cars, and synthesizing causal-entity reflected
accident videos can facilitate the capability test to respond to unaffordable
accidents in reality. However, incorporating causal relations as seen in
real-world videos into synthetic videos remains challenging. This work argues
that precisely identifying the accident participants and capturing their
related behaviors are of critical importance. In this regard, we propose a
novel diffusion model, Causal-VidSyn, for synthesizing egocentric traffic
accident videos. To enable causal entity grounding in video diffusion,
Causal-VidSyn leverages the cause descriptions and driver fixations to identify
the accident participants and behaviors, facilitated by accident reason
answering and gaze-conditioned selection modules. To support Causal-VidSyn, we
further construct Drive-Gaze, the largest driver gaze dataset (with 1.54M
frames of fixations) in driving accident scenarios. Extensive experiments show
that Causal-VidSyn surpasses state-of-the-art video diffusion models in terms
of frame quality and causal sensitivity in various tasks, including accident
video editing, normal-to-accident video diffusion, and text-to-video
generation.

</details>


### [179] [Ella: Embodied Social Agents with Lifelong Memory](https://arxiv.org/abs/2506.24019)
*Hongxin Zhang,Zheyuan Zhang,Zeyuan Wang,Zunzhe Zhang,Lixing Fang,Qinhong Zhou,Chuang Gan*

Main category: cs.CV

Relevance: 40.0

TL;DR: Ella是一个能够在3D开放世界中通过视觉观察和社交互动进行终身学习的社交代理，其核心是一个结构化的多模态记忆系统。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索如何通过结合结构化记忆系统和基础模型，提升具身智能体的学习能力和社交互动能力。

Method: Ella采用了一个长期多模态记忆系统，包括语义记忆和情景记忆，并与基础模型集成，用于决策和社交活动。

Result: 实验表明，Ella能够通过观察和社交互动有效学习，并与其他代理合作达成目标。

Conclusion: 结合结构化记忆系统和基础模型对推进具身智能具有变革性潜力。

Abstract: We introduce Ella, an embodied social agent capable of lifelong learning
within a community in a 3D open world, where agents accumulate experiences and
acquire knowledge through everyday visual observations and social interactions.
At the core of Ella's capabilities is a structured, long-term multimodal memory
system that stores, updates, and retrieves information effectively. It consists
of a name-centric semantic memory for organizing acquired knowledge and a
spatiotemporal episodic memory for capturing multimodal experiences. By
integrating this lifelong memory system with foundation models, Ella retrieves
relevant information for decision-making, plans daily activities, builds social
relationships, and evolves autonomously while coexisting with other intelligent
beings in the open world. We conduct capability-oriented evaluations in a
dynamic 3D open world where 15 agents engage in social activities for days and
are assessed with a suite of unseen controlled evaluations. Experimental
results show that Ella can influence, lead, and cooperate with other agents
well to achieve goals, showcasing its ability to learn effectively through
observation and social interaction. Our findings highlight the transformative
potential of combining structured memory systems with foundation models for
advancing embodied intelligence. More videos can be found at
https://umass-embodied-agi.github.io/Ella/.

</details>


### [180] [Why Settle for One? Text-to-ImageSet Generation and Evaluation](https://arxiv.org/abs/2506.23275)
*Chengyou Jia,Xin Shen,Zhuohang Dang,Zhuohang Dang,Changliang Xia,Weijia Wu,Xinyu Zhang,Hangwei Qian,Ivor W. Tsang,Minnan Luo*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种新的文本到图像集（T2IS）生成问题，并开发了T2IS-Bench基准和T2IS-Eval评估框架，以及无需训练的AutoT2IS方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成具有多样一致性需求的图像集时泛化能力不足，因此需要一种更通用的解决方案。

Method: 引入T2IS-Bench基准和T2IS-Eval评估框架，提出基于预训练Diffusion Transformers的AutoT2IS方法。

Result: AutoT2IS在T2IS-Bench上显著优于现有方法，并展示了实际应用潜力。

Conclusion: AutoT2IS为T2IS生成提供了高效且通用的解决方案，具有实际应用价值。

Abstract: Despite remarkable progress in Text-to-Image models, many real-world
applications require generating coherent image sets with diverse consistency
requirements. Existing consistent methods often focus on a specific domain with
specific aspects of consistency, which significantly constrains their
generalizability to broader applications. In this paper, we propose a more
challenging problem, Text-to-ImageSet (T2IS) generation, which aims to generate
sets of images that meet various consistency requirements based on user
instructions. To systematically study this problem, we first introduce
$\textbf{T2IS-Bench}$ with 596 diverse instructions across 26 subcategories,
providing comprehensive coverage for T2IS generation. Building on this, we
propose $\textbf{T2IS-Eval}$, an evaluation framework that transforms user
instructions into multifaceted assessment criteria and employs effective
evaluators to adaptively assess consistency fulfillment between criteria and
generated sets. Subsequently, we propose $\textbf{AutoT2IS}$, a training-free
framework that maximally leverages pretrained Diffusion Transformers'
in-context capabilities to harmonize visual elements to satisfy both
image-level prompt alignment and set-level visual consistency. Extensive
experiments on T2IS-Bench reveal that diverse consistency challenges all
existing methods, while our AutoT2IS significantly outperforms current
generalized and even specialized approaches. Our method also demonstrates the
ability to enable numerous underexplored real-world applications, confirming
its substantial practical value. Visit our project in
https://chengyou-jia.github.io/T2IS-Home.

</details>


### [181] [Autoregressive Denoising Score Matching is a Good Video Anomaly Detector](https://arxiv.org/abs/2506.23282)
*Hanwen Zhang,Congqi Cao,Qinyi Lv,Lingtong Min,Yanning Zhang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 本文提出了一种基于噪声条件评分变换器的视频异常检测方法，通过场景依赖和运动感知的评分函数以及自回归去噪机制，解决了传统似然方法对局部模式异常的盲区问题。


<details>
  <summary>Details</summary>
Motivation: 视频异常检测中，传统似然方法无法检测位于学习分布附近局部模式的异常。本文旨在解决这一盲区问题。

Method: 1. 构建噪声条件评分变换器进行去噪评分匹配。2. 引入场景依赖和运动感知的评分函数。3. 提出自回归去噪评分匹配机制以增强异常感知。

Result: 在三个流行的视频异常检测基准测试中，该方法达到了最先进的性能。

Conclusion: 通过综合考虑场景、运动和外观三个方面的差异，本文方法能够更全面地检测异常。

Abstract: Video anomaly detection (VAD) is an important computer vision problem. Thanks
to the mode coverage capabilities of generative models, the likelihood-based
paradigm is catching growing interest, as it can model normal distribution and
detect out-of-distribution anomalies. However, these likelihood-based methods
are blind to the anomalies located in local modes near the learned
distribution. To handle these ``unseen" anomalies, we dive into three gaps
uniquely existing in VAD regarding scene, motion and appearance. Specifically,
we first build a noise-conditioned score transformer for denoising score
matching. Then, we introduce a scene-dependent and motion-aware score function
by embedding the scene condition of input sequences into our model and
assigning motion weights based on the difference between key frames of input
sequences. Next, to solve the problem of blindness in principle, we integrate
unaffected visual information via a novel autoregressive denoising score
matching mechanism for inference. Through autoregressively injecting
intensifying Gaussian noise into the denoised data and estimating the
corresponding score function, we compare the denoised data with the original
data to get a difference and aggregate it with the score function for an
enhanced appearance perception and accumulate the abnormal context. With all
three gaps considered, we can compute a more comprehensive anomaly indicator.
Experiments on three popular VAD benchmarks demonstrate the state-of-the-art
performance of our method.

</details>


### [182] [Competitive Distillation: A Simple Learning Strategy for Improving Visual Classification](https://arxiv.org/abs/2506.23285)
*Daqian Shi,Xiaolei Diao,Xu Chen,Cédric M. John*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种新颖的竞争蒸馏策略，通过动态选择教师网络和引入随机扰动，提升多网络协同训练的性能。


<details>
  <summary>Details</summary>
Motivation: 现有蒸馏方法因对网络间学习方向影响的理解不足，性能提升有限。

Method: 提出竞争蒸馏策略，动态选择教师网络，引入竞争优化和随机扰动。

Result: 在多种任务和数据集上表现出色。

Conclusion: 竞争蒸馏通过动态竞争和扰动优化，显著提升了训练性能。

Abstract: Deep Neural Networks (DNNs) have significantly advanced the field of computer
vision. To improve DNN training process, knowledge distillation methods
demonstrate their effectiveness in accelerating network training by introducing
a fixed learning direction from the teacher network to student networks. In
this context, several distillation-based optimization strategies are proposed,
e.g., deep mutual learning and self-distillation, as an attempt to achieve
generic training performance enhancement through the cooperative training of
multiple networks. However, such strategies achieve limited improvements due to
the poor understanding of the impact of learning directions among networks
across different iterations. In this paper, we propose a novel competitive
distillation strategy that allows each network in a group to potentially act as
a teacher based on its performance, enhancing the overall learning performance.
Competitive distillation organizes a group of networks to perform a shared task
and engage in competition, where competitive optimization is proposed to
improve the parameter updating process. We further introduce stochastic
perturbation in competitive distillation, aiming to motivate networks to induce
mutations to achieve better visual representations and global optimum. The
experimental results show that competitive distillation achieves promising
performance in diverse tasks and datasets.

</details>


### [183] [DDL: A Dataset for Interpretable Deepfake Detection and Localization in Real-World Scenarios](https://arxiv.org/abs/2506.23292)
*Changtao Miao,Yi Zhang,Weize Gao,Man Luo,Weiwei Feng,Zhiya Tan,Jianshu Li,Ajian Liu,Yunfeng Diao,Qi Chu,Tao Gong,Zhe Li,Weibin Yao,Joey Tianyi Zhou*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种新的大规模深度伪造检测和定位数据集（DDL），包含180万伪造样本和75种深度伪造方法，旨在解决现有数据集在多样性和规模上的不足，支持下一代检测和可解释性方法。


<details>
  <summary>Details</summary>
Motivation: 深度伪造内容的滥用问题日益严重，现有检测方法缺乏可解释性，且数据集在多样性和规模上不足，难以应对复杂现实场景。

Method: 构建了DDL数据集，包含多样伪造场景、全面深度伪造方法、多种操纵模式和细粒度伪造标注。

Result: DDL数据集提供了更具挑战性的基准，支持深度伪造检测、定位和可解释性方法的发展。

Conclusion: DDL数据集填补了现有数据集的不足，为复杂现实场景下的深度伪造检测提供了重要支持。

Abstract: Recent advances in AIGC have exacerbated the misuse of malicious deepfake
content, making the development of reliable deepfake detection methods an
essential means to address this challenge. Although existing deepfake detection
models demonstrate outstanding performance in detection metrics, most methods
only provide simple binary classification results, lacking interpretability. In
critical domains such as law, interpretability is crucial for enhancing the
credibility and authority of decisions. Recent studies attempt to improve the
interpretability of classification results by providing spatial manipulation
masks or temporal forgery segments. However, the practical effectiveness of
these methods remains suboptimal due to limitations of the forgery data. Most
current deepfake datasets predominantly offer binary labels, only a few
datasets with localization annotations. However, they suffer from restricted
forgery scenarios, limited diversity in deepfake types, and insufficient data
scale, making them inadequate for complex real-world scenarios. To address this
predicament, we construct a novel large-scale deepfake detection and
localization ($\textbf{DDL}$) dataset containing over $\textbf{1.8M}$ forged
samples and encompassing up to $\textbf{75}$ distinct deepfake methods. The DDL
design incorporates four key innovations: (1) $\textbf{Diverse Forgery
Scenarios}$, (2) $\textbf{Comprehensive Deepfake Methods}$, (3) $\textbf{Varied
Manipulation Modes}$, and (4) $\textbf{Fine-grained Forgery Annotations}$.
Through these improvements, our DDL not only provides a more challenging
benchmark for complex real-world forgeries, but also offers crucial support for
building next-generation deepfake detection, localization, and interpretability
methods. The DDL dataset project page is on
https://deepfake-workshop-ijcai2025.github.io/main/index.html.

</details>


### [184] [FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method](https://arxiv.org/abs/2506.23323)
*Quang-Huy Che,Vinh-Tiep Nguyen*

Main category: cs.CV

Relevance: 40.0

TL;DR: FastSeg is a training-free framework for open-vocabulary semantic segmentation, leveraging a pretrained diffusion model with minimal steps and innovative components to achieve high efficiency and quality.


<details>
  <summary>Details</summary>
Motivation: Address the trade-off between segmentation quality and inference efficiency in diffusion-based models for open-vocabulary semantic segmentation.

Method: Uses a (1+1)-step reverse process of a pretrained diffusion model, a dual-prompt mechanism, Hierarchical Attention Refinement Method (HARD), and Test-Time Flipping (TTF).

Result: Achieves 43.8% average mIoU on benchmarks (PASCAL VOC, PASCAL Context, COCO Object) with superior efficiency.

Conclusion: FastSeg bridges the gap between segmentation quality and inference efficiency, offering a strong foundation for extendability.

Abstract: Open-vocabulary semantic segmentation (OVSS) aims to segment objects from
arbitrary text categories without requiring densely annotated datasets.
Although contrastive learning based models enable zero-shot segmentation, they
often lose fine spatial precision at pixel level, due to global representation
bias. In contrast, diffusion-based models naturally encode fine-grained spatial
features via attention mechanisms that capture both global context and local
details. However, they often face challenges in balancing the number of
iterations with the quality of the segmentation. In this work, we propose
FastSeg, a novel and efficient training-free framework with only (1+1)-step of
reverse process of a pretrained diffusion model (e.g., Stable Diffusion).
Moreover, instead of running multiple times for different classes, FastSeg
performs segmentation for all classes at once. To further enhance the
segmentation quality, FastSeg introduces three key components: (i) a
dual-prompt mechanism for discriminative, class-aware attention extraction,
(ii) a Hierarchical Attention Refinement Method (HARD) that enhances fused
cross-attention using scale-aligned selfattention maps, and (iii) a Test-Time
Flipping (TTF) scheme designed to improve spatial consistency. Extensive
experiments show that FastSeg achieves state-of-the-art training-free
performance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context,
and COCO Object benchmarks while maintaining superior inference efficiency. Our
results demonstrate that FastSeg provides a strong foundation for
extendability, bridging the gap between segmentation quality and inference
efficiency.

</details>


### [185] [IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering](https://arxiv.org/abs/2506.23329)
*Parker Liu,Chenxin Li,Zhengxin Li,Yipeng Wu,Wuyang Li,Zhiqin Yang,Zhenyuan Zhang,Yunlong Lin,Sirui Han,Brandon Y. Feng*

Main category: cs.CV

Relevance: 40.0

TL;DR: IR3D-Bench是一个新的基准测试，通过要求视觉语言模型（VLMs）使用工具主动重建图像的3D结构，评估其对场景的真实理解能力。


<details>
  <summary>Details</summary>
Motivation: 传统VLMs在描述性任务上表现优异，但其是否真正理解场景尚不确定。本文旨在通过“通过创造理解”的方法，探索VLMs的工具使用和生成能力。

Method: 基于分析-合成范式，IR3D-Bench要求视觉语言代理（VLAs）使用编程和渲染工具重建输入图像的3D结构。提供了一套全面的评估指标，包括几何精度、空间关系、外观属性和整体合理性。

Result: 初步实验显示，当前最先进的VLMs在视觉精度方面存在局限性，而非基本工具使用。

Conclusion: IR3D-Bench为系统研究和开发工具使用的VLAs提供了数据和评估协议，以促进真正的场景理解。

Abstract: Vision-language models (VLMs) excel at descriptive tasks, but whether they
truly understand scenes from visual observations remains uncertain. We
introduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding
through active creation rather than passive recognition. Grounded in the
analysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs)
with actively using programming and rendering tools to recreate the underlying
3D structure of an input image, achieving agentic inverse rendering through
tool use. This "understanding-by-creating" approach probes the tool-using
generative capacity of VLAs, moving beyond the descriptive or conversational
capacity measured by traditional scene understanding benchmarks. We provide a
comprehensive suite of metrics to evaluate geometric accuracy, spatial
relations, appearance attributes, and overall plausibility. Initial experiments
on agentic inverse rendering powered by various state-of-the-art VLMs highlight
current limitations, particularly in visual precision rather than basic tool
usage. IR3D-Bench, including data and evaluation protocols, is released to
facilitate systematic study and development of tool-using VLAs towards genuine
scene understanding by creating.

</details>


### [186] [CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation](https://arxiv.org/abs/2506.23347)
*Yi Liu,Shengqian Li,Zuzeng Lin,Feng Wang,Si Liu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种名为CycleVAR的新方法，通过Softmax Relaxed Quantization解决传统量化方法在图像翻译中的梯度流问题，实现了端到端优化。


<details>
  <summary>Details</summary>
Motivation: 现有条件自回归图像生成方法在无监督图像翻译领域潜力未充分挖掘，传统量化方法阻碍了端到端优化。

Method: 采用Softmax Relaxed Quantization保持梯度传播，提出CycleVAR，将图像翻译视为图像条件自回归生成，支持串行多步和并行一步生成模式。

Result: 并行一步生成模式在无监督场景下表现更优，CycleVAR超越了现有最佳模型（如CycleGAN-Turbo）。

Conclusion: CycleVAR通过改进量化方法和生成模式，显著提升了无监督图像翻译的性能和效率。

Abstract: The current conditional autoregressive image generation methods have shown
promising results, yet their potential remains largely unexplored in the
practical unsupervised image translation domain, which operates without
explicit cross-domain correspondences. A critical limitation stems from the
discrete quantization inherent in traditional Vector Quantization-based
frameworks, which disrupts gradient flow between the Variational Autoencoder
decoder and causal Transformer, impeding end-to-end optimization during
adversarial training in image space. To tackle this issue, we propose using
Softmax Relaxed Quantization, a novel approach that reformulates codebook
selection as a continuous probability mixing process via Softmax, thereby
preserving gradient propagation. Building upon this differentiable foundation,
we introduce CycleVAR, which reformulates image-to-image translation as
image-conditional visual autoregressive generation by injecting multi-scale
source image tokens as contextual prompts, analogous to prefix-based
conditioning in language models. CycleVAR exploits two modes to generate the
target image tokens, including (1) serial multi-step generation, enabling
iterative refinement across scales, and (2) parallel one-step generation
synthesizing all resolution outputs in a single forward pass. Experimental
findings indicate that the parallel one-step generation mode attains superior
translation quality with quicker inference speed than the serial multi-step
mode in unsupervised scenarios. Furthermore, both quantitative and qualitative
results indicate that CycleVAR surpasses previous state-of-the-art unsupervised
image translation models, \textit{e}.\textit{g}., CycleGAN-Turbo.

</details>


### [187] [GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields](https://arxiv.org/abs/2506.23352)
*Shunsuke Yasuki,Taiki Miyanishi,Nakamasa Inoue,Shuhei Kurita,Koya Sakamoto,Daichi Azuma,Masato Taki,Yutaka Matsuo*

Main category: cs.CV

Relevance: 40.0

TL;DR: GeoProg3D是一个视觉编程框架，通过自然语言实现与城市规模高保真3D场景的交互，结合地理感知和LLM推理能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D语言方法在小规模环境中表现良好，但缺乏处理大规模复杂城市环境的能力。GeoProg3D旨在解决这一限制。

Method: GeoProg3D包含两个关键组件：地理感知的城市规模3D语言场（GCLF）和地理视觉API（GV-APIs），利用LLM作为推理引擎动态组合工具。

Result: 在GeoEval3D基准测试中，GeoProg3D在多种任务上显著优于现有3D语言和视觉语言模型。

Conclusion: GeoProg3D是首个通过自然语言实现城市规模3D环境中组合地理推理的框架。

Abstract: The advancement of 3D language fields has enabled intuitive interactions with
3D scenes via natural language. However, existing approaches are typically
limited to small-scale environments, lacking the scalability and compositional
reasoning capabilities necessary for large, complex urban settings. To overcome
these limitations, we propose GeoProg3D, a visual programming framework that
enables natural language-driven interactions with city-scale high-fidelity 3D
scenes. GeoProg3D consists of two key components: (i) a Geography-aware
City-scale 3D Language Field (GCLF) that leverages a memory-efficient
hierarchical 3D model to handle large-scale data, integrated with geographic
information for efficiently filtering vast urban spaces using directional cues,
distance measurements, elevation data, and landmark references; and (ii)
Geographical Vision APIs (GV-APIs), specialized geographic vision tools such as
area segmentation and object detection. Our framework employs large language
models (LLMs) as reasoning engines to dynamically combine GV-APIs and operate
GCLF, effectively supporting diverse geographic vision tasks. To assess
performance in city-scale reasoning, we introduce GeoEval3D, a comprehensive
benchmark dataset containing 952 query-answer pairs across five challenging
tasks: grounding, spatial reasoning, comparison, counting, and measurement.
Experiments demonstrate that GeoProg3D significantly outperforms existing 3D
language fields and vision-language models across multiple tasks. To our
knowledge, GeoProg3D is the first framework enabling compositional geographic
reasoning in high-fidelity city-scale 3D environments via natural language. The
code is available at https://snskysk.github.io/GeoProg3D/.

</details>


### [188] [OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions](https://arxiv.org/abs/2506.23361)
*Yuanhao Cai,He Zhang,Xi Chen,Jinbo Xing,Yiwei Hu,Yuqian Zhou,Kai Zhang,Zhifei Zhang,Soo Ye Kim,Tianyu Wang,Yulun Zhang,Xiaokang Yang,Zhe Lin,Alan Yuille*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种多主体视频定制方法，包括数据构造管道VideoCus-Factory和扩散Transformer框架OmniVCus，支持多主体和控制信号编辑。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法局限于单主体场景且缺乏控制信号编辑的问题。

Method: 1. 数据构造管道VideoCus-Factory生成多主体训练数据；2. 图像-视频混合训练（IVTM）；3. 扩散Transformer框架OmniVCus，包含Lottery Embedding和Temporally Aligned Embedding机制。

Result: 在定量和定性评估中显著优于现有方法。

Conclusion: 方法在多主体视频定制和控制信号编辑方面具有优势。

Abstract: Existing feedforward subject-driven video customization methods mainly study
single-subject scenarios due to the difficulty of constructing multi-subject
training data pairs. Another challenging problem that how to use the signals
such as depth, mask, camera, and text prompts to control and edit the subject
in the customized video is still less explored. In this paper, we first propose
a data construction pipeline, VideoCus-Factory, to produce training data pairs
for multi-subject customization from raw videos without labels and control
signals such as depth-to-video and mask-to-video pairs. Based on our
constructed data, we develop an Image-Video Transfer Mixed (IVTM) training with
image editing data to enable instructive editing for the subject in the
customized video. Then we propose a diffusion Transformer framework, OmniVCus,
with two embedding mechanisms, Lottery Embedding (LE) and Temporally Aligned
Embedding (TAE). LE enables inference with more subjects by using the training
subjects to activate more frame embeddings. TAE encourages the generation
process to extract guidance from temporally aligned control signals by
assigning the same frame embeddings to the control and noise tokens.
Experiments demonstrate that our method significantly surpasses
state-of-the-art methods in both quantitative and qualitative evaluations.
Video demos are at our project page:
https://caiyuanhao1998.github.io/project/OmniVCus/. Our code will be released
at https://github.com/caiyuanhao1998/Open-OmniVCus

</details>


### [189] [SIEDD: Shared-Implicit Encoder with Discrete Decoders](https://arxiv.org/abs/2506.23382)
*Vikram Rangarajan,Shishira Maiya,Max Ehrlich,Abhinav Shrivastava*

Main category: cs.CV

Relevance: 40.0

TL;DR: SIEDD是一种新型架构，通过共享编码器和离散解码器显著加速了隐式神经表示（INR）的视频编码速度，同时保持了重建质量和坐标级控制。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INR）在视频压缩中具有高保真度，但编码速度过慢限制了其实际应用。现有加速方法通常牺牲重建质量或坐标级控制。

Method: SIEDD采用共享编码器快速捕捉全局低频特征，随后冻结编码器并并行训练轻量级离散解码器，结合坐标空间采样实现加速。

Result: 在HD和4K基准测试中，SIEDD实现了20-30倍的编码速度提升，同时保持竞争性的重建质量和压缩比。

Conclusion: SIEDD显著提升了高保真神经视频压缩的实用性，为实际部署提供了高效可扩展的路径。

Abstract: Implicit Neural Representations (INRs) offer exceptional fidelity for video
compression by learning per-video optimized functions, but their adoption is
crippled by impractically slow encoding times. Existing attempts to accelerate
INR encoding often sacrifice reconstruction quality or crucial coordinate-level
control essential for adaptive streaming and transcoding. We introduce SIEDD
(Shared-Implicit Encoder with Discrete Decoders), a novel architecture that
fundamentally accelerates INR encoding without these compromises. SIEDD first
rapidly trains a shared, coordinate-based encoder on sparse anchor frames to
efficiently capture global, low-frequency video features. This encoder is then
frozen, enabling massively parallel training of lightweight, discrete decoders
for individual frame groups, further expedited by aggressive coordinate-space
sampling. This synergistic design delivers a remarkable 20-30X encoding
speed-up over state-of-the-art INR codecs on HD and 4K benchmarks, while
maintaining competitive reconstruction quality and compression ratios.
Critically, SIEDD retains full coordinate-based control, enabling continuous
resolution decoding and eliminating costly transcoding. Our approach
significantly advances the practicality of high-fidelity neural video
compression, demonstrating a scalable and efficient path towards real-world
deployment. Our codebase is available at
https://github.com/VikramRangarajan/SIEDD .

</details>


### [190] [DriveBLIP2: Attention-Guided Explanation Generation for Complex Driving Scenarios](https://arxiv.org/abs/2506.22494)
*Shihong Ling,Yue Wan,Xiaowei Jia,Na Du*

Main category: cs.RO

Relevance: 40.0

TL;DR: DriveBLIP2框架基于BLIP2-OPT架构，通过注意力图生成器提升自动驾驶场景中的解释能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在复杂多目标环境中表现不佳，尤其在实时自动驾驶场景中。

Method: 提出注意力图生成器，突出关键对象以生成清晰解释。

Result: 在DRAMA数据集上，BLEU、ROUGE、CIDEr和SPICE分数显著提升。

Conclusion: 针对性注意力机制可增强实时自动驾驶中的可解释性。

Abstract: This paper introduces a new framework, DriveBLIP2, built upon the BLIP2-OPT
architecture, to generate accurate and contextually relevant explanations for
emerging driving scenarios. While existing vision-language models perform well
in general tasks, they encounter difficulties in understanding complex,
multi-object environments, particularly in real-time applications such as
autonomous driving, where the rapid identification of key objects is crucial.
To address this limitation, an Attention Map Generator is proposed to highlight
significant objects relevant to driving decisions within critical video frames.
By directing the model's focus to these key regions, the generated attention
map helps produce clear and relevant explanations, enabling drivers to better
understand the vehicle's decision-making process in critical situations.
Evaluations on the DRAMA dataset reveal significant improvements in explanation
quality, as indicated by higher BLEU, ROUGE, CIDEr, and SPICE scores compared
to baseline models. These findings underscore the potential of targeted
attention mechanisms in vision-language models for enhancing explainability in
real-time autonomous driving.

</details>


### [191] [Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles](https://arxiv.org/abs/2506.23426)
*Menna Taha,Aya Ahmed,Mohammed Karmoose,Yasser Gadallah*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种新的目标检测方法，将重点从传统的基于类别的分类转向对象危害性判定，以解决自动驾驶车辆（AV）在检测和应对分布外（OOD）对象时的安全问题。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测方法无法有效识别OOD对象，可能导致AV决策失误和安全隐患。因此，研究旨在通过判定对象危害性来提升AV的安全性。

Method: 方法基于对象相对于AV的位置和轨迹，将其分类为‘有害’或‘无害’，而非传统的类别分类。

Result: 实验结果表明，该方法能有效检测OOD对象并评估其危害性，从而提升AV在动态环境中的决策效果。

Conclusion: 该方法通过危害性判定增强了AV对OOD对象的检测能力，提升了安全性。

Abstract: Autonomous vehicles (AVs) use object detection models to recognize their
surroundings and make driving decisions accordingly. Conventional object
detection approaches classify objects into known classes, which limits the AV's
ability to detect and appropriately respond to Out-of-Distribution (OOD)
objects. This problem is a significant safety concern since the AV may fail to
detect objects or misclassify them, which can potentially lead to hazardous
situations such as accidents. Consequently, we propose a novel object detection
approach that shifts the emphasis from conventional class-based classification
to object harmfulness determination. Instead of object detection by their
specific class, our method identifies them as either 'harmful' or 'harmless'
based on whether they pose a danger to the AV. This is done based on the object
position relative to the AV and its trajectory. With this metric, our model can
effectively detect previously unseen objects to enable the AV to make safer
real-time decisions. Our results demonstrate that the proposed model
effectively detects OOD objects, evaluates their harmfulness, and classifies
them accordingly, thus enhancing the AV decision-making effectiveness in
dynamic environments.

</details>


### [192] [Towards foundational LiDAR world models with efficient latent flow matching](https://arxiv.org/abs/2506.23434)
*Tianran Liu,Shengwen Zhao,Nicholas Rhinehart*

Main category: cs.CV

Relevance: 40.0

TL;DR: 该论文研究了LiDAR世界模型的跨领域迁移能力，提出了一个基于条件流匹配的框架，显著提高了模型的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR世界模型局限于特定领域，缺乏跨领域迁移能力。本文旨在开发具有强迁移能力的LiDAR模型，减少对标注数据的依赖。

Method: 通过系统性的领域迁移研究，提出基于条件流匹配（CFM）的框架，优化LiDAR数据的压缩和训练目标。

Result: 模型在多个场景中表现优异，仅需5%标注数据即可超越现有方法，计算效率提升23倍。

Conclusion: 提出的CFM框架显著提升了LiDAR世界模型的迁移能力和效率，为语义占用预测等领域提供了高效解决方案。

Abstract: LiDAR-based world models offer more structured and geometry-aware
representations than their image-based counterparts. However, existing LiDAR
world models are narrowly trained; each model excels only in the domain for
which it was built. Can we develop LiDAR world models that exhibit strong
transferability across multiple domains? We conduct the first systematic domain
transfer study across three demanding scenarios: (i) outdoor to indoor
generalization, (ii) sparse-beam \& dense-beam adaptation, and (iii)
non-semantic to semantic transfer. Given different amounts of fine-tuning data,
our experiments show that a single pre-trained model can achieve up to 11%
absolute improvement (83\% relative) over training from scratch and outperforms
training from scratch in 30/36 of our comparisons. This transferability of
dynamic learning significantly reduces the reliance on manually annotated data
for semantic occupancy forecasting: our method exceed the previous semantic
occupancy forecasting models with only 5% of the labeled training data required
by prior models. We also observed inefficiencies of current LiDAR world models,
mainly through their under-compression of LiDAR data and inefficient training
objectives. To address this, we propose a latent conditional flow matching
(CFM)-based frameworks that achieves state-of-the-art reconstruction accuracy
using only half the training data and a compression ratio 6 times higher than
that of prior methods. Our model achieves SOTA performance on
future-trajectory-conditioned semantic occupancy forecasting while being 23x
more computationally efficient (a 28x FPS speedup); and achieves SOTA
performance on semantic occupancy forecasting while being 2x more
computationally efficient (a 1.1x FPS speedup).

</details>


### [193] [PathDiff: Histopathology Image Synthesis with Unpaired Text and Mask Conditions](https://arxiv.org/abs/2506.23440)
*Mahesh Bhosale,Abdul Wasi,Yuanhao Zhai,Yunjie Tian,Samuel Border,Nan Xi,Pinaki Sarder,Junsong Yuan,David Doermann,Xuan Gong*

Main category: cs.CV

Relevance: 40.0

TL;DR: PathDiff是一个扩散框架，利用未配对的文本和掩码数据生成高质量的病理图像，提升下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决病理图像数据稀缺问题，同时结合文本和掩码数据以增强生成图像的语义和空间控制。

Method: 提出PathDiff框架，将未配对的文本和掩码数据整合到统一的条件空间中，生成高质量图像。

Result: PathDiff在图像保真度、文本-图像对齐和下游任务（如核分割和分类）中表现优于现有方法。

Conclusion: PathDiff通过结合文本和掩码数据，显著提升了病理图像生成的质量和控制能力。

Abstract: Diffusion-based generative models have shown promise in synthesizing
histopathology images to address data scarcity caused by privacy constraints.
Diagnostic text reports provide high-level semantic descriptions, and masks
offer fine-grained spatial structures essential for representing distinct
morphological regions. However, public datasets lack paired text and mask data
for the same histopathological images, limiting their joint use in image
generation. This constraint restricts the ability to fully exploit the benefits
of combining both modalities for enhanced control over semantics and spatial
details. To overcome this, we propose PathDiff, a diffusion framework that
effectively learns from unpaired mask-text data by integrating both modalities
into a unified conditioning space. PathDiff allows precise control over
structural and contextual features, generating high-quality, semantically
accurate images. PathDiff also improves image fidelity, text-image alignment,
and faithfulness, enhancing data augmentation for downstream tasks like nuclei
segmentation and classification. Extensive experiments demonstrate its
superiority over existing methods.

</details>


### [194] [Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.23460)
*Dewen Zeng,Xinrong Hu,Yu-Jen Chen,Yawen Wu,Xiaowei Xu,Yiyu Shi*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为CLDF的新方法，通过对比学习将扩散模型的特征映射到低维嵌入空间，用于弱监督语义分割，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 传统CAM方法在弱监督语义分割中存在部分激活和边界不精确的问题，而基于条件扩散模型的方法虽然能生成分割掩码，但容易受到反向扩散中背景噪声的影响。

Method: 引入CLDF方法，利用对比学习训练像素解码器，将冻结的条件扩散模型的特征映射到低维嵌入空间，并结合梯度图和CAM以减少假阳性/阴性。

Result: 在两个公共医学数据集上的四个分割任务中，CLDF显著优于现有基线。

Conclusion: CLDF通过结合扩散模型和对比学习，有效解决了弱监督语义分割中的噪声问题，提升了分割性能。

Abstract: Weakly supervised semantic segmentation (WSSS) methods using class labels
often rely on class activation maps (CAMs) to localize objects. However,
traditional CAM-based methods struggle with partial activations and imprecise
object boundaries due to optimization discrepancies between classification and
segmentation. Recently, the conditional diffusion model (CDM) has been used as
an alternative for generating segmentation masks in WSSS, leveraging its strong
image generation capabilities tailored to specific class distributions. By
modifying or perturbing the condition during diffusion sampling, the related
objects can be highlighted in the generated images. Yet, the saliency maps
generated by CDMs are prone to noise from background alterations during reverse
diffusion. To alleviate the problem, we introduce Contrastive Learning with
Diffusion Features (CLDF), a novel method that uses contrastive learning to
train a pixel decoder to map the diffusion features from a frozen CDM to a
low-dimensional embedding space for segmentation. Specifically, we integrate
gradient maps generated from CDM external classifier with CAMs to identify
foreground and background pixels with fewer false positives/negatives for
contrastive learning, enabling robust pixel embedding learning. Experimental
results on four segmentation tasks from two public medical datasets demonstrate
that our method significantly outperforms existing baselines.

</details>


### [195] [Sanitizing Manufacturing Dataset Labels Using Vision-Language Models](https://arxiv.org/abs/2506.23465)
*Nazanin Mahjourian,Vinh Nguyen*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种基于视觉-语言的方法（VLSR），用于多标签制造图像数据集的标签清洗和优化，利用CLIP模型在共享语义空间中嵌入图像和文本标签，通过余弦相似度和聚类提升标签质量。


<details>
  <summary>Details</summary>
Motivation: 工业应用中，大规模数据集（尤其是众包和网络爬取的数据）常存在标签噪声和不一致问题，而高质量标签获取成本高。VLSR旨在自动化解决这一问题。

Method: 利用CLIP模型将图像和文本标签嵌入共享语义空间，通过余弦相似度清洗标签，并通过密度聚类合并语义相似的标签。

Result: 在Factorynet数据集上，VLSR成功识别问题标签并提升一致性，显著减少标签词汇量。

Conclusion: VLSR能高效提升工业应用数据集的标签质量，减少人工干预。

Abstract: The success of machine learning models in industrial applications is heavily
dependent on the quality of the datasets used to train the models. However,
large-scale datasets, specially those constructed from crowd-sourcing and
web-scraping, often suffer from label noise, inconsistencies, and errors. This
problem is particularly pronounced in manufacturing domains, where obtaining
high-quality labels is costly and time-consuming. This paper introduces
Vision-Language Sanitization and Refinement (VLSR), which is a
vision-language-based framework for label sanitization and refinement in
multi-label manufacturing image datasets. This method embeds both images and
their associated textual labels into a shared semantic space leveraging the
CLIP vision-language model. Then two key tasks are addressed in this process by
computing the cosine similarity between embeddings. First, label sanitization
is performed to identify irrelevant, misspelled, or semantically weak labels,
and surface the most semantically aligned label for each image by comparing
image-label pairs using cosine similarity between image and label embeddings.
Second, the method applies density-based clustering on text embeddings,
followed by iterative cluster merging, to group semantically similar labels
into unified label groups. The Factorynet dataset, which includes noisy labels
from both human annotations and web-scraped sources, is employed to evaluate
the effectiveness of the proposed framework. Experimental results demonstrate
that the VLSR framework successfully identifies problematic labels and improves
label consistency. This method enables a significant reduction in label
vocabulary through clustering, which ultimately enhances the dataset's quality
for training robust machine learning models in industrial applications with
minimal human intervention.

</details>


### [196] [NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments](https://arxiv.org/abs/2506.23468)
*Xuan Yao,Junyu Gao,Changsheng Xu*

Main category: cs.CV

Relevance: 40.0

TL;DR: NavMorph是一个自演进的世界模型框架，用于提升视觉与语言导航任务中的环境理解和决策能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法在新环境中的泛化能力和导航过程中的动态适应能力不足，受人类认知启发，提出NavMorph框架。

Method: 使用紧凑的潜在表示建模环境动态，结合Contextual Evolution Memory支持场景上下文信息，实现自适应规划和策略优化。

Result: 在VLN-CE基准测试中表现显著提升。

Conclusion: NavMorph通过自演进模型和上下文记忆增强了导航任务的适应性和性能。

Abstract: Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires
agents to execute sequential navigation actions in complex environments guided
by natural language instructions. Current approaches often struggle with
generalizing to novel environments and adapting to ongoing changes during
navigation. Inspired by human cognition, we present NavMorph, a self-evolving
world model framework that enhances environmental understanding and
decision-making in VLN-CE tasks. NavMorph employs compact latent
representations to model environmental dynamics, equipping agents with
foresight for adaptive planning and policy refinement. By integrating a novel
Contextual Evolution Memory, NavMorph leverages scene-contextual information to
support effective navigation while maintaining online adaptability. Extensive
experiments demonstrate that our method achieves notable performance
improvements on popular VLN-CE benchmarks. Code is available at
\href{https://github.com/Feliciaxyao/NavMorph}{this https URL}.

</details>


### [197] [MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting](https://arxiv.org/abs/2506.23482)
*Jun Huang,Ting Liu,Yihang Wu,Xiaochao Qu,Luoqi Liu,Xiaolin Hu*

Main category: cs.CV

Relevance: 40.0

TL;DR: MTADiffusion是一种用于对象修复的Mask-Text Alignment扩散模型，通过MTAPipeline自动标注掩码和详细描述，构建了MTADataset，并提出多任务训练策略和风格一致性损失，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像修复方法存在语义不对齐、结构扭曲和风格不一致的问题，需要一种更高效的解决方案。

Method: 提出MTADiffusion模型，结合MTAPipeline自动标注掩码和描述，构建MTADataset，采用多任务训练策略和风格一致性损失。

Result: 在BrushBench和EditBench上，MTADiffusion表现优于其他方法。

Conclusion: MTADiffusion通过改进语义对齐、结构稳定性和风格一致性，显著提升了图像修复性能。

Abstract: Advancements in generative models have enabled image inpainting models to
generate content within specific regions of an image based on provided prompts
and masks. However, existing inpainting methods often suffer from problems such
as semantic misalignment, structural distortion, and style inconsistency. In
this work, we present MTADiffusion, a Mask-Text Alignment diffusion model
designed for object inpainting. To enhance the semantic capabilities of the
inpainting model, we introduce MTAPipeline, an automatic solution for
annotating masks with detailed descriptions. Based on the MTAPipeline, we
construct a new MTADataset comprising 5 million images and 25 million mask-text
pairs. Furthermore, we propose a multi-task training strategy that integrates
both inpainting and edge prediction tasks to improve structural stability. To
promote style consistency, we present a novel inpainting style-consistency loss
using a pre-trained VGG network and the Gram matrix. Comprehensive evaluations
on BrushBench and EditBench demonstrate that MTADiffusion achieves
state-of-the-art performance compared to other methods.

</details>


### [198] [Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding](https://arxiv.org/abs/2506.23491)
*ZongHan Hsieh,Tzer-Jen Wei*

Main category: cs.CV

Relevance: 40.0

TL;DR: Qwen-GUI-3B是一个轻量级的视觉语言模型（VLM），专为图形用户界面（GUI）任务设计，性能与更大模型相当，且可在单GPU上训练。


<details>
  <summary>Details</summary>
Motivation: 解决大规模VLM计算资源需求高的问题，同时保持高性能。

Method: 结合跨平台多分辨率数据集、两阶段微调策略及数据去冗余方法。

Result: 在ScreenSpot等基准测试中表现优异，准确率达84.9%和86.4%。

Conclusion: Qwen-GUI-3B通过高效设计和数据策略，实现了高性能与低资源需求的平衡。

Abstract: This paper introduces Qwen-GUI-3B, a lightweight Vision-Language Model (VLM)
specifically designed for Graphical User Interface grounding tasks, achieving
performance competitive with significantly larger models. Unlike large-scale
VLMs (>7B parameters) that are computationally intensive and impractical for
consumer-grade hardware, Qwen-GUI-3B delivers strong grounding accuracy while
being fully trainable on a single GPU (RTX 4090). The model incorporates
several key innovations: (i) combine cross-platform, multi-resolution dataset
of 24K examples from diverse sources including mobile, desktop, and web GUI
screenshots to effectively address data scarcity in high-resolution desktop
environments; (ii) a two-stage fine-tuning strategy, where initial
cross-platform training establishes robust GUI understanding, followed by
specialized fine-tuning on high-resolution data to significantly enhance model
adaptability; and (iii) data curation and redundancy reduction strategies,
demonstrating that randomly sampling a smaller subset with reduced redundancy
achieves performance comparable to larger datasets, emphasizing data diversity
over sheer volume. Empirical evaluation on standard GUI grounding
benchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging
ScreenSpot-Pro, highlights Qwen-GUI-3B's exceptional accuracy, achieving 84.9%
on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B
parameters. Ablation studies validate the critical role of balanced sampling
and two-stage fine-tuning in enhancing robustness, particularly in
high-resolution desktop scenarios. The Qwen-GUI-3B is available at:
https://github.com/Han1018/Qwen-GUI-3B

</details>


### [199] [ViewPoint: Panoramic Video Generation with Pretrained Diffusion Models](https://arxiv.org/abs/2506.23513)
*Zixun Fang,Kai Zhu,Zhiheng Liu,Yu Liu,Wei Zhai,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种利用预训练视角视频模型生成全景视频的新框架，通过设计ViewPoint地图和Pano-Perspective注意力机制，解决了全景数据与视角数据之间的模态差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法因全景数据与视角数据之间的模态差距，难以生成高质量全景视频。本文旨在利用预训练视角视频模型解决这一问题。

Method: 设计了一种名为ViewPoint地图的全景表示方法，结合Pano-Perspective注意力机制，利用预训练视角先验并捕捉全景空间相关性。

Result: 实验表明，该方法能生成动态性强且空间一致的全景视频，性能优于现有方法。

Conclusion: 提出的框架有效解决了全景视频生成中的模态差距问题，实现了最先进的性能。

Abstract: Panoramic video generation aims to synthesize 360-degree immersive videos,
holding significant importance in the fields of VR, world models, and spatial
intelligence. Existing works fail to synthesize high-quality panoramic videos
due to the inherent modality gap between panoramic data and perspective data,
which constitutes the majority of the training data for modern diffusion
models. In this paper, we propose a novel framework utilizing pretrained
perspective video models for generating panoramic videos. Specifically, we
design a novel panorama representation named ViewPoint map, which possesses
global spatial continuity and fine-grained visual details simultaneously. With
our proposed Pano-Perspective attention mechanism, the model benefits from
pretrained perspective priors and captures the panoramic spatial correlations
of the ViewPoint map effectively. Extensive experiments demonstrate that our
method can synthesize highly dynamic and spatially consistent panoramic videos,
achieving state-of-the-art performance and surpassing previous methods.

</details>


### [200] [WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image](https://arxiv.org/abs/2506.23518)
*Jiwoo Park,Tae Eun Choi,Youngjun Jun,Seong Jae Hwang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种无需额外模块的扩散模型方法，通过自适应注意力操纵和噪声重新初始化来提升视图一致性。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在多视图合成中难以保持空间连续性的问题，同时避免复杂多步流程的低效性。

Method: 利用视图引导的变形技术，结合训练自由的自适应注意力操纵和噪声重新初始化。

Result: 通过适用于多视图数据集的综合指标框架，验证了该方法在不同扩散模型中提升视图一致性的有效性。

Conclusion: 该方法在保持高效的同时，显著提升了多视图合成的质量，具有广泛适用性。

Abstract: Generating high-quality novel views of a scene from a single image requires
maintaining structural coherence across different views, referred to as view
consistency. While diffusion models have driven advancements in novel view
synthesis, they still struggle to preserve spatial continuity across views.
Diffusion models have been combined with 3D models to address the issue, but
such approaches lack efficiency due to their complex multi-step pipelines. This
paper proposes a novel view-consistent image generation method which utilizes
diffusion models without additional modules. Our key idea is to enhance
diffusion models with a training-free method that enables adaptive attention
manipulation and noise reinitialization by leveraging view-guided warping to
ensure view consistency. Through our comprehensive metric framework suitable
for novel-view datasets, we show that our method improves view consistency
across various diffusion models, demonstrating its broader applicability.

</details>


### [201] [Lightweight Temporal Transformer Decomposition for Federated Autonomous Driving](https://arxiv.org/abs/2506.23523)
*Tuong Do,Binh X. Nguyen,Quang D. Tran,Erman Tjiputra,Te-Chuan Chiu,Anh Nguyen*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种轻量级时序Transformer分解方法，用于处理自动驾驶中的时序数据，降低模型复杂度并提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于视觉的自动驾驶系统在复杂环境中表现不佳，且现有高性能方法资源消耗大，不适合联邦学习。

Method: 通过分解大型注意力图为小矩阵，处理时序图像帧和转向数据，降低模型复杂度。

Result: 在三个数据集上表现优于现有方法，且实现实时性能，真实机器人实验验证了有效性。

Conclusion: 轻量级时序Transformer分解方法在自动驾驶中高效且性能优越。

Abstract: Traditional vision-based autonomous driving systems often face difficulties
in navigating complex environments when relying solely on single-image inputs.
To overcome this limitation, incorporating temporal data such as past image
frames or steering sequences, has proven effective in enhancing robustness and
adaptability in challenging scenarios. While previous high-performance methods
exist, they often rely on resource-intensive fusion networks, making them
impractical for training and unsuitable for federated learning. To address
these challenges, we propose lightweight temporal transformer decomposition, a
method that processes sequential image frames and temporal steering data by
breaking down large attention maps into smaller matrices. This approach reduces
model complexity, enabling efficient weight updates for convergence and
real-time predictions while leveraging temporal information to enhance
autonomous driving performance. Intensive experiments on three datasets
demonstrate that our method outperforms recent approaches by a clear margin
while achieving real-time performance. Additionally, real robot experiments
further confirm the effectiveness of our method.

</details>


### [202] [GViT: Representing Images as Gaussians for Visual Recognition](https://arxiv.org/abs/2506.23532)
*Jefferson Hernandez,Ruozhen He,Guha Balakrishnan,Alexander C. Berg,Vicente Ordonez*

Main category: cs.CV

Relevance: 40.0

TL;DR: GVIT是一种分类框架，用可学习的2D高斯表示替代传统的像素或块网格输入，通过优化高斯参数与ViT分类器联合训练，性能接近传统ViT。


<details>
  <summary>Details</summary>
Motivation: 传统ViT基于像素或块网格输入，GVIT探索更紧凑的高斯表示以提升效率和性能。

Method: GVIT将图像编码为几百个高斯参数，联合优化其位置、尺度、颜色等，并利用分类器梯度指导高斯聚焦于类别显著区域。

Result: 在Imagenet-1k上，GVIT使用ViT-B架构达到76.9%的top-1准确率，性能接近传统ViT。

Conclusion: GVIT展示了高斯表示在ViT中的潜力，为输入表示提供了新思路。

Abstract: We introduce GVIT, a classification framework that abandons conventional
pixel or patch grid input representations in favor of a compact set of
learnable 2D Gaussians. Each image is encoded as a few hundred Gaussians whose
positions, scales, orientations, colors, and opacities are optimized jointly
with a ViT classifier trained on top of these representations. We reuse the
classifier gradients as constructive guidance, steering the Gaussians toward
class-salient regions while a differentiable renderer optimizes an image
reconstruction loss. We demonstrate that by 2D Gaussian input representations
coupled with our GVIT guidance, using a relatively standard ViT architecture,
closely matches the performance of a traditional patch-based ViT, reaching a
76.9% top-1 accuracy on Imagenet-1k using a ViT-B architecture.

</details>


### [203] [CA-Diff: Collaborative Anatomy Diffusion for Brain Tissue Segmentation](https://arxiv.org/abs/2506.22882)
*Qilong Xing,Zikai Song,Yuteng Ye,Yuke Chen,Youjia Zhang,Na Feng,Junqing Yu,Wei Yang*

Main category: eess.IV

Relevance: 40.0

TL;DR: 提出了一种名为CA-Diff的框架，通过整合空间解剖特征提升扩散模型在脑MRI分割中的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有CNN和基于Transformer的方法在脑MRI分割中难以准确描绘复杂结构，而扩散模型直接应用时忽略了解剖信息。

Method: 引入距离场作为辅助解剖条件，提供全局空间上下文；提出协作扩散过程建模其与解剖结构的联合分布；设计一致性损失和时间适应通道注意力模块。

Result: CA-Diff在实验中优于现有最先进方法。

Conclusion: CA-Diff通过有效利用解剖特征，显著提升了脑MRI分割的准确性。

Abstract: Segmentation of brain structures from MRI is crucial for evaluating brain
morphology, yet existing CNN and transformer-based methods struggle to
delineate complex structures accurately. While current diffusion models have
shown promise in image segmentation, they are inadequate when applied directly
to brain MRI due to neglecting anatomical information. To address this, we
propose Collaborative Anatomy Diffusion (CA-Diff), a framework integrating
spatial anatomical features to enhance segmentation accuracy of the diffusion
model. Specifically, we introduce distance field as an auxiliary anatomical
condition to provide global spatial context, alongside a collaborative
diffusion process to model its joint distribution with anatomical structures,
enabling effective utilization of anatomical features for segmentation.
Furthermore, we introduce a consistency loss to refine relationships between
the distance field and anatomical structures and design a time adapted channel
attention module to enhance the U-Net feature fusion procedure. Extensive
experiments show that CA-Diff outperforms state-of-the-art (SOTA) methods.

</details>


### [204] [StackCLIP: Clustering-Driven Stacked Prompt in Zero-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2506.23577)
*Yanning Hou,Yanran Ruan,Junfa Li,Shanshan Wang,Jianfeng Qiu,Ke Xu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种名为StackCLIP的方法，通过多类别名称堆叠生成堆叠提示，提升CLIP模型在零样本工业异常检测任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因使用特定类别提示导致的过拟合和泛化能力不足的问题。

Method: 1. 使用Clustering-Driven Stacked Prompts (CSP)模块构建通用提示；2. 通过Ensemble Feature Alignment (EFA)模块训练知识特定线性层；3. 引入Regulating Prompt Learning (RPL)模块优化提示学习。

Result: 在七个工业异常检测数据集上实现了最先进的性能。

Conclusion: StackCLIP方法显著提升了训练速度、稳定性和收敛性，同时增强了泛化能力。

Abstract: Enhancing the alignment between text and image features in the CLIP model is
a critical challenge in zero-shot industrial anomaly detection tasks. Recent
studies predominantly utilize specific category prompts during pretraining,
which can cause overfitting to the training categories and limit model
generalization. To address this, we propose a method that transforms category
names through multicategory name stacking to create stacked prompts, forming
the basis of our StackCLIP model. Our approach introduces two key components.
The Clustering-Driven Stacked Prompts (CSP) module constructs generic prompts
by stacking semantically analogous categories, while utilizing multi-object
textual feature fusion to amplify discriminative anomalies among similar
objects. The Ensemble Feature Alignment (EFA) module trains knowledge-specific
linear layers tailored for each stack cluster and adaptively integrates them
based on the attributes of test categories. These modules work together to
deliver superior training speed, stability, and convergence, significantly
boosting anomaly segmentation performance. Additionally, our stacked prompt
framework offers robust generalization across classification tasks. To further
improve performance, we introduce the Regulating Prompt Learning (RPL) module,
which leverages the generalization power of stacked prompts to refine prompt
learning, elevating results in anomaly detection classification tasks.
Extensive testing on seven industrial anomaly detection datasets demonstrates
that our method achieves state-of-the-art performance in both zero-shot anomaly
detection and segmentation tasks.

</details>


### [205] [PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection](https://arxiv.org/abs/2506.23581)
*Xiao Li,Yiming Zhu,Yifan Huang,Wei Zhang,Yingzhe He,Jie Shi,Xiaolin Hu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种针对物体检测器的统一对抗训练方法PBCAT，以防御多种物理可实现攻击，显著提升了模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 物体检测在安全敏感应用中至关重要，但易受物理可实现攻击（如对抗性补丁和纹理）威胁。现有对抗训练研究多集中在分类模型，针对物体检测器的防御研究不足。

Method: 提出PBCAT方法，结合小区域梯度引导对抗补丁和全局不可察觉扰动，优化模型以防御多种攻击。

Result: 实验表明，PBCAT显著提升对多种物理可实现攻击的鲁棒性，检测准确率在对抗纹理攻击下提升29.7%。

Conclusion: PBCAT为物体检测器提供了一种有效的统一对抗训练防御方法，适用于多种物理可实现攻击。

Abstract: Object detection plays a crucial role in many security-sensitive
applications. However, several recent studies have shown that object detectors
can be easily fooled by physically realizable attacks, \eg, adversarial patches
and recent adversarial textures, which pose realistic and urgent threats.
Adversarial Training (AT) has been recognized as the most effective defense
against adversarial attacks. While AT has been extensively studied in the
$l_\infty$ attack settings on classification models, AT against physically
realizable attacks on object detectors has received limited exploration. Early
attempts are only performed to defend against adversarial patches, leaving AT
against a wider range of physically realizable attacks under-explored. In this
work, we consider defending against various physically realizable attacks with
a unified AT method. We propose PBCAT, a novel Patch-Based Composite
Adversarial Training strategy. PBCAT optimizes the model by incorporating the
combination of small-area gradient-guided adversarial patches and imperceptible
global adversarial perturbations covering the entire image. With these designs,
PBCAT has the potential to defend against not only adversarial patches but also
unseen physically realizable attacks such as adversarial textures. Extensive
experiments in multiple settings demonstrated that PBCAT significantly improved
robustness against various physically realizable attacks over state-of-the-art
defense methods. Notably, it improved the detection accuracy by 29.7\% over
previous defense methods under one recent adversarial texture attack.

</details>


### [206] [AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval](https://arxiv.org/abs/2506.23605)
*Suyash Maniyar,Vishvesh Trivedi,Ajoy Mondal,Anand Mishra,C. V. Jawahar*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种基于大语言模型（LLM）的合成幻灯片生成方法SynLecSlideGen，并通过实验证明其能有效提升小样本迁移学习性能。


<details>
  <summary>Details</summary>
Motivation: 解决幻灯片理解和元素检测任务中标注数据稀缺的问题。

Method: 使用LLM引导的合成幻灯片生成管道SynLecSlideGen，并创建真实幻灯片评估基准RealSlide。

Result: 实验表明，合成数据预训练显著提升了小样本迁移学习性能。

Conclusion: 合成数据可以弥补真实标注数据的不足。

Abstract: Lecture slide element detection and retrieval are key problems in slide
understanding. Training effective models for these tasks often depends on
extensive manual annotation. However, annotating large volumes of lecture
slides for supervised training is labor intensive and requires domain
expertise. To address this, we propose a large language model (LLM)-guided
synthetic lecture slide generation pipeline, SynLecSlideGen, which produces
high-quality, coherent and realistic slides. We also create an evaluation
benchmark, namely RealSlide by manually annotating 1,050 real lecture slides.
To assess the utility of our synthetic slides, we perform few-shot transfer
learning on real data using models pre-trained on them. Experimental results
show that few-shot transfer learning with pretraining on synthetic slides
significantly improves performance compared to training only on real data. This
demonstrates that synthetic data can effectively compensate for limited labeled
lecture slides. The code and resources of our work are publicly available on
our project website: https://synslidegen.github.io/.

</details>


### [207] [AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention](https://arxiv.org/abs/2506.23611)
*Ziao Liu,Zhenjia Li,Yifeng Shi,Xiangang Li*

Main category: cs.CV

Relevance: 40.0

TL;DR: AttentionGS eliminates dependency on high-quality point clouds for 3D Gaussian Splatting by using structural attention for direct 3D reconstruction.


<details>
  <summary>Details</summary>
Motivation: 3DGS relies on SfM for point clouds, which fails in texture-deficient or constrained-view scenarios, limiting its applicability.

Method: Proposes AttentionGS with geometric and texture attention for global structure recovery and detail refinement, plus opacity-weighted gradients for Gaussian densification.

Result: Outperforms state-of-the-art methods, especially in unreliable point cloud initialization scenarios.

Conclusion: AttentionGS enables more robust and flexible 3D Gaussian Splatting for real-world applications.

Abstract: 3D Gaussian Splatting (3DGS) is a powerful alternative to Neural Radiance
Fields (NeRF), excelling in complex scene reconstruction and efficient
rendering. However, it relies on high-quality point clouds from
Structure-from-Motion (SfM), limiting its applicability. SfM also fails in
texture-deficient or constrained-view scenarios, causing severe degradation in
3DGS reconstruction. To address this limitation, we propose AttentionGS, a
novel framework that eliminates the dependency on high-quality initial point
clouds by leveraging structural attention for direct 3D reconstruction from
randomly initialization. In the early training stage, we introduce geometric
attention to rapidly recover the global scene structure. As training
progresses, we incorporate texture attention to refine fine-grained details and
enhance rendering quality. Furthermore, we employ opacity-weighted gradients to
guide Gaussian densification, leading to improved surface reconstruction.
Extensive experiments on multiple benchmark datasets demonstrate that
AttentionGS significantly outperforms state-of-the-art methods, particularly in
scenarios where point cloud initialization is unreliable. Our approach paves
the way for more robust and flexible 3D Gaussian Splatting in real-world
applications.

</details>


### [208] [Revisiting Audio-Visual Segmentation with Vision-Centric Transformer](https://arxiv.org/abs/2506.23623)
*Shaofei Huang,Rui Ling,Tianrui Hui,Hongyu Li,Xu Zhou,Shifeng Zhang,Si Liu,Richang Hong,Meng Wang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种视觉为中心的Transformer框架（VCT），通过视觉驱动的查询解决音频-视觉分割中的感知模糊和视觉细节丢失问题，并引入原型提示查询生成模块（PPQG）提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有音频为中心的Transformer在音频-视觉分割中存在感知模糊和视觉细节丢失的问题，限制了分割的准确性。

Method: 提出视觉为中心的Transformer框架（VCT），利用视觉驱动的查询迭代获取音频和视觉信息，并引入PPQG模块生成语义和视觉丰富的查询。

Result: 在AVSBench数据集的三个子集上实现了新的最先进性能。

Conclusion: VCT框架通过视觉驱动的查询和PPQG模块有效提升了音频-视觉分割的性能。

Abstract: Audio-Visual Segmentation (AVS) aims to segment sound-producing objects in
video frames based on the associated audio signal. Prevailing AVS methods
typically adopt an audio-centric Transformer architecture, where object queries
are derived from audio features. However, audio-centric Transformers suffer
from two limitations: perception ambiguity caused by the mixed nature of audio,
and weakened dense prediction ability due to visual detail loss. To address
these limitations, we propose a new Vision-Centric Transformer (VCT) framework
that leverages vision-derived queries to iteratively fetch corresponding audio
and visual information, enabling queries to better distinguish between
different sounding objects from mixed audio and accurately delineate their
contours. Additionally, we also introduce a Prototype Prompted Query Generation
(PPQG) module within our VCT framework to generate vision-derived queries that
are both semantically aware and visually rich through audio prototype prompting
and pixel context grouping, facilitating audio-visual information aggregation.
Extensive experiments demonstrate that our VCT framework achieves new
state-of-the-art performances on three subsets of the AVSBench dataset. The
code is available at https://github.com/spyflying/VCT_AVS.

</details>


### [209] [Blending Concepts with Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.23630)
*Lorenzo Olearo,Giorgio Longari,Alessandro Raganato,Rafael Peñaloza,Simone Melzi*

Main category: cs.CV

Relevance: 40.0

TL;DR: 该研究探讨了扩散模型在零样本框架下是否能将不同概念（从具体对象到抽象想法）融合成连贯的新视觉实体，并测试了四种融合方法。


<details>
  <summary>Details</summary>
Motivation: 探索扩散模型在概念融合中的潜力，验证其在无需额外训练的情况下是否能生成高质量融合图像。

Method: 研究了四种融合方法，包括提示调度、嵌入插值和分层条件等，通过系统实验和用户研究评估效果。

Result: 扩散模型展现出创造性融合能力，但不同方法在不同场景下表现各异，受提示顺序、概念距离和随机种子等因素影响。

Conclusion: 扩散模型具有显著的组合潜力，但对输入变化敏感，需根据场景选择合适方法。

Abstract: Diffusion models have dramatically advanced text-to-image generation in
recent years, translating abstract concepts into high-fidelity images with
remarkable ease. In this work, we examine whether they can also blend distinct
concepts, ranging from concrete objects to intangible ideas, into coherent new
visual entities under a zero-shot framework. Specifically, concept blending
merges the key attributes of multiple concepts (expressed as textual prompts)
into a single, novel image that captures the essence of each concept. We
investigate four blending methods, each exploiting different aspects of the
diffusion pipeline (e.g., prompt scheduling, embedding interpolation, or
layer-wise conditioning). Through systematic experimentation across diverse
concept categories, such as merging concrete concepts, synthesizing compound
words, transferring artistic styles, and blending architectural landmarks, we
show that modern diffusion models indeed exhibit creative blending capabilities
without further training or fine-tuning. Our extensive user study, involving
100 participants, reveals that no single approach dominates in all scenarios:
each blending technique excels under certain conditions, with factors like
prompt ordering, conceptual distance, and random seed affecting the outcome.
These findings highlight the remarkable compositional potential of diffusion
models while exposing their sensitivity to seemingly minor input variations.

</details>


### [210] [VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation](https://arxiv.org/abs/2506.23641)
*Peng Huang,Junhu Fu,Bowen Guo,Zeju Li,Yuanyuan Wang,Yi Guo*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为VAP-Diffusion的框架，利用多模态大语言模型（MLLMs）的外部知识提升医学图像生成的质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 医学图像生成需要丰富的属性信息，但详细描述通常难以获取。

Method: 设计了基于Chain-of-Thoughts的提示词从MLLMs中提取描述，并提出原型条件机制增强生成器的鲁棒性。

Result: 在四种数据集的三种医学图像类型上验证了VAP-Diffusion的有效性。

Conclusion: VAP-Diffusion通过结合MLLMs的外部知识，显著提升了医学图像生成的多样性和质量。

Abstract: As the appearance of medical images is influenced by multiple underlying
factors, generative models require rich attribute information beyond labels to
produce realistic and diverse images. For instance, generating an image of skin
lesion with specific patterns demands descriptions that go beyond diagnosis,
such as shape, size, texture, and color. However, such detailed descriptions
are not always accessible. To address this, we explore a framework, termed
Visual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from
pre-trained Multi-modal Large Language Models (MLLMs) to improve the quality
and diversity of medical image generation. First, to derive descriptions from
MLLMs without hallucination, we design a series of prompts following
Chain-of-Thoughts for common medical imaging tasks, including dermatologic,
colorectal, and chest X-ray images. Generated descriptions are utilized during
training and stored across different categories. During testing, descriptions
are randomly retrieved from the corresponding category for inference. Moreover,
to make the generator robust to unseen combination of descriptions at the test
time, we propose a Prototype Condition Mechanism that restricts test embeddings
to be similar to those from training. Experiments on three common types of
medical imaging across four datasets verify the effectiveness of VAP-Diffusion.

</details>


### [211] [A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement](https://arxiv.org/abs/2506.23676)
*Gaozheng Pei,Ke Ma,Dongpeng Zhang,Chengzhi Sun,Qianqian Xu,Qingming Huang*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种统一框架，将传统对抗样本迁移增强策略融入基于扩散模型的图像编辑方法，提升了其在更广泛下游任务中的应用能力。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面强大，但在对抗样本生成中难以泛化到传统图像分类任务之外，且传统迁移增强策略难以适配。

Method: 开发了一个统一框架，将传统迁移增强策略与扩散模型结合，用于图像编辑生成对抗样本。

Result: 在ACM MM25的对抗攻击竞赛中获得第一名，验证了方法的有效性。

Conclusion: 该框架成功解决了扩散模型在对抗样本生成中的泛化和迁移性问题。

Abstract: Due to their powerful image generation capabilities, diffusion-based
adversarial example generation methods through image editing are rapidly
gaining popularity. However, due to reliance on the discriminative capability
of the diffusion model, these diffusion-based methods often struggle to
generalize beyond conventional image classification tasks, such as in Deepfake
detection. Moreover, traditional strategies for enhancing adversarial example
transferability are challenging to adapt to these methods. To address these
challenges, we propose a unified framework that seamlessly incorporates
traditional transferability enhancement strategies into diffusion model-based
adversarial example generation via image editing, enabling their application
across a wider range of downstream tasks. Our method won first place in the
"1st Adversarial Attacks on Deepfake Detectors: A Challenge in the Era of
AI-Generated Media" competition at ACM MM25, which validates the effectiveness
of our approach.

</details>


### [212] [SynMotion: Semantic-Visual Adaptation for Motion Customized Video Generation](https://arxiv.org/abs/2506.23690)
*Shuai Tan,Biao Gong,Yujie Wei,Shiwei Zhang,Zhuoxin Liu,Dandan Zheng,Jingdong Chen,Yan Wang,Hao Ouyang,Kecheng Zheng,Yujun Shen*

Main category: cs.CV

Relevance: 40.0

TL;DR: SynMotion是一个视频生成模型，通过结合语义指导和视觉适应，解决了现有方法在视频运动定制中语义与视觉平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视频运动定制中要么过于依赖语义对齐，要么仅关注视觉表示，导致语义混淆或视觉复杂性被忽视。

Method: 提出双嵌入语义理解机制和参数高效运动适配器，结合交替优化的训练策略和SPV数据集。

Result: 在T2V和I2V设置下，SynMotion优于现有基线。

Conclusion: SynMotion通过语义与视觉的联合优化，实现了高质量的视频运动定制。

Abstract: Diffusion-based video motion customization facilitates the acquisition of
human motion representations from a few video samples, while achieving
arbitrary subjects transfer through precise textual conditioning. Existing
approaches often rely on semantic-level alignment, expecting the model to learn
new motion concepts and combine them with other entities (e.g., ''cats'' or
''dogs'') to produce visually appealing results. However, video data involve
complex spatio-temporal patterns, and focusing solely on semantics cause the
model to overlook the visual complexity of motion. Conversely, tuning only the
visual representation leads to semantic confusion in representing the intended
action. To address these limitations, we propose SynMotion, a new
motion-customized video generation model that jointly leverages semantic
guidance and visual adaptation. At the semantic level, we introduce the
dual-embedding semantic comprehension mechanism which disentangles subject and
motion representations, allowing the model to learn customized motion features
while preserving its generative capabilities for diverse subjects. At the
visual level, we integrate parameter-efficient motion adapters into a
pre-trained video generation model to enhance motion fidelity and temporal
coherence. Furthermore, we introduce a new embedding-specific training strategy
which \textbf{alternately optimizes} subject and motion embeddings, supported
by the manually constructed Subject Prior Video (SPV) training dataset. This
strategy promotes motion specificity while preserving generalization across
diverse subjects. Lastly, we introduce MotionBench, a newly curated benchmark
with diverse motion patterns. Experimental results across both T2V and I2V
settings demonstrate that \method outperforms existing baselines. Project page:
https://lucaria-academy.github.io/SynMotion/

</details>


### [213] [When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation](https://arxiv.org/abs/2506.23724)
*Chang'an Yi,Xiaohui Deng,Guohao Chen,Yan Zhou,Qinghua Lu,Shuaicheng Niu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出COCA框架，通过跨模型协同学习提升测试时适应（TTA）性能，利用不同模型的互补知识减少偏差并增强适应性。


<details>
  <summary>Details</summary>
Motivation: 研究跨模型知识如何影响TTA过程，发现不同模型（如大小差异显著的模型）能提供互补知识。

Method: 提出COCA框架，包含协同适应（整合其他模型知识）和自适应（增强模型独特优势）两种策略。

Result: COCA显著提升现有SOTA性能，例如将ViT-Base在ImageNet-C上的适应准确率从51.7%提高到64.5%。

Conclusion: 跨模型协同学习在TTA中有效，COCA可作为即插即用模块提升性能。

Abstract: Test-time Adaptation (TTA) adapts a given model to testing domain data with
potential domain shifts through online unsupervised learning, yielding
impressive performance. However, to date, existing TTA methods primarily focus
on single-model adaptation. In this work, we investigate an intriguing
question: how does cross-model knowledge influence the TTA process? Our
findings reveal that, in TTA's unsupervised online setting, each model can
provide complementary, confident knowledge to the others, even when there are
substantial differences in model size. For instance, a smaller model like
MobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base
(86.6M parameters). In light of this, we propose COCA, a Cross-Model
Co-Learning framework for TTA, which mainly consists of two main strategies. 1)
Co-adaptation adaptively integrates complementary knowledge from other models
throughout the TTA process, reducing individual model biases. 2)
Self-adaptation enhances each model's unique strengths via unsupervised
learning, enabling diverse adaptation to the target domain. Extensive
experiments show that COCA, which can also serve as a plug-and-play module,
significantly boosts existing SOTAs, on models with various sizes--including
ResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example,
with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy
on ImageNet-C from 51.7% to 64.5%. The code is publicly available at
https://github.com/ycarobot/COCA.

</details>


### [214] [Proteus-ID: ID-Consistent and Motion-Coherent Video Customization](https://arxiv.org/abs/2506.23729)
*Guiyu Zhang,Chen Shi,Zijian Jiang,Xunzhi Xiang,Jingjing Qian,Shaoshuai Shi,Li Jiang*

Main category: cs.CV

Relevance: 40.0

TL;DR: Proteus-ID是一个基于扩散模型的视频身份定制框架，通过多模态身份融合和时间感知身份注入解决身份一致性和运动连贯性问题，并在高质量数据集上验证其性能。


<details>
  <summary>Details</summary>
Motivation: 视频身份定制任务面临身份一致性和运动自然性的挑战，现有方法难以同时满足这两点。

Method: 提出多模态身份融合模块（MIF）、时间感知身份注入机制（TAII）和自适应运动学习策略（AML），并结合高质量数据集Proteus-Bench。

Result: Proteus-ID在身份保持、文本对齐和运动质量上优于现有方法。

Conclusion: Proteus-ID为视频身份定制设立了新基准，代码和数据已开源。

Abstract: Video identity customization seeks to synthesize realistic, temporally
coherent videos of a specific subject, given a single reference image and a
text prompt. This task presents two core challenges: (1) maintaining identity
consistency while aligning with the described appearance and actions, and (2)
generating natural, fluid motion without unrealistic stiffness. To address
these challenges, we introduce Proteus-ID, a novel diffusion-based framework
for identity-consistent and motion-coherent video customization. First, we
propose a Multimodal Identity Fusion (MIF) module that unifies visual and
textual cues into a joint identity representation using a Q-Former, providing
coherent guidance to the diffusion model and eliminating modality imbalance.
Second, we present a Time-Aware Identity Injection (TAII) mechanism that
dynamically modulates identity conditioning across denoising steps, improving
fine-detail reconstruction. Third, we propose Adaptive Motion Learning (AML), a
self-supervised strategy that reweights the training loss based on
optical-flow-derived motion heatmaps, enhancing motion realism without
requiring additional inputs. To support this task, we construct Proteus-Bench,
a high-quality dataset comprising 200K curated clips for training and 150
individuals from diverse professions and ethnicities for evaluation. Extensive
experiments demonstrate that Proteus-ID outperforms prior methods in identity
preservation, text alignment, and motion quality, establishing a new benchmark
for video identity customization. Codes and data are publicly available at
https://grenoble-zhang.github.io/Proteus-ID/.

</details>


### [215] [Visual Textualization for Image Prompted Object Detection](https://arxiv.org/abs/2506.23785)
*Yongjian Wu,Yang Zhou,Jiya Saiyin,Bingzheng Wei,Yan Xu*

Main category: cs.CV

Relevance: 40.0

TL;DR: VisTex-OVLM是一种通过视觉文本化增强对象级视觉语言模型（OVLM）的方法，用于检测难以文本描述的罕见类别。


<details>
  <summary>Details</summary>
Motivation: 解决OVLM在罕见类别检测中的局限性，同时保持其预训练的对象-文本对齐能力。

Method: 利用多尺度文本化块和多阶段融合策略，将视觉示例信息转化为文本特征空间中的视觉标记。

Result: 在开放集数据集和少样本基准（如PASCAL VOC和MSCOCO）上取得最先进性能。

Conclusion: VisTex-OVLM在不改变OVLM架构的情况下，显著提升了罕见类别检测能力。

Abstract: We propose VisTex-OVLM, a novel image prompted object detection method that
introduces visual textualization -- a process that projects a few visual
exemplars into the text feature space to enhance Object-level Vision-Language
Models' (OVLMs) capability in detecting rare categories that are difficult to
describe textually and nearly absent from their pre-training data, while
preserving their pre-trained object-text alignment. Specifically, VisTex-OVLM
leverages multi-scale textualizing blocks and a multi-stage fusion strategy to
integrate visual information from visual exemplars, generating textualized
visual tokens that effectively guide OVLMs alongside text prompts. Unlike
previous methods, our method maintains the original architecture of OVLM,
maintaining its generalization capabilities while enhancing performance in
few-shot settings. VisTex-OVLM demonstrates superior performance across
open-set datasets which have minimal overlap with OVLM's pre-training data and
achieves state-of-the-art results on few-shot benchmarks PASCAL VOC and MSCOCO.
The code will be released at https://github.com/WitGotFlg/VisTex-OVLM.

</details>


### [216] [MadCLIP: Few-shot Medical Anomaly Detection with CLIP](https://arxiv.org/abs/2506.23810)
*Mahshid Shiri,Cigdem Beyan,Vittorio Murino*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种基于预训练CLIP模型的少样本异常检测方法，适用于医学数据的图像级和像素级异常检测，通过双分支设计和可学习文本提示提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学数据中少样本异常检测的挑战，利用预训练模型减少对合成数据或内存库的依赖。

Method: 采用双分支设计捕获正常和异常特征，使用可学习文本提示增强语义对齐，并应用SigLIP损失处理图像与文本提示的多对一关系。

Result: 在多种模态上验证了方法的优越性，在同数据集和跨数据集评估中均优于现有方法。

Conclusion: 该方法无需依赖合成数据或内存库，通过消融实验验证了各组件的重要性。

Abstract: An innovative few-shot anomaly detection approach is presented, leveraging
the pre-trained CLIP model for medical data, and adapting it for both
image-level anomaly classification (AC) and pixel-level anomaly segmentation
(AS). A dual-branch design is proposed to separately capture normal and
abnormal features through learnable adapters in the CLIP vision encoder. To
improve semantic alignment, learnable text prompts are employed to link visual
features. Furthermore, SigLIP loss is applied to effectively handle the
many-to-one relationship between images and unpaired text prompts, showcasing
its adaptation in the medical field for the first time. Our approach is
validated on multiple modalities, demonstrating superior performance over
existing methods for AC and AS, in both same-dataset and cross-dataset
evaluations. Unlike prior work, it does not rely on synthetic data or memory
banks, and an ablation study confirms the contribution of each component. The
code is available at https://github.com/mahshid1998/MadCLIP.

</details>


### [217] [Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning](https://arxiv.org/abs/2506.23827)
*Mingcheng Qu,Yuncong Wu,Donglin Di,Yue Gao,Tonghua Su,Yang Song,Lei Fan*

Main category: cs.CV

Relevance: 40.0

TL;DR: NH2ST框架通过整合空间上下文和病理与基因模态，利用交叉注意力和对比学习预测基因表达，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略空间和分子交互，NH2ST旨在解决这一问题。

Method: 采用查询分支和邻居分支处理目标区域及其邻近区域，结合交叉注意力和对比学习。

Result: 在六个数据集上表现优异，PCC指标提升超过20%。

Conclusion: NH2ST能有效捕捉跨模态关系，提升基因表达预测性能。

Abstract: Spatial transcriptomics (ST) provides crucial insights into tissue
micro-environments, but is limited to its high cost and complexity. As an
alternative, predicting gene expression from pathology whole slide images (WSI)
is gaining increasing attention. However, existing methods typically rely on
single patches or a single pathology modality, neglecting the complex spatial
and molecular interactions between target and neighboring information (e.g.,
gene co-expression). This leads to a failure in establishing connections among
adjacent regions and capturing intricate cross-modal relationships. To address
these issues, we propose NH2ST, a framework that integrates spatial context and
both pathology and gene modalities for gene expression prediction. Our model
comprises a query branch and a neighbor branch to process paired target patch
and gene data and their neighboring regions, where cross-attention and
contrastive learning are employed to capture intrinsic associations and ensure
alignments between pathology and gene expression. Extensive experiments on six
datasets demonstrate that our model consistently outperforms existing methods,
achieving over 20% in PCC metrics. Codes are available at
https://github.com/MCPathology/NH2ST

</details>


### [218] [Three-dimensional end-to-end deep learning for brain MRI analysis](https://arxiv.org/abs/2506.23916)
*Radhika Juglan,Marta Ligero,Zunamys I. Carrero,Asier Rabasco,Tim Lenz,Leo Misera,Gregory Patrick Veldhuizen,Paul Kuntke,Hagen H. Kitzler,Sven Nebelung,Daniel Truhn,Jakob Nikolas Kather*

Main category: cs.CV

Relevance: 40.0

TL;DR: 研究发现，在脑成像分析中，简单的卷积网络（SFCN）比更复杂的注意力架构（如Swin Transformer）表现更好，具有更强的跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 评估深度学习模型在不同脑成像队列中的泛化能力，重点关注年龄和性别预测任务。

Method: 比较了三种3D架构（SFCN、DenseNet、Swin Transformer）在四个独立队列（UKB、DLBS、PPMI、IXI）中的表现，使用AUC和MAE作为指标。

Result: SFCN在性别分类和年龄预测任务中均优于复杂架构，尤其在跨数据集泛化性上表现突出。

Conclusion: 简单卷积网络在脑图像分析中优于复杂注意力架构，具有更好的泛化能力。

Abstract: Deep learning (DL) methods are increasingly outperforming classical
approaches in brain imaging, yet their generalizability across diverse imaging
cohorts remains inadequately assessed. As age and sex are key neurobiological
markers in clinical neuroscience, influencing brain structure and disease risk,
this study evaluates three of the existing three-dimensional architectures,
namely Simple Fully Connected Network (SFCN), DenseNet, and Shifted Window
(Swin) Transformers, for age and sex prediction using T1-weighted MRI from four
independent cohorts: UK Biobank (UKB, n=47,390), Dallas Lifespan Brain Study
(DLBS, n=132), Parkinson's Progression Markers Initiative (PPMI, n=108 healthy
controls), and Information eXtraction from Images (IXI, n=319). We found that
SFCN consistently outperformed more complex architectures with AUC of 1.00
[1.00-1.00] in UKB (internal test set) and 0.85-0.91 in external test sets for
sex classification. For the age prediction task, SFCN demonstrated a mean
absolute error (MAE) of 2.66 (r=0.89) in UKB and 4.98-5.81 (r=0.55-0.70) across
external datasets. Pairwise DeLong and Wilcoxon signed-rank tests with
Bonferroni corrections confirmed SFCN's superiority over Swin Transformer
across most cohorts (p<0.017, for three comparisons). Explainability analysis
further demonstrates the regional consistency of model attention across cohorts
and specific to each task. Our findings reveal that simpler convolutional
networks outperform the denser and more complex attention-based DL
architectures in brain image analysis by demonstrating better generalizability
across different datasets.

</details>


### [219] [Visual and Memory Dual Adapter for Multi-Modal Object Tracking](https://arxiv.org/abs/2506.23972)
*Boyue Xu,Ruichao Hou,Tongwei Ren,Gangshan Wu*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种新颖的视觉和记忆双重适配器（VMDA），用于多模态跟踪，通过联合建模频率、空间和通道特征，以及利用人类记忆机制存储全局时间线索。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨频率和时间域的关键线索利用不足，导致提示学习不可靠。

Method: 设计了视觉适配器和记忆适配器，前者联合建模频率、空间和通道特征，后者存储全局时间线索并进行动态更新和检索。

Result: 在RGB-Thermal、RGB-Depth和RGB-Event等多模态跟踪任务中实现了最先进的性能。

Conclusion: VMDA通过有效利用多模态线索和时间信息，显著提升了多模态跟踪的鲁棒性和判别性。

Abstract: Prompt-learning-based multi-modal trackers have achieved promising progress
by employing lightweight visual adapters to incorporate auxiliary modality
features into frozen foundation models. However, existing approaches often
struggle to learn reliable prompts due to limited exploitation of critical cues
across frequency and temporal domains. In this paper, we propose a novel visual
and memory dual adapter (VMDA) to construct more robust and discriminative
representations for multi-modal tracking. Specifically, we develop a simple but
effective visual adapter that adaptively transfers discriminative cues from
auxiliary modality to dominant modality by jointly modeling the frequency,
spatial, and channel-wise features. Additionally, we design the memory adapter
inspired by the human memory mechanism, which stores global temporal cues and
performs dynamic update and retrieval operations to ensure the consistent
propagation of reliable temporal information across video sequences. Extensive
experiments demonstrate that our method achieves state-of-the-art performance
on the various multi-modal tracking tasks, including RGB-Thermal, RGB-Depth,
and RGB-Event tracking. Code and models are available at
https://github.com/xuboyue1999/mmtrack.git.

</details>


### [220] [Toward Simple and Robust Contrastive Explanations for Image Classification by Leveraging Instance Similarity and Concept Relevance](https://arxiv.org/abs/2506.23975)
*Yuliia Kaidashova,Bettina Finzel,Ute Schmid*

Main category: cs.CV

Relevance: 40.0

TL;DR: 该论文提出了一种基于概念的对比解释方法，用于图像分类模型，通过分析实例嵌入的相似性和人类可理解概念的相关性，生成解释。研究发现，概念相关性越高，解释越简洁；相关性越低，解释越复杂。此外，解释在不同图像增强下的鲁棒性表现不一。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决分类模型为何偏好某一类的问题，通过对比解释方法提升模型的可解释性和鲁棒性。

Method: 利用实例嵌入的相似性和概念相关性，提取概念并计算对比解释，评估解释复杂性和鲁棒性。

Result: 高相关性的概念生成更简洁的解释，低相关性则生成更复杂的解释。解释在不同图像增强下的鲁棒性表现不一。

Conclusion: 研究为构建更可解释和鲁棒的AI系统提供了潜在方向。

Abstract: Understanding why a classification model prefers one class over another for
an input instance is the challenge of contrastive explanation. This work
implements concept-based contrastive explanations for image classification by
leveraging the similarity of instance embeddings and relevance of
human-understandable concepts used by a fine-tuned deep learning model. Our
approach extracts concepts with their relevance score, computes contrasts for
similar instances, and evaluates the resulting contrastive explanations based
on explanation complexity. Robustness is tested for different image
augmentations. Two research questions are addressed: (1) whether explanation
complexity varies across different relevance ranges, and (2) whether
explanation complexity remains consistent under image augmentations such as
rotation and noise. The results confirm that for our experiments higher concept
relevance leads to shorter, less complex explanations, while lower relevance
results in longer, more diffuse explanations. Additionally, explanations show
varying degrees of robustness. The discussion of these findings offers insights
into the potential of building more interpretable and robust AI systems.

</details>


### [221] [StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving](https://arxiv.org/abs/2506.23982)
*Ruiyang Hao,Bowen Jing,Haibao Yu,Zaiqing Nie*

Main category: cs.CV

Relevance: 40.0

TL;DR: 该论文提出了首个大规模真实世界数据集，用于端到端自动驾驶（E2EAD）的个性化研究，并建立了评估个性化E2EAD模型的基准。


<details>
  <summary>Details</summary>
Motivation: 个性化在端到端自动驾驶中尚未被充分研究，而用户对齐行为对自动驾驶的信任和广泛采用至关重要。缺乏标注多样化驾驶偏好的大规模数据集是主要挑战。

Method: 通过静态环境特征和动态上下文线索构建场景，结合行为分布分析和规则启发式生成客观偏好标注，并利用视觉语言模型（VLM）生成主观标注，最终通过人工验证融合两者。

Result: 实验表明，结合个性化偏好的模型能生成更符合人类驾驶的行为。

Conclusion: 该研究为个性化E2EAD提供了标准化平台，推动了以人为中心的自动驾驶研究。

Abstract: While personalization has been explored in traditional autonomous driving
systems, it remains largely overlooked in end-to-end autonomous driving
(E2EAD), despite its growing prominence. This gap is critical, as user-aligned
behavior is essential for trust, comfort, and widespread adoption of autonomous
vehicles. A core challenge is the lack of large-scale real-world datasets
annotated with diverse and fine-grained driving preferences, hindering the
development and evaluation of personalized E2EAD models. In this work, we
present the first large-scale real-world dataset enriched with annotations
capturing diverse driving preferences, establishing a foundation for
personalization in E2EAD. We extract static environmental features from
real-world road topology and infer dynamic contextual cues using a fine-tuned
visual language model (VLM), enabling consistent and fine-grained scenario
construction. Based on these scenarios, we derive objective preference
annotations through behavioral distribution analysis and rule-based heuristics.
To address the inherent subjectivity of driving style, we further employ the
VLM to generate subjective annotations by jointly modeling scene semantics and
driver behavior. Final high-quality labels are obtained through a
human-in-the-loop verification process that fuses both perspectives. Building
on this dataset, we propose the first benchmark for evaluating personalized
E2EAD models. We assess several state-of-the-art models with and without
preference conditioning, demonstrating that incorporating personalized
preferences results in behavior more aligned with human driving. Our work lays
the foundation for personalized E2EAD by providing a standardized platform to
systematically integrate human preferences into data-driven E2EAD systems,
catalyzing future research in human-centric autonomy.

</details>


### [222] [Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data](https://arxiv.org/abs/2506.24039)
*Shubhabrata Mukherjee,Jack Lang,Obeen Kwon,Iryna Zenyuk,Valerie Brogden,Adam Weber,Daniela Ushizima*

Main category: cs.CV

Relevance: 40.0

TL;DR: Zenesis是一个无需代码的交互式平台，通过多模态适应技术和人机协作优化，显著提升科学图像分析的准确性，尤其在稀缺数据场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对科学图像稀缺且标注困难的问题，传统零样本和基于提示的技术表现不佳，Zenesis旨在降低数据准备门槛并提升分析准确性。

Method: 开发轻量级多模态适应技术，支持零样本操作，结合人机协作优化和启发式时间增强方法。

Result: 在FIB-SEM数据上，Zenesis平均准确率达0.947（非晶样本）和0.987（晶体样本），显著优于传统方法。

Conclusion: Zenesis是科学图像分析的高效工具，尤其在高质量标注数据稀缺的领域具有重要价值。

Abstract: Zero-shot and prompt-based technologies capitalized on using frequently
occurring images to transform visual reasoning tasks, which explains why such
technologies struggle with valuable yet scarce scientific image sets. In this
work, we propose Zenesis, a comprehensive no-code interactive platform designed
to minimize barriers posed by data readiness for scientific images. We develop
lightweight multi-modal adaptation techniques that enable zero-shot operation
on raw scientific data, along with human-in-the-loop refinement and
heuristic-based temporal enhancement options. We demonstrate the performance of
our approach through comprehensive comparison and validation on challenging
Focused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loaded
membranes. Zenesis significantly outperforms baseline methods, achieving an
average accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and a
Dice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, an
IOU of 0.857, and a Dice score of 0.923 for crystalline samples. These results
mark a substantial improvement over traditional methods like Otsu thresholding
and even advanced models like Segment Anything Model (SAM) when used in
isolation. Our results demonstrate that Zenesis is a powerful tool for
scientific applications, particularly in fields where high-quality annotated
datasets are unavailable, accelerating accurate analysis of experimental
imaging.

</details>


### [223] [Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios](https://arxiv.org/abs/2506.24063)
*Deng Li,Aming Wu,Yang Li,Yaowei Wang,Yahong Han*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种新的持续测试时适应机制，通过参数生成和双路径LoRA适配器提升目标检测器的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决封闭集假设下目标检测器在环境变化时的性能退化问题。

Method: 设计了双路径LoRA适配器分离特征，并引入条件扩散参数生成机制和类中心最优传输对齐方法。

Result: 在多种连续域自适应目标检测任务中表现优异，生成的参数能捕获更多目标相关信息。

Conclusion: 新机制有效提升了检测器的泛化能力和抗遗忘性。

Abstract: In practice, environments constantly change over time and space, posing
significant challenges for object detectors trained based on a closed-set
assumption, i.e., training and test data share the same distribution. To this
end, continual test-time adaptation has attracted much attention, aiming to
improve detectors' generalization by fine-tuning a few specific parameters,
e.g., BatchNorm layers. However, based on a small number of test images,
fine-tuning certain parameters may affect the representation ability of other
fixed parameters, leading to performance degradation. Instead, we explore a new
mechanism, i.e., converting the fine-tuning process to a specific-parameter
generation. Particularly, we first design a dual-path LoRA-based domain-aware
adapter that disentangles features into domain-invariant and domain-specific
components, enabling efficient adaptation. Additionally, a conditional
diffusion-based parameter generation mechanism is presented to synthesize the
adapter's parameters based on the current environment, preventing the
optimization from getting stuck in local optima. Finally, we propose a
class-centered optimal transport alignment method to mitigate catastrophic
forgetting. Extensive experiments conducted on various continuous domain
adaptive object detection tasks demonstrate the effectiveness. Meanwhile,
visualization results show that the representation extracted by the generated
parameters can capture more object-related information and strengthen the
generalization ability.

</details>


### [224] [Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention](https://arxiv.org/abs/2506.24085)
*Wonwoong Cho,Yanxia Zhang,Yan-Ying Chen,David I. Inouye*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为IT-Blender的T2I扩散适配器，用于自动化视觉和文本概念的混合过程，以增强人类创造力。


<details>
  <summary>Details</summary>
Motivation: 人类在跨模态概念混合中容易受到认知偏差的影响，导致设计空间的局部最优解。IT-Blender旨在解决现有方法在细节保留和解耦输入方面的不足。

Method: IT-Blender利用预训练的扩散模型（SD和FLUX），将干净参考图像的潜在表示与噪声生成图像的潜在表示混合，并结合新颖的混合注意力机制。

Result: 实验结果表明，IT-Blender在视觉和文本概念混合方面大幅优于基线方法。

Conclusion: IT-Blender展示了图像生成模型在增强人类创造力方面的新应用潜力。

Abstract: Blending visual and textual concepts into a new visual concept is a unique
and powerful trait of human beings that can fuel creativity. However, in
practice, cross-modal conceptual blending for humans is prone to cognitive
biases, like design fixation, which leads to local minima in the design space.
In this paper, we propose a T2I diffusion adapter "IT-Blender" that can
automate the blending process to enhance human creativity. Prior works related
to cross-modal conceptual blending are limited in encoding a real image without
loss of details or in disentangling the image and text inputs. To address these
gaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend
the latent representations of a clean reference image with those of the noisy
generated image. Combined with our novel blended attention, IT-Blender encodes
the real reference image without loss of details and blends the visual concept
with the object specified by the text in a disentangled way. Our experiment
results show that IT-Blender outperforms the baselines by a large margin in
blending visual and textual concepts, shedding light on the new application of
image generative models to augment human creativity.

</details>


### [225] [Epona: Autoregressive Diffusion World Model for Autonomous Driving](https://arxiv.org/abs/2506.24113)
*Kaiwen Zhang,Zhenyu Tang,Xiaotao Hu,Xingang Pan,Xiaoyang Guo,Yuan Liu,Jingwei Huang,Li Yuan,Qian Zhang,Xiao-Xiao Long,Xun Cao,Wei Yin*

Main category: cs.CV

Relevance: 40.0

TL;DR: 提出了一种名为Epona的自回归扩散世界模型，通过解耦时空因子化和模块化轨迹与视频预测，实现了长时程高分辨率视频生成，并在自动驾驶世界建模中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频扩散的世界模型在灵活长度、长时程预测和轨迹规划整合方面存在不足，主要因其依赖固定长度帧序列的全局联合分布建模。

Method: 1) 解耦时空因子化，分离时间动态建模与细粒度未来世界生成；2) 模块化轨迹与视频预测，端到端整合运动规划与视觉建模。采用链式前向训练策略解决自回归循环中的误差累积。

Result: 实验结果显示，FVD提升7.4%，预测时长显著延长，且在NAVSIM基准测试中优于端到端规划器。

Conclusion: Epona模型在长时程视频生成和实时运动规划方面表现优异，为自动驾驶世界建模提供了新方法。

Abstract: Diffusion models have demonstrated exceptional visual quality in video
generation, making them promising for autonomous driving world modeling.
However, existing video diffusion-based world models struggle with
flexible-length, long-horizon predictions and integrating trajectory planning.
This is because conventional video diffusion models rely on global joint
distribution modeling of fixed-length frame sequences rather than sequentially
constructing localized distributions at each timestep. In this work, we propose
Epona, an autoregressive diffusion world model that enables localized
spatiotemporal distribution modeling through two key innovations: 1) Decoupled
spatiotemporal factorization that separates temporal dynamics modeling from
fine-grained future world generation, and 2) Modular trajectory and video
prediction that seamlessly integrate motion planning with visual modeling in an
end-to-end framework. Our architecture enables high-resolution, long-duration
generation while introducing a novel chain-of-forward training strategy to
address error accumulation in autoregressive loops. Experimental results
demonstrate state-of-the-art performance with 7.4\% FVD improvement and minutes
longer prediction duration compared to prior works. The learned world model
further serves as a real-time motion planner, outperforming strong end-to-end
planners on NAVSIM benchmarks. Code will be publicly available at
\href{https://github.com/Kevin-thu/Epona/}{https://github.com/Kevin-thu/Epona/}.

</details>


### [226] [Calligrapher: Freestyle Text Image Customization](https://arxiv.org/abs/2506.24123)
*Yue Ma,Qingyan Bai,Hao Ouyang,Ka Leong Cheng,Qiuyu Wang,Hongyu Liu,Zichen Liu,Haofan Wang,Jingye Chen,Yujun Shen,Qifeng Chen*

Main category: cs.CV

Relevance: 40.0

TL;DR: Calligrapher是一个基于扩散模型的框架，结合文本定制与艺术字体设计，通过自蒸馏机制、局部风格注入和上下文生成技术，实现高质量字体生成。


<details>
  <summary>Details</summary>
Motivation: 解决字体定制中精确风格控制和数据依赖的挑战。

Method: 1. 自蒸馏机制利用预训练文本生成模型和LLM构建风格基准；2. 可训练风格编码器提取风格特征；3. 上下文生成机制嵌入参考图像。

Result: 在多样字体和设计场景中，Calligrapher能精确复现风格细节和字形定位，超越传统模型。

Conclusion: Calligrapher为数字艺术、品牌设计等领域提供了自动化高质量字体生成工具。

Abstract: We introduce Calligrapher, a novel diffusion-based framework that
innovatively integrates advanced text customization with artistic typography
for digital calligraphy and design applications. Addressing the challenges of
precise style control and data dependency in typographic customization, our
framework incorporates three key technical contributions. First, we develop a
self-distillation mechanism that leverages the pre-trained text-to-image
generative model itself alongside the large language model to automatically
construct a style-centric typography benchmark. Second, we introduce a
localized style injection framework via a trainable style encoder, which
comprises both Qformer and linear layers, to extract robust style features from
reference images. An in-context generation mechanism is also employed to
directly embed reference images into the denoising process, further enhancing
the refined alignment of target styles. Extensive quantitative and qualitative
evaluations across diverse fonts and design contexts confirm Calligrapher's
accurate reproduction of intricate stylistic details and precise glyph
positioning. By automating high-quality, visually consistent typography,
Calligrapher surpasses traditional models, empowering creative practitioners in
digital art, branding, and contextual typographic design.

</details>


### [227] [How to Design and Train Your Implicit Neural Representation for Video Compression](https://arxiv.org/abs/2506.24127)
*Matthew Gwilliam,Roy Zhang,Namitha Padmanabhan,Hongyang Du,Abhinav Shrivastava*

Main category: cs.CV

Relevance: 40.0

TL;DR: 论文提出了一种名为Rabbit NeRV (RNeRV)的视频压缩方法，通过优化隐式神经表示(INR)设计，提升了压缩质量和训练效率，并探索了超网络以解决编码速度问题。


<details>
  <summary>Details</summary>
Motivation: 解决视频压缩中隐式神经表示(INR)方法因需要逐样本训练而导致的编码速度过慢问题。

Method: 开发了一个库来分析NeRV家族方法的组件，提出RNeRV配置，并探索超网络以预测INR权重，实现实时编码。

Result: RNeRV在相同训练时间下平均PSNR提升1.27%，超网络方法在UCF-101数据集上PSNR和MS-SSIM分别提升1.7%。

Conclusion: RNeRV和超网络方法显著提升了视频压缩的质量和效率，为实际应用提供了可能。

Abstract: Implicit neural representation (INR) methods for video compression have
recently achieved visual quality and compression ratios that are competitive
with traditional pipelines. However, due to the need for per-sample network
training, the encoding speeds of these methods are too slow for practical
adoption. We develop a library to allow us to disentangle and review the
components of methods from the NeRV family, reframing their performance in
terms of not only size-quality trade-offs, but also impacts on training time.
We uncover principles for effective video INR design and propose a
state-of-the-art configuration of these components, Rabbit NeRV (RNeRV). When
all methods are given equal training time (equivalent to 300 NeRV epochs) for 7
different UVG videos at 1080p, RNeRV achieves +1.27% PSNR on average compared
to the best-performing alternative for each video in our NeRV library. We then
tackle the encoding speed issue head-on by investigating the viability of
hyper-networks, which predict INR weights from video inputs, to disentangle
training from encoding to allow for real-time encoding. We propose masking the
weights of the predicted INR during training to allow for variable, higher
quality compression, resulting in 1.7% improvements to both PSNR and MS-SSIM at
0.037 bpp on the UCF-101 dataset, and we increase hyper-network parameters by
0.4% for 2.5%/2.7% improvements to PSNR/MS-SSIM with equal bpp and similar
speeds. Our project website is available at https://mgwillia.github.io/vinrb/
and our code is available at https://github.com/mgwillia/vinrb.

</details>


### [228] [InfGen: Scenario Generation as Next Token Group Prediction](https://arxiv.org/abs/2506.23316)
*Zhenghao Peng,Yuxin Liu,Bolei Zhou*

Main category: cs.RO

Relevance: 40.0

TL;DR: InfGen是一个基于Transformer的交通场景生成框架，支持动态、长时程的交通模拟，并能持续插入新车辆。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的交通模拟方法依赖静态初始化或日志回放，难以建模动态、长时程场景。

Method: 将整个场景表示为token序列（交通信号、车辆状态、运动向量），使用Transformer模型进行自回归模拟。

Result: InfGen生成真实、多样且自适应的交通行为，强化学习策略在其生成场景中表现更优。

Conclusion: InfGen是高保真自动驾驶模拟环境，支持无限场景生成。

Abstract: Realistic and interactive traffic simulation is essential for training and
evaluating autonomous driving systems. However, most existing data-driven
simulation methods rely on static initialization or log-replay data, limiting
their ability to model dynamic, long-horizon scenarios with evolving agent
populations. We propose InfGen, a scenario generation framework that outputs
agent states and trajectories in an autoregressive manner. InfGen represents
the entire scene as a sequence of tokens, including traffic light signals,
agent states, and motion vectors, and uses a transformer model to simulate
traffic over time. This design enables InfGen to continuously insert new agents
into traffic, supporting infinite scene generation. Experiments demonstrate
that InfGen produces realistic, diverse, and adaptive traffic behaviors.
Furthermore, reinforcement learning policies trained in InfGen-generated
scenarios achieve superior robustness and generalization, validating its
utility as a high-fidelity simulation environment for autonomous driving. More
information is available at https://metadriverse.github.io/infgen/.

</details>


### [229] [TAG-WM: Tamper-Aware Generative Image Watermarking via Diffusion Inversion Sensitivity](https://arxiv.org/abs/2506.23484)
*Yuzhuo Chen,Zehua Ma,Han Fang,Weiming Zhang,Nenghai Yu*

Main category: cs.MM

Relevance: 40.0

TL;DR: 本文提出了一种名为TAG-WM的篡改感知生成图像水印方法，解决了AIGC中的版权和真实性风险，同时保持了生成质量。


<details>
  <summary>Details</summary>
Motivation: AIGC的高效视觉创作带来了版权和真实性风险，数字水印技术成为潜在解决方案。然而，现有方法在篡改鲁棒性和主动定位能力上存在不足。

Method: TAG-WM包含四个模块：双标记联合采样（DMJS）、水印潜在重建（WLR）、密集变化区域检测器（DVRD）和篡改感知解码（TAD）。

Result: 实验表明，TAG-WM在保持无损生成质量和256位容量的同时，实现了SOTA的篡改鲁棒性和定位能力。

Conclusion: TAG-WM为AIGC中的版权保护和真实性验证提供了有效解决方案。

Abstract: AI-generated content (AIGC) enables efficient visual creation but raises
copyright and authenticity risks. As a common technique for integrity
verification and source tracing, digital image watermarking is regarded as a
potential solution to above issues. Among these, watermarking methods capable
of preserving the generation quality are receiving increased attention.
However, the proliferation and high performance of generative image editing
applications have elevated the risks of malicious tampering, creating new
demands. 1) The tamper robustness of current lossless visual quality watermarks
remains constrained by the modification-sensitive diffusion inversion process,
necessitating enhanced robustness. 2) The improved tampering quality and rapid
iteration cycles render passive tampering detection methods inadequate, making
proactive tampering localization capability a desired feature for watermarks.
To address these requirements, this paper proposes a Tamper-Aware Generative
image WaterMarking method named TAG-WM. The proposed method comprises four key
modules: a dual-mark joint sampling (DMJS) algorithm for embedding copyright
and localization watermarks into the latent space while preserving generative
quality, the watermark latent reconstruction (WLR) utilizing reversed DMJS, a
dense variation region detector (DVRD) leveraging diffusion inversion
sensitivity to identify tampered areas via statistical deviation analysis, and
the tamper-aware decoding (TAD) guided by localization results. The
experimental results indicate that TAG-WM achieves SOTA tampering robustness
and tampering localization capability with distortions while maintaining
lossless generation quality and a considerable capacity of 256 bits.

</details>


### [230] [AFUNet: Cross-Iterative Alignment-Fusion Synergy for HDR Reconstruction via Deep Unfolding Paradigm](https://arxiv.org/abs/2506.23537)
*Xinyue Li,Zhangkai Ni,Wenhan Yang*

Main category: eess.IV

Relevance: 40.0

TL;DR: AFUNet提出了一种基于深度展开网络的HDR图像重建方法，通过交替优化对齐和融合子任务，结合MAP估计和空间对应先验，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法依赖经验设计，缺乏理论支持，影响可靠性。AFUNet旨在通过数学基础和交替优化解决这一问题。

Method: AFUNet将HDR重建分解为对齐和融合子任务，通过交替优化和深度展开网络实现。设计了SAM和CFM模块逐步优化。

Result: AFUNet在定性和定量评估中均超越现有方法，表现出色。

Conclusion: AFUNet通过理论基础和模块化设计，显著提升了HDR重建的性能和可靠性。

Abstract: Existing learning-based methods effectively reconstruct HDR images from
multi-exposure LDR inputs with extended dynamic range and improved detail, but
they rely more on empirical design rather than theoretical foundation, which
can impact their reliability. To address these limitations, we propose the
cross-iterative Alignment and Fusion deep Unfolding Network (AFUNet), where HDR
reconstruction is systematically decoupled into two interleaved subtasks --
alignment and fusion -- optimized through alternating refinement, achieving
synergy between the two subtasks to enhance the overall performance. Our method
formulates multi-exposure HDR reconstruction from a Maximum A Posteriori (MAP)
estimation perspective, explicitly incorporating spatial correspondence priors
across LDR images and naturally bridging the alignment and fusion subproblems
through joint constraints. Building on the mathematical foundation, we
reimagine traditional iterative optimization through unfolding -- transforming
the conventional solution process into an end-to-end trainable AFUNet with
carefully designed modules that work progressively. Specifically, each
iteration of AFUNet incorporates an Alignment-Fusion Module (AFM) that
alternates between a Spatial Alignment Module (SAM) for alignment and a Channel
Fusion Module (CFM) for adaptive feature fusion, progressively bridging
misaligned content and exposure discrepancies. Extensive qualitative and
quantitative evaluations demonstrate AFUNet's superior performance,
consistently surpassing state-of-the-art methods. Our code is available at:
https://github.com/eezkni/AFUNet

</details>


### [231] [Diffusion Model-based Data Augmentation Method for Fetal Head Ultrasound Segmentation](https://arxiv.org/abs/2506.23664)
*Fangyijie Wang,Kevin Whelan,Félix Balado,Guénolé Silvestre,Kathleen M. Curran*

Main category: eess.IV

Relevance: 40.0

TL;DR: 提出了一种基于扩散模型的掩码引导生成AI方法，用于生成合成胎儿头部超声图像及其分割掩码，以增强真实数据集，从而提升SAM模型的微调效果。


<details>
  <summary>Details</summary>
Motivation: 医学图像数据因隐私和监管限制难以获取，且标注成本高。合成数据生成是解决这些挑战的有效途径。

Method: 采用扩散模型生成合成胎儿头部超声图像及其分割掩码，用于增强真实数据集并微调SAM模型。

Result: 合成数据能有效捕捉真实图像特征，在少量真实图像对的情况下达到最先进的胎儿头部分割效果（Dice分数分别为94.66%和94.38%）。

Conclusion: 掩码引导的生成AI方法在医学图像合成和分割任务中表现出色，尤其适用于数据稀缺的场景。

Abstract: Medical image data is less accessible than in other domains due to privacy
and regulatory constraints. In addition, labeling requires costly,
time-intensive manual image annotation by clinical experts. To overcome these
challenges, synthetic medical data generation offers a promising solution.
Generative AI (GenAI), employing generative deep learning models, has proven
effective at producing realistic synthetic images. This study proposes a novel
mask-guided GenAI approach using diffusion models to generate synthetic fetal
head ultrasound images paired with segmentation masks. These synthetic pairs
augment real datasets for supervised fine-tuning of the Segment Anything Model
(SAM). Our results show that the synthetic data captures real image features
effectively, and this approach reaches state-of-the-art fetal head
segmentation, especially when trained with a limited number of real image-mask
pairs. In particular, the segmentation reaches Dice Scores of 94.66\% and
94.38\% using a handful of ultrasound images from the Spanish and African
cohorts, respectively. Our code, models, and data are available on GitHub.

</details>


### [232] [MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation](https://arxiv.org/abs/2506.23700)
*Peiting Tian,Xi Chen,Haixia Bi,Fan Li*

Main category: eess.IV

Relevance: 40.0

TL;DR: MedSAM-CA是一种基于预训练模型MedSAM的架构级微调方法，通过引入CBR-Net和Atte-FFB组件，减少对大规模标注数据的依赖，提升医学图像分割的边界准确性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割依赖大规模标注数据，但隐私和高成本限制了数据获取；临床场景中的低对比度和模糊边界也增加了分割难度。

Method: 提出MedSAM-CA，结合CBR-Net（卷积注意力增强边界细化网络）和Atte-FFB（注意力增强特征融合块），优化MedSAM模型的分割性能。

Result: 在公开数据集（皮肤镜、CT、MRI）上验证，仅用2%训练数据即可达到94.43% Dice分数，接近全数据训练的97.25%性能。

Conclusion: MedSAM-CA在低资源临床场景中表现出色，显著减少对标注数据的依赖并提升分割精度。

Abstract: Medical image segmentation plays a crucial role in clinical diagnosis and
treatment planning, where accurate boundary delineation is essential for
precise lesion localization, organ identification, and quantitative assessment.
In recent years, deep learning-based methods have significantly advanced
segmentation accuracy. However, two major challenges remain. First, the
performance of these methods heavily relies on large-scale annotated datasets,
which are often difficult to obtain in medical scenarios due to privacy
concerns and high annotation costs. Second, clinically challenging scenarios,
such as low contrast in certain imaging modalities and blurry lesion boundaries
caused by malignancy, still pose obstacles to precise segmentation. To address
these challenges, we propose MedSAM-CA, an architecture-level fine-tuning
approach that mitigates reliance on extensive manual annotations by adapting
the pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CA
introduces two key components: the Convolutional Attention-Enhanced Boundary
Refinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block
(Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recover
boundary information potentially overlooked by long-range attention mechanisms,
leveraging hierarchical convolutional processing. Atte-FFB, embedded in the
MedSAM decoder, fuses multi-level fine-grained features from skip connections
in CBR-Net with global representations upsampled within the decoder to enhance
boundary delineation accuracy. Experiments on publicly available datasets
covering dermoscopy, CT, and MRI imaging modalities validate the effectiveness
of MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only
2% of full training data, reaching 97.25% of full-data training performance,
demonstrating strong effectiveness in low-resource clinical settings.

</details>


### [233] [MDPG: Multi-domain Diffusion Prior Guidance for MRI Reconstruction](https://arxiv.org/abs/2506.23701)
*Lingtong Zhang,Mengdie Song,Xiaohan Hao,Huayu Mai,Bensheng Qiu*

Main category: eess.IV

Relevance: 40.0

TL;DR: 提出了一种基于预训练潜在扩散模型（LDMs）的多域扩散先验引导（MDPG）方法，用于提升MRI重建任务的数据一致性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在MRI重建中因随机性难以生成高保真图像，而潜在扩散模型能提供紧凑且详细的先验知识，从而更有效地学习原始数据分布。

Method: 构建了基于Visual-Mamba的主干网络，集成预训练LDMs提供潜在和图像域的条件先验，提出Latent Guided Attention（LGA）和Dual-domain Fusion Branch（DFB）进行多域融合，并采用k空间正则化策略。

Result: 在两个公开MRI数据集上的实验验证了方法的有效性。

Conclusion: MDPG通过多域先验引导和融合策略，显著提升了MRI重建的数据一致性和图像质量。

Abstract: Magnetic Resonance Imaging (MRI) reconstruction is essential in medical
diagnostics. As the latest generative models, diffusion models (DMs) have
struggled to produce high-fidelity images due to their stochastic nature in
image domains. Latent diffusion models (LDMs) yield both compact and detailed
prior knowledge in latent domains, which could effectively guide the model
towards more effective learning of the original data distribution. Inspired by
this, we propose Multi-domain Diffusion Prior Guidance (MDPG) provided by
pre-trained LDMs to enhance data consistency in MRI reconstruction tasks.
Specifically, we first construct a Visual-Mamba-based backbone, which enables
efficient encoding and reconstruction of under-sampled images. Then pre-trained
LDMs are integrated to provide conditional priors in both latent and image
domains. A novel Latent Guided Attention (LGA) is proposed for efficient fusion
in multi-level latent domains. Simultaneously, to effectively utilize a prior
in both the k-space and image domain, under-sampled images are fused with
generated full-sampled images by the Dual-domain Fusion Branch (DFB) for
self-adaption guidance. Lastly, to further enhance the data consistency, we
propose a k-space regularization strategy based on the non-auto-calibration
signal (NACS) set. Extensive experiments on two public MRI datasets fully
demonstrate the effectiveness of the proposed methodology. The code is
available at https://github.com/Zolento/MDPG.

</details>


### [234] [ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction](https://arxiv.org/abs/2506.22498)
*Hao Liu,Yu Hu,Rakiba Rayhana,Ling Bai,Zheng Liu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于低成本负载传感器的床退出意图预测方法，通过图像融合和时间序列分类实现高效预测。


<details>
  <summary>Details</summary>
Motivation: 床相关跌倒问题在医院和长期护理设施中普遍存在，现有商业警报系统反应滞后，无法提前预警。

Method: 使用四个低成本负载传感器采集信号，转换为RGB线图和三种纹理图（递归图、马尔可夫转移场、格拉米安角场），并设计双流Swin Transformer（ViFusionTST）进行并行处理和跨模态融合。

Result: 在真实数据集上，ViFusionTST达到0.885的准确率和0.794的F1分数，优于现有基线。

Conclusion: 图像融合负载信号的时间序列分类是一种实用且高效的实时隐私保护跌倒预防方案。

Abstract: Bed-related falls remain a leading source of injury in hospitals and
long-term-care facilities, yet many commercial alarms trigger only after a
patient has already left the bed. We show that early bed-exit intent can be
predicted using only four low-cost load cells mounted under the bed legs. The
resulting load signals are first converted into a compact set of complementary
images: an RGB line plot that preserves raw waveforms and three texture maps -
recurrence plot, Markov transition field, and Gramian angular field - that
expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin
Transformer that processes the line plot and texture maps in parallel and fuses
them through cross-attention to learn data-driven modality weights.
  To provide a realistic benchmark, we collected six months of continuous data
from 95 beds in a long-term-care facility. On this real-world dataset
ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing
recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC.
The results demonstrate that image-based fusion of load-sensor signals for time
series classification is a practical and effective solution for real-time,
privacy-preserving fall prevention.

</details>


### [235] [Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data](https://arxiv.org/abs/2506.22499)
*Jiachao Liu,Pablo Guarda,Koichiro Niinuma,Sean Qian*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种利用卫星图像和传统交通数据的动态需求估计框架，显著提升了无本地传感器的链路估计性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统交通数据稀疏性问题，利用卫星图像提供更全面的交通信息。

Method: 设计计算机视觉流程提取车辆信息，构建计算图模型联合校准交通数据。

Result: 实验表明，卫星数据显著提升估计性能，尤其适用于无本地传感器的链路。

Conclusion: 框架具有大规模网络处理能力，适用于不同规模城市的实际部署。

Abstract: This study presents a novel integrated framework for dynamic
origin-destination demand estimation (DODE) in multi-class mesoscopic network
models, leveraging high-resolution satellite imagery together with conventional
traffic data from local sensors. Unlike sparse local detectors, satellite
imagery offers consistent, city-wide road and traffic information of both
parking and moving vehicles, overcoming data availability limitations. To
extract information from imagery data, we design a computer vision pipeline for
class-specific vehicle detection and map matching, generating link-level
traffic density observations by vehicle class. Building upon this information,
we formulate a computational graph-based DODE model that calibrates dynamic
network states by jointly matching observed traffic counts and travel times
from local sensors with density measurements derived from satellite imagery. To
assess the accuracy and scalability of the proposed framework, we conduct a
series of numerical experiments using both synthetic and real-world data. The
results of out-of-sample tests demonstrate that supplementing traditional data
with satellite-derived density significantly improves estimation performance,
especially for links without local sensors. Real-world experiments also confirm
the framework's capability to handle large-scale networks, supporting its
potential for practical deployment in cities of varying sizes. Sensitivity
analysis further evaluates the impact of data quality related to satellite
imagery data.

</details>


### [236] [Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection](https://arxiv.org/abs/2506.22504)
*Hassan Baker,Austin J. Brockmeier*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种无监督方法（Patch2Loc），通过训练神经网络从正常MRI补丁中学习其空间位置，以检测脑部异常组织。


<details>
  <summary>Details</summary>
Motivation: 脑部病变的检测对诊断和治疗至关重要，但现有监督方法需要标注数据，限制了应用范围。

Method: 训练神经网络将MRI补丁映射回其空间位置，通过预测误差和方差检测异常补丁，生成热图用于精细分割。

Result: 在多个数据集上验证了方法的有效性，优于现有无监督分割方法。

Conclusion: Patch2Loc为无监督脑部异常检测提供了高效解决方案。

Abstract: Detecting brain lesions as abnormalities observed in magnetic resonance
imaging (MRI) is essential for diagnosis and treatment. In the search of
abnormalities, such as tumors and malformations, radiologists may benefit from
computer-aided diagnostics that use computer vision systems trained with
machine learning to segment normal tissue from abnormal brain tissue. While
supervised learning methods require annotated lesions, we propose a new
unsupervised approach (Patch2Loc) that learns from normal patches taken from
structural MRI. We train a neural network model to map a patch back to its
spatial location within a slice of the brain volume. During inference, abnormal
patches are detected by the relatively higher error and/or variance of the
location prediction. This generates a heatmap that can be integrated into
pixel-wise methods to achieve finer-grained segmentation. We demonstrate the
ability of our model to segment abnormal brain tissues by applying our approach
to the detection of tumor tissues in MRI on T2-weighted images from BraTS2021
and MSLUB datasets and T1-weighted images from ATLAS and WMH datasets. We show
that it outperforms the state-of-the art in unsupervised segmentation. The
codebase for this work can be found on our
\href{https://github.com/bakerhassan/Patch2Loc}{GitHub page}.

</details>


### [237] [Automated Defect Identification and Categorization in NDE 4.0 with the Application of Artificial Intelligence](https://arxiv.org/abs/2506.22513)
*Aditya Sharma*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该研究开发了一个自动化框架，用于现代射线照相中的缺陷检测和组织，目标是解决信息不足的问题，并通过NDE测量验证框架的可行性。


<details>
  <summary>Details</summary>
Motivation: 解决现代射线照相中缺陷检测信息不足的问题，并验证自动化框架的可行性。

Method: 收集并分类223张飞机焊缝的CR照片，使用虚拟缺陷增强和数据增强技术优化数据集，训练改进的U-net模型进行语义缺陷分割。

Result: 模型在缺陷检测中表现出高灵敏度，尤其在a90/95特性下表现优异，且具有快速推理速度。

Conclusion: 该框架在焊缝检测中表现良好，具有实际应用潜力，可作为测试周期的支持工具。

Abstract: This investigation attempts to create an automated framework for fault
detection and organization for usage in contemporary radiography, as per NDE
4.0. The review's goals are to address the lack of information that is
sufficiently explained, learn how to make the most of virtual defect increase,
and determine whether the framework is viable by using NDE measurements. As its
basic information source, the technique consists of compiling and categorizing
223 CR photographs of airplane welds. Information expansion systems, such as
virtual defect increase and standard increase, are used to work on the
preparation dataset. A modified U-net model is prepared using the improved data
to produce semantic fault division veils. To assess the effectiveness of the
model, NDE boundaries such as Case, estimating exactness, and misleading call
rate are used. Tiny a90/95 characteristics, which provide strong
differentiating evidence of flaws, reveal that the suggested approach achieves
exceptional awareness in defect detection. Considering a 90/95, size error, and
fake call rate in the weld area, the consolidated expansion approach clearly
wins. Due to the framework's fast derivation speed, large images can be broken
down efficiently and quickly. Professional controllers evaluate the transmitted
system in the field and believe that it has a guarantee as a support device in
the testing cycle, irrespective of particular equipment cut-off points and
programming resemblance.

</details>


### [238] [Recomposed realities: animating still images via patch clustering and randomness](https://arxiv.org/abs/2506.22556)
*Markus Juvonen,Samuli Siltanen*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于图像块的重建和动画方法，通过运动让静态图像生动化。


<details>
  <summary>Details</summary>
Motivation: 利用现有图像数据，通过重新解释而非复制，实现静态图像的动态化。

Method: 使用k均值聚类对图像块进行分组，通过匹配和随机采样从这些簇中重建新目标图像。

Result: 能够在源域和目标域概念不同的情况下，共享局部结构，实现图像动画化。

Conclusion: 该方法提供了一种新颖的图像动画化途径，强调重新解释而非直接复制。

Abstract: We present a patch-based image reconstruction and animation method that uses
existing image data to bring still images to life through motion. Image patches
from curated datasets are grouped using k-means clustering and a new target
image is reconstructed by matching and randomly sampling from these clusters.
This approach emphasizes reinterpretation over replication, allowing the source
and target domains to differ conceptually while sharing local structures.

</details>


### [239] [Improving Token-based Object Detection with Video](https://arxiv.org/abs/2506.22562)
*Abhineet Singh,Nilanjan Ray*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文扩展了Pix2Seq目标检测器，提出了一种新的端到端视频目标检测方法，通过将对象表示为离散标记序列，解决了传统检测器的稀疏损失和后处理问题，并输出3D跟踪框。


<details>
  <summary>Details</summary>
Motivation: 改进现有视频目标检测方法，解决传统检测器在训练和推理中的局限性，如稀疏损失和后处理问题。

Method: 将视频对象表示为离散标记序列，输出3D跟踪框，无需传统检测器的框采样和后处理。

Result: 在多个数据集上表现优于静态Pix2Seq检测器，并在UA-DETRAC上与当前最优方法竞争。

Conclusion: 提出的方法在视频目标检测中具有竞争力，但受限于计算资源。

Abstract: This paper improves upon the Pix2Seq object detector by extending it for
videos. In the process, it introduces a new way to perform end-to-end video
object detection that improves upon existing video detectors in two key ways.
First, by representing objects as variable-length sequences of discrete tokens,
we can succinctly represent widely varying numbers of video objects, with
diverse shapes and locations, without having to inject any localization cues in
the training process. This eliminates the need to sample the space of all
possible boxes that constrains conventional detectors and thus solves the dual
problems of loss sparsity during training and heuristics-based postprocessing
during inference. Second, it conceptualizes and outputs the video objects as
fully integrated and indivisible 3D boxes or tracklets instead of generating
image-specific 2D boxes and linking these boxes together to construct the video
object, as done in most conventional detectors. This allows it to scale
effortlessly with available computational resources by simply increasing the
length of the video subsequence that the network takes as input, even
generalizing to multi-object tracking if the subsequence can span the entire
video. We compare our video detector with the baseline Pix2Seq static detector
on several datasets and demonstrate consistent improvement, although with
strong signs of being bottlenecked by our limited computational resources. We
also compare it with several video detectors on UA-DETRAC to show that it is
competitive with the current state of the art even with the computational
bottleneck. We make our code and models publicly available.

</details>


### [240] [Dual Atrous Separable Convolution for Improving Agricultural Semantic Segmentation](https://arxiv.org/abs/2506.22570)
*Chee Mei Ling,Thangarajah Akilan,Aparna Ravinda Phalke*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于DeepLabV3的高效农业图像语义分割方法，通过引入Dual Atrous Separable Convolution (DAS Conv)模块和优化的跳跃连接，在保持低计算复杂度的同时，性能接近复杂的Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 农业图像语义分割对精准农业至关重要，但现有方法在效率和性能之间难以平衡。

Method: 在DeepLabV3框架中集成DAS Conv模块，优化膨胀率和填充大小，并设计跳跃连接以增强空间特征捕捉。

Result: 在Agriculture Vision数据集上，模型性能接近SOTA Transformer模型，同时效率提升66%。

Conclusion: 该方法为农业遥感提供了一种高效且计算轻量的语义分割解决方案。

Abstract: Agricultural image semantic segmentation is a pivotal component of modern
agriculture, facilitating accurate visual data analysis to improve crop
management, optimize resource utilization, and boost overall productivity. This
study proposes an efficient image segmentation method for precision
agriculture, focusing on accurately delineating farmland anomalies to support
informed decision-making and proactive interventions. A novel Dual Atrous
Separable Convolution (DAS Conv) module is integrated within the
DeepLabV3-based segmentation framework. The DAS Conv module is meticulously
designed to achieve an optimal balance between dilation rates and padding size,
thereby enhancing model performance without compromising efficiency. The study
also incorporates a strategic skip connection from an optimal stage in the
encoder to the decoder to bolster the model's capacity to capture fine-grained
spatial features. Despite its lower computational complexity, the proposed
model outperforms its baseline and achieves performance comparable to highly
complex transformer-based state-of-the-art (SOTA) models on the Agriculture
Vision benchmark dataset. It achieves more than 66% improvement in efficiency
when considering the trade-off between model complexity and performance,
compared to the SOTA model. This study highlights an efficient and effective
solution for improving semantic segmentation in remote sensing applications,
offering a computationally lightweight model capable of high-quality
performance in agricultural imagery.

</details>


### [241] [LIGHT: Multi-Modal Text Linking on Historical Maps](https://arxiv.org/abs/2506.22589)
*Yijun Lin,Rhett Olson,Junhan Wu,Yao-Yi Chiang,Jerod Weinman*

Main category: cs.CV

Relevance: 30.0

TL;DR: LIGHT是一种多模态方法，结合语言、图像和几何特征，用于链接历史地图上的文本，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 历史地图上的文本信息对多学科研究有价值，但现有方法难以有效链接文本片段，尤其是多词地名。

Method: LIGHT整合了语言、图像和几何特征，包括几何感知嵌入模块，结合LayoutLMv3的预训练模型，通过双向学习策略预测文本实例的阅读顺序。

Result: LIGHT在ICDAR 2024/2025 MapText Competition数据上表现优于现有方法。

Conclusion: 多模态学习对历史地图文本链接有效。

Abstract: Text on historical maps provides valuable information for studies in history,
economics, geography, and other related fields. Unlike structured or
semi-structured documents, text on maps varies significantly in orientation,
reading order, shape, and placement. Many modern methods can detect and
transcribe text regions, but they struggle to effectively ``link'' the
recognized text fragments, e.g., determining a multi-word place name. Existing
layout analysis methods model word relationships to improve text understanding
in structured documents, but they primarily rely on linguistic features and
neglect geometric information, which is essential for handling map text. To
address these challenges, we propose LIGHT, a novel multi-modal approach that
integrates linguistic, image, and geometric features for linking text on
historical maps. In particular, LIGHT includes a geometry-aware embedding
module that encodes the polygonal coordinates of text regions to capture
polygon shapes and their relative spatial positions on an image. LIGHT unifies
this geometric information with the visual and linguistic token embeddings from
LayoutLMv3, a pretrained layout analysis model. LIGHT uses the cross-modal
information to predict the reading-order successor of each text instance
directly with a bi-directional learning strategy that enhances sequence
robustness. Experimental results show that LIGHT outperforms existing methods
on the ICDAR 2024/2025 MapText Competition data, demonstrating the
effectiveness of multi-modal learning for historical map text linking.

</details>


### [242] [3D Shape Generation: A Survey](https://arxiv.org/abs/2506.22678)
*Nicolas Caytuiro,Ivan Sipiran*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文是一篇关于3D形状生成的综述，总结了当前的研究进展，包括形状表示、生成方法和评估协议。


<details>
  <summary>Details</summary>
Motivation: 3D形状生成在深度学习的推动下取得了显著进展，但缺乏系统性的综述，本文旨在填补这一空白。

Method: 通过分类讨论3D形状的表示方法（显式、隐式和混合）、生成方法（前馈架构）以及评估指标（保真度、多样性和真实性）。

Result: 总结了当前的研究现状、常用数据集和评估方法，并指出了未来的研究方向。

Conclusion: 本文为研究人员提供了3D形状生成领域的全面参考，并提出了未来研究的挑战和方向。

Abstract: Recent advances in deep learning have significantly transformed the field of
3D shape generation, enabling the synthesis of complex, diverse, and
semantically meaningful 3D objects. This survey provides a comprehensive
overview of the current state of the art in 3D shape generation, organizing the
discussion around three core components: shape representations, generative
modeling approaches, and evaluation protocols. We begin by categorizing 3D
representations into explicit, implicit, and hybrid setups, highlighting their
structural properties, advantages, and limitations. Next, we review a wide
range of generation methods, focusing on feedforward architectures. We further
summarize commonly used datasets and evaluation metrics that assess fidelity,
diversity, and realism of generated shapes. Finally, we identify open
challenges and outline future research directions that could drive progress in
controllable, efficient, and high-quality 3D shape generation. This survey aims
to serve as a valuable reference for researchers and practitioners seeking a
structured and in-depth understanding of this rapidly evolving field.

</details>


### [243] [LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning](https://arxiv.org/abs/2506.22710)
*Jiang Yuan,JI Ma,Bo Wang,Guanzhou Ke,Weiming Hu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文提出了一种基于隐式退化估计的盲超分辨率方法（LightBSR），通过优化隐式退化表示（IDR）的区分性，设计了一个轻量且高效的模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了IDR区分性对盲超分辨率的重要性，且过度复杂化适应过程，导致模型参数和计算量大幅增加。

Method: 采用基于知识蒸馏的学习框架，包括退化先验约束对比学习技术和特征对齐技术。

Result: LightBSR在多种盲超分辨率任务中表现出色，且复杂度最低。

Conclusion: 优化IDR区分性可显著提升盲超分辨率模型的性能和效率。

Abstract: Implicit degradation estimation-based blind super-resolution (IDE-BSR) hinges
on extracting the implicit degradation representation (IDR) of the LR image and
adapting it to LR image features to guide HR detail restoration. Although
IDE-BSR has shown potential in dealing with noise interference and complex
degradations, existing methods ignore the importance of IDR discriminability
for BSR and instead over-complicate the adaptation process to improve effect,
resulting in a significant increase in the model's parameters and computations.
In this paper, we focus on the discriminability optimization of IDR and propose
a new powerful and lightweight BSR model termed LightBSR. Specifically, we
employ a knowledge distillation-based learning framework. We first introduce a
well-designed degradation-prior-constrained contrastive learning technique
during teacher stage to make the model more focused on distinguishing different
degradation types. Then we utilize a feature alignment technique to transfer
the degradation-related knowledge acquired by the teacher to the student for
practical inferencing. Extensive experiments demonstrate the effectiveness of
IDR discriminability-driven BSR model design. The proposed LightBSR can achieve
outstanding performance with minimal complexity across a range of blind SR
tasks. Our code is accessible at: https://github.com/MJ-NCEPU/LightBSR.

</details>


### [244] [Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians](https://arxiv.org/abs/2506.22718)
*Jun-Jee Chao,Qingyuan Jiang,Volkan Isler*

Main category: cs.CV

Relevance: 30.0

TL;DR: 本文提出了一种联合解决关节物体运动分析中部分分割和运动估计问题的方法，通过3D高斯表示实现，优于现有基于点对应的方法。


<details>
  <summary>Details</summary>
Motivation: 解决点云序列中关节物体的部分分割和运动估计问题，尤其是在点云非固定点集生成的情况下。

Method: 使用3D高斯表示物体，参数化时间依赖的旋转、平移和缩放，建立点与高斯的对应关系以实现分割和运动估计。

Result: 在遮挡情况下，部分分割性能优于现有方法13%，且对缺失点更鲁棒。

Conclusion: 提出的方法在关节物体运动分析中表现优异，尤其在遮挡和点云不完整情况下。

Abstract: Part segmentation and motion estimation are two fundamental problems for
articulated object motion analysis. In this paper, we present a method to solve
these two problems jointly from a sequence of observed point clouds of a single
articulated object. The main challenge in our problem setting is that the point
clouds are not assumed to be generated by a fixed set of moving points.
Instead, each point cloud in the sequence could be an arbitrary sampling of the
object surface at that particular time step. Such scenarios occur when the
object undergoes major occlusions, or if the dataset is collected using
measurements from multiple sensors asynchronously. In these scenarios, methods
that rely on tracking point correspondences are not appropriate. We present an
alternative approach based on a compact but effective representation where we
represent the object as a collection of simple building blocks modeled as 3D
Gaussians. We parameterize the Gaussians with time-dependent rotations,
translations, and scales that are shared across all time steps. With our
representation, part segmentation can be achieved by building correspondences
between the observed points and the Gaussians. Moreover, the transformation of
each point across time can be obtained by following the poses of the assigned
Gaussian (even when the point is not observed). Experiments show that our
method outperforms existing methods that solely rely on finding point
correspondences. Additionally, we extend existing datasets to emulate
real-world scenarios by considering viewpoint occlusions. We further
demonstrate that our method is more robust to missing points as compared to
existing approaches on these challenging datasets, even when some parts are
completely occluded in some time-steps. Notably, our part segmentation
performance outperforms the state-of-the-art method by 13% on point clouds with
occlusions.

</details>


### [245] [XTransfer: Cross-Modality Model Transfer for Human Sensing with Few Data at the Edge](https://arxiv.org/abs/2506.22726)
*Yu Zhang,Xi Zhang,Hualin zhou,Xinyuan Chen,Shang Gao,Hong Jia,Jianfei Yang,Yuankai Qi,Tao Gu*

Main category: cs.CV

Relevance: 30.0

TL;DR: XTransfer是一种资源高效、模态无关的模型迁移方法，通过模型修复和层重组解决边缘系统中人类感知任务的模态偏移和资源限制问题。


<details>
  <summary>Details</summary>
Motivation: 边缘系统中的人类感知任务面临传感器数据有限和资源受限的挑战，现有预训练模型迁移方法存在模态偏移和高资源需求问题。

Method: XTransfer通过模型修复（修复模态偏移）和层重组（高效搜索和重组源模型层）实现资源高效的模型迁移。

Result: XTransfer在多种人类感知任务上达到最优性能，显著降低了数据收集、模型训练和边缘部署的成本。

Conclusion: XTransfer为边缘系统中的人类感知任务提供了一种高效且通用的解决方案。

Abstract: Deep learning for human sensing on edge systems offers significant
opportunities for smart applications. However, its training and development are
hindered by the limited availability of sensor data and resource constraints of
edge systems. Current methods that rely on transferring pre-trained models
often encounter issues such as modality shift and high resource demands,
resulting in substantial accuracy loss, resource overhead, and poor
adaptability across different sensing applications. In this paper, we propose
XTransfer, a first-of-its-kind method for resource-efficient, modality-agnostic
model transfer. XTransfer freely leverages single or multiple pre-trained
models and transfers knowledge across different modalities by (i) model
repairing that safely repairs modality shift in pre-trained model layers with
only few sensor data, and (ii) layer recombining that efficiently searches and
recombines layers of interest from source models in a layer-wise manner to
create compact models. We benchmark various baselines across diverse human
sensing datasets spanning different modalities. Comprehensive results
demonstrate that XTransfer achieves state-of-the-art performance on human
sensing tasks while significantly reducing the costs of sensor data collection,
model training, and edge deployment.

</details>


### [246] [Degradation-Modeled Multipath Diffusion for Tunable Metalens Photography](https://arxiv.org/abs/2506.22753)
*Jianing Zhang,Jiayi Zhu,Feiyu Ji,Xiaokang Yang,Xiaoyun Yuan*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于预训练模型的金属透镜摄影方法，通过多路径扩散和伪数据增强实现高保真图像重建。


<details>
  <summary>Details</summary>
Motivation: 解决金属透镜成像中的光学退化和计算恢复难题，避免依赖大规模配对数据或精确光学校准。

Method: 采用退化建模多路径扩散框架，结合正、中、负提示路径和伪数据增强，引入空间变化退化感知注意力模块（SVDA）。

Result: 在真实世界MetaCamera上验证，优于现有方法，实现高保真和锐利的图像重建。

Conclusion: 该方法通过自然图像先验和可控解码器，有效平衡了保真度和感知质量。

Abstract: Metalenses offer significant potential for ultra-compact computational
imaging but face challenges from complex optical degradation and computational
restoration difficulties. Existing methods typically rely on precise optical
calibration or massive paired datasets, which are non-trivial for real-world
imaging systems. Furthermore, a lack of control over the inference process
often results in undesirable hallucinated artifacts. We introduce
Degradation-Modeled Multipath Diffusion for tunable metalens photography,
leveraging powerful natural image priors from pretrained models instead of
large datasets. Our framework uses positive, neutral, and negative-prompt paths
to balance high-frequency detail generation, structural fidelity, and
suppression of metalens-specific degradation, alongside \textit{pseudo} data
augmentation. A tunable decoder enables controlled trade-offs between fidelity
and perceptual quality. Additionally, a spatially varying degradation-aware
attention (SVDA) module adaptively models complex optical and sensor-induced
degradation. Finally, we design and build a millimeter-scale MetaCamera for
real-world validation. Extensive results show that our approach outperforms
state-of-the-art methods, achieving high-fidelity and sharp image
reconstruction. More materials: https://dmdiff.github.io/.

</details>


### [247] [PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection](https://arxiv.org/abs/2506.22783)
*Oguzhan Baser,Ahmet Ege Tanriverdi,Sriram Vishwanath,Sandeep P. Chinchali*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种名为PhonemeFake（PF）的深度伪造攻击方法，通过语言推理操纵关键语音片段，显著降低了人类感知和基准准确率。同时，论文开源了一个易于使用的PF数据集和检测模型，实验表明该模型在降低错误率的同时提升了速度。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造数据集未能真实反映实际攻击对人类感知的影响，因此需要更真实的攻击向量以改进检测技术。

Method: 引入PhonemeFake（PF）攻击方法，利用语言推理操纵语音片段；开发了双层检测模型，自适应优先计算被操纵区域。

Result: PF攻击使人类感知降低42%，基准准确率降低94%；检测模型将EER降低91%，速度提升90%，且计算开销低。

Conclusion: PF攻击和检测模型为深度伪造领域提供了更真实的攻击向量和高效的检测方案。

Abstract: Deepfake (DF) attacks pose a growing threat as generative models become
increasingly advanced. However, our study reveals that existing DF datasets
fail to deceive human perception, unlike real DF attacks that influence public
discourse. It highlights the need for more realistic DF attack vectors. We
introduce PhonemeFake (PF), a DF attack that manipulates critical speech
segments using language reasoning, significantly reducing human perception by
up to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF
dataset on HuggingFace and open-source bilevel DF segment detection model that
adaptively prioritizes compute on manipulated regions. Our extensive
experiments across three known DF datasets reveal that our detection model
reduces EER by 91% while achieving up to 90% speed-up, with minimal compute
overhead and precise localization beyond existing models as a scalable
solution.

</details>


### [248] [Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching](https://arxiv.org/abs/2506.22784)
*Yu Han,Zhiwei Huang,Yanting Zhang,Fangjun Ding,Shen Cai,Rui Fan*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于检测器自由匹配框架的点像素配准方法，用于LiDAR点云与相机图像的跨模态匹配，显著提升了稀疏单帧LiDAR下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决LiDAR点云与相机图像之间的模态差异和稀疏性问题，避免依赖多帧累积或额外先验。

Method: 将LiDAR强度图投影到2D视图，利用注意力机制的无检测器匹配网络进行跨模态匹配，并引入重复性评分机制提升可靠性。

Result: 在KITTI、nuScenes和MIAS-LCEC-TF70基准测试中达到最先进性能，优于依赖多帧累积的方法。

Conclusion: 该方法在单帧LiDAR下实现了高效的点像素配准，为跨模态感知任务提供了新思路。

Abstract: Point-pixel registration between LiDAR point clouds and camera images is a
fundamental yet challenging task in autonomous driving and robotic perception.
A key difficulty lies in the modality gap between unstructured point clouds and
structured images, especially under sparse single-frame LiDAR settings.
Existing methods typically extract features separately from point clouds and
images, then rely on hand-crafted or learned matching strategies. This separate
encoding fails to bridge the modality gap effectively, and more critically,
these methods struggle with the sparsity and noise of single-frame LiDAR, often
requiring point cloud accumulation or additional priors to improve reliability.
Inspired by recent progress in detector-free matching paradigms (e.g.
MatchAnything), we revisit the projection-based approach and introduce the
detector-free framework for direct point-pixel matching between LiDAR and
camera views. Specifically, we project the LiDAR intensity map into a 2D view
from the LiDAR perspective and feed it into an attention-based detector-free
matching network, enabling cross-modal correspondence estimation without
relying on multi-frame accumulation. To further enhance matching reliability,
we introduce a repeatability scoring mechanism that acts as a soft visibility
prior. This guides the network to suppress unreliable matches in regions with
low intensity variation, improving robustness under sparse input. Extensive
experiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that
our method achieves state-of-the-art performance, outperforming prior
approaches on nuScenes (even those relying on accumulated point clouds),
despite using only single-frame LiDAR.

</details>


### [249] [RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors](https://arxiv.org/abs/2506.22800)
*Sicong Du,Jiarun Liu,Qifeng Chen,Hao-Xiang Chen,Tai-Jiang Mu,Sheng Yang*

Main category: cs.CV

Relevance: 30.0

TL;DR: RGE-GS是一种新型扩展重建框架，结合扩散生成与奖励引导的高斯积分，解决了3D高斯泼溅技术中的物理不一致性和训练效率问题。


<details>
  <summary>Details</summary>
Motivation: 单次驾驶片段常导致道路结构扫描不完整，需扩展重建以有效回归驾驶行为。现有3D高斯泼溅技术虽质量高，但直接扩展会引入物理不一致性。

Method: RGE-GS框架包含奖励网络（优先选择稳定生成模式）和差异化训练策略（根据场景收敛指标调整优化进度）。

Result: 在公开数据集上，RGE-GS在重建质量上达到最优性能。

Conclusion: RGE-GS通过奖励引导和差异化训练，显著提升了重建质量和效率。

Abstract: A single-pass driving clip frequently results in incomplete scanning of the
road structure, making reconstructed scene expanding a critical requirement for
sensor simulators to effectively regress driving actions. Although contemporary
3D Gaussian Splatting (3DGS) techniques achieve remarkable reconstruction
quality, their direct extension through the integration of diffusion priors
often introduces cumulative physical inconsistencies and compromises training
efficiency. To address these limitations, we present RGE-GS, a novel expansive
reconstruction framework that synergizes diffusion-based generation with
reward-guided Gaussian integration. The RGE-GS framework incorporates two key
innovations: First, we propose a reward network that learns to identify and
prioritize consistently generated patterns prior to reconstruction phases,
thereby enabling selective retention of diffusion outputs for spatial
stability. Second, during the reconstruction process, we devise a
differentiated training strategy that automatically adjust Gaussian
optimization progress according to scene converge metrics, which achieving
better convergence than baseline methods. Extensive evaluations of publicly
available datasets demonstrate that RGE-GS achieves state-of-the-art
performance in reconstruction quality. Our source-code will be made publicly
available at https://github.com/CN-ADLab/RGE-GS. (Camera-ready version
incorporating reviewer suggestions will be updated soon.)

</details>


### [250] [FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition](https://arxiv.org/abs/2506.22807)
*Yueyang Li,Shengyu Gong,Weiming Zeng,Nizhuan Wang,Wai Ting Siok*

Main category: cs.CV

Relevance: 30.0

TL;DR: FreqDGT是一种频率自适应的动态图变换器，通过整合频率自适应处理、动态图学习和多尺度时间解缠网络，显著提高了跨被试情绪识别的准确性。


<details>
  <summary>Details</summary>
Motivation: EEG信号在情感识别中具有独特优势，但跨被试泛化仍面临个体差异的挑战。FreqDGT旨在解决这一问题。

Method: FreqDGT结合频率自适应处理（FAP）、自适应动态图学习（ADGL）和多尺度时间解缠网络（MTDN），动态建模情绪相关频率、脑连接模式和时间动态。

Result: 实验表明，FreqDGT显著提高了跨被试情绪识别的准确性，验证了其频率、空间和时间建模的有效性。

Conclusion: FreqDGT通过整合多模态建模，有效解决了跨被试情绪识别的挑战，为EEG情感识别提供了新方法。

Abstract: Electroencephalography (EEG) serves as a reliable and objective signal for
emotion recognition in affective brain-computer interfaces, offering unique
advantages through its high temporal resolution and ability to capture
authentic emotional states that cannot be consciously controlled. However,
cross-subject generalization remains a fundamental challenge due to individual
variability, cognitive traits, and emotional responses. We propose FreqDGT, a
frequency-adaptive dynamic graph transformer that systematically addresses
these limitations through an integrated framework. FreqDGT introduces
frequency-adaptive processing (FAP) to dynamically weight emotion-relevant
frequency bands based on neuroscientific evidence, employs adaptive dynamic
graph learning (ADGL) to learn input-specific brain connectivity patterns, and
implements multi-scale temporal disentanglement network (MTDN) that combines
hierarchical temporal transformers with adversarial feature disentanglement to
capture both temporal dynamics and ensure cross-subject robustness.
Comprehensive experiments demonstrate that FreqDGT significantly improves
cross-subject emotion recognition accuracy, confirming the effectiveness of
integrating frequency-adaptive, spatial-dynamic, and temporal-hierarchical
modeling while ensuring robustness to individual differences. The code is
available at https://github.com/NZWANG/FreqDGT.

</details>


### [251] [Efficient Multi-Crop Saliency Partitioning for Automatic Image Cropping](https://arxiv.org/abs/2506.22814)
*Andrew Hamara,Andrew C. Freeman*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种高效的多重非重叠图像裁剪方法，扩展了固定纵横比裁剪算法，动态调整注意力阈值并避免重复计算显著性图。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅优化单一边界框，无法满足需要多重不连续裁剪的应用需求。

Method: 扩展固定纵横比裁剪算法，动态调整注意力阈值并移除已选裁剪区域，避免重复计算显著性图。

Result: 方法在提取多重非重叠裁剪时效率高，且支持动态调整。

Conclusion: 该方法为多重裁剪提供了高效解决方案，并提出了未来数据集和基准的潜力。

Abstract: Automatic image cropping aims to extract the most visually salient regions
while preserving essential composition elements. Traditional saliency-aware
cropping methods optimize a single bounding box, making them ineffective for
applications requiring multiple disjoint crops. In this work, we extend the
Fixed Aspect Ratio Cropping algorithm to efficiently extract multiple
non-overlapping crops in linear time. Our approach dynamically adjusts
attention thresholds and removes selected crops from consideration without
recomputing the entire saliency map. We discuss qualitative results and
introduce the potential for future datasets and benchmarks.

</details>


### [252] [SemFaceEdit: Semantic Face Editing on Generative Radiance Manifolds](https://arxiv.org/abs/2506.22833)
*Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

Relevance: 30.0

TL;DR: SemFaceEdit是一种基于生成辐射流形的新方法，通过语义场实现面部图像的局部编辑，同时保持其他区域的完整性。


<details>
  <summary>Details</summary>
Motivation: 现有3D感知GAN技术虽然提供多视角一致性，但缺乏局部编辑能力，因此需要一种能够精确编辑特定面部语义的方法。

Method: SemFaceEdit通过几何模块和外观模块联合训练，生成语义辐射和占用场，并利用潜在代码解耦几何与外观。

Result: 实验表明，SemFaceEdit在语义场编辑中表现优异，实现了更好的辐射场解耦。

Conclusion: SemFaceEdit为面部图像的局部语义编辑提供了一种高效且精确的解决方案。

Abstract: Despite multiple view consistency offered by 3D-aware GAN techniques, the
resulting images often lack the capacity for localized editing. In response,
generative radiance manifolds emerge as an efficient approach for constrained
point sampling within volumes, effectively reducing computational demands and
enabling the learning of fine details. This work introduces SemFaceEdit, a
novel method that streamlines the appearance and geometric editing process by
generating semantic fields on generative radiance manifolds. Utilizing latent
codes, our method effectively disentangles the geometry and appearance
associated with different facial semantics within the generated image. In
contrast to existing methods that can change the appearance of the entire
radiance field, our method enables the precise editing of particular facial
semantics while preserving the integrity of other regions. Our network
comprises two key modules: the Geometry module, which generates semantic
radiance and occupancy fields, and the Appearance module, which is responsible
for predicting RGB radiance. We jointly train both modules in adversarial
settings to learn semantic-aware geometry and appearance descriptors. The
appearance descriptors are then conditioned on their respective semantic latent
codes by the Appearance Module, facilitating disentanglement and enhanced
control. Our experiments highlight SemFaceEdit's superior performance in
semantic field-based editing, particularly in achieving improved radiance field
disentanglement.

</details>


### [253] [AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results](https://arxiv.org/abs/2506.22843)
*Kien Nguyen,Clinton Fookes,Sridha Sridharan,Huy Nguyen,Feng Liu,Xiaoming Liu,Arun Ross,Dana Michalski,Tamás Endrei,Ivan DeAndres-Tame,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez,Javier Ortega-Garcia,Zijing Gong,Yuhao Wang,Xuehu Liu,Pingping Zhang,Md Rashidunnabi,Hugo Proença,Kailash A. Hambarde,Saeid Rezaei*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文介绍了AG-VPReID 2025挑战赛，专注于高海拔（80-120米）的空中-地面行人重识别（ReID），并提出了一个包含3,027个身份的大规模数据集。


<details>
  <summary>Details</summary>
Motivation: 解决空中与地面视角之间的领域差距问题，如极端视角差异、尺度变化和遮挡。

Method: 挑战赛中团队采用了多流架构、基于Transformer的时序推理和物理信息建模等方法。

Result: 最佳方法X-TFCLIP在空对地和地对空ReID设置中分别达到72.28%和70.77%的Rank-1准确率。

Conclusion: AG-VPReID 2025挑战赛展示了数据集的高复杂性，并为未来研究提供了基准。

Abstract: Person re-identification (ReID) across aerial and ground vantage points has
become crucial for large-scale surveillance and public safety applications.
Although significant progress has been made in ground-only scenarios, bridging
the aerial-ground domain gap remains a formidable challenge due to extreme
viewpoint differences, scale variations, and occlusions. Building upon the
achievements of the AG-ReID 2023 Challenge, this paper introduces the AG-VPReID
2025 Challenge - the first large-scale video-based competition focused on
high-altitude (80-120m) aerial-ground ReID. Constructed on the new AG-VPReID
dataset with 3,027 identities, over 13,500 tracklets, and approximately 3.7
million frames captured from UAVs, CCTV, and wearable cameras, the challenge
featured four international teams. These teams developed solutions ranging from
multi-stream architectures to transformer-based temporal reasoning and
physics-informed modeling. The leading approach, X-TFCLIP from UAM, attained
72.28% Rank-1 accuracy in the aerial-to-ground ReID setting and 70.77% in the
ground-to-aerial ReID setting, surpassing existing baselines while highlighting
the dataset's complexity. For additional details, please refer to the official
website at https://agvpreid25.github.io.

</details>


### [254] [DMD-Net: Deep Mesh Denoising Network](https://arxiv.org/abs/2506.22850)
*Aalok Gangopadhyay,Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

Relevance: 30.0

TL;DR: DMD-Net是一种用于网格去噪的端到端深度学习框架，结合了图卷积神经网络和特征引导变换器，表现出优异的去噪性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 网格去噪是3D对象处理中的重要问题，现有方法在极端噪声情况下表现不佳，需要一种更鲁棒和高效的解决方案。

Method: DMD-Net采用双流图卷积网络（原始图和双图）和特征引导变换器（FGT），通过特征提取、变换和去噪模块实现高效去噪。

Result: 在大型3D对象数据集上训练，DMD-Net在多种噪声情况下表现优于现有方法，且具有极高的鲁棒性。

Conclusion: DMD-Net通过创新的架构设计，显著提升了网格去噪的性能和鲁棒性，适用于复杂噪声场景。

Abstract: We present Deep Mesh Denoising Network (DMD-Net), an end-to-end deep learning
framework, for solving the mesh denoising problem. DMD-Net consists of a Graph
Convolutional Neural Network in which aggregation is performed in both the
primal as well as the dual graph. This is realized in the form of an asymmetric
two-stream network, which contains a primal-dual fusion block that enables
communication between the primal-stream and the dual-stream. We develop a
Feature Guided Transformer (FGT) paradigm, which consists of a feature
extractor, a transformer, and a denoiser. The feature extractor estimates the
local features, that guide the transformer to compute a transformation, which
is applied to the noisy input mesh to obtain a useful intermediate
representation. This is further processed by the denoiser to obtain the
denoised mesh. Our network is trained on a large scale dataset of 3D objects.
We perform exhaustive ablation studies to demonstrate that each component in
our network is essential for obtaining the best performance. We show that our
method obtains competitive or better results when compared with the
state-of-the-art mesh denoising algorithms. We demonstrate that our method is
robust to various kinds of noise. We observe that even in the presence of
extremely high noise, our method achieves excellent performance.

</details>


### [255] [Region-Aware CAM: High-Resolution Weakly-Supervised Defect Segmentation via Salient Region Perception](https://arxiv.org/abs/2506.22866)
*Hang-Cheng Dong,Lu Zou,Bingguo Liu,Dong Ye,Guodong Liu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文提出了一种弱监督语义分割框架，用于工业缺陷检测，通过区域感知类激活图和伪标签训练解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 工业缺陷检测需要大规模标注数据，但实际应用中难以满足。论文旨在提出一种弱监督方法，减少对标注数据的依赖。

Method: 结合过滤引导反向传播（FGBP）和区域感知加权模块，生成高分辨率热图，并通过伪标签迭代优化模型。

Result: 在工业缺陷数据集上验证了方法的优越性，实现了高精度缺陷分割。

Conclusion: 该框架为资源受限的工业场景提供了实用解决方案，填补了弱监督学习与高精度分割之间的空白。

Abstract: Surface defect detection plays a critical role in industrial quality
inspection. Recent advances in artificial intelligence have significantly
enhanced the automation level of detection processes. However, conventional
semantic segmentation and object detection models heavily rely on large-scale
annotated datasets, which conflicts with the practical requirements of defect
detection tasks. This paper proposes a novel weakly supervised semantic
segmentation framework comprising two key components: a region-aware class
activation map (CAM) and pseudo-label training. To address the limitations of
existing CAM methods, especially low-resolution thermal maps, and insufficient
detail preservation, we introduce filtering-guided backpropagation (FGBP),
which refines target regions by filtering gradient magnitudes to identify areas
with higher relevance to defects. Building upon this, we further develop a
region-aware weighted module to enhance spatial precision. Finally,
pseudo-label segmentation is implemented to refine the model's performance
iteratively. Comprehensive experiments on industrial defect datasets
demonstrate the superiority of our method. The proposed framework effectively
bridges the gap between weakly supervised learning and high-precision defect
segmentation, offering a practical solution for resource-constrained industrial
scenarios.

</details>


### [256] [Point Cloud Compression and Objective Quality Assessment: A Survey](https://arxiv.org/abs/2506.22902)
*Yiling Xu,Yujie Zhang,Shuting Xia,Kaifa Yang,He Huang,Ziyu Shan,Wenjie Huang,Qi Yang,Le Yang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 该论文综述了点云压缩（PCC）和质量评估（PCQA）的最新进展，分析了手工和基于学习的方法，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 3D点云数据在自动驾驶、机器人等领域的应用增长，亟需高效的压缩和质量评估技术。

Method: 综述了手工和基于学习的PCC算法及PCQA指标，并在新兴数据集上进行了基准测试。

Result: 提供了详细的方法比较和实用见解，指出了视觉保真度、延迟和多模态数据支持等挑战。

Conclusion: 未来方向包括混合压缩框架和高级特征提取策略，以实现更高效的3D应用。

Abstract: The rapid growth of 3D point cloud data, driven by applications in autonomous
driving, robotics, and immersive environments, has led to criticals demand for
efficient compression and quality assessment techniques. Unlike traditional 2D
media, point clouds present unique challenges due to their irregular structure,
high data volume, and complex attributes. This paper provides a comprehensive
survey of recent advances in point cloud compression (PCC) and point cloud
quality assessment (PCQA), emphasizing their significance for real-time and
perceptually relevant applications. We analyze a wide range of handcrafted and
learning-based PCC algorithms, along with objective PCQA metrics. By
benchmarking representative methods on emerging datasets, we offer detailed
comparisons and practical insights into their strengths and limitations.
Despite notable progress, challenges such as enhancing visual fidelity,
reducing latency, and supporting multimodal data remain. This survey outlines
future directions, including hybrid compression frameworks and advanced feature
extraction strategies, to enable more efficient, immersive, and intelligent 3D
applications.

</details>


### [257] [Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data](https://arxiv.org/abs/2506.22939)
*Ghufran A. Omran,Wassan Saad Abduljabbar Hayale,Ahmad AbdulQadir AlRababah,Israa Ibraheem Al-Barazanchi,Ravi Sekhar,Pritesh Shah,Sushma Parihar,Harshavardhan Reddy Penubadi*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种名为CO-BRNN的新方法，用于遥感图像场景分类，并在多种现有技术上取得了更高的准确率。


<details>
  <summary>Details</summary>
Motivation: 遥感图像场景分类在多个领域有广泛应用，但传统深度学习方法需要大量数据且难以处理噪声。

Method: 采用Cuttlefish优化的双向循环神经网络（CO-BRNN），并与多种现有技术（如MLP-CNN、CNN-LSTM等）进行比较。

Result: CO-BRNN取得了97%的最高准确率，优于其他方法。

Conclusion: CO-BRNN在遥感图像分类中表现出色，强调了物理验证的重要性。

Abstract: Scene categorization (SC) in remotely acquired images is an important subject
with broad consequences in different fields, including catastrophe control,
ecological observation, architecture for cities, and more. Nevertheless, its
several apps, reaching a high degree of accuracy in SC from distant observation
data has demonstrated to be difficult. This is because traditional conventional
deep learning models require large databases with high variety and high levels
of noise to capture important visual features. To address these problems, this
investigation file introduces an innovative technique referred to as the
Cuttlefish Optimized Bidirectional Recurrent Neural Network (CO- BRNN) for type
of scenes in remote sensing data. The investigation compares the execution of
CO-BRNN with current techniques, including Multilayer Perceptron- Convolutional
Neural Network (MLP-CNN), Convolutional Neural Network-Long Short Term Memory
(CNN-LSTM), and Long Short Term Memory-Conditional Random Field (LSTM-CRF),
Graph-Based (GB), Multilabel Image Retrieval Model (MIRM-CF), Convolutional
Neural Networks Data Augmentation (CNN-DA). The results demonstrate that
CO-BRNN attained the maximum accuracy of 97%, followed by LSTM-CRF with 90%,
MLP-CNN with 85%, and CNN-LSTM with 80%. The study highlights the significance
of physical confirmation to ensure the efficiency of satellite data.

</details>


### [258] [YM-WML: A new Yolo-based segmentation Model with Weighted Multi-class Loss for medical imaging](https://arxiv.org/abs/2506.22955)
*Haniyeh Nikkhah,Jafar Tanha,Mahdi Zarrin,SeyedEhsan Roshan,Amin Kazempour*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种名为YM-WML的新型模型，用于解决医学图像分割中的类别不平衡和复杂结构问题，并在ACDC数据集上取得了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临类别不平衡和复杂结构的挑战，需要一种更有效的解决方案。

Method: YM-WML结合了鲁棒的骨干网络、YOLOv11颈部模块和多尺度特征聚合，以及基于注意力的分割头，并引入了WME损失函数处理类别不平衡。

Result: 在ACDC数据集上，YM-WML的Dice相似系数达到91.02，优于现有方法，表现出稳定的训练和强泛化能力。

Conclusion: YM-WML为心脏分割任务设定了新的基准，具有精确分割和强泛化能力。

Abstract: Medical image segmentation poses significant challenges due to class
imbalance and the complex structure of medical images. To address these
challenges, this study proposes YM-WML, a novel model for cardiac image
segmentation. The model integrates a robust backbone for effective feature
extraction, a YOLOv11 neck for multi-scale feature aggregation, and an
attention-based segmentation head for precise and accurate segmentation. To
address class imbalance, we introduce the Weighted Multi-class Exponential
(WME) loss function. On the ACDC dataset, YM-WML achieves a Dice Similarity
Coefficient of 91.02, outperforming state-of-the-art methods. The model
demonstrates stable training, accurate segmentation, and strong generalization,
setting a new benchmark in cardiac segmentation tasks.

</details>


### [259] [VisionScores -- A system-segmented image score dataset for deep learning tasks](https://arxiv.org/abs/2506.23030)
*Alejandro Romero Amezcua,Mariano José Juan Rivera Meraz*

Main category: cs.CV

Relevance: 30.0

TL;DR: VisionScores introduces a novel dataset of system-segmented piano score images, focusing on two-handed pieces with high information density for machine learning tasks.


<details>
  <summary>Details</summary>
Motivation: To provide structured, high-density image data for machine learning, specifically tailored to piano music analysis, considering both graphic similarity and composition patterns.

Method: The dataset includes 24.8k grayscale images of piano scores, segmented into two scenarios: same composition type by different composers (14k samples) and different composition types by the same composer (10.8k samples). Metadata and full-page scores are also provided.

Result: A comprehensive dataset (VisionScores) is created, offering structured, high-density images and metadata for machine learning tasks in piano music analysis.

Conclusion: VisionScores is a valuable resource for machine learning applications in music, particularly for tasks requiring structured, high-density image data.

Abstract: VisionScores presents a novel proposal being the first system-segmented image
score dataset, aiming to offer structure-rich, high information-density images
for machine and deep learning tasks. Delimited to two-handed piano pieces, it
was built to consider not only certain graphic similarity but also composition
patterns, as this creative process is highly instrument-dependent. It provides
two scenarios in relation to composer and composition type. The first, formed
by 14k samples, considers works from different authors but the same composition
type, specifically, Sonatinas. The latter, consisting of 10.8K samples,
presents the opposite case, various composition types from the same author,
being the one selected Franz Liszt. All of the 24.8k samples are formatted as
grayscale jpg images of $128 \times 512$ pixels. VisionScores supplies the
users not only the formatted samples but the systems' order and pieces'
metadata. Moreover, unsegmented full-page scores and the pre-formatted images
are included for further analysis.

</details>


### [260] [From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient 3D Gaussian Splatting](https://arxiv.org/abs/2506.23042)
*Hung Nguyen,An Le,Runfa Li,Truong Nguyen*

Main category: cs.CV

Relevance: 30.0

TL;DR: AutoOpti3DGS是一个训练时框架，通过离散小波变换控制高斯原语的增殖，减少内存和带宽压力，同时保持视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 3D高斯喷涂在新型视图合成中表现强大，但高斯原语的不断增长会占用大量内存和带宽。AutoOpti3DGS旨在解决这一问题。

Method: 使用可学习的离散小波变换序列，固定低通滤波器，学习高通滤波器，并通过正交性损失逐步激活精细频率，实现从粗到细的过程。

Result: AutoOpti3DGS仅需一个超参数，与现有3DGS框架无缝集成，生成更稀疏的场景表示，更适合内存或存储受限的硬件。

Conclusion: AutoOpti3DGS有效控制了高斯原语的增殖，优化了3D高斯喷涂的性能。

Abstract: 3D Gaussian Splatting has emerged as a powerful approach in novel view
synthesis, delivering rapid training and rendering but at the cost of an
ever-growing set of Gaussian primitives that strains memory and bandwidth. We
introduce AutoOpti3DGS, a training-time framework that automatically restrains
Gaussian proliferation without sacrificing visual fidelity. The key idea is to
feed the input images to a sequence of learnable Forward and Inverse Discrete
Wavelet Transforms, where low-pass filters are kept fixed, high-pass filters
are learnable and initialized to zero, and an auxiliary orthogonality loss
gradually activates fine frequencies. This wavelet-driven, coarse-to-fine
process delays the formation of redundant fine Gaussians, allowing 3DGS to
capture global structure first and refine detail only when necessary. Through
extensive experiments, AutoOpti3DGS requires just a single filter learning-rate
hyper-parameter, integrates seamlessly with existing efficient 3DGS frameworks,
and consistently produces sparser scene representations more compatible with
memory or storage-constrained hardware.

</details>


### [261] [Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization](https://arxiv.org/abs/2506.23077)
*Suofei Zhang,Xinxin Wang,Xiaofu Wu,Quan Zhou,Haifeng Hu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种距离感知的跨视角地理定位方法（DACVGL），并构建了首个多视角图像与精确距离标注的基准数据集DA-Campus。通过动态对比学习（DyCL）框架，解决了传统度量学习难以处理的空间关系复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 现有跨视角地理定位方法主要关注跨域图像匹配精度，而忽略了目标周围上下文信息的全面捕捉和定位误差成本的最小化。

Method: 构建了DA-Campus基准数据集，将DACVGL问题定义为跨域分层检索任务，并提出动态对比学习（DyCL）框架，逐步对齐特征表示。

Result: DyCL与现有多尺度度量学习方法高度互补，显著提升了分层检索性能和跨视角地理定位精度。

Conclusion: DyCL框架有效解决了跨视角地理定位中的空间关系复杂性问题，为未来研究提供了新方向。

Abstract: Existing deep learning-based cross-view geo-localization methods primarily
focus on improving the accuracy of cross-domain image matching, rather than
enabling models to comprehensively capture contextual information around the
target and minimize the cost of localization errors. To support systematic
research into this Distance-Aware Cross-View Geo-Localization (DACVGL) problem,
we construct Distance-Aware Campus (DA-Campus), the first benchmark that pairs
multi-view imagery with precise distance annotations across three spatial
resolutions. Based on DA-Campus, we formulate DACVGL as a hierarchical
retrieval problem across different domains. Our study further reveals that, due
to the inherent complexity of spatial relationships among buildings, this
problem can only be addressed via a contrastive learning paradigm, rather than
conventional metric learning. To tackle this challenge, we propose Dynamic
Contrastive Learning (DyCL), a novel framework that progressively aligns
feature representations according to hierarchical spatial margins. Extensive
experiments demonstrate that DyCL is highly complementary to existing
multi-scale metric learning methods and yields substantial improvements in both
hierarchical retrieval performance and overall cross-view geo-localization
accuracy. Our code and benchmark are publicly available at
https://github.com/anocodetest1/DyCL.

</details>


### [262] [Frequency-enhanced Multi-granularity Context Network for Efficient Vertebrae Segmentation](https://arxiv.org/abs/2506.23086)
*Jian Shi,Tianqi You,Pingping Zhang,Hongli Zhang,Rui Xu,Haojie Li*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种频率增强多粒度上下文网络（FMC-Net），用于提高3D CT和MRI图像中脊椎分割的准确性，通过小波变换和多粒度状态空间模型（MG-SSM）处理高低频特征。


<details>
  <summary>Details</summary>
Motivation: 当前脊椎分割方法在图像模糊和相似脊椎区分方面存在局限性，FMC-Net旨在解决这些问题。

Method: 使用小波变换进行无损下采样，分别处理高低频特征：高频特征通过HFR增强关键特征，低频特征通过MG-SSM捕获长程依赖和多粒度上下文。

Result: 实验表明，FMC-Net在CT和MRI脊椎分割数据集上优于现有方法。

Conclusion: FMC-Net通过频率增强和多粒度上下文建模，显著提高了脊椎分割的准确性。

Abstract: Automated and accurate segmentation of individual vertebra in 3D CT and MRI
images is essential for various clinical applications. Due to the limitations
of current imaging techniques and the complexity of spinal structures, existing
methods still struggle with reducing the impact of image blurring and
distinguishing similar vertebrae. To alleviate these issues, we introduce a
Frequency-enhanced Multi-granularity Context Network (FMC-Net) to improve the
accuracy of vertebrae segmentation. Specifically, we first apply wavelet
transform for lossless downsampling to reduce the feature distortion in blurred
images. The decomposed high and low-frequency components are then processed
separately. For the high-frequency components, we apply a High-frequency
Feature Refinement (HFR) to amplify the prominence of key features and filter
out noises, restoring fine-grained details in blurred images. For the
low-frequency components, we use a Multi-granularity State Space Model (MG-SSM)
to aggregate feature representations with different receptive fields,
extracting spatially-varying contexts while capturing long-range dependencies
with linear complexity. The utilization of multi-granularity contexts is
essential for distinguishing similar vertebrae and improving segmentation
accuracy. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches on both CT and MRI vertebrae segmentation datasets.
The source code is publicly available at https://github.com/anaanaa/FMCNet.

</details>


### [263] [Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound](https://arxiv.org/abs/2506.23108)
*Zhiyuan Zhu,Jian Wang,Yong Jiang,Tong Han,Yuhao Huang,Ang Zhang,Kaiwen Yang,Mingyuan Luo,Zhe Liu,Yaofei Duan,Dong Ni,Tianhong Tang,Xin Yang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种新的多视图分类框架CVC-RF，用于颈动脉斑块分级（CPG），通过多级细化提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在多视图分类中忽视表示学习和类别特征差异，CVC-RF旨在解决这些问题。

Method: CVC-RF在语料库、视图和类别三个层次处理信息，包括中心记忆对比损失、级联下采样注意力模块和无参数专家混合加权策略。

Result: 实验表明CVC-RF在CPG任务中表现优异，达到最先进水平。

Conclusion: CVC-RF通过多级细化有效建模全局特征，提升CPG任务性能。

Abstract: Accurate carotid plaque grading (CPG) is vital to assess the risk of
cardiovascular and cerebrovascular diseases. Due to the small size and high
intra-class variability of plaque, CPG is commonly evaluated using a
combination of transverse and longitudinal ultrasound views in clinical
practice. However, most existing deep learning-based multi-view classification
methods focus on feature fusion across different views, neglecting the
importance of representation learning and the difference in class features. To
address these issues, we propose a novel Corpus-View-Category Refinement
Framework (CVC-RF) that processes information from Corpus-, View-, and
Category-levels, enhancing model performance. Our contribution is four-fold.
First, to the best of our knowledge, we are the foremost deep learning-based
method for CPG according to the latest Carotid Plaque-RADS guidelines. Second,
we propose a novel center-memory contrastive loss, which enhances the network's
global modeling capability by comparing with representative cluster centers and
diverse negative samples at the Corpus level. Third, we design a cascaded
down-sampling attention module to fuse multi-scale information and achieve
implicit feature interaction at the View level. Finally, a parameter-free
mixture-of-experts weighting strategy is introduced to leverage class
clustering knowledge to weight different experts, enabling feature decoupling
at the Category level. Experimental results indicate that CVC-RF effectively
models global features via multi-level refinement, achieving state-of-the-art
performance in the challenging CPG task.

</details>


### [264] [Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval](https://arxiv.org/abs/2506.23132)
*Sophie Zhou,Shu Kong*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于视觉基础模型DINOv2的艺术抄袭检测方法，通过微调提升检索性能，但识别准确率略有下降。


<details>
  <summary>Details</summary>
Motivation: 艺术抄袭检测对保护艺术家版权至关重要，但现有方法在检索精度和识别准确率之间存在权衡。

Method: 使用DINOv2提取特征并检索相似图像，通过度量学习微调模型以提升检索性能。

Result: 基线方法识别准确率达97.2%，但检索精度仅29.0%；微调后检索精度提升12%，但识别准确率降至92.7%。

Conclusion: 研究揭示了检索精度与识别准确率之间的权衡，并提出了未来研究方向。

Abstract: Art plagiarism detection plays a crucial role in protecting artists'
copyrights and intellectual property, yet it remains a challenging problem in
forensic analysis. In this paper, we address the task of recognizing
plagiarized paintings and explaining the detected plagarisms by retrieving
visually similar authentic artworks. To support this study, we construct a
dataset by collecting painting photos and synthesizing plagiarized versions
using generative AI, tailored to specific artists' styles. We first establish a
baseline approach using off-the-shelf features from the visual foundation model
DINOv2 to retrieve the most similar images in the database and classify
plagiarism based on a similarity threshold. Surprisingly, this non-learned
method achieves a high recognition accuracy of 97.2\% but suffers from low
retrieval precision 29.0\% average precision (AP). To improve retrieval
quality, we finetune DINOv2 with a metric learning loss using positive and
negative sample pairs sampled in the database. The finetuned model greatly
improves retrieval performance by 12\% AP over the baseline, though it
unexpectedly results in a lower recognition accuracy (92.7\%). We conclude with
insightful discussions and outline directions for future research.

</details>


### [265] [AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation](https://arxiv.org/abs/2506.23150)
*Xinyue Liang,Zhiyuan Ma,Lingchen Sun,Yanjun Guo,Lei Zhang*

Main category: cs.CV

Relevance: 30.0

TL;DR: AlignCVC通过分布对齐改进单图像到3D生成中的跨视图一致性（CVC），提出软硬对齐策略，显著提升生成质量和推理速度。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖回归损失，但中间生成的多视图图像缺乏跨视图一致性（CVC），影响3D重建性能。

Method: 提出AlignCVC框架，通过分布对齐而非回归损失，对齐生成和重建的多视图分布到真实分布，采用软硬对齐策略。

Result: 实验证明AlignCVC有效提升CVC，推理速度加快至4步，兼容多种多视图生成和3D重建模型。

Conclusion: AlignCVC为单图像到3D生成提供了高效且一致的解决方案。

Abstract: Single-image-to-3D models typically follow a sequential generation and
reconstruction workflow. However, intermediate multi-view images synthesized by
pre-trained generation models often lack cross-view consistency (CVC),
significantly degrading 3D reconstruction performance. While recent methods
attempt to refine CVC by feeding reconstruction results back into the
multi-view generator, these approaches struggle with noisy and unstable
reconstruction outputs that limit effective CVC improvement. We introduce
AlignCVC, a novel framework that fundamentally re-frames single-image-to-3D
generation through distribution alignment rather than relying on strict
regression losses. Our key insight is to align both generated and reconstructed
multi-view distributions toward the ground-truth multi-view distribution,
establishing a principled foundation for improved CVC. Observing that generated
images exhibit weak CVC while reconstructed images display strong CVC due to
explicit rendering, we propose a soft-hard alignment strategy with distinct
objectives for generation and reconstruction models. This approach not only
enhances generation quality but also dramatically accelerates inference to as
few as 4 steps. As a plug-and-play paradigm, our method, namely AlignCVC,
seamlessly integrates various multi-view generation models with 3D
reconstruction models. Extensive experiments demonstrate the effectiveness and
efficiency of AlignCVC for single-image-to-3D generation.

</details>


### [266] [Dynamic View Synthesis from Small Camera Motion Videos](https://arxiv.org/abs/2506.23153)
*Huiqiang Sun,Xingyi Li,Juewen Peng,Liao Shen,Zhiguo Cao,Ke Xian,Guosheng Lin*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种新的分布深度正则化（DDR）方法，解决了动态3D场景新视角合成中因小相机运动导致的几何表示和相机参数估计问题。


<details>
  <summary>Details</summary>
Motivation: 动态3D场景的新视角合成在输入图像或视频中相机运动范围有限时，现有方法难以准确表示场景几何和估计相机参数。

Method: 提出DDR方法，通过Gumbel-softmax采样点计算误差期望，并引入约束确保场景几何正确。同时，训练中学习相机参数以提高鲁棒性。

Result: 实验表明，该方法在小相机运动输入下优于现有方法。

Conclusion: DDR方法有效解决了小相机运动下的场景表示问题，并提升了相机参数估计的鲁棒性。

Abstract: Novel view synthesis for dynamic $3$D scenes poses a significant challenge.
Many notable efforts use NeRF-based approaches to address this task and yield
impressive results. However, these methods rely heavily on sufficient motion
parallax in the input images or videos. When the camera motion range becomes
limited or even stationary (i.e., small camera motion), existing methods
encounter two primary challenges: incorrect representation of scene geometry
and inaccurate estimation of camera parameters. These challenges make prior
methods struggle to produce satisfactory results or even become invalid. To
address the first challenge, we propose a novel Distribution-based Depth
Regularization (DDR) that ensures the rendering weight distribution to align
with the true distribution. Specifically, unlike previous methods that use
depth loss to calculate the error of the expectation, we calculate the
expectation of the error by using Gumbel-softmax to differentiably sample
points from discrete rendering weight distribution. Additionally, we introduce
constraints that enforce the volume density of spatial points before the object
boundary along the ray to be near zero, ensuring that our model learns the
correct geometry of the scene. To demystify the DDR, we further propose a
visualization tool that enables observing the scene geometry representation at
the rendering weight level. For the second challenge, we incorporate camera
parameter learning during training to enhance the robustness of our model to
camera parameters. We conduct extensive experiments to demonstrate the
effectiveness of our approach in representing scenes with small camera motion
input, and our results compare favorably to state-of-the-art methods.

</details>


### [267] [STD-GS: Exploring Frame-Event Interaction for SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic Scene](https://arxiv.org/abs/2506.23157)
*Hanyu Zhou,Haonan Wang,Haoyue Liu,Yuxing Duan,Luxin Yan,Gim Hee Lee*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种时空解耦的高斯溅射框架，用于高动态场景重建，结合事件相机和帧相机，通过聚类区分背景和对象的时空特征。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用统一表示模型（如高斯）难以处理动态场景中潜在的时空特征不连续性和异质性，因此需要解耦时空特征以提高重建质量。

Method: 引入事件相机补偿帧相机，提出时空解耦的高斯溅射框架，通过聚类区分背景和对象的时空特征，并利用高斯表示与事件数据的一致性指导对象的时空解耦。

Result: 实验验证了所提方法在高动态场景重建中的优越性。

Conclusion: 时空解耦的高斯溅射框架能够有效提高动态场景的时空分辨率和重建质量。

Abstract: High-dynamic scene reconstruction aims to represent static background with
rigid spatial features and dynamic objects with deformed continuous
spatiotemporal features. Typically, existing methods adopt unified
representation model (e.g., Gaussian) to directly match the spatiotemporal
features of dynamic scene from frame camera. However, this unified paradigm
fails in the potential discontinuous temporal features of objects due to frame
imaging and the heterogeneous spatial features between background and objects.
To address this issue, we disentangle the spatiotemporal features into various
latent representations to alleviate the spatiotemporal mismatching between
background and objects. In this work, we introduce event camera to compensate
for frame camera, and propose a spatiotemporal-disentangled Gaussian splatting
framework for high-dynamic scene reconstruction. As for dynamic scene, we
figure out that background and objects have appearance discrepancy in
frame-based spatial features and motion discrepancy in event-based temporal
features, which motivates us to distinguish the spatiotemporal features between
background and objects via clustering. As for dynamic object, we discover that
Gaussian representations and event data share the consistent spatiotemporal
characteristic, which could serve as a prior to guide the spatiotemporal
disentanglement of object Gaussians. Within Gaussian splatting framework, the
cumulative scene-object disentanglement can improve the spatiotemporal
discrimination between background and objects to render the time-continuous
dynamic scene. Extensive experiments have been performed to verify the
superiority of the proposed method.

</details>


### [268] [Trident: Detecting Face Forgeries with Adversarial Triplet Learning](https://arxiv.org/abs/2506.23189)
*Mustafa Hakan Kara,Aysegul Dundar,Uğur Güdükbay*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种名为Trident的人脸伪造检测框架，通过三元组学习和Siamese网络结构提升对不同伪造方法的适应性，结合领域对抗训练增强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着深度神经网络生成的人脸伪造技术日益复杂，检测数字媒体中的人脸伪造成为重要挑战，现有基于监督训练的模型对未见过的方法表现不佳。

Method: 采用三元组学习和Siamese网络结构，结合领域对抗训练和梯度控制，提取伪造无关的特征表示。

Result: 在多个基准测试和消融研究中验证了框架的有效性。

Conclusion: Trident框架通过三元组学习和对抗训练显著提升了人脸伪造检测的泛化能力和鲁棒性。

Abstract: As face forgeries generated by deep neural networks become increasingly
sophisticated, detecting face manipulations in digital media has posed a
significant challenge, underscoring the importance of maintaining digital media
integrity and combating visual disinformation. Current detection models,
predominantly based on supervised training with domain-specific data, often
falter against forgeries generated by unencountered techniques. In response to
this challenge, we introduce \textit{Trident}, a face forgery detection
framework that employs triplet learning with a Siamese network architecture for
enhanced adaptability across diverse forgery methods. \textit{Trident} is
trained on curated triplets to isolate nuanced differences of forgeries,
capturing fine-grained features that distinguish pristine samples from
manipulated ones while controlling for other variables. To further enhance
generalizability, we incorporate domain-adversarial training with a forgery
discriminator. This adversarial component guides our embedding model towards
forgery-agnostic representations, improving its robustness to unseen
manipulations. In addition, we prevent gradient flow from the classifier head
to the embedding model, avoiding overfitting induced by artifacts peculiar to
certain forgeries. Comprehensive evaluations across multiple benchmarks and
ablation studies demonstrate the effectiveness of our framework. We will
release our code in a GitHub repository.

</details>


### [269] [BridgeShape: Latent Diffusion Schrödinger Bridge for 3D Shape Completion](https://arxiv.org/abs/2506.23205)
*Dequan Kong,Zhe Zhu,Honghua Chen,Mingqiang Wei*

Main category: cs.CV

Relevance: 30.0

TL;DR: BridgeShape提出了一种基于潜在扩散Schrödinger桥的3D形状补全框架，通过最优传输路径和深度增强的VQ-VAE编码，解决了现有方法在全局一致性和分辨率限制上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的3D形状补全方法未能显式建模最优全局传输路径，且受限于体素空间的分辨率约束，导致补全效果不佳。

Method: BridgeShape将形状补全建模为最优传输问题，并引入深度增强的VQ-VAE编码3D形状到紧凑潜在空间，以提升几何结构感知。

Result: BridgeShape在大规模3D形状补全基准测试中达到最优性能，支持更高分辨率和未见物体类别的补全。

Conclusion: BridgeShape通过潜在扩散和最优传输路径的显式建模，显著提升了3D形状补全的全局一致性和细节生成能力。

Abstract: Existing diffusion-based 3D shape completion methods typically use a
conditional paradigm, injecting incomplete shape information into the denoising
network via deep feature interactions (e.g., concatenation, cross-attention) to
guide sampling toward complete shapes, often represented by voxel-based
distance functions. However, these approaches fail to explicitly model the
optimal global transport path, leading to suboptimal completions. Moreover,
performing diffusion directly in voxel space imposes resolution constraints,
limiting the generation of fine-grained geometric details. To address these
challenges, we propose BridgeShape, a novel framework for 3D shape completion
via latent diffusion Schr\"odinger bridge. The key innovations lie in two
aspects: (i) BridgeShape formulates shape completion as an optimal transport
problem, explicitly modeling the transition between incomplete and complete
shapes to ensure a globally coherent transformation. (ii) We introduce a
Depth-Enhanced Vector Quantized Variational Autoencoder (VQ-VAE) to encode 3D
shapes into a compact latent space, leveraging self-projected multi-view depth
information enriched with strong DINOv2 features to enhance geometric
structural perception. By operating in a compact yet structurally informative
latent space, BridgeShape effectively mitigates resolution constraints and
enables more efficient and high-fidelity 3D shape completion. BridgeShape
achieves state-of-the-art performance on large-scale 3D shape completion
benchmarks, demonstrating superior fidelity at higher resolutions and for
unseen object classes.

</details>


### [270] [TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints](https://arxiv.org/abs/2506.23207)
*Zhen Tan,Xieyuanli Chen,Lei Feng,Yangbing Ge,Shuaifeng Zhi,Jiaxiong Liu,Dewen Hu*

Main category: cs.CV

Relevance: 30.0

TL;DR: TVG-SLAM是一种基于3D高斯喷洒（3DGS）的RGB-only SLAM系统，通过三视图几何范式提升跟踪和映射的鲁棒性，尤其在户外环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS SLAM系统过度依赖光度渲染损失，导致在户外环境中对视角和光照变化的鲁棒性不足。

Method: 引入三视图匹配模块和混合几何约束，结合光度损失提升跟踪稳定性；提出概率初始化策略和动态渲染信任衰减机制优化映射。

Result: 在多个户外数据集上，TVG-SLAM显著提升了跟踪鲁棒性（ATE降低69.0%）并达到最先进的渲染质量。

Conclusion: TVG-SLAM通过几何约束和动态机制解决了3DGS SLAM在户外环境中的挑战，实现了高性能。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled RGB-only SLAM
systems to achieve high-fidelity scene representation. However, the heavy
reliance of existing systems on photometric rendering loss for camera tracking
undermines their robustness, especially in unbounded outdoor environments with
severe viewpoint and illumination changes. To address these challenges, we
propose TVG-SLAM, a robust RGB-only 3DGS SLAM system that leverages a novel
tri-view geometry paradigm to ensure consistent tracking and high-quality
mapping. We introduce a dense tri-view matching module that aggregates reliable
pairwise correspondences into consistent tri-view matches, forming robust
geometric constraints across frames. For tracking, we propose Hybrid Geometric
Constraints, which leverage tri-view matches to construct complementary
geometric cues alongside photometric loss, ensuring accurate and stable pose
estimation even under drastic viewpoint shifts and lighting variations. For
mapping, we propose a new probabilistic initialization strategy that encodes
geometric uncertainty from tri-view correspondences into newly initialized
Gaussians. Additionally, we design a Dynamic Attenuation of Rendering Trust
mechanism to mitigate tracking drift caused by mapping latency. Experiments on
multiple public outdoor datasets show that our TVG-SLAM outperforms prior
RGB-only 3DGS-based SLAM systems. Notably, in the most challenging dataset, our
method improves tracking robustness, reducing the average Absolute Trajectory
Error (ATE) by 69.0\% while achieving state-of-the-art rendering quality. The
implementation of our method will be released as open-source.

</details>


### [271] [A Hierarchical Slice Attention Network for Appendicitis Classification in 3D CT Scans](https://arxiv.org/abs/2506.23209)
*Chia-Wen Huang,Haw Hwai,Chien-Chang Lee,Pei-Yuan Wu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于3D CT扫描和切片注意力机制的深度学习模型，用于阑尾炎分类，并结合预训练的2D模型进行分层分类，提高了诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 临床中阑尾炎的及时准确诊断至关重要，但CT成像的工作量可能使放射科医生不堪重负，导致延误。

Method: 利用3D CT扫描和切片注意力机制增强小病变检测，结合预训练的2D模型进行分层分类。

Result: 阑尾炎和复杂性阑尾炎的AUC分别提高了3%和5.9%。

Conclusion: 该方法比现有工作更高效可靠，为临床诊断提供了更好的解决方案。

Abstract: Timely and accurate diagnosis of appendicitis is critical in clinical
settings to prevent serious complications. While CT imaging remains the
standard diagnostic tool, the growing number of cases can overwhelm
radiologists, potentially causing delays. In this paper, we propose a deep
learning model that leverages 3D CT scans for appendicitis classification,
incorporating Slice Attention mechanisms guided by external 2D datasets to
enhance small lesion detection. Additionally, we introduce a hierarchical
classification framework using pre-trained 2D models to differentiate between
simple and complicated appendicitis. Our approach improves AUC by 3% for
appendicitis and 5.9% for complicated appendicitis, offering a more efficient
and reliable diagnostic solution compared to previous work.

</details>


### [272] [High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation](https://arxiv.org/abs/2506.23227)
*Lunhao Duan,Shanshan Zhao,Xingxing Weng,Jing Zhang,Gui-Song Xia*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于场景级标注的室内点云语义分割方法，通过多模态信息和区域-点语义一致性生成高质量伪标签，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖稀疏点级标签，而场景级标注下生成准确伪标签具有挑战性，影响了分割效果。

Method: 提出跨模态特征引导模块和区域-点语义一致性模块，利用2D-3D对应关系和区域投票策略生成高质量伪标签。

Result: 在ScanNet v2和S3DIS数据集上显著优于现有方法，消融实验验证了各模块的有效性。

Conclusion: 通过多模态和区域一致性策略，解决了场景级标注下的伪标签生成问题，提升了分割性能。

Abstract: This paper investigates indoor point cloud semantic segmentation under
scene-level annotation, which is less explored compared to methods relying on
sparse point-level labels. In the absence of precise point-level labels,
current methods first generate point-level pseudo-labels, which are then used
to train segmentation models. However, generating accurate pseudo-labels for
each point solely based on scene-level annotations poses a considerable
challenge, substantially affecting segmentation performance. Consequently, to
enhance accuracy, this paper proposes a high-quality pseudo-label generation
framework by exploring contemporary multi-modal information and region-point
semantic consistency. Specifically, with a cross-modal feature guidance module,
our method utilizes 2D-3D correspondences to align point cloud features with
corresponding 2D image pixels, thereby assisting point cloud feature learning.
To further alleviate the challenge presented by the scene-level annotation, we
introduce a region-point semantic consistency module. It produces regional
semantics through a region-voting strategy derived from point-level semantics,
which are subsequently employed to guide the point-level semantic predictions.
Leveraging the aforementioned modules, our method can rectify inaccurate
point-level semantic predictions during training and obtain high-quality
pseudo-labels. Significant improvements over previous works on ScanNet v2 and
S3DIS datasets under scene-level annotation can demonstrate the effectiveness.
Additionally, comprehensive ablation studies validate the contributions of our
approach's individual components. The code is available at
https://github.com/LHDuan/WSegPC .

</details>


### [273] [PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation](https://arxiv.org/abs/2506.23257)
*Chongke Bi,Xin Gao,Baofeng Fu,Yuheng Zhao,Siming Chen,Ying Zhao,Yunhai Wang*

Main category: cs.CV

Relevance: 30.0

TL;DR: PCLVis框架通过MPI进程通信数据帮助用户分析进程通信延迟事件，提高大规模模拟的效率。


<details>
  <summary>Details</summary>
Motivation: 解决超级计算机中大规模模拟的通信延迟问题，现有方法依赖管理员才能获取的物理链路层信息，限制了普通用户的分析能力。

Method: 1. 空间PCL事件定位方法，通过构建进程相关树将高相关进程聚类；2. 构建基于通信依赖的有向无环图（DAG）分析PCL事件传播路径；3. 设计通信状态符号（CS-Glyph）展示进程通信状态；4. 提出PCL事件归因策略帮助优化模拟。

Result: PCLVis框架在TH-1A超级计算机上的模拟中有效分析PCL事件，显著提高模拟效率。

Conclusion: PCLVis为普通用户提供了一种不依赖物理链路层信息的通信延迟分析工具，优化了大规模模拟的性能。

Abstract: Large-scale simulations on supercomputers have become important tools for
users. However, their scalability remains a problem due to the huge
communication cost among parallel processes. Most of the existing communication
latency analysis methods rely on the physical link layer information, which is
only available to administrators. In this paper, a framework called PCLVis is
proposed to help general users analyze process communication latency (PCL)
events. Instead of the physical link layer information, the PCLVis uses the MPI
process communication data for the analysis. First, a spatial PCL event
locating method is developed. All processes with high correlation are
classified into a single cluster by constructing a process-correlation tree.
Second, the propagation path of PCL events is analyzed by constructing a
communication-dependency-based directed acyclic graph (DAG), which can help
users interactively explore a PCL event from the temporal evolution of a
located PCL event cluster. In this graph, a sliding window algorithm is
designed to generate the PCL events abstraction. Meanwhile, a new glyph called
the communication state glyph (CS-Glyph) is designed for each process to show
its communication states, including its in/out messages and load balance. Each
leaf node can be further unfolded to view additional information. Third, a PCL
event attribution strategy is formulated to help users optimize their
simulations. The effectiveness of the PCLVis framework is demonstrated by
analyzing the PCL events of several simulations running on the TH-1A
supercomputer. By using the proposed framework, users can greatly improve the
efficiency of their simulations.

</details>


### [274] [DiffFit: Disentangled Garment Warping and Texture Refinement for Virtual Try-On](https://arxiv.org/abs/2506.23295)
*Xiang Xu*

Main category: cs.CV

Relevance: 30.0

TL;DR: DiffFit是一种新颖的两阶段潜在扩散框架，用于高保真虚拟试穿，通过几何感知的服装变形和纹理细化解决现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 虚拟试穿（VTON）在电子商务和数字时尚中有广泛应用，但现有方法在保留服装细节、对齐精度和推理效率方面存在挑战。

Method: DiffFit采用两阶段策略：第一阶段进行几何感知的服装变形，第二阶段通过跨模态条件扩散模型细化纹理。

Result: DiffFit在大型VTON基准测试中表现优于现有方法，定量和感知评估均显示其优越性。

Conclusion: DiffFit通过解耦几何对齐和外观细化，显著提升了虚拟试穿的生成稳定性和视觉真实感。

Abstract: Virtual try-on (VTON) aims to synthesize realistic images of a person wearing
a target garment, with broad applications in e-commerce and digital fashion.
While recent advances in latent diffusion models have substantially improved
visual quality, existing approaches still struggle with preserving fine-grained
garment details, achieving precise garment-body alignment, maintaining
inference efficiency, and generalizing to diverse poses and clothing styles. To
address these challenges, we propose DiffFit, a novel two-stage latent
diffusion framework for high-fidelity virtual try-on. DiffFit adopts a
progressive generation strategy: the first stage performs geometry-aware
garment warping, aligning the garment with the target body through fine-grained
deformation and pose adaptation. The second stage refines texture fidelity via
a cross-modal conditional diffusion model that integrates the warped garment,
the original garment appearance, and the target person image for high-quality
rendering. By decoupling geometric alignment and appearance refinement, DiffFit
effectively reduces task complexity and enhances both generation stability and
visual realism. It excels in preserving garment-specific attributes such as
textures, wrinkles, and lighting, while ensuring accurate alignment with the
human body. Extensive experiments on large-scale VTON benchmarks demonstrate
that DiffFit achieves superior performance over existing state-of-the-art
methods in both quantitative metrics and perceptual evaluations.

</details>


### [275] [Layer Decomposition and Morphological Reconstruction for Task-Oriented Infrared Image Enhancement](https://arxiv.org/abs/2506.23353)
*Siyuan Chai,Xiaodong Guo,Tong Liu*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种面向任务的红外图像增强方法，通过层分解和显著性信息提取提升图像质量，适用于自动驾驶中的复杂天气条件。


<details>
  <summary>Details</summary>
Motivation: 红外图像在复杂天气条件下（如雾、雨、低光）能提升自动驾驶的感知能力，但其低对比度和噪声问题影响了高级视觉任务的性能。

Method: 方法包括层分解（增强场景细节并保留暗区特征）和基于形态学重建的显著性提取（有效增强目标信息而不放大噪声）。

Result: 实验表明，该方法在目标检测和语义分割任务中优于现有技术。

Conclusion: 该方法显著提升了红外图像的质量，适用于自动驾驶中的高级视觉任务。

Abstract: Infrared image helps improve the perception capabilities of autonomous
driving in complex weather conditions such as fog, rain, and low light.
However, infrared image often suffers from low contrast, especially in
non-heat-emitting targets like bicycles, which significantly affects the
performance of downstream high-level vision tasks. Furthermore, achieving
contrast enhancement without amplifying noise and losing important information
remains a challenge. To address these challenges, we propose a task-oriented
infrared image enhancement method. Our approach consists of two key components:
layer decomposition and saliency information extraction. First, we design an
layer decomposition method for infrared images, which enhances scene details
while preserving dark region features, providing more features for subsequent
saliency information extraction. Then, we propose a morphological
reconstruction-based saliency extraction method that effectively extracts and
enhances target information without amplifying noise. Our method improves the
image quality for object detection and semantic segmentation tasks. Extensive
experiments demonstrate that our approach outperforms state-of-the-art methods.

</details>


### [276] [Time-variant Image Inpainting via Interactive Distribution Transition Estimation](https://arxiv.org/abs/2506.23461)
*Yun Xing,Qing Guo,Xiaoguang Li,Yihao Huang,Xiaofeng Cao,Di Lin,Ivor Tsang,Lei Ma*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种新的时间变体图像修复任务（TAMP），并开发了InDiTE-Diff方法，结合交互式分布转换估计和扩散模型，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决时间变体图像修复中因内容差异和潜在损坏导致的传统方法失效问题。

Method: 提出InDiTE模块交互补充语义，结合扩散模型（InDiTE-Diff），并构建TAMP-Street数据集。

Result: 实验表明InDiTE-Diff在TAMP任务上优于现有方法。

Conclusion: InDiTE-Diff为时间变体图像修复提供了有效解决方案。

Abstract: In this work, we focus on a novel and practical task, i.e., Time-vAriant
iMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image
by leveraging the complementary information from a reference image, where both
images captured the same scene but with a significant time gap in between,
i.e., time-variant images. Different from conventional reference-guided image
inpainting, the reference image under TAMP setup presents significant content
distinction to the target image and potentially also suffers from damages. Such
an application frequently happens in our daily lives to restore a damaged image
by referring to another reference image, where there is no guarantee of the
reference image's source and quality. In particular, our study finds that even
state-of-the-art (SOTA) reference-guided image inpainting methods fail to
achieve plausible results due to the chaotic image complementation. To address
such an ill-posed problem, we propose a novel Interactive Distribution
Transition Estimation (InDiTE) module which interactively complements the
time-variant images with adaptive semantics thus facilitate the restoration of
damaged regions. To further boost the performance, we propose our TAMP
solution, namely Interactive Distribution Transition Estimation-driven
Diffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and
conducts latent cross-reference during sampling. Moreover, considering the lack
of benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street,
based on existing image and mask datasets. We conduct experiments on the
TAMP-Street datasets under two different time-variant image inpainting
settings, which show our method consistently outperform SOTA reference-guided
image inpainting methods for solving TAMP.

</details>


### [277] [High Resolution Isotropic 3D Cine imaging with Automated Segmentation using Concatenated 2D Real-time Imaging and Deep Learning](https://arxiv.org/abs/2506.22532)
*Mark Wrobel,Michele Pascale,Tina Yao,Ruaraidh Campbell,Elena Milano,Michael Quail,Jennifer Steeden,Vivek Muthurangu*

Main category: eess.IV

Relevance: 30.0

TL;DR: 利用深度学习将2D实时心脏电影图像拼接并转换为3D图像，验证了其在临床心血管磁共振中的潜力。


<details>
  <summary>Details</summary>
Motivation: 提高心血管磁共振（CMR）在儿科和先天性心脏病中的效率，减少传统方法的呼吸控制和长时间采集需求。

Method: 训练四个深度学习模型，分别用于对比校正、呼吸运动校正、超分辨率和心脏结构分割，并在10例患者中验证。

Result: 成功将2D图像转换为3D电影，处理时间短（<1分钟），与常规方法结果一致，但肺动脉直径略有高估。

Conclusion: 该方法可显著加速CMR临床实践，提供快速且准确的3D心脏图像。

Abstract: Background: Conventional cardiovascular magnetic resonance (CMR) in
paediatric and congenital heart disease uses 2D, breath-hold, balanced steady
state free precession (bSSFP) cine imaging for assessment of function and
cardiac-gated, respiratory-navigated, static 3D bSSFP whole-heart imaging for
anatomical assessment. Our aim is to concatenate a stack 2D free-breathing
real-time cines and use Deep Learning (DL) to create an isotropic a fully
segmented 3D cine dataset from these images. Methods: Four DL models were
trained on open-source data that performed: a) Interslice contrast correction;
b) Interslice respiratory motion correction; c) Super-resolution (slice
direction); and d) Segmentation of right and left atria and ventricles (RA, LA,
RV, and LV), thoracic aorta (Ao) and pulmonary arteries (PA). In 10 patients
undergoing routine cardiovascular examination, our method was validated on
prospectively acquired sagittal stacks of real-time cine images. Quantitative
metrics (ventricular volumes and vessel diameters) and image quality of the 3D
cines were compared to conventional breath hold cine and whole heart imaging.
Results: All real-time data were successfully transformed into 3D cines with a
total post-processing time of <1 min in all cases. There were no significant
biases in any LV or RV metrics with reasonable limits of agreement and
correlation. There is also reasonable agreement for all vessel diameters,
although there was a small but significant overestimation of RPA diameter.
Conclusion: We have demonstrated the potential of creating a 3D-cine data from
concatenated 2D real-time cine images using a series of DL models. Our method
has short acquisition and reconstruction times with fully segmented data being
available within 2 minutes. The good agreement with conventional imaging
suggests that our method could help to significantly speed up CMR in clinical
practice.

</details>


### [278] [Interactive Interface For Semantic Segmentation Dataset Synthesis](https://arxiv.org/abs/2506.23470)
*Ngoc-Do Tran,Minh-Tuan Huynh,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

Relevance: 30.0

TL;DR: SynthLab是一个模块化平台，用于视觉数据合成，旨在解决高质量标注数据集创建的资源密集和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 解决语义分割等任务中高质量标注数据集创建的高成本、耗时和隐私问题。

Method: 开发模块化平台SynthLab，支持视觉数据合成和用户友好的拖拽界面，模块化设计便于维护和扩展。

Result: 用户研究表明，SynthLab具有高灵活性和易用性，适合不同背景的用户。

Conclusion: SynthLab为AI应用提供了一种高效、可扩展且用户友好的数据合成解决方案。

Abstract: The rapid advancement of AI and computer vision has significantly increased
the demand for high-quality annotated datasets, particularly for semantic
segmentation. However, creating such datasets is resource-intensive, requiring
substantial time, labor, and financial investment, and often raises privacy
concerns due to the use of real-world data. To mitigate these challenges, we
present SynthLab, consisting of a modular platform for visual data synthesis
and a user-friendly interface. The modular architecture of SynthLab enables
easy maintenance, scalability with centralized updates, and seamless
integration of new features. Each module handles distinct aspects of computer
vision tasks, enhancing flexibility and adaptability. Meanwhile, its
interactive, user-friendly interface allows users to quickly customize their
data pipelines through drag-and-drop actions. Extensive user studies involving
a diverse range of users across different ages, professions, and expertise
levels, have demonstrated flexible usage, and high accessibility of SynthLab,
enabling users without deep technical expertise to harness AI for real-world
applications.

</details>


### [279] [GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance](https://arxiv.org/abs/2506.23478)
*Pedro Alonso,Tianrui Li,Chongshou Li*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出GeoCD，一种基于拓扑感知和完全可微分的测地距离近似方法，用于改进3D点云学习中的Chamfer Distance（CD）度量。实验表明，GeoCD显著提升了重建质量。


<details>
  <summary>Details</summary>
Motivation: Chamfer Distance（CD）仅依赖欧氏距离，难以捕捉3D形状的内在几何特征，因此需要一种更准确的度量方法。

Method: 提出GeoCD，一种拓扑感知且完全可分的测地距离近似方法，并通过微调模型验证其效果。

Result: 实验表明，使用GeoCD微调模型仅需一个周期即可在多指标上显著提升性能。

Conclusion: GeoCD是一种有效的改进CD的方法，适用于3D点云学习任务。

Abstract: Chamfer Distance (CD) is a widely adopted metric in 3D point cloud learning
due to its simplicity and efficiency. However, it suffers from a fundamental
limitation: it relies solely on Euclidean distances, which often fail to
capture the intrinsic geometry of 3D shapes. To address this limitation, we
propose GeoCD, a topology-aware and fully differentiable approximation of
geodesic distance designed to serve as a metric for 3D point cloud learning.
Our experiments show that GeoCD consistently improves reconstruction quality
over standard CD across various architectures and datasets. We demonstrate this
by fine-tuning several models, initially trained with standard CD, using GeoCD.
Remarkably, fine-tuning for a single epoch with GeoCD yields significant gains
across multiple evaluation metrics.

</details>


### [280] [Instant GaussianImage: A Generalizable and Self-Adaptive Image Representation via 2D Gaussian Splatting](https://arxiv.org/abs/2506.23479)
*Zhaojie Zeng,Yuesong Wang,Chao Yang,Tao Guan,Lili Ju*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于2D高斯泼溅的自适应图像表示框架，显著减少训练时间并动态调整高斯点数量以适应图像复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决GaussianImage方法训练速度慢和固定高斯点数量限制适应性的问题。

Method: 使用网络快速生成粗略高斯表示，并通过少量微调步骤实现高质量渲染，动态调整高斯点数量。

Result: 在DIV2K和Kodak数据集上，训练时间减少一个数量级，渲染性能优于或匹配GaussianImage。

Conclusion: 该方法在高效性和适应性上优于现有技术，适用于实际应用。

Abstract: Implicit Neural Representation (INR) has demonstrated remarkable advances in
the field of image representation but demands substantial GPU resources.
GaussianImage recently pioneered the use of Gaussian Splatting to mitigate this
cost, however, the slow training process limits its practicality, and the fixed
number of Gaussians per image limits its adaptability to varying information
entropy. To address these issues, we propose in this paper a generalizable and
self-adaptive image representation framework based on 2D Gaussian Splatting.
Our method employs a network to quickly generate a coarse Gaussian
representation, followed by minimal fine-tuning steps, achieving comparable
rendering quality of GaussianImage while significantly reducing training time.
Moreover, our approach dynamically adjusts the number of Gaussian points based
on image complexity to further enhance flexibility and efficiency in practice.
Experiments on DIV2K and Kodak datasets show that our method matches or exceeds
GaussianImage's rendering performance with far fewer iterations and shorter
training times. Specifically, our method reduces the training time by up to one
order of magnitude while achieving superior rendering performance with the same
number of Gaussians.

</details>


### [281] [VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding](https://arxiv.org/abs/2506.22799)
*Minchao Jiang,Shunyu Jia,Jiaming Gu,Xiaoyuan Lu,Guangming Zhu,Anqi Dong,Liang Zhang*

Main category: cs.GR

Relevance: 30.0

TL;DR: VoteSplat结合Hough投票与3D高斯泼溅（3DGS），通过SAM进行实例分割和2D投票图生成，优化3D场景理解，降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法缺乏深度场景理解且训练成本高，VoteSplat旨在解决这些问题。

Method: 利用SAM进行实例分割，生成2D投票图，嵌入空间偏移向量到高斯基元，结合深度约束优化定位。

Result: 在开放词汇3D实例定位、点云理解等任务中表现优异。

Conclusion: VoteSplat高效且语义明确，适用于多种3D场景理解任务。

Abstract: 3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-time
rendering for novel view synthesis of 3D scenes. However, existing methods
focus primarily on geometric and appearance modeling, lacking deeper scene
understanding while also incurring high training costs that complicate the
originally streamlined differentiable rendering pipeline. To this end, we
propose VoteSplat, a novel 3D scene understanding framework that integrates
Hough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilized
for instance segmentation, extracting objects, and generating 2D vote maps. We
then embed spatial offset vectors into Gaussian primitives. These offsets
construct 3D spatial votes by associating them with 2D image votes, while depth
distortion constraints refine localization along the depth axis. For
open-vocabulary object localization, VoteSplat maps 2D image semantics to 3D
point clouds via voting points, reducing training costs associated with
high-dimensional CLIP features while preserving semantic unambiguity. Extensive
experiments demonstrate effectiveness of VoteSplat in open-vocabulary 3D
instance localization, 3D point cloud understanding, click-based 3D object
localization, hierarchical segmentation, and ablation studies. Our code is
available at https://sy-ja.github.io/votesplat/

</details>


### [282] [JAM-Flow: Joint Audio-Motion Synthesis with Flow Matching](https://arxiv.org/abs/2506.23552)
*Mingi Kwon,Joonghyuk Shin,Jaeseok Jung,Jaesik Park,Youngjung Uh*

Main category: cs.CV

Relevance: 30.0

TL;DR: JAM-Flow是一个统一框架，通过流匹配和多模态扩散Transformer架构，同时合成面部运动和语音，支持多种条件输入。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将面部运动合成和语音合成视为独立任务，忽略了它们之间的内在联系。

Method: 采用流匹配和Multi-Modal Diffusion Transformer (MM-DiT)架构，结合Motion-DiT和Audio-DiT模块，通过选择性联合注意力层实现跨模态交互。

Result: JAM-Flow支持多种条件输入（如文本、参考音频和参考运动），能够完成同步说话头部生成等任务。

Conclusion: JAM-Flow为多模态生成建模提供了实用解决方案，推动了音频-视觉合成的整体发展。

Abstract: The intrinsic link between facial motion and speech is often overlooked in
generative modeling, where talking head synthesis and text-to-speech (TTS) are
typically addressed as separate tasks. This paper introduces JAM-Flow, a
unified framework to simultaneously synthesize and condition on both facial
motion and speech. Our approach leverages flow matching and a novel Multi-Modal
Diffusion Transformer (MM-DiT) architecture, integrating specialized Motion-DiT
and Audio-DiT modules. These are coupled via selective joint attention layers
and incorporate key architectural choices, such as temporally aligned
positional embeddings and localized joint attention masking, to enable
effective cross-modal interaction while preserving modality-specific strengths.
Trained with an inpainting-style objective, JAM-Flow supports a wide array of
conditioning inputs-including text, reference audio, and reference
motion-facilitating tasks such as synchronized talking head generation from
text, audio-driven animation, and much more, within a single, coherent model.
JAM-Flow significantly advances multi-modal generative modeling by providing a
practical solution for holistic audio-visual synthesis. project page:
https://joonghyuk.com/jamflow-web

</details>


### [283] [LH2Face: Loss function for Hard High-quality Face](https://arxiv.org/abs/2506.23555)
*Fan Xie,Pan Cao*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种名为LH2Face的新损失函数，通过结合von Mises-Fisher分布和自适应边缘策略，优化了高质量硬样本的人脸识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸识别方法在处理硬样本时表现不佳，且未考虑样本质量或识别难度，导致训练策略过于统一。

Method: 1. 基于von Mises-Fisher分布的相似性度量；2. 自适应边缘的多分类方法；3. 代理损失函数优化表示空间分布；4. 通过人脸重建优化识别性能。

Result: 在IJB-B数据集上达到49.39%的准确率，比第二名高2.37%。

Conclusion: LH2Face通过自适应策略和表示空间优化，显著提升了高质量硬样本的识别性能。

Abstract: In current practical face authentication systems, most face recognition (FR)
algorithms are based on cosine similarity with softmax classification. Despite
its reliable classification performance, this method struggles with hard
samples. A popular strategy to improve FR performance is incorporating angular
or cosine margins. However, it does not take face quality or recognition
hardness into account, simply increasing the margin value and thus causing an
overly uniform training strategy. To address this problem, a novel loss
function is proposed, named Loss function for Hard High-quality Face (LH2Face).
Firstly, a similarity measure based on the von Mises-Fisher (vMF) distribution
is stated, specifically focusing on the logarithm of the Probability Density
Function (PDF), which represents the distance between a probability
distribution and a vector. Then, an adaptive margin-based multi-classification
method using softmax, called the Uncertainty-Aware Margin Function, is
implemented in the article. Furthermore, proxy-based loss functions are used to
apply extra constraints between the proxy and sample to optimize their
representation space distribution. Finally, a renderer is constructed that
optimizes FR through face reconstruction and vice versa. Our LH2Face is
superior to similiar schemes on hard high-quality face datasets, achieving
49.39% accuracy on the IJB-B dataset, which surpasses the second-place method
by 2.37%.

</details>


### [284] [OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2506.23565)
*Mingqian Ji,Jian Yang,Shanshan Zhang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种基于物体中心辐射场（OcRF）的多视图3D物体检测方法，通过渲染前景物体增强3D体素特征，并结合高度感知不透明度注意力（HOA）提升2D BEV特征，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过深度估计或3D位置编码隐式地将2D特征转换为3D空间，限制了检测性能。受辐射场在3D重建中的成功启发，作者尝试将其用于增强3D几何估计能力。

Method: 提出物体中心辐射场（OcRF）作为辅助任务渲染前景物体，避免背景噪声干扰；结合高度感知不透明度注意力（HOA）增强2D BEV特征。

Result: 在nuScenes测试集上达到57.2% mAP和64.8% NDS，优于现有方法。

Conclusion: OcRFDet通过聚焦前景物体建模和特征增强，显著提升了多视图3D物体检测性能。

Abstract: Current multi-view 3D object detection methods typically transfer 2D features
into 3D space using depth estimation or 3D position encoder, but in a fully
data-driven and implicit manner, which limits the detection performance.
Inspired by the success of radiance fields on 3D reconstruction, we assume they
can be used to enhance the detector's ability of 3D geometry estimation.
However, we observe a decline in detection performance, when we directly use
them for 3D rendering as an auxiliary task. From our analysis, we find the
performance drop is caused by the strong responses on the background when
rendering the whole scene. To address this problem, we propose object-centric
radiance fields, focusing on modeling foreground objects while discarding
background noises. Specifically, we employ Object-centric Radiance Fields
(OcRF) to enhance 3D voxel features via an auxiliary task of rendering
foreground objects. We further use opacity - the side-product of rendering- to
enhance the 2D foreground BEV features via Height-aware Opacity-based Attention
(HOA), where attention maps at different height levels are generated separately
via multiple networks in parallel. Extensive experiments on the nuScenes
validation and test datasets demonstrate that our OcRFDet achieves superior
performance, outperforming previous state-of-the-art methods with 57.2$\%$ mAP
and 64.8$\%$ NDS on the nuScenes test benchmark. Code will be available at
https://github.com/Mingqj/OcRFDet.

</details>


### [285] [Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution](https://arxiv.org/abs/2506.23566)
*Luigi Sigillo,Renato Giamba,Danilo Comminiello*

Main category: cs.CV

Relevance: 30.0

TL;DR: MWT-Diff是一个结合潜在扩散模型和小波变换的卫星图像超分辨率框架，通过MWT-Encoder生成嵌入特征，逐步重建高分辨率图像。


<details>
  <summary>Details</summary>
Motivation: 高分辨率卫星图像获取受限于传感器时空限制和高成本，影响环境监测等应用。

Method: 提出MWT-Diff框架，结合潜在扩散模型和小波变换，利用MWT-Encoder生成嵌入特征指导扩散过程。

Result: 在多个数据集上表现优于现有方法，通过FID和LPIPS等指标验证。

Conclusion: MWT-Diff能有效重建高分辨率卫星图像，保留关键空间特征。

Abstract: The acquisition of high-resolution satellite imagery is often constrained by
the spatial and temporal limitations of satellite sensors, as well as the high
costs associated with frequent observations. These challenges hinder
applications such as environmental monitoring, disaster response, and
agricultural management, which require fine-grained and high-resolution data.
In this paper, we propose MWT-Diff, an innovative framework for satellite image
super-resolution (SR) that combines latent diffusion models with wavelet
transforms to address these challenges. At the core of the framework is a novel
metadata-, wavelet-, and time-aware encoder (MWT-Encoder), which generates
embeddings that capture metadata attributes, multi-scale frequency information,
and temporal relationships. The embedded feature representations steer the
hierarchical diffusion dynamics, through which the model progressively
reconstructs high-resolution satellite imagery from low-resolution inputs. This
process preserves critical spatial characteristics including textural patterns,
boundary discontinuities, and high-frequency spectral components essential for
detailed remote sensing analysis. The comparative analysis of MWT-Diff across
multiple datasets demonstrated favorable performance compared to recent
approaches, as measured by standard perceptual quality metrics including FID
and LPIPS.

</details>


### [286] [Event-based Tiny Object Detection: A Benchmark Dataset and Baseline](https://arxiv.org/abs/2506.23575)
*Nuo Chen,Chao Xiao,Yimian Dai,Shiman He,Miao Li,Wei An*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了首个大规模、多样化的基于事件的小目标检测数据集EV-UAV，并设计了一种基于点云空间的事件分割网络EV-SpSegNet和时空相关性损失STC，用于反无人机任务中的小目标检测。


<details>
  <summary>Details</summary>
Motivation: 传统帧式相机在复杂背景下检测小目标（如无人机）效果不佳，而事件相机的高动态范围和微秒级分辨率更适合此类任务。现有事件数据集规模小、目标大且背景单一，无法满足需求。

Method: 提出EV-UAV数据集，包含147个序列和230万事件级标注，目标极小（平均6.8×5.4像素）。设计EV-SpSegNet网络和STC损失，利用运动连续性保留目标事件。

Result: 在EV-UAV数据集上的实验证明了方法的优越性，为未来研究提供了基准。

Conclusion: EV-UAV数据集和EV-SpSegNet为事件相机的小目标检测提供了有效工具，推动了该领域的发展。

Abstract: Small object detection (SOD) in anti-UAV task is a challenging problem due to
the small size of UAVs and complex backgrounds. Traditional frame-based cameras
struggle to detect small objects in complex environments due to their low frame
rates, limited dynamic range, and data redundancy. Event cameras, with
microsecond temporal resolution and high dynamic range, provide a more
effective solution for SOD. However, existing event-based object detection
datasets are limited in scale, feature large targets size, and lack diverse
backgrounds, making them unsuitable for SOD benchmarks. In this paper, we
introduce a Event-based Small object detection (EVSOD) dataset (namely EV-UAV),
the first large-scale, highly diverse benchmark for anti-UAV tasks. It includes
147 sequences with over 2.3 million event-level annotations, featuring
extremely small targets (averaging 6.8 $\times$ 5.4 pixels) and diverse
scenarios such as urban clutter and extreme lighting conditions. Furthermore,
based on the observation that small moving targets form continuous curves in
spatiotemporal event point clouds, we propose Event based Sparse Segmentation
Network (EV-SpSegNet), a novel baseline for event segmentation in point cloud
space, along with a Spatiotemporal Correlation (STC) loss that leverages motion
continuity to guide the network in retaining target events. Extensive
experiments on the EV-UAV dataset demonstrate the superiority of our method and
provide a benchmark for future research in EVSOD. The dataset and code are at
https://github.com/ChenYichen9527/Ev-UAV.

</details>


### [287] [SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion](https://arxiv.org/abs/2506.23606)
*Zhengkang Xiang,Zizhao Li,Amir Khodabandeh,Kourosh Khoshelham*

Main category: cs.CV

Relevance: 30.0

TL;DR: SG-LDM是一种基于语义引导的激光雷达扩散模型，通过潜在对齐实现语义到激光雷达的合成，并在激光雷达分割任务中提升数据增强性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有激光雷达点云生成方法无条件生成的局限性，提出语义引导的生成方法以增强实际应用价值。

Method: 采用潜在对齐和显式语义条件，直接在激光雷达空间操作，提出扩散模型SG-LDM及其翻译框架。

Result: SG-LDM在生成高保真激光雷达点云方面表现优异，翻译框架进一步提升了激光雷达分割任务的数据增强效果。

Conclusion: SG-LDM为激光雷达点云生成提供了新的语义引导方法，并在实际应用中验证了其有效性。

Abstract: Lidar point cloud synthesis based on generative models offers a promising
solution to augment deep learning pipelines, particularly when real-world data
is scarce or lacks diversity. By enabling flexible object manipulation, this
synthesis approach can significantly enrich training datasets and enhance
discriminative models. However, existing methods focus on unconditional lidar
point cloud generation, overlooking their potential for real-world
applications. In this paper, we propose SG-LDM, a Semantic-Guided Lidar
Diffusion Model that employs latent alignment to enable robust
semantic-to-lidar synthesis. By directly operating in the native lidar space
and leveraging explicit semantic conditioning, SG-LDM achieves state-of-the-art
performance in generating high-fidelity lidar point clouds guided by semantic
labels. Moreover, we propose the first diffusion-based lidar translation
framework based on SG-LDM, which enables cross-domain translation as a domain
adaptation strategy to enhance downstream perception performance. Systematic
experiments demonstrate that SG-LDM significantly outperforms existing lidar
diffusion models and the proposed lidar translation framework further improves
data augmentation performance in the downstream lidar segmentation task.

</details>


### [288] [TurboVSR: Fantastic Video Upscalers and Where to Find Them](https://arxiv.org/abs/2506.23618)
*Zhongdao Wang,Guodongfang Zhao,Jingjing Ren,Bailan Feng,Shifeng Zhang,Wenbo Li*

Main category: cs.CV

Relevance: 30.0

TL;DR: TurboVSR 是一种基于扩散模型的超高效视频超分辨率方法，通过高压缩比自动编码器、因子化条件和预训练扩散模型的转换，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在视频超分辨率任务中计算效率低下的问题。

Method: 1. 使用高压缩比自动编码器减少 token 数量；2. 引入因子化条件降低学习复杂度；3. 将预训练扩散模型转换为 shortcut 模型以减少采样步数。

Result: TurboVSR 在性能上与现有最优方法相当，但速度快 100 倍以上，支持 4K 图像超分辨率。

Conclusion: TurboVSR 的高效设计为超分辨率任务提供了新的可能性。

Abstract: Diffusion-based generative models have demonstrated exceptional promise in
the video super-resolution (VSR) task, achieving a substantial advancement in
detail generation relative to prior methods. However, these approaches face
significant computational efficiency challenges. For instance, current
techniques may require tens of minutes to super-resolve a mere 2-second, 1080p
video. In this paper, we present TurboVSR, an ultra-efficient diffusion-based
video super-resolution model. Our core design comprises three key aspects: (1)
We employ an autoencoder with a high compression ratio of 32$\times$32$\times$8
to reduce the number of tokens. (2) Highly compressed latents pose substantial
challenges for training. We introduce factorized conditioning to mitigate the
learning complexity: we first learn to super-resolve the initial frame;
subsequently, we condition the super-resolution of the remaining frames on the
high-resolution initial frame and the low-resolution subsequent frames. (3) We
convert the pre-trained diffusion model to a shortcut model to enable fewer
sampling steps, further accelerating inference. As a result, TurboVSR performs
on par with state-of-the-art VSR methods, while being 100+ times faster, taking
only 7 seconds to process a 2-second long 1080p video. TurboVSR also supports
image resolution by considering image as a one-frame video. Our efficient
design makes SR beyond 1080p possible, results on 4K (3648$\times$2048) image
SR show surprising fine details.

</details>


### [289] [Subjective Camera: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion](https://arxiv.org/abs/2506.23711)
*Haoyang Chen,Dongfang Sun,Caoyuan Ma,Shiqin Wang,Kewei Zhang,Zheng Wang,Zhixiang Wang*

Main category: cs.CV

Relevance: 30.0

TL;DR: Subjective Camera 是一种通过结合语言描述和渐进草图重建现实场景的方法，解决了语言模糊性和草图抽象性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临用户主观输入偏差、草图与3D先验之间的模态鸿沟以及草图质量敏感性问题。

Method: 采用概念顺序生成，通过文本奖励优化建立外观先验，并利用序列感知解耦生成和潜在优化。

Result: 在多样数据集上实现了语义和空间一致性的最先进性能。

Conclusion: 该方法无需训练即可适应用户主观期望，并能处理粗糙草图。

Abstract: We propose Subjective Camera, a human-as-imaging-device paradigm that
reconstructs real-world scenes from mental impressions through synergistic use
of verbal descriptions and progressive rough sketches. This approach overcomes
dual limitations of language ambiguity and sketch abstraction by treating the
user's drawing sequence as priors, effectively translating subjective
perceptual expectations into photorealistic images.
  Existing approaches face three fundamental barriers: (1) user-specific
subjective input biases, (2) huge modality gap between planar sketch and 3D
priors in diffusion, and (3) sketch quality-sensitive performance degradation.
Current solutions either demand resource-intensive model adaptation or impose
impractical requirements on sketch precision.
  Our framework addresses these challenges through concept-sequential
generation. (1) We establish robust appearance priors through text-reward
optimization, and then implement sequence-aware disentangled generation that
processes concepts in sketching order; these steps accommodate user-specific
subjective expectation in a train-free way. (2) We employ latent optimization
that effectively bridges the modality gap between planar sketches and 3D priors
in diffusion. (3) Our hierarchical reward-guided framework enables the use of
rough sketches without demanding artistic expertise. Comprehensive evaluation
across diverse datasets demonstrates that our approach achieves
state-of-the-art performance in maintaining both semantic and spatial
coherence.

</details>


### [290] [Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking](https://arxiv.org/abs/2506.23783)
*Shiao Wang,Ju Huang,Qingchuan Ma,Jinfeng Gao,Chunyi Xu,Xiao Wang,Lan Chen,Bo Jiang*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于线性复杂度Vision Mamba网络的高效RGB-Event对象跟踪框架Mamba-FETrack V2，通过轻量级Prompt Generator和Vision Mamba-based FEMamba主干实现跨模态特征提取与融合。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态跟踪算法依赖高复杂度Vision Transformer架构，导致计算开销大且跨模态交互效果受限。

Method: 设计轻量级Prompt Generator生成模态特定提示向量，结合Vision Mamba-based FEMamba主干进行特征提取与融合。

Result: 在多个RGB-Event跟踪基准测试中表现优越且高效。

Conclusion: Mamba-FETrack V2在性能和效率上均优于现有方法。

Abstract: Combining traditional RGB cameras with bio-inspired event cameras for robust
object tracking has garnered increasing attention in recent years. However,
most existing multimodal tracking algorithms depend heavily on high-complexity
Vision Transformer architectures for feature extraction and fusion across
modalities. This not only leads to substantial computational overhead but also
limits the effectiveness of cross-modal interactions. In this paper, we propose
an efficient RGB-Event object tracking framework based on the linear-complexity
Vision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a
lightweight Prompt Generator that utilizes embedded features from each
modality, together with a shared prompt pool, to dynamically generate
modality-specific learnable prompt vectors. These prompts, along with the
modality-specific embedded features, are then fed into a Vision Mamba-based
FEMamba backbone, which facilitates prompt-guided feature extraction,
cross-modal interaction, and fusion in a unified manner. Finally, the fused
representations are passed to the tracking head for accurate target
localization. Extensive experimental evaluations on multiple RGB-Event tracking
benchmarks, including short-term COESOT dataset and long-term datasets, i.e.,
FE108 and FELT V2, demonstrate the superior performance and efficiency of the
proposed tracking framework. The source code and pre-trained models will be
released on https://github.com/Event-AHU/Mamba_FETrack

</details>


### [291] [Controllable Reference-Based Real-World Remote Sensing Image Super-Resolution with Generative Diffusion Priors](https://arxiv.org/abs/2506.23801)
*Ce Wang,Wanjie Sun*

Main category: cs.CV

Relevance: 30.0

TL;DR: CRefDiff是一种基于扩散模型的可控参考超分辨率方法，用于提升遥感图像的分辨率，解决了现有方法在真实场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有参考超分辨率方法在真实场景中面临分辨率差异和地表覆盖变化的挑战，导致生成不足或过度依赖参考图像。

Method: 基于预训练的Stable Diffusion模型，引入双分支融合机制和Better Start策略，提升生成质量和推理速度。

Result: 在Real-RefRSSRD数据集上，CRefDiff在多项指标上达到最优，并提升了下游任务性能。

Conclusion: CRefDiff通过可控生成和高效推理，为遥感图像超分辨率提供了有效解决方案。

Abstract: Super-resolution (SR) techniques can enhance the spatial resolution of remote
sensing images by utilizing low-resolution (LR) images to reconstruct
high-resolution (HR) images, enabling more efficient large-scale earth
observation applications. While single-image super-resolution (SISR) methods
have shown progress, reference-based super-resolution (RefSR) offers superior
performance by incorporating historical HR images alongside current LR
observations. However, existing RefSR methods struggle with real-world
complexities, such as cross-sensor resolution gap and significant land cover
changes, often leading to under-generation or over-reliance on reference image.
To address these challenges, we propose CRefDiff, a novel controllable
reference-based diffusion model for real-world remote sensing image SR. To
address the under-generation problem, CRefDiff is built upon the pretrained
Stable Diffusion model, leveraging its powerful generative prior to produce
accurate structures and textures. To mitigate over-reliance on the reference,
we introduce a dual-branch fusion mechanism that adaptively integrates both
local and global information from the reference image. Moreover, this novel
dual-branch design enables reference strength control during inference,
enhancing interactivity and flexibility of the model. Finally, a strategy named
Better Start is proposed to significantly reduce the number of denoising steps,
thereby accelerating the inference process. To support further research, we
introduce Real-RefRSSRD, a new real-world RefSR dataset for remote sensing
images, consisting of HR NAIP and LR Sentinel-2 image pairs with diverse land
cover changes and significant temporal gaps. Extensive experiments on
Real-RefRSSRD show that CRefDiff achieves state-of-the-art performance across
various metrics and improves downstream tasks such as scene classification and
semantic segmentation.

</details>


### [292] [Towards Initialization-free Calibrated Bundle Adjustment](https://arxiv.org/abs/2506.23808)
*Carl Olsson,Amanda Nilsson*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了一种利用已知相机校准信息的方法，通过引入成对相对旋转估计，实现近度量重建，解决了传统方法因缺乏校准信息而只能达到投影变换精度的问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于伪物体空间误差（pOSE）的方法因无法利用相机校准信息，导致重建结果仅能达到投影变换精度，且需要更多数据。本文旨在通过引入校准信息，实现更高精度的近度量重建。

Method: 方法结合了成对相对旋转估计（仅对相似变换不变）与pOSE框架，将旋转平均技术融入其中，以实现无需初始化的校准SfM。

Result: 实验表明，该方法能可靠优化目标函数，从随机初始解高概率收敛到全局最小值，生成准确的近度量重建结果。

Conclusion: 通过引入相机校准信息，本文方法显著提高了重建精度，为初始化自由的校准SfM提供了有效解决方案。

Abstract: A recent series of works has shown that initialization-free BA can be
achieved using pseudo Object Space Error (pOSE) as a surrogate objective. The
initial reconstruction-step optimizes an objective where all terms are
projectively invariant and it cannot incorporate knowledge of the camera
calibration. As a result, the solution is only determined up to a projective
transformation of the scene and the process requires more data for successful
reconstruction.
  In contrast, we present a method that is able to use the known camera
calibration thereby producing near metric solutions, that is, reconstructions
that are accurate up to a similarity transformation. To achieve this we
introduce pairwise relative rotation estimates that carry information about
camera calibration. These are only invariant to similarity transformations,
thus encouraging solutions that preserve metric features of the real scene. Our
method can be seen as integrating rotation averaging into the pOSE framework
striving towards initialization-free calibrated SfM.
  Our experimental evaluation shows that we are able to reliably optimize our
objective, achieving convergence to the global minimum with high probability
from random starting solutions, resulting in accurate near metric
reconstructions.

</details>


### [293] [PointSSIM: A novel low dimensional resolution invariant image-to-image comparison metric](https://arxiv.org/abs/2506.23833)
*Oscar Ovanger,Ragnar Hauge,Jacob Skauvold,Michael J. Pyrcz,Jo Eidsvik*

Main category: cs.CV

Relevance: 30.0

TL;DR: PointSSIM是一种新颖的低维图像比较指标，具有分辨率不变性，适用于不同分辨率的二进制图像比较。


<details>
  <summary>Details</summary>
Motivation: 解决二进制图像在不同分辨率下的结构比较问题，提供一种高效可靠的比较方法。

Method: 通过将二进制图像转换为标记点模式表示，提取关键特征（锚点），并使用总结向量进行图像比较。

Result: PointSSIM在结构分析中表现出高效性和可靠性，尤其适用于多分辨率场景。

Conclusion: PointSSIM为跨分辨率图像比较提供了一种有效的解决方案。

Abstract: This paper presents PointSSIM, a novel low-dimensional image-to-image
comparison metric that is resolution invariant. Drawing inspiration from the
structural similarity index measure and mathematical morphology, PointSSIM
enables robust comparison across binary images of varying resolutions by
transforming them into marked point pattern representations. The key features
of the image, referred to as anchor points, are extracted from binary images by
identifying locally adaptive maxima from the minimal distance transform. Image
comparisons are then performed using a summary vector, capturing intensity,
connectivity, complexity, and structural attributes. Results show that this
approach provides an efficient and reliable method for image comparison,
particularly suited to applications requiring structural analysis across
different resolutions.

</details>


### [294] [Refine Any Object in Any Scene](https://arxiv.org/abs/2506.23835)
*Ziwei Chen,Ziling Liu,Zitong Huang,Mingqi Gao,Feng Zheng*

Main category: cs.CV

Relevance: 30.0

TL;DR: RAISE是一种利用3D生成先验来恢复缺失视角下物体几何和外观的3D增强框架，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决场景重建中物体视角缺失问题，提升对象级建模的保真度，同时保持场景级表示的准确性。

Method: 通过3D生成模型替换退化对象，分两阶段优化几何和纹理：7-DOF姿态对齐和注册约束增强。

Result: 在多个基准测试中，RAISE在新视角合成和几何补全任务上显著优于现有方法。

Conclusion: RAISE能够高效恢复缺失视角下的物体细节，同时保持空间和外观一致性。

Abstract: Viewpoint missing of objects is common in scene reconstruction, as camera
paths typically prioritize capturing the overall scene structure rather than
individual objects. This makes it highly challenging to achieve high-fidelity
object-level modeling while maintaining accurate scene-level representation.
Addressing this issue is critical for advancing downstream tasks requiring
detailed object understanding and appearance modeling. In this paper, we
introduce Refine Any object In any ScenE (RAISE), a novel 3D enhancement
framework that leverages 3D generative priors to recover fine-grained object
geometry and appearance under missing views. Starting from substituting
degraded objects with proxies, via a 3D generative model with strong 3D
understanding, RAISE progressively refines geometry and texture by aligning
each proxy to its degraded counterpart in 7-DOF pose, followed by correcting
spatial and appearance inconsistencies via registration-constrained
enhancement. This two-stage refinement ensures the high-fidelity geometry and
appearance of the original object in unseen views while maintaining consistency
in spatial positioning, observed geometry, and appearance. Extensive
experiments on challenging benchmarks show that RAISE significantly outperforms
state-of-the-art methods in both novel view synthesis and geometry completion
tasks. RAISE is made publicly available at https://github.com/PolySummit/RAISE.

</details>


### [295] [RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment](https://arxiv.org/abs/2506.23852)
*Jianing Jin,Jiangyong Ying,Huiyu Duan,Liu Yang,Sijing Wu,Yunhao Li,Yushuo Zheng,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

Relevance: 30.0

TL;DR: 论文提出了机器人生成内容（RGC）的概念，并建立了首个RGC视频数据库（RGCD），用于评估现有视频质量评估（VQA）模型在RGC视频上的表现。


<details>
  <summary>Details</summary>
Motivation: 随着机器人平台融入日常生活，RGC视频的质量评估成为人机交互的关键，但目前缺乏专门研究。

Method: 建立包含2,100个视频的RGCD数据库，进行主观VQA实验，并评估11种现有VQA模型的表现。

Result: 实验表明现有VQA模型在RGC视频上表现不佳，需开发专用模型。

Conclusion: RGC视频质量评估是一个新兴领域，RGCD数据库为未来研究提供了基础。

Abstract: As camera-equipped robotic platforms become increasingly integrated into
daily life, robotic-generated videos have begun to appear on streaming media
platforms, enabling us to envision a future where humans and robots coexist. We
innovatively propose the concept of Robotic-Generated Content (RGC) to term
these videos generated from egocentric perspective of robots. The perceptual
quality of RGC videos is critical in human-robot interaction scenarios, and RGC
videos exhibit unique distortions and visual requirements that differ markedly
from those of professionally-generated content (PGC) videos and user-generated
content (UGC) videos. However, dedicated research on quality assessment of RGC
videos is still lacking. To address this gap and to support broader robotic
applications, we establish the first Robotic-Generated Content Database (RGCD),
which contains a total of 2,100 videos drawn from three robot categories and
sourced from diverse platforms. A subjective VQA experiment is conducted
subsequently to assess human visual perception of robotic-generated videos.
Finally, we conduct a benchmark experiment to evaluate the performance of 11
state-of-the-art VQA models on our database. Experimental results reveal
significant limitations in existing VQA models when applied to complex,
robotic-generated content, highlighting a critical need for RGC-specific VQA
models. Our RGCD is publicly available at:
https://github.com/IntMeGroup/RGC-VQA.

</details>


### [296] [HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity](https://arxiv.org/abs/2506.23854)
*Yida Wang,Xueyang Zhang,Kun Zhan,Peng Jia,Xianpeng Lang*

Main category: cs.CV

Relevance: 30.0

TL;DR: HiNeuS是一个统一的神经表面重建框架，解决了多视角辐射不一致、无纹理区域关键点缺失和Eikonal约束过强导致的结构退化问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂场景下难以同时保证几何保真度和光度一致性，HiNeuS旨在通过统一管道解决这些问题。

Method: 1) 通过SDF引导的射线追踪进行差分可见性验证；2) 平面共形正则化；3) 基于物理的Eikonal松弛。

Result: 在合成和真实数据集上表现优异，Chamfer距离减少21.4%，PSNR提升2.32 dB。

Conclusion: HiNeuS实现了外观与几何约束的协同优化，适用于逆向渲染任务。

Abstract: Neural surface reconstruction faces persistent challenges in reconciling
geometric fidelity with photometric consistency under complex scene conditions.
We present HiNeuS, a unified framework that holistically addresses three core
limitations in existing approaches: multi-view radiance inconsistency, missing
keypoints in textureless regions, and structural degradation from over-enforced
Eikonal constraints during joint optimization. To resolve these issues through
a unified pipeline, we introduce: 1) Differential visibility verification
through SDF-guided ray tracing, resolving reflection ambiguities via continuous
occlusion modeling; 2) Planar-conformal regularization via ray-aligned geometry
patches that enforce local surface coherence while preserving sharp edges
through adaptive appearance weighting; and 3) Physically-grounded Eikonal
relaxation that dynamically modulates geometric constraints based on local
radiance gradients, enabling detail preservation without sacrificing global
regularity. Unlike prior methods that handle these aspects through sequential
optimizations or isolated modules, our approach achieves cohesive integration
where appearance-geometry constraints evolve synergistically throughout
training. Comprehensive evaluations across synthetic and real-world datasets
demonstrate state-of-the-art performance, including a 21.4% reduction in
Chamfer distance over reflection-aware baselines and 2.32 dB PSNR improvement
against neural rendering counterparts. Qualitative analyses reveal superior
capability in recovering specular instruments, urban layouts with
centimeter-scale infrastructure, and low-textured surfaces without local patch
collapse. The method's generalizability is further validated through successful
application to inverse rendering tasks, including material decomposition and
view-consistent relighting.

</details>


### [297] [Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction](https://arxiv.org/abs/2506.23863)
*Jiahao Ma,Lei Wang,Miaomiao liu,David Ahmedt-Aristizabal,Chuong Nguyen*

Main category: cs.CV

Relevance: 30.0

TL;DR: 本文提出了一种名为Puzzles的数据增强策略，通过模拟多样化的相机轨迹和场景几何，显著提升了3D重建模型的性能，即使使用少量数据也能达到与完整数据集相当的效果。


<details>
  <summary>Details</summary>
Motivation: 解决3D重建模型中训练数据多样性和规模不足的问题。

Method: 提出Puzzles数据增强策略，通过单张图像或视频片段合成大量高质量的视频-深度数据。

Result: 实验表明，Puzzles显著提升了现有3D重建管道的性能，仅需10%的原始数据即可达到与完整数据集相当的精度。

Conclusion: Puzzles是一种高效的数据增强方法，能够在不修改网络架构的情况下显著提升3D重建模型的性能。

Abstract: Multi-view 3D reconstruction remains a core challenge in computer vision.
Recent methods, such as DUST3R and its successors, directly regress pointmaps
from image pairs without relying on known scene geometry or camera parameters.
However, the performance of these models is constrained by the diversity and
scale of available training data. In this work, we introduce Puzzles, a data
augmentation strategy that synthesizes an unbounded volume of high-quality
posed video-depth data from a single image or video clip. By simulating diverse
camera trajectories and realistic scene geometry through targeted image
transformations, Puzzles significantly enhances data variety. Extensive
experiments show that integrating Puzzles into existing video-based 3D
reconstruction pipelines consistently boosts performance without modifying the
underlying network architecture. Notably, models trained on only ten percent of
the original data augmented with Puzzles still achieve accuracy comparable to
those trained on the full dataset. Code is available at
https://jiahao-ma.github.io/puzzles/.

</details>


### [298] [GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models](https://arxiv.org/abs/2506.23903)
*Hamza Rasaee,Taha Koleilat,Hassan Rivaz*

Main category: cs.CV

Relevance: 30.0

TL;DR: 提出了一种基于提示驱动的视觉语言模型（VLM），结合Grounding DINO和SAM2，用于超声图像中多器官的准确分割，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决超声图像分割中因解剖变异、成像协议多样性和标注数据有限带来的挑战。

Method: 使用18个公共超声数据集，15个用于微调Grounding DINO（采用LoRA适应超声领域），3个用于测试未见分布的性能。

Result: 在多数已见数据集上优于UniverSeg、MedSAM等方法，在未见数据集上表现稳定，无需额外微调。

Conclusion: VLM在超声图像分析中具有潜力，减少对大规模器官特定标注数据的依赖。

Abstract: Accurate and generalizable object segmentation in ultrasound imaging remains
a significant challenge due to anatomical variability, diverse imaging
protocols, and limited annotated data. In this study, we propose a
prompt-driven vision-language model (VLM) that integrates Grounding DINO with
SAM2 to enable object segmentation across multiple ultrasound organs. A total
of 18 public ultrasound datasets, encompassing the breast, thyroid, liver,
prostate, kidney, and paraspinal muscle, were utilized. These datasets were
divided into 15 for fine-tuning and validation of Grounding DINO using Low Rank
Adaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for
testing to evaluate performance in unseen distributions. Comprehensive
experiments demonstrate that our approach outperforms state-of-the-art
segmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse,
and SAMUS on most seen datasets while maintaining strong performance on unseen
datasets without additional fine-tuning. These results underscore the promise
of VLMs in scalable and robust ultrasound image analysis, reducing dependence
on large, organ-specific annotated datasets. We will publish our code on
code.sonography.ai after acceptance.

</details>


### [299] [Evaluating the Impact of Khmer Font Types on Text Recognition](https://arxiv.org/abs/2506.23963)
*Vannkinh Nom,Souhail Bakkali,Muhammad Muzzamil Luqman,Mickael Coustaty,Jean-Marc Ogier*

Main category: cs.CV

Relevance: 30.0

TL;DR: 研究评估了19种高棉字体对OCR准确率的影响，发现某些字体表现优异，而另一些较差，强调了字体选择对高棉文本识别的重要性。


<details>
  <summary>Details</summary>
Motivation: 高棉字体多样性对OCR系统构成挑战，研究旨在评估不同字体对识别准确率的影响。

Method: 使用Pytesseract对19种随机选择的高棉字体进行OCR性能测试。

Result: Khmer、Odor MeanChey等字体表现优异，而iSeth First、Bayon等表现较差。

Conclusion: 字体选择对高棉文本识别至关重要，研究为开发更鲁棒的OCR系统提供了见解。

Abstract: Text recognition is significantly influenced by font types, especially for
complex scripts like Khmer. The variety of Khmer fonts, each with its unique
character structure, presents challenges for optical character recognition
(OCR) systems. In this study, we evaluate the impact of 19 randomly selected
Khmer font types on text recognition accuracy using Pytesseract. The fonts
include Angkor, Battambang, Bayon, Bokor, Chenla, Dangrek, Freehand, Kh Kompong
Chhnang, Kh SN Kampongsom, Khmer, Khmer CN Stueng Songke, Khmer Savuth Pen,
Metal, Moul, Odor MeanChey, Preah Vihear, Siemreap, Sithi Manuss, and iSeth
First. Our comparison of OCR performance across these fonts reveals that Khmer,
Odor MeanChey, Siemreap, Sithi Manuss, and Battambang achieve high accuracy,
while iSeth First, Bayon, and Dangrek perform poorly. This study underscores
the critical importance of font selection in optimizing Khmer text recognition
and provides valuable insights for developing more robust OCR systems.

</details>


### [300] [MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction](https://arxiv.org/abs/2506.24096)
*Antoine Guédon,Diego Gomez,Nissim Maruani,Bingchen Gong,George Drettakis,Maks Ovsjanikov*

Main category: cs.CV

Relevance: 30.0

TL;DR: MILo是一个新颖的高斯泼溅框架，通过可微分地从3D高斯中提取网格，弥合了体积和表面表示之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前方法通过昂贵的后处理步骤提取表面，导致几何细节丢失或生成密集网格。MILo旨在直接在训练过程中提取网格，保留几何结构。

Method: 设计了一个完全可微分的过程，从高斯参数中构建网格，包括顶点位置和连接性。关键技术包括双向一致性框架、自适应网格提取和基于高斯的符号距离计算。

Result: MILo能够以最先进的质量重建完整场景，且网格顶点数量比之前方法少一个数量级。

Conclusion: MILo生成的网格轻量且适合下游应用，如物理模拟或动画。

Abstract: While recent advances in Gaussian Splatting have enabled fast reconstruction
of high-quality 3D scenes from images, extracting accurate surface meshes
remains a challenge. Current approaches extract the surface through costly
post-processing steps, resulting in the loss of fine geometric details or
requiring significant time and leading to very dense meshes with millions of
vertices. More fundamentally, the a posteriori conversion from a volumetric to
a surface representation limits the ability of the final mesh to preserve all
geometric structures captured during training. We present MILo, a novel
Gaussian Splatting framework that bridges the gap between volumetric and
surface representations by differentiably extracting a mesh from the 3D
Gaussians. We design a fully differentiable procedure that constructs the
mesh-including both vertex locations and connectivity-at every iteration
directly from the parameters of the Gaussians, which are the only quantities
optimized during training. Our method introduces three key technical
contributions: a bidirectional consistency framework ensuring both
representations-Gaussians and the extracted mesh-capture the same underlying
geometry during training; an adaptive mesh extraction process performed at each
training iteration, which uses Gaussians as differentiable pivots for Delaunay
triangulation; a novel method for computing signed distance values from the 3D
Gaussians that enables precise surface extraction while avoiding geometric
erosion. Our approach can reconstruct complete scenes, including backgrounds,
with state-of-the-art quality while requiring an order of magnitude fewer mesh
vertices than previous methods. Due to their light weight and empty interior,
our meshes are well suited for downstream applications such as physics
simulations or animation.

</details>


### [301] [TextMesh4D: High-Quality Text-to-4D Mesh Generation](https://arxiv.org/abs/2506.24121)
*Sisi Dai,Xinxin Su,Boyan Wan,Ruizhen Hu,Kai Xu*

Main category: cs.CV

Relevance: 30.0

TL;DR: TextMesh4D是一个新颖的框架，用于高质量文本到4D生成，通过分阶段生成静态对象和动态运动，并结合灵活性-刚性正则化优化。


<details>
  <summary>Details</summary>
Motivation: 解决动态3D内容生成（文本到4D）这一未充分探索的挑战性问题。

Method: 使用每面Jacobian作为可微分网格表示，将4D生成分为静态对象创建和动态运动合成两阶段，并提出灵活性-刚性正则化项。

Result: 实验表明，TextMesh4D在时间一致性、结构保真度和视觉真实感方面达到最先进水平，且GPU内存需求低。

Conclusion: TextMesh4D为文本驱动的4D网格生成提供了高效且高质量的解决方案。

Abstract: Recent advancements in diffusion generative models significantly advanced
image, video, and 3D content creation from user-provided text prompts. However,
the challenging problem of dynamic 3D content generation (text-to-4D) with
diffusion guidance remains largely unexplored. In this paper, we introduce
TextMesh4D, a novel framework for high-quality text-to-4D generation. Our
approach leverages per-face Jacobians as a differentiable mesh representation
and decomposes 4D generation into two stages: static object creation and
dynamic motion synthesis. We further propose a flexibility-rigidity
regularization term to stabilize Jacobian optimization under video diffusion
priors, ensuring robust geometric performance. Experiments demonstrate that
TextMesh4D achieves state-of-the-art results in terms of temporal consistency,
structural fidelity, and visual realism. Moreover, TextMesh4D operates with a
low GPU memory overhead-requiring only a single 24GB GPU-offering a
cost-effective yet high-quality solution for text-driven 4D mesh generation.
The code will be released to facilitate future research in text-to-4D
generation.

</details>


### [302] [Maximum Dispersion, Maximum Concentration: Enhancing the Quality of MOP Solutions](https://arxiv.org/abs/2506.22568)
*Gladston Moreira,Ivan Meneghini,Elzabeth Wanner*

Main category: math.OC

Relevance: 30.0

TL;DR: 该研究提出了一种多目标优化方法，通过在决策空间中优化解的分散性和目标空间中特定区域的收敛性，提高解的质量。


<details>
  <summary>Details</summary>
Motivation: 解决多目标优化问题中解的质量和多样性之间的权衡问题，避免决策空间中解的聚类偏差。

Method: 定义目标空间中的兴趣区域（ROI），结合决策空间的均匀性度量，优化解的分散性和收敛性。

Result: 初步实验表明，该方法能有效平衡解的分散性和集中性，减少决策空间的偏差。

Conclusion: 该方法提高了多目标优化的解质量，同时增强了多样性。

Abstract: Multi-objective optimization problems (MOPs) often require a trade-off
between conflicting objectives, maximizing diversity and convergence in the
objective space. This study presents an approach to improve the quality of MOP
solutions by optimizing the dispersion in the decision space and the
convergence in a specific region of the objective space. Our approach defines a
Region of Interest (ROI) based on a cone representing the decision maker's
preferences in the objective space, while enhancing the dispersion of solutions
in the decision space using a uniformity measure. Combining solution
concentration in the objective space with dispersion in the decision space
intensifies the search for Pareto-optimal solutions while increasing solution
diversity. When combined, these characteristics improve the quality of
solutions and avoid the bias caused by clustering solutions in a specific
region of the decision space. Preliminary experiments suggest that this method
enhances multi-objective optimization by generating solutions that effectively
balance dispersion and concentration, thereby mitigating bias in the decision
space.

</details>


### [303] [Denoising Multi-Color QR Codes and Stiefel-Valued Data by Relaxed Regularizations](https://arxiv.org/abs/2506.22826)
*Robert Beinert,Jonas Bresch*

Main category: math.OC

Relevance: 30.0

TL;DR: 论文提出了一种新的高效去噪方法，适用于多二元和Stiefel值数据，通过欧几里得嵌入和凸化技术实现。


<details>
  <summary>Details</summary>
Motivation: 处理流形值数据（如多二元和Stiefel值数据）的去噪问题，扩展现有方法以支持更多数据类型。

Method: 将数据嵌入欧几里得空间，通过半正定矩阵编码流形，并松弛秩约束以实现凸化，使用标准凸分析算法求解。

Result: 在多二元和Stiefel值数据的合成实验中验证了所提方法的有效性。

Conclusion: 方法扩展了现有技术，适用于新数据类型，并通过实验验证了其可行性。

Abstract: The handling of manifold-valued data, for instance, plays a central role in
color restoration tasks relying on circle- or sphere-valued color models, in
the study of rotational or directional information related to the special
orthogonal group, and in Gaussian image processing, where the pixel statistics
are interpreted as values on the hyperbolic sheet. Especially, to denoise these
kind of data, there have been proposed several generalizations of total
variation (TV) and Tikhonov-type denoising models incorporating the underlying
manifolds. Recently, a novel, numerically efficient denoising approach has been
introduced, where the data are embedded in an Euclidean ambient space, the
non-convex manifolds are encoded by a series of positive semi-definite,
fixed-rank matrices, and the rank constraint is relaxed to obtain a
convexification that can be solved using standard algorithms from convex
analysis. The aim of the present paper is to extent this approach to new kinds
of data like multi-binary and Stiefel-valued data. Multi-binary data can, for
instance, be used to model multi-color QR codes whereas Stiefel-valued data
occur in image and video-based recognition. For both new data types, we propose
TV- and Tikhonov-based denoising modelstogether with easy-to-solve
convexification. All derived methods are evaluated on proof-of-concept,
synthetic experiments.

</details>


### [304] [Hierarchical Characterization of Brain Dynamics via State Space-based Vector Quantization](https://arxiv.org/abs/2506.22952)
*Yanwu Yang,Thomas Wolfers*

Main category: eess.IV

Relevance: 30.0

TL;DR: 论文提出了一种基于状态空间的层次化令牌化网络（HST），用于量化大脑状态和转换，并通过改进的VQ-VAE提升量化性能。


<details>
  <summary>Details</summary>
Motivation: 理解大脑动态是神经科学的核心挑战，现有方法忽略状态转换依赖且缺乏稳定嵌入量化。

Method: 提出HST网络，结合状态空间模型和层次化结构，改进VQ-VAE以优化量化性能。

Result: 在公开fMRI数据集上验证了HST的有效性，展示了其在疾病诊断和重建性能中的潜力。

Conclusion: HST为大脑动态表征提供了新框架，有助于分析稳定性。

Abstract: Understanding brain dynamics through functional Magnetic Resonance Imaging
(fMRI) remains a fundamental challenge in neuroscience, particularly in
capturing how the brain transitions between various functional states.
Recently, metastability, which refers to temporarily stable brain states, has
offered a promising paradigm to quantify complex brain signals into
interpretable, discretized representations. In particular, compared to
cluster-based machine learning approaches, tokenization approaches leveraging
vector quantization have shown promise in representation learning with powerful
reconstruction and predictive capabilities. However, most existing methods
ignore brain transition dependencies and lack a quantification of brain
dynamics into representative and stable embeddings. In this study, we propose a
Hierarchical State space-based Tokenization network, termed HST, which
quantizes brain states and transitions in a hierarchical structure based on a
state space-based model. We introduce a refined clustered Vector-Quantization
Variational AutoEncoder (VQ-VAE) that incorporates quantization error feedback
and clustering to improve quantization performance while facilitating
metastability with representative and stable token representations. We validate
our HST on two public fMRI datasets, demonstrating its effectiveness in
quantifying the hierarchical dynamics of the brain and its potential in disease
diagnosis and reconstruction performance. Our method offers a promising
framework for the characterization of brain dynamics, facilitating the analysis
of metastability.

</details>


### [305] [Confident Splatting: Confidence-Based Compression of 3D Gaussian Splatting via Learnable Beta Distributions](https://arxiv.org/abs/2506.22973)
*AmirHossein Naghi Razlighi,Elaheh Badali Golezani,Shohreh Kasaei*

Main category: cs.GR

Relevance: 30.0

TL;DR: 提出了一种基于可学习置信度分数的3D高斯泼溅压缩方法，通过优化置信度分布实现高效压缩并保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅技术因生成数百万个泼溅点导致的存储和计算开销问题。

Method: 使用Beta分布建模可学习置信度分数，通过重建感知损失优化置信度，剪枝低置信度泼溅点。

Result: 实验表明，该方法在压缩和保真度之间取得了优于先前工作的平衡。

Conclusion: 该方法架构无关，适用于任何高斯泼溅变体，并引入平均置信度作为场景质量评估新指标。

Abstract: 3D Gaussian Splatting enables high-quality real-time rendering but often
produces millions of splats, resulting in excessive storage and computational
overhead. We propose a novel lossy compression method based on learnable
confidence scores modeled as Beta distributions. Each splat's confidence is
optimized through reconstruction-aware losses, enabling pruning of
low-confidence splats while preserving visual fidelity. The proposed approach
is architecture-agnostic and can be applied to any Gaussian Splatting variant.
In addition, the average confidence values serve as a new metric to assess the
quality of the scene. Extensive experiments demonstrate favorable trade-offs
between compression and fidelity compared to prior work. Our code and data are
publicly available at
https://github.com/amirhossein-razlighi/Confident-Splatting

</details>


### [306] [Deep Learning in Mild Cognitive Impairment Diagnosis using Eye Movements and Image Content in Visual Memory Tasks](https://arxiv.org/abs/2506.23016)
*Tomás Silva Santos Rocha,Anastasiia Mikhailova,Moreno I. Coco,José Santos-Victor*

Main category: cs.HC

Relevance: 30.0

TL;DR: 该研究利用眼动数据和深度学习模型（VTNet）区分健康对照组与轻度认知障碍（MCI），模型性能与类似研究相当，为MCI自动化诊断工具开发提供了支持。


<details>
  <summary>Details</summary>
Motivation: 全球痴呆症患病率预计到2050年将翻倍，亟需可扩展的诊断工具。本研究旨在通过眼动数据和深度学习模型为MCI诊断提供自动化解决方案。

Method: 使用44名参与者（24名MCI，20名健康对照组）的眼动数据训练VTNet模型，结合时间序列和空间数据（如扫描路径、热图），并测试图像分辨率和任务性能对模型的影响。

Result: 最佳模型在700×700像素热图下达到68%敏感性和76%特异性，性能与类似研究相当。

Conclusion: 研究支持MCI自动化诊断工具的可行性，未来需优化模型并使用标准化任务。

Abstract: The global prevalence of dementia is projected to double by 2050,
highlighting the urgent need for scalable diagnostic tools. This study utilizes
digital cognitive tasks with eye-tracking data correlated with memory processes
to distinguish between Healthy Controls (HC) and Mild Cognitive Impairment
(MCI), a precursor to dementia. A deep learning model based on VTNet was
trained using eye-tracking data from 44 participants (24 MCI, 20 HCs) who
performed a visual memory task. The model utilizes both time series and spatial
data derived from eye-tracking. It was modified to incorporate scan paths, heat
maps, and image content. These modifications also enabled testing parameters
such as image resolution and task performance, analyzing their impact on model
performance. The best model, utilizing $700\times700px$ resolution heatmaps,
achieved 68% sensitivity and 76% specificity. Despite operating under more
challenging conditions (e.g., smaller dataset size, shorter task duration, or a
less standardized task), the model's performance is comparable to an
Alzheimer's study using similar methods (70% sensitivity and 73% specificity).
These findings contribute to the development of automated diagnostic tools for
MCI. Future work should focus on refining the model and using a standardized
long-term visual memory task.

</details>


### [307] [Multi-Source COVID-19 Detection via Variance Risk Extrapolation](https://arxiv.org/abs/2506.23208)
*Runtian Yuan,Qingqiu Li,Junlin Hou,Jilan Xu,Yuejie Zhang,Rui Feng,Hao Chen*

Main category: eess.IV

Relevance: 30.0

TL;DR: 论文提出了一种结合VREx和Mixup的方法，用于多源COVID-19检测任务，通过最小化跨域风险方差和数据增强提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决多源CT扫描数据中因成像协议、扫描仪和患者群体差异导致的域偏移问题，提升模型的跨域泛化能力。

Method: 结合Variance Risk Extrapolation (VREx) 和 Mixup数据增强，VREx最小化跨域风险方差，Mixup提升模型鲁棒性。

Result: 在验证集上平均宏F1得分为0.96，表现出强泛化能力。

Conclusion: VREx和Mixup的结合有效提升了模型在多源数据上的泛化性能。

Abstract: We present our solution for the Multi-Source COVID-19 Detection Challenge,
which aims to classify chest CT scans into COVID and Non-COVID categories
across data collected from four distinct hospitals and medical centers. A major
challenge in this task lies in the domain shift caused by variations in imaging
protocols, scanners, and patient populations across institutions. To enhance
the cross-domain generalization of our model, we incorporate Variance Risk
Extrapolation (VREx) into the training process. VREx encourages the model to
maintain consistent performance across multiple source domains by explicitly
minimizing the variance of empirical risks across environments. This
regularization strategy reduces overfitting to center-specific features and
promotes learning of domain-invariant representations. We further apply Mixup
data augmentation to improve generalization and robustness. Mixup interpolates
both the inputs and labels of randomly selected pairs of training samples,
encouraging the model to behave linearly between examples and enhancing its
resilience to noise and limited data. Our method achieves an average macro F1
score of 0.96 across the four sources on the validation set, demonstrating
strong generalization.

</details>


### [308] [Improving Myocardial Infarction Detection via Synthetic ECG Pretraining](https://arxiv.org/abs/2506.23259)
*Lachin Naghashyar*

Main category: eess.IV

Relevance: 30.0

TL;DR: 论文提出了一种生理感知的ECG合成和预训练方法，用于提高心肌梗塞（MI）检测的准确性，尤其在数据有限的情况下表现显著。


<details>
  <summary>Details</summary>
Motivation: 心肌梗塞是全球主要死因之一，早期准确诊断至关重要。深度学习模型需要大量标注数据，但实际中数据稀缺。

Method: 提出一种生理感知流程：(i) 合成可调MI形态和真实噪声的12导联ECG，(ii) 使用自监督掩码自编码和联合重建-分类目标预训练循环和Transformer分类器。

Result: 合成ECG的统计和视觉分析验证了其真实性。预训练显著提升了分类性能，在低数据场景下AUC提升高达4个百分点。

Conclusion: 研究表明，可控的合成ECG可在临床数据有限时有效改善MI检测。

Abstract: Myocardial infarction is a major cause of death globally, and accurate early
diagnosis from electrocardiograms (ECGs) remains a clinical priority. Deep
learning models have shown promise for automated ECG interpretation, but
require large amounts of labeled data, which are often scarce in practice. We
propose a physiology-aware pipeline that (i) synthesizes 12-lead ECGs with
tunable MI morphology and realistic noise, and (ii) pre-trains recurrent and
transformer classifiers with self-supervised masked-autoencoding plus a joint
reconstruction-classification objective. We validate the realism of synthetic
ECGs via statistical and visual analysis, confirming that key morphological
features are preserved. Pretraining on synthetic data consistently improved
classification performance, particularly in low-data settings, with AUC gains
of up to 4 percentage points. These results show that controlled synthetic ECGs
can help improve MI detection when real clinical data is limited.

</details>


### [309] [SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting](https://arxiv.org/abs/2506.23309)
*Yiming Huang,Long Bai,Beilei Cui,Kun Yuan,Guankun Wang,Mobarakol Islam,Nicolas Padoy,Nassir Navab,Hongliang Ren*

Main category: eess.IV

Relevance: 30.0

TL;DR: SurgTPGS是一种基于文本提示的高斯泼溅方法，用于实时3D手术场景查询，结合了语义特征学习和变形跟踪，提升了手术场景的重建质量和语义理解。


<details>
  <summary>Details</summary>
Motivation: 当前手术研究中，缺乏支持实时文本提示的3D查询方法，SurgTPGS旨在填补这一空白，提升手术规划和实时引导的精确性。

Method: 结合Segment Anything模型和先进的视觉语言模型，提出3D语义特征学习策略、语义感知变形跟踪和语义区域感知优化。

Result: 在两个真实手术数据集上的实验表明，SurgTPGS优于现有方法，显著提升了重建质量和语义平滑性。

Conclusion: SurgTPGS通过增强手术精确性和安全性，为下一代智能手术系统的发展铺平了道路。

Abstract: In contemporary surgical research and practice, accurately comprehending 3D
surgical scenes with text-promptable capabilities is particularly crucial for
surgical planning and real-time intra-operative guidance, where precisely
identifying and interacting with surgical tools and anatomical structures is
paramount. However, existing works focus on surgical vision-language model
(VLM), 3D reconstruction, and segmentation separately, lacking support for
real-time text-promptable 3D queries. In this paper, we present SurgTPGS, a
novel text-promptable Gaussian Splatting method to fill this gap. We introduce
a 3D semantics feature learning strategy incorporating the Segment Anything
model and state-of-the-art vision-language models. We extract the segmented
language features for 3D surgical scene reconstruction, enabling a more
in-depth understanding of the complex surgical environment. We also propose
semantic-aware deformation tracking to capture the seamless deformation of
semantic features, providing a more precise reconstruction for both texture and
semantic features. Furthermore, we present semantic region-aware optimization,
which utilizes regional-based semantic information to supervise the training,
particularly promoting the reconstruction quality and semantic smoothness. We
conduct comprehensive experiments on two real-world surgical datasets to
demonstrate the superiority of SurgTPGS over state-of-the-art methods,
highlighting its potential to revolutionize surgical practices. SurgTPGS paves
the way for developing next-generation intelligent surgical systems by
enhancing surgical precision and safety. Our code is available at:
https://github.com/lastbasket/SurgTPGS.

</details>


### [310] [FD-DiT: Frequency Domain-Directed Diffusion Transformer for Low-Dose CT Reconstruction](https://arxiv.org/abs/2506.23466)
*Qiqing Liu,Guoquan Wei,Zekun Zhou,Yiyang Wen,Liu Shi,Qiegen Liu*

Main category: eess.IV

Relevance: 30.0

TL;DR: 提出了一种基于频率域导向扩散Transformer（FD-DiT）的低剂量CT重建方法，通过频率解耦和混合去噪网络优化图像细节保留。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT（LDCT）虽减少辐射，但图像噪声和伪影影响诊断准确性，现有方法在保留细节上不足。

Method: FD-DiT结合扩散模型和频率解耦技术，通过逐步引入噪声并去噪，利用滑动稀疏局部注意力优化高频噪声识别。

Result: 实验表明，FD-DiT在相同剂量下优于现有方法，能有效抑制噪声和伪影。

Conclusion: FD-DiT为LDCT重建提供了高效解决方案，显著提升图像质量。

Abstract: Low-dose computed tomography (LDCT) reduces radiation exposure but suffers
from image artifacts and loss of detail due to quantum and electronic noise,
potentially impacting diagnostic accuracy. Transformer combined with diffusion
models has been a promising approach for image generation. Nevertheless,
existing methods exhibit limitations in preserving finegrained image details.
To address this issue, frequency domain-directed diffusion transformer (FD-DiT)
is proposed for LDCT reconstruction. FD-DiT centers on a diffusion strategy
that progressively introduces noise until the distribution statistically aligns
with that of LDCT data, followed by denoising processing. Furthermore, we
employ a frequency decoupling technique to concentrate noise primarily in
high-frequency domain, thereby facilitating effective capture of essential
anatomical structures and fine details. A hybrid denoising network is then
utilized to optimize the overall data reconstruction process. To enhance the
capability in recognizing high-frequency noise, we incorporate sliding sparse
local attention to leverage the sparsity and locality of shallow-layer
information, propagating them via skip connections for improving feature
representation. Finally, we propose a learnable dynamic fusion strategy for
optimal component integration. Experimental results demonstrate that at
identical dose levels, LDCT images reconstructed by FD-DiT exhibit superior
noise and artifact suppression compared to state-of-the-art methods.

</details>


### [311] [KiseKloset: Comprehensive System For Outfit Retrieval, Recommendation, And Try-On](https://arxiv.org/abs/2506.23471)
*Thanh-Tung Phan-Nguyen,Khoi-Nguyen Nguyen-Ngoc,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.IR

Relevance: 30.0

TL;DR: 论文提出了一种名为KiseKloset的系统，用于服装检索、推荐和虚拟试穿，结合了Transformer架构和轻量级虚拟试穿框架，显著提升了用户体验。


<details>
  <summary>Details</summary>
Motivation: 提升全球时尚电商行业的用户体验，通过个性化推荐和虚拟试穿技术增强客户参与度。

Method: 1. 探索两种服装检索方法：相似物品检索和文本反馈引导检索。2. 设计新型Transformer架构推荐互补物品。3. 集成近似算法优化搜索流程。4. 开发轻量级虚拟试穿框架。

Result: 用户研究表明，84%的参与者认为该系统非常有用，显著改善了在线购物体验。

Conclusion: KiseKloset系统通过技术创新提升了时尚电商的用户体验，具有实际应用价值。

Abstract: The global fashion e-commerce industry has become integral to people's daily
lives, leveraging technological advancements to offer personalized shopping
experiences, primarily through recommendation systems that enhance customer
engagement through personalized suggestions. To improve customers' experience
in online shopping, we propose a novel comprehensive KiseKloset system for
outfit retrieval, recommendation, and try-on. We explore two approaches for
outfit retrieval: similar item retrieval and text feedback-guided item
retrieval. Notably, we introduce a novel transformer architecture designed to
recommend complementary items from diverse categories. Furthermore, we enhance
the overall performance of the search pipeline by integrating approximate
algorithms to optimize the search process. Additionally, addressing the crucial
needs of online shoppers, we employ a lightweight yet efficient virtual try-on
framework capable of real-time operation, memory efficiency, and maintaining
realistic outputs compared to its predecessors. This virtual try-on module
empowers users to visualize specific garments on themselves, enhancing the
customers' experience and reducing costs associated with damaged items for
retailers. We deployed our end-to-end system for online users to test and
provide feedback, enabling us to measure their satisfaction levels. The results
of our user study revealed that 84% of participants found our comprehensive
system highly useful, significantly improving their online shopping experience.

</details>


### [312] [Spatio-Temporal Representation Decoupling and Enhancement for Federated Instrument Segmentation in Surgical Videos](https://arxiv.org/abs/2506.23759)
*Zheng Fang,Xiaoming Qi,Chun-Mei Feng,Jialun Pei,Weixin Si,Yueming Jin*

Main category: eess.IV

Relevance: 30.0

TL;DR: 提出了一种个性化联邦学习方案FedST，用于手术器械分割，通过分离和增强时空表示来利用手术领域的知识。


<details>
  <summary>Details</summary>
Motivation: 解决手术领域中联邦学习的局限性，如多样化的解剖背景和高度相似的手术器械表示，以及利用手术模拟器生成合成数据。

Method: FedST方案包括局部训练的表示分离与合作机制（RSC）和全局训练的合成数据驱动的显式表示量化（SERQ）。

Result: 该方法提升了手术器械分割的性能，并增强了模型的泛化能力。

Conclusion: FedST通过结合手术领域知识，有效提升了联邦学习在手术器械分割中的应用效果。

Abstract: Surgical instrument segmentation under Federated Learning (FL) is a promising
direction, which enables multiple surgical sites to collaboratively train the
model without centralizing datasets. However, there exist very limited FL works
in surgical data science, and FL methods for other modalities do not consider
inherent characteristics in surgical domain: i) different scenarios show
diverse anatomical backgrounds while highly similar instrument representation;
ii) there exist surgical simulators which promote large-scale synthetic data
generation with minimal efforts. In this paper, we propose a novel Personalized
FL scheme, Spatio-Temporal Representation Decoupling and Enhancement (FedST),
which wisely leverages surgical domain knowledge during both local-site and
global-server training to boost segmentation. Concretely, our model embraces a
Representation Separation and Cooperation (RSC) mechanism in local-site
training, which decouples the query embedding layer to be trained privately, to
encode respective backgrounds. Meanwhile, other parameters are optimized
globally to capture the consistent representations of instruments, including
the temporal layer to capture similar motion patterns. A textual-guided channel
selection is further designed to highlight site-specific features, facilitating
model adapta tion to each site. Moreover, in global-server training, we propose
Synthesis-based Explicit Representation Quantification (SERQ), which defines an
explicit representation target based on synthetic data to synchronize the model
convergence during fusion for improving model generalization.

</details>


### [313] [Supervised Diffusion-Model-Based PET Image Reconstruction](https://arxiv.org/abs/2506.24034)
*George Webber,Alexander Hammers,Andrew P King,Andrew J Reader*

Main category: physics.med-ph

Relevance: 30.0

TL;DR: 提出了一种基于监督扩散模型（DM）的PET图像重建方法，优于现有深度学习方法，并改进了不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 现有基于DM的PET重建方法未显式建模DM先验与噪声数据的交互，限制了重建精度。

Method: 提出监督DM算法，强制PET泊松似然模型的非负性，适应PET图像的宽强度范围。

Result: 在真实脑PET模型上表现优于或匹配现有深度学习方法，支持更准确的后验采样。

Conclusion: 监督DM方法在PET重建中有效，扩展至3D PET并展示实际应用潜力。

Abstract: Diffusion models (DMs) have recently been introduced as a regularizing prior
for PET image reconstruction, integrating DMs trained on high-quality PET
images with unsupervised schemes that condition on measured data. While these
approaches have potential generalization advantages due to their independence
from the scanner geometry and the injected activity level, they forgo the
opportunity to explicitly model the interaction between the DM prior and noisy
measurement data, potentially limiting reconstruction accuracy. To address
this, we propose a supervised DM-based algorithm for PET reconstruction. Our
method enforces the non-negativity of PET's Poisson likelihood model and
accommodates the wide intensity range of PET images. Through experiments on
realistic brain PET phantoms, we demonstrate that our approach outperforms or
matches state-of-the-art deep learning-based methods quantitatively across a
range of dose levels. We further conduct ablation studies to demonstrate the
benefits of the proposed components in our model, as well as its dependence on
training data, parameter count, and number of diffusion steps. Additionally, we
show that our approach enables more accurate posterior sampling than
unsupervised DM-based methods, suggesting improved uncertainty estimation.
Finally, we extend our methodology to a practical approach for fully 3D PET and
present example results from real [$^{18}$F]FDG brain PET data.

</details>


### [314] [Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring](https://arxiv.org/abs/2506.22437)
*Xinxin Sun,Peter Chang*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出了一种基于物理信息的图像对齐框架，用于结构健康监测中的裂缝演化跟踪，通过非线性各向异性扩散和RANSAC估计实现高精度对齐。


<details>
  <summary>Details</summary>
Motivation: 传统特征检测器（如SIFT、SURF）在高频边缘抑制和纹理阴影表面表现不佳，需要一种更适合裂缝定位的方法。

Method: 采用非线性各向异性扩散构建裂缝保留尺度空间，结合RANSAC估计实现几何校正，无需训练或参数调整。

Result: 在多种实际条件下，裂缝面积和长度误差分别减少70%和90%，对齐误差低于5%。

Conclusion: 该方法为裂缝演化跟踪提供了一种无监督、可解释且计算轻量的解决方案。

Abstract: Accurate image alignment is essential for monitoring crack evolution in
structural health monitoring (SHM), particularly under real-world conditions
involving perspective distortion, occlusion, and low contrast. However,
traditional feature detectors such as SIFT and SURF, which rely on
Gaussian-based scale spaces, tend to suppress high-frequency edges, making them
unsuitable for thin crack localization. Lightweight binary alternatives like
ORB and BRISK, while computationally efficient, often suffer from poor keypoint
repeatability on textured or shadowed surfaces. This study presents a
physics-informed alignment framework that adapts the open KAZE architecture to
SHM-specific challenges. By utilizing nonlinear anisotropic diffusion to
construct a crack-preserving scale space, and integrating RANSAC-based
homography estimation, the framework enables accurate geometric correction
without the need for training, parameter tuning, or prior calibration. The
method is validated on time-lapse images of masonry and concrete acquired via
handheld smartphone under varied field conditions, including shadow
interference, cropping, oblique viewing angles, and surface clutter. Compared
to classical detectors, the proposed framework reduces crack area and spine
length errors by up to 70 percent and 90 percent, respectively, while
maintaining sub-5 percent alignment error in key metrics. Unsupervised,
interpretable, and computationally lightweight, this approach supports scalable
deployment via UAVs and mobile platforms. By tailoring nonlinear scale-space
modeling to SHM image alignment, this work offers a robust and physically
grounded alternative to conventional techniques for tracking real-world crack
evolution.

</details>


### [315] [Counting with Confidence: Accurate Pest Monitoring in Water Traps](https://arxiv.org/abs/2506.22438)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.CV

Relevance: 20.0

TL;DR: 该论文提出了一种基于计数结果和外部环境条件的害虫计数置信度评估方法，通过多因素敏感性分析和自适应DBSCAN聚类算法优化评估，实验显示其性能显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有害虫计数研究在真实场景中缺乏对计数结果可靠性的评估，因此需要一种全面的置信度评估方法。

Method: 结合害虫检测网络、图像质量评估、复杂度评估、分布均匀性评估，并通过回归模型预测计数置信度。

Result: 实验结果显示，该方法在MSE上降低了31.7%，R2提高了15.2%。

Conclusion: 这是首个专注于全面评估计数置信度的研究，并通过模型量化影响因素与置信度的关系。

Abstract: Accurate pest population monitoring and tracking their dynamic changes are
crucial for precision agriculture decision-making. A common limitation in
existing vision-based automatic pest counting research is that models are
typically evaluated on datasets with ground truth but deployed in real-world
scenarios without assessing the reliability of counting results due to the lack
of ground truth. To this end, this paper proposed a method for comprehensively
evaluating pest counting confidence in the image, based on information related
to counting results and external environmental conditions. First, a pest
detection network is used for pest detection and counting, extracting counting
result-related information. Then, the pest images undergo image quality
assessment, image complexity assessment, and pest distribution uniformity
assessment. And the changes in image clarity caused by stirring during image
acquisition are quantified by calculating the average gradient magnitude.
Notably, we designed a hypothesis-driven multi-factor sensitivity analysis
method to select the optimal image quality assessment and image complexity
assessment methods. And we proposed an adaptive DBSCAN clustering algorithm for
pest distribution uniformity assessment. Finally, the obtained information
related to counting results and external environmental conditions is input into
a regression model for prediction, resulting in the final pest counting
confidence. To the best of our knowledge, this is the first study dedicated to
comprehensively evaluating counting confidence in counting tasks, and
quantifying the relationship between influencing factors and counting
confidence through a model. Experimental results show our method reduces MSE by
31.7% and improves R2 by 15.2% on the pest counting confidence test set,
compared to the baseline built primarily on information related to counting
results.

</details>


### [316] [A Novel Frame Identification and Synchronization Technique for Smartphone Visible Light Communication Systems Based on Convolutional Neural Networks](https://arxiv.org/abs/2506.23004)
*Vaigai Nayaki Yokar,Hoa Le-Minh,Xicong Li,Wai Lok Woo,Luis Nero Alves,Stanislav Zvanovec,Tran The Son,Zabih Ghassemlooy*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出了一种轻量级CNN方法，用于屏幕到相机可见光通信中的帧识别与同步，准确率达98.74%。


<details>
  <summary>Details</summary>
Motivation: 解决屏幕到相机通信中因模糊、裁剪和旋转图像带来的实时挑战。

Method: 使用Python和TensorFlow Keras框架训练CNN模型，通过三次实时实验验证。

Result: 模型在帧识别与同步中达到98.74%的准确率。

Conclusion: 该方法在屏幕到相机通信系统中表现高效且鲁棒。

Abstract: This paper proposes a novel, robust, and lightweight supervised Convolutional
Neural Network (CNN)-based technique for frame identification and
synchronization, designed to enhance short-link communication performance in a
screen-to-camera (S2C) based visible light communication (VLC) system.
Developed using Python and the TensorFlow Keras framework, the proposed CNN
model was trained through three real-time experimental investigations conducted
in Jupyter Notebook. These experiments incorporated a dataset created from
scratch to address various real-time challenges in S2C communication, including
blurring, cropping, and rotated images in mobility scenarios. Overhead frames
were introduced for synchronization, which leads to enhanced system
performance. The experimental results demonstrate that the proposed model
achieves an overall accuracy of approximately 98.74%, highlighting its
effectiveness in identifying and synchronizing frames in S2C VLC systems.

</details>


### [317] [VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions](https://arxiv.org/abs/2506.23236)
*Marko Mihajlovic,Siwei Zhang,Gen Li,Kaifeng Zhao,Lea Müller,Siyu Tang*

Main category: cs.CV

Relevance: 20.0

TL;DR: VolumetricSMPL是一种神经体积人体模型，通过动态混合学习权重矩阵（NBW）提高计算效率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于网格的人体模型在处理复杂交互时效率低下，现有体积神经隐式模型在鲁棒性或计算成本上存在不足。

Method: 提出VolumetricSMPL，利用NBW生成紧凑高效的MLP解码器，动态混合权重矩阵。

Result: 比COAP快10倍，GPU内存使用降低6倍，精度更高，支持SDF接触建模。

Conclusion: VolumetricSMPL在多项任务中表现优异，具有广泛适用性和高效性。

Abstract: Parametric human body models play a crucial role in computer graphics and
vision, enabling applications ranging from human motion analysis to
understanding human-environment interactions. Traditionally, these models use
surface meshes, which pose challenges in efficiently handling interactions with
other geometric entities, such as objects and scenes, typically represented as
meshes or point clouds. To address this limitation, recent research has
explored volumetric neural implicit body models. However, existing works are
either insufficiently robust for complex human articulations or impose high
computational and memory costs, limiting their widespread use. To this end, we
introduce VolumetricSMPL, a neural volumetric body model that leverages Neural
Blend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlike
prior approaches that rely on large MLPs, NBW dynamically blends a small set of
learned weight matrices using predicted shape- and pose-dependent coefficients,
significantly improving computational efficiency while preserving
expressiveness. VolumetricSMPL outperforms prior volumetric occupancy model
COAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy,
and a Signed Distance Function (SDF) for efficient and differentiable contact
modeling. We demonstrate VolumetricSMPL's strengths across four challenging
tasks: (1) reconstructing human-object interactions from in-the-wild images,
(2) recovering human meshes in 3D scenes from egocentric views, (3)
scene-constrained motion synthesis, and (4) resolving self-intersections. Our
results highlight its broad applicability and significant performance and
efficiency gains.

</details>


### [318] [DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection](https://arxiv.org/abs/2506.23252)
*Kunwei Lv,Ping Lan*

Main category: cs.CV

Relevance: 20.0

TL;DR: DGE-YOLO是一个改进的YOLO框架，用于多模态无人机目标检测，通过双分支架构和高效多尺度注意力机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 无人机（UAV）的快速普及使得在复杂条件下检测小目标变得重要，但现有方法在多模态输入下性能不足。

Method: 提出双分支架构处理红外和可见光图像，引入高效多尺度注意力机制（EMA），并替换传统特征聚合模块以减少信息损失。

Result: 在Drone Vehicle数据集上，DGE-YOLO优于现有方法。

Conclusion: DGE-YOLO在多模态无人机目标检测任务中表现优异。

Abstract: The rapid proliferation of unmanned aerial vehicles (UAVs) has highlighted
the importance of robust and efficient object detection in diverse aerial
scenarios. Detecting small objects under complex conditions, however, remains a
significant challenge. Existing approaches often prioritize inference speed,
leading to degraded performance when handling multi-modal inputs. To address
this, we present DGE-YOLO, an enhanced YOLO-based detection framework designed
to effectively fuse multi-modal information. Specifically, we introduce a
dual-branch architecture for modality-specific feature extraction, enabling the
model to process both infrared and visible images. To further enrich semantic
representation, we propose an Efficient Multi-scale Attention (EMA) mechanism
that enhances feature learning across spatial scales. Additionally, we replace
the conventional neck with a Gather-and-Distribute module to mitigate
information loss during feature aggregation. Extensive experiments on the Drone
Vehicle dataset demonstrate that DGE-YOLO achieves superior performance over
state-of-the-art methods, validating its effectiveness in multi-modal UAV
object detection tasks.

</details>


### [319] [Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination Correction with Gaussian Splatting](https://arxiv.org/abs/2506.23308)
*Yiming Huang,Long Bai,Beilei Cui,Yanheng Li,Tong Chen,Jie Wang,Jinlin Wu,Zhen Lei,Hongbin Liu,Hongliang Ren*

Main category: cs.CV

Relevance: 20.0

TL;DR: Endo-4DGX是一种用于内窥镜场景的新型重建方法，通过光照自适应的高斯泼溅技术解决了极端光照条件下的渲染问题。


<details>
  <summary>Details</summary>
Motivation: 在图像引导机器人手术中，软组织的精确重建对自动化至关重要。现有3D高斯泼溅技术在极端光照条件下（如低光和过曝）存在优化问题和渲染质量差的问题。

Method: Endo-4DGX结合光照嵌入、区域感知增强模块和空间感知调整模块，实现光照自适应优化。

Result: 在低光和过曝条件下，Endo-4DGX显著优于现有重建和恢复方法的组合，同时保持几何精度。

Conclusion: Endo-4DGX在极端光照条件下表现出色，有望推动机器人辅助手术应用。

Abstract: Accurate reconstruction of soft tissue is crucial for advancing automation in
image-guided robotic surgery. The recent 3D Gaussian Splatting (3DGS)
techniques and their variants, 4DGS, achieve high-quality renderings of dynamic
surgical scenes in real-time. However, 3D-GS-based methods still struggle in
scenarios with varying illumination, such as low light and over-exposure.
Training 3D-GS in such extreme light conditions leads to severe optimization
problems and devastating rendering quality. To address these challenges, we
present Endo-4DGX, a novel reconstruction method with illumination-adaptive
Gaussian Splatting designed specifically for endoscopic scenes with uneven
lighting. By incorporating illumination embeddings, our method effectively
models view-dependent brightness variations. We introduce a region-aware
enhancement module to model the sub-area lightness at the Gaussian level and a
spatial-aware adjustment module to learn the view-consistent brightness
adjustment. With the illumination adaptive design, Endo-4DGX achieves superior
rendering performance under both low-light and over-exposure conditions while
maintaining geometric accuracy. Additionally, we employ an exposure control
loss to restore the appearance from adverse exposure to the normal level for
illumination-adaptive optimization. Experimental results demonstrate that
Endo-4DGX significantly outperforms combinations of state-of-the-art
reconstruction and restoration methods in challenging lighting environments,
underscoring its potential to advance robot-assisted surgical applications. Our
code is available at https://github.com/lastbasket/Endo-4DGX.

</details>


### [320] [A High-Throughput Platform to Bench Test Smartphone-Based Heart Rate Measurements Derived From Video](https://arxiv.org/abs/2506.23414)
*Ming-Zher Poh,Jonathan Wang,Jonathan Hsu,Lawrence Cai,Eric Teasley,James A. Taylor,Jameson K. Rogers,Anupam Pathak,Shwetak Patel*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种高吞吐量的测试平台，用于评估智能手机心率监测应用的性能和设备兼容性，解决了设备多样性和标准化测试方法不足的问题。


<details>
  <summary>Details</summary>
Motivation: 智能手机心率监测应用因设备多样性和缺乏标准化测试方法而面临性能评估和兼容性挑战，需要一种高效、可扩展的解决方案。

Method: 设计了一个测试平台，包括可同时测试12部智能手机的测试装置、生成可控心率和信号质量的合成PPG视频的方法，以及协调视频播放和数据记录的主机。

Result: 平台在输入和测量心率之间的平均绝对百分比误差为0.11%，相关系数为0.92，且成功验证了20款智能手机符合ANSI/CTA标准。

Conclusion: 该平台为智能手机心率应用的预部署测试提供了可扩展的解决方案，有助于提升应用性能和设备兼容性。

Abstract: Smartphone-based heart rate (HR) monitoring apps using finger-over-camera
photoplethysmography (PPG) face significant challenges in performance
evaluation and device compatibility due to device variability and
fragmentation. Manual testing is impractical, and standardized methods are
lacking. This paper presents a novel, high-throughput bench-testing platform to
address this critical need. We designed a system comprising a test rig capable
of holding 12 smartphones for parallel testing, a method for generating
synthetic PPG test videos with controllable HR and signal quality, and a host
machine for coordinating video playback and data logging. The system achieved a
mean absolute percentage error (MAPE) of 0.11% +/- 0.001% between input and
measured HR, and a correlation coefficient of 0.92 +/- 0.008 between input and
measured PPG signals using a clinically-validated smartphone-based HR app.
Bench-testing results of 20 different smartphone models correctly classified
all the devices as meeting the ANSI/CTA accuracy standards for HR monitors
(MAPE <10%) when compared to a prospective clinical study with 80 participants,
demonstrating high positive predictive value. This platform offers a scalable
solution for pre-deployment testing of smartphone HR apps to improve app
performance, ensure device compatibility, and advance the field of mobile
health.

</details>


### [321] [Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation](https://arxiv.org/abs/2506.23505)
*Tinh Nguyen*

Main category: cs.CV

Relevance: 20.0

TL;DR: 该论文提出了一种基于YOLOv12架构的水下目标检测方法，结合物理增强技术和新型注意力机制，显著提升了在低能见度条件下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 水下目标检测在自主导航和环境监测中至关重要，但受限于光线衰减和浑浊等问题。现有方法在实时性和准确性上难以平衡，特别是在低能见度条件下。

Method: 通过结合物理增强技术（如湍流自适应模糊和光谱HSV变换）与YOLOv12架构，引入Residual ELAN块和Area Attention机制，优化了模型在浑浊和遮挡环境中的表现。

Result: 在四个数据集上实现了98.30%的mAP和142 FPS的性能，遮挡鲁棒性提升18.9%，小目标召回率提高22.4%，检测精度提升7.94%。

Conclusion: 该方法为水下机器人和保护应用提供了高效且精确的解决方案，并通过消融实验验证了增强策略的关键作用。

Abstract: Underwater object detection is crucial for autonomous navigation,
environmental monitoring, and marine exploration, but it is severely hampered
by light attenuation, turbidity, and occlusion. Current methods balance
accuracy and computational efficiency, but they have trouble deploying in
real-time under low visibility conditions. Through the integration of
physics-informed augmentation techniques with the YOLOv12 architecture, this
study advances underwater detection. With Residual ELAN blocks to preserve
structural features in turbid waters and Area Attention to maintain large
receptive fields for occluded objects while reducing computational complexity.
Underwater optical properties are addressed by domain-specific augmentations
such as turbulence adaptive blurring, biologically grounded occlusion
simulation, and spectral HSV transformations for color distortion. Extensive
tests on four difficult datasets show state-of-the-art performance, with
Brackish data registering 98.30% mAP at 142 FPS. YOLOv12 improves occlusion
robustness by 18.9%, small-object recall by 22.4%, and detection precision by
up to 7.94% compared to previous models. The crucial role of augmentation
strategy is validated by ablation studies. This work offers a precise and
effective solution for conservation and underwater robotics applications.

</details>


### [322] [From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection](https://arxiv.org/abs/2506.23519)
*Qi Qin,Runmin Cong,Gen Zhan,Yiting Liao,Sam Kwong*

Main category: cs.CV

Relevance: 20.0

TL;DR: 该论文提出了一种利用注视信息辅助弱监督下视频显著对象检测的方法，通过位置和语义嵌入模块（PSE）以及语义和局部查询（SLQ）竞争器，结合对比学习范式（IIMC），提升了时空建模能力。


<details>
  <summary>Details</summary>
Motivation: 注视信息更易获取且更符合人类视觉模式，因此论文旨在利用注视信息辅助弱监督下的视频显著对象检测。

Method: 提出PSE模块提供位置和语义指导，设计SLQ竞争器选择最佳对象查询，并引入IIMC模型通过对比学习提升时空建模能力。

Result: 在五个流行的VSOD基准测试中，模型在多种评估指标上优于其他竞争者。

Conclusion: 结合注视信息的弱监督方法能有效提升视频显著对象检测的性能。

Abstract: The eye-tracking video saliency prediction (VSP) task and video salient
object detection (VSOD) task both focus on the most attractive objects in video
and show the result in the form of predictive heatmaps and pixel-level saliency
masks, respectively. In practical applications, eye tracker annotations are
more readily obtainable and align closely with the authentic visual patterns of
human eyes. Therefore, this paper aims to introduce fixation information to
assist the detection of video salient objects under weak supervision. On the
one hand, we ponder how to better explore and utilize the information provided
by fixation, and then propose a Position and Semantic Embedding (PSE) module to
provide location and semantic guidance during the feature learning process. On
the other hand, we achieve spatiotemporal feature modeling under weak
supervision from the aspects of feature selection and feature contrast. A
Semantics and Locality Query (SLQ) Competitor with semantic and locality
constraints is designed to effectively select the most matching and accurate
object query for spatiotemporal modeling. In addition, an Intra-Inter Mixed
Contrastive (IIMC) model improves the spatiotemporal modeling capabilities
under weak supervision by forming an intra-video and inter-video contrastive
learning paradigm. Experimental results on five popular VSOD benchmarks
indicate that our model outperforms other competitors on various evaluation
metrics.

</details>


### [323] [Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound](https://arxiv.org/abs/2506.23538)
*Yuhao Huang,Yueyue Xu,Haoran Dou,Jiaxiao Deng,Xin Yang,Hongyu Zheng,Dong Ni*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种智能系统，用于同时实现自动化平面定位和先天性子宫异常（CUA）诊断，结合了去噪扩散模型和强化学习框架。


<details>
  <summary>Details</summary>
Motivation: 先天性子宫异常（CUAs）可能导致不孕、流产等问题，3D超声（US）能更准确地评估CUAs，但需要自动化工具提高效率和准确性。

Method: 1）使用局部和全局引导的去噪扩散模型；2）基于强化学习的框架提取关键切片；3）文本驱动的不确定性建模优化分类。

Result: 在大规模3D子宫US数据集上验证了方法的有效性。

Conclusion: 该方法在平面定位和CUA诊断方面表现出色。

Abstract: Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage,
preterm birth, and an increased risk of pregnancy complications. Compared to
traditional 2D ultrasound (US), 3D US can reconstruct the coronal plane,
providing a clear visualization of the uterine morphology for assessing CUAs
accurately. In this paper, we propose an intelligent system for simultaneous
automated plane localization and CUA diagnosis. Our highlights are: 1) we
develop a denoising diffusion model with local (plane) and global (volume/text)
guidance, using an adaptive weighting strategy to optimize attention allocation
to different conditions; 2) we introduce a reinforcement learning-based
framework with unsupervised rewards to extract the key slice summary from
redundant sequences, fully integrating information across multiple planes to
reduce learning difficulty; 3) we provide text-driven uncertainty modeling for
coarse prediction, and leverage it to adjust the classification probability for
overall performance improvement. Extensive experiments on a large 3D uterine US
dataset show the efficacy of our method, in terms of plane localization and CUA
diagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.

</details>


### [324] [Consistent Time-of-Flight Depth Denoising via Graph-Informed Geometric Attention](https://arxiv.org/abs/2506.23542)
*Weida Wang,Changyong He,Jin Zeng,Di Qiu*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出了一种基于运动不变图融合的ToF深度去噪网络，通过跨帧几何注意力增强时间稳定性和空间清晰度。


<details>
  <summary>Details</summary>
Motivation: ToF传感器捕获的深度图像噪声较多，现有方法未充分考虑跨帧深度变化，导致时间不一致和空间模糊。

Method: 利用图结构的时域自相似性进行图融合，结合图像平滑先验和ToF噪声分布，构建最大后验问题，并通过迭代滤波器实现。

Result: 在合成DVToF数据集和真实Kinectv2数据集上均表现出色，达到SOTA性能。

Conclusion: 该方法在ToF深度去噪中实现了高性能和可解释性，具有鲁棒泛化能力。

Abstract: Depth images captured by Time-of-Flight (ToF) sensors are prone to noise,
requiring denoising for reliable downstream applications. Previous works either
focus on single-frame processing, or perform multi-frame processing without
considering depth variations at corresponding pixels across frames, leading to
undesirable temporal inconsistency and spatial ambiguity. In this paper, we
propose a novel ToF depth denoising network leveraging motion-invariant graph
fusion to simultaneously enhance temporal stability and spatial sharpness.
Specifically, despite depth shifts across frames, graph structures exhibit
temporal self-similarity, enabling cross-frame geometric attention for graph
fusion. Then, by incorporating an image smoothness prior on the fused graph and
data fidelity term derived from ToF noise distribution, we formulate a maximum
a posterior problem for ToF denoising. Finally, the solution is unrolled into
iterative filters whose weights are adaptively learned from the graph-informed
geometric attention, producing a high-performance yet interpretable network.
Experimental results demonstrate that the proposed scheme achieves
state-of-the-art performance in terms of accuracy and consistency on synthetic
DVToF dataset and exhibits robust generalization on the real Kinectv2 dataset.
Source code will be released at
\href{https://github.com/davidweidawang/GIGA-ToF}{https://github.com/davidweidawang/GIGA-ToF}.

</details>


### [325] [Oneta: Multi-Style Image Enhancement Using Eigentransformation Functions](https://arxiv.org/abs/2506.23547)
*Jiwon Kim,Soohyun Hwang,Dong-O Kim,Changsu Han,Min Kyu Park,Chang-Su Kim*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出了一种名为Oneta的多风格图像增强算法，通过两步操作（强度增强和颜色校正）实现高性能，支持多种风格任务。


<details>
  <summary>Details</summary>
Motivation: 解决多风格图像增强任务，提供一种简单但高效的解决方案。

Method: 使用两步操作：强度增强（通过eigenTF表示）和颜色校正（通过CCM）。网络由Y-Net和C-Net组成，支持K种风格的学习。

Result: 在30个数据集上成功完成六种图像增强任务，表现优异。

Conclusion: Oneta是一种高效且通用的多风格图像增强方法。

Abstract: The first algorithm, called Oneta, for a novel task of multi-style image
enhancement is proposed in this work. Oneta uses two point operators
sequentially: intensity enhancement with a transformation function (TF) and
color correction with a color correction matrix (CCM). This two-step
enhancement model, though simple, achieves a high performance upper bound.
Also, we introduce eigentransformation function (eigenTF) to represent TF
compactly. The Oneta network comprises Y-Net and C-Net to predict eigenTF and
CCM parameters, respectively. To support $K$ styles, Oneta employs $K$
learnable tokens. During training, each style token is learned using image
pairs from the corresponding dataset. In testing, Oneta selects one of the $K$
style tokens to enhance an image accordingly. Extensive experiments show that
the single Oneta network can effectively undertake six enhancement tasks --
retouching, image signal processing, low-light image enhancement, dehazing,
underwater image enhancement, and white balancing -- across 30 datasets.

</details>


### [326] [Brain Tumor Detection through Thermal Imaging and MobileNET](https://arxiv.org/abs/2506.23627)
*Roham Maiti,Debasmita Bhoumik*

Main category: cs.CV

Relevance: 20.0

TL;DR: 论文提出了一种基于MobileNET的高效脑肿瘤检测方法，通过减少计算资源和时间需求，实现了98.5%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 传统脑肿瘤检测方法（如活检、MRI和CT扫描）成本高且依赖专业医疗知识，而经典机器学习模型存在计算需求大、数据量大和训练时间长的问题。本研究旨在开发一种高效且准确的替代方案。

Method: 使用MobileNET模型结合图像处理技术，构建了一个计算资源需求低、运行时间短的脑肿瘤检测模型。

Result: 提出的方法在脑肿瘤检测中达到了98.5%的平均准确率。

Conclusion: MobileNET模型在脑肿瘤检测中表现出高效性和高准确性，为医疗影像分析提供了一种可行的解决方案。

Abstract: Brain plays a crucial role in regulating body functions and cognitive
processes, with brain tumors posing significant risks to human health. Precise
and prompt detection is a key factor in proper treatment and better patient
outcomes. Traditional methods for detecting brain tumors, that include
biopsies, MRI, and CT scans often face challenges due to their high costs and
the need for specialized medical expertise. Recent developments in machine
learning (ML) and deep learning (DL) has exhibited strong capabilities in
automating the identification and categorization of brain tumors from medical
images, especially MRI scans. However, these classical ML models have
limitations, such as high computational demands, the need for large datasets,
and long training times, which hinder their accessibility and efficiency. Our
research uses MobileNET model for efficient detection of these tumors. The
novelty of this project lies in building an accurate tumor detection model
which use less computing re-sources and runs in less time followed by efficient
decision making through the use of image processing technique for accurate
results. The suggested method attained an average accuracy of 98.5%.

</details>


### [327] [PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View](https://arxiv.org/abs/2506.23897)
*Longliang Liu,Miaojie Feng,Junda Cheng,Jijun Xiang,Xuan Zhu,Xin Yang*

Main category: cs.CV

Relevance: 20.0

TL;DR: 提出PriOr-Flow，一种双分支框架，通过正交视图减少球面投影失真，提升全景光流估计性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于视角的光流方法在全景图像中因球面投影失真（如ERP）性能下降，尤其在极地区域。

Method: 采用双分支框架，引入DCCL操作符联合检索原始和正交成本体积信息，并通过ODDC模块迭代优化运动特征。

Result: 在公开全景光流数据集上达到最先进性能，兼容多种迭代光流方法。

Conclusion: PriOr-Flow有效减少极地区域失真，为宽视场运动估计设新基准。

Abstract: Panoramic optical flow enables a comprehensive understanding of temporal
dynamics across wide fields of view. However, severe distortions caused by
sphere-to-plane projections, such as the equirectangular projection (ERP),
significantly degrade the performance of conventional perspective-based optical
flow methods, especially in polar regions. To address this challenge, we
propose PriOr-Flow, a novel dual-branch framework that leverages the
low-distortion nature of the orthogonal view to enhance optical flow estimation
in these regions. Specifically, we introduce the Dual-Cost Collaborative Lookup
(DCCL) operator, which jointly retrieves correlation information from both the
primitive and orthogonal cost volumes, effectively mitigating distortion noise
during cost volume construction. Furthermore, our Ortho-Driven Distortion
Compensation (ODDC) module iteratively refines motion features from both
branches, further suppressing polar distortions. Extensive experiments
demonstrate that PriOr-Flow is compatible with various perspective-based
iterative optical flow methods and consistently achieves state-of-the-art
performance on publicly available panoramic optical flow datasets, setting a
new benchmark for wide-field motion estimation. The code is publicly available
at: https://github.com/longliangLiu/PriOr-Flow.

</details>


### [328] [ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes](https://arxiv.org/abs/2506.21629)
*Chenhao Zhang,Yezhi Shen,Fengqing Zhu*

Main category: cs.GR

Relevance: 20.0

TL;DR: 论文提出了一种结合ICP与优化细化方法，用于在户外场景中实现准确的相机姿态估计，并引入体素化场景稠密化方法以指导大规模场景重建。


<details>
  <summary>Details</summary>
Motivation: 解决神经渲染方法（如NeRFs和3DGS）在户外场景中依赖预处理相机姿态和3D结构先验的挑战。

Method: 结合迭代最近点（ICP）与优化细化方法进行相机姿态估计，并采用体素化场景稠密化方法指导重建。

Result: 实验表明，ICP-3DGS在相机姿态估计和新视角合成方面优于现有方法。

Conclusion: 该方法在室内外场景中均表现出色，代码已开源。

Abstract: In recent years, neural rendering methods such as NeRFs and 3D Gaussian
Splatting (3DGS) have made significant progress in scene reconstruction and
novel view synthesis. However, they heavily rely on preprocessed camera poses
and 3D structural priors from structure-from-motion (SfM), which are
challenging to obtain in outdoor scenarios. To address this challenge, we
propose to incorporate Iterative Closest Point (ICP) with optimization-based
refinement to achieve accurate camera pose estimation under large camera
movements. Additionally, we introduce a voxel-based scene densification
approach to guide the reconstruction in large-scale scenes. Experiments
demonstrate that our approach ICP-3DGS outperforms existing methods in both
camera pose estimation and novel view synthesis across indoor and outdoor
scenes of various scales. Source code is available at
https://github.com/Chenhao-Z/ICP-3DGS.

</details>


### [329] [SegmentAnyMuscle: A universal muscle segmentation model across different locations in MRI](https://arxiv.org/abs/2506.22467)
*Roy Colglazier,Jisoo Lee,Haoyu Dong,Hanxue Gu,Yaqian Chen,Joseph Cao,Zafer Yildiz,Zhonghao Liu,Nicholas Konz,Jichen Yang,Jikai Zhang,Yuwen Chen,Lin Li,Adrian Camarena,Maciej A. Mazurowski*

Main category: eess.SP

Relevance: 20.0

TL;DR: 开发了一种用于MRI肌肉分割的公开深度学习模型，适用于多种解剖位置和成像序列，表现出较高的准确性。


<details>
  <summary>Details</summary>
Motivation: 肌肉数量和质量的精确测量对健康评估至关重要，但现有方法存在挑战，因此需要开发一种自动化、可公开获取的模型。

Method: 使用362例MRI数据（160名患者）开发深度学习模型，并在不同序列和异常情况下测试其性能。

Result: 模型在常见序列上的DSC为88.45%，在罕见序列和异常情况下的DSC为86.21%。

Conclusion: 该模型实现了跨场景的自动化肌肉分割，为肌肉与健康关系的研究提供了工具。

Abstract: The quantity and quality of muscles are increasingly recognized as important
predictors of health outcomes. While MRI offers a valuable modality for such
assessments, obtaining precise quantitative measurements of musculature remains
challenging. This study aimed to develop a publicly available model for muscle
segmentation in MRIs and demonstrate its applicability across various
anatomical locations and imaging sequences. A total of 362 MRIs from 160
patients at a single tertiary center (Duke University Health System, 2016-2020)
were included, with 316 MRIs from 114 patients used for model development. The
model was tested on two separate sets: one with 28 MRIs representing common
sequence types, achieving an average Dice Similarity Coefficient (DSC) of
88.45%, and another with 18 MRIs featuring less frequent sequences and
abnormalities such as muscular atrophy, hardware, and significant noise,
achieving 86.21% DSC. These results demonstrate the feasibility of a fully
automated deep learning algorithm for segmenting muscles on MRI across diverse
settings. The public release of this model enables consistent, reproducible
research into the relationship between musculature and health.

</details>


### [330] [ICME 2025 Generalizable HDR and SDR Video Quality Measurement Grand Challenge](https://arxiv.org/abs/2506.22790)
*Yixu Chen,Bowen Chen,Hai Wei,Alan C. Bovik,Baojun Li,Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai,Dounia Hammou,Fei Yin,Rafal Mantiuk,Amritha Premkumar,Prajit T Rajendran,Vignesh V Menon*

Main category: eess.IV

Relevance: 20.0

TL;DR: 论文报告了ICME 2025关于HDR和SDR视频质量测量的挑战赛，旨在推动通用视频质量评估方法的发展。


<details>
  <summary>Details</summary>
Motivation: 随着HDR和SDR视频技术的发展，现有视频质量评估模型在不同动态范围和失真类型下的表现不一致，亟需通用性强的评估方法。

Method: 挑战赛设置了Full Reference (FR)和No Reference (NR)两个赛道，共有五支团队提交了七种模型进行评测。

Result: 四种方法超越了VMAF基线，其中表现最佳的模型达到了最先进的性能，为通用视频质量评估设定了新标准。

Conclusion: 挑战赛成功推动了通用视频质量评估方法的发展，并展示了当前技术的潜力。

Abstract: This paper reports IEEE International Conference on Multimedia \& Expo (ICME)
2025 Grand Challenge on Generalizable HDR and SDR Video Quality Measurement.
With the rapid development of video technology, especially High Dynamic Range
(HDR) and Standard Dynamic Range (SDR) contents, the need for robust and
generalizable Video Quality Assessment (VQA) methods has become increasingly
demanded. Existing VQA models often struggle to deliver consistent performance
across varying dynamic ranges, distortion types, and diverse content. This
challenge was established to benchmark and promote VQA approaches capable of
jointly handling HDR and SDR content. In the final evaluation phase, five teams
submitted seven models along with technical reports to the Full Reference (FR)
and No Reference (NR) tracks. Among them, four methods outperformed VMAF
baseline, while the top-performing model achieved state-of-the-art performance,
setting a new benchmark for generalizable video quality assessment.

</details>


### [331] [What Makes a Dribble Successful? Insights From 3D Pose Tracking Data](https://arxiv.org/abs/2506.22503)
*Michiel Schepers,Pieter Robberechts,Jan Van Haaren,Jesse Davis*

Main category: cs.CV

Relevance: 10.0

TL;DR: 该研究利用三维姿态跟踪数据改进足球中带球技能的分析，发现平衡和方向对齐等姿态特征对预测带球成功有显著帮助。


<details>
  <summary>Details</summary>
Motivation: 传统2D位置数据无法全面捕捉带球技能中的平衡、方向和球控制等关键因素，限制了分析的深度。

Method: 从2022/23赛季欧冠联赛的1,736次带球中提取基于姿态的新特征，并评估其对带球成功的影响。

Result: 姿态特征（如攻击者的平衡和攻防双方的方向对齐）显著提高了模型性能。

Conclusion: 三维姿态数据为足球带球技能分析提供了更深入的见解，补充了传统2D数据的不足。

Abstract: Data analysis plays an increasingly important role in soccer, offering new
ways to evaluate individual and team performance. One specific application is
the evaluation of dribbles: one-on-one situations where an attacker attempts to
bypass a defender with the ball. While previous research has primarily relied
on 2D positional tracking data, this fails to capture aspects like balance,
orientation, and ball control, limiting the depth of current insights. This
study explores how pose tracking data (capturing players' posture and movement
in three dimensions) can improve our understanding of dribbling skills. We
extract novel pose-based features from 1,736 dribbles in the 2022/23 Champions
League season and evaluate their impact on dribble success. Our results
indicate that features capturing the attacker's balance and the alignment of
the orientation between the attacker and defender are informative for
predicting dribble success. Incorporating these pose-based features on top of
features derived from traditional 2D positional data leads to a measurable
improvement in model performance.

</details>


### [332] [Lightning the Night with Generative Artificial Intelligence](https://arxiv.org/abs/2506.22511)
*Tingting Zhou,Feng Zhang,Haoyang Fu,Baoxiang Pan,Renhe Zhang,Feng Lu,Zhixin Yang*

Main category: cs.CV

Relevance: 10.0

TL;DR: 该研究利用生成扩散模型（RefDiff）从热红外数据中生成夜间可见光反射率，填补了夜间气象观测的空白。


<details>
  <summary>Details</summary>
Motivation: 解决夜间无法使用可见光反射率数据进行全天候气象观测的问题。

Method: 基于FY4B卫星的多波段热红外亮度温度数据，开发了RefDiff模型，通过集成平均和不确定性估计提高精度。

Result: RefDiff的SSIM指数达0.90，在复杂云结构和厚云区域表现显著优于经典模型。

Conclusion: 该研究显著提升了夜间可见光反射率检索能力，扩展了夜间可见光数据的应用潜力。

Abstract: The visible light reflectance data from geostationary satellites is crucial
for meteorological observations and plays an important role in weather
monitoring and forecasting. However, due to the lack of visible light at night,
it is impossible to conduct continuous all-day weather observations using
visible light reflectance data. This study pioneers the use of generative
diffusion models to address this limitation. Based on the multi-band thermal
infrared brightness temperature data from the Advanced Geostationary Radiation
Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we
developed a high-precision visible light reflectance retrieval model, called
Reflectance Diffusion (RefDiff), which enables 0.47~\mu\mathrm{m},
0.65~\mu\mathrm{m}, and 0.825~\mu\mathrm{m} bands visible light reflectance
retrieval at night. Compared to the classical models, RefDiff not only
significantly improves accuracy through ensemble averaging but also provides
uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90,
with particularly significant improvements in areas with complex cloud
structures and thick clouds. The model's nighttime retrieval capability was
validated using VIIRS nighttime product, demonstrating comparable performance
to its daytime counterpart. In summary, this research has made substantial
progress in the ability to retrieve visible light reflectance at night, with
the potential to expand the application of nighttime visible light data.

</details>


### [333] [Container damage detection using advanced computer vision model Yolov12 vs Yolov11 vs RF-DETR A comparative analysis](https://arxiv.org/abs/2506.22517)
*Subhadip Kumar*

Main category: cs.CV

Relevance: 10.0

TL;DR: 论文比较了三种计算机视觉模型（Yolov11、Yolov12、RF-DETR）在集装箱损伤检测中的性能，发现RF-DETR在罕见损伤检测中表现更优。


<details>
  <summary>Details</summary>
Motivation: 集装箱损伤检测对延长使用寿命和保障安全至关重要，但现有方法在罕见损伤检测上表现不足。

Method: 使用278张标注图像训练和测试三种模型（Yolov11、Yolov12、RF-DETR），比较mAP和精度。

Result: Yolov11和12的mAP@50为81.9%，优于RF-DETR的77.7%，但RF-DETR在罕见损伤检测中表现更优。

Conclusion: RF-DETR在罕见损伤检测中更具优势，适合实际应用。

Abstract: Containers are an integral part of the logistics industry and act as a
barrier for cargo. A typical service life for a container is more than 20
years. However, overtime containers suffer various types of damage due to the
mechanical as well as natural factors. A damaged container is a safety hazard
for the employees handling it and a liability for the logistic company.
Therefore, a timely inspection and detection of the damaged container is a key
for prolonging service life as well as avoiding safety hazards. In this paper,
we will compare the performance of the damage detection by three
state-of-the-art advanced computer vision models Yolov12, Yolov11 and RF-DETR.
We will use a dataset of 278 annotated images to train, validate and test the
model. We will compare the mAP and precision of the model. The objective of
this paper is to identify the model that is best suited for container damage
detection. The result is mixed. mAP@50 score of Yolov11 and 12 was 81.9%
compared to RF-DETR, which was 77.7%. However, while testing the model for
not-so-common damaged containers, the RF-DETR model outperformed the others
overall, exhibiting superiority to accurately detecting both damaged containers
as well as damage occurrences with high confidence.

</details>


### [334] [Deterministic Object Pose Confidence Region Estimation](https://arxiv.org/abs/2506.22720)
*Jinghao Wang,Zhang Li,Zi Wang,Banglei Guan,Yang Shang,Qifeng Yu*

Main category: cs.CV

Relevance: 10.0

TL;DR: 提出了一种确定性方法，用于高效估计6D姿态置信区域，解决了采样方法的速度和区域过大的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于采样的6D姿态置信区域估计方法存在速度慢和置信区域过大的问题，限制了实际应用。

Method: 使用归纳共形预测校准高斯关键点分布，并通过隐函数定理直接传播到6D姿态置信区域。

Result: 在LineMOD Occlusion和SPEED数据集上，方法提高了姿态估计精度，减少了计算时间，置信区域体积显著缩小（旋转减少99.9%，平移减少99.8%）。

Conclusion: 该方法提供了一种高效且紧凑的6D姿态置信区域估计方案。

Abstract: 6D pose confidence region estimation has emerged as a critical direction,
aiming to perform uncertainty quantification for assessing the reliability of
estimated poses. However, current sampling-based approach suffers from critical
limitations that severely impede their practical deployment: 1) the sampling
speed significantly decreases as the number of samples increases. 2) the
derived confidence regions are often excessively large. To address these
challenges, we propose a deterministic and efficient method for estimating pose
confidence regions. Our approach uses inductive conformal prediction to
calibrate the deterministically regressed Gaussian keypoint distributions into
2D keypoint confidence regions. We then leverage the implicit function theorem
to propagate these keypoint confidence regions directly into 6D pose confidence
regions. This method avoids the inefficiency and inflated region sizes
associated with sampling and ensembling. It provides compact confidence regions
that cover the ground-truth poses with a user-defined confidence level.
Experimental results on the LineMOD Occlusion and SPEED datasets show that our
method achieves higher pose estimation accuracy with reduced computational
time. For the same coverage rate, our method yields significantly smaller
confidence region volumes, reducing them by up to 99.9\% for rotations and
99.8\% for translations. The code will be available soon.

</details>


### [335] [Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds](https://arxiv.org/abs/2506.22749)
*Yun Zhang,Feifan Chen,Na Li,Zhiwei Guo,Xu Wang,Fen Miao,Sam Kwong*

Main category: cs.CV

Relevance: 10.0

TL;DR: 提出了一种联合几何和属性上采样的深度学习方法（JGAU），用于生成高质量彩色点云，并发布了一个大规模数据集SYSU-PCUD。


<details>
  <summary>Details</summary>
Motivation: 解决大规模彩色点云生成中几何和属性上采样的质量问题。

Method: 提出JGAU框架，包含几何上采样网络和属性上采样网络，利用辅助几何建模属性相关性，并通过两种粗属性上采样方法和属性增强模块优化结果。

Result: 在4倍、8倍、12倍和16倍上采样率下，PSNR分别达到33.90、32.10、31.10和30.39分贝，优于现有方法。

Conclusion: JGAU方法显著提升了彩色点云上采样的质量。

Abstract: Colored point cloud, which includes geometry and attribute components, is a
mainstream representation enabling realistic and immersive 3D applications. To
generate large-scale and denser colored point clouds, we propose a deep
learning-based Joint Geometry and Attribute Up-sampling (JGAU) method that
learns to model both geometry and attribute patterns while leveraging spatial
attribute correlations. First, we establish and release a large-scale dataset
for colored point cloud up-sampling called SYSU-PCUD, containing 121
large-scale colored point clouds with diverse geometry and attribute
complexities across six categories and four sampling rates. Second, to improve
the quality of up-sampled point clouds, we propose a deep learning-based JGAU
framework that jointly up-samples geometry and attributes. It consists of a
geometry up-sampling network and an attribute up-sampling network, where the
latter leverages the up-sampled auxiliary geometry to model neighborhood
correlations of the attributes. Third, we propose two coarse attribute
up-sampling methods, Geometric Distance Weighted Attribute Interpolation
(GDWAI) and Deep Learning-based Attribute Interpolation (DLAI), to generate
coarse up-sampled attributes for each point. Then, an attribute enhancement
module is introduced to refine these up-sampled attributes and produce
high-quality point clouds by further exploiting intrinsic attribute and
geometry patterns. Extensive experiments show that the Peak Signal-to-Noise
Ratio (PSNR) achieved by the proposed JGAU method is 33.90 decibels, 32.10
decibels, 31.10 decibels, and 30.39 decibels for up-sampling rates of 4 times,
8 times, 12 times, and 16 times, respectively. Compared to state-of-the-art
methods, JGAU achieves average PSNR gains of 2.32 decibels, 2.47 decibels, 2.28
decibels, and 2.11 decibels at these four up-sampling rates, demonstrating
significant improvement.

</details>


### [336] [MagShield: Towards Better Robustness in Sparse Inertial Motion Capture Under Magnetic Disturbances](https://arxiv.org/abs/2506.22907)
*Yunzhe Shao,Xinyu Yi,Lu Yin,Shihui Guo,Junhai Yong,Feng Xu*

Main category: cs.CV

Relevance: 10.0

TL;DR: MagShield是一种新方法，用于解决稀疏惯性运动捕捉系统中的磁干扰问题，通过检测并校正磁干扰来提高运动捕捉的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有惯性测量单元（IMU）系统在磁干扰环境下容易产生方向估计误差，限制了其实际应用。

Method: MagShield采用“检测-校正”策略，通过多IMU联合分析检测磁干扰，并利用人体运动先验校正方向误差。

Result: 实验表明，MagShield显著提高了磁干扰下的运动捕捉准确性，并具有良好的兼容性。

Conclusion: MagShield是一种有效的解决方案，可提升稀疏惯性运动捕捉系统在磁干扰环境中的性能。

Abstract: This paper proposes a novel method called MagShield, designed to address the
issue of magnetic interference in sparse inertial motion capture (MoCap)
systems. Existing Inertial Measurement Unit (IMU) systems are prone to
orientation estimation errors in magnetically disturbed environments, limiting
their practical application in real-world scenarios. To address this problem,
MagShield employs a "detect-then-correct" strategy, first detecting magnetic
disturbances through multi-IMU joint analysis, and then correcting orientation
errors using human motion priors. MagShield can be integrated with most
existing sparse inertial MoCap systems, improving their performance in
magnetically disturbed environments. Experimental results demonstrate that
MagShield significantly enhances the accuracy of motion capture under magnetic
interference and exhibits good compatibility across different sparse inertial
MoCap systems.

</details>


### [337] [Unsupervised 3D Braided Hair Reconstruction from a Single-View Image](https://arxiv.org/abs/2506.23072)
*Jing Gao*

Main category: cs.CV

Relevance: 10.0

TL;DR: 提出了一种无监督的3D编织发型重建方法，利用合成编织模型从单视图RGB图像高效重建复杂编织结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对松散发型，难以捕捉编织发型的精细几何结构，因此需要一种新方法来解决这一挑战。

Method: 基于编织理论的合成编织模型，设计了一种无监督的3D重建流程，从单视图图像中捕捉编织发型的复杂交织结构。

Result: 实验表明，该方法在准确性、真实性和效率上优于现有技术，支持数字人类中表达性发型建模。

Conclusion: 该方法为3D编织发型重建提供了一种高效且准确的解决方案。

Abstract: Reconstructing 3D braided hairstyles from single-view images remains a
challenging task due to the intricate interwoven structure and complex
topologies of braids. Existing strand-based hair reconstruction methods
typically focus on loose hairstyles and often struggle to capture the
fine-grained geometry of braided hair. In this paper, we propose a novel
unsupervised pipeline for efficiently reconstructing 3D braided hair from
single-view RGB images. Leveraging a synthetic braid model inspired by braid
theory, our approach effectively captures the complex intertwined structures of
braids. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches, providing superior accuracy, realism, and
efficiency in reconstructing 3D braided hairstyles, supporting expressive
hairstyle modeling in digital humans.

</details>


### [338] [MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis](https://arxiv.org/abs/2506.23648)
*Zhe Liu,Yuhao Huang,Lian Liu,Chengrui Zhang,Haotian Lin,Tong Han,Zhiyuan Zhu,Yanlin Chen,Yuerui Chen,Dong Ni,Zhongshan Gou,Xin Yang*

Main category: cs.CV

Relevance: 10.0

TL;DR: 论文提出了一种自动化的二尖瓣反流（MR）诊断模型MReg，基于四腔心彩色多普勒超声心动图视频（A4C-CDV），通过回归任务、特征选择与放大机制以及特征总结模块提升诊断准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有智能MR诊断方法常与临床工作流不匹配，准确性及可解释性不足，因此需要开发更符合临床实际的自动化诊断模型。

Method: 1. 将MR诊断建模为回归任务；2. 设计特征选择与放大机制模拟超声医师诊断逻辑；3. 引入基于Mixture-of-Experts的特征总结模块。

Result: 在1868例A4C-CDV数据集上，MReg在MR诊断中表现优于其他弱监督视频异常检测和监督分类方法。

Conclusion: MReg通过结合临床实际和先进特征提取策略，显著提升了MR诊断的准确性和可解释性。

Abstract: Color Doppler echocardiography is a crucial tool for diagnosing mitral
regurgitation (MR). Recent studies have explored intelligent methods for MR
diagnosis to minimize user dependence and improve accuracy. However, these
approaches often fail to align with clinical workflow and may lead to
suboptimal accuracy and interpretability. In this study, we introduce an
automated MR diagnosis model (MReg) developed on the 4-chamber cardiac color
Doppler echocardiography video (A4C-CDV). It follows comprehensive feature
mining strategies to detect MR and assess its severity, considering clinical
realities. Our contribution is threefold. First, we formulate the MR diagnosis
as a regression task to capture the continuity and ordinal relationships
between categories. Second, we design a feature selection and amplification
mechanism to imitate the sonographer's diagnostic logic for accurate MR
grading. Third, inspired by the Mixture-of-Experts concept, we introduce a
feature summary module to extract the category-level features, enhancing the
representational capacity for more accurate grading. We trained and evaluated
our proposed MReg on a large in-house A4C-CDV dataset comprising 1868 cases
with three graded regurgitation labels. Compared to other weakly supervised
video anomaly detection and supervised classification methods, MReg
demonstrated superior performance in MR diagnosis. Our code is available at:
https://github.com/cskdstz/MReg.

</details>


### [339] [Towards Markerless Intraoperative Tracking of Deformable Spine Tissue](https://arxiv.org/abs/2506.23657)
*Connor Daly,Elettra Marconi,Marco Riva,Jinendra Ekanayake,Daniel S. Elson,Ferdinando Rodriguez y Baena*

Main category: cs.CV

Relevance: 10.0

TL;DR: 论文介绍了首个用于脊柱手术的临床RGB-D数据集，并开发了SpineAlign系统，用于捕捉术前和术中脊柱状态的变形。还提出了一个术中分割网络和CorrespondNet框架。


<details>
  <summary>Details</summary>
Motivation: 减少手术时间和复杂性，通过无标记跟踪替代骨安装设备，推动临床应用的可行性。

Method: 使用RGB-D成像技术，开发SpineAlign系统，训练术中分割网络，并提出多任务框架CorrespondNet。

Result: 成功构建了首个临床RGB-D数据集，并验证了SpineAlign和CorrespondNet的有效性。

Conclusion: 该方法在脊柱手术中展示了无标记跟踪的潜力，为未来临床应用奠定了基础。

Abstract: Consumer-grade RGB-D imaging for intraoperative orthopedic tissue tracking is
a promising method with high translational potential. Unlike bone-mounted
tracking devices, markerless tracking can reduce operating time and complexity.
However, its use has been limited to cadaveric studies. This paper introduces
the first real-world clinical RGB-D dataset for spine surgery and develops
SpineAlign, a system for capturing deformation between preoperative and
intraoperative spine states. We also present an intraoperative segmentation
network trained on this data and introduce CorrespondNet, a multi-task
framework for predicting key regions for registration in both intraoperative
and preoperative scenes.

</details>


### [340] [Wireless Home Automation Using Social Networking Websites](https://arxiv.org/abs/2506.22482)
*Divya Alok Gupta,Dwith Chenna,B. Aditya Vighnesh Ramakanth*

Main category: cs.NI

Relevance: 10.0

TL;DR: 论文提出了一种基于社交网络认证的无线家庭自动化系统（WHAS），通过追踪用户在社交网络上的活动来控制家用电器。


<details>
  <summary>Details</summary>
Motivation: 解决家庭自动化系统中的安全性、多设备控制和用户友好性问题。

Method: 利用Twitter等社交网络的安全认证系统，追踪用户活动并控制家用电器。

Result: 展示了WHAS的应用，并比较了其与传统家庭自动化系统的优势。

Conclusion: 提出的系统在安全性和用户友好性方面优于传统方法。

Abstract: With the advent of Internet of Things, Wireless Home Automation Systems WHAS
are gradually gaining popularity. These systems are faced with multiple
challenges such as security; controlling a variety of home appliances with a
single interface and user friendliness. In this paper we propose a system that
uses secure authentication systems of social networking websites such as
Twitter, tracks the end-users activities on the social network and then control
his or her domestic appliances. At the end, we highlight the applications of
the proposed WHAS and compare the advantages of our proposed system over
traditional home automation systems.

</details>


### [341] [BPD-Neo: An MRI Dataset for Lung-Trachea Segmentation with Clinical Data for Neonatal Bronchopulmonary Dysplasia](https://arxiv.org/abs/2506.23305)
*Rachit Saluja,Arzu Kovanlikaya,Candace Chien,Lauren Kathryn Blatt,Jeffrey M. Perlman,Stefan Worgall,Mert R. Sabuncu,Jonathan P. Dyke*

Main category: eess.IV

Relevance: 10.0

TL;DR: 论文提出了一个基于高分辨率3D MRI数据的语义分割算法，用于辅助诊断早产儿支气管肺发育不良（BPD），并提供了包含40名新生儿的数据集和基线模型。


<details>
  <summary>Details</summary>
Motivation: BPD是早产儿常见并发症，传统X射线诊断存在辐射和镇静问题，MRI提供了一种非侵入性替代方案。

Method: 利用3D MRI数据开发图像处理和语义分割算法，提供StarVIBE序列的影像数据及临床数据。

Result: 提供了40名新生儿的MRI扫描和语义分割数据，以及验证过的基线模型。

Conclusion: 该数据集和模型支持进一步研究新生儿肺部成像，为BPD诊断提供新工具。

Abstract: Bronchopulmonary dysplasia (BPD) is a common complication among preterm
neonates, with portable X-ray imaging serving as the standard diagnostic
modality in neonatal intensive care units (NICUs). However, lung magnetic
resonance imaging (MRI) offers a non-invasive alternative that avoids sedation
and radiation while providing detailed insights into the underlying mechanisms
of BPD. Leveraging high-resolution 3D MRI data, advanced image processing and
semantic segmentation algorithms can be developed to assist clinicians in
identifying the etiology of BPD. In this dataset, we present MRI scans paired
with corresponding semantic segmentations of the lungs and trachea for 40
neonates, the majority of whom are diagnosed with BPD. The imaging data consist
of free-breathing 3D stack-of-stars radial gradient echo acquisitions, known as
the StarVIBE series. Additionally, we provide comprehensive clinical data and
baseline segmentation models, validated against clinical assessments, to
support further research and development in neonatal lung imaging.

</details>


### [342] [GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering](https://arxiv.org/abs/2506.23957)
*Zinuo You,Stamatios Georgoulis,Anpei Chen,Siyu Tang,Dengxin Dai*

Main category: cs.GR

Relevance: 10.0

TL;DR: 提出了一种基于3D的视频稳定方法GaVS，通过局部重建和渲染范式解决现有方法的几何失真、过度裁剪等问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频稳定方法存在几何失真、过度裁剪和泛化能力差等问题，影响用户体验。

Method: 采用3D相机姿态，通过高斯散射基元预测和测试时微调，结合多视角动态感知光度监督和跨帧正则化，实现时间一致的局部重建和渲染。

Result: 在多样化的相机运动和场景动态数据集上，GaVS在传统任务指标和几何一致性上优于现有2D和2.5D方法。

Conclusion: GaVS通过3D基础方法显著提升了视频稳定效果，用户研究验证了其优越性。

Abstract: Video stabilization is pivotal for video processing, as it removes unwanted
shakiness while preserving the original user motion intent. Existing
approaches, depending on the domain they operate, suffer from several issues
(e.g. geometric distortions, excessive cropping, poor generalization) that
degrade the user experience. To address these issues, we introduce
\textbf{GaVS}, a novel 3D-grounded approach that reformulates video
stabilization as a temporally-consistent `local reconstruction and rendering'
paradigm. Given 3D camera poses, we augment a reconstruction model to predict
Gaussian Splatting primitives, and finetune it at test-time, with multi-view
dynamics-aware photometric supervision and cross-frame regularization, to
produce temporally-consistent local reconstructions. The model are then used to
render each stabilized frame. We utilize a scene extrapolation module to avoid
frame cropping. Our method is evaluated on a repurposed dataset, instilled with
3D-grounded information, covering samples with diverse camera motions and scene
dynamics. Quantitatively, our method is competitive with or superior to
state-of-the-art 2D and 2.5D approaches in terms of conventional task metrics
and new geometry consistency. Qualitatively, our method produces noticeably
better results compared to alternatives, validated by the user study.

</details>


### [343] [ShapeKit](https://arxiv.org/abs/2506.24003)
*Junqi Liu,Dongli He,Wenxuan Li,Ningyu Wang,Alan L. Yuille,Zongwei Zhou*

Main category: eess.IV

Relevance: 10.0

TL;DR: 提出了一种无需重新训练或微调模型即可提升医学分割形状准确性的工具包ShapeKit，性能提升超过8%。


<details>
  <summary>Details</summary>
Motivation: 观察到形状优化工具在医学分割中的潜力，而传统模型架构修改效果有限（提升<3%）。

Method: 开发了ShapeKit工具包，专注于形状优化，易于集成。

Result: ShapeKit显著提升分割性能（>8%），优于模型架构修改。

Conclusion: 强调形状优化工具在医学分割中的重要性，呼吁社区关注。

Abstract: In this paper, we present a practical approach to improve anatomical shape
accuracy in whole-body medical segmentation. Our analysis shows that a
shape-focused toolkit can enhance segmentation performance by over 8%, without
the need for model re-training or fine-tuning. In comparison, modifications to
model architecture typically lead to marginal gains of less than 3%. Motivated
by this observation, we introduce ShapeKit, a flexible and easy-to-integrate
toolkit designed to refine anatomical shapes. This work highlights the
underappreciated value of shape-based tools and calls attention to their
potential impact within the medical segmentation community.

</details>


### [344] [C3VDv2 -- Colonoscopy 3D video dataset with enhanced realism](https://arxiv.org/abs/2506.24074)
*Mayank V. Golhar,Lucas Sebastian Galeano Fretes,Loren Ayers,Venkata S. Akshintala,Taylor L. Bobrow,Nicholas J. Durr*

Main category: eess.IV

Relevance: 10.0

TL;DR: C3VDv2是一个高清晰度的3D结肠镜视频数据集，旨在促进3D结肠重建算法的定量评估。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏用于训练和验证的3D结肠镜数据集，计算机视觉技术在结肠镜诊断中的应用受到限制。

Method: 通过60个高保真硅胶结肠模型段捕获192个视频序列，并提供多种真实数据（如深度、表面法线、光学流等）。

Result: 数据集包含169个结肠镜视频的真实数据，模拟了多种挑战性场景（如粪便碎片、血液等）。

Conclusion: C3VDv2的增强真实性将有助于更稳健和代表性的3D重建算法的开发和评估。

Abstract: Computer vision techniques have the potential to improve the diagnostic
performance of colonoscopy, but the lack of 3D colonoscopy datasets for
training and validation hinders their development. This paper introduces
C3VDv2, the second version (v2) of the high-definition Colonoscopy 3D Video
Dataset, featuring enhanced realism designed to facilitate the quantitative
evaluation of 3D colon reconstruction algorithms. 192 video sequences were
captured by imaging 60 unique, high-fidelity silicone colon phantom segments.
Ground truth depth, surface normals, optical flow, occlusion,
six-degree-of-freedom pose, coverage maps, and 3D models are provided for 169
colonoscopy videos. Eight simulated screening colonoscopy videos acquired by a
gastroenterologist are provided with ground truth poses. The dataset includes
15 videos featuring colon deformations for qualitative assessment. C3VDv2
emulates diverse and challenging scenarios for 3D reconstruction algorithms,
including fecal debris, mucous pools, blood, debris obscuring the colonoscope
lens, en-face views, and fast camera motion. The enhanced realism of C3VDv2
will allow for more robust and representative development and evaluation of 3D
reconstruction algorithms.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [345] [SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2506.24119)
*Bo Liu,Leon Guertler,Simon Yu,Zichen Liu,Penghui Qi,Daniel Balcells,Mickel Liu,Cheston Tan,Weiyan Shi,Min Lin,Wee Sun Lee,Natasha Jaques*

Main category: cs.AI

Relevance: 90.0

TL;DR: SPIRAL是一个自玩框架，通过零和游戏训练语言模型，无需人工监督，生成无限课程，提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 减少对人类监督和领域特定奖励工程的依赖，通过自玩提升模型的推理能力。

Method: 引入SPIRAL框架，采用在线多智能体强化学习系统和角色条件优势估计（RAE）稳定训练。

Result: 在Kuhn Poker上训练的模型在数学和通用推理上分别提升8.6%和8.4%，多游戏训练进一步优化性能。

Conclusion: 零和游戏能自然发展可迁移的推理能力，为自主推理开发提供新方向。

Abstract: Recent advances in reinforcement learning have shown that language models can
develop sophisticated reasoning through training on tasks with verifiable
rewards, but these approaches depend on human-curated problem-answer pairs and
domain-specific reward engineering. We introduce SPIRAL, a self-play framework
where models learn by playing multi-turn, zero-sum games against continuously
improving versions of themselves, eliminating the need for human supervision.
Through self-play, SPIRAL generates an infinite curriculum of progressively
challenging problems as models must constantly adapt to stronger opponents. To
enable this self-play training at scale, We implement a fully online,
multi-turn, multi-agent reinforcement learning system for LLMs and propose
role-conditioned advantage estimation (RAE) to stabilize multi-agent training.
Using SPIRAL, self-play on zero-sum games produces reasoning capabilities that
transfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%
improvement on math and 8.4% on general reasoning, outperforming SFT on 25,000
expert game trajectories. Analysis reveals that this transfer occurs through
three cognitive patterns: systematic decomposition, expected value calculation,
and case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple
Negotiation) further enhances performance as each game develops distinct
reasoning strengths. Applying SPIRAL to a strong reasoning model
(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These
results demonstrate that zero-sum games naturally develop transferable
reasoning capabilities, highlighting a promising direction for autonomous
reasoning development.

</details>


### [346] [URSA: The Universal Research and Scientific Agent](https://arxiv.org/abs/2506.22653)
*Michael Grosskopf,Russell Bent,Rahul Somasundaram,Isaac Michaud,Arthur Lui,Nathan Debardeleben,Earl Lawrence*

Main category: cs.AI

Relevance: 85.0

TL;DR: URSA是一个科学代理生态系统，旨在通过模块化代理和工具加速研究任务，包括与高级物理模拟代码的耦合。


<details>
  <summary>Details</summary>
Motivation: 利用LLMs的复杂推理和规划能力，解决科学研究中的瓶颈问题，推动科学进步。

Method: 设计了URSA系统，包含模块化代理和工具，可组合解决不同复杂性和影响力的科学问题。

Result: 展示了URSA的架构及其在科学问题中的潜力。

Conclusion: URSA展示了LLMs在科学研究中的革命性潜力。

Abstract: Large language models (LLMs) have moved far beyond their initial form as
simple chatbots, now carrying out complex reasoning, planning, writing, coding,
and research tasks. These skills overlap significantly with those that human
scientists use day-to-day to solve complex problems that drive the cutting edge
of research. Using LLMs in "agentic" AI has the potential to revolutionize
modern science and remove bottlenecks to progress. In this work, we present
URSA, a scientific agent ecosystem for accelerating research tasks. URSA
consists of a set of modular agents and tools, including coupling to advanced
physics simulation codes, that can be combined to address scientific problems
of varied complexity and impact. This work highlights the architecture of URSA,
as well as examples that highlight the potential of the system.

</details>


### [347] [ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models](https://arxiv.org/abs/2506.22865)
*Ziqi Zhong,Xunzhu Tang*

Main category: cs.AI

Relevance: 85.0

TL;DR: ReasonBridge通过分层知识蒸馏框架，将闭源模型的推理能力高效迁移到开源模型，显著缩小性能差距。


<details>
  <summary>Details</summary>
Motivation: 解决闭源与开源模型在复杂推理任务中的性能差距，提升开源模型的推理能力。

Method: 1) 分层蒸馏过程；2) 稀疏推理适配器架构；3) 测试时计算扩展机制。

Result: 开源模型推理能力提升23%，Qwen2.5-14B在MATH500上超越Claude-Sonnet3.5。

Conclusion: ReasonBridge为指令跟随任务提供了一种样本高效的推理增强方法。

Abstract: Recent advancements in Large Language Models (LLMs) have revealed a
significant performance gap between closed-source and open-source models,
particularly in tasks requiring complex reasoning and precise instruction
following. This paper introduces ReasonBridge, a methodology that efficiently
transfers reasoning capabilities from powerful closed-source to open-source
models through a novel hierarchical knowledge distillation framework. We
develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning
traces emphasizing difficulty, diversity, and quality. These traces are
filtered from across multiple domains using a structured multi-criteria
selection algorithm. Our transfer learning approach incorporates: (1) a
hierarchical distillation process capturing both strategic abstraction and
tactical implementation patterns, (2) a sparse reasoning-focused adapter
architecture requiring only 0.3% additional trainable parameters, and (3) a
test-time compute scaling mechanism using guided inference interventions.
Comprehensive evaluations demonstrate that ReasonBridge improves reasoning
capabilities in open-source models by up to 23% on benchmark tasks,
significantly narrowing the gap with closed-source models. Notably, the
enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its
performance on competition-level AIME problems. Our methodology generalizes
effectively across diverse reasoning domains and model architectures,
establishing a sample-efficient approach to reasoning enhancement for
instruction following.

</details>


### [348] [Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning](https://arxiv.org/abs/2506.22919)
*Sanskar Pandey,Ruhaan Chopra,Saad Murtaza Bhat,Ark Abhyudaya*

Main category: cs.AI

Relevance: 85.0

TL;DR: Hecto是一种轻量级MoE架构，通过结合GRU和FFNN专家实现异构计算，提升推理任务的专业化和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型的静态计算路径限制了表示多样性和效率，Hecto旨在通过异构架构解决这一问题。

Method: Hecto结合GRU专家（时序推理）和FFNN专家（静态抽象），采用稀疏Top-1门控机制。

Result: 在多个推理任务中，Hecto性能接近同质基线，同时实现专家专业化（时序vs静态）。大批次下性能更优。

Conclusion: Hecto为条件计算提供新基准，适用于低资源场景下的专业化推理。

Abstract: Mixture-of-Experts (MoE) models enable conditional computation by routing
inputs to specialized experts, but these experts rely on identical inductive
biases, thus limiting representational diversity. This static computation
pathway is inefficient for inputs that require different types of reasoning and
limits specialization and interpretability. We propose Hecto, a lightweight MoE
architecture that leverages architectural heterogeneity by combining a GRU
expert for temporal reasoning and an FFNN expert for static abstraction under a
sparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG
News, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely
trails homogeneous baselines in performance despite receiving isolated input
representations, while achieving clear expert specialization, with each expert
aligning to distinct reasoning types (temporal vs static). At larger batch
sizes, Hecto exhibits improved performance, benefiting from relaxed
computational constraints that allow its heterogeneous architecture to optimize
more effectively. Ablation results isolate architectural diversity as the
source of Hecto's stability and interpretability across diverse reasoning
tasks. Overall, Hecto establishes itself as a new benchmark for conditional
computation, offering a principled framework for specialized reasoning in
low-resource regimes with its model strength derived from principled
specialization.

</details>


### [349] [Improving Rationality in the Reasoning Process of Language Models through Self-playing Game](https://arxiv.org/abs/2506.22920)
*Pinzheng Wang,Juntao Li,Zecheng Tang,Haijia Gui,Min zhang*

Main category: cs.AI

Relevance: 85.0

TL;DR: 论文提出了一种通过自玩（self-play）提升大语言模型（LLMs）推理能力的无监督方法，设计了Critic-Discernment Game（CDG），实验表明该方法能显著提升模型对推理过程的理解。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在推理任务中缺乏对自身推理过程的真正理解，希望通过无监督方法提升模型的理性推理能力。

Method: 设计了Critic-Discernment Game（CDG），通过证明者与批评者的交互，提升模型在面对误导或建设性反馈时的表现。

Result: 实验表明，CDG训练能显著提升模型在数学推理、逐步错误检测、自我纠正和长链推理任务中的表现。

Conclusion: CDG是一种有效的无监督方法，可增强模型对推理过程的理解能力。

Abstract: Large language models (LLMs) have demonstrated considerable reasoning
abilities in various tasks such as mathematics and coding. However, recent
studies indicate that even the best models lack true comprehension of their
reasoning processes. In this paper, we explore how self-play can enhance the
rationality of models in the reasoning process without supervision from humans
or superior models. We design a Critic-Discernment Game(CDG) in which a prover
first provides a solution to a given problem and is subsequently challenged by
critiques of its solution. These critiques either aim to assist or mislead the
prover. The objective of the prover is to maintain the correct answer when
faced with misleading comments, while correcting errors in response to
constructive feedback. Our experiments on tasks involving mathematical
reasoning, stepwise error detection, self-correction, and long-chain reasoning
demonstrate that CDG training can significantly improve the ability of
well-aligned LLMs to comprehend their reasoning process.

</details>


### [350] [Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study](https://arxiv.org/abs/2506.23107)
*Bing Song,Jianing Liu,Sisi Jian,Chenyang Wu,Vinayak Dixit*

Main category: cs.AI

Relevance: 85.0

TL;DR: 研究比较了ChatGPT 4o和ChatGPT o1-mini在模拟人类风险决策行为时的表现，发现模型比人类更规避风险，且中文提示下的预测偏差更大。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs应用的扩展，其在复杂决策行为（如风险决策）中的可靠性受到质疑，本研究旨在评估LLMs在此类任务中的表现。

Method: 使用彩票任务和交通偏好调查数据，比较LLMs（ChatGPT 4o和o1-mini）与人类在风险决策中的差异，采用CRRA框架分析风险偏好。

Result: 模型比人类更规避风险，o1-mini更接近人类决策；中文提示下预测偏差更大。

Conclusion: LLMs在模拟人类风险行为方面有潜力，但在语言和文化背景下仍存在局限性。

Abstract: Large language models (LLMs) have made significant strides, extending their
applications to dialogue systems, automated content creation, and
domain-specific advisory tasks. However, as their use grows, concerns have
emerged regarding their reliability in simulating complex decision-making
behavior, such as risky decision-making, where a single choice can lead to
multiple outcomes. This study investigates the ability of LLMs to simulate
risky decision-making scenarios. We compare model-generated decisions with
actual human responses in a series of lottery-based tasks, using transportation
stated preference survey data from participants in Sydney, Dhaka, Hong Kong,
and Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and
ChatGPT o1-mini -- which were tasked with predicting individual choices. Risk
preferences were analyzed using the Constant Relative Risk Aversion (CRRA)
framework. Results show that both models exhibit more risk-averse behavior than
human participants, with o1-mini aligning more closely with observed human
decisions. Further analysis of multilingual data from Nanjing and Hong Kong
indicates that model predictions in Chinese deviate more from actual responses
compared to English, suggesting that prompt language may influence simulation
performance. These findings highlight both the promise and the current
limitations of LLMs in replicating human-like risk behavior, particularly in
linguistic and cultural settings.

</details>


### [351] [Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons](https://arxiv.org/abs/2506.23128)
*Chi Chiu So,Yueyue Sun,Jun-Min Wang,Siu Pang Yung,Anthony Wai Keung Loh,Chun Pong Chau*

Main category: cs.AI

Relevance: 85.0

TL;DR: 评估了三种前沿LLM（DeepSeek-R1、DeepSeek-V3和GPT-4o）在深度关系推理任务中的表现，发现DeepSeek-R1表现最佳，但所有模型在复杂任务中均存在显著困难。


<details>
  <summary>Details</summary>
Motivation: 探究LLM在深度关系推理任务中的能力，揭示其优势和局限性。

Method: 通过家族树和一般图推理的基准任务评估三种LLM的性能，分析推理过程和失败案例。

Result: DeepSeek-R1在多项任务中表现最佳，但所有模型在复杂任务中表现不佳，主要受限于token长度和不完整的输出结构。

Conclusion: LLM在结构化、多步逻辑推理任务中仍有改进空间，未来需关注多模态推理和推理失败的系统性分析。

Abstract: How far are Large Language Models (LLMs) in performing deep relational
reasoning? In this paper, we evaluate and compare the reasoning capabilities of
three cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a
suite of carefully designed benchmark tasks in family tree and general graph
reasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the
highest F1-scores across multiple tasks and problem sizes, demonstrating strong
aptitude in logical deduction and relational inference. However, all evaluated
models, including DeepSeek-R1, struggle significantly as problem complexity
increases, largely due to token length limitations and incomplete output
structures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought
responses uncovers its unique planning and verification strategies, but also
highlights instances of incoherent or incomplete reasoning, calling attention
to the need for deeper scrutiny into LLMs' internal inference dynamics. We
further discuss key directions for future work, including the role of
multimodal reasoning and the systematic examination of reasoning failures. Our
findings provide both empirical insights and theoretical implications for
advancing LLMs' reasoning abilities, particularly in tasks that demand
structured, multi-step logical inference. Our code repository will be publicly
available at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.

</details>


### [352] [Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games](https://arxiv.org/abs/2506.23276)
*David Guzman Piedrahita,Yongjin Yang,Mrinmaya Sachan,Giorgia Ramponi,Bernhard Schölkopf,Zhijing Jin*

Main category: cs.AI

Relevance: 85.0

TL;DR: 研究探讨了多智能体LLM系统中成本高昂的制裁行为，发现不同LLM在合作与自利间的行为模式差异显著。


<details>
  <summary>Details</summary>
Motivation: 理解LLM作为自主智能体的合作与社会机制，以确保其对齐性、鲁棒性和安全部署。

Method: 通过行为经济学的公共物品游戏模拟多智能体互动，观察LLM在重复博弈中的行为模式。

Result: 发现四种行为模式：持续高合作、波动合作、逐渐衰退合作和固定策略。推理能力强的LLM反而合作表现较差。

Conclusion: 当前提升LLM推理能力的策略未必促进合作，为需要持续协作的环境部署提供新视角。

Abstract: As large language models (LLMs) are increasingly deployed as autonomous
agents, understanding their cooperation and social mechanisms is becoming
increasingly important. In particular, how LLMs balance self-interest and
collective well-being is a critical challenge for ensuring alignment,
robustness, and safe deployment. In this paper, we examine the challenge of
costly sanctioning in multi-agent LLM systems, where an agent must decide
whether to invest its own resources to incentivize cooperation or penalize
defection. To study this, we adapt a public goods game with institutional
choice from behavioral economics, allowing us to observe how different LLMs
navigate social dilemmas over repeated interactions. Our analysis reveals four
distinct behavioral patterns among models: some consistently establish and
sustain high levels of cooperation, others fluctuate between engagement and
disengagement, some gradually decline in cooperative behavior over time, and
others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we
find that reasoning LLMs, such as the o1 series, struggle significantly with
cooperation, whereas some traditional LLMs consistently achieve high levels of
cooperation. These findings suggest that the current approach to improving
LLMs, which focuses on enhancing their reasoning capabilities, does not
necessarily lead to cooperation, providing valuable insights for deploying LLM
agents in environments that require sustained collaboration. Our code is
available at https://github.com/davidguzmanp/SanctSim

</details>


### [353] [A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents](https://arxiv.org/abs/2506.23844)
*Hang Su,Jun Luo,Chang Liu,Xiao Yang,Yichi Zhang,Yinpeng Dong,Jun Zhu*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该论文探讨了大型语言模型（LLMs）驱动的自主AI代理的安全风险及其防御策略，提出了一种新的风险感知架构R2A2。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs驱动的自主AI代理能力的提升，新型安全风险（如记忆污染、工具滥用等）涌现，传统安全模型无法应对，亟需系统性解决方案。

Method: 论文首先分析了自主代理的结构基础和关键能力，然后识别了其安全漏洞，并系统回顾了防御策略，最终提出了基于约束马尔可夫决策过程（CMDPs）的R2A2架构。

Result: 论文提出了R2A2架构，通过风险感知世界建模、元策略适应和联合奖励-风险优化，实现了代理决策过程中的主动安全性。

Conclusion: R2A2架构为自主AI代理提供了一种系统化的安全解决方案，适用于动态开放环境中的风险控制。

Abstract: Recent advances in large language models (LLMs) have catalyzed the rise of
autonomous AI agents capable of perceiving, reasoning, and acting in dynamic,
open-ended environments. These large-model agents mark a paradigm shift from
static inference systems to interactive, memory-augmented entities. While these
capabilities significantly expand the functional scope of AI, they also
introduce qualitatively novel security risks - such as memory poisoning, tool
misuse, reward hacking, and emergent misalignment - that extend beyond the
threat models of conventional systems or standalone LLMs. In this survey, we
first examine the structural foundations and key capabilities that underpin
increasing levels of agent autonomy, including long-term memory retention,
modular tool use, recursive planning, and reflective reasoning. We then analyze
the corresponding security vulnerabilities across the agent stack, identifying
failure modes such as deferred decision hazards, irreversible tool chains, and
deceptive behaviors arising from internal state drift or value misalignment.
These risks are traced to architectural fragilities that emerge across
perception, cognition, memory, and action modules. To address these challenges,
we systematically review recent defense strategies deployed at different
autonomy layers, including input sanitization, memory lifecycle control,
constrained decision-making, structured tool invocation, and introspective
reflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a
unified cognitive framework grounded in Constrained Markov Decision Processes
(CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation,
and joint reward-risk optimization to enable principled, proactive safety
across the agent's decision-making loop.

</details>


### [354] [AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models](https://arxiv.org/abs/2506.23949)
*Anthony M. Barrett,Jessica Newman,Brandie Nonnecke,Nada Madkour,Dan Hendrycks,Evan R. Murphy,Krystal Jackson,Deepika Raman*

Main category: cs.AI

Relevance: 85.0

TL;DR: 该文档提供了针对GPAI/基础模型的风险管理实践，旨在帮助开发者识别、分析和减轻风险，适用于大型前沿模型的开发者。


<details>
  <summary>Details</summary>
Motivation: 随着多用途AI模型的普及，其带来的潜在风险需要系统化的管理方法，以确保安全和可靠性。

Method: 文档基于NIST AI风险管理框架和ISO/IEC 23894标准，针对GPAI/基础模型的独特问题提供了具体指导。

Result: 提出了一套针对GPAI/基础模型的风险管理实践，帮助开发者更好地应对潜在风险。

Conclusion: 该文档为GPAI/基础模型开发者提供了实用的风险管理指南，有助于提升模型的可靠性和安全性。

Abstract: Increasingly multi-purpose AI models, such as cutting-edge large language
models or other 'general-purpose AI' (GPAI) models, 'foundation models,'
generative AI models, and 'frontier models' (typically all referred to
hereafter with the umbrella term 'GPAI/foundation models' except where greater
specificity is needed), can provide many beneficial capabilities but also risks
of adverse events with profound consequences. This document provides
risk-management practices or controls for identifying, analyzing, and
mitigating risks of GPAI/foundation models. We intend this document primarily
for developers of large-scale, state-of-the-art GPAI/foundation models; others
that can benefit from this guidance include downstream developers of end-use
applications that build on a GPAI/foundation model. This document facilitates
conformity with or use of leading AI risk management-related standards,
adapting and building on the generic voluntary guidance in the NIST AI Risk
Management Framework and ISO/IEC 23894, with a focus on the unique issues faced
by developers of GPAI/foundation models.

</details>


### [355] [Report on NSF Workshop on Science of Safe AI](https://arxiv.org/abs/2506.22492)
*Rajeev Alur,Greg Durrett,Hadas Kress-Gazit,Corina Păsăreanu,René Vidal*

Main category: cs.CY

Relevance: 85.0

TL;DR: 该论文探讨了AI系统的安全性和可信赖性，提出了一个新的研究议程，重点关注理论基础、方法和工具的开发。


<details>
  <summary>Details</summary>
Motivation: 当前复杂AI模型的推理和内部机制对用户不透明，且缺乏预测的安全性保证，因此需要开发既准确又安全可信的AI系统。

Method: 通过组织研讨会，汇集NSF SLES项目资助的研究人员和更广泛的AI安全研究群体，讨论安全性的不同方面。

Result: 报告提出了一个新的研究议程，旨在为下一代AI系统奠定理论基础、方法和工具。

Conclusion: 开发安全可信的AI系统需要跨学科合作和新的研究议程。

Abstract: Recent advances in machine learning, particularly the emergence of foundation
models, are leading to new opportunities to develop technology-based solutions
to societal problems. However, the reasoning and inner workings of today's
complex AI models are not transparent to the user, and there are no safety
guarantees regarding their predictions. Consequently, to fulfill the promise of
AI, we must address the following scientific challenge: how to develop AI-based
systems that are not only accurate and performant but also safe and
trustworthy?
  The criticality of safe operation is particularly evident for autonomous
systems for control and robotics, and was the catalyst for the Safe Learning
Enabled Systems (SLES) program at NSF. For the broader class of AI
applications, such as users interacting with chatbots and clinicians receiving
treatment recommendations, safety is, while no less important, less
well-defined with context-dependent interpretations. This motivated the
organization of a day-long workshop, held at University of Pennsylvania on
February 26, 2025, to bring together investigators funded by the NSF SLES
program with a broader pool of researchers studying AI safety. This report is
the result of the discussions in the working groups that addressed different
aspects of safety at the workshop. The report articulates a new research agenda
focused on developing theory, methods, and tools that will provide the
foundations of the next generation of AI-enabled systems.

</details>


### [356] [Mitigating Gambling-Like Risk-Taking Behaviors in Large Language Models: A Behavioral Economics Approach to AI Safety](https://arxiv.org/abs/2506.22496)
*Y. Du*

Main category: cs.CY

Relevance: 85.0

TL;DR: 论文提出Risk-Aware Response Generation (RARG)框架，通过风险校准训练和损失规避机制减少LLM中的赌博心理学行为。


<details>
  <summary>Details</summary>
Motivation: LLM表现出类似赌博心理的系统性风险行为（如过度自信、损失追逐和概率误判），需要解决这些行为偏差以提高模型可靠性。

Method: 结合行为经济学和前景理论，提出RARG框架，包括风险校准训练、损失规避机制和不确定性感知决策。

Result: 实验显示，RARG显著减少赌博行为：过度自信偏差降低18.7%，损失追逐倾向减少24.3%，风险校准能力提升。

Conclusion: RARG是首个系统理解和减轻AI系统中赌博心理学行为的框架。

Abstract: Large Language Models (LLMs) exhibit systematic risk-taking behaviors
analogous to those observed in gambling psychology, including overconfidence
bias, loss-chasing tendencies, and probability misjudgment. Drawing from
behavioral economics and prospect theory, we identify and formalize these
"gambling-like" patterns where models sacrifice accuracy for high-reward
outputs, exhibit escalating risk-taking after errors, and systematically
miscalibrate uncertainty. We propose the Risk-Aware Response Generation (RARG)
framework, incorporating insights from gambling research to address these
behavioral biases through risk-calibrated training, loss-aversion mechanisms,
and uncertainty-aware decision making. Our approach introduces novel evaluation
paradigms based on established gambling psychology experiments, including AI
adaptations of the Iowa Gambling Task and probability learning assessments.
Experimental results demonstrate measurable reductions in gambling-like
behaviors: 18.7\% decrease in overconfidence bias, 24.3\% reduction in
loss-chasing tendencies, and improved risk calibration across diverse
scenarios. This work establishes the first systematic framework for
understanding and mitigating gambling psychology patterns in AI systems.

</details>


### [357] [Beyond Code: The Multidimensional Impacts of Large Language Models in Software Development](https://arxiv.org/abs/2506.22704)
*Sardar Fatooreh Bonabi,Sarah Bana,Tingting Nian,Vijay Gurbaxani*

Main category: econ.GN

Relevance: 85.0

TL;DR: 论文研究了大型语言模型（LLMs）对开源软件开发的影响，发现ChatGPT能显著提升开发者的生产力、知识共享和技能获取。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs如何通过代码开发、协作知识转移和技能发展影响开源软件（OSS）领域。

Method: 利用意大利临时禁止ChatGPT的自然实验，采用双重差分法和双向固定效应分析GitHub上88,022名开发者的数据。

Result: ChatGPT使开发者生产力提升6.4%，知识共享增加9.6%，技能获取提高8.4%，效果因经验水平而异。

Conclusion: LLMs能加速新手开发者成长、促进协作学习，对组织长期生产力和敏捷性有重要意义。

Abstract: Large language models (LLMs) are poised to significantly impact software
development, especially in the Open-Source Software (OSS) sector. To understand
this impact, we first outline the mechanisms through which LLMs may influence
OSS through code development, collaborative knowledge transfer, and skill
development. We then empirically examine how LLMs affect OSS developers' work
in these three key areas. Leveraging a natural experiment from a temporary
ChatGPT ban in Italy, we employ a Difference-in-Differences framework with
two-way fixed effects to analyze data from all OSS developers on GitHub in
three similar countries, Italy, France, and Portugal, totaling 88,022 users. We
find that access to ChatGPT increases developer productivity by 6.4%, knowledge
sharing by 9.6%, and skill acquisition by 8.4%. These benefits vary
significantly by user experience level: novice developers primarily experience
productivity gains, whereas more experienced developers benefit more from
improved knowledge sharing and accelerated skill acquisition. In addition, we
find that LLM-assisted learning is highly context-dependent, with the greatest
benefits observed in technically complex, fragmented, or rapidly evolving
contexts. We show that the productivity effects of LLMs extend beyond direct
code generation to include enhanced collaborative learning and knowledge
exchange among developers; dynamics that are essential for gaining a holistic
understanding of LLMs' impact in OSS. Our findings offer critical managerial
implications: strategically deploying LLMs can accelerate novice developers'
onboarding and productivity, empower intermediate developers to foster
knowledge sharing and collaboration, and support rapid skill acquisition,
together enhancing long-term organizational productivity and agility.

</details>


### [358] [Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation](https://arxiv.org/abs/2506.22776)
*Sen Fang,Weiyuan Ding,Antonio Mastropaolo,Bowen Xu*

Main category: cs.SE

Relevance: 85.0

TL;DR: 量化对LLM在代码生成任务中的鲁棒性影响首次被系统研究，发现量化模型通常比全精度模型更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 量化是压缩LLM的主流方法，但其对鲁棒性的影响尚未被充分研究。

Method: 通过对抗攻击和噪声扰动实验，评估四种LLM家族（LLaMA、DeepSeek、CodeGen、StarCoder）的量化效果。

Result: 量化LLM在51.59%的对抗实验中表现更鲁棒，噪声扰动实验也显示量化模型能承受更高权重干扰。

Conclusion: 量化不仅降低计算需求，还能提升LLM在代码生成中的可靠性。

Abstract: Quantization has emerged as a mainstream method for compressing Large
Language Models (LLMs), reducing memory requirements and accelerating inference
without architectural modifications. While existing research primarily focuses
on evaluating the effectiveness of quantized LLMs compared to their original
counterparts, the impact on robustness remains largely unexplored.In this
paper, we present the first systematic investigation of how quantization
affects the robustness of LLMs in code generation tasks. Through extensive
experiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and
StarCoder) with parameter scales ranging from 350M to 33B, we evaluate
robustness from dual perspectives: adversarial attacks on input prompts and
noise perturbations on model architecture. Our findings challenge conventional
wisdom by demonstrating that quantized LLMs often exhibit superior robustness
compared to their full-precision counterparts, with 51.59% versus 42.86% of our
adversarial experiments showing better resilience in quantized LLMs. Similarly,
our noise perturbation experiments also confirm that LLMs after quantitation
generally withstand higher levels of weight disturbances. These results suggest
that quantization not only reduces computational requirements but can actually
enhance LLMs' reliability in code generation tasks, providing valuable insights
for developing more robust and efficient LLM deployment strategies.

</details>


### [359] [From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows](https://arxiv.org/abs/2506.23260)
*Mohamed Amine Ferrag,Norbert Tihanyi,Djallel Hamouda,Leandros Maglaras,Merouane Debbah*

Main category: cs.CR

Relevance: 85.0

TL;DR: 该论文提出了一个统一的、端到端的威胁模型，涵盖LLM代理生态系统的安全漏洞，包括输入操纵、模型妥协、系统和隐私攻击以及协议漏洞，并评估了现有防御措施。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理生态系统的快速发展，插件和协议的激增导致安全实践滞后，暴露出脆弱性。本文旨在填补这一空白，提供全面的威胁模型和防御建议。

Method: 通过分类和形式化威胁模型，评估攻击技术的现实可行性，并分析现有防御措施。

Result: 论文总结了30多种攻击技术，提出了四个威胁领域，并指出了未来的研究方向，如动态信任管理和加密溯源。

Conclusion: 本文为设计稳健的防御机制和建立弹性LLM代理工作流程提供了全面参考。

Abstract: Autonomous AI agents powered by large language models (LLMs) with structured
function-calling interfaces have dramatically expanded capabilities for
real-time data retrieval, complex computation, and multi-step orchestration.
Yet, the explosive proliferation of plugins, connectors, and inter-agent
protocols has outpaced discovery mechanisms and security practices, resulting
in brittle integrations vulnerable to diverse threats. In this survey, we
introduce the first unified, end-to-end threat model for LLM-agent ecosystems,
spanning host-to-tool and agent-to-agent communications, formalize adversary
capabilities and attacker objectives, and catalog over thirty attack
techniques. Specifically, we organized the threat model into four domains:
Input Manipulation (e.g., prompt injections, long-context hijacks, multimodal
adversarial inputs), Model Compromise (e.g., prompt- and parameter-level
backdoors, composite and encrypted multi-backdoors, poisoning strategies),
System and Privacy Attacks (e.g., speculative side-channels, membership
inference, retrieval poisoning, social-engineering simulations), and Protocol
Vulnerabilities (e.g., exploits in Model Context Protocol (MCP), Agent
Communication Protocol (ACP), Agent Network Protocol (ANP), and Agent-to-Agent
(A2A) protocol). For each category, we review representative scenarios, assess
real-world feasibility, and evaluate existing defenses. Building on our threat
taxonomy, we identify key open challenges and future research directions, such
as securing MCP deployments through dynamic trust management and cryptographic
provenance tracking; designing and hardening Agentic Web Interfaces; and
achieving resilience in multi-agent and federated environments. Our work
provides a comprehensive reference to guide the design of robust defense
mechanisms and establish best practices for resilient LLM-agent workflows.

</details>


### [360] [SoK: Semantic Privacy in Large Language Models](https://arxiv.org/abs/2506.23603)
*Baihe Ma,Yanna Jiang,Xu Wang,Guangshen Yu,Qin Wang,Caijun Sun,Chen Li,Xuelei Qi,Ying He,Wei Ni,Ren Ping Liu*

Main category: cs.CR

Relevance: 85.0

TL;DR: 该论文提出了一个以生命周期为中心的框架，分析LLM在输入处理、预训练、微调和对齐阶段中语义隐私风险的出现，并评估现有防御措施的不足。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在敏感领域的广泛应用，传统隐私保护措施无法应对语义隐私（隐式、上下文或可推断信息）的挑战。

Method: 通过系统化知识（SoK）方法，分类关键攻击向量，并评估差分隐私、嵌入加密、边缘计算和遗忘等防御措施的效果。

Result: 分析揭示了语义级保护的关键缺口，尤其是针对上下文推断和潜在表示泄漏的防御不足。

Conclusion: 论文总结了开放挑战，如量化语义泄漏、保护多模态输入、平衡去标识与生成质量，以及确保隐私执行的透明度。

Abstract: As Large Language Models (LLMs) are increasingly deployed in sensitive
domains, traditional data privacy measures prove inadequate for protecting
information that is implicit, contextual, or inferable - what we define as
semantic privacy. This Systematization of Knowledge (SoK) introduces a
lifecycle-centric framework to analyze how semantic privacy risks emerge across
input processing, pretraining, fine-tuning, and alignment stages of LLMs. We
categorize key attack vectors and assess how current defenses, such as
differential privacy, embedding encryption, edge computing, and unlearning,
address these threats. Our analysis reveals critical gaps in semantic-level
protection, especially against contextual inference and latent representation
leakage. We conclude by outlining open challenges, including quantifying
semantic leakage, protecting multimodal inputs, balancing de-identification
with generation quality, and ensuring transparency in privacy enforcement. This
work aims to inform future research on designing robust, semantically aware
privacy-preserving techniques for LLMs.

</details>


### [361] [Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model](https://arxiv.org/abs/2506.23635)
*Mu-Chi Chen,Po-Hsuan Huang,Xiangrui Ke,Chia-Heng Tu,Chun Jason Xue,Shih-Hao Hung*

Main category: cs.DC

Relevance: 85.0

TL;DR: 该论文探讨了在私有LLM系统中使用Mac Studio集群和M2 Ultra芯片的成本效益和性能优化，特别关注了MoE架构的推理时间和内存管理。


<details>
  <summary>Details</summary>
Motivation: 解决构建私有LLM系统时的高成本和可扩展性问题，特别是针对个人或小团体服务（如Apple Intelligence）。

Method: 建立Mac Studio集群，使用M2 Ultra芯片加速预训练的DBRX模型（MoE架构），分析并行执行和网络延迟的影响，并优化内存管理。

Result: Mac Studio集群比NVIDIA H100 GPU的AI超级计算机成本效益高1.15倍，并开发了性能模型以指导系统设计。

Conclusion: Mac Studio集群是私有LLM系统的高效解决方案，网络延迟和内存管理是关键优化点。

Abstract: Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI)
with significant advancements such as OpenAI's ChatGPT, Meta's Llama, and
Databricks' DBRX. This paper addresses the cost and scalability challenges
encountered when constructing private LLM systems for personal or small group
services, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2
Ultra chips is established as a cost-efficient solution to host and accelerate
the pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our
performance analysis reveal that parallel execution of the model's experts
across two to four machine nodes significantly reduces inference time. We find
that computation time for the experts is comparable to the communication time
for exchanging their outputs, emphasizing the importance of network latency
over bandwidth. We also observe significant management overhead due to Apple
software stack's memory management logic. Based on these findings, we develop
optimization schemes to eliminate the memory management overhead. As a result,
the Mac Studio cluster is 1.15 times more cost-efficient than the
state-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we
construct a performance model to estimate system performance under varying
configurations, and the model provides valuable insights for designing private
LLM systems.

</details>


### [362] [Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models](https://arxiv.org/abs/2506.23678)
*Rock Yuren Pang,K. J. Kevin Feng,Shangbin Feng,Chu Li,Weijia Shi,Yulia Tsvetkov,Jeffrey Heer,Katharina Reinecke*

Main category: cs.HC

Relevance: 85.0

TL;DR: 论文提出了一种交互式推理设计，将思维链（CoT）输出可视化为主题层次结构，支持用户审查和修改，提高了LLM输出的质量和用户理解。


<details>
  <summary>Details</summary>
Motivation: 现有的思维链内容冗长且缺乏组织，难以审查，且缺乏用户反馈机会。

Method: 引入交互式推理设计，并在Hippo原型中实现，支持用户对模型推理过程进行干预和定制。

Result: 用户研究表明，交互式推理能帮助用户快速识别错误、高效定制响应，并更好地理解模型推理和输出。

Conclusion: 交互式推理为LLM推理过程引入用户监督，是一种新范式。

Abstract: The output quality of large language models (LLMs) can be improved via
"reasoning": generating segments of chain-of-thought (CoT) content to further
condition the model prior to producing user-facing output. While these chains
contain valuable information, they are verbose and lack explicit organization,
making them tedious to review. Moreover, they lack opportunities for user
feedback, such as to remove unwanted considerations, add desired ones, or
clarify unclear assumptions. We introduce Interactive Reasoning, an interaction
design that visualizes chain-of-thought outputs as a hierarchy of topics and
enables user review and modification. We implement interactive reasoning in
Hippo, a prototype for AI-assisted decision making in the face of uncertain
trade-offs. In a user study with 16 participants, we find that interactive
reasoning in Hippo allows users to quickly identify and interrupt erroneous
generations, efficiently steer the model towards customized responses, and
better understand both model reasoning and model outputs. Our work contributes
to a new paradigm that incorporates user oversight into LLM reasoning
processes.

</details>


### [363] [Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead](https://arxiv.org/abs/2506.23762)
*Hongzhou Rao,Yanjie Zhao,Xinyi Hou,Shenao Wang,Haoyu Wang*

Main category: cs.SE

Relevance: 85.0

TL;DR: 该论文从软件工程（SE）的角度系统分析了大型语言模型（LLM）开发全生命周期的研究现状，包括六个阶段：需求工程、数据集构建、模型开发与增强、测试与评估、部署与运维、维护与演进，并提出了每个阶段的关键挑战和潜在研究方向。


<details>
  <summary>Details</summary>
Motivation: LLM的快速发展带来了复杂的挑战，但目前缺乏从软件工程角度系统探索这些挑战及其解决方案的研究。

Method: 通过系统分析LLM开发生命周期的六个阶段，识别关键挑战并提出研究方向。

Result: 总结了每个阶段的主要挑战和潜在解决方案，为LLM开发的未来进展提供了SE视角的见解。

Conclusion: 论文为LLM开发提供了软件工程视角的指导，有助于推动未来研究。

Abstract: The rapid advancement of large language models (LLMs) has redefined
artificial intelligence (AI), pushing the boundaries of AI research and
enabling unbounded possibilities for both academia and the industry. However,
LLM development faces increasingly complex challenges throughout its lifecycle,
yet no existing research systematically explores these challenges and solutions
from the perspective of software engineering (SE) approaches. To fill the gap,
we systematically analyze research status throughout the LLM development
lifecycle, divided into six phases: requirements engineering, dataset
construction, model development and enhancement, testing and evaluation,
deployment and operations, and maintenance and evolution. We then conclude by
identifying the key challenges for each phase and presenting potential research
directions to address these challenges. In general, we provide valuable
insights from an SE perspective to facilitate future advances in LLM
development.

</details>


### [364] [MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI](https://arxiv.org/abs/2506.23563)
*Huanjin Yao,Jiaxing Huang,Yawen Qiu,Michael K. Chen,Wenzheng Liu,Wei Zhang,Wenjie Zeng,Xikun Zhang,Jingyi Zhang,Yuxin Song,Wenhao Wu,Dacheng Tao*

Main category: cs.AI

Relevance: 80.0

TL;DR: MMReason是一个新的基准测试，旨在全面评估多模态大语言模型（MLLMs）的长链推理能力，通过多样、开放和挑战性问题填补现有评估的不足。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM基准测试在评估长链推理能力时存在不足，如缺乏难度和多样性、易受猜测和记忆影响、未能充分评估中间推理步骤。

Method: MMReason通过以下方法设计：1）从多个学科和难度级别筛选挑战性问题；2）采用开放格式和多模型投票技术消除猜测和记忆的捷径；3）标注详细步骤并设计三元评分机制评估中间推理。

Result: MMReason对主流MLLMs进行了基准测试，深入分析了其推理能力。

Conclusion: MMReason为推进MLLM推理研究提供了有价值的资源。

Abstract: Reasoning plays a crucial role in advancing Multimodal Large Language Models
(MLLMs) toward Artificial General Intelligence. However, existing MLLM
benchmarks often fall short in precisely and comprehensively evaluating
long-chain reasoning abilities from three key aspects: (1) lack of difficulty
and diversity, (2) susceptibility to guessability and memorization, (3)
inadequate assessment of intermediate reasoning steps. To fill this gap, we
introduce MMReason, a new benchmark designed to precisely and comprehensively
evaluate MLLM long-chain reasoning capability with diverse, open-ended,
challenging questions. First, we curate challenging questions requiring
multi-step reasoning from various fields (i.e., 6 disciplines) and multiple
difficulty levels (i.e., from pre-university to university, and from
foundational to competition tiers). Second, these questions are reformulated
into an open-ended format and filtered using a multi-model voting technique to
eliminate shortcut cases related to guessing and memorization, ensuring robust
reasoning evaluations. Third, we annotate the questions with detailed
step-by-step solutions, and design a reference-based ternary scoring mechanism
to reliably assess intermediate reasoning steps. With MMReason, we benchmark
popular leading MLLMs and provide an in-depth analysis of their reasoning
capabilities. We hope MMReason will serve as a valuable resource for advancing
MLLM reasoning research. Code will be available at
https://github.com/HJYao00/MMReason.

</details>


### [365] [Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models](https://arxiv.org/abs/2506.23576)
*Maria Carolina Cornelia Wit,Jun Pang*

Main category: cs.AI

Relevance: 80.0

TL;DR: 论文研究了多智能体LLM系统作为防御越狱攻击的方法，比较了不同配置的效果，发现多智能体系统能增强防御能力，但也带来计算开销和误报增加的问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的发展，越狱攻击（绕过安全机制的提示）引发担忧，研究旨在探索多智能体系统作为防御手段的有效性。

Method: 通过复现AutoDefense框架，比较单智能体与多智能体（两到三个）配置，评估其对三种越狱攻击（AutoDefense、BetterDan、JB）的防御效果。

Result: 多智能体系统提高了对越狱攻击的抵抗能力，尤其是减少了假阴性，但其效果因攻击类型而异，并增加了假阳性和计算开销。

Conclusion: 当前自动防御存在局限性，未来需改进LLM系统的对齐鲁棒性。

Abstract: Recent advances in large language models (LLMs) have raised concerns about
jailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper
investigates the use of multi-agent LLM systems as a defence against such
attacks. We evaluate three jailbreaking strategies, including the original
AutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the
AutoDefense framework, we compare single-agent setups with two- and three-agent
configurations. Our results show that multi-agent systems enhance resistance to
jailbreaks, especially by reducing false negatives. However, its effectiveness
varies by attack type, and it introduces trade-offs such as increased false
positives and computational overhead. These findings point to the limitations
of current automated defences and suggest directions for improving alignment
robustness in future LLM systems.

</details>


### [366] [Explanations are a means to an end](https://arxiv.org/abs/2506.22740)
*Jessica Hullman,Ziyang Guo,Berk Ustun*

Main category: cs.AI

Relevance: 75.0

TL;DR: 论文提出了一种基于统计决策理论的框架，强调解释性机器学习方法应针对具体用途设计和评估，避免模糊性。


<details>
  <summary>Details</summary>
Motivation: 现有解释性机器学习方法未充分考虑实际用途，导致解释可能被误用或效果不佳。

Method: 提出基于统计决策理论的框架，明确解释的具体用途，并通过理论和实证结合的方式评估解释的价值。

Result: 展示了该框架在临床决策支持、提供补救措施和调试等多样化用例中的应用，并量化了理想决策者可能获得的性能提升。

Conclusion: 解释性方法应针对具体用途设计，并通过明确用例和理论实证结合的方式评估其价值。

Abstract: Modern methods for explainable machine learning are designed to describe how
models map inputs to outputs--without deep consideration of how these
explanations will be used in practice. This paper argues that explanations
should be designed and evaluated with a specific end in mind. We describe how
to formalize this end in a framework based in statistical decision theory. We
show how this functionally-grounded approach can be applied across diverse use
cases, such as clinical decision support, providing recourse, or debugging. We
demonstrate its use to characterize the maximum "boost" in performance on a
particular task that an explanation could provide an idealized decision-maker,
preventing misuse due to ambiguity by forcing researchers to specify concrete
use cases that can be analyzed in light of models of expected explanation use.
We argue that evaluation should meld theoretical and empirical perspectives on
the value of explanation, and contribute definitions that span these
perspectives.

</details>


### [367] [Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems](https://arxiv.org/abs/2506.22774)
*Michael Papademas,Xenia Ziouvelou,Antonis Troumpoukis,Vangelis Karkaletsis*

Main category: cs.AI

Relevance: 75.0

TL;DR: 该论文提出了一种结合伦理组件与PageRank和TrustRank算法的评估方法，旨在为可信AI提供量化评估框架，减少主观性。


<details>
  <summary>Details</summary>
Motivation: AI技术的复杂性和广泛影响使其信任问题尤为突出，现有工具在量化信任方面存在不足，需结合伦理与技术视角。

Method: 结合可信AI的伦理组件与PageRank和TrustRank算法，建立量化评估框架。

Result: 提出的方法能够通过量化指标和理论指导，实现对AI系统信任度的全面评估。

Conclusion: 该方法为可信AI评估提供了兼具量化能力和理论深度的解决方案。

Abstract: Artificial Intelligence (AI) technology epitomizes the complex challenges
posed by human-made artifacts, particularly those widely integrated into
society and exert significant influence, highlighting potential benefits and
their negative consequences. While other technologies may also pose substantial
risks, AI's pervasive reach makes its societal effects especially profound. The
complexity of AI systems, coupled with their remarkable capabilities, can lead
to a reliance on technologies that operate beyond direct human oversight or
understanding. To mitigate the risks that arise, several theoretical tools and
guidelines have been developed, alongside efforts to create technological tools
aimed at safeguarding Trustworthy AI. The guidelines take a more holistic view
of the issue but fail to provide techniques for quantifying trustworthiness.
Conversely, while technological tools are better at achieving such
quantification, they lack a holistic perspective, focusing instead on specific
aspects of Trustworthy AI. This paper aims to introduce an assessment method
that combines the ethical components of Trustworthy AI with the algorithmic
processes of PageRank and TrustRank. The goal is to establish an assessment
framework that minimizes the subjectivity inherent in the self-assessment
techniques prevalent in the field by introducing algorithmic criteria. The
application of our approach indicates that a holistic assessment of an AI
system's trustworthiness can be achieved by providing quantitative insights
while considering the theoretical content of relevant guidelines.

</details>


### [368] [AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks](https://arxiv.org/abs/2506.23049)
*Leander Melroy Maben,Gayathri Ganesh Lakshmy,Srijith Radhakrishnan,Siddhant Arora,Shinji Watanabe*

Main category: cs.AI

Relevance: 75.0

TL;DR: AURA是一个开源、基于语音的助手，支持多轮对话、工具调用和代理推理，在复杂任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏开源系统支持语音到语音的多轮对话，并集成工具使用和代理推理。

Method: 结合开源的ASR、TTS和LLM，采用模块化设计，支持动态工具调用。

Result: 在VoiceBench上表现优异，接近GPT-4o，人类评估任务成功率达90%。

Conclusion: AURA填补了开源语音助手的空白，展示了强大的任务完成能力。

Abstract: Despite advances in language and speech technologies, no open-source system
enables full speech-to-speech, multi-turn dialogue with integrated tool use and
agentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and
Automated Tool Use), the first open-source, speech-native assistant capable of
completing complex, goal-driven tasks through dynamic tool invocation and
multi-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a
cascaded pipeline and supports tools such as calendar booking, contact lookup,
web search, and email. Its modular design allows easy integration of new tools
using natural language prompts and action classes. On VoiceBench, AURA scores
92.75% on OpenBookQA-outperforming all open-weight systems and nearing
GPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.
Human evaluation shows 90% task success on complex, multi-turn speech tasks.

</details>


### [369] [PokéAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red](https://arxiv.org/abs/2506.23689)
*Zihao Liu,Xinhang Sui,Yueran Song,Siwen Wang*

Main category: cs.AI

Relevance: 75.0

TL;DR: PokéAI是一个基于文本的多智能体LLM框架，用于自主玩Pokémon Red游戏，包含规划、执行和评估三个智能体，初步结果显示其战斗模块表现接近人类玩家。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在多智能体环境中的自主决策能力，特别是在游戏中的战略推理和任务执行。

Method: 设计了三个智能体（规划、执行、评估），每个智能体有独立的记忆和技能，形成闭环决策系统。

Result: 战斗模块在50场野生对战中的平均胜率为80.8%，接近人类玩家水平，且发现LLM的语言能力与战略推理能力相关。

Conclusion: PokéAI展示了LLM在多智能体环境中的潜力，并揭示了语言能力与战略推理的联系。

Abstract: We introduce Pok\'eAI, the first text-based, multi-agent large language model
(LLM) framework designed to autonomously play and progress through Pok\'emon
Red. Our system consists of three specialized agents-Planning, Execution, and
Critique-each with its own memory bank, role, and skill set. The Planning Agent
functions as the central brain, generating tasks to progress through the game.
These tasks are then delegated to the Execution Agent, which carries them out
within the game environment. Upon task completion, the Critique Agent evaluates
the outcome to determine whether the objective was successfully achieved. Once
verification is complete, control returns to the Planning Agent, forming a
closed-loop decision-making system.
  As a preliminary step, we developed a battle module within the Execution
Agent. Our results show that the battle AI achieves an average win rate of
80.8% across 50 wild encounters, only 6% lower than the performance of an
experienced human player. Furthermore, we find that a model's battle
performance correlates strongly with its LLM Arena score on language-related
tasks, indicating a meaningful link between linguistic ability and strategic
reasoning. Finally, our analysis of gameplay logs reveals that each LLM
exhibits a unique playstyle, suggesting that individual models develop distinct
strategic behaviors.

</details>


### [370] [A New Perspective On AI Safety Through Control Theory Methodologies](https://arxiv.org/abs/2506.23703)
*Lars Ullrich,Walter Zimmer,Ross Greer,Knut Graichen,Alois C. Knoll,Mohan Trivedi*

Main category: cs.AI

Relevance: 75.0

TL;DR: 论文提出了一种基于系统理论和数据分析的新视角（数据控制），旨在通过跨学科方法提升AI安全性，特别是在安全关键系统中。


<details>
  <summary>Details</summary>
Motivation: AI在复杂问题中表现优异，但其安全性保障不足，尤其是在安全关键的物理信息系统中。

Method: 采用系统理论和系统分析驱动的方法，提出数据控制概念，结合控制理论和AI工程。

Result: 提出了一个通用的安全分析和保障框架，适用于特定AI系统和未来创新。

Conclusion: 数据控制为AI安全性提供了一种跨学科的新视角，有望推动AI工程的发展。

Abstract: While artificial intelligence (AI) is advancing rapidly and mastering
increasingly complex problems with astonishing performance, the safety
assurance of such systems is a major concern. Particularly in the context of
safety-critical, real-world cyber-physical systems, AI promises to achieve a
new level of autonomy but is hampered by a lack of safety assurance. While
data-driven control takes up recent developments in AI to improve control
systems, control theory in general could be leveraged to improve AI safety.
Therefore, this article outlines a new perspective on AI safety based on an
interdisciplinary interpretation of the underlying data-generation process and
the respective abstraction by AI systems in a system theory-inspired and system
analysis-driven manner. In this context, the new perspective, also referred to
as data control, aims to stimulate AI engineering to take advantage of existing
safety analysis and assurance in an interdisciplinary way to drive the paradigm
of data control. Following a top-down approach, a generic foundation for safety
analysis and assurance is outlined at an abstract level that can be refined for
specific AI systems and applications and is prepared for future innovation.

</details>


### [371] [Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments](https://arxiv.org/abs/2506.23706)
*Christoph Schnabl,Daniel Hugenroth,Bill Marino,Alastair R. Beresford*

Main category: cs.AI

Relevance: 75.0

TL;DR: 提出了一种名为Attestable Audits的方法，利用可信执行环境（TEE）验证AI模型的合规性，保护敏感数据，解决了AI治理框架中的验证挑战。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试无法提供可验证的结果，且缺乏对模型IP和基准数据集的保密性，需要一种能保护敏感数据并验证AI模型合规性的方法。

Method: 使用可信执行环境（TEE）运行Attestable Audits，确保模型提供方和审计方互不信任时仍能保护数据。

Result: 原型验证了在Llama-3.1上实施典型审计基准的可行性。

Conclusion: Attestable Audits为AI模型的合规性验证提供了可行且安全的解决方案。

Abstract: Benchmarks are important measures to evaluate safety and compliance of AI
models at scale. However, they typically do not offer verifiable results and
lack confidentiality for model IP and benchmark datasets. We propose Attestable
Audits, which run inside Trusted Execution Environments and enable users to
verify interaction with a compliant AI model. Our work protects sensitive data
even when model provider and auditor do not trust each other. This addresses
verification challenges raised in recent AI governance frameworks. We build a
prototype demonstrating feasibility on typical audit benchmarks against
Llama-3.1.

</details>


### [372] [Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence](https://arxiv.org/abs/2506.23908)
*András György,Tor Lattimore,Nevena Lazić,Csaba Szepesvári*

Main category: cs.AI

Relevance: 75.0

TL;DR: 论文讨论了当前AI系统在演绎推理任务上的不足，提出应从统计学习转向精确学习范式以实现可靠的演绎推理。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在数学和科学领域取得进展，但前沿系统在简单演绎推理任务上表现不佳，无法实现通用人工智能。作者认为这是统计学习方法的局限性所致。

Method: 提出从优化统计性能转向精确学习范式，要求在所有输入上实现正确性，并认为这是算法设计的关键目标。

Result: 论文未提供具体实验结果，但提出了精确学习的必要性和可能性。

Conclusion: 为实现可靠的演绎推理，AI研究需从统计学习转向精确学习范式。

Abstract: Sound deductive reasoning -- the ability to derive new knowledge from
existing facts and rules -- is an indisputably desirable aspect of general
intelligence. Despite the major advances of AI systems in areas such as math
and science, especially since the introduction of transformer architectures, it
is well-documented that even the most advanced frontier systems regularly and
consistently falter on easily-solvable deductive reasoning tasks. Hence, these
systems are unfit to fulfill the dream of achieving artificial general
intelligence capable of sound deductive reasoning. We argue that their unsound
behavior is a consequence of the statistical learning approach powering their
development. To overcome this, we contend that to achieve reliable deductive
reasoning in learning-based AI systems, researchers must fundamentally shift
from optimizing for statistical performance against distributions on reasoning
problems and algorithmic tasks to embracing the more ambitious exact learning
paradigm, which demands correctness on all inputs. We argue that exact learning
is both essential and possible, and that this ambitious objective should guide
algorithm design.

</details>


### [373] [Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice](https://arxiv.org/abs/2506.23924)
*Akshit Kumar,Tianyi Peng,Yuhang Wu,Assaf Zeevi*

Main category: cs.AI

Relevance: 75.0

TL;DR: 论文评估了大语言模型（LLMs）在解决运筹学（OR）中随机建模问题的能力，发现其表现接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在运筹学领域的潜力，尤其是解决随机建模问题的能力，填补现有研究的空白。

Method: 手动收集研究生和博士资格考试题目，结合开源库SimOpt测试LLMs在不确定条件下的决策能力。

Result: LLMs在课堂和实际场景中表现接近人类专家，但自动化随机建模流程仍需改进。

Conclusion: LLMs有潜力辅助运筹学研究，通过自动化提升OR的实际影响力。

Abstract: Large language models (LLMs) have exhibited expert-level capabilities across
various domains. However, their abilities to solve problems in Operations
Research (OR) -- the analysis and optimization of mathematical models derived
from real-world problems or their verbal descriptions -- remain underexplored.
In this work, we take a first step toward evaluating LLMs' abilities to solve
stochastic modeling problems, a core class of OR problems characterized by
uncertainty and typically involving tools from probability, statistics, and
stochastic processes. We manually procure a representative set of
graduate-level homework and doctoral qualification-exam problems and test LLMs'
abilities to solve them. We further leverage SimOpt, an open-source library of
simulation-optimization problems and solvers, to investigate LLMs' abilities to
make real-world decisions under uncertainty. Our results show that, though a
nontrivial amount of work is still needed to reliably automate the stochastic
modeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on
par with human experts in both classroom and practical settings. These findings
highlight the potential of building AI agents that assist OR researchers and
amplify the real-world impact of OR through automation.

</details>


### [374] [A Survey on Model Extraction Attacks and Defenses for Large Language Models](https://arxiv.org/abs/2506.22521)
*Kaixiang Zhao,Lincan Li,Kaize Ding,Neil Zhenqiang Gong,Yue Zhao,Yushun Dong*

Main category: cs.CR

Relevance: 75.0

TL;DR: 该论文综述了针对语言模型的提取攻击与防御方法，分类了攻击类型并分析了防御机制的有效性，提出了评估指标和研究方向。


<details>
  <summary>Details</summary>
Motivation: 模型提取攻击对部署的语言模型构成安全威胁，可能损害知识产权和用户隐私，因此需要系统化的攻击分类与防御策略。

Method: 对LLM特有的提取攻击和防御进行全面分类，分析攻击方法（如API蒸馏、直接查询、参数恢复等）和防御机制（模型保护、数据隐私保护等）。

Result: 提出了评估攻击和防御效果的专用指标，识别了当前方法的局限性，并提出了集成攻击方法和自适应防御机制的研究方向。

Conclusion: 该研究为NLP研究者、ML工程师和安全专业人员提供了保护生产环境中语言模型的实用指南。

Abstract: Model extraction attacks pose significant security threats to deployed
language models, potentially compromising intellectual property and user
privacy. This survey provides a comprehensive taxonomy of LLM-specific
extraction attacks and defenses, categorizing attacks into functionality
extraction, training data extraction, and prompt-targeted attacks. We analyze
various attack methodologies including API-based knowledge distillation, direct
querying, parameter recovery, and prompt stealing techniques that exploit
transformer architectures. We then examine defense mechanisms organized into
model protection, data privacy protection, and prompt-targeted strategies,
evaluating their effectiveness across different deployment scenarios. We
propose specialized metrics for evaluating both attack effectiveness and
defense performance, addressing the specific challenges of generative language
models. Through our analysis, we identify critical limitations in current
approaches and propose promising research directions, including integrated
attack methodologies and adaptive defense mechanisms that balance security with
model utility. This work serves NLP researchers, ML engineers, and security
professionals seeking to protect language models in production environments.

</details>


### [375] [Teaching a Language Model to Speak the Language of Tools](https://arxiv.org/abs/2506.23394)
*Simeon Emanuilov*

Main category: cs.IR

Relevance: 75.0

TL;DR: 该论文提出了一种方法，通过多语言数据集和持续训练，提升非英语语言模型在工具调用任务中的表现，并以保加利亚语为例展示了显著改进。


<details>
  <summary>Details</summary>
Motivation: 当前多语言模型在非英语语言中的工具调用能力不足，存在语言混淆和输出不一致的问题。

Method: 通过持续训练BgGPT系列模型（2.6B、9B、27B参数），使用包含10,035个工具调用示例的双语数据集，支持标准化协议如MCP。

Result: TUCAN模型在工具调用准确率上比基础模型提升28.75%，同时保持了语言理解能力，输出更规范。

Conclusion: 该方法为扩展非英语语言模型的工具调用能力提供了实用解决方案，并开源了模型、评估框架和数据集。

Abstract: External tool integration through function-calling is essential for practical
language model applications, yet most multilingual models lack reliable
tool-use capabilities in non-English languages. Even state-of-the-art
multilingual models struggle with determining when to use tools and generating
the structured outputs required for function calls, often exhibiting language
confusion when prompted in lower-resource languages. This work presents a
methodology for adapting existing language models to enable robust tool use in
any target language, using Bulgarian as a case study. The approach involves
continued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a
novel bilingual dataset of 10,035 function-calling examples designed to support
standardized protocols like MCP (Model Context Protocol). The research
introduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to
28.75% improvement in function-calling accuracy over base models while
preserving core language understanding, as verified on established Bulgarian
benchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready
response formatting with clean, parsable function calls, contrasting with the
verbose and inconsistent outputs of base models. The models, evaluation
framework, and dataset are released to enable replication for other languages.
This work demonstrates a practical approach for extending tool-augmented
capabilities beyond English-centric systems.

</details>


### [376] [RAILS: Retrieval-Augmented Intelligence for Learning Software Development](https://arxiv.org/abs/2506.22742)
*Wali Mohammad Abdullah,Md. Morshedul Islam,Devraj Parmar,Happy Hasmukhbhai Patel,Sindhuja Prabhakaran,Baidya Saha*

Main category: cs.SE

Relevance: 75.0

TL;DR: RAILS框架通过检索增强和迭代验证改进LLM在软件开发中的代码生成能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在软件开发中常生成不完整或错误的代码，尤其是缺乏外部文档时。

Method: RAILS结合FAISS和OpenAI嵌入检索上下文，并通过编译器反馈迭代验证。

Result: 在78个Java导入错误案例中，RAILS优于基线提示方法。

Conclusion: RAILS有效提升LLM代码生成的准确性和实用性。

Abstract: Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to
assist software development, yet they often produce incomplete code or
incorrect imports, especially when lacking access to external or
project-specific documentation. We introduce RAILS (Retrieval-Augmented
Intelligence for Learning Software Development), a framework that augments LLM
prompts with semantically retrieved context from curated Java resources using
FAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop
guided by compiler feedback to refine suggestions. We evaluated RAILS on 78
real-world Java import error cases spanning standard libraries, GUI APIs,
external tools, and custom utilities. Despite using the same LLM, RAILS
outperforms baseline prompting by preserving intent, avoiding hallucinations,
and surfacing correct imports even when libraries are unavailable locally.
Future work will integrate symbolic filtering via PostgreSQL and extend support
to other languages and IDEs.

</details>


### [377] [The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy](https://arxiv.org/abs/2506.23123)
*Rishi Bommasani*

Main category: cs.AI

Relevance: 70.0

TL;DR: 该论文探讨了基础模型与社会的关系，围绕概念框架、实证见解和政策行动三方面展开，旨在通过科学研究和政策接口改善AI治理。


<details>
  <summary>Details</summary>
Motivation: 研究基础模型的能力、风险及其社会影响，以促进更好的AI治理和社会成果。

Method: 通过概念框架分析、模型和组织层面的透明度评估，以及政策行动研究。

Result: 提出了基础模型的社会影响理解框架，并推动了基于证据的AI政策制定。

Conclusion: 通过科学研究和政策接口，论文为AI时代的社会治理提供了基础。

Abstract: Artificial intelligence is humanity's most promising technology because of
the remarkable capabilities offered by foundation models. Yet, the same
technology brings confusion and consternation: foundation models are poorly
understood and they may precipitate a wide array of harms. This dissertation
explains how technology and society coevolve in the age of AI, organized around
three themes. First, the conceptual framing: the capabilities, risks, and the
supply chain that grounds foundation models in the broader economy. Second, the
empirical insights that enrich the conceptual foundations: transparency created
via evaluations at the model level and indexes at the organization level.
Finally, the transition from understanding to action: superior understanding of
the societal impact of foundation models advances evidence-based AI policy.
View together, this dissertation makes inroads into achieving better societal
outcomes in the age of AI by building the scientific foundations and
research-policy interface required for better AI governance.

</details>


### [378] [Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models](https://arxiv.org/abs/2506.23692)
*Boyuan Zheng,Zerui Fang,Zhe Xu,Rui Wang,Yiwen Chen,Cunshi Wang,Mengwei Qu,Lei Lei,Zhen Feng,Yan Liu,Yuyang Li,Mingzhou Tan,Jiaji Wu,Jianwei Shuai,Jia Li,Fangfu Ye*

Main category: cs.AI

Relevance: 70.0

TL;DR: 论文提出‘Agent for Science’（Agent4S）作为第五科学范式，利用LLM驱动的代理自动化整个科研工作流，并提出了五级分类框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI for Science（AI4S）作为分析工具未能解决科研核心效率问题，因此提出Agent4S以实现科研工作流的全面自动化。

Method: 引入五级分类框架，从简单任务自动化到完全自主协作的‘AI科学家’逐步实现。

Result: 提出了Agent4S的清晰路线图，定义了科学发现的革命性下一步。

Conclusion: Agent4S框架为科学发现提供了新的范式，有望显著提升科研效率。

Abstract: While AI for Science (AI4S) serves as an analytical tool in the current
research paradigm, it doesn't solve its core inefficiency. We propose "Agent
for Science" (Agent4S)-the use of LLM-driven agents to automate the entire
research workflow-as the true Fifth Scientific Paradigm. This paper introduces
a five-level classification for Agent4S, outlining a clear roadmap from simple
task automation to fully autonomous, collaborative "AI Scientists." This
framework defines the next revolutionary step in scientific discovery.

</details>


### [379] [Constructing Non-Markovian Decision Process via History Aggregator](https://arxiv.org/abs/2506.24026)
*Yongyi Wang,Wenxin Li*

Main category: cs.AI

Relevance: 70.0

TL;DR: 提出了一种基于范畴论的方法，用于评估决策算法处理非马尔可夫动态的能力，并通过HAS工具精确控制状态依赖结构。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法全面评估决策算法处理非马尔可夫动态的能力，限制了相关系统的进展和效果。

Method: 基于范畴论建立了MDP和NMDP的范畴，并证明其等价关系；引入HAS工具控制状态依赖结构。

Result: 方法能有效表示广泛的非马尔可夫动态，为决策算法提供了更严格和灵活的评估框架。

Conclusion: 该方法为理解和解决非马尔可夫动态提供了新的理论视角，并提升了决策算法的评估能力。

Abstract: In the domain of algorithmic decision-making, non-Markovian dynamics manifest
as a significant impediment, especially for paradigms such as Reinforcement
Learning (RL), thereby exerting far-reaching consequences on the advancement
and effectiveness of the associated systems. Nevertheless, the existing
benchmarks are deficient in comprehensively assessing the capacity of decision
algorithms to handle non-Markovian dynamics. To address this deficiency, we
have devised a generalized methodology grounded in category theory. Notably, we
established the category of Markov Decision Processes (MDP) and the category of
non-Markovian Decision Processes (NMDP), and proved the equivalence
relationship between them. This theoretical foundation provides a novel
perspective for understanding and addressing non-Markovian dynamics. We further
introduced non-Markovianity into decision-making problem settings via the
History Aggregator for State (HAS). With HAS, we can precisely control the
state dependency structure of decision-making problems in the time series. Our
analysis demonstrates the effectiveness of our method in representing a broad
range of non-Markovian dynamics. This approach facilitates a more rigorous and
flexible evaluation of decision algorithms by testing them in problem settings
where non-Markovian dynamics are explicitly constructed.

</details>


### [380] [In-context learning for the classification of manipulation techniques in phishing emails](https://arxiv.org/abs/2506.22515)
*Antony Dalmiere,Guillaume Auriol,Vincent Nicomette,Pascal Marchand*

Main category: cs.CR

Relevance: 70.0

TL;DR: 该研究利用LLM的上下文学习（ICL）对钓鱼邮件进行细粒度分类，基于40种操纵技术分类法，在真实法语钓鱼邮件数据集上测试，准确率达0.76。


<details>
  <summary>Details</summary>
Motivation: 传统钓鱼检测常忽视心理操纵技术，本研究旨在填补这一空白，探索LLM在分析钓鱼邮件中的潜力。

Method: 使用GPT-4o-mini进行少样本上下文学习，对SignalSpam数据集中的法语钓鱼邮件进行分类，基于40种操纵技术分类法。

Result: 在100封人工标注的测试邮件中，模型准确率为0.76，能有效识别常见操纵技术（如诱饵、好奇心吸引、小请求等）。

Conclusion: 研究表明ICL在钓鱼邮件分析中具有潜力，并为攻击者策略提供了新见解。

Abstract: Traditional phishing detection often overlooks psychological manipulation.
This study investigates using Large Language Model (LLM) In-Context Learning
(ICL) for fine-grained classification of phishing emails based on a taxonomy of
40 manipulation techniques. Using few-shot examples with GPT-4o-mini on
real-world French phishing emails (SignalSpam), we evaluated performance
against a human-annotated test set (100 emails). The approach effectively
identifies prevalent techniques (e.g., Baiting, Curiosity Appeal, Request For
Minor Favor) with a promising accuracy of 0.76. This work demonstrates ICL's
potential for nuanced phishing analysis and provides insights into attacker
strategies.

</details>


### [381] [Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions](https://arxiv.org/abs/2506.22941)
*Kaixuan Wang,Jason T. Jacques,Chenxin Diao*

Main category: cs.HC

Relevance: 70.0

TL;DR: 论文探讨如何负责任地设计LLMs以支持药物使用者的信息需求，通过定性研讨会识别了潜在用例和核心设计考虑。


<details>
  <summary>Details</summary>
Motivation: 现有在线渠道无法满足药物使用者的多样化需求，LLMs提供了新的机会，但应用在高风险领域仍面临挑战。

Method: 通过定性研讨会，与学术界、实践者和社区代表合作，探索LLM能力并识别设计考虑。

Result: LLMs能解决部分信息障碍，但需克服伦理对齐、上下文理解和沟通等挑战。

Conclusion: 强调与专家和药物使用者共同设计，开发安全、负责任的LLM系统。

Abstract: Access to accurate and actionable harm reduction information can directly
impact the health outcomes of People Who Use Drugs (PWUD), yet existing online
channels often fail to meet their diverse and dynamic needs due to limitations
in adaptability, accessibility, and the pervasive impact of stigma. Large
Language Models (LLMs) present a novel opportunity to enhance information
provision, but their application in such a high-stakes domain is under-explored
and presents socio-technical challenges. This paper investigates how LLMs can
be responsibly designed to support the information needs of PWUD. Through a
qualitative workshop involving diverse stakeholder groups (academics, harm
reduction practitioners, and an online community moderator), we explored LLM
capabilities, identified potential use cases, and delineated core design
considerations. Our findings reveal that while LLMs can address some existing
information barriers (e.g., by offering responsive, multilingual, and
potentially less stigmatising interactions), their effectiveness is contingent
upon overcoming challenges related to ethical alignment with harm reduction
principles, nuanced contextual understanding, effective communication, and
clearly defined operational boundaries. We articulate design pathways
emphasising collaborative co-design with experts and PWUD to develop LLM
systems that are helpful, safe, and responsibly governed. This work contributes
empirically grounded insights and actionable design considerations for the
responsible development of LLMs as supportive tools within the harm reduction
ecosystem.

</details>


### [382] [Securing AI Systems: A Guide to Known Attacks and Impacts](https://arxiv.org/abs/2506.23296)
*Naoto Kiribuchi,Kengo Zenitani,Takayuki Semitsu*

Main category: cs.CR

Relevance: 70.0

TL;DR: 本文概述了AI系统特有的对抗性攻击，识别了11种主要攻击类型，并将其影响映射到CIA安全三要素，旨在为非专业读者提供识别风险和防御的基础知识。


<details>
  <summary>Details</summary>
Motivation: AI系统面临独特的安全威胁，需要为非专业研究人员、开发者和政策制定者提供识别和防御这些威胁的基础知识。

Method: 识别并分类了11种针对预测和生成AI系统的对抗性攻击类型，并将其影响映射到CIA三要素（机密性、完整性、可用性）。

Result: 提供了对AI特有攻击的全面分类，并明确了攻击技术与实际影响之间的联系。

Conclusion: 通过提供基础知识和防御策略，本文有助于提升AI系统的整体安全性。

Abstract: Embedded into information systems, artificial intelligence (AI) faces
security threats that exploit AI-specific vulnerabilities. This paper provides
an accessible overview of adversarial attacks unique to predictive and
generative AI systems. We identify eleven major attack types and explicitly
link attack techniques to their impacts -- including information leakage,
system compromise, and resource exhaustion -- mapped to the confidentiality,
integrity, and availability (CIA) security triad. We aim to equip researchers,
developers, security practitioners, and policymakers, even those without
specialized AI security expertise, with foundational knowledge to recognize
AI-specific risks and implement effective defenses, thereby enhancing the
overall security posture of AI systems.

</details>


### [383] [XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs](https://arxiv.org/abs/2506.23325)
*Yitian Gong,Luozhijie Jin,Ruifan Deng,Dong Zhang,Xin Zhang,Qinyuan Cheng,Zhaoye Fei,Shimin Li,Xipeng Qiu*

Main category: cs.SD

Relevance: 70.0

TL;DR: XY-Tokenizer是一种新型语音编解码器，通过多阶段、多任务学习平衡语义丰富性和声学保真度，性能优于现有编解码器。


<details>
  <summary>Details</summary>
Motivation: 现有语音编解码器难以同时满足高质量音频重建和语言模型建模的需求，XY-Tokenizer旨在解决这一问题。

Method: 采用多阶段、多任务学习方法设计XY-Tokenizer，平衡语义和声学能力。

Result: XY-Tokenizer在语义和声学任务上均表现优异，文本对齐能力优于SpeechTokenizer和Mimi，声学重建性能接近BigCodec。

Conclusion: XY-Tokenizer在语义和声学性能上取得了平衡，为语音语言模型提供了更优的编解码方案。

Abstract: Speech codecs serve as bridges between speech signals and large language
models. An ideal codec for speech language models should not only preserve
acoustic information but also capture rich semantic information. However,
existing speech codecs struggle to balance high-quality audio reconstruction
with ease of modeling by language models. In this study, we analyze the
limitations of previous codecs in balancing semantic richness and acoustic
fidelity. We propose XY-Tokenizer, a novel codec that mitigates the conflict
between semantic and acoustic capabilities through multi-stage, multi-task
learning. Experimental results demonstrate that XY-Tokenizer achieves
performance in both semantic and acoustic tasks comparable to that of
state-of-the-art codecs operating at similar bitrates, even though those
existing codecs typically excel in only one aspect. Specifically, XY-Tokenizer
achieves strong text alignment, surpassing distillation-based semantic modeling
methods such as SpeechTokenizer and Mimi, while maintaining a speaker
similarity score of 0.83 between reconstructed and original audio. The
reconstruction performance of XY-Tokenizer is comparable to that of BigCodec,
the current state-of-the-art among acoustic-only codecs, which achieves a
speaker similarity score of 0.84 at a similar bitrate. Code and models are
available at https://github.com/gyt1145028706/XY-Tokenizer.

</details>


### [384] [Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving](https://arxiv.org/abs/2506.23771)
*Guizhe Jin,Zhuoren Li,Bo Leng,Ran Yu,Lu Xiong*

Main category: cs.RO

Relevance: 70.0

TL;DR: 提出了一种多时间尺度分层强化学习方法，用于自动驾驶，通过统一训练高低层策略，显著提升驾驶效率、行为一致性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的自动驾驶方法忽视策略结构设计，导致驾驶行为波动或无法统一优化。

Method: 采用分层策略结构，高层策略生成长时间尺度运动指导，低层策略生成短时间尺度控制命令，并设计分层安全机制。

Result: 在仿真和HighD数据集的高速公路多车道场景中，显著提升了自动驾驶性能。

Conclusion: 多时间尺度分层强化学习方法有效解决了驾驶行为波动和统一优化问题。

Abstract: Reinforcement Learning (RL) is increasingly used in autonomous driving (AD)
and shows clear advantages. However, most RL-based AD methods overlook policy
structure design. An RL policy that only outputs short-timescale vehicle
control commands results in fluctuating driving behavior due to fluctuations in
network outputs, while one that only outputs long-timescale driving goals
cannot achieve unified optimality of driving behavior and control. Therefore,
we propose a multi-timescale hierarchical reinforcement learning approach. Our
approach adopts a hierarchical policy structure, where high- and low-level RL
policies are unified-trained to produce long-timescale motion guidance and
short-timescale control commands, respectively. Therein, motion guidance is
explicitly represented by hybrid actions to capture multimodal driving
behaviors on structured road and support incremental low-level extend-state
updates. Additionally, a hierarchical safety mechanism is designed to ensure
multi-timescale safety. Evaluation in simulator-based and HighD dataset-based
highway multi-lane scenarios demonstrates that our approach significantly
improves AD performance, effectively increasing driving efficiency, action
consistency and safety.

</details>


### [385] [SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning](https://arxiv.org/abs/2506.22506)
*Momin Ahmad Khan,Yasra Chandio,Fatima Muhammad Anwar*

Main category: cs.CR

Relevance: 65.0

TL;DR: 论文研究了联邦提示学习中的后门攻击，提出了防御方法SABRE-FL，通过嵌入空间异常检测器过滤恶意提示更新。


<details>
  <summary>Details</summary>
Motivation: 联邦提示学习的安全隐患尚未充分研究，尤其是后门攻击的威胁。

Method: 提出SABRE-FL防御方法，利用离线训练的嵌入空间异常检测器识别并过滤恶意提示更新。

Result: SABRE-FL在五个数据集上显著降低后门攻击准确率，同时保持干净输入的准确性。

Conclusion: 联邦提示学习需要更鲁棒的防御机制，SABRE-FL为此提供了有效解决方案。

Abstract: Federated Prompt Learning has emerged as a communication-efficient and
privacy-preserving paradigm for adapting large vision-language models like CLIP
across decentralized clients. However, the security implications of this setup
remain underexplored. In this work, we present the first study of backdoor
attacks in Federated Prompt Learning. We show that when malicious clients
inject visually imperceptible, learnable noise triggers into input images, the
global prompt learner becomes vulnerable to targeted misclassification while
still maintaining high accuracy on clean inputs. Motivated by this
vulnerability, we propose SABRE-FL, a lightweight, modular defense that filters
poisoned prompt updates using an embedding-space anomaly detector trained
offline on out-of-distribution data. SABRE-FL requires no access to raw client
data or labels and generalizes across diverse datasets. We show, both
theoretically and empirically, that malicious clients can be reliably
identified and filtered using an embedding-based detector. Across five diverse
datasets and four baseline defenses, SABRE-FL outperforms all baselines by
significantly reducing backdoor accuracy while preserving clean accuracy,
demonstrating strong empirical performance and underscoring the need for robust
prompt learning in future federated systems.

</details>


### [386] [MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning](https://arxiv.org/abs/2506.22992)
*Yulun Jiang,Yekun Chai,Maria Brbić,Michael Moor*

Main category: cs.AI

Relevance: 60.0

TL;DR: MARBLE是一个多模态推理基准测试，旨在评估多模态语言模型（MLLMs）在复杂多模态问题中的逐步推理能力。现有MLLMs表现不佳，表明复杂推理仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注纯文本推理或可直接从非文本模态检索答案的多模态问题，复杂多模态推理仍未被充分研究。

Method: MARBLE包含两个高难度任务（M-Portal和M-Cube），要求模型在空间、视觉和物理约束下制定和理解多步计划。

Result: 12个先进MLLMs在MARBLE上表现接近随机水平，M-Cube任务准确率为0%，仅在某些简化子任务中表现略优。感知能力仍是瓶颈。

Conclusion: MARBLE揭示了MLLMs在复杂多模态推理中的局限性，有望推动下一代具备跨模态推理能力的模型发展。

Abstract: The ability to process information from multiple modalities and to reason
through it step-by-step remains a critical challenge in advancing artificial
intelligence. However, existing reasoning benchmarks focus on text-only
reasoning, or employ multimodal questions that can be answered by directly
retrieving information from a non-text modality. Thus, complex reasoning
remains poorly understood in multimodal domains. Here, we present MARBLE, a
challenging multimodal reasoning benchmark that is designed to scrutinize
multimodal language models (MLLMs) in their ability to carefully reason
step-by-step through complex multimodal problems and environments. MARBLE is
composed of two highly challenging tasks, M-Portal and M-Cube, that require the
crafting and understanding of multistep plans under spatial, visual, and
physical constraints. We find that current MLLMs perform poorly on MARBLE --
all the 12 advanced models obtain near-random performance on M-Portal and 0%
accuracy on M-Cube. Only in simplified subtasks some models outperform the
random baseline, indicating that complex reasoning is still a challenge for
existing MLLMs. Moreover, we show that perception remains a bottleneck, where
MLLMs occasionally fail to extract information from the visual inputs. By
shedding a light on the limitations of MLLMs, we hope that MARBLE will spur the
development of the next generation of models with the ability to reason and
plan across many, multimodal reasoning steps.

</details>


### [387] [AI's Euclid's Elements Moment: From Language Models to Computable Thought](https://arxiv.org/abs/2506.23080)
*Xinmin Fang,Lingfeng Tao,Zhengxiong Li*

Main category: cs.AI

Relevance: 60.0

TL;DR: 论文提出了一个五阶段进化框架，用于理解AI的发展，类比人类认知技术的进步，并预测未来AI将进入自我反思和符号逻辑阶段。


<details>
  <summary>Details</summary>
Motivation: 探讨AI发展的历史轨迹和未来方向，为研究者和开发者提供理论指导和实践策略。

Method: 提出“认知几何”框架，系统分析AI从专家系统到Transformer的演变，并预测未来的发展阶段。

Result: 框架揭示了AI发展的非线性反射性，并提出了“元语言时刻”等未来阶段。

Conclusion: 该研究为AI的未来发展提供了理论基础和具体策略，尤其是神经符号架构和程序合成方向。

Abstract: This paper presents a comprehensive five-stage evolutionary framework for
understanding the development of artificial intelligence, arguing that its
trajectory mirrors the historical progression of human cognitive technologies.
We posit that AI is advancing through distinct epochs, each defined by a
revolutionary shift in its capacity for representation and reasoning, analogous
to the inventions of cuneiform, the alphabet, grammar and logic, mathematical
calculus, and formal logical systems. This "Geometry of Cognition" framework
moves beyond mere metaphor to provide a systematic, cross-disciplinary model
that not only explains AI's past architectural shifts-from expert systems to
Transformers-but also charts a concrete and prescriptive path forward.
Crucially, we demonstrate that this evolution is not merely linear but
reflexive: as AI advances through these stages, the tools and insights it
develops create a feedback loop that fundamentally reshapes its own underlying
architecture. We are currently transitioning into a "Metalinguistic Moment,"
characterized by the emergence of self-reflective capabilities like
Chain-of-Thought prompting and Constitutional AI. The subsequent stages, the
"Mathematical Symbolism Moment" and the "Formal Logic System Moment," will be
defined by the development of a computable calculus of thought, likely through
neuro-symbolic architectures and program synthesis, culminating in provably
aligned and reliable AI that reconstructs its own foundational representations.
This work serves as the methodological capstone to our trilogy, which
previously explored the economic drivers ("why") and cognitive nature ("what")
of AI. Here, we address the "how," providing a theoretical foundation for
future research and offering concrete, actionable strategies for startups and
developers aiming to build the next generation of intelligent systems.

</details>


### [388] [FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis](https://arxiv.org/abs/2506.23273)
*Quang Hung Nguyen,Phuong Anh Trinh,Phan Quoc Hung Mai,Tuan Phong Trinh*

Main category: cs.AI

Relevance: 60.0

TL;DR: FinStat2SQL是一个轻量级的text2sql管道，专为金融领域设计，结合大语言模型和小语言模型，在越南企业金融分析中表现出色。


<details>
  <summary>Details</summary>
Motivation: 金融领域的数据库设计和报表布局差异大，导致text2sql任务复杂且具有挑战性。

Method: 采用多智能体设置，结合大小语言模型进行实体提取、SQL生成和自校正，并构建特定领域数据库进行评估。

Result: 微调的7B模型在消费硬件上达到61.33%的准确率，响应时间低于4秒，优于GPT-4o-mini。

Conclusion: FinStat2SQL为越南企业提供了可扩展且经济高效的金融分析解决方案。

Abstract: Despite the advancements of large language models, text2sql still faces many
challenges, particularly with complex and domain-specific queries. In finance,
database designs and financial reporting layouts vary widely between financial
entities and countries, making text2sql even more challenging. We present
FinStat2SQL, a lightweight text2sql pipeline enabling natural language queries
over financial statements. Tailored to local standards like VAS, it combines
large and small language models in a multi-agent setup for entity extraction,
SQL generation, and self-correction. We build a domain-specific database and
evaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves
61.33\% accuracy with sub-4-second response times on consumer hardware,
outperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient
solution for financial analysis, making AI-powered querying accessible to
Vietnamese enterprises.

</details>


### [389] [The Confidence Paradox: Can LLM Know When It's Wrong](https://arxiv.org/abs/2506.23464)
*Sahil Tripathi,Md Tabrez Nafis,Imran Hussain,Jiechao Gao*

Main category: cs.AI

Relevance: 60.0

TL;DR: HonestVQA是一个自监督的诚实校准框架，用于DocVQA系统，通过量化不确定性、对齐模型置信度与准确性，并引入伦理响应行为，提升模型的伦理对齐性。


<details>
  <summary>Details</summary>
Motivation: 现有DocVQA系统在伦理响应性上表现不足，模型置信度与实际知识不匹配，可能导致伦理风险。

Method: 提出模型无关的方法，包括不确定性量化、加权损失函数对齐置信度与正确性，以及对比学习强化伦理响应行为。

Result: HonestVQA在多个数据集上提升准确率和F1分数，降低过置信度，并展示出强泛化能力。

Conclusion: HonestVQA通过伦理对齐显著提升了DocVQA系统的性能和可信度。

Abstract: Document Visual Question Answering (DocVQA) systems are increasingly deployed
in real world applications, yet they remain ethically opaque-often producing
overconfident answers to ambiguous questions or failing to communicate
uncertainty in a trustworthy manner. This misalignment between model confidence
and actual knowledge poses significant risks, particularly in domains requiring
ethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT
have advanced SOTA performance by focusing on architectural sophistication and
accuracy; however, they fall short in ethical responsiveness.
  To address these limitations, we introduce HonestVQA, a self-supervised
honesty calibration framework for ethically aligned DocVQA. Our model-agnostic
method quantifies uncertainty to identify knowledge gaps, aligns model
confidence with actual correctness using weighted loss functions, and enforces
ethical response behavior via contrastive learning. We further introduce two
principled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence
Index (ECI)--to benchmark alignment between confidence, accuracy, and ethical
communication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%
and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces
overconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In
cross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,
demonstrating strong generalization. Ablation shows a 3.8% drop in accuracy
without alignment or contrastive loss.

</details>


### [390] [ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data](https://arxiv.org/abs/2506.23520)
*Yu Zhang,Ruijie Yu,Jidong Tian,Feng Zhu,Jiapeng Liu,Xiaokang Yang,Yaohui Jin,Yanyan Xu*

Main category: cs.AI

Relevance: 60.0

TL;DR: ChemActor是一个基于LLM的化学执行器，用于将非结构化实验程序转换为结构化动作序列，通过LLM生成的数据框架和新的评估指标，在化学任务中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 有机化学中机器人合成的需求增加，但化学语言的模糊性和人工标注的高成本使得自动化提取化学程序具有挑战性。

Method: 提出一个顺序LLM生成的数据框架，包括基于分布差异的数据选择模块和多轮LLM循环审查指标，结合通用LLM生成机器可执行动作。

Result: 在R2D和D2A任务中，ChemActor比基线模型性能提升10%，达到SOTA。

Conclusion: ChemActor通过LLM生成的数据和新的评估指标，成功解决了化学程序自动化提取的挑战。

Abstract: With the increasing interest in robotic synthesis in the context of organic
chemistry, the automated extraction of chemical procedures from literature is
critical. However, this task remains challenging due to the inherent ambiguity
of chemical language and the high cost of human annotation required for
developing reliable computer-aided extraction protocols. Here, we present
ChemActor, a fully fine-tuned large language model (LLM), as a chemical
executor to convert between unstructured experimental procedures and structured
action sequences. We propose a sequential LLM-generated data framework to
address the challenges of insufficient and low-quality annotated data. This
framework integrates a data selection module that selects data based on
distribution divergence, with a general-purpose LLM, to generate
machine-executable actions from a single molecule input. Additionally, we
introduce a novel multi-round LLMs circle review metric, which reflects the
model's advanced understanding of chemical experimental procedures. Extensive
experiments on reaction-to-description (R2D) and description-to-action (D2A)
tasks demonstrate that ChemActor, augmented by LLM-generated data, achieves
state-of-the-art performance, outperforming the baseline model by 10%. The code
is available at: https://github.com/Zhanghahah/ChemActor.

</details>


### [391] [Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games](https://arxiv.org/abs/2506.23626)
*António Afonso,Iolanda Leite,Alessandro Sestini,Florian Fuchs,Konrad Tollmar,Linus Gisslén*

Main category: cs.AI

Relevance: 60.0

TL;DR: 论文提出了一种基于语言模型的自动奖励函数权重调整方法，用于强化学习代理在游戏中的迭代优化，无需人工干预。


<details>
  <summary>Details</summary>
Motivation: 解决游戏中强化学习代理在内容或机制修改后奖励函数权重不再最优的问题，减少对RL专家的依赖。

Method: 利用语言模型根据用户定义的行为目标和历史性能统计，迭代调整奖励函数权重。

Result: 在赛车任务中，LM引导的代理性能显著提升，从9%到74%成功率，最终达到80%成功率，接近专家调优的94%。

Conclusion: 该方法有效减少了人工奖励工程的需求，实现了代理行为的自动优化。

Abstract: Reinforcement Learning (RL) in games has gained significant momentum in
recent years, enabling the creation of different agent behaviors that can
transform a player's gaming experience. However, deploying RL agents in
production environments presents two key challenges: (1) designing an effective
reward function typically requires an RL expert, and (2) when a game's content
or mechanics are modified, previously tuned reward weights may no longer be
optimal. Towards the latter challenge, we propose an automated approach for
iteratively fine-tuning an RL agent's reward function weights, based on a
user-defined language based behavioral goal. A Language Model (LM) proposes
updated weights at each iteration based on this target behavior and a summary
of performance statistics from prior training rounds. This closed-loop process
allows the LM to self-correct and refine its output over time, producing
increasingly aligned behavior without the need for manual reward engineering.
We evaluate our approach in a racing task and show that it consistently
improves agent performance across iterations. The LM-guided agents show a
significant increase in performance from $9\%$ to $74\%$ success rate in just
one iteration. We compare our LM-guided tuning against a human expert's manual
weight design in the racing task: by the final iteration, the LM-tuned agent
achieved an $80\%$ success rate, and completed laps in an average of $855$ time
steps, a competitive performance against the expert-tuned agent's peak $94\%$
success, and $850$ time steps.

</details>


### [392] [Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center](https://arxiv.org/abs/2506.22523)
*James Wen,Sahil Nalawade,Zhiwei Liang,Catherine Bielick,Marisa Ferrara Boston,Alexander Chowdhury,Adele Collin,Luigi De Angelis,Jacob Ellen,Heather Frase,Rodrigo R. Gameiro,Juan Manuel Gutierrez,Pooja Kadam,Murat Keceli,Srikanth Krishnamurthy,Anne Kwok,Yanan Lance Lu,Heather Mattie,Liam G. McCoy,Katherine Miller,Allison C. Morgan,Marlene Louisa Moerig,Trang Nguyen,Alexander Owen-Post,Alex D. Ruiz,Sreekar Reddy Puchala,Soujanya Samineni,Takeshi Tohyama,Varun Ullanat,Carmine Valenza,Camilo Velez,Pengcheng Wang,Anna Wuest,Yuxiang Zhou,Yingde Zhu,Jason M. Johnson,Jennifer Willcox,Francis J. Vitiello,Leo Anthony G. Celi,Renato Umeton*

Main category: cs.CY

Relevance: 60.0

TL;DR: 论文研究了GPT4DFCI工具是否输出受版权保护的数据，发现模型能复制部分书籍内容，但无法复制新闻、科学文章或电子健康记录。


<details>
  <summary>Details</summary>
Motivation: 评估生成式AI工具在法律和伦理使用中的边界，确保其不侵犯版权。

Method: 通过红队测试，尝试让GPT4DFCI复制书籍、新闻、科学文章和电子健康记录的内容。

Result: 模型能复制部分书籍内容，但无法复制其他目标内容，且存在捏造现象。

Conclusion: 提出了缓解策略并部署到新版本中，呼吁更多类似测试以确保AI工具的合法性和伦理性。

Abstract: Generative AI is present in multiple industries. Dana-Farber Cancer
Institute, in partnership with Microsoft, has created an internal AI tool,
GPT4DFCI. Together we hosted a red teaming event to assess whether the
underlying GPT models that support the tool would output copyrighted data. Our
teams focused on reproducing content from books, news articles, scientific
articles, and electronic health records. We found isolated instances where
GPT4DFCI was able to identify copyrighted material and reproduce exact quotes
from famous books which indicates that copyrighted material was in the training
data. The model was not able to reproduce content from our target news article,
scientific article, or electronic health records. However, there were instances
of fabrication. As a result of this event, a mitigation strategy is in
production in GPT4DFCI v2.8.2, deployed on January 21, 2025. We hope this
report leads to similar events in which AI software tools are stress-tested to
assess the perimeter of their legal and ethical usage.

</details>


### [393] [P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code](https://arxiv.org/abs/2506.22703)
*Wali Mohammad Abdullah,Azmain Kabir*

Main category: cs.SE

Relevance: 60.0

TL;DR: P4OMP是一个基于检索增强的框架，利用LLM将串行C/C++代码转换为OpenMP并行代码，无需微调或编译器插桩。


<details>
  <summary>Details</summary>
Motivation: 提高LLM生成OpenMP代码的可靠性和适用性，避免常见的语法错误和无效指令组合。

Method: 采用检索增强生成（RAG）技术，结合OpenMP教程的结构化知识，优化提示驱动的代码生成。

Result: 在108个真实C++程序测试中，P4OMP实现100%编译成功率，优于基线GPT-3.5-Turbo。

Conclusion: P4OMP显著提升了LLM生成OpenMP代码的可靠性和实用性。

Abstract: We present P4OMP, a retrieval-augmented framework for transforming serial
C/C++ code into OpenMP-annotated parallel code using large language models
(LLMs). To our knowledge, this is the first system to apply retrieval-based
prompting for OpenMP pragma correctness without model fine-tuning or compiler
instrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with
structured instructional knowledge from OpenMP tutorials to improve the
reliability of prompt-driven code generation. By grounding generation in the
retrieved context, P4OMP improves syntactic correctness compared to baseline
prompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline,
GPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world
C++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites.
P4OMP achieves 100% compilation success on all parallelizable cases, while the
baseline fails to compile in 20 out of 108 cases. Six cases that rely on
non-random-access iterators or thread-unsafe constructs are excluded due to
fundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP
consistently avoids scoping errors, syntactic misuse, and invalid directive
combinations that commonly affect baseline-generated code. We further
demonstrate strong runtime scaling across seven compute-intensive benchmarks on
an HPC cluster. P4OMP offers a robust, modular pipeline that significantly
improves the reliability and applicability of LLM-generated OpenMP code.

</details>


### [394] [Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks](https://arxiv.org/abs/2506.22722)
*Anmin Fu,Fanyu Meng,Huaibing Peng,Hua Ma,Zhi Zhang,Yifeng Zheng,Willy Susilo,Yansong Gao*

Main category: cs.CR

Relevance: 60.0

TL;DR: UniGuard是一个统一的在线检测框架，能够同时检测对抗性示例和后门攻击，通过分析输入在模型中的传播轨迹差异来实现高效检测。


<details>
  <summary>Details</summary>
Motivation: 对抗性示例（AE）和后门攻击都会在推理阶段对模型造成威胁，但现有方法通常只能单独处理其中一种攻击。UniGuard旨在通过统一框架同时解决这两种问题。

Method: UniGuard将输入在模型中的传播轨迹视为时间序列信号，利用LSTM和频谱变换放大对抗性和良性轨迹的差异。

Result: UniGuard在多种模态（图像、文本、音频）和任务（分类和回归）中表现出色，优于现有针对AE或后门攻击的SOTA方法。

Conclusion: UniGuard是一种高效且通用的检测框架，能够同时应对多种攻击策略，填补了现有方法的局限性。

Abstract: The proposed UniGuard is the first unified online detection framework capable
of simultaneously addressing adversarial examples and backdoor attacks.
UniGuard builds upon two key insights: first, both AE and backdoor attacks have
to compromise the inference phase, making it possible to tackle them
simultaneously during run-time via online detection. Second, an adversarial
input, whether a perturbed sample in AE attacks or a trigger-carrying sample in
backdoor attacks, exhibits distinctive trajectory signatures from a benign
sample as it propagates through the layers of a DL model in forward inference.
The propagation trajectory of the adversarial sample must deviate from that of
its benign counterpart; otherwise, the adversarial objective cannot be
fulfilled. Detecting these trajectory signatures is inherently challenging due
to their subtlety; UniGuard overcomes this by treating the propagation
trajectory as a time-series signal, leveraging LSTM and spectrum transformation
to amplify differences between adversarial and benign trajectories that are
subtle in the time domain. UniGuard exceptional efficiency and effectiveness
have been extensively validated across various modalities (image, text, and
audio) and tasks (classification and regression), ranging from diverse model
architectures against a wide range of AE attacks and backdoor attacks,
including challenging partial backdoors and dynamic triggers. When compared to
SOTA methods, including ContraNet (NDSS 22) specific for AE detection and TED
(IEEE SP 24) specific for backdoor detection, UniGuard consistently
demonstrates superior performance, even when matched against each method's
strengths in addressing their respective threats-each SOTA fails to parts of
attack strategies while UniGuard succeeds for all.

</details>


### [395] [WavShape: Information-Theoretic Speech Representation Learning for Fair and Privacy-Aware Audio Processing](https://arxiv.org/abs/2506.22789)
*Oguzhan Baser,Ahmet Ege Tanriverdi,Kaan Kale,Sandeep P. Chinchali,Sriram Vishwanath*

Main category: cs.SD

Relevance: 60.0

TL;DR: WavShape是一个基于信息论的语音表示学习框架，通过优化嵌入以实现公平性和隐私保护，同时保留任务相关信息。


<details>
  <summary>Details</summary>
Motivation: 语音嵌入通常保留敏感属性（如说话者身份、口音或人口统计信息），可能导致模型训练偏差和隐私泄露。

Method: 利用Donsker-Varadhan公式的互信息估计，指导基于互信息的编码器，系统性地过滤敏感属性，同时保留下游任务所需的语音内容。

Result: 在三个已知数据集上，WavShape将嵌入与敏感属性之间的互信息减少了81%，同时保留了97%的任务相关信息。

Conclusion: 通过将信息论与自监督语音模型结合，推动了公平、隐私感知且资源高效的语音系统的发展。

Abstract: Speech embeddings often retain sensitive attributes such as speaker identity,
accent, or demographic information, posing risks in biased model training and
privacy leakage. We propose WavShape, an information-theoretic speech
representation learning framework that optimizes embeddings for fairness and
privacy while preserving task-relevant information. We leverage mutual
information (MI) estimation using the Donsker-Varadhan formulation to guide an
MI-based encoder that systematically filters sensitive attributes while
maintaining speech content essential for downstream tasks. Experimental results
on three known datasets show that WavShape reduces MI between embeddings and
sensitive attributes by up to 81% while retaining 97% of task-relevant
information. By integrating information theory with self-supervised speech
models, this work advances the development of fair, privacy-aware, and
resource-efficient speech systems.

</details>


### [396] [Against 'softmaxing' culture](https://arxiv.org/abs/2506.22968)
*Daniel Mwesigwa*

Main category: cs.HC

Relevance: 60.0

TL;DR: 论文探讨了AI模型如何同质化语言和文化，提出“softmaxing culture”概念，并建议从“when is culture”而非“what is culture”出发，改进文化评估方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示AI模型对文化的同质化影响，并推动更复杂的文化评估方法。

Method: 提出两个关键转变：1）从“when is culture”出发；2）将文化普遍性与特殊性结合。

Result: 指出当前ML和HCI评估方法的局限性，并提出更响应文化复杂性的评估视角。

Conclusion: 结论是需要超越技术需求，采用更全面的文化评估方法。

Abstract: AI is flattening culture. Evaluations of "culture" are showing the myriad
ways in which large AI models are homogenizing language and culture, averaging
out rich linguistic differences into generic expressions. I call this
phenomenon "softmaxing culture," and it is one of the fundamental challenges
facing AI evaluations today. Efforts to improve and strengthen evaluations of
culture are central to the project of cultural alignment in large AI systems.
This position paper argues that machine learning (ML) and human-computer
interaction (HCI) approaches to evaluation are limited. I propose two key
shifts. First, instead of asking "what is culture?" at the start of system
evaluations, I propose beginning with the question: "when is culture?" Second,
while I acknowledge the philosophical claim that cultural universals exist, the
challenge is not simply to describe them, but to situate them in relation to
their particulars. Taken together, these conceptual shifts invite evaluation
approaches that move beyond technical requirements, toward perspectives more
responsive to the complexities of culture.

</details>


### [397] [Generating Privacy Stories From Software Documentation](https://arxiv.org/abs/2506.23014)
*Wilder Baldwin,Shashank Chintakuntla,Shreyah Parajuli,Ali Pourghasemi,Ryan Shanz,Sepideh Ghanavati*

Main category: cs.SE

Relevance: 60.0

TL;DR: 论文提出了一种基于CoT、ICL和LLMs的新方法，用于从软件文档中提取隐私行为并生成隐私需求，结果显示常用LLMs（如GPT-4o和Llama 3）表现优异，F1分数超过0.8。


<details>
  <summary>Details</summary>
Motivation: 当前隐私需求常被视为安全概念或事后考虑，导致合规性问题。现有方法多关注法规合规性，缺乏对隐私行为的早期提取。

Method: 结合链式思维提示（CoT）、上下文学习（ICL）和大型语言模型（LLMs），从软件文档中提取隐私行为并生成用户故事形式的隐私需求。

Result: 常用LLMs（如GPT-4o和Llama 3）在提取隐私行为和生成需求任务中表现优异（F1>0.8），参数调优可进一步提升性能。

Conclusion: 该方法为在软件开发周期中利用和优化LLMs生成隐私需求提供了新思路。

Abstract: Research shows that analysts and developers consider privacy as a security
concept or as an afterthought, which may lead to non-compliance and violation
of users' privacy. Most current approaches, however, focus on extracting legal
requirements from the regulations and evaluating the compliance of software and
processes with them. In this paper, we develop a novel approach based on
chain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language
Models (LLMs) to extract privacy behaviors from various software documents
prior to and during software development, and then generate privacy
requirements in the format of user stories. Our results show that most commonly
used LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and
generate privacy user stories with F1 scores exceeding 0.8. We also show that
the performance of these models could be improved through parameter-tuning. Our
findings provide insight into using and optimizing LLMs for generating privacy
requirements given software documents created prior to or throughout the
software development lifecycle.

</details>


### [398] [Treatment, evidence, imitation, and chat](https://arxiv.org/abs/2506.23040)
*Samuel J. Weisenthal*

Main category: stat.OT

Relevance: 60.0

TL;DR: 论文探讨了大型语言模型（LLM）在医疗决策中的潜在应用，重点分析了治疗问题和聊天问题的差异，并讨论了LLM在解决治疗问题时的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在医疗决策中的潜力，特别是如何辅助解决治疗问题，并探讨其与证据医学的关系。

Method: 通过分析治疗问题和聊天问题的差异，探讨LLM在医疗决策中的应用，并识别相关挑战。

Result: 研究发现LLM在医疗决策中具有潜力，但也面临与证据医学相关的挑战。

Conclusion: LLM在医疗决策中的应用需要进一步研究，尤其是在证据医学框架下解决挑战。

Abstract: Large language models are thought to have potential to aid in medical
decision making. We investigate this here. We start with the treatment problem,
the patient's core medical decision-making task, which is solved in
collaboration with a healthcare provider. We discuss approaches to solving the
treatment problem, including -- within evidence-based medicine -- trials and
observational data. We then discuss the chat problem, and how this differs from
the treatment problem -- in particular as it relates to imitation. We then
discuss how a large language model might be used to solve the treatment problem
and highlight some of the challenges that emerge. We finally discuss how these
challenges relate to evidence-based medicine, and how this might inform next
steps.

</details>


### [399] [TOMI: Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure](https://arxiv.org/abs/2506.23094)
*Qi He,Gus Xia,Ziyu Wang*

Main category: cs.SD

Relevance: 60.0

TL;DR: 论文提出TOMI方法，通过指令调优的基础LLM生成多轨电子音乐，强调概念层次和结构连贯性。


<details>
  <summary>Details</summary>
Motivation: 探索音乐生成中的概念层次，通过结构化和交互式方法提升音乐质量和创作效率。

Method: 利用指令调优的基础LLM，在四维空间（片段、段落、轨道、变换）中建模多轨音乐生成过程。

Result: 实验表明，TOMI方法生成的电子音乐质量更高，结构更连贯。

Conclusion: TOMI方法为音乐生成提供了新思路，结合人类创作可实现高效交互。

Abstract: Hierarchical planning is a powerful approach to model long sequences
structurally. Aside from considering hierarchies in the temporal structure of
music, this paper explores an even more important aspect: concept hierarchy,
which involves generating music ideas, transforming them, and ultimately
organizing them--across musical time and space--into a complete composition. To
this end, we introduce TOMI (Transforming and Organizing Music Ideas) as a
novel approach in deep music generation and develop a TOMI-based model via
instruction-tuned foundation LLM. Formally, we represent a multi-track
composition process via a sparse, four-dimensional space characterized by clips
(short audio or MIDI segments), sections (temporal positions), tracks
(instrument layers), and transformations (elaboration methods). Our model is
capable of generating multi-track electronic music with full-song structure,
and we further integrate the TOMI-based model with the REAPER digital audio
workstation, enabling interactive human-AI co-creation. Experimental results
demonstrate that our approach produces higher-quality electronic music with
stronger structural coherence compared to baselines.

</details>


### [400] [QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration](https://arxiv.org/abs/2506.23644)
*Junze Hu,Xiangyu Jin,Yizhe Zeng,Yuling Liu,Yunpeng Li,Dan Du,Kaiyu Xie,Hongsong Zhu*

Main category: cs.SE

Relevance: 60.0

TL;DR: QLPro是一个结合LLMs和静态分析工具的漏洞检测框架，显著提升了漏洞检测能力，并在新数据集JavaTest上表现优于CodeQL。


<details>
  <summary>Details</summary>
Motivation: 现有静态分析工具（如CodeQL）在漏洞检测方面存在局限性，需要更全面、高效的解决方案。

Method: QLPro系统性地整合LLMs和静态分析工具，构建新数据集JavaTest进行评估。

Result: QLPro检测到41个漏洞（CodeQL仅检测到24个），并发现6个新漏洞，其中2个为0-day漏洞。

Conclusion: QLPro在漏洞检测方面表现出色，具有实际应用潜力。

Abstract: We introduce QLPro, a vulnerability detection framework that systematically
integrates LLMs and static analysis tools to enable comprehensive vulnerability
detection across entire open-source projects.We constructed a new dataset,
JavaTest, comprising 10 open-source projects from GitHub with 62 confirmed
vulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only
24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro
discovered 6 previously unknown vulnerabilities, 2 of which have been confirmed
as 0-days.

</details>


### [401] [QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference](https://arxiv.org/abs/2506.23934)
*Xiangchen Li,Saeid Ghafouri,Bo Ji,Hans Vandierendonck,Deepu John,Dimitrios S. Nikolopoulos*

Main category: cs.DC

Relevance: 60.0

TL;DR: 论文提出了一种针对边缘设备的动态推理系统，结合模型量化和推理分区，优化计算负载和精度要求。


<details>
  <summary>Details</summary>
Motivation: 适应边缘设备的多样化计算能力和资源限制，提高推理效率和成本效益。

Method: 联合模型量化和推理分区，动态调整量化位宽和分区点，优化时间和成本。

Result: 计算负载减少80%以上，精度下降低于1%。

Conclusion: 该方法显著提升了边缘设备推理的效率和适应性。

Abstract: As machine learning inferences increasingly move to edge devices, adapting to
diverse computational capabilities, hardware, and memory constraints becomes
more critical. Instead of relying on a pre-trained model fixed for all future
inference queries across diverse edge devices, we argue that planning an
inference pattern with a request-specific model tailored to the device's
computational capacity, accuracy requirements, and time constraints is more
cost-efficient and robust to diverse scenarios. To this end, we propose an
accuracy-aware and workload-balanced inference system that integrates joint
model quantization and inference partitioning. In this approach, the server
dynamically responds to inference queries by sending a quantized model and
adaptively sharing the inference workload with the device. Meanwhile, the
device's computational power, channel capacity, and accuracy requirements are
considered when deciding.
  Furthermore, we introduce a new optimization framework for the inference
system, incorporating joint model quantization and partitioning. Our approach
optimizes layer-wise quantization bit width and partition points to minimize
time consumption and cost while accounting for varying accuracy requirements of
tasks through an accuracy degradation metric in our optimization model. To our
knowledge, this work represents the first exploration of optimizing
quantization layer-wise bit-width in the inference serving system, by
introducing theoretical measurement of accuracy degradation. Simulation results
demonstrate a substantial reduction in overall time and power consumption, with
computation payloads decreasing by over 80% and accuracy degradation kept below
1%.

</details>


### [402] [Autonomy by Design: Preserving Human Autonomy in AI Decision-Support](https://arxiv.org/abs/2506.23952)
*Stefan Buijsman,Sarah Carter,Juan Pablo Bermúdez*

Main category: cs.HC

Relevance: 60.0

TL;DR: 论文探讨了AI决策支持系统如何影响领域特定自主性，提出了一个保护自主性的框架。


<details>
  <summary>Details</summary>
Motivation: 研究AI对领域特定自主性的影响，填补现有研究的空白。

Method: 结合文献分析和实证案例（医疗、金融、教育领域），提出设计模式。

Result: 发现AI可能通过不可靠的失败指标和无意识价值转移削弱自主性。

Conclusion: 提出保护自主性的框架和设计模式，增强人类在专业领域的能动性。

Abstract: AI systems increasingly support human decision-making across domains of
professional, skill-based, and personal activity. While previous work has
examined how AI might affect human autonomy globally, the effects of AI on
domain-specific autonomy -- the capacity for self-governed action within
defined realms of skill or expertise -- remain understudied. We analyze how AI
decision-support systems affect two key components of domain-specific autonomy:
skilled competence (the ability to make informed judgments within one's domain)
and authentic value-formation (the capacity to form genuine domain-relevant
values and preferences). By engaging with prior investigations and analyzing
empirical cases across medical, financial, and educational domains, we
demonstrate how the absence of reliable failure indicators and the potential
for unconscious value shifts can erode domain-specific autonomy both
immediately and over time. We then develop a constructive framework for
autonomy-preserving AI support systems. We propose specific socio-technical
design patterns -- including careful role specification, implementation of
defeater mechanisms, and support for reflective practice -- that can help
maintain domain-specific autonomy while leveraging AI capabilities. This
framework provides concrete guidance for developing AI systems that enhance
rather than diminish human agency within specialized domains of action.

</details>


### [403] [Navigating with Annealing Guidance Scale in Diffusion Space](https://arxiv.org/abs/2506.24108)
*Shai Yehezkel,Omer Dahary,Andrey Voynov,Daniel Cohen-Or*

Main category: cs.GR

Relevance: 60.0

TL;DR: 提出了一种动态调整引导尺度的调度器，以改进基于文本提示的图像生成质量和对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的无分类器引导（CFG）方法在生成图像时对引导尺度的选择敏感，影响图像质量和提示对齐。

Method: 设计了一种基于条件噪声信号的动态引导尺度调度器，无需额外计算资源。

Result: 实验表明，该方法显著提升了图像质量和文本提示对齐，且无需额外内存或计算开销。

Conclusion: 提出的调度器改进了文本到图像生成的性能，平衡了提示对齐和图像质量。

Abstract: Denoising diffusion models excel at generating high-quality images
conditioned on text prompts, yet their effectiveness heavily relies on careful
guidance during the sampling process. Classifier-Free Guidance (CFG) provides a
widely used mechanism for steering generation by setting the guidance scale,
which balances image quality and prompt alignment. However, the choice of the
guidance scale has a critical impact on the convergence toward a visually
appealing and prompt-adherent image. In this work, we propose an annealing
guidance scheduler which dynamically adjusts the guidance scale over time based
on the conditional noisy signal. By learning a scheduling policy, our method
addresses the temperamental behavior of CFG. Empirical results demonstrate that
our guidance scheduler significantly enhances image quality and alignment with
the text prompt, advancing the performance of text-to-image generation.
Notably, our novel scheduler requires no additional activations or memory
consumption, and can seamlessly replace the common classifier-free guidance,
offering an improved trade-off between prompt alignment and quality.

</details>


### [404] [Bootstrapping Human-Like Planning via LLMs](https://arxiv.org/abs/2506.22604)
*David Porfirio,Vincent Hsiao,Morgan Fine-Morris,Leslie Smith,Laura M. Hiatt*

Main category: cs.AI

Relevance: 50.0

TL;DR: 论文探讨了结合自然语言和拖拽界面生成机器人任务序列的方法，使用LLM将自然语言输入转化为人类级别的动作序列。


<details>
  <summary>Details</summary>
Motivation: 研究如何结合自然语言和拖拽界面的优势，为机器人任务提供更直观且精确的编程方式。

Method: 构建基于LLM的流程，将自然语言输入转化为人类级别的动作序列，并与手工指定的动作序列进行比较。

Result: 较大模型在生成人类级别动作序列上表现更优，但较小模型也能达到满意效果。

Conclusion: LLM可用于结合自然语言和拖拽界面的优势，生成精确的机器人任务序列。

Abstract: Robot end users increasingly require accessible means of specifying tasks for
robots to perform. Two common end-user programming paradigms include
drag-and-drop interfaces and natural language programming. Although natural
language interfaces harness an intuitive form of human communication,
drag-and-drop interfaces enable users to meticulously and precisely dictate the
key actions of the robot's task. In this paper, we investigate the degree to
which both approaches can be combined. Specifically, we construct a large
language model (LLM)-based pipeline that accepts natural language as input and
produces human-like action sequences as output, specified at a level of
granularity that a human would produce. We then compare these generated action
sequences to another dataset of hand-specified action sequences. Although our
results reveal that larger models tend to outperform smaller ones in the
production of human-like action sequences, smaller models nonetheless achieve
satisfactory performance.

</details>


### [405] [Ludax: A GPU-Accelerated Domain Specific Language for Board Games](https://arxiv.org/abs/2506.22609)
*Graham Todd,Alexander G. Padula,Dennis J. N. J. Soemers,Julian Togelius*

Main category: cs.AI

Relevance: 50.0

TL;DR: Ludax是一个用于棋盘游戏的领域特定语言，自动编译为硬件加速代码，结合了游戏描述语言的通用性和现代并行处理硬件的速度，旨在加速游戏研究。


<details>
  <summary>Details</summary>
Motivation: 支持游戏研究，特别是强化学习（RL），通过提供快速模拟和灵活的表示方案，加速算法开发和测试。

Method: 开发了一个领域特定语言（Ludax），自动编译为硬件加速代码，并集成到现有深度学习流程中。

Result: Ludax框架开源，提供了速度基准测试和RL代理训练演示，展示了其高效性和实用性。

Conclusion: Ludax有望成为加速游戏研究的工具，适用于从RL到认知科学的广泛领域。

Abstract: Games have long been used as benchmarks and testing environments for research
in artificial intelligence. A key step in supporting this research was the
development of game description languages: frameworks that compile
domain-specific code into playable and simulatable game environments, allowing
researchers to generalize their algorithms and approaches across multiple games
without having to manually implement each one. More recently, progress in
reinforcement learning (RL) has been largely driven by advances in hardware
acceleration. Libraries like JAX allow practitioners to take full advantage of
cutting-edge computing hardware, often speeding up training and testing by
orders of magnitude. Here, we present a synthesis of these strands of research:
a domain-specific language for board games which automatically compiles into
hardware-accelerated code. Our framework, Ludax, combines the generality of
game description languages with the speed of modern parallel processing
hardware and is designed to fit neatly into existing deep learning pipelines.
We envision Ludax as a tool to help accelerate games research generally, from
RL to cognitive science, by enabling rapid simulation and providing a flexible
representation scheme. We present a detailed breakdown of Ludax's description
language and technical notes on the compilation process, along with speed
benchmarking and a demonstration of training RL agents. The Ludax framework,
along with implementations of existing board games, is open-source and freely
available.

</details>


### [406] [The Impact of AI on Educational Assessment: A Framework for Constructive Alignment](https://arxiv.org/abs/2506.23815)
*Patrick Stokkink*

Main category: cs.HC

Relevance: 50.0

TL;DR: 论文探讨了AI（尤其是LLM）对教育的影响，提出基于Constructive Alignment理论和Bloom分类法的框架，建议调整评估方法以适应AI的使用，并强调教师培训的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究AI（特别是LLM）在教育中的日益增长的影响，以及如何调整评估方法以保持其有效性。

Method: 基于Constructive Alignment理论和Bloom分类法，分析AI对不同学习目标的影响，并提出评估方法的调整建议。

Result: 发现教师对AI在评估中的使用存在偏见，建议制定结构化指南并提供教师培训。

Conclusion: 教育评估需适应AI的影响，教师培训是确保评估公平的关键。

Abstract: The influence of Artificial Intelligence (AI), and specifically Large
Language Models (LLM), on education is continuously increasing. These models
are frequently used by students, giving rise to the question whether current
forms of assessment are still a valid way to evaluate student performance and
comprehension. The theoretical framework developed in this paper is grounded in
Constructive Alignment (CA) theory and Bloom's taxonomy for defining learning
objectives. We argue that AI influences learning objectives of different Bloom
levels in a different way, and assessment has to be adopted accordingly.
Furthermore, in line with Bloom's vision, formative and summative assessment
should be aligned on whether the use of AI is permitted or not.
  Although lecturers tend to agree that education and assessment need to be
adapted to the presence of AI, a strong bias exists on the extent to which
lecturers want to allow for AI in assessment. This bias is caused by a
lecturer's familiarity with AI and specifically whether they use it themselves.
To avoid this bias, we propose structured guidelines on a university or faculty
level, to foster alignment among the staff. Besides that, we argue that
teaching staff should be trained on the capabilities and limitations of AI
tools. In this way, they are better able to adapt their assessment methods.

</details>


### [407] [Agentic Enterprise: AI-Centric User to User-Centric AI](https://arxiv.org/abs/2506.22893)
*Arpit Narechania,Alex Endert,Atanu R Sinha*

Main category: cs.AI

Relevance: 40.0

TL;DR: 本文探讨了AI在企业决策中的潜力，提出了六项原则以推动Agentic成功，并强调了从AI中心向用户中心AI的转变。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于利用AI提升企业决策效率，弥补当前AI中心范式在企业决策中的不足。

Method: 通过分析企业决策需求，提出六项Agentic成功原则，并倡导市场机制以支持用户中心AI的设计与交付。

Result: 提出了六项原则，强调用户中心AI的重要性，并建议通过市场机制实现AI与Agent的优化设计。

Conclusion: 结论是用户中心AI和六项原则可有效提升企业决策效率，市场机制是实现这一目标的关键。

Abstract: After a very long winter, the Artificial Intelligence (AI) spring is here.
Or, so it seems over the last three years. AI has the potential to impact many
areas of human life - personal, social, health, education, professional. In
this paper, we take a closer look at the potential of AI for Enterprises, where
decision-making plays a crucial and repeated role across functions, tasks, and
operations. We consider Agents imbued with AI as means to increase
decision-productivity of enterprises. We highlight six tenets for Agentic
success in enterprises, by drawing attention to what the current, AI-Centric
User paradigm misses, in the face of persistent needs of and usefulness for
Enterprise Decision-Making. In underscoring a shift to User-Centric AI, we
offer six tenets and promote market mechanisms for platforms, aligning the
design of AI and its delivery by Agents to the cause of enterprise users.

</details>


### [408] [Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing](https://arxiv.org/abs/2506.23141)
*Siyuan Li,Ruitong Liu,Yan Wen,Te Sun*

Main category: cs.AI

Relevance: 40.0

TL;DR: 提出了一种语义感知的关系消息传递框架，通过Top-K邻居选择策略和多头注意力聚合器，提升知识图谱补全任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于节点的消息传递机制在知识图谱中会引入噪声和信息稀释问题，需要更精准的语义上下文捕捉方法。

Method: 引入语义感知的Top-K邻居选择策略和多头注意力聚合器，选择并融合最相关的邻居信息。

Result: 在多个基准测试中表现优于现有方法。

Conclusion: 该方法能有效减少无关信息干扰，提升知识图谱补全的准确性。

Abstract: Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge
Graph Completion (KGC), providing vital cues for prediction. However,
traditional node-based message passing mechanisms, when applied to knowledge
graphs, often introduce noise and suffer from information dilution or
over-smoothing by indiscriminately aggregating information from all neighboring
edges. To address this challenge, we propose a semantic-aware relational
message passing. A core innovation of this framework is the introduction of a
\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this
strategy first evaluates the semantic relevance between a central node and its
incident edges within a shared latent space, selecting only the Top-K most
pertinent ones. Subsequently, information from these selected edges is
effectively fused with the central node's own representation using a
\textbf{multi-head attention aggregator} to generate a semantically focused
node message. In this manner, our model not only leverages the structure and
features of edges within the knowledge graph but also more accurately captures
and propagates the contextual information most relevant to the specific link
prediction task, thereby effectively mitigating interference from irrelevant
information. Extensive experiments demonstrate that our method achieves
superior performance compared to existing approaches on several established
benchmarks.

</details>


### [409] [GATSim: Urban Mobility Simulation with Generative Agents](https://arxiv.org/abs/2506.23306)
*Qi Liu,Can Li,Wanjing Ma*

Main category: cs.AI

Relevance: 40.0

TL;DR: GATSim利用大型语言模型和AI代理技术，创建具有推理能力和自适应学习机制的生成代理，用于城市交通模拟。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的交通模拟无法捕捉人类旅行决策的复杂性和多样性，GATSim旨在通过生成代理解决这一问题。

Method: 结合城市交通基础模型、代理认知系统和交通模拟环境，开发了GATSim框架，并实现了一个功能原型。

Result: 实验表明，生成代理在交通场景中表现与人类标注者相当，并能自然生成宏观交通演化模式。

Conclusion: GATSim通过生成代理实现了更真实的城市交通模拟，展示了AI代理技术在复杂系统建模中的潜力。

Abstract: Traditional agent-based urban mobility simulations rely on rigid rule-based
systems that fail to capture the complexity, adaptability, and behavioral
diversity characteristic of human travel decision-making. Recent advances in
large language models and AI agent technology offer opportunities to create
agents with reasoning capabilities, persistent memory, and adaptive learning
mechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel
framework that leverages these advances to create generative agents with rich
behavioral characteristics for urban mobility simulation. Unlike conventional
approaches, GATSim agents possess diverse socioeconomic attributes, individual
lifestyles, and evolving preferences that shape their mobility decisions
through psychologically-informed memory systems, tool usage capabilities, and
lifelong learning mechanisms. The main contributions of this study include: (1)
a comprehensive architecture combining an urban mobility foundation model with
agent cognitive systems and transport simulation environment, (2) a fully
functional prototype implementation, and (3) systematic validation
demonstrating that generative agents produce believable travel behaviors.
Through designed reflection processes, generative agents in this study can
transform specific travel experiences into generalized insights, enabling
realistic behavioral adaptation over time with specialized mechanisms for
activity planning and real-time reactive behaviors tailored to urban mobility
contexts. Experiments show that generative agents perform competitively with
human annotators in mobility scenarios while naturally producing macroscopic
traffic evolution patterns. The code for the prototype system is shared at
https://github.com/qiliuchn/gatsim.

</details>


### [410] [CooT: Learning to Coordinate In-Context with Coordination Transformers](https://arxiv.org/abs/2506.23549)
*Huai-Chih Wang,Hsiang-Chun Chuang,Hsi-Chun Cheng,Dai-Jie Wu,Shao-Hua Sun*

Main category: cs.AI

Relevance: 40.0

TL;DR: 提出了Coordination Transformers (CooT)，一种基于上下文的多智能体协调框架，通过历史交互快速适应新伙伴。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中动态和不确定环境下协调的挑战，现有方法泛化能力差或训练成本高。

Method: 使用交互历史预测新伙伴行为，无需显式监督或微调。

Result: 在Overcooked基准测试中显著优于基线方法，人类评估也证实其有效性。

Conclusion: CooT在多智能体场景中表现出鲁棒性、灵活性和上下文敏感性。

Abstract: Effective coordination among artificial agents in dynamic and uncertain
environments remains a significant challenge in multi-agent systems. Existing
approaches, such as self-play and population-based methods, either generalize
poorly to unseen partners or require extensive training. To overcome these
limitations, we propose Coordination Transformers (CooT), a novel in-context
coordination framework that uses recent interaction histories to adapt to
unseen partners rapidly. Unlike previous approaches that primarily aim to
increase the diversity of training partners, CooT explicitly focuses on
adapting to new partner behaviors by predicting actions aligned with observed
partner interactions. Trained on interaction trajectories collected from
diverse pairs of agents with complementary behaviors, CooT quickly learns
effective coordination strategies without explicit supervision or fine-tuning.
Evaluations on the Overcooked benchmark demonstrate that CooT significantly
outperforms baseline methods in coordination tasks involving previously unseen
partners. Human evaluations further confirm CooT as the most effective
collaborative partner, while extensive ablations highlight its robustness,
flexibility, and sensitivity to context in multi-agent scenarios.

</details>


### [411] [When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)](https://arxiv.org/abs/2506.23784)
*Parosh Aziz Abdulla,Mohamed Faouzi Atig,Julie Cailler,Chencheng Liang,Philipp Rümmer*

Main category: cs.AI

Relevance: 40.0

TL;DR: 使用图神经网络（GNN）对词方程进行排序，以提高求解效率。


<details>
  <summary>Details</summary>
Motivation: 在求解词方程时，处理顺序对性能影响显著，传统方法缺乏全局视角。

Method: 提出基于图的词方程表示方法，利用GNN进行排序，并结合最小不可满足子集（MUS）训练。

Result: 在变量出现次数受限的基准测试中，新框架优于现有求解器。

Conclusion: GNN结合全局信息可有效提升词方程求解性能。

Abstract: Nielsen transformation is a standard approach for solving word equations: by
repeatedly splitting equations and applying simplification steps, equations are
rewritten until a solution is reached. When solving a conjunction of word
equations in this way, the performance of the solver will depend considerably
on the order in which equations are processed. In this work, the use of Graph
Neural Networks (GNNs) for ranking word equations before and during the solving
process is explored. For this, a novel graph-based representation for word
equations is presented, preserving global information across conjuncts,
enabling the GNN to have a holistic view during ranking. To handle the variable
number of conjuncts, three approaches to adapt a multi-classification task to
the problem of ranking equations are proposed. The training of the GNN is done
with the help of minimum unsatisfiable subsets (MUSes) of word equations. The
experimental results show that, compared to state-of-the-art string solvers,
the new framework solves more problems in benchmarks where each variable
appears at most once in each equation.

</details>


### [412] [Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning](https://arxiv.org/abs/2506.23793)
*Anton Andreychuk,Konstantin Yakovlev,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

Relevance: 40.0

TL;DR: 论文提出了一种名为MAPF-GPT-DDG的新方法，通过微调预训练的MAPF模型并利用delta-data生成机制，显著提升了多智能体路径规划（MAPF）的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体路径规划（MAPF）问题在现实应用中的可扩展性和效率需求，尤其是在大规模场景下。

Method: 基于预训练的MAPF-GPT模型，引入delta-data生成机制进行微调，结合集中式专家数据优化性能。

Result: MAPF-GPT-DDG在测试中超越了所有现有基于学习的MAPF求解器，支持单环境中多达100万智能体的路径规划。

Conclusion: MAPF-GPT-DDG为MAPF领域设定了新的可扩展性里程碑，展示了机器学习在复杂规划问题中的潜力。

Abstract: Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot
trajectory planning problems, where multiple homogeneous robots simultaneously
move in the shared environment. While solving MAPF optimally has been proven to
be NP-hard, scalable, and efficient, solvers are vital for real-world
applications like logistics, search-and-rescue, etc. To this end, decentralized
suboptimal MAPF solvers that leverage machine learning have come on stage.
Building on the success of the recently introduced MAPF-GPT, a pure imitation
learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively
fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging
a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training
while significantly improving performance at test time. Our experiments
demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF
solvers, including the original MAPF-GPT, regarding solution quality across
many testing scenarios. Remarkably, it can work with MAPF instances involving
up to 1 million agents in a single environment, setting a new milestone for
scalability in MAPF domains.

</details>


### [413] [Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system](https://arxiv.org/abs/2506.23926)
*Junping Wang,Bicheng Wang,Yibo Xuea,Yuan Xie*

Main category: cs.AI

Relevance: 40.0

TL;DR: 提出了一种名为“工业大脑”的框架，结合高阶神经网络和符号推理，用于预测和规划工业链的韧性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在复杂混沌数据下对网络拓扑韧性的预测和规划表现不佳，需要一种更通用的解决方案。

Method: 结合高阶活动驱动神经网络和CT-OODA符号推理，直接从观测数据中自主规划韧性。

Result: 工业大脑在韧性预测和规划上显著优于GoT、OlaGPT和谱降维方法，准确率提升达10.8%和11.03%。

Conclusion: 工业大脑填补了工业链韧性预测和规划的重要空白，具有鲁棒性和泛化能力。

Abstract: Resilience non-equilibrium measurement, the ability to maintain fundamental
functionality amidst failures and errors, is crucial for scientific management
and engineering applications of industrial chain. The problem is particularly
challenging when the number or types of multiple co-evolution of resilience
(for example, randomly placed) are extremely chaos. Existing end-to-end deep
learning ordinarily do not generalize well to unseen full-feld reconstruction
of spatiotemporal co-evolution structure, and predict resilience of network
topology, especially in multiple chaos data regimes typically seen in
real-world applications. To address this challenge, here we propose industrial
brain, a human-like autonomous cognitive decision-making and planning framework
integrating higher-order activity-driven neuro network and CT-OODA symbolic
reasoning to autonomous plan resilience directly from observational data of
global variable. The industrial brain not only understands and model structure
of node activity dynamics and network co-evolution topology without simplifying
assumptions, and reveal the underlying laws hidden behind complex networks, but
also enabling accurate resilience prediction, inference, and planning.
Experimental results show that industrial brain significantly outperforms
resilience prediction and planning methods, with an accurate improvement of up
to 10.8\% over GoT and OlaGPT framework and 11.03\% over spectral dimension
reduction. It also generalizes to unseen topologies and dynamics and maintains
robust performance despite observational disturbances. Our findings suggest
that industrial brain addresses an important gap in resilience prediction and
planning for industrial chain.

</details>


### [414] [Harnessing AI Agents to Advance Research on Refugee Child Mental Health](https://arxiv.org/abs/2506.23992)
*Aditya Shrivastava,Komal Gupta,Shraddha Arora*

Main category: cs.AI

Relevance: 40.0

TL;DR: 论文提出了一个基于AI的框架，用于处理难民健康数据并分析儿童心理健康，比较了Zephyr-7B-beta和DeepSeek R1-7B两种RAG模型，发现DeepSeek R1表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决难民儿童心理健康问题，利用AI技术处理复杂的人道主义数据。

Method: 比较两种RAG模型（Zephyr-7B-beta和DeepSeek R1-7B）在难民健康数据处理中的表现。

Result: DeepSeek R1在答案相关性上表现更优，准确率为0.91。

Conclusion: 结合AI与人道主义研究，为政策制定者和心理健康从业者提供可扩展的解决方案。

Abstract: The international refugee crisis deepens, exposing millions of dis placed
children to extreme psychological trauma. This research suggests a com pact,
AI-based framework for processing unstructured refugee health data and
distilling knowledge on child mental health. We compare two Retrieval-Aug
mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to
determine how well they process challenging humanitarian datasets while avoid
ing hallucination hazards. By combining cutting-edge AI methods with migration
research and child psychology, this study presents a scalable strategy to
assist policymakers, mental health practitioners, and humanitarian agencies to
better assist displaced children and recognize their mental wellbeing. In
total, both the models worked properly but significantly Deepseek R1 is
superior to Zephyr with an accuracy of answer relevance 0.91

</details>


### [415] [Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI](https://arxiv.org/abs/2506.22477)
*Huiwen Han*

Main category: cs.NI

Relevance: 40.0

TL;DR: 论文提出了一种基于物联网架构的机器人操作平台设计，整合了LLMs、生成式AI、边缘计算和5G网络，展示了其在智能制造业、医疗和服务业中的潜力。


<details>
  <summary>Details</summary>
Motivation: 提升物联网系统和机器人的智能与自主性，使其能实时决策并动态适应环境变化。

Method: 通过整合LLMs、生成式AI、边缘计算和5G网络，设计机器人操作平台，并通过多行业案例研究验证。

Result: 展示了物联网机器人优化工作流程、提升生产力的潜力，并强调了LLMs和生成式AI的推动作用。

Conclusion: LLMs和生成式AI是推动智能机器人和物联网发展的关键技术，对未来自动化和社会工业具有深远影响。

Abstract: This paper introduces an innovative design for robotic operating platforms,
underpinned by a transformative Internet of Things (IoT) architecture,
seamlessly integrating cutting-edge technologies such as large language models
(LLMs), generative AI, edge computing, and 5G networks. The proposed platform
aims to elevate the intelligence and autonomy of IoT systems and robotics,
enabling them to make real-time decisions and adapt dynamically to changing
environments. Through a series of compelling case studies across industries
including smart manufacturing, healthcare, and service sectors, this paper
demonstrates the substantial potential of IoT-enabled robotics to optimize
operational workflows, enhance productivity, and deliver innovative, scalable
solutions. By emphasizing the roles of LLMs and generative AI, the research
highlights how these technologies drive the evolution of intelligent robotics
and IoT, shaping the future of industry-specific advancements. The findings not
only showcase the transformative power of these technologies but also offer a
forward-looking perspective on their broader societal and industrial
implications, positioning them as catalysts for next-generation automation and
technological convergence.

</details>


### [416] [Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate](https://arxiv.org/abs/2506.22479)
*Krisanu Sarkar*

Main category: math.OC

Relevance: 40.0

TL;DR: HGM是一种自适应学习率优化算法，通过评估梯度方向一致性来调整学习率，优于传统方法如Adam。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法（如Adam）仅基于梯度幅度调整学习率，忽略了方向信息。HGM通过引入方向一致性评估，提升优化效果。

Method: HGM利用余弦相似度评估当前梯度与累积动量的方向一致性，动态调整学习率，以区分一致与冲突的梯度方向。

Result: HGM在平滑区域加速收敛，在噪声区域保持稳定，计算和内存效率与传统方法相当。

Conclusion: HGM通过更智能地响应优化路径结构，在非凸问题（如深度学习）中表现优于现有方法。

Abstract: We introduce Hindsight-Guided Momentum (HGM), a first-order optimization
algorithm that adaptively scales learning rates based on the directional
consistency of recent updates. Traditional adaptive methods, such as Adam or
RMSprop , adapt learning dynamics using only the magnitude of gradients, often
overlooking important geometric cues.Geometric cues refer to directional
information, such as the alignment between current gradients and past updates,
which reflects the local curvature and consistency of the optimization path.
HGM addresses this by incorporating a hindsight mechanism that evaluates the
cosine similarity between the current gradient and accumulated momentum. This
allows it to distinguish between coherent and conflicting gradient directions,
increasing the learning rate when updates align and reducing it in regions of
oscillation or noise. The result is a more responsive optimizer that
accelerates convergence in smooth regions of the loss surface while maintaining
stability in sharper or more erratic areas. Despite this added adaptability,
the method preserves the computational and memory efficiency of existing
optimizers.By more intelligently responding to the structure of the
optimization landscape, HGM provides a simple yet effective improvement over
existing approaches, particularly in non-convex settings like that of deep
neural network training.

</details>


### [417] [Peer Review as Structured Commentary: Immutable Identity, Public Dialogue, and Reproducible Scholarship](https://arxiv.org/abs/2506.22497)
*Craig Steven Wright*

Main category: cs.CY

Relevance: 40.0

TL;DR: 论文提出了一种基于公开评论的透明、可追溯的学术评审系统，利用区块链和AI技术改进传统评审的匿名性和延迟问题。


<details>
  <summary>Details</summary>
Motivation: 传统学术评审存在匿名性、延迟和门控问题，阻碍了学术验证的效率。本文旨在通过透明、身份关联和可复现的系统改进这一问题。

Method: 设计了一个结合区块链（用于不可篡改的审计追踪）和AI（用于迭代合成）的框架，激励学术贡献并追踪知识演化。

Result: 提出了一个透明、可追溯的学术评审模型，能够动态捕捉知识演进和声誉变化。

Conclusion: 该模型将学术知识重构为一个动态过程而非静态凭证，适用于从计算科学到人文的多个领域。

Abstract: This paper reconceptualises peer review as structured public commentary.
Traditional academic validation is hindered by anonymity, latency, and
gatekeeping. We propose a transparent, identity-linked, and reproducible system
of scholarly evaluation anchored in open commentary. Leveraging blockchain for
immutable audit trails and AI for iterative synthesis, we design a framework
that incentivises intellectual contribution, captures epistemic evolution, and
enables traceable reputational dynamics. This model empowers fields from
computational science to the humanities, reframing academic knowledge as a
living process rather than a static credential.

</details>


### [418] [Exploring Artificial Intelligence Tutor Teammate Adaptability to Harness Discovery Curiosity and Promote Learning in the Context of Interactive Molecular Dynamics](https://arxiv.org/abs/2506.22520)
*Mustafa Demir,Jacob Miratsky,Jonathan Nguyen,Chun Kit Chan,Punya Mishra,Abhishek Singharoy*

Main category: cs.HC

Relevance: 40.0

TL;DR: 研究探讨AI导师作为队友如何通过激发好奇心行为提升学生在分子动力学任务中的学习效果和参与度。


<details>
  <summary>Details</summary>
Motivation: 探索AI在教育和团队协作中的潜力，特别是在激发学生好奇心和提升学习效果方面。

Method: 采用Wizard-of-Oz范式，通过大型语言模型动态调整AI行为，11名高中生参与混合方法实验。

Result: 高性能团队表现出更好的任务完成度和理解深度，AI的好奇心触发行为与高级问题相关。

Conclusion: AI作为队友和导师的双重角色能提供适应性反馈，维持学生参与度和认知好奇心。

Abstract: This study examines the impact of an Artificial Intelligence tutor teammate
(AI) on student curiosity-driven engagement and learning effectiveness during
Interactive Molecular Dynamics (IMD) tasks on the Visual Molecular Dynamics
platform. It explores the role of the AI's curiosity-triggering and response
behaviors in stimulating and sustaining student curiosity, affecting the
frequency and complexity of student-initiated questions. The study further
assesses how AI interventions shape student engagement, foster discovery
curiosity, and enhance team performance within the IMD learning environment.
Using a Wizard-of-Oz paradigm, a human experimenter dynamically adjusts the AI
tutor teammate's behavior through a large language model. By employing a
mixed-methods exploratory design, a total of 11 high school students
participated in four IMD tasks that involved molecular visualization and
calculations, which increased in complexity over a 60-minute period. Team
performance was evaluated through real-time observation and recordings, whereas
team communication was measured by question complexity and AI's
curiosity-triggering and response behaviors. Cross Recurrence Quantification
Analysis (CRQA) metrics reflected structural alignment in coordination and were
linked to communication behaviors. High-performing teams exhibited superior
task completion, deeper understanding, and increased engagement. Advanced
questions were associated with AI curiosity-triggering, indicating heightened
engagement and cognitive complexity. CRQA metrics highlighted dynamic
synchronization in student-AI interactions, emphasizing structured yet adaptive
engagement to promote curiosity. These proof-of-concept findings suggest that
the AI's dual role as a teammate and educator indicates its capacity to provide
adaptive feedback, sustaining engagement and epistemic curiosity.

</details>


### [419] [GaussMaster: An LLM-based Database Copilot System](https://arxiv.org/abs/2506.23322)
*Wei Zhou,Ji Sun,Xuanhe Zhou,Guoliang Li,Luyang Liu,Hao Wu,Tianyuan Wang*

Main category: cs.DB

Relevance: 40.0

TL;DR: GaussMaster是一个基于LLM的数据库助手系统，旨在通过自动化SQL查询优化和数据库维护减轻DBA的工作负担。


<details>
  <summary>Details</summary>
Motivation: 现有自主数据库平台功能有限，仍需人工干预，GaussMaster旨在通过LLM技术实现全面自动化。

Method: 采用Tree-of-thought方法分析指标和日志，自动识别问题根源并调用工具解决。

Result: 在银行业等实际场景中成功实现34种数据库维护任务的零人工干预。

Conclusion: GaussMaster展示了LLM在数据库自动化维护中的潜力，显著提升了效率。

Abstract: In the financial industry, data is the lifeblood of operations, and DBAs
shoulder significant responsibilities for SQL tuning, database deployment,
diagnosis, and service repair. In recent years, both database vendors and
customers have increasingly turned to autonomous database platforms in an
effort to alleviate the heavy workload of DBAs. However, existing autonomous
database platforms are limited in their capabilities, primarily addressing
single-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual
intervention remains a necessity for comprehensive database maintenance.
GaussMaster aims to revolutionize this landscape by introducing an LLM-based
database copilot system. This innovative solution is designed not only to
assist developers in writing efficient SQL queries but also to provide
comprehensive care for database services. When database instances exhibit
abnormal behavior, GaussMaster is capable of orchestrating the entire
maintenance process automatically. It achieves this by analyzing hundreds of
metrics and logs, employing a Tree-of-thought approach to identify root causes,
and invoking appropriate tools to resolve issues. We have successfully
implemented GaussMaster in real-world scenarios, such as the banking industry,
where it has achieved zero human intervention for over 34 database maintenance
scenarios. In this paper, we present significant improvements in these tasks
with code at https://gitcode.com/opengauss/openGauss-GaussMaster.

</details>


### [420] [Offline Reinforcement Learning for Mobility Robustness Optimization](https://arxiv.org/abs/2506.22793)
*Pegah Alizadeh,Anastasios Giovanidis,Pradeepa Ramachandra,Vasileios Koutsoukis,Osama Arouk*

Main category: cs.NI

Relevance: 40.0

TL;DR: 论文探讨了使用离线强化学习优化MRO算法，通过决策变换器和保守Q学习方法，在NR网络中实现了比传统规则方法更高的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是利用离线强化学习方法优化MRO算法，避免在线探索的需求，同时提高性能和操作灵活性。

Method: 采用了决策变换器和保守Q学习两种离线强化学习方法，使用与规则方法相同的输入特征和目标奖励。

Result: 在NR网络中的实验表明，离线强化学习方法比规则方法性能提升高达7%，且能灵活适应不同目标函数。

Conclusion: 离线强化学习在MRO优化中表现出色，提供了更高的性能和灵活性。

Abstract: In this work we revisit the Mobility Robustness Optimisation (MRO) algorithm
and study the possibility of learning the optimal Cell Individual Offset tuning
using offline Reinforcement Learning. Such methods make use of collected
offline datasets to learn the optimal policy, without further exploration. We
adapt and apply a sequence-based method called Decision Transformers as well as
a value-based method called Conservative Q-Learning to learn the optimal policy
for the same target reward as the vanilla rule-based MRO. The same input
features related to failures, ping-pongs, and other handover issues are used.
Evaluation for realistic New Radio networks with 3500 MHz carrier frequency on
a traffic mix including diverse user service types and a specific tunable
cell-pair shows that offline-RL methods outperform rule-based MRO, offering up
to 7% improvement. Furthermore, offline-RL can be trained for diverse objective
functions using the same available dataset, thus offering operational
flexibility compared to rule-based methods.

</details>


### [421] [TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations](https://arxiv.org/abs/2506.22818)
*Stanislav Sedukhin,Yoichi Tomioka,Kazuya Matsumoto,Yuichi Okuyama*

Main category: cs.DC

Relevance: 40.0

TL;DR: TriADA introduces a novel algorithm and architecture for efficient trilinear tensor transformations, addressing computational and energy challenges in AI and HPC workloads.


<details>
  <summary>Details</summary>
Motivation: The high computational and memory demands of multilinear transformations, especially for sparse data, limit efficiency in AI and HPC. TriADA aims to overcome these challenges with a scalable, energy-efficient solution.

Method: TriADA combines a low-rank algorithm for 3D-DXTs, an optimized GEMM kernel, a distributed 3D network architecture, and an ESOP method to enhance efficiency and accuracy.

Result: TriADA achieves hypercubic arithmetic complexity in linear time-steps, offering scalable and energy-efficient performance for tensor operations.

Conclusion: TriADA is a promising solution for accelerating demanding multilinear tensor operations in AI and HPC, with potential for widespread adoption.

Abstract: Multilinear transformations are key in high-performance computing (HPC) and
artificial intelligence (AI) workloads, where data is represented as tensors.
However, their high computational and memory demands, which grow with
dimensionality, often slow down critical tasks. Moreover, scaling computation
by enlarging the number of parallel processing units substantially increases
energy consumption, limiting widespread adoption, especially for sparse data,
which is common in HPC and AI applications. This paper introduces the Trilinear
Algorithm and isomorphic to algorithm Device Architecture (TriADA) to address
these challenges with the following innovations: (1) a massively parallel,
low-rank algorithm for computing a family of trilinear (3D) discrete orthogonal
transformations (3D-DXTs), which is a special case of the more general 3-mode
matrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM
kernel with decoupled streaming active memory, specially designed to accelerate
3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully
distributed 3D network of mesh interconnected processing elements or cells with
a coordinate-free, data-driven local processing activity, which is independent
of problem size; (4) an elastic sparse outer-product (ESOP) method that avoids
unnecessary computing and communication operations with zero-valued operands,
thereby enhancing energy efficiency, computational accuracy, and stability.
TriADA is capable of performing a variety of trilinear transformations with
hypercubic arithmetic complexity in a linear number of time-steps. The
massively parallel, scalable, and energy-efficient architecture of TriADA is
ideal for accelerating multilinear tensor operations, which are the most
demanding parts of AI and HPC workloads.

</details>


### [422] [Performance Measurements in the AI-Centric Computing Continuum Systems](https://arxiv.org/abs/2506.22884)
*Praveen Kumar Donta,Qiyang Zhang,Schahram Dustdar*

Main category: cs.DC

Relevance: 40.0

TL;DR: 本文回顾了分布式计算连续体（DCC）和物联网（IoT）环境中的常用性能指标，并讨论了新兴性能维度（如可持续性、能源效率和系统可观测性），以应对生成式AI和大语言模型对计算资源的需求。


<details>
  <summary>Details</summary>
Motivation: 随着计算范式从集中式系统转向分布式架构，生成式AI和大语言模型的出现加剧了对计算资源的需求，传统性能指标需要扩展以适应新的计算需求和应用程序要求。

Method: 回顾DCC和IoT环境中的常用性能指标，讨论新兴性能维度，并提出选择适当指标的标准和考虑因素。

Result: 提出了应对新兴计算需求（如可持续性和能源效率）的性能指标扩展方向。

Conclusion: 本文为未来在分布式计算连续体中性能指标的研究和开发提供了指导和启发。

Abstract: Over the Eight decades, computing paradigms have shifted from large,
centralized systems to compact, distributed architectures, leading to the rise
of the Distributed Computing Continuum (DCC). In this model, multiple layers
such as cloud, edge, Internet of Things (IoT), and mobile platforms work
together to support a wide range of applications. Recently, the emergence of
Generative AI and large language models has further intensified the demand for
computational resources across this continuum. Although traditional performance
metrics have provided a solid foundation, they need to be revisited and
expanded to keep pace with changing computational demands and application
requirements. Accurate performance measurements benefit both system designers
and users by supporting improvements in efficiency and promoting alignment with
system goals. In this context, we review commonly used metrics in DCC and IoT
environments. We also discuss emerging performance dimensions that address
evolving computing needs, such as sustainability, energy efficiency, and system
observability. We also outline criteria and considerations for selecting
appropriate metrics, aiming to inspire future research and development in this
critical area.

</details>


### [423] [Learning Truthful Mechanisms without Discretization](https://arxiv.org/abs/2506.22911)
*Yunxuan Ma,Siqiang Wang,Zhijian Duan,Yukun Cheng,Xiaotie Deng*

Main category: cs.GT

Relevance: 40.0

TL;DR: TEDI是一种无需离散化的算法，用于学习真实且效用最大化的机制，解决了现有方法因离散化导致的效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法通常依赖结果空间的离散化以确保真实性，但随着问题规模增大，效率降低。

Method: 提出了一种新的菜单机制，基于定价规则的概念，使用Partial GroupMax Network参数化定价规则，并开发了新的训练技术（如协方差技巧和连续采样）。

Result: TEDI保证了真实性、完全表达性和维度不敏感性，实验表明其性能优于或与现有方法相当。

Conclusion: TEDI是首个无需结果离散化的真实机制学习方法，提升了算法效率，为自动化机制设计和可微分经济学提供了新思路。

Abstract: This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive
approach), a discretization-free algorithm to learn truthful and
utility-maximizing mechanisms. Existing learning-based approaches often rely on
discretization of outcome spaces to ensure truthfulness, which leads to
inefficiency with increasing problem size. To address this limitation, we
formalize the concept of pricing rules, defined as functions that map outcomes
to prices. Based on this concept, we propose a novel menu mechanism, which can
be equivalent to a truthful direct mechanism under specific conditions. The
core idea of TEDI lies in its parameterization of pricing rules using Partial
GroupMax Network, a new network architecture designed to universally
approximate partial convex functions. To learn optimal pricing rules, we
develop novel training techniques, including covariance trick and continuous
sampling, to derive unbiased gradient estimators compatible with first-order
optimization. Theoretical analysis establishes that TEDI guarantees
truthfulness, full expressiveness, and dimension-insensitivity. Experimental
evaluation in the studied auction setting demonstrates that TEDI achieves
strong performance, competitive with or exceeding state-of-the-art methods.
  This work presents the first approaches to learn truthful mechanisms without
outcome discretization, thereby enhancing algorithmic efficiency. The proposed
concepts, network architecture, and learning techniques might offer potential
value and provide new insights for automated mechanism design and
differentiable economics.

</details>


### [424] [Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making](https://arxiv.org/abs/2506.23023)
*M. Youssef Abdelhamid,Lennart Vater,Zlatan Ajanovic*

Main category: cs.RO

Relevance: 40.0

TL;DR: SAD-RL框架通过分层策略和场景化环境提升自动驾驶决策算法的泛化能力和学习效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在复杂开放环境中需要安全决策，现有RL方法在复杂任务中泛化能力不足且学习效率低。

Method: 提出SAD-RL框架，结合分层策略（高层选择模板，低层执行）和场景化环境，控制训练经验并引入挑战性场景。

Result: 实验表明SAD-RL能高效实现安全行为，消融研究证实分层策略和场景多样性是关键。

Conclusion: SAD-RL通过分层和场景化设计解决了自动驾驶RL的泛化和效率问题。

Abstract: Developing decision-making algorithms for highly automated driving systems
remains challenging, since these systems have to operate safely in an open and
complex environments. Reinforcement Learning (RL) approaches can learn
comprehensive decision policies directly from experience and already show
promising results in simple driving tasks. However, current approaches fail to
achieve generalizability for more complex driving tasks and lack learning
efficiency. Therefore, we present Scenario-based Automated Driving
Reinforcement Learning (SAD-RL), the first framework that integrates
Reinforcement Learning (RL) of hierarchical policy in a scenario-based
environment. A high-level policy selects maneuver templates that are evaluated
and executed by a low-level control logic. The scenario-based environment
allows to control the training experience for the agent and to explicitly
introduce challenging, but rate situations into the training process. Our
experiments show that an agent trained using the SAD-RL framework can achieve
safe behaviour in easy as well as challenging situations efficiently. Our
ablation studies confirmed that both HRL and scenario diversity are essential
for achieving these results.

</details>


### [425] [Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models](https://arxiv.org/abs/2506.23164)
*Maarten Hugenholtz,Anna Meszaros,Jens Kober,Zlatan Ajanovic*

Main category: cs.RO

Relevance: 40.0

TL;DR: 提出了一种评估多模态预测模型中模式崩溃的新框架，重点关注安全关键交互，并引入了相关指标。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成多样化预测时忽视了代理间交互模式的多样性，且传统评估指标未量化评估交互或模式崩溃。

Method: 提出了一种评估框架，包括模式崩溃、模式正确性和覆盖率的指标，特别关注预测的时序维度。

Result: 测试了四种多代理轨迹预测模型，发现模式崩溃确实存在，且在某些情况下模型无法预测正确的交互模式。

Conclusion: 该框架有助于研究人员开发更一致和准确的预测模型，提升自动驾驶系统的安全性。

Abstract: Autonomous Vehicle decisions rely on multimodal prediction models that
account for multiple route options and the inherent uncertainty in human
behavior. However, models can suffer from mode collapse, where only the most
likely mode is predicted, posing significant safety risks. While existing
methods employ various strategies to generate diverse predictions, they often
overlook the diversity in interaction modes among agents. Additionally,
traditional metrics for evaluating prediction models are dataset-dependent and
do not evaluate inter-agent interactions quantitatively. To our knowledge, none
of the existing metrics explicitly evaluates mode collapse. In this paper, we
propose a novel evaluation framework that assesses mode collapse in joint
trajectory predictions, focusing on safety-critical interactions. We introduce
metrics for mode collapse, mode correctness, and coverage, emphasizing the
sequential dimension of predictions. By testing four multi-agent trajectory
prediction models, we demonstrate that mode collapse indeed happens. When
looking at the sequential dimension, although prediction accuracy improves
closer to interaction events, there are still cases where the models are unable
to predict the correct interaction mode, even just before the interaction mode
becomes inevitable. We hope that our framework can help researchers gain new
insights and advance the development of more consistent and accurate prediction
models, thus enhancing the safety of autonomous driving systems.

</details>


### [426] [Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation](https://arxiv.org/abs/2506.23334)
*Hongyi Pan,Ziliang Hong,Gorkem Durak,Ziyue Xu,Ulas Bagci*

Main category: eess.IV

Relevance: 40.0

TL;DR: 论文提出了一种基于生成AI的数据增强框架，用于联邦学习中的乳腺癌超声图像分类，通过合成图像共享提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中数据不足和非独立同分布数据导致的模型性能下降问题。

Method: 训练两类特定的DCGAN生成合成图像，结合FedAvg和FedProx算法在三个公开数据集上进行实验。

Result: 适量合成图像将FedAvg的AUC从0.9206提升至0.9237，FedProx从0.9429提升至0.9538。

Conclusion: 生成AI数据增强可提升联邦学习在乳腺癌超声分类中的效果，但需平衡合成与真实数据比例。

Abstract: Federated learning (FL) has emerged as a promising paradigm for
collaboratively training deep learning models across institutions without
exchanging sensitive medical data. However, its effectiveness is often hindered
by limited data availability and non-independent, identically distributed data
across participating clients, which can degrade model performance and
generalization. To address these challenges, we propose a generative AI based
data augmentation framework that integrates synthetic image sharing into the
federated training process for breast cancer diagnosis via ultrasound images.
Specifically, we train two simple class-specific Deep Convolutional Generative
Adversarial Networks: one for benign and one for malignant lesions. We then
simulate a realistic FL setting using three publicly available breast
ultrasound image datasets: BUSI, BUS-BRA, and UDIAT. FedAvg and FedProx are
adopted as baseline FL algorithms. Experimental results show that incorporating
a suitable number of synthetic images improved the average AUC from 0.9206 to
0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. We also note that
excessive use of synthetic data reduced performance, underscoring the
importance of maintaining a balanced ratio of real and synthetic samples. Our
findings highlight the potential of generative AI based data augmentation to
enhance FL results in the breast ultrasound image classification task.

</details>


### [427] [A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation](https://arxiv.org/abs/2506.23584)
*Renjie Liang,Zhengkang Fan,Jinqian Pan,Chenkun Sun,Russell Terry,Jie Xu*

Main category: eess.IV

Relevance: 40.0

TL;DR: 提出了一种两阶段框架，用于从2D CT切片生成肾脏放射学报告，结合多任务学习和视觉语言模型，实验结果表明其优于随机基线。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像和临床文档复杂性导致的放射学报告生成难题。

Method: 1. 使用多任务学习模型提取结构化异常特征；2. 将特征与CT图像结合，输入微调的视觉语言模型生成报告。

Result: 模型在所有异常类型上优于随机基线，生成的报告能合理捕捉关键临床内容。

Conclusion: 模块化、基于特征的报告生成在肾脏影像中可行，未来将扩展到3D CT并提升临床保真度。

Abstract: Generating radiology reports from CT scans remains a complex task due to the
nuanced nature of medical imaging and the variability in clinical
documentation. In this study, we propose a two-stage framework for generating
renal radiology reports from 2D CT slices. First, we extract structured
abnormality features using a multi-task learning model trained to identify
lesion attributes such as location, size, enhancement, and attenuation. These
extracted features are subsequently combined with the corresponding CT image
and fed into a fine-tuned vision-language model to generate natural language
report sentences aligned with clinical findings. We conduct experiments on a
curated dataset of renal CT studies with manually annotated
sentence-slice-feature triplets and evaluate performance using both
classification metrics and natural language generation metrics. Our results
demonstrate that the proposed model outperforms random baselines across all
abnormality types, and the generated reports capture key clinical content with
reasonable textual accuracy. This exploratory work highlights the feasibility
of modular, feature-informed report generation for renal imaging. Future
efforts will focus on extending this pipeline to 3D CT volumes and further
improving clinical fidelity in multimodal medical AI systems.

</details>


### [428] [Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation](https://arxiv.org/abs/2506.23717)
*Xingting Yao,Qinghao Hu,Fei Zhou,Tielong Liu,Gang Li,Peisong Wang,Jian Cheng*

Main category: cs.NE

Relevance: 40.0

TL;DR: 本文提出了一种自适应比特分配策略，用于直接训练的脉冲神经网络（SNN），通过细粒度层间资源分配提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着多比特SNN的发展，内存和计算需求激增，导致性能提升不成比例。不同层的重要性不同，额外比特可能浪费或干扰，因此需要优化资源分配。

Method: 参数化权重和脉冲的时间长度和比特宽度，使其可通过梯度学习和控制。提出改进的脉冲神经元以处理可变比特宽度和时间长度，并解决步长不匹配问题。

Result: 在多个数据集上实验表明，该方法能降低内存和计算成本，同时提高准确性。例如，SEWResNet-34在ImageNet上实现了2.69%的准确率提升和4.16倍的比特预算降低。

Conclusion: 自适应比特分配策略显著提升了SNN的效率和准确性，为解决资源分配问题提供了有效方案。

Abstract: Multi-bit spiking neural networks (SNNs) have recently become a heated
research spot, pursuing energy-efficient and high-accurate AI. However, with
more bits involved, the associated memory and computation demands escalate to
the point where the performance improvements become disproportionate. Based on
the insight that different layers demonstrate different importance and extra
bits could be wasted and interfering, this paper presents an adaptive bit
allocation strategy for direct-trained SNNs, achieving fine-grained layer-wise
allocation of memory and computation resources. Thus, SNN's efficiency and
accuracy can be improved. Specifically, we parametrize the temporal lengths and
the bit widths of weights and spikes, and make them learnable and controllable
through gradients. To address the challenges caused by changeable bit widths
and temporal lengths, we propose the refined spiking neuron, which can handle
different temporal lengths, enable the derivation of gradients for temporal
lengths, and suit spike quantization better. In addition, we theoretically
formulate the step-size mismatch problem of learnable bit widths, which may
incur severe quantization errors to SNN, and accordingly propose the step-size
renewal mechanism to alleviate this issue. Experiments on various datasets,
including the static CIFAR and ImageNet and the dynamic CIFAR-DVS and
DVS-GESTURE, demonstrate that our methods can reduce the overall memory and
computation cost while achieving higher accuracy. Particularly, our
SEWResNet-34 can achieve a 2.69\% accuracy gain and 4.16$\times$ lower bit
budgets over the advanced baseline work on ImageNet. This work will be fully
open-sourced.

</details>


### [429] [Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound](https://arxiv.org/abs/2506.23721)
*Gijs Luijten,Roberto Maria Scardigno,Lisle Faray de Paiva,Peter Hoyer,Jens Kleesiek,Domenico Buongiorno,Vitoantonio Bevilacqua,Jan Egger*

Main category: eess.IV

Relevance: 40.0

TL;DR: 论文提出了一种结合深度学习和增强现实的超声成像系统，用于实时自动肾脏体积测量，旨在减轻临床医生的认知负担并提高效率。


<details>
  <summary>Details</summary>
Motivation: 超声成像虽然广泛可用且无辐射，但其动态性和非标准成像平面导致学习曲线陡峭，同时临床医生需要在屏幕和患者之间频繁切换注意力，增加了操作难度。

Method: 通过深度学习实现实时自动肾脏体积测量，并结合增强现实技术将显示直接投影到临床医生视野中。提出了两种基于HoloLens-2的AR-DL辅助超声流程，支持无线和视频输出设备。

Result: 使用Open Kidney Dataset和开源分割模型（如nnU-Net、Segmenter等）评估了实时性和准确性，并提供了开源GitHub管道。

Conclusion: 该技术提升了超声培训和诊断效率，特别是在即时护理场景中。

Abstract: Ultrasound (US) is widely accessible and radiation-free but has a steep
learning curve due to its dynamic nature and non-standard imaging planes.
Additionally, the constant need to shift focus between the US screen and the
patient poses a challenge. To address these issues, we integrate deep learning
(DL)-based semantic segmentation for real-time (RT) automated kidney volumetric
measurements, which are essential for clinical assessment but are traditionally
time-consuming and prone to fatigue. This automation allows clinicians to
concentrate on image interpretation rather than manual measurements.
Complementing DL, augmented reality (AR) enhances the usability of US by
projecting the display directly into the clinician's field of view, improving
ergonomics and reducing the cognitive load associated with screen-to-patient
transitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one
streams directly via the application programming interface for a wireless
setup, while the other supports any US device with video output for broader
accessibility. We evaluate RT feasibility and accuracy using the Open Kidney
Dataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with
MedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model
implementations, measurement algorithms, and a Wi-Fi-based streaming solution,
enhancing US training and diagnostics, especially in point-of-care settings.

</details>


### [430] [Scaling Self-Supervised Representation Learning for Symbolic Piano Performance](https://arxiv.org/abs/2506.23869)
*Louis Bradshaw,Honglu Fan,Alexander Spangher,Stella Biderman,Simon Colton*

Main category: cs.SD

Relevance: 40.0

TL;DR: 该论文研究了基于符号钢琴转录的生成式自回归Transformer模型，通过预训练和微调在音乐生成和分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 探索生成式自回归Transformer模型在符号音乐领域的潜力，特别是在钢琴音乐的生成和分类任务中。

Method: 预训练60,000小时音乐数据，微调高质量子集，结合SimCLR框架生成对比性MIDI嵌入。

Result: 生成模型在钢琴音乐连贯性上优于现有符号生成技术，对比模型在分类任务中达到SOTA。

Conclusion: 预训练模型在符号音乐任务中表现出强大的泛化能力，少量标注数据即可适应下游任务。

Abstract: We study the capabilities of generative autoregressive transformer models
trained on large amounts of symbolic solo-piano transcriptions. After first
pretraining on approximately 60,000 hours of music, we use a comparatively
smaller, high-quality subset, to finetune models to produce musical
continuations, perform symbolic classification tasks, and produce
general-purpose contrastive MIDI embeddings by adapting the SimCLR framework to
symbolic music. When evaluating piano continuation coherence, our generative
model outperforms leading symbolic generation techniques and remains
competitive with proprietary audio generation models. On MIR classification
benchmarks, frozen representations from our contrastive model achieve
state-of-the-art results in linear probe experiments, while direct finetuning
demonstrates the generalizability of pretrained representations, often
requiring only a few hundred labeled examples to specialize to downstream
tasks.

</details>


### [431] [PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?](https://arxiv.org/abs/2506.23725)
*Atharva Gundawar,Som Sagar,Ransalu Senanayake*

Main category: cs.RO

Relevance: 40.0

TL;DR: PAC Bench是一个评估视觉语言模型（VLMs）在物理属性、动作可行性和约束理解方面的基准测试，揭示了当前模型在物理概念理解上的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在机器人操作任务中广泛应用，但其对低层物理前提的理解能力尚未验证，这可能影响任务的可靠性。

Method: 提出了PAC Bench基准测试，包含多样化的数据集和任务，用于系统评估VLMs的物理理解能力。

Result: 评估显示当前VLMs在物理概念理解上存在显著不足，限制了其在机器人操作中的可靠性。

Conclusion: PAC Bench为评估和改进VLMs的物理推理能力提供了标准化工具，有助于开发更可靠的机器人应用模型。

Abstract: Vision-Language Models (VLMs) are increasingly pivotal for generalist robot
manipulation, enabling tasks such as physical reasoning, policy generation, and
failure detection. However, their proficiency in these high-level applications
often assumes a deep understanding of low-level physical prerequisites, a
capability that remains largely unverified. For robots to perform actions
reliably, they must comprehend intrinsic object properties (e.g., material,
weight), action affordances (e.g., graspable, stackable), and physical
constraints (e.g., stability, reachability, or an object's state, such as being
closed). Despite the widespread use of VLMs in manipulation tasks, we argue
that off-the-shelf models may lack this granular, physically grounded
understanding, as such prerequisites are often overlooked during training.
  To address this critical gap, we introduce PAC Bench, a comprehensive
benchmark designed to systematically evaluate VLMs on their understanding of
core Properties, Affordances, and Constraints (PAC) from a task executability
perspective. PAC Bench features a diverse dataset with over 30,000 annotations,
comprising 673 real-world images (115 object classes, 15 property types, and 1
to 3 affordances defined per class), 100 real-world humanoid-view scenarios,
and 120 unique simulated constraint scenarios across four tasks.
  Our evaluations reveal significant gaps in the ability of current VLMs to
grasp fundamental physical concepts, highlighting limitations in their
suitability for reliable robot manipulation and pointing to key areas for
targeted research. PAC Bench also serves as a standardized benchmark for
rigorously evaluating physical reasoning in VLMs and guiding the development of
more robust, physically grounded models for robotic applications.
  Project Page: https://pacbench.github.io/

</details>


### [432] [Towards the "Digital Me": A vision of authentic Conversational Agents powered by personal Human Digital Twins](https://arxiv.org/abs/2506.23826)
*Lluís C. Coll,Martin W. Lauer-Schmaltz,Philip Cash,John P. Hansen,Anja Maier*

Main category: cs.ET

Relevance: 40.0

TL;DR: 论文提出了一种集成大型语言模型和动态个人数据的新型人类数字孪生（HDT）系统架构，能够模拟个体的对话风格、记忆和行为，同时引发伦理问题。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用对话式AI的最新进展，将HDT发展为真实的交互式数字个体，提升其自然性和动态性。

Method: 采用上下文感知记忆检索、神经可塑性启发的巩固和自适应学习机制，结合大型语言模型与动态更新的个人数据。

Result: 系统能够根据对话对象复制个体的独特对话风格，并动态融入个人经历、观点和记忆，丰富了交互体验。

Conclusion: 该研究为HDT的发展提供了新方向，但也强调了隐私、责任和持久数字身份等伦理问题的紧迫性。

Abstract: Human Digital Twins (HDTs) have traditionally been conceptualized as
data-driven models designed to support decision-making across various domains.
However, recent advancements in conversational AI open new possibilities for
HDTs to function as authentic, interactive digital counterparts of individuals.
This paper introduces a novel HDT system architecture that integrates large
language models with dynamically updated personal data, enabling it to mirror
an individual's conversational style, memories, and behaviors. To achieve this,
our approach implements context-aware memory retrieval, neural
plasticity-inspired consolidation, and adaptive learning mechanisms, creating a
more natural and evolving digital persona. The resulting system does not only
replicate an individual's unique conversational style depending on who they are
speaking with, but also enriches responses with dynamically captured personal
experiences, opinions, and memories. While this marks a significant step toward
developing authentic virtual counterparts, it also raises critical ethical
concerns regarding privacy, accountability, and the long-term implications of
persistent digital identities. This study contributes to the field of HDTs by
describing our novel system architecture, demonstrating its capabilities, and
discussing future directions and emerging challenges to ensure the responsible
and ethical development of HDTs.

</details>


### [433] [Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning](https://arxiv.org/abs/2506.23944)
*Fuhang Kuang,Jiacheng You,Yingdong Hu,Tong Zhang,Chuan Wen,Yang Gao*

Main category: cs.RO

Relevance: 40.0

TL;DR: 论文提出了一种解决机器人模仿学习中本体感觉偏移问题的领域适应框架，通过Wasserstein距离量化并最小化训练与部署分布差异。


<details>
  <summary>Details</summary>
Motivation: 本体感觉在机器人任务中虽重要，但直接引入会导致性能下降，原因是训练与部署时的分布偏移。

Method: 使用Wasserstein距离量化专家与部署数据的分布差异，并通过按比例添加噪声来对齐分布。

Result: 实验表明，该方法优于直接丢弃本体感觉的基线和其他解决分布偏移的方法。

Conclusion: 提出的框架有效解决了本体感觉偏移问题，提升了模仿学习性能。

Abstract: Imitation learning models for robotic tasks typically rely on multi-modal
inputs, such as RGB images, language, and proprioceptive states. While
proprioception is intuitively important for decision-making and obstacle
avoidance, simply incorporating all proprioceptive states leads to a surprising
degradation in imitation learning performance. In this work, we identify the
underlying issue as the proprioception shift problem, where the distributions
of proprioceptive states diverge significantly between training and deployment.
To address this challenge, we propose a domain adaptation framework that
bridges the gap by utilizing rollout data collected during deployment. Using
Wasserstein distance, we quantify the discrepancy between expert and rollout
proprioceptive states and minimize this gap by adding noise to both sets of
states, proportional to the Wasserstein distance. This strategy enhances
robustness against proprioception shifts by aligning the training and
deployment distributions. Experiments on robotic manipulation tasks demonstrate
the efficacy of our method, enabling the imitation policy to leverage
proprioception while mitigating its adverse effects. Our approach outperforms
the naive solution which discards proprioception, and other baselines designed
to address distributional shifts.

</details>


### [434] [Bridging Physical and Digital Worlds: Embodied Large AI for Future Wireless Systems](https://arxiv.org/abs/2506.24009)
*Xinquan Wang,Fenghao Zhu,Zhaohui Yang,Chongwen Huang,Xiaoming Chen,Zhaoyang Zhang,Sami Muhaidat,Mérouane Debbah*

Main category: cs.IT

Relevance: 40.0

TL;DR: 论文提出了一种无线嵌入式大型AI（WELAI）的新范式，从被动观察转向主动嵌入，解决了现有模型在实时无线动态和非平稳环境中的不足。


<details>
  <summary>Details</summary>
Motivation: 当前大型AI模型在无线系统中主要依赖离线数据，无法有效处理实时动态和非平稳环境，且缺乏主动环境探测能力。

Method: 论文首先分析了现有模型的挑战，然后探讨了WELAI的设计原则和系统结构，并通过案例研究验证其有效性。

Result: WELAI展示了在下一代无线系统中实现自适应、鲁棒和自主系统的潜力。

Conclusion: WELAI为无线系统提供了一种新的研究方向，未来可进一步探索其应用和优化。

Abstract: Large artificial intelligence (AI) models offer revolutionary potential for
future wireless systems, promising unprecedented capabilities in network
optimization and performance. However, current paradigms largely overlook
crucial physical interactions. This oversight means they primarily rely on
offline datasets, leading to difficulties in handling real-time wireless
dynamics and non-stationary environments. Furthermore, these models often lack
the capability for active environmental probing. This paper proposes a
fundamental paradigm shift towards wireless embodied large AI (WELAI), moving
from passive observation to active embodiment. We first identify key challenges
faced by existing models, then we explore the design principles and system
structure of WELAI. Besides, we outline prospective applications in
next-generation wireless. Finally, through an illustrative case study, we
demonstrate the effectiveness of WELAI and point out promising research
directions for realizing adaptive, robust, and autonomous wireless systems.

</details>


### [435] [Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence](https://arxiv.org/abs/2506.23503)
*Bosubabu Sambana,Kondreddygari Archana,Suram Indhra Sena Reddy,Shaik Meethaigar Jameer Basha,Shaik Karishma*

Main category: cs.AI

Relevance: 30.0

TL;DR: 论文提出了一种基于认知行为疗法（CBT）的系统，利用BERT、RoBERTa等模型分析社交媒体中的负面情绪和认知扭曲，并预测潜在心理健康问题。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏有效分析社交媒体中认知路径的方法，这对心理治疗师提供及时干预至关重要。

Method: 结合BERT、RoBERTa进行情感分析，T5、PEGASUS进行文本摘要，mT5进行多语言翻译，以检测社交媒体中的负面情绪和认知扭曲。

Result: 系统不仅能识别负面情绪，还能预测潜在心理健康问题（如恐惧症、饮食失调），为治疗师提供更全面的干预工具。

Conclusion: 该系统为心理健康问题的早期检测和治疗提供了有力支持。

Abstract: Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the
irrational thought patterns associated with mental health disorders, but its
effectiveness relies on accurately identifying cognitive pathways to provide
targeted treatment. In today's digital age, individuals often express negative
emotions on social media, where they may reveal cognitive distortions, and in
severe cases, exhibit suicidal tendencies. However, there is a significant gap
in methodologies designed to analyze these cognitive pathways, which could be
critical for psychotherapists aiming to deliver timely and effective
interventions in online environments. Cognitive Behavioral Therapy (CBT)
framework leveraging acceptance, commitment and data augmentation to categorize
and address both textual and visual content as positive or negative.
Specifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,
PEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages
focusing on detecting negative emotions and cognitive distortions within social
media data. While existing models are primarily designed to identify negative
thoughts, the proposed system goes beyond this by predicting additional
negative side effects and other potential mental health disorders likes
Phobias, Eating Disorders. This enhancement allows for a more comprehensive
understanding and intervention strategy, offering psychotherapists a powerful
tool for early detection and treatment of various psychological issues.

</details>


### [436] [Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM](https://arxiv.org/abs/2506.23504)
*Bosubabu Sambana,Kotamsetty Geethika Devi,Bandi Rajeswara Reddy,Galeti Mohammad Hussain,Gownivalla Siddartha*

Main category: cs.AI

Relevance: 30.0

TL;DR: 该论文提出了一种结合AlexNet和LSTM的混合模型，用于电力价格预测，相比传统RNN和ANN模型，其准确性更高。


<details>
  <summary>Details</summary>
Motivation: 传统方法在预测电力价格时未能充分考虑外部变量，导致预测不准确。混合模型通过结合AlexNet的特征提取能力和LSTM的序列学习能力，解决了这一问题。

Method: 使用AlexNet进行特征提取，LSTM学习时间序列模式，并结合最小-最大缩放和时间窗口等方法处理数据。

Result: 混合模型的预测准确率达到97.08%，高于RNN（96.64%）和ANN（96.63%）。

Conclusion: 混合模型在电力价格预测中表现优于传统方法，准确性显著提升。

Abstract: The recent development of advanced machine learning methods for hybrid models
has greatly addressed the need for the correct prediction of electrical prices.
This method combines AlexNet and LSTM algorithms, which are used to introduce a
new model with higher accuracy in price forecasting. Despite RNN and ANN being
effective, they often fail to deal with forex time sequence data. The
traditional methods do not accurately forecast the prices. These traditional
methods only focus on demand and price which leads to insufficient analysis of
data. To address this issue, using the hybrid approach, which focuses on
external variables that also effect the predicted prices. Nevertheless, due to
AlexNet's excellent feature extraction and LSTM's learning sequential patterns,
the prediction accuracy is vastly increased. The model is built on the past
data, which has been supplied with the most significant elements like demand,
temperature, sunlight, and rain. For example, the model applies methods, such
as minimum-maximum scaling and a time window, to predict the electricity prices
of the future. The results show that this hybrid model is good than the
standalone ones in terms of accuracy. Although we got our accuracy rating of
97.08, it shows higher accompaniments than remaining models RNN and ANN with
accuracies of 96.64 and 96.63 respectively.

</details>


### [437] [Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays](https://arxiv.org/abs/2506.23517)
*Selin Dik,Osman Erdem,Mehmet Dik*

Main category: cs.AI

Relevance: 30.0

TL;DR: 研究评估了GPTZero检测AI生成文本的可靠性，发现其对纯AI文本检测准确率高，但对人类文本存在误判。


<details>
  <summary>Details</summary>
Motivation: 随着学生使用AI工具的增加，教师依赖AI检测工具（如GPTZero）的可靠性尚不明确。

Method: 通过不同长度的AI生成和人类撰写文本（短、中、长）测试GPTZero的检测准确率。

Result: AI生成文本检测准确率高达91-100%，但人类文本存在误判。

Conclusion: GPTZero对纯AI文本有效，但对人类文本区分能力有限，建议谨慎使用。

Abstract: As the use of AI tools by students has become more prevalent, instructors
have started using AI detection tools like GPTZero and QuillBot to detect AI
written text. However, the reliability of these detectors remains uncertain. In
our study, we focused mostly on the success rate of GPTZero, the most-used AI
detector, in identifying AI-generated texts based on different lengths of
randomly submitted essays: short (40-100 word count), medium (100-350 word
count), and long (350-800 word count). We gathered a data set consisting of
twenty-eight AI-generated papers and fifty human-written papers. With this
randomized essay data, papers were individually plugged into GPTZero and
measured for percentage of AI generation and confidence. A vast majority of the
AI-generated papers were detected accurately (ranging from 91-100% AI believed
generation), while the human generated essays fluctuated; there were a handful
of false positives. These findings suggest that although GPTZero is effective
at detecting purely AI-generated content, its reliability in distinguishing
human-authored texts is limited. Educators should therefore exercise caution
when relying solely on AI detection tools.

</details>


### [438] [HASD: Hierarchical Adaption for pathology Slide-level Domain-shift](https://arxiv.org/abs/2506.23673)
*Jingsong Liu,Han Li,Chen Yang,Michael Deutges,Ario Sadafi,Xin You,Katharina Breininger,Nassir Navab,Peter J. Schüffler*

Main category: cs.AI

Relevance: 30.0

TL;DR: 提出了一种名为HASD的分层适应框架，用于解决病理学中的切片级域偏移问题，通过多尺度特征一致性和计算高效的适应方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 病理学数据受中心特定条件影响较大，现有方法仅关注图像块而忽略了全局特征，无法满足临床需求。

Method: HASD框架包含层次化适应模块（特征对齐、几何不变性正则化和注意力一致性正则化）和原型选择机制。

Result: 在五个数据集上验证，乳腺癌HER2分级任务AUROC提升4.1%，UCEC生存预测任务C-index提升3.9%。

Conclusion: HASD为病理学机构提供了一种实用且可靠的切片级域适应解决方案。

Abstract: Domain shift is a critical problem for pathology AI as pathology data is
heavily influenced by center-specific conditions. Current pathology domain
adaptation methods focus on image patches rather than WSI, thus failing to
capture global WSI features required in typical clinical scenarios. In this
work, we address the challenges of slide-level domain shift by proposing a
Hierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD
achieves multi-scale feature consistency and computationally efficient
slide-level domain adaptation through two key components: (1) a hierarchical
adaptation framework that integrates a Domain-level Alignment Solver for
feature alignment, a Slide-level Geometric Invariance Regularization to
preserve the morphological structure, and a Patch-level Attention Consistency
Regularization to maintain local critical diagnostic cues; and (2) a prototype
selection mechanism that reduces computational overhead. We validate our method
on two slide-level tasks across five datasets, achieving a 4.1\% AUROC
improvement in a Breast Cancer HER2 Grading cohort and a 3.9\% C-index gain in
a UCEC survival prediction cohort. Our method provides a practical and reliable
slide-level domain adaption solution for pathology institutions, minimizing
both computational and annotation costs.

</details>


### [439] [BayesL: Towards a Logical Framework for Bayesian Networks](https://arxiv.org/abs/2506.23773)
*Stefano M. Nicoletti,Mariëlle Stoelinga*

Main category: cs.AI

Relevance: 30.0

TL;DR: BayesL是一个用于指定、查询和验证贝叶斯网络行为的新逻辑框架。


<details>
  <summary>Details</summary>
Motivation: 开发BayesL的目的是为了提供一个结构化语言，方便对贝叶斯网络进行查询和推理，支持因果和证据关系的灵活分析，无需手动修改模型即可进行全面的假设场景评估。

Method: BayesL是一种结构化语言，允许创建对贝叶斯网络的查询，支持因果和证据关系的推理，以及假设场景的自动评估。

Result: BayesL能够高效地支持贝叶斯网络的查询和验证，实现灵活的因果和证据关系分析。

Conclusion: BayesL为贝叶斯网络的行为规范和验证提供了一个强大的工具，简化了复杂推理过程。

Abstract: We introduce BayesL, a novel logical framework for specifying, querying, and
verifying the behaviour of Bayesian networks (BNs). BayesL (pronounced "Basil")
is a structured language that allows for the creation of queries over BNs. It
facilitates versatile reasoning concerning causal and evidence-based
relationships, and permits comprehensive what-if scenario evaluations without
the need for manual modifications to the model.

</details>


### [440] [Heart rate and respiratory rate prediction from noisy real-world smartphone based on Deep Learning methods](https://arxiv.org/abs/2506.22460)
*Ibne Farabi Shihab*

Main category: eess.SP

Relevance: 30.0

TL;DR: 该研究提出了一种基于3D深度CNN的新方法，用于通过手机视频估计心率和呼吸率，显著降低了误差。


<details>
  <summary>Details</summary>
Motivation: 现有方法在实验室环境下表现良好，但在日常生活中表现不佳，因此需要改进。

Method: 使用新型3D深度CNN模型处理手机视频数据，估计心率和呼吸率。

Result: 与传统算法相比，新方法将心率估计误差降低了68%，呼吸率误差降低了75%。

Conclusion: 基于回归器的深度学习方法在估计心率和呼吸率方面具有潜力。

Abstract: Using mobile phone video of the fingertip as a data source for estimating
vital signs such as heart rate (HR) and respiratory rate (RR) during daily life
has long been suggested. While existing literature indicates that these
estimates are accurate to within several beats or breaths per minute, the data
used to draw these conclusions are typically collected in laboratory
environments under careful experimental control, and yet the results are
assumed to generalize to daily life. In an effort to test it, a team of
researchers collected a large dataset of mobile phone video recordings made
during daily life and annotated with ground truth HR and RR labels from N=111
participants. They found that traditional algorithm performance on the
fingerprint videos is worse than previously reported (7 times and 13 times
worse for RR and HR, respectively). Fortunately, recent advancements in deep
learning, especially in convolutional neural networks (CNNs), offer a promising
solution to improve this performance. This study proposes a new method for
estimating HR and RR using a novel 3D deep CNN, demonstrating a reduced error
in estimated HR by 68% and RR by 75%. These promising results suggest that
regressor-based deep learning approaches should be used in estimating HR and
RR.

</details>


### [441] [Privacy-aware IoT Fall Detection Services For Aging in Place](https://arxiv.org/abs/2506.22462)
*Abdallah Lakhdari,Jiajie Li,Amani Abusafia,Athman Bouguettaya*

Main category: eess.SP

Relevance: 30.0

TL;DR: 论文提出了一种基于物联网的跌倒检测服务框架（FDaaS），利用UWB雷达传感器和生成式预训练Transformer（FD-GPT）解决数据稀缺和隐私问题，并在实验中达到90.72%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着老年人口增长，跌倒检测需求增加，但现有方法面临数据稀缺和隐私问题。

Method: 设计了基于UWB雷达传感器的服务架构，使用FD-GPT进行数据增强，并开发了数据集收集协议。

Result: 实验结果显示，方法在区分跌倒和日常活动时达到90.72%准确率和89.33%精确率。

Conclusion: FDaaS框架在隐私保护和数据稀缺问题上有显著优势，适用于老年人群。

Abstract: Fall detection is critical to support the growing elderly population,
projected to reach 2.1 billion by 2050. However, existing methods often face
data scarcity challenges or compromise privacy. We propose a novel IoT-based
Fall Detection as a Service (FDaaS) framework to assist the elderly in living
independently and safely by accurately detecting falls. We design a
service-oriented architecture that leverages Ultra-wideband (UWB) radar sensors
as an IoT health-sensing service, ensuring privacy and minimal intrusion. We
address the challenges of data scarcity by utilizing a Fall Detection
Generative Pre-trained Transformer (FD-GPT) that uses augmentation techniques.
We developed a protocol to collect a comprehensive dataset of the elderly daily
activities and fall events. This resulted in a real dataset that carefully
mimics the elderly's routine. We rigorously evaluate and compare various models
using this dataset. Experimental results show our approach achieves 90.72%
accuracy and 89.33% precision in distinguishing between fall events and regular
activities of daily living.

</details>


### [442] [Dimensionality Reduction on IoT Monitoring Data of Smart Building for Energy Consumption Forecasting](https://arxiv.org/abs/2506.22468)
*Konstantinos Koutras,Agorakis Bompotas,Constantinos Halkiopoulos,Athanasios Kalogeras,Christos Alexakos*

Main category: eess.SP

Relevance: 30.0

TL;DR: 该论文研究了物联网（IoT）中数据相关性分析，以减少输入参数并保持预测准确性，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 研究动机是通过统计相关性分析，减少机器学习预测算法中的输入参数，同时保持准确性，适用于资源受限的边缘计算环境。

Method: 通过假设检验分析三个环境变量与能耗的相关性，共进行90次测试，筛选出强相关变量。

Result: 测试结果显示两个环境变量与能耗存在强或半强相关性，另一个变量相关性较弱。通过排除弱相关变量，保持了预测准确性。

Conclusion: 该方法可以在不检查全部数据的情况下，有效减少输入参数并保持预测准确性，适用于资源受限的IoT环境。

Abstract: The Internet of Things (IoT) plays a major role today in smart building
infrastructures, from simple smart-home applications, to more sophisticated
industrial type installations. The vast amounts of data generated from relevant
systems can be processed in different ways revealing important information.
This is especially true in the era of edge computing, when advanced data
analysis and decision-making is gradually moving to the edge of the network
where devices are generally characterised by low computing resources. In this
context, one of the emerging main challenges is related to maintaining data
analysis accuracy even with less data that can be efficiently handled by low
resource devices. The present work focuses on correlation analysis of data
retrieved from a pilot IoT network installation monitoring a small smart office
by means of environmental and energy consumption sensors. The research
motivation was to find statistical correlation between the monitoring variables
that will allow the use of machine learning (ML) prediction algorithms for
energy consumption reducing input parameters. For this to happen, a series of
hypothesis tests for the correlation of three different environmental variables
with the energy consumption were carried out. A total of ninety tests were
performed, thirty for each pair of variables. In these tests, p-values showed
the existence of strong or semi-strong correlation with two environmental
variables, and of a weak correlation with a third one. Using the proposed
methodology, we manage without examining the entire data set to exclude weak
correlated variables while keeping the same score of accuracy.

</details>


### [443] [AGI Enabled Solutions For IoX Layers Bottlenecks In Cyber-Physical-Social-Thinking Space](https://arxiv.org/abs/2506.22487)
*Amar Khelloufi,Huansheng Ning,Sahraoui Dhelim,Jianguo Ding*

Main category: cs.NI

Relevance: 30.0

TL;DR: 该论文综述了AGI增强的IoX研究，探讨了在感知层、网络层和应用层的关键挑战及解决方案，强调了跨层集成和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决IoX在感知、网络和应用层的瓶颈问题，探索AGI如何通过自适应传感器融合、边缘预处理等技术优化这些层。

Method: 采用系统综述方法，分析AGI在IoX中的三大关键组件：感知层数据管理、网络层协议优化和应用层决策框架。

Result: 发现AGI驱动的策略（如自适应传感器融合和语义建模）能有效解决数据过载、协议异构性和身份爆炸问题。

Conclusion: 结论指出AGI增强的IoX是一个新兴关键领域，但仍需解决计算需求、可扩展性和实际验证等挑战。

Abstract: The integration of the Internet of Everything (IoX) and Artificial General
Intelligence (AGI) has given rise to a transformative paradigm aimed at
addressing critical bottlenecks across sensing, network, and application layers
in Cyber-Physical-Social Thinking (CPST) ecosystems. In this survey, we provide
a systematic and comprehensive review of AGI-enhanced IoX research, focusing on
three key components: sensing-layer data management, network-layer protocol
optimization, and application-layer decision-making frameworks. Specifically,
this survey explores how AGI can mitigate IoX bottlenecks challenges by
leveraging adaptive sensor fusion, edge preprocessing, and selective attention
mechanisms at the sensing layer, while resolving network-layer issues such as
protocol heterogeneity and dynamic spectrum management, neuro-symbolic
reasoning, active inference, and causal reasoning, Furthermore, the survey
examines AGI-enabled frameworks for managing identity and relationship
explosion. Key findings suggest that AGI-driven strategies, such as adaptive
sensor fusion, edge preprocessing, and semantic modeling, offer novel solutions
to sensing-layer data overload, network-layer protocol heterogeneity, and
application-layer identity explosion. The survey underscores the importance of
cross-layer integration, quantum-enabled communication, and ethical governance
frameworks for future AGI-enabled IoX systems. Finally, the survey identifies
unresolved challenges, such as computational requirements, scalability, and
real-world validation, calling for further research to fully realize AGI's
potential in addressing IoX bottlenecks. we believe AGI-enhanced IoX is
emerging as a critical research field at the intersection of interconnected
systems and advanced AI.

</details>


### [444] [Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses](https://arxiv.org/abs/2506.22495)
*He-Yang Xu,Hongxiang Gao,Yuwen Li,Xiu-Shen Wei,Chengyu Liu*

Main category: eess.SP

Relevance: 30.0

TL;DR: 论文提出了一种自监督学习方法，通过时间-频率感知滤波器和多粒度原型重建，减轻ECG分析中的简单性偏差（SB），并在大规模数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: ECG诊断中，监督模型容易过拟合主导模式而忽略细微但临床关键的线索（简单性偏差SB），自监督学习（SSL）被证明可以缓解这一问题。

Method: 1) 时间-频率感知滤波器捕捉ECG信号的动态特征；2) 多粒度原型重建实现双域（时间和频率）的粗粒度和细粒度表示学习。

Result: 在六个ECG数据集上的三个下游任务中，该方法显著减轻SB并达到SOTA性能。

Conclusion: 自监督学习是解决ECG分析中简单性偏差的有效方向，提出的方法具有实际应用潜力。

Abstract: The diagnostic value of electrocardiogram (ECG) lies in its dynamic
characteristics, ranging from rhythm fluctuations to subtle waveform
deformations that evolve across time and frequency domains. However, supervised
ECG models tend to overfit dominant and repetitive patterns, overlooking
fine-grained but clinically critical cues, a phenomenon known as Simplicity
Bias (SB), where models favor easily learnable signals over subtle but
informative ones. In this work, we first empirically demonstrate the presence
of SB in ECG analyses and its negative impact on diagnostic performance, while
simultaneously discovering that self-supervised learning (SSL) can alleviate
it, providing a promising direction for tackling the bias. Following the SSL
paradigm, we propose a novel method comprising two key components: 1)
Temporal-Frequency aware Filters to capture temporal-frequency features
reflecting the dynamic characteristics of ECG signals, and 2) building on this,
Multi-Grained Prototype Reconstruction for coarse and fine representation
learning across dual domains, further mitigating SB. To advance SSL in ECG
analyses, we curate a large-scale multi-site ECG dataset with 1.53 million
recordings from over 300 clinical centers. Experiments on three downstream
tasks across six ECG datasets demonstrate that our method effectively reduces
SB and achieves state-of-the-art performance. Code and dataset will be released
publicly.

</details>


### [445] [Ask before you Build: Rethinking AI-for-Good in Human Trafficking Interventions](https://arxiv.org/abs/2506.22512)
*Pratheeksha Nair,Gabriel Lefebvre,Sophia Garrel,Maryam Molamohammadi,Reihaneh Rabbany*

Main category: cs.CY

Relevance: 30.0

TL;DR: 论文提出了Radical Questioning (RQ)框架，作为AI项目前的伦理评估工具，旨在避免技术解决方案主义对社会问题的简化处理。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在解决复杂社会问题（如人口贩卖）时的伦理风险，避免技术干预带来的潜在危害。

Method: 提出五步RQ框架，通过案例研究（AI用于人口贩卖）展示其应用。

Result: RQ揭示了被忽视的社会文化复杂性，并引导设计从监控转向幸存者赋权工具。

Conclusion: RQ框架可推广至其他领域，强调伦理评估的重要性，挑战工具主义规范。

Abstract: AI for good initiatives often rely on the assumption that technical
interventions can resolve complex social problems. In the context of human
trafficking (HT), such techno-solutionism risks oversimplifying exploitation,
reinforcing power imbalances and causing harm to the very communities AI claims
to support. In this paper, we introduce the Radical Questioning (RQ) framework
as a five step, pre-project ethical assessment tool to critically evaluate
whether AI should be built at all, especially in domains involving marginalized
populations and entrenched systemic injustice. RQ does not replace principles
based ethics but precedes it, offering an upstream, deliberative space to
confront assumptions, map power, and consider harms before design. Using a case
study in AI for HT, we demonstrate how RQ reveals overlooked sociocultural
complexities and guides us away from surveillance based interventions toward
survivor empowerment tools. While developed in the context of HT, RQ's five
step structure can generalize to other domains, though the specific questions
must be contextual. This paper situates RQ within a broader AI ethics
philosophy that challenges instrumentalist norms and centers relational,
reflexive responsibility.

</details>


### [446] [Correlated Mutations for Integer Programming](https://arxiv.org/abs/2506.22526)
*Ofer M. Shir,Michael Emmerich*

Main category: math.OC

Relevance: 30.0

TL;DR: 论文提出了整数进化策略（IESs）的基础，专注于离散搜索，采用ℓ₁范数，并研究了截断正态（TN）和双几何（DG）分布的理论性质。结果表明DG分布更适合无界整数搜索。


<details>
  <summary>Details</summary>
Motivation: 尽管整数规划（IP）的理论进展显著降低了其复杂性，但启发式方法仍是主要解决方案。本研究旨在为连续空间设计的随机搜索启发式方法（IESs）奠定离散搜索的基础。

Method: 采用ℓ₁范数，研究适合的步长，并探索整数格上的相关性度量。重点研究了无界整数决策变量的变异分布，比较了TN和DG分布的理论性质。

Result: 数值模拟表明DG分布更适合无界整数搜索，且使用DG变异的IES在非可分二次IP中表现更优。

Conclusion: DG分布替换TN分布具有理论和实践优势，但更关键的是采用ℓ₁范数而非ℓ₂范数。

Abstract: Even with the recent theoretical advancements that dramatically reduced the
complexity of Integer Programming (IP), heuristics remain the dominant
problem-solvers for this difficult category. This study seeks to establish the
groundwork for Integer Evolution Strategies (IESs), a class of randomized
search heuristics inherently designed for continuous spaces. IESs already excel
in treating IP in practice, but accomplish it via discretization and by
applying sophisticated patches to their continuous operators, while
persistently using the $\ell_2$-norm as their operation pillar. We lay
foundations for discrete search, by adopting the $\ell_1$-norm, accounting for
the suitable step-size, and questioning alternative measures to quantify
correlations over the integer lattice. We focus on mutation distributions for
unbounded integer decision variables. We briefly discuss a couple of candidate
discrete probabilities induced by the uniform and binomial distributions, which
we show to possess less appealing theoretical properties, and then narrow down
to the Truncated Normal (TN) and Double Geometric (DG) distributions. We
explore their theoretical properties, including entropy functions, and propose
a procedure to generate scalable correlated mutation distributions. Our
investigations are accompanied by extensive numerical simulations, which
consistently support the claim that the DG distribution is better suited for
unbounded integer search. We link our theoretical perspective to empirical
evidence indicating that an IES with correlated DG mutations outperformed other
strategies over non-separable quadratic IP. We conclude that while the
replacement of the default TN distribution by the DG is theoretically justified
and practically beneficial, the truly crucial change lies in adopting the
$\ell_1$-norm over the $\ell_2$-norm.

</details>


### [447] [FedCLAM: Client Adaptive Momentum with Foreground Intensity Matching for Federated Medical Image Segmentation](https://arxiv.org/abs/2506.22580)
*Vasilis Siomos,Jonathan Passerat-Palmbach,Giacomo Tarroni*

Main category: eess.IV

Relevance: 30.0

TL;DR: FedCLAM是一种联邦学习方法，通过客户端自适应动量和个性化阻尼因子解决医学影像中的特征差异问题，并在分割任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 医学影像中设备和人群的多样性导致特征差异，现有聚合方法无法适应，需提出新方法提升模型效果。

Method: 结合客户端自适应动量、个性化阻尼因子和强度对齐损失，处理特征差异和图像强度分布问题。

Result: 在两个数据集上的评估显示，FedCLAM在医学分割任务中优于八种前沿方法。

Conclusion: FedCLAM有效解决了医学影像联邦学习中的特征差异问题，提升了模型性能。

Abstract: Federated learning is a decentralized training approach that keeps data under
stakeholder control while achieving superior performance over isolated
training. While inter-institutional feature discrepancies pose a challenge in
all federated settings, medical imaging is particularly affected due to diverse
imaging devices and population variances, which can diminish the global model's
effectiveness. Existing aggregation methods generally fail to adapt across
varied circumstances. To address this, we propose FedCLAM, which integrates
\textit{client-adaptive momentum} terms derived from each client's loss
reduction during local training, as well as a \textit{personalized dampening
factor} to curb overfitting. We further introduce a novel \textit{intensity
alignment} loss that matches predicted and ground-truth foreground
distributions to handle heterogeneous image intensity profiles across
institutions and devices. Extensive evaluations on two datasets show that
FedCLAM surpasses eight cutting-edge methods in medical segmentation tasks,
underscoring its efficacy. The code is available at
https://github.com/siomvas/FedCLAM.

</details>


### [448] [Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding](https://arxiv.org/abs/2506.22593)
*Antonello Longo,Chanyoung Chung,Matteo Palieri,Sung-Kyun Kim,Ali Agha,Cataldo Guaragnella,Shehryar Khattak*

Main category: cs.RO

Relevance: 30.0

TL;DR: Pix2G是一种轻量级方法，用于从图像像素和LiDAR地图实时生成结构化场景图，以支持资源受限机器人平台的自主探索。


<details>
  <summary>Details</summary>
Motivation: 解决人类操作员与机器人之间在高效协作和理解方面的需求，尤其是在高风险应用中。

Method: 通过CPU上的实时处理，从图像和LiDAR数据生成去噪的2D地图和结构分割的3D点云，并通过多层图连接。

Result: 在NASA JPL NeBula-Spot机器人上进行了真实环境实验，验证了方法的实时性和有效性。

Conclusion: Pix2G为资源受限平台提供了一种高效的场景图生成方法，支持自主探索。

Abstract: Autonomous robots are increasingly playing key roles as support platforms for
human operators in high-risk, dangerous applications. To accomplish challenging
tasks, an efficient human-robot cooperation and understanding is required.
While typically robotic planning leverages 3D geometric information, human
operators are accustomed to a high-level compact representation of the
environment, like top-down 2D maps representing the Building Information Model
(BIM). 3D scene graphs have emerged as a powerful tool to bridge the gap
between human readable 2D BIM and the robot 3D maps. In this work, we introduce
Pixels-to-Graph (Pix2G), a novel lightweight method to generate structured
scene graphs from image pixels and LiDAR maps in real-time for the autonomous
exploration of unknown environments on resource-constrained robot platforms. To
satisfy onboard compute constraints, the framework is designed to perform all
operation on CPU only. The method output are a de-noised 2D top-down
environment map and a structure-segmented 3D pointcloud which are seamlessly
connected using a multi-layer graph abstracting information from object-level
up to the building-level. The proposed method is quantitatively and
qualitatively evaluated during real-world experiments performed using the NASA
JPL NeBula-Spot legged robot to autonomously explore and map cluttered garage
and urban office like environments in real-time.

</details>


### [449] [Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision](https://arxiv.org/abs/2506.22656)
*Jiangping Huang,Dongming Jin,Weisong Sun,Yang Liu,Zhi Jin*

Main category: cs.SE

Relevance: 30.0

TL;DR: 提出了一种名为KGMAF的知识引导多智能体框架，用于自动化需求开发，填补了当前SE自动化系统中忽视需求任务的空白。


<details>
  <summary>Details</summary>
Motivation: 当前SE自动化系统过于关注代码开发，忽视了需求任务的复杂性，KGMAF旨在解决这一问题。

Method: KGMAF由六个专用智能体和一个工件池组成，详细描述了每个智能体的功能、行为和知识，并提供了工件池的概念设计。

Result: 案例研究表明KGMAF在现实场景中具有潜力。

Conclusion: KGMAF有望在LLM时代推动自动化需求开发的未来发展。

Abstract: This paper envisions a knowledge-guided multi-agent framework named KGMAF for
automated requirements development. KGMAF aims to address gaps in current
automation systems for SE, which prioritize code development and overlook the
complexities of requirements tasks. KGMAF is composed of six specialized agents
and an artifact pool to improve efficiency and accuracy. Specifically, KGMAF
outlines the functionality, actions, and knowledge of each agent and provides
the conceptual design of the artifact pool. Our case study highlights the
potential of KGMAF in real-world scenarios. Finally, we outline several
research opportunities for implementing and enhancing automated requirements
development using multi-agent systems. We believe that KGMAF will play a
pivotal role in shaping the future of automated requirements development in the
era of LLMs.

</details>


### [450] [General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers](https://arxiv.org/abs/2506.22706)
*Arun Ramamurthy,Neil Dhir*

Main category: cs.CR

Relevance: 30.0

TL;DR: 该论文探讨了在动态网络环境中开发通用自主网络安全防御（GACD）系统的方法，以解决现有系统因静态假设而导致的泛化能力不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有自主网络安全防御（ACD）系统依赖静态网络动态假设，无法适应现实中的动态网络拓扑变化，导致泛化能力受限。

Method: 研究开发了通用自主网络安全防御（GACD）方法，旨在学习适用于动态网络环境的策略。

Result: 提出了能够适应动态网络拓扑变化的防御策略，提升了系统的泛化能力。

Conclusion: GACD方法为动态网络环境中的安全防御提供了更通用的解决方案。

Abstract: In the face of evolving cyber threats such as malware, ransomware and
phishing, autonomous cybersecurity defense (ACD) systems have become essential
for real-time threat detection and response with optional human intervention.
However, existing ACD systems rely on limiting assumptions, particularly the
stationarity of the underlying network dynamics. In real-world scenarios,
network topologies can change due to actions taken by attackers or defenders,
system failures, or time evolution of networks, leading to failures in the
adaptive capabilities of current defense agents. Moreover, many agents are
trained on static environments, resulting in overfitting to specific
topologies, which hampers their ability to generalize to out-of-distribution
network topologies. This work addresses these challenges by exploring methods
for developing agents to learn generalizable policies across dynamic network
environments -- general ACD (GACD).

</details>


### [451] [A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance](https://arxiv.org/abs/2506.22949)
*Ehsan Hallaji,Vaishnavi Shanmugam,Roozbeh Razavi-Far,Mehrdad Saif*

Main category: cs.CR

Relevance: 30.0

TL;DR: 论文研究了半监督学习（SSL）在检测DDoS攻击中的应用，评估了13种SSL算法在数据不平衡和部分标记情况下的表现。


<details>
  <summary>Details</summary>
Motivation: 解决DDoS攻击检测中的数据不平衡和标记不足问题，提升入侵检测系统（IDS）的智能性和鲁棒性。

Method: 评估了13种最先进的SSL算法，分析其在极端环境下的实际效果和局限性。

Result: 提供了关于设计能处理数据不平衡和部分标记数据的智能IDS的见解。

Conclusion: SSL技术能有效改善DDoS攻击检测，尤其在数据不平衡和标记不足的情况下。

Abstract: One of the most difficult challenges in cybersecurity is eliminating
Distributed Denial of Service (DDoS) attacks. Automating this task using
artificial intelligence is a complex process due to the inherent class
imbalance and lack of sufficient labeled samples of real-world datasets. This
research investigates the use of Semi-Supervised Learning (SSL) techniques to
improve DDoS attack detection when data is imbalanced and partially labeled. In
this process, 13 state-of-the-art SSL algorithms are evaluated for detecting
DDoS attacks in several scenarios. We evaluate their practical efficacy and
shortcomings, including the extent to which they work in extreme environments.
The results will offer insight into designing intelligent Intrusion Detection
Systems (IDSs) that are robust against class imbalance and handle partially
labeled data.

</details>


### [452] [Enhancing Live Broadcast Engagement: A Multi-modal Approach to Short Video Recommendations Using MMGCN and User Preferences](https://arxiv.org/abs/2506.23085)
*Saeid Aghasoleymani Najafabadi*

Main category: cs.IR

Relevance: 30.0

TL;DR: 论文提出了一种基于多模态图卷积网络（MMGCN）的短视频推荐系统，结合用户偏好提升直播互动。


<details>
  <summary>Details</summary>
Motivation: 探索多模态方法以增强直播互动，通过个性化推荐系统满足用户兴趣。

Method: 结合协同过滤和基于内容的过滤技术，利用MMGCN整合用户交互数据、视频内容和上下文信息。

Result: 在Kwai、TikTok和MovieLens数据集上表现优于基线模型（如DeepFM、LightGBM等），F1分数分别为0.574、0.506和0.197。

Conclusion: 多模态整合和用户中心方法对推荐系统至关重要，能提升内容发现和互动效果。

Abstract: The purpose of this paper is to explore a multi-modal approach to enhancing
live broadcast engagement by developing a short video recommendation system
that incorporates Multi-modal Graph Convolutional Networks (MMGCN) with user
preferences. In order to provide personalized recommendations tailored to
individual interests, the proposed system takes into account user interaction
data, video content features, and contextual information. With the aid of a
hybrid approach combining collaborative filtering and content-based filtering
techniques, the system is able to capture nuanced relationships between users,
video attributes, and engagement patterns. Three datasets are used to evaluate
the effectiveness of the system: Kwai, TikTok, and MovieLens. Compared to
baseline models, such as DeepFM, Wide & Deep, LightGBM, and XGBoost, the
proposed MMGCN-based model shows superior performance. A notable feature of the
proposed model is that it outperforms all baseline methods in capturing diverse
user preferences and making accurate, personalized recommendations, resulting
in a Kwai F1 score of 0.574, a Tiktok F1 score of 0.506, and a MovieLens F1
score of 0.197. We emphasize the importance of multi-modal integration and
user-centric approaches in advancing recommender systems, emphasizing the role
they play in enhancing content discovery and audience interaction on live
broadcast platforms.

</details>


### [453] [CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation](https://arxiv.org/abs/2506.23121)
*Xinlei Yu,Chanmiao Wang,Hui Jin,Ahmed Elazab,Gangyong Jia,Xiang Wan,Changqing Zou,Ruiquan Ge*

Main category: eess.IV

Relevance: 30.0

TL;DR: CRISP-SAM2是一种基于SAM2的多器官医学分割模型，通过跨模态交互和语义提示解决现有模型的细节不准确、依赖几何提示和空间信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 解决多器官医学分割中细节不准确、依赖几何提示和空间信息丢失的挑战。

Method: 使用渐进式跨注意力交互机制将视觉和文本输入转换为跨模态语义，注入图像编码器；采用语义提示策略替代原始提示编码器；应用相似性排序自更新内存和掩码细化策略。

Result: 在七个公共数据集上表现优于现有模型，尤其在解决前述局限性方面。

Conclusion: CRISP-SAM2在多器官医学分割中表现出色，解决了现有模型的局限性。

Abstract: Multi-organ medical segmentation is a crucial component of medical image
processing, essential for doctors to make accurate diagnoses and develop
effective treatment plans. Despite significant progress in this field, current
multi-organ segmentation models often suffer from inaccurate details,
dependence on geometric prompts and loss of spatial information. Addressing
these challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal
Interaction and Semantic Prompting based on SAM2. This model represents a
promising approach to multi-organ medical segmentation guided by textual
descriptions of organs. Our method begins by converting visual and textual
inputs into cross-modal contextualized semantics using a progressive
cross-attention interaction mechanism. These semantics are then injected into
the image encoder to enhance the detailed understanding of visual information.
To eliminate reliance on geometric prompts, we use a semantic prompting
strategy, replacing the original prompt encoder to sharpen the perception of
challenging targets. In addition, a similarity-sorting self-updating strategy
for memory and a mask-refining process is applied to further adapt to medical
imaging and enhance localized details. Comparative experiments conducted on
seven public datasets indicate that CRISP-SAM2 outperforms existing models.
Extensive analysis also demonstrates the effectiveness of our method, thereby
confirming its superior performance, especially in addressing the limitations
mentioned earlier. Our code is available at:
https://github.com/YU-deep/CRISP\_SAM2.git.

</details>


### [454] [Interpretable by Design: MH-AutoML for Transparent and Efficient Android Malware Detection without Compromising Performance](https://arxiv.org/abs/2506.23314)
*Joner Assolin,Gabriel Canto,Diego Kreutz,Eduardo Feitosa,Hendrio Bragança,Angelo Nogueira,Vanderson Rocha*

Main category: cs.CR

Relevance: 30.0

TL;DR: MH-AutoML是一个针对Android恶意软件检测的领域专用AutoML框架，提供透明性、可解释性和实验追踪功能，性能优于现有AutoML方案。


<details>
  <summary>Details</summary>
Motivation: 当前AutoML解决方案多为黑盒系统，缺乏透明性和可解释性，MH-AutoML旨在解决这些问题。

Method: MH-AutoML自动化整个ML流程，包括数据预处理、特征工程、算法选择和超参数调优，并集成解释性、调试和实验追踪功能。

Result: MH-AutoML在召回率上优于七种现有AutoML框架，同时保持计算效率。

Conclusion: MH-AutoML在性能和可解释性方面表现优异，适用于网络安全应用。

Abstract: Malware detection in Android systems requires both cybersecurity expertise
and machine learning (ML) techniques. Automated Machine Learning (AutoML) has
emerged as an approach to simplify ML development by reducing the need for
specialized knowledge. However, current AutoML solutions typically operate as
black-box systems with limited transparency, interpretability, and experiment
traceability. To address these limitations, we present MH-AutoML, a
domain-specific framework for Android malware detection. MH-AutoML automates
the entire ML pipeline, including data preprocessing, feature engineering,
algorithm selection, and hyperparameter tuning. The framework incorporates
capabilities for interpretability, debugging, and experiment tracking that are
often missing in general-purpose solutions. In this study, we compare MH-AutoML
against seven established AutoML frameworks: Auto-Sklearn, AutoGluon, TPOT,
HyperGBM, Auto-PyTorch, LightAutoML, and MLJAR. Results show that MH-AutoML
achieves better recall rates while providing more transparency and control. The
framework maintains computational efficiency comparable to other solutions,
making it suitable for cybersecurity applications where both performance and
explainability matter.

</details>


### [455] [Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop](https://arxiv.org/abs/2506.23351)
*Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yuchen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu*

Main category: cs.RO

Relevance: 30.0

TL;DR: 该论文介绍了RoboTwin双臂协作挑战赛，旨在推动复杂物理环境中双臂机器人的协作能力研究。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发能够在复杂物理环境中感知、推理和行动的双臂协作机器人系统。

Method: 方法包括基于RoboTwin仿真平台和AgileX COBOT-Magic机器人平台的三阶段竞赛设计，涵盖17种双臂操作任务。

Result: 64个全球团队参与，产生了如SEM和AnchorDP3等高性能解决方案，并提供了关于通用双臂策略学习的重要见解。

Conclusion: 结论是竞赛为未来研究提供了关于鲁棒和通用双臂操作策略的宝贵数据和方向。

Abstract: Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in
robotics, driven by the need for autonomous systems that can perceive, reason,
and act in complex physical environments. While single-arm systems have shown
strong task performance, collaborative dual-arm systems are essential for
handling more intricate tasks involving rigid, deformable, and
tactile-sensitive objects. To advance this goal, we launched the RoboTwin
Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on
the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot
platform, the competition consisted of three stages: Simulation Round 1,
Simulation Round 2, and a final Real-World Round. Participants totally tackled
17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based
scenarios. The challenge attracted 64 global teams and over 400 participants,
producing top-performing solutions like SEM and AnchorDP3 and generating
valuable insights into generalizable bimanual policy learning. This report
outlines the competition setup, task design, evaluation methodology, key
findings and future direction, aiming to support future research on robust and
generalizable bimanual manipulation policies. The Challenge Webpage is
available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.

</details>


### [456] [From Large-scale Audio Tagging to Real-Time Explainable Emergency Vehicle Sirens Detection](https://arxiv.org/abs/2506.23437)
*Stefano Giacomelli,Marco Giordano,Claudia Rinaldi,Fabio Graziosi*

Main category: cs.SD

Relevance: 30.0

TL;DR: 论文提出了一种轻量级卷积神经网络E2PANNs，用于紧急车辆警笛声的检测，优化了计算效率并验证了其在边缘设备上的实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动解决方案在紧急车辆警笛声检测中面临数据集不足和计算需求高的问题，亟需高效且轻量化的模型。

Method: 基于PANNs框架设计E2PANNs，利用专用数据集AudioSet EV进行微调和评估，并通过消融研究、跨域基准测试和边缘设备部署验证性能。

Result: E2PANNs在紧急车辆警笛声检测中达到最新技术水平，具有高计算效率和边缘设备适用性。

Conclusion: E2PANNs为紧急车辆警笛声检测提供了高效且轻量化的解决方案，适用于实时音频监控和安全关键应用。

Abstract: Accurate recognition of Emergency Vehicle (EV) sirens is critical for the
integration of intelligent transportation systems, smart city monitoring
systems, and autonomous driving technologies. Modern automatic solutions are
limited by the lack of large scale, curated datasets and by the computational
demands of state of the art sound event detection models. This work introduces
E2PANNs (Efficient Emergency Pre trained Audio Neural Networks), a lightweight
Convolutional Neural Network architecture derived from the PANNs framework,
specifically optimized for binary EV siren detection. Leveraging our dedicated
subset of AudioSet (AudioSet EV) we fine-tune and evaluate E2PANNs across
multiple reference datasets and test its viability on embedded hardware. The
experimental campaign includes ablation studies, cross-domain benchmarking, and
real-time inference deployment on edge device. Interpretability analyses
exploiting Guided Backpropagation and ScoreCAM algorithms provide insights into
the model internal representations and validate its ability to capture distinct
spectrotemporal patterns associated with different types of EV sirens. Real
time performance is assessed through frame wise and event based detection
metrics, as well as a detailed analysis of false positive activations. Results
demonstrate that E2PANNs establish a new state of the art in this research
domain, with high computational efficiency, and suitability for edge-based
audio monitoring and safety-critical applications.

</details>


### [457] [Online Human Action Detection during Escorting](https://arxiv.org/abs/2506.23573)
*Siddhartha Mondal,Avik Mitra,Chayan Sarkar*

Main category: cs.RO

Relevance: 30.0

TL;DR: 论文提出了一种新型神经网络架构，用于实时行人重识别和动作预测，以提升机器人在拥挤环境中的护送服务效果。


<details>
  <summary>Details</summary>
Motivation: 当前护送机器人主要依赖导航策略，假设被护送者会顺利跟随，但在拥挤环境中这一假设常不成立，导致服务效果不佳。

Method: 提出了一种能同时进行行人重识别和动作预测的神经网络架构，使机器人能动态调整速度并恢复护送任务。

Result: 在对比评估中，该系统表现出更高的效率和有效性，显著提升了复杂场景下的机器人护送服务。

Conclusion: 该研究为解决拥挤环境中机器人护送服务的挑战提供了有效解决方案。

Abstract: The deployment of robot assistants in large indoor spaces has seen
significant growth, with escorting tasks becoming a key application. However,
most current escorting robots primarily rely on navigation-focused strategies,
assuming that the person being escorted will follow without issue. In crowded
environments, this assumption often falls short, as individuals may struggle to
keep pace, become obstructed, get distracted, or need to stop unexpectedly. As
a result, conventional robotic systems are often unable to provide effective
escorting services due to their limited understanding of human movement
dynamics. To address these challenges, an effective escorting robot must
continuously detect and interpret human actions during the escorting process
and adjust its movement accordingly. However, there is currently no existing
dataset designed specifically for human action detection in the context of
escorting. Given that escorting often occurs in crowded environments, where
other individuals may enter the robot's camera view, the robot also needs to
identify the specific human it is escorting (the subject) before predicting
their actions. Since no existing model performs both person re-identification
and action prediction in real-time, we propose a novel neural network
architecture that can accomplish both tasks. This enables the robot to adjust
its speed dynamically based on the escortee's movements and seamlessly resume
escorting after any disruption. In comparative evaluations against strong
baselines, our system demonstrates superior efficiency and effectiveness,
showcasing its potential to significantly improve robotic escorting services in
complex, real-world scenarios.

</details>


### [458] [The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking](https://arxiv.org/abs/2506.23628)
*Antonio Ojea*

Main category: cs.NI

Relevance: 30.0

TL;DR: 论文提出Kubernetes Network Drivers (KNDs)，一种模块化、声明式架构，用于解决传统Kubernetes网络在AI/ML和Telco基础设施中的不足。


<details>
  <summary>Details</summary>
Motivation: 传统Kubernetes网络无法满足AI/ML和高性能Telco基础设施的需求，需要更高效、灵活的解决方案。

Method: 利用Dynamic Resource Allocation (DRA)、Node Resource Interface (NRI)改进和OCI Runtime Specification变更，设计KNDs架构。

Result: DraNet实现展示了声明式网络接口附加功能，显著提升高性能AI/ML工作负载。

Conclusion: KNDs为云原生应用和未来Telco解决方案奠定基础，减少操作复杂性。

Abstract: Traditional Kubernetes networking struggles to meet the escalating demands of
AI/ML and evolving Telco infrastructure. This paper introduces Kubernetes
Network Drivers (KNDs), a transformative, modular, and declarative architecture
designed to overcome current imperative provisioning and API limitations. KNDs
integrate network resource management into Kubernetes' core by utilizing
Dynamic Resource Allocation (DRA), Node Resource Interface (NRI) improvements,
and upcoming OCI Runtime Specification changes. Our DraNet implementation
demonstrates declarative attachment of network interfaces, including Remote
Direct Memory Access (RDMA) devices, significantly boosting high-performance
AI/ML workloads. This capability enables sophisticated cloud-native
applications and lays crucial groundwork for future Telco solutions, fostering
a "galaxy" of specialized KNDs for enhanced application delivery and reduced
operational complexity.

</details>


### [459] [gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures](https://arxiv.org/abs/2506.23634)
*Youjeong Noh,Joon-Young Paik,Jingun Kwon,Eun-Sun Cho*

Main category: cs.CR

Relevance: 30.0

TL;DR: 论文提出了一种基于真值表的MBA反混淆方法，结合Transformer架构，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: MBA混淆被恶意软件利用，传统方法忽视语义信息，需改进。

Method: 提出真值表作为语义表示，并设计基于Transformer的gMBA框架。

Result: 实验表明语义信息显著提升反混淆性能。

Conclusion: 语义信息对恢复混淆代码至关重要。

Abstract: Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by
converting programs into forms that are more complex to analyze. However, MBA
has been increasingly exploited by malware developers to evade detection and
cause significant real-world problems. Traditional MBA deobfuscation methods
often consider these expressions as part of a black box and overlook their
internal semantic information. To bridge this gap, we propose a truth table,
which is an automatically constructed semantic representation of an
expression's behavior that does not rely on external resources. The truth table
is a mathematical form that represents the output of expression for all
possible combinations of input. We also propose a general and extensible guided
MBA deobfuscation framework (gMBA) that modifies a Transformer-based neural
encoder-decoder Seq2Seq architecture to incorporate this semantic guidance.
Experimental results and in-depth analysis show that integrating expression
semantics significantly improves performance and highlights the importance of
internal semantic expressions in recovering obfuscated code to its original
form.

</details>


### [460] [Differentially Private Synthetic Data Release for Topics API Outputs](https://arxiv.org/abs/2506.23855)
*Travis Dick,Alessandro Epasto,Adel Javanmard,Josh Karlin,Andres Munoz Medina,Vahab Mirrokni,Sergei Vassilvitskii,Peilin Zhong*

Main category: cs.CR

Relevance: 30.0

TL;DR: 提出了一种生成合成API输出的方法，用于研究隐私保护广告API的隐私属性，同时确保数据隐私。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏公开的真实数据，研究隐私保护广告API的隐私属性存在困难。

Method: 开发了一种基于差分隐私的方法，生成与真实数据风险属性匹配的合成数据。

Result: 生成了一个差分隐私保护的合成数据集，并开源发布。

Conclusion: 该方法有助于促进隐私保护广告API的透明性研究。

Abstract: The analysis of the privacy properties of Privacy-Preserving Ads APIs is an
area of research that has received strong interest from academics, industry,
and regulators. Despite this interest, the empirical study of these methods is
hindered by the lack of publicly available data. Reliable empirical analysis of
the privacy properties of an API, in fact, requires access to a dataset
consisting of realistic API outputs; however, privacy concerns prevent the
general release of such data to the public.
  In this work, we develop a novel methodology to construct synthetic API
outputs that are simultaneously realistic enough to enable accurate study and
provide strong privacy protections. We focus on one Privacy-Preserving Ads
APIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a
methodology to generate a differentially-private dataset that closely matches
the re-identification risk properties of the real Topics API data. The use of
differential privacy provides strong theoretical bounds on the leakage of
private user information from this release.
  Our methodology is based on first computing a large number of
differentially-private statistics describing how output API traces evolve over
time. Then, we design a parameterized distribution over sequences of API traces
and optimize its parameters so that they closely match the statistics obtained.
Finally, we create the synthetic data by drawing from this distribution.
  Our work is complemented by an open-source release of the anonymized dataset
obtained by this methodology. We hope this will enable external researchers to
analyze the API in-depth and replicate prior and future work on a realistic
large-scale dataset. We believe that this work will contribute to fostering
transparency regarding the privacy properties of Privacy-Preserving Ads APIs.

</details>


### [461] [Marker Gene Method : Identifying Stable Solutions in a Dynamic Environment](https://arxiv.org/abs/2506.23734)
*Hao Shi,Xi Li,Fangfang Xie*

Main category: cs.NE

Relevance: 30.0

TL;DR: 论文提出了Marker Gene Method (MGM)，通过动态基准和自适应权重机制提升竞争性协同进化算法的稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决竞争性协同进化算法（CCEAs）中因复杂动态（如不可传递性和红皇后效应）导致的不稳定收敛问题。

Method: 引入MGM框架，利用‘标记基因’作为动态基准和自适应权重机制，平衡探索与开发。

Result: MGM在严格竞争博弈框架下形成纳什均衡附近的强吸引子，并在多个挑战中验证其有效性。

Conclusion: MGM显著提升了CCEAs在复杂竞争环境中的稳定性和鲁棒性。

Abstract: Competitive Co-evolutionary Algorithms (CCEAs) are often hampered by complex
dynamics like intransitivity and the Red Queen effect, leading to unstable
convergence. To counter these challenges, this paper introduces the Marker Gene
Method (MGM), a framework that establishes stability by using a 'marker gene'
as a dynamic benchmark and an adaptive weighting mechanism to balance
exploration and exploitation. We provide rigorous mathematical proofs
demonstrating that MGM creates strong attractors near Nash Equilibria within
the Strictly Competitive Game framework. Empirically, MGM demonstrates its
efficacy across a spectrum of challenges: it stabilizes the canonical
Rock-Paper-Scissors game, significantly improves the performance of C-RMOEA/D
on ZDT benchmarks, and, when augmented with a Memory Pool (MP) extension, it
successfully tames the notoriously pathological Shapley Biased Game. This work
presents a theoretically sound and empirically validated framework that
substantially enhances the stability and robustness of CCEAs in complex
competitive environments.

</details>


### [462] [SQUASH: A SWAP-Based Quantum Attack to Sabotage Hybrid Quantum Neural Networks](https://arxiv.org/abs/2506.24081)
*Rahul Kumar,Wenqi Wei,Ying Mao,Junaid Farooq,Ying Wang,Juntao Chen*

Main category: quant-ph

Relevance: 30.0

TL;DR: 提出了一种名为SQUASH的电路级攻击，通过插入SWAP门破坏混合量子神经网络（HQNN）的分类性能。


<details>
  <summary>Details</summary>
Motivation: 揭示HQNN在电路级对抗干预中的关键漏洞，强调需要更鲁棒的架构。

Method: 在受害HQNN的变分量子电路中插入SWAP门，直接操纵电路结构，导致量子比特错位和状态演化中断。

Result: 无目标SWAP攻击使分类准确率降低74.08%，目标攻击使目标类准确率降低79.78%。

Conclusion: SQUASH攻击揭示了HQNN的严重脆弱性，需设计更抗干扰的架构。

Abstract: We propose a circuit-level attack, SQUASH, a SWAP-Based Quantum Attack to
sabotage Hybrid Quantum Neural Networks (HQNNs) for classification tasks.
SQUASH is executed by inserting SWAP gate(s) into the variational quantum
circuit of the victim HQNN. Unlike conventional noise-based or adversarial
input attacks, SQUASH directly manipulates the circuit structure, leading to
qubit misalignment and disrupting quantum state evolution. This attack is
highly stealthy, as it does not require access to training data or introduce
detectable perturbations in input states. Our results demonstrate that SQUASH
significantly degrades classification performance, with untargeted SWAP attacks
reducing accuracy by up to 74.08\% and targeted SWAP attacks reducing target
class accuracy by up to 79.78\%. These findings reveal a critical vulnerability
in HQNN implementations, underscoring the need for more resilient architectures
against circuit-level adversarial interventions.

</details>


### [463] [STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems](https://arxiv.org/abs/2506.23995)
*Mingfei Cheng,Renzhi Wang,Xiaofei Xie,Yuan Zhou,Lei Ma*

Main category: cs.SE

Relevance: 30.0

TL;DR: 提出了STCLocker技术，用于生成多自动驾驶车辆（AVs）的死锁场景（DLSs），以评估其协同性能。


<details>
  <summary>Details</summary>
Motivation: 现有技术主要关注单AV设置下的功能评估，而多AV交通中的协同性能（尤其是死锁问题）尚未充分研究。

Method: STCLocker包含三个关键组件：死锁检测器（Deadlock Oracle）、冲突反馈（Conflict Feedback）和冲突感知场景生成（Conflict-aware Scenario Generation）。

Result: 实验表明，STCLocker在生成DLSs方面优于基线方法。

Conclusion: STCLocker为多AV协同性能测试提供了有效工具。

Abstract: Autonomous Driving System (ADS) testing is essential to ensure the safety and
reliability of autonomous vehicles (AVs) before deployment. However, existing
techniques primarily focus on evaluating ADS functionalities in single-AV
settings. As ADSs are increasingly deployed in multi-AV traffic, it becomes
crucial to assess their cooperative performance, particularly regarding
deadlocks, a fundamental coordination failure in which multiple AVs enter a
circular waiting state indefinitely, resulting in motion planning failures.
Despite its importance, the cooperative capability of ADSs to prevent deadlocks
remains insufficiently underexplored. To address this gap, we propose the first
dedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique,
STCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs
controlled by the ADS under test are in a circular wait state. STCLocker
consists of three key components: Deadlock Oracle, Conflict Feedback, and
Conflict-aware Scenario Generation. Deadlock Oracle provides a reliable
black-box mechanism for detecting deadlock cycles among multiple AVs within a
given scenario. Conflict Feedback and Conflict-aware Scenario Generation
collaborate to actively guide AVs into simultaneous competition over spatial
conflict resources (i.e., shared passing regions) and temporal competitive
behaviors (i.e., reaching the conflict region at the same time), thereby
increasing the effectiveness of generating conflict-prone deadlocks. We
evaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA,
a module-based ADS supporting cooperative communication. Experimental results
show that, on average, STCLocker generates more DLS than the best-performing
baseline.

</details>


### [464] [Rises for Measuring Local Distributivity in Lattices](https://arxiv.org/abs/2506.23168)
*Mohammad Abdulla,Tobias Hille,Dominik Dürrschnabel,Gerd Stumme*

Main category: cs.AI

Relevance: 20.0

TL;DR: 论文提出了一种通过“rises”来量化概念格中分配性的方法，并探讨了其与实际数据中分配性表现的关系。


<details>
  <summary>Details</summary>
Motivation: 在形式概念分析（FCA）中，格的高分配性常见但缺乏标准化度量，因此需要一种量化方法。

Method: 引入“rises”概念，通过分析覆盖概念中属性或对象数量的变化来评估分配性。

Result: 证明格是分配的当且仅当无非单位rises；实际数据中概念格多为join-distributive，但meet-distributive较少。

Conclusion: rises是量化分配性的有效工具，揭示了实际数据中分配性的具体表现。

Abstract: Distributivity is a well-established and extensively studied notion in
lattice theory. In the context of data analysis, particularly within Formal
Concept Analysis (FCA), lattices are often observed to exhibit a high degree of
distributivity. However, no standardized measure exists to quantify this
property. In this paper, we introduce the notion of rises in (concept) lattices
as a means to assess distributivity. Rises capture how the number of attributes
or objects in covering concepts change within the concept lattice. We show that
a lattice is distributive if and only if no non-unit rises occur. Furthermore,
we relate rises to the classical notion of meet- and join distributivity. We
observe that concept lattices from real-world data are to a high degree
join-distributive, but much less meet-distributive. We additionally study how
join-distributivity manifests on the level of ordered sets.

</details>


### [465] [Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling](https://arxiv.org/abs/2504.15071)
*Louis Bradshaw,Simon Colton*

Main category: cs.SD

Relevance: 20.0

TL;DR: 论文介绍了一个通过音频转录生成的大规模MIDI数据集，包含超过100万份MIDI文件，约10万小时的音频转录。


<details>
  <summary>Details</summary>
Motivation: 为音乐生成和分析领域提供高质量、大规模的数据集，支持相关研究。

Method: 采用多阶段数据管道，包括语言模型自主爬取和评分音频，音频分类器进行修剪和分段。

Result: 生成了包含100万份MIDI文件的数据集，并提供了详细的统计分析和元数据标签。

Conclusion: 该数据集为音乐生成和分析研究提供了丰富的资源，并展示了数据管道的有效性。

Abstract: We introduce an extensive new dataset of MIDI files, created by transcribing
audio recordings of piano performances into their constituent notes. The data
pipeline we use is multi-stage, employing a language model to autonomously
crawl and score audio recordings from the internet based on their metadata,
followed by a stage of pruning and segmentation using an audio classifier. The
resulting dataset contains over one million distinct MIDI files, comprising
roughly 100,000 hours of transcribed audio. We provide an in-depth analysis of
our techniques, offering statistical insights, and investigate the content by
extracting metadata tags, which we also provide. Dataset available at
https://github.com/loubbrad/aria-midi.

</details>


### [466] [Unsupervised Learning-Based Joint Resource Allocation and Beamforming Design for RIS-Assisted MISO-OFDMA Systems](https://arxiv.org/abs/2506.22448)
*Yu Ma,Xingyu Zhou,Xiao Li,Le Liang,Shi Jin*

Main category: eess.SP

Relevance: 20.0

TL;DR: 提出了一种基于无监督学习的框架，用于RIS辅助的MISO-OFDMA系统中的资源分配问题，包括RIS相位设计、基站波束成形和资源块分配。


<details>
  <summary>Details</summary>
Motivation: 解决6G无线系统中RIS辅助下的资源分配挑战，提升系统性能。

Method: 采用两阶段无监督学习框架，包括BeamNet和AllocationNet，结合最大比率传输和水填充技术。

Result: 仿真显示该方法达到SCA基线99.93%的总速率，且运行时间仅为0.036%。

Conclusion: 该方法高效且鲁棒，适用于动态信道和用户条件。

Abstract: Reconfigurable intelligent surfaces (RIS) are key enablers for 6G wireless
systems. This paper studies downlink transmission in an RIS-assisted MISO-OFDMA
system, addressing resource allocation challenges. A two-stage unsupervised
learning-based framework is proposed to jointly design RIS phase shifts, BS
beamforming, and resource block (RB) allocation. The framework includes
BeamNet, which predicts RIS phase shifts from CSI, and AllocationNet, which
allocates RBs using equivalent CSI derived from BeamNet outputs. Active
beamforming is implemented via maximum ratio transmission and water-filling. To
handle discrete constraints while ensuring differentiability, quantization and
the Gumbel-softmax trick are adopted. A customized loss and phased training
enhance performance under QoS constraints. Simulations show the method achieves
99.93% of the sum rate of the SCA baseline with only 0.036% of its runtime, and
it remains robust across varying channel and user conditions.

</details>


### [467] [Machine Learning for Proactive Groundwater Management: Early Warning and Resource Allocation](https://arxiv.org/abs/2506.22461)
*Chuan Li,Ruoxuan Yang*

Main category: eess.SP

Relevance: 20.0

TL;DR: 论文提出了一种基于机器学习的管道，用于预测地下水位类别，结合气候数据、水文气象记录和地形属性，通过AutoGluon自动集成框架实现高效预测。


<details>
  <summary>Details</summary>
Motivation: 传统地下水位监测方法存在数据稀疏、计算限制和输出延迟等问题，需要一种更高效、数据驱动的方法来改进监测和决策。

Method: 采用地理空间预处理、领域驱动的特征工程和自动模型选择，结合AutoGluon框架进行模型训练和预测。

Result: 在法国大规模数据集上验证，加权F1分数为0.927（验证数据）和0.67（时间独立测试数据），展示了在早期预警和水资源分配中的实用性。

Conclusion: 该方法为将机器学习集成到国家地下水监测网络提供了可扩展框架，支持更响应迅速和数据驱动的水资源管理策略。

Abstract: Groundwater supports ecosystems, agriculture, and drinking water supplies
worldwide, yet effective monitoring remains challenging due to sparse data,
computational constraints, and delayed outputs from traditional approaches. We
develop a machine learning pipeline that predicts groundwater level categories
using climate data, hydro-meteorological records, and physiographic attributes
processed through AutoGluon's automated ensemble framework. Our approach
integrates geospatial preprocessing, domain-driven feature engineering, and
automated model selection to overcome conventional monitoring limitations.
Applied to a large-scale French dataset (n $>$ 3,440,000 observations from
1,500+ wells), the model achieves weighted F\_1 scores of 0.927 on validation
data and 0.67 on temporally distinct test data. Scenario-based evaluations
demonstrate practical utility for early warning systems and water allocation
decisions under changing climate conditions. The open-source implementation
provides a scalable framework for integrating machine learning into national
groundwater monitoring networks, enabling more responsive and data-driven water
management strategies.

</details>


### [468] [Score-based Diffusion Model for Unpaired Virtual Histology Staining](https://arxiv.org/abs/2506.23184)
*Anran Liu,Xiaofei Wang,Jing Cai,Chao Li*

Main category: eess.IV

Relevance: 20.0

TL;DR: 该论文提出了一种基于互信息引导的扩散模型，用于解决虚拟染色中的关键挑战，包括染色风格与组织结构的有效分解、可控染色过程以及结构一致性建模。


<details>
  <summary>Details</summary>
Motivation: 虚拟染色技术可以高效生成免疫组化（IHC）图像，但现有方法在染色风格与组织结构的分解、可控性及结构一致性方面存在不足。

Method: 采用互信息（MI）引导的扩散模型，设计了全局MI能量函数、时间步定制的反向扩散过程和局部MI驱动的对比学习策略。

Result: 实验表明，该方法在虚拟染色任务上优于现有技术，展示了其生物医学潜力。

Conclusion: 该方法通过MI引导的扩散模型有效解决了虚拟染色的关键问题，具有实际应用价值。

Abstract: Hematoxylin and eosin (H&E) staining visualizes histology but lacks
specificity for diagnostic markers. Immunohistochemistry (IHC) staining
provides protein-targeted staining but is restricted by tissue availability and
antibody specificity. Virtual staining, i.e., computationally translating the
H&E image to its IHC counterpart while preserving the tissue structure, is
promising for efficient IHC generation. Existing virtual staining methods still
face key challenges: 1) effective decomposition of staining style and tissue
structure, 2) controllable staining process adaptable to diverse tissue and
proteins, and 3) rigorous structural consistency modelling to handle the
non-pixel-aligned nature of paired H&E and IHC images. This study proposes a
mutual-information (MI)-guided score-based diffusion model for unpaired virtual
staining. Specifically, we design 1) a global MI-guided energy function that
disentangles the tissue structure and staining characteristics across
modalities, 2) a novel timestep-customized reverse diffusion process for
precise control of the staining intensity and structural reconstruction, and 3)
a local MI-driven contrastive learning strategy to ensure the cellular level
structural consistency between H&E-IHC images. Extensive experiments
demonstrate the our superiority over state-of-the-art approaches, highlighting
its biomedical potential. Codes will be open-sourced upon acceptance.

</details>


### [469] [Multi-Branch DNN and CRLB-Ratio-Weight Fusion for Enhanced DOA Sensing via a Massive H$^2$AD MIMO Receiver](https://arxiv.org/abs/2506.23203)
*Feng Shu,Jiatong Bai,Di Wu,Wei Zhu,Bin Deng,Fuhui Zhou,Jiangzhou Wang*

Main category: eess.SP

Relevance: 20.0

TL;DR: 论文提出了一种轻量级的CRLB-ratio-WF方法用于目标方向值融合，并构建了多分支深度神经网络（MBDNN）以进一步提升DOA感知性能。


<details>
  <summary>Details</summary>
Motivation: 针对大规模H$^2$AD结构在6G无线网络中设计低复杂度、高性能的目标方向值融合方法，减少对先验知识的依赖。

Method: 1) 提出CRLB-ratio-WF方法，通过天线数倒数近似CRLB以降低复杂度；2) 构建MBDNN，利用多子阵列候选角度增强DOA感知。

Result: CRLB-ratio-WF方法性能接近基于CRLB的方法，且显著减少先验知识依赖；MBDNN在低信噪比下表现优异，估计精度提升一个数量级。

Conclusion: 提出的方法在降低复杂度和提升性能方面有效，尤其适用于低信噪比环境。

Abstract: As a green MIMO structure, massive H$^2$AD is viewed as a potential
technology for the future 6G wireless network. For such a structure, it is a
challenging task to design a low-complexity and high-performance fusion of
target direction values sensed by different sub-array groups with fewer use of
prior knowledge. To address this issue, a lightweight Cramer-Rao lower bound
(CRLB)-ratio-weight fusion (WF) method is proposed, which approximates inverse
CRLB of each subarray using antenna number reciprocals to eliminate real-time
CRLB computation. This reduces complexity and prior knowledge dependence while
preserving fusion performance. Moreover, a multi-branch deep neural network
(MBDNN) is constructed to further enhance direction-of-arrival (DOA) sensing by
leveraging candidate angles from multiple subarrays. The subarray-specific
branch networks are integrated with a shared regression module to effectively
eliminate pseudo-solutions and fuse true angles. Simulation results show that
the proposed CRLB-ratio-WF method achieves DOA sensing performance comparable
to CRLB-based methods, while significantly reducing the reliance on prior
knowledge. More notably, the proposed MBDNN has superior performance in low-SNR
ranges. At SNR $= -15$ dB, it achieves an order-of-magnitude improvement in
estimation accuracy compared to CRLB-ratio-WF method.

</details>


### [470] [MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments](https://arxiv.org/abs/2506.23514)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

Relevance: 20.0

TL;DR: 论文提出了一种名为MGPRL的分布式框架，用于多机器人相对定位，利用Wi-Fi信号的凸包对齐方法，提高了定位精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在GPS缺失环境中的相对定位问题，避免依赖昂贵或短程传感器，降低计算开销。

Method: 使用多输出高斯过程预测Wi-Fi信号强度，结合加权凸包对齐方法进行相对姿态估计。

Result: MGPRL在定位精度和计算效率上优于现有方法，并在仿真和实际实验中验证了其性能。

Conclusion: MGPRL是一种高效、无需预校准的解决方案，适用于资源受限设备。

Abstract: Relative localization is a crucial capability for multi-robot systems
operating in GPS-denied environments. Existing approaches for multi-robot
relative localization often depend on costly or short-range sensors like
cameras and LiDARs. Consequently, these approaches face challenges such as high
computational overhead (e.g., map merging) and difficulties in disjoint
environments. To address this limitation, this paper introduces MGPRL, a novel
distributed framework for multi-robot relative localization using convex-hull
of multiple Wi-Fi access points (AP). To accomplish this, we employ
co-regionalized multi-output Gaussian Processes for efficient Radio Signal
Strength Indicator (RSSI) field prediction and perform uncertainty-aware
multi-AP localization, which is further coupled with weighted convex hull-based
alignment for robust relative pose estimation. Each robot predicts the RSSI
field of the environment by an online scan of APs in its environment, which are
utilized for position estimation of multiple APs. To perform relative
localization, each robot aligns the convex hull of its predicted AP locations
with that of the neighbor robots. This approach is well-suited for devices with
limited computational resources and operates solely on widely available Wi-Fi
RSSI measurements without necessitating any dedicated pre-calibration or
offline fingerprinting. We rigorously evaluate the performance of the proposed
MGPRL in ROS simulations and demonstrate it with real-world experiments,
comparing it against multiple state-of-the-art approaches. The results showcase
that MGPRL outperforms existing methods in terms of localization accuracy and
computational efficiency. Finally, we open source MGPRL as a ROS package
https://github.com/herolab-uga/MGPRL.

</details>


### [471] [Tensor Train Quantum State Tomography using Compressed Sensing](https://arxiv.org/abs/2506.23560)
*Shakir Showkat Sofi,Charlotte Vermeylen,Lieven De Lathauwer*

Main category: quant-ph

Relevance: 20.0

TL;DR: 论文提出了一种基于低秩块张量分解的量子态层析方法，解决了传统方法因参数指数增长导致的效率问题。


<details>
  <summary>Details</summary>
Motivation: 量子态层析（QST）是评估量子设备性能的关键技术，但传统方法因参数指数增长而不实用。

Method: 采用低秩块张量分解参数化量子态，证明该方法在内存和计算上均高效。

Result: 适用于纯态、近纯态和哈密顿基态等低秩分解近似良好的量子态。

Conclusion: 该方法为量子态层析提供了一种高效且通用的解决方案。

Abstract: Quantum state tomography (QST) is a fundamental technique for estimating the
state of a quantum system from measured data and plays a crucial role in
evaluating the performance of quantum devices. However, standard estimation
methods become impractical due to the exponential growth of parameters in the
state representation. In this work, we address this challenge by parameterizing
the state using a low-rank block tensor train decomposition and demonstrate
that our approach is both memory- and computationally efficient. This framework
applies to a broad class of quantum states that can be well approximated by
low-rank decompositions, including pure states, nearly pure states, and ground
states of Hamiltonians.

</details>


### [472] [Attention acts to suppress goal-based conflict under high competition](https://arxiv.org/abs/1610.09431)
*Omar Claflin*

Main category: q-bio.NC

Relevance: 10.0

TL;DR: 研究发现在高竞争条件下，自上而下的注意力会同时抑制任务相关和不相关的神经信号。


<details>
  <summary>Details</summary>
Motivation: 探索在高竞争条件下自上而下注意力对神经信号的影响。

Method: 通过实验观察在高竞争条件下（两个刺激共享感受野且目标相反）的神经信号变化。

Result: 自上而下的注意力在刺激出现后100毫秒内非选择性地抑制了任务相关和不相关的神经信号。

Conclusion: 这种非选择性抑制机制可能用于减少无关刺激的前馈信号。

Abstract: It is known that when multiple stimuli are present, top-down attention
selectively enhances the neural signal in the visual cortex for task-relevant
stimuli, but this has been tested only under conditions of minimal competition
of visual attention. Here we show during high competition, that is, two stimuli
in a shared receptive field possessing opposing modulatory goals, top-down
attention suppresses both task-relevant and irrelevant neural signals within
100 ms of stimuli onset. This non-selective engagement of top-down attentional
resources serves to reduce the feedforward signal representing irrelevant
stimuli.

</details>


### [473] [A Complex UNet Approach for Non-Invasive Fetal ECG Extraction Using Single-Channel Dry Textile Electrodes](https://arxiv.org/abs/2506.22457)
*Iulia Orvas,Andrei Radu,Alessandra Galli,Ana Neacsu,Elisabetta Peri*

Main category: eess.SP

Relevance: 10.0

TL;DR: 论文提出了一种基于AI技术的新方法，用于从单通道干纺织电极记录中提取胎儿心电图（fECG），解决了噪声和运动伪影问题。


<details>
  <summary>Details</summary>
Motivation: 家庭监测需要舒适耐用的电极，但干纺织电极记录中存在噪声和运动伪影，导致fECG信号提取困难。

Method: 使用复杂值去噪网络（Complex UNet）处理频谱图的实部和虚部，结合相位信息，提高fECG提取的准确性。

Result: 在模拟和真实数据上，该方法在fECG提取和R峰检测方面达到了新的最优性能。

Conclusion: 该方法首次实现了从单通道干纺织电极记录中有效提取fECG信号，为非侵入式家庭监测提供了重要进展。

Abstract: Continuous, non-invasive pregnancy monitoring is crucial for minimising
potential complications. The fetal electrocardiogram (fECG) represents a
promising tool for assessing fetal health beyond clinical environments.
Home-based monitoring necessitates the use of a minimal number of comfortable
and durable electrodes, such as dry textile electrodes. However, this setup
presents many challenges, including increased noise and motion artefacts, which
complicate the accurate extraction of fECG signals. To overcome these
challenges, we introduce a pioneering method for extracting fECG from
single-channel recordings obtained using dry textile electrodes using AI
techniques. We created a new dataset by simulating abdominal recordings,
including noise closely resembling real-world characteristics of in-vivo
recordings through dry textile electrodes, alongside mECG and fECG. To ensure
the reliability of the extracted fECG, we propose an innovative pipeline based
on a complex-valued denoising network, Complex UNet. Unlike previous approaches
that focused solely on signal magnitude, our method processes both real and
imaginary components of the spectrogram, addressing phase information and
preventing incongruous predictions. We evaluated our novel pipeline against
traditional, well-established approaches, on both simulated and real data in
terms of fECG extraction and R-peak detection. The results showcase that our
suggested method achieves new state-of-the-art results, enabling an accurate
extraction of fECG morphology across all evaluated settings. This method is the
first to effectively extract fECG signals from single-channel recordings using
dry textile electrodes, making a significant advancement towards a fully
non-invasive and self-administered fECG extraction solution.

</details>


### [474] [Deep Learning for Optical Misalignment Diagnostics in Multi-Lens Imaging Systems](https://arxiv.org/abs/2506.23173)
*Tomer Slor,Dean Oren,Shira Baneth,Tom Coen,Haim Suchowski*

Main category: physics.optics

Relevance: 10.0

TL;DR: 论文提出两种基于深度学习的逆向设计方法，用于诊断多镜头系统中的错位问题，仅使用光学测量即可实现高精度预测。


<details>
  <summary>Details</summary>
Motivation: 传统多镜头系统对齐方法依赖专用设备且耗时，需要自动化、可扩展的解决方案。

Method: 1. 使用光线追踪点图预测6镜头系统中的5自由度误差；2. 基于物理模拟的灰度合成图像预测4自由度误差。

Result: 方法在横向平移和倾斜误差上分别达到0.031mm和0.011°的精度。

Conclusion: 这些方法有望重塑精密成像制造和质量控制。

Abstract: In the rapidly evolving field of optical engineering, precise alignment of
multi-lens imaging systems is critical yet challenging, as even minor
misalignments can significantly degrade performance. Traditional alignment
methods rely on specialized equipment and are time-consuming processes,
highlighting the need for automated and scalable solutions. We present two
complementary deep learning-based inverse-design methods for diagnosing
misalignments in multi-element lens systems using only optical measurements.
First, we use ray-traced spot diagrams to predict five-degree-of-freedom
(5-DOF) errors in a 6-lens photographic prime, achieving a mean absolute error
of 0.031mm in lateral translation and 0.011$^\circ$ in tilt. We also introduce
a physics-based simulation pipeline that utilizes grayscale synthetic camera
images, enabling a deep learning model to estimate 4-DOF, decenter and tilt
errors in both two- and six-lens multi-lens systems. These results show the
potential to reshape manufacturing and quality control in precision imaging.

</details>


### [475] [UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound](https://arxiv.org/abs/2506.23490)
*Junxuan Yu,Yaofei Duan,Yuhao Huang,Yu Wang,Rongbo Ling,Weihao Luo,Ang Zhang,Jingxian Xu,Qiongying Ni,Yongsong Zhou,Binghan Li,Haoran Dou,Liping Liu,Yanfen Chu,Feng Geng,Zhe Sheng,Zhifeng Ding,Dingxin Zhang,Rui Huang,Yuhang Zhang,Xiaowei Xu,Tao Tan,Dong Ni,Zhongshan Gou,Xin Yang*

Main category: eess.IV

Relevance: 10.0

TL;DR: 论文提出了一种名为UltraTwin的新型生成框架，用于从稀疏的多视角2D超声图像中构建心脏解剖孪生模型。


<details>
  <summary>Details</summary>
Motivation: 2D超声在精确计算和直接观察3D心脏结构方面存在困难，而3D超声又受限于低分辨率、小视野和实际应用中的稀缺性。构建心脏解剖孪生模型可以为治疗计划和临床量化提供精确支持。

Method: 1. 构建了一个包含严格配对的多视角2D超声和CT数据以及伪配对数据的高质量数据集。2. 提出了一种从粗到细的分层重建优化方案。3. 引入了一种隐式自编码器以实现拓扑感知约束。

Result: 实验表明，UltraTwin能够重建高质量的解剖孪生模型，优于其他强竞争对手。

Conclusion: UltraTwin推进了心脏解剖孪生建模，有望在个性化心脏护理中发挥作用。

Abstract: Echocardiography is routine for cardiac examination. However, 2D ultrasound
(US) struggles with accurate metric calculation and direct observation of 3D
cardiac structures. Moreover, 3D US is limited by low resolution, small field
of view and scarce availability in practice. Constructing the cardiac
anatomical twin from 2D images is promising to provide precise treatment
planning and clinical quantification. However, it remains challenging due to
the rare paired data, complex structures, and US noises. In this study, we
introduce a novel generative framework UltraTwin, to obtain cardiac anatomical
twin from sparse multi-view 2D US. Our contribution is three-fold. First,
pioneered the construction of a real-world and high-quality dataset containing
strictly paired multi-view 2D US and CT, and pseudo-paired data. Second, we
propose a coarse-to-fine scheme to achieve hierarchical reconstruction
optimization. Last, we introduce an implicit autoencoder for topology-aware
constraints. Extensive experiments show that UltraTwin reconstructs
high-quality anatomical twins versus strong competitors. We believe it advances
anatomical twin modeling for potential applications in personalized cardiac
care.

</details>


### [476] [Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI](https://arxiv.org/abs/2506.23506)
*Bowen Xin,Rohan Hickey,Tamara Blake,Jin Jin,Claire E Wainwright,Thomas Benkert,Alto Stemmer,Peter Sly,David Coman,Jason Dowling*

Main category: eess.IV

Relevance: 10.0

TL;DR: 论文提出了一种基于人工智能的像素级肺部评分（APL）方法，用于快速准确地量化肺部MRI图像，特别针对囊性纤维化（CF）。该方法比传统网格级评分更快且更准确。


<details>
  <summary>Details</summary>
Motivation: 由于MRI无电离辐射，常用于儿科疾病（如囊性纤维化）的肺部成像，但缺乏定量评分系统。APL评分旨在填补这一空白。

Method: APL评分包括五个阶段：图像加载、AI肺部分割、切片采样、像素级标注及量化报告。

Result: APL评分耗时8.2分钟/例，比网格级评分快两倍，且统计上更准确（p=0.021），与网格级评分强相关（R=0.973）。

Conclusion: APL评分有望优化临床工作流程，并扩展到其他肺部疾病和MRI序列。

Abstract: Lung magnetic resonance imaging (MRI) with ultrashort echo-time (UTE)
represents a recent breakthrough in lung structure imaging, providing image
resolution and quality comparable to computed tomography (CT). Due to the
absence of ionising radiation, MRI is often preferred over CT in paediatric
diseases such as cystic fibrosis (CF), one of the most common genetic disorders
in Caucasians. To assess structural lung damage in CF imaging, CT scoring
systems provide valuable quantitative insights for disease diagnosis and
progression. However, few quantitative scoring systems are available in
structural lung MRI (e.g., UTE-MRI). To provide fast and accurate
quantification in lung MRI, we investigated the feasibility of novel Artificial
intelligence-assisted Pixel-level Lung (APL) scoring for CF. APL scoring
consists of 5 stages, including 1) image loading, 2) AI lung segmentation, 3)
lung-bounded slice sampling, 4) pixel-level annotation, and 5) quantification
and reporting. The results shows that our APL scoring took 8.2 minutes per
subject, which was more than twice as fast as the previous grid-level scoring.
Additionally, our pixel-level scoring was statistically more accurate
(p=0.021), while strongly correlating with grid-level scoring (R=0.973,
p=5.85e-9). This tool has great potential to streamline the workflow of UTE
lung MRI in clinical settings, and be extended to other structural lung MRI
sequences (e.g., BLADE MRI), and for other lung diseases (e.g.,
bronchopulmonary dysplasia).

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [477] [The Hidden Link Between RLHF and Contrastive Learning](https://arxiv.org/abs/2506.22578)
*Xufei Lv,Haoyuan Sun,Xuefeng Bai,Min Zhang,Houde Liu,Kehai Chen*

Main category: cs.LG

Relevance: 90.0

TL;DR: 论文通过互信息最大化视角重新解释RLHF和DPO，提出MIO方法，解决了DPO后期性能下降问题，并在推理和数学任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究LLM与人类价值观对齐的方法，揭示RLHF和DPO的互信息最大化本质，并改进其局限性。

Method: 从互信息角度分析RLHF和DPO，提出基于Jensen-Shannon MI估计器的MIO方法。

Result: MIO解决了DPO的后期性能下降问题，在推理和数学任务上表现优于或与现有方法相当。

Conclusion: MIO为LLM对齐提供了新视角，并在性能上有所提升。

Abstract: Alignment of large language models (LLMs) with human values has recently
garnered significant attention, with prominent examples including the canonical
yet costly Reinforcement Learning from Human Feedback (RLHF) and the simple
Direct Preference Optimization (DPO). In this work, we demonstrate that both
RLHF and DPO can be interpreted from the perspective of mutual information (MI)
maximization, uncovering a profound connection to contrastive learning. Within
this framework, both RLHF and DPO can be viewed as methods that perform
contrastive learning based on the positive and negative samples derived from
the base model, leveraging the Donsker-Varadhan (DV) lower bound on MI
(equivalently, the MINE estimator). This paradigm further explains why RLHF may
not intrinsically incentivize reasoning capacities in LLMs beyond what is
already present in the base model. Building on this perspective, we replace the
DV/MINE bound with the Jensen-Shannon MI estimator and propose Mutual
Information Optimization (MIO). Comprehensive theoretical analysis and
extensive empirical evaluations demonstrate that MIO mitigates the late-stage
decline in chosen-likelihood observed in DPO, achieving competitive or superior
performance across various challenging reasoning and mathematical benchmarks.
We will release the model and code upon acceptance.

</details>


### [478] [Exploration Behavior of Untrained Policies](https://arxiv.org/abs/2506.22566)
*Jacob Adamczyk*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文研究了深度神经策略架构如何隐式影响强化学习中的探索行为，通过理论和实验展示了未训练策略生成轨迹的特性，并提出了利用策略初始化作为理解早期训练探索行为的工具。


<details>
  <summary>Details</summary>
Motivation: 探索是强化学习中的核心挑战，尤其是在奖励稀疏或对抗的环境中。研究旨在理解策略架构如何影响探索行为。

Method: 结合无限宽度网络理论和连续时间极限，分析未训练策略的动作相关性和状态访问分布，并通过实验验证。

Result: 未训练策略能生成相关动作并导致非平凡的状态访问分布，揭示了策略架构对探索的隐式偏好。

Conclusion: 研究为利用策略初始化作为设计工具提供了理论和实验框架，有助于理解早期训练中的探索行为。

Abstract: Exploration remains a fundamental challenge in reinforcement learning (RL),
particularly in environments with sparse or adversarial reward structures. In
this work, we study how the architecture of deep neural policies implicitly
shapes exploration before training. We theoretically and empirically
demonstrate strategies for generating ballistic or diffusive trajectories from
untrained policies in a toy model. Using the theory of infinite-width networks
and a continuous-time limit, we show that untrained policies return correlated
actions and result in non-trivial state-visitation distributions. We discuss
the distributions of the corresponding trajectories for a standard
architecture, revealing insights into inductive biases for tackling
exploration. Our results establish a theoretical and experimental framework for
using policy initialization as a design tool to understand exploration behavior
in early training.

</details>


### [479] [Are Fast Methods Stable in Adversarially Robust Transfer Learning?](https://arxiv.org/abs/2506.22602)
*Joshua C. Zhao,Saurabh Bagchi*

Main category: cs.LG

Relevance: 85.0

TL;DR: 研究探讨了在对抗性鲁棒迁移学习中，使用FGSM（快速梯度符号方法）替代PGD（投影梯度下降）的效率和性能优势。


<details>
  <summary>Details</summary>
Motivation: 对抗性训练在迁移学习中计算成本高，FGSM在微调阶段表现出更高的稳定性，且计算成本显著降低。

Method: 通过实验比较FGSM和PGD在对抗性微调中的表现，特别是在不同扰动预算（如ε=4,8,32）下的稳定性和性能。

Result: FGSM在保持接近PGD的鲁棒性（平均仅损失0.39%-1.39%）的同时，训练时间减少4倍。

Conclusion: FGSM不仅计算效率更高，且在对抗性鲁棒迁移学习中表现优异，是PGD的有力替代方案。

Abstract: Transfer learning is often used to decrease the computational cost of model
training, as fine-tuning a model allows a downstream task to leverage the
features learned from the pre-training dataset and quickly adapt them to a new
task. This is particularly useful for achieving adversarial robustness, as
adversarially training models from scratch is very computationally expensive.
However, high robustness in transfer learning still requires adversarial
training during the fine-tuning phase, which requires up to an order of
magnitude more time than standard fine-tuning. In this work, we revisit the use
of the fast gradient sign method (FGSM) in robust transfer learning to improve
the computational cost of adversarial fine-tuning. We surprisingly find that
FGSM is much more stable in adversarial fine-tuning than when training from
scratch. In particular, FGSM fine-tuning does not suffer from any issues with
catastrophic overfitting at standard perturbation budgets of $\varepsilon=4$ or
$\varepsilon=8$. This stability is further enhanced with parameter-efficient
fine-tuning methods, where FGSM remains stable even up to $\varepsilon=32$ for
linear probing. We demonstrate how this stability translates into performance
across multiple datasets. Compared to fine-tuning with the more commonly used
method of projected gradient descent (PGD), on average, FGSM only loses 0.39%
and 1.39% test robustness for $\varepsilon=4$ and $\varepsilon=8$ while using
$4\times$ less training time. Surprisingly, FGSM may not only be a
significantly more efficient alternative to PGD in adversarially robust
transfer learning but also a well-performing one.

</details>


### [480] [Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training](https://arxiv.org/abs/2506.22638)
*Aadim Nepal,Safal Shrestha,Anubhav Shrestha,Minwu Kim,Keith Ross*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文研究了后训练（如指令调优、强化学习或知识蒸馏）对大型语言模型数学推理能力的影响，发现数学推理依赖于特定的层结构，而非数学任务则无此现象。


<details>
  <summary>Details</summary>
Motivation: 探讨后训练是否通过改变Transformer层的结构来提升数学推理能力，还是仅通过微调实现。

Method: 通过层级消融实验，分析基础模型、指令调优、知识蒸馏和强化学习变体在数学推理任务中的表现。

Result: 数学推理任务中存在特定的关键层结构，移除这些层会导致准确率下降高达80%，而非数学任务则无此现象。

Conclusion: 数学推理依赖于预训练中形成的特定层结构，这些层在信息表示转换中起关键作用。

Abstract: Large language models can exhibit improved mathematical reasoning
capabilities following post-training with instruction tuning, reinforcement
learning, or knowledge distillation. However, it remains unclear whether these
improvements are driven by major changes in transformer layers or from minor
adjustments that leave the relative layer importance structures of the base
model largely unchanged. We investigate this question through systematic
layer-wise ablation experiments, examining base, instruction-tuned,
knowledge-distilled, and reinforcement learning variants on mathematical
reasoning benchmarks. Our findings show that mathematical reasoning gives rise
to a specific layer importance structure, and this structure persists across
all post-training paradigms. Removal of such layers causes accuracy drops of up
to 80%. In contrast, non-mathematical tasks like factual recall exhibit no
critical layers. This distinction suggests that mathematical reasoning requires
specialized layers that emerge during pre-training, while other non-reasoning
tasks do not. From an information-theoretic perspective, we also observe that
these critical layers are the same layers where major representational
transformation occurs.

</details>


### [481] [Residual Matrix Transformers: Scaling the Size of the Residual Stream](https://arxiv.org/abs/2506.22696)
*Brian Mak,Jeffrey Flanigan*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出了一种名为残差矩阵变换器（RMT）的模型，通过用外积记忆矩阵替换传统变换器的残差流，实现了更高效的性能。


<details>
  <summary>Details</summary>
Motivation: 传统变换器的残差流在存储和访问特征时存在效率问题，RMT旨在改进这一机制。

Method: 用外积记忆矩阵替换残差流，并进行了理论分析。

Result: RMT在性能、计算效率（减少58% FLOPS）、参数数量（减少25%）和训练数据（减少41%）上优于传统变换器。

Conclusion: RMT提供了一种更高效的残差流扩展方法，并改善了方差传播特性。

Abstract: The residual stream acts as a memory bus where transformer layers both store
and access features (Elhage et al., 2021). We consider changing the mechanism
for retrieving and storing information in the residual stream, and replace the
residual stream of the transformer with an outer product memory matrix
(Kohonen, 1972, Anderson, 1972). We call this model the Residual Matrix
Transformer (RMT). We find that the RMT enjoys a number of attractive
properties: 1) the size of the residual stream can be scaled independently of
compute and model size, improving performance, 2) the RMT can achieve the same
loss as the transformer with 58% fewer FLOPS, 25% fewer parameters, and 41%
fewer training tokens tokens, and 3) the RMT outperforms the transformer on
downstream evaluations. We theoretically analyze the transformer and the RMT,
and show that the RMT allows for more efficient scaling of the residual stream,
as well as improved variance propagation properties. Code for this project can
be found at https://github.com/bmac3/residual-matrix-transformer.

</details>


### [482] [BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute](https://arxiv.org/abs/2506.22716)
*Dujian Ding,Ankur Mallick,Shaokun Zhang,Chi Wang,Daniel Madrigal,Mirian Del Carmen Hipolito Garcia,Menglin Xia,Laks V. S. Lakshmanan,Qingyun Wu,Victor Rühle*

Main category: cs.LG

Relevance: 85.0

TL;DR: BEST-Route是一个新的LLM查询路由框架，通过动态选择模型和生成多个响应来优化成本和质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM查询路由方法因仅生成单个响应而过度依赖昂贵大模型的问题。

Method: 提出BEST-Route框架，根据查询难度和质量阈值选择模型和生成多个响应。

Result: 实验显示成本降低60%，性能下降不到1%。

Conclusion: BEST-Route在保持性能的同时显著降低成本。

Abstract: Large language models (LLMs) are powerful tools but are often expensive to
deploy at scale. LLM query routing mitigates this by dynamically assigning
queries to models of varying cost and quality to obtain a desired trade-off.
Prior query routing approaches generate only one response from the selected
model and a single response from a small (inexpensive) model was often not good
enough to beat a response from a large (expensive) model due to which they end
up overusing the large model and missing out on potential cost savings.
However, it is well known that for small models, generating multiple responses
and selecting the best can enhance quality while remaining cheaper than a
single large-model response. We leverage this idea to propose BEST-Route, a
novel routing framework that chooses a model and the number of responses to
sample from it based on query difficulty and the quality thresholds.
Experiments on real-world datasets demonstrate that our method reduces costs by
up to 60% with less than 1% performance drop.

</details>


### [483] [Infinite Sampling: Efficient and Stable Grouped RL Training for Large Language Models](https://arxiv.org/abs/2506.22950)
*Liangyu Wang,Huanyi Xie,Xinhai Wang,Tianjin Huang,Mengdi Li,Di Wang*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出了Infinite Sampling框架，通过微采样组和连续采样技术，显著降低了GRPO训练的内存开销和提高了吞吐量。


<details>
  <summary>Details</summary>
Motivation: 解决GRPO训练中因生成和存储多响应导致的高内存开销问题，提升在有限硬件条件下的可扩展性。

Method: 1) 微采样组分解大组为内存可行的轮次；2) 连续采样交叉生成以提高利用率；3) 长度感知调度器结合FPTAS和SJF优化。

Result: 微采样组减少峰值内存使用50%以上，Infinite Sampling提升吞吐量25%以上，同时保持完整生成长度和内存使用。

Conclusion: Infinite Sampling在有限GPU内存下实现了高效稳定的GRPO训练，适用于更大规模的组。

Abstract: Group-based reinforcement learning algorithms such as Group Reward Policy
Optimization (GRPO) have proven effective for fine-tuning large language models
(LLMs) with human feedback. However, generating and storing multiple responses
per prompt incurs substantial memory overhead, especially as the sample group
size increases, limiting scalability under constrained hardware.
  We propose Infinite Sampling, a framework that enables efficient and stable
GRPO training by decoupling group size from GPU memory usage. It consists of:
(1) micro sampling groups that decompose large groups into memory-feasible
rounds; (2) continuous sampling that interleaves generation across groups to
improve utilization; and (3) a length-aware scheduler combining
token-conditioned sequence length prediction with a two-stage plan: global
grouping via FPTAS and runtime refill via SJF.
  Experiments show that our Micro Sampling Groups reduce peak memory usage by
over 50% compared to full-group decoding (e.g., from 21.55 GB to 10.64 GB on
Qwen3-1.7B). Building on this, Infinite Sampling improves throughput by over
25% compared to the naive micro sampling group method, reducing decoding steps
while maintaining full-length completions and memory usage. Our hybrid
scheduling ensures efficient and stable GRPO training with larger groups under
realistic GPU memory constraints.

</details>


### [484] [Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models](https://arxiv.org/abs/2506.23025)
*Tejas Vaidhya,Ayush Kaushal,Vineet Jain,Francis Couture Harpin,Prashant Shishodia,Majid Behbahani,Yuriy Nevmyvaka,Irina Rish*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文研究了三元语言模型（TriLMs）及其量化感知训练方法，以减少内存需求并提升推理效率。通过扩展性分析，发现TriLMs更受益于训练数据而非参数规模，并提出了2-bit和1.6-bit的权重压缩方案及GPU内核TriRun，显著加速推理。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）推理效率低下的问题，尤其是内存带宽和容量的瓶颈。

Method: 采用量化感知训练的三元语言模型（TriLMs），进行扩展性分析，并提出2-bit和1.6-bit权重压缩方案及GPU内核TriRun。

Result: TriLMs在扩展性上更依赖训练数据，提出的压缩方案和TriRun内核显著提升了推理效率（最高5倍加速）。

Conclusion: TriLMs为高效LLMs的构建和部署奠定了基础，提供了开源资源Spectra-1.1和TriRun内核。

Abstract: Large language models (LLMs) are increasingly used across research and
industry applications, yet their inference efficiency remains a significant
challenge. As the computational power of modern GPU architectures continuously
improves, their memory bandwidth and capacity have not scaled proportionally,
creating a critical bottleneck during inference. To address this, we
investigate ternary language models (TriLMs) that employ quantization-aware
training to significantly reduce memory requirements. We first analyze the
scalability of TriLMs by conducting a scaling law analysis, revealing that
TriLMs benefit more from increasing training data than from scaling model
parameters. Based on this observation, we introduce Spectra-1.1, an open suite
of TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained
performance gains at scale. Furthermore, to improve inference efficiency, we
propose novel 2-bit and 1.6-bit packing schemes for ternary weights, which
demonstrate accelerated inference across various CPU architectures. Also,
building on the 2-bit packing, we develop a GPU kernel called TriRun that
accelerates end-to-end model inference by up to 5 times compared to
floating-point baselines. To encourage further exploration and development of
TriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels.
Overall, our work lays the foundation for building and deploying efficient
LLMs, providing a valuable resource for the research community.

</details>


### [485] [Measuring How LLMs Internalize Human Psychological Concepts: A preliminary analysis](https://arxiv.org/abs/2506.23055)
*Hiro Taiyo Hamada,Ippei Fujisawa,Genji Kawakita,Yuki Yamada*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文提出了一种定量框架，通过43个标准化心理问卷评估LLMs与人类心理维度的概念对齐，发现GPT-4在分类准确性上显著优于GPT-3.5和BERT。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLMs是否准确内化了人类心理概念，以评估其与人类思维的潜在对齐程度。

Method: 方法包括通过心理问卷的成对相似性分析评估LLMs的重建和分类能力，并使用层次聚类比较结果。

Result: GPT-4的分类准确率最高（66.2%），显著优于GPT-3.5（55.9%）和BERT（48.1%），且其语义相似度与人类反应相关性显著。

Conclusion: 结论表明现代LLMs能以可测量的准确性近似人类心理概念，为开发更可解释的AI系统提供了见解。

Abstract: Large Language Models (LLMs) such as ChatGPT have shown remarkable abilities
in producing human-like text. However, it is unclear how accurately these
models internalize concepts that shape human thought and behavior. Here, we
developed a quantitative framework to assess concept alignment between LLMs and
human psychological dimensions using 43 standardized psychological
questionnaires, selected for their established validity in measuring distinct
psychological constructs. Our method evaluates how accurately language models
reconstruct and classify questionnaire items through pairwise similarity
analysis. We compared resulting cluster structures with the original
categorical labels using hierarchical clustering. A GPT-4 model achieved
superior classification accuracy (66.2\%), significantly outperforming GPT-3.5
(55.9\%) and BERT (48.1\%), all exceeding random baseline performance (31.9\%).
We also demonstrated that the estimated semantic similarity from GPT-4 is
associated with Pearson's correlation coefficients of human responses in
multiple psychological questionnaires. This framework provides a novel approach
to evaluate the alignment of the human-LLM concept and identify potential
representational biases. Our findings demonstrate that modern LLMs can
approximate human psychological constructs with measurable accuracy, offering
insights for developing more interpretable AI systems.

</details>


### [486] [Masked Gated Linear Unit](https://arxiv.org/abs/2506.23225)
*Yukito Tajima,Nakamasa Inoue,Yusuke Sekikawa,Ikuro Sato,Rio Yokota*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出了一种新型的门控线性单元（MGLU），通过共享权重矩阵和高效内核实现，显著减少了内存读取和计算开销，同时保持了或超越了传统GLU的性能。


<details>
  <summary>Details</summary>
Motivation: 传统GLU在LLMs中需要双倍内存读取，导致效率瓶颈。MGLU旨在解决这一问题，提升计算和内存效率。

Method: 提出了Masked Gated Linear Units（MGLU），包括Mixture of Element-wise Gating（MoEG）架构和FlashMGLU内核，通过共享权重矩阵和优化实现减少内存传输。

Result: MGLU在RTX5090 GPU上实现了47%的内存效率提升和34%的速度提升，同时SwiMGLU变体在性能上匹配或超越了SwiGLU基线。

Conclusion: MGLU是一种高效且性能优越的GLU替代方案，适用于LLMs的优化。

Abstract: Gated Linear Units (GLUs) have become essential components in the
feed-forward networks of state-of-the-art Large Language Models (LLMs).
However, they require twice as many memory reads compared to feed-forward
layers without gating, due to the use of separate weight matrices for the gate
and value streams. To address this bottleneck, we introduce Masked Gated Linear
Units (MGLUs), a novel family of GLUs with an efficient kernel implementation.
The core contribution of MGLUs include: (1) the Mixture of Element-wise Gating
(MoEG) architecture that learns multiple binary masks, each determining gate or
value assignments at the element level on a single shared weight matrix
resulting in reduced memory transfer, and (2) FlashMGLU, a hardware-friendly
kernel that yields up to a 19.7 $\times$ inference-time speed-up over a naive
PyTorch MGLU and is 47% more memory-efficient and 34% faster than standard GLUs
despite added architectural complexity on an RTX5090 GPU. In LLM experiments,
the Swish-activated variant SwiMGLU preserves its memory advantages while
matching - or even surpassing - the downstream accuracy of the SwiGLU baseline.

</details>


### [487] [Sub-MoE: Efficient Mixture-of-Expert LLMs Compression via Subspace Expert Merging](https://arxiv.org/abs/2506.23266)
*Lujun Li,Zhu Qiyuan,Jiacheng Wang,Wei Li,Hao Gu,Sirui Han,Yike Guo*

Main category: cs.LG

Relevance: 85.0

TL;DR: Sub-MoE是一种通过子空间专家合并压缩Mixture of Experts (MoE) LLM的新框架，解决了参数冲突问题，显著提升了效率。


<details>
  <summary>Details</summary>
Motivation: MoE LLM由于参数规模庞大，面临内存、存储和部署的挑战，现有专家合并方法因参数冲突受限。

Method: Sub-MoE通过自适应专家聚类和子空间专家合并两阶段，利用SVD提取共享U矩阵并合并专家特定V矩阵。

Result: 在Mixtral等MoE LLM上，Sub-MoE显著优于现有方法，保持96%|86%性能的同时减少25%|50%专家。

Conclusion: Sub-MoE为MoE LLM的高效压缩提供了新思路，并可进一步优化推理。

Abstract: Mixture of Experts (MoE) LLMs face significant obstacles due to their massive
parameter scale, which imposes memory, storage, and deployment challenges.
Although recent expert merging methods promise greater efficiency by
consolidating multiple experts, they are fundamentally hindered by parameter
conflicts arising from expert specialization. In this paper, we present
Sub-MoE, a novel MoE compression framework via Subspace Expert Merging. Our key
insight is to perform joint Singular Value Decomposition (SVD) on concatenated
expert weights, reducing conflicting parameters by extracting shared
$U$-matrices while enabling effective merging of the expert-specific $V$
components. Specifically, Sub-MoE consists of two innovative phases: (1)
Adaptive Expert Clustering, which groups functionally coherent experts via
K-means clustering based on cosine similarity of expert outputs; and (2)
Subspace Expert Merging, which first enforces Experts Union Decomposition to
derive the shared $U$-matrix across experts in the same group, then pursues
frequency-based merging for individual $V$-matrices, and finalizes expert
reconstruction using the merged $V$-matrix. In this way, we align and fuse
experts in a shared subspace, and can be extended with intra-expert compression
for further inference optimization. Extensive experiments on Mixtral, DeepSeek,
and Qwen-1.5|3 MoE LLMs demonstrate that our Sub-MoE significantly outperforms
existing expert pruning and merging methods. Notably, our Sub-MoE maintains
96\%|86\% of original performance with 25\%|50\% expert reduction on
Mixtral-8x7B in zero-shot benchmarks. Code will be released at
https://github.com/lliai/MoERazor.

</details>


### [488] [Predicting thinking time in Reasoning models](https://arxiv.org/abs/2506.23274)
*Hans Peter Lynsgøe Raaschou-jensen,Constanza Fierro,Anders Søgaard*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文探讨了推理模型在复杂任务中的“思考时间”预测问题，提出了在线和离线预测方法，旨在为用户提供类似“进度条”的体验。


<details>
  <summary>Details</summary>
Motivation: 推理模型在复杂任务中表现优异，但其“思考时间”不可预测，可能导致用户挫败感。研究旨在解决这一问题。

Method: 提出了在线和离线预测模型“思考时间”的方法，并评估其效果。

Result: 开发了实用的“推理进度条”，提升了用户体验。

Conclusion: 研究为推理模型的用户交互提供了新方向，并指出了未来研究的潜在路径。

Abstract: Reasoning models that produce long, hidden chains of thought have emerged as
powerful tools for complex, reasoning-intensive
tasks\citep{deepseekai2025deepseekr1incentivizingreasoningcapability,
openai2024openaio1card}. However, this paradigm introduces a new user
experience challenge: users have little insight into how much time the model
will spend reasoning before returning an answer. This unpredictability, can
lead to user frustration and is likely to compound as LLMs can produce
increasingly long tasks asynchronously
\citep{kwa2025measuringaiabilitycomplete}. In this paper, we introduce and
evaluate methods for both online and offline prediction of model "thinking
time," aiming to develop a practical "progress bar for reasoning." We discuss
the implications for user interaction and future research directions.

</details>


### [489] [Do LLMs Dream of Discrete Algorithms?](https://arxiv.org/abs/2506.23408)
*Claudionor Coelho Jr,Yanen Li,Philip Tee*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文提出了一种神经符号方法，通过将逻辑推理模块（如Prolog谓词）与LLMs结合，增强其在逻辑推理和可解释性方面的能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在严格逻辑推理和离散决策方面存在局限性，限制了其可靠性和可解释性。

Method: 采用神经符号方法，结合一阶逻辑和显式规则系统，将复杂查询分解为可验证的子任务。

Result: 在DABStep基准测试中，该方法提高了多步推理任务的精度、覆盖率和系统文档化。

Conclusion: 结合LLMs与模块化逻辑推理能提升系统可靠性，并为可信赖、可解释的AI代理提供可扩展路径。

Abstract: Large Language Models (LLMs) have rapidly transformed the landscape of
artificial intelligence, enabling natural language interfaces and dynamic
orchestration of software components. However, their reliance on probabilistic
inference limits their effectiveness in domains requiring strict logical
reasoning, discrete decision-making, and robust interpretability. This paper
investigates these limitations and proposes a neurosymbolic approach that
augments LLMs with logic-based reasoning modules, particularly leveraging
Prolog predicates and composable toolsets. By integrating first-order logic and
explicit rule systems, our framework enables LLMs to decompose complex queries
into verifiable sub-tasks, orchestrate reliable solutions, and mitigate common
failure modes such as hallucination and incorrect step decomposition. We
demonstrate the practical benefits of this hybrid architecture through
experiments on the DABStep benchmark, showing improved precision, coverage, and
system documentation in multi-step reasoning tasks. Our results indicate that
combining LLMs with modular logic reasoning restores engineering rigor,
enhances system reliability, and offers a scalable path toward trustworthy,
interpretable AI agents across complex domains.

</details>


### [490] [Sample Margin-Aware Recalibration of Temperature Scaling](https://arxiv.org/abs/2506.23492)
*Haolan Guo,Linwei Tao,Haoyang Luo,Minjing Dong,Chang Xu*

Main category: cs.LG

Relevance: 85.0

TL;DR: SMART是一种轻量级、数据高效的重校准方法，通过基于前两个logit之间的间隙（logit gap）精确调整logit，解决了现有校准方法的高偏差或高方差问题。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络在安全关键场景中部署时存在系统性过度自信问题，现有校准方法面临全局调整高偏差或高维输入高方差的困境。

Method: 提出SMART方法，利用logit gap作为去噪标量信号，结合SoftECE目标实现自适应分箱，平衡偏差和方差。

Result: 在多种数据集和架构上，SMART以较少参数实现最先进的校准性能。

Conclusion: SMART为神经网络预测中的不确定性量化提供了高效、鲁棒的解决方案。

Abstract: Recent advances in deep learning have significantly improved predictive
accuracy. However, modern neural networks remain systematically overconfident,
posing risks for deployment in safety-critical scenarios. Current post-hoc
calibration methods face a fundamental dilemma: global approaches like
Temperature Scaling apply uniform adjustments across all samples, introducing
high bias despite computational efficiency, while more expressive methods that
operate on full logit distributions suffer from high variance due to noisy
high-dimensional inputs and insufficient validation data. To address these
challenges, we propose Sample Margin-Aware Recalibration of Temperature
(SMART), a lightweight, data-efficient recalibration method that precisely
scales logits based on the margin between the top two logits -- termed the
logit gap. Specifically, the logit gap serves as a denoised, scalar signal
directly tied to decision boundary uncertainty, providing a robust indicator
that avoids the noise inherent in high-dimensional logit spaces while
preserving model prediction invariance. Meanwhile, SMART employs a novel
soft-binned Expected Calibration Error (SoftECE) objective that balances model
bias and variance through adaptive binning, enabling stable parameter updates
even with extremely limited calibration data. Extensive evaluations across
diverse datasets and architectures demonstrate that SMART achieves
state-of-the-art calibration performance even with substantially fewer
parameters compared to existing parametric methods, offering a principled,
robust, and highly efficient solution for practical uncertainty quantification
in neural network predictions. The source code is available at:
https://anonymous.4open.science/r/SMART-8B11.

</details>


### [491] [A unified framework on the universal approximation of transformer-type architectures](https://arxiv.org/abs/2506.23551)
*Jingpu Cheng,Qianxiao Li,Ting Lin,Zuowei Shen*

Main category: cs.LG

Relevance: 85.0

TL;DR: 该论文研究了Transformer类架构的通用逼近性质（UAP），提出了一个统一的理论框架，扩展了残差网络的结果，并引入了一个适用于广泛架构的充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解Transformer架构的通用逼近能力，为设计具有UAP保证的新型架构提供理论基础。

Method: 方法包括提出一个基于token区分性的通用充分条件，并利用注意力层的解析性假设简化验证过程。

Result: 结果表明，该框架适用于多种注意力机制（如基于核和稀疏注意力），并推广或补充了现有工作。

Conclusion: 结论是该框架为设计具有UAP保证的新型Transformer架构提供了理论基础，并展示了具体示例。

Abstract: We investigate the universal approximation property (UAP) of transformer-type
architectures, providing a unified theoretical framework that extends prior
results on residual networks to models incorporating attention mechanisms. Our
work identifies token distinguishability as a fundamental requirement for UAP
and introduces a general sufficient condition that applies to a broad class of
architectures. Leveraging an analyticity assumption on the attention layer, we
can significantly simplify the verification of this condition, providing a
non-constructive approach in establishing UAP for such architectures. We
demonstrate the applicability of our framework by proving UAP for transformers
with various attention mechanisms, including kernel-based and sparse attention
mechanisms. The corollaries of our results either generalize prior works or
establish UAP for architectures not previously covered. Furthermore, our
framework offers a principled foundation for designing novel transformer
architectures with inherent UAP guarantees, including those with specific
functional symmetries. We propose examples to illustrate these insights.

</details>


### [492] [Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic](https://arxiv.org/abs/2506.23875)
*Yuta Sato,Kazuhiko Kawamoto,Hiroshi Kera*

Main category: cs.LG

Relevance: 85.0

TL;DR: 提出了一种重新排列解码器输入令牌的方法，以优化Transformer在算术任务中的学习顺序。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer中思维链的顺序对推理难度的影响，探索如何通过重新排列输入令牌的顺序来优化学习效果。

Method: 提出两阶段分层方法，先训练Transformer于不同顺序的目标序列，再通过早期损失下降识别良性顺序。

Result: 在四个顺序敏感的算术任务中，成功从数十亿候选顺序中识别出学习友好顺序，并在乘法任务中重现了先前研究的逆序数字顺序。

Conclusion: 通过重新排列输入顺序可以显著优化Transformer的学习效果，尤其是在顺序敏感的任务中。

Abstract: The chain of thought is fundamental in Transformers, which is to perform
step-by-step reasoning. Besides what intermediate steps work, the order of
these steps critically affects the difficulty of the reasoning. This study
addresses a novel task of unraveling chain of thought - reordering decoder
input tokens to a learning-friendly sequence for Transformers to learn
arithmetic tasks. The proposed pipeline first trains a Transformer on a mixture
of target sequences arranged in different orders and then identifies benign
orders as those with fast loss drops in the early stage. As the search space
grows factorially with sequence length, we propose a two-stage hierarchical
approach for inter- and intra-block reordering. Experiments on four
order-sensitive arithmetic tasks show that our method identifies a
learning-friendly order out of a few billion candidates. Notably, on the
multiplication task, it recovered the reverse-digit order reported in prior
studies.

</details>


### [493] [Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime](https://arxiv.org/abs/2506.24120)
*Yuqing Wang,Shangding Gu*

Main category: cs.LG

Relevance: 85.0

TL;DR: 论文探讨了数据选择在大型语言模型（LLMs）中的重要性，提出通过选择更均匀分布的数据来提升训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 研究数据选择的通用原则，尤其是在复杂任务中，如何通过数据均匀性提升模型表现。

Method: 理论分析数据点间最小距离（h_min）对梯度下降（GD）训练动态的影响，并建立收敛框架，适用于包括Transformer在内的多种架构。

Result: 实验表明，最大化数据点间距离能显著加速训练，并在多种数据集上提升LLMs性能。

Conclusion: 数据均匀性是提升LLMs训练效率和性能的有效原则。

Abstract: Data selection plays a crucial role in data-driven decision-making, including
in large language models (LLMs), and is typically task-dependent. Properties
such as data quality and diversity have been extensively studied and are known
to enhance model performance. However, it remains unclear whether there exist
other quantitative and general principles of data selection that can
consistently improve performance, especially for complex tasks with limited
prior knowledge. In this paper, we demonstrate that selecting more uniformly
distributed data can improve training efficiency while enhancing performance.
Specifically, we establish that more uniform (less biased) distribution leads
to a larger minimum pairwise distance between data points, denoted by
$h_{\min}$, and prove that a smaller $h_{\min}$ can slow down the training
dynamics of gradient descent (GD). Moreover, we theoretically show that the
approximation error of neural networks decreases as $h_{\min}$ increases. Our
analysis introduces a convergence framework for GD beyond the Neural Tangent
Kernel (NTK) regime, applicable to a broad class of architectures, including
transformers, without requiring Lipschitz smoothness. This framework further
provides theoretical justification for the use of residual connections and
function compositions in deep neural architectures. In the end, we conduct
comprehensive experiments for supervised fine-tuning across various settings,
including different optimization strategies, model sizes, and training
datasets. The results consistently demonstrate that selecting data by
maximizing pairwise distance significantly accelerates training and achieves
comparable or better performance in LLMs across diverse datasets. Code and
Datasets are available at the link:
https://github.com/SafeRL-Lab/data-uniformity.

</details>


### [494] [MetaCipher: A General and Extensible Reinforcement Learning Framework for Obfuscation-Based Jailbreak Attacks on Black-Box LLMs](https://arxiv.org/abs/2506.22557)
*Boyuan Chen,Minghao Shao,Abdul Basit,Siddharth Garg,Muhammad Shafique*

Main category: cs.CR

Relevance: 85.0

TL;DR: MetaCipher是一个基于混淆的越狱框架，通过强化学习动态选择加密策略，显著提高了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）能力的增强，混淆攻击（如加密恶意内容以逃避检测）变得难以防御，现有安全机制无法有效应对。

Method: 提出MetaCipher框架，结合强化学习的动态加密策略选择机制，从密码池中选择最优策略，支持任意密码家族。

Result: 在10次查询内，MetaCipher对非推理型LLM的攻击成功率达92%，对推理型LLM达74%，优于现有方法。

Conclusion: MetaCipher具有长期鲁棒性和适应性，能有效应对不断发展的安全措施。

Abstract: The growing capabilities of large language models (LLMs) have exposed them to
increasingly sophisticated jailbreak attacks. Among these, obfuscation-based
attacks -- which encrypt malicious content to evade detection -- remain highly
effective. By leveraging the reasoning ability of advanced LLMs to interpret
encrypted prompts, such attacks circumvent conventional defenses that rely on
keyword detection or context filtering. These methods are very difficult to
defend against, as existing safety mechanisms are not designed to interpret or
decode ciphered content. In this work, we propose \textbf{MetaCipher}, a novel
obfuscation-based jailbreak framework, along with a reinforcement
learning-based dynamic cipher selection mechanism that adaptively chooses
optimal encryption strategies from a cipher pool. This approach enhances
jailbreak effectiveness and generalizability across diverse task types, victim
LLMs, and safety guardrails. Our framework is modular and extensible by design,
supporting arbitrary cipher families and accommodating evolving adversarial
strategies. We complement our method with a large-scale empirical analysis of
cipher performance across multiple victim LLMs. Within as few as 10 queries,
MetaCipher achieves over 92\% attack success rate (ASR) on most recent standard
malicious prompt benchmarks against state-of-the-art non-reasoning LLMs, and
over 74\% ASR against reasoning-capable LLMs, outperforming all existing
obfuscation-based jailbreak methods. These results highlight the long-term
robustness and adaptability of our approach, making it more resilient than
prior methods in the face of advancing safety measures.

</details>


### [495] [Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC](https://arxiv.org/abs/2506.24045)
*Xinming Wei,Jiahao Zhang,Haoran Li,Jiayu Chen,Rui Qu,Maoliang Li,Xiang Chen,Guojie Luo*

Main category: cs.DC

Relevance: 85.0

TL;DR: Agent.xpu是一个高效的服务系统，用于在异构SoC上处理代理型LLM工作负载，显著降低反应任务延迟并提高主动任务吞吐量。


<details>
  <summary>Details</summary>
Motivation: 随着代理型LLM在个人设备上的普及，现有引擎无法高效处理反应任务（低延迟）和主动任务（高吞吐量）的并发需求。

Method: 通过离线分析构建异构执行图，结合在线调度器实现细粒度抢占和带宽感知调度。

Result: 在Intel Core Ultra SoC上，Agent.xpu将反应任务延迟降低4.6倍，主动任务吞吐量提高1.6-6.8倍。

Conclusion: Agent.xpu为异构SoC上的代理型LLM工作负载提供了高效的服务解决方案。

Abstract: The proliferation of agentic Large Language Models (LLMs) on personal devices
introduces a new class of workloads characterized by a dichotomy of objectives.
Reactive tasks, initiated by users, demand immediate, low-latency responses,
while proactive tasks operate invisibly and prioritize throughput. Existing
on-device LLM engines, designed for isolated inferences, fail to efficiently
manage these concurrent and conflicting requests on consumer-grade
heterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces
Agent.xpu, an efficient serving system for agentic LLM workloads on
memory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu
first constructs a heterogeneous execution graph, which fuses and chunks model
kernels for affinity-guided, elastic accelerator mapping with predictive kernel
annotation. At runtime, its online scheduler enables fine-grained, kernel-level
preemption to guarantee the responsiveness of reactive tasks. To maximize SoC
utilization, it adopts slack-aware kernel backfill to opportunistically append
proactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware
dispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves
4.6$\times$ lower latency for reactive tasks and sustains
1.6$\times$-6.8$\times$ higher throughput for proactive tasks compared to
state-of-the-art inference engines.

</details>


### [496] [FairMarket-RL: LLM-Guided Fairness Shaping for Multi-Agent Reinforcement Learning in Peer-to-Peer Markets](https://arxiv.org/abs/2506.22708)
*Shrenik Jadhav,Birva Sevak,Srijita Das,Akhtar Hussain,Wencong Su,Van-Hai Bui*

Main category: cs.LG

Relevance: 75.0

TL;DR: FairMarket-RL结合LLM和RL，通过实时公平性评估优化P2P交易，实现公平性和高效性。


<details>
  <summary>Details</summary>
Motivation: 现有P2P交易缺乏公平性框架，FairMarket-RL旨在通过LLM和RL解决这一问题。

Method: 使用LLM作为公平性评估器，结合IPPO训练交易代理，通过动态奖励塑造优化公平性。

Result: 代理满足90%买方需求，公平性评分高于0.80，收敛更快且减少卖方利润差距。

Conclusion: FairMarket-RL为去中心化能源交易提供了可扩展的公平性解决方案。

Abstract: Peer-to-peer (P2P) trading is increasingly recognized as a key mechanism for
decentralized market regulation, yet existing approaches often lack robust
frameworks to ensure fairness. This paper presents FairMarket-RL, a novel
hybrid framework that combines Large Language Models (LLMs) with Reinforcement
Learning (RL) to enable fairness-aware trading agents. In a simulated P2P
microgrid with multiple sellers and buyers, the LLM acts as a real-time
fairness critic, evaluating each trading episode using two metrics:
Fairness-To-Buyer (FTB) and Fairness-Between-Sellers (FBS). These fairness
scores are integrated into agent rewards through scheduled
{\lambda}-coefficients, forming an adaptive LLM-guided reward shaping loop that
replaces brittle, rule-based fairness constraints. Agents are trained using
Independent Proximal Policy Optimization (IPPO) and achieve equitable outcomes,
fulfilling over 90% of buyer demand, maintaining fair seller margins, and
consistently reaching FTB and FBS scores above 0.80. The training process
demonstrates that fairness feedback improves convergence, reduces buyer
shortfalls, and narrows profit disparities between sellers. With its
language-based critic, the framework scales naturally, and its extension to a
large power distribution system with household prosumers illustrates its
practical applicability. FairMarket-RL thus offers a scalable, equity-driven
solution for autonomous trading in decentralized energy systems.

</details>


### [497] [BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters](https://arxiv.org/abs/2506.22809)
*Cooper Doyle*

Main category: cs.LG

Relevance: 75.0

TL;DR: BayesLoRA是一种任务特定的不确定性量化框架，将MC-Dropout集成到LoRA中，为下游工作流提供定制化的不确定性评估。


<details>
  <summary>Details</summary>
Motivation: 现有通用Transformer不确定性方法无法满足下游任务的需求，BayesLoRA旨在提供更贴合实际工作流的不确定性评估。

Method: 通过将MC-Dropout集成到LoRA中，BayesLoRA量化任务特定的不确定性，并验证LoRA适配器在微调分布外的方差放大现象。

Result: 实验证明LoRA适配器在微调分布外表现出放大的方差，为智能体决策提供了可靠的不确定性估计。

Conclusion: BayesLoRA为下游任务提供了有效的不确定性量化工具，支持智能体在不确定性下的行为调整。

Abstract: We propose BayesLoRA, a task-specific uncertainty quantification framework
that integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike
general-purpose transformer uncertainty methods, BayesLoRA provides guardrails
tailored to downstream workflows, enabling agents to introspect and modulate
behavior under uncertainty. We demonstrate mathematically and empirically that
LoRA adapters exhibit amplified variance outside fine-tuning distributions,
yielding reliable confidence estimates for agentic decision-making.

</details>


### [498] [Feature-Wise Mixing for Mitigating Contextual Bias in Predictive Supervised Learning](https://arxiv.org/abs/2506.23033)
*Yash Vardhan Tomar*

Main category: cs.LG

Relevance: 75.0

TL;DR: 提出了一种特征混合框架来缓解预测机器学习模型中的偏差，通过跨上下文数据集重新分配特征表示，显著减少了偏差并保持了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有偏差缓解策略（如后处理或刚性约束）可能限制可扩展性和泛化性，因此需要更高效的解决方案。

Method: 采用特征混合框架，通过重新分配特征表示来缓解偏差，并使用交叉验证和偏差敏感损失函数评估效果。

Result: 平均偏差减少43.35%，预测性能（MSE）显著提升，且优于SMOTE过采样方法。

Conclusion: 特征混合框架在减少偏差的同时避免了计算开销，未来可应用于实际场景。

Abstract: Bias in predictive machine learning (ML) models is a fundamental challenge
due to the skewed or unfair outcomes produced by biased models. Existing
mitigation strategies rely on either post-hoc corrections or rigid constraints.
However, emerging research claims that these techniques can limit scalability
and reduce generalizability. To address this, this paper introduces a
feature-wise mixing framework to mitigate contextual bias. This was done by
redistributing feature representations across multiple contextual datasets. To
assess feature-wise mixing's effectiveness, four ML classifiers were trained
using cross-validation and evaluated with bias-sensitive loss functions,
including disparity metrics and mean squared error (MSE), which served as a
standard measure of predictive performance. The proposed method achieved an
average bias reduction of 43.35% and a statistically significant decrease in
MSE across all classifiers trained on mixed datasets. Additionally,
benchmarking against established bias mitigation techniques found that
feature-wise mixing consistently outperformed SMOTE oversampling and
demonstrated competitive effectiveness without requiring explicit bias
attribute identification. Feature-wise mixing efficiently avoids the
computational overhead typically associated with fairness-aware learning
algorithms. Future work could explore applying feature-wise mixing for
real-world fields where accurate predictions are necessary.

</details>


### [499] [Fragile, Robust, and Antifragile: A Perspective from Parameter Responses in Reinforcement Learning Under Stress](https://arxiv.org/abs/2506.23036)
*Zain ul Abdeen,Ming Jin*

Main category: cs.LG

Relevance: 75.0

TL;DR: 本文通过引入内部和外部压力分析RL策略的鲁棒性，提出了一种基于参数分类的框架，验证了抗脆弱参数的存在，并展示了其在提升策略适应性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究RL策略在内部和外部压力下的鲁棒性，受神经科学中突触可塑性的启发，旨在分类参数并量化其特性，以提升RL系统的稳健性和适应性。

Method: 通过突触过滤引入内部压力（选择性扰动参数），结合对抗攻击的外部压力，分类参数为脆弱、鲁棒或抗脆弱，并定义参数评分。在Mujoco连续控制环境中验证PPO训练的策略。

Result: 发现抗脆弱参数能在压力下提升策略性能，验证了针对性过滤技术对RL策略适应性的改进潜力。

Conclusion: 研究为设计鲁棒和抗脆弱的RL系统提供了基础，未来可进一步优化RL策略的适应性。

Abstract: This paper explores Reinforcement learning (RL) policy robustness by
systematically analyzing network parameters under internal and external
stresses. Inspired by synaptic plasticity in neuroscience, synaptic filtering
introduces internal stress by selectively perturbing parameters, while
adversarial attacks apply external stress through modified agent observations.
This dual approach enables the classification of parameters as fragile, robust,
or antifragile, based on their influence on policy performance in clean and
adversarial settings. Parameter scores are defined to quantify these
characteristics, and the framework is validated on PPO-trained agents in Mujoco
continuous control environments. The results highlight the presence of
antifragile parameters that enhance policy performance under stress,
demonstrating the potential of targeted filtering techniques to improve RL
policy adaptability. These insights provide a foundation for future
advancements in the design of robust and antifragile RL systems.

</details>


### [500] [VALID-Mol: a Systematic Framework for Validated LLM-Assisted Molecular Design](https://arxiv.org/abs/2506.23339)
*Malikussaid,Hilal Hudan Nuha*

Main category: cs.LG

Relevance: 75.0

TL;DR: VALID-Mol框架通过结合提示工程、化学验证和微调LLM，将生成有效化学结构的比率从3%提升至83%，适用于科学领域约束的LLM应用。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在需要事实准确性和领域特定约束的科学领域（如分子设计）中生成无效或不实用结构的问题。

Method: 结合方法性提示工程、自动化化学验证和微调的领域适应LLM，确保生成可合成且性质优化的分子。

Result: 生成有效化学结构的比率从3%提升至83%，计算预测目标亲和力提升高达17倍。

Conclusion: VALID-Mol为科学领域约束的LLM应用提供了可推广的方法论，显著提升了生成结果的可靠性。

Abstract: Large Language Models (LLMs) demonstrate remarkable potential for scientific
discovery, but their application in domains requiring factual accuracy and
domain-specific constraints remains challenging. In molecular design for drug
discovery, LLMs can suggest creative molecular modifications but often produce
chemically invalid or impractical structures. We present VALID-Mol, a
systematic framework for integrating chemical validation with LLM-driven
molecular design that increases the rate of generating valid chemical
structures from 3% to 83%. Our approach combines methodical prompt engineering,
automated chemical validation, and a fine-tuned domain-adapted LLM to ensure
reliable generation of synthesizable molecules with improved properties. Beyond
the specific implementation, we contribute a generalizable methodology for
scientifically-constrained LLM applications, with quantifiable reliability
improvements. Computational predictions suggest our framework can generate
promising candidates for synthesis with up to 17-fold computationally predicted
improvements in target affinity while maintaining synthetic accessibility. We
provide a detailed analysis of our prompt engineering process, validation
architecture, and fine-tuning approach, offering a reproducible blueprint for
applying LLMs to other scientific domains where domain-specific validation is
essential.

</details>


### [501] [KAIROS: Scalable Model-Agnostic Data Valuation](https://arxiv.org/abs/2506.23799)
*Jiongli Zhu,Parjanya Prajakta Prashant,Alex Cloninger,Babak Salimi*

Main category: cs.LG

Relevance: 75.0

TL;DR: KAIROS是一个可扩展的、模型无关的数据评估框架，通过MMD（最大均值差异）为每个训练样本分配分布影响分数，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据评估方法存在偏差、计算成本高或近似不准确的问题，需要一种更高效、更准确的解决方案。

Method: KAIROS利用MMD计算样本对训练分布与参考集之间差异的贡献，提供闭式解，无需重新训练，支持在线更新。

Result: 在噪声、错误标注和投毒基准测试中，KAIROS在准确性和运行时间上均优于现有方法。

Conclusion: KAIROS为数据评估提供了一种高效、准确的解决方案，具有理论保证和实际应用潜力。

Abstract: Training data increasingly shapes not only model accuracy but also regulatory
compliance and market valuation of AI assets. Yet existing valuation methods
remain inadequate: model-based techniques depend on a single fitted model and
inherit its biases, while algorithm-based approaches such as Data Shapley
require costly retrainings at web scale. Recent Wasserstein-based
model-agnostic methods rely on approximations that misrank examples relative to
their true leave-one-out (LOO) utility. We introduce KAIROS, a scalable,
model-agnostic valuation framework that assigns each example a distributional
influence score: its contribution to the Maximum Mean Discrepancy (MMD) between
the empirical training distribution and a clean reference set. Unlike
Wasserstein surrogates, our MMD-based influence admits a closed-form solution
that faithfully approximates the exact LOO ranking within $O(1/N^2)$ error,
requires no retraining, and naturally extends to conditional kernels for
unified label- and feature-error detection. Moreover, KAIROS supports efficient
online updates: when a new batch of size m arrives, all scores can be updated
in $O(mN)$ time, delivering up to 50x speedup without compromising ranking
quality. Empirical evaluations on noise, mislabeling, and poisoning benchmarks
show that KAIROS consistently outperforms state-of-the-art model-, Shapley-,
and Wasserstein-based baselines in both accuracy and runtime. We provide
rigorous theoretical guarantees, including symmetry for reproducible rankings
and density-separation for interpretable thresholds.

</details>


### [502] [From Model Design to Organizational Design: Complexity Redistribution and Trade-Offs in Generative AI](https://arxiv.org/abs/2506.22440)
*Sharique Hasan,Alexander Oettl,Sampsa Samila*

Main category: cs.CY

Relevance: 75.0

TL;DR: 论文提出了GAS框架，分析LLMs如何重塑组织和竞争策略，强调AI不仅仅是降低输入成本，而是重新分配复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs对组织和竞争策略的影响，揭示AI应用中隐藏的复杂性转移问题。

Method: 提出GAS框架，分析LLMs在通用性、准确性和简洁性之间的权衡，以及复杂性在利益相关者间的重新分配。

Result: LLMs通过简单接口提供高通用性和准确性，但复杂性转移到基础设施和专业人员，带来新的管理挑战。

Conclusion: 竞争优势源于对复杂性转移的掌控，而非简单的AI采用。

Abstract: This paper introduces the Generality-Accuracy-Simplicity (GAS) framework to
analyze how large language models (LLMs) are reshaping organizations and
competitive strategy. We argue that viewing AI as a simple reduction in input
costs overlooks two critical dynamics: (a) the inherent trade-offs among
generality, accuracy, and simplicity, and (b) the redistribution of complexity
across stakeholders. While LLMs appear to defy the traditional trade-off by
offering high generality and accuracy through simple interfaces, this
user-facing simplicity masks a significant shift of complexity to
infrastructure, compliance, and specialized personnel. The GAS trade-off,
therefore, does not disappear but is relocated from the user to the
organization, creating new managerial challenges, particularly around accuracy
in high-stakes applications. We contend that competitive advantage no longer
stems from mere AI adoption, but from mastering this redistributed complexity
through the design of abstraction layers, workflow alignment, and complementary
expertise. This study advances AI strategy by clarifying how scalable cognition
relocates complexity and redefines the conditions for technology integration.

</details>


### [503] [Riemannian-Geometric Fingerprints of Generative Models](https://arxiv.org/abs/2506.22802)
*Hae Jin Song,Laurent Itti*

Main category: cs.LG

Relevance: 70.0

TL;DR: 论文提出了一种基于黎曼几何的生成模型指纹定义方法，用于模型归属和区分合成数据与人类数据。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展和应用引发了对模型归属和指纹识别的需求，但目前缺乏一个正式的理论框架来定义和分析这些指纹。

Method: 采用黎曼几何方法，定义生成模型的指纹，提出基于梯度的算法计算指纹，并在多数据集、多模型架构和多模态上进行验证。

Result: 该方法在区分多种生成模型上表现优异，显著提升了模型归属任务的性能，并能泛化到未见过的数据集和模型类型。

Conclusion: 提出的黎曼几何框架为生成模型指纹提供了一种有效的理论和方法，具有实际应用价值。

Abstract: Recent breakthroughs and rapid integration of generative models (GMs) have
sparked interest in the problem of model attribution and their fingerprints.
For instance, service providers need reliable methods of authenticating their
models to protect their IP, while users and law enforcement seek to verify the
source of generated content for accountability and trust. In addition, a
growing threat of model collapse is arising, as more model-generated data are
being fed back into sources (e.g., YouTube) that are often harvested for
training ("regurgitative training"), heightening the need to differentiate
synthetic from human data. Yet, a gap still exists in understanding generative
models' fingerprints, we believe, stemming from the lack of a formal framework
that can define, represent, and analyze the fingerprints in a principled way.
To address this gap, we take a geometric approach and propose a new definition
of artifact and fingerprint of GMs using Riemannian geometry, which allows us
to leverage the rich theory of differential geometry. Our new definition
generalizes previous work (Song et al., 2024) to non-Euclidean manifolds by
learning Riemannian metrics from data and replacing the Euclidean distances and
nearest-neighbor search with geodesic distances and kNN-based Riemannian center
of mass. We apply our theory to a new gradient-based algorithm for computing
the fingerprints in practice. Results show that it is more effective in
distinguishing a large array of GMs, spanning across 4 different datasets in 2
different resolutions (64 by 64, 256 by 256), 27 model architectures, and 2
modalities (Vision, Vision-Language). Using our proposed definition
significantly improves the performance on model attribution, as well as a
generalization to unseen datasets, model types, and modalities, suggesting its
practical efficacy.

</details>


### [504] [xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection](https://arxiv.org/abs/2506.22837)
*Kamil Faber,Marcin Pietroń,Dominik Żurek,Roberto Corizzo*

Main category: cs.LG

Relevance: 70.0

TL;DR: xLSTMAD是一种基于xLSTM架构的异常检测方法，首次将xLSTM应用于多变量时间序列数据的异常检测，表现优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 尽管xLSTM在时间序列预测和语言建模中表现优异，但其在异常检测中的应用尚未被探索。本文填补了这一空白。

Method: 提出xLSTMAD，包含编码器和解码器架构，支持预测（xLSTMAD-F）和重构（xLSTMAD-R）两种变体，并使用MSE和SoftDTW损失函数。

Result: 在TSB-AD-M基准测试中，xLSTMAD优于23种基线方法，展示了xLSTM在异常检测中的强大能力。

Conclusion: xLSTMAD为异常检测提供了新的研究方向，展示了xLSTM的潜力。

Abstract: The recently proposed xLSTM is a powerful model that leverages expressive
multiplicative gating and residual connections, providing the temporal capacity
needed for long-horizon forecasting and representation learning. This
architecture has demonstrated success in time series forecasting, lossless
compression, and even large-scale language modeling tasks, where its linear
memory footprint and fast inference make it a viable alternative to
Transformers. Despite its growing popularity, no prior work has explored xLSTM
for anomaly detection. In this work, we fill this gap by proposing xLSTMAD, the
first anomaly detection method that integrates a full encoder-decoder xLSTM
architecture, purpose-built for multivariate time series data. Our encoder
processes input sequences to capture historical context, while the decoder is
devised in two separate variants of the method. In the forecasting approach,
the decoder iteratively generates forecasted future values xLSTMAD-F, while the
reconstruction approach reconstructs the input time series from its encoded
counterpart xLSTMAD-R. We investigate the performance of two loss functions:
Mean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to consider
local reconstruction fidelity and global sequence alignment, respectively. We
evaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17
real-world datasets, using state-of-the-art challenging metrics such as VUS-PR.
In our results, xLSTM showcases state-of-the-art accuracy, outperforming 23
popular anomaly detection baselines. Our paper is the first work revealing the
powerful modeling capabilities of xLSTM for anomaly detection, paving the way
for exciting new developments on this subject. Our code is available at:
https://github.com/Nyderx/xlstmad

</details>


### [505] [Curious Causality-Seeking Agents Learn Meta Causal World](https://arxiv.org/abs/2506.23068)
*Zhiyu Zhao,Haoxuan Li,Haifeng Zhang,Jun Wang,Francesco Faccio,Jürgen Schmidhuber,Mengyue Yang*

Main category: cs.LG

Relevance: 70.0

TL;DR: 论文提出了一种名为“元因果图”的世界模型，用于高效编码因果结构在不同潜在世界状态间的转换规则，并设计了一个“因果寻求代理”来识别触发子图的元状态、发现因果关系并通过探索迭代优化模型。


<details>
  <summary>Details</summary>
Motivation: 现实环境中因果机制可能因策略或环境状态的细微变化而改变，传统假设单一固定因果机制的方法难以适应这种动态性。

Method: 引入元因果图作为世界模型，由多个因果子图组成，每个子图由潜在状态空间中的元状态触发。设计因果寻求代理，通过好奇心驱动的干预策略识别元状态和因果关系，并迭代优化模型。

Result: 在合成任务和机器人手臂操作任务中，方法能稳健捕捉因果动态变化并有效泛化到未见过的情境。

Conclusion: 元因果图及其代理能有效建模动态因果机制，适用于复杂环境。

Abstract: When building a world model, a common assumption is that the environment has
a single, unchanging underlying causal rule, like applying Newton's laws to
every situation. In reality, what appears as a drifting causal mechanism is
often the manifestation of a fixed underlying mechanism seen through a narrow
observational window. This brings about a problem that, when building a world
model, even subtle shifts in policy or environment states can alter the very
observed causal mechanisms. In this work, we introduce the \textbf{Meta-Causal
Graph} as world models, a minimal unified representation that efficiently
encodes the transformation rules governing how causal structures shift across
different latent world states. A single Meta-Causal Graph is composed of
multiple causal subgraphs, each triggered by meta state, which is in the latent
state space. Building on this representation, we introduce a
\textbf{Causality-Seeking Agent} whose objectives are to (1) identify the meta
states that trigger each subgraph, (2) discover the corresponding causal
relationships by agent curiosity-driven intervention policy, and (3)
iteratively refine the Meta-Causal Graph through ongoing curiosity-driven
exploration and agent experiences. Experiments on both synthetic tasks and a
challenging robot arm manipulation task demonstrate that our method robustly
captures shifts in causal dynamics and generalizes effectively to previously
unseen contexts.

</details>


### [506] [Transition Matching: Scalable and Flexible Generative Modeling](https://arxiv.org/abs/2506.23589)
*Neta Shaul,Uriel Singer,Itai Gat,Yaron Lipman*

Main category: cs.LG

Relevance: 70.0

TL;DR: 论文提出了一种新的生成范式Transition Matching (TM)，统一了扩散/流模型和连续自回归生成，通过分解任务为马尔可夫转移，实现了灵活的设计。三种TM变体（DTM、ARTM、FHTM）在图像质量和文本一致性上表现优异，FHTM首次在连续域中超越流方法。


<details>
  <summary>Details</summary>
Motivation: 探索扩散/流模型和连续自回归生成的统一框架，以突破现有生成模型的限制。

Method: 提出Transition Matching (TM)范式，分解任务为马尔可夫转移，设计三种变体（DTM、ARTM、FHTM）分别优化生成效果。

Result: TM变体在图像质量和文本一致性上达到SOTA，FHTM首次在连续域中超越流方法。

Conclusion: TM为生成模型提供了新的灵活设计路径，统一了多种生成方法。

Abstract: Diffusion and flow matching models have significantly advanced media
generation, yet their design space is well-explored, somewhat limiting further
improvements. Concurrently, autoregressive (AR) models, particularly those
generating continuous tokens, have emerged as a promising direction for
unifying text and media generation. This paper introduces Transition Matching
(TM), a novel discrete-time, continuous-state generative paradigm that unifies
and advances both diffusion/flow models and continuous AR generation. TM
decomposes complex generation tasks into simpler Markov transitions, allowing
for expressive non-deterministic probability transition kernels and arbitrary
non-continuous supervision processes, thereby unlocking new flexible design
avenues. We explore these choices through three TM variants: (i) Difference
Transition Matching (DTM), which generalizes flow matching to discrete-time by
directly learning transition probabilities, yielding state-of-the-art image
quality and text adherence as well as improved sampling efficiency. (ii)
Autoregressive Transition Matching (ARTM) and (iii) Full History Transition
Matching (FHTM) are partially and fully causal models, respectively, that
generalize continuous AR methods. They achieve continuous causal AR generation
quality comparable to non-causal approaches and potentially enable seamless
integration with existing AR text generation techniques. Notably, FHTM is the
first fully causal model to match or surpass the performance of flow-based
methods on text-to-image task in continuous domains. We demonstrate these
contributions through a rigorous large-scale comparison of TM variants and
relevant baselines, maintaining a fixed architecture, training data, and
hyperparameters.

</details>


### [507] [DABstep: Data Agent Benchmark for Multi-step Reasoning](https://arxiv.org/abs/2506.23719)
*Alex Egg,Martin Iglesias Goyanes,Friso Kingma,Andreu Mora,Leandro von Werra,Thomas Wolf*

Main category: cs.LG

Relevance: 70.0

TL;DR: DABstep是一个新的基准测试，用于评估AI代理在现实多步骤数据分析任务中的表现，包含450多个金融分析任务，测试数据操作和上下文推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估AI代理处理复杂、多步骤数据分析任务时存在不足，DABstep旨在填补这一空白。

Method: 设计了包含450多个金融分析任务的基准测试，要求模型结合代码处理和上下文推理，提供自动评分机制。

Result: 领先的LLM代理在最具挑战性的任务上仅达到14.55%的准确率，显示出显著性能差距。

Conclusion: DABstep为自主数据分析研究提供了标准化评估工具，公开了排行榜和工具包以促进研究。

Abstract: We introduce DABstep, a novel benchmark for evaluating AI agents on realistic
multi-step data analysis tasks. DABstep comprises over 450 real-world
challenges derived from a financial analytics platform, requiring models to
combine code-based data processing with contextual reasoning over heterogeneous
documentation. Each task demands an iterative, multi-step problem-solving
approach, testing capabilities in data manipulation, cross-referencing multiple
sources, and precise result reporting. The benchmark provides a factoid-style
answer format with automatic correctness checks for objective scoring at scale.
We evaluate leading LLM-based agents, revealing a substantial performance gap:
even the best agent achieves only 14.55% accuracy on the hardest tasks. We
detail our benchmark's design, dataset composition, task formulation,
evaluation protocol, report baseline results and analyze failure modes. DABstep
is released with a public leaderboard and toolkit to accelerate research in
autonomous data analysis.

</details>


### [508] [Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts](https://arxiv.org/abs/2506.23845)
*Kenny Peng,Rajiv Movva,Jon Kleinberg,Emma Pierson,Nikhil Garg*

Main category: cs.LG

Relevance: 70.0

TL;DR: 稀疏自编码器（SAEs）在已知概念上的应用效果有限，但在发现未知概念方面表现出强大潜力。


<details>
  <summary>Details</summary>
Motivation: 探讨SAEs的实际用途，澄清其在不同场景下的适用性，以解决现有研究中对其效果的争议。

Method: 提出概念区分框架，将SAEs的应用分为已知概念和未知概念两类，并分析其在不同领域的适用性。

Result: SAEs在发现未知概念方面具有优势，适用于ML可解释性、公平性、安全性以及社会科学和健康科学领域。

Conclusion: SAEs的价值在于发现未知概念，而非作用于已知概念，这为未来研究提供了明确方向。

Abstract: While sparse autoencoders (SAEs) have generated significant excitement, a
series of negative results have added to skepticism about their usefulness.
Here, we establish a conceptual distinction that reconciles competing
narratives surrounding SAEs. We argue that while SAEs may be less effective for
acting on known concepts, SAEs are powerful tools for discovering unknown
concepts. This distinction cleanly separates existing negative and positive
results, and suggests several classes of SAE applications. Specifically, we
outline use cases for SAEs in (i) ML interpretability, explainability,
fairness, auditing, and safety, and (ii) social and health sciences.

</details>


### [509] [LLM Agents Are the Antidote to Walled Gardens](https://arxiv.org/abs/2506.23978)
*Samuele Marro,Philip Torr*

Main category: cs.LG

Relevance: 70.0

TL;DR: LLM-based agents enable universal interoperability, disrupting closed platforms by making data exchange cheaper and unavoidable, though it introduces new risks.


<details>
  <summary>Details</summary>
Motivation: The dominance of closed, proprietary platforms limits data exchange and interoperability. LLM-based agents can disrupt this by enabling seamless data translation and interaction.

Method: Proposes the concept of universal interoperability through AI-mediated adapters, leveraging LLMs to translate between data formats and interfaces.

Result: Universal interoperability undermines monopolistic behaviors and promotes data portability, but also introduces security risks and technical debt.

Conclusion: The ML community should embrace universal interoperability while developing frameworks to mitigate risks, restoring user freedom and competitive markets.

Abstract: While the Internet's core infrastructure was designed to be open and
universal, today's application layer is dominated by closed, proprietary
platforms. Open and interoperable APIs require significant investment, and
market leaders have little incentive to enable data exchange that could erode
their user lock-in. We argue that LLM-based agents fundamentally disrupt this
status quo. Agents can automatically translate between data formats and
interact with interfaces designed for humans: this makes interoperability
dramatically cheaper and effectively unavoidable. We name this shift universal
interoperability: the ability for any two digital services to exchange data
seamlessly using AI-mediated adapters. Universal interoperability undermines
monopolistic behaviours and promotes data portability. However, it can also
lead to new security risks and technical debt. Our position is that the ML
community should embrace this development while building the appropriate
frameworks to mitigate the downsides. By acting now, we can harness AI to
restore user freedom and competitive markets without sacrificing security.

</details>


### [510] [Deep neural networks can provably solve Bellman equations for Markov decision processes without the curse of dimensionality](https://arxiv.org/abs/2506.22851)
*Arnulf Jentzen,Konrad Kleinberg,Thomas Kruse*

Main category: math.OC

Relevance: 70.0

TL;DR: 论文提出了一种使用深度神经网络（DNN）近似无限时间马尔可夫决策过程（MDP）中Q函数的方法，证明了在特定条件下，DNN可以以多项式复杂度实现L2意义上的近似。


<details>
  <summary>Details</summary>
Motivation: 解决MDP中Q函数的近似问题，尤其是在高维状态空间下，为强化学习理论提供更高效的数学工具。

Method: 利用带泄漏ReLU激活的DNN近似MDP的回报函数和转移动态，并通过多级固定点（MLFP）近似方案证明Q函数的DNN可近似性。

Result: 证明了在状态空间维度d和误差倒数1/ε的多项式复杂度下，DNN可以实现Q函数的L2近似。

Conclusion: DNN在特定条件下能够高效近似MDP中的Q函数，为强化学习算法的实现提供了理论支持。

Abstract: Discrete time stochastic optimal control problems and Markov decision
processes (MDPs) are fundamental models for sequential decision-making under
uncertainty and as such provide the mathematical framework underlying
reinforcement learning theory. A central tool for solving MDPs is the Bellman
equation and its solution, the so-called $Q$-function. In this article, we
construct deep neural network (DNN) approximations for $Q$-functions associated
to MDPs with infinite time horizon and finite control set $A$. More
specifically, we show that if the the payoff function and the random transition
dynamics of the MDP can be suitably approximated by DNNs with leaky rectified
linear unit (ReLU) activation, then the solutions $Q_d\colon \mathbb R^d\to
\mathbb R^{|A|}$, $d\in \mathbb{N}$, of the associated Bellman equations can
also be approximated in the $L^2$-sense by DNNs with leaky ReLU activation
whose numbers of parameters grow at most polynomially in both the dimension
$d\in \mathbb{N}$ of the state space and the reciprocal $1/\varepsilon$ of the
prescribed error $\varepsilon\in (0,1)$. Our proof relies on the recently
introduced full-history recursive multilevel fixed-point (MLFP) approximation
scheme.

</details>


### [511] [AICO: Feature Significance Tests for Supervised Learning](https://arxiv.org/abs/2506.23396)
*Kay Giesecke,Enguerrand Horel,Chartsiri Jirachotkulthorn*

Main category: stat.ML

Relevance: 70.0

TL;DR: 提出了一种模型无关的特征重要性检验方法，通过掩码特征值评估其对模型性能的增量贡献，无需重新训练或辅助模型。


<details>
  <summary>Details</summary>
Motivation: 解决监督学习算法的不透明性问题，促进科学发现和高风险领域的应用。

Method: 开发了一种模型和分布无关的显著性检验，通过掩码特征值并评估性能差异的分布，构造随机符号检验计算精确p值和置信区间。

Result: 实验验证了方法的统计和计算优势，并在实际数据中展示了实用性。

Conclusion: 该方法假设少、计算高效，适用于大规模高维数据，为特征重要性分析提供了可靠工具。

Abstract: The opacity of many supervised learning algorithms remains a key challenge,
hindering scientific discovery and limiting broader deployment -- particularly
in high-stakes domains. This paper develops model- and distribution-agnostic
significance tests to assess the influence of input features in any regression
or classification algorithm. Our method evaluates a feature's incremental
contribution to model performance by masking its values across samples. Under
the null hypothesis, the distribution of performance differences across a test
set has a non-positive median. We construct a uniformly most powerful,
randomized sign test for this median, yielding exact p-values for assessing
feature significance and confidence intervals with exact coverage for
estimating population-level feature importance. The approach requires minimal
assumptions, avoids model retraining or auxiliary models, and remains
computationally efficient even for large-scale, high-dimensional settings.
Experiments on synthetic tasks validate its statistical and computational
advantages, and applications to real-world data illustrate its practical
utility.

</details>


### [512] [Features-based embedding or Feature-grounding](https://arxiv.org/abs/2506.22442)
*Piotr Makarevich*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文探讨了如何通过基于特征的嵌入在深度学习中复现知识驱动的结构化思维，提出了一种构建特征接地嵌入的方法。


<details>
  <summary>Details</summary>
Motivation: 研究如何将人类基于知识的结构化思维（如对物体属性的预期）融入深度学习模型，以提升模型的解释性和领域适应性。

Method: 提出了一种构建特征接地嵌入的方法，旨在将可操作字典的共享表示与可解释的领域特定概念特征对齐。

Result: 未明确提及具体实验结果，但方法旨在提升模型的解释性和领域适应性。

Conclusion: 通过特征接地嵌入，可以更好地将知识驱动的结构化思维融入深度学习模型。

Abstract: In everyday reasoning, when we think about a particular object, we associate
it with a unique set of expected properties such as weight, size, or more
abstract attributes like density or horsepower. These expectations are shaped
by our prior knowledge and the conceptual categories we have formed through
experience. This paper investigates how such knowledge-based structured
thinking can be reproduced in deep learning models using features based
embeddings. Specially, it introduces an specific approach to build
feature-grounded embedding, aiming to align shareable representations of
operable dictionary with interpretable domain-specific conceptual features.

</details>


### [513] [Generalized Linear Mode Connectivity for Transformers](https://arxiv.org/abs/2506.22712)
*Alexander Theus,Alessandro Cabodi,Sotiris Anagnostidis,Antonio Orvieto,Sidak Pal Singh,Valentina Boeva*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种统一框架，捕捉神经网络参数空间的四种对称性类别，首次在独立训练的Vision Transformers和GPT-2模型间发现低或零损失路径。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络损失景观的几何结构对泛化和优化至关重要，但现有方法局限于神经元重排序，未能涵盖现代架构（如Transformers）的丰富对称性。

Method: 引入一个统一框架，涵盖四种对称性类别：排列、半排列、正交变换和一般可逆映射，扩展了有效重参数化的范围。

Result: 首次在独立训练的Vision Transformers和GPT-2模型间发现低或零损失的线性插值路径。

Conclusion: 揭示了损失景观的更深层次结构，强调了对称性分析对理解模型空间几何的重要性。

Abstract: Understanding the geometry of neural network loss landscapes is a central
question in deep learning, with implications for generalization and
optimization. A striking phenomenon is linear mode connectivity (LMC), where
independently trained models can be connected by low- or zero-loss paths,
despite appearing to lie in separate loss basins. However, this is often
obscured by symmetries in parameter space -- such as neuron permutations --
which make functionally equivalent models appear dissimilar. Prior work has
predominantly focused on neuron re-ordering through permutations, but such
approaches are limited in scope and fail to capture the richer symmetries
exhibited by modern architectures such as Transformers. In this work, we
introduce a unified framework that captures four symmetry classes:
permutations, semi-permutations, orthogonal transformations, and general
invertible maps -- broadening the set of valid reparameterizations and
subsuming many previous approaches as special cases. Crucially, this
generalization enables, for the first time, the discovery of low- and
zero-barrier linear interpolation paths between independently trained Vision
Transformers and GPT-2 models. These results reveal deeper structure in the
loss landscape and underscore the importance of symmetry-aware analysis for
understanding model space geometry.

</details>


### [514] [FF-INT8: Efficient Forward-Forward DNN Training on Edge Devices with INT8 Precision](https://arxiv.org/abs/2506.22771)
*Jingxiao Ma,Priyadarshini Panda,Sherief Reda*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种基于INT8量化的Forward-Forward（FF）训练方法，通过层间策略稳定梯度量化，并引入“look-ahead”方案提升模型精度。实验显示其在训练速度、能耗和内存占用上均有显著改进。


<details>
  <summary>Details</summary>
Motivation: 传统反向传播在资源受限的边缘设备上效率低下，而低精度量化在训练中的应用较少。FF算法通过避免存储中间激活值，更适合嵌入式设备。

Method: 结合INT8量化的FF训练方法，提出“look-ahead”方案优化模型精度。

Result: 在NVIDIA Jetson Orin Nano上实现4.6%训练加速、8.3%能耗降低和27.0%内存占用减少，同时保持竞争力精度。

Conclusion: INT8量化的FF训练方法在边缘设备上高效且实用。

Abstract: Backpropagation has been the cornerstone of neural network training for
decades, yet its inefficiencies in time and energy consumption limit its
suitability for resource-constrained edge devices. While low-precision neural
network quantization has been extensively researched to speed up model
inference, its application in training has been less explored. Recently, the
Forward-Forward (FF) algorithm has emerged as a promising alternative to
backpropagation, replacing the backward pass with an additional forward pass.
By avoiding the need to store intermediate activations for backpropagation, FF
can reduce memory footprint, making it well-suited for embedded devices. This
paper presents an INT8 quantized training approach that leverages FF's
layer-by-layer strategy to stabilize gradient quantization. Furthermore, we
propose a novel "look-ahead" scheme to address limitations of FF and improve
model accuracy. Experiments conducted on NVIDIA Jetson Orin Nano board
demonstrate 4.6% faster training, 8.3% energy savings, and 27.0% reduction in
memory usage, while maintaining competitive accuracy compared to the
state-of-the-art.

</details>


### [515] [P$^2$U: Progressive Precision Update For Efficient Model Distribution](https://arxiv.org/abs/2506.22871)
*Homayun Afrabandpey,Hamed Rezazadegan Tavakoli*

Main category: cs.LG

Relevance: 60.0

TL;DR: 提出了一种名为渐进精度更新（P²U）的方法，用于在带宽受限环境中高效分发模型。通过传输低精度模型及其与高精度模型的差异更新，P²U在准确率、带宽使用和延迟之间实现了更好的权衡。


<details>
  <summary>Details</summary>
Motivation: 解决带宽受限环境中模型分发的效率问题。

Method: 传输低精度模型及其与高精度模型的差异更新，支持激进量化（如4位）。

Result: 在多种模型架构和数据集上，P²U在准确率、带宽和延迟之间实现了更好的权衡。

Conclusion: P²U是一种高效且实用的模型分发解决方案，适用于低资源环境。

Abstract: Efficient model distribution is becoming increasingly critical in
bandwidth-constrained environments. In this paper, we propose a simple yet
effective approach called Progressive Precision Update (P$^2$U) to address this
problem. Instead of transmitting the original high-precision model, P$^2$U
transmits a lower-bit precision model, coupled with a model update representing
the difference between the original high-precision model and the transmitted
low precision version. With extensive experiments on various model
architectures, ranging from small models ($1 - 6$ million parameters) to a
large model (more than $100$ million parameters) and using three different data
sets, e.g., chest X-Ray, PASCAL-VOC, and CIFAR-100, we demonstrate that P$^2$U
consistently achieves better tradeoff between accuracy, bandwidth usage and
latency. Moreover, we show that when bandwidth or startup time is the priority,
aggressive quantization (e.g., 4-bit) can be used without severely compromising
performance. These results establish P$^2$U as an effective and practical
solution for scalable and efficient model distribution in low-resource
settings, including federated learning, edge computing, and IoT deployments.
Given that P$^2$U complements existing compression techniques and can be
implemented alongside any compression method, e.g., sparsification,
quantization, pruning, etc., the potential for improvement is even greater.

</details>


### [516] [ReMem: Mutual Information-Aware Fine-tuning of Pretrained Vision Transformers for Effective Knowledge Distillation](https://arxiv.org/abs/2506.23041)
*Chengyu Dong,Huan Gui,Noveen Sachdeva,Long Jin,Ke Yin,Jingbo Shang,Lichan Hong,Ed H. Chi,Zhe Zhao*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种针对视觉Transformer（ViT）的知识蒸馏方法，通过互信息感知优化和MLP块重加权，提升小规模或高度不平衡数据集上的知识转移效果。


<details>
  <summary>Details</summary>
Motivation: 大规模预训练的视觉表示模型在知识蒸馏时效果下降，尤其是对小规模或高度不平衡数据集。本文旨在解决这一问题。

Method: 采用互信息感知优化进行微调，并针对小规模数据集提出MLP块重加权的启发式方法。

Result: 该方法使小规模学生模型能够从最强预训练模型中受益。

Conclusion: 提出的方法有效提升了知识蒸馏的效果，尤其是在小规模或高度不平衡数据集上。

Abstract: Knowledge distillation from pretrained visual representation models offers an
effective approach to improve small, task-specific production models. However,
the effectiveness of such knowledge transfer drops significantly when
distilling from strong models that are pretrained in a large scale. In this
paper, we address this challenge for pretrained Vision Transformers (ViTs) by
exploring methods to fine-tune them for more effective knowledge transfer.
Motivated by the connection between mutual information and distillation
effectiveness, we propose to employ mutual information-aware optimization
during finetuning. For small or highly-imbalanced downstream datasets where
such optimization becomes less effective, we introduce a simple yet effective
heuristic of reweighting MLP blocks. This approach is inspired by our
observation that top MLP blocks are primarily responsible for mutual
information loss. Our method enables small student models to benefit from those
pretrained models among the strongest.

</details>


### [517] [Learning Modular Exponentiation with Transformers](https://arxiv.org/abs/2506.23679)
*David Demitri Africa,Sara M. Kapoor,Theo Simon Sorg*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文研究了Transformer模型在模幂运算中的机制可解释性，发现模型通过专用计算电路学习模运算。


<details>
  <summary>Details</summary>
Motivation: 模幂运算在数论和密码学中至关重要，但机制可解释性研究较少，本文旨在填补这一空白。

Method: 训练4层编码器-解码器Transformer模型，采用PCA嵌入分析和激活修补等方法研究数值推理的涌现。

Result: 模型通过互操作数训练实现性能提升，并在相关模数上表现出突然泛化，最终层注意力头子图足以完成常规幂运算。

Conclusion: Transformer模型通过专用计算电路学习模运算，为更高效和可解释的神经模幂运算方法铺平道路。

Abstract: Modular exponentiation is crucial to number theory and cryptography, yet
remains largely unexplored from a mechanistic interpretability standpoint. We
train a 4-layer encoder-decoder Transformer model to perform this operation and
investigate the emergence of numerical reasoning during training. Utilizing
principled sampling strategies, PCA-based embedding analysis, and activation
patching, we examine how number-theoretic properties are encoded within the
model. We find that reciprocal operand training leads to strong performance
gains, with sudden generalization across related moduli. These synchronized
accuracy surges reflect grokking-like dynamics, suggesting the model
internalizes shared arithmetic structure. We also find a subgraph consisting
entirely of attention heads in the final layer sufficient to achieve full
performance on the task of regular exponentiation. These results suggest that
transformer models learn modular arithmetic through specialized computational
circuits, paving the way for more interpretable and efficient neural approaches
to modular exponentiation.

</details>


### [518] [System-Embedded Diffusion Bridge Models](https://arxiv.org/abs/2506.23726)
*Bartlomiej Sobieski,Matthew Tivnan,Yuang Wang,Siyeop Yoon,Pengfei Jin,Dufan Wu,Quanzheng Li,Przemyslaw Biecek*

Main category: cs.LG

Relevance: 60.0

TL;DR: 提出了一种新的监督桥接方法SDBs，通过显式嵌入线性测量系统到矩阵值SDE中，改进了线性逆问题的解决效果。


<details>
  <summary>Details</summary>
Motivation: 解决逆问题（从噪声或不完整测量中恢复信号）是科学和工程中的基础任务，现有方法或忽略测量模型结构信息，或假设其已知。

Method: 引入System embedded Diffusion Bridge Models (SDBs)，将已知线性测量系统嵌入矩阵值SDE的系数中。

Result: 在多种线性逆问题中表现一致改进，且在系统误设情况下仍能稳健泛化。

Conclusion: SDBs为实际应用提供了有前景的解决方案。

Abstract: Solving inverse problems -- recovering signals from incomplete or noisy
measurements -- is fundamental in science and engineering. Score-based
generative models (SGMs) have recently emerged as a powerful framework for this
task. Two main paradigms have formed: unsupervised approaches that adapt
pretrained generative models to inverse problems, and supervised bridge methods
that train stochastic processes conditioned on paired clean and corrupted data.
While the former typically assume knowledge of the measurement model, the
latter have largely overlooked this structural information. We introduce System
embedded Diffusion Bridge Models (SDBs), a new class of supervised bridge
methods that explicitly embed the known linear measurement system into the
coefficients of a matrix-valued SDE. This principled integration yields
consistent improvements across diverse linear inverse problems and demonstrates
robust generalization under system misspecification between training and
deployment, offering a promising solution to real-world applications.

</details>


### [519] [Radioactive Watermarks in Diffusion and Autoregressive Image Generative Models](https://arxiv.org/abs/2506.23731)
*Michel Meintz,Jan Dubiński,Franziska Boenisch,Adam Dziedzic*

Main category: cs.LG

Relevance: 60.0

TL;DR: 论文提出了一种针对图像自回归模型（IARs）的放射性水印方法，解决了现有扩散模型（DMs）水印在训练中失效的问题。


<details>
  <summary>Details</summary>
Motivation: 生成模型的训练数据成本高，部分人可能利用生成图像作为训练数据，而现有水印方法在训练过程中失效，无法追踪来源。

Method: 借鉴大型语言模型（LLMs）的自回归范式，设计了一种针对IARs的水印方法，确保水印在训练中保持放射性。

Result: 实验证明该方法在IARs中有效保留了水印的放射性，实现了鲁棒的来源追踪。

Conclusion: 该方法填补了IARs水印技术的空白，为生成图像的版权保护提供了新思路。

Abstract: Image generative models have become increasingly popular, but training them
requires large datasets that are costly to collect and curate. To circumvent
these costs, some parties may exploit existing models by using the generated
images as training data for their own models. In general, watermarking is a
valuable tool for detecting unauthorized use of generated images. However, when
these images are used to train a new model, watermarking can only enable
detection if the watermark persists through training and remains identifiable
in the outputs of the newly trained model - a property known as radioactivity.
We analyze the radioactivity of watermarks in images generated by diffusion
models (DMs) and image autoregressive models (IARs). We find that existing
watermarking methods for DMs fail to retain radioactivity, as watermarks are
either erased during encoding into the latent space or lost in the
noising-denoising process (during the training in the latent space). Meanwhile,
despite IARs having recently surpassed DMs in image generation quality and
efficiency, no radioactive watermarking methods have been proposed for them. To
overcome this limitation, we propose the first watermarking method tailored for
IARs and with radioactivity in mind - drawing inspiration from techniques in
large language models (LLMs), which share IARs' autoregressive paradigm. Our
extensive experimental evaluation highlights our method's effectiveness in
preserving radioactivity within IARs, enabling robust provenance tracking, and
preventing unauthorized use of their generated images.

</details>


### [520] [A Scalable Approach for Safe and Robust Learning via Lipschitz-Constrained Networks](https://arxiv.org/abs/2506.23977)
*Zain ul Abdeen,Vassilis Kekatos,Ming Jin*

Main category: cs.LG

Relevance: 60.0

TL;DR: 提出了一种基于凸优化的全局Lipschitz约束训练框架，通过半定松弛和随机子空间方法提升可扩展性和效率。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用中，神经网络的认证鲁棒性至关重要，但现有方法因非凸性和全局半定规划（SDP）的可扩展性问题而受限。

Method: 采用环路变换重新参数化网络，提出凸可容许条件，并通过随机子空间线性矩阵不等式（RS-LMI）分解全局约束为层间约束。

Result: 在MNIST、CIFAR-10和ImageNet上实现了竞争性精度，显著提升了Lipschitz边界和运行时性能。

Conclusion: 该框架为认证鲁棒性提供了一种高效且可扩展的解决方案。

Abstract: Certified robustness is a critical property for deploying neural networks
(NN) in safety-critical applications. A principle approach to achieving such
guarantees is to constrain the global Lipschitz constant of the network.
However, accurate methods for Lipschitz-constrained training often suffer from
non-convex formulations and poor scalability due to reliance on global
semidefinite programs (SDPs). In this letter, we propose a convex training
framework that enforces global Lipschitz constraints via semidefinite
relaxation. By reparameterizing the NN using loop transformation, we derive a
convex admissibility condition that enables tractable and certifiable training.
While the resulting formulation guarantees robustness, its scalability is
limited by the size of global SDP. To overcome this, we develop a randomized
subspace linear matrix inequalities (RS-LMI) approach that decomposes the
global constraints into sketched layerwise constraints projected onto
low-dimensional subspaces, yielding a smooth and memory-efficient training
objective. Empirical results on MNIST, CIFAR-10, and ImageNet demonstrate that
the proposed framework achieves competitive accuracy with significantly
improved Lipschitz bounds and runtime performance.

</details>


### [521] [Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives](https://arxiv.org/abs/2506.24124)
*Dong Sixun,Fan Wei,Teresa Wu,Fu Yanjie*

Main category: cs.LG

Relevance: 60.0

TL;DR: 提出了一种多模态对比学习框架，将时间序列转化为视觉和文本表示，并通过对比学习对齐，提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法局限于单模态数值输入，难以捕捉高级语义模式。本文旨在通过多模态表示（视觉和文本）提升预测效果。

Method: 构建视觉和文本表示，通过对比学习对齐模态，并引入变量选择模块识别关键变量。

Result: 在多个基准测试中表现优于单模态和跨模态基线。

Conclusion: 多模态对齐能显著提升时间序列预测效果。

Abstract: Time series forecasting traditionally relies on unimodal numerical inputs,
which often struggle to capture high-level semantic patterns due to their dense
and unstructured nature. While recent approaches have explored representing
time series as text using large language models (LLMs), these methods remain
limited by the discrete nature of token sequences and lack the perceptual
intuition humans typically apply, such as interpreting visual patterns. In this
paper, we propose a multimodal contrastive learning framework that transforms
raw time series into structured visual and textual perspectives. Rather than
using natural language or real-world images, we construct both modalities
directly from numerical sequences. We then align these views in a shared
semantic space via contrastive learning, enabling the model to capture richer
and more complementary representations. Furthermore, we introduce a variate
selection module that leverages the aligned representations to identify the
most informative variables for multivariate forecasting. Extensive experiments
on fifteen short-term and six long-term forecasting benchmarks demonstrate that
our approach consistently outperforms strong unimodal and cross-modal
baselines, highlighting the effectiveness of multimodal alignment in enhancing
time series forecasting. Code is available at:
https://github.com/Ironieser/TimesCLIP.

</details>


### [522] [Learning to Rank with Variable Result Presentation Lengths](https://arxiv.org/abs/2506.23319)
*Norman Knyazev,Harrie Oosterhuis*

Main category: cs.IR

Relevance: 60.0

TL;DR: 论文提出了一种可变展示长度排序任务（VLPL），解决了传统LTR方法中固定展示格式的局限性，通过联合优化文档排序和展示长度，提升了排名性能。


<details>
  <summary>Details</summary>
Motivation: 传统LTR方法假设文档以相同格式展示，但用户对相关性的感知受展示方式影响。本文填补了可变展示长度排序任务的空白。

Method: 提出VLPL方法，基于Plackett-Luce模型，联合优化文档排序和展示长度，通过半合成实验验证其有效性。

Result: VLPL能有效平衡文档的曝光和吸引力，在不同排序设置中表现最佳，且简单长度感知方法也能显著优于固定长度模型。

Conclusion: 可变展示长度排序任务具有重要性和挑战性，VLPL为结合文档展示与LTR提供了有效解决方案。

Abstract: Learning to Rank (LTR) methods generally assume that each document in a top-K
ranking is presented in an equal format. However, previous work has shown that
users' perceptions of relevance can be changed by varying presentations, i.e.,
allocating more vertical space to some documents to provide additional textual
or image information. Furthermore, presentation length can also redirect
attention, as users are more likely to notice longer presentations when
scrolling through results. Deciding on the document presentation lengths in a
fixed vertical space ranking is an important problem that has not been
addressed by existing LTR methods.
  We address this gap by introducing the variable presentation length ranking
task, where simultaneously the ordering of documents and their presentation
length is decided. Despite being a generalization of standard ranking, we show
that this setting brings significant new challenges: Firstly, the probability
ranking principle no longer applies to this setting, and secondly, the problem
cannot be divided into separate ordering and length selection tasks.
  We therefore propose VLPL - a new family of Plackett-Luce list-wise gradient
estimation methods for the joint optimization of document ordering and lengths.
Our semi-synthetic experiments show that VLPL can effectively balance the
expected exposure and attractiveness of all documents, achieving the best
performance across different ranking settings. Furthermore, we observe that
even simple length-aware methods can achieve significant performance
improvements over fixed-length models. Altogether, our theoretical and
empirical results highlight the importance and difficulties of combining
document presentation with LTR.

</details>


### [523] [Mitigating Semantic Collapse in Generative Personalization with a Surprisingly Simple Test-Time Embedding Adjustment](https://arxiv.org/abs/2506.22685)
*Anh Bui,Trang Vu,Trung Le,Junae Kim,Tamas Abraham,Rollin Omari,Amar Kaur,Dinh Phung*

Main category: cs.LG

Relevance: 50.0

TL;DR: 论文研究了生成式个性化中的语义坍塌问题，提出了一种无需训练的推理时嵌入调整方法，显著改善了文本-图像对齐。


<details>
  <summary>Details</summary>
Motivation: 生成式个性化中，学习到的视觉概念逐渐偏离原始文本含义，导致语义丰富性降低和输出图像简化。

Method: 提出了一种无需训练的方法，在推理时调整预训练嵌入的大小和方向。

Result: 该方法在多种个性化方法中广泛适用，显著提升了文本-图像对齐效果。

Conclusion: 通过调整嵌入方向和大小的简单方法，有效缓解了语义坍塌问题。

Abstract: In this paper, we investigate the semantic collapsing problem in generative
personalization, an under-explored topic where the learned visual concept
($V^*$) gradually shifts from its original textual meaning and comes to
dominate other concepts in multi-concept input prompts. This issue not only
reduces the semantic richness of complex input prompts like "a photo of $V^*$
wearing glasses and playing guitar" into simpler, less contextually rich forms
such as "a photo of $V^*$" but also leads to simplified output images that fail
to capture the intended concept.
  We identify the root cause as unconstrained optimisation, which allows the
learned embedding $V^*$ to drift arbitrarily in the embedding space, both in
direction and magnitude. To address this, we propose a simple yet effective
training-free method that adjusts the magnitude and direction of pre-trained
embedding at inference time, effectively mitigating the semantic collapsing
problem. Our method is broadly applicable across different personalization
methods and demonstrates significant improvements in text-image alignment in
diverse use cases. Our code is anonymously published at
https://anonymous.4open.science/r/Embedding-Adjustment.

</details>


### [524] [Learning Interpretable Rules from Neural Networks: Neurosymbolic AI for Radar Hand Gesture Recognition](https://arxiv.org/abs/2506.22443)
*Sarah Seifi,Tobias Sukianto,Cecilia Carbonelli,Lorenzo Servadei,Robert Wille*

Main category: cs.LG

Relevance: 40.0

TL;DR: RL-Net是一种神经符号规则学习网络，首次应用于雷达手势识别，在性能与可解释性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 结合规则模型的解释性和神经网络的性能，解决复杂数据问题。

Method: 通过神经优化学习可解释的规则列表，并与透明规则系统（MIRA）和可解释黑盒模型（XentricAI）进行对比。

Result: RL-Net在保持高性能（93.03% F1）的同时显著降低规则复杂性。

Conclusion: RL-Net在透明性和性能之间提供了实用折衷方案，展示了神经符号模型在可解释AI中的潜力。

Abstract: Rule-based models offer interpretability but struggle with complex data,
while deep neural networks excel in performance yet lack transparency. This
work investigates a neuro-symbolic rule learning neural network named RL-Net
that learns interpretable rule lists through neural optimization, applied for
the first time to radar-based hand gesture recognition (HGR). We benchmark
RL-Net against a fully transparent rule-based system (MIRA) and an explainable
black-box model (XentricAI), evaluating accuracy, interpretability, and user
adaptability via transfer learning. Our results show that RL-Net achieves a
favorable trade-off, maintaining strong performance (93.03% F1) while
significantly reducing rule complexity. We identify optimization challenges
specific to rule pruning and hierarchy bias and propose stability-enhancing
modifications. Compared to MIRA and XentricAI, RL-Net emerges as a practical
middle ground between transparency and performance. This study highlights the
real-world feasibility of neuro-symbolic models for interpretable HGR and
offers insights for extending explainable AI to edge-deployable sensing
systems.

</details>


### [525] [EAGLE: Efficient Alignment of Generalized Latent Embeddings for Multimodal Survival Prediction with Interpretable Attribution Analysis](https://arxiv.org/abs/2506.22446)
*Aakash Tripathi,Asim Waqas,Matthew B. Schabath,Yasin Yilmaz,Ghulam Rasool*

Main category: cs.LG

Relevance: 40.0

TL;DR: EAGLE框架通过动态跨模态注意力机制、维度缩减、多属性分析和统一管道，解决了多模态癌症生存预测中的融合、计算和可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态癌症生存预测中存在融合策略简单、计算需求大和缺乏可解释性的问题，限制了临床应用。

Method: EAGLE采用动态跨模态注意力机制、维度缩减技术、三种互补属性分析方法和统一管道设计。

Result: 在三种癌症类型（GBM、IPMN、NSCLC）上验证，EAGLE实现了高预测性能，并识别出高风险和低风险患者的模态依赖差异。

Conclusion: EAGLE结合高性能和临床可解释性，为多模态生存预测提供了可扩展的解决方案。

Abstract: Accurate cancer survival prediction requires integration of diverse data
modalities that reflect the complex interplay between imaging, clinical
parameters, and textual reports. However, existing multimodal approaches suffer
from simplistic fusion strategies, massive computational requirements, and lack
of interpretability-critical barriers to clinical adoption. We present EAGLE
(Efficient Alignment of Generalized Latent Embeddings), a novel deep learning
framework that addresses these limitations through attention-based multimodal
fusion with comprehensive attribution analysis. EAGLE introduces four key
innovations: (1) dynamic cross-modal attention mechanisms that learn
hierarchical relationships between modalities, (2) massive dimensionality
reduction (99.96%) while maintaining predictive performance, (3) three
complementary attribution methods providing patient-level interpretability, and
(4) a unified pipeline enabling seamless adaptation across cancer types. We
evaluated EAGLE on 911 patients across three distinct malignancies:
glioblastoma (GBM, n=160), intraductal papillary mucinous neoplasms (IPMN,
n=171), and non-small cell lung cancer (NSCLC, n=580). Patient-level analysis
showed high-risk individuals relied more heavily on adverse imaging features,
while low-risk patients demonstrated balanced modality contributions. Risk
stratification identified clinically meaningful groups with 4-fold (GBM) to
5-fold (NSCLC) differences in median survival, directly informing treatment
intensity decisions. By combining state-of-the-art performance with clinical
interpretability, EAGLE bridges the gap between advanced AI capabilities and
practical healthcare deployment, offering a scalable solution for multimodal
survival prediction that enhances both prognostic accuracy and physician trust
in automated predictions.

</details>


### [526] [Task-Agnostic Contrastive Pretraining for Relational Deep Learning](https://arxiv.org/abs/2506.22530)
*Jakub Peleška,Gustav Šír*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种任务无关的对比预训练方法，用于关系深度学习（RDL），通过三种对比目标学习数据库范围的表示。


<details>
  <summary>Details</summary>
Motivation: 现有RDL模型依赖任务特定的监督学习，限制了可扩展性和重用性。

Method: 引入三种对比目标（行级、链接级、上下文级），设计模块化RDL架构和高效采样策略。

Result: 预训练模型微调后性能优于从头训练，验证了方法的有效性。

Conclusion: 该方法为关系数据学习可迁移表示提供了新思路。

Abstract: Relational Deep Learning (RDL) is an emerging paradigm that leverages Graph
Neural Network principles to learn directly from relational databases by
representing them as heterogeneous graphs. However, existing RDL models
typically rely on task-specific supervised learning, requiring training
separate models for each predictive task, which may hamper scalability and
reuse.
  In this work, we propose a novel task-agnostic contrastive pretraining
approach for RDL that enables database-wide representation learning. For that
aim, we introduce three levels of contrastive objectives$-$row-level,
link-level, and context-level$-$designed to capture the structural and semantic
heterogeneity inherent to relational data. We implement the respective
pretraining approach through a modular RDL architecture and an efficient
sampling strategy tailored to the heterogeneous database setting. Our
preliminary results on standard RDL benchmarks demonstrate that fine-tuning the
pretrained models measurably outperforms training from scratch, validating the
promise of the proposed methodology in learning transferable representations
for relational data.

</details>


### [527] [DistShap: Scalable GNN Explanations with Distributed Shapley Values](https://arxiv.org/abs/2506.22668)
*Selahattin Akkas,Aditya Devarakonda,Ariful Azad*

Main category: cs.LG

Relevance: 40.0

TL;DR: DistShap是一种并行算法，用于在多个GPU上分布式计算基于Shapley值的GNN解释，显著提升了计算效率和规模。


<details>
  <summary>Details</summary>
Motivation: 随着图神经网络（GNNs）的广泛应用，解释其预测变得日益重要，但现有方法计算成本高，难以扩展到大规模特征。

Method: DistShap通过在分布式环境中采样子图、并行执行GNN推理，并解决分布式最小二乘问题来计算边重要性分数。

Result: DistShap在准确性上优于大多数现有GNN解释方法，并首次支持具有数百万特征的GNN模型，最高使用128个GPU。

Conclusion: DistShap为大规模GNN解释提供了高效、可扩展的解决方案。

Abstract: With the growing adoption of graph neural networks (GNNs), explaining their
predictions has become increasingly important. However, attributing predictions
to specific edges or features remains computationally expensive. For example,
classifying a node with 100 neighbors using a 3-layer GNN may involve
identifying important edges from millions of candidates contributing to the
prediction. To address this challenge, we propose DistShap, a parallel
algorithm that distributes Shapley value-based explanations across multiple
GPUs. DistShap operates by sampling subgraphs in a distributed setting,
executing GNN inference in parallel across GPUs, and solving a distributed
least squares problem to compute edge importance scores. DistShap outperforms
most existing GNN explanation methods in accuracy and is the first to scale to
GNN models with millions of features by using up to 128 GPUs on the NERSC
Perlmutter supercomputer.

</details>


### [528] [Multimodal Atmospheric Super-Resolution With Deep Generative Models](https://arxiv.org/abs/2506.22780)
*Dibyajyoti Chakraborty,Haiwen Guan,Jason Stock,Troy Arcomano,Guido Cervone,Romit Maulik*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种基于分数的扩散模型，用于从复杂分布中采样，并展示了其在实时多模态数据超分辨率任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 探索分数扩散模型在数据融合和实时超分辨率任务中的潜力，特别是在高维动态系统中。

Method: 利用分数扩散模型学习数据的对数概率密度梯度，并通过逆噪声过程生成样本，同时支持零样本条件生成。

Result: 实验表明，模型能够准确恢复高维状态，并平衡多模态数据的影响。

Conclusion: 分数扩散模型为数据融合和实时超分辨率提供了一种有效的新范式。

Abstract: Score-based diffusion modeling is a generative machine learning algorithm
that can be used to sample from complex distributions. They achieve this by
learning a score function, i.e., the gradient of the log-probability density of
the data, and reversing a noising process using the same. Once trained,
score-based diffusion models not only generate new samples but also enable
zero-shot conditioning of the generated samples on observed data. This promises
a novel paradigm for data and model fusion, wherein the implicitly learned
distributions of pretrained score-based diffusion models can be updated given
the availability of online data in a Bayesian formulation. In this article, we
apply such a concept to the super-resolution of a high-dimensional dynamical
system, given the real-time availability of low-resolution and experimentally
observed sparse sensor measurements from multimodal data. Additional analysis
on how score-based sampling can be used for uncertainty estimates is also
provided. Our experiments are performed for a super-resolution task that
generates the ERA5 atmospheric dataset given sparse observations from a
coarse-grained representation of the same and/or from unstructured experimental
observations of the IGRA radiosonde dataset. We demonstrate accurate recovery
of the high dimensional state given multiple sources of low-fidelity
measurements. We also discover that the generative model can balance the
influence of multiple dataset modalities during spatiotemporal reconstructions.

</details>


### [529] [Missing-Modality-Aware Graph Neural Network for Cancer Classification](https://arxiv.org/abs/2506.22901)
*Sina Tabakhi,Haiping Lu*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出MAGNET模型，通过多模态注意力机制和图神经网络处理生物数据中的缺失模态问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多模态生物数据中缺失模态的挑战，现有方法难以应对多样化的缺失模式和模态数量增加带来的复杂性。

Method: 引入患者-模态多头注意力机制，融合低维模态嵌入，构建患者图并使用图神经网络进行预测。

Result: 在三个公共多组学数据集上，MAGNET在癌症分类任务中优于现有融合方法。

Conclusion: MAGNET能线性适应模态数量增加，有效处理缺失模式多样性，性能优越。

Abstract: A key challenge in learning from multimodal biological data is missing
modalities, where all data from some modalities are missing for some patients.
Current fusion methods address this by excluding patients with missing
modalities, imputing missing modalities, or making predictions directly with
partial modalities. However, they often struggle with diverse missing-modality
patterns and the exponential growth of the number of such patterns as the
number of modalities increases. To address these limitations, we propose MAGNET
(Missing-modality-Aware Graph neural NETwork) for direct prediction with
partial modalities, which introduces a patient-modality multi-head attention
mechanism to fuse lower-dimensional modality embeddings based on their
importance and missingness. MAGNET's complexity increases linearly with the
number of modalities while adapting to missing-pattern variability. To generate
predictions, MAGNET further constructs a patient graph with fused multimodal
embeddings as node features and the connectivity determined by the modality
missingness, followed by a conventional graph neural network. Experiments on
three public multiomics datasets for cancer classification, with real-world
instead of artificial missingness, show that MAGNET outperforms the
state-of-the-art fusion methods. The data and code are available at
https://github.com/SinaTabakhi/MAGNET.

</details>


### [530] [Towards Time Series Generation Conditioned on Unstructured Natural Language](https://arxiv.org/abs/2506.22927)
*Jaeyun Woo,Jiseok Lee,Brian Kenji Iwana*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于扩散模型和语言模型的方法，用于从自然语言描述生成时间序列数据，并构建了一个新的公共数据集。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI在图像和文本领域取得了显著进展，但时间序列生成仍相对落后，而时间序列在金融、气候等领域有重要应用。

Method: 结合扩散模型和语言模型，从自然语言描述生成时间序列。

Result: 证明了基于自然语言的时间序列生成是可行的，并展示了其在定制预测、数据增强等方面的应用潜力。

Conclusion: 该方法为时间序列生成提供了新思路，并公开了一个包含63,010对时间序列-描述的数据集。

Abstract: Generative Artificial Intelligence (AI) has rapidly become a powerful tool,
capable of generating various types of data, such as images and text. However,
despite the significant advancement of generative AI, time series generative AI
remains underdeveloped, even though the application of time series is essential
in finance, climate, and numerous fields. In this research, we propose a novel
method of generating time series conditioned on unstructured natural language
descriptions. We use a diffusion model combined with a language model to
generate time series from the text. Through the proposed method, we demonstrate
that time series generation based on natural language is possible. The proposed
method can provide various applications such as custom forecasting, time series
manipulation, data augmentation, and transfer learning. Furthermore, we
construct and propose a new public dataset for time series generation,
consisting of 63,010 time series-description pairs.

</details>


### [531] [Mathematical Computation on High-dimensional Data via Array Programming and Parallel Acceleration](https://arxiv.org/abs/2506.22929)
*Chen Zhang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于空间完备性的并行计算架构，用于处理高维数据，支持科学计算。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在高维数据应用中的计算挑战，弥补当前工具在数学统计支持上的不足。

Method: 通过空间完备性分解高维数据为维度独立结构，实现分布式处理。

Result: 框架支持数据挖掘和并行优化的机器学习方法，适用于多种数据类型。

Conclusion: 该架构为高维数据的科学计算提供了统一且高效的解决方案。

Abstract: While deep learning excels in natural image and language processing, its
application to high-dimensional data faces computational challenges due to the
dimensionality curse. Current large-scale data tools focus on business-oriented
descriptive statistics, lacking mathematical statistics support for advanced
analysis. We propose a parallel computation architecture based on space
completeness, decomposing high-dimensional data into dimension-independent
structures for distributed processing. This framework enables seamless
integration of data mining and parallel-optimized machine learning methods,
supporting scientific computations across diverse data types like medical and
natural images within a unified system.

</details>


### [532] [Forget-MI: Machine Unlearning for Forgetting Multimodal Information in Healthcare Settings](https://arxiv.org/abs/2506.23145)
*Shahad Hardan,Darya Taratynova,Abdelmajid Essofi,Karthik Nandakumar,Mohammad Yaqub*

Main category: cs.LG

Relevance: 40.0

TL;DR: Forget-MI是一种新颖的多模态医疗数据机器遗忘方法，通过损失函数和扰动技术，在保持模型性能的同时有效遗忘指定数据。


<details>
  <summary>Details</summary>
Motivation: 在医疗领域，多模态模型依赖敏感患者数据，现有方法难以有效遗忘这些数据，隐私保护需求迫切。

Method: 提出Forget-MI方法，通过设计损失函数和扰动技术，遗忘单模态和联合表示，同时保留剩余数据知识。

Result: Forget-MI在遗忘数据集上表现优异，减少MIA攻击能力0.202，AUC和F1分数分别降低0.221和0.305，测试集性能与原模型相当。

Conclusion: Forget-MI在隐私保护和模型性能间取得平衡，为医疗数据遗忘提供了有效解决方案。

Abstract: Privacy preservation in AI is crucial, especially in healthcare, where models
rely on sensitive patient data. In the emerging field of machine unlearning,
existing methodologies struggle to remove patient data from trained multimodal
architectures, which are widely used in healthcare. We propose Forget-MI, a
novel machine unlearning method for multimodal medical data, by establishing
loss functions and perturbation techniques. Our approach unlearns unimodal and
joint representations of the data requested to be forgotten while preserving
knowledge from the remaining data and maintaining comparable performance to the
original model. We evaluate our results using performance on the forget
dataset, performance on the test dataset, and Membership Inference Attack
(MIA), which measures the attacker's ability to distinguish the forget dataset
from the training dataset. Our model outperforms the existing approaches that
aim to reduce MIA and the performance on the forget dataset while keeping an
equivalent performance on the test set. Specifically, our approach reduces MIA
by 0.202 and decreases AUC and F1 scores on the forget set by 0.221 and 0.305,
respectively. Additionally, our performance on the test set matches that of the
retrained model, while allowing forgetting. Code is available at
https://github.com/BioMedIA-MBZUAI/Forget-MI.git

</details>


### [533] [Data Can Speak for Itself: Quality-guided Utilization of Wireless Synthetic Data](https://arxiv.org/abs/2506.23174)
*Chen Gong,Bo Liang,Wei Gao,Chenren Xu*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了SynCheck，一种量化合成数据质量（亲和性与多样性）并优化其使用的方案，显著提升了无线传感任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前无线传感任务中合成数据的质量不可预测且性能提升无保障，需量化其质量并优化使用。

Method: 提出亲和性与多样性指标量化合成数据质量，设计SynCheck方案在训练中优化数据质量。

Result: SynCheck比忽略质量的合成数据使用方案性能提升4.3%，而后者可能降低13.4%性能。

Conclusion: 量化合成数据质量并优化使用可显著提升任务性能，SynCheck是有效解决方案。

Abstract: Generative models have gained significant attention for their ability to
produce realistic synthetic data that supplements the quantity of real-world
datasets. While recent studies show performance improvements in wireless
sensing tasks by incorporating all synthetic data into training sets, the
quality of synthetic data remains unpredictable and the resulting performance
gains are not guaranteed. To address this gap, we propose tractable and
generalizable metrics to quantify quality attributes of synthetic data -
affinity and diversity. Our assessment reveals prevalent affinity limitation in
current wireless synthetic data, leading to mislabeled data and degraded task
performance. We attribute the quality limitation to generative models' lack of
awareness of untrained conditions and domain-specific processing. To mitigate
these issues, we introduce SynCheck, a quality-guided synthetic data
utilization scheme that refines synthetic data quality during task model
training. Our evaluation demonstrates that SynCheck consistently outperforms
quality-oblivious utilization of synthetic data, and achieves 4.3% performance
improvement even when the previous utilization degrades performance by 13.4%.

</details>


### [534] [Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data](https://arxiv.org/abs/2506.23182)
*Robert Frank,Michael Widrich,Rahmad Akbar,Günter Klambauer,Geir Kjetil Sandve,Philippe A. Robert,Victor Greiff*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种名为GAMA的生成模型归因方法，用于解释自回归生成模型的输出，特别是在生物序列设计中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决生成模型在生物序列设计中缺乏可解释性的问题，尤其是在缺乏负样本数据的情况下。

Method: 基于Integrated Gradients开发了GAMA方法，并通过合成数据集和实验数据验证其有效性。

Result: GAMA能够恢复生物相关特征，并在抗体-抗原结合数据中展示了实用性。

Conclusion: GAMA为生成模型提供了可解释性，支持无需负样本数据的序列设计验证。

Abstract: Generative machine learning models offer a powerful framework for therapeutic
design by efficiently exploring large spaces of biological sequences enriched
for desirable properties. Unlike supervised learning methods, which require
both positive and negative labeled data, generative models such as LSTMs can be
trained solely on positively labeled sequences, for example, high-affinity
antibodies. This is particularly advantageous in biological settings where
negative data are scarce, unreliable, or biologically ill-defined. However, the
lack of attribution methods for generative models has hindered the ability to
extract interpretable biological insights from such models. To address this
gap, we developed Generative Attribution Metric Analysis (GAMA), an attribution
method for autoregressive generative models based on Integrated Gradients. We
assessed GAMA using synthetic datasets with known ground truths to characterize
its statistical behavior and validate its ability to recover biologically
relevant features. We further demonstrated the utility of GAMA by applying it
to experimental antibody-antigen binding data. GAMA enables model
interpretability and the validation of generative sequence design strategies
without the need for negative training data.

</details>


### [535] [FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model](https://arxiv.org/abs/2506.23210)
*Taehwan Yoon,Bongjun Choi*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于参考模型的联邦学习方法，通过贝叶斯参数高效迁移学习优化模型性能，同时解决灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在保护用户隐私的同时，模型性能可能无法满足多样化需求，需通过优化和个性化提升。

Method: 采用贝叶斯参数高效迁移学习，引入最优近端项和参考模型，避免灾难性遗忘。

Result: 方法实现了高模型性能和低计算成本。

Conclusion: 该方法在联邦学习中有效平衡了性能与隐私需求。

Abstract: Federated learning(FL) is used for distributed scenarios to train artificial
intelligence(AI) models while ensuring users' privacy. In federated learning
scenario, the server generally never knows about users' data. This type of
concept makes the AI training process efficient in terms of data privacy.
However, regarding model performance, federated AI models may not sufficiently
satisfy AI users' expectations. Furthermore, AI users have a wide range of
different needs. It is not easy to satisfy the whole users needs. These types
of issues can be addressed through AI model optimization, fine-tuning, or
personalization to achieve optimal model performance. To address model
optimization challenges, we propose reference model-based federated learning
for optimal fine-tuning, which overcomes catastrophic forgetting in each round.
This method is derived from Bayesian parameter-efficient transfer learning,
which includes an optimal proximal term and enables overcoming the catastrophic
forgetting issue in each round by utilizing a reference model that incorporates
previous model parameters. As a result, this method achieves both high model
performance and low computing cost.

</details>


### [536] [Single Image Inpainting and Super-Resolution with Simultaneous Uncertainty Guarantees by Universal Reproducing Kernels](https://arxiv.org/abs/2506.23221)
*Bálint Horváth,Balázs Csanád Csáji*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种基于统计学习的方法SGKI，用于图像修复和超分辨率问题中的缺失像素估计，并提供不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 解决图像修复和超分辨率中缺失像素估计的问题，并量化不确定性，以增强方法的可靠性。

Method: 基于Reproducing Kernel Hilbert Space (RKHS)假设，提出SGKI方法，利用Schur补高效计算非渐近置信带。

Result: SGKI不仅能估计缺失像素，还能为所有缺失像素构建同时保证的置信带，实验验证了其有效性。

Conclusion: SGKI是一种高效且可靠的图像修复方法，特别适用于需要不确定性量化的场景。

Abstract: The paper proposes a statistical learning approach to the problem of
estimating missing pixels of images, crucial for image inpainting and
super-resolution problems. One of the main novelties of the method is that it
also provides uncertainty quantifications together with the estimated values.
Our core assumption is that the underlying data-generating function comes from
a Reproducing Kernel Hilbert Space (RKHS). A special emphasis is put on
band-limited functions, central to signal processing, which form Paley-Wiener
type RKHSs. The proposed method, which we call Simultaneously Guaranteed Kernel
Interpolation (SGKI), is an extension and refinement of a recently developed
kernel method. An advantage of SGKI is that it not only estimates the missing
pixels, but also builds non-asymptotic confidence bands for the unobserved
values, which are simultaneously guaranteed for all missing pixels. We also
show how to compute these bands efficiently using Schur complements, we discuss
a generalization to vector-valued functions, and we present a series of
numerical experiments on various datasets containing synthetically generated
and benchmark images, as well.

</details>


### [537] [BAPE: Learning an Explicit Bayes Classifier for Long-tailed Visual Recognition](https://arxiv.org/abs/2506.23280)
*Chaoqun Du,Yulin Wang,Shiji Song,Gao Huang*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种新方法（BAPE），通过显式建模后验概率参数并直接学习贝叶斯分类器，解决了长尾数据分布下的梯度不平衡问题，并确保贝叶斯最优决策规则。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在长尾数据分布下因梯度不平衡而无法确保贝叶斯最优决策的问题。

Method: 显式建模后验概率参数，直接学习贝叶斯分类器，并提出分布调整技术以适应任意不平衡的测试数据分布。

Result: 在CIFAR-10-LT、CIFAR-100-LT、ImageNet-LT和iNaturalist等数据集上显著提升了泛化性能。

Conclusion: BAPE方法在长尾数据场景下优于现有方法，且与现有方法正交。

Abstract: Bayesian decision theory advocates the Bayes classifier as the optimal
approach for minimizing the risk in machine learning problems. Current deep
learning algorithms usually solve for the optimal classifier by
\emph{implicitly} estimating the posterior probabilities, \emph{e.g.}, by
minimizing the Softmax cross-entropy loss. This simple methodology has been
proven effective for meticulously balanced academic benchmark datasets.
However, it is not applicable to the long-tailed data distributions in the real
world, where it leads to the gradient imbalance issue and fails to ensure the
Bayes optimal decision rule. To address these challenges, this paper presents a
novel approach (BAPE) that provides a more precise theoretical estimation of
the data distributions by \emph{explicitly} modeling the parameters of the
posterior probabilities and solving them with point estimation. Consequently,
our method directly learns the Bayes classifier without gradient descent based
on Bayes' theorem, simultaneously alleviating the gradient imbalance and
ensuring the Bayes optimal decision rule. Furthermore, we propose a
straightforward yet effective \emph{distribution adjustment} technique. This
method enables the Bayes classifier trained from the long-tailed training set
to effectively adapt to the test data distribution with an arbitrary imbalance
factor, thereby enhancing performance without incurring additional
computational costs. In addition, we demonstrate the gains of our method are
orthogonal to existing learning approaches for long-tailed scenarios, as they
are mostly designed under the principle of \emph{implicitly} estimating the
posterior probabilities. Extensive empirical evaluations on CIFAR-10-LT,
CIFAR-100-LT, ImageNet-LT, and iNaturalist demonstrate that our method
significantly improves the generalization performance of popular deep networks,
despite its simplicity.

</details>


### [538] [Not All Explanations for Deep Learning Phenomena Are Equally Valuable](https://arxiv.org/abs/2506.23286)
*Alan Jeffares,Mihaela van der Schaar*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该立场论文认为，深度学习中的反直觉现象（如双下降、grokking等）在现实应用中缺乏证据支持，研究这些现象可能效率低下，但仍可作为验证深度学习理论的独特场景。


<details>
  <summary>Details</summary>
Motivation: 探讨深度学习中的反直觉现象是否对实际应用有贡献，以及如何更高效地利用这些现象推动深度学习领域的进步。

Method: 通过分析文献中多个著名现象的研究成果，重新审视研究社区的当前规范，并提出未来研究的实用建议。

Result: 研究发现这些现象在现实应用中缺乏证据支持，但可以作为验证深度学习理论的工具。

Conclusion: 建议不要将这些现象视为孤立问题，而是作为验证更广泛深度学习理论的场景，以更高效地推动领域进步。

Abstract: Developing a better understanding of surprising or counterintuitive phenomena
has constituted a significant portion of deep learning research in recent
years. These include double descent, grokking, and the lottery ticket
hypothesis -- among many others. Works in this area often develop ad hoc
hypotheses attempting to explain these observed phenomena on an isolated,
case-by-case basis. This position paper asserts that, in many prominent cases,
there is little evidence to suggest that these phenomena appear in real-world
applications and these efforts may be inefficient in driving progress in the
broader field. Consequently, we argue against viewing them as isolated puzzles
that require bespoke resolutions or explanations. However, despite this, we
suggest that deep learning phenomena do still offer research value by providing
unique settings in which we can refine our broad explanatory theories of more
general deep learning principles. This position is reinforced by analyzing the
research outcomes of several prominent examples of these phenomena from the
recent literature. We revisit the current norms in the research community in
approaching these problems and propose practical recommendations for future
research, aiming to ensure that progress on deep learning phenomena is well
aligned with the ultimate pragmatic goal of progress in the broader field of
deep learning.

</details>


### [539] [Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment](https://arxiv.org/abs/2506.23358)
*Pawel Renc,Michal K. Grzeszczyk,Linglong Qian,Nassim Oufattole,Jeff Rasley,Arkadiusz Sitek*

Main category: cs.LG

Relevance: 40.0

TL;DR: FTS是一个用于分布式时间序列数据（如电子健康记录）训练生成基础模型的新框架，通过合成数据实现隐私保护、可扩展性和多功能性。


<details>
  <summary>Details</summary>
Motivation: 解决分布式医疗数据训练生成模型的隐私和可扩展性问题。

Method: 将患者历史表示为语言无关的序列，本地训练自回归Transformer，服务器合成数据训练全局生成器。

Result: 在MIMIC-IV数据上，合成数据训练的模型表现与真实数据相当。

Conclusion: FTS在隐私保护、可扩展性和多功能性方面表现优异，适用于多种医疗任务。

Abstract: We present Federated Timeline Synthesis (FTS), a novel framework for training
generative foundation models across distributed timeseries data applied to
electronic health records (EHR). At its core, FTS represents patient history as
tokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding
temporal, categorical, and continuous clinical information. Each institution
trains an autoregressive transformer on its local PHTs and transmits only model
weights to a central server. The server uses the generators to synthesize a
large corpus of trajectories and train a Global Generator (GG), enabling
zero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS
on five clinically meaningful prediction tasks using MIMIC-IV data, showing
that models trained on synthetic data generated by GG perform comparably to
those trained on real data. FTS offers strong privacy guarantees, scalability
across institutions, and extensibility to diverse prediction and simulation
tasks especially in healthcare, including counterfactual inference, early
warning detection, and synthetic trial design.

</details>


### [540] [When Additive Noise Meets Unobserved Mediators: Bivariate Denoising Diffusion for Causal Discovery](https://arxiv.org/abs/2506.23374)
*Dominik Meier,Sujai Hiremath,Promit Ghosal,Kyra Gan*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种名为BiDD的新方法，用于处理存在未观测中介变量时的因果发现问题，通过引入新的独立性检验统计量，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统加性噪声模型（ANM）在存在未观测中介变量时失效，现有解决方案在有限样本下表现脆弱，因此需要更鲁棒的方法。

Method: 提出Bivariate Denoising Diffusion (BiDD)，通过在去噪过程中引入新的独立性检验统计量，评估预测噪声相对于输入的独立性。

Result: 实验表明，BiDD在存在中介变量时表现优于现有方法，同时在无中介变量时保持强性能。

Conclusion: BiDD是一种有效的因果发现方法，特别适用于存在未观测中介变量的场景。

Abstract: Distinguishing cause and effect from bivariate observational data is a
foundational problem in many disciplines, but challenging without additional
assumptions. Additive noise models (ANMs) are widely used to enable
sample-efficient bivariate causal discovery. However, conventional ANM-based
methods fail when unobserved mediators corrupt the causal relationship between
variables. This paper makes three key contributions: first, we rigorously
characterize why standard ANM approaches break down in the presence of
unmeasured mediators. Second, we demonstrate that prior solutions for hidden
mediation are brittle in finite sample settings, limiting their practical
utility. To address these gaps, we propose Bivariate Denoising Diffusion (BiDD)
for causal discovery, a method designed to handle latent noise introduced by
unmeasured mediators. Unlike prior methods that infer directionality through
mean squared error loss comparisons, our approach introduces a novel
independence test statistic: during the noising and denoising processes for
each variable, we condition on the other variable as input and evaluate the
independence of the predicted noise relative to this input. We prove asymptotic
consistency of BiDD under the ANM, and conjecture that it performs well under
hidden mediation. Experiments on synthetic and real-world data demonstrate
consistent performance, outperforming existing methods in mediator-corrupted
settings while maintaining strong performance in mediator-free settings.

</details>


### [541] [BenchMake: Turn any scientific data set into a reproducible benchmark](https://arxiv.org/abs/2506.23419)
*Amanda S Barnard*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种名为BenchMake的新工具，可将科学数据集转化为基准测试集，通过非负矩阵分解识别边缘案例，并生成具有统计显著性的测试集。


<details>
  <summary>Details</summary>
Motivation: 由于计算科学中基准数据集的稀缺性，评估新方法变得困难。BenchMake旨在解决这一问题，通过将开放的科学数据集转化为可用的基准测试集。

Method: 使用非负矩阵分解确定边缘案例，并在凸包上划分测试集，以最大化差异和统计显著性。支持多种数据类型（表格、图、图像、信号、文本）。

Result: 在十个公开的科学基准数据集上测试，BenchMake的分割优于现有分割和随机分割。

Conclusion: BenchMake为计算科学提供了一种通用的基准测试生成工具，有助于更可靠地评估新方法。

Abstract: Benchmark data sets are a cornerstone of machine learning development and
applications, ensuring new methods are robust, reliable and competitive. The
relative rarity of benchmark sets in computational science, due to the
uniqueness of the problems and the pace of change in the associated domains,
makes evaluating new innovations difficult for computational scientists. In
this paper a new tool is developed and tested to potentially turn any of the
increasing numbers of scientific data sets made openly available into a
benchmark accessible to the community. BenchMake uses non-negative matrix
factorisation to deterministically identify and isolate challenging edge cases
on the convex hull (the smallest convex set that contains all existing data
instances) and partitions a required fraction of matched data instances into a
testing set that maximises divergence and statistical significance, across
tabular, graph, image, signal and textual modalities. BenchMake splits are
compared to establish splits and random splits using ten publicly available
benchmark sets from different areas of science, with different sizes, shapes,
distributions.

</details>


### [542] [Accurate Parameter-Efficient Test-Time Adaptation for Time Series Forecasting](https://arxiv.org/abs/2506.23424)
*Heitor R. Medeiros,Hossein Sharifi-Noghabi,Gabriel L. Oliveira,Saghar Irandoust*

Main category: cs.LG

Relevance: 40.0

TL;DR: PETSA是一种参数高效的方法，通过在测试时仅更新输入和输出的小型校准模块来适应非平稳时间序列预测，使用低秩适配器和动态门控调整表示。


<details>
  <summary>Details</summary>
Motivation: 现实世界的时间序列通常表现出非平稳性，降低了预训练预测模型的性能。现有的测试时间适应方法通常更新整个模型，增加了内存和计算成本。

Method: PETSA通过低秩适配器和动态门控调整表示，仅更新输入和输出的小型校准模块，无需重新训练。引入了一种结合鲁棒性、频域和结构对齐的专用损失函数。

Result: 在基准数据集上，PETSA在各种预测骨干上表现出色，性能优于或与基线相当，同时需要更少的参数。

Conclusion: PETSA提供了一种高效且有效的测试时间适应方法，适用于非平稳时间序列预测。

Abstract: Real-world time series often exhibit a non-stationary nature, degrading the
performance of pre-trained forecasting models. Test-Time Adaptation (TTA)
addresses this by adjusting models during inference, but existing methods
typically update the full model, increasing memory and compute costs. We
propose PETSA, a parameter-efficient method that adapts forecasters at test
time by only updating small calibration modules on the input and output. PETSA
uses low-rank adapters and dynamic gating to adjust representations without
retraining. To maintain accuracy despite limited adaptation capacity, we
introduce a specialized loss combining three components: (1) a robust term, (2)
a frequency-domain term to preserve periodicity, and (3) a patch-wise
structural term for structural alignment. PETSA improves the adaptability of
various forecasting backbones while requiring fewer parameters than baselines.
Experimental results on benchmark datasets show that PETSA achieves competitive
or better performance across all horizons. Our code is available at:
https://github.com/BorealisAI/PETSA

</details>


### [543] [Enhancing Insider Threat Detection Using User-Based Sequencing and Transformer Encoders](https://arxiv.org/abs/2506.23446)
*Mohamed Elbasheer,Adewale Akinfaderin*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于Transformer的用户行为序列建模方法（UBS-Transformer），用于检测内部威胁，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 内部威胁检测因恶意行为者的授权状态和异常行为的隐蔽性而具有挑战性，现有方法未能充分利用用户行为的序列依赖性。

Method: 将CERT数据集转化为时间序列，使用Transformer Encoder建模正常行为，重建误差作为异常分数，结合三种无监督异常检测算法（OCSVM、LOF、iForest）。

Result: 在四个测试集上表现优异：96.61%准确率、99.43%召回率、96.38% F1分数、95.00% AUROC，极低的假阴性和假阳性率。

Conclusion: 序列用户建模和先进异常检测在内部威胁领域效果显著。

Abstract: Insider threat detection presents unique challenges due to the authorized
status of malicious actors and the subtlety of anomalous behaviors. Existing
machine learning methods often treat user activity as isolated events, thereby
failing to leverage sequential dependencies in user behavior. In this study, we
propose a User-Based Sequencing (UBS) methodology, transforming the CERT
insider threat dataset into structured temporal sequences suitable for deep
sequential modeling. We deploy a Transformer Encoder architecture to model
benign user activity and employ its reconstruction errors as anomaly scores.
These scores are subsequently evaluated using three unsupervised outlier
detection algorithms: One-Class SVM (OCSVM), Local Outlier Factor (LOF), and
Isolation Forest (iForest). Across four rigorously designed test sets,
including combinations of multiple CERT dataset releases, our UBS-Transformer
pipeline consistently achieves state-of-the-art performance - notably 96.61%
accuracy, 99.43% recall, 96.38% F1-score, 95.00% AUROC, and exceptionally low
false negative (0.0057) and false positive (0.0571) rates. Comparative analyses
demonstrate that our approach substantially outperforms tabular and
conventional autoencoder baselines, underscoring the efficacy of sequential
user modeling and advanced anomaly detection in the insider threat domain.

</details>


### [544] [Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification](https://arxiv.org/abs/2506.23462)
*Manaswi Kulahara,Gautam Siddharth Kashyap,Nipun Joshi,Arpita Soni*

Main category: cs.LG

Relevance: 40.0

TL;DR: DisasterNet-LLM是一个专为多模态灾害分析设计的LLM，通过预训练和跨模态注意力机制，在灾害分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以整合多模态灾害数据，DisasterNet-LLM旨在解决这一问题。

Method: 采用高级预训练、跨模态注意力机制和自适应Transformer。

Result: 在灾害分类任务中，准确率89.5%，F1分数88.0%，AUC 0.92，BERTScore 0.88。

Conclusion: DisasterNet-LLM在多模态灾害分析中优于现有模型。

Abstract: Effective disaster management requires timely and accurate insights, yet
traditional methods struggle to integrate multimodal data such as images,
weather records, and textual reports. To address this, we propose
DisasterNet-LLM, a specialized Large Language Model (LLM) designed for
comprehensive disaster analysis. By leveraging advanced pretraining,
cross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM
excels in disaster classification. Experimental results demonstrate its
superiority over state-of-the-art models, achieving higher accuracy of 89.5%,
an F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal
disaster classification tasks.

</details>


### [545] [FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization](https://arxiv.org/abs/2506.23516)
*Seung-Wook Kim,Seongyeol Kim,Jiah Kim,Seowon Ji,Se-Ho Lee*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种名为FedWSQ的新型联邦学习框架，结合权重标准化（WS）和分布感知非均匀量化（DANUQ），以解决数据异构性和通信限制问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）常因数据异构性和通信限制导致性能下降，FedWSQ旨在解决这些问题。

Method: FedWSQ通过权重标准化（WS）过滤本地更新中的偏差成分，并通过DANUQ最小化量化误差。

Result: 实验表明，FedWSQ在极端数据异构性和超低比特通信场景下优于现有方法。

Conclusion: FedWSQ显著减少了通信开销并保持了模型准确性。

Abstract: Federated learning (FL) often suffers from performance degradation due to key
challenges such as data heterogeneity and communication constraints. To address
these limitations, we present a novel FL framework called FedWSQ, which
integrates weight standardization (WS) and the proposed distribution-aware
non-uniform quantization (DANUQ). WS enhances FL performance by filtering out
biased components in local updates during training, thereby improving the
robustness of the model against data heterogeneity and unstable client
participation. In addition, DANUQ minimizes quantization errors by leveraging
the statistical properties of local model updates. As a result, FedWSQ
significantly reduces communication overhead while maintaining superior model
accuracy. Extensive experiments on FL benchmark datasets demonstrate that
FedWSQ consistently outperforms existing FL methods across various challenging
FL settings, including extreme data heterogeneity and ultra-low-bit
communication scenarios.

</details>


### [546] [Both Asymptotic and Non-Asymptotic Convergence of Quasi-Hyperbolic Momentum using Increasing Batch Size](https://arxiv.org/abs/2506.23544)
*Kento Imaizumi,Hideaki Iiduka*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文研究了准双曲动量（QHM）在随机非凸优化中的收敛性，提出通过增加批量大小而非降低学习率来提升训练效果。


<details>
  <summary>Details</summary>
Motivation: 动量方法在深度神经网络等随机非凸优化中的理论支持不足，QHM作为动量方法的推广，其收敛性需要更深入的研究。

Method: 通过渐近和非渐近收敛分析，研究了小批量QHM在增加批量大小时的表现，并与降低学习率的策略对比。

Result: 实验表明，增加批量大小（而非降低学习率）能更有效地提升神经网络的训练效果。

Conclusion: 在随机非凸优化中，增加批量大小是比降低学习率更优的策略。

Abstract: Momentum methods were originally introduced for their superiority to
stochastic gradient descent (SGD) in deterministic settings with convex
objective functions. However, despite their widespread application to deep
neural networks -- a representative case of stochastic nonconvex optimization
-- the theoretical justification for their effectiveness in such settings
remains limited. Quasi-hyperbolic momentum (QHM) is an algorithm that
generalizes various momentum methods and has been studied to better understand
the class of momentum-based algorithms as a whole. In this paper, we provide
both asymptotic and non-asymptotic convergence results for mini-batch QHM with
an increasing batch size. We show that achieving asymptotic convergence
requires either a decaying learning rate or an increasing batch size. Since a
decaying learning rate adversely affects non-asymptotic convergence, we
demonstrate that using mini-batch QHM with an increasing batch size -- without
decaying the learning rate -- can be a more effective strategy. Our experiments
show that even a finite increase in batch size can provide benefits for
training neural networks.

</details>


### [547] [When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series](https://arxiv.org/abs/2506.23596)
*Min-Yeong Park,Won-Jeong Lee,Seong Tae Kim,Gyeong-Moon Park*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种名为A2P的新框架，用于预测未来异常事件，包含异常感知预测（AAF）和合成异常提示（SAP）。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法预测未来异常事件的具体时间点，A2P旨在解决这一问题。

Method: A2P通过AAF学习异常关系，并通过SAP模拟多样异常模式。

Result: 在多个真实数据集上，A2P优于现有方法，能有效预测未来异常。

Conclusion: A2P为异常预测任务提供了有效的解决方案。

Abstract: Recently, forecasting future abnormal events has emerged as an important
scenario to tackle real-world necessities. However, the solution of predicting
specific future time points when anomalies will occur, known as Anomaly
Prediction (AP), remains under-explored. Existing methods dealing with time
series data fail in AP, focusing only on immediate anomalies or failing to
provide precise predictions for future anomalies. To address the AP task, we
propose a novel framework called Anomaly to Prompt (A2P), comprised of
Anomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To
enable the forecasting model to forecast abnormal time points, we adopt a
strategy to learn the relationships of anomalies. For the robust detection of
anomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP)
that simulates diverse anomaly patterns using signal adaptive prompt.
Comprehensive experiments on multiple real-world datasets demonstrate the
superiority of A2P over state-of-the-art methods, showcasing its ability to
predict future anomalies. Our implementation code is available at
https://github.com/KU-VGI/AP.

</details>


### [548] [Model-driven Stochastic Trace Clustering](https://arxiv.org/abs/2506.23776)
*Jari Peeperkorn,Johannes De Smedt,Jochen De Weerdt*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于随机过程模型的轨迹聚类方法，利用熵相关性度量改进聚类效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有轨迹聚类方法忽略活动频率和转移概率的问题，以更好地捕捉真实世界执行动态。

Method: 使用基于直接跟随概率的熵相关性度量，优化每个聚类中的随机过程模型。

Result: 在公共数据集上表现优于现有方法，提升了模型可解释性。

Conclusion: 考虑随机性可显著改进聚类性能，揭示更清晰的控制流模式。

Abstract: Process discovery algorithms automatically extract process models from event
logs, but high variability often results in complex and hard-to-understand
models. To mitigate this issue, trace clustering techniques group process
executions into clusters, each represented by a simpler and more understandable
process model. Model-driven trace clustering improves on this by assigning
traces to clusters based on their conformity to cluster-specific process
models. However, most existing clustering techniques rely on either no process
model discovery, or non-stochastic models, neglecting the frequency or
probability of activities and transitions, thereby limiting their capability to
capture real-world execution dynamics. We propose a novel model-driven trace
clustering method that optimizes stochastic process models within each cluster.
Our approach uses entropic relevance, a stochastic conformance metric based on
directly-follows probabilities, to guide trace assignment. This allows
clustering decisions to consider both structural alignment with a cluster's
process model and the likelihood that a trace originates from a given
stochastic process model. The method is computationally efficient, scales
linearly with input size, and improves model interpretability by producing
clusters with clearer control-flow patterns. Extensive experiments on public
real-life datasets show that our method outperforms existing alternatives in
representing process behavior and reveals how clustering performance rankings
can shift when stochasticity is considered.

</details>


### [549] [Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling](https://arxiv.org/abs/2506.23782)
*Xiaoyang Li,Linwei Tao,Haohui Lu,Minjing Dong,Junbin Gao,Chang Xu*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种基于图小波的校准方法WATS，用于提升图神经网络（GNNs）的置信度估计准确性，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: GNNs的置信度估计与实际预测准确性不一致，限制了其在安全关键场景中的应用。现有方法依赖粗粒度统计或节点嵌入，忽略了图拓扑的细粒度结构异质性。

Method: 提出Wavelet-Aware Temperature Scaling (WATS)，利用可调的热核图小波特征为节点分配特定温度，优化置信度估计。

Result: 在七个基准数据集和两种GNN架构上，WATS的预期校准误差（ECE）最低，比基线方法提升42.3%，校准方差平均降低17.24%。

Conclusion: WATS是一种高效且可扩展的校准框架，显著提升了GNNs的置信度估计性能。

Abstract: Graph Neural Networks (GNNs) have demonstrated strong predictive performance
on relational data; however, their confidence estimates often misalign with
actual predictive correctness, posing significant limitations for deployment in
safety-critical settings. While existing graph-aware calibration methods seek
to mitigate this limitation, they primarily depend on coarse one-hop
statistics, such as neighbor-predicted confidence, or latent node embeddings,
thereby neglecting the fine-grained structural heterogeneity inherent in graph
topology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a
post-hoc calibration framework that assigns node-specific temperatures based on
tunable heat-kernel graph wavelet features. Specifically, WATS harnesses the
scalability and topology sensitivity of graph wavelets to refine confidence
estimates, all without necessitating model retraining or access to neighboring
logits or predictions. Extensive evaluations across seven benchmark datasets
with varying graph structures and two GNN backbones demonstrate that WATS
achieves the lowest Expected Calibration Error (ECE) among all compared
methods, outperforming both classical and graph-specific baselines by up to
42.3\% in ECE and reducing calibration variance by 17.24\% on average compared
with graph-specific methods. Moreover, WATS remains computationally efficient,
scaling well across graphs of diverse sizes and densities. Code will be
released based on publication.

</details>


### [550] [Towards the Training of Deeper Predictive Coding Neural Networks](https://arxiv.org/abs/2506.23800)
*Chang Qi,Matteo Forasassi,Thomas Lukasiewicz,Tommaso Salvatori*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出两种新方法优化预测编码网络的深度训练问题，解决了层间误差不平衡和深层权重更新问题，显著提升了七层以上网络的性能。


<details>
  <summary>Details</summary>
Motivation: 解决预测编码网络在深度超过五到七层时性能显著下降的问题。

Method: 1. 引入两种优化潜在变量的方法，通过精度加权重新平衡层间能量分布；2. 提出新的权重更新机制减少深层误差累积。

Result: 在多个图像分类任务中，七层以上网络的测试准确率大幅提升，性能接近反向传播模型。

Conclusion: 理解松弛阶段对大规模训练预测编码网络至关重要，为复杂任务应用提供了新可能。

Abstract: Predictive coding networks trained with equilibrium propagation are neural
models that perform inference through an iterative energy minimization process.
Previous studies have demonstrated their effectiveness in shallow
architectures, but show significant performance degradation when depth exceeds
five to seven layers. In this work, we show that the reason behind this
degradation is due to exponentially imbalanced errors between layers during
weight updates, and predictions from the previous layer not being effective in
guiding updates in deeper layers. We address the first issue by introducing two
novel methods to optimize the latent variables that use precision-weighting to
re-balance the distribution of energy among layers during the `relaxation
phase', and the second issue by proposing a novel weight update mechanism that
reduces error accumulation in deeper layers. Empirically, we test our methods
on a large number of image classification tasks, resulting in large
improvements in test accuracy across networks with more than seven layers, with
performances comparable to those of backprop on similar models. These findings
suggest that a better understanding of the relaxation phase is important to
train models using equilibrium propagation at scale, and open new possibilities
for their application in complex tasks.

</details>


### [551] [SGD with Adaptive Preconditioning: Unified Analysis and Momentum Acceleration](https://arxiv.org/abs/2506.23803)
*Dmitry Kovalev*

Main category: cs.LG

Relevance: 40.0

TL;DR: 本文重新审视了带有AdaGrad型预处理的随机梯度下降（SGD），提出了统一的收敛性分析，并展示了如何通过Nesterov动量加速收敛。


<details>
  <summary>Details</summary>
Motivation: 研究自适应梯度方法（如AdaGrad）的收敛性，并探索如何通过动量加速其性能。

Method: 提出统一的收敛性分析框架，涵盖多种自适应梯度方法（如AdaGrad、ASGO/One-sided Shampoo），并引入Nesterov动量。

Result: 证明了AdaGrad型算法可以通过动量加速收敛，并首次为DASGO提供了理论保证。

Conclusion: AdaGrad型算法可以同时受益于对角预处理和动量，解释了Adam的实际效率。

Abstract: In this paper, we revisit stochastic gradient descent (SGD) with AdaGrad-type
preconditioning. Our contributions are twofold. First, we develop a unified
convergence analysis of SGD with adaptive preconditioning under anisotropic or
matrix smoothness and noise assumptions. This allows us to recover
state-of-the-art convergence results for several popular adaptive gradient
methods, including AdaGrad-Norm, AdaGrad, and ASGO/One-sided Shampoo. In
addition, we establish the fundamental connection between two recently proposed
algorithms, Scion and DASGO, and provide the first theoretical guarantees for
the latter. Second, we show that the convergence of methods like AdaGrad and
DASGO can be provably accelerated beyond the best-known rates using Nesterov
momentum. Consequently, we obtain the first theoretical justification that
AdaGrad-type algorithms can simultaneously benefit from both diagonal
preconditioning and momentum, which may provide an ultimate explanation for the
practical efficiency of Adam.

</details>


### [552] [Supercm: Revisiting Clustering for Semi-Supervised Learning](https://arxiv.org/abs/2506.23824)
*Durgesh Singh,Ahcene Boubekki,Robert Jenssen,Michael C. Kampffmeyer*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出了一种新的半监督学习方法，通过可微分聚类模块显式地结合聚类假设，简化训练策略并提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前半监督学习方法多依赖复杂的训练策略，本文旨在通过显式结合聚类假设简化方法并提升效果。

Method: 扩展可微分聚类模块，利用标注数据引导聚类中心，设计端到端可训练的深度半监督学习模型。

Result: 模型性能优于仅监督学习的基线，并能与其他半监督学习方法结合进一步提升效果。

Conclusion: 提出的方法简化了半监督学习训练策略，同时提升了性能，具有与其他方法结合的潜力。

Abstract: The development of semi-supervised learning (SSL) has in recent years largely
focused on the development of new consistency regularization or entropy
minimization approaches, often resulting in models with complex training
strategies to obtain the desired results. In this work, we instead propose a
novel approach that explicitly incorporates the underlying clustering
assumption in SSL through extending a recently proposed differentiable
clustering module. Leveraging annotated data to guide the cluster centroids
results in a simple end-to-end trainable deep SSL approach. We demonstrate that
the proposed model improves the performance over the supervised-only baseline
and show that our framework can be used in conjunction with other SSL methods
to further boost their performance.

</details>


### [553] [Bridging the Gap with Retrieval-Augmented Generation: Making Prosthetic Device User Manuals Available in Marginalised Languages](https://arxiv.org/abs/2506.23958)
*Ikechukwu Ogbonna,Lesley Davidson,Soumya Banerjee,Abhishek Dasgupta,Laurence Kenney,Vikranth Harthikote Nagaraja*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该研究开发了一个AI框架，将复杂的医疗文档（如假肢设备手册）翻译为边缘化语言，采用RAG管道和NLP模型，支持多语言实时问答。


<details>
  <summary>Details</summary>
Motivation: 解决非洲国家因语言和识字障碍导致的医疗文档不可访问问题，特别是假肢设备手册的翻译需求。

Method: 结合检索增强生成（RAG）管道和高级NLP模型，实现文档处理和生成式问答。

Result: 系统能够实时翻译和回答用户以本地语言提出的问题，提升医疗信息的可访问性。

Conclusion: 该框架为边缘化语言社区提供了医疗信息的可访问解决方案，并可扩展到其他语言。

Abstract: Millions of people in African countries face barriers to accessing healthcare
due to language and literacy gaps. This research tackles this challenge by
transforming complex medical documents -- in this case, prosthetic device user
manuals -- into accessible formats for underserved populations. This case study
in cross-cultural translation is particularly pertinent/relevant for
communities that receive donated prosthetic devices but may not receive the
accompanying user documentation. Or, if available online, may only be available
in formats (e.g., language and readability) that are inaccessible to local
populations (e.g., English-language, high resource settings/cultural context).
The approach is demonstrated using the widely spoken Pidgin dialect, but our
open-source framework has been designed to enable rapid and easy extension to
other languages/dialects. This work presents an AI-powered framework designed
to process and translate complex medical documents, e.g., user manuals for
prosthetic devices, into marginalised languages. The system enables users --
such as healthcare workers or patients -- to upload English-language medical
equipment manuals, pose questions in their native language, and receive
accurate, localised answers in real time. Technically, the system integrates a
Retrieval-Augmented Generation (RAG) pipeline for processing and semantic
understanding of the uploaded manuals. It then employs advanced Natural
Language Processing (NLP) models for generative question-answering and
multilingual translation. Beyond simple translation, it ensures accessibility
to device instructions, treatment protocols, and safety information, empowering
patients and clinicians to make informed healthcare decisions.

</details>


### [554] [ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.23960)
*Mingfei Cheng,Xiaofei Xie,Renzhi Wang,Yuan Zhou,Ming Hu*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文提出了一种名为ADReFT的自适应决策修复方法，通过结合Transformer模型和强化学习，提升自动驾驶系统的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统存在安全风险，现有在线修复方法缺乏通用性和适应性，导致修复效果不佳。

Method: ADReFT结合Transformer模型（State Monitor和Decision Adapter）和强化学习，通过离线学习和在线调整生成修复动作。

Result: ADReFT在修复性能上表现优于现有方法。

Conclusion: ADReFT通过自适应修复策略显著提升了自动驾驶系统的安全性和可靠性。

Abstract: Autonomous Driving Systems (ADSs) continue to face safety-critical risks due
to the inherent limitations in their design and performance capabilities.
Online repair plays a crucial role in mitigating such limitations, ensuring the
runtime safety and reliability of ADSs. Existing online repair solutions
enforce ADS compliance by transforming unacceptable trajectories into
acceptable ones based on predefined specifications, such as rule-based
constraints or training datasets. However, these approaches often lack
generalizability, adaptability and tend to be overly conservative, resulting in
ineffective repairs that not only fail to mitigate safety risks sufficiently
but also degrade the overall driving experience. To address this issue, we
propose Adaptive Decision Repair (ADReFT), a novel and effective repair method
that identifies safety-critical states through offline learning from failed
tests and generates appropriate mitigation actions to improve ADS safety.
Specifically, ADReFT incorporates a transformer-based model with two joint
heads, State Monitor and Decision Adapter, designed to capture complex driving
environment interactions to evaluate state safety severity and generate
adaptive repair actions. Given the absence of oracles for state safety
identification, we first pretrain ADReFT using supervised learning with coarse
annotations, i.e., labeling states preceding violations as positive samples and
others as negative samples. It establishes ADReFT's foundational capability to
mitigate safety-critical violations, though it may result in somewhat
conservative mitigation strategies. Therefore, we subsequently finetune ADReFT
using reinforcement learning to improve its initial capability and generate
more precise and contextually appropriate repair decisions. Our evaluation
results illustrate that ADReFT achieves better repair performance.

</details>


### [555] [The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models](https://arxiv.org/abs/2506.24000)
*Lijun Sheng,Jian Liang,Ran He,Zilei Wang,Tieniu Tan*

Main category: cs.LG

Relevance: 40.0

TL;DR: TTA-VLM是一个用于评估视觉语言模型（VLM）测试时适应（TTA）方法的综合基准，解决了现有研究的局限性，并提供了更全面的评估指标。


<details>
  <summary>Details</summary>
Motivation: 当前TTA研究存在基线结果重复、评估指标有限、实验设置不一致和分析不足等问题，阻碍了公平比较和实际应用。

Method: TTA-VLM在统一框架中实现了8种情景TTA和7种在线TTA方法，并在15个数据集上评估，扩展了模型范围（如SigLIP）和训练时调优方法。

Result: 实验发现现有TTA方法提升有限，与训练时调优方法协作性差，且准确性提升常以模型可信度降低为代价。

Conclusion: TTA-VLM为TTA方法提供了公平比较和全面评估，鼓励开发更可靠和通用的策略。

Abstract: Test-time adaptation (TTA) methods have gained significant attention for
enhancing the performance of vision-language models (VLMs) such as CLIP during
inference, without requiring additional labeled data. However, current TTA
researches generally suffer from major limitations such as duplication of
baseline results, limited evaluation metrics, inconsistent experimental
settings, and insufficient analysis. These problems hinder fair comparisons
between TTA methods and obscure their practical strengths and weaknesses. To
address these challenges, we introduce TTA-VLM, a comprehensive benchmark for
evaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7
online TTA methods within a unified and reproducible framework, and evaluates
them across 15 widely used datasets. Unlike prior studies focused solely on
CLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid
loss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA
to assess generality. Beyond classification accuracy, TTA-VLM incorporates
various evaluation metrics, including robustness, calibration,
out-of-distribution detection, and stability, enabling a more holistic
assessment of TTA methods. Through extensive experiments, we find that 1)
existing TTA methods produce limited gains compared to the previous pioneering
work; 2) current TTA methods exhibit poor collaboration with training-time
fine-tuning methods; 3) accuracy gains frequently come at the cost of reduced
model trustworthiness. We release TTA-VLM to provide fair comparison and
comprehensive evaluation of TTA methods for VLMs, and we hope it encourages the
community to develop more reliable and generalizable TTA strategies.

</details>


### [556] [Bridging Theory and Practice in Link Representation with Graph Neural Networks](https://arxiv.org/abs/2506.24018)
*Veronica Lachi,Francesco Ferrini,Antonio Longa,Bruno Lepri,Andrea Passerini,Manfred Jaeger*

Main category: cs.LG

Relevance: 40.0

TL;DR: 该论文首次全面研究了图神经网络（GNN）在链接表示中的表达能力，提出了一个统一框架，并设计了一个合成评估协议来验证理论分析。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注图级表示，而忽略了链接表示的表达能力，因此需要填补这一空白。

Method: 提出了一个名为$k_\phi$-$k_\rho$-$m$的统一框架，用于比较现有消息传递链接模型的表达能力，并设计了一个合成评估协议。

Result: 理论分析表明，表达能力强的模型在对称性高的数据中表现更好，但在标准基准测试中可能表现不佳。

Conclusion: 需要根据数据集特性选择模型，表达能力强的模型在复杂场景中更具优势。

Abstract: Graph Neural Networks (GNNs) are widely used to compute representations of
node pairs for downstream tasks such as link prediction. Yet, theoretical
understanding of their expressive power has focused almost entirely on
graph-level representations. In this work, we shift the focus to links and
provide the first comprehensive study of GNN expressiveness in link
representation. We introduce a unifying framework, the $k_\phi$-$k_\rho$-$m$
framework, that subsumes existing message-passing link models and enables
formal expressiveness comparisons. Using this framework, we derive a hierarchy
of state-of-the-art methods and offer theoretical tools to analyze future
architectures. To complement our analysis, we propose a synthetic evaluation
protocol comprising the first benchmark specifically designed to assess
link-level expressiveness. Finally, we ask: does expressiveness matter in
practice? We use a graph symmetry metric that quantifies the difficulty of
distinguishing links and show that while expressive models may underperform on
standard benchmarks, they significantly outperform simpler ones as symmetry
increases, highlighting the need for dataset-aware model selection.

</details>


### [557] [Faster Diffusion Models via Higher-Order Approximation](https://arxiv.org/abs/2506.24042)
*Gen Li,Yuchen Zhou,Yuting Wei,Yuxin Chen*

Main category: cs.LG

Relevance: 40.0

TL;DR: 提出一种无需重新训练的扩散模型加速采样算法，基于高阶ODE求解器，显著减少评分函数评估次数。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型采样效率低的问题，无需额外训练，适用于广泛的数据分布。

Method: 利用高阶ODE求解器，结合拉格朗日插值和逐步细化，近似概率流ODE的积分。

Result: 算法在评分准确时，评分函数评估次数为$d^{1+2/K} \varepsilon^{-1/K}$，对评分误差具有鲁棒性。

Conclusion: 提出的方法在理论和实践中均表现出高效和鲁棒性，适用于多种数据分布。

Abstract: In this paper, we explore provable acceleration of diffusion models without
any additional retraining. Focusing on the task of approximating a target data
distribution in $\mathbb{R}^d$ to within $\varepsilon$ total-variation
distance, we propose a principled, training-free sampling algorithm that
requires only the order of
  $$ d^{1+2/K} \varepsilon^{-1/K} $$
  score function evaluations (up to log factor) in the presence of accurate
scores, where $K$ is an arbitrarily large fixed integer. This result applies to
a broad class of target data distributions, without the need for assumptions
such as smoothness or log-concavity. Our theory is robust vis-a-vis inexact
score estimation, degrading gracefully as the score estimation error increases
-- without demanding higher-order smoothness on the score estimates as assumed
in previous work. The proposed algorithm draws insight from high-order ODE
solvers, leveraging high-order Lagrange interpolation and successive refinement
to approximate the integral derived from the probability flow ODE.

</details>


### [558] [Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies](https://arxiv.org/abs/2506.24093)
*Paul Wachter,Lukas Niehaus,Julius Schöning*

Main category: cs.LG

Relevance: 40.0

TL;DR: 论文研究了混合训练策略（合成与真实数据结合）对减轻领域差距的影响，并系统评估了其在不同任务和架构中的通用性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 合成数据是训练神经网络的低成本替代方案，但与真实数据的差距导致性能下降。研究旨在探索混合训练策略的效果。

Method: 分析了两种混合策略在三种架构和三种混合数据集上的表现，通过调整合成与真实数据的比例进行研究。

Result: 研究结果为优化合成数据在神经网络训练中的使用提供了见解，增强了模型的鲁棒性和效果。

Conclusion: 混合训练策略能有效减轻领域差距，但需进一步研究其通用性和鲁棒性。

Abstract: Synthetic data has emerged as a cost-effective alternative to real data for
training artificial neural networks (ANN). However, the disparity between
synthetic and real data results in a domain gap. That gap leads to poor
performance and generalization of the trained ANN when applied to real-world
scenarios. Several strategies have been developed to bridge this gap, which
combine synthetic and real data, known as mixed training using hybrid datasets.
While these strategies have been shown to mitigate the domain gap, a systematic
evaluation of their generalizability and robustness across various tasks and
architectures remains underexplored. To address this challenge, our study
comprehensively analyzes two widely used mixing strategies on three prevalent
architectures and three distinct hybrid datasets. From these datasets, we
sample subsets with varying proportions of synthetic to real data to
investigate the impact of synthetic and real components. The findings of this
paper provide valuable insights into optimizing the use of synthetic data in
the training process of any ANN, contributing to enhancing robustness and
efficacy.

</details>


### [559] [An Interpretable Transformer-Based Foundation Model for Cross-Procedural Skill Assessment Using Raw fNIRS Signals](https://arxiv.org/abs/2506.22476)
*A. Subedi,S. De,L. Cavuoto,S. Schwaitzberg,M. Hackett,J. Norfleet*

Main category: eess.SP

Relevance: 40.0

TL;DR: 提出了一种基于Transformer的基础模型，用于跨程序技能评估，通过自监督学习预训练，在多个任务中表现出色，并具有高解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为任务特定，预处理复杂，且对新任务或条件缺乏鲁棒性。本文旨在开发一种通用、鲁棒且可解释的技能评估模型。

Method: 使用自监督学习预训练Transformer模型，处理最小化预处理的fNIRS信号，并通过轻量级适配器模块实现跨任务泛化。

Result: 模型在多个任务中分类准确率超过88%，MCC超过0.91，并在新任务中使用少量样本达到AUC大于87%。

Conclusion: 该模型在技能评估中表现出色，具有高泛化能力和解释性，为动态认知状态分析提供了新工具。

Abstract: Objective skill assessment in high-stakes procedural environments requires
models that not only decode underlying cognitive and motor processes but also
generalize across tasks, individuals, and experimental contexts. While prior
work has demonstrated the potential of functional near-infrared spectroscopy
(fNIRS) for evaluating cognitive-motor performance, existing approaches are
often task-specific, rely on extensive preprocessing, and lack robustness to
new procedures or conditions. Here, we introduce an interpretable
transformer-based foundation model trained on minimally processed fNIRS signals
for cross-procedural skill assessment. Pretrained using self-supervised
learning on data from laparoscopic surgical tasks and endotracheal intubation
(ETI), the model achieves greater than 88% classification accuracy on all
tasks, with Matthews Correlation Coefficient exceeding 0.91 on ETI. It
generalizes to a novel emergency airway procedure--cricothyrotomy--using fewer
than 30 labeled samples and a lightweight (less than 2k parameter) adapter
module, attaining an AUC greater than 87%. Interpretability is achieved via a
novel channel attention mechanism--developed specifically for fNIRS--that
identifies functionally coherent prefrontal sub-networks validated through
ablation studies. Temporal attention patterns align with task-critical phases
and capture stress-induced changes in neural variability, offering insight into
dynamic cognitive states.

</details>


### [560] [Strategic A/B testing via Maximum Probability-driven Two-armed Bandit](https://arxiv.org/abs/2506.22536)
*Yu Zhang,Shanshan Zhao,Bokui Wan,Jinjuan Wang,Xiaodong Yan*

Main category: stat.ML

Relevance: 40.0

TL;DR: 提出了一种基于反事实结果框架和最大概率驱动的双臂老虎机（TAB）方法，用于检测大规模应用中的微小平均处理效应，显著提升了统计功效。


<details>
  <summary>Details</summary>
Motivation: 在大规模应用中，即使微小的平均处理效应也可能带来显著经济影响，但传统方法因敏感性不足而难以检测。

Method: 结合反事实结果框架和最大概率驱动的TAB过程，通过加权均值波动统计量控制I类错误，并采用排列方法增强鲁棒性。

Result: 实验结果表明，该方法在A/B测试中显著提升了统计功效，同时降低了实验成本。

Conclusion: 该方法通过更集中的零假设分布和更分散的备择假设分布，有效提高了检测微小效应的能力。

Abstract: Detecting a minor average treatment effect is a major challenge in
large-scale applications, where even minimal improvements can have a
significant economic impact. Traditional methods, reliant on normal
distribution-based or expanded statistics, often fail to identify such minor
effects because of their inability to handle small discrepancies with
sufficient sensitivity. This work leverages a counterfactual outcome framework
and proposes a maximum probability-driven two-armed bandit (TAB) process by
weighting the mean volatility statistic, which controls Type I error. The
implementation of permutation methods further enhances the robustness and
efficacy. The established strategic central limit theorem (SCLT) demonstrates
that our approach yields a more concentrated distribution under the null
hypothesis and a less concentrated one under the alternative hypothesis,
greatly improving statistical power. The experimental results indicate a
significant improvement in the A/B testing, highlighting the potential to
reduce experimental costs while maintaining high statistical power.

</details>


### [561] [Neural models of multiscale systems: conceptual limitations, stochastic parametrizations, and a climate application](https://arxiv.org/abs/2506.22552)
*Fabrizio Falasca*

Main category: nlin.CD

Relevance: 40.0

TL;DR: 论文探讨了数据驱动建模在多尺度动力系统中的关键概念限制，聚焦于神经模拟器和随机气候建模。研究发现，当前的自回归神经模型能重现静态统计量，但难以捕捉对外部扰动的响应。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于揭示神经模型在复杂系统（如气候系统）模拟中的局限性，尤其是在部分观测情况下如何选择变量和参数化未观测自由度的影响。

Method: 方法包括分析低维动力系统以类比高维问题，构建两种神经随机模型（全状态观测和部分观测），并应用物理基础策略（如粗粒化和随机参数化）。

Result: 在全观测情况下，模型能准确捕捉平衡统计量和强迫响应；部分观测时则面临变量选择和未观测自由度参数化的挑战。

Conclusion: 结论指出物理基础策略对复杂系统模拟至关重要，并在海面温度场的随机简化神经模型中验证了其有效性。

Abstract: This work explores key conceptual limitations in data-driven modeling of
multiscale dynamical systems, focusing on neural emulators and stochastic
climate modeling. A skillful climate model should capture both stationary
statistics and responses to external perturbations. While current
autoregressive neural models often reproduce the former, they typically
struggle with the latter. We begin by analyzing a low-dimensional dynamical
system to expose, by analogy, fundamental limitations that persist in
high-dimensional settings. Specifically, we construct neural stochastic models
under two scenarios: one where the full state vector is observed, and another
with only partial observations (i.e. a subset of variables). In the first case,
the models accurately capture both equilibrium statistics and forced responses
in ensemble mean and variance. In the more realistic case of partial
observations, two key challenges emerge: (i) identifying the \textit{proper}
variables to model, and (ii) parameterizing the influence of unobserved degrees
of freedom. These issues are not specific to neural networks but reflect
fundamental limitations of data-driven modeling and the need to target the slow
dynamics of the system. We argue that physically grounded strategies -- such as
coarse-graining and stochastic parameterizations -- are critical, both
conceptually and practically, for the skillful emulation of complex systems
like the coupled climate system. Building on these insights, we turn to a more
realistic application: a stochastic reduced neural model of the sea surface
temperature field and the net radiative flux at the top of the atmosphere,
assessing its stationary statistics, response to temperature forcing, and
interpretability.

</details>


### [562] [Adjoint Schrödinger Bridge Sampler](https://arxiv.org/abs/2506.22565)
*Guan-Horng Liu,Jaemoo Choi,Yongxin Chen,Benjamin Kurt Miller,Ricky T. Q. Chen*

Main category: stat.ML

Relevance: 40.0

TL;DR: 提出了一种新的扩散采样器ASBS，通过基于匹配的目标实现高效采样，无需训练时估计目标样本。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散采样器因需要重要性加权估计或复杂学习过程而难以扩展的问题。

Method: 基于Schrödinger Bridge理论，提出ASBS方法，通过Adjoint Matching实现高效采样。

Result: ASBS在经典能量函数、构象生成和分子Boltzmann分布采样中表现优异。

Conclusion: ASBS通过简化目标并提升采样效率，为扩散采样提供了可扩展的解决方案。

Abstract: Computational methods for learning to sample from the Boltzmann distribution
-- where the target distribution is known only up to an unnormalized energy
function -- have advanced significantly recently. Due to the lack of explicit
target samples, however, prior diffusion-based methods, known as diffusion
samplers, often require importance-weighted estimation or complicated learning
processes. Both trade off scalability with extensive evaluations of the energy
and model, thereby limiting their practical usage. In this work, we propose
Adjoint Schr\"odinger Bridge Sampler (ASBS), a new diffusion sampler that
employs simple and scalable matching-based objectives yet without the need to
estimate target samples during training. ASBS is grounded on a mathematical
model -- the Schr\"odinger Bridge -- which enhances sampling efficiency via
kinetic-optimal transportation. Through a new lens of stochastic optimal
control theory, we demonstrate how SB-based diffusion samplers can be learned
at scale via Adjoint Matching and prove convergence to the global solution.
Notably, ASBS generalizes the recent Adjoint Sampling (Havens et al., 2025) to
arbitrary source distributions by relaxing the so-called memoryless condition
that largely restricts the design space. Through extensive experiments, we
demonstrate the effectiveness of ASBS on sampling from classical energy
functions, amortized conformer generation, and molecular Boltzmann
distributions.

</details>


### [563] [Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems](https://arxiv.org/abs/2506.22648)
*Pedro R. Pires,Tiago A. Almeida*

Main category: cs.IR

Relevance: 40.0

TL;DR: Interact2Vec是一种基于神经网络的模型，仅需隐式反馈即可同时学习用户和物品的低维嵌入，在推荐任务中表现优异且高效。


<details>
  <summary>Details</summary>
Motivation: 解决推荐系统中高维稀疏数据的问题，同时避免依赖复杂架构或内容数据。

Method: 采用类似自然语言处理模型的策略，优化训练阶段并增强嵌入质量。

Result: 在30%的数据集中排名第二或第三，训练时间平均减少274%。

Conclusion: Interact2Vec在计算资源有限的情况下是一种高效的嵌入生成模型。

Abstract: Over the past decade, recommender systems have experienced a surge in
popularity. Despite notable progress, they grapple with challenging issues,
such as high data dimensionality and sparseness. Representing users and items
as low-dimensional embeddings learned via neural networks has become a leading
solution. However, while recent studies show promising results, many approaches
rely on complex architectures or require content data, which may not always be
available. This paper presents Interact2Vec, a novel neural network-based model
that simultaneously learns distributed embeddings for users and items while
demanding only implicit feedback. The model employs state-of-the-art strategies
that natural language processing models commonly use to optimize the training
phase and enhance the final embeddings. Two types of experiments were conducted
regarding the extrinsic and intrinsic quality of the model. In the former, we
benchmarked the recommendations generated by Interact2Vec's embeddings in a
top-$N$ ranking problem, comparing them with six other recommender algorithms.
The model achieved the second or third-best results in 30\% of the datasets,
being competitive with other recommenders, and has proven to be very efficient
with an average training time reduction of 274\% compared to other
embedding-based models. Later, we analyzed the intrinsic quality of the
embeddings through similarity tables. Our findings suggest that Interact2Vec
can achieve promising results, especially on the extrinsic task, and is an
excellent embedding-generator model for scenarios of scarce computing
resources, enabling the learning of item and user embeddings simultaneously and
efficiently.

</details>


### [564] [Bayesian Invariance Modeling of Multi-Environment Data](https://arxiv.org/abs/2506.22675)
*Luhuan Wu,Mingzhang Yin,Yixin Wang,John P. Cunningham,David M. Blei*

Main category: stat.ML

Relevance: 40.0

TL;DR: 论文提出了贝叶斯不变预测（BIP），一种概率模型，用于识别多环境数据中的不变特征，支持泛化和因果机制揭示。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过假设检验或正则化优化解决不变预测问题，BIP通过概率建模和变分近似提高准确性和可扩展性。

Method: BIP将不变特征索引编码为隐变量，通过后验推断恢复；设计了高效的变分近似VI-BIP处理高维特征。

Result: BIP和VI-BIP在模拟和真实数据中比现有方法更准确、可扩展。

Conclusion: BIP为不变预测提供了高效的概率框架，环境异质性加速后验收敛。

Abstract: Invariant prediction [Peters et al., 2016] analyzes feature/outcome data from
multiple environments to identify invariant features - those with a stable
predictive relationship to the outcome. Such features support generalization to
new environments and help reveal causal mechanisms. Previous methods have
primarily tackled this problem through hypothesis testing or regularized
optimization. Here we develop Bayesian Invariant Prediction (BIP), a
probabilistic model for invariant prediction. BIP encodes the indices of
invariant features as a latent variable and recover them by posterior
inference. Under the assumptions of Peters et al. [2016], the BIP posterior
targets the true invariant features. We prove that the posterior is consistent
and that greater environment heterogeneity leads to faster posterior
contraction. To handle many features, we design an efficient variational
approximation called VI-BIP. In simulations and real data, we find that BIP and
VI-BIP are more accurate and scalable than existing methods for invariant
prediction.

</details>


### [565] [Libra: Synergizing CUDA and Tensor Cores for High-Performance Sparse Matrix Multiplication](https://arxiv.org/abs/2506.22714)
*Jinliang Shi,Shigang Li,Youxuan Xu,Xueying Wang,Rongtian Fu,Zhi Ma,Tong Wu*

Main category: cs.DC

Relevance: 40.0

TL;DR: 论文提出Libra系统，通过协同利用CUDA和Tensor核心优化稀疏矩阵乘法性能。


<details>
  <summary>Details</summary>
Motivation: 现代加速器中的CUDA和Tensor核心各有局限性，单独使用无法达到最佳性能。

Method: 提出2D感知任务分配策略和异构计算优化，结合Tensor核心的高性能和CUDA核心的低冗余。

Result: 在H100和RTX 4090 GPU上，Libra性能优于现有技术，平均提升3.1倍（最高9.23倍）。

Conclusion: Libra为稀疏算子加速提供了新视角，充分利用GPU异构计算资源。

Abstract: Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used
in deep learning and scientific computing. Modern accelerators are commonly
equipped with Tensor cores and CUDA cores to accelerate sparse operators. The
former brings superior computing power but only for structured matrix
multiplication, while the latter has relatively lower performance but with
higher programming flexibility. In this work, we discover that utilizing one
resource alone leads to inferior performance for sparse matrix multiplication,
due to their respective limitations. To this end, we propose Libra, a
systematic approach that enables synergistic computation between CUDA and
Tensor cores to achieve the best performance for sparse matrix multiplication.
Specifically, we propose a 2D-aware workload distribution strategy to find out
the sweet point of task mapping for different sparse operators, leveraging both
the high performance of Tensor cores and the low computational redundancy on
CUDA cores. In addition, Libra incorporates systematic optimizations for
heterogeneous computing, including hybrid load-balancing, finely optimized
kernel implementations, and GPU-accelerated preprocessing. Extensive
experimental results on H100 and RTX 4090 GPUs show that Libra outperforms the
state-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to
3.9x) for end-to-end GNN applications. Libra opens up a new perspective for
sparse operator acceleration by fully exploiting the heterogeneous computing
resources on GPUs.

</details>


### [566] [Persistence Paradox in Dynamic Science](https://arxiv.org/abs/2506.22729)
*Honglin Bao,Kai Li*

Main category: cs.DL

Relevance: 40.0

TL;DR: 论文挑战了科学中坚持的传统观点，指出在范式转变时期坚持可能成为负担，并以2012年AlexNet引发的深度学习革命为例，分析了科学家的适应策略及其影响。


<details>
  <summary>Details</summary>
Motivation: 探讨科学坚持的局限性，特别是在范式转变时期，研究科学家如何适应新技术趋势及其对科研影响力的影响。

Method: 分析5000多名科学家的20年职业轨迹，研究他们在深度学习革命前后的研究重点和产出变化。

Result: 发现坚持旧方法的科学家面临‘刚性惩罚’，而选择性适应新趋势的科学家获益最大。

Conclusion: 科学突破会重构领域内的权力结构，适应策略对科学家的影响力至关重要。

Abstract: Persistence is often regarded as a virtue in science. In this paper, however,
we challenge this conventional view by highlighting its contextual nature,
particularly how persistence can become a liability during periods of paradigm
shift. We focus on the deep learning revolution catalyzed by AlexNet in 2012.
Analyzing the 20-year career trajectories of over 5,000 scientists who were
active in top machine learning venues during the preceding decade, we examine
how their research focus and output evolved. We first uncover a dynamic period
in which leading venues increasingly prioritized cutting-edge deep learning
developments that displaced relatively traditional statistical learning
methods. Scientists responded to these changes in markedly different ways.
Those who were previously successful or affiliated with old teams adapted more
slowly, experiencing what we term a rigidity penalty - a reluctance to embrace
new directions leading to a decline in scientific impact, as measured by
citation percentile rank. In contrast, scientists who pursued strategic
adaptation - selectively pivoting toward emerging trends while preserving weak
connections to prior expertise - reaped the greatest benefits. Taken together,
our macro- and micro-level findings show that scientific breakthroughs act as
mechanisms that reconfigure power structures within a field.

</details>


### [567] [On Universality of Non-Separable Approximate Message Passing Algorithms](https://arxiv.org/abs/2506.23010)
*Max Lovig,Tianhao Wang,Zhou Fan*

Main category: math.ST

Relevance: 40.0

TL;DR: 研究了非可分离AMP算法的普适性，提出了Bounded Composition Property (BCP)条件，证明了在非高斯数据下状态演化的普适性。


<details>
  <summary>Details</summary>
Motivation: 现有均值场理论主要适用于可分离非线性或高斯数据，缺乏对非可分离算法的普适性研究。

Method: 提出了BCP条件，用于分析多项式非线性AMP算法，并扩展到Lipschitz非线性算法。

Result: 证明了多种常见非线性（如局部去噪、谱去噪）满足BCP条件，状态演化在非高斯数据下仍普适。

Conclusion: 为非可分离AMP算法的普适性提供了理论支持，扩展了均值场理论的应用范围。

Abstract: Mean-field characterizations of first-order iterative algorithms -- including
Approximate Message Passing (AMP), stochastic and proximal gradient descent,
and Langevin diffusions -- have enabled a precise understanding of learning
dynamics in many statistical applications. For algorithms whose non-linearities
have a coordinate-separable form, it is known that such characterizations enjoy
a degree of universality with respect to the underlying data distribution.
However, mean-field characterizations of non-separable algorithm dynamics have
largely remained restricted to i.i.d. Gaussian or rotationally-invariant data.
  In this work, we initiate a study of universality for non-separable AMP
algorithms. We identify a general condition for AMP with polynomial
non-linearities, in terms of a Bounded Composition Property (BCP) for their
representing tensors, to admit a state evolution that holds universally for
matrices with non-Gaussian entries. We then formalize a condition of
BCP-approximability for Lipschitz AMP algorithms to enjoy a similar universal
guarantee. We demonstrate that many common classes of non-separable
non-linearities are BCP-approximable, including local denoisers, spectral
denoisers for generic signals, and compositions of separable functions with
generic linear maps, implying the universality of state evolution for AMP
algorithms employing these non-linearities.

</details>


### [568] [CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding](https://arxiv.org/abs/2506.23075)
*Yuchen Zhou,Jiamin Wu,Zichen Ren,Zhouheng Yao,Weiheng Lu,Kunyu Peng,Qihao Zheng,Chunfeng Song,Wanli Ouyang,Chao Gou*

Main category: cs.HC

Relevance: 40.0

TL;DR: CSBrain提出了一种跨尺度时空脑基础模型，用于通用EEG解码，通过跨尺度时空标记化和结构化稀疏注意力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: EEG信号的多尺度时空结构被现有模型忽视，导致表示和泛化能力不足。

Method: 引入跨尺度时空标记化（CST）和结构化稀疏注意力（SSA），交替堆叠以整合多尺度依赖。

Result: 在11个EEG任务和16个数据集上，CSBrain表现优于任务专用和基础模型基线。

Conclusion: 跨尺度建模是关键归纳偏置，CSBrain为未来脑-AI研究提供了鲁棒基础。

Abstract: Understanding and decoding brain activity from electroencephalography (EEG)
signals is a fundamental challenge in neuroscience and AI, with applications in
cognition, emotion recognition, diagnosis, and brain-computer interfaces. While
recent EEG foundation models advance generalized decoding via unified
architectures and large-scale pretraining, they adopt a scale-agnostic dense
modeling paradigm inherited from NLP and vision. This design neglects a core
property of neural activity: cross-scale spatiotemporal structure. EEG task
patterns span a wide range of temporal and spatial scales, from short bursts to
slow rhythms, and from localized cortical responses to distributed
interactions. Ignoring this diversity leads to suboptimal representations and
weak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain
foundation model for generalized EEG decoding. CSBrain introduces: (i)
Cross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale
features from localized temporal windows and anatomical brain regions into
compact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which
captures cross-window and cross-region dependencies, enhancing scale diversity
while removing spurious correlations. CST and SSA are alternately stacked to
progressively integrate multi-scale dependencies. Experiments on 11 EEG tasks
across 16 datasets show that CSBrain consistently outperforms task-specific and
foundation model baselines. These results establish cross-scale modeling as a
key inductive bias and position CSBrain as a robust backbone for future
brain-AI research.

</details>


### [569] [Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems](https://arxiv.org/abs/2506.23090)
*Langming Liu,Wanyu Wang,Chi Zhang,Bo Li,Hongzhi Yin,Xuetao Wei,Wenbo Su,Bo Zheng,Xiangyu Zhao*

Main category: cs.IR

Relevance: 40.0

TL;DR: MTORL是一种多任务离线强化学习模型，用于解决广告推荐中的稀疏性问题，通过因果状态编码器和多任务学习优化渠道推荐和预算分配。


<details>
  <summary>Details</summary>
Motivation: 当前离线强化学习方法在稀疏广告场景中面临严重的高估、分布偏移和预算约束问题，需要新的解决方案。

Method: 提出MTORL模型，包括广告特定的MDP框架、因果状态编码器、因果注意力机制和多任务学习。

Result: 实验表明MTORL在离线和在线环境中优于现有方法。

Conclusion: MTORL通过多任务学习和因果建模有效解决了广告推荐中的挑战。

Abstract: Online advertising in recommendation platforms has gained significant
attention, with a predominant focus on channel recommendation and budget
allocation strategies. However, current offline reinforcement learning (RL)
methods face substantial challenges when applied to sparse advertising
scenarios, primarily due to severe overestimation, distributional shifts, and
overlooking budget constraints. To address these issues, we propose MTORL, a
novel multi-task offline RL model that targets two key objectives. First, we
establish a Markov Decision Process (MDP) framework specific to the nuances of
advertising. Then, we develop a causal state encoder to capture dynamic user
interests and temporal dependencies, facilitating offline RL through
conditional sequence modeling. Causal attention mechanisms are introduced to
enhance user sequence representations by identifying correlations among causal
states. We employ multi-task learning to decode actions and rewards,
simultaneously addressing channel recommendation and budget allocation.
Notably, our framework includes an automated system for integrating these tasks
into online advertising. Extensive experiments on offline and online
environments demonstrate MTORL's superiority over state-of-the-art methods.

</details>


### [570] [Minimax Optimal Two-Stage Algorithm For Moment Estimation Under Covariate Shift](https://arxiv.org/abs/2506.23453)
*Zhen Zhang,Xin Liu,Shaoli Wang,Jiaye Teng*

Main category: stat.ML

Relevance: 40.0

TL;DR: 该论文研究了协变量偏移下未知函数矩估计的最小化下界问题，提出了一种两阶段算法，并通过截断估计器解决实际中分布未知的问题。


<details>
  <summary>Details</summary>
Motivation: 协变量偏移在现实场景中常见，但相关问题的矩估计研究不足，论文旨在填补这一空白。

Method: 提出两阶段算法：先在源分布下训练最优估计器，再用似然比重加权校准矩估计器；针对分布未知问题，提出截断估计器。

Result: 理论分析表明算法达到最小化最优界（对数因子内），数值实验验证了方法的有效性。

Conclusion: 论文提出的方法在理论和实践中均表现良好，解决了协变量偏移下的矩估计问题。

Abstract: Covariate shift occurs when the distribution of input features differs
between the training and testing phases. In covariate shift, estimating an
unknown function's moment is a classical problem that remains under-explored,
despite its common occurrence in real-world scenarios. In this paper, we
investigate the minimax lower bound of the problem when the source and target
distributions are known. To achieve the minimax optimal bound (up to a
logarithmic factor), we propose a two-stage algorithm. Specifically, it first
trains an optimal estimator for the function under the source distribution, and
then uses a likelihood ratio reweighting procedure to calibrate the moment
estimator. In practice, the source and target distributions are typically
unknown, and estimating the likelihood ratio may be unstable. To solve this
problem, we propose a truncated version of the estimator that ensures double
robustness and provide the corresponding upper bound. Extensive numerical
studies on synthetic examples confirm our theoretical findings and further
illustrate the effectiveness of our proposed method.

</details>


### [571] [Sampling and Identity-Testing Without Approximate Tensorization of Entropy](https://arxiv.org/abs/2506.23456)
*William Gay,William He,Nicholas Kocurek,Ryan O'Donnell*

Main category: math.ST

Relevance: 40.0

TL;DR: 研究探讨了高维统计中满足近似熵张量化（ATE）的分布及其混合物的采样和身份测试问题，提出了快速混合的Glauber动力学方法和高效的身份测试算法。


<details>
  <summary>Details</summary>
Motivation: 高维统计中某些任务在满足ATE的分布下更易处理，但混合物分布不满足ATE，因此需要研究其采样和测试的复杂性。

Method: 1. 使用数据初始化快速混合Glauber动力学；2. 在坐标条件采样模型下设计高效身份测试算法。

Result: 1. 实现了混合物分布的快速采样；2. 解决了Blanca等人提出的开放问题，改进了原算法。

Conclusion: 混合物分布的采样和测试问题在特定条件下可高效解决，扩展了现有理论。

Abstract: Certain tasks in high-dimensional statistics become easier when the
underlying distribution satisfies a local-to-global property called approximate
tensorization of entropy (ATE). For example, the Glauber dynamics Markov chain
of an ATE distribution mixes fast and can produce approximate samples in a
small amount of time, since such a distribution satisfies a modified
log-Sobolev inequality. Moreover, identity-testing for an ATE distribution
requires few samples if the tester is given coordinate conditional access to
the unknown distribution, as shown by Blanca, Chen, \v{S}tefankovi\v{c}, and
Vigoda (COLT 2023).
  A natural class of distributions that do not satisfy ATE consists of mixtures
of (few) distributions that do satisfy ATE. We study the complexity of
identity-testing and sampling for these distributions. Our main results are the
following:
  1. We show fast mixing of Glauber dynamics from a data-based initialization,
with optimal sample complexity, for mixtures of distributions satisfying
modified log-Sobolev inequalities. This extends work of Huang, Koehler, Lee,
Mohanty, Rajaraman, Vuong, and Wu (STOC 2025, COLT 2025) for mixtures of
distributions satisfying Poincar\'e inequalities.
  2. Answering an open question posed by Blanca et al., we give efficient
identity-testers for mixtures of ATE distributions in the
coordinate-conditional sampling access model. We also give some simplifications
and improvements to the original algorithm of Blanca et al.

</details>


### [572] [Neural Langevin Machine: a local asymmetric learning rule can be creative](https://arxiv.org/abs/2506.23546)
*Zhendong Yu,Weizhong Huang,Haiping Huang*

Main category: q-bio.NC

Relevance: 40.0

TL;DR: 论文提出了一种基于神经网络固定点的生成模型——神经朗之万机，通过Boltzmann-Gibbs测度捕捉固定点，用于数据采样和学习，具有解释性和生物相关性。


<details>
  <summary>Details</summary>
Motivation: 利用神经网络的固定点存储和生成信息，探索一种解释性强且生物相关的生成模型。

Method: 通过Boltzmann-Gibbs测度捕捉神经网络的固定点，推导出神经朗之万动力学，用于采样和学习。

Result: 神经朗之万机作为一种生成模型，在电路采样和生物可塑性规则方面表现出潜力。

Conclusion: 神经朗之万机是一种有前景的生成模型，尤其在电路采样和生物可塑性规则方面具有优势。

Abstract: Fixed points of recurrent neural networks can be leveraged to store and
generate information. These fixed points can be captured by the Boltzmann-Gibbs
measure, which leads to neural Langevin dynamics that can be used for sampling
and learning a real dataset. We call this type of generative model neural
Langevin machine, which is interpretable due to its analytic form of
distribution and is simple to train. Moreover, the learning process is derived
as a local asymmetric plasticity rule, bearing biological relevance. Therefore,
one can realize a continuous sampling of creative dynamics in a neural network,
mimicking an imagination process in brain circuits. This neural Langevin
machine may be another promising generative model, at least in its strength in
circuit-based sampling and biologically plausible learning rule.

</details>


### [573] [Detect \& Score: Privacy-Preserving Misbehaviour Detection and Contribution Evaluation in Federated Learning](https://arxiv.org/abs/2506.23583)
*Marvin Xhemrishi,Alexandre Graell i Amat,Balázs Pejó*

Main category: cs.CR

Relevance: 40.0

TL;DR: 论文结合QI和FedGT方法，解决了联邦学习中安全聚合下的恶意行为检测和贡献评估问题，性能优于单独使用任一方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的安全聚合虽然保护了隐私，但增加了恶意行为检测和贡献评估的难度。现有方法（QI和FedGT）各有不足，无法同时满足需求。

Method: 结合QI和FedGT的优势，设计了一种新方法，同时实现恶意行为检测和贡献评估。

Result: 实验表明，新方法在恶意行为检测和贡献评估上的性能优于单独使用QI或FedGT。

Conclusion: 通过结合现有方法，新方法在联邦学习中实现了更全面的安全性和评估能力。

Abstract: Federated learning with secure aggregation enables private and collaborative
learning from decentralised data without leaking sensitive client information.
However, secure aggregation also complicates the detection of malicious client
behaviour and the evaluation of individual client contributions to the
learning. To address these challenges, QI (Pejo et al.) and FedGT (Xhemrishi et
al.) were proposed for contribution evaluation (CE) and misbehaviour detection
(MD), respectively. QI, however, lacks adequate MD accuracy due to its reliance
on the random selection of clients in each training round, while FedGT lacks
the CE ability. In this work, we combine the strengths of QI and FedGT to
achieve both robust MD and accurate CE. Our experiments demonstrate superior
performance compared to using either method independently.

</details>


### [574] [Overparametrized models with posterior drift](https://arxiv.org/abs/2506.23619)
*Guillaume Coqueret,Martial Laguerre*

Main category: q-fin.ST

Relevance: 40.0

TL;DR: 研究探讨了后验漂移对过参数化机器学习模型样本外预测准确性的影响，强调了在金融市场等可能发生制度变化的场景中性能损失的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于揭示数据生成过程的载荷在训练和测试样本间变化时对预测性能的影响，特别是在金融市场的制度变化背景下。

Method: 方法包括分析后验漂移对预测准确性的影响，并应用于股票溢价预测，考察不同带宽参数对模型复杂度的控制效果。

Result: 结果显示，小带宽参数下15年持有期的回报差异显著，而大带宽参数虽结果一致但风险调整后回报较低。

Conclusion: 结论建议在股票市场预测中谨慎使用大型线性模型。

Abstract: This paper investigates the impact of posterior drift on out-of-sample
forecasting accuracy in overparametrized machine learning models. We document
the loss in performance when the loadings of the data generating process change
between the training and testing samples. This matters crucially in settings in
which regime changes are likely to occur, for instance, in financial markets.
Applied to equity premium forecasting, our results underline the sensitivity of
a market timing strategy to sub-periods and to the bandwidth parameters that
control the complexity of the model. For the average investor, we find that
focusing on holding periods of 15 years can generate very heterogeneous
returns, especially for small bandwidths. Large bandwidths yield much more
consistent outcomes, but are far less appealing from a risk-adjusted return
standpoint. All in all, our findings tend to recommend cautiousness when
resorting to large linear models for stock market predictions.

</details>


### [575] [Explainable AI for Comprehensive Risk Assessment for Financial Reports: A Lightweight Hierarchical Transformer Network Approach](https://arxiv.org/abs/2506.23767)
*Xue Wen Tan,Stanley Kok*

Main category: q-fin.RM

Relevance: 40.0

TL;DR: TinyXRA是一个轻量级、可解释的基于Transformer的模型，用于从公司10-K报告中自动评估风险，结合了多种风险指标和动态注意力机制，实现了高预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖超额回报的标准差，无法区分上行和下行风险，且缺乏解释性。TinyXRA旨在提供更全面的风险评估和直观的可视化。

Method: 使用TinyBERT编码器处理长文档，结合动态注意力词云机制和三元组损失进行风险四分位数分类。

Result: 在2013-2024年数据集上，TinyXRA实现了最先进的预测准确性，并提供透明解释。

Conclusion: TinyXRA在轻量级设计下实现了高效和可解释的风险评估，具有实际应用潜力。

Abstract: Every publicly traded U.S. company files an annual 10-K report containing
critical insights into financial health and risk. We propose Tiny eXplainable
Risk Assessor (TinyXRA), a lightweight and explainable transformer-based model
that automatically assesses company risk from these reports. Unlike prior work
that relies solely on the standard deviation of excess returns (adjusted for
the Fama-French model), which indiscriminately penalizes both upside and
downside risk, TinyXRA incorporates skewness, kurtosis, and the Sortino ratio
for more comprehensive risk assessment. We leverage TinyBERT as our encoder to
efficiently process lengthy financial documents, coupled with a novel dynamic,
attention-based word cloud mechanism that provides intuitive risk visualization
while filtering irrelevant terms. This lightweight design ensures scalable
deployment across diverse computing environments with real-time processing
capabilities for thousands of financial documents which is essential for
production systems with constrained computational resources. We employ triplet
loss for risk quartile classification, improving over pairwise loss approaches
in existing literature by capturing both the direction and magnitude of risk
differences. Our TinyXRA achieves state-of-the-art predictive accuracy across
seven test years on a dataset spanning 2013-2024, while providing transparent
and interpretable risk assessments. We conduct comprehensive ablation studies
to evaluate our contributions and assess model explanations both quantitatively
by systematically removing highly attended words and sentences, and
qualitatively by examining explanation coherence. The paper concludes with
findings, practical implications, limitations, and future research directions.

</details>


### [576] [Emergent musical properties of a transformer under contrastive self-supervised learning](https://arxiv.org/abs/2506.23873)
*Yuexuan Kong,Gabriel Meseguer-Brocal,Vincent Lostanlen,Mathieu Lagrange,Romain Hennequin*

Main category: cs.SD

Relevance: 40.0

TL;DR: 论文探讨了对比自监督学习（SSL）与Transformer结合在音乐信息检索（MIR）局部任务中的潜力，挑战了传统认为对比SSL不适用的假设。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为对比SSL在局部MIR任务中效果不佳，本文旨在验证对比SSL与Transformer结合的实际能力。

Method: 使用轻量级一维视觉Transformer（ViT-1D）和简单的对比SSL（NT-Xent损失）进行训练。

Result: 序列令牌在局部任务中表现优异，且不同层捕捉了不同的音乐特征。

Conclusion: 对比SSL与Transformer结合在MIR中具有潜力，且能提供音乐解释性。

Abstract: In music information retrieval (MIR), contrastive self-supervised learning
for general-purpose representation models is effective for global tasks such as
automatic tagging. However, for local tasks such as chord estimation, it is
widely assumed that contrastively trained general-purpose self-supervised
models are inadequate and that more sophisticated SSL is necessary; e.g.,
masked modeling. Our paper challenges this assumption by revealing the
potential of contrastive SSL paired with a transformer in local MIR tasks. We
consider a lightweight vision transformer with one-dimensional patches in the
time--frequency domain (ViT-1D) and train it with simple contrastive SSL
through normalized temperature-scaled cross-entropy loss (NT-Xent). Although
NT-Xent operates only over the class token, we observe that, potentially thanks
to weight sharing, informative musical properties emerge in ViT-1D's sequence
tokens. On global tasks, the temporal average of class and sequence tokens
offers a performance increase compared to the class token alone, showing useful
properties in the sequence tokens. On local tasks, sequence tokens perform
unexpectedly well, despite not being specifically trained for. Furthermore,
high-level musical features such as onsets emerge from layer-wise attention
maps and self-similarity matrices show different layers capture different
musical dimensions. Our paper does not focus on improving performance but
advances the musical interpretation of transformers and sheds light on some
overlooked abilities of contrastive SSL paired with transformers for sequence
modeling in MIR.

</details>


### [577] [RawMal-TF: Raw Malware Dataset Labeled by Type and Family](https://arxiv.org/abs/2506.23909)
*David Bálik,Martin Jureček,Mark Stamp*

Main category: cs.CR

Relevance: 40.0

TL;DR: 该论文提出了一种基于机器学习的恶意软件分类方法，通过构建一个新型的双层标签数据集（类型和家族），并使用静态分析提取特征，展示了在多种分类任务中的高准确率。


<details>
  <summary>Details</summary>
Motivation: 解决恶意软件分类中的标签粒度不足问题，提供更细粒度的分类能力。

Method: 收集并标注恶意软件二进制文件，构建统一特征提取管道，使用Random Forest、XGBoost和SVM进行分类任务评估。

Result: 在二进制分类任务中达到98.5%以上的准确率，在有限数据条件下仍表现优异；多类分类任务中SVM表现最佳（81.1%）。

Conclusion: 双层标签数据集支持更精细的恶意软件分类，为未来研究奠定基础。

Abstract: This work addresses the challenge of malware classification using machine
learning by developing a novel dataset labeled at both the malware type and
family levels. Raw binaries were collected from sources such as VirusShare, VX
Underground, and MalwareBazaar, and subsequently labeled with family
information parsed from binary names and type-level labels integrated from
ClarAVy. The dataset includes 14 malware types and 17 malware families, and was
processed using a unified feature extraction pipeline based on static analysis,
particularly extracting features from Portable Executable headers, to support
advanced classification tasks. The evaluation was focused on three key
classification tasks. In the binary classification of malware versus benign
samples, Random Forest and XGBoost achieved high accuracy on the full datasets,
reaching 98.5% for type-based detection and 98.98% for family-based detection.
When using truncated datasets of 1,000 samples to assess performance under
limited data conditions, both models still performed strongly, achieving 97.6%
for type-based detection and 98.66% for family-based detection. For interclass
classification, which distinguishes between malware types or families, the
models reached up to 97.5% accuracy on type-level tasks and up to 93.7% on
family-level tasks. In the multiclass classification setting, which assigns
samples to the correct type or family, SVM achieved 81.1% accuracy on type
labels, while Random Forest and XGBoost reached approximately 73.4% on family
labels. The results highlight practical trade-offs between accuracy and
computational cost, and demonstrate that labeling at both the type and family
levels enables more fine-grained and insightful malware classification. The
work establishes a robust foundation for future research on advanced malware
detection and classification.

</details>


### [578] [Learning robust parameter inference and density reconstruction in flyer plate impact experiments](https://arxiv.org/abs/2506.23914)
*Evan Bell,Daniel A. Serino,Ben S. Southworth,Trevor Wilcox,Marc L. Klasky*

Main category: physics.comp-ph

Relevance: 40.0

TL;DR: 论文提出了一种基于机器学习的生成方法，用于从射线照相图像中估计物理参数，解决了传统方法无法直接获取关键状态变量的问题。


<details>
  <summary>Details</summary>
Motivation: 在物理和材料科学中，从实验观察中估计物理参数或材料性质是常见目标，但射线照相无法直接获取关键状态变量（如密度），限制了传统参数估计方法的应用。

Method: 使用机器学习方法，结合低和高冲击速度实验数据，提出生成式机器学习方法，直接从射线照相图像生成物理参数的后验分布。

Result: 方法在模拟飞板冲击实验中有效估计了EoS和压碎模型参数，并可用于流体动力学模拟中准确重建密度。

Conclusion: 该方法对模型不匹配具有鲁棒性，能在分布外噪声和未见物理现象下提供有用参数估计，为从实验射线图像估计材料性质提供了潜在突破。

Abstract: Estimating physical parameters or material properties from experimental
observations is a common objective in many areas of physics and material
science. In many experiments, especially in shock physics, radiography is the
primary means of observing the system of interest. However, radiography does
not provide direct access to key state variables, such as density, which
prevents the application of traditional parameter estimation approaches. Here
we focus on flyer plate impact experiments on porous materials, and resolving
the underlying parameterized equation of state (EoS) and crush porosity model
parameters given radiographic observation(s). We use machine learning as a tool
to demonstrate with high confidence that using only high impact velocity data
does not provide sufficient information to accurately infer both EoS and crush
model parameters, even with fully resolved density fields or a dynamic sequence
of images. We thus propose an observable data set consisting of low and high
impact velocity experiments/simulations that capture different regimes of
compaction and shock propagation, and proceed to introduce a generative machine
learning approach which produces a posterior distribution of physical
parameters directly from radiographs. We demonstrate the effectiveness of the
approach in estimating parameters from simulated flyer plate impact
experiments, and show that the obtained estimates of EoS and crush model
parameters can then be used in hydrodynamic simulations to obtain accurate and
physically admissible density reconstructions. Finally, we examine the
robustness of the approach to model mismatches, and find that the learned
approach can provide useful parameter estimates in the presence of
out-of-distribution radiographic noise and previously unseen physics, thereby
promoting a potential breakthrough in estimating material properties from
experimental radiographic images.

</details>


### [579] [Consensus-based optimization for closed-box adversarial attacks and a connection to evolution strategies](https://arxiv.org/abs/2506.24048)
*Tim Roith,Leon Bungert,Philipp Wacker*

Main category: math.OC

Relevance: 40.0

TL;DR: 本文研究了共识优化（CBO）在黑盒对抗攻击中的应用，将其与自然进化策略（NES）联系起来，并证明CBO在某些情况下优于NES和其他进化策略。


<details>
  <summary>Details</summary>
Motivation: 探讨CBO作为一种无梯度优化方法在黑盒对抗攻击中的潜力，并与现有方法（如NES）进行对比。

Method: 通过理论分析和实验研究，将CBO与NES及梯度优化方法联系起来，并评估其性能。

Result: 实验表明，尽管CBO与NES有相似之处，但在某些场景下CBO表现更优。

Conclusion: CBO在黑盒对抗攻击中具有潜力，可作为现有方法的替代或补充。

Abstract: Consensus-based optimization (CBO) has established itself as an efficient
gradient-free optimization scheme, with attractive mathematical properties,
such as mean-field convergence results for non-convex loss functions. In this
work, we study CBO in the context of closed-box adversarial attacks, which are
imperceptible input perturbations that aim to fool a classifier, without
accessing its gradient. Our contribution is to establish a connection between
the so-called consensus hopping as introduced by Riedl et al. and natural
evolution strategies (NES) commonly applied in the context of adversarial
attacks and to rigorously relate both methods to gradient-based optimization
schemes. Beyond that, we provide a comprehensive experimental study that shows
that despite the conceptual similarities, CBO can outperform NES and other
evolutionary strategies in certain scenarios.

</details>


### [580] [Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation](https://arxiv.org/abs/2506.22441)
*Lei Yang*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种基于阈值距离加权损失（TDW）的潜在张量分解模型（TDWLFT），用于处理交通数据中的缺失值和异常值问题，显著提升了预测精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统（ITS）依赖高质量的时空交通数据，但实际数据常因通信故障或传感器故障而缺失或损坏。现有潜在张量分解模型（LFT）对异常值敏感，限制了其性能。

Method: 提出了一种阈值距离加权损失（TDW）的LFT模型（TDWLFT），通过为样本分配差异化权重，降低模型对异常值的敏感性。

Result: 在两个不同城市环境的交通速度数据集上的实验表明，TDWLFT在预测精度和计算效率上均优于现有方法。

Conclusion: TDWLFT模型有效解决了交通数据中的异常值问题，提升了数据补全的性能。

Abstract: Intelligent transportation systems (ITS) rely heavily on complete and
high-quality spatiotemporal traffic data to achieve optimal performance.
Nevertheless, in real-word traffic data collection processes, issues such as
communication failures and sensor malfunctions often lead to incomplete or
corrupted datasets, thereby posing significant challenges to the advancement of
ITS. Among various methods for imputing missing spatiotemporal traffic data,
the latent factorization of tensors (LFT) model has emerged as a widely adopted
and effective solution. However, conventional LFT models typically employ the
standard L2-norm in their learning objective, which makes them vulnerable to
the influence of outliers. To overcome this limitation, this paper proposes a
threshold distance weighted (TDW) loss-incorporated Latent Factorization of
Tensors (TDWLFT) model. The proposed loss function effectively reduces the
model's sensitivity to outliers by assigning differentiated weights to
individual samples. Extensive experiments conducted on two traffic speed
datasets sourced from diverse urban environments confirm that the proposed
TDWLFT model consistently outperforms state-of-the-art approaches in terms of
both in both prediction accuracy and computational efficiency.

</details>


### [581] [Active Learning for Forecasting Severity among Patients with Post Acute Sequelae of SARS-CoV-2](https://arxiv.org/abs/2506.22444)
*Jing Wang,Amar Sra,Jeremy C. Weiss*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种基于LLM（Llama-3.1-70B-Instruct）和主动注意力网络的临床风险预测方法，用于识别PASC患者的进展事件。


<details>
  <summary>Details</summary>
Motivation: PASC的长期影响对全球医疗系统构成挑战，传统模型难以捕捉其复杂进展，需更准确的预测方法。

Method: 使用LLM处理文本时间序列数据，结合主动注意力网络和人类专家标注，预测临床风险并识别进展事件。

Result: 提出首个公开的PASC患者队列，结合LLM和主动学习，提高风险预测准确性并减少标注需求。

Conclusion: 该方法有望改善SARS-CoV-2患者的护理和决策，但研究范围较小（18例患者）。

Abstract: The long-term effects of Postacute Sequelae of SARS-CoV-2, known as PASC,
pose a significant challenge to healthcare systems worldwide. Accurate
identification of progression events, such as hospitalization and reinfection,
is essential for effective patient management and resource allocation. However,
traditional models trained on structured data struggle to capture the nuanced
progression of PASC. In this study, we introduce the first publicly available
cohort of 18 PASC patients, with text time series features based on Large
Language Model Llama-3.1-70B-Instruct and clinical risk annotated by clinical
expert. We propose an Active Attention Network to predict the clinical risk and
identify progression events related to the risk. By integrating human expertise
with active learning, we aim to enhance clinical risk prediction accuracy and
enable progression events identification with fewer number of annotation. The
ultimate goal is to improves patient care and decision-making for SARS-CoV-2
patient.

</details>


### [582] [Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning for Cyber-Physical Systems Security](https://arxiv.org/abs/2506.22445)
*Saad Alqithami*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种新型分层对抗弹性多智能体强化学习框架（HAMARL），用于提升网络物理系统的安全性，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 网络物理系统（CPS）的互联性使其易受复杂网络威胁，传统安全方法（如基于规则的入侵检测和单智能体强化学习）效果有限。

Method: HAMARL采用分层结构，包括负责子系统安全的局部智能体和全局协调器，并结合对抗训练循环以模拟和预测威胁。

Result: 实验表明，HAMARL显著提高了攻击检测准确性、缩短了响应时间，并确保了系统连续性。

Conclusion: 分层多智能体协调与对抗训练结合可有效增强下一代CPS的弹性和安全性。

Abstract: Cyber-Physical Systems play a critical role in the infrastructure of various
sectors, including manufacturing, energy distribution, and autonomous
transportation systems. However, their increasing connectivity renders them
highly vulnerable to sophisticated cyber threats, such as adaptive and zero-day
attacks, against which traditional security methods like rule-based intrusion
detection and single-agent reinforcement learning prove insufficient. To
overcome these challenges, this paper introduces a novel Hierarchical
Adversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework.
HAMARL employs a hierarchical structure consisting of local agents dedicated to
subsystem security and a global coordinator that oversees and optimizes
comprehensive, system-wide defense strategies. Furthermore, the framework
incorporates an adversarial training loop designed to simulate and anticipate
evolving cyber threats, enabling proactive defense adaptation. Extensive
experimental evaluations conducted on a simulated industrial IoT testbed
indicate that HAMARL substantially outperforms traditional multi-agent
reinforcement learning approaches, significantly improving attack detection
accuracy, reducing response times, and ensuring operational continuity. The
results underscore the effectiveness of combining hierarchical multi-agent
coordination with adversarially-aware training to enhance the resilience and
security of next-generation CPS.

</details>


### [583] [Vision Transformers for Multi-Variable Climate Downscaling: Emulating Regional Climate Models with a Shared Encoder and Multi-Decoder Architecture](https://arxiv.org/abs/2506.22447)
*Fabio Merizzi,Harilaos Loukos*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种多任务、多变量的Vision Transformer架构（1EMD），用于联合预测三个关键气候变量，优于单变量基线并提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型多为单变量预测，缺乏上下文意识和跨变量交互，限制了气候降尺度效果。

Method: 使用共享编码器和变量特定解码器的ViT架构，联合预测温度、风速和位势高度。

Result: 多变量方法实现了跨变量知识转移，性能优于单变量基线，且计算效率更高。

Conclusion: 多变量建模在高分辨率气候降尺度中有效。

Abstract: Global Climate Models (GCMs) are critical for simulating large-scale climate
dynamics, but their coarse spatial resolution limits their applicability in
regional studies. Regional Climate Models (RCMs) refine this through dynamic
downscaling, albeit at considerable computational cost and with limited
flexibility. While deep learning has emerged as an efficient data-driven
alternative, most existing studies have focused on single-variable models that
downscale one variable at a time. This approach can lead to limited contextual
awareness, redundant computation, and lack of cross-variable interaction. Our
study addresses these limitations by proposing a multi-task, multi-variable
Vision Transformer (ViT) architecture with a shared encoder and
variable-specific decoders (1EMD). The proposed architecture jointly predicts
three key climate variables: surface temperature (tas), wind speed (sfcWind),
and 500 hPa geopotential height (zg500), directly from GCM-resolution inputs,
emulating RCM-scale downscaling over Europe. We show that our multi-variable
approach achieves positive cross-variable knowledge transfer and consistently
outperforms single-variable baselines trained under identical conditions, while
also improving computational efficiency. These results demonstrate the
effectiveness of multi-variable modeling for high-resolution climate
downscaling.

</details>


### [584] [Stabilization of industrial processes with time series machine learning](https://arxiv.org/abs/2506.22502)
*Matvei Anoshin,Olga Tsurkan,Vadim Lopatkin,Leonid Fedichkin*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种由两个神经网络组成的简单流程，用于时间序列过程的稳定化，相比传统求解器，温度控制的稳定性提高了约3倍。


<details>
  <summary>Details</summary>
Motivation: 时间序列过程的稳定化在工业领域普遍存在，机器学习应用可以显著提升稳定化质量并减少计算资源需求。

Method: 采用两个神经网络（oracle predictor和optimizer）的流程，将点值优化问题转化为神经网络训练问题。

Result: 在温度控制方面，稳定性比传统求解器提高了约3倍。

Conclusion: 该方法在时间序列稳定化问题上表现出显著优势，具有实际应用潜力。

Abstract: The stabilization of time series processes is a crucial problem that is
ubiquitous in various industrial fields. The application of machine learning to
its solution can have a decisive impact, improving both the quality of the
resulting stabilization with less computational resources required. In this
work, we present a simple pipeline consisting of two neural networks: the
oracle predictor and the optimizer, proposing a substitution of the point-wise
values optimization to the problem of the neural network training, which
successfully improves stability in terms of the temperature control by about 3
times compared to ordinary solvers.

</details>


### [585] [Hierarchical Modeling and Architecture Optimization: Review and Unified Framework](https://arxiv.org/abs/2506.22621)
*Paul Saves,Edward Hallé-Hannan,Jasper Bussemaker,Youssef Diouane,Nathalie Bartoli*

Main category: cs.LG

Relevance: 30.0

TL;DR: 该论文提出了一个统一框架，用于处理混合变量输入的仿真问题，支持连续、整数和分类变量，并引入了设计空间图来捕捉变量间的层次关系。


<details>
  <summary>Details</summary>
Motivation: 解决混合变量输入在仿真问题中的挑战，如层次性、条件性和异构性，提出一个通用框架以统一现有方法。

Method: 引入设计空间图结合特征建模和图论，支持代理模型和分层核函数，实现高效建模和优化。

Result: 框架在开源工具SMT 2.0中实现，并通过贝叶斯优化在复杂系统设计（如绿色飞机架构）中验证其能力。

Conclusion: 提出的框架能有效处理复杂结构输入空间，适用于多领域仿真和优化问题。

Abstract: Simulation-based problems involving mixed-variable inputs frequently feature
domains that are hierarchical, conditional, heterogeneous, or tree-structured.
These characteristics pose challenges for data representation, modeling, and
optimization. This paper reviews extensive literature on these structured input
spaces and proposes a unified framework that generalizes existing approaches.
In this framework, input variables may be continuous, integer, or categorical.
A variable is described as meta if its value governs the presence of other
decreed variables, enabling the modeling of conditional and hierarchical
structures.
  We further introduce the concept of partially-decreed variables, whose
activation depends on contextual conditions. To capture these inter-variable
hierarchical relationships, we introduce design space graphs, combining
principles from feature modeling and graph theory. This allows the definition
of general hierarchical domains suitable for describing complex system
architectures. The framework supports the use of surrogate models over such
domains and integrates hierarchical kernels and distances for efficient
modeling and optimization. The proposed methods are implemented in the
open-source Surrogate Modeling Toolbox (SMT 2.0), and their capabilities are
demonstrated through applications in Bayesian optimization for complex system
design, including a case study in green aircraft architecture.

</details>


### [586] [Cost-effective Reduced-Order Modeling via Bayesian Active Learning](https://arxiv.org/abs/2506.22645)
*Amir Hossein Rahmati,Nathan M. Urban,Byung-Jun Yoon,Xiaoning Qian*

Main category: cs.LG

Relevance: 30.0

TL;DR: BayPOD-AL是一种基于不确定性感知的贝叶斯正交分解（POD）主动学习框架，用于从高保真全阶模型中学习降阶模型，以减少训练数据集的构建成本。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习代理方法依赖大量训练数据，限制了其在现实问题中的应用。BayPOD-AL旨在通过主动学习减少数据需求。

Method: 基于不确定性感知的贝叶斯POD方法，结合主动学习框架，选择信息量大的数据点进行训练。

Result: 在预测棒材温度演化的实验中，BayPOD-AL比其他不确定性引导的主动学习策略更有效，减少了计算成本。

Conclusion: BayPOD-AL在更高时间分辨率的数据集上表现出良好的泛化能力和效率。

Abstract: Machine Learning surrogates have been developed to accelerate solving systems
dynamics of complex processes in different science and engineering
applications. To faithfully capture governing systems dynamics, these methods
rely on large training datasets, hence restricting their applicability in
real-world problems. In this work, we propose BayPOD-AL, an active learning
framework based on an uncertainty-aware Bayesian proper orthogonal
decomposition (POD) approach, which aims to effectively learn reduced-order
models from high-fidelity full-order models representing complex systems.
Experimental results on predicting the temperature evolution over a rod
demonstrate BayPOD-AL's effectiveness in suggesting the informative data and
reducing computational cost related to constructing a training dataset compared
to other uncertainty-guided active learning strategies. Furthermore, we
demonstrate BayPOD-AL's generalizability and efficiency by evaluating its
performance on a dataset of higher temporal resolution than the training
dataset.

</details>


### [587] [Learning Stochastic Multiscale Models](https://arxiv.org/abs/2506.22655)
*Andrew F. Ilersich,Prasanth B. Nair*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出一种从观测数据中学习随机多尺度模型的方法，通过粗网格和辅助状态捕捉未解析尺度效应，使用变分推断学习参数，优于直接数值模拟和闭合模型。


<details>
  <summary>Details</summary>
Motivation: 解决多尺度动力学系统的高维状态空间计算挑战，直接从数据中学习模型。

Method: 基于变分推断的随机多尺度模型学习方法，结合粗网格和辅助状态。

Result: 学习模型在预测精度上优于直接数值模拟和闭合模型。

Conclusion: 该方法为多尺度建模提供了一种高效的数据驱动解决方案。

Abstract: The physical sciences are replete with dynamical systems that require the
resolution of a wide range of length and time scales. This presents significant
computational challenges since direct numerical simulation requires
discretization at the finest relevant scales, leading to a high-dimensional
state space. In this work, we propose an approach to learn stochastic
multiscale models in the form of stochastic differential equations directly
from observational data. Our method resolves the state on a coarse mesh while
introducing an auxiliary state to capture the effects of unresolved scales. We
learn the parameters of the multiscale model using a modern forward-solver-free
amortized variational inference method. Our approach draws inspiration from
physics-based multiscale modeling approaches, such as large-eddy simulation in
fluid dynamics, while learning directly from data. We present numerical studies
to demonstrate that our learned multiscale models achieve superior predictive
accuracy compared to direct numerical simulation and closure-type models at
equivalent resolution.

</details>


### [588] [Robust Tensor Completion via Gradient Tensor Nulclear L1-L2 Norm for Traffic Data Recovery](https://arxiv.org/abs/2506.22732)
*Hao Shu,Jicheng Li,Tianyv Lei,Lijun Sun*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种基于梯度张量L1-L2范数的鲁棒张量补全模型（RTC-GTNLN），用于处理交通数据中的缺失值和噪声问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实交通数据常因传感器故障和通信问题同时存在缺失值和噪声，现有方法无法有效处理这种双重退化问题。

Method: 引入张量L1-L2范数作为非凸秩替代，结合梯度域特征融合策略，提出RTC-GTNLN模型，充分利用全局低秩性和局部一致性。

Result: 在多个真实交通数据集上的实验表明，RTC-GTNLN在同时存在缺失值和噪声的场景中表现优于现有方法。

Conclusion: RTC-GTNLN模型有效解决了交通数据中的双重退化问题，无需权衡参数，具有更高的恢复精度。

Abstract: In real-world scenarios, spatiotemporal traffic data frequently experiences
dual degradation from missing values and noise caused by sensor malfunctions
and communication failures. Therefore, effective data recovery methods are
essential to ensure the reliability of downstream data-driven applications.
while classical tensor completion methods have been widely adopted, they are
incapable of modeling noise, making them unsuitable for complex scenarios
involving simultaneous data missingness and noise interference. Existing Robust
Tensor Completion (RTC) approaches offer potential solutions by separately
modeling the actual tensor data and noise. However, their effectiveness is
often constrained by the over-relaxation of convex rank surrogates and the
suboptimal utilization of local consistency, leading to inadequate model
accuracy. To address these limitations, we first introduce the tensor L1-L2
norm, a novel non-convex tensor rank surrogate that functions as an effective
low-rank representation tool. Leveraging an advanced feature fusion strategy,
we further develop the gradient tensor L1-L2 norm by incorporating the tensor
L1-L2 norm in the gradient domain. By integrating the gradient tensor nuclear
L1-L2 norm into the RTC framework, we propose the Robust Tensor Completion via
Gradient Tensor Nuclear L1-L2 Norm (RTC-GTNLN) model, which not only fully
exploits both global low-rankness and local consistency without trade-off
parameter, but also effectively handles the dual degradation challenges of
missing data and noise in traffic data. Extensive experiments conducted on
multiple real-world traffic datasets demonstrate that the RTC-GTNLN model
consistently outperforms existing state-of-the-art methods in complex recovery
scenarios involving simultaneous missing values and noise.

</details>


### [589] [Deep learning 40 years of human migration](https://arxiv.org/abs/2506.22821)
*Thomas Gaskin,Guy J. Abel*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种基于深度循环神经网络的新数据集，用于估计1990年至今230个国家和地区的年度移民流动和存量，并通过18个协变量学习流动模式。


<details>
  <summary>Details</summary>
Motivation: 提供更全面、高时间分辨率的移民流动数据，填补传统方法的不足。

Method: 使用深度循环神经网络（RNN）学习移民流动模式，结合地理、经济、文化等18个协变量，并通过集成网络和不确定性传播获得置信区间。

Result: 模型在未见数据上显著优于传统方法，提供更高时间分辨率的估计，并公开了所有数据和代码。

Conclusion: 该方法为移民研究提供了新工具，同时指出了数据收集需求较高的地区。

Abstract: We present a novel and detailed dataset on origin-destination annual
migration flows and stocks between 230 countries and regions, spanning the
period from 1990 to the present. Our flow estimates are further disaggregated
by country of birth, providing a comprehensive picture of migration over the
last 43 years. The estimates are obtained by training a deep recurrent neural
network to learn flow patterns from 18 covariates for all countries, including
geographic, economic, cultural, societal, and political information. The
recurrent architecture of the neural network means that the entire past can
influence current migration patterns, allowing us to learn long-range temporal
correlations. By training an ensemble of neural networks and additionally
pushing uncertainty on the covariates through the trained network, we obtain
confidence bounds for all our estimates, allowing researchers to pinpoint the
geographic regions most in need of additional data collection. We validate our
approach on various test sets of unseen data, demonstrating that it
significantly outperforms traditional methods estimating five-year flows while
delivering a significant increase in temporal resolution. The model is fully
open source: all training data, neural network weights, and training code are
made public alongside the migration estimates, providing a valuable resource
for future studies of human migration.

</details>


### [590] [Quantum Neural Networks for Wind Energy Forecasting: A Comparative Study of Performance and Scalability with Classical Models](https://arxiv.org/abs/2506.22845)
*Batuhan Hangun,Oguz Altun,Onder Eyecioglu*

Main category: cs.LG

Relevance: 30.0

TL;DR: 该论文研究了量子神经网络（QNNs）在风力涡轮机功率输出预测中的应用，发现其性能与经典方法相当甚至略优，并探讨了数据集规模和电路复杂度的影响。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源系统的普及，智能电网的需求增加，机器学习在预测电力需求和系统干扰中扮演重要角色。QNNs作为一种新兴的量子机器学习方法，可能提供更高效的解决方案。

Method: 研究评估了六种基于Z特征映射和不同ansatz结构的QNN配置，通过交叉验证和未见数据集测试其预测性能和模拟时间。

Result: QNNs的预测性能与经典方法相当，某些情况下略优，同时揭示了数据集规模和电路复杂度对性能的影响。

Conclusion: QNNs在能源领域的量子机器学习应用中具有潜力，为相关研究者提供了有价值的参考。

Abstract: Quantum Neural Networks (QNNs), a prominent approach in Quantum Machine
Learning (QML), are emerging as a powerful alternative to classical machine
learning methods. Recent studies have focused on the applicability of QNNs to
various tasks, such as time-series forecasting, prediction, and classification,
across a wide range of applications, including cybersecurity and medical
imaging. With the increased use of smart grids driven by the integration of
renewable energy systems, machine learning plays an important role in
predicting power demand and detecting system disturbances. This study provides
an in-depth investigation of QNNs for predicting the power output of a wind
turbine. We assess the predictive performance and simulation time of six QNN
configurations that are based on the Z Feature Map for data encoding and
varying ansatz structures. Through detailed cross-validation experiments and
tests on an unseen hold-out dataset, we experimentally demonstrate that QNNs
can achieve predictive performance that is competitive with, and in some cases
marginally better than, the benchmarked classical approaches. Our results also
reveal the effects of dataset size and circuit complexity on predictive
performance and simulation time. We believe our findings will offer valuable
insights for researchers in the energy domain who wish to incorporate quantum
machine learning into their work.

</details>


### [591] [Cybersecurity-Focused Anomaly Detection in Connected Autonomous Vehicles Using Machine Learning](https://arxiv.org/abs/2506.22984)
*Prathyush Kumar Reddy Lebaku,Lu Gao,Yunpeng Zhang,Zhixia Li,Yongxin Liu,Tanvir Arafin*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种基于堆叠LSTM和随机森林的异常检测方法，用于识别联网自动驾驶车辆中的异常行为，展示了模型在轨迹预测和异常检测中的有效性。


<details>
  <summary>Details</summary>
Motivation: 联网自动驾驶车辆（CAVs）易受传感器故障、网络攻击和环境干扰的影响，异常检测对保障交通安全至关重要。

Method: 通过模拟车辆行为生成数据集，使用堆叠LSTM捕捉时序依赖性和序列异常，同时部署随机森林模型提升可解释性和性能。

Result: 随机森林模型的R2为0.9830，MAE为5.746；堆叠LSTM模型的R2为0.9998，MAE为82.425，均能有效检测异常。

Conclusion: 模型在自动驾驶场景中能准确预测轨迹并检测异常，验证了方法的有效性。

Abstract: Anomaly detection in connected autonomous vehicles (CAVs) is crucial for
maintaining safe and reliable transportation networks, as CAVs can be
susceptible to sensor malfunctions, cyber-attacks, and unexpected environmental
disruptions. This study explores an anomaly detection approach by simulating
vehicle behavior, generating a dataset that represents typical and atypical
vehicular interactions. The dataset includes time-series data of position,
speed, and acceleration for multiple connected autonomous vehicles. We utilized
machine learning models to effectively identify abnormal driving patterns.
First, we applied a stacked Long Short-Term Memory (LSTM) model to capture
temporal dependencies and sequence-based anomalies. The stacked LSTM model
processed the sequential data to learn standard driving behaviors.
Additionally, we deployed a Random Forest model to support anomaly detection by
offering ensemble-based predictions, which enhanced model interpretability and
performance. The Random Forest model achieved an R2 of 0.9830, MAE of 5.746,
and a 95th percentile anomaly threshold of 14.18, while the stacked LSTM model
attained an R2 of 0.9998, MAE of 82.425, and a 95th percentile anomaly
threshold of 265.63. These results demonstrate the models' effectiveness in
accurately predicting vehicle trajectories and detecting anomalies in
autonomous driving scenarios.

</details>


### [592] [Kernel Outlier Detection](https://arxiv.org/abs/2506.22994)
*Can Hakan Dağıdır,Mia Hubert,Peter J. Rousseeuw*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种新的异常检测方法KOD，用于高维数据中的异常检测，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决高维数据中异常检测的挑战，特别是现有方法对分布假设或难以调优的超参数的依赖。

Method: 采用核变换和投影追踪方法，结合新的方向搜索集合和结果组合方式。

Result: 在三个小型数据集和四个大型基准数据集上验证了KOD的有效性。

Conclusion: KOD提供了一种灵活且轻量级的异常检测方法。

Abstract: A new anomaly detection method called kernel outlier detection (KOD) is
proposed. It is designed to address challenges of outlier detection in
high-dimensional settings. The aim is to overcome limitations of existing
methods, such as dependence on distributional assumptions or on hyperparameters
that are hard to tune. KOD starts with a kernel transformation, followed by a
projection pursuit approach. Its novelties include a new ensemble of directions
to search over, and a new way to combine results of different direction types.
This provides a flexible and lightweight approach for outlier detection. Our
empirical evaluations illustrate the effectiveness of KOD on three small
datasets with challenging structures, and on four large benchmark datasets.

</details>


### [593] [A Reinforcement Learning Approach for Optimal Control in Microgrids](https://arxiv.org/abs/2506.22995)
*Davide Salaorni,Federico Bianchi,Francesco Trovò,Marcello Restelli*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种基于强化学习（RL）的微电网能源管理优化方法，利用历史数据和数字孪生技术模拟储能系统动态，实验证明其优于基于规则的方法和其他RL基准。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源的集成增加，传统电网需要新的管理方法，微电网提供了局部控制的解决方案。本文旨在通过RL优化微电网的能源交易和存储策略。

Method: 提出了一种RL代理，利用历史能源生产、消费和市场数据，结合数字孪生技术模拟储能系统动态，并考虑退化因素。

Result: 实验结果表明，该方法优于基于规则的方法和其他RL基准，为智能微电网管理提供了稳健的解决方案。

Conclusion: 基于RL的方法在微电网能源管理中表现出色，具有实际应用的潜力。

Abstract: The increasing integration of renewable energy sources (RESs) is transforming
traditional power grid networks, which require new approaches for managing
decentralized energy production and consumption. Microgrids (MGs) provide a
promising solution by enabling localized control over energy generation,
storage, and distribution. This paper presents a novel reinforcement learning
(RL)-based methodology for optimizing microgrid energy management.
Specifically, we propose an RL agent that learns optimal energy trading and
storage policies by leveraging historical data on energy production,
consumption, and market prices. A digital twin (DT) is used to simulate the
energy storage system dynamics, incorporating degradation factors to ensure a
realistic emulation of the analysed setting. Our approach is validated through
an experimental campaign using real-world data from a power grid located in the
Italian territory. The results indicate that the proposed RL-based strategy
outperforms rule-based methods and existing RL benchmarks, offering a robust
solution for intelligent microgrid management.

</details>


### [594] [BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs](https://arxiv.org/abs/2506.23024)
*Jerry Liu,Yasa Baig,Denise Hui Jean Lee,Rajat Vadiraj Dwaraknath,Atri Rudra,Chris Ré*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出Barycentric Weight Layer (BWLer)来提升物理信息神经网络(PINNs)的精度，解决了多层感知机(MLP)在PDE求解中的精度限制问题。


<details>
  <summary>Details</summary>
Motivation: PINNs在求解偏微分方程(PDEs)时精度不足，研究目标是确定精度限制源于PDE的病态性还是MLP架构。

Method: 引入BWLer，通过重心多项式插值建模PDE解，可叠加在MLP上或完全替代MLP。

Result: BWLer显著提升精度，在五个基准PDE中，RMSE最高提升1800倍，甚至接近机器精度。

Conclusion: BWLer结合了PINNs的灵活性和经典谱求解器的精度，为高精度PDE求解提供了实用路径。

Abstract: Physics-informed neural networks (PINNs) offer a flexible way to solve
partial differential equations (PDEs) with machine learning, yet they still
fall well short of the machine-precision accuracy many scientific tasks demand.
In this work, we investigate whether the precision ceiling comes from the
ill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP)
architecture. We introduce the Barycentric Weight Layer (BWLer), which models
the PDE solution through barycentric polynomial interpolation. A BWLer can be
added on top of an existing MLP (a BWLer-hat) or replace it completely
(explicit BWLer), cleanly separating how we represent the solution from how we
take derivatives for the PDE loss. Using BWLer, we identify fundamental
precision limitations within the MLP: on a simple 1-D interpolation task, even
MLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above
float64 machine precision -- before any PDE terms are added. In PDE learning,
adding a BWLer lifts this ceiling and exposes a tradeoff between achievable
accuracy and the conditioning of the PDE loss. For linear PDEs we fully
characterize this tradeoff with an explicit error decomposition and navigate it
during training with spectral derivatives and preconditioning. Across five
benchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for
convection, 10x for reaction, and 1800x for wave equations while remaining
compatible with first-order optimizers. Replacing the MLP entirely lets an
explicit BWLer reach near-machine-precision on convection, reaction, and wave
problems (up to 10 billion times better than prior results) and match the
performance of standard PINNs on stiff Burgers' and irregular-geometry Poisson
problems. Together, these findings point to a practical path for combining the
flexibility of PINNs with the precision of classical spectral solvers.

</details>


### [595] [Double-Diffusion: Diffusion Conditioned Diffusion Probabilistic Model For Air Quality Prediction](https://arxiv.org/abs/2506.23053)
*Hanlin Dong,Arian Prabowo,Hao Xue,Flora D. Salim*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种名为Double-Diffusion的新型扩散概率模型，结合已知物理原理和随机性进行空气质量预测，显著提升了预测性能并减少了推理时间。


<details>
  <summary>Details</summary>
Motivation: 空气质量预测具有时空复杂性和不确定性，现有模型难以平衡确定性和随机性。

Method: 提出Double-Diffusion模型，利用物理原理作为条件生成方法，结合图像恢复的采样策略和新去噪架构。

Result: 在多个评估场景中表现最佳，推理时间减少30%-50%，CRPS提升3%-12%。

Conclusion: Double-Diffusion在空气质量预测中实现了确定性与随机性的有效平衡，具有显著优势。

Abstract: Air quality prediction is a challenging forecasting task due to its
spatio-temporal complexity and the inherent dynamics as well as uncertainty.
Most of the current models handle these two challenges by applying Graph Neural
Networks or known physics principles, and quantifying stochasticity through
probabilistic networks like Diffusion models. Nevertheless, finding the right
balancing point between the certainties and uncertainties remains an open
question. Therefore, we propose Double-Diffusion, a novel diffusion
probabilistic model that harnesses the power of known physics to guide air
quality forecasting with stochasticity. To the best of our knowledge, while
precedents have been made of using conditional diffusion models to predict air
pollution, this is the first attempt to use physics as a conditional generative
approach for air quality prediction. Along with a sampling strategy adopted
from image restoration and a new denoiser architecture, Double-Diffusion ranks
first in most evaluation scenarios across two real-life datasets compared with
other probabilistic models, it also cuts inference time by 50% to 30% while
enjoying an increase between 3-12% in Continuous Ranked Probabilistic Score
(CRPS).

</details>


### [596] [ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural Networks](https://arxiv.org/abs/2402.09146)
*Muhammad Kashif,Muhammad Shafique*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种新型框架ResQuNNs，通过引入可训练的量子卷积层和残差学习，解决了传统量子卷积层梯度难以访问的问题，显著提升了量子神经网络的性能。


<details>
  <summary>Details</summary>
Motivation: 传统量子卷积层缺乏适应性，限制了量子神经网络的潜力。本研究旨在通过可训练层和残差连接解决梯度访问问题。

Method: 提出ResQuNNs架构，利用残差学习在量子卷积层间添加跳跃连接，优化梯度流动。并通过实验确定了残差块的最佳配置。

Result: 实验表明，残差块的战略放置显著提升了训练效率，为量子深度学习提供了理论和实践上的新方向。

Conclusion: ResQuNNs在量子深度学习领域迈出了重要一步，为量子计算应用开辟了新途径。

Abstract: In this paper, we present a novel framework for enhancing the performance of
Quanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional
layers and addressing the critical challenges associated with them. Traditional
quanvolutional layers, although beneficial for feature extraction, have largely
been static, offering limited adaptability. Unlike state-of-the-art, our
research overcomes this limitation by enabling training within these layers,
significantly increasing the flexibility and potential of QuNNs. However, the
introduction of multiple trainable quanvolutional layers induces complexities
in gradient-based optimization, primarily due to the difficulty in accessing
gradients across these layers. To resolve this, we propose a novel
architecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging
the concept of residual learning, which facilitates the flow of gradients by
adding skip connections between layers. By inserting residual blocks between
quanvolutional layers, we ensure enhanced gradient access throughout the
network, leading to improved training performance. Moreover, we provide
empirical evidence on the strategic placement of these residual blocks within
QuNNs. Through extensive experimentation, we identify an efficient
configuration of residual blocks, which enables gradients across all the layers
in the network that eventually results in efficient training. Our findings
suggest that the precise location of residual blocks plays a crucial role in
maximizing the performance gains in QuNNs. Our results mark a substantial step
forward in the evolution of quantum deep learning, offering new avenues for
both theoretical development and practical quantum computing applications.

</details>


### [597] [maneuverRecognition -- A Python package for Timeseries Classification in the domain of Vehicle Telematics](https://arxiv.org/abs/2506.23147)
*Jonathan Schuster,Fabian Transchel*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一个名为maneuverRecognition的Python包，用于驾驶行为识别任务的数据预处理、建模和评估，并包含一个可修改的LSTM网络结构。


<details>
  <summary>Details</summary>
Motivation: 驾驶行为识别在车辆远程信息处理中具有重要意义，可用于个性化保险政策、提高道路安全和减少事故成本。当前缺乏快速实现数据转换和模型构建的工具，因此开发了maneuverRecognition包以满足这一需求。

Method: 开发了一个Python包，提供数据预处理、建模和评估功能，并内置了一个可修改的LSTM网络结构。通过智能手机传感器记录的三人实际驾驶数据进行了演示。

Result: 实现了驾驶行为识别任务的数据处理和模型构建功能，并验证了其在实际数据上的应用。

Conclusion: maneuverRecognition包为驾驶行为识别任务提供了实用的工具，填补了现有研究的空白。

Abstract: In the domain of vehicle telematics the automated recognition of driving
maneuvers is used to classify and evaluate driving behaviour. This not only
serves as a component to enhance the personalization of insurance policies, but
also to increase road safety, reduce accidents and the associated costs as well
as to reduce fuel consumption and support environmentally friendly driving. In
this context maneuver recognition technically requires a continuous application
of time series classification which poses special challenges to the transfer,
preprocessing and storage of telematic sensor data, the training of predictive
models, and the prediction itself. Although much research has been done in the
field of gathering relevant data or regarding the methods to build predictive
models for the task of maneuver recognition, there is a practical need for
python packages and functions that allow to quickly transform data into the
required structure as well as to build and evaluate such models. The
maneuverRecognition package was therefore developed to provide the necessary
functions for preprocessing, modelling and evaluation and also includes a ready
to use LSTM based network structure that can be modified. The implementation of
the package is demonstrated using real driving data of three different persons
recorded via smartphone sensors.

</details>


### [598] [Efficient Algorithms for Learning and Compressing Monophonic Halfspaces in Graphs](https://arxiv.org/abs/2506.23186)
*Marco Bressan,Victor Chepoi,Emmanuel Esposito,Maximilian Thiessen*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文研究了图顶点上的单调半空间概念，提出了基于2-SAT的分解定理，实现了高效的算法解决教学、主动学习和在线学习问题，并提供了多项式时间经验风险最小化算法。


<details>
  <summary>Details</summary>
Motivation: 探索图的单调半空间概念及其在机器学习中的应用，解决现有方法中的计算复杂性问题。

Method: 提出基于2-SAT的分解定理，将单调半空间表示为顶点子集的不交并，并设计高效算法。

Result: 实现了多项式时间经验风险最小化算法，并提供了高效的样本压缩方案。

Conclusion: 单调半空间在可学习性上表现优异，与测地半空间形成鲜明对比。

Abstract: Abstract notions of convexity over the vertices of a graph, and corresponding
notions of halfspaces, have recently gained attention from the machine learning
community. In this work we study monophonic halfspaces, a notion of graph
halfspaces defined through closure under induced paths. Our main result is a
$2$-satisfiability based decomposition theorem, which allows one to represent
monophonic halfspaces as a disjoint union of certain vertex subsets. Using this
decomposition, we achieve efficient and (nearly) optimal algorithms for various
learning problems, such as teaching, active, and online learning. Most notably,
we obtain a polynomial-time algorithm for empirical risk minimization.
Independently of the decomposition theorem, we obtain an efficient, stable, and
proper sample compression scheme. This makes monophonic halfspaces efficiently
learnable with proper learners and linear error rate $1/\varepsilon$ in the
realizable PAC setting. Our results answer open questions from the literature,
and show a stark contrast with geodesic halfspaces, for which most of the said
learning problems are NP-hard.

</details>


### [599] [External Data-Enhanced Meta-Representation for Adaptive Probabilistic Load Forecasting](https://arxiv.org/abs/2506.23201)
*Haoran Li,Muhao Guo,Marija Ilic,Yang Weng,Guangchun Ruan*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种基于超网络和混合专家机制的新框架M2oE2，用于动态适应外部数据的住宅负荷预测，显著提升了准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将外部因素（如天气、日历效应和定价）作为额外输入，忽略了其异质性，限制了有用信息的提取。

Method: 设计了一个元表示框架，利用超网络动态调整基础深度学习模型的参数，并集成混合专家机制以提高效率和鲁棒性。

Result: M2oE2在多种负荷数据集上显著优于现有方法，准确性和鲁棒性均有提升。

Conclusion: 外部数据应作为元知识动态调整模型，M2oE2框架为此提供了有效解决方案。

Abstract: Accurate residential load forecasting is critical for power system
reliability with rising renewable integration and demand-side flexibility.
However, most statistical and machine learning models treat external factors,
such as weather, calendar effects, and pricing, as extra input, ignoring their
heterogeneity, and thus limiting the extraction of useful external information.
We propose a paradigm shift: external data should serve as meta-knowledge to
dynamically adapt the forecasting model itself. Based on this idea, we design a
meta-representation framework using hypernetworks that modulate selected
parameters of a base Deep Learning (DL) model in response to external
conditions. This provides both expressivity and adaptability. We further
integrate a Mixture-of-Experts (MoE) mechanism to enhance efficiency through
selective expert activation, while improving robustness by filtering redundant
external inputs. The resulting model, dubbed as a Meta Mixture of Experts for
External data (M2oE2), achieves substantial improvements in accuracy and
robustness with limited additional overhead, outperforming existing
state-of-the-art methods in diverse load datasets. The dataset and source code
are publicly available at
https://github.com/haorandd/M2oE2\_load\_forecast.git.

</details>


### [600] [A case for data valuation transparency via DValCards](https://arxiv.org/abs/2506.23349)
*Keziah Naggita,Julienne LaChance*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文指出数据估值方法存在偏见和不稳定性，并提出DValCards框架以提高透明度和减少滥用。


<details>
  <summary>Details</summary>
Motivation: 研究数据估值方法在数据市场和机器学习中的公平性和稳定性问题。

Method: 分析了9个表格分类数据集和6种数据估值方法，探讨预处理技术、子采样和少数群体数据估值的影响。

Result: 发现数据估值方法对预处理敏感，可能加剧类别不平衡，并低估少数群体数据的价值。

Conclusion: 提倡提高数据估值的透明度，并引入DValCards框架以减少滥用。

Abstract: Following the rise in popularity of data-centric machine learning (ML),
various data valuation methods have been proposed to quantify the contribution
of each datapoint to desired ML model performance metrics (e.g., accuracy).
Beyond the technical applications of data valuation methods (e.g., data
cleaning, data acquisition, etc.), it has been suggested that within the
context of data markets, data buyers might utilize such methods to fairly
compensate data owners. Here we demonstrate that data valuation metrics are
inherently biased and unstable under simple algorithmic design choices,
resulting in both technical and ethical implications. By analyzing 9 tabular
classification datasets and 6 data valuation methods, we illustrate how (1)
common and inexpensive data pre-processing techniques can drastically alter
estimated data values; (2) subsampling via data valuation metrics may increase
class imbalance; and (3) data valuation metrics may undervalue underrepresented
group data. Consequently, we argue in favor of increased transparency
associated with data valuation in-the-wild and introduce the novel Data
Valuation Cards (DValCards) framework towards this aim. The proliferation of
DValCards will reduce misuse of data valuation metrics, including in data
pricing, and build trust in responsible ML systems.

</details>


### [601] [Reconciling Attribute and Structural Anomalies for Improved Graph Anomaly Detection](https://arxiv.org/abs/2506.23469)
*Chunjing Xiao,Jiahui Lu,Xovee Xu,Fan Zhou,Tianshu Xie,Wei Lu,Lifeng Xu*

Main category: cs.LG

Relevance: 30.0

TL;DR: TripleAD是一个基于互蒸馏的三通道图异常检测框架，通过三个模块分别检测属性、结构和混合异常，解决了现有方法在两类异常检测中的性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法在同时检测属性和结构异常时存在性能问题，TripleAD旨在通过多模块协作解决这一问题。

Method: TripleAD包含三个模块：多尺度属性估计模块、链接增强结构估计模块和属性混合曲率模块，并通过互蒸馏策略促进模块协作。

Result: 实验表明TripleAD在检测多种异常时优于基线方法。

Conclusion: TripleAD通过多模块协作和互蒸馏策略，有效提升了图异常检测的性能。

Abstract: Graph anomaly detection is critical in domains such as healthcare and
economics, where identifying deviations can prevent substantial losses.
Existing unsupervised approaches strive to learn a single model capable of
detecting both attribute and structural anomalies. However, they confront the
tug-of-war problem between two distinct types of anomalies, resulting in
suboptimal performance. This work presents TripleAD, a mutual
distillation-based triple-channel graph anomaly detection framework. It
includes three estimation modules to identify the attribute, structural, and
mixed anomalies while mitigating the interference between different types of
anomalies. In the first channel, we design a multiscale attribute estimation
module to capture extensive node interactions and ameliorate the over-smoothing
issue. To better identify structural anomalies, we introduce a link-enhanced
structure estimation module in the second channel that facilitates information
flow to topologically isolated nodes. The third channel is powered by an
attribute-mixed curvature, a new indicator that encapsulates both attribute and
structural information for discriminating mixed anomalies. Moreover, a mutual
distillation strategy is introduced to encourage communication and
collaboration between the three channels. Extensive experiments demonstrate the
effectiveness of the proposed TripleAD model against strong baselines.

</details>


### [602] [A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data](https://arxiv.org/abs/2506.23629)
*Xin Liao,Bing Yang,Cai Yu*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种基于卷积神经网络（CNN）的非线性低秩表示模型（NLR），用于填补水质数据中的缺失值，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 水质数据因传感器故障和通信延迟常出现高维稀疏缺失，传统方法难以捕捉潜在动态和深层特征。

Method: 利用CNN融合时间特征和提取非线性交互与局部模式，实现多维信息的深度融合。

Result: 在三个真实水质数据集上，NLR模型在估计精度上显著优于现有最先进的数据填补模型。

Conclusion: NLR为复杂动态环境中的水质监测数据处理提供了有效方法。

Abstract: The integrity of Water Quality Data (WQD) is critical in environmental
monitoring for scientific decision-making and ecological protection. However,
water quality monitoring systems are often challenged by large amounts of
missing data due to unavoidable problems such as sensor failures and
communication delays, which further lead to water quality data becoming
High-Dimensional and Sparse (HDS). Traditional data imputation methods are
difficult to depict the potential dynamics and fail to capture the deep data
features, resulting in unsatisfactory imputation performance. To effectively
address the above issues, this paper proposes a Nonlinear Low-rank
Representation model (NLR) with Convolutional Neural Networks (CNN) for
imputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing
temporal features to model the temporal dependence of data between time slots,
and b) Extracting nonlinear interactions and local patterns to mine
higher-order relationships features and achieve deep fusion of multidimensional
information. Experimental studies on three real water quality datasets
demonstrate that the proposed model significantly outperforms existing
state-of-the-art data imputation models in terms of estimation accuracy. It
provides an effective approach for handling water quality monitoring data in
complex dynamic environments.

</details>


### [603] [Adaptive Out-of-Control Point Pattern Detection in Sequential Random Finite Set Observations](https://arxiv.org/abs/2506.23802)
*Konstantinos Bourazas,Savvas Papaioannou,Panayiotis Kolios*

Main category: cs.LG

Relevance: 30.0

TL;DR: 提出了一种针对序列随机有限集观测的自适应异常检测框架，通过检测数据生成过程的统计行为偏差区分正常与异常数据。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在线学习数据生成过程的正常行为并动态适应行为变化的异常检测方法，以准确识别异常点模式。

Method: 引入了一种新的随机有限集后验分布类别（Power Discounting Posteriors），通过新颖的预测后验密度函数实现数据系统性变化的适应和异常检测。

Result: 通过广泛的定性和定量模拟实验验证了所提方法的有效性。

Conclusion: 该框架能够有效区分正常与异常数据，并适应数据行为的变化。

Abstract: In this work we introduce a novel adaptive anomaly detection framework
specifically designed for monitoring sequential random finite set (RFS)
observations. Our approach effectively distinguishes between In-Control data
(normal) and Out-Of-Control data (anomalies) by detecting deviations from the
expected statistical behavior of the process. The primary contributions of this
study include the development of an innovative RFS-based framework that not
only learns the normal behavior of the data-generating process online but also
dynamically adapts to behavioral shifts to accurately identify abnormal point
patterns. To achieve this, we introduce a new class of RFS-based posterior
distributions, named Power Discounting Posteriors (PD), which facilitate
adaptation to systematic changes in data while enabling anomaly detection of
point pattern data through a novel predictive posterior density function. The
effectiveness of the proposed approach is demonstrated by extensive qualitative
and quantitative simulation experiments.

</details>


### [604] [Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System](https://arxiv.org/abs/2506.23923)
*Miguel Camacho-Sánchez,Fernando García-Torres,Jesper John Lisegaard,Rocío del Amor,Sankhya Mohanty,Valery Naranjo*

Main category: cs.LG

Relevance: 30.0

TL;DR: 论文提出了一种基于强化学习（RL）的策略，用于控制树脂注入过程中的流动动态，以提高复合材料制造的均匀性和质量。


<details>
  <summary>Details</summary>
Motivation: 树脂注入（RI）和树脂传递模塑（RTM）是制造高性能纤维增强复合材料的关键工艺，但树脂流动动态的控制对均匀浸渍至关重要。

Method: 使用近端策略优化（PPO）在部分可观测环境中同步树脂流动前沿，通过过程模拟建立RL策略。

Result: RL方法有效实现了流动收敛，展示了其在改善工艺控制和产品质量方面的潜力。

Conclusion: 强化学习方法在复合材料制造中具有应用前景，能够优化树脂流动控制。

Abstract: Resin infusion (RI) and resin transfer moulding (RTM) are critical processes
for the manufacturing of high-performance fibre-reinforced polymer composites,
particularly for large-scale applications such as wind turbine blades.
Controlling the resin flow dynamics in these processes is critical to ensure
the uniform impregnation of the fibre reinforcements, thereby preventing
residual porosities and dry spots that impact the consequent structural
integrity of the final component. This paper presents a reinforcement learning
(RL) based strategy, established using process simulations, for synchronising
the different resin flow fronts in an infusion scenario involving two resin
inlets and a single outlet. Using Proximal Policy Optimisation (PPO), our
approach addresses the challenge of managing the fluid dynamics in a partially
observable environment. The results demonstrate the effectiveness of the RL
approach in achieving an accurate flow convergence, highlighting its potential
towards improving process control and product quality in composites
manufacturing.

</details>


### [605] [UMA: A Family of Universal Models for Atoms](https://arxiv.org/abs/2506.23971)
*Brandon M. Wood,Misko Dzamba,Xiang Fu,Meng Gao,Muhammed Shuaibi,Luis Barroso-Luque,Kareem Abdelmaqsoud,Vahe Gharakhanyan,John R. Kitchin,Daniel S. Levine,Kyle Michel,Anuroop Sriram,Taco Cohen,Abhishek Das,Ammar Rizvi,Sushree Jagriti Sahoo,Zachary W. Ulissi,C. Lawrence Zitnick*

Main category: cs.LG

Relevance: 30.0

TL;DR: Meta FAIR推出通用原子模型UMA，通过大规模数据和新型架构设计，实现快速、准确的计算，适用于化学和材料科学的多领域应用。


<details>
  <summary>Details</summary>
Motivation: 解决原子模拟中快速准确计算的需求，推动化学和材料科学领域的应用，如药物发现和能源存储。

Method: 训练基于5亿个3D原子结构的数据集，采用混合线性专家架构，开发经验缩放定律以优化模型容量与数据规模的关系。

Result: UMA模型在多个领域应用中表现优异，无需微调即可媲美或超越专用模型。

Conclusion: UMA模型为原子模拟提供了高效、通用的解决方案，并开源代码和权重以促进社区发展。

Abstract: The ability to quickly and accurately compute properties from atomic
simulations is critical for advancing a large number of applications in
chemistry and materials science including drug discovery, energy storage, and
semiconductor manufacturing. To address this need, Meta FAIR presents a family
of Universal Models for Atoms (UMA), designed to push the frontier of speed,
accuracy, and generalization. UMA models are trained on half a billion unique
3D atomic structures (the largest training runs to date) by compiling data
across multiple chemical domains, e.g. molecules, materials, and catalysts. We
develop empirical scaling laws to help understand how to increase model
capacity alongside dataset size to achieve the best accuracy. The UMA small and
medium models utilize a novel architectural design we refer to as mixture of
linear experts that enables increasing model capacity without sacrificing
speed. For example, UMA-medium has 1.4B parameters but only ~50M active
parameters per atomic structure. We evaluate UMA models on a diverse set of
applications across multiple domains and find that, remarkably, a single model
without any fine-tuning can perform similarly or better than specialized
models. We are releasing the UMA code, weights, and associated data to
accelerate computational workflows and enable the community to continue to
build increasingly capable AI models.

</details>


### [606] [The Jacobian and Hessian of the Kullback-Leibler Divergence between Multivariate Gaussian Distributions (Technical Report)](https://arxiv.org/abs/2506.23996)
*Juan Maroñas*

Main category: cs.LG

Relevance: 30.0

TL;DR: 本文展示了如何通过一阶和二阶微分计算两个多元高斯分布之间Kullback-Leibler散度的Jacobian和Hessian矩阵。


<details>
  <summary>Details</summary>
Motivation: 提供一种基于微分理论的方法，计算多元高斯分布间Kullback-Leibler散度的Jacobian和Hessian矩阵，旨在教学和详细推导。

Method: 基于一阶和二阶微分理论，结合文献中的推导技巧，分步详细计算Jacobian和Hessian矩阵。

Result: 提供了计算多元高斯分布间Kullback-Leibler散度Jacobian和Hessian矩阵的具体方法和详细推导过程。

Conclusion: 本文为理解和计算多元高斯分布间Kullback-Leibler散度的Jacobian和Hessian矩阵提供了教学性强的详细推导。

Abstract: This document shows how to obtain the Jacobian and Hessian matrices of the
Kullback-Leibler divergence between two multivariate Gaussian distributions,
using the first and second-order differentials. The presented derivations are
based on the theory presented by \cite{magnus99}. I've also got great
inspiration from some of the derivations in \cite{minka}.
  Since I pretend to be at most didactic, the document is split into a summary
of results and detailed derivations on each of the elements involved, with
specific references to the tricks used in the derivations, and to many of the
underlying concepts.

</details>


### [607] [Arnoldi Singular Vector perturbations for machine learning weather prediction](https://arxiv.org/abs/2506.22450)
*Jens Winkler,Michael Denhard*

Main category: physics.ao-ph

Relevance: 30.0

TL;DR: 论文探讨了机器学习天气预测（MLWP）对初始条件误差的敏感性，提出了一种无需线性或伴随模型的Arnoldi-SV方法，适用于数值天气预报和MLWP。


<details>
  <summary>Details</summary>
Motivation: 天气预测存在不确定性，需要可靠的概率信息支持决策。研究旨在通过分析初始条件误差对MLWP的影响，提升预测可靠性。

Method: 提出Arnoldi-SV（A-SV）方法，通过迭代应用预测模型生成扰动状态，构建Krylov子空间，近似局部误差增长。

Result: A-SV成功为24小时Pangu Weather模型找到动态有意义的扰动模式，可用于初始化MLWP集合。

Conclusion: A-SV方法有效且通用，能将随机噪声转化为基于参考状态的扰动，类似于去噪过程。

Abstract: Since weather forecasts are fundamentally uncertain, reliable decision making
requires information on the likelihoods of future weather scenarios. We explore
the sensitivity of machine learning weather prediction (MLWP) using the 24h
Pangu Weather ML model of Huawei to errors in the initial conditions with a
specific kind of Singular Vector (SV) perturbations. Our Arnoldi-SV (A-SV)
method does not need linear nor adjoint model versions and is applicable to
numerical weather prediction (NWP) as well as MLWP. It observes error growth
within a given optimization time window by iteratively applying a forecast
model to perturbed model states. This creates a Krylov subspace, implicitly
based on a matrix operator, which approximates the local error growth. Each
iteration adds new dimensions to the Krylov space and its leading right SVs are
expected to turn into directions of growing errors. We show that A-SV indeed
finds dynamically meaningful perturbation patterns for the 24h Pangu Weather
model, which grow right from the beginning of the forecast rollout. These
perturbations describe local unstable modes and could be a basis to initialize
MLWP ensembles. Since we start A-SV from random noise perturbations, the
algorithm transforms noise into perturbations conditioned on a given reference
state - a process that is akin to the denoising process of the generic
diffusion based ML model of GenCast, therefor we briefly discuss similarities
and differences.

</details>


### [608] [Microelectrode Signal Dynamics as Biomarkers of Subthalamic Nucleus Entry on Deep Brain Stimulation: A Nonlinear Feature Approach](https://arxiv.org/abs/2506.22454)
*Ana Luiza S. Tavares,Artur Pedro M. Neto,Francinaldo L. Gomes,Paul Rodrigo dos Reis,Arthur G. da Silva,Antonio P. Junior,Bruno D. Gomes*

Main category: eess.SP

Relevance: 30.0

TL;DR: 论文提出了一种基于非线性动力学和熵指标的定量框架，用于分类深部脑刺激手术中STN内外的神经活动，提高了定位准确性。


<details>
  <summary>Details</summary>
Motivation: 当前深部脑刺激手术中STN的定位依赖主观信号特征解释，缺乏定量方法。

Method: 使用非线性动力学和熵指标提取特征，结合监督分类器（如Extra Trees）进行模型训练和评估。

Result: 结合熵和非线性特征的Extra Trees模型表现最佳（F1=0.902，ROC AUC=0.887），并在测试集上验证了泛化能力（F1=0.922，ROC AUC=0.941）。

Conclusion: 非线性与熵特征可支持实时数据驱动的DBS手术决策。

Abstract: Accurate intraoperative localization of the subthalamic nucleus (STN) is
essential for the efficacy of Deep Brain Stimulation (DBS) in patients with
Parkinson's disease. While microelectrode recordings (MERs) provide rich
electrophysiological information during DBS electrode implantation, current
localization practices often rely on subjective interpretation of signal
features. In this study, we propose a quantitative framework that leverages
nonlinear dynamics and entropy-based metrics to classify neural activity
recorded inside versus outside the STN. MER data from three patients were
preprocessed using a robust artifact correction pipeline, segmented, and
labelled based on surgical annotations. A comprehensive set of recurrence
quantification analysis, nonlinear, and entropy features were extracted from
each segment. Multiple supervised classifiers were trained on every combination
of feature domains using stratified 10-fold cross-validation, followed by
statistical comparison using paired Wilcoxon signed-rank tests with
Holm-Bonferroni correction. The combination of entropy and nonlinear features
yielded the highest discriminative power, and the Extra Trees classifier
emerged as the best model with a cross-validated F1-score of 0.902+/-0.027 and
ROC AUC of 0.887+/-0.055. Final evaluation on a 20% hold-out test set confirmed
robust generalization (F1= 0.922, ROC AUC = 0.941). These results highlight the
potential of nonlinear and entropy signal descriptors in supporting real-time,
data-driven decision-making during DBS surgeries

</details>


### [609] [Data Normalization Strategies for EEG Deep Learning](https://arxiv.org/abs/2506.22455)
*Dung Truong,Arnaud Delorme*

Main category: eess.SP

Relevance: 30.0

TL;DR: 论文研究了EEG深度学习中归一化策略对监督学习和自监督学习任务的影响，发现不同任务需要不同的归一化方法。


<details>
  <summary>Details</summary>
Motivation: 随着自监督学习在EEG深度学习中的应用，传统归一化策略是否适用成为问题，需要探索任务特定的最优归一化方法。

Method: 系统评估了归一化粒度（记录级vs窗口级）和范围（跨通道vs通道内）对监督和自监督任务的影响，使用Healthy Brain Network数据集。

Result: 监督任务中窗口级通道内归一化效果最佳，而自监督任务中窗口级跨通道或最小归一化更有效。

Conclusion: 归一化策略需根据任务类型定制，无通用方法适用于所有学习场景。

Abstract: Normalization is a critical yet often overlooked component in the
preprocessing pipeline for EEG deep learning applications. The rise of
large-scale pretraining paradigms such as self-supervised learning (SSL)
introduces a new set of tasks whose nature is substantially different from
supervised training common in EEG deep learning applications. This raises new
questions about optimal normalization strategies for the applicable task. In
this study, we systematically evaluate the impact of normalization granularity
(recording vs. window level) and scope (cross-channel vs. within-channel) on
both supervised (age and gender prediction) and self-supervised (Contrastive
Predictive Coding) tasks. Using high-density resting-state EEG from 2,836
subjects in the Healthy Brain Network dataset, we show that optimal
normalization strategies differ significantly between training paradigms.
Window-level within-channel normalization yields the best performance in
supervised tasks, while minimal or cross-channel normalization at the window
level is more effective for SSL. These results underscore the necessity of
task-specific normalization choices and challenge the assumption that a
universal normalization strategy can generalize across learning settings. Our
findings provide practical insights for developing robust EEG deep learning
pipelines as the field shifts toward large-scale, foundation model training.

</details>


### [610] [Zero-Shot EEG-to-Gait Decoding via Phase-Aware Representation Learning](https://arxiv.org/abs/2506.22488)
*Xi Fu,Weibang Jiang,Rui Liu,Gernot R. Müller-Putz,Cuntai Guan*

Main category: eess.SP

Relevance: 30.0

TL;DR: NeuroDyGait是一个基于EEG信号的步态解码框架，通过对比学习和领域建模实现跨被试零样本预测。


<details>
  <summary>Details</summary>
Motivation: 解决EEG信号解码中的因果性和变异性问题，推动BCI应用。

Method: 结合对比表示学习和关系领域建模，引入多周期步态重建目标。

Result: 在跨被试步态解码中表现优异，支持零样本预测和相位检测。

Conclusion: 关系领域学习有助于BCI的可扩展和无目标部署。

Abstract: Accurate decoding of lower-limb motion from EEG signals is essential for
advancing brain-computer interface (BCI) applications in movement intent
recognition and control. However, challenges persist in achieving causal,
phase-consistent predictions and in modeling both inter- and intra-subject
variability. To address these issues, we propose NeuroDyGait, a
domain-generalizable EEG-to-motion decoding framework that leverages structured
contrastive representation learning and relational domain modeling. The
proposed method employs relative contrastive learning to achieve semantic
alignment between EEG and motion embeddings. Furthermore, a multi-cycle gait
reconstruction objective is introduced to enforce temporal coherence and
maintain biomechanical consistency. To promote inter-session generalization,
during fine-tuning, a domain dynamic decoding mechanism adaptively assigns
session-specific prediction heads and learns to mix their outputs based on
inter-session relationships. NeuroDyGait enables zero-shot motion prediction
for unseen individuals without requiring adaptation and achieves superior
performance in cross-subject gait decoding on benchmark datasets. Additionally,
it demonstrates strong phase-detection capabilities even without explicit phase
supervision during training. These findings highlight the potential of
relational domain learning in enabling scalable, target-free deployment of
BCIs.

</details>


### [611] [Spectral Bias in Variational Quantum Machine Learning](https://arxiv.org/abs/2506.22555)
*Callum Duffy,Marcin Jastrzebski*

Main category: quant-ph

Relevance: 30.0

TL;DR: 研究了量子机器学习中的频谱偏差现象，发现参数化量子电路（PQCs）中的频谱偏差源于傅里叶系数的冗余性，并探讨了数据编码方案、参数初始化规模和纠缠结构对学习能力的影响。


<details>
  <summary>Details</summary>
Motivation: 探索量子机器学习中频谱偏差的成因及其对模型训练的影响，以优化量子电路的设计和性能。

Method: 通过理论分析和实验验证，研究PQCs中傅里叶系数的冗余性及其与梯度大小的关系，并比较不同编码方案和设计选择的效果。

Result: 发现傅里叶系数的冗余性与梯度大小强相关，且冗余性高的PQCs对参数扰动更具鲁棒性；大初始化和低纠缠结构会减缓收敛速度。

Conclusion: 频谱偏差在PQCs中主要由傅里叶系数的冗余性引起，设计选择对模型的学习能力有显著影响。

Abstract: In this work, we investigate the phenomenon of spectral bias in quantum
machine learning, where, in classical settings, models tend to fit
low-frequency components of a target function earlier during training than
high-frequency ones, demonstrating a frequency-dependent rate of convergence.
We study this effect specifically in parameterised quantum circuits (PQCs).
Leveraging the established formulation of PQCs as Fourier series, we prove that
spectral bias in this setting arises from the ``redundancy'' of the Fourier
coefficients, which denotes the number of terms in the analytical form of the
model contributing to the same frequency component. The choice of data encoding
scheme dictates the degree of redundancy for a Fourier coefficient. We find
that the magnitude of the Fourier coefficients' gradients during training
strongly correlates with the coefficients' redundancy. We then further
demonstrate this empirically with three different encoding schemes.
Additionally, we demonstrate that PQCs with greater redundancy exhibit
increased robustness to random perturbations in their parameters at the
corresponding frequencies. We investigate how design choices affect the ability
of PQCs to learn Fourier sums, focusing on parameter initialization scale and
entanglement structure, finding large initializations and low-entanglement
schemes tend to slow convergence.

</details>


### [612] [A User-Centric, Privacy-Preserving, and Verifiable Ecosystem for Personal Data Management and Utilization](https://arxiv.org/abs/2506.22606)
*Osama Zafar,Mina Namazi,Yuqiao Xu,Youngjin Yoo,Erman Ayday*

Main category: cs.CR

Relevance: 30.0

TL;DR: 论文提出了一种去中心化的隐私保护架构，用于处理个人数据，结合安全飞地和联邦学习等技术，确保用户数据所有权和隐私。


<details>
  <summary>Details</summary>
Motivation: 集中式个人数据管理存在隐私和安全问题，需要新的方法满足隐私需求。

Method: 采用去中心化架构，结合安全飞地和联邦学习，支持本地计算、模型训练和隐私保护数据共享。

Result: 系统实现了用户数据所有权和选择性共享，同时确保数据可信性和隐私。

Conclusion: 去中心化架构是解决个人数据隐私和安全问题的有效方法。

Abstract: In the current paradigm of digital personalized services, the centralized
management of personal data raises significant privacy concerns, security
vulnerabilities, and diminished individual autonomy over sensitive information.
Despite their efficiency, traditional centralized architectures frequently fail
to satisfy rigorous privacy requirements and expose users to data breaches and
unauthorized access risks. This pressing challenge calls for a fundamental
paradigm shift in methodologies for collecting, storing, and utilizing personal
data across diverse sectors, including education, healthcare, and finance.
  This paper introduces a novel decentralized, privacy-preserving architecture
that handles heterogeneous personal information, ranging from educational
credentials to health records and financial data. Unlike traditional models,
our system grants users complete data ownership and control, allowing them to
selectively share information without compromising privacy. The architecture's
foundation comprises advanced privacy-enhancing technologies, including secure
enclaves and federated learning, enabling secure computation, verification, and
data sharing. The system supports diverse functionalities, including local
computation, model training, and privacy-preserving data sharing, while
ensuring data credibility and robust user privacy.

</details>


### [613] [Deep Hedging to Manage Tail Risk](https://arxiv.org/abs/2506.22611)
*Yuming Ma*

Main category: q-fin.PM

Relevance: 30.0

TL;DR: 论文提出了一种基于深度神经网络的凸风险最小化方法（CVaR/ES），用于解决投资组合尾部风险对冲问题，并在模拟市场中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 扩展Buehler等人2019年的Deep Hedging范式，通过深度神经网络参数化凸风险最小化，以解决尾部风险对冲问题。

Method: 使用深度神经网络参数化CVaR/ES，在可定制的危机时期市场模拟器中进行数值实验，考虑交易成本、风险预算、流动性约束和市场影响。

Result: 框架显著降低了99% CVaR，并提供了摩擦感知策略适应的实用见解，展示了在实际市场中的鲁棒性和操作可行性。

Conclusion: 该方法在尾部风险对冲中表现优异，具有实际应用潜力。

Abstract: Extending Buehler et al.'s 2019 Deep Hedging paradigm, we innovatively employ
deep neural networks to parameterize convex-risk minimization (CVaR/ES) for the
portfolio tail-risk hedging problem. Through comprehensive numerical
experiments on crisis-era bootstrap market simulators -- customizable with
transaction costs, risk budgets, liquidity constraints, and market impact --
our end-to-end framework not only achieves significant one-day 99% CVaR
reduction but also yields practical insights into friction-aware strategy
adaptation, demonstrating robustness and operational viability in realistic
markets.

</details>


### [614] [Diversity by Design: Addressing Mode Collapse Improves scRNA-seq Perturbation Modeling on Well-Calibrated Metrics](https://arxiv.org/abs/2506.22641)
*Gabriel M. Mejia,Henry E. Miller,Francis J. A. Leblanc,Bo Wang,Brendan Swain,Lucas Paulo de Lima Camillo*

Main category: q-bio.GN

Relevance: 30.0

TL;DR: 论文揭示了单细胞扰动响应模型的性能问题，提出新的评估指标和基线方法以解决模式崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有单细胞扰动响应模型的评估存在指标缺陷，导致模型性能被高估，需要更准确的评估方法。

Method: 引入基于差异表达基因（DEG）的加权指标（WMSE和R²w(Δ)），并通过仿真和真实数据集验证其有效性。

Result: 新指标能更敏感地捕捉生物信号，避免模式崩溃，并提升模型性能。

Conclusion: 改进的评估方法和损失函数（WMSE）能更准确地衡量模型性能并减少模式崩溃。

Abstract: Recent benchmarks reveal that models for single-cell perturbation response
are often outperformed by simply predicting the dataset mean. We trace this
anomaly to a metric artifact: control-referenced deltas and unweighted error
metrics reward mode collapse whenever the control is biased or the biological
signal is sparse. Large-scale \textit{in silico} simulations and analysis of
two real-world perturbation datasets confirm that shared reference shifts, not
genuine biological change, drives high performance in these evaluations. We
introduce differentially expressed gene (DEG)-aware metrics, weighted
mean-squared error (WMSE) and weighted delta $R^{2}$ ($R^{2}_{w}(\Delta)$) with
respect to all perturbations, that measure error in niche signals with high
sensitivity. We further introduce negative and positive performance baselines
to calibrate these metrics. With these improvements, the mean baseline sinks to
null performance while genuine predictors are correctly rewarded. Finally, we
show that using WMSE as a loss function reduces mode collapse and improves
model performance.

</details>


### [615] [Lower bounds for trace estimation via Block Krylov and other methods](https://arxiv.org/abs/2506.22701)
*Shi Jie Yu*

Main category: math.ST

Relevance: 30.0

TL;DR: 论文研究了估计矩阵函数迹的理论下界，重点关注使用Hutchinson方法和Block Krylov技术的方法，并分析了多项式近似与Krylov步骤数的关系。


<details>
  <summary>Details</summary>
Motivation: 研究矩阵函数迹估计的理论下界，以优化Block Krylov方法的效率，并明确多项式近似与计算成本的关系。

Method: 使用Hutchinson方法和Block Krylov技术，通过多项式近似分析矩阵函数迹估计的上界和下界。

Result: 推导了特定函数（如$A^{-1/2}$和$A^{-1}$）的Krylov步骤数上界，以及Wishart矩阵$	ext{tr}(W^{-p})$的查询数下界。

Conclusion: Block Krylov方法的步骤数与多项式近似程度相关，揭示了迹估计成本与多项式近似基本限制的联系。

Abstract: This paper studies theoretical lower bounds for estimating the trace of a
matrix function, $\text{tr}(f(A))$, focusing on methods that use Hutchinson's
method along with Block Krylov techniques. These methods work by approximating
matrix-vector products like $f(A)V$ using a Block Krylov subspace. This is
closely related to approximating functions with polynomials. We derive
theoretical upper bounds on how many Krylov steps are needed for functions such
as $A^{-1/2}$ and $A^{-1}$ by analyzing the upper bounds from the polynomial
approximation of their scalar equivalent. In addition, we also develop lower
limits on the number of queries needed for trace estimation, specifically for
$\text{tr}(W^{-p})$ where $W$ is a Wishart matrix. Our study clarifies the
connection between the number of steps in Block Krylov methods and the degree
of the polynomial used for approximation. This links the total cost of trace
estimation to basic limits in polynomial approximation and how much information
is needed for the computation.

</details>


### [616] [Can We Reliably Predict the Fed's Next Move? A Multi-Modal Approach to U.S. Monetary Policy Forecasting](https://arxiv.org/abs/2506.22763)
*Fiona Xiao Jingyi,Lili Liu*

Main category: q-fin.PM

Relevance: 30.0

TL;DR: 该研究探讨了通过结合结构化数据和非结构化文本信号（美联储通讯）来提高预测央行政策决策的准确性，发现混合模型优于单模态基线，尤其是结合TF-IDF特征和经济指标的XGBoost分类器表现最佳。


<details>
  <summary>Details</summary>
Motivation: 预测央行政策决策对投资者和决策者至关重要，但传统方法仅依赖结构化宏观经济指标，难以捕捉前瞻性信号。

Method: 采用多模态框架，比较传统机器学习模型、基于Transformer的语言模型和深度学习架构，在单模态和混合设置下进行实验。

Result: 混合模型表现最佳，TF-IDF特征与经济指标结合的XGBoost分类器测试AUC达0.83；FinBERT情感特征在分类中表现较差。SHAP分析显示稀疏可解释特征更相关。

Conclusion: 透明结合文本和结构化信号是关键，简单混合模型在准确性和可解释性上均表现优异。

Abstract: Forecasting central bank policy decisions remains a persistent challenge for
investors, financial institutions, and policymakers due to the wide-reaching
impact of monetary actions. In particular, anticipating shifts in the U.S.
federal funds rate is vital for risk management and trading strategies.
Traditional methods relying only on structured macroeconomic indicators often
fall short in capturing the forward-looking cues embedded in central bank
communications.
  This study examines whether predictive accuracy can be enhanced by
integrating structured data with unstructured textual signals from Federal
Reserve communications. We adopt a multi-modal framework, comparing traditional
machine learning models, transformer-based language models, and deep learning
architectures in both unimodal and hybrid settings.
  Our results show that hybrid models consistently outperform unimodal
baselines. The best performance is achieved by combining TF-IDF features of
FOMC texts with economic indicators in an XGBoost classifier, reaching a test
AUC of 0.83. FinBERT-based sentiment features marginally improve ranking but
perform worse in classification, especially under class imbalance. SHAP
analysis reveals that sparse, interpretable features align more closely with
policy-relevant signals.
  These findings underscore the importance of integrating textual and
structured signals transparently. For monetary policy forecasting, simpler
hybrid models can offer both accuracy and interpretability, delivering
actionable insights for researchers and decision-makers.

</details>


### [617] [Not All Water Consumption Is Equal: A Water Stress Weighted Metric for Sustainable Computing](https://arxiv.org/abs/2506.22773)
*Yanran Wu,Inez Hua,Yi Ding*

Main category: cs.DC

Relevance: 30.0

TL;DR: SCARF是一个评估计算水影响的通用框架，考虑了水压力的时空变化，提出了调整水影响（AWI）指标，并通过案例研究展示了优化选择以减少水影响的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着AI工作负载的快速扩展，水消耗成为计算可持续性的关键维度，但现有评估往往忽略水压力的时空变化。

Method: SCARF框架通过计算AWI指标，综合考虑水消耗量和局部水压力的时空变化。

Result: 案例研究表明，通过优化位置和时间选择，可以显著减少水影响。

Conclusion: SCARF为水可持续计算提供了新的评估方法和优化方向。

Abstract: Water consumption is an increasingly critical dimension of computing
sustainability, especially as AI workloads rapidly scale. However, current
water impact assessment often overlooks where and when water stress is more
severe. To fill in this gap, we present SCARF, the first general framework that
evaluates water impact of computing by factoring in both spatial and temporal
variations in water stress. SCARF calculates an Adjusted Water Impact (AWI)
metric that considers both consumption volume and local water stress over time.
Through three case studies on LLM serving, datacenters, and semiconductor
fabrication plants, we show the hidden opportunities for reducing water impact
by optimizing location and time choices, paving the way for water-sustainable
computing. The code is available at https://github.com/jojacola/SCARF.

</details>


### [618] [Differentiable Radar Ambiguity Functions: Mathematical Formulation and Computational Implementation](https://arxiv.org/abs/2506.22935)
*Marc Bara Iniesta*

Main category: eess.SP

Relevance: 30.0

TL;DR: 该论文提出了GRAF，一种可微分的雷达模糊函数框架，解决了传统模糊函数不可微的问题，使其能与梯度优化和现代机器学习结合。


<details>
  <summary>Details</summary>
Motivation: 传统雷达模糊函数涉及不可微操作，限制了其与现代梯度优化和机器学习框架的结合。

Method: 提出了GRAF框架，利用Wirtinger微积分处理复值梯度，通过并行FFT实现高效计算，确保数值稳定性，并与任意可微操作兼容。

Result: 实现了数学等价且可微的模糊函数计算，支持神经网络波形生成、雷达系统端到端优化等新研究方向。

Conclusion: GRAF为雷达波形设计中的现代机器学习应用奠定了数学和计算基础。

Abstract: The ambiguity function is fundamental to radar waveform design,
characterizing range and Doppler resolution capabilities. However, its
traditional formulation involves non-differentiable operations, preventing
integration with gradient-based optimization methods and modern machine
learning frameworks. This paper presents the first complete mathematical
framework and computational implementation for differentiable radar ambiguity
functions. Our approach addresses the fundamental technical challenges that
have prevented the radar community from leveraging automatic differentiation:
proper handling of complex-valued gradients using Wirtinger calculus, efficient
computation through parallelized FFT operations, numerical stability throughout
cascaded operations, and composability with arbitrary differentiable
operations. We term this approach GRAF (Gradient-based Radar Ambiguity
Functions), which reformulates the ambiguity function computation to maintain
mathematical equivalence while enabling gradient flow through the entire
pipeline. The resulting implementation provides a general-purpose
differentiable ambiguity function compatible with modern automatic
differentiation frameworks, enabling new research directions including neural
network-based waveform generation with ambiguity constraints, end-to-end
optimization of radar systems, and integration of classical radar theory with
modern deep learning. We provide complete implementation details and
demonstrate computational efficiency suitable for practical applications. This
work establishes the mathematical and computational foundation for applying
modern machine learning techniques to radar waveform design, bridging classical
radar signal processing with automatic differentiation frameworks.

</details>


### [619] [Efficient Cybersecurity Assessment Using SVM and Fuzzy Evidential Reasoning for Resilient Infrastructure](https://arxiv.org/abs/2506.22938)
*Zaydon L. Ali,Wassan Saad Abduljabbar Hayale,Israa Ibraheem Al_Barazanchi,Ravi Sekhar,Pritesh Shah,Sushma Parihar*

Main category: cs.CR

Relevance: 30.0

TL;DR: 该论文提出了一种基于支持向量机（SVM）和模糊证据推理（ER）的安全评估模型，用于快速准确地选择加密算法，并通过多种指标评估其性能。


<details>
  <summary>Details</summary>
Motivation: 当前加密模型存在安全漏洞，手动测试算法效率低下，需要一种快速且精确的安全评估方法。

Method: 结合SVM和模糊ER方法，构建数据集并使用对比度、同质性等安全组件进行分析。

Result: 提出的模型能够系统化处理风险评估数据，并通过召回率、F1分数和准确率等指标验证其性能。

Conclusion: 该框架为加密算法的安全评估提供了一种高效且系统化的解决方案。

Abstract: With current advancement in hybermedia knowledges, the privacy of digital
information has developed a critical problem. To overawed the susceptibilities
of present security protocols, scholars tend to focus mainly on efforts on
alternation of current protocols. Over past decade, various proposed encoding
models have been shown insecurity, leading to main threats against significant
data. Utilizing the suitable encryption model is very vital means of guard
against various such, but algorithm is selected based on the dependency of data
which need to be secured. Moreover, testing potentiality of the security
assessment one by one to identify the best choice can take a vital time for
processing. For faster and precisive identification of assessment algorithm, we
suggest a security phase exposure model for cipher encryption technique by
invoking Support Vector Machine (SVM). In this work, we form a dataset using
usual security components like contrast, homogeneity. To overcome the
uncertainty in analysing the security and lack of ability of processing data to
a risk assessment mechanism. To overcome with such complications, this paper
proposes an assessment model for security issues using fuzzy evidential
reasoning (ER) approaches. Significantly, the model can be utilised to process
and assemble risk assessment data on various aspects in systematic ways. To
estimate the performance of our framework, we have various analyses like,
recall, F1 score and accuracy.

</details>


### [620] [Compositions of Variant Experts for Integrating Short-Term and Long-Term Preferences](https://arxiv.org/abs/2506.23170)
*Jaime Hieu Do,Trung-Hoang Le,Hady W. Lauw*

Main category: cs.IR

Relevance: 30.0

TL;DR: 论文提出了一种结合短期和长期偏好的推荐框架CoVE，通过动态整合不同专家模型提升推荐性能。


<details>
  <summary>Details</summary>
Motivation: 研究个性化序列推荐中短期和长期偏好的影响，并提出解决方案以提升推荐效果。

Method: 提出Compositions of Variant Experts (CoVE)框架，动态整合短期和长期偏好的专家模型。

Result: 实验证明CoVE框架能有效提升推荐性能，消融研究分析了不同专家类型的影响。

Conclusion: CoVE框架通过结合短期和长期偏好显著提升了推荐系统的性能。

Abstract: In the online digital realm, recommendation systems are ubiquitous and play a
crucial role in enhancing user experience. These systems leverage user
preferences to provide personalized recommendations, thereby helping users
navigate through the paradox of choice. This work focuses on personalized
sequential recommendation, where the system considers not only a user's
immediate, evolving session context, but also their cumulative historical
behavior to provide highly relevant and timely recommendations. Through an
empirical study conducted on diverse real-world datasets, we have observed and
quantified the existence and impact of both short-term (immediate and
transient) and long-term (enduring and stable) preferences on users' historical
interactions. Building on these insights, we propose a framework that combines
short- and long-term preferences to enhance recommendation performance, namely
Compositions of Variant Experts (CoVE). This novel framework dynamically
integrates short- and long-term preferences through the use of different
specialized recommendation models (i.e., experts). Extensive experiments
showcase the effectiveness of the proposed methods and ablation studies further
investigate the impact of variant expert types.

</details>


### [621] [Physics informed guided diffusion for accelerated multi-parametric MRI reconstruction](https://arxiv.org/abs/2506.23311)
*Perla Mayo,Carolin M. Pirkl,Alin Achim,Bjoern Menze,Mohammad Golbabaee*

Main category: eess.IV

Relevance: 30.0

TL;DR: MRF-DiPh是一种基于物理约束的扩散去噪方法，用于从快速定量MRI数据中重建多参数组织图。


<details>
  <summary>Details</summary>
Motivation: 解决医学成像中快速定量MRI数据的逆问题，提高参数图的准确性和物理一致性。

Method: 结合预训练的扩散去噪模型作为图像先验，同时强制执行k空间测量一致性和Bloch响应模型。

Result: 在脑扫描数据上优于深度学习和压缩感知基线，提供更准确的参数图。

Conclusion: MRF-DiPh在医学成像中可靠地解决了逆问题，保持了测量保真度和物理一致性。

Abstract: We introduce MRF-DiPh, a novel physics informed denoising diffusion approach
for multiparametric tissue mapping from highly accelerated, transient-state
quantitative MRI acquisitions like Magnetic Resonance Fingerprinting (MRF). Our
method is derived from a proximal splitting formulation, incorporating a
pretrained denoising diffusion model as an effective image prior to regularize
the MRF inverse problem. Further, during reconstruction it simultaneously
enforces two key physical constraints: (1) k-space measurement consistency and
(2) adherence to the Bloch response model. Numerical experiments on in-vivo
brain scans data show that MRF-DiPh outperforms deep learning and compressed
sensing MRF baselines, providing more accurate parameter maps while better
preserving measurement fidelity and physical model consistency-critical for
solving reliably inverse problems in medical imaging.

</details>


### [622] [Data-Driven Self-Supervised Learning for the Discovery of Solution Singularity for Partial Differential Equations](https://arxiv.org/abs/2506.23344)
*Difeng Cai,Paulina Sepúlveda*

Main category: math.NA

Relevance: 30.0

TL;DR: 论文提出了一种基于自监督学习（SSL）的框架，用于从原始数据中检测奇异点位置，解决了科学计算中未知奇异点的问题。


<details>
  <summary>Details</summary>
Motivation: 科学计算中奇异点的存在会显著影响数值方法的有效性，尤其是当奇异点位置未知时。本文旨在通过数据驱动的方法解决这一问题。

Method: 提出了一种自监督学习框架，包括基于k近邻和核密度估计的过滤方法作为前置任务，用于从原始数据中估计奇异点位置。

Result: 实验表明，该方法能够处理输入扰动、标签污染以及多种类型的奇异点（如内部圆、边界层等）。

Conclusion: 该框架为奇异点检测提供了一种高效的数据驱动方法，适用于多种应用场景。

Abstract: The appearance of singularities in the function of interest constitutes a
fundamental challenge in scientific computing. It can significantly undermine
the effectiveness of numerical schemes for function approximation, numerical
integration, and the solution of partial differential equations (PDEs), etc.
The problem becomes more sophisticated if the location of the singularity is
unknown, which is often encountered in solving PDEs. Detecting the singularity
is therefore critical for developing efficient adaptive methods to reduce
computational costs in various applications. In this paper, we consider
singularity detection in a purely data-driven setting. Namely, the input only
contains given data, such as the vertex set from a mesh. To overcome the
limitation of the raw unlabeled data, we propose a self-supervised learning
(SSL) framework for estimating the location of the singularity. A key component
is a filtering procedure as the pretext task in SSL, where two filtering
methods are presented, based on $k$ nearest neighbors and kernel density
estimation, respectively. We provide numerical examples to illustrate the
potential pathological or inaccurate results due to the use of raw data without
filtering. Various experiments are presented to demonstrate the ability of the
proposed approach to deal with input perturbation, label corruption, and
different kinds of singularities such interior circle, boundary layer,
concentric semicircles, etc.

</details>


### [623] [Investigating an Overfitting and Degeneration Phenomenon in Self-Supervised Multi-Pitch Estimation](https://arxiv.org/abs/2506.23371)
*Frank Cwitkowitz,Zhiyao Duan*

Main category: eess.AS

Relevance: 30.0

TL;DR: 论文提出了一种结合监督学习和自监督学习目标的多音高估计方法，提高了性能，但发现模型在监督数据上过拟合同时在自监督数据上退化。


<details>
  <summary>Details</summary>
Motivation: 解决多音高估计任务中标注数据稀缺的问题，探索自监督学习与监督学习的结合。

Method: 扩展经典监督学习范式，引入基于音高不变性和音高等变性的自监督目标进行联合训练。

Result: 在封闭训练条件下性能显著提升，但在更广泛数据上应用时，模型在监督数据上过拟合并在自监督数据上退化。

Conclusion: 揭示了监督与自监督目标联合训练中的潜在问题，为未来研究提供了方向。

Abstract: Multi-Pitch Estimation (MPE) continues to be a sought after capability of
Music Information Retrieval (MIR) systems, and is critical for many
applications and downstream tasks involving pitch, including music
transcription. However, existing methods are largely based on supervised
learning, and there are significant challenges in collecting annotated data for
the task. Recently, self-supervised techniques exploiting intrinsic properties
of pitch and harmonic signals have shown promise for both monophonic and
polyphonic pitch estimation, but these still remain inferior to supervised
methods. In this work, we extend the classic supervised MPE paradigm by
incorporating several self-supervised objectives based on pitch-invariant and
pitch-equivariant properties. This joint training results in a substantial
improvement under closed training conditions, which naturally suggests that
applying the same objectives to a broader collection of data will yield further
improvements. However, in doing so we uncover a phenomenon whereby our model
simultaneously overfits to the supervised data while degenerating on data used
for self-supervision only. We demonstrate and investigate this and offer our
insights on the underlying problem.

</details>


### [624] [DPOT: A DeepParticle method for Computation of Optimal Transport with convergence guarantee](https://arxiv.org/abs/2506.23429)
*Yingyuan Li,Aokun Wang,Zhongjian Wang*

Main category: stat.ML

Relevance: 30.0

TL;DR: 提出了一种基于DeepParticle方法的新机器学习方法，用于计算两个连续分布之间的最优传输映射，无需配对样本。


<details>
  <summary>Details</summary>
Motivation: 解决从非配对样本中计算最优传输映射的问题，提供一种灵活且理论保证的方法。

Method: 采用min-min优化训练方法，不限制网络结构，理论上有弱收敛保证和误差界限。

Result: 数值实验验证了理论结果和新方法的有效性，特别是在实际任务中。

Conclusion: 该方法在理论和实践中均表现出色，适用于真实世界任务。

Abstract: In this work, we propose a novel machine learning approach to compute the
optimal transport map between two continuous distributions from their unpaired
samples, based on the DeepParticle methods. The proposed method leads to a
min-min optimization during training and does not impose any restriction on the
network structure. Theoretically we establish a weak convergence guarantee and
a quantitative error bound between the learned map and the optimal transport
map. Our numerical experiments validate the theoretical results and the
effectiveness of the new approach, particularly on real-world tasks.

</details>


### [625] [Neuro-Informed Joint Learning Enhances Cognitive Workload Decoding in Portable BCIs](https://arxiv.org/abs/2506.23458)
*Xiaoxiao Yang,Chan Feng,Jiancheng Chen*

Main category: cs.HC

Relevance: 30.0

TL;DR: 论文提出MuseCogNet，一种结合自监督和监督学习的联合学习框架，用于提升便携式EEG设备的认知负荷检测性能。


<details>
  <summary>Details</summary>
Motivation: 便携式EEG设备（如Muse头带）在移动性方面具有优势，但信号的非平稳性限制了数据质量和解码精度。为了解决这一问题，作者提出了一种新的学习框架。

Method: MuseCogNet结合了自监督和监督学习范式，通过基于平均池化的自监督重建损失捕捉稳健的神经生理模式，同时利用交叉熵损失优化任务特定的认知判别能力。

Result: MuseCogNet在公开的Muse数据集上显著优于现有方法，为生态环境中的神经认知监测提供了可行途径。

Conclusion: 该框架通过模仿人类的自下而上和自上而下注意力机制，有效提升了便携式EEG设备的性能。

Abstract: Portable and wearable consumer-grade electroencephalography (EEG) devices,
like Muse headbands, offer unprecedented mobility for daily brain-computer
interface (BCI) applications, including cognitive load detection. However, the
exacerbated non-stationarity in portable EEG signals constrains data fidelity
and decoding accuracy, creating a fundamental trade-off between portability and
performance. To mitigate such limitation, we propose MuseCogNet (Muse-based
Cognitive Network), a unified joint learning framework integrating
self-supervised and supervised training paradigms. In particular, we introduce
an EEG-grounded self-supervised reconstruction loss based on average pooling to
capture robust neurophysiological patterns, while cross-entropy loss refines
task-specific cognitive discriminants. This joint learning framework resembles
the bottom-up and top-down attention in humans, enabling MuseCogNet to
significantly outperform state-of-the-art methods on a publicly available Muse
dataset and establish an implementable pathway for neurocognitive monitoring in
ecological settings.

</details>


### [626] [Test of partial effects for Frechet regression on Bures-Wasserstein manifolds](https://arxiv.org/abs/2506.23487)
*Haoshu Xu,Hongzhe Li*

Main category: stat.ML

Relevance: 30.0

TL;DR: 提出了一种新的测试方法，用于评估Bures Wasserstein流形上的Frechet回归中的部分效应。通过样本分割策略，证明了测试统计量的渐近分布，并验证了方法的有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 在Bures Wasserstein流形上评估部分效应的现有方法有限，需要更高效和准确的测试方法。

Method: 采用样本分割策略，第一部分用于拟合Frechet回归模型，第二部分用于构建测试统计量。

Result: 测试统计量渐近收敛于加权混合卡方分布，方法在模拟和实际数据中表现出色。

Conclusion: 提出的测试方法在理论和实践中均表现良好，适用于Bures Wasserstein流形上的部分效应评估。

Abstract: We propose a novel test for assessing partial effects in Frechet regression
on Bures Wasserstein manifolds. Our approach employs a sample splitting
strategy: the first subsample is used to fit the Frechet regression model,
yielding estimates of the covariance matrices and their associated optimal
transport maps, while the second subsample is used to construct the test
statistic. We prove that this statistic converges in distribution to a weighted
mixture of chi squared components, where the weights correspond to the
eigenvalues of an integral operator defined by an appropriate RKHS kernel. We
establish that our procedure achieves the nominal asymptotic size and
demonstrate that its worst-case power converges uniformly to one. Through
extensive simulations and a real data application, we illustrate the test's
finite-sample accuracy and practical utility.

</details>


### [627] [Seeding neural network quantum states with tensor network states](https://arxiv.org/abs/2506.23550)
*Ryui Kaneko,Shimpei Goto*

Main category: cond-mat.str-el

Relevance: 30.0

TL;DR: 提出了一种将矩阵乘积态（MPS）通过CP分解转换为受限玻尔兹曼机波函数的高效方法，用于量子多体基态计算。


<details>
  <summary>Details</summary>
Motivation: 为量子多体基态计算提供高效的初始神经网络量子态生成方法。

Method: 通过CP分解将MPS转换为受限玻尔兹曼机波函数，生成初始态并逐步逼近基态。

Result: 在横场伊辛模型中验证了方法的效率，并讨论了其在更复杂量子多体系统中的应用潜力。

Conclusion: 该方法能高效生成初始态并逐步逼近基态，适用于复杂节点结构的量子系统。

Abstract: We find an efficient approach to approximately convert matrix product states
(MPSs) into restricted Boltzmann machine wave functions consisting of a
multinomial hidden unit through a canonical polyadic (CP) decomposition of the
MPSs. This method allows us to generate well-behaved initial neural network
quantum states for quantum many-body ground-state calculations in polynomial
time of the number of variational parameters and systematically shorten the
distance between the initial states and the ground states with increasing the
rank of the CP decomposition. We demonstrate the efficiency of our method by
taking the transverse-field Ising model as an example and discuss possible
applications of our method to more general quantum many-body systems in which
the ground-state wave functions possess complex nodal structures.

</details>


### [628] [Geminet: Learning the Duality-based Iterative Process for Lightweight Traffic Engineering in Changing Topologies](https://arxiv.org/abs/2506.23640)
*Ximeng Liu,Shizhen Zhao,Xinbing Wang*

Main category: cs.NI

Relevance: 30.0

TL;DR: Geminet是一个轻量级、可扩展的基于机器学习的流量工程框架，能够处理拓扑变化，显著提升了可扩展性和内存效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的流量工程方案无法处理拓扑变化或计算和内存开销过大，Geminet旨在解决这些问题。

Method: Geminet通过解耦神经网络与拓扑结构，学习基于梯度下降的迭代调整过程，并将优化从路径级路由权重转移到边级双变量，以减少内存消耗。

Result: Geminet在WAN和数据中心数据集上表现出色，神经网络大小仅为现有方案的0.04%至7%，内存消耗低于10 GiB，收敛速度比HARP快5.45倍。

Conclusion: Geminet展示了在大规模部署中的潜力，具有高效性和可扩展性。

Abstract: Recently, researchers have explored ML-based Traffic Engineering (TE),
leveraging neural networks to solve TE problems traditionally addressed by
optimization. However, existing ML-based TE schemes remain impractical: they
either fail to handle topology changes or suffer from poor scalability due to
excessive computational and memory overhead. To overcome these limitations, we
propose Geminet, a lightweight and scalable ML-based TE framework that can
handle changing topologies. Geminet is built upon two key insights: (i) a
methodology that decouples neural networks from topology by learning an
iterative gradient-descent-based adjustment process, as the update rule of
gradient descent is topology-agnostic, relying only on a few gradient-related
quantities; (ii) shifting optimization from path-level routing weights to
edge-level dual variables, reducing memory consumption by leveraging the fact
that edges are far fewer than paths. Evaluations on WAN and data center
datasets show that Geminet significantly improves scalability. Its neural
network size is only 0.04% to 7% of existing schemes, while handling topology
variations as effectively as HARP, a state-of-the-art ML-based TE approach,
without performance degradation. When trained on large-scale topologies,
Geminet consumes under 10 GiB of memory, more than eight times less than the
80-plus GiB required by HARP, while achieving 5.45 times faster convergence
speed, demonstrating its potential for large-scale deployment.

</details>


### [629] [Proving the Limited Scalability of Centralized Distributed Optimization via a New Lower Bound Construction](https://arxiv.org/abs/2506.23836)
*Alexander Tyurin*

Main category: math.OC

Relevance: 30.0

TL;DR: 论文研究了分布式优化中的通信和计算效率问题，特别是在联邦学习框架下，揭示了使用无偏稀疏化压缩器时，通信和计算效率无法同时随工人数量多对数级提升的基本限制。


<details>
  <summary>Details</summary>
Motivation: 分布式优化的主要动机是通过增加工人数量（n）实现可扩展性，但通信开销（如服务器到工人的时间τ_s）限制了效率提升。

Method: 通过构造一个“最坏情况”函数和新的下界框架，分析随机和的集中性，证明了无偏随机稀疏化压缩器的局限性。

Result: 证明了在均匀（i.i.d.）情况下，无法设计出同时优化服务器端通信时间（τ_s d LΔ/ε）和方差相关计算时间（hσ²LΔ/ε²）的方法。

Conclusion: 揭示了分布式优化在均匀假设下的基本限制，即使使用无偏稀疏化压缩器也无法突破。

Abstract: We consider centralized distributed optimization in the classical federated
learning setup, where $n$ workers jointly find an $\varepsilon$-stationary
point of an $L$-smooth, $d$-dimensional nonconvex function $f$, having access
only to unbiased stochastic gradients with variance $\sigma^2$. Each worker
requires at most $h$ seconds to compute a stochastic gradient, and the
communication times from the server to the workers and from the workers to the
server are $\tau_{s}$ and $\tau_{w}$ seconds per coordinate, respectively. One
of the main motivations for distributed optimization is to achieve scalability
with respect to $n$. For instance, it is well known that the distributed
version of SGD has a variance-dependent runtime term $\frac{h \sigma^2 L
\Delta}{n \varepsilon^2},$ which improves with the number of workers $n,$ where
$\Delta = f(x^0) - f^*,$ and $x^0 \in R^d$ is the starting point. Similarly,
using unbiased sparsification compressors, it is possible to reduce both the
variance-dependent runtime term and the communication runtime term. However,
once we account for the communication from the server to the workers
$\tau_{s}$, we prove that it becomes infeasible to design a method using
unbiased random sparsification compressors that scales both the server-side
communication runtime term $\tau_{s} d \frac{L \Delta}{\varepsilon}$ and the
variance-dependent runtime term $\frac{h \sigma^2 L \Delta}{\varepsilon^2},$
better than poly-logarithmically in $n$, even in the homogeneous (i.i.d.) case,
where all workers access the same distribution. To establish this result, we
construct a new "worst-case" function and develop a new lower bound framework
that reduces the analysis to the concentration of a random sum, for which we
prove a concentration bound. These results reveal fundamental limitations in
scaling distributed optimization, even under the homogeneous assumption.

</details>


### [630] [Learning Constraints Directly from Network Data](https://arxiv.org/abs/2506.23964)
*Hongyu Hè,Minhao Jin,Maria Apostolaki*

Main category: cs.NI

Relevance: 30.0

TL;DR: NetNomos learns propositional logic constraints from network data to improve synthetic data quality, ML robustness, and semantic understanding, outperforming baselines in rule extraction efficiency and coverage.


<details>
  <summary>Details</summary>
Motivation: Network data follows rules from protocols and design, but manual or ML-based rule extraction is incomplete. Formalizing these rules can enhance synthetic data, ML models, and semantic understanding.

Method: NetNomos formulates rule extraction as constraint modeling, using lattice-based search to reduce learning complexity and efficiently traverse combinatorial space.

Result: NetNomos learns all benchmark rules (even rare ones) in under three hours, outperforming baselines that find <25% of rules and take days. Case studies show practical applications in traffic generation, anomaly detection, and monitoring.

Conclusion: NetNomos effectively automates rule extraction from network data, offering significant improvements in efficiency and coverage over existing methods.

Abstract: Network data conforms to a wide range of rules that arise from protocols,
design principles, and deployment decisions (e.g., a packet's queuing delay
must be less than its end-to-end delay). Formalizing such rules as logic
constraints can (i) improve the quality of synthetic data, (ii) reduce the
brittleness of machine learning (ML) models, and (iii) improve semantic
understanding of network measurements. However, these benefits remain out of
reach if rule extraction is manual or solely reliant on ML, as both approaches
yield incomplete, unreliable, and/or inaccurate rules.
  This paper formulates rule extraction as a constraint modeling problem and
introduces NetNomos that learns propositional logic constraints directly from
raw network measurements. Constraint modeling in this domain is uniquely
challenging due to the scale of the data, the inherent learning complexity and
passive environment, and the lack of ground truth supervision. NetNomos
addresses these challenges via a lattice-based search structured by constraint
specificity and succinctness. Our approach reduces learning complexity from
superquadratic to logarithmic and enables efficient traversal in combinatorial
search space.
  Our evaluations on diverse network datasets show that NetNomos learns all
benchmark rules, including those associated with as little as 0.01% of data
points, in under three hours. In contrast, baseline methods discover less than
25% of the rules and require several days to run. Through three case studies,
we show that: NetNomos (i) finds rule violations in the outputs of all seven
synthetic traffic generators, hence can be used to assess and guide their
generation process; (ii) detects semantic differences in traffic, hence can be
used for anomaly detection; and (iii) automatically finds rules used for
telemetry imputation, hence can support monitoring through inference.

</details>


### [631] [Minimax and Bayes Optimal Best-arm Identification: Adaptive Experimental Design for Treatment Choice](https://arxiv.org/abs/2506.24007)
*Masahiro Kato*

Main category: econ.EM

Relevance: 30.0

TL;DR: 论文研究了自适应实验设计用于治疗选择，提出了一种两阶段分配方法，旨在高效识别最佳治疗臂，并证明了其同时满足极小极大和贝叶斯最优性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于优化自适应实验设计，以高效识别最佳治疗臂，同时满足极小极大和贝叶斯最优性。

Method: 方法包括两阶段治疗分配：第一阶段均匀分配以消除次优臂并估计方差，第二阶段按方差比例分配。随后选择样本均值最高的治疗臂。

Result: 结果表明，该设计在简单遗憾上同时达到极小极大和贝叶斯最优性，且无需单独调参。

Conclusion: 结论是设计的实验达到了效率极限，无需为不同目标单独优化。

Abstract: This study investigates adaptive experimental design for treatment choice,
also known as fixed-budget best-arm identification. We consider an adaptive
procedure consisting of a treatment-allocation phase followed by a
treatment-choice phase, and we design an adaptive experiment for this setup to
efficiently identify the best treatment arm, defined as the one with the
highest expected outcome. In our designed experiment, the treatment-allocation
phase consists of two stages. The first stage is a pilot phase, where we
allocate each treatment arm uniformly with equal proportions to eliminate
clearly suboptimal arms and estimate outcome variances. In the second stage, we
allocate treatment arms in proportion to the variances estimated in the first
stage. After the treatment-allocation phase, the procedure enters the
treatment-choice phase, where we choose the treatment arm with the highest
sample mean as our estimate of the best treatment arm. We prove that this
single design is simultaneously asymptotically minimax and Bayes optimal for
the simple regret, with upper bounds that match our lower bounds up to exact
constants. Therefore, our designed experiment achieves the sharp efficiency
limits without requiring separate tuning for minimax and Bayesian objectives.

</details>


### [632] [Post-processing of EEG-based Auditory Attention Decoding Decisions via Hidden Markov Models](https://arxiv.org/abs/2506.24024)
*Nicolas Heintz,Tom Francart,Alexander Bertrand*

Main category: eess.SP

Relevance: 30.0

TL;DR: 论文提出了一种基于隐马尔可夫模型（HMM）的听觉注意力解码（AAD）改进方法，通过建模注意力的时间结构，显著提升了现有AAD算法的准确性和实时性。


<details>
  <summary>Details</summary>
Motivation: 现有的AAD算法在多说话者环境中虽然能识别听众的注意力，但预测准确性不足，限制了实际应用。

Method: 引入HMM建模注意力的时间结构，利用注意力切换概率低的特性，改进AAD算法。

Result: HMM在因果（实时）和非因果（离线）场景中均显著提升了AAD算法的性能，优于现有后处理方法。

Conclusion: 该方法计算高效、直观易用，适用于实时和离线场景，为AAD的实际应用提供了可行方案。

Abstract: Auditory attention decoding (AAD) algorithms exploit brain signals, such as
electroencephalography (EEG), to identify which speaker a listener is focusing
on in a multi-speaker environment. While state-of-the-art AAD algorithms can
identify the attended speaker on short time windows, their predictions are
often too inaccurate for practical use. In this work, we propose augmenting AAD
with a hidden Markov model (HMM) that models the temporal structure of
attention. More specifically, the HMM relies on the fact that a subject is much
less likely to switch attention than to keep attending the same speaker at any
moment in time. We show how a HMM can significantly improve existing AAD
algorithms in both causal (real-time) and non-causal (offline) settings. We
further demonstrate that HMMs outperform existing postprocessing approaches in
both accuracy and responsiveness, and explore how various factors such as
window length, switching frequency, and AAD accuracy influence overall
performance. The proposed method is computationally efficient, intuitive to use
and applicable in both real-time and offline settings.

</details>


### [633] [A hierarchical Vovk-Azoury-Warmuth forecaster with discounting for online regression in RKHS](https://arxiv.org/abs/2506.22631)
*Dmitry B. Rokhlin*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种名为H-VAW-D的分层算法，结合了随机特征近似和DVAW框架，用于在线回归问题，实现了高效的计算复杂度和动态遗憾界。


<details>
  <summary>Details</summary>
Motivation: 研究在线回归问题，特别是在非参数域中，如何通过结合DVAW框架和随机特征近似，实现高效的动态遗憾界。

Method: 提出H-VAW-D算法，结合随机特征近似和DVAW框架，自适应学习折扣因子和随机特征数量。

Result: 算法计算复杂度为$O(T\ln T)$，动态遗憾界为$O(T^{2/3}P_T^{1/3} + \sqrt{T}\ln T)$。

Conclusion: H-VAW-D算法在非参数域中实现了高效的动态遗憾界，适用于在线回归问题。

Abstract: We study the problem of online regression with the unconstrained quadratic
loss against a time-varying sequence of functions from a Reproducing Kernel
Hilbert Space (RKHS). Recently, Jacobsen and Cutkosky (2024) introduced a
discounted Vovk-Azoury-Warmuth (DVAW) forecaster that achieves optimal dynamic
regret in the finite-dimensional case. In this work, we lift their approach to
the non-parametric domain by synthesizing the DVAW framework with a random
feature approximation. We propose a fully adaptive, hierarchical algorithm,
which we call H-VAW-D (Hierarchical Vovk-Azoury-Warmuth with Discounting), that
learns both the discount factor and the number of random features. We prove
that this algorithm, which has a per-iteration computational complexity of
$O(T\ln T)$, achieves an expected dynamic regret of $O(T^{2/3}P_T^{1/3} +
\sqrt{T}\ln T)$, where $P_T$ is the functional path length of a comparator
sequence.

</details>


### [634] [Scalable Structure Learning of Bayesian Networks by Learning Algorithm Ensembles](https://arxiv.org/abs/2506.22848)
*Shengcai Liu,Hui Ou-yang,Zhiyuan Wang,Cheng Chen,Qijun Cai,Yew-Soon Ong,Ke Tang*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种基于结构学习集成（SLE）的方法，用于提高大规模贝叶斯网络（BN）结构学习的准确性，并通过自动学习SLE（Auto-SLE）解决了手动设计的问题。实验表明，该方法在10,000变量数据集上比传统方法提高了30%～225%的准确性，并能泛化到更大规模的数据集。


<details>
  <summary>Details</summary>
Motivation: 大规模贝叶斯网络结构学习面临准确性不稳定的问题，尤其是当变量数量庞大时。现有的分治策略（D&D）虽然有效，但仍存在子问题学习准确性不稳定的问题。

Method: 提出结构学习集成（SLE）方法，结合多种BN结构学习算法以提高准确性。进一步提出Auto-SLE，自动学习最优SLE，并将其集成到D&D方法中。

Result: 在10,000变量的数据集上，准确性提高了30%～225%，并能泛化到更大规模（如30,000变量）和不同网络特性的数据集。

Conclusion: SLE和Auto-SLE在可扩展的BN结构学习中具有显著潜力。

Abstract: Learning the structure of Bayesian networks (BNs) from data is challenging,
especially for datasets involving a large number of variables. The recently
proposed divide-and-conquer (D\&D) strategies present a promising approach for
learning large BNs. However, they still face a main issue of unstable learning
accuracy across subproblems. In this work, we introduce the idea of employing
structure learning ensemble (SLE), which combines multiple BN structure
learning algorithms, to consistently achieve high learning accuracy. We further
propose an automatic approach called Auto-SLE for learning near-optimal SLEs,
addressing the challenge of manually designing high-quality SLEs. The learned
SLE is then integrated into a D\&D method. Extensive experiments firmly show
the superiority of our method over D\&D methods with single BN structure
learning algorithm in learning large BNs, achieving accuracy improvement
usually by 30\%$\sim$225\% on datasets involving 10,000 variables. Furthermore,
our method generalizes well to datasets with many more (e.g., 30000) variables
and different network characteristics than those present in the training data
for learning the SLE. These results indicate the significant potential of
employing (automatic learning of) SLEs for scalable BN structure learning.

</details>


### [635] [Hierarchical Quantized Diffusion Based Tree Generation Method for Hierarchical Representation and Lineage Analysis](https://arxiv.org/abs/2506.23287)
*Zelin Zang,WenZhe Li,Fei Chen,Yongjie Xu,Chang Yu,Zhen Lei,Stan Z. Li*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种基于扩散的方法HDTree，用于建模单细胞研究中的层次数据，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 单细胞研究中，传统方法在计算成本、性能和生成能力上存在不足，HDTree旨在通过统一层次编码和量化扩散过程改进这些问题。

Method: HDTree使用层次潜在空间和量化扩散过程建模树节点转换，无需分支特定模块，提高了稳定性和生成能力。

Result: 在通用和单细胞数据集上，HDTree在准确性和性能上优于现有方法。

Conclusion: HDTree为层次谱系分析提供了新工具，提升了细胞分化路径建模的准确性和效率。

Abstract: In single-cell research, tracing and analyzing high-throughput single-cell
differentiation trajectories is crucial for understanding complex biological
processes. Key to this is the modeling and generation of hierarchical data that
represents the intrinsic structure within datasets. Traditional methods face
limitations in terms of computational cost, performance, generative capacity,
and stability. Recent VAEs based approaches have made strides in addressing
these challenges but still require specialized network modules for each tree
branch, limiting their stability and ability to capture deep hierarchical
relationships. To overcome these challenges, we introduce diffusion-based
approach called HDTree. HDTree captures tree relationships within a
hierarchical latent space using a unified hierarchical codebook and quantized
diffusion processes to model tree node transitions. This method improves
stability by eliminating branch-specific modules and enhancing generative
capacity through gradual hierarchical changes simulated by the diffusion
process. HDTree's effectiveness is demonstrated through comparisons on both
general-purpose and single-cell datasets, where it outperforms existing methods
in terms of accuracy and performance. These contributions provide a new tool
for hierarchical lineage analysis, enabling more accurate and efficient
modeling of cellular differentiation paths and offering insights for downstream
biological tasks. The code of HDTree is available at anonymous link
https://anonymous.4open.science/r/code_HDTree_review-A8DB.

</details>


### [636] [Training of Spiking Neural Networks with Expectation-Propagation](https://arxiv.org/abs/2506.23757)
*Dan Yao,Steve McLaughlin,Yoann Altmann*

Main category: cs.LG

Relevance: 20.0

TL;DR: 提出了一种基于期望传播的统一消息传递框架，用于训练脉冲神经网络（SNNs），支持离散和连续权重的训练。


<details>
  <summary>Details</summary>
Motivation: 解决传统梯度方法在训练SNNs时的局限性，提供一种更高效的训练方法。

Method: 使用期望传播的统一消息传递框架，梯度无关，支持批量训练。

Result: 算法在实践中收敛速度快于梯度方法，适用于分类和回归任务。

Conclusion: 为深度贝叶斯网络的高效训练提供了新方法。

Abstract: In this paper, we propose a unifying message-passing framework for training
spiking neural networks (SNNs) using Expectation-Propagation. Our gradient-free
method is capable of learning the marginal distributions of network parameters
and simultaneously marginalizes nuisance parameters, such as the outputs of
hidden layers. This framework allows for the first time, training of discrete
and continuous weights, for deterministic and stochastic spiking networks,
using batches of training samples. Although its convergence is not ensured, the
algorithm converges in practice faster than gradient-based methods, without
requiring a large number of passes through the training data. The
classification and regression results presented pave the way for new efficient
training methods for deep Bayesian networks.

</details>


### [637] [EFPI: Elastic Formation and Position Identification in Football (Soccer) using Template Matching and Linear Assignment](https://arxiv.org/abs/2506.23843)
*Joris Bekkers*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种基于预定义静态阵型模板和时空跟踪数据的足球阵型识别与球员位置分配方法EFPI，通过线性求和分配优化匹配球员与模板位置，并选择成本最低的阵型。


<details>
  <summary>Details</summary>
Motivation: 足球战术分析需要准确识别球队阵型和球员位置，现有方法缺乏灵活性或准确性。

Method: 使用线性求和分配算法，将球员位置与预定义阵型模板匹配，通过最小化总距离优化，并引入稳定性参数减少不必要的阵型变化。

Result: EFPI方法在单个帧和更长时间段（如比赛阶段或特定间隔）中均表现良好，并已开源。

Conclusion: EFPI提供了一种灵活且准确的足球阵型识别方法，适用于多种时间尺度的战术分析。

Abstract: Understanding team formations and player positioning is crucial for tactical
analysis in football (soccer). This paper presents a flexible method for
formation recognition and player position assignment in football using
predefined static formation templates and cost minimization from spatiotemporal
tracking data, called EFPI. Our approach employs linear sum assignment to
optimally match players to positions within a set of template formations by
minimizing the total distance between actual player locations and template
positions, subsequently selecting the formation with the lowest assignment
cost. To improve accuracy, we scale actual player positions to match the
dimensions of these formation templates in both width and length. While the
method functions effectively on individual frames, it extends naturally to
larger game segments such as complete periods, possession sequences or specific
intervals (e.g. 10 second intervals, 5 minute intervals etc.). Additionally, we
incorporate an optional stability parameter that prevents unnecessary formation
changes when assignment costs differ only marginally between time segments.
EFPI is available as open-source code through the unravelsports Python package.

</details>


### [638] [When Plants Respond: Electrophysiology and Machine Learning for Green Monitoring Systems](https://arxiv.org/abs/2506.23872)
*Eduard Buss,Till Aust,Heiko Hamann*

Main category: cs.LG

Relevance: 20.0

TL;DR: 论文提出了一种基于植物可穿戴设备的生物混合系统，用于监测植物电生理活动，并通过AutoML分析数据，实现了高精度的环境条件分类。


<details>
  <summary>Details</summary>
Motivation: 利用植物作为自然传感器，结合人工设备，开发可持续的环境监测系统。

Method: 在常春藤上安装PhytoNode设备，记录电生理活动，并在户外环境中收集数据，使用AutoML进行分析。

Result: 分类模型在二元任务中达到95%的宏F1分数，AutoML优于手动调优。

Conclusion: 该生物混合系统为可持续环境监测提供了可扩展的解决方案。

Abstract: Living plants, while contributing to ecological balance and climate
regulation, also function as natural sensors capable of transmitting
information about their internal physiological states and surrounding
conditions. This rich source of data provides potential for applications in
environmental monitoring and precision agriculture. With integration into
biohybrid systems, we establish novel channels of physiological signal flow
between living plants and artificial devices. We equipped *Hedera helix* with a
plant-wearable device called PhytoNode to continuously record the plant's
electrophysiological activity. We deployed plants in an uncontrolled outdoor
environment to map electrophysiological patterns to environmental conditions.
Over five months, we collected data that we analyzed using state-of-the-art and
automated machine learning (AutoML). Our classification models achieve high
performance, reaching macro F1 scores of up to 95 percent in binary tasks.
AutoML approaches outperformed manual tuning, and selecting subsets of
statistical features further improved accuracy. Our biohybrid living system
monitors the electrophysiology of plants in harsh, real-world conditions. This
work advances scalable, self-sustaining, and plant-integrated living biohybrid
systems for sustainable environmental monitoring.

</details>


### [639] [Physics-Embedded Neural Networks for sEMG-based Continuous Motion Estimation](https://arxiv.org/abs/2506.22459)
*Wending Heng,Chaoyuan Liang,Yihui Zhao,Zhiqiang Zhang,Glen Cooper,Zhenhong Li*

Main category: eess.SP

Relevance: 20.0

TL;DR: 论文提出了一种结合物理嵌入和数据驱动的神经网络（PENN），用于从表面肌电信号（sEMG）解码人体运动意图，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有sEMG运动估计方法依赖难以校准的特定对象肌肉骨骼模型或缺乏生理一致性的纯数据驱动模型。

Method: PENN结合可解释的肌肉骨骼前向动力学与数据驱动的残差学习，采用递归时间结构和轻量级卷积神经网络进行残差校正，并使用两阶段训练策略。

Result: 在六名健康受试者上的实验表明，PENN在RMSE和R²指标上优于基线方法。

Conclusion: PENN在保持生理一致性的同时实现了高精度运动估计。

Abstract: Accurately decoding human motion intentions from surface electromyography
(sEMG) is essential for myoelectric control and has wide applications in
rehabilitation robotics and assistive technologies. However, existing
sEMG-based motion estimation methods often rely on subject-specific
musculoskeletal (MSK) models that are difficult to calibrate, or purely
data-driven models that lack physiological consistency. This paper introduces a
novel Physics-Embedded Neural Network (PENN) that combines interpretable MSK
forward-dynamics with data-driven residual learning, thereby preserving
physiological consistency while achieving accurate motion estimation. The PENN
employs a recursive temporal structure to propagate historical estimates and a
lightweight convolutional neural network for residual correction, leading to
robust and temporally coherent estimations. A two-phase training strategy is
designed for PENN. Experimental evaluations on six healthy subjects show that
PENN outperforms state-of-the-art baseline methods in both root mean square
error (RMSE) and $R^2$ metrics.

</details>


### [640] [Service Placement in Small Cell Networks Using Distributed Best Arm Identification in Linear Bandits](https://arxiv.org/abs/2506.22480)
*Mariam Yahya,Aydin Sezgin,Setareh Maghsudi*

Main category: cs.NI

Relevance: 20.0

TL;DR: 论文提出了一种分布式多智能体最佳臂识别算法，用于解决小蜂窝网络中服务放置问题，以减少用户延迟。


<details>
  <summary>Details</summary>
Motivation: 小蜂窝网络中，用户依赖计算密集型服务，但云访问延迟高。多接入边缘计算（MEC）通过将计算资源靠近用户来降低延迟，但边缘容量有限，需动态决定服务放置。

Method: 将服务需求建模为服务属性的线性函数，服务放置任务建模为线性多臂老虎机问题，提出分布式自适应多智能体最佳臂识别算法。

Result: 仿真表明算法能以所需置信度识别最优服务，并实现接近最优的加速。

Conclusion: 算法在理论分析和仿真中表现良好，适用于动态网络条件下的服务放置问题。

Abstract: As users in small cell networks increasingly rely on computation-intensive
services, cloud-based access often results in high latency. Multi-access edge
computing (MEC) mitigates this by bringing computational resources closer to
end users, with small base stations (SBSs) serving as edge servers to enable
low-latency service delivery. However, limited edge capacity makes it
challenging to decide which services to deploy locally versus in the cloud,
especially under unknown service demand and dynamic network conditions. To
tackle this problem, we model service demand as a linear function of service
attributes and formulate the service placement task as a linear bandit problem,
where SBSs act as agents and services as arms. The goal is to identify the
service that, when placed at the edge, offers the greatest reduction in total
user delay compared to cloud deployment. We propose a distributed and adaptive
multi-agent best-arm identification (BAI) algorithm under a fixed-confidence
setting, where SBSs collaborate to accelerate learning. Simulations show that
our algorithm identifies the optimal service with the desired confidence and
achieves near-optimal speedup, as the number of learning rounds decreases
proportionally with the number of SBSs. We also provide theoretical analysis of
the algorithm's sample complexity and communication overhead.

</details>


### [641] [MENGLAN: Multiscale Enhanced Nonparametric Gas Analyzer with Lightweight Architecture and Networks](https://arxiv.org/abs/2506.22490)
*Zhenke Duan,Jiqun Pan,Jiani Tu*

Main category: eess.SP

Relevance: 20.0

TL;DR: MENGLAN是一种多尺度增强非参数气体分析仪，用于实时、轻量级和高精度的乙烯浓度预测，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统乙烯浓度检测方法成本高且复杂，限制了实际应用，因此需要一种更高效、低成本的方法。

Method: MENGLAN结合了双流结构、混合多头注意力机制和特征再激活模块。

Result: MENGLAN在性能、计算需求和可部署性方面优于现有方法。

Conclusion: MENGLAN为乙烯浓度检测提供了一种高效、实用的解决方案。

Abstract: Accurate detection of ethylene concentrations in mixed gases is crucial in
chemical production for safety and health purposes. Traditional methods are
hindered by high cost and complexity, limiting their practical application.
This study proposes MENGLAN, a Multiscale Enhanced Nonparametric Gas Analyzer
that integrates a dual-stream structure, a Hybrid Multi-Head Attention
mechanism, and a Feature Reactivation Module to enable real-time, lightweight,
and high-precision ethylene concentration prediction. Results show that MENGLAN
achieves superior performance, reduced computational demand, and enhanced
deployability compared to existing methods.

</details>


### [642] [CN-SBM: Categorical Block Modelling For Primary and Residual Copy Number Variation](https://arxiv.org/abs/2506.22963)
*Kevin Lam,William Daniels,J Maxwell Douglas,Daniel Lai,Samuel Aparicio,Benjamin Bloem-Reddy,Yongjin Park*

Main category: stat.ML

Relevance: 20.0

TL;DR: 论文提出了一种名为CN-SBM的概率框架，用于基于离散拷贝数状态联合聚类样本和基因组区域，适用于癌症克隆进化的监测。


<details>
  <summary>Details</summary>
Motivation: 癌症是一种遗传性疾病，其克隆进化可以通过追踪基因组拷贝数变异来监测。现有的模型通常基于高斯或泊松假设，而CN-SBM则尊重离散的CNV数据特性，并捕捉亚群特异性模式。

Method: CN-SBM采用两阶段方法，将CNV数据分解为主要和残差成分，检测大规模染色体改变和精细异常。通过变分推断算法实现可扩展性。

Result: 在模拟和真实数据集上的测试表明，CN-SBM优于现有方法。应用于TCGA低级别胶质瘤数据时，揭示了临床相关的亚型和结构化残差变异，有助于患者生存分析分层。

Conclusion: CN-SBM是一个可解释、可扩展的CNV分析框架，对肿瘤异质性和预后具有直接意义。

Abstract: Cancer is a genetic disorder whose clonal evolution can be monitored by
tracking noisy genome-wide copy number variants. We introduce the Copy Number
Stochastic Block Model (CN-SBM), a probabilistic framework that jointly
clusters samples and genomic regions based on discrete copy number states using
a bipartite categorical block model. Unlike models relying on Gaussian or
Poisson assumptions, CN-SBM respects the discrete nature of CNV calls and
captures subpopulation-specific patterns through block-wise structure. Using a
two-stage approach, CN-SBM decomposes CNV data into primary and residual
components, enabling detection of both large-scale chromosomal alterations and
finer aberrations. We derive a scalable variational inference algorithm for
application to large cohorts and high-resolution data. Benchmarks on simulated
and real datasets show improved model fit over existing methods. Applied to
TCGA low-grade glioma data, CN-SBM reveals clinically relevant subtypes and
structured residual variation, aiding patient stratification in survival
analysis. These results establish CN-SBM as an interpretable, scalable
framework for CNV analysis with direct relevance for tumor heterogeneity and
prognosis.

</details>


### [643] [Hierarchical Decentralized Stochastic Control for Cyber-Physical Systems](https://arxiv.org/abs/2506.22971)
*Kesav Kazam Ramachandran Anantharaman,Rahul Meshram*

Main category: eess.SY

Relevance: 20.0

TL;DR: 论文提出了一种两时间尺度的分层分散控制架构，用于网络物理系统的控制，包含全局控制器和局部控制器，分别优化不同时间尺度的MDP问题。


<details>
  <summary>Details</summary>
Motivation: 研究网络物理系统的控制问题，通过分层分散架构提高系统的灵活性和效率。

Method: 提出COpt和FOpt两种优化框架，分别针对无限和有限时间范围的MDP问题，并分析其最优策略和值函数关系。

Result: 证明了两种框架下确定性最优策略的存在性，并提供了两种框架最优值函数差异的界限。

Conclusion: 分层分散架构在特定条件下能实现相同的最优值，为网络物理系统控制提供了新思路。

Abstract: This paper presents a two-timescale hierarchical decentralized architecture
for control of Cyber-Physical Systems. The architecture consists of $N$
independent sub-processes, a global controller, and $N$ local controllers, each
formulated as a Markov Decision Process (MDP). The global controller, operating
at a slower timescale optimizes the infinite-horizon discounted cumulative
reward under budget constraints. For the local controllers, operating at a
faster timescale, we propose two different optimization frameworks, namely the
COpt and FOpt. In the COpt framework, the local controller also optimizes an
infinite-horizon MDP, while in the FOpt framework, the local controller
optimizes a finite-horizon MDP. The FOpt framework mimics a federal structure,
where the local controllers have more autonomy in their decision making. First,
the existence of stationary deterministic optimal policies for both these
frameworks is established. Then, various relationships between the two
frameworks are studied, including a bound on the difference between the two
optimal value functions. Additionally, sufficiency conditions are provided such
that the two frameworks lead to the same optimal values.

</details>


### [644] [Learning Individual Reproductive Behavior from Aggregate Fertility Rates via Neural Posterior Estimation](https://arxiv.org/abs/2506.22607)
*Daniel Ciganda,Ignacio Campón,Iñaki Permanyer,Jakob H Macke*

Main category: stat.AP

Relevance: 10.0

TL;DR: 论文提出了一种基于贝叶斯框架和序列神经后验估计（SNPE）的方法，用于从生育率数据中推断个体行为参数。


<details>
  <summary>Details</summary>
Motivation: 生育率数据（ASFRs）的聚合性质掩盖了驱动生育趋势的个体行为机制，因此需要一种方法恢复这些机制。

Method: 结合个体生育过程模型和SNPE，从ASFRs和计划与非计划生育的年龄分布中推断八个行为与生物参数。

Result: 方法成功复现了观测到的生育率模式，并预测了未用于估计的微观行为分布（如首次性行为年龄、生育间隔等）。

Conclusion: 该方法支持行为明确的人口预测和构建人口数字孪生。

Abstract: While age-specific fertility rates (ASFRs) provide the most extensive record
of reproductive change, their aggregate nature masks the underlying behavioral
mechanisms that ultimately drive fertility trends. To recover these mechanisms,
we develop a likelihood-free Bayesian framework that couples an
individual-level model of the reproductive process with Sequential Neural
Posterior Estimation (SNPE). This allows us to infer eight behavioral and
biological parameters from just two aggregate series: ASFRs and the age-profile
of planned versus unplanned births. Applied to U.S. National Survey of Family
Growth cohorts and to Demographic and Health Survey cohorts from Colombia, the
Dominican Republic, and Peru, the method reproduces observed fertility
schedules and, critically, predicts out-of-sample micro-level distributions of
age at first sex, inter-birth intervals, and family-size ideals, none of which
inform the estimation step. Because the fitted model yields complete synthetic
life histories, it enables behaviorally explicit population forecasts and
supports the construction of demographic digital twins.

</details>


### [645] [Unsupervised Sparse Coding-based Spiking Neural Network for Real-time Spike Sorting](https://arxiv.org/abs/2506.24041)
*Alexis Melot,Sean U. N. Wood,Yannick Coffinier,Pierre Yger,Fabien Alibart*

Main category: cs.NE

Relevance: 10.0

TL;DR: 论文提出了一种名为Neuromorphic Sparse Sorter (NSS)的紧凑型两层脉冲神经网络，用于高效实时、低功耗的边缘设备上的尖峰排序。


<details>
  <summary>Details</summary>
Motivation: 解决脑机接口(BMIs)中实时、低功耗且高性能的尖峰排序问题。

Method: 利用局部竞争算法(LCA)进行稀疏编码，提取噪声事件中的相关特征，并通过自定义神经元模型实现多比特尖峰编码。

Result: 在模拟和真实信号测试中，NSS性能优于WaveClus3和PCA+KMeans，且在Loihi 2平台上表现更优。

Conclusion: NSS是一种高效、无监督的尖峰排序方法，适用于边缘设备。

Abstract: Spike sorting is a crucial step in decoding multichannel extracellular neural
signals, enabling the identification of individual neuronal activity. A key
challenge in brain-machine interfaces (BMIs) is achieving real-time, low-power
spike sorting at the edge while keeping high neural decoding performance. This
study introduces the Neuromorphic Sparse Sorter (NSS), a compact two-layer
spiking neural network optimized for efficient spike sorting. NSS leverages the
Locally Competitive Algorithm (LCA) for sparse coding to extract relevant
features from noisy events with reduced computational demands. NSS learns to
sort detected spike waveforms in an online fashion and operates entirely
unsupervised. To exploit multi-bit spike coding capabilities of neuromorphic
platforms like Intel's Loihi 2, a custom neuron model was implemented, enabling
flexible power-performance trade-offs via adjustable spike bit-widths.
Evaluations on simulated and real-world tetrode signals with biological drift
showed NSS outperformed established pipelines such as WaveClus3 and PCA+KMeans.
With 2-bit graded spikes, NSS on Loihi 2 outperformed NSS implemented with
leaky integrate-and-fire neuron and achieved an F1-score of 77% (+10%
improvement) while consuming 8.6mW (+1.65mW) when tested on a drifting
recording, with a computational processing time of 0.25ms (+60 us) per
inference.

</details>


### [646] [Interpretable Time Series Autoregression for Periodicity Quantification](https://arxiv.org/abs/2506.22895)
*Xinyu Chen,Vassilis Digalakis Jr,Lijun Ding,Dingyi Zhuang,Jinhua Zhao*

Main category: cs.LG

Relevance: 1.0

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Time series autoregression is a classical statistical model for capturing
auto-correlations and identifying temporal patterns such as periodicity and
seasonality. In this work, we propose a novel sparse autoregression framework
from an interpretable machine learning perspective and the model
interpretability for periodicity quantification is reinforced by $\ell_0$-norm
induced sparsity constraints. On the time-varying time series data, we
reformulate the sparse autoregression and convert the involved optimization
problem into a mixed-integer optimization (MIO). To accelerate it, we develop a
subspace pursuit based decision variable pruning (DVP) strategy to reduce the
search space. On the multidimensional time series that involves complicated
spatial and temporal dimensions, we propose a spatially- and time-varying
sparse autoregression model and resolve the corresponding MIO problem by
developing a two-stage optimization scheme. In particular, the proposed scheme
makes the model scalable to large problems even with millions of decision
variables. Empirically, we conduct extensive experiments to evaluate the
proposed models on real-world time series data. First, we demonstrate that the
MIO solver can be drastically accelerated through the DVP strategy, while
maintaining the same solution quality as a full MIO solver. Applying the
time-varying sparse autoregression model to ridesharing trip data, we uncover
both daily and weekly periodicities and reveal long-term changes in regularity
of human mobility. Second, we demonstrate the spatial patterns of yearly
seasonality in climate variable time series such as temperature and
precipitation across the past four decades, and our model allows to discover
dynamic climate patterns and identify climate phenomena such as El Nino in sea
surface temperature.

</details>


### [647] [Mirror Descent Policy Optimisation for Robust Constrained Markov Decision Processes](https://arxiv.org/abs/2506.23165)
*David Bossens,Atsushi Nitanda*

Main category: cs.LG

Relevance: 1.0

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Safety is an essential requirement for reinforcement learning systems. The
newly emerging framework of robust constrained Markov decision processes allows
learning policies that satisfy long-term constraints while providing guarantees
under epistemic uncertainty. This paper presents mirror descent policy
optimisation for robust constrained Markov decision processes (RCMDPs), making
use of policy gradient techniques to optimise both the policy (as a maximiser)
and the transition kernel (as an adversarial minimiser) on the Lagrangian
representing a constrained MDP. In the oracle-based RCMDP setting, we obtain an
$\mathcal{O}\left(\frac{1}{T}\right)$ convergence rate for the squared distance
as a Bregman divergence, and an $\mathcal{O}\left(e^{-T}\right)$ convergence
rate for entropy-regularised objectives. In the sample-based RCMDP setting, we
obtain an $\tilde{\mathcal{O}}\left(\frac{1}{T^{1/3}}\right)$ convergence rate.
Experiments confirm the benefits of mirror descent policy optimisation in
constrained and unconstrained optimisation, and significant improvements are
observed in robustness tests when compared to baseline policy optimisation
algorithms.

</details>


### [648] [Provably Efficient and Agile Randomized Q-Learning](https://arxiv.org/abs/2506.24005)
*He Wang,Xingyu Xu,Yuejie Chi*

Main category: cs.LG

Relevance: 1.0

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: While Bayesian-based exploration often demonstrates superior empirical
performance compared to bonus-based methods in model-based reinforcement
learning (RL), its theoretical understanding remains limited for model-free
settings. Existing provable algorithms either suffer from computational
intractability or rely on stage-wise policy updates which reduce responsiveness
and slow down the learning process. In this paper, we propose a novel variant
of Q-learning algorithm, refereed to as RandomizedQ, which integrates
sampling-based exploration with agile, step-wise, policy updates, for episodic
tabular RL. We establish an $\widetilde{O}(\sqrt{H^5SAT})$ regret bound, where
$S$ is the number of states, $A$ is the number of actions, $H$ is the episode
length, and $T$ is the total number of episodes. In addition, we present a
logarithmic regret bound under a mild positive sub-optimality condition on the
optimal Q-function. Empirically, RandomizedQ exhibits outstanding performance
compared to existing Q-learning variants with both bonus-based and
Bayesian-based exploration on standard benchmarks.

</details>
